[
  {
    "id": "arXiv:2110.11954",
    "title": "Variational Probabilistic Multi-Hypothesis Tracking",
    "abstract": "This paper proposes a novel multi-target tracking (MTT) algorithm for\nscenarios with arbitrary numbers of measurements per target. We propose the\nvariational probabilistic multi-hypothesis tracking (VPMHT) algorithm based on\nthe variational Bayesian expectation-maximisation (VBEM) algorithm to resolve\nthe MTT problem in the classic PMHT algorithm. With the introduction of\nvariational inference, the proposed VPMHT handles track-loss much better than\nthe conventional probabilistic multi-hypothesis tracking (PMHT) while\npreserving a similar or even better tracking accuracy. Extensive numerical\nsimulations are conducted to demonstrate the effectiveness of the proposed\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Shuoyuan Xu",
      "Hyo-Sang Shin",
      "Antonios Tsourdos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11954"
  },
  {
    "id": "arXiv:2110.11960",
    "title": "ReLACE: Reinforcement Learning Agent for Counterfactual Explanations of  Arbitrary Predictive Models",
    "abstract": "The demand for explainable machine learning (ML) models has been growing\nrapidly in recent years. Amongst the methods proposed to associate ML model\npredictions with human-understandable rationale, counterfactual explanations\nare one of the most popular. They consist of post-hoc rules derived from\ncounterfactual examples (CFs), i.e., modified versions of input samples that\nresult in alternative output responses from the predictive model to be\nexplained. However, existing CF generation strategies either exploit the\ninternals of specific models (e.g., random forests or neural networks), or\ndepend on each sample's neighborhood, which makes them hard to be generalized\nfor more complex models and inefficient for larger datasets. In this work, we\naim to overcome these limitations and introduce a model-agnostic algorithm to\ngenerate optimal counterfactual explanations. Specifically, we formulate the\nproblem of crafting CFs as a sequential decision-making task and then find the\noptimal CFs via deep reinforcement learning (DRL) with discrete-continuous\nhybrid action space. Differently from other techniques, our method is easily\napplied to any black-box model, as this resembles the environment that the DRL\nagent interacts with. In addition, we develop an algorithm to extract\nexplainable decision rules from the DRL agent's policy, so as to make the\nprocess of generating CFs itself transparent. Extensive experiments conducted\non several datasets have shown that our method outperforms existing CF\ngeneration baselines.",
    "descriptor": "",
    "authors": [
      "Ziheng Chen",
      "Fabrizio Silvestri",
      "Gabriele Tolomei",
      "He Zhu",
      "Jia Wang",
      "Hongshik Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11960"
  },
  {
    "id": "arXiv:2110.11981",
    "title": "How to Quantify Polarization in Models of Opinion Dynamics",
    "abstract": "It is widely believed that society is becoming increasingly polarized around\nimportant issues, a dynamic that does not align with common mathematical models\nof opinion formation in social networks. In particular, measures of\npolarization based on opinion variance are known to decrease over time in\nframeworks such as the popular DeGroot model. Complementing recent work that\nseeks to resolve this apparent inconsistency by modifying opinion models, we\ninstead resolve the inconsistency by proposing changes to how polarization is\nquantified.\nWe present a natural class of group-based polarization measures that capture\nthe extent to which opinions are clustered into distinct groups. Using\ntheoretical arguments and empirical evidence, we show that these group-based\nmeasures display interesting, non-monotonic dynamics, even in the simple\nDeGroot model. In particular, for many natural social networks, group-based\nmetrics can increase over time, and thereby correctly capture perceptions of\nincreasing polarization.\nOur results build on work by DeMarzo et al., who introduced a group-based\npolarization metric based on ideological alignment. We show that a central tool\nfrom that work, a limit analysis of individual opinions under the DeGroot\nmodel, can be extended to the dynamics of other group-based polarization\nmeasures, including established statistical measures like bimodality.\nWe also consider local measures of polarization that operationalize how\npolarization is perceived in a network setting. In conjunction with evidence\nfrom prior work that group-based measures better align with real-world\nperceptions of polarization, our work provides formal support for the use of\nthese measures in place of variance-based polarization in future studies of\nopinion dynamics.",
    "descriptor": "",
    "authors": [
      "Christopher Musco",
      "Indu Ramesh",
      "Johan Ugander",
      "R. Teal Witter"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11981"
  },
  {
    "id": "arXiv:2110.11984",
    "title": "Law Smells: Defining and Detecting Problematic Patterns in Legal  Drafting",
    "abstract": "Building on the computer science concept of code smells, we initiate the\nstudy of law smells, i.e., patterns in legal texts that pose threats to the\ncomprehensibility and maintainability of the law. With five intuitive law\nsmells as running examples - namely, duplicated phrase, long element, large\nreference tree, ambiguous syntax, and natural language obsession -, we develop\na comprehensive law smell taxonomy. This taxonomy classifies law smells by when\nthey can be detected, which aspects of law they relate to, and how they can be\ndiscovered. We introduce text-based and graph-based methods to identify\ninstances of law smells, confirming their utility in practice using the United\nStates Code as a test case. Our work demonstrates how ideas from software\nengineering can be leveraged to assess and improve the quality of legal code,\nthus drawing attention to an understudied area in the intersection of law and\ncomputer science and highlighting the potential of computational legal\ndrafting.",
    "descriptor": "\nComments: 36 pages, 11 figures\n",
    "authors": [
      "Corinna Coupette",
      "Dirk Hartung",
      "Janis Beckedorf",
      "Maximilian B\u00f6ther",
      "Daniel Martin Katz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11984"
  },
  {
    "id": "arXiv:2110.11986",
    "title": "Local, Interactive, and Actionable: a Pandemic Behavioral Nudge",
    "abstract": "The informational environment surrounding the Covid-19 pandemic has been\nwidely recognized as fragmented, politicized, and complex [1]. This has\nresulted in polarized public views regarding the veracity of scientific\ncommunication, the severity of the threat posed by the virus, and the necessity\nof nonpharmaceutical interventions (NPIs) which can slow the spread of\ninfections [2]. This paper describes CovidCommitment.org, an effort toward\nenhancing NPI adoption through the combination of a social behavioral\ncommitment device and interactive map-based visualizations of localized\ninfection data as tabulated via a 1-hourdrive-time isochrone. This paper\ndescribes the system design and presents a preliminary analysis of user\nbehavior within the system.",
    "descriptor": "",
    "authors": [
      "Alex Rich",
      "Cameron Yick",
      "David Gotz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11986"
  },
  {
    "id": "arXiv:2110.11987",
    "title": "Improving Robustness of Malware Classifiers using Adversarial Strings  Generated from Perturbed Latent Representations",
    "abstract": "In malware behavioral analysis, the list of accessed and created files very\noften indicates whether the examined file is malicious or benign. However,\nmalware authors are trying to avoid detection by generating random filenames\nand/or modifying used filenames with new versions of the malware. These changes\nrepresent real-world adversarial examples. The goal of this work is to generate\nrealistic adversarial examples and improve the classifier's robustness against\nthese attacks. Our approach learns latent representations of input strings in\nan unsupervised fashion and uses gradient-based adversarial attack methods in\nthe latent domain to generate adversarial examples in the input domain. We use\nthese examples to improve the classifier's robustness by training on the\ngenerated adversarial set of strings. Compared to classifiers trained only on\nperturbed latent vectors, our approach produces classifiers that are\nsignificantly more robust without a large trade-off in standard accuracy.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Strategic ML Workshop\n",
    "authors": [
      "Marek Galovic",
      "Branislav Bosansky",
      "Viliam Lisy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11987"
  },
  {
    "id": "arXiv:2110.11991",
    "title": "A Reinforcement Learning Approach to Parameter Selection for Distributed  Optimization in Power Systems",
    "abstract": "With the increasing penetration of distributed energy resources, distributed\noptimization algorithms have attracted significant attention for power systems\napplications due to their potential for superior scalability, privacy, and\nrobustness to a single point-of-failure. The Alternating Direction Method of\nMultipliers (ADMM) is a popular distributed optimization algorithm; however,\nits convergence performance is highly dependent on the selection of penalty\nparameters, which are usually chosen heuristically. In this work, we use\nreinforcement learning (RL) to develop an adaptive penalty parameter selection\npolicy for the AC optimal power flow (ACOPF) problem solved via ADMM with the\ngoal of minimizing the number of iterations until convergence. We train our RL\npolicy using deep Q-learning, and show that this policy can result in\nsignificantly accelerated convergence (up to a 59% reduction in the number of\niterations compared to existing, curvature-informed penalty parameter selection\nmethods). Furthermore, we show that our RL policy demonstrates promise for\ngeneralizability, performing well under unseen loading schemes as well as under\nunseen losses of lines and generators (up to a 50% reduction in iterations).\nThis work thus provides a proof-of-concept for using RL for parameter selection\nin ADMM for power systems applications.",
    "descriptor": "",
    "authors": [
      "Sihan Zeng",
      "Alyssa Kody",
      "Youngdae Kim",
      "Kibaek Kim",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11991"
  },
  {
    "id": "arXiv:2110.12002",
    "title": "Fairness in Missing Data Imputation",
    "abstract": "Missing data are ubiquitous in the era of big data and, if inadequately\nhandled, are known to lead to biased findings and have deleterious impact on\ndata-driven decision makings. To mitigate its impact, many missing value\nimputation methods have been developed. However, the fairness of these\nimputation methods across sensitive groups has not been studied. In this paper,\nwe conduct the first known research on fairness of missing data imputation. By\nstudying the performance of imputation methods in three commonly used datasets,\nwe demonstrate that unfairness of missing value imputation widely exists and\nmay be associated with multiple factors. Our results suggest that, in practice,\na careful investigation of related factors can provide valuable insights on\nmitigating unfairness associated with missing data imputation.",
    "descriptor": "\nComments: Accepted to ICML 2021 Workshop\n",
    "authors": [
      "Yiliang Zhang",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12002"
  },
  {
    "id": "arXiv:2110.12007",
    "title": "When to Prune? A Policy towards Early Structural Pruning",
    "abstract": "Pruning enables appealing reductions in network memory footprint and time\ncomplexity. Conventional post-training pruning techniques lean towards\nefficient inference while overlooking the heavy computation for training.\nRecent exploration of pre-training pruning at initialization hints on training\ncost reduction via pruning, but suffers noticeable performance degradation. We\nattempt to combine the benefits of both directions and propose a policy that\nprunes as early as possible during training without hurting performance.\nInstead of pruning at initialization, our method exploits initial dense\ntraining for few epochs to quickly guide the architecture, while constantly\nevaluating dominant sub-networks via neuron importance ranking. This unveils\ndominant sub-networks whose structures turn stable, allowing conventional\npruning to be pushed earlier into the training. To do this early, we further\nintroduce an Early Pruning Indicator (EPI) that relies on sub-network\narchitectural similarity and quickly triggers pruning when the sub-network's\narchitecture stabilizes. Through extensive experiments on ImageNet, we show\nthat EPI empowers a quick tracking of early training epochs suitable for\npruning, offering same efficacy as an otherwise ``oracle'' grid-search that\nscans through epochs and requires orders of magnitude more compute. Our method\nyields $1.4\\%$ top-1 accuracy boost over state-of-the-art pruning counterparts,\ncuts down training cost on GPU by $2.4\\times$, hence offers a new\nefficiency-accuracy boundary for network pruning during training.",
    "descriptor": "",
    "authors": [
      "Maying Shen",
      "Pavlo Molchanov",
      "Hongxu Yin",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12007"
  },
  {
    "id": "arXiv:2110.12009",
    "title": "Definition and Implications of the Digital Near-Death Experience: A  Theoretical Essay on Preliminary Empiricism",
    "abstract": "Purpose: People are increasingly adhering to social networking platforms\n(SNP), and this adhesion is often unreflective, which makes them alienate data,\nactions, and decisions to tech giants. This essay discusses what happens when,\neventually, someone chooses to cancel their participation in a large SNP.\nMethodology/design: This is a theoretical essay, whose narrative resembles a\ntheoretical-empirical manuscript, grounded on the author's experience and his\nsubjective perceptions regarding being out of the WhatsApp (nowadays, the main\nSNP instance in the world). Findings/highlights: This study proposes a\ndefinition and implications of the supposedly new \"digital near-death\nexperience\" concept, a metaphor for the classic near-death experience (NDE). A\nresearch agenda is also proposed. Limitations: The resulting propositions are\ngrounded on a set of assumptions, that if falsified, make the findings invalid.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Pedro Jacome de Moura Jr"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.12009"
  },
  {
    "id": "arXiv:2110.12010",
    "title": "ClimateBert: A Pretrained Language Model for Climate-Related Text",
    "abstract": "Over the recent years, large pretrained language models (LM) have\nrevolutionized the field of natural language processing (NLP). However, while\npretraining on general language has been shown to work very well for common\nlanguage, it has been observed that niche language poses problems. In\nparticular, climate-related texts include specific language that common LMs can\nnot represent accurately. We argue that this shortcoming of today's LMs limits\nthe applicability of modern NLP to the broad field of text processing of\nclimate-related texts. As a remedy, we propose ClimateBert, a transformer-based\nlanguage model that is further pretrained on over 1.6 million paragraphs of\nclimate-related texts, crawled from various sources such as common news,\nresearch articles, and climate reporting of companies. We find that\nClimateBertleads to a 46% improvement on a masked language model objective\nwhich, in turn, leads to lowering error rates by 3.57% to 35.71% for various\nclimate-related downstream tasks like text classification, sentiment analysis,\nand fact-checking.",
    "descriptor": "",
    "authors": [
      "Nicolas Webersinke",
      "Mathias Kraus",
      "Julia Anna Bingler",
      "Markus Leippold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12010"
  },
  {
    "id": "arXiv:2110.12012",
    "title": "RDD-Eclat: Approaches to Parallelize Eclat Algorithm on Spark RDD  Framework (Extended Version)",
    "abstract": "Frequent itemset mining (FIM) is a highly computational and data intensive\nalgorithm. Therefore, parallel and distributed FIM algorithms have been\ndesigned to process large volume of data in a reduced time. Recently, a number\nof FIM algorithms have been designed on Hadoop MapReduce, a distributed big\ndata processing framework. But, due to heavy disk I/O, MapReduce is found to be\ninefficient for the highly iterative FIM algorithms. Therefore, Spark, a more\nefficient distributed data processing framework, has been developed with\nin-memory computation and resilient distributed dataset (RDD) features to\nsupport the iterative algorithms. On this framework, Apriori and FP-Growth\nbased FIM algorithms have been designed on the Spark RDD framework, but\nEclat-based algorithm has not been explored yet. In this paper, RDD-Eclat, a\nparallel Eclat algorithm on the Spark RDD framework is proposed with its five\nvariants. The proposed algorithms are evaluated on the various benchmark\ndatasets, and the experimental results show that RDD-Eclat outperforms the\nSpark-based Apriori by many times. Also, the experimental results show the\nscalability of the proposed algorithms on increasing the number of cores and\nsize of the dataset.",
    "descriptor": "\nComments: This version is not published or communicated anywhere. arXiv admin note: substantial text overlap with arXiv:1912.06415\n",
    "authors": [
      "Pankaj Singh",
      "Sudhakar Singh",
      "P K Mishra",
      "Rakhi Garg"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12012"
  },
  {
    "id": "arXiv:2110.12014",
    "title": "Disturbance Bounds for Signal Temporal Logic Task Satisfaction: A  Dynamics Perspective",
    "abstract": "This letter offers a novel approach to Test and Evaluation of pre-existing\ncontrollers from a control barrier function and dynamics perspective. More\naptly, prior Test and Evaluation techniques tend to require apriori knowledge\nof a space of allowable disturbances. Our work, however, determines a two-norm\ndisturbance-bound rejectable by a system's controller without requiring\nspecific knowledge of these disturbances beforehand. The authors posit that\ndetermination of such a disturbance bound offers a better understanding of the\nrobustness with which a given controller achieves a specified task - as\nmotivated through a simple, linear-system example. Additionally, we show that\nour resulting disturbance bound is accurate through simulation of 1000\nrandomized trials in which a Segway-controller pair satisfies its specification\ndespite randomized perturbations within our identified bound.",
    "descriptor": "",
    "authors": [
      "Prithvi Akella",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12014"
  },
  {
    "id": "arXiv:2110.12018",
    "title": "Local-Global Associative Frame Assemble in Video Re-ID",
    "abstract": "Noisy and unrepresentative frames in automatically generated object bounding\nboxes from video sequences cause significant challenges in learning\ndiscriminative representations in video re-identification (Re-ID). Most\nexisting methods tackle this problem by assessing the importance of video\nframes according to either their local part alignments or global appearance\ncorrelations separately. However, given the diverse and unknown sources of\nnoise which usually co-exist in captured video data, existing methods have not\nbeen effective satisfactorily. In this work, we explore jointly both local\nalignments and global correlations with further consideration of their mutual\npromotion/reinforcement so to better assemble complementary discriminative\nRe-ID information within all the relevant frames in video tracklets.\nSpecifically, we concurrently optimise a local aligned quality (LAQ) module\nthat distinguishes the quality of each frame based on local alignments, and a\nglobal correlated quality (GCQ) module that estimates global appearance\ncorrelations. With the help of a local-assembled global appearance prototype,\nwe associate LAQ and GCQ to exploit their mutual complement. Extensive\nexperiments demonstrate the superiority of the proposed model against\nstate-of-the-art methods on five Re-ID benchmarks, including MARS, Duke-Video,\nDuke-SI, iLIDS-VID, and PRID2011.",
    "descriptor": "\nComments: British Machine Vision Conference (BMVC) 2021. Project at this http URL\n",
    "authors": [
      "Qilei Li",
      "Jiabo Huang",
      "Shaogang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12018"
  },
  {
    "id": "arXiv:2110.12020",
    "title": "Fairness Degrading Adversarial Attacks Against Clustering Algorithms",
    "abstract": "Clustering algorithms are ubiquitous in modern data science pipelines, and\nare utilized in numerous fields ranging from biology to facility location. Due\nto their widespread use, especially in societal resource allocation problems,\nrecent research has aimed at making clustering algorithms fair, with great\nsuccess. Furthermore, it has also been shown that clustering algorithms, much\nlike other machine learning algorithms, are susceptible to adversarial attacks\nwhere a malicious entity seeks to subvert the performance of the learning\nalgorithm. However, despite these known vulnerabilities, there has been no\nresearch undertaken that investigates fairness degrading adversarial attacks\nfor clustering. We seek to bridge this gap by formulating a generalized attack\noptimization problem aimed at worsening the group-level fairness of\ncentroid-based clustering algorithms. As a first step, we propose a fairness\ndegrading attack algorithm for k-median clustering that operates under a\nwhitebox threat model -- where the clustering algorithm, fairness notion, and\nthe input dataset are known to the adversary. We provide empirical results as\nwell as theoretical analysis for our simple attack algorithm, and find that the\naddition of the generated adversarial samples can lead to significantly lower\nfairness values. In this manner, we aim to motivate fairness degrading\nadversarial attacks as a direction for future research in fair clustering.",
    "descriptor": "\nComments: Accepted at AFCR workshop, NeurIPS 2021\n",
    "authors": [
      "Anshuman Chhabra",
      "Adish Singla",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.12020"
  },
  {
    "id": "arXiv:2110.12024",
    "title": "A Prototype-Oriented Framework for Unsupervised Domain Adaptation",
    "abstract": "Existing methods for unsupervised domain adaptation often rely on minimizing\nsome statistical distance between the source and target samples in the latent\nspace. To avoid the sampling variability, class imbalance, and data-privacy\nconcerns that often plague these methods, we instead provide a memory and\ncomputation-efficient probabilistic framework to extract class prototypes and\nalign the target features with them. We demonstrate the general applicability\nof our method on a wide range of scenarios, including single-source,\nmulti-source, class-imbalance, and source-private domain adaptation. Requiring\nno additional model parameters and having a moderate increase in computation\nover the source model alone, the proposed method achieves competitive\nperformance with state-of-the-art methods.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Korawat Tanwisuth",
      "Xinjie Fan",
      "Huangjie Zheng",
      "Shujian Zhang",
      "Hao Zhang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12024"
  },
  {
    "id": "arXiv:2110.12025",
    "title": "Interaction and Conflict Management in AI-assisted Operational Control  Loops in 6G",
    "abstract": "This paper studies autonomous and AI-assisted control loops (ACLs) in the\nnext generation of wireless networks in the lens of multi-agent environments.\nWe will study the diverse interactions and conflict management among these\nloops. We propose \"interaction and conflict management\" (ICM) modules to\nachieve coherent, consistent and interactions among these ACLs. We introduce\nthree categories of ACLs based on their sizes, their cooperative and\ncompetitive behaviors, and their sharing of datasets and models. These\ncategories help to introduce conflict resolution and interaction management\nmechanisms for ICM. Using Kubernetes, we present an implementation of ICM to\nremove the conflicts in the scheduling and rescheduling of Pods for different\nACLs in networks.",
    "descriptor": "",
    "authors": [
      "Saeedeh Parsaeefard",
      "Pooyan Habibi",
      "Alberto Leon Garcia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12025"
  },
  {
    "id": "arXiv:2110.12033",
    "title": "A Simple Baseline for Low-Budget Active Learning",
    "abstract": "Active learning focuses on choosing a subset of unlabeled data to be labeled.\nHowever, most such methods assume that a large subset of the data can be\nannotated. We are interested in low-budget active learning where only a small\nsubset (e.g., 0.2% of ImageNet) can be annotated. Instead of proposing a new\nquery strategy to iteratively sample batches of unlabeled data given an initial\npool, we learn rich features by an off-the-shelf self-supervised learning\nmethod only once and then study the effectiveness of different sampling\nstrategies given a low budget on a variety of datasets as well as ImageNet\ndataset. We show that although the state-of-the-art active learning methods\nwork well given a large budget of data labeling, a simple k-means clustering\nalgorithm can outperform them on low budgets. We believe this method can be\nused as a simple baseline for low-budget active learning on image\nclassification. Code is available at:\nhttps://github.com/UCDvision/low-budget-al",
    "descriptor": "\nComments: 11 pages, 13 tables\n",
    "authors": [
      "Kossar Pourahmadi",
      "Parsa Nooralinejad",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12033"
  },
  {
    "id": "arXiv:2110.12035",
    "title": "Distance-wise Prototypical Graph Neural Network in Node Imbalance  Classification",
    "abstract": "Recent years have witnessed the significant success of applying graph neural\nnetworks (GNNs) in learning effective node representations for classification.\nHowever, current GNNs are mostly built under the balanced data-splitting, which\nis inconsistent with many real-world networks where the number of training\nnodes can be extremely imbalanced among the classes. Thus, directly utilizing\ncurrent GNNs on imbalanced data would generate coarse representations of nodes\nin minority classes and ultimately compromise the classification performance.\nThis therefore portends the importance of developing effective GNNs for\nhandling imbalanced graph data. In this work, we propose a novel Distance-wise\nPrototypical Graph Neural Network (DPGNN), which proposes a class\nprototype-driven training to balance the training loss between majority and\nminority classes and then leverages distance metric learning to differentiate\nthe contributions of different dimensions of representations and fully encode\nthe relative position of each node to each class prototype. Moreover, we design\na new imbalanced label propagation mechanism to derive extra supervision from\nunlabeled nodes and employ self-supervised learning to smooth representations\nof adjacent nodes while separating inter-class prototypes. Comprehensive node\nclassification experiments and parameter analysis on multiple networks are\nconducted and the proposed DPGNN almost always significantly outperforms all\nother baselines, which demonstrates its effectiveness in imbalanced node\nclassification. The implementation of DPGNN is available at\n\\url{https://github.com/YuWVandy/DPGNN}.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Charu Aggarwal",
      "Tyler Derr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12035"
  },
  {
    "id": "arXiv:2110.12036",
    "title": "Recursive Causal Structure Learning in the Presence of Latent Variables  and Selection Bias",
    "abstract": "We consider the problem of learning the causal MAG of a system from\nobservational data in the presence of latent variables and selection bias.\nConstraint-based methods are one of the main approaches for solving this\nproblem, but the existing methods are either computationally impractical when\ndealing with large graphs or lacking completeness guarantees. We propose a\nnovel computationally efficient recursive constraint-based method that is sound\nand complete. The key idea of our approach is that at each iteration a specific\ntype of variable is identified and removed. This allows us to learn the\nstructure efficiently and recursively, as this technique reduces both the\nnumber of required conditional independence (CI) tests and the size of the\nconditioning sets. The former substantially reduces the computational\ncomplexity, while the latter results in more reliable CI tests. We provide an\nupper bound on the number of required CI tests in the worst case. To the best\nof our knowledge, this is the tightest bound in the literature. We further\nprovide a lower bound on the number of CI tests required by any\nconstraint-based method. The upper bound of our proposed approach and the lower\nbound at most differ by a factor equal to the number of variables in the worst\ncase. We provide experimental results to compare the proposed approach with the\nstate of the art on both synthetic and real-world structures.",
    "descriptor": "\nComments: 23 pages, 5 figures, NeurIPS 2021\n",
    "authors": [
      "Sina Akbari",
      "Ehsan Mokhtarian",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12036"
  },
  {
    "id": "arXiv:2110.12038",
    "title": "Characterizing Performance Inequity Across U.S. Ookla Speedtest Users",
    "abstract": "The Internet has become indispensable to daily activities, such as work,\neducation and health care. Many of these activities require Internet access\ndata rates that support real-time video conferencing. However, digital\ninequality persists across the United States, not only in who has access but in\nthe quality of that access. Speedtest by Ookla allows users to run network\ndiagnostic tests to better understand the current performance of their network.\nIn this work, we leverage an Internet performance dataset from Ookla, together\nwith an ESRI demographic dataset, to conduct a comprehensive analysis that\ncharacterizes performance differences between Speedtest users across the U.S.\nOur analysis shows that median download speeds for Speedtest users can differ\nby over 150Mbps between states. Further, there are important distinctions\nbetween user categories. For instance, all but one state showed statistically\nsignificant differences in performance between Speedtest users in urban and\nrural areas. The difference also exists in urban areas between high and low\nincome users in 27 states. Our analysis reveals that states that demonstrate\nthis disparity in Speedtest results are geographically bigger, more populous\nand have a wider dispersion of median household income. We conclude by\nhighlighting several challenges to the complex problem space of digital\ninequality characterization and provide recommendations for furthering research\non this topic.",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables\n",
    "authors": [
      "Udit Paul",
      "Jiamo Liu",
      "Vivek Adarsh",
      "Mengyang Gu",
      "Arpit Gupta",
      "Elizabeth Belding"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.12038"
  },
  {
    "id": "arXiv:2110.12039",
    "title": "Generative Adversarial Networks for Non-Raytraced Global Illumination on  Older GPU Hardware",
    "abstract": "We give an overview of the different rendering methods and we demonstrate\nthat the use of a Generative Adversarial Networks (GAN) for Global Illumination\n(GI) gives a superior quality rendered image to that of a rasterisations image.\nWe utilise the Pix2Pix architecture and specify the hyper-parameters and\nmethodology used to mimic ray-traced images from a set of input features. We\nalso demonstrate that the GANs quality is comparable to the quality of the\nray-traced images, but is able to produce the image, at a fraction of the time.",
    "descriptor": "\nComments: 5 pages,7 figure\n",
    "authors": [
      "Jared Harris-Dewey",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12039"
  },
  {
    "id": "arXiv:2110.12052",
    "title": "On the Tractability of Neural Causal Inference",
    "abstract": "Roth (1996) proved that any form of marginal inference with probabilistic\ngraphical models (e.g. Bayesian Networks) will at least be NP-hard. Introduced\nand extensively investigated in the past decade, the neural probabilistic\ncircuits known as sum-product network (SPN) offers linear time complexity. On\nanother note, research around neural causal models (NCM) recently gained\ntraction, demanding a tighter integration of causality for machine learning. To\nthis end, we present a theoretical investigation of if, when, how and under\nwhat cost tractability occurs for different NCM. We prove that SPN-based causal\ninference is generally tractable, opposed to standard MLP-based NCM. We further\nintroduce a new tractable NCM-class that is efficient in inference and fully\nexpressive in terms of Pearl's Causal Hierarchy. Our comparative empirical\nillustration on simulations and standard benchmarks validates our theoretical\nproofs.",
    "descriptor": "\nComments: Main paper: 8 pages, References: 2 pages, Appendix: 5 pages. Figures: 5 main, 2 appendix\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12052"
  },
  {
    "id": "arXiv:2110.12053",
    "title": "Towards Dynamic Consistency Checking in Goal-directed Predicate Answer  Set Programming",
    "abstract": "Goal-directed evaluation of Answer Set Programs is gaining traction thanks to\nits amenability to create AI systems that can, due to the evaluation mechanism\nused, generate explanations and justifications. s(CASP) is one of these systems\nand has been already used to write reasoning systems in several fields. It\nprovides enhanced expressiveness w.r.t. other ASP systems due to its ability to\nuse constraints, data structures, and unbound variables natively. However, the\nperformance of existing s(CASP) implementations is not on par with other ASP\nsystems: model consistency is checked once models have been generated, in\nkeeping with the generate-and-test paradigm. In this work, we present a\nvariation of the top-down evaluation strategy, termed Dynamic Consistency\nChecking, which interleaves model generation and consistency checking. This\nmakes it possible to determine when a literal is not compatible with the\ndenials associated to the global constraints in the program, prune the current\nexecution branch, and choose a different alternative. This strategy is\nspecially (but not exclusively) relevant in problems with a high combinatorial\ncomponent. We have experimentally observed speedups of up to 90x w.r.t. the\nstandard versions of s(CASP).",
    "descriptor": "\nComments: Submitted to PADL'22. arXiv admin note: text overlap with arXiv:2106.14566\n",
    "authors": [
      "Joaqu\u00edn Arias",
      "Manuel Carro",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12053"
  },
  {
    "id": "arXiv:2110.12059",
    "title": "Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid  Precoding",
    "abstract": "In this paper, we propose an end-to-end deep learning-based joint transceiver\ndesign algorithm for millimeter wave (mmWave) massive multiple-input\nmultiple-output (MIMO) systems, which consists of deep neural network\n(DNN)-aided pilot training, channel feedback, and hybrid analog-digital (HAD)\nprecoding. Specifically, we develop a DNN architecture that maps the received\npilots into feedback bits at the receiver, and then further maps the feedback\nbits into the hybrid precoder at the transmitter. To reduce the signaling\noverhead and channel state information (CSI) mismatch caused by the\ntransmission delay, a two-timescale DNN composed of a long-term DNN and a\nshort-term DNN is developed. The analog precoders are designed by the long-term\nDNN based on the CSI statistics and updated once in a frame consisting of a\nnumber of time slots. In contrast, the digital precoders are optimized by the\nshort-term DNN at each time slot based on the estimated low-dimensional\nequivalent CSI matrices. A two-timescale training method is also developed for\nthe proposed DNN with a binary layer. We then analyze the generalization\nability and signaling overhead for the proposed DNN based algorithm. Simulation\nresults show that our proposed technique significantly outperforms conventional\nschemes in terms of bit-error rate performance with reduced signaling overhead\nand shorter pilot sequences.",
    "descriptor": "\nComments: 18 pages, 26 figures\n",
    "authors": [
      "Qiyu Hu",
      "Yunlong Cai",
      "Kai Kang",
      "Guanding Yu",
      "Jakob Hoydis",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12059"
  },
  {
    "id": "arXiv:2110.12062",
    "title": "DeepAg: Deep Learning Approach for Measuring the Effects of Outlier  Events on Agricultural Production and Policy",
    "abstract": "Quantitative metrics that measure the global economy's equilibrium have\nstrong and interdependent relationships with the agricultural supply chain and\ninternational trade flows. Sudden shocks in these processes caused by outlier\nevents such as trade wars, pandemics, or weather can have complex effects on\nthe global economy. In this paper, we propose a novel framework, namely:\nDeepAg, that employs econometrics and measures the effects of outlier events\ndetection using Deep Learning (DL) to determine relationships between\ncommonplace financial indices (such as the DowJones), and the production values\nof agricultural commodities (such as Cheese and Milk). We employed a DL\ntechnique called Long Short-Term Memory (LSTM) networks successfully to predict\ncommodity production with high accuracy and also present five popular models\n(regression and boosting) as baselines to measure the effects of outlier\nevents. The results indicate that DeepAg with outliers' considerations (using\nIsolation Forests) outperforms baseline models, as well as the same model\nwithout outliers detection. Outlier events make a considerable impact when\npredicting commodity production with respect to financial indices. Moreover, we\npresent the implications of DeepAg on public policy, provide insights for\npolicymakers and farmers, and for operational decisions in the agricultural\necosystem. Data are collected, models developed, and the results are recorded\nand presented.",
    "descriptor": "\nComments: Presented at AAAI FSS-21: Artificial Intelligence in Government and Public Sector, Washington, DC, USA\n",
    "authors": [
      "Sai Gurrapu",
      "Feras A. Batarseh",
      "Pei Wang",
      "Md Nazmul Kabir Sikder",
      "Nitish Gorentala",
      "Gopinath Munisamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12062"
  },
  {
    "id": "arXiv:2110.12064",
    "title": "Causal Effect Identification with Context-specific Independence  Relations of Control Variables",
    "abstract": "We study the problem of causal effect identification from observational\ndistribution given the causal graph and some context-specific independence\n(CSI) relations. It was recently shown that this problem is NP-hard, and while\na sound algorithm to learn the causal effects is proposed in Tikka et al.\n(2019), no complete algorithm for the task exists. In this work, we propose a\nsound and complete algorithm for the setting when the CSI relations are limited\nto observed nodes with no parents in the causal graph. One limitation of the\nstate of the art in terms of its applicability is that the CSI relations among\nall variables, even unobserved ones, must be given (as opposed to learned).\nInstead, We introduce a set of graphical constraints under which the CSI\nrelations can be learned from mere observational distribution. This expands the\nset of identifiable causal effects beyond the state of the art.",
    "descriptor": "\nComments: 9 pages, 4 figures, 2 algorithms, 1 table\n",
    "authors": [
      "Ehsan Mokhtarian",
      "Fateme Jamshidi",
      "Jalal Etesami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12064"
  },
  {
    "id": "arXiv:2110.12066",
    "title": "The Causal Loss: Driving Correlation to Imply Causation",
    "abstract": "Most algorithms in classical and contemporary machine learning focus on\ncorrelation-based dependence between features to drive performance. Although\nsuccess has been observed in many relevant problems, these algorithms fail when\nthe underlying causality is inconsistent with the assumed relations. We propose\na novel model-agnostic loss function called Causal Loss that improves the\ninterventional quality of the prediction using an intervened neural-causal\nregularizer. In support of our theoretical results, our experimental\nillustration shows how causal loss bestows a non-causal associative model (like\na standard neural net or decision tree) with interventional capabilities.",
    "descriptor": "\nComments: Main paper: 8 pages, References: 2 pages, Appendix: 3 pages. Figures: 4 main, 4 appendix. Tables: 2 main\n",
    "authors": [
      "Moritz Willig",
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12066"
  },
  {
    "id": "arXiv:2110.12072",
    "title": "How and When Adversarial Robustness Transfers in Knowledge Distillation?",
    "abstract": "Knowledge distillation (KD) has been widely used in teacher-student training,\nwith applications to model compression in resource-constrained deep learning.\nCurrent works mainly focus on preserving the accuracy of the teacher model.\nHowever, other important model properties, such as adversarial robustness, can\nbe lost during distillation. This paper studies how and when the adversarial\nrobustness can be transferred from a teacher model to a student model in KD. We\nshow that standard KD training fails to preserve adversarial robustness, and we\npropose KD with input gradient alignment (KDIGA) for remedy. Under certain\nassumptions, we prove that the student model using our proposed KDIGA can\nachieve at least the same certified robustness as the teacher model. Our\nexperiments of KD contain a diverse set of teacher and student models with\nvarying network architectures and sizes evaluated on ImageNet and CIFAR-10\ndatasets, including residual neural networks (ResNets) and vision transformers\n(ViTs). Our comprehensive analysis shows several novel insights that (1) With\nKDIGA, students can preserve or even exceed the adversarial robustness of the\nteacher model, even when their models have fundamentally different\narchitectures; (2) KDIGA enables robustness to transfer to pre-trained\nstudents, such as KD from an adversarially trained ResNet to a pre-trained ViT,\nwithout loss of clean accuracy; and (3) Our derived local linearity bounds for\ncharacterizing adversarial robustness in KD are consistent with the empirical\nresults.",
    "descriptor": "",
    "authors": [
      "Rulin Shao",
      "Jinfeng Yi",
      "Pin-Yu Chen",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12072"
  },
  {
    "id": "arXiv:2110.12076",
    "title": "Applications of Generative Adversarial Networks in Anomaly Detection: A  Systematic Literature Review",
    "abstract": "Anomaly detection has become an indispensable tool for modern society,\napplied in a wide range of applications, from detecting fraudulent transactions\nto malignant brain tumours. Over time, many anomaly detection techniques have\nbeen introduced. However, in general, they all suffer from the same problem: a\nlack of data that represents anomalous behaviour. As anomalous behaviour is\nusually costly (or dangerous) for a system, it is difficult to gather enough\ndata that represents such behaviour. This, in turn, makes it difficult to\ndevelop and evaluate anomaly detection techniques. Recently, generative\nadversarial networks (GANs) have attracted a great deal of attention in anomaly\ndetection research, due to their unique ability to generate new data. In this\npaper, we present a systematic literature review of the applications of GANs in\nanomaly detection, covering 128 papers on the subject. The goal of this review\npaper is to analyze and summarize: (1) which anomaly detection techniques can\nbenefit from certain types of GANs, and how, (2) in which application domains\nGAN-assisted anomaly detection techniques have been applied, and (3) which\ndatasets and performance metrics have been used to evaluate these techniques.\nOur study helps researchers and practitioners to find the most suitable\nGAN-assisted anomaly detection technique for their application. In addition, we\npresent a research roadmap for future studies in this area.",
    "descriptor": "\nComments: 34 pages,5 figures\n",
    "authors": [
      "Mikael Sabuhi",
      "Ming Zhou",
      "Cor-Paul Bezemer",
      "Petr Musilek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12076"
  },
  {
    "id": "arXiv:2110.12078",
    "title": "Feasibility of Remote Landmark Identification for Cricothyrotomy Using  Robotic Palpation",
    "abstract": "Cricothyrotomy is a life-saving emergency intervention that secures an\nalternate airway route after a neck injury or obstruction. The procedure starts\nwith identifying the correct location (the cricothyroid membrane) for creating\nan incision to insert an endotracheal tube. This location is determined using a\ncombination of visual and palpation cues. Enabling robot-assisted remote\ncricothyrotomy may extend this life-saving procedure to injured soldiers or\npatients who may not be readily accessible for on-site intervention during\nsearch-and-rescue scenarios. As a first step towards achieving this goal, this\npaper explores the feasibility of palpation-assisted landmark identification\nfor cricothyrotomy. Using a cricothyrotomy training simulator, we explore\nseveral alternatives for in-situ remote localization of the cricothyroid\nmembrane. These alternatives include a) unaided telemanipulation, b)\ntelemanipulation with direct force feedback, c) telemanipulation with\nsuperimposed motion excitation for online stiffness estimation and display, and\nd) fully autonomous palpation scan initialized based on the user's\nunderstanding of key anatomical landmarks. Using the manually digitized\ncricothyroid membrane location as ground truth, we compare these four methods\nfor accuracy and repeatability of identifying the landmark for cricothyrotomy,\ntime of completion, and ease of use. These preliminary results suggest that the\naccuracy of remote cricothyrotomy landmark identification is improved when the\nuser is aided with visual and force cues. They also show that, with proper user\ninitialization, landmark identification using remote palpation is feasible -\ntherefore satisfying a key pre-requisite for future robotic solutions for\nremote cricothyrotomy.",
    "descriptor": "\nComments: Accepted for publication in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'2021)\n",
    "authors": [
      "Neel Shihora",
      "Rashid M. Yasin",
      "Ryan Walsh",
      "Nabil Simaan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12078"
  },
  {
    "id": "arXiv:2110.12080",
    "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
    "abstract": "Goal-conditioned reinforcement learning (RL) can solve tasks in a wide range\nof domains, including navigation and manipulation, but learning to reach\ndistant goals remains a central challenge to the field. Learning to reach such\ngoals is particularly hard without any offline data, expert demonstrations, and\nreward shaping. In this paper, we propose an algorithm to solve the distant\ngoal-reaching task by using search at training time to automatically generate a\ncurriculum of intermediate states. Our algorithm, Classifier-Planning\n(C-Planning), frames the learning of the goal-conditioned policies as\nexpectation maximization: the E-step corresponds to planning an optimal\nsequence of waypoints using graph search, while the M-step aims to learn a\ngoal-conditioned policy to reach those waypoints. Unlike prior methods that\ncombine goal-conditioned RL with graph search, ours performs search only during\ntraining and not testing, significantly decreasing the compute costs of\ndeploying the learned policy. Empirically, we demonstrate that our method is\nmore sample efficient than prior methods. Moreover, it is able to solve very\nlong horizons manipulation and navigation tasks, tasks that prior\ngoal-conditioned methods and methods based on graph search fail to solve.",
    "descriptor": "",
    "authors": [
      "Tianjun Zhang",
      "Benjamin Eysenbach",
      "Ruslan Salakhutdinov",
      "Sergey Levine",
      "Joseph E. Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12080"
  },
  {
    "id": "arXiv:2110.12081",
    "title": "Off-policy Reinforcement Learning with Optimistic Exploration and  Distribution Correction",
    "abstract": "Improving sample efficiency of reinforcement learning algorithms requires\neffective exploration. Following the principle of $\\textit{optimism in the face\nof uncertainty}$, we train a separate exploration policy to maximize an\napproximate upper confidence bound of the critics in an off-policy actor-critic\nframework. However, this introduces extra differences between the replay buffer\nand the target policy in terms of their stationary state-action distributions.\nTo mitigate the off-policy-ness, we adapt the recently introduced DICE\nframework to learn a distribution correction ratio for off-policy actor-critic\ntraining. In particular, we correct the training distribution for both policies\nand critics. Empirically, we evaluate our proposed method in several\nchallenging continuous control tasks and show superior performance compared to\nstate-of-the-art methods. We also conduct extensive ablation studies to\ndemonstrate the effectiveness and the rationality of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Shuo Cheng",
      "Zhenyu Liao",
      "Huayan Wang",
      "William Yang Wang",
      "Qinxun Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12081"
  },
  {
    "id": "arXiv:2110.12084",
    "title": "CD&S Dataset: Handheld Imagery Dataset Acquired Under Field Conditions  for Corn Disease Identification and Severity Estimation",
    "abstract": "Accurate disease identification and its severity estimation is an important\nconsideration for disease management. Deep learning-based solutions for disease\nmanagement using imagery datasets are being increasingly explored by the\nresearch community. However, most reported studies have relied on imagery\ndatasets that were acquired under controlled lab conditions. As a result, such\nmodels lacked the ability to identify diseases in the field. Therefore, to\ntrain a robust deep learning model for field use, an imagery dataset was\ncreated using raw images acquired under field conditions using a handheld\nsensor and augmented images with varying backgrounds. The Corn Disease and\nSeverity (CD&S) dataset consisted of 511, 524, and 562, field acquired raw\nimages, corresponding to three common foliar corn diseases, namely Northern\nLeaf Blight (NLB), Gray Leaf Spot (GLS), and Northern Leaf Spot (NLS),\nrespectively. For training disease identification models, half of the imagery\ndata for each disease was annotated using bounding boxes and also used to\ngenerate 2343 additional images through augmentation using three different\nbackgrounds. For severity estimation, an additional 515 raw images for NLS were\nacquired and categorized into severity classes ranging from 1 (resistant) to 5\n(susceptible). Overall, the CD&S dataset consisted of 4455 total images\ncomprising of 2112 field images and 2343 augmented images.",
    "descriptor": "",
    "authors": [
      "Aanis Ahmad",
      "Dharmendra Saraswat",
      "Aly El Gamal",
      "Gurmukh Johal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12084"
  },
  {
    "id": "arXiv:2110.12087",
    "title": "Gaussian Process Sampling and Optimization with Approximate Upper and  Lower Bounds",
    "abstract": "Many functions have approximately-known upper and/or lower bounds,\npotentially aiding the modeling of such functions. In this paper, we introduce\nGaussian process models for functions where such bounds are (approximately)\nknown. More specifically, we propose the first use of such bounds to improve\nGaussian process (GP) posterior sampling and Bayesian optimization (BO). That\nis, we transform a GP model satisfying the given bounds, and then sample and\nweight functions from its posterior. To further exploit these bounds in BO\nsettings, we present bounded entropy search (BES) to select the point gaining\nthe most information about the underlying function, estimated by the GP\nsamples, while satisfying the output constraints. We characterize the sample\nvariance bounds and show that the decision made by BES is explainable. Our\nproposed approach is conceptually straightforward and can be used as a plug in\nextension to existing methods for GP posterior sampling and Bayesian\noptimization.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Vu Nguyen",
      "Marc Peter Deisenroth",
      "Michael A. Osborne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12087"
  },
  {
    "id": "arXiv:2110.12088",
    "title": "Learning with Noisy Labels Revisited: A Study Using Real-World Human  Annotations",
    "abstract": "Existing research on learning with noisy labels mainly focuses on synthetic\nlabel noise. Synthetic label noise, though has clean structures which greatly\nenable statistical analyses, often fails to model the real-world noise\npatterns. The recent literature has observed several efforts to offer\nreal-world noisy datasets, yet the existing efforts suffer from two caveats:\nfirstly, the lack of ground-truth verification makes it hard to theoretically\nstudy the property and treatment of real-world label noise. Secondly, these\nefforts are often of large scales, which may lead to unfair comparisons of\nrobust methods within reasonable and accessible computation power. To better\nunderstand real-world label noise, it is important to establish controllable\nand moderate-sized real-world noisy datasets with both ground-truth and noisy\nlabels. This work presents two new benchmark datasets (CIFAR-10N, CIFAR-100N),\nequipping the train dataset of CIFAR-10 and CIFAR-100 with human-annotated\nreal-world noisy labels that we collect from Amazon Mechanical Turk. We\nquantitatively and qualitatively show that real-world noisy labels follow an\ninstance-dependent pattern rather than the classically adopted class-dependent\nones. We then initiate an effort to benchmark a subset of existing solutions\nusing CIFAR-10N, CIFAR-100N. We next proceed to study the memorization of model\npredictions, which further illustrates the difference between human noise and\nclass-dependent synthetic noise. We show indeed the real-world noise patterns\nimpose new and outstanding challenges as compared to synthetic ones. These\nobservations require us to rethink the treatment of noisy labels, and we hope\nthe availability of these two datasets would facilitate the development and\nevaluation of future learning with noisy label solutions. The corresponding\ndatasets and the leaderboard are publicly available at\n\\url{this http URL}.",
    "descriptor": "",
    "authors": [
      "Jiaheng Wei",
      "Zhaowei Zhu",
      "Hao Cheng",
      "Tongliang Liu",
      "Gang Niu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12088"
  },
  {
    "id": "arXiv:2110.12090",
    "title": "Towards Demystifying Intra-Function Parallelism in Serverless Computing",
    "abstract": "Serverless computing offers a pay-per-use model with high elasticity and\nautomatic scaling for a wide range of applications. Since cloud providers\nabstract most of the underlying infrastructure, these services work similarly\nto black-boxes. As a result, users can influence the resources allocated to\ntheir functions, but might not be aware that they have to parallelize them to\nprofit from the additionally allocated virtual CPUs (vCPUs). In this paper, we\nanalyze the impact of parallelization within a single function and container\ninstance for AWS Lambda, Google Cloud Functions (GCF), and Google Cloud Run\n(GCR). We focus on compute-intensive workloads since they benefit greatly from\nparallelization. Furthermore, we investigate the correlation between the number\nof allocated CPU cores and vCPUs in serverless environments. Our results show\nthat the number of available cores to a function/container instance does not\nalways equal the number of allocated vCPUs. By parallelizing serverless\nworkloads, we observed cost savings up to 81% for AWS Lambda, 49% for GCF, and\n69.8% for GCR.",
    "descriptor": "\nComments: International Workshop on Serverless Computing (WoSC@Middleware 2021)\n",
    "authors": [
      "Michael Kiener",
      "Mohak Chadha",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.12090"
  },
  {
    "id": "arXiv:2110.12091",
    "title": "Contrastively Disentangled Sequential Variational Autoencoder",
    "abstract": "Self-supervised disentangled representation learning is a critical task in\nsequence modeling. The learnt representations contribute to better model\ninterpretability as well as the data generation, and improve the sample\nefficiency for downstream tasks. We propose a novel sequence representation\nlearning method, named Contrastively Disentangled Sequential Variational\nAutoencoder (C-DSVAE), to extract and separate the static (time-invariant) and\ndynamic (time-variant) factors in the latent space. Different from previous\nsequential variational autoencoder methods, we use a novel evidence lower bound\nwhich maximizes the mutual information between the input and the latent\nfactors, while penalizes the mutual information between the static and dynamic\nfactors. We leverage contrastive estimations of the mutual information terms in\ntraining, together with simple yet effective augmentation techniques, to\nintroduce additional inductive biases. Our experiments show that C-DSVAE\nsignificantly outperforms the previous state-of-the-art methods on multiple\nmetrics.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Junwen Bai",
      "Weiran Wang",
      "Carla Gomes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12091"
  },
  {
    "id": "arXiv:2110.12093",
    "title": "Circle Representation for Medical Object Detection",
    "abstract": "Box representation has been extensively used for object detection in computer\nvision. Such representation is efficacious but not necessarily optimized for\nbiomedical objects (e.g., glomeruli), which play an essential role in renal\npathology. In this paper, we propose a simple circle representation for medical\nobject detection and introduce CircleNet, an anchor-free detection framework.\nCompared with the conventional bounding box representation, the proposed\nbounding circle representation innovates in three-fold: (1) it is optimized for\nball-shaped biomedical objects; (2) The circle representation reduced the\ndegree of freedom compared with box representation; (3) It is naturally more\nrotation invariant. When detecting glomeruli and nuclei on pathological images,\nthe proposed circle representation achieved superior detection performance and\nbe more rotation-invariant, compared with the bounding box. The code has been\nmade publicly available: https://github.com/hrlblab/CircleNet",
    "descriptor": "\nComments: 10 pages, 8 figures, to be published in IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Ethan H. Nguyen",
      "Haichun Yang",
      "Ruining Deng",
      "Yuzhe Lu",
      "Zheyu Zhu",
      "Joseph T. Roland",
      "Le Lu",
      "Bennett A. Landman",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12093"
  },
  {
    "id": "arXiv:2110.12097",
    "title": "Integrated Task and Motion Planning for Safe Legged Navigation in  Partially Observable Environments",
    "abstract": "This study proposes a hierarchically integrated framework for safe task and\nmotion planning (TAMP) of bipedal locomotion in a partially observable\nenvironment with dynamic obstacles and uneven terrain. The high-level task\nplanner employs linear temporal logic (LTL) for a reactive game synthesis\nbetween the robot and its environment and provides a formal guarantee on\nnavigation safety and task completion. To address environmental partial\nobservability, a belief abstraction is employed at the high-level navigation\nplanner to estimate the dynamic obstacles' location when they are out of the\nrobot's local field of view. Accordingly, a synthesized action planner sends a\nset of locomotion actions including walking step, step height, and heading\nangle change, to the middle-level motion planner, while incorporating safe\nlocomotion specifications extracted from safety theorems based on a\nreduced-order model (ROM) of the locomotion process. The motion planner employs\nthe ROM to design safety criteria and a sampling algorithm to generate\nnon-periodic motion plans that accurately track high-level actions. To address\nexternal perturbations, this study also investigates safe sequential\ncomposition of the keyframe locomotion state and achieves robust transitions\nagainst external perturbations through reachability analysis. A set of\nROM-based hyperparameters are finally interpolated to design whole-body\nlocomotion gaits generated by trajectory optimization and validate the viable\ndeployment of the ROM-based TAMP to the full-body trajectory generation for a\n20-degrees-of-freedom Cassie bipedal robot designed by Agility Robotics. The\nproposed framework is validated by a set of scenarios in uneven, partially\nobservable environments with dynamical obstacles.",
    "descriptor": "\nComments: 19 pages, 16 figures\n",
    "authors": [
      "Abdulaziz Shamsah",
      "Jonas Warnke",
      "Zhaoyuan Gu",
      "Ye Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12097"
  },
  {
    "id": "arXiv:2110.12099",
    "title": "Strategically revealing intentions in General Lotto games",
    "abstract": "In this paper, we highlight scenarios in General Lotto games where there\nexist incentives to reveal one's intentions to an opponent. The General Lotto\ngame is a popular model of competitive resource allocation. We study a\nmulti-step extension where one player has the option to publicly pre-commit\nresources to battlefields before play begins. In response, the opponent decides\nwhich of these battlefields to secure by matching the pre-commitment with its\nown resources, and which of them to withdraw from entirely. They then engage in\na General Lotto game over the remaining set of battlefields. We show that the\nweaker-resource player never has an incentive to pre-commit, while a stronger\nplayer can have incentives to pre-commit. However, this is not necessarily true\nin settings where the battlefield valuations are asymmetric across players.\nThis setting is known to admit a richer set of outcomes, where multiple\npayoff-distinct equilibria can arise in simultaneous play. We show that\npre-committing in this environment can guarantee a payoff that exceeds the\nsecond-highest equilibrium payoff from simultaneous play. Our work highlights\nthe strategic role that revealing information plays can have in a variety of\nadversarial contexts.",
    "descriptor": "",
    "authors": [
      "Keith Paarporn",
      "Rahul Chandan",
      "Dan Kovenock",
      "Mahnoosh Alizadeh",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12099"
  },
  {
    "id": "arXiv:2110.12100",
    "title": "MTGLS: Multi-Task Gaze Estimation with Limited Supervision",
    "abstract": "Robust gaze estimation is a challenging task, even for deep CNNs, due to the\nnon-availability of large-scale labeled data. Moreover, gaze annotation is a\ntime-consuming process and requires specialized hardware setups. We propose\nMTGLS: a Multi-Task Gaze estimation framework with Limited Supervision, which\nleverages abundantly available non-annotated facial image data. MTGLS distills\nknowledge from off-the-shelf facial image analysis models, and learns strong\nfeature representations of human eyes, guided by three complementary auxiliary\nsignals: (a) the line of sight of the pupil (i.e. pseudo-gaze) defined by the\nlocalized facial landmarks, (b) the head-pose given by Euler angles, and (c)\nthe orientation of the eye patch (left/right eye). To overcome inherent noise\nin the supervisory signals, MTGLS further incorporates a noise distribution\nmodelling approach. Our experimental results show that MTGLS learns highly\ngeneralized representations which consistently perform well on a range of\ndatasets. Our proposed framework outperforms the unsupervised state-of-the-art\non CAVE (by 6.43%) and even supervised state-of-the-art methods on Gaze360 (by\n6.59%) datasets.",
    "descriptor": "",
    "authors": [
      "Shreya Ghosh",
      "Munawar Hayat",
      "Abhinav Dhall",
      "Jarrod Knibbe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12100"
  },
  {
    "id": "arXiv:2110.12106",
    "title": "HWTool: Fully Automatic Mapping of an Extensible C++ Image Processing  Language to Hardware",
    "abstract": "Implementing image processing algorithms using FPGAs or ASICs can improve\nenergy efficiency by orders of magnitude over optimized CPU, DSP, or GPU code.\nThese efficiency improvements are crucial for enabling new applications on\nmobile power-constrained devices, such as cell phones or AR/VR headsets.\nUnfortunately, custom hardware is commonly implemented using a waterfall\nprocess with time-intensive manual mapping and optimization phases. Thus, it\ncan take years for a new algorithm to make it all the way from an algorithm\ndesign to shipping silicon. Recent improvements in hardware design tools, such\nas C-to-gates High-Level Synthesis (HLS), can reduce design time, but still\nrequire manual tuning from hardware experts.\nIn this paper, we present HWTool, a novel system for automatically mapping\nimage processing and computer vision algorithms to hardware. Our system maps\nbetween two domains: HWImg, an extensible C++ image processing library\ncontaining common image processing and parallel computing operators, and\nRigel2, a library of optimized hardware implementations of HWImg's operators\nand backend Verilog compiler. We show how to automatically compile HWImg to\nRigel2, by solving for interfaces, hardware sizing, and FIFO buffer allocation.\nFinally, we map full-scale image processing applications like convolution,\noptical flow, depth from stereo, and feature descriptors to FPGA using our\nsystem. On these examples, HWTool requires on average only 11% more FPGA area\nthan hand-optimized designs (with manual FIFO allocation), and 33% more FPGA\narea than hand-optimized designs with automatic FIFO allocation, and performs\nsimilarly to HLS.",
    "descriptor": "",
    "authors": [
      "James Hegarty",
      "Omar Eldash",
      "Amr Suleiman",
      "Armin Alaghi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.12106"
  },
  {
    "id": "arXiv:2110.12108",
    "title": "ConformalLayers: A non-linear sequential neural network with associative  layers",
    "abstract": "Convolutional Neural Networks (CNNs) have been widely applied. But as the\nCNNs grow, the number of arithmetic operations and memory footprint also\nincrease. Furthermore, typical non-linear activation functions do not allow\nassociativity of the operations encoded by consecutive layers, preventing the\nsimplification of intermediate steps by combining them. We present a new\nactivation function that allows associativity between sequential layers of\nCNNs. Even though our activation function is non-linear, it can be represented\nby a sequence of linear operations in the conformal model for Euclidean\ngeometry. In this domain, operations like, but not limited to, convolution,\naverage pooling, and dropout remain linear. We take advantage of associativity\nto combine all the \"conformal layers\" and make the cost of inference constant\nregardless of the depth of the network.",
    "descriptor": "\nComments: Best Paper on Pattern Recognition and Related Field at SIBGRAPI 2021 -- 34th Conference on Graphics, Patterns and Images\n",
    "authors": [
      "Eduardo Vera Sousa",
      "Leandro A. F. Fernandes",
      "Cristina Nader Vasconcelos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12108"
  },
  {
    "id": "arXiv:2110.12111",
    "title": "Improve High Level Classification with a More Sensitive metric and  Optimization approach for Complex Network Building",
    "abstract": "Complex Networks are a good approach to find internal relationships and\nrepresent the structure of classes in a dataset then they are used for High\nLevel Classification. Previous works use K-Nearest Neighbors to build each\nComplex Network considering all the available samples. This paper introduces a\ndifferent creation of Complex Networks, considering only sample which belongs\nto each class. And metric is used to analyze the structure of Complex Networks,\nbesides an optimization approach to improve the performance is presented.\nExperiments are executed considering a cross validation process, the\noptimization approach is performed using grid search and Genetic Algorithm,\nthis process can improve the results up to 10%.",
    "descriptor": "",
    "authors": [
      "Josimar Chire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12111"
  },
  {
    "id": "arXiv:2110.12113",
    "title": "Multi-task Recurrent Neural Networks to Simultaneously Infer Mode and  Purpose in GPS Trajectories",
    "abstract": "Multi-task learning is assumed as a powerful inference method, specifically,\nwhere there is a considerable correlation between multiple tasks, predicting\nthem in an unique framework may enhance prediction results. This research\nchallenges this assumption by developing several single-task models to compare\ntheir results against multi-task learners to infer mode and purpose of trip\nfrom smartphone travel survey data collected as part of a smartphone-based\ntravel survey. GPS trajectory data along with socio-demographics and\ndestination-related characteristics are fed into a multi-input neural network\nframework to predict two outputs; mode and purpose. We deployed Recurrent\nNeural Networks (RNN) that are fed by sequential GPS trajectories. To process\nthe socio-demographics and destination-related characteristics, another neural\nnetwork, with different embedding and dense layers is used in parallel with RNN\nlayers in a multi-input multi-output framework. The results are compared\nagainst the single-task learners that classify mode and purpose independently.\nWe also investigate different RNN approaches such as Long-Short Term Memory\n(LSTM), Gated Recurrent Units (GRU) and Bi-directional Gated Recurrent Units\n(Bi-GRU). The best multi-task learner was a Bi-GRU model able to classify mode\nand purpose with an F1-measures of 84.33% and 78.28%, while the best\nsingle-task learner to infer mode of transport was a GRU model that achieved an\nF1-measure of 86.50%, and the best single-task Bi-GRU purpose detection model\nthat reached an F1-measure of 77.38%. While there's an assumption of higher\nperformance of multi-task over sing-task learners, the results of this study\ndoes not hold such an assumption and shows, in the context of mode and trip\npurpose inference from GPS trajectory data, a multi-task learning approach does\nnot bring any considerable advantage over single-task learners.",
    "descriptor": "",
    "authors": [
      "Ali Yazdizadeh",
      "Arash Kalatian",
      "Zachary Patterson",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12113"
  },
  {
    "id": "arXiv:2110.12115",
    "title": "Joint Task Offloading and Resource Allocation for IoT Edge Computing  with Sequential Task Dependency",
    "abstract": "Incorporating mobile edge computing (MEC) in the Internet of Things (IoT)\nenables resource-limited IoT devices to offload their computation tasks to a\nnearby edge server. In this paper, we investigate an IoT system assisted by the\nMEC technique with its computation task subjected to sequential task\ndependency, which is critical for video stream processing and other intelligent\napplications. To minimize energy consumption per IoT device while limiting task\nprocessing delay, task offloading strategy, communication resource, and\ncomputation resource are optimized jointly under both slow and fast fading\nchannels. In slow fading channels, an optimization problem is formulated, which\nis mixed-integer and non-convex. To solve this challenging problem, we\ndecompose it as a one-dimensional search of task offloading decision problem\nand a non-convex optimization problem with task offloading decision given.\nThrough mathematical manipulations, the non-convex problem is transformed to be\na convex one, which is shown to be solvable only with the simple Golden search\nmethod. In fast fading channels, optimal online policy depending on instant\nchannel state is derived. In addition, it is proved that the derived policy\nwill converge to the offline policy when channel coherence time is low, which\ncan help to save extra computation complexity. Numerical results verify the\ncorrectness of our analysis and the effectiveness of our proposed strategies\nover existing methods.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.12552\n",
    "authors": [
      "Xuming An",
      "Rongfei Fan",
      "Han Hu",
      "Ning Zhang",
      "Saman Atapattu",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12115"
  },
  {
    "id": "arXiv:2110.12118",
    "title": "The Countable-armed Bandit with Vanishing Arms",
    "abstract": "We consider a bandit problem with countably many arms, partitioned into\nfinitely many \"types,\" each characterized by a unique mean reward. A\n\"non-stationary\" distribution governs the relative abundance of each arm-type\nin the population of arms, aka the \"arm-reservoir.\" This non-stationarity is\nattributable to a probabilistic leakage of \"optimal\" arms from the reservoir\nover time, which we refer to as the \"vanishing arms\" phenomenon; this induces a\ntime-varying (potentially \"endogenous,\" policy-dependent) distribution over the\nreservoir. The objective is minimization of the expected cumulative regret. We\ncharacterize necessary and sufficient conditions for achievability of\nsub-linear regret in terms of a critical vanishing rate of optimal arms. We\nalso discuss two reservoir distribution-oblivious algorithms that are\nlong-run-average optimal whenever sub-linear regret is statistically\nachievable. Numerical experiments highlight a distinctive characteristic of\nthis problem related to ex ante knowledge of the \"gap\" parameter (the\ndifference between the top two mean rewards): in contrast to the stationary\nbandit formulation, regret in our setting may suffer substantial inflation\nunder adaptive exploration-based (gap-oblivious) algorithms such as UCB\nvis-`a-vis their non-adaptive forced exploration-based (gap-aware) counterparts\nlike ETC.",
    "descriptor": "",
    "authors": [
      "Anand Kalvit",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12118"
  },
  {
    "id": "arXiv:2110.12122",
    "title": "Quantifying Epistemic Uncertainty in Deep Learning",
    "abstract": "Uncertainty quantification is at the core of the reliability and robustness\nof machine learning. It is well-known that uncertainty consists of two\ndifferent types, often referred to as aleatoric and epistemic uncertainties. In\nthis paper, we provide a systematic study on the epistemic uncertainty in deep\nsupervised learning. We rigorously distinguish different sources of epistemic\nuncertainty, including in particular procedural variability (from the training\nprocedure) and data variability (from the training data). We use our framework\nto explain how deep ensemble enhances prediction by reducing procedural\nvariability. We also propose two approaches to estimate epistemic uncertainty\nfor a well-trained neural network in practice. One uses influence function\nderived from the theory of neural tangent kernel that bypasses the convexity\nassumption violated by modern neural networks. Another uses batching that\nbypasses the time-consuming Gram matrix inversion in the influence function\ncalculation, while expending minimal re-training effort. We discuss how both\napproaches overcome some difficulties in applying classical statistical methods\nto the inference on deep learning.",
    "descriptor": "",
    "authors": [
      "Ziyi Huang",
      "Henry Lam",
      "Haofeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12122"
  },
  {
    "id": "arXiv:2110.12123",
    "title": "Three-Layer Joint Distributionally Robust Chance-Constrained Framework  for Optimal Day-Ahead Scheduling of E-mobility Ecosystem",
    "abstract": "A high number of electric vehicles (EVs) in the transportation sector\nnecessitates an advanced scheduling framework for e-mobility ecosystem\noperation as a whole in order to overcome range anxiety and create a viable\nbusiness model for charging stations (CSs). The framework must account for the\nstochastic nature of all stakeholders' operations, including EV drivers, CSs,\nand retailers and their mutual interactions. In this paper, a three-layer joint\ndistributionally robust chance-constrained (DRCC) model is proposed to plan\ngrid-to-vehicle (G2V) and vehicle-to-grid (V2G) operation in day-ahead for\ne-mobility ecosystems. The proposed stochastic model does not rely on a\nspecific probability distribution for stochastic parameters. To solve the\nproblem, an iterative process is proposed using joint DRCC formulation. To\nachieve computational traceability, the exact reformulation is implemented for\ndouble-sided and single-sided chance constraints (CCs). Furthermore, the impact\nof temporal correlation of uncertain PV generation on CSs operation is\nconsidered. A simulation study is carried out for an ecosystem of three\nretailers, nine CSs, and 600 EVs based on real data from San Francisco, the\nUSA. The simulation results show the necessity and applicability of such a\nscheduling method for the e-mobility ecosystem in an uncertain environment,\ne.g., by reducing the number of unique EVs that failed to reach their\ndestination from 272 to 61.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Power System, 10 pages, 9 figures, 29 references\n",
    "authors": [
      "Mahsa Bagheri Tookanlou",
      "S. Ali Pourmousavi",
      "Mousa Marzband"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12123"
  },
  {
    "id": "arXiv:2110.12127",
    "title": "Low-Latency VLSI Architectures for Modular Polynomial Multiplication via  Fast Filtering and Applications to Lattice-Based Cryptography",
    "abstract": "This paper presents a low-latency hardware accelerator for modular polynomial\nmultiplication for lattice-based post-quantum cryptography and homomorphic\nencryption applications. The proposed novel modular polynomial multiplier\nexploits the fast finite impulse response (FIR) filter architecture to reduce\nthe computational complexity for the schoolbook modular polynomial\nmultiplication. We also extend this structure to fast M-parallel architectures\nwhile achieving low-latency, high-speed, and full hardware utilization. We\ncomprehensively evaluate the performance of the proposed architectures under\nvarious polynomial settings as well as in the Saber scheme for post-quantum\ncryptography as a case study. The experimental results show that our design\nreduces the computational time and area-time product by 61% and 32%,\nrespectively, compared to the state-of-the-art designs.",
    "descriptor": "",
    "authors": [
      "Weihang Tan",
      "Antian Wang",
      "Yingjie Lao",
      "Xinmiao Zhang",
      "Keshab K. Parhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.12127"
  },
  {
    "id": "arXiv:2110.12130",
    "title": "RCNet: Reverse Feature Pyramid and Cross-scale Shift Network for Object  Detection",
    "abstract": "Feature pyramid networks (FPN) are widely exploited for multi-scale feature\nfusion in existing advanced object detection frameworks. Numerous previous\nworks have developed various structures for bidirectional feature fusion, all\nof which are shown to improve the detection performance effectively. We observe\nthat these complicated network structures require feature pyramids to be\nstacked in a fixed order, which introduces longer pipelines and reduces the\ninference speed. Moreover, semantics from non-adjacent levels are diluted in\nthe feature pyramid since only features at adjacent pyramid levels are merged\nby the local fusion operation in a sequence manner. To address these issues, we\npropose a novel architecture named RCNet, which consists of Reverse Feature\nPyramid (RevFP) and Cross-scale Shift Network (CSN). RevFP utilizes local\nbidirectional feature fusion to simplify the bidirectional pyramid inference\npipeline. CSN directly propagates representations to both adjacent and\nnon-adjacent levels to enable multi-scale features more correlative. Extensive\nexperiments on the MS COCO dataset demonstrate RCNet can consistently bring\nsignificant improvements over both one-stage and two-stage detectors with\nsubtle extra computational overhead. In particular, RetinaNet is boosted to\n40.2 AP, which is 3.7 points higher than baseline, by replacing FPN with our\nproposed model. On COCO test-dev, RCNet can achieve very competitive\nperformance with a single-model single-scale 50.5 AP. Codes will be made\navailable.",
    "descriptor": "\nComments: Accepted by ACM MM2021\n",
    "authors": [
      "Zhuofan Zong",
      "Qianggang Cao",
      "Biao Leng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12130"
  },
  {
    "id": "arXiv:2110.12132",
    "title": "Towards the D-Optimal Online Experiment Design for Recommender Selection",
    "abstract": "Selecting the optimal recommender via online exploration-exploitation is\ncatching increasing attention where the traditional A/B testing can be slow and\ncostly, and offline evaluations are prone to the bias of history data. Finding\nthe optimal online experiment is nontrivial since both the users and displayed\nrecommendations carry contextual features that are informative to the reward.\nWhile the problem can be formalized via the lens of multi-armed bandits, the\nexisting solutions are found less satisfactorily because the general\nmethodologies do not account for the case-specific structures, particularly for\nthe e-commerce recommendation we study. To fill in the gap, we leverage the\n\\emph{D-optimal design} from the classical statistics literature to achieve the\nmaximum information gain during exploration, and reveal how it fits seamlessly\nwith the modern infrastructure of online inference. To demonstrate the\neffectiveness of the optimal designs, we provide semi-synthetic simulation\nstudies with published code and data for reproducibility purposes. We then use\nour deployment example on Walmart.com to fully illustrate the practical\ninsights and effectiveness of the proposed methods.",
    "descriptor": "",
    "authors": [
      "Da Xu",
      "Chuanwei Ruan",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12132"
  },
  {
    "id": "arXiv:2110.12133",
    "title": "Distributed Dynamic State Estimation for Microgrids",
    "abstract": "Conventionally, the dynamic state estimation of variables in power networks\nis performed based on the forecasting-aided model of bus voltages. This\napproach is effective in the stiff grids at the transmission level, where the\nbus voltages are less sensitive to variations of the load. However, in\nmicrogrids, bus voltages can fluctuate significantly under load changes, the\nforecasting-aided model may not sufficiently accurate. To resolve this problem,\nthis paper proposes a dynamic state estimation scheme for microgrids using the\nstate-space model derived from differential equations of power networks. In the\nproposed scheme, the branch currents are the state variables, whereas the bus\nvoltages become the inputs which can vary freely with loads. As a result, the\nentire microgrids system can be partitioned into local areas, where neighbor\nareas share the common inputs. The proposed estimation scheme then can be\nimplemented in a distributed manner. A novel Kalman-based filtering method is\nderived to estimate both states and inputs simultaneously. Only information of\ncommon inputs is exchanged between neighboring estimators. Simulation results\nof the 13-bus Potsdam microgrid (New York State) are provided to prove the\nfeasibility and performances of the proposed scheme.",
    "descriptor": "\nComments: 5 pages, 9 figures\n",
    "authors": [
      "Bang L. H. Nguyen",
      "Tuyen V. Vu",
      "Thomas H. Ortmeyer",
      "Tuan Ngo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12133"
  },
  {
    "id": "arXiv:2110.12134",
    "title": "Advanced Load Shedding for Integrated Power and Energy Systems",
    "abstract": "This paper introduces an advanced load shedding algorithm to improve the\noperability performance of a medium voltage direct current (MVDC) integrated\nshipboard power and energy system. Outcomes are compared to a baseline\nalgorithm while considering power generation contingency scenarios. The case\nstudy is conducted with a real-time, embedded algorithm implementation using a\ncontrol hardware-in-the-loop (CHIL) setup.",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Bang L. H. Nguyen",
      "Tuyen Vu",
      "Colin Ogilvie",
      "Harsha Ravindra",
      "Mark Stanovich",
      "Karl Schoder",
      "Michael Steurer",
      "Charalambos Konstantinou",
      "Herbert Ginn",
      "Christian Schegan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12134"
  },
  {
    "id": "arXiv:2110.12136",
    "title": "A Study of Multimodal Person Verification Using Audio-Visual-Thermal  Data",
    "abstract": "In this paper, we study an approach to multimodal person verification using\naudio, visual, and thermal modalities. The combination of audio and visual\nmodalities has already been shown to be effective for robust person\nverification. From this perspective, we investigate the impact of further\nincreasing the number of modalities by supplementing thermal images. In\nparticular, we implemented unimodal, bimodal, and trimodal verification systems\nusing the state-of-the-art deep learning architectures and compared their\nperformance under clean and noisy conditions. We also compared two popular\nfusion approaches based on simple score averaging and soft attention mechanism.\nThe experiment conducted on the SpeakingFaces dataset demonstrates the\nsuperiority of the trimodal verification system over both unimodal and bimodal\nsystems. To enable the reproducibility of the experiment and facilitate\nresearch into multimodal person verification, we make our code, pretrained\nmodels and preprocessed dataset freely available in our GitHub repository.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Madina Abdrakhmanova",
      "Saniya Abushakimova",
      "Yerbolat Khassanov",
      "Huseyin Atakan Varol"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12136"
  },
  {
    "id": "arXiv:2110.12138",
    "title": "Optimizing Alignment of Speech and Language Latent Spaces for End-to-End  Speech Recognition and Understanding",
    "abstract": "The advances in attention-based encoder-decoder (AED) networks have brought\ngreat progress to end-to-end (E2E) automatic speech recognition (ASR). One way\nto further improve the performance of AED-based E2E ASR is to introduce an\nextra text encoder for leveraging extensive text data and thus capture more\ncontext-aware linguistic information. However, this approach brings a mismatch\nproblem between the speech encoder and the text encoder due to the different\nunits used for modeling. In this paper, we propose an embedding aligner and\nmodality switch training to better align the speech and text latent spaces. The\nembedding aligner is a shared linear projection between text encoder and speech\nencoder trained by masked language modeling (MLM) loss and connectionist\ntemporal classification (CTC), respectively. The modality switch training\nrandomly swaps speech and text embeddings based on the forced alignment result\nto learn a joint representation space. Experimental results show that our\nproposed approach achieves a relative 14% to 19% word error rate (WER)\nreduction on Librispeech ASR task. We further verify its effectiveness on\nspoken language understanding (SLU), i.e., an absolute 2.5% to 2.8% F1 score\nimprovement on SNIPS slot filling task.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Wei Wang",
      "Shuo Ren",
      "Yao Qian",
      "Shujie Liu",
      "Yu Shi",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12138"
  },
  {
    "id": "arXiv:2110.12139",
    "title": "Family of Integrated Multi-Input Multi-Output DC-DC Power Converters",
    "abstract": "This paper explores a family of integrated multiport converters using\nthree-switch which can provide single-input dual-output (SIDO) or dual-input\nsingle-output (DISO) with bidirectional power flow between any two ports. The\nconcept can be extended to the n-switch converters to achieve more inputs\nand/or outputs. The proposed converters can be applied to interfacing sources,\nloads and storage elements having different voltage levels in applications such\nas dc nanogrids, electric vehicle, multiport power supplies, distributed\ngeneration systems. Various topological configurations of the integrated\nmultiport n-switch converter are investigated. The operating principles and PWM\ncontrol strategy of these converters are analyzed in detail. A universalized\nhardware prototype is built, experimental results are provided for\nverification.",
    "descriptor": "",
    "authors": [
      "Bang Le-Huy Nguyen",
      "Honnyong Cha",
      "Tien-The Nguyen",
      "Heung-Geun Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12139"
  },
  {
    "id": "arXiv:2110.12141",
    "title": "Rethinking Neural vs. Matrix-Factorization Collaborative Filtering: the  Theoretical Perspectives",
    "abstract": "The recent work by Rendle et al. (2020), based on empirical observations,\nargues that matrix-factorization collaborative filtering (MCF) compares\nfavorably to neural collaborative filtering (NCF), and conjectures the dot\nproduct's superiority over the feed-forward neural network as similarity\nfunction. In this paper, we address the comparison rigorously by answering the\nfollowing questions: 1. what is the limiting expressivity of each model; 2.\nunder the practical gradient descent, to which solution does each optimization\npath converge; 3. how would the models generalize under the inductive and\ntransductive learning setting. Our results highlight the similar expressivity\nfor the overparameterized NCF and MCF as kernelized predictors, and reveal the\nrelation between their optimization paths. We further show their different\ngeneralization behaviors, where MCF and NCF experience specific tradeoff and\ncomparison in the transductive and inductive collaborative filtering setting.\nLastly, by showing a novel generalization result, we reveal the critical role\nof correcting exposure bias for model evaluation in the inductive setting. Our\nresults explain some of the previously observed conflicts, and we provide\nsynthetic and real-data experiments to shed further insights to this topic.",
    "descriptor": "",
    "authors": [
      "Da Xu",
      "Chuanwei Ruan",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12141"
  },
  {
    "id": "arXiv:2110.12143",
    "title": "A Dissipation Theory for Potentials-Based FDTD for Lossless  Inhomogeneous Media",
    "abstract": "A dissipation theory is proposed for the potentials-based FDTD algorithm for\nthe case of inhomogeneous lossless media. We show that under the\nCourant-Friedrichs-Lewy (CFL) limit, the equations describing the time\nevolution of scalar and vector potentials can be seen as a lossless system. The\ndeveloped theory provides insights into how electromagnetic energy and power\nflow are approximated in FDTD schemes. It can also be used to create new\nalgorithms with guaranteed stability.",
    "descriptor": "\nComments: 5 pages, 3 figures. Submitted for review to IEEE Antennas and Wireless Propagation Letters\n",
    "authors": [
      "Fadime Bekmambetova",
      "Piero Triverio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.12143"
  },
  {
    "id": "arXiv:2110.12144",
    "title": "Foresight of Graph Reinforcement Learning Latent Permutations Learnt by  Gumbel Sinkhorn Network",
    "abstract": "Vital importance has necessity to be attached to cooperation in multi-agent\nenvironments, as a result of which some reinforcement learning algorithms\ncombined with graph neural networks have been proposed to understand the mutual\ninterplay between agents. However, highly complicated and dynamic multi-agent\nenvironments require more ingenious graph neural networks, which can\ncomprehensively represent not only the graph topology structure but also\nevolution process of the structure due to agents emerging, disappearing and\nmoving. To tackle these difficulties, we propose Gumbel Sinkhorn graph\nattention reinforcement learning, where a graph attention network highly\nrepresents the underlying graph topology structure of the multi-agent\nenvironment, and can adapt to the dynamic topology structure of graph better\nwith the help of Gumbel Sinkhorn network by learning latent permutations.\nEmpirically, simulation results show how our proposed graph reinforcement\nlearning methodology outperforms existing methods in the PettingZoo multi-agent\nenvironment by learning latent permutations.",
    "descriptor": "",
    "authors": [
      "Tianqi Shen",
      "Hong Zhang",
      "Ding Yuan",
      "Jiaping Xiao",
      "Yifan Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12144"
  },
  {
    "id": "arXiv:2110.12148",
    "title": "Event Detection on Dynamic Graphs",
    "abstract": "Event detection is a critical task for timely decision-making in graph\nanalytics applications. Despite the recent progress towards deep learning on\ngraphs, event detection on dynamic graphs presents particular challenges to\nexisting architectures. Real-life events are often associated with sudden\ndeviations of the normal behavior of the graph. However, existing approaches\nfor dynamic node embedding are unable to capture the graph-level dynamics\nrelated to events.\nIn this paper, we propose DyGED, a simple yet novel deep learning model for\nevent detection on dynamic graphs. DyGED learns correlations between the graph\nmacro dynamics -- i.e. a sequence of graph-level representations -- and labeled\nevents. Moreover, our approach combines structural and temporal self-attention\nmechanisms to account for application-specific node and time importances\neffectively. Our experimental evaluation, using a representative set of\ndatasets, demonstrates that DyGED outperforms competing solutions in terms of\nevent detection accuracy by up to 8.5% while being more scalable than the top\nalternatives. We also present case studies illustrating key features of our\nmodel.",
    "descriptor": "",
    "authors": [
      "Mert Kosan",
      "Arlei Silva",
      "Sourav Medya",
      "Brian Uzzi",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12148"
  },
  {
    "id": "arXiv:2110.12150",
    "title": "Spatio-Temporal Graph Complementary Scattering Networks",
    "abstract": "Spatio-temporal graph signal analysis has a significant impact on a wide\nrange of applications, including hand/body pose action recognition. To achieve\neffective analysis, spatio-temporal graph convolutional networks (ST-GCN)\nleverage the powerful learning ability to achieve great empirical successes;\nhowever, those methods need a huge amount of high-quality training data and\nlack theoretical interpretation. To address this issue, the spatio-temporal\ngraph scattering transform (ST-GST) was proposed to put forth a theoretically\ninterpretable framework; however, the empirical performance of this approach is\nconstrainted by the fully mathematical design. To benefit from both sides, this\nwork proposes a novel complementary mechanism to organically combine the\nspatio-temporal graph scattering transform and neural networks, resulting in\nthe proposed spatio-temporal graph complementary scattering networks (ST-GCSN).\nThe essence is to leverage the mathematically designed graph wavelets with\npruning techniques to cover major information and use trainable networks to\ncapture complementary information. The empirical experiments on hand pose\naction recognition show that the proposed ST-GCSN outperforms both ST-GCN and\nST-GST.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Zida Cheng",
      "Siheng Chen",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12150"
  },
  {
    "id": "arXiv:2110.12151",
    "title": "Spectrum-to-Kernel Translation for Accurate Blind Image Super-Resolution",
    "abstract": "Deep-learning based Super-Resolution (SR) methods have exhibited promising\nperformance under non-blind setting where blur kernel is known. However, blur\nkernels of Low-Resolution (LR) images in different practical applications are\nusually unknown. It may lead to significant performance drop when degradation\nprocess of training images deviates from that of real images. In this paper, we\npropose a novel blind SR framework to super-resolve LR images degraded by\narbitrary blur kernel with accurate kernel estimation in frequency domain. To\nour best knowledge, this is the first deep learning method which conducts blur\nkernel estimation in frequency domain. Specifically, we first demonstrate that\nfeature representation in frequency domain is more conducive for blur kernel\nreconstruction than in spatial domain. Next, we present a Spectrum-to-Kernel\n(S$2$K) network to estimate general blur kernels in diverse forms. We use a\nConditional GAN (CGAN) combined with SR-oriented optimization target to learn\nthe end-to-end translation from degraded images' spectra to unknown kernels.\nExtensive experiments on both synthetic and real-world images demonstrate that\nour proposed method sufficiently reduces blur kernel estimation error, thus\nenables the off-the-shelf non-blind SR methods to work under blind setting\neffectively, and achieves superior performance over state-of-the-art blind SR\nmethods, averagely by 1.39dB, 0.48dB on commom blind SR setting (with Gaussian\nkernels) for scales $2\\times$ and $4\\times$, respectively.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Guangpin Tao",
      "Xiaozhong Ji",
      "Wenzhuo Wang",
      "Shuo Chen",
      "Chuming Lin",
      "Yun Cao",
      "Tong Lu",
      "Donghao Luo",
      "Ying Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12151"
  },
  {
    "id": "arXiv:2110.12160",
    "title": "Multi-armed Bandit Algorithm against Strategic Replication",
    "abstract": "We consider a multi-armed bandit problem in which a set of arms is registered\nby each agent, and the agent receives reward when its arm is selected. An agent\nmight strategically submit more arms with replications, which can bring more\nreward by abusing the bandit algorithm's exploration-exploitation balance. Our\nanalysis reveals that a standard algorithm indeed fails at preventing\nreplication and suffers from linear regret in time $T$. We aim to design a\nbandit algorithm which demotivates replications and also achieves a small\ncumulative regret. We devise Hierarchical UCB (H-UCB) of replication-proof,\nwhich has $O(\\ln T)$-regret under any equilibrium. We further propose Robust\nHierarchical UCB (RH-UCB) which has a sublinear regret even in a realistic\nscenario with irrational agents replicating careless. We verify our theoretical\nfindings through numerical experiments.",
    "descriptor": "",
    "authors": [
      "Suho Shin",
      "Seungjoon Lee",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12160"
  },
  {
    "id": "arXiv:2110.12162",
    "title": "Diving Into Blockchain's Weaknesses: An Empirical Study of Blockchain  System Vulnerabilities",
    "abstract": "Blockchain is an emerging technology for its decentralization and the\ncapability of enabling cryptocurrencies and smart contracts. However, as a\ndistributed ledger software by nature, blockchain inevitably has software\nissues. While application-level smart contracts have been extensively\ninvestigated, the underlying system-level security bugs of blockchain are much\nless explored. In this paper, we conduct an empirical study of blockchain's\nsystem vulnerabilities using four representative blockchains, Bitcoin,\nEthereum, Monero, and Stellar. Due to the lack of CVE information associated\nwith these blockchain projects, we first design a systematic process to\neffectively identify 1,037 vulnerabilities and their 2,317 patches from 34,245\nissues/PRs (pull requests) and 85,164 commits on GitHub. Atop this unique\ndataset, we perform three levels of analyses, including (i) file-level\nvulnerable module categorization by identifying and correlating module paths\nacross projects, (ii) text-level vulnerability type clustering by combining\nnatural language processing with similarity-based sentence clustering, and\n(iii) code-level vulnerability pattern analysis by generating and clustering\nthe code change signatures that concisely capture both syntactic and semantic\ninformation of patch code fragments.\nAmong detailed results, our analysis reveals three key findings, including\n(i) some blockchain modules are more susceptible than the others; notably, the\nmodules related to consensus, wallet, and networking are highly susceptible,\neach with over 200 issues; (ii) around 70% of blockchain vulnerabilities are in\ntraditional types, but we also identify four new types specific to blockchains;\nand (iii) we obtain 21 blockchain-specific vulnerability patterns and\ndemonstrate that they can be used to detect similar vulnerabilities in other\ntop blockchains (e.g., Dogecoin and Bitcoin SV).",
    "descriptor": "\nComments: Due to length limit, we slightly trimmed the abstract displayed on arXiv\n",
    "authors": [
      "Xiao Yi",
      "Daoyuan Wu",
      "Lingxiao Jiang",
      "Kehuan Zhang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12162"
  },
  {
    "id": "arXiv:2110.12172",
    "title": "Scalable Smartphone Cluster for Deep Learning",
    "abstract": "Various deep learning applications on smartphones have been rapidly rising,\nbut training deep neural networks (DNNs) has too large computational burden to\nbe executed on a single smartphone. A portable cluster, which connects\nsmartphones with a wireless network and supports parallel computation using\nthem, can be a potential approach to resolve the issue. However, by our\nfindings, the limitations of wireless communication restrict the cluster size\nto up to 30 smartphones. Such small-scale clusters have insufficient\ncomputational power to train DNNs from scratch. In this paper, we propose a\nscalable smartphone cluster enabling deep learning training by removing the\nportability to increase its computational efficiency. The cluster connects 138\nGalaxy S10+ devices with a wired network using Ethernet. We implemented\nlarge-batch synchronous training of DNNs based on Caffe, a deep learning\nlibrary. The smartphone cluster yielded 90% of the speed of a P100 when\ntraining ResNet-50, and approximately 43x speed-up of a V100 when training\nMobileNet-v1.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Byunggook Na",
      "Jaehee Jang",
      "Seongsik Park",
      "Seijoon Kim",
      "Joonoo Kim",
      "Moon Sik Jeong",
      "Kwang Choon Kim",
      "Seon Heo",
      "Yoonsang Kim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12172"
  },
  {
    "id": "arXiv:2110.12178",
    "title": "An attention-driven hierarchical multi-scale representation for visual  recognition",
    "abstract": "Convolutional Neural Networks (CNNs) have revolutionized the understanding of\nvisual content. This is mainly due to their ability to break down an image into\nsmaller pieces, extract multi-scale localized features and compose them to\nconstruct highly expressive representations for decision making. However, the\nconvolution operation is unable to capture long-range dependencies such as\narbitrary relations between pixels since it operates on a fixed-size window.\nTherefore, it may not be suitable for discriminating subtle changes (e.g.\nfine-grained visual recognition). To this end, our proposed method captures the\nhigh-level long-range dependencies by exploring Graph Convolutional Networks\n(GCNs), which aggregate information by establishing relationships among\nmulti-scale hierarchical regions. These regions consist of smaller (closer\nlook) to larger (far look), and the dependency between regions is modeled by an\ninnovative attention-driven message propagation, guided by the graph structure\nto emphasize the neighborhoods of a given region. Our approach is simple yet\nextremely effective in solving both the fine-grained and generic visual\nclassification problems. It outperforms the state-of-the-arts with a\nsignificant margin on three and is very competitive on other two datasets.",
    "descriptor": "\nComments: Accepted in the 32nd British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "Zachary Wharton",
      "Ardhendu Behera",
      "Asish Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12178"
  },
  {
    "id": "arXiv:2110.12179",
    "title": "MisMatch: Learning to Change Predictive Confidences with Attention for  Consistency-Based, Semi-Supervised Medical Image Segmentation",
    "abstract": "The lack of labels is one of the fundamental constraints in deep learning\nbased methods for image classification and segmentation, especially in\napplications such as medical imaging. Semi-supervised learning (SSL) is a\npromising method to address the challenge of labels carcity. The\nstate-of-the-art SSL methods utilise consistency regularisation to learn\nunlabelled predictions which are invariant to perturbations on the prediction\nconfidence. However, such SSL approaches rely on hand-crafted augmentation\ntechniques which could be sub-optimal. In this paper, we propose MisMatch, a\nnovel consistency based semi-supervised segmentation method. MisMatch\nautomatically learns to produce paired predictions with increasedand decreased\nconfidences. MisMatch consists of an encoder and two decoders. One decoder\nlearns positive attention for regions of interest (RoI) on unlabelled data\nthereby generating higher confidence predictions of RoI. The other decoder\nlearns negative attention for RoI on the same unlabelled data thereby\ngenerating lower confidence predictions. We then apply a consistency\nregularisation between the paired predictions of the decoders. For evaluation,\nwe first perform extensive cross-validation on a CT-based pulmonary vessel\nsegmentation task and show that MisMatch statistically outperforms\nstate-of-the-art semi-supervised methods when only 6.25% of the total labels\nare used. Furthermore MisMatch performance using 6.25% ofthe total labels is\ncomparable to state-of-the-art methodsthat utilise all available labels. In a\nsecond experiment, MisMatch outperforms state-of-the-art methods on an\nMRI-based brain tumour segmentation task.",
    "descriptor": "",
    "authors": [
      "Mou-Cheng Xu",
      "Yu-Kun Zhou",
      "Chen Jin",
      "Stefano B. Blumberg",
      "Frederick J. Wilson",
      "Marius De Groot",
      "Neil P. Oxtoby",
      "Daniel C. Alexander",
      "Joseph Jacob"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12179"
  },
  {
    "id": "arXiv:2110.12180",
    "title": "Newtonian Mechanics Based Transient Stability PART III: Superimposed  Machine",
    "abstract": "This paper analyzes the mechanisms of the superimposed machine and also its\ninherit problems in TSA. Based on the global monitoring of the original system\ntrajectory, the transient energy is mistakenly defined as the superimposition\nof the transient energy of all machines in the system. This \"energy\nsuperimposition\" directly causes the superimposed machine to become a pseudo\nmachine without any equation of motion, and in this way the superimposed\nmachine completely violates all the machine paradigms. The violations bring the\ntwo inherit defects in TSA: (i) the stability of the superimposed machine is\nunable to be characterized precisely, and (ii) the variance of the original\nsystem trajectory is unstable to be depicted clearly. The two defects are also\nreflected in the definitions of the superimposed-machine based transient\nstability concepts. In particular, the swing and the critical stability of the\nsystem are unable to be defined strictly, and the potential energy surface\ncannot be modeled precisely. Simulation results show that the problems of the\npseudo superimposed-machine in TSA.",
    "descriptor": "\nComments: This papaer contains 11 pages and 23 figures\n",
    "authors": [
      "Songyan Wang",
      "Jilai Yu",
      "Aoife Foley",
      "Jingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12180"
  },
  {
    "id": "arXiv:2110.12183",
    "title": "Attend and Guide (AG-Net): A Keypoints-driven Attention-based Deep  Network for Image Recognition",
    "abstract": "This paper presents a novel keypoints-based attention mechanism for visual\nrecognition in still images. Deep Convolutional Neural Networks (CNNs) for\nrecognizing images with distinctive classes have shown great success, but their\nperformance in discriminating fine-grained changes is not at the same level. We\naddress this by proposing an end-to-end CNN model, which learns meaningful\nfeatures linking fine-grained changes using our novel attention mechanism. It\ncaptures the spatial structures in images by identifying semantic regions (SRs)\nand their spatial distributions, and is proved to be the key to modelling\nsubtle changes in images. We automatically identify these SRs by grouping the\ndetected keypoints in a given image. The ``usefulness'' of these SRs for image\nrecognition is measured using our innovative attentional mechanism focusing on\nparts of the image that are most relevant to a given task. This framework\napplies to traditional and fine-grained image recognition tasks and does not\nrequire manually annotated regions (e.g. bounding-box of body parts, objects,\netc.) for learning and prediction. Moreover, the proposed keypoints-driven\nattention mechanism can be easily integrated into the existing CNN models. The\nframework is evaluated on six diverse benchmark datasets. The model outperforms\nthe state-of-the-art approaches by a considerable margin using Distracted\nDriver V1 (Acc: 3.39%), Distracted Driver V2 (Acc: 6.58%), Stanford-40 Actions\n(mAP: 2.15%), People Playing Musical Instruments (mAP: 16.05%), Food-101 (Acc:\n6.30%) and Caltech-256 (Acc: 2.59%) datasets.",
    "descriptor": "\nComments: Published in IEEE Transaction on Image Processing 2021, Vol. 30, pp. 3691 - 3704\n",
    "authors": [
      "Asish Bera",
      "Zachary Wharton",
      "Yonghuai Liu",
      "Nik Bessis",
      "Ardhendu Behera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12183"
  },
  {
    "id": "arXiv:2110.12184",
    "title": "Domain Adaptation via Maximizing Surrogate Mutual Information",
    "abstract": "Unsupervised domain adaptation (UDA), which is an important topic in transfer\nlearning, aims to predict unlabeled data from target domain with access to\nlabeled data from the source domain. In this work, we propose a novel framework\ncalled SIDA (Surrogate Mutual Information Maximization Domain Adaptation) with\nstrong theoretical guarantees. To be specific, SIDA implements adaptation by\nmaximizing mutual information (MI) between features. In the framework, a\nsurrogate joint distribution models the underlying joint distribution of the\nunlabeled target domain. Our theoretical analysis validates SIDA by bounding\nthe expected risk on target domain with MI and surrogate distribution bias.\nExperiments show that our approach is comparable with state-of-the-art\nunsupervised adaptation methods on standard UDA tasks.",
    "descriptor": "",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Qinyu Chen",
      "Zhihong Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12184"
  },
  {
    "id": "arXiv:2110.12185",
    "title": "Group-disentangled Representation Learning with Weakly-Supervised  Regularization",
    "abstract": "Learning interpretable and human-controllable representations that uncover\nfactors of variation in data remains an ongoing key challenge in representation\nlearning. We investigate learning group-disentangled representations for groups\nof factors with weak supervision. Existing techniques to address this challenge\nmerely constrain the approximate posterior by averaging over observations of a\nshared group. As a result, observations with a common set of variations are\nencoded to distinct latent representations, reducing their capacity to\ndisentangle and generalize to downstream tasks. In contrast to previous works,\nwe propose GroupVAE, a simple yet effective Kullback-Leibler (KL)\ndivergence-based regularization across shared latent representations to enforce\nconsistent and disentangled representations. We conduct a thorough evaluation\nand demonstrate that our GroupVAE significantly improves group disentanglement.\nFurther, we demonstrate that learning group-disentangled representations\nimprove upon downstream tasks, including fair classification and 3D\nshape-related tasks such as reconstruction, classification, and transfer\nlearning, and is competitive to supervised methods.",
    "descriptor": "",
    "authors": [
      "Linh Tran",
      "Amir Hosein Khasahmadi",
      "Aditya Sanghi",
      "Saeid Asgari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12185"
  },
  {
    "id": "arXiv:2110.12187",
    "title": "AFEC: Active Forgetting of Negative Transfer in Continual Learning",
    "abstract": "Continual learning aims to learn a sequence of tasks from dynamic data\ndistributions. Without accessing to the old training samples, knowledge\ntransfer from the old tasks to each new task is difficult to determine, which\nmight be either positive or negative. If the old knowledge interferes with the\nlearning of a new task, i.e., the forward knowledge transfer is negative, then\nprecisely remembering the old tasks will further aggravate the interference,\nthus decreasing the performance of continual learning. By contrast, biological\nneural networks can actively forget the old knowledge that conflicts with the\nlearning of a new experience, through regulating the learning-triggered\nsynaptic expansion and synaptic convergence. Inspired by the biological active\nforgetting, we propose to actively forget the old knowledge that limits the\nlearning of new tasks to benefit continual learning. Under the framework of\nBayesian continual learning, we develop a novel approach named Active\nForgetting with synaptic Expansion-Convergence (AFEC). Our method dynamically\nexpands parameters to learn each new task and then selectively combines them,\nwhich is formally consistent with the underlying mechanism of biological active\nforgetting. We extensively evaluate AFEC on a variety of continual learning\nbenchmarks, including CIFAR-10 regression tasks, visual classification tasks\nand Atari reinforcement tasks, where AFEC effectively improves the learning of\nnew tasks and achieves the state-of-the-art performance in a plug-and-play way.",
    "descriptor": "",
    "authors": [
      "Liyuan Wang",
      "Mingtian Zhang",
      "Zhongfan Jia",
      "Qian Li",
      "Chenglong Bao",
      "Kaisheng Ma",
      "Jun Zhu",
      "Yi Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12187"
  },
  {
    "id": "arXiv:2110.12190",
    "title": "PROMPT: Parallel Iterative Algorithm for $\\ell_{p}$ norm linear  regression via Majorization Minimization with an application to  semi-supervised graph learning",
    "abstract": "In this paper, we consider the problem of $\\ell_{p}$ norm linear regression,\nwhich has several applications such as in sparse recovery, data clustering, and\nsemi-supervised learning. The problem, even though convex, does not enjoy a\nclosed-form solution. The state-of-the-art algorithms are iterative but suffer\nfrom convergence issues, i.e., they either diverge for p>3 or the convergence\nto the optimal solution is sensitive to the initialization of the algorithm.\nAlso, these algorithms are not generalizable to every possible value of $p$. In\nthis paper, we propose an iterative algorithm : Parallel IteRative AlgOrithM\nfor $\\ell_{P}$ norm regression via MajorizaTion Minimization (PROMPT) based on\nthe principle of Majorization Minimization and prove that the proposed\nalgorithm is monotonic and converges to the optimal solution of the problem for\nany value of $p$. The proposed algorithm can also parallelly update each\nelement of the regression variable, which helps to handle large scale data\nefficiently, a common scenario in this era of data explosion. Subsequently, we\nshow that the proposed algorithm can also be applied for the graph based\nsemi-supervised learning problem. We show through numerical simulations that\nthe proposed algorithm converges to the optimal solution for any random\ninitialization and also performs better than the state-of-the-art algorithms in\nterms of speed of convergence. We also evaluate the performance of the proposed\nalgorithm using simulated and real data for the graph based semi-supervised\nlearning problem.",
    "descriptor": "",
    "authors": [
      "R.Jyothi",
      "P.Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12190"
  },
  {
    "id": "arXiv:2110.12193",
    "title": "Towards User Engagement Dynamics in Social Networks",
    "abstract": "The engagement of each user in a social network is an essential indicator for\nmaintaining a sustainable service. Existing studies use the $coreness$ of a\nuser to well estimate its static engagement in a network. However, when the\nengagement of a user is weakened or strengthened, the influence on other users'\nengagement is unclear. Besides, the dynamic of user engagement has not been\nwell captured for evolving social networks. In this paper, we systematically\nstudy the network dynamic against the engagement change of each user for the\nfirst time. The influence of a user is monitored via two novel concepts: the\n$collapsed~power$ to measure the effect of user weakening, and the\n$anchored~power$ to measure the effect of user strengthening. We show that the\ntwo concepts can be naturally integrated such that a unified offline algorithm\nis proposed to compute both the collapsed and anchored followers for each user.\nWhen the network structure evolves, online techniques are designed to maintain\nthe users' followers, which is faster than redoing the offline algorithm by\naround 3 orders of magnitude. Extensive experiments on real-life data\ndemonstrate the effectiveness of our model and the efficiency of our\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Qingyuan Linghu",
      "Fan Zhang",
      "Xuemin Lin",
      "Wenjie Zhang",
      "Ying Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12193"
  },
  {
    "id": "arXiv:2110.12194",
    "title": "RPT++: Customized Feature Representation for Siamese Visual Tracking",
    "abstract": "While recent years have witnessed remarkable progress in the feature\nrepresentation of visual tracking, the problem of feature misalignment between\nthe classification and regression tasks is largely overlooked. The approaches\nof feature extraction make no difference for these two tasks in most of\nadvanced trackers. We argue that the performance gain of visual tracking is\nlimited since features extracted from the salient area provide more\nrecognizable visual patterns for classification, while these around the\nboundaries contribute to accurately estimating the target state.\nWe address this problem by proposing two customized feature extractors, named\npolar pooling and extreme pooling to capture task-specific visual patterns.\nPolar pooling plays the role of enriching information collected from the\nsemantic keypoints for stronger classification, while extreme pooling\nfacilitates explicit visual patterns of the object boundary for accurate target\nstate estimation. We demonstrate the effectiveness of the task-specific feature\nrepresentation by integrating it into the recent and advanced tracker RPT.\nExtensive experiments on several benchmarks show that our Customized Features\nbased RPT (RPT++) achieves new state-of-the-art performances on OTB-100,\nVOT2018, VOT2019, GOT-10k, TrackingNet and LaSOT.",
    "descriptor": "",
    "authors": [
      "Ziang Ma",
      "Haitao Zhang",
      "Linyuan Wang",
      "Jun Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12194"
  },
  {
    "id": "arXiv:2110.12197",
    "title": "Towards a Robust Differentiable Architecture Search under Label Noise",
    "abstract": "Neural Architecture Search (NAS) is the game changer in designing robust\nneural architectures. Architectures designed by NAS outperform or compete with\nthe best manual network designs in terms of accuracy, size, memory footprint\nand FLOPs. That said, previous studies focus on developing NAS algorithms for\nclean high quality data, a restrictive and somewhat unrealistic assumption. In\nthis paper, focusing on the differentiable NAS algorithms, we show that vanilla\nNAS algorithms suffer from a performance loss if class labels are noisy. To\ncombat this issue, we make use of the principle of information bottleneck as a\nregularizer. This leads us to develop a noise injecting operation that is\nincluded during the learning process, preventing the network from learning from\nnoisy samples. Our empirical evaluations show that the noise injecting\noperation does not degrade the performance of the NAS algorithm if the data is\nindeed clean. In contrast, if the data is noisy, the architecture learned by\nour algorithm comfortably outperforms algorithms specifically equipped with\nsophisticated mechanisms to learn in the presence of label noise. In contrast\nto many algorithms designed to work in the presence of noisy labels, prior\nknowledge about the properties of the noise and its characteristics are not\nrequired for our algorithm.",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Christian Simon",
      "Piotr Koniusz",
      "Lars Petersson",
      "Yan Han",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12197"
  },
  {
    "id": "arXiv:2110.12199",
    "title": "PhoMT: A High-Quality and Large-Scale Benchmark Dataset for  Vietnamese-English Machine Translation",
    "abstract": "We introduce a high-quality and large-scale Vietnamese-English parallel\ndataset of 3.02M sentence pairs, which is 2.9M pairs larger than the benchmark\nVietnamese-English machine translation corpus IWSLT15. We conduct experiments\ncomparing strong neural baselines and well-known automatic translation engines\non our dataset and find that in both automatic and human evaluations: the best\nperformance is obtained by fine-tuning the pre-trained sequence-to-sequence\ndenoising auto-encoder mBART. To our best knowledge, this is the first\nlarge-scale Vietnamese-English machine translation study. We hope our publicly\navailable dataset and study can serve as a starting point for future research\nand applications on Vietnamese-English machine translation.",
    "descriptor": "\nComments: To appear in Proceedings of EMNLP 2021 (main conference). The first three authors contribute equally to this work\n",
    "authors": [
      "Long Doan",
      "Linh The Nguyen",
      "Nguyen Luong Tran",
      "Thai Hoang",
      "Dat Quoc Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12199"
  },
  {
    "id": "arXiv:2110.12200",
    "title": "Hate and Offensive Speech Detection in Hindi and Marathi",
    "abstract": "Sentiment analysis is the most basic NLP task to determine the polarity of\ntext data. There has been a significant amount of work in the area of\nmultilingual text as well. Still hate and offensive speech detection faces a\nchallenge due to inadequate availability of data, especially for Indian\nlanguages like Hindi and Marathi. In this work, we consider hate and offensive\nspeech detection in Hindi and Marathi texts. The problem is formulated as a\ntext classification task using the state of the art deep learning approaches.\nWe explore different deep learning architectures like CNN, LSTM, and variations\nof BERT like multilingual BERT, IndicBERT, and monolingual RoBERTa. The basic\nmodels based on CNN and LSTM are augmented with fast text word embeddings. We\nuse the HASOC 2021 Hindi and Marathi hate speech datasets to compare these\nalgorithms. The Marathi dataset consists of binary labels and the Hindi dataset\nconsists of binary as well as more-fine grained labels. We show that the\ntransformer-based models perform the best and even the basic models along with\nFastText embeddings give a competitive performance. Moreover, with normal\nhyper-parameter tuning, the basic models perform better than BERT-based models\non the fine-grained Hindi dataset.",
    "descriptor": "\nComments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021\n",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Amol Gore",
      "Shubham Salunke",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12200"
  },
  {
    "id": "arXiv:2110.12201",
    "title": "Spanish Legalese Language Model and Corpora",
    "abstract": "There are many Language Models for the English language according to its\nworldwide relevance. However, for the Spanish language, even if it is a widely\nspoken language, there are very few Spanish Language Models which result to be\nsmall and too general. Legal slang could be think of a Spanish variant on its\nown as it is very complicated in vocabulary, semantics and phrase\nunderstanding. For this work we gathered legal-domain corpora from different\nsources, generated a model and evaluated against Spanish general domain tasks.\nThe model provides reasonable results in those tasks.",
    "descriptor": "",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "Jordi Armengol-Estap\u00e9",
      "Aitor Gonzalez-Agirre",
      "Marta Villegas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12201"
  },
  {
    "id": "arXiv:2110.12204",
    "title": "Cascading Feature Extraction for Fast Point Cloud Registration",
    "abstract": "We propose a method for speeding up a 3D point cloud registration through a\ncascading feature extraction. The current approach with the highest accuracy is\nrealized by iteratively executing feature extraction and registration using\ndeep features. However, iterative feature extraction takes time. Our proposed\nmethod significantly reduces the computational cost using cascading shallow\nlayers. Our idea is to omit redundant computations that do not always\ncontribute to the final accuracy. The proposed approach is approximately three\ntimes faster than the existing methods without a loss of accuracy.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Yoichiro Hisadome",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12204"
  },
  {
    "id": "arXiv:2110.12205",
    "title": "Multi-Domain Incremental Learning for Semantic Segmentation",
    "abstract": "Recent efforts in multi-domain learning for semantic segmentation attempt to\nlearn multiple geographical datasets in a universal, joint model. A simple\nfine-tuning experiment performed sequentially on three popular road scene\nsegmentation datasets demonstrates that existing segmentation frameworks fail\nat incrementally learning on a series of visually disparate geographical\ndomains. When learning a new domain, the model catastrophically forgets\npreviously learned knowledge. In this work, we pose the problem of multi-domain\nincremental learning for semantic segmentation. Given a model trained on a\nparticular geographical domain, the goal is to (i) incrementally learn a new\ngeographical domain, (ii) while retaining performance on the old domain, (iii)\ngiven that the previous domain's dataset is not accessible. We propose a\ndynamic architecture that assigns universally shared, domain-invariant\nparameters to capture homogeneous semantic features present in all domains,\nwhile dedicated domain-specific parameters learn the statistics of each domain.\nOur novel optimization strategy helps achieve a good balance between retention\nof old knowledge (stability) and acquiring new knowledge (plasticity). We\ndemonstrate the effectiveness of our proposed solution on domain incremental\nsettings pertaining to real-world driving scenes from roads of Germany\n(Cityscapes), the United States (BDD100k), and India (IDD).",
    "descriptor": "\nComments: 11 pages, 5 figures, Accepted in WACV 2022\n",
    "authors": [
      "Prachi Garg",
      "Rohit Saluja",
      "Vineeth N Balasubramanian",
      "Chetan Arora",
      "Anbumani Subramanian",
      "C.V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12205"
  },
  {
    "id": "arXiv:2110.12207",
    "title": "MaskSplit: Self-supervised Meta-learning for Few-shot Semantic  Segmentation",
    "abstract": "Just like other few-shot learning problems, few-shot segmentation aims to\nminimize the need for manual annotation, which is particularly costly in\nsegmentation tasks. Even though the few-shot setting reduces this cost for\nnovel test classes, there is still a need to annotate the training data. To\nalleviate this need, we propose a self-supervised training approach for\nlearning few-shot segmentation models. We first use unsupervised saliency\nestimation to obtain pseudo-masks on images. We then train a simple prototype\nbased model over different splits of pseudo masks and augmentations of images.\nOur extensive experiments show that the proposed approach achieves promising\nresults, highlighting the potential of self-supervised training. To the best of\nour knowledge this is the first work that addresses unsupervised few-shot\nsegmentation problem on natural images.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Mustafa Sercan Amac",
      "Ahmet Sencan",
      "Orhun Bugra Baran",
      "Nazli Ikizler-Cinbis",
      "Ramazan Gokberk Cinbis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12207"
  },
  {
    "id": "arXiv:2110.12211",
    "title": "ES-ImageNet: A Million Event-Stream Classification Dataset for Spiking  Neural Networks",
    "abstract": "With event-driven algorithms, especially the spiking neural networks (SNNs),\nachieving continuous improvement in neuromorphic vision processing, a more\nchallenging event-stream-dataset is urgently needed. However, it is well known\nthat creating an ES-dataset is a time-consuming and costly task with\nneuromorphic cameras like dynamic vision sensors (DVS). In this work, we\npropose a fast and effective algorithm termed Omnidirectional Discrete Gradient\n(ODG) to convert the popular computer vision dataset ILSVRC2012 into its\nevent-stream (ES) version, generating about 1,300,000 frame-based images into\nES-samples in 1000 categories. In this way, we propose an ES-dataset called\nES-ImageNet, which is dozens of times larger than other neuromorphic\nclassification datasets at present and completely generated by the software.\nThe ODG algorithm implements an image motion to generate local value changes\nwith discrete gradient information in different directions, providing a\nlow-cost and high-speed way for converting frame-based images into event\nstreams, along with Edge-Integral to reconstruct the high-quality images from\nevent streams. Furthermore, we analyze the statistics of the ES-ImageNet in\nmultiple ways, and a performance benchmark of the dataset is also provided\nusing both famous deep neural network algorithms and spiking neural network\nalgorithms. We believe that this work shall provide a new large-scale benchmark\ndataset for SNNs and neuromorphic vision.",
    "descriptor": "",
    "authors": [
      "Yihan Lin",
      "Wei Ding",
      "Shaohua Qiang",
      "Lei Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12211"
  },
  {
    "id": "arXiv:2110.12216",
    "title": "Domain Adaptation for Rare Classes Augmented with Synthetic Samples",
    "abstract": "To alleviate lower classification performance on rare classes in imbalanced\ndatasets, a possible solution is to augment the underrepresented classes with\nsynthetic samples. Domain adaptation can be incorporated in a classifier to\ndecrease the domain discrepancy between real and synthetic samples. While\ndomain adaptation is generally applied on completely synthetic source domains\nand real target domains, we explore how domain adaptation can be applied when\nonly a single rare class is augmented with simulated samples. As a testbed, we\nuse a camera trap animal dataset with a rare deer class, which is augmented\nwith synthetic deer samples. We adapt existing domain adaptation methods to two\nnew methods for the single rare class setting: DeerDANN, based on the\nDomain-Adversarial Neural Network (DANN), and DeerCORAL, based on deep\ncorrelation alignment (Deep CORAL) architectures. Experiments show that\nDeerDANN has the highest improvement in deer classification accuracy of 24.0%\nversus 22.4% improvement of DeerCORAL when compared to the baseline. Further,\nboth methods require fewer than 10k synthetic samples, as used by the baseline,\nto achieve these higher accuracies. DeerCORAL requires the least number of\nsynthetic samples (2k deer), followed by DeerDANN (8k deer).",
    "descriptor": "\nComments: 14 pages, 6 figures, to be published\n",
    "authors": [
      "Tuhin Das",
      "Robert-Jan Bruintjes",
      "Attila Lengyel",
      "Jan van Gemert",
      "Sara Beery"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12216"
  },
  {
    "id": "arXiv:2110.12217",
    "title": "Deep Structured Teams in Arbitrary-Size Linear Networks: Decentralized  Estimation, Optimal Control and Separation Principle",
    "abstract": "In this article, we introduce decentralized Kalman filters for linear\nquadratic deep structured teams. The agents in deep structured teams are\ncoupled in dynamics, costs and measurements through a set of linear regressions\nof the states and actions (also called deep states and deep actions). The\ninformation structure is decentralized, where every agent observes a noisy\nmeasurement of its local state and the global deep state. Since the number of\nagents is often very large in deep structured teams, any naive approach to\nfinding an optimal Kalman filter suffers from the curse of dimensionality.\nMoreover, due to the decentralized nature of information structure, the\nresultant optimization problem is non-convex, in general, where non-linear\nstrategies can outperform linear ones. However, we prove that the optimal\nstrategy is linear in the local state estimate as well as the deep state\nestimate and can be efficiently computed by two scale-free Riccati equations\nand Kalman filters. We propose a bi-level orthogonal approach across both space\nand time levels based on a gauge transformation technique to achieve the above\nresult.\nWe also establish a separation principle between optimal control and optimal\nestimation. Furthermore, we show that as the number of agents goes to infinity,\nthe Kalman gain associated with the deep state estimate converges to zero at a\nrate inversely proportional to the number of agents. This leads to a fully\ndecentralized approximate strategy where every agent predicts the deep state by\nits conditional and unconditional expected value, also known as the certainty\nequivalence approximation and (weighted) mean-field approximation,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Jalal Arabneydi",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12217"
  },
  {
    "id": "arXiv:2110.12224",
    "title": "Generalized Polarization Transform: A Novel Coded Transmission Paradigm",
    "abstract": "With the standardization and deployment of 5G, the focus has now shifted\ntoward developing beyond-5G (B5G) solutions. A new wave of applications and\nservices will demand ultra-high data rates and reliability. To this end, future\nwireless systems are expected to pave the way for entirely new fundamental air\ninterface technologies to attain a breakthrough in spectrum efficiency (SE).\nThis article discusses a new paradigm, named generalized polarization transform\n(GPT), to achieve an integrated design of coding, modulation, multi-antenna,\nmultiple access, etc., in a real sense. The GPT enabled air interface develops\nfar-reaching insights that the joint optimization of critical air interface\ningredients can achieve remarkable gains on SE compared with the\nstate-of-the-art module-stacking design. We present a comprehensive overview of\nthe application of GPT in various coded transmission systems approaching\nShannon limits under short to moderate blocklengths and highlight several\npromising trends for future research.",
    "descriptor": "",
    "authors": [
      "Jincheng Dai",
      "Dexin Zhang",
      "Kai Niu",
      "Zhongwei Si",
      "Ping Zhang",
      "Sen Wang",
      "Yifei Yuan",
      "Chih-Lin I"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12224"
  },
  {
    "id": "arXiv:2110.12225",
    "title": "A Comprehensive Electric Vehicle Model for Vehicle-to-Grid Strategy  Development",
    "abstract": "An electric vehicle model is developed to characterize the behavior of the\nSmart e.d. (2013) while driving, charging and providing vehicle-to-grid\nservices. The battery model is an electro-thermal model with a dual\npolarization equivalent circuit electrical model coupled with a lumped thermal\nmodel with active liquid cooling. The aging trend of the EV's 50 Ah large\nformat pouch cell with NMC chemistry is evaluated via accelerated aging tests\nin the laboratory. The EV model is completed with the measurement of the\non-board charger efficiency and the charging control behavior via IEC 61851-1.\nPerformance of the model is validated using laboratory pack tests, charging and\ndriving field data. The RMSE of the cell voltage was between 18.49 mV and 67.17\nmV per cell for the validation profiles. Cells stored at 100 % SOC and 40\n$^{\\circ}C$ reached end-of-life (80 % of initial capacity) after 431 days to\n589 days. The end-of-life for a cell cycled with 80 % DOD around an SOC of 50 %\nis reached after 3634 equivalent full cycles which equates to a driving\ndistance of over 420000 km. The full parameter set of the model is provided to\nserve as a resource for vehicle-to-grid strategy development.",
    "descriptor": "\nComments: 26 pages, 41 figures, under review at Journal of Applied Energy (Elsevier)\n",
    "authors": [
      "Fabian R\u00fccker",
      "Ilka Schoeneberger",
      "Till Wilmschen",
      "Ahmed Chahbaz",
      "Philipp Dechent",
      "Felix Hildenbrand",
      "Elias Barbers",
      "Matthias Kuipers",
      "Jan Figgener",
      "Dirk Uwe Sauer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12225"
  },
  {
    "id": "arXiv:2110.12229",
    "title": "How Do I Refactor This? An Empirical Study on Refactoring Trends and  Topics in Stack Overflow",
    "abstract": "An essential part of software maintenance and evolution, refactoring is\nperformed by developers, regardless of technology or domain, to improve the\ninternal quality of the system, and reduce its technical debt. However,\nchoosing the appropriate refactoring strategy is not always straightforward,\nresulting in developers seeking assistance. Although research in refactoring is\nwell-established, with several studies altering between the detection of\nrefactoring opportunities and the recommendation of appropriate code changes,\nlittle is known about their adoption in practice. Analyzing the perception of\ndevelopers is critical to understand better what developers consider to be\nproblematic in their code and how they handle it. Additionally, there is a need\nfor bridging the gap between refactoring, as research, and its adoption in\npractice, by extracting common refactoring intents that are more suitable for\nwhat developers face in reality. In this study, we analyze refactoring\ndiscussions on Stack Overflow through a series of quantitative and qualitative\nexperiments. Our results show that Stack Overflow is utilized by a diverse set\nof developers for refactoring assistance for a variety of technologies. Our\nobservations show five areas that developers typically require help with\nrefactoring -- Code Optimization, Tools and IDEs, Architecture and Design\nPatterns, Unit Testing, and Database. We envision our findings better bridge\nthe support between traditional (or academic) aspects of refactoring and their\nreal-world applicability, including better tool support.",
    "descriptor": "\nComments: Part of a collection: Collective Knowledge in Software Engineering ISSN: 1382-3256 (Print) 1573-7616 (Online)\n",
    "authors": [
      "Anthony Peruma",
      "Steven Simmons",
      "Eman Abdullah AlOmar",
      "Christian D. Newman",
      "Mohamed Wiem Mkaouer",
      "Ali Ouni"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12229"
  },
  {
    "id": "arXiv:2110.12231",
    "title": "Learning curves for Gaussian process regression with power-law priors  and targets",
    "abstract": "We study the power-law asymptotics of learning curves for Gaussian process\nregression (GPR). When the eigenspectrum of the prior decays with rate $\\alpha$\nand the eigenexpansion coefficients of the target function decay with rate\n$\\beta$, we show that the generalization error behaves as $\\tilde\nO(n^{\\max\\{\\frac{1}{\\alpha}-1, \\frac{1-2\\beta}{\\alpha}\\}})$ with high\nprobability over the draw of $n$ input samples. Under similar assumptions, we\nshow that the generalization error of kernel ridge regression (KRR) has the\nsame asymptotics. Infinitely wide neural networks can be related to KRR with\nrespect to the neural tangent kernel (NTK), which in several cases is known to\nhave a power-law spectrum. Hence our methods can be applied to study the\ngeneralization error of infinitely wide neural networks. We present toy\nexperiments demonstrating the theory.",
    "descriptor": "\nComments: 51 pages, 1 table, 1 figure\n",
    "authors": [
      "Hui Jin",
      "Pradeep Kr. Banerjee",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12231"
  },
  {
    "id": "arXiv:2110.12237",
    "title": "Characterizing User and Provider Reported Cloud Failures",
    "abstract": "Cloud computing is the backbone of the digital society. Digital banking,\nmedia, communication, gaming, and many others depend on cloud services.\nUnfortunately, cloud services may fail, leading to damaged services, unhappy\nusers, and perhaps millions of dollars lost for companies. Understanding a\ncloud service failure requires a detailed report on why and how the service\nfailed. Previous work studies how cloud services fail using logs published by\ncloud operators. However, information is lacking on how users perceive and\nexperience cloud failures. Therefore, we collect and characterize the data for\nuser-reported cloud failures from Down Detector for three cloud service\nproviders over three years. We count and analyze time patterns in the user\nreports, and derive failures from those user reports and characterize their\nduration and interarrival time. We characterize provider-reported cloud\nfailures and compare the results with the characterization of user-reported\nfailures. The comparison reveals the information of how users perceive failures\nand how much of the failures are reported by cloud service providers. Overall,\nthis work provides a characterization of user- and provider-reported cloud\nfailures and compares them with each other.",
    "descriptor": "",
    "authors": [
      "Mehmet Berk Cetin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12237"
  },
  {
    "id": "arXiv:2110.12239",
    "title": "Policy Search using Dynamic Mirror Descent MPC for Model Free Off Policy  RL",
    "abstract": "Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL\nalgorithms with model-based (Mb)-RL approaches to get the best from both:\nasymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired\nby these works, we propose a hierarchical framework that integrates online\nlearning for the Mb-trajectory optimization with off-policy methods for the\nMf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent\nbased Model Predictive Control (DMD-MPC) is used as the inner loop to obtain an\noptimal sequence of actions. These actions are in turn used to significantly\naccelerate the outer loop Mf-RL. We show that our formulation is generic for a\nbroad class of MPC based policies and objectives, and includes some of the\nwell-known Mb-Mf approaches. Based on the framework we define two algorithms to\nincrease sample efficiency of Off Policy RL and to guide end to end RL\nalgorithms for online adaption respectively. Thus we finally introduce two\nnovel algorithms: Dynamic-Mirror Descent Model Predictive RL(DeMoRL), which\nuses the method of elite fractions for the inner loop and Soft Actor-Critic\n(SAC) as the off-policy RL for the outer loop and Dynamic-Mirror Descent Model\nPredictive Layer(DeMo Layer), a special case of the hierarchical framework\nwhich guides linear policies trained using Augmented Random Search(ARS). Our\nexperiments show faster convergence of the proposed DeMo RL, and better or\nequal performance compared to other Mf-Mb approaches on benchmark MuJoCo\ncontrol tasks. The DeMo Layer was tested on classical Cartpole and custom-built\nQuadruped trained using Linear Policy.",
    "descriptor": "\nComments: Master's Thesis\n",
    "authors": [
      "Soumya Rani Samineni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12239"
  },
  {
    "id": "arXiv:2110.12241",
    "title": "Changing Software Engineers' Self-Efficacy in industrial Bootcamps:A  Research Proposal",
    "abstract": "In several areas of knowledge, self-efficacy is related to the perfomance of\nindividuals, including in Software Engineering. However,it is not clear how\nself-efficacy can be modified in training conducted by the industry.\nFurthermore, we still do not understand how self-efficacy can impact an\nindividual's team and career in the industry. This lack of understanding can\nnegatively impact how companies and individuals perceive the importance of\nself-efficacy in the field. Therefore, We present a research proposal that aims\nto understand the relationship between self-efficacy and training in Software\nEngineering. Moreover, we look to understand the role of self-efficacy at\nSoftware Development industry. We propose a longitudinal case study with\nsoftware engineers at Zup Innovation that participating of our bootcamp\ntraining. We expect to collect data to support our assumptions that\nself-efficacy can be related to training in Software Engineering. The other\nassumption is that self-efficacy at the beginning of training is higher than\nthe middle, and that self-efficacy at the end of training is higher than the\nmiddle. We expect that the study proposed in this article will motivate a\ndiscussion about self-efficacy and the importance of training employers in the\nindustry of software development.",
    "descriptor": "\nComments: 7 pages, 0 figures, SEET\n",
    "authors": [
      "Danilo Monteiro Ribeiro",
      "Alberto Souza",
      "Victor Santiago",
      "Danilo Lucena",
      "Geraldo Gomes",
      "Gustavo Pinto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12241"
  },
  {
    "id": "arXiv:2110.12243",
    "title": "PASTRIE: A Corpus of Prepositions Annotated with Supersense Tags in  Reddit International English",
    "abstract": "We present the Prepositions Annotated with Supersense Tags in Reddit\nInternational English (\"PASTRIE\") corpus, a new dataset containing manually\nannotated preposition supersenses of English data from presumed speakers of\nfour L1s: English, French, German, and Spanish. The annotations are\ncomprehensive, covering all preposition types and tokens in the sample. Along\nwith the corpus, we provide analysis of distributional patterns across the\nincluded L1s and a discussion of the influence of L1s on L2 preposition choice.",
    "descriptor": "\nComments: Expanded from the version published at the Linguistic Annotation Workshop 2020\n",
    "authors": [
      "Michael Kranzlein",
      "Emma Manning",
      "Siyao Peng",
      "Shira Wein",
      "Aryaman Arora",
      "Bradford Salen",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12243"
  },
  {
    "id": "arXiv:2110.12244",
    "title": "Operational Characterization of a Public Scientific Datacenter During  and Beyond the COVID-19 Period",
    "abstract": "Datacenters are imperative for the digital society. They offer services such\nas computing, telecommunication, media, and entertainment. Datacenters,\nhowever, consume a lot of power. Thus, Improving datacenter operations is\nimportant and may result in better services, reduced energy consumption and\nreduced costs. To improve datacenters, we must understand what is going on\ninside them. Therefore, we use operational traces from a scientific cluster in\nthe Netherlands to investigate and understand how that cluster operates. Due to\nwork-from-home circumstance, the covid period might have changed our daily\nusage of online applications, such as zoom and google meet. In this research,\nwe focus on the operations of a scientific cluster (LISA) inside the SURF\ndatacenter. The global pandemic might have changed how the LISA cluster\noperates. To understand the change, we collect, combine, and analyze\noperational logs from the LISA cluster. The tool to collect the data that\nbelongs to the non-covid period was accomplished in previous research.\nNonetheless, both the tool and instrument to combine and analyze the traces are\nlacking. This research focuses on designing an instrument that can combine and\nanalyze the traces during and before the coronavirus period. The instrument can\nalso produce graphs for customarily selected rack, nodes and periods. Moreover,\nwe characterize the traces that belong to the coronavirus period using the\nscientific instrument and additional tools. The outcome of this research helps\nus understand how the operations for a scientific cluster (LISA) in the\nNetherlands has changed after the global pandemic.",
    "descriptor": "",
    "authors": [
      "Mehmet Berk Cetin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12244"
  },
  {
    "id": "arXiv:2110.12245",
    "title": "Knowledge Transfer based Radio and Computation Resource Allocation for  5G RAN Slicing",
    "abstract": "To implement network slicing in 5G, resource allocation is a key function to\nallocate limited network resources such as radio and computation resources to\nmultiple slices. However, the joint resource allocation also leads to a higher\ncomplexity in the network management. In this work, we propose a knowledge\ntransfer based resource allocation (KTRA) method to jointly allocate radio and\ncomputation resources for 5G RAN slicing. Compared with existing works, the\nmain difference is that the proposed KTRA method has a knowledge transfer\ncapability. It is designed to use the prior knowledge of similar tasks to\nimprove performance of the target task, e.g., faster convergence speed or\nhigher average reward. The proposed KTRA is compared with Qlearning based\nresource allocation (QLRA), and KTRA method presents a 18.4% lower URLLC delay\nand a 30.1% higher eMBB throughput as well as a faster convergence speed.",
    "descriptor": "\nComments: Accepted by 2022 IEEE Consumer Communications & Networking Conference\n",
    "authors": [
      "Hao Zhou",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12245"
  },
  {
    "id": "arXiv:2110.12246",
    "title": "Parametric Variational Linear Units (PVLUs) in Deep Convolutional  Networks",
    "abstract": "The Rectified Linear Unit is currently a state-of-the-art activation function\nin deep convolutional neural networks. To combat ReLU's dying neuron problem,\nwe propose the Parametric Variational Linear Unit (PVLU), which adds a\nsinusoidal function with trainable coefficients to ReLU. Along with introducing\nnonlinearity and non-zero gradients across the entire real domain, PVLU allows\nfor increased model generalization and robustness when implemented in the\ncontext of transfer learning. On a simple, non-transfer sequential CNN, PVLU\nled to relative error decrease of 16.3% and 11.3% without and with data\naugmentation, relative to ReLU. PVLU is also tested on transfer learning\nproblems. The VGG-16 and VGG-19 models experience relative error reductions of\n9.5% and 10.7% on CIFAR-10, respectively, after the substitution of ReLU with\nPVLU. When training on Gaussian-filtered CIFAR-10 images, similar improvements\nare noted for the VGG models. Most notably, PVLU fine tuning allows for\nrelative error reductions up to and exceeding 10% on near state-of-the-art\nResNet models for both CIFAR-10 and CIFAR-100.",
    "descriptor": "\nComments: Both authors contributed equally to this research\n",
    "authors": [
      "Aarush Gupta",
      "Shikhar Ahuja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12246"
  },
  {
    "id": "arXiv:2110.12255",
    "title": "Confidence-Aware Active Feedback for Efficient Instance Search",
    "abstract": "Relevance feedback is widely used in instance search (INS) tasks to further\nrefine imperfect ranking results, but it often comes with low interaction\nefficiency. Active learning (AL) technique has achieved great success in\nimproving annotation efficiency in classification tasks. However, considering\nirrelevant samples' diversity and class imbalance in INS tasks, existing AL\nmethods cannot always select the most suitable feedback candidates for INS\nproblems. In addition, they are often too computationally complex to be applied\nin interactive INS scenario. To address the above problems, we propose a\nconfidence-aware active feedback (CAAF) method that can efficiently select the\nmost valuable feedback candidates to improve the re-ranking performance.\nSpecifically, inspired by the explicit sample difficulty modeling in self-paced\nlearning, we utilize a pairwise manifold ranking loss to evaluate the ranking\nconfidence of each unlabeled sample, and formulate the INS process as a\nconfidence-weighted manifold ranking problem. Furthermore, we introduce an\napproximate optimization scheme to simplify the solution from QP problems with\nconstraints to closed-form expressions, and selects only the top-K samples in\nthe initial ranking list for INS, so that CAAF is able to handle large-scale\nINS tasks in a short period of time. Extensive experiments on both image and\nvideo INS tasks demonstrate the effectiveness of the proposed CAAF method. In\nparticular, CAAF outperforms the first-place record in the public large-scale\nvideo INS evaluation of TRECVID 2021.",
    "descriptor": "",
    "authors": [
      "Yue Zhang",
      "Chao Liang",
      "Longxiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.12255"
  },
  {
    "id": "arXiv:2110.12257",
    "title": "Game of Gradients: Mitigating Irrelevant Clients in Federated Learning",
    "abstract": "The paradigm of Federated learning (FL) deals with multiple clients\nparticipating in collaborative training of a machine learning model under the\norchestration of a central server. In this setup, each client's data is private\nto itself and is not transferable to other clients or the server. Though FL\nparadigm has received significant interest recently from the research\ncommunity, the problem of selecting the relevant clients w.r.t. the central\nserver's learning objective is under-explored. We refer to these problems as\nFederated Relevant Client Selection (FRCS). Because the server doesn't have\nexplicit control over the nature of data possessed by each client, the problem\nof selecting relevant clients is significantly complex in FL settings. In this\npaper, we resolve important and related FRCS problems viz., selecting clients\nwith relevant data, detecting clients that possess data relevant to a\nparticular target label, and rectifying corrupted data samples of individual\nclients. We follow a principled approach to address the above FRCS problems and\ndevelop a new federated learning method using the Shapley value concept from\ncooperative game theory. Towards this end, we propose a cooperative game\ninvolving the gradients shared by the clients. Using this game, we compute\nShapley values of clients and then present Shapley value based Federated\nAveraging (S-FedAvg) algorithm that empowers the server to select relevant\nclients with high probability. S-FedAvg turns out to be critical in designing\nspecific algorithms to address the FRCS problems. We finally conduct a thorough\nempirical analysis on image classification and speech recognition tasks to show\nthe superior performance of S-FedAvg than the baselines in the context of\nsupervised federated learning settings.",
    "descriptor": "\nComments: Accepted at AAAI-21\n",
    "authors": [
      "Lokesh Nagalapatti",
      "Ramasuri Narayanam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12257"
  },
  {
    "id": "arXiv:2110.12259",
    "title": "In Search of Probeable Generalization Measures",
    "abstract": "Understanding the generalization behaviour of deep neural networks is a topic\nof recent interest that has driven the production of many studies, notably the\ndevelopment and evaluation of generalization \"explainability\" measures that\nquantify model generalization ability. Generalization measures have also proven\nuseful in the development of powerful layer-wise model tuning and optimization\nalgorithms, though these algorithms require specific kinds of generalization\nmeasures which can probe individual layers. The purpose of this paper is to\nexplore the neglected subtopic of probeable generalization measures; to\nestablish firm ground for further investigations, and to inspire and guide the\ndevelopment of novel model tuning and optimization algorithms. We evaluate and\ncompare measures, demonstrating effectiveness and robustness across model\nvariations, dataset complexities, training hyperparameters, and training\nstages. We also introduce a new dataset of trained models and performance\nmetrics, GenProb, for testing generalization measures, model tuning algorithms\nand optimization algorithms.",
    "descriptor": "\nComments: Accepted in ICMLA2021\n",
    "authors": [
      "Jonathan Jaegerman",
      "Khalil Damouni",
      "Mahdi S. Hosseini",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12259"
  },
  {
    "id": "arXiv:2110.12260",
    "title": "Adaptive Control of Underactuated Planar Pronking Hexapod",
    "abstract": "Underactuated legged robots depict highly nonlinear and complex dynamical\nbehaviors that create significant challenges in accurately modeling system\ndynamics using both first principles and system identification approaches.\nHence, it makes a more substantial challenge to design stabilizing controllers.\nIf physical parameters on mathematical models have miscalibrations due to\nuncertainty in identifying and modeling processes, designed controllers could\nperform poorly or even result in unstable responses. Moreover, these parameters\ncan certainly change-over-time due to operation and environmental conditions.\nIn that respect, analogous to a living organism modifying its behavior in\nresponse to novel conditions, adapting/updating system parameters, such as\nspring constant, to compensate for modeling errors could provide the advantage\nof constructing a stable gait level controller without needing \"exact\"\ndynamical parameter values. This paper presents an online, model-based adaptive\ncontrol approach for an underactuated planar hexapod robot's pronking behavior\nadopted from antelope species. We show through systematic simulation studies\nthat the adaptive control policy is robust to high levels of parameter\nuncertainties compared to a non-adaptive model-based dead-beat controller.",
    "descriptor": "\nComments: 19 pages, 17 figures\n",
    "authors": [
      "G\u00fcner Dil\u015fad Er",
      "Mustafa Mert Ankaral\u0131"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12260"
  },
  {
    "id": "arXiv:2110.12261",
    "title": "espiownage: Tracking Transients in Steelpan Drum Strikes Using  Surveillance Technology",
    "abstract": "We present an improvement in the ability to meaningfully track features in\nhigh speed videos of Caribbean steelpan drums illuminated by Electronic Speckle\nPattern Interferometry (ESPI). This is achieved through the use of up-to-date\ncomputer vision libraries for object detection and image segmentation as well\nas a significant effort toward cleaning the dataset previously used to train\nsystems for this application. Besides improvements on previous metric scores by\n10% or more, noteworthy in this project are the introduction of a\nsegmentation-regression map for the entire drum surface yielding interference\nfringe counts comparable to those obtained via object detection, as well as the\naccelerated workflow for coordinating the data-cleaning-and-model-training\nfeedback loop for rapid iteration allowing this project to be conducted on a\ntimescale of only 18 days.",
    "descriptor": "\nComments: 6 pages, 5 figures, submitted to NeurIPS 2021 Workshop on Machine Learning and the Physical Sciences\n",
    "authors": [
      "Scott H. Hawley",
      "Andrew C. Morrison",
      "Grant S. Morgan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12261"
  },
  {
    "id": "arXiv:2110.12263",
    "title": "Fixed-Time Convergent Distributed Observer Design of Linear Systems: A  Kernel-Based Approach",
    "abstract": "This note investigates the distributed observer for a continuous-time linear\ntime-invariant system with distributed sensor nodes and each can access a\nportion of the system output. The communication network between the agents is\nprescribed by a directed graph in which each node involves a finite-time\nconvergent state observer. The local observer estimates and broadcasts the\nobservable states among neighbours so that the full state vector can be\nrecovered at each node and the estimation error reaches zero after a fixed time\nin the absence of perturbation. This represents a new distributed estimation\nframework that enables reduced information exchange compared to a\nLuenberger-like approach, and the ubiquitous communication delay can be\ncompensated. Moreover, the robustness of the algorithm in the presence of\nbounded measurement and process noise is characterised. Numerical simulations\nand comparisons show the effectiveness of the observer and its advantages over\nthe renewed existing methods.",
    "descriptor": "",
    "authors": [
      "Pudong Ge",
      "Peng Li",
      "Boli Chen",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12263"
  },
  {
    "id": "arXiv:2110.12271",
    "title": "Self-Validation: Early Stopping for Single-Instance Deep Generative  Priors",
    "abstract": "Recent works have shown the surprising effectiveness of deep generative\nmodels in solving numerous image reconstruction (IR) tasks, even without\ntraining data. We call these models, such as deep image prior and deep decoder,\ncollectively as single-instance deep generative priors (SIDGPs). The successes,\nhowever, often hinge on appropriate early stopping (ES), which by far has\nlargely been handled in an ad-hoc manner. In this paper, we propose the first\nprincipled method for ES when applying SIDGPs to IR, taking advantage of the\ntypical bell trend of the reconstruction quality. In particular, our method is\nbased on collaborative training and self-validation: the primal reconstruction\nprocess is monitored by a deep autoencoder, which is trained online with the\nhistoric reconstructed images and used to validate the reconstruction quality\nconstantly. Experimentally, on several IR problems and different SIDGPs, our\nself-validation method is able to reliably detect near-peak performance and\nsignal good ES points. Our code is available at\nhttps://sun-umn.github.io/Self-Validation/.",
    "descriptor": "\nComments: To appear in British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "Taihui Li",
      "Zhong Zhuang",
      "Hengyue Liang",
      "Le Peng",
      "Hengkang Wang",
      "Ju Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12271"
  },
  {
    "id": "arXiv:2110.12275",
    "title": "Signal to Noise Ratio Loss Function",
    "abstract": "This work proposes a new loss function targeting classification problems,\nutilizing a source of information overlooked by cross entropy loss. First, we\nderive a series of the tightest upper and lower bounds for the probability of a\nrandom variable in a given interval. Second, a lower bound is proposed for the\nprobability of a true positive for a parametric classification problem, where\nthe form of probability density function (pdf) of data is given. A closed form\nfor finding the optimal function of unknowns is derived to maximize the\nprobability of true positives. Finally, for the case that the pdf of data is\nunknown, we apply the proposed boundaries to find the lower bound of the\nprobability of true positives and upper bound of the probability of false\npositives and optimize them using a loss function which is given by combining\nthe boundaries. We demonstrate that the resultant loss function is a function\nof the signal to noise ratio both within and across logits. We empirically\nevaluate our proposals to show their benefit for classification problems.",
    "descriptor": "",
    "authors": [
      "Ali Ghobadzadeh",
      "Amir Lashkari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12275"
  },
  {
    "id": "arXiv:2110.12276",
    "title": "Coarse-Grained Smoothness for RL in Metric Spaces",
    "abstract": "Principled decision-making in continuous state--action spaces is impossible\nwithout some assumptions. A common approach is to assume Lipschitz continuity\nof the Q-function. We show that, unfortunately, this property fails to hold in\nmany typical domains. We propose a new coarse-grained smoothness definition\nthat generalizes the notion of Lipschitz continuity, is more widely applicable,\nand allows us to compute significantly tighter bounds on Q-functions, leading\nto improved learning. We provide a theoretical analysis of our new smoothness\ndefinition, and discuss its implications and impact on control and exploration\nin continuous domains.",
    "descriptor": "",
    "authors": [
      "Omer Gottesman",
      "Kavosh Asadi",
      "Cameron Allen",
      "Sam Lobel",
      "George Konidaris",
      "Michael Littman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12276"
  },
  {
    "id": "arXiv:2110.12279",
    "title": "Hierarchical Few-Shot Generative Models",
    "abstract": "A few-shot generative model should be able to generate data from a\ndistribution by only observing a limited set of examples. In few-shot learning\nthe model is trained on data from many sets from different distributions\nsharing some underlying properties such as sets of characters from different\nalphabets or sets of images of different type objects. We study a latent\nvariables approach that extends the Neural Statistician to a fully hierarchical\napproach with an attention-based point to set-level aggregation. We extend the\nprevious work to iterative data sampling, likelihood-based model comparison,\nand adaptation-free out of distribution generalization. Our results show that\nthe hierarchical formulation better captures the intrinsic variability within\nthe sets in the small data regime. With this work we generalize deep latent\nvariable approaches to few-shot learning, taking a step towards large-scale\nfew-shot generation with a formulation that readily can work with current\nstate-of-the-art deep generative models.",
    "descriptor": "\nComments: 5th Workshop on Meta-Learning at NeurIPS 2021\n",
    "authors": [
      "Giorgio Giannone",
      "Ole Winther"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12279"
  },
  {
    "id": "arXiv:2110.12284",
    "title": "A phase-field model for thermo-mechanical fracture with an open-source  implementation of it using Gridap in Julia",
    "abstract": "In this article, we propose a thermodynamically consistent phase-field model\nfor thermo-mechanical fracture and provide an open-source implementation of the\nproposed model using a recently developed finite element toolbox, Gridap in\nJulia. Here, we have derived the balance equations for the thermo-mechanical\nfracture by invoking the virtual power principle and determined the\nconstitutive relations for the thermodynamic fluxes based on the satisfaction\nof the thermodynamic laws. Our proposed formulation provides an equation of\ntemperature evolution that can easily accommodate dissipative effects such as\nviscous damping. One may consider the proposed model as a non-trivial extension\nof a recently developed iso-thermal phase-field model by Dhas {\\it{et al.}}\n\\cite{dhas2018phase} for the non-isothermal case. We provide very compact and\nuser-friendly open-source codes for implementing the proposed model using\nGridap in Julia that requires very low memory usage and gives a high degree of\nflexibility to the users in defining weak forms of the governing partial\ndifferential equations. We have validated the proposed model and its\nimplementation against such standard results available in the literature as\ncrack propagation in the cruciform shape material, single edge-notched plate,\nbi-material beam and a quenching test.",
    "descriptor": "",
    "authors": [
      "Ved Prakash",
      "Akash Kumar Behera",
      "Mohammad Masiur Rahaman"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.12284"
  },
  {
    "id": "arXiv:2110.12289",
    "title": "pystorms: A simulation sandbox for the development and evaluation of  stormwater control algorithms",
    "abstract": "Recent accessibility of affordable sensing technologies, microcontrollers,\nand wireless communication technology has made it possible for stormwater\nsystems to be retrofitted with an assortment of sensors and actuators. These\nsmart stormwater systems have enabled the real-time sensing of their\nsurrounding environmental dynamics, and subsequently, provide the basis for\nautonomous and adaptive operational control strategies. Additionally, these\nsystems allow for inexpensive and minimally-invasive stormwater control\ninterventions (e.g. hydraulic valve operated by cellularly-connected actuator)\nin lieu of new construction. However promising this area of smart stormwater\ncontrol, there still remain barriers -- for experts and novices alike -- to\naccess a set of shared tools and methods for investigating, developing, and\ncontributing to it. In an effort to make smart stormwater control research more\nmethodical, efficient, and accessible, we present pystorms, a Python-based\nsimulation sandbox that facilitates the quantitative evaluation and comparison\nof control strategies. The pystorms simulation sandbox comes with (i) a\ncollection of real world-inspired stormwater control scenarios on which any\nnumber of control strategies can be applied and tested via (ii) an accompanying\nPython programming interface coupled with a stormwater simulator. For the first\ntime, pystorms enables rigorous and efficient evaluation of smart stormwater\ncontrol methodologies across a diverse set of watersheds with only a few lines\nof code. We present the details of pystorms here and demonstrate its usage by\napplying and evaluating two stormwater control strategies.",
    "descriptor": "",
    "authors": [
      "Sara P. Rimer",
      "Abhiram Mullapudi",
      "Sara C. Troutman",
      "Gregory Ewing",
      "Benjamin D. Bowes",
      "Aaron A. Akin",
      "Jeffrey Sadler",
      "Ruben Kertesz",
      "Bryant McDonnell",
      "Luis Montestruque",
      "Jon Hathaway",
      "Jonathan L. Goodall",
      "Branko Kerkez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12289"
  },
  {
    "id": "arXiv:2110.12290",
    "title": "Face sketch to photo translation using generative adversarial networks",
    "abstract": "Translating face sketches to photo-realistic faces is an interesting and\nessential task in many applications like law enforcement and the digital\nentertainment industry. One of the most important challenges of this task is\nthe inherent differences between the sketch and the real image such as the lack\nof color and details of the skin tissue in the sketch. With the advent of\nadversarial generative models, an increasing number of methods have been\nproposed for sketch-to-image synthesis. However, these models still suffer from\nlimitations such as the large number of paired data required for training, the\nlow resolution of the produced images, or the unrealistic appearance of the\ngenerated images. In this paper, we propose a method for converting an input\nfacial sketch to a colorful photo without the need for any paired dataset. To\ndo so, we use a pre-trained face photo generating model to synthesize\nhigh-quality natural face photos and employ an optimization procedure to keep\nhigh-fidelity to the input sketch. We train a network to map the facial\nfeatures extracted from the input sketch to a vector in the latent space of the\nface generating model. Also, we study different optimization criteria and\ncompare the results of the proposed model with those of the state-of-the-art\nmodels quantitatively and qualitatively. The proposed model achieved 0.655 in\nthe SSIM index and 97.59% rank-1 face recognition rate with higher quality of\nthe produced images.",
    "descriptor": "",
    "authors": [
      "Nastaran Moradzadeh Farid",
      "Maryam Saeedi Fard",
      "Ahmad Nickabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12290"
  },
  {
    "id": "arXiv:2110.12292",
    "title": "Federated Multiple Label Hashing (FedMLH): Communication Efficient  Federated Learning on Extreme Classification Tasks",
    "abstract": "Federated learning enables many local devices to train a deep learning model\njointly without sharing the local data. Currently, most of federated training\nschemes learns a global model by averaging the parameters of local models.\nHowever, most of these training schemes suffer from high communication cost\nresulted from transmitting full local model parameters. Moreover, directly\naveraging model parameters leads to a significant performance degradation, due\nto the class-imbalanced non-iid data on different devices. Especially for the\nreal life federated learning tasks involving extreme classification, (1)\ncommunication becomes the main bottleneck since the model size increases\nproportionally to the number of output classes; (2) extreme classification\n(such as user recommendation) normally have extremely imbalanced classes and\nheterogeneous data on different devices. To overcome this problem, we propose\nfederated multiple label hashing (FedMLH), which leverages label hashing to\nsimultaneously reduce the model size (up to 3.40X decrease) with communication\ncost (up to 18.75X decrease) and achieves significant better accuracy (up to\n35.5%} relative accuracy improvement) and faster convergence rate (up to 5.5X\nincrease) for free on the federated extreme classification tasks compared to\nfederated average algorithm.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhenwei Dai",
      "Chen Dun",
      "Yuxin Tang",
      "Anastasios Kyrillidis",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12292"
  },
  {
    "id": "arXiv:2110.12296",
    "title": "The Prevalence of Cybersecurity Misinformation on Social Media: Case  Studies on Phishing Reports and Zoom's Threats",
    "abstract": "Recently, threat intelligence and security tools have been augmented to use\nthe timely and relevant security information extracted from social media.\nHowever, both ordinary users and malicious actors may spread misinformation,\nwhich can misguide not only the end-users but also the threat intelligence\ntools. In this work, for the first time, we study the prevalence of\ncybersecurity and privacy misinformation on social media, focusing on two\ndifferent topics: phishing websites and Zoom's security & privacy. We collected\nTwitter posts that were warning users about phishing websites and tried to\nverify these claims. We found about 22% of these tweets to be not valid claims.\nWe then investigated posts about Zoom's security and privacy on multiple\nplatforms, including Instagram, Reddit, Twitter, and Facebook. To detect\nmisinformation related to Zoom, we first created a groundtruth dataset and a\ntaxonomy of misinformation and identified the textual and contextual features\nto be used for training classifiers to detect posts that discuss the security\nand privacy of Zoom and detect misinformation. Our classifiers showed great\nperformance, e.g., Reddit and Facebook misinformation classifier reached an\naccuracy of 99% while Twitter and Instagram reached an accuracy of 98%.\nEmploying these classifiers on the posts from Instagram, Facebook, Reddit, and\nTwitter, we found that respectively about 3%, 10%, 4%, and 0.4% of Zoom's\nsecurity and privacy posts as misinformation. This highlights the need for\nsocial media platforms to dedicate resources to curb the spread of\nmisinformation, and for data-driven security tools to propose methods to\nminimize the impact of such misinformation on their performance.",
    "descriptor": "",
    "authors": [
      "Mohit Singhal",
      "Nihal Kumarswamy",
      "Shreyasi Kinhekar",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12296"
  },
  {
    "id": "arXiv:2110.12301",
    "title": "Map Induction: Compositional spatial submap learning for efficient  exploration in novel environments",
    "abstract": "Humans are expert explorers. Understanding the computational cognitive\nmechanisms that support this efficiency can advance the study of the human mind\nand enable more efficient exploration algorithms. We hypothesize that humans\nexplore new environments efficiently by inferring the structure of unobserved\nspaces using spatial information collected from previously explored spaces.\nThis cognitive process can be modeled computationally using program induction\nin a Hierarchical Bayesian framework that explicitly reasons about uncertainty\nwith strong spatial priors. Using a new behavioral Map Induction Task, we\ndemonstrate that this computational framework explains human exploration\nbehavior better than non-inductive models and outperforms state-of-the-art\nplanning algorithms when applied to a realistic spatial navigation domain.",
    "descriptor": "",
    "authors": [
      "Sugandha Sharma",
      "Aidan Curtis",
      "Marta Kryven",
      "Josh Tenenbaum",
      "Ila Fiete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12301"
  },
  {
    "id": "arXiv:2110.12306",
    "title": "Fully Distributed Actor-Critic Architecture for Multitask Deep  Reinforcement Learning",
    "abstract": "We propose a fully distributed actor-critic architecture, named Diff-DAC,\nwith application to multitask reinforcement learning (MRL). During the learning\nprocess, agents communicate their value and policy parameters to their\nneighbours, diffusing the information across a network of agents with no need\nfor a central station. Each agent can only access data from its local task, but\naims to learn a common policy that performs well for the whole set of tasks.\nThe architecture is scalable, since the computational and communication cost\nper agent depends on the number of neighbours rather than the overall number of\nagents. We derive Diff-DAC from duality theory and provide novel insights into\nthe actor-critic framework, showing that it is actually an instance of the dual\nascent method. We prove almost sure convergence of Diff-DAC to a common policy\nunder general assumptions that hold even for deep-neural network\napproximations. For more restrictive assumptions, we also prove that this\ncommon policy is a stationary point of an approximation of the original\nproblem. Numerical results on multitask extensions of common continuous control\nbenchmarks demonstrate that Diff-DAC stabilises learning and has a regularising\neffect that induces higher performance and better generalisation properties\nthan previous architectures.",
    "descriptor": "\nComments: 27 pages, 8 figures\n",
    "authors": [
      "Sergio Valcarcel Macua",
      "Ian Davies",
      "Aleksi Tukiainen",
      "Enrique Munoz de Cote"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12306"
  },
  {
    "id": "arXiv:2110.12307",
    "title": "Characterizing The Limits of Linear Modeling of Non-Linear Swarm  Behaviors",
    "abstract": "We study the limits of linear modeling of swarm behavior by characterizing\nthe inflection point beyond which linear models of swarm collective behavior\nbreak down. The problem we consider is a central place object gathering task.\nWe design a linear model which strives to capture the underlying dynamics of\nobject gathering in robot swarms from first principles, rather than extensively\nrelying on post-hoc model fitting. We evaluate our model with swarms of up to\n8,000 robots in simulation, demonstrating that it accurately captures\nunderlying swarm behavioral dynamics when the swarm can be approximated using\nthe mean-field model, and when it cannot, and finite-size effects are present.\nWe further apply our model to swarms exhibiting non-linear behaviors, and show\nthat it still provides accurate predictions in some scenarios, thereby\nestablishing better practical limits on linear modeling of swarm behaviors.",
    "descriptor": "",
    "authors": [
      "John Harwell",
      "Angel Sylvester",
      "Maria Gini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.12307"
  },
  {
    "id": "arXiv:2110.12308",
    "title": "A Layer-wise Adversarial-aware Quantization Optimization for Improving  Robustness",
    "abstract": "Neural networks are getting better accuracy with higher energy and\ncomputational cost. After quantization, the cost can be greatly saved, and the\nquantized models are more hardware friendly with acceptable accuracy loss. On\nthe other hand, recent research has found that neural networks are vulnerable\nto adversarial attacks, and the robustness of a neural network model can only\nbe improved with defense methods, such as adversarial training. In this work,\nwe find that adversarially-trained neural networks are more vulnerable to\nquantization loss than plain models. To minimize both the adversarial and the\nquantization losses simultaneously and to make the quantized model robust, we\npropose a layer-wise adversarial-aware quantization method, using the Lipschitz\nconstant to choose the best quantization parameter settings for a neural\nnetwork. We theoretically derive the losses and prove the consistency of our\nmetric selection. The experiment results show that our method can effectively\nand efficiently improve the robustness of quantized adversarially-trained\nneural networks.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.14965\n",
    "authors": [
      "Chang Song",
      "Riya Ranjan",
      "Hai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12308"
  },
  {
    "id": "arXiv:2110.12310",
    "title": "Data-driven estimation of system norms via impulse response",
    "abstract": "This paper proposes a method for estimating the norms of a system in a pure\ndata-driven fashion based on their identified Impulse Response (IR)\ncoefficients. The calculation of norms is briefly reviewed and the main\nexpressions for the IR-based estimations are presented. As a case study, the\n$\\mathcal{H}_{1}$, $\\mathcal{H}_2$, and $\\mathcal{H}_{\\infty}$ norms of the\nsensitivity transfer function of five different discrete-time closed-loop\nsystems are estimated for a Signal-to-Noise-Ratio (SNR) of 10 dB, achieving low\npercent error values if compared to the real value. To verify the influence of\nthe noise amplitude, norms are estimated considering a wide range of SNR\nvalues, for a specific system, presenting low Mean Percent Error (MPE) if\ncompared to the real norms. The proposed technique is also compared to an\nexisting state-space-based method in terms of $\\mathcal{H}_{\\infty}$, through\nMonte Carlo, showing a reduction of approximately 48 % in the MPE for a wide\nrange of SNR values.",
    "descriptor": "\nComments: 4 pages, 2 figures, journal\n",
    "authors": [
      "L. V. Fiorio",
      "C. L. Remes",
      "L. Campestrini",
      "Y. R. de Novaes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12310"
  },
  {
    "id": "arXiv:2110.12311",
    "title": "Vector Optimization with Stochastic Bandit Feedback",
    "abstract": "We introduce vector optimization problems with stochastic bandit feedback,\nwhich extends the best arm identification problem to vector-valued rewards. We\nconsider $K$ designs, with multi-dimensional mean reward vectors, which are\npartially ordered according to a polyhedral ordering cone $C$. This generalizes\nthe concept of Pareto set in multi-objective optimization and allows different\nsets of preferences of decision-makers to be encoded by $C$. Different than\nprior work, we define approximations of the Pareto set based on direction-free\ncovering and gap notions. We study the setting where an evaluation of each\ndesign yields a noisy observation of the mean reward vector. Under subgaussian\nnoise assumption, we investigate the sample complexity of the na\\\"ive\nelimination algorithm in an ($\\epsilon,\\delta$)-PAC setting, where the goal is\nto identify an ($\\epsilon,\\delta$)-PAC Pareto set with the minimum number of\ndesign evaluations. In particular, we identify cone-dependent geometric\nconditions on the deviations of empirical reward vectors from their mean under\nwhich the Pareto front can be approximated accurately. We run experiments to\nverify our theoretical results and illustrate how $C$ and sampling budget\naffect the Pareto set, returned ($\\epsilon,\\delta$)-PAC Pareto set and the\nsuccess of identification.",
    "descriptor": "\nComments: 12 pages, 3 tables, 2 figures\n",
    "authors": [
      "\u00c7a\u011f\u0131n Ararat",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12311"
  },
  {
    "id": "arXiv:2110.12319",
    "title": "Non-Asymptotic Error Bounds for Bidirectional GANs",
    "abstract": "We derive nearly sharp bounds for the bidirectional GAN (BiGAN) estimation\nerror under the Dudley distance between the latent joint distribution and the\ndata joint distribution with appropriately specified architecture of the neural\nnetworks used in the model. To the best of our knowledge, this is the first\ntheoretical guarantee for the bidirectional GAN learning approach. An appealing\nfeature of our results is that they do not assume the reference and the data\ndistributions to have the same dimensions or these distributions to have\nbounded support. These assumptions are commonly assumed in the existing\nconvergence analysis of the unidirectional GANs but may not be satisfied in\npractice. Our results are also applicable to the Wasserstein bidirectional GAN\nif the target distribution is assumed to have a bounded support. To prove these\nresults, we construct neural network functions that push forward an empirical\ndistribution to another arbitrary empirical distribution on a possibly\ndifferent-dimensional space. We also develop a novel decomposition of the\nintegral probability metric for the error analysis of bidirectional GANs. These\nbasic theoretical results are of independent interest and can be applied to\nother related learning problems.",
    "descriptor": "\nComments: Corresponding authors: Yunfei Yang (yyangdc@connect.ust.hk), Jian Huang (jian-huang@uiowa.edu), Yuling Jiao (yulingjiaomath@whu.edu.cn)\n",
    "authors": [
      "Shiao Liu",
      "Yunfei Yang",
      "Jian Huang",
      "Yuling Jiao",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12319"
  },
  {
    "id": "arXiv:2110.12320",
    "title": "CoVA: Context-aware Visual Attention for Webpage Information Extraction",
    "abstract": "Webpage information extraction (WIE) is an important step to create knowledge\nbases. For this, classical WIE methods leverage the Document Object Model (DOM)\ntree of a website. However, use of the DOM tree poses significant challenges as\ncontext and appearance are encoded in an abstract manner. To address this\nchallenge we propose to reformulate WIE as a context-aware Webpage Object\nDetection task. Specifically, we develop a Context-aware Visual Attention-based\n(CoVA) detection pipeline which combines appearance features with syntactical\nstructure from the DOM tree. To study the approach we collect a new large-scale\ndataset of e-commerce websites for which we manually annotate every web element\nwith four labels: product price, product title, product image and background.\nOn this dataset we show that the proposed CoVA approach is a new challenging\nbaseline which improves upon prior state-of-the-art methods.",
    "descriptor": "\nComments: 11 Pages, 6 Figures, 3 Tables\n",
    "authors": [
      "Anurendra Kumar",
      "Keval Morabia",
      "Jingjin Wang",
      "Kevin Chen-Chuan Chang",
      "Alexander Schwing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12320"
  },
  {
    "id": "arXiv:2110.12321",
    "title": "ADC: Adversarial attacks against object Detection that evade Context  consistency checks",
    "abstract": "Deep Neural Networks (DNNs) have been shown to be vulnerable to adversarial\nexamples, which are slightly perturbed input images which lead DNNs to make\nwrong predictions. To protect from such examples, various defense strategies\nhave been proposed. A very recent defense strategy for detecting adversarial\nexamples, that has been shown to be robust to current attacks, is to check for\nintrinsic context consistencies in the input data, where context refers to\nvarious relationships (e.g., object-to-object co-occurrence relationships) in\nimages. In this paper, we show that even context consistency checks can be\nbrittle to properly crafted adversarial examples and to the best of our\nknowledge, we are the first to do so. Specifically, we propose an adaptive\nframework to generate examples that subvert such defenses, namely, Adversarial\nattacks against object Detection that evade Context consistency checks (ADC).\nIn ADC, we formulate a joint optimization problem which has two attack goals,\nviz., (i) fooling the object detector and (ii) evading the context consistency\ncheck system, at the same time. Experiments on both PASCAL VOC and MS COCO\ndatasets show that examples generated with ADC fool the object detector with a\nsuccess rate of over 85% in most cases, and at the same time evade the recently\nproposed context consistency checks, with a bypassing rate of over 80% in most\ncases. Our results suggest that how to robustly model context and check its\nconsistency, is still an open problem.",
    "descriptor": "\nComments: WCAV'22 Acceptted\n",
    "authors": [
      "Mingjun Yin",
      "Shasha Li",
      "Chengyu Song",
      "M. Salman Asif",
      "Amit K. Roy-Chowdhury",
      "Srikanth V. Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12321"
  },
  {
    "id": "arXiv:2110.12325",
    "title": "Fast High-Quality Tabletop Rearrangement in Bounded Workspace",
    "abstract": "In this paper, we examine the problem of rearranging many objects on a\ntabletop in a cluttered setting using overhand grasps. Efficient solutions for\nthe problem, which capture a common task that we solve on a daily basis, are\nessential in enabling truly intelligent robotic manipulation. In a given\ninstance, objects may need to be placed at temporary positions (\"buffers\") to\ncomplete the rearrangement, but allocating these buffer locations can be highly\nchallenging in a cluttered environment. To tackle the challenge, a two-step\nbaseline planner is first developed, which generates a primitive plan based on\ninherent combinatorial constraints induced by start and goal poses of the\nobjects and then selects buffer locations assisted by the primitive plan. We\nthen employ the \"lazy\" planner in a tree search framework which is further sped\nup by adapting a novel preprocessing routine. Simulation experiments show our\nmethods can quickly generate high-quality solutions and are more robust in\nsolving large-scale instances than existing state-of-the-art approaches.\nsource:github.com/arc-l/TRLB",
    "descriptor": "\nComments: Summitted to 2022 IEEE International Conference on Robotics and Automation(ICRA 2022)\n",
    "authors": [
      "Kai Gao",
      "Darren Lau",
      "Baichuan Huang",
      "Kostas E. Bekris",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12325"
  },
  {
    "id": "arXiv:2110.12328",
    "title": "Improving Spectral Clustering Using Spectrum-Preserving Node Reduction",
    "abstract": "Spectral clustering is one of the most popular clustering methods. However,\nthe high computational cost due to the involved eigen-decomposition procedure\ncan immediately hinder its applications in large-scale tasks. In this paper we\nuse spectrum-preserving node reduction to accelerate eigen-decomposition and\ngenerate concise representations of data sets. Specifically, we create a small\nnumber of pseudonodes based on spectral similarity. Then, standard spectral\nclustering algorithm is performed on the smaller node set. Finally, each data\npoint in the original data set is assigned to the cluster as its representative\npseudo-node. The proposed framework run in nearly-linear time. Meanwhile, the\nclustering accuracy can be significantly improved by mining concise\nrepresentations. The experimental results show dramatically improved clustering\nperformance when compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yongyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12328"
  },
  {
    "id": "arXiv:2110.12329",
    "title": "The network signature of constellation line figures",
    "abstract": "In traditional astronomies across the world, groups of stars in the night sky\nwere linked into constellations -- symbolic representations on the celestial\nsphere, rich in meaning and with practical roles. In cultures where line or\nconnect-the-dot figures were documented, these visual representations are\nconstrained to the fixed background of stars, but are free in their choice of\nstars and lines to draw. Over a dataset of 1591 constellation line figures from\n50 astronomical cultures, we define metrics to measure the visual signature (or\ncomplexity) of a constellation, and answer two questions: (1) does the type of\nculture associate with the visual signature of constellations? 2) does the sky\nregion associate with the visual signature of constellations? We find that (1)\nindividual cultures are only rarely and weakly thus associated, but the type of\nculture (by practical use, level of development, and ancestry) show an\nassociation. We find clear clusters of cross-culture and cross-type similarity\nin visual signatures, with SE Asian traditions far apart from Mesopotamian, N\nand S American, Austronesian and Polynesian traditions, which are similar. We\nalso find (2) more diversity of constellation signature per sky region than\nexpected, with diverse designs around the majority of popular stars.",
    "descriptor": "\nComments: 26 pages, 12 figures\n",
    "authors": [
      "Doina Bucur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12329"
  },
  {
    "id": "arXiv:2110.12331",
    "title": "A methodology for detection and localization of fruits in apples  orchards from aerial images",
    "abstract": "Computer vision methods based on convolutional neural networks (CNNs) have\npresented promising results on image-based fruit detection at ground-level for\ndifferent crops. However, the integration of the detections found in different\nimages, allowing accurate fruit counting and yield prediction, have received\nless attention. This work presents a methodology for automated fruit counting\nemploying aerial-images. It includes algorithms based on multiple view geometry\nto perform fruits tracking, not just avoiding double counting but also locating\nthe fruits in the 3-D space. Preliminary assessments show correlations above\n0.8 between fruit counting and true yield for apples. The annotated dataset\nemployed on CNN training is publicly available.",
    "descriptor": "\nComments: Accepted for oral presentation at SBIAgro 2021 (XIII Congresso Brasileiro de Agroinform\\'atica)\n",
    "authors": [
      "Thiago T. Santos",
      "Luciano Gebler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12331"
  },
  {
    "id": "arXiv:2110.12334",
    "title": "SOLVER: Scene-Object Interrelated Visual Emotion Reasoning Network",
    "abstract": "Visual Emotion Analysis (VEA) aims at finding out how people feel emotionally\ntowards different visual stimuli, which has attracted great attention recently\nwith the prevalence of sharing images on social networks. Since human emotion\ninvolves a highly complex and abstract cognitive process, it is difficult to\ninfer visual emotions directly from holistic or regional features in affective\nimages. It has been demonstrated in psychology that visual emotions are evoked\nby the interactions between objects as well as the interactions between objects\nand scenes within an image. Inspired by this, we propose a novel Scene-Object\ninterreLated Visual Emotion Reasoning network (SOLVER) to predict emotions from\nimages. To mine the emotional relationships between distinct objects, we first\nbuild up an Emotion Graph based on semantic concepts and visual features. Then,\nwe conduct reasoning on the Emotion Graph using Graph Convolutional Network\n(GCN), yielding emotion-enhanced object features. We also design a Scene-Object\nFusion Module to integrate scenes and objects, which exploits scene features to\nguide the fusion process of object features with the proposed scene-based\nattention mechanism. Extensive experiments and comparisons are conducted on\neight public visual emotion datasets, and the results demonstrate that the\nproposed SOLVER consistently outperforms the state-of-the-art methods by a\nlarge margin. Ablation studies verify the effectiveness of our method and\nvisualizations prove its interpretability, which also bring new insight to\nexplore the mysteries in VEA. Notably, we further discuss SOLVER on three other\npotential datasets with extended experiments, where we validate the robustness\nof our method and notice some limitations of it.",
    "descriptor": "\nComments: Accepted by TIP\n",
    "authors": [
      "Jingyuan Yang",
      "Xinbo Gao",
      "Leida Li",
      "Xiumei Wang",
      "Jinshan Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12334"
  },
  {
    "id": "arXiv:2110.12335",
    "title": "Chinese Traditional Poetry Generating System Based on Deep Learning",
    "abstract": "Chinese traditional poetry is an important intangible cultural heritage of\nChina and an artistic carrier of thought, culture, spirit and emotion. However,\ndue to the strict rules of ancient poetry, it is very difficult to write poetry\nby machine. This paper proposes an automatic generation method of Chinese\ntraditional poetry based on deep learning technology, which extracts keywords\nfrom each poem and matches them with the previous text to make the poem conform\nto the theme, and when a user inputs a paragraph of text, the machine obtains\nthe theme and generates poem sentence by sentence. Using the classic word2vec\nmodel as the preprocessing model, the Chinese characters which are not\nunderstood by the computer are transformed into matrix for processing.\nBi-directional Long Short-Term Memory is used as the neural network model to\ngenerate Chinese characters one by one and make the meaning of Chinese\ncharacters as accurate as possible. At the same time, TF-IDF and TextRank are\nused to extract keywords. Using the attention mechanism based encoding-decoding\nmodel, we can solve practical problems by transforming the model, and\nstrengthen the important information of long-distance information, so as to\ngrasp the key points without losing important information. In the aspect of\nemotion judgment, Long Short-Term Memory network is used. The final result\nshows that it can get good poetry outputs according to the user input text.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Chenlei Bao",
      "Lican Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12335"
  },
  {
    "id": "arXiv:2110.12338",
    "title": "Quality Map Fusion for Adversarial Learning",
    "abstract": "Generative adversarial models that capture salient low-level features which\nconvey visual information in correlation with the human visual system (HVS)\nstill suffer from perceptible image degradations. The inability to convey such\nhighly informative features can be attributed to mode collapse, convergence\nfailure and vanishing gradients. In this paper, we improve image quality\nadversarially by introducing a novel quality map fusion technique that\nharnesses image features similar to the HVS and the perceptual properties of a\ndeep convolutional neural network (DCNN). We extend the widely adopted l2\nWasserstein distance metric to other preferable quality norms derived from\nBanach spaces that capture richer image properties like structure, luminance,\ncontrast and the naturalness of images. We also show that incorporating a\nperceptual attention mechanism (PAM) that extracts global feature embeddings\nfrom the network bottleneck with aggregated perceptual maps derived from\nstandard image quality metrics translate to a better image quality. We also\ndemonstrate impressive performance over other methods.",
    "descriptor": "",
    "authors": [
      "Uche Osahor",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12338"
  },
  {
    "id": "arXiv:2110.12340",
    "title": "Adversarial Prefetch: New Cross-Core Cache Side Channel Attacks",
    "abstract": "On modern x86 processors, data prefetching instructions can be used by\nprogrammers to boost performance. Although good for performance, we found that\nPREFETCHW, which is a data prefetching instruction to accelerate future write\noperations, has two significant security flaws on Intel processors: first, this\ninstruction can execute on data with read-only permission; second, the\nexecution time of this instruction leaks the current coherence state of the\ntarget data.\nBased on these two design flaws, we build the first two cross-core cache\ntiming attacks that can work on private caches. Specifically, we first propose\ntwo covert channel attacks that can achieve a 864KB/s transmission rate which\nis higher than all existing cache covert channel attacks. Then we further\npropose two side channel attacks that can be used to monitor the access pattern\nof the victim running on the same processor. We demonstrate the efficacy of our\nattacks by using them to leak private information from daily applications.\nFinally, we show that our prefetch based attacks can be used in transient\nexecution attacks to leak more secrets within one speculative window.",
    "descriptor": "",
    "authors": [
      "Yanan Guo",
      "Andrew Zigerelli",
      "Youtao Zhang",
      "Jun Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12340"
  },
  {
    "id": "arXiv:2110.12341",
    "title": "Scalable knowledge base completion with superposition memories",
    "abstract": "We present Harmonic Memory Networks (HMem), a neural architecture for\nknowledge base completion that models entities as weighted sums of pairwise\nbindings between an entity's neighbors and corresponding relations. Since\nentities are modeled as aggregated neighborhoods, representations of unseen\nentities can be generated on the fly. We demonstrate this with two new\ndatasets: WNGen and FBGen. Experiments show that the model is SOTA on\nbenchmarks, and flexible enough to evolve without retraining as the knowledge\ngraph grows.",
    "descriptor": "",
    "authors": [
      "Matthias Lalisse",
      "Eric Rosen",
      "Paul Smolensky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12341"
  },
  {
    "id": "arXiv:2110.12342",
    "title": "Distributed neural encoding of binding to thematic roles",
    "abstract": "A framework and method are proposed for the study of constituent composition\nin fMRI. The method produces estimates of neural patterns encoding complex\nlinguistic structures, under the assumption that the contributions of\nindividual constituents are additive. Like usual techniques for modeling\ncompositional structure in fMRI, the proposed method employs pattern\nsuperposition to synthesize complex structures from their parts. Unlike these\ntechniques, superpositions are sensitive to the structural positions of\nconstituents, making them irreducible to structure-indiscriminate\n(\"bag-of-words\") models of composition. Reanalyzing data from a study by\nFrankland and Greene (2015), it is shown that comparison of neural predictive\nmodels with differing specifications can illuminate aspects of neural\nrepresentational contents that are not apparent when composition is not\nmodelled. The results indicate that the neural instantiations of the binding of\nfillers to thematic roles in a sentence are non-orthogonal, and therefore\nspatially overlapping.",
    "descriptor": "\nComments: Originally presented as a poster MACSIM 8 (2019)\n",
    "authors": [
      "Matthias Lalisse",
      "Paul Smolensky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12342"
  },
  {
    "id": "arXiv:2110.12343",
    "title": "Off-Policy Evaluation in Partially Observed Markov Decision Processes",
    "abstract": "We consider off-policy evaluation of dynamic treatment rules under the\nassumption that the underlying system can be modeled as a partially observed\nMarkov decision process (POMDP). We propose an estimator, partial history\nimportance weighting, and show that it can consistently estimate the stationary\nmean rewards of a target policy given long enough draws from the behavior\npolicy. Furthermore, we establish an upper bound on its error that decays\npolynomially in the number of observations (i.e., the number of trajectories\ntimes their length), with an exponent that depends on the overlap of the target\nand behavior policies, and on the mixing time of the underlying system. We also\nestablish a polynomial minimax lower bound for off-policy evaluation under the\nPOMDP assumption, and show that its exponent has the same qualitative\ndependence on overlap and mixing time as obtained in our upper bound. Together,\nour upper and lower bounds imply that off-policy evaluation in POMDPs is\nstrictly harder than off-policy evaluation in (fully observed) Markov decision\nprocesses, but strictly easier than model-free off-policy evaluation.",
    "descriptor": "",
    "authors": [
      "Yuchen Hu",
      "Stefan Wager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12343"
  },
  {
    "id": "arXiv:2110.12344",
    "title": "A Broader Picture of Random-walk Based Graph Embedding",
    "abstract": "Graph embedding based on random-walks supports effective solutions for many\ngraph-related downstream tasks. However, the abundance of embedding literature\nhas made it increasingly difficult to compare existing methods and to identify\nopportunities to advance the state-of-the-art. Meanwhile, existing work has\nleft several fundamental questions -- such as how embeddings capture different\nstructural scales and how they should be applied for effective link prediction\n-- unanswered. This paper addresses these challenges with an analytical\nframework for random-walk based graph embedding that consists of three\ncomponents: a random-walk process, a similarity function, and an embedding\nalgorithm. Our framework not only categorizes many existing approaches but\nnaturally motivates new ones. With it, we illustrate novel ways to incorporate\nembeddings at multiple scales to improve downstream task performance. We also\nshow that embeddings based on autocovariance similarity, when paired with dot\nproduct ranking for link prediction, outperform state-of-the-art methods based\non Pointwise Mutual Information similarity by up to 100%.",
    "descriptor": "\nComments: Accepted to KDD 2021\n",
    "authors": [
      "Zexi Huang",
      "Arlei Silva",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12344"
  },
  {
    "id": "arXiv:2110.12345",
    "title": "Quantitative Analysis of Demand Response Using Thermostatically  Controlled Loads",
    "abstract": "The flexible power consumption feature of thermostatically controlled loads\n(TCLs) such as heating, ventilation, and air-conditioning (HVAC) systems makes\nthem attractive targets for demand response (DR). TCLs possess a brief period\nwhere their power utilization can be altered without any significant impact on\ncustomer comfort level. This indicates TCLs are hidden potentials for providing\nancillary services. This paper proposes a novel metric of demand response\nsupport time (DRST) for HVAC enabled demand response and a novel algorithm for\nthe quantification of such HVAC-DR. The consumers' comfort will not be\ncompromised with the proposed DRST-based HVAC-DR. Case studies demonstrate its\nbenefits in terms of cost saving in microgrid day-ahead scheduling and\nreduction of forced load shedding during a grid-microgrid tie-line outage\nevent. This illustrates the reserve potential benefits and the increase of\nmicrogrid reliability when DRST-based HVAC-DR is considered.",
    "descriptor": "",
    "authors": [
      "Praveen Dhanasekar",
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12345"
  },
  {
    "id": "arXiv:2110.12349",
    "title": "Think about it! Improving defeasible reasoning by first modeling the  question scenario",
    "abstract": "Defeasible reasoning is the mode of reasoning where conclusions can be\noverturned by taking into account new evidence. Existing cognitive science\nliterature on defeasible reasoning suggests that a person forms a mental model\nof the problem scenario before answering questions. Our research goal asks\nwhether neural models can similarly benefit from envisioning the question\nscenario before answering a defeasible query. Our approach is, given a\nquestion, to have a model first create a graph of relevant influences, and then\nleverage that graph as an additional input when answering the question. Our\nsystem, CURIOUS, achieves a new state-of-the-art on three different defeasible\nreasoning datasets. This result is significant as it illustrates that\nperformance can be improved by guiding a system to \"think about\" a question and\nexplicitly model the scenario, rather than answering reflexively. Code, data,\nand pre-trained models are located at https://github.com/madaan/thinkaboutit.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Aman Madaan",
      "Niket Tandon",
      "Dheeraj Rajagopal",
      "Peter Clark",
      "Yiming Yang",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12349"
  },
  {
    "id": "arXiv:2110.12352",
    "title": "DiffSRL: Learning Dynamic-aware State Representation for Deformable  Object Control with Differentiable Simulator",
    "abstract": "Dynamic state representation learning is an important task in robot learning.\nLatent space that can capture dynamics related information has wide application\nin areas such as accelerating model free reinforcement learning, closing the\nsimulation to reality gap, as well as reducing the motion planning complexity.\nHowever, current dynamic state representation learning methods scale poorly on\ncomplex dynamic systems such as deformable objects, and cannot directly embed\nwell defined simulation function into the training pipeline. We propose\nDiffSRL, a dynamic state representation learning pipeline utilizing\ndifferentiable simulation that can embed complex dynamics models as part of the\nend-to-end training. We also integrate differentiable dynamic constraints as\npart of the pipeline which provide incentives for the latent state to be aware\nof dynamical constraints. We further establish a state representation learning\nbenchmark on a soft-body simulation system, PlasticineLab, and our model\ndemonstrates superior performance in terms of capturing long-term dynamics as\nwell as reward prediction.",
    "descriptor": "\nComments: 8 pages 9 figures\n",
    "authors": [
      "Sirui Chen",
      "Yunhao Liu",
      "Jialong Li",
      "Shang Wen Yao",
      "Tingxiang Fan",
      "Jia Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12352"
  },
  {
    "id": "arXiv:2110.12357",
    "title": "Towards A Conceptually Simple Defensive Approach for Few-shot  classifiers Against Adversarial Support Samples",
    "abstract": "Few-shot classifiers have been shown to exhibit promising results in use\ncases where user-provided labels are scarce. These models are able to learn to\npredict novel classes simply by training on a non-overlapping set of classes.\nThis can be largely attributed to the differences in their mechanisms as\ncompared to conventional deep networks. However, this also offers new\nopportunities for novel attackers to induce integrity attacks against such\nmodels, which are not present in other machine learning setups. In this work,\nwe aim to close this gap by studying a conceptually simple approach to defend\nfew-shot classifiers against adversarial attacks. More specifically, we propose\na simple attack-agnostic detection method, using the concept of self-similarity\nand filtering, to flag out adversarial support sets which destroy the\nunderstanding of a victim classifier for a certain class. Our extended\nevaluation on the miniImagenet (MI) and CUB datasets exhibit good attack\ndetection performance, across three different few-shot classifiers and across\ndifferent attack strengths, beating baselines. Our observed results allow our\napproach to establishing itself as a strong detection method for support set\npoisoning attacks. We also show that our approach constitutes a generalizable\nconcept, as it can be paired with other filtering functions. Finally, we\nprovide an analysis of our results when we vary two components found in our\ndetection approach.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.06330\n",
    "authors": [
      "Yi Xiang Marcus Tan",
      "Penny Chong",
      "Jiamei Sun",
      "Ngai-man Cheung",
      "Yuval Elovici",
      "Alexander Binder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12357"
  },
  {
    "id": "arXiv:2110.12358",
    "title": "A Closer Look at Few-Shot Video Classification: A New Baseline and  Benchmark",
    "abstract": "The existing few-shot video classification methods often employ a\nmeta-learning paradigm by designing customized temporal alignment module for\nsimilarity calculation. While significant progress has been made, these methods\nfail to focus on learning effective representations, and heavily rely on the\nImageNet pre-training, which might be unreasonable for the few-shot recognition\nsetting due to semantics overlap. In this paper, we aim to present an in-depth\nstudy on few-shot video classification by making three contributions. First, we\nperform a consistent comparative study on the existing metric-based methods to\nfigure out their limitations in representation learning. Accordingly, we\npropose a simple classifier-based baseline without any temporal alignment that\nsurprisingly outperforms the state-of-the-art meta-learning based methods.\nSecond, we discover that there is a high correlation between the novel action\nclass and the ImageNet object class, which is problematic in the few-shot\nrecognition setting. Our results show that the performance of training from\nscratch drops significantly, which implies that the existing benchmarks cannot\nprovide enough base data. Finally, we present a new benchmark with more base\ndata to facilitate future few-shot video classification without pre-training.\nThe code will be made available at https://github.com/MCG-NJU/FSL-Video.",
    "descriptor": "\nComments: BMVC2021 camera-ready version\n",
    "authors": [
      "Zhenxi Zhu",
      "Limin Wang",
      "Sheng Guo",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12358"
  },
  {
    "id": "arXiv:2110.12359",
    "title": "Encoding Integrated Decision and Control for Autonomous Driving with  Mixed Traffic Flow",
    "abstract": "Reinforcement learning (RL) has been widely adopted to make intelligent\ndriving policy in autonomous driving due to the self-evolution ability and\nhumanoid learning paradigm. Despite many elegant demonstrations of RL-enabled\ndecision-making, current research mainly focuses on the pure vehicle driving\nenvironment while ignoring other traffic participants like bicycles and\npedestrians. For urban roads, the interaction of mixed traffic flows leads to a\nquite dynamic and complex relationship, which poses great difficulty to learn a\nsafe and intelligent policy. This paper proposes the encoding integrated\ndecision and control (E-IDC) to handle complicated driving tasks with mixed\ntraffic flows, which composes of an encoding function to construct driving\nstates, a value function to choose the optimal path as well as a policy\nfunction to output the control command of ego vehicle. Specially, the encoding\nfunction is capable of dealing with different types and variant number of\ntraffic participants and extracting features from original driving observation.\nNext, we design the training principle for the functions of E-IDC with RL\nalgorithms by adding the gradient-based update rules and refine the safety\nconstraints concerning the otherness of different participants. The\nverification is conducted on the intersection scenario with mixed traffic flows\nand result shows that E-IDC can enhance the driving performance, including the\ntracking performance and safety constraint requirements with a large margin.\nThe online application indicates that E-IDC can realize efficient and smooth\ndriving in the complex intersection, guaranteeing the intelligence and safety\nsimultaneously.",
    "descriptor": "",
    "authors": [
      "Yangang Ren",
      "Jianhua Jiang",
      "Jingliang Duan",
      "Shengbo Eben Li",
      "Dongjie Yu",
      "Guojian Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12359"
  },
  {
    "id": "arXiv:2110.12363",
    "title": "Robust Sliding Mode Control of a Magnetic Levitation System:  Continuous-Time and Discrete-Time Approaches",
    "abstract": "This paper presents three types of sliding mode controllers for a magnetic\nlevitation system. First, a proportional-integral sliding mode controller\n(PI-SMC) is designed using a new switching surface and a proportional plus\npower rate reaching law. The PI-SMC is more robust than a feedback\nlinearization controller in the presence of mismatched uncertainties and\noutperforms the SMC schemes reported recently in the literature in terms of the\nconvergence rate and settling time. Next, to reduce the chattering phenomenon\nin the PI-SMC, a state feedback-based discrete-time SMC algorithm is developed.\nHowever, the disturbance rejection ability is compromised to some extent.\nFurthermore, to improve the robustness without compromising the chattering\nreduction benefits of the discrete-time SMC, mismatched uncertainties like\nsensor noise and track input disturbance are incorporated in a robust\ndiscrete-time SMC design using multirate output feedback (MROF). With this\ntechnique, it is possible to realize the effect of a full-state feedback\ncontroller without incurring the complexity of a dynamic controller or an\nadditional discrete-time observer. Also, the MROF-based discrete-time SMC\nstrategy can stabilize the magnetic levitation system with excellent dynamic\nand steady-state performance with superior robustness in the presence of\nmismatched uncertainties. The stability of the closed-loop system under the\nproposed controllers is proved by using the Lyapunov stability theory. The\nsimulation results and analytical comparisons demonstrate the effectiveness and\nrobustness of the proposed control schemes.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Pratik Vernekar",
      "Vitthal Bandal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12363"
  },
  {
    "id": "arXiv:2110.12364",
    "title": "CvT-ASSD: Convolutional vision-Transformer Based Attentive Single Shot  MultiBox Detector",
    "abstract": "Due to the success of Bidirectional Encoder Representations from Transformers\n(BERT) in natural language process (NLP), the multi-head attention transformer\nhas been more and more prevalent in computer-vision researches (CV). However,\nit still remains a challenge for researchers to put forward complex tasks such\nas vision detection and semantic segmentation. Although multiple\nTransformer-Based architectures like DETR and ViT-FRCNN have been proposed to\ncomplete object detection task, they inevitably decreases discrimination\naccuracy and brings down computational efficiency caused by the enormous\nlearning parameters and heavy computational complexity incurred by the\ntraditional self-attention operation. In order to alleviate these issues, we\npresent a novel object detection architecture, named Convolutional vision\nTransformer Based Attentive Single Shot MultiBox Detector (CvT-ASSD), that\nbuilt on the top of Convolutional vision Transormer (CvT) with the efficient\nAttentive Single Shot MultiBox Detector (ASSD). We provide comprehensive\nempirical evidence showing that our model CvT-ASSD can leads to good system\nefficiency and performance while being pretrained on large-scale detection\ndatasets such as PASCAL VOC and MS COCO. Code has been released on public\ngithub repository at https://github.com/albert-jin/CvT-ASSD.",
    "descriptor": "\nComments: 9 pages;5 figures; conference: IEEE ICTAI; Acknowledgment: The research reported in this paper was supported in part by the National Natural Science Foundation of China under the grant 91746203 and the Outstanding Academic Leader Project of Shanghai under the grant No.20XD1401700\n",
    "authors": [
      "Weiqiang Jin",
      "Hang Yu",
      "Hang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12364"
  },
  {
    "id": "arXiv:2110.12365",
    "title": "Conditional Generation of Periodic Signals with Fourier-Based Decoder",
    "abstract": "Periodic signals play an important role in daily lives. Although conventional\nsequential models have shown remarkable success in various fields, they still\ncome short in modeling periodicity; they either collapse, diverge or ignore\ndetails. In this paper, we introduce a novel framework inspired by Fourier\nseries to generate periodic signals. We first decompose the given signals into\nmultiple sines and cosines and then conditionally generate periodic signals\nwith the output components. We have shown our model efficacy on three tasks:\nreconstruction, imputation and conditional generation. Our model outperforms\nbaselines in all tasks and shows more stable and refined results.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications Poster Presentation\n",
    "authors": [
      "Jiyoung Lee",
      "Wonjae Kim",
      "Daehoon Gwak",
      "Edward Choi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12365"
  },
  {
    "id": "arXiv:2110.12367",
    "title": "Deep Learning for Simultaneous Inference of Hydraulic and Transport  Properties",
    "abstract": "Identifying the heterogeneous conductivity field and reconstructing the\ncontaminant release history are key aspects of subsurface remediation.\nAchieving these two goals with limited and noisy hydraulic head and\nconcentration measurements is challenging. The obstacles include solving an\ninverse problem for high-dimensional parameters, and the high-computational\ncost needed for the repeated forward modeling. We use a convolutional\nadversarial autoencoder (CAAE) for the parameterization of the heterogeneous\nnon-Gaussian conductivity field with a low-dimensional latent representation.\nAdditionally, we trained a three-dimensional dense convolutional\nencoder-decoder (DenseED) network to serve as the forward surrogate for the\nflow and transport processes. Combining the CAAE and DenseED forward surrogate\nmodels, the ensemble smoother with multiple data assimilation (ESMDA) algorithm\nis used to sample from the Bayesian posterior distribution of the unknown\nparameters, forming a CAAE-DenseED-ESMDA inversion framework. We applied this\nCAAE-DenseED-ESMDA inversion framework in a three-dimensional contaminant\nsource and conductivity field identification problem. A comparison of the\ninversion results from CAAE-ESMDA with physical flow and transport simulator\nand CAAE-DenseED-ESMDA is provided, showing that accurate reconstruction\nresults were achieved with a much higher computational efficiency.",
    "descriptor": "",
    "authors": [
      "Zitong Zhou",
      "Nicholas Zabaras",
      "Daniel M. Tartakovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12367"
  },
  {
    "id": "arXiv:2110.12369",
    "title": "AuxAdapt: Stable and Efficient Test-Time Adaptation for Temporally  Consistent Video Semantic Segmentation",
    "abstract": "In video segmentation, generating temporally consistent results across frames\nis as important as achieving frame-wise accuracy. Existing methods rely either\non optical flow regularization or fine-tuning with test data to attain temporal\nconsistency. However, optical flow is not always avail-able and reliable.\nBesides, it is expensive to compute. Fine-tuning the original model in test\ntime is cost sensitive.\nThis paper presents an efficient, intuitive, and unsupervised online\nadaptation method, AuxAdapt, for improving the temporal consistency of most\nneural network models. It does not require optical flow and only takes one pass\nof the video. Since inconsistency mainly arises from the model's uncertainty in\nits output, we propose an adaptation scheme where the model learns from its own\nsegmentation decisions as it streams a video, which allows producing more\nconfident and temporally consistent labeling for similarly-looking pixels\nacross frames. For stability and efficiency, we leverage a small auxiliary\nsegmentation network (AuxNet) to assist with this adaptation. More\nspecifically, AuxNet readjusts the decision of the original segmentation\nnetwork (Main-Net) by adding its own estimations to that of MainNet. At every\nframe, only AuxNet is updated via back-propagation while keeping MainNet fixed.\nWe extensively evaluate our test-time adaptation approach on standard video\nbenchmarks, including Cityscapes, CamVid, and KITTI. The results demonstrate\nthat our approach provides label-wise accurate, temporally consistent, and\ncomputationally efficient adaptation (5+ folds overhead reduction comparing to\nstate-of-the-art test-time adaptation methods).",
    "descriptor": "\nComments: To appear in WACV 2022; Comments and questions are welcome;\n",
    "authors": [
      "Yizhe Zhang",
      "Shubhankar Borse",
      "Hong Cai",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.12369"
  },
  {
    "id": "arXiv:2110.12370",
    "title": "Team Enigma at ArgMining-EMNLP 2021: Leveraging Pre-trained Language  Models for Key Point Matching",
    "abstract": "We present the system description for our submission towards the Key Point\nAnalysis Shared Task at ArgMining 2021. Track 1 of the shared task requires\nparticipants to develop methods to predict the match score between each pair of\narguments and keypoints, provided they belong to the same topic under the same\nstance. We leveraged existing state of the art pre-trained language models\nalong with incorporating additional data and features extracted from the inputs\n(topics, key points, and arguments) to improve performance. We were able to\nachieve mAP strict and mAP relaxed score of 0.872 and 0.966 respectively in the\nevaluation phase, securing 5th place on the leaderboard. In the post evaluation\nphase, we achieved a mAP strict and mAP relaxed score of 0.921 and 0.982\nrespectively. All the codes to generate reproducible results on our models are\navailable on Github.",
    "descriptor": "",
    "authors": [
      "Manav Nitin Kapadnis",
      "Sohan Patnaik",
      "Siba Smarak Panigrahi",
      "Varun Madhavan",
      "Abhilash Nandy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12370"
  },
  {
    "id": "arXiv:2110.12373",
    "title": "Inspiration Hunter for Picture Design via Cut-transform-paste",
    "abstract": "The digital era transformed design paradigms, blurring borders among\nexploration, ideation, and construction. Crowd generated big digital data\nemerged as a new material. There appears to be a need for new content creation\ntools which do not ignore complex interaction among traditionally separate\nstages and roles. To address this need in picture design, we present an\nopen-source platform called Inspiration Hunter. It facilitates ideation via\nsearch-edit by supplying infinitely many dynamic possibilities available\nthrough the web without leaving the content creation environment, hence,\nseamlessly integrates exploration, ideation, and construction. User experiences\nshow that the platform successfully enables reuse of web data both as a\nconceptual stimulant and as a material available for cut-transform-paste.\nExtending grammar-based approach to shape design, Inspiration Hunter mediates\ndata-enabled collaborative creativity beyond common intention, time or space.",
    "descriptor": "",
    "authors": [
      "Gulce Bal Bozkurt",
      "Sibel Tari"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12373"
  },
  {
    "id": "arXiv:2110.12374",
    "title": "Transliterating Kurdish texts in Latin into Persian-Arabic script",
    "abstract": "Kurdish is written in different scripts. The two most popular scripts are\nLatin and Persian-Arabic. However, not all Kurdish readers are familiar with\nboth mentioned scripts that could be resolved by automatic transliterators. So\nfar, the developed tools mostly transliterate Persian-Arabic scripts into\nLatin. We present a transliterator to transliterate Kurdish texts in Latin into\nPersian-Arabic script. We also discuss the issues that should be considered in\nthe transliteration process. The tool is a part of Kurdish BLARK, and it is\npublicly available for non-commercial use",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Hossein Hassani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12374"
  },
  {
    "id": "arXiv:2110.12377",
    "title": "SenseMag: Enabling Low-Cost Traffic Monitoring using Non-invasive  Magnetic Sensing",
    "abstract": "The operation and management of intelligent transportation systems (ITS),\nsuch as traffic monitoring, relies on real-time data aggregation of vehicular\ntraffic information, including vehicular types (e.g., cars, trucks, and buses),\nin the critical roads and highways. While traditional approaches based on\nvehicular-embedded GPS sensors or camera networks would either invade drivers'\nprivacy or require high deployment cost, this paper introduces a low-cost\nmethod, namely SenseMag, to recognize the vehicular type using a pair of\nnon-invasive magnetic sensors deployed on the straight road section. SenseMag\nfilters out noises and segments received magnetic signals by the exact time\npoints that the vehicle arrives or departs from every sensor node. Further,\nSenseMag adopts a hierarchical recognition model to first estimate the\nspeed/velocity, then identify the length of vehicle using the predicted speed,\nsampling cycles, and the distance between the sensor nodes. With the vehicle\nlength identified and the temporal/spectral features extracted from the\nmagnetic signals, SenseMag classify the types of vehicles accordingly. Some\nsemi-automated learning techniques have been adopted for the design of filters,\nfeatures, and the choice of hyper-parameters. Extensive experiment based on\nreal-word field deployment (on the highways in Shenzhen, China) shows that\nSenseMag significantly outperforms the existing methods in both classification\naccuracy and the granularity of vehicle types (i.e., 7 types by SenseMag versus\n4 types by the existing work in comparisons). To be specific, our field\nexperiment results validate that SenseMag is with at least $90\\%$ vehicle type\nclassification accuracy and less than 5\\% vehicle length classification error.",
    "descriptor": "\nComments: Accepted by IEEE Internet of Things Journal\n",
    "authors": [
      "Kafeng Wang",
      "Haoyi Xiong",
      "Jie Zhang",
      "Hongyang Chen",
      "Dejing Dou",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12377"
  },
  {
    "id": "arXiv:2110.12381",
    "title": "Regularizing Variational Autoencoder with Diversity and Uncertainty  Awareness",
    "abstract": "As one of the most popular generative models, Variational Autoencoder (VAE)\napproximates the posterior of latent variables based on amortized variational\ninference. However, when the decoder network is sufficiently expressive, VAE\nmay lead to posterior collapse; that is, uninformative latent representations\nmay be learned. To this end, in this paper, we propose an alternative model,\nDU-VAE, for learning a more Diverse and less Uncertain latent space, and thus\nthe representation can be learned in a meaningful and compact manner.\nSpecifically, we first theoretically demonstrate that it will result in better\nlatent space with high diversity and low uncertainty awareness by controlling\nthe distribution of posterior's parameters across the whole data accordingly.\nThen, without the introduction of new loss terms or modifying training\nstrategies, we propose to exploit Dropout on the variances and\nBatch-Normalization on the means simultaneously to regularize their\ndistributions implicitly. Furthermore, to evaluate the generalization effect,\nwe also exploit DU-VAE for inverse autoregressive flow based-VAE (VAE-IAF)\nempirically. Finally, extensive experiments on three benchmark datasets clearly\nshow that our approach can outperform state-of-the-art baselines on both\nlikelihood estimation and underlying classification tasks.",
    "descriptor": "",
    "authors": [
      "Dazhong Shen",
      "Chuan Qin",
      "Chao Wang",
      "Hengshu Zhu",
      "Enhong Chen",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12381"
  },
  {
    "id": "arXiv:2110.12383",
    "title": "Automated Extraction of Sentencing Decisions from Court Cases in the  Hebrew Language",
    "abstract": "We present the task of Automated Punishment Extraction (APE) in sentencing\ndecisions from criminal court cases in Hebrew. Addressing APE will enable the\nidentification of sentencing patterns and constitute an important stepping\nstone for many follow up legal NLP applications in Hebrew, including the\nprediction of sentencing decisions. We curate a dataset of sexual assault\nsentencing decisions and a manually-annotated evaluation dataset, and implement\nrule-based and supervised models. We find that while supervised models can\nidentify the sentence containing the punishment with good accuracy, rule-based\napproaches outperform them on the full APE task. We conclude by presenting a\nfirst analysis of sentencing patterns in our dataset and analyze common models'\nerrors, indicating avenues for future work, such as distinguishing between\nprobation and actual imprisonment punishment. We will make all our resources\navailable upon request, including data, annotation, and first benchmark models.",
    "descriptor": "\nComments: Accepted to the Natural Legal Language Processing workshop (NLLP 2021), colocated with EMNLP 2021\n",
    "authors": [
      "Mohr Wenger",
      "Tom Kalir",
      "Noga Berger",
      "Carmit Chalamish",
      "Renana Keydar",
      "Gabriel Stanovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12383"
  },
  {
    "id": "arXiv:2110.12385",
    "title": "Perceptual Consistency in Video Segmentation",
    "abstract": "In this paper, we present a novel perceptual consistency perspective on video\nsemantic segmentation, which can capture both temporal consistency and\npixel-wise correctness. Given two nearby video frames, perceptual consistency\nmeasures how much the segmentation decisions agree with the pixel\ncorrespondences obtained via matching general perceptual features. More\nspecifically, for each pixel in one frame, we find the most perceptually\ncorrelated pixel in the other frame. Our intuition is that such a pair of\npixels are highly likely to belong to the same class. Next, we assess how much\nthe segmentation agrees with such perceptual correspondences, based on which we\nderive the perceptual consistency of the segmentation maps across these two\nframes. Utilizing perceptual consistency, we can evaluate the temporal\nconsistency of video segmentation by measuring the perceptual consistency over\nconsecutive pairs of segmentation maps in a video. Furthermore, given a\nsparsely labeled test video, perceptual consistency can be utilized to aid with\npredicting the pixel-wise correctness of the segmentation on an unlabeled\nframe. More specifically, by measuring the perceptual consistency between the\npredicted segmentation and the available ground truth on a nearby frame and\ncombining it with the segmentation confidence, we can accurately assess the\nclassification correctness on each pixel. Our experiments show that the\nproposed perceptual consistency can more accurately evaluate the temporal\nconsistency of video segmentation as compared to flow-based measures.\nFurthermore, it can help more confidently predict segmentation accuracy on\nunlabeled test frames, as compared to using classification confidence alone.\nFinally, our proposed measure can be used as a regularizer during the training\nof segmentation models, which leads to more temporally consistent video\nsegmentation while maintaining accuracy.",
    "descriptor": "\nComments: To appear in WACV 2022. Comments and questions are welcome\n",
    "authors": [
      "Yizhe Zhang",
      "Shubhankar Borse",
      "Hong Cai",
      "Ying Wang",
      "Ning Bi",
      "Xiaoyun Jiang",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.12385"
  },
  {
    "id": "arXiv:2110.12388",
    "title": "An adaptive model hierarchy for data-augmented training of kernel models  for reactive flow",
    "abstract": "We consider machine-learning of time-dependent quantities of interest derived\nfrom solution trajectories of parabolic partial differential equations. For\nlarge-scale or long-time integration scenarios, where using a full order model\n(FOM) to generate sufficient training data is computationally prohibitive, we\npropose an adaptive hierarchy of intermediate Reduced Basis reduced order\nmodels (ROM) to augment the FOM training data by certified ROM training data\nrequired to fit a kernel model.",
    "descriptor": "",
    "authors": [
      "Bernard Haasdonk",
      "Mario Ohlberger",
      "Felix Schindler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12388"
  },
  {
    "id": "arXiv:2110.12395",
    "title": "Weighted Automata and Expressions over Pre-Rational Monoids",
    "abstract": "The Kleene theorem establishes a fundamental link between automata and\nexpressions over the free monoid. Numerous generalisations of this result exist\nin the literature. Lifting this result to a weighted setting has been widely\nstudied. Moreover, different monoids can be considered: for instance, two-way\nautomata, and even tree-walking automata, can be described by expressions using\nthe free inverse monoid. In the present work, we aim at combining both research\ndirections and consider weighted extensions of automata and expressions over a\nclass of monoids that we call pre-rational, generalising both the free inverse\nmonoid and graded monoids. The presence of idempotent elements in these\npre-rational monoids leads in the weighted setting to consider infinite sums.\nTo handle such sums, we will have to restrict ourselves to rationally additive\nsemirings. Our main result is thus a generalisation of the Kleene theorem for\npre-rational monoids and rationally additive semirings. As a corollary, we\nobtain a class of expressions equivalent to weighted two-way automata, as well\nas one for tree-walking automata.",
    "descriptor": "",
    "authors": [
      "Nicolas Baudru",
      "Louis-Marie Dando",
      "Nathan Lhote",
      "Benjamin Monmege",
      "Pierre-Alain Reynier",
      "Jean-Marc Talbot"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.12395"
  },
  {
    "id": "arXiv:2110.12396",
    "title": "Using Motion History Images with 3D Convolutional Networks in Isolated  Sign Language Recognition",
    "abstract": "Sign language recognition using computational models is a challenging problem\nthat requires simultaneous spatio-temporal modeling of the multiple sources,\ni.e. faces, hands, body etc. In this paper, we propose an isolated sign\nlanguage recognition model based on a model trained using Motion History Images\n(MHI) that are generated from RGB video frames. RGB-MHI images represent\nspatio-temporal summary of each sign video effectively in a single RGB image.\nWe propose two different approaches using this model. In the first approach, we\nuse RGB-MHI model as a motion-based spatial attention module integrated in a\n3D-CNN architecture. In the second approach, we use RGB-MHI model features\ndirectly with a late fusion technique with the features of a 3D-CNN model. We\nperform extensive experiments on two recently released large-scale isolated\nsign language datasets, namely AUTSL and BosphorusSign22k datasets. Our\nexperiments show that our models, which use only RGB data, can compete with the\nstate-of-the-art models in the literature that use multi-modal data.",
    "descriptor": "",
    "authors": [
      "Ozge Mercanoglu Sincan",
      "Hacer Yalim Keles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12396"
  },
  {
    "id": "arXiv:2110.12397",
    "title": "Path Planning of a Spin-Rolling Sphere on a Plane",
    "abstract": "The paper deals with motion planning for a spin-rolling sphere when the\nsphere follows a straight path on a plane. Since the motion of the sphere is\nconstrained by the straight line, the control of the sphere's spin motion is\nessential to converge to a desired configuration of the sphere. In this paper,\nwe show a new geometric-based planning approach that is based on a full-state\ndescription of this nonlinear system. First, the problem statement of the\nmotion planning is posed. Next, we develop a geometric controller implemented\nas a virtual surface by using the Darboux frame kinematics. This virtual\nsurface generates arc-length-based inputs for controlling the trajectories of\nthe sphere. Then, an iterative algorithm is designed to tune these inputs for\nthe desired configurations. The feasibility of the proposed approach is\nverified by simulations.",
    "descriptor": "\nComments: 23 Pages, 16 figures, under review\n",
    "authors": [
      "Seyed Amir Tafrishi",
      "Mikhail Svinin",
      "Motoji Yamamoto",
      "Yasuhisa Hirata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2110.12397"
  },
  {
    "id": "arXiv:2110.12399",
    "title": "IQNAS: Interpretable Integer Quadratic Programming Neural Architecture  Search",
    "abstract": "Realistic use of neural networks often requires adhering to multiple\nconstraints on latency, energy and memory among others. A popular approach to\nfind fitting networks is through constrained Neural Architecture Search (NAS).\nHowever, previous methods use complicated predictors for the accuracy of the\nnetwork. Those predictors are hard to interpret and sensitive to many\nhyperparameters to be tuned, hence, the resulting accuracy of the generated\nmodels is often harmed. In this work we resolve this by introducing\nInterpretable Integer Quadratic programming Neural Architecture Search (IQNAS),\nthat is based on an accurate and simple quadratic formulation of both the\naccuracy predictor and the expected resource requirement, together with a\nscalable search method with theoretical guarantees. The simplicity of our\nproposed predictor together with the intuitive way it is constructed bring\ninterpretability through many insights about the contribution of different\ndesign choices. For example, we find that in the examined search space, adding\ndepth and width is more effective at deeper stages of the network and at the\nbeginning of each resolution stage. Our experiments show that IQNAS generates\ncomparable to or better architectures than other state-of-the-art NAS methods\nwithin a reduced search cost for each additional generated network, while\nstrictly satisfying the resource constraints.",
    "descriptor": "",
    "authors": [
      "Niv Nayman",
      "Yonathan Aflalo",
      "Asaf Noy",
      "Rong Jin",
      "Lihi Zelnik-Manor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12399"
  },
  {
    "id": "arXiv:2110.12401",
    "title": "A Dynamic Keypoints Selection Network for 6DoF Pose Estimation",
    "abstract": "6 DoF poses estimation problem aims to estimate the rotation and translation\nparameters between two coordinates, such as object world coordinate and camera\nworld coordinate. Although some advances are made with the help of deep\nlearning, how to full use scene information is still a problem. Prior works\ntackle the problem by pixel-wise feature fusion but need to randomly selecte\nnumerous points from images, which can not satisfy the demands of fast\ninference simultaneously and accurate pose estimation. In this work, we present\na novel deep neural network based on dynamic keypoints selection designed for\n6DoF pose estimation from a single RGBD image. Our network includes three\nparts, instance semantic segmentation, edge points detection and 6DoF pose\nestimation. Given an RGBD image, our network is trained to predict pixel\ncategory and the translation to edge points and center points. Then, a\nleast-square fitting manner is applied to estimate the 6DoF pose parameters.\nSpecifically, we propose a dynamic keypoints selection algorithm to choose\nkeypoints from the foreground feature map. It allows us to leverage geometric\nand appearance information. During 6DoF pose estimation, we utilize the\ninstance semantic segmentation result to filter out background points and only\nuse foreground points to finish edge points detection and 6DoF pose estimation.\nExperiments on two commonly used 6DoF estimation benchmark datasets, YCB-Video\nand LineMoD, demonstrate that our method outperforms the state-of-the-art\nmethods and achieves significant improvements over other same category methods\ntime efficiency.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Haowen Sun",
      "Taiyong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12401"
  },
  {
    "id": "arXiv:2110.12402",
    "title": "Approximating LCS and Alignment Distance over Multiple Sequences",
    "abstract": "We study the problem of aligning multiple sequences with the goal of finding\nan alignment that either maximizes the number of aligned symbols (the longest\ncommon subsequence (LCS)), or minimizes the number of unaligned symbols (the\nalignment distance (AD)). Multiple sequence alignment is a well-studied problem\nin bioinformatics and is used to identify regions of similarity among DNA, RNA,\nor protein sequences to detect functional, structural, or evolutionary\nrelationships among them. It is known that exact computation of LCS or AD of\n$m$ sequences each of length $n$ requires $\\Theta(n^m)$ time unless the Strong\nExponential Time Hypothesis is false. In this paper, we provide several results\nto approximate LCS and AD of multiple sequences.\nIf the LCS of $m$ sequences each of length $n$ is $\\lambda n$ for some\n$\\lambda \\in [0,1]$, then in $\\tilde{O}_m(n^{\\lfloor\\frac{m}{2}\\rfloor+1})$\ntime, we can return a common subsequence of length at least $\\frac{\\lambda^2\nn}{2+\\epsilon}$ for any arbitrary constant $\\epsilon >0$.\nIt is possible to approximate the AD within a factor of two in time\n$\\tilde{O}_m(n^{\\lceil\\frac{m}{2}\\rceil})$. However, going below-2\napproximation requires breaking the triangle inequality barrier which is a\nmajor challenge in this area. No such algorithm with a running time of\n$O(n^{\\alpha m})$ for any $\\alpha < 1$ is known. If the AD is $\\theta n$, then\nwe design an algorithm that approximates the AD within an approximation factor\nof $\\left(2-\\frac{3\\theta}{16}+\\epsilon\\right)$ in\n$\\tilde{O}_m(n^{\\lfloor\\frac{m}{2}\\rfloor+2})$ time. Thus, if $\\theta$ is a\nconstant, we get a below-two approximation in\n$\\tilde{O}_m(n^{\\lfloor\\frac{m}{2}\\rfloor+2})$ time. Moreover, we show if just\none out of $m$ sequences is $(p,B)$-pseudorandom then, we get a below-2\napproximation in $\\tilde{O}_m(nB^{m-1}+n^{\\lfloor \\frac{m}{2}\\rfloor+3})$ time\nirrespective of $\\theta$.",
    "descriptor": "",
    "authors": [
      "Debarati Das",
      "Barna Saha"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.12402"
  },
  {
    "id": "arXiv:2110.12403",
    "title": "Learning to Estimate Without Bias",
    "abstract": "We consider the use of deep learning for parameter estimation. We propose\nBias Constrained Estimators (BCE) that add a squared bias term to the standard\nmean squared error (MSE) loss. The main motivation to BCE is learning to\nestimate deterministic unknown parameters with no Bayesian prior. Unlike\nstandard learning based estimators that are optimal on average, we prove that\nBCEs converge to Minimum Variance Unbiased Estimators (MVUEs). We derive closed\nform solutions to linear BCEs. These provide a flexible bridge between linear\nregrssion and the least squares method. In non-linear settings, we demonstrate\nthat BCEs perform similarly to MVUEs even when the latter are computationally\nintractable. A second motivation to BCE is in applications where multiple\nestimates of the same unknown are averaged for improved performance. Examples\ninclude distributed sensor networks and data augmentation in test-time. In such\napplications, unbiasedness is a necessary condition for asymptotic consistency.",
    "descriptor": "",
    "authors": [
      "Tzvi Diskin",
      "Yonina C. Eldar",
      "Ami Wiesel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12403"
  },
  {
    "id": "arXiv:2110.12408",
    "title": "Quantum Computer Music: Foundations and Initial Experiments",
    "abstract": "Quantum computing is a nascent technology, which is advancing rapidly. There\nis a long history of research into using computers for music. Nowadays\ncomputers are absolutely essential for the music economy. Thus, it is very\nlikely that quantum computers will impact the music industry in time to come.\nThis chapter lays the foundations of the new field of 'Quantum Computer Music'.\nIt begins with an introduction to algorithmic computer music and methods to\nprogram computers to generate music, such as Markov chains and random walks.\nThen, it presents quantum computing versions of those methods. The discussions\nare supported by detailed explanations of quantum computing concepts and\nwalk-through examples. A bespoke generative music algorithm is presented, the\nBasak-Miranda algorithm, which leverages a property of quantum mechanics known\nas constructive and destructive interference to operate a musical Markov chain.\nAn Appendix introducing the fundamentals of quantum computing deemed necessary\nto understand the chapter and a link to access Jupyter Notebooks with examples\nare also provided.",
    "descriptor": "\nComments: Pre-publication draft, to appear in book 'Quantum Computer Music', E. R. Miranda (Ed.). arXiv admin note: text overlap with arXiv:2006.13849\n",
    "authors": [
      "Eduardo R. Miranda",
      "Suchitra T. Bask"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.12408"
  },
  {
    "id": "arXiv:2110.12412",
    "title": "Improved Goal Oriented Dialogue via Utterance Generation and Look Ahead",
    "abstract": "Goal oriented dialogue systems have become a prominent customer-care\ninteraction channel for most businesses. However, not all interactions are\nsmooth, and customer intent misunderstanding is a major cause of dialogue\nfailure. We show that intent prediction can be improved by training a deep\ntext-to-text neural model to generate successive user utterances from unlabeled\ndialogue data. For that, we define a multi-task training regime that utilizes\nsuccessive user-utterance generation to improve the intent prediction. Our\napproach achieves the reported improvement due to two complementary factors:\nFirst, it uses a large amount of unlabeled dialogue data for an auxiliary\ngeneration task. Second, it uses the generated user utterance as an additional\nsignal for the intent prediction model. Lastly, we present a novel look-ahead\napproach that uses user utterance generation to improve intent prediction in\ninference time. Specifically, we generate counterfactual successive user\nutterances for conversations with ambiguous predicted intents, and disambiguate\nthe prediction by reassessing the concatenated sequence of available and\ngenerated utterances.",
    "descriptor": "",
    "authors": [
      "Eyal Ben-David",
      "Boaz Carmeli",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12412"
  },
  {
    "id": "arXiv:2110.12414",
    "title": "A Compact Coupling Interface Method with Accurate Gradient Approximation  for Elliptic Interface Problems",
    "abstract": "Elliptic interface boundary value problems play a major role in numerous\napplications involving heat, fluids, materials, and proteins, to name a few. As\nan example, in implicit variational solvation, for the construction of\nbiomolecular shapes, the electrostatic contributions satisfy the\nPoisson-Boltzmann equation with discontinuous dielectric constants across the\ninterface. When interface motions are involved, one often needs not only\naccurate solution values, but accurate derivatives as well, such as the normal\nderivatives at the interface. We introduce here the Compact Coupling Interface\nMethod (CCIM), a finite difference method for the elliptic interface problem\nwith interfacial jump conditions. The CCIM can calculate solution values and\ntheir derivatives up to second-order accuracy in arbitrary ambient space\ndimensions. It combines elements of Chern and Shu's Coupling Interface Method\nand Mayo's approach for elliptic interface boundary value problems, leading to\nmore compact finite difference stencils that are applicable to more general\nsituations. Numerical results on a variety of geometric interfacial shapes and\non complex protein molecules in three dimensions support the efficacy of our\napproach and reveal advantages in accuracy and robustness.",
    "descriptor": "",
    "authors": [
      "Zirui Zhang",
      "Li-Tien Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12414"
  },
  {
    "id": "arXiv:2110.12415",
    "title": "A Distributed Deep Reinforcement Learning Technique for Application  Placement in Edge and Fog Computing Environments",
    "abstract": "Fog/Edge computing is a novel computing paradigm supporting\nresource-constrained Internet of Things (IoT) devices by the placement of their\ntasks on the edge and/or cloud servers. Recently, several Deep Reinforcement\nLearning (DRL)-based placement techniques have been proposed in fog/edge\ncomputing environments, which are only suitable for centralized setups. The\ntraining of well-performed DRL agents requires manifold training data while\nobtaining training data is costly. Hence, these centralized DRL-based\ntechniques lack generalizability and quick adaptability, thus failing to\nefficiently tackle application placement problems. Moreover, many IoT\napplications are modeled as Directed Acyclic Graphs (DAGs) with diverse\ntopologies. Satisfying dependencies of DAG-based IoT applications incur\nadditional constraints and increase the complexity of placement problems. To\novercome these challenges, we propose an actor-critic-based distributed\napplication placement technique, working based on the IMPortance weighted\nActor-Learner Architectures (IMPALA). IMPALA is known for efficient distributed\nexperience trajectory generation that significantly reduces the exploration\ncosts of agents. Besides, it uses an adaptive off-policy correction method for\nfaster convergence to optimal solutions. Our technique uses recurrent layers to\ncapture temporal behaviors of input data and a replay buffer to improve the\nsample efficiency. The performance results, obtained from simulation and\ntestbed experiments, demonstrate that our technique significantly improves the\nexecution cost of IoT applications up to 30\\% compared to its counterparts.",
    "descriptor": "\nComments: This Paper is accepted in IEEE Transactions on Mobile Computing (TMC), on 23 October 2021\n",
    "authors": [
      "Mohammad Goudarzi",
      "Marimuthu Palaniswami",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12415"
  },
  {
    "id": "arXiv:2110.12416",
    "title": "Sentence Punctuation for Collaborative Commentary Generation in Esports  Live-Streaming",
    "abstract": "To solve the existing sentence punctuation problem for collaborative\ncommentary generation in Esports live-streaming, this paper presents two\nstrategies for sentence punctuation for text sequences of game commentary, that\nis, punctuating sentences by two or three text sequence(s) originally\npunctuated by Youtube to obtain a complete sentence of commentary. We conducted\ncomparative experiments utilizing and fine-tuning a state-of-the-art\npre-trained generative language model among two strategies and the baseline to\ngenerate collaborative commentary. Both objective evaluations by automatic\nmetrics and subjective analyses showed that our strategy of punctuating\nsentences by two text sequences outperformed the baseline.",
    "descriptor": "\nComments: 2 pages, review manuscript, accepted by IEEE ICCE 2022\n",
    "authors": [
      "Hong Huang",
      "Junjie H. Xu",
      "Xiaoling Ling",
      "Pujana Paliyawan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.12416"
  },
  {
    "id": "arXiv:2110.12421",
    "title": "Refuting Tianrong Lin's arXiv:2110.05942 \"Resolution of The  Linear-Bounded Automata Question''",
    "abstract": "In the preprint mentioned in the title Mr. Tianrong claims to prove\n$\\textrm{NSPACE}[n]\\neq\\textrm{DSPACE}[n]$, resolving a longstanding open\nproblem in automata theory called the LBA question. He claims to achieve this\nby showing more generally $\\textrm{NSPACE}[S(n)]\\neq\\textrm{DSPACE}[S(n)]$ for\nsuitable $S(n)$. We demonstrate that his proof is incomplete, even wrong, and\nhis strategy cannot be repaired.",
    "descriptor": "\nComments: 7 pages, refers to arXiv:2110.05942 by Tianrong Lin\n",
    "authors": [
      "Thomas Preu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.12421"
  },
  {
    "id": "arXiv:2110.12422",
    "title": "A Differentiable Newton-Euler Algorithm for Real-World Robotics",
    "abstract": "Obtaining dynamics models is essential for robotics to achieve accurate\nmodel-based controllers and simulators for planning. The dynamics models are\ntypically obtained using model specification of the manufacturer or simple\nnumerical methods such as linear regression. However, this approach does not\nguarantee physically plausible parameters and can only be applied to kinematic\nchains consisting of rigid bodies. In this article, we describe a\ndifferentiable simulator that can be used to identify the system parameters of\nreal-world mechanical systems with complex friction models, holonomic as well\nas non-holonomic constraints. To guarantee physically consistent parameters, we\nutilize virtual parameters and gradient-based optimization. The described\nDifferentiable Newton-Euler Algorithm (DiffNEA) can be applied to a class of\ndynamical systems and guarantees physically plausible predictions. The\nextensive experimental evaluation shows, that the proposed model learning\napproach learns accurate dynamics models of systems with complex friction and\nnon-holonomic constraints. Especially in the offline reinforcement learning\nexperiments, the identified DiffNEA models excel. For the challenging ball in a\ncup task, these models solve the task using model-based offline reinforcement\nlearning on the physical system. The black-box baselines fail on this task in\nsimulation and on the physical system despite using more data for learning the\nmodel.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.01734\n",
    "authors": [
      "Michael Lutter",
      "Johannes Silberbauer",
      "Joe Watson",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12422"
  },
  {
    "id": "arXiv:2110.12423",
    "title": "NAS-FCOS: Efficient Search for Object Detection Architectures",
    "abstract": "Neural Architecture Search (NAS) has shown great potential in effectively\nreducing manual effort in network design by automatically discovering optimal\narchitectures. What is noteworthy is that as of now, object detection is less\ntouched by NAS algorithms despite its significant importance in computer\nvision. To the best of our knowledge, most of the recent NAS studies on object\ndetection tasks fail to satisfactorily strike a balance between performance and\nefficiency of the resulting models, let alone the excessive amount of\ncomputational resources cost by those algorithms. Here we propose an efficient\nmethod to obtain better object detectors by searching for the feature pyramid\nnetwork (FPN) as well as the prediction head of a simple anchor-free object\ndetector, namely, FCOS [36], using a tailored reinforcement learning paradigm.\nWith carefully designed search space, search algorithms, and strategies for\nevaluating network quality, we are able to find top-performing detection\narchitectures within 4 days using 8 V100 GPUs. The discovered architectures\nsurpass state-of-the-art object detection models (such as Faster R-CNN,\nRetina-Net and, FCOS) by 1.0% to 5.4% points in AP on the COCO dataset, with\ncomparable computation complexity and memory footprint, demonstrating the\nefficacy of the proposed NAS method for object detection. Code is available at\nhttps://github.com/Lausannen/NAS-FCOS.",
    "descriptor": "\nComments: 14 pages, 11 figures, journal extension of NAS-FCOS (CVPR 2020), accepted by IJCV. arXiv admin note: substantial text overlap with arXiv:1906.04423\n",
    "authors": [
      "Ning Wang",
      "Yang Gao",
      "Hao Chen",
      "Peng Wang",
      "Zhi Tian",
      "Chunhua Shen",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12423"
  },
  {
    "id": "arXiv:2110.12425",
    "title": "Kernelized Heterogeneous Risk Minimization",
    "abstract": "The ability to generalize under distributional shifts is essential to\nreliable machine learning, while models optimized with empirical risk\nminimization usually fail on non-$i.i.d$ testing data. Recently, invariant\nlearning methods for out-of-distribution (OOD) generalization propose to find\ncausally invariant relationships with multi-environments. However, modern\ndatasets are frequently multi-sourced without explicit source labels, rendering\nmany invariant learning methods inapplicable. In this paper, we propose\nKernelized Heterogeneous Risk Minimization (KerHRM) algorithm, which achieves\nboth the latent heterogeneity exploration and invariant learning in kernel\nspace, and then gives feedback to the original neural network by appointing\ninvariant gradient direction. We theoretically justify our algorithm and\nempirically validate the effectiveness of our algorithm with extensive\nexperiments.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia. arXiv admin note: text overlap with arXiv:2105.03818\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyuan Hu",
      "Peng Cui",
      "Bo Li",
      "Zheyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12425"
  },
  {
    "id": "arXiv:2110.12427",
    "title": "Image-Based CLIP-Guided Essence Transfer",
    "abstract": "CLIP is trained on a large corpus of matched images and text captions and is,\ntherefore, much richer semantically than networks that perform multiclass\nclassification for a limited number of classes only. It has been shown to be\nextremely suitable for zero-shot computer vision tasks; here, we demonstrate\nits ability to support semantic blending. While the StyleGAN space already\nperforms reasonable blending for images of, e.g., two children, it struggles\nwhen blending images with different attributes. On the other hand, CLIP by\nitself struggles to maintain identity when blending. The combination of the two\nseems to provide a powerful blending technique, which enjoys the benefits of\nboth representations. This is enabled through a novel method, which assumes\nadditivity in the first latent space and ensures additivity in the second\nthrough optimization.",
    "descriptor": "",
    "authors": [
      "Hila Chefer",
      "Sagie Benaim",
      "Roni Paiss",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12427"
  },
  {
    "id": "arXiv:2110.12432",
    "title": "Numerical reparametrization of periodic planar curves via curvature  interpolation",
    "abstract": "A novel static algorithm is proposed for numerical reparametrization of\nperiodic planar curves. The method identifies a monitor function of the\narclength variable with the true curvature of an open planar curve and\nconsiders a simple interpolation between the object and the unit circle at the\ncurvature level. Since a convenient formula is known for tangential velocity\nthat maintains the equidistribution rule with curvature-type monitor functions,\nthe strategy enables to compute the correspondence between the arclength and\nanother spatial variable by evolving the interpolated curve. With a certain\nnormalization, velocity information in the motion is obtained with spectral\naccuracy while the resulting parametrization remains unchanged. Then, the\nalgorithm extracts a refined representation of the input curve by sampling its\narclength parametrization whose Fourier coefficients are directly accessed\nthrough a simple change of variables. As a validation, improvements to spatial\nresolution are evaluated by approximating the invariant coefficients from\ndownsampled data and observing faster global convergence to the original shape.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Kazuki Koga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12432"
  },
  {
    "id": "arXiv:2110.12433",
    "title": "Model Predictive Control with Gaussian Processes for Flexible  Multi-Modal Physical Human Robot Interaction",
    "abstract": "Physical human-robot interaction can improve human ergonomics, task\nefficiency, and the flexibility of automation, but often requires\napplication-specific methods to detect human state and determine robot\nresponse. At the same time, many potential human-robot interaction tasks\ninvolve discrete modes, such as phases of a task or multiple possible goals,\nwhere each mode has a distinct objective and human behavior. In this paper, we\npropose a novel method for multi-modal physical human-robot interaction that\nbuilds a Gaussian process model for human force in each mode of a collaborative\ntask. These models are then used for Bayesian inference of the mode, and to\ndetermine robot reactions through model predictive control. This approach\nenables optimization of robot trajectory based on the belief of human intent,\nwhile considering robot impedance and human joint configuration, according to\nergonomic- and/or task-related objectives. The proposed method reduces\nprogramming time and complexity, requiring only a low number of demonstrations\n(here, three per mode) and a mode-specific objective function to commission a\nflexible online human-robot collaboration task. We validate the method with\nexperiments on an admittance-controlled industrial robot, performing a\ncollaborative assembly task with two modes where assistance is provided in full\nsix degrees of freedom. It is shown that the developed algorithm robustly\nre-plans to changes in intent or robot initial position, achieving online\ncontrol at 15 Hz.",
    "descriptor": "\nComments: Submitted, ICRA 2022. Video: this https URL Data and code: this https URL\n",
    "authors": [
      "Kevin Haninger",
      "Christian Hegeler",
      "Luka Peternel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12433"
  },
  {
    "id": "arXiv:2110.12435",
    "title": "Contact Information Flow and Design of Compliance",
    "abstract": "The objective of many contact-rich manipulation tasks can be expressed as\ndesired contacts between environmental objects. Simulation and planning for\nrigid-body contact continues to advance, but the achievable performance is\nsignificantly impacted by hardware design, such as physical compliance and\nsensor placement. Much of mechatronic design for contact is done from a\ncontinuous controls perspective (e.g. peak collision force, contact stability),\nbut hardware also affects the ability to infer discrete changes in contact.\nRobustly detecting contact state can support the correction of errors, both\nonline and in trial-and-error learning.\nHere, discrete contact states are considered as changes in environmental\ndynamics, and the ability to infer this with proprioception (motor position and\nforce sensors) is investigated. A metric of information gain is proposed,\nmeasuring the reduction in contact belief uncertainty from force/position\nmeasurements, and developed for fully- and partially-observed systems. The\ninformation gain depends on the coupled robot/environment dynamics and sensor\nplacement, especially the location and degree of compliance. Hardware\nexperiments over a range of physical compliance conditions validate that\ninformation gain predicts the speed and certainty with which contact is\ndetected in (i) monitoring of contact-rich assembly and (ii) collision\ndetection. Compliant environmental structures are then optimized to allow\nindustrial robots to achieve safe, higher-speed contact.",
    "descriptor": "\nComments: Submitted, ICRA 2022 Video: this https URL\n",
    "authors": [
      "Kevin Haninger",
      "Marcel Radke",
      "Richard Hartisch",
      "J\u00f6rg Kr\u00fcger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12435"
  },
  {
    "id": "arXiv:2110.12437",
    "title": "WARPd: A linearly convergent first-order method for inverse problems  with approximate sharpness conditions",
    "abstract": "Reconstruction of signals from undersampled and noisy measurements is a topic\nof considerable interest. Sharpness conditions directly control the recovery\nperformance of restart schemes for first-order methods without the need for\nrestrictive assumptions such as strong convexity. However, they are challenging\nto apply in the presence of noise or approximate model classes (e.g.,\napproximate sparsity). We provide a first-order method: Weighted, Accelerated\nand Restarted Primal-dual (WARPd), based on primal-dual iterations and a novel\nrestart-reweight scheme. Under a generic approximate sharpness condition, WARPd\nachieves stable linear convergence to the desired vector. Many problems of\ninterest fit into this framework. For example, we analyze sparse recovery in\ncompressed sensing, low-rank matrix recovery, matrix completion, TV\nregularization, minimization of $\\|Bx\\|_{l^1}$ under constraints\n($l^1$-analysis problems for general $B$), and mixed regularization problems.\nWe show how several quantities controlling recovery performance also provide\nexplicit approximate sharpness constants. Numerical experiments show that WARPd\ncompares favorably with specialized state-of-the-art methods and is ideally\nsuited for solving large-scale problems. We also present a noise-blind variant\nbased on the Square-Root LASSO decoder. Finally, we show how to unroll WARPd as\nneural networks. This approximation theory result provides lower bounds for\nstable and accurate neural networks for inverse problems and sheds light on\narchitecture choices. Code and a gallery of examples are made available online\nas a MATLAB package.",
    "descriptor": "",
    "authors": [
      "Matthew J. Colbrook"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12437"
  },
  {
    "id": "arXiv:2110.12442",
    "title": "Bangla Image Caption Generation through CNN-Transformer based  Encoder-Decoder Network",
    "abstract": "Automatic Image Captioning is the never-ending effort of creating\nsyntactically and validating the accuracy of textual descriptions of an image\nin natural language with context. The encoder-decoder structure used throughout\nexisting Bengali Image Captioning (BIC) research utilized abstract image\nfeature vectors as the encoder's input. We propose a novel transformer-based\narchitecture with an attention mechanism with a pre-trained ResNet-101 model\nimage encoder for feature extraction from images. Experiments demonstrate that\nthe language decoder in our technique captures fine-grained information in the\ncaption and, then paired with image features, produces accurate and diverse\ncaptions on the BanglaLekhaImageCaptions dataset. Our approach outperforms all\nexisting Bengali Image Captioning work and sets a new benchmark by scoring\n0.694 on BLEU-1, 0.630 on BLEU-2, 0.582 on BLEU-3, and 0.337 on METEOR.",
    "descriptor": "\nComments: 15 pages, 6 figures, 1 table, 6 equations\n",
    "authors": [
      "Md Aminul Haque Palash",
      "MD Abdullah Al Nasim",
      "Sourav Saha",
      "Faria Afrin",
      "Raisa Mallik",
      "Sathishkumar Samiappan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12442"
  },
  {
    "id": "arXiv:2110.12452",
    "title": "New Bounds for the Flock-of-Birds Problem",
    "abstract": "In this paper, we continue a line of work on obtaining succinct population\nprotocols for Presburger-definable predicates. More specifically, we focus on\nthreshold predicates. These are predicates of the form $n\\ge d$, where $n$ is a\nfree variable and $d$ is a constant.\nFor every $d$, we establish a 1-aware population protocol for this predicate\nwith $\\log_2 d + \\min\\{e, z\\} + O(1)$ states, where $e$ (resp., $z$) is the\nnumber of $1$'s (resp., $0$'s) in the binary representation of $d$ (resp., $d -\n1$). This improves upon an upper bound $4\\log_2 d + O(1)$ due to Blondin et al.\nWe also show that any 1-aware protocol for our problem must have at least\n$\\log_2(d)$ states. This improves upon a lower bound $\\log_3 d$ due to Blondin\net al.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Alexander Kozachinskiy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.12452"
  },
  {
    "id": "arXiv:2110.12459",
    "title": "Non-convex Distributionally Robust Optimization: Non-asymptotic Analysis",
    "abstract": "Distributionally robust optimization (DRO) is a widely-used approach to learn\nmodels that are robust against distribution shift. Compared with the standard\noptimization setting, the objective function in DRO is more difficult to\noptimize, and most of the existing theoretical results make strong assumptions\non the loss function. In this work we bridge the gap by studying DRO algorithms\nfor general smooth non-convex losses. By carefully exploiting the specific form\nof the DRO objective, we are able to provide non-asymptotic convergence\nguarantees even though the objective function is possibly non-convex,\nnon-smooth and has unbounded gradient noise. In particular, we prove that a\nspecial algorithm called the mini-batch normalized gradient descent with\nmomentum, can find an $\\epsilon$ first-order stationary point within $O(\n\\epsilon^{-4} )$ gradient complexity. We also discuss the conditional\nvalue-at-risk (CVaR) setting, where we propose a penalized DRO objective based\non a smoothed version of the CVaR that allows us to obtain a similar\nconvergence guarantee. We finally verify our theoretical results in a number of\ntasks and find that the proposed algorithm can consistently achieve prominent\nacceleration.",
    "descriptor": "\nComments: 25 pages; to appear in NeurIPS 2021\n",
    "authors": [
      "Jikai Jin",
      "Bohang Zhang",
      "Haiyang Wang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12459"
  },
  {
    "id": "arXiv:2110.12467",
    "title": "Robustness via Uncertainty-aware Cycle Consistency",
    "abstract": "Unpaired image-to-image translation refers to learning inter-image-domain\nmapping without corresponding image pairs. Existing methods learn deterministic\nmappings without explicitly modelling the robustness to outliers or predictive\nuncertainty, leading to performance degradation when encountering unseen\nperturbations at test time. To address this, we propose a novel probabilistic\nmethod based on Uncertainty-aware Generalized Adaptive Cycle Consistency\n(UGAC), which models the per-pixel residual by generalized Gaussian\ndistribution, capable of modelling heavy-tailed distributions. We compare our\nmodel with a wide variety of state-of-the-art methods on various challenging\ntasks including unpaired image translation of natural images, using standard\ndatasets, spanning autonomous driving, maps, facades, and also in medical\nimaging domain consisting of MRI. Experimental results demonstrate that our\nmethod exhibits stronger robustness towards unseen perturbations in test data.\nCode is released here:\nhttps://github.com/ExplainableML/UncertaintyAwareCycleConsistency.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021. Code is at this https URL arXiv admin note: substantial text overlap with arXiv:2102.11747\n",
    "authors": [
      "Uddeshya Upadhyay",
      "Yanbei Chen",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12467"
  },
  {
    "id": "arXiv:2110.12468",
    "title": "SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) aims to learn the optimal policy from a\npre-collected dataset without online interactions. Most of the existing studies\nfocus on distributional shift caused by out-of-distribution actions. However,\neven in-distribution actions can raise serious problems. Since the dataset only\ncontains limited information about the underlying model, offline RL is\nvulnerable to spurious correlations, i.e., the agent tends to prefer actions\nthat by chance lead to high returns, resulting in a highly suboptimal policy.\nTo address such a challenge, we propose a practical and theoretically\nguaranteed algorithm SCORE that reduces spurious correlations by combing an\nuncertainty penalty into policy evaluation. We show that this is consistent\nwith the pessimism principle studied in theory, and the proposed algorithm\nconverges to the optimal policy with a sublinear rate under mild assumptions.\nBy conducting extensive experiments on existing benchmarks, we show that SCORE\nnot only benefits from a solid theory but also obtains strong empirical results\non a variety of tasks.",
    "descriptor": "",
    "authors": [
      "Zhihong Deng",
      "Zuyue Fu",
      "Lingxiao Wang",
      "Zhuoran Yang",
      "Chenjia Bai",
      "Zhaoran Wang",
      "Jing Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12468"
  },
  {
    "id": "arXiv:2110.12470",
    "title": "Strongly minimal self-conjugate linearizations for polynomial and  rational matrices",
    "abstract": "We prove that we can always construct strongly minimal linearizations of an\narbitrary rational matrix from its Laurent expansion around the point at\ninfinity, which happens to be the case for polynomial matrices expressed in the\nmonomial basis. If the rational matrix has a particular self-conjugate\nstructure we show how to construct strongly minimal linearizations that\npreserve it. The structures that are considered are the Hermitian and\nskew-Hermitian rational matrices with respect to the real line, and the\npara-Hermitian and para-skew-Hermitian matrices with respect to the imaginary\naxis. We pay special attention to the construction of strongly minimal\nlinearizations for the particular case of structured polynomial matrices. The\nproposed constructions lead to efficient numerical algorithms for constructing\nstrongly minimal linearizations. The fact that they are valid for {\\em any}\nrational matrix is an improvement on any other previous approach for\nconstructing other classes of structure preserving linearizations, which are\nnot valid for any structured rational or polynomial matrix. The use of the\nrecent concept of strongly minimal linearization is the key for getting such\ngenerality.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Froil\u00e1n M. Dopico",
      "Mar\u00eda C. Quintana",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12470"
  },
  {
    "id": "arXiv:2110.12477",
    "title": "Exploring Gradient Flow Based Saliency for DNN Model Compression",
    "abstract": "Model pruning aims to reduce the deep neural network (DNN) model size or\ncomputational overhead. Traditional model pruning methods such as l-1 pruning\nthat evaluates the channel significance for DNN pay too much attention to the\nlocal analysis of each channel and make use of the magnitude of the entire\nfeature while ignoring its relevance to the batch normalization (BN) and ReLU\nlayer after each convolutional operation. To overcome these problems, we\npropose a new model pruning method from a new perspective of gradient flow in\nthis paper. Specifically, we first theoretically analyze the channel's\ninfluence based on Taylor expansion by integrating the effects of BN layer and\nReLU activation function. Then, the incorporation of the first-order Talyor\npolynomial of the scaling parameter and the shifting parameter in the BN layer\nis suggested to effectively indicate the significance of a channel in a DNN.\nComprehensive experiments on both image classification and image denoising\ntasks demonstrate the superiority of the proposed novel theory and scheme. Code\nis available at https://github.com/CityU-AIM-Group/GFBS.",
    "descriptor": "\nComments: ACM Multimedia 2021 (ACM MM'21)\n",
    "authors": [
      "Xinyu Liu",
      "Baopu Li",
      "Zhen Chen",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12477"
  },
  {
    "id": "arXiv:2110.12478",
    "title": "Deep Asymmetric Hashing with Dual Semantic Regression and Class  Structure Quantization",
    "abstract": "Recently, deep hashing methods have been widely used in image retrieval task.\nMost existing deep hashing approaches adopt one-to-one quantization to reduce\ninformation loss. However, such class-unrelated quantization cannot give\ndiscriminative feedback for network training. In addition, these methods only\nutilize single label to integrate supervision information of data for hashing\nfunction learning, which may result in inferior network generalization\nperformance and relatively low-quality hash codes since the inter-class\ninformation of data is totally ignored. In this paper, we propose a dual\nsemantic asymmetric hashing (DSAH) method, which generates discriminative hash\ncodes under three-fold constrains. Firstly, DSAH utilizes class prior to\nconduct class structure quantization so as to transmit class information during\nthe quantization process. Secondly, a simple yet effective label mechanism is\ndesigned to characterize both the intra-class compactness and inter-class\nseparability of data, thereby achieving semantic-sensitive binary code\nlearning. Finally, a meaningful pairwise similarity preserving loss is devised\nto minimize the distances between class-related network outputs based on an\naffinity graph. With these three main components, high-quality hash codes can\nbe generated through network. Extensive experiments conducted on various\ndatasets demonstrate the superiority of DSAH in comparison with\nstate-of-the-art deep hashing methods.",
    "descriptor": "",
    "authors": [
      "Jianglin Lu",
      "Hailing Wang",
      "Jie Zhou",
      "Mengfan Yan",
      "Jiajun Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12478"
  },
  {
    "id": "arXiv:2110.12481",
    "title": "Spurious solutions for high order curl problems",
    "abstract": "We investigate numerical solutions of high order curl problems with various\nformulations and finite elements. We show that several classical conforming\nfinite elements lead to spurious solutions, while mixed formulations with\nfinite elements in complexes solve the problems correctly.\nTo explain the numerical results, we clarify the cohomological structures in\nhigh order curl problems by relating the partial differential equations to the\nHodge-Laplacian boundary problems of the gradcurl-complexes.",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Kaibo Hu",
      "Qian Zhang",
      "Jiayu Han",
      "Lixiu Wang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12481"
  },
  {
    "id": "arXiv:2110.12484",
    "title": "Micro Batch Streaming: Allowing the Training of DNN models Using a large  batch size on Small Memory Systems",
    "abstract": "The size of the deep learning models has greatly increased over the past\ndecade. Such models are difficult to train using a large batch size, because\ncommodity machines do not have enough memory to accommodate both the model and\na large data size. The batch size is one of the hyper-parameters used in the\ntraining model, and it is dependent on and is limited by the target machine\nmemory capacity and it is dependent on the remaining memory after the model is\nuploaded. A smaller batch size usually results in performance degradation. This\npaper proposes a framework called Micro-Batch Streaming (MBS) to address this\nproblem. This method helps deep learning models to train by providing a batch\nstreaming algorithm that splits a batch into the appropriate size for the\nremaining memory size and streams them sequentially to the target machine. A\nloss normalization algorithm based on the gradient accumulation is used to\nmaintain the performance. The purpose of our method is to allow deep learning\nmodels to train using mathematically determined optimal batch sizes that cannot\nfit into the memory of a target system.",
    "descriptor": "\nComments: In submitted\n",
    "authors": [
      "DoangJoo Synn",
      "XinYu Piao",
      "JooYoung Park",
      "Jong-Kook Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12484"
  },
  {
    "id": "arXiv:2110.12485",
    "title": "Scaling Neural Program Synthesis with Distribution-based Search",
    "abstract": "We consider the problem of automatically constructing computer programs from\ninput-output examples. We investigate how to augment probabilistic and neural\nprogram synthesis methods with new search algorithms, proposing a framework\ncalled distribution-based search. Within this framework, we introduce two new\nsearch algorithms: Heap Search, an enumerative method, and SQRT Sampling, a\nprobabilistic method. We prove certain optimality guarantees for both methods,\nshow how they integrate with probabilistic and neural techniques, and\ndemonstrate how they can operate at scale across parallel compute environments.\nCollectively these findings offer theoretical and applied studies of search\nalgorithms for program synthesis that integrate with recent developments in\nmachine-learned program synthesizers.",
    "descriptor": "\nComments: Attached repository: this https URL\n",
    "authors": [
      "Nathana\u00ebl Fijalkow",
      "Guillaume Lagarde",
      "Th\u00e9o Matricon",
      "Kevin Ellis",
      "Pierre Ohlmann",
      "Akarsh Potta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.12485"
  },
  {
    "id": "arXiv:2110.12486",
    "title": "EgoNN: Egocentric Neural Network for Point Cloud Based 6DoF  Relocalization at the City Scale",
    "abstract": "The paper presents a deep neural network-based method for global and local\ndescriptors extraction from a point cloud acquired by a rotating 3D LiDAR. The\ndescriptors can be used for two-stage 6DoF relocalization. First, a course\nposition is retrieved by finding candidates with the closest global descriptor\nin the database of geo-tagged point clouds. Then, the 6DoF pose between a query\npoint cloud and a database point cloud is estimated by matching local\ndescriptors and using a robust estimator such as RANSAC. Our method has a\nsimple, fully convolutional architecture based on a sparse voxelized\nrepresentation. It can efficiently extract a global descriptor and a set of\nkeypoints with local descriptors from large point clouds with tens of thousand\npoints. Our code and pretrained models are publicly available on the project\nwebsite.",
    "descriptor": "",
    "authors": [
      "Jacek Komorowski",
      "Monika Wysoczanska",
      "Tomasz Trzcinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12486"
  },
  {
    "id": "arXiv:2110.12489",
    "title": "A Comprehensive Survey of Logging in Software: From Logging Statements  Automation to Log Mining and Analysis",
    "abstract": "Logs are widely used to record runtime information of software systems, such\nas the timestamp and the importance of an event, the unique ID of the source of\nthe log, and a part of the state of a task's execution. The rich information of\nlogs enables system developers (and operators) to monitor the runtime behaviors\nof their systems and further track down system problems and perform analysis on\nlog data in production settings. However, the prior research on utilizing logs\nis scattered and that limits the ability of new researchers in this field to\nquickly get to the speed and hampers currently active researchers to advance\nthis field further. Therefore, this paper surveys and provides a systematic\nliterature review of the contemporary logging practices and log statements'\nmining and monitoring techniques and their applications such as in system\nfailure detection and diagnosis. We study a large number of conference and\njournal papers that appeared on top-level peer-reviewed venues. Additionally,\nwe draw high-level trends of ongoing research and categorize publications into\nsubdivisions. In the end, and based on our holistic observations during this\nsurvey, we provide a set of challenges and opportunities that will lead the\nresearchers in academia and industry in moving the field forward.",
    "descriptor": "\nComments: Under second revision at Transactions on Software Engineering\n",
    "authors": [
      "Sina Gholamian",
      "Paul A. S. Ward"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12489"
  },
  {
    "id": "arXiv:2110.12490",
    "title": "PaperFetcher: A tool to automate handsearch for systematic reviews",
    "abstract": "This paper presents a browser-based software tool, Paperfetcher, to automate\nthe handsearch portion of systematic reviews. Paperfetcher has two parts: an\nextensible back-end framework written in Python, which does all the heavy\nlifting, and a set of easy-to-use front-end apps for researchers. The front-end\napps can be run online, with no setup, on a cloud platform. Privacy-conscious\nusers can run the app on their computers after a few steps of installation, and\nadvanced users can modify the source code and extend the back-end interface for\ntheir own specific needs. Paperfetcher's website has user guidelines and a\nstep-by-step setup video to coach researchers to use the software. With\nPaperfetcher's assistance, researchers can retrieve articles from designated\njournals and a given timeframe with just a few clicks. Researchers can also\nrestrict their search to papers matching a set of keywords. In addition,\nPaperfetcher automates snowball-search, which retrieves all references from\nselected articles. Paperfetcher helps save a considerable amount of time and\nenergy in the literature search portion of systematic reviews.",
    "descriptor": "",
    "authors": [
      "Akash Pallath",
      "Qiyang Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.12490"
  },
  {
    "id": "arXiv:2110.12493",
    "title": "The privacy protection effectiveness of the video conference platforms'  virtual background and the privacy concerns from the end-users",
    "abstract": "Due to the abrupt arise of pandemic worldwide, the video conferencing\nplatforms are becoming ubiquitously available and being embedded into either\nvarious digital devices or the collaborative daily work. Even though the\nservice provider has designed many security functions to protect individual's\nprivacy, such as virtual background (VB), it still remains to be explored that\nhow the instability of VB leaks users' privacy or impacts their mentality and\nbehaviours. In order to understand and locate implications for the contextual\nof the end-users' privacy awareness and its mental model, we will conduct\nsurvey and interviews for users as the first stage research. We will raise\nconceptual challenges in terms of the designing safety and stable VB, as well\nas provide design suggestions.",
    "descriptor": "",
    "authors": [
      "Shijing He",
      "Yaxiong Lei"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12493"
  },
  {
    "id": "arXiv:2110.12497",
    "title": "Problems with information theoretic approaches to causal learning",
    "abstract": "The language of information theory is favored in both causal reasoning and\nmachine learning frameworks. But, is there a better language than this? In this\nstudy, we demonstrate the pitfalls of infotheoretic estimation using first\norder statistics on (short) sequences for causal learning. We recommend the use\nof data compression based approaches for causality testing since these make\nvery little assumptions on data as opposed to infotheoretic measures, and are\nmore robust to finite data length effects. We conclude with a discussion on the\nchallenges posed in modeling the effects of conditioning process $X$ with\nanother process $Y$ in causal machine learning. Specifically, conditioning can\nincrease 'confusion' which can be difficult to model by classical information\ntheory. A conscious causal agent creates new choices, decisions and meaning\nwhich poses huge challenges for AI.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Nithin Nagaraj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12497"
  },
  {
    "id": "arXiv:2110.12499",
    "title": "Approximate Core for Committee Selection via Multilinear Extension and  Market Clearing",
    "abstract": "Motivated by civic problems such as participatory budgeting and multiwinner\nelections, we consider the problem of public good allocation: Given a set of\nindivisible projects (or candidates) of different sizes, and voters with\ndifferent monotone utility functions over subsets of these candidates, the goal\nis to choose a budget-constrained subset of these candidates (or a committee)\nthat provides fair utility to the voters. The notion of fairness we adopt is\nthat of core stability from cooperative game theory: No subset of voters should\nbe able to choose another blocking committee of proportionally smaller size\nthat provides strictly larger utility to all voters that deviate. The core\nprovides a strong notion of fairness, subsuming other notions that have been\nwidely studied in computational social choice.\nIt is well-known that an exact core need not exist even when utility\nfunctions of the voters are additive across candidates. We therefore relax the\nproblem to allow approximation: Voters can only deviate to the blocking\ncommittee if after they choose any extra candidate (called an additament),\ntheir utility still increases by an $\\alpha$ factor. If no blocking committee\nexists under this definition, we call this an $\\alpha$-core.\nOur main result is that an $\\alpha$-core, for $\\alpha < 67.37$, always exists\nwhen utilities of the voters are arbitrary monotone submodular functions, and\nthis can be computed in polynomial time. This result improves to $\\alpha <\n9.27$ for additive utilities, albeit without the polynomial time guarantee. Our\nresults are a significant improvement over prior work that only shows\nlogarithmic approximations for the case of additive utilities. We complement\nour results with a lower bound of $\\alpha > 1.015$ for submodular utilities,\nand a lower bound of any function in the number of voters and candidates for\ngeneral monotone utilities.",
    "descriptor": "\nComments: Accepted by ACM-SIAM Symposium on Discrete Algorithms (SODA 2022)\n",
    "authors": [
      "Kamesh Munagala",
      "Yiheng Shen",
      "Kangning Wang",
      "Zhiyi Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.12499"
  },
  {
    "id": "arXiv:2110.12501",
    "title": "Abstractified Multi-instance Learning (AMIL) for Biomedical Relation  Extraction",
    "abstract": "Relation extraction in the biomedical domain is a challenging task due to a\nlack of labeled data and a long-tail distribution of fact triples. Many works\nleverage distant supervision which automatically generates labeled data by\npairing a knowledge graph with raw textual data. Distant supervision produces\nnoisy labels and requires additional techniques, such as multi-instance\nlearning (MIL), to denoise the training signal. However, MIL requires multiple\ninstances of data and struggles with very long-tail datasets such as those\nfound in the biomedical domain. In this work, we propose a novel reformulation\nof MIL for biomedical relation extraction that abstractifies biomedical\nentities into their corresponding semantic types. By grouping entities by\ntypes, we are better able to take advantage of the benefits of MIL and further\ndenoise the training signal. We show this reformulation, which we refer to as\nabstractified multi-instance learning (AMIL), improves performance in\nbiomedical relationship extraction. We also propose a novel relationship\nembedding architecture that further improves model performance.",
    "descriptor": "\nComments: 14 pages, 3 figures, submitted to Automated Knowledge Base Construction (2021)\n",
    "authors": [
      "William Hogan",
      "Molly Huang",
      "Yannis Katsis",
      "Tyler Baldwin",
      "Ho-Cheol Kim",
      "Yoshiki Vazquez Baeza",
      "Andrew Bartko",
      "Chun-Nan Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12501"
  },
  {
    "id": "arXiv:2110.12503",
    "title": "Deep Neural Networks on EEG Signals to Predict Auditory Attention Score  Using Gramian Angular Difference Field",
    "abstract": "Auditory attention is a selective type of hearing in which people focus their\nattention intentionally on a specific source of a sound or spoken words whilst\nignoring or inhibiting other auditory stimuli. In some sense, the auditory\nattention score of an individual shows the focus the person can have in\nauditory tasks. The recent advancements in deep learning and in the\nnon-invasive technologies recording neural activity beg the question, can deep\nlearning along with technologies such as electroencephalography (EEG) be used\nto predict the auditory attention score of an individual? In this paper, we\nfocus on this very problem of estimating a person's auditory attention level\nbased on their brain's electrical activity captured using 14-channeled EEG\nsignals. More specifically, we deal with attention estimation as a regression\nproblem. The work has been performed on the publicly available Phyaat dataset.\nThe concept of Gramian Angular Difference Field (GADF) has been used to convert\ntime-series EEG data into an image having 14 channels, enabling us to train\nvarious deep learning models such as 2D CNN, 3D CNN, and convolutional\nautoencoders. Their performances have been compared amongst themselves as well\nas with the work done previously. Amongst the different models we tried, 2D CNN\ngave the best performance. It outperformed the existing methods by a decent\nmargin of 0.22 mean absolute error (MAE).",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Mahak Kothari",
      "Shreyansh Joshi",
      "Adarsh Nandanwar",
      "Aadetya Jaiswal",
      "Veeky Baths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12503"
  },
  {
    "id": "arXiv:2110.12506",
    "title": "Detecting model drift using polynomial relations",
    "abstract": "Machine learning (ML) models serve critical functions, such as classifying\nloan applicants as good or bad risks. Each model is trained under the\nassumption that the data used in training, and the data used in field come from\nthe same underlying unknown distribution. Often this assumption is broken in\npractice. It is desirable to identify when this occurs in order to minimize the\nimpact on model performance.\nWe suggest a new approach to detect change in the data distribution by\nidentifying polynomial relations between the data features. We measure the\nstrength of each identified relation using its R-square value. A strong\npolynomial relation captures a significant trait of the data which should\nremain stable if the data distribution does not change. We thus use a set of\nlearned strong polynomial relations to identify drift. For a set of polynomial\nrelations that are stronger than a given desired threshold, we calculate the\namount of drift observed for that relation. The amount of drift is estimated by\ncalculating the Bayes Factor for the polynomial relation likelihood of the\nbaseline data versus field data. We empirically validate the approach by\nsimulating a range of changes in three publicly-available data sets, and\ndemonstrate the ability to identify drift using the Bayes Factor of the\npolynomial relation likelihood change.",
    "descriptor": "",
    "authors": [
      "Eliran Roffe",
      "Samuel Ackerman",
      "Orna Raz",
      "Eitan Farchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12506"
  },
  {
    "id": "arXiv:2110.12508",
    "title": "A Deep Learning Approach to Predicting Collateral Flow in Stroke  Patients Using Radiomic Features from Perfusion Images",
    "abstract": "Collateral circulation results from specialized anastomotic channels which\nare capable of providing oxygenated blood to regions with compromised blood\nflow caused by ischemic injuries. The quality of collateral circulation has\nbeen established as a key factor in determining the likelihood of a favorable\nclinical outcome and goes a long way to determine the choice of stroke care\nmodel - that is the decision to transport or treat eligible patients\nimmediately.\nThough there exist several imaging methods and grading criteria for\nquantifying collateral blood flow, the actual grading is mostly done through\nmanual inspection of the acquired images. This approach is associated with a\nnumber of challenges. First, it is time-consuming - the clinician needs to scan\nthrough several slices of images to ascertain the region of interest before\ndeciding on what severity grade to assign to a patient. Second, there is a high\ntendency for bias and inconsistency in the final grade assigned to a patient\ndepending on the experience level of the clinician.\nWe present a deep learning approach to predicting collateral flow grading in\nstroke patients based on radiomic features extracted from MR perfusion data.\nFirst, we formulate a region of interest detection task as a reinforcement\nlearning problem and train a deep learning network to automatically detect the\noccluded region within the 3D MR perfusion volumes. Second, we extract radiomic\nfeatures from the obtained region of interest through local image descriptors\nand denoising auto-encoders. Finally, we apply a convolutional neural network\nand other machine learning classifiers to the extracted radiomic features to\nautomatically predict the collateral flow grading of the given patient volume\nas one of three severity classes - no flow (0), moderate flow (1), and good\nflow (2)...",
    "descriptor": "",
    "authors": [
      "Giles Tetteh",
      "Fernando Navarro",
      "Johannes Paetzold",
      "Jan Kirschke",
      "Claus Zimmer",
      "Bjoern H. Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12508"
  },
  {
    "id": "arXiv:2110.12509",
    "title": "Per-Pixel Lung Thickness and Lung Capacity Estimation on Chest X-Rays  using Convolutional Neural Networks",
    "abstract": "Estimating the lung depth on x-ray images could provide both an accurate\nopportunistic lung volume estimation during clinical routine and improve image\ncontrast in modern structural chest imaging techniques like x-ray dark-field\nimaging. We present a method based on a convolutional neural network that\nallows a per-pixel lung thickness estimation and subsequent total lung capacity\nestimation. The network was trained and validated using 5250 simulated\nradiographs generated from 525 real CT scans. Furthermore, we are able to infer\nthe model trained with simulation data on real radiographs.\nFor 35 patients, quantitative and qualitative evaluation was performed on\nstandard clinical radiographs. The ground-truth for each patient's total lung\nvolume was defined based on the patients' corresponding CT scan. The\nmean-absolute error between the estimated lung volume on the 35 real\nradiographs and groundtruth volume was 0.73 liter. Additionally, we predicted\nthe lung thicknesses on a synthetic dataset of 131 radiographs, where the\nmean-absolute error was 0.27 liter. The results show, that it is possible to\ntransfer the knowledge obtained in a simulation model to real x-ray images.",
    "descriptor": "",
    "authors": [
      "Manuel Schultheiss",
      "Philipp Schmette",
      "Thorsten Sellerer",
      "Rafael Schick",
      "Kirsten Taphorn",
      "Korbinian Mechlem",
      "Lorenz Birnbacher",
      "Bernhard Renger",
      "Marcus R. Makowski",
      "Franz Pfeiffer",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12509"
  },
  {
    "id": "arXiv:2110.12511",
    "title": "Parallel Peeling of Bipartite Networks for Hierarchical Dense Subgraph  Discovery",
    "abstract": "Wing and Tip decomposition construct a hierarchy of butterfly-dense edge and\nvertex induced bipartite subgraphs, respectively. They have applications in\nseveral domains including e-commerce, recommendation systems and document\nanalysis. Existing decomposition algorithms use a bottom-up approach that\nconstructs the hierarchy in an increasing order of subgraph density. They\niteratively peel the entities with minimum butterfly count i.e. remove them\nfrom the graph and update the butterfly count of other entities. However, the\namount of butterflies in large bipartite graphs makes bottom-up peeling\ncomputationally demanding. Furthermore, the strict order of peeling entities\nresults in a numerous sequentially dependent iterations, which makes\nparallelization challenging.\nIn this paper, we propose a novel Parallel Bipartite Network peelinG (PBNG)\nframework which adopts a two-phased peeling approach to relax the order of\npeeling, and in turn, reduce synchronization. The first phase divides the\ndecomposition hierarchy into several partitions using very few peeling\niterations. The second phase concurrently processes these partitions to\ngenerate the final hierarchy, and requires no global synchronization. The\ntwo-phased peeling further enables batching optimizations that dramatically\nimprove the computational efficiency.\nWe empirically evaluate PBNG using several real-world bipartite graphs.\nCompared to the state-of-the-art frameworks and decomposition algorithms, PBNG\nachieves up to four orders of magnitude reduction in synchronization and two\norders of magnitude speedup, respectively. We also present the first\ndecomposition results of some of the largest public real-world datasets, which\nPBNG can peel in few minutes but existing algorithms fail to process even in\nseveral days.",
    "descriptor": "\nComments: 31 pages, 11 figures, 4 tables. Source code available at this https URL\n",
    "authors": [
      "Kartik Lakhotia",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12511"
  },
  {
    "id": "arXiv:2110.12516",
    "title": "X-Distill: Improving Self-Supervised Monocular Depth via Cross-Task  Distillation",
    "abstract": "In this paper, we propose a novel method, X-Distill, to improve the\nself-supervised training of monocular depth via cross-task knowledge\ndistillation from semantic segmentation to depth estimation. More specifically,\nduring training, we utilize a pretrained semantic segmentation teacher network\nand transfer its semantic knowledge to the depth network. In order to enable\nsuch knowledge distillation across two different visual tasks, we introduce a\nsmall, trainable network that translates the predicted depth map to a semantic\nsegmentation map, which can then be supervised by the teacher network. In this\nway, this small network enables the backpropagation from the semantic\nsegmentation teacher's supervision to the depth network during training. In\naddition, since the commonly used object classes in semantic segmentation are\nnot directly transferable to depth, we study the visual and geometric\ncharacteristics of the objects and design a new way of grouping them that can\nbe shared by both tasks. It is noteworthy that our approach only modifies the\ntraining process and does not incur additional computation during inference. We\nextensively evaluate the efficacy of our proposed approach on the standard\nKITTI benchmark and compare it with the latest state of the art. We further\ntest the generalizability of our approach on Make3D. Overall, the results show\nthat our approach significantly improves the depth estimation accuracy and\noutperforms the state of the art.",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Hong Cai",
      "Janarbek Matai",
      "Shubhankar Borse",
      "Yizhe Zhang",
      "Amin Ansari",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12516"
  },
  {
    "id": "arXiv:2110.12518",
    "title": "GraspLook: a VR-based Telemanipulation System with R-CNN-driven  Augmentation of Virtual Environment",
    "abstract": "The teleoperation of robotic systems in medical applications requires stable\nand convenient visual feedback for the operator. The most accessible approach\nto delivering visual information from the remote area is using cameras to\ntransmit a video stream from the environment. However, such systems are\nsensitive to the camera resolution, limited viewpoints, and cluttered\nenvironment bringing additional mental demands to the human operator. The paper\nproposes a novel system of teleoperation based on an augmented virtual\nenvironment (VE). The region-based convolutional neural network (R-CNN) is\napplied to detect the laboratory instrument and estimate its position in the\nremote environment to display further its digital twin in the VE, which is\nnecessary for dexterous telemanipulation. The experimental results revealed\nthat the developed system allows users to operate the robot smoother, which\nleads to a decrease in task execution time when manipulating test tubes. In\naddition, the participants evaluated the developed system as less mentally\ndemanding (by 11%) and requiring less effort (by 16%) to accomplish the task\nthan the camera-based teleoperation approach and highly assessed their\nperformance in the augmented VE. The proposed technology can be potentially\napplied for conducting laboratory tests in remote areas when operating with\ninfectious and poisonous reagents.",
    "descriptor": "\nComments: Accepted to IEEE 20th International Conference on Advanced Robotics (ICAR) 2021, 6 pages, 8 figures\n",
    "authors": [
      "Polina Ponomareva",
      "Daria Trinitatova",
      "Aleksey Fedoseev",
      "Ivan Kalinov",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12518"
  },
  {
    "id": "arXiv:2110.12520",
    "title": "Learning convex regularizers satisfying the variational source condition  for inverse problems",
    "abstract": "Variational regularization has remained one of the most successful approaches\nfor reconstruction in imaging inverse problems for several decades. With the\nemergence and astonishing success of deep learning in recent years, a\nconsiderable amount of research has gone into data-driven modeling of the\nregularizer in the variational setting. Our work extends a recently proposed\nmethod, referred to as adversarial convex regularization (ACR), that seeks to\nlearn data-driven convex regularizers via adversarial training in an attempt to\ncombine the power of data with the classical convex regularization theory.\nSpecifically, we leverage the variational source condition (SC) during training\nto enforce that the ground-truth images minimize the variational loss\ncorresponding to the learned convex regularizer. This is achieved by adding an\nappropriate penalty term to the ACR training objective. The resulting\nregularizer (abbreviated as ACR-SC) performs on par with the ACR, but unlike\nACR, comes with a quantitative convergence rate estimate.",
    "descriptor": "\nComments: Accepted to the NeurIPS-2021 Workshop on Deep Learning and Inverse Problems\n",
    "authors": [
      "Subhadip Mukherjee",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Martin Burger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12520"
  },
  {
    "id": "arXiv:2110.12521",
    "title": "Reachability Embeddings: Scalable Self-Supervised Representation  Learning from Markovian Trajectories for Geospatial Computer Vision",
    "abstract": "Self-supervised representation learning techniques utilize large datasets\nwithout semantic annotations to learn meaningful, universal features that can\nbe conveniently transferred to solve a wide variety of downstream supervised\ntasks. In this paper, we propose a self-supervised method for learning\nrepresentations of geographic locations from unlabeled GPS trajectories to\nsolve downstream geospatial computer vision tasks. Tiles resulting from a\nraster representation of the earth's surface are modeled as nodes on a graph or\npixels of an image. GPS trajectories are modeled as allowed Markovian paths on\nthese nodes. A scalable and distributed algorithm is presented to compute\nimage-like representations, called reachability summaries, of the spatial\nconnectivity patterns between tiles and their neighbors implied by the observed\nMarkovian paths. A convolutional, contractive autoencoder is trained to learn\ncompressed representations, called reachability embeddings, of reachability\nsummaries for every tile. Reachability embeddings serve as task-agnostic,\nfeature representations of geographic locations. Using reachability embeddings\nas pixel representations for five different downstream geospatial tasks, cast\nas supervised semantic segmentation problems, we quantitatively demonstrate\nthat reachability embeddings are semantically meaningful representations and\nresult in 4-23% gain in performance, while using upto 67% less trajectory data,\nas measured using area under the precision-recall curve (AUPRC) metric, when\ncompared to baseline models that use pixel representations that do not account\nfor the spatial connectivity between tiles. Reachability embeddings transform\nsequential, spatiotemporal mobility data into semantically meaningful\nimage-like representations that can be combined with other sources of imagery\nand are designed to facilitate multimodal learning in geospatial computer\nvision.",
    "descriptor": "\nComments: 14 pages, 6 figures, 2 tables\n",
    "authors": [
      "Swetava Ganguli",
      "C. V. Krishnakumar Iyer",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12521"
  },
  {
    "id": "arXiv:2110.12530",
    "title": "On Throughput Bounds of NOMA-ALOHA",
    "abstract": "In this paper, we focus on the throughput of random access with power-domain\nnon-orthogonal multiple access (NOMA) and derive bounds on the throughput. In\nparticular, we demonstrate that the expression for the throughput derived in\n[1] is an upper-bound and derive a new lower-bound as a closed-form expression.\nThis expression allows to find the traffic intensity that maximizes the\nlower-bound, which is shown to be the square root of the number of power levels\nin NOMA. Furthermore, with this expression, for a large number of power levels,\nwe obtain the asymptotic maximum throughput that is increased at a rate of the\nsquare root of the number of power levels.",
    "descriptor": "\nComments: 4 pages, 3 figures (to appear in IEEE Wireless Communications Letters)\n",
    "authors": [
      "Jinho Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12530"
  },
  {
    "id": "arXiv:2110.12532",
    "title": "Fronthaul Compression for Uplink Massive MIMO using Matrix Decomposition",
    "abstract": "Massive MIMO opens up attractive possibilities for next generation wireless\nsystems with its large number of antennas offering spatial diversity and\nmultiplexing gain. However, the fronthaul link that connects a massive MIMO\nRemote Radio Head (RRH) and carries IQ samples to the Baseband Unit (BBU) of\nthe base station can throttle the network capacity/speed if appropriate data\ncompression techniques are not applied. In this paper, we propose an iterative\ntechnique for fronthaul load reduction in the uplink for massive MIMO systems\nthat utilizes the convolution structure of the received signals. We use an\nalternating minimisation algorithm for blind deconvolution of the received data\nmatrix that provides compression ratios of 30-50. In addition, the technique\npresented here can be used for blind decoding of OFDM signals in massive MIMO\nsystems.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Aswathylakshmi P",
      "Radha Krishna Ganti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12532"
  },
  {
    "id": "arXiv:2110.12534",
    "title": "When Blockchain Meets Auction Models: A Survey, Some Applications, and  Challenges",
    "abstract": "In recent years, blockchain has gained widespread attention as an emerging\ntechnology for decentralization, transparency, and immutability in advancing\nonline activities over public networks. As an essential market process,\nauctions have been well studied and applied in many business fields due to\ntheir efficiency and contributions to fair trade. Complementary features\nbetween blockchain and auction models trigger a great potential for research\nand innovation. On the one hand, the decentralized nature of blockchain can\nprovide a trustworthy, secure, and cost-effective mechanism to manage the\nauction process; on the other hand, auction models can be utilized to design\nincentive and consensus protocols in blockchain architectures. These\nopportunities have attracted enormous research and innovation activities in\nboth academia and industry; however, there is a lack of an in-depth review of\nexisting solutions and achievements. In this paper, we conduct a comprehensive\nstate-of-the-art survey of these two research topics. We review the existing\nsolutions for integrating blockchain and auction models, with some\napplication-oriented taxonomies generated. Additionally, we highlight some open\nresearch challenges and future directions towards integrated blockchain-auction\nmodels.",
    "descriptor": "",
    "authors": [
      "Zeshun Shi",
      "Cees de Laat",
      "Paola Grosso",
      "Zhiming Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.12534"
  },
  {
    "id": "arXiv:2110.12536",
    "title": "Neo: Generalizing Confusion Matrix Visualization to Hierarchical and  Multi-Output Labels",
    "abstract": "The confusion matrix, a ubiquitous visualization for helping people evaluate\nmachine learning models, is a tabular layout that compares predicted class\nlabels against actual class labels over all data instances. We conduct\nformative research with machine learning practitioners at a large technology\ncompany and find that conventional confusion matrices do not support more\ncomplex data-structures found in modern-day applications, such as hierarchical\nand multi-output labels. To express such variations of confusion matrices, we\ndesign an algebra that models confusion matrices as probability distributions.\nBased on this algebra, we develop Neo, a visual analytics system that enables\npractitioners to flexibly author and interact with hierarchical and\nmulti-output confusion matrices, visualize derived metrics, renormalize\nconfusions, and share matrix specifications. Finally, we demonstrate Neo's\nutility with three case studies that help people better understand model\nperformance and reveal hidden confusions.",
    "descriptor": "",
    "authors": [
      "Jochen G\u00f6rtler",
      "Fred Hohman",
      "Dominik Moritz",
      "Kanit Wongsuphasawat",
      "Donghao Ren",
      "Rahul Nair",
      "Marc Kirchner",
      "Kayur Patel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12536"
  },
  {
    "id": "arXiv:2110.12539",
    "title": "Discrete acoustic space for an efficient sampling in neural  text-to-speech",
    "abstract": "We present an SVQ-VAE architecture using a split vector quantizer for NTTS,\nas an enhancement to the well-known VAE and VQ-VAE architectures. Compared to\nthese previous architectures, our proposed model retains the benefits of using\nan utterance-level bottleneck, while reducing the associated loss of\nrepresentation power. We train the model on recordings in the highly expressive\ntask-oriented dialogues domain and show that SVQ-VAE achieves a statistically\nsignificant improvement in naturalness over the VAE and VQ-VAE models.\nFurthermore, we demonstrate that the SVQ-VAE acoustic space is predictable from\ntext, reducing the gap between the standard constant vector synthesis and\nvocoded recordings by 32%.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Marek Strelec",
      "Jonas Rohnke",
      "Antonio Bonafonte",
      "Mateusz \u0141ajszczak",
      "Trevor Wood"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12539"
  },
  {
    "id": "arXiv:2110.12543",
    "title": "Understanding the World Through Action",
    "abstract": "The recent history of machine learning research has taught us that machine\nlearning methods can be most effective when they are provided with very large,\nhigh-capacity models, and trained on very large and diverse datasets. This has\nspurred the community to search for ways to remove any bottlenecks to scale.\nOften the foremost among such bottlenecks is the need for human effort,\nincluding the effort of curating and labeling datasets. As a result,\nconsiderable attention in recent years has been devoted to utilizing unlabeled\ndata, which can be collected in vast quantities. However, some of the most\nwidely used methods for training on such unlabeled data themselves require\nhuman-designed objective functions that must correlate in some meaningful way\nto downstream tasks. I will argue that a general, principled, and powerful\nframework for utilizing unlabeled data can be derived from reinforcement\nlearning, using general purpose unsupervised or self-supervised reinforcement\nlearning objectives in concert with offline reinforcement learning methods that\ncan leverage large datasets. I will discuss how such a procedure is more\nclosely aligned with potential downstream tasks, and how it could build on\nexisting techniques that have been developed in recent years.",
    "descriptor": "\nComments: Published in Conference on Robot Learning (CoRL) 2021, Blue Sky Track\n",
    "authors": [
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12543"
  },
  {
    "id": "arXiv:2110.12544",
    "title": "Online estimation and control with optimal pathlength regret",
    "abstract": "A natural goal when designing online learning algorithms for non-stationary\nenvironments is to bound the regret of the algorithm in terms of the temporal\nvariation of the input sequence. Intuitively, when the variation is small, it\nshould be easier for the algorithm to achieve low regret, since past\nobservations are predictive of future inputs. Such data-dependent \"pathlength\"\nregret bounds have recently been obtained for a wide variety of online learning\nproblems, including OCO and bandits. We obtain the first pathlength regret\nbounds for online control and estimation (e.g. Kalman filtering) in linear\ndynamical systems. The key idea in our derivation is to reduce\npathlength-optimal filtering and control to certain variational problems in\nrobust estimation and control; these reductions may be of independent interest.\nNumerical simulations confirm that our pathlength-optimal algorithms outperform\ntraditional $H_2$ and $H_{\\infty}$ algorithms when the environment varies over\ntime.",
    "descriptor": "",
    "authors": [
      "Gautam Goel",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12544"
  },
  {
    "id": "arXiv:2110.12545",
    "title": "Networks of Ethereum Non-Fungible Tokens: A graph-based analysis of the  ERC-721 ecosystem",
    "abstract": "Non-fungible tokens (NFTs) as a decentralized proof of ownership represent\none of the main reasons why Ethereum is a disruptive technology. This paper\npresents the first systematic study of the interactions occurring in a number\nof NFT ecosystems. We illustrate how to retrieve transaction data available on\nthe blockchain and structure it as a graph-based model. Thanks to this\nmethodology, we are able to study for the first time the topological structure\nof NFT networks and show that their properties (degree distribution and others)\nare similar to those of interaction graphs in social networks. Time-dependent\nanalysis metrics, useful to characterize market influencers and interactions\nbetween different wallets, are also introduced. Based on those, we identify\nacross a number of NFT networks the widespread presence of both investors\naccumulating NFTs and individuals who make large profits.",
    "descriptor": "\nComments: To be published in Proceedings of IEEE Blockchain 2021, The 4th IEEE International Conference on Blockchain, Melbourne (Australia), 06-08 December 2021\n",
    "authors": [
      "S. Casale-Brunet",
      "P. Ribeca",
      "P. Doyle",
      "M. Mattavelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12545"
  },
  {
    "id": "arXiv:2110.12551",
    "title": "Understanding the Impact of UGC Specificities on Translation Quality",
    "abstract": "This work takes a critical look at the evaluation of user-generated content\nautomatic translation, the well-known specificities of which raise many\nchallenges for MT. Our analyses show that measuring the average-case\nperformance using a standard metric on a UGC test set falls far short of giving\na reliable image of the UGC translation quality. That is why we introduce a new\ndata set for the evaluation of UGC translation in which UGC specificities have\nbeen manually annotated using a fine-grained typology. Using this data set, we\nconduct several experiments to measure the impact of different kinds of UGC\nspecificities on translation quality, more precisely than previously possible.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Carlos Rosales N\u00fa\u00f1ez",
      "Djam\u00e9 Seddah",
      "Guillaume Wisniewski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12551"
  },
  {
    "id": "arXiv:2110.12552",
    "title": "Noisy UGC Translation at the Character Level: Revisiting Open-Vocabulary  Capabilities and Robustness of Char-Based Models",
    "abstract": "This work explores the capacities of character-based Neural Machine\nTranslation to translate noisy User-Generated Content (UGC) with a strong focus\non exploring the limits of such approaches to handle productive UGC phenomena,\nwhich almost by definition, cannot be seen at training time. Within a strict\nzero-shot scenario, we first study the detrimental impact on translation\nperformance of various user-generated content phenomena on a small annotated\ndataset we developed, and then show that such models are indeed incapable of\nhandling unknown letters, which leads to catastrophic translation failure once\nsuch characters are encountered. We further confirm this behavior with a\nsimple, yet insightful, copy task experiment and highlight the importance of\nreducing the vocabulary size hyper-parameter to increase the robustness of\ncharacter-based models for machine translation.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Carlos Rosales N\u00fa\u00f1ez",
      "Guillaume Wisniewski",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12552"
  },
  {
    "id": "arXiv:2110.12553",
    "title": "Towards Blockchain-enabled Open Architectures for Scalable Digital Asset  Platforms",
    "abstract": "Today there is considerable interest in deploying blockchains and\ndecentralized ledger technology as a means to address the deficiencies of\ncurrent financial and digital asset infrastructures. The focal point of\nattention in many projects on digital asset and cryptocurrency is centered\naround blockchain systems and smart contracts. Many projects seek to make the\nblockchain as the centerpiece of the new decentralized world of finance.\nHowever, several roadblocks and challenges currently face this predominant\nblockchain-centric view. In this paper we argue that the proper and correct\nperspective on decentralized economy should be one that is asset-centric, where\nthe goal should be the consistent lifecycle management of assets in the\nreal-world with their digital representation on the blockchain. We introduce\nthe notion of the digital twin to capture the relationship between a real-world\nasset and its on-chain representation. A digital twin container is utilized to\npermit off-chain state persistence and on-chain state traceability, where the\ncontainer can be deployed on the blockchain as well as on traditional\napplication servers. The digital twin container becomes the bridge between\nlegacy infrastructures and the newly emergent blockchain infrastructures,\npermitting legacy systems to interoperate consistently with blockchain systems.\nWe believe this asset-centric view to be the correct evolutionary direction for\nthe nascent field of blockchains and decentralized ledger technology.",
    "descriptor": "\nComments: 21 pages, 9 diagrams\n",
    "authors": [
      "Denis Avrilionis",
      "Thomas Hardjono"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12553"
  },
  {
    "id": "arXiv:2110.12555",
    "title": "HSDB-instrument: Instrument Localization Database for Laparoscopic and  Robotic Surgeries",
    "abstract": "Automated surgical instrument localization is an important technology to\nunderstand the surgical process and in order to analyze them to provide\nmeaningful guidance during surgery or surgical index after surgery to the\nsurgeon. We introduce a new dataset that reflects the kinematic characteristics\nof surgical instruments for automated surgical instrument localization of\nsurgical videos. The hSDB(hutom Surgery DataBase)-instrument dataset consists\nof instrument localization information from 24 cases of laparoscopic\ncholecystecomy and 24 cases of robotic gastrectomy. Localization information\nfor all instruments is provided in the form of a bounding box for object\ndetection. To handle class imbalance problem between instruments, synthesized\ninstruments modeled in Unity for 3D models are included as training data.\nBesides, for 3D instrument data, a polygon annotation is provided to enable\ninstance segmentation of the tool. To reflect the kinematic characteristics of\nall instruments, they are annotated with head and body parts for laparoscopic\ninstruments, and with head, wrist, and body parts for robotic instruments\nseparately. Annotation data of assistive tools (specimen bag, needle, etc.)\nthat are frequently used for surgery are also included. Moreover, we provide\nstatistical information on the hSDB-instrument dataset and the baseline\nlocalization performances of the object detection networks trained by the\nMMDetection library and resulting analyses.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jihun Yoon",
      "Jiwon Lee",
      "Sunghwan Heo",
      "Hayeong Yu",
      "Jayeon Lim",
      "Chi Hyun Song",
      "SeulGi Hong",
      "Seungbum Hong",
      "Bokyung Park",
      "SungHyun Park",
      "Woo Jin Hyung",
      "Min-Kook Choi1"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12555"
  },
  {
    "id": "arXiv:2110.12558",
    "title": "Recommender Systems meet Mechanism Design",
    "abstract": "Machine learning has developed a variety of tools for learning and\nrepresenting high-dimensional distributions with structure. Recent years have\nalso seen big advances in designing multi-item mechanisms. Akin to overfitting,\nhowever, these mechanisms can be extremely sensitive to the Bayesian prior that\nthey target, which becomes problematic when that prior is only approximately\nknown. We consider a multi-item mechanism design problem where the bidders'\nvalue distributions can be approximated by a topic model. Our solution builds\non a recent robustification framework by Brustle et al., which disentangles the\nstatistical challenge of estimating a multi-dimensional prior from the task of\ndesigning a good mechanism for it, robustifying the performance of the latter\nagainst the estimation error of the former. We provide an extension of the\nframework that allows us to exploit the expressive power of topic models to\nreduce the effective dimensionality of the mechanism design problem.",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Constantinos Daskalakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12558"
  },
  {
    "id": "arXiv:2110.12561",
    "title": "Lhotse: a speech data representation library for the modern deep  learning ecosystem",
    "abstract": "Speech data is notoriously difficult to work with due to a variety of codecs,\nlengths of recordings, and meta-data formats. We present Lhotse, a speech data\nrepresentation library that draws upon lessons learned from Kaldi speech\nrecognition toolkit and brings its concepts into the modern deep learning\necosystem. Lhotse provides a common JSON description format with corresponding\nPython classes and data preparation recipes for over 30 popular speech corpora.\nVarious datasets can be easily combined together and re-purposed for different\ntasks. The library handles multi-channel recordings, long recordings, local and\ncloud storage, lazy and on-the-fly operations amongst other features. We\nintroduce Cut and CutSet concepts, which simplify common data wrangling tasks\nfor audio and help incorporate acoustic context of speech utterances. Finally,\nwe show how Lhotse leverages PyTorch data API abstractions and adopts them to\nhandle speech data for deep learning.",
    "descriptor": "\nComments: Accepted for presentation at NeurIPS 2021 Data-Centric AI (DCAI) Workshop\n",
    "authors": [
      "Piotr \u017belasko",
      "Daniel Povey",
      "Jan \"Yenda\" Trmal",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12561"
  },
  {
    "id": "arXiv:2110.12564",
    "title": "A rank-adaptive higher-order orthogonal iteration algorithm for  truncated Tucker decomposition",
    "abstract": "We propose a novel rank-adaptive higher-order orthogonal iteration (HOOI)\nalgorithm to compute the truncated Tucker decomposition of higher-order tensors\nwith a given error tolerance, and prove that the method is locally optimal and\nmonotonically convergent. A series of numerical experiments related to both\nsynthetic and real-world tensors are carried out to show that the proposed\nrank-adaptive HOOI algorithm is advantageous in terms of both accuracy and\nefficiency. Some further analysis on the HOOI algorithm and the classical\nalternating least squares method are presented to further understand why rank\nadaptivity can be introduced into the HOOI algorithm and how it works.",
    "descriptor": "",
    "authors": [
      "Chuanfu Xiao",
      "Chao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12564"
  },
  {
    "id": "arXiv:2110.12567",
    "title": "Alignment Attention by Matching Key and Query Distributions",
    "abstract": "The neural attention mechanism has been incorporated into deep neural\nnetworks to achieve state-of-the-art performance in various domains. Most such\nmodels use multi-head self-attention which is appealing for the ability to\nattend to information from different perspectives. This paper introduces\nalignment attention that explicitly encourages self-attention to match the\ndistributions of the key and query within each head. The resulting alignment\nattention networks can be optimized as an unsupervised regularization in the\nexisting attention framework. It is simple to convert any models with\nself-attention, including pre-trained ones, to the proposed alignment\nattention. On a variety of language understanding tasks, we show the\neffectiveness of our method in accuracy, uncertainty estimation, generalization\nacross domains, and robustness to adversarial attacks. We further demonstrate\nthe general applicability of our approach on graph attention and visual\nquestion answering, showing the great potential of incorporating our alignment\nmethod into various attention-related tasks.",
    "descriptor": "\nComments: NeurIPS 2021; Our code is publicly available at this https URL\n",
    "authors": [
      "Shujian Zhang",
      "Xinjie Fan",
      "Huangjie Zheng",
      "Korawat Tanwisuth",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12567"
  },
  {
    "id": "arXiv:2110.12569",
    "title": "Conductance and Social Capital: Modeling and Empirically Measuring  Online Social Influence",
    "abstract": "Social influence pervades our everyday lives and lays the foundation for\ncomplex social phenomena. In a crisis like the COVID-19 pandemic, social\ninfluence can determine whether life-saving information is adopted. Existing\nliterature studying online social influence suffers from several drawbacks.\nFirst, a disconnect appears between psychology approaches, which are generally\nperformed and tested in controlled lab experiments, and the quantitative\nmethods, which are usually data-driven and rely on network and event analysis.\nThe former are slow, expensive to deploy, and typically do not generalize well\nto topical issues (such as an ongoing pandemic); the latter often oversimplify\nthe complexities of social influence and ignore psychosocial literature. This\nwork bridges this gap and presents three contributions towards modeling and\nempirically quantifying online influence. The first contribution is a\ndata-driven Generalized Influence Model that incorporates two novel\npsychosocial-inspired mechanisms: the conductance of the diffusion network and\nthe social capital distribution. The second contribution is a framework to\nempirically rank users' social influence using a human-in-the-loop active\nlearning method combined with crowdsourced pairwise influence comparisons. We\nbuild a human-labeled ground truth, calibrate our generalized influence model\nand perform a large-scale evaluation of influence. We find that our generalized\nmodel outperforms the current state-of-the-art approaches and corrects the\ninherent biases introduced by the widely used follower count. As the third\ncontribution, we apply the influence model to discussions around COVID-19. We\nquantify users' influence, and we tabulate it against their professions. We\nfind that the executives, media, and military are more influential than\npandemic-related experts such as life scientists and healthcare professionals.",
    "descriptor": "",
    "authors": [
      "Rohit Ram",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.12569"
  },
  {
    "id": "arXiv:2110.12576",
    "title": "Maximizing the Smallest Eigenvalue of Grounded Laplacian Matrix",
    "abstract": "For a connected graph $\\mathcal{G}=(V,E)$ with $n$ nodes, $m$ edges, and\nLaplacian matrix $\\boldsymbol{{\\mathit{L}}}$, a grounded Laplacian matrix\n$\\boldsymbol{{\\mathit{L}}}(S)$ of $\\mathcal{G}$ is a $(n-k) \\times (n-k)$\nprincipal submatrix of $\\boldsymbol{{\\mathit{L}}}$, obtained from\n$\\boldsymbol{{\\mathit{L}}}$ by deleting $k$ rows and columns corresponding to\n$k$ selected nodes forming a set $S\\subseteq V$. The smallest eigenvalue\n$\\lambda(S)$ of $\\boldsymbol{{\\mathit{L}}}(S)$ plays a pivotal role in various\ndynamics defined on $\\mathcal{G}$. For example, $\\lambda(S)$ characterizes the\nconvergence rate of leader-follower consensus, as well as the effectiveness of\na pinning scheme for the pinning control problem, with larger $\\lambda(S)$\ncorresponding to smaller convergence time or better effectiveness of a pinning\nscheme. In this paper, we focus on the problem of optimally selecting a subset\n$S$ of fixed $k \\ll n$ nodes, in order to maximize the smallest eigenvalue\n$\\lambda(S)$ of the grounded Laplacian matrix $\\boldsymbol{{\\mathit{L}}}(S)$.\nWe show that this optimization problem is NP-hard and that the objective\nfunction is non-submodular but monotone. Due to the difficulty to obtain the\noptimal solution, we first propose a na\\\"{\\i}ve heuristic algorithm selecting\none optimal node at each time for $k$ iterations. Then we propose a fast\nheuristic scalable algorithm to approximately solve this problem, using\nderivative matrix, matrix perturbations, and Laplacian solvers as tools. Our\nna\\\"{\\i}ve heuristic algorithm takes $\\tilde{O}(knm)$ time, while the fast\ngreedy heuristic has a nearly linear time complexity of $\\tilde{O}(km)$. We\nalso conduct numerous experiments on different networks sized up to one million\nnodes, demonstrating the superiority of our algorithm in terms of efficiency\nand effectiveness.",
    "descriptor": "",
    "authors": [
      "Run Wang",
      "Xiaotian Zhou",
      "Wei Li",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12576"
  },
  {
    "id": "arXiv:2110.12577",
    "title": "Simulation and Model Checking for Close to Realtime Overtaking Planning",
    "abstract": "Fast and reliable trajectory planning is a key requirement of autonomous\nvehicles. In this paper we introduce a novel technique for planning the route\nof an autonomous vehicle on a straight rural road using the Spin model checker.\nWe show how we can combine Spins ability to identify paths violating temporal\nproperties with sensor information from a 3D Unity simulation of an autonomous\nvehicle, to plan and perform consecutive overtaking manoeuvres on a traffic\nheavy road. This involves discretising the sensory information and combining\nmultiple sequential Spin models with a Linear Time Temporal Logic specification\nto generate an error path. This path provides the autonomous vehicle with an\naction plan. The entire process takes place in close to realtime using no\nprecomputed data and the action plan is specifically tailored for individual\nscenarios. Our experiments demonstrate that the simulated autonomous vehicle\nimplementing our approach can drive on average at least 40km and overtake 214\nvehicles before experiencing a collision, which is usually caused by\ninaccuracies in the sensory system. While the proposed system has some\ndrawbacks, we believe that our novel approach demonstrates a potentially\npowerful future tool for efficient trajectory planning for autonomous vehicles.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Daumantas Pagojus",
      "Alice Miller",
      "Bernd Porr",
      "Ivaylo Valkov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.12577"
  },
  {
    "id": "arXiv:2110.12578",
    "title": "Improving Online Railway Deadlock Detection using a Partial Order  Reduction",
    "abstract": "Although railway dispatching on large national networks is gradually becoming\nmore computerized, there are still major obstacles to retrofitting\n(semi-)autonomous control systems. In addition to requiring extensive and\ndetailed digitalization of infrastructure models and information systems, exact\noptimization for railway dispatching is computationally hard. Heuristic\nalgorithms and manual overrides are likely to be required for semi-autonomous\nrailway operations for the foreseeable future.\nIn this context, being able to detect problems such as deadlocks can be a\nvaluable part of a runtime verification system. If bound-for-deadlock\nsituations are correctly recognized as early as possible, human operators will\nhave more time to better plan for recovery operations. Deadlock detection may\nalso be useful for verification in a feedback loop with a heuristic or\nsemi-autonomous dispatching algorithm if the dispatching algorithm cannot\nitself guarantee a deadlock-free plan.\nWe describe a SAT-based planning algorithm for online detection of\nbound-for-deadlock situations. The algorithm exploits parallel updates of train\npositions and a partial order reduction technique to significantly reduce the\nnumber of state transitions (and correspondingly, the sizes of the formulas) in\nthe SAT instances needed to prove whether a deadlock situation is bound to\nhappen in the future. Implementation source code and benchmark instances are\nsupplied, and a direct comparison against another recent study demonstrates\nsignificant performance gains.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Bj\u00f8rnar Luteberget"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12578"
  },
  {
    "id": "arXiv:2110.12579",
    "title": "Observable and Attention-Directing BDI Agents for Human-Autonomy Teaming",
    "abstract": "Human-autonomy teaming (HAT) scenarios feature humans and autonomous agents\ncollaborating to meet a shared goal. For effective collaboration, the agents\nmust be transparent and able to share important information about their\noperation with human teammates. We address the challenge of transparency for\nBelief-Desire-Intention agents defined in the Conceptual Agent Notation (CAN)\nlanguage. We extend the semantics to model agents that are observable (i.e. the\ninternal state of tasks is available), and attention-directing (i.e. specific\nstates can be flagged to users), and provide an executable semantics via an\nencoding in Milner's bigraphs. Using an example of unmanned aerial vehicles,\nthe BigraphER tool, and PRISM, we show and verify how the extensions work in\npractice.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Blair Archibald",
      "Muffy Calder",
      "Michele Sevegnani",
      "Mengwei Xu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Human-Computer Interaction (cs.HC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.12579"
  },
  {
    "id": "arXiv:2110.12581",
    "title": "Towards a Formalisation of Justification and Justifiability",
    "abstract": "We introduce the logic QKSD which is a normal multi-modal logic over finitely\nmany modalities that additionally supports bounded quantification of\nmodalities. An important feature of this logic is that it allows to quantify\nover the information components of systems and, hence, can be used to derive\njustifications. We compare the proposed logic with Artemov's justification\nlogic and also report on a prototypical implementation of a satisfiability\nsolver of this logic and show some examples.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Willem Hagemann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.12581"
  },
  {
    "id": "arXiv:2110.12583",
    "title": "Extending Urban Multi-Lane Spatial Logic to Formalise Road Junction  Rules",
    "abstract": "During the design of autonomous vehicles (AVs), several stages should include\na verification process to guarantee that the AV is driving safely on the roads.\nOne of these stages is to assure the AVs abide by the road traffic rules. To\ninclude road traffic rules in the design of an AV, a precise and unambiguous\nformalisation of these rules is needed. However, only recently this has been\npointed out as an issue for the design of AVs and the few works on this only\ncapture the temporal aspects of the rules, leaving behind the spatial aspects.\nHere, we extend the spatial traffic logic, Urban Multi-lane Spatial Logic, to\nformalise a subset of the UK road junction rules, where both temporal and\nspatial aspects of the rules are captured. Our approach has an abstraction\nlevel for urban road junctions that could easily promote the formalisation of\nthe whole set of road junction rules and we exemplarily formalise three of the\nUK road junction rules. Once we have the whole set formalised, we will model,\nimplement, and formally verify the behaviour of an AV against road traffic\nrules so that guidelines for the creation of a Digital Highway Code for AVs can\nbe established.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Maike Schwammberger",
      "Gleifer Vaz Alves"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.12583"
  },
  {
    "id": "arXiv:2110.12585",
    "title": "Towards Partial Monitoring: It is Always too Soon to Give Up",
    "abstract": "Runtime Verification is a lightweight formal verification technique. It is\nused to verify at runtime whether the system under analysis behaves as\nexpected. The expected behaviour is usually formally specified by means of\nproperties, which are used to automatically synthesise monitors. A monitor is a\ndevice that, given a sequence of events representing a system execution,\nreturns a verdict symbolising the satisfaction or violation of the formal\nproperty. Properties that can (resp. cannot) be verified at runtime by a\nmonitor are called monitorable and non-monitorable, respectively. In this\npaper, we revise the notion of monitorability from a practical perspective,\nwhere we show how non-monitorable properties can still be used to generate\npartial monitors, which can partially check the properties. Finally, we present\nthe implications both from a theoretical and practical perspectives.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Angelo Ferrando",
      "Rafael C. Cardoso"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.12585"
  },
  {
    "id": "arXiv:2110.12586",
    "title": "Complete Agent-driven Model-based System Testing for Autonomous Systems",
    "abstract": "In this position paper, a novel approach to testing complex autonomous\ntransportation systems (ATS) in the automotive, avionic, and railway domains is\ndescribed. It is intended to mitigate some of the most critical problems\nregarding verification and validation (V&V) effort for ATS. V&V is known to\nbecome infeasible for complex ATS, when using conventional methods only. The\napproach advocated here uses complete testing methods on the module level,\nbecause these establish formal proofs for the logical correctness of the\nsoftware. Having established logical correctness, system-level tests are\nperformed in simulated cloud environments and on the target system. To give\nevidence that 'sufficiently many' system tests have been performed with the\ntarget system, a formally justified coverage criterion is introduced. To\noptimise the execution of very large system test suites, we advocate an online\ntesting approach where multiple tests are executed in parallel, and test steps\nare identified on-the-fly. The coordination and optimisation of these\nexecutions is achieved by an agent-based approach. Each aspect of the testing\napproach advocated here is shown to either be consistent with existing\nstandards for development and V&V of safety-critical transportation systems, or\nit is justified why it should become acceptable in future revisions of the\napplicable standards.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Kerstin I. Eder",
      "Wen-ling Huang",
      "Jan Peleska"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.12586"
  },
  {
    "id": "arXiv:2110.12587",
    "title": "Formal Guarantees of Timely Progress for Distributed Knowledge  Propagation",
    "abstract": "Autonomous air traffic management (ATM) operations for urban air mobility\n(UAM) will necessitate the use of distributed protocols for decentralized\ncoordination between aircraft. As UAM operations are time-critical, it will be\nimperative to have formal guarantees of progress for the distributed protocols\nused in ATM. Under asynchronous settings, message transmission and processing\ndelays are unbounded, making it impossible to provide deterministic bounds on\nthe time required to make progress. We present an approach for formally\nguaranteeing timely progress in a Two-Phase Acknowledge distributed knowledge\npropagation protocol by probabilistically modeling the delays using theories of\nthe Multicopy Two-Hop Relay protocol and the M/M/1 queue system. The guarantee\nstates a probabilistic upper bound to the time for progress as a function of\nthe probabilities of the total transmission and processing delays being less\nthan two given values. We also showcase the development of a library of formal\ntheories, that is tailored towards reasoning about timely progress in\ndistributed protocols deployed in airborne networks, in the Athena proof\nassistant.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Saswata Paul",
      "Stacy Patterson",
      "Carlos Varela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12587"
  },
  {
    "id": "arXiv:2110.12588",
    "title": "QuantifyML: How Good is my Machine Learning Model?",
    "abstract": "The efficacy of machine learning models is typically determined by computing\ntheir accuracy on test data sets. However, this may often be misleading, since\nthe test data may not be representative of the problem that is being studied.\nWith QuantifyML we aim to precisely quantify the extent to which machine\nlearning models have learned and generalized from the given data. Given a\ntrained model, QuantifyML translates it into a C program and feeds it to the\nCBMC model checker to produce a formula in Conjunctive Normal Form (CNF). The\nformula is analyzed with off-the-shelf model counters to obtain precise counts\nwith respect to different model behavior. QuantifyML enables i) evaluating\nlearnability by comparing the counts for the outputs to ground truth, expressed\nas logical predicates, ii) comparing the performance of models built with\ndifferent machine learning algorithms (decision-trees vs. neural networks), and\niii) quantifying the safety and robustness of models.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Muhammad Usman",
      "Divya Gopinath",
      "Corina S. P\u0103s\u0103reanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12588"
  },
  {
    "id": "arXiv:2110.12589",
    "title": "Complete Test of Synthesised Safety Supervisors for Robots and  Autonomous Systems",
    "abstract": "Verified controller synthesis uses world models that comprise all potential\nbehaviours of humans, robots, further equipment, and the controller to be\nsynthesised. A world model enables quantitative risk assessment, for example,\nby stochastic model checking. Such a model describes a range of controller\nbehaviours some of which -- when implemented correctly -- guarantee that the\noverall risk in the actual world is acceptable, provided that the stochastic\nassumptions have been made to the safe side. Synthesis then selects an\nacceptable-risk controller behaviour. However, because of crossing abstraction,\nformalism, and tool boundaries, verified synthesis for robots and autonomous\nsystems has to be accompanied by rigorous testing. In general, standards and\nregulations for safety-critical systems require testing as a key element to\nobtain certification credit before entry into service. This work-in-progress\npaper presents an approach to the complete testing of synthesised supervisory\ncontrollers that enforce safety properties in domains such as human-robot\ncollaboration and autonomous driving. Controller code is generated from the\nselected controller behaviour. The code generator, however, is hard, if not\ninfeasible, to verify in a formal and comprehensive way. Instead, utilising\ntesting, an abstract test reference is generated, a symbolic finite state\nmachine with simpler semantics than code semantics. From this reference, a\ncomplete test suite is derived and applied to demonstrate the observational\nequivalence between the synthesised abstract test reference and the generated\nconcrete controller code running on a control system platform.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Mario Gleirscher",
      "Jan Peleska"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12589"
  },
  {
    "id": "arXiv:2110.12590",
    "title": "Online Strategy Synthesis for Safe and Optimized Control of Steerable  Needles",
    "abstract": "Autonomous systems are often applied in uncertain environments, which require\nprospective action planning and retrospective data evaluation for future\nplanning to ensure safe operation. Formal approaches may support these systems\nwith safety guarantees, but are usually expensive and do not scale well with\ngrowing system complexity. In this paper, we introduce online strategy\nsynthesis based on classical strategy synthesis to derive formal safety\nguarantees while reacting and adapting to environment changes. To guarantee\nsafety online, we split the environment into region types which determine the\nacceptance of action plans and trigger local correcting actions. Using model\nchecking on a frequently updated model, we can then derive locally safe action\nplans (prospectively), and match the current model against new observations via\nreachability checks (retrospectively). As use case, we successfully apply\nonline strategy synthesis to medical needle steering, i.e., navigating a\n(flexible and beveled) needle through tissue towards a target without damaging\nits surroundings.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Sascha Lehmann",
      "Antje Rogalla",
      "Maximilian Neidhardt",
      "Alexander Schlaefer",
      "Sibylle Schupp"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.12590"
  },
  {
    "id": "arXiv:2110.12591",
    "title": "Assuring Increasingly Autonomous Systems in Human-Machine Teams: An  Urban Air Mobility Case Study",
    "abstract": "As aircraft systems become increasingly autonomous, the human-machine role\nallocation changes and opportunities for new failure modes arise. This\nnecessitates an approach to identify the safety requirements for the\nincreasingly autonomous system (IAS) as well as a framework and techniques to\nverify and validate that an IAS meets its safety requirements. We use Crew\nResource Management techniques to identify requirements and behaviors for safe\nhuman-machine teaming behaviors. We provide a methodology to verify that an IAS\nmeets its requirements. We apply the methodology to a case study in Urban Air\nMobility, which includes two contingency scenarios: unreliable sensor and\naborted landing. For this case study, we implement an IAS agent in the Soar\nlanguage that acts as a copilot for the selected contingency scenarios and\nperforms takeoff and landing preparation, while the pilot maintains final\ndecision authority. We develop a formal human-machine team architecture model\nin the Architectural Analysis and Design Language (AADL), with operator and IAS\nrequirements formalized in the Assume Guarantee REasoning Environment (AGREE)\nAnnex to AADL. We formally verify safety requirements for the human-machine\nteam given the requirements on the IAS and operator. We develop an automated\ntranslator from Soar to the nuXmv model checking language and formally verify\nthat the IAS agent satisfies its requirements using nuXmv. We share the design\nand requirements errors found in the process as well as our lessons learned.",
    "descriptor": "\nComments: In Proceedings FMAS 2021, arXiv:2110.11527\n",
    "authors": [
      "Siddhartha Bhattacharyya",
      "Jennifer Davis",
      "Anubhav Gupta",
      "Nandith Narayan",
      "Michael Matessa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12591"
  },
  {
    "id": "arXiv:2110.12594",
    "title": "Developing a Meta-suggestion Engine for Search Query",
    "abstract": "With the development of the Internet and the accumulation of information on\nthe web, users use a search engine to easily obtain the desired information. A\nquery suggestion is one of the main services provided by a search engine, and\nis very important for improving search performance, creating efficient queries,\nand reducing search time. However, there are search engines that do not support\nthe query suggestion service. Under such engines, if users want to perform a\nsearch, they would have much difficulties in effectively performing the search.\nIn this paper, to tackle the problem, we propose and develop a metasuggestion\nengine that crawls suggested search queries from search engines with a\nsuggestion service, applies a re-ranking algorithm, and provides the suggested\nsearch queries in the form of an extension program on a web browser.\nMeta-suggestion engine are useful for users searching in engines that do not\nprovide query suggestions, as they provide query suggestions wherever the user\nsearches. We evaluate engines with relevance-based and predictive hit-based\nevaluation methods, showing that MSE produces good quality suggestions. We\nstudy improvements in target engine selection and re-ranking algorithms in\nfuture studies.",
    "descriptor": "",
    "authors": [
      "Seungmin Kim",
      "EunChan Na",
      "Seong Baeg Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12594"
  },
  {
    "id": "arXiv:2110.12596",
    "title": "GeoSneakPique: Visual Autocompletion for Geospatial Queries",
    "abstract": "How many crimes occurred in the city center? And exactly which part of town\nis the 'city center'? While location is at the heart of many data questions,\ngeographic location can be difficult to specify in natural language (NL)\nqueries. This is especially true when working with fuzzy cognitive regions or\nregions that may be defined based on data distributions instead of absolute\nadministrative location (e.g., state, country). GeoSneakPique presents a novel\nmethod for using a mapping widget to support the NL query process, allowing\nusers to specify location via direct manipulation with data-driven guidance on\nspatial distributions to help select the area of interest. Users receive\nfeedback to help them evaluate and refine their spatial selection interactively\nand can save spatial definitions for re-use in subsequent queries. We conduct a\nqualitative evaluation of the GeoSneakPique that indicates the usefulness of\nthe interface as well as opportunities for better supporting geospatial\nworkflows in visual analysis tasks employing cognitive regions.",
    "descriptor": "\nComments: 5 pages (4 + 1 page references), two figures\n",
    "authors": [
      "Vidya Setlur",
      "Sarah Battersby",
      "Tracy Wong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12596"
  },
  {
    "id": "arXiv:2110.12601",
    "title": "Semantic Resizing of Charts Through Generalization:A Case Study with  Line Charts",
    "abstract": "Inspired by cartographic generalization principles, we present a\ngeneralization technique for rendering line charts at different sizes,\npreserving the important semantics of the data at that display size. The\nalgorithm automatically determines the generalization operators to be applied\nat that size based on spatial density, distance, and the semantic importance of\nthe various visualization elements in the line chart. A qualitative evaluation\nof the prototype that implemented the algorithm indicates that the generalized\nline charts pre-served the general data shape, while minimizing visual clutter.\nWe identify future opportunities where generalization can be extended and\napplied to other chart types and visual analysis authoring tools.",
    "descriptor": "\nComments: 5 pages (4 + 1 page references), 4 figures\n",
    "authors": [
      "Vidya Setlur",
      "Haeyong Chung"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12601"
  },
  {
    "id": "arXiv:2110.12602",
    "title": "Dynamic Influence Maximization",
    "abstract": "We initiate a systematic study on $\\mathit{dynamic}$ $\\mathit{influence}$\n$\\mathit{maximization}$ (DIM). In the DIM problem, one maintains a seed set $S$\nof at most $k$ nodes in a dynamically involving social network, with the goal\nof maximizing the expected influence spread while minimizing the amortized\nupdating cost. We consider two involution models. In the $\\mathit{incremental}$\nmodel, the social network gets enlarged over time and one only introduces new\nusers and establishes new social links, we design an algorithm that achieves\n$(1-1/e-\\epsilon)$-approximation to the optimal solution and has $k\n\\cdot\\mathsf{poly}(\\log n, \\epsilon^{-1})$ amortized running time, which\nmatches the state-of-art offline algorithm with only poly-logarithmic overhead.\nIn the $\\mathit{fully}$ $\\mathit{dynamic}$ model, users join in and leave,\ninfluence propagation gets strengthened or weakened in real time, we prove that\nunder the Strong Exponential Time Hypothesis (SETH), no algorithm can achieve\n$2^{-(\\log n)^{1-o(1)}}$-approximation unless the amortized running time is\n$n^{1-o(1)}$. On the technical side, we exploit novel adaptive sampling\napproaches that reduce DIM to the dynamic MAX-k coverage problem, and design an\nefficient $(1-1/e-\\epsilon)$-approximation algorithm for it. Our lower bound\nleverages the recent developed distributed PCP framework.",
    "descriptor": "",
    "authors": [
      "Binghui Peng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12602"
  },
  {
    "id": "arXiv:2110.12603",
    "title": "Common Information based Approximate State Representations in  Multi-Agent Reinforcement Learning",
    "abstract": "Due to information asymmetry, finding optimal policies for Decentralized\nPartially Observable Markov Decision Processes (Dec-POMDPs) is hard with the\ncomplexity growing doubly exponentially in the horizon length. The challenge\nincreases greatly in the multi-agent reinforcement learning (MARL) setting\nwhere the transition probabilities, observation kernel, and reward function are\nunknown. Here, we develop a general compression framework with approximate\ncommon and private state representations, based on which decentralized policies\ncan be constructed. We derive the optimality gap of executing dynamic\nprogramming (DP) with the approximate states in terms of the approximation\nerror parameters and the remaining time steps. When the compression is exact\n(no error), the resulting DP is equivalent to the one in existing work. Our\ngeneral framework generalizes a number of methods proposed in the literature.\nThe results shed light on designing practically useful deep-MARL network\nstructures under the \"centralized learning distributed execution\" scheme.",
    "descriptor": "",
    "authors": [
      "Hsu Kao",
      "Vijay Subramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.12603"
  },
  {
    "id": "arXiv:2110.12606",
    "title": "MUSE: Feature Self-Distillation with Mutual Information and  Self-Information",
    "abstract": "We present a novel information-theoretic approach to introduce dependency\namong features of a deep convolutional neural network (CNN). The core idea of\nour proposed method, called MUSE, is to combine MUtual information and\nSElf-information to jointly improve the expressivity of all features extracted\nfrom different layers in a CNN. We present two variants of the realization of\nMUSE -- Additive Information and Multiplicative Information. Importantly, we\nargue and empirically demonstrate that MUSE, compared to other feature\ndiscrepancy functions, is a more functional proxy to introduce dependency and\neffectively improve the expressivity of all features in the knowledge\ndistillation framework. MUSE achieves superior performance over a variety of\npopular architectures and feature discrepancy functions for self-distillation\nand online distillation, and performs competitively with the state-of-the-art\nmethods for offline distillation. MUSE is also demonstrably versatile that\nenables it to be easily extended to CNN-based models on tasks other than image\nclassification such as object detection.",
    "descriptor": "\nComments: The 32nd British Machine Vision Conference (BMVC 2021)\n",
    "authors": [
      "Yu Gong",
      "Ye Yu",
      "Gaurav Mittal",
      "Greg Mori",
      "Mei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12606"
  },
  {
    "id": "arXiv:2110.12607",
    "title": "Least Square Calibration for Peer Review",
    "abstract": "Peer review systems such as conference paper review often suffer from the\nissue of miscalibration. Previous works on peer review calibration usually only\nuse the ordinal information or assume simplistic reviewer scoring functions\nsuch as linear functions. In practice, applications like academic conferences\noften rely on manual methods, such as open discussions, to mitigate\nmiscalibration. It remains an important question to develop algorithms that can\nhandle different types of miscalibrations based on available prior knowledge.\nIn this paper, we propose a flexible framework, namely least square calibration\n(LSC), for selecting top candidates from peer ratings. Our framework provably\nperforms perfect calibration from noiseless linear scoring functions under mild\nassumptions, yet also provides competitive calibration results when the scoring\nfunction is from broader classes beyond linear functions and with arbitrary\nnoise. On our synthetic dataset, we empirically demonstrate that our algorithm\nconsistently outperforms the baseline which select top papers based on the\nhighest average ratings.",
    "descriptor": "",
    "authors": [
      "Sijun Tan",
      "Jibang Wu",
      "Xiaohui Bei",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.12607"
  },
  {
    "id": "arXiv:2110.12609",
    "title": "No News is Good News: A Critique of the One Billion Word Benchmark",
    "abstract": "The One Billion Word Benchmark is a dataset derived from the WMT 2011 News\nCrawl, commonly used to measure language modeling ability in natural language\nprocessing. We train models solely on Common Crawl web scrapes partitioned by\nyear, and demonstrate that they perform worse on this task over time due to\ndistributional shift. Analysis of this corpus reveals that it contains several\nexamples of harmful text, as well as outdated references to current events. We\nsuggest that the temporal nature of news and its distribution shift over time\nmakes it poorly suited for measuring language modeling ability, and discuss\npotential impact and considerations for researchers building language models\nand evaluation datasets.",
    "descriptor": "",
    "authors": [
      "Helen Ngo",
      "Jo\u00e3o G.M. Ara\u00fajo",
      "Jeffrey Hui",
      "Nicholas Frosst"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12609"
  },
  {
    "id": "arXiv:2110.12610",
    "title": "Antenna Array Enabled Space/Air/Ground Communications and Networking for  6G",
    "abstract": "Antenna arrays have a long history of more than 100 years and have evolved\nclosely with the development of electronic and information technologies,\nplaying an indispensable role in wireless communications and radar. With the\nrapid development of electronic and information technologies, the demand for\nall-time, all-domain, and full-space network services has exploded, and new\ncommunication requirements have been put forward on various space/air/ground\nplatforms. To meet the ever increasing requirements of the future sixth\ngeneration (6G) wireless communications, such as high capacity, wide coverage,\nlow latency, and strong robustness, it is promising to employ different types\nof antenna arrays with various beamforming technologies in space/air/ground\ncommunication networks, bringing in advantages such as considerable antenna\ngains, multiplexing gains, and diversity gains. However, enabling antenna array\nfor space/air/ground communication networks poses specific, distinctive and\ntricky challenges, which has aroused extensive research attention. This paper\naims to overview the field of antenna array enabled space/air/ground\ncommunications and networking. The technical potentials and challenges of\nantenna array enabled space/air/ground communications and networking are\npresented first. Subsequently, the antenna array structures and designs are\ndiscussed. We then discuss various emerging technologies facilitated by antenna\narrays to meet the new communication requirements of space/air/ground\ncommunication systems. Enabled by these emerging technologies, the distinct\ncharacteristics, challenges, and solutions for space communications, airborne\ncommunications, and ground communications are reviewed. Finally, we present\npromising directions for future research in antenna array enabled\nspace/air/ground communications and networking.",
    "descriptor": "",
    "authors": [
      "Zhenyu Xiao",
      "Zhu Han",
      "Arumugam Nallanathan",
      "Octavia A. Dobre",
      "Bruno Clerckx",
      "Jinho Choi",
      "Chong He",
      "Wen Tong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12610"
  },
  {
    "id": "arXiv:2110.12612",
    "title": "DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard  Challenge 2021",
    "abstract": "This paper describes the Microsoft end-to-end neural text to speech (TTS)\nsystem: DelightfulTTS for Blizzard Challenge 2021. The goal of this challenge\nis to synthesize natural and high-quality speech from text, and we approach\nthis goal in two perspectives: The first is to directly model and generate\nwaveform in 48 kHz sampling rate, which brings higher perception quality than\nprevious systems with 16 kHz or 24 kHz sampling rate; The second is to model\nthe variation information in speech through a systematic design, which improves\nthe prosody and naturalness. Specifically, for 48 kHz modeling, we predict 16\nkHz mel-spectrogram in acoustic model, and propose a vocoder called HiFiNet to\ndirectly generate 48 kHz waveform from predicted 16 kHz mel-spectrogram, which\ncan better trade off training efficiency, modelling stability and voice\nquality. We model variation information systematically from both explicit\n(speaker ID, language ID, pitch and duration) and implicit (utterance-level and\nphoneme-level prosody) perspectives: 1) For speaker and language ID, we use\nlookup embedding in training and inference; 2) For pitch and duration, we\nextract the values from paired text-speech data in training and use two\npredictors to predict the values in inference; 3) For utterance-level and\nphoneme-level prosody, we use two reference encoders to extract the values in\ntraining, and use two separate predictors to predict the values in inference.\nAdditionally, we introduce an improved Conformer block to better model the\nlocal and global dependency in acoustic model. For task SH1, DelightfulTTS\nachieves 4.17 mean score in MOS test and 4.35 in SMOS test, which indicates the\neffectiveness of our proposed system",
    "descriptor": "",
    "authors": [
      "Yanqing Liu",
      "Zhihang Xu",
      "Gang Wang",
      "Kuan Chen",
      "Bohan Li",
      "Xu Tan",
      "Jinzhu Li",
      "Lei He",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12612"
  },
  {
    "id": "arXiv:2110.12613",
    "title": "Federated Test-Time Adaptive Face Presentation Attack Detection with  Dual-Phase Privacy Preservation",
    "abstract": "Face presentation attack detection (fPAD) plays a critical role in the modern\nface recognition pipeline. The generalization ability of face presentation\nattack detection models to unseen attacks has become a key issue for real-world\ndeployment, which can be improved when models are trained with face images from\ndifferent input distributions and different types of spoof attacks. In reality,\ndue to legal and privacy issues, training data (both real face images and spoof\nimages) are not allowed to be directly shared between different data sources.\nIn this paper, to circumvent this challenge, we propose a Federated Test-Time\nAdaptive Face Presentation Attack Detection with Dual-Phase Privacy\nPreservation framework, with the aim of enhancing the generalization ability of\nfPAD models in both training and testing phase while preserving data privacy.\nIn the training phase, the proposed framework exploits the federated learning\ntechnique, which simultaneously takes advantage of rich fPAD information\navailable at different data sources by aggregating model updates from them\nwithout accessing their private data. To further boost the generalization\nability, in the testing phase, we explore test-time adaptation by minimizing\nthe entropy of fPAD model prediction on the testing data, which alleviates the\ndomain gap between training and testing data and thus reduces the\ngeneralization error of a fPAD model. We introduce the experimental setting to\nevaluate the proposed framework and carry out extensive experiments to provide\nvarious insights about the proposed method for fPAD.",
    "descriptor": "\nComments: Accepted by FG 2021. arXiv admin note: substantial text overlap with arXiv:2104.06595, arXiv:2005.14638\n",
    "authors": [
      "Rui Shao",
      "Bochao Zhang",
      "Pong C. Yuen",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12613"
  },
  {
    "id": "arXiv:2110.12615",
    "title": "Linear Contextual Bandits with Adversarial Corruptions",
    "abstract": "We study the linear contextual bandit problem in the presence of adversarial\ncorruption, where the interaction between the player and a possibly infinite\ndecision set is contaminated by an adversary that can corrupt the reward up to\na corruption level $C$ measured by the sum of the largest alteration on rewards\nin each round. We present a variance-aware algorithm that is adaptive to the\nlevel of adversarial contamination $C$. The key algorithmic design includes (1)\na multi-level partition scheme of the observed data, (2) a cascade of\nconfidence sets that are adaptive to the level of the corruption, and (3) a\nvariance-aware confidence set construction that can take advantage of\nlow-variance reward. We further prove that the regret of the proposed algorithm\nis $\\tilde{O}(C^2d\\sqrt{\\sum_{t = 1}^T \\sigma_t^2} + C^2R\\sqrt{dT})$, where $d$\nis the dimension of context vectors, $T$ is the number of rounds, $R$ is the\nrange of noise and $\\sigma_t^2,t=1\\ldots,T$ are the variances of instantaneous\nreward. We also prove a gap-dependent regret bound for the proposed algorithm,\nwhich is instance-dependent and thus leads to better performance on good\npractical instances. To the best of our knowledge, this is the first\nvariance-aware corruption-robust algorithm for contextual bandits. Experiments\non synthetic data corroborate our theory.",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Heyang Zhao",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12615"
  },
  {
    "id": "arXiv:2110.12618",
    "title": "Learning Insertion Primitives with Discrete-Continuous Hybrid Action  Space for Robotic Assembly Tasks",
    "abstract": "This paper introduces a discrete-continuous action space to learn insertion\nprimitives for robotic assembly tasks. Primitive is a sequence of elementary\nactions with certain exit conditions, such as \"pushing down the peg until\ncontact\". Since the primitive is an abstraction of robot control commands and\nencodes human prior knowledge, it reduces the exploration difficulty and yields\nbetter learning efficiency. In this paper, we learn robot assembly skills via\nprimitives. Specifically, we formulate insertion primitives as parameterized\nactions: hybrid actions consisting of discrete primitive types and continuous\nprimitive parameters. Compared with the previous work using a set of\ndiscretized parameters for each primitive, the agent in our method can freely\nchoose primitive parameters from a continuous space, which is more flexible and\nefficient. To learn these insertion primitives, we propose Twin-Smoothed\nMulti-pass Deep Q-Network (TS-MP-DQN), an advanced version of MP-DQN with twin\nQ-network to reduce the Q-value over-estimation. Extensive experiments are\nconducted in the simulation and real world for validation. From experiment\nresults, our approach achieves higher success rates than three baselines:\nMP-DQN with parameterized actions, primitives with discrete parameters, and\ncontinuous velocity control. Furthermore, learned primitives are robust to\nsim-to-real transfer and can generalize to challenging assembly tasks such as\ntight round peg-hole and complex shaped electric connectors with promising\nsuccess rates. Experiment videos are available at\nhttps://msc.berkeley.edu/research/insertion-primitives.html.",
    "descriptor": "\nComments: Submitted to ICRA 22\n",
    "authors": [
      "Xiang Zhang",
      "Shiyu Jin",
      "Changhao Wang",
      "Xinghao Zhu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12618"
  },
  {
    "id": "arXiv:2110.12621",
    "title": "Accelerate 3D Object Processing via Spectral Layout",
    "abstract": "3D image processing is an important problem in computer vision and pattern\nrecognition fields. Compared with 2D image processing, its computation\ndifficulty and cost are much higher due to the extra dimension. To\nfundamentally address this problem, we propose to embed the essential\ninformation in a 3D object into 2D space via spectral layout. Specifically, we\nconstruct a 3D adjacency graph to capture spatial structure of the 3D voxel\ngrid. Then we calculate the eigenvectors corresponding to the second and third\nsmallest eigenvalues of its graph Laplacian and perform spectral layout to map\neach voxel into a pixel in 2D Cartesian coordinate plane. The proposed method\ncan achieve high quality 2D representations for 3D objects, which enables to\nuse 2D-based methods to process 3D objects. The experimental results\ndemonstrate the effectiveness and efficiency of our method.",
    "descriptor": "",
    "authors": [
      "Yongyu Wang",
      "Hang Su",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12621"
  },
  {
    "id": "arXiv:2110.12623",
    "title": "Ultra Light OCR Competition Technical Report",
    "abstract": "Ultra Light OCR Competition is a Chinese scene text recognition competition\njointly organized by CSIG (China Society of Image and Graphics) and Baidu, Inc.\nIn addition to focusing on common problems in Chinese scene text recognition,\nsuch as long text length and massive characters, we need to balance the\ntrade-off of model scale and accuracy since the model size limitation in the\ncompetition is 10M.\nFrom experiments in aspects of data, model, training, etc, we proposed a\ngeneral and effective method for Chinese scene text recognition, which got us\nsecond place among over 100 teams with accuracy 0.817 in TestB dataset. The\ncode is available at https://aistudio.baidu.com/aistudio/projectdetail/2159102.",
    "descriptor": "",
    "authors": [
      "Shuhan Zhang",
      "Yuxin Zou",
      "Tianhe Wang",
      "Yichao Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12623"
  },
  {
    "id": "arXiv:2110.12627",
    "title": "Orthogonal variance-based feature selection for intrusion detection  systems",
    "abstract": "In this paper, we apply a fusion machine learning method to construct an\nautomatic intrusion detection system. Concretely, we employ the orthogonal\nvariance decomposition technique to identify the relevant features in network\ntraffic data. The selected features are used to build a deep neural network for\nintrusion detection. The proposed algorithm achieves 100% detection accuracy in\nidentifying DDoS attacks. The test results indicate a great potential of the\nproposed method.",
    "descriptor": "\nComments: Accepted at ISNCC 2021\n",
    "authors": [
      "Firuz Kamalov",
      "Sherif Moussa",
      "Ziad El Khatib",
      "Adel Ben Mnaouer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12627"
  },
  {
    "id": "arXiv:2110.12628",
    "title": "Recurrent Off-policy Baselines for Memory-based Continuous Control",
    "abstract": "When the environment is partially observable (PO), a deep reinforcement\nlearning (RL) agent must learn a suitable temporal representation of the entire\nhistory in addition to a strategy to control. This problem is not novel, and\nthere have been model-free and model-based algorithms proposed for this\nproblem. However, inspired by recent success in model-free image-based RL, we\nnoticed the absence of a model-free baseline for history-based RL that (1) uses\nfull history and (2) incorporates recent advances in off-policy continuous\ncontrol. Therefore, we implement recurrent versions of DDPG, TD3, and SAC\n(RDPG, RTD3, and RSAC) in this work, evaluate them on short-term and long-term\nPO domains, and investigate key design choices. Our experiments show that RDPG\nand RTD3 can surprisingly fail on some domains and that RSAC is the most\nreliable, reaching near-optimal performance on nearly all domains. However, one\ntask that requires systematic exploration still proved to be difficult, even\nfor RSAC. These results show that model-free RL can learn good temporal\nrepresentation using only reward signals; the primary difficulty seems to be\ncomputational cost and exploration. To facilitate future research, we have made\nour PyTorch implementation publicly available at\nhttps://github.com/zhihanyang2022/off-policy-continuous-control.",
    "descriptor": "",
    "authors": [
      "Zhihan Yang",
      "Hai Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12628"
  },
  {
    "id": "arXiv:2110.12633",
    "title": "Age and Gender Prediction using Deep CNNs and Transfer Learning",
    "abstract": "The last decade or two has witnessed a boom of images. With the increasing\nubiquity of cameras and with the advent of selfies, the number of facial images\navailable in the world has skyrocketed. Consequently, there has been a growing\ninterest in automatic age and gender prediction of a person using facial\nimages. We in this paper focus on this challenging problem. Specifically, this\npaper focuses on age estimation, age classification and gender classification\nfrom still facial images of an individual. We train different models for each\nproblem and we also draw comparisons between building a custom CNN\n(Convolutional Neural Network) architecture and using various CNN architectures\nas feature extractors, namely VGG16 pre-trained on VGGFace, Res-Net50 and\nSE-ResNet50 pre-trained on VGGFace2 dataset and training over those extracted\nfeatures. We also provide baseline performance of various machine learning\nalgorithms on the feature extraction which gave us the best results. It was\nobserved that even simple linear regression trained on such extracted features\noutperformed training CNN, ResNet50 and ResNeXt50 from scratch for age\nestimation.",
    "descriptor": "\nComments: 12 pages, 2 figures, 11 tables\n",
    "authors": [
      "Vikas Sheoran",
      "Shreyansh Joshi",
      "Tanisha R. Bhayani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12633"
  },
  {
    "id": "arXiv:2110.12635",
    "title": "Progressively Select and Reject Pseudo-labelled Samples for Open-Set  Domain Adaptation",
    "abstract": "Domain adaptation solves image classification problems in the target domain\nby taking advantage of the labelled source data and unlabelled target data.\nUsually, the source and target domains share the same set of classes. As a\nspecial case, Open-Set Domain Adaptation (OSDA) assumes there exist additional\nclasses in the target domain but not present in the source domain. To solve\nsuch a domain adaptation problem, our proposed method learns discriminative\ncommon subspaces for the source and target domains using a novel Open-Set\nLocality Preserving Projection (OSLPP) algorithm. The source and target domain\ndata are aligned in the learned common spaces class-wisely. To handle the\nopen-set classification problem, our method progressively selects target\nsamples to be pseudo-labelled as known classes and rejects the outliers if they\nare detected as from unknown classes. The common subspace learning algorithm\nOSLPP simultaneously aligns the labelled source data and pseudo-labelled target\ndata from known classes and pushes the rejected target data away from the known\nclasses. The common subspace learning and the pseudo-labelled sample\nselection/rejection facilitate each other in an iterative learning framework\nand achieves state-of-the-art performance on benchmark datasets Office-31 and\nOffice-Home with the average HOS of 87.4% and 67.0% respectively.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Qian Wang",
      "Fanlin Meng",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12635"
  },
  {
    "id": "arXiv:2110.12638",
    "title": "Deep Learning for UAV-based Object Detection and Tracking: A Survey",
    "abstract": "Owing to effective and flexible data acquisition, unmanned aerial vehicle\n(UAV) has recently become a hotspot across the fields of computer vision (CV)\nand remote sensing (RS). Inspired by recent success of deep learning (DL), many\nadvanced object detection and tracking approaches have been widely applied to\nvarious UAV-related tasks, such as environmental monitoring, precision\nagriculture, traffic management. This paper provides a comprehensive survey on\nthe research progress and prospects of DL-based UAV object detection and\ntracking methods. More specifically, we first outline the challenges,\nstatistics of existing methods, and provide solutions from the perspectives of\nDL-based models in three research topics: object detection from the image,\nobject detection from the video, and object tracking from the video. Open\ndatasets related to UAV-dominated object detection and tracking are exhausted,\nand four benchmark datasets are employed for performance evaluation using some\nstate-of-the-art methods. Finally, prospects and considerations for the future\nwork are discussed and summarized. It is expected that this survey can\nfacilitate those researchers who come from remote sensing field with an\noverview of DL-based UAV object detection and tracking methods, along with some\nthoughts on their further developments.",
    "descriptor": "",
    "authors": [
      "Xin Wu",
      "Wei Li",
      "Danfeng Hong",
      "Ran Tao",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12638"
  },
  {
    "id": "arXiv:2110.12644",
    "title": "Kernel density estimation-based sampling for neural network  classification",
    "abstract": "Imbalanced data occurs in a wide range of scenarios. The skewed distribution\nof the target variable elicits bias in machine learning algorithms. One of the\npopular methods to combat imbalanced data is to artificially balance the data\nthrough resampling. In this paper, we compare the efficacy of a recently\nproposed kernel density estimation (KDE) sampling technique in the context of\nartificial neural networks. We benchmark the KDE sampling method against two\nbase sampling techniques and perform comparative experiments using 8 datasets\nand 3 neural networks architectures. The results show that KDE sampling\nproduces the best performance on 6 out of 8 datasets. However, it must be used\nwith caution on image datasets. We conclude that KDE sampling is capable of\nsignificantly improving the performance of neural networks.",
    "descriptor": "\nComments: Accepted ISNCC\n",
    "authors": [
      "Firuz Kamalov",
      "Ashraf Elnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12644"
  },
  {
    "id": "arXiv:2110.12645",
    "title": "SgSum: Transforming Multi-document Summarization into Sub-graph  Selection",
    "abstract": "Most of existing extractive multi-document summarization (MDS) methods score\neach sentence individually and extract salient sentences one by one to compose\na summary, which have two main drawbacks: (1) neglecting both the intra and\ncross-document relations between sentences; (2) neglecting the coherence and\nconciseness of the whole summary. In this paper, we propose a novel MDS\nframework (SgSum) to formulate the MDS task as a sub-graph selection problem,\nin which source documents are regarded as a relation graph of sentences (e.g.,\nsimilarity graph or discourse graph) and the candidate summaries are its\nsub-graphs. Instead of selecting salient sentences, SgSum selects a salient\nsub-graph from the relation graph as the summary. Comparing with traditional\nmethods, our method has two main advantages: (1) the relations between\nsentences are captured by modeling both the graph structure of the whole\ndocument set and the candidate sub-graphs; (2) directly outputs an integrate\nsummary in the form of sub-graph which is more informative and coherent.\nExtensive experiments on MultiNews and DUC datasets show that our proposed\nmethod brings substantial improvements over several strong baselines. Human\nevaluation results also demonstrate that our model can produce significantly\nmore coherent and informative summaries compared with traditional MDS methods.\nMoreover, the proposed architecture has strong transfer ability from single to\nmulti-document input, which can reduce the resource bottleneck in MDS tasks.\nOur code and results are available at:\n\\url{https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2021-SgSum}.",
    "descriptor": "\nComments: Accepted by EMNLP2021, Main Conference\n",
    "authors": [
      "Moye Chen",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12645"
  },
  {
    "id": "arXiv:2110.12646",
    "title": "Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response  Selection",
    "abstract": "Dialogue disentanglement aims to group utterances in a long and\nmulti-participant dialogue into threads. This is useful for discourse analysis\nand downstream applications such as dialogue response selection, where it can\nbe the first step to construct a clean context/response set. Unfortunately,\nlabeling all~\\emph{reply-to} links takes quadratic effort w.r.t the number of\nutterances: an annotator must check all preceding utterances to identify the\none to which the current utterance is a reply. In this paper, we are the first\nto propose a~\\textbf{zero-shot} dialogue disentanglement solution. Firstly, we\ntrain a model on a multi-participant response selection dataset harvested from\nthe web which is not annotated; we then apply the trained model to perform\nzero-shot dialogue disentanglement. Without any labeled data, our model can\nachieve a cluster F1 score of 25. We also fine-tune the model using various\namounts of labeled data. Experiments show that with only 10\\% of the data, we\nachieve nearly the same performance of using the full dataset\\footnote{Code is\nreleased at\n\\url{https://github.com/chijames/zero_shot_dialogue_disentanglement}}.",
    "descriptor": "\nComments: 6 pages, accepted by EMNLP 2021\n",
    "authors": [
      "Ta-Chung Chi",
      "Alexander I. Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12646"
  },
  {
    "id": "arXiv:2110.12647",
    "title": "Bone Marrow Cell Recognition: Training Deep Object Detection with A New  Loss Function",
    "abstract": "For a long time, bone marrow cell morphology examination has been an\nessential tool for diagnosing blood diseases. However, it is still mainly\ndependent on the subjective diagnosis of experienced doctors, and there is no\nobjective quantitative standard. Therefore, it is crucial to study a robust\nbone marrow cell detection algorithm for a quantitative automatic analysis\nsystem. Currently, due to the dense distribution of cells in the bone marrow\nsmear and the diverse cell classes, the detection of bone marrow cells is\ndifficult. The existing bone marrow cell detection algorithms are still\ninsufficient for the automatic analysis system of bone marrow smears. This\npaper proposes a bone marrow cell detection algorithm based on the YOLOv5\nnetwork, trained by minimizing a novel loss function. The classification method\nof bone marrow cell detection tasks is the basis of the proposed novel loss\nfunction. Since bone marrow cells are classified according to series and\nstages, part of the classes in adjacent stages are similar. The proposed novel\nloss function considers the similarity between bone marrow cell classes,\nincreases the penalty for prediction errors between dissimilar classes, and\nreduces the penalty for prediction errors between similar classes. The results\nshow that the proposed loss function effectively improves the algorithm's\nperformance, and the proposed bone marrow cell detection algorithm has achieved\nbetter performance than other cell detection algorithms.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Dehao Huang",
      "Jintao Cheng",
      "Rui Fan",
      "Zhihao Su",
      "Qiongxiong Ma",
      "Jie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12647"
  },
  {
    "id": "arXiv:2110.12648",
    "title": "DaRE: A Cross-Domain Recommender System with Domain-aware Feature  Extraction and Review Encoder",
    "abstract": "Recent advent in recommender systems, especially text-aided methods and CDR\n(Cross-Domain Recommendation) leads to promising results in solving\ndata-sparsity and cold-start problems. Despite such progress, prior algorithms\neither require user overlapping or ignore domain-aware feature extraction. In\naddition, text-aided methods exceedingly emphasize aggregated documents and\nfail to capture the specifics embedded in individual reviews. To overcome such\nlimitations, we propose a novel method, named DaRE (Domainaware Feature\nExtraction and Review Encoder), a comprehensive solution that consists of three\nkey components; text-based representation learning, domain-aware feature\nextraction, and a review encoder. DaRE debilitate noises by separating\ndomain-invariant features from domain-specific features through selective\nadversarial training. DaRE extracts features from aggregated documents, and the\nreview encoder fine-tunes the representations by aligning them with the\nfeatures extracted from individual reviews. Experiments on four real-world\ndatasets show the superiority of DaRE over state-ofthe-art single-domain and\ncross-domain methodologies, achieving 9.2 % and 3.6 % improvements,\nrespectively. We upload our implementations\n(https://anonymous.4open.science/r/DaRE-9CC9/) for a reproducibility",
    "descriptor": "",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chongkwon Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12648"
  },
  {
    "id": "arXiv:2110.12652",
    "title": "Extractors for Sum of Two Sources",
    "abstract": "We consider the problem of extracting randomness from \\textit{sumset\nsources}, a general class of weak sources introduced by Chattopadhyay and Li\n(STOC, 2016). An $(n,k,C)$-sumset source $\\mathbf{X}$ is a distribution on\n$\\{0,1\\}^n$ of the form $\\mathbf{X}_1 + \\mathbf{X}_2 + \\ldots + \\mathbf{X}_C$,\nwhere $\\mathbf{X}_i$'s are independent sources on $n$ bits with min-entropy at\nleast $k$. Prior extractors either required the number of sources $C$ to be a\nlarge constant or the min-entropy $k$ to be at least $0.51 n$.\nAs our main result, we construct an explicit extractor for sumset sources in\nthe setting of $C=2$ for min-entropy $\\mathrm{poly}(\\log n)$ and polynomially\nsmall error. We can further improve the min-entropy requirement to $(\\log n)\n\\cdot (\\log \\log n)^{1 + o(1)}$ at the expense of worse error parameter of our\nextractor. We find applications of our sumset extractor for extracting\nrandomness from other well-studied models of weak sources such as affine\nsources, small-space sources, and interleaved sources.\nInterestingly, it is unknown if a random function is an extractor for sumset\nsources. We use techniques from additive combinatorics to show that it is a\ndisperser, and further prove that an affine extractor works for an interesting\nsubclass of sumset sources which informally corresponds to the \"low doubling\"\ncase (i.e., the support of $\\mathbf{X_1} + \\mathbf{X_2}$ is not much larger\nthan $2^k$).",
    "descriptor": "",
    "authors": [
      "Eshan Chattopadhyay",
      "Jyun-Jie Liao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12652"
  },
  {
    "id": "arXiv:2110.12654",
    "title": "Facilitating Database Tuning with Hyper-Parameter Optimization: A  Comprehensive Experimental Evaluation",
    "abstract": "Recently, automatic configuration tuning has attracted intensive interests\nfrom the database community to improve the performance of modern database\nmanagement systems (DBMS). As a result, a line of configuration tuning systems\nwith new algorithms and advanced features have been developed. However, the\nexisting evaluations of database tuning systems are conducted system-wide in\nlimited scenarios. It remains unclear to identify the best combination of\nalgorithm designs for database configuration tuning in practice, given the\nlarge body of solutions and the expensive evaluations. In addition, when\njumping out of the database community, we could find even more underlying\nsolutions that are designed for configuration tuning. To this end, this paper\nprovides a comprehensive evaluation of configuration tuning techniques from a\nbroader domain, not limited to database community. In particular, we present a\nunified pipeline of database knob tuning with three key components and evaluate\nthe fine-grained intra-algorithms in various and challenging scenarios. Our\nevaluation has demonstrated that the hype-parameter optimization techniques can\nbe borrowed to facilitate the database configuration tuning and we further\nidentify the best solution ``path'' in different scenarios. We identify design\ntrade-offs to suggest desirable optimizations and directions for future\ndevelopment of database tuning approaches. Beyond the comprehensive\nevaluations, we offer an efficient and unified benchmark via surrogate that\nreduces the evaluation cost to a minimum, allowing for extensive runs and\nanalysis of new optimizers.",
    "descriptor": "",
    "authors": [
      "Xinyi Zhang",
      "Zhuo Chang",
      "Yang Li",
      "Hong Wu",
      "Jian Tan",
      "Feifei Li",
      "Bin Cui"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12654"
  },
  {
    "id": "arXiv:2110.12658",
    "title": "Operator Augmentation for Model-based Policy Evaluation",
    "abstract": "In model-based reinforcement learning, the transition matrix and reward\nvector are often estimated from random samples subject to noise. Even if the\nestimated model is an unbiased estimate of the true underlying model, the value\nfunction computed from the estimated model is biased. We introduce an operator\naugmentation method for reducing the error introduced by the estimated model.\nWhen the error is in the residual norm, we prove that the augmentation factor\nis always positive and upper bounded by $1 + O (1/n)$, where n is the number of\nsamples used in learning each row of the transition matrix. We also propose a\npractical numerical algorithm for implementing the operator augmentation.",
    "descriptor": "",
    "authors": [
      "Xun Tang",
      "Lexing Ying",
      "Yuhua Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12658"
  },
  {
    "id": "arXiv:2110.12661",
    "title": "ZerO Initialization: Initializing Residual Networks with only Zeros and  Ones",
    "abstract": "Deep neural networks are usually initialized with random weights, with\nadequately selected initial variance to ensure stable signal propagation during\ntraining. However, there is no consensus on how to select the variance, and\nthis becomes challenging especially as the number of layers grows. In this\nwork, we replace the widely used random weight initialization with a fully\ndeterministic initialization scheme ZerO, which initializes residual networks\nwith only zeros and ones. By augmenting the standard ResNet architectures with\na few extra skip connections and Hadamard transforms, ZerO allows us to start\nthe training from zeros and ones entirely. This has many benefits such as\nimproving reproducibility (by reducing the variance over different experimental\nruns) and allowing network training without batch normalization. Surprisingly,\nwe find that ZerO achieves state-of-the-art performance over various image\nclassification datasets, including ImageNet, which suggests random weights may\nbe unnecessary for modern network initialization.",
    "descriptor": "",
    "authors": [
      "Jiawei Zhao",
      "Florian Sch\u00e4fer",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12661"
  },
  {
    "id": "arXiv:2110.12662",
    "title": "Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian  Noise",
    "abstract": "Controllers for autonomous systems that operate in safety-critical settings\nmust account for stochastic disturbances. Such disturbances are often modelled\nas process noise, and common assumptions are that the underlying distributions\nare known and/or Gaussian. In practice, however, these assumptions may be\nunrealistic and can lead to poor approximations of the true noise distribution.\nWe present a novel planning method that does not rely on any explicit\nrepresentation of the noise distributions. In particular, we address the\nproblem of computing a controller that provides probabilistic guarantees on\nsafely reaching a target. First, we abstract the continuous system into a\ndiscrete-state model that captures noise by probabilistic transitions between\nstates. As a key contribution, we adapt tools from the scenario approach to\ncompute probably approximately correct (PAC) bounds on these transition\nprobabilities, based on a finite number of samples of the noise. We capture\nthese bounds in the transition probability intervals of a so-called interval\nMarkov decision process (iMDP). This iMDP is robust against uncertainty in the\ntransition probabilities, and the tightness of the probability intervals can be\ncontrolled through the number of samples. We use state-of-the-art verification\ntechniques to provide guarantees on the iMDP, and compute a controller for\nwhich these guarantees carry over to the autonomous system. Realistic\nbenchmarks show the practical applicability of our method, even when the iMDP\nhas millions of states or transitions.",
    "descriptor": "",
    "authors": [
      "Thom S. Badings",
      "Alessandro Abate",
      "Nils Jansen",
      "David Parker",
      "Hasan A. Poonawala",
      "Marielle Stoelinga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12662"
  },
  {
    "id": "arXiv:2110.12663",
    "title": "Industrial Scene Text Detection with Refined Feature-attentive Network",
    "abstract": "Detecting the marking characters of industrial metal parts remains\nchallenging due to low visual contrast, uneven illumination, corroded character\nstructures, and cluttered background of metal part images. Affected by these\nfactors, bounding boxes generated by most existing methods locate low-contrast\ntext areas inaccurately. In this paper, we propose a refined feature-attentive\nnetwork (RFN) to solve the inaccurate localization problem. Specifically, we\ndesign a parallel feature integration mechanism to construct an adaptive\nfeature representation from multi-resolution features, which enhances the\nperception of multi-scale texts at each scale-specific level to generate a\nhigh-quality attention map. Then, an attentive refinement network is developed\nby the attention map to rectify the location deviation of candidate boxes. In\naddition, a re-scoring mechanism is designed to select text boxes with the best\nrectified location. Moreover, we construct two industrial scene text datasets,\nincluding a total of 102156 images and 1948809 text instances with various\ncharacter structures and metal parts. Extensive experiments on our dataset and\nfour public datasets demonstrate that our proposed method achieves the\nstate-of-the-art performance.",
    "descriptor": "\nComments: 11 pages, 9 figures, 7 tables\n",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Changsheng Lu",
      "Jingzheng Tu",
      "Qi Feng",
      "Kaijie Wu",
      "Xinping Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12663"
  },
  {
    "id": "arXiv:2110.12667",
    "title": "Mixture-of-Variational-Experts for Continual Learning",
    "abstract": "One significant shortcoming of machine learning is the poor ability of models\nto solve new problems quicker and without forgetting acquired knowledge. To\nbetter understand this issue, continual learning has emerged to systematically\ninvestigate learning protocols where the model sequentially observes samples\ngenerated by a series of tasks. First, we propose an optimality principle that\nfacilitates a trade-off between learning and forgetting. We derive this\nprinciple from an information-theoretic formulation of bounded rationality and\nshow its connections to other continual learning methods. Second, based on this\nprinciple, we propose a neural network layer for continual learning, called\nMixture-of-Variational-Experts (MoVE), that alleviates forgetting while\nenabling the beneficial transfer of knowledge to new tasks. Our experiments on\nvariants of the MNIST and CIFAR10 datasets demonstrate the competitive\nperformance of MoVE layers when compared to state-of-the-art approaches.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Heinke Hihn",
      "Daniel A. Braun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12667"
  },
  {
    "id": "arXiv:2110.12675",
    "title": "Duals of linearized Reed-Solomon codes",
    "abstract": "We give a description of the duals of linearized Reed-Solomon codes in terms\nof codes obtained by taking residues of Ore rational functions. Our\nconstruction shows in particular that, under some assumptions on the base\nfield, the class of linearized Reed-Solomon codes is stable under duality. As a\nbyproduct of our work, we develop a theory of residues in the Ore setting.",
    "descriptor": "",
    "authors": [
      "Xavier Caruso",
      "Amaury Durand"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2110.12675"
  },
  {
    "id": "arXiv:2110.12678",
    "title": "Nearly Tight Convergence Bounds for Semi-discrete Entropic Optimal  Transport",
    "abstract": "We derive nearly tight and non-asymptotic convergence bounds for solutions of\nentropic semi-discrete optimal transport. These bounds quantify the stability\nof the dual solutions of the regularized problem (sometimes called Sinkhorn\npotentials) w.r.t. the regularization parameter, for which we ensure a better\nthan Lipschitz dependence. Such facts may be a first step towards a\nmathematical justification of annealing or $\\eps$-scaling heuristics for the\nnumerical resolution of regularized semi-discrete optimal transport. Our\nresults also entail a non-asymptotic and tight expansion of the difference\nbetween the entropic and the unregularized costs.",
    "descriptor": "",
    "authors": [
      "Alex Delalande"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.12678"
  },
  {
    "id": "arXiv:2110.12679",
    "title": "Improving Embedded Knowledge Graph Multi-hop Question Answering by  introducing Relational Chain Reasoning",
    "abstract": "Knowledge Base Question Answering (KBQA) aims to answer userquestions from a\nknowledge base (KB) by identifying the reasoningrelations between topic entity\nand answer. As a complex branchtask of KBQA, multi-hop KGQA requires reasoning\nover multi-hop relational chains preserved in KG to arrive at the right\nanswer.Despite the successes made in recent years, the existing works\nonanswering multi-hop complex question face the following challenges: i)\nsuffering from poor performances due to the neglect of explicit relational\nchain order and its relational types reflected inuser questions; ii) failing to\nconsider implicit relations between thetopic entity and the answer implied in\nstructured KG because oflimited neighborhood size constraints in subgraph\nretrieval based algorithms. To address these issues in multi-hop KGQA, we\nproposea novel model in this paper, namely Relational Chain-based Embed-ded\nKGQA (Rce-KGQA), which simultaneously utilizes the explicitrelational chain\ndescribed in natural language questions and the implicit relational chain\nstored in structured KG. Our extensiveempirical study on two open-domain\nbenchmarks proves that ourmethod significantly outperforms the state-of-the-art\ncounterpartslike GraftNet, PullNet and EmbedKGQA. Comprehensive ablation\nexperiments also verify the effectiveness of our method for multi-hop KGQA\ntasks. We have made our model's source code availableat Github:\nhttps://github.com/albert-jin/Rce-KGQA.",
    "descriptor": "\nComments: 10 pages, 5 figures; 36 references; This work was carried out during the first author's master time at Shanghai University. This work is also partially supported by an anonymous Natural Research Foundation. We would like to thank Hang Yu for providing helpful discussions and valuable recommendations\n",
    "authors": [
      "Weiqiang Jin",
      "Hang Yu",
      "Xi Tao",
      "Ruiping Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12679"
  },
  {
    "id": "arXiv:2110.12680",
    "title": "TODSum: Task-Oriented Dialogue Summarization with State Tracking",
    "abstract": "Previous dialogue summarization datasets mainly focus on open-domain chitchat\ndialogues, while summarization datasets for the broadly used task-oriented\ndialogue haven't been explored yet. Automatically summarizing such\ntask-oriented dialogues can help a business collect and review needs to improve\nthe service. Besides, previous datasets pay more attention to generate good\nsummaries with higher ROUGE scores, but they hardly understand the structured\ninformation of dialogues and ignore the factuality of summaries. In this paper,\nwe introduce a large-scale public Task-Oriented Dialogue Summarization dataset,\nTODSum, which aims to summarize the key points of the agent completing certain\ntasks with the user. Compared to existing work, TODSum suffers from severe\nscattered information issues and requires strict factual consistency, which\nmakes it hard to directly apply recent dialogue summarization models.\nTherefore, we introduce additional dialogue state knowledge for TODSum to\nenhance the faithfulness of generated summaries. We hope a better understanding\nof conversational content helps summarization models generate concise and\ncoherent summaries. Meanwhile, we establish a comprehensive benchmark for\nTODSum and propose a state-aware structured dialogue summarization model to\nintegrate dialogue state information and dialogue history. Exhaustive\nexperiments and qualitative analysis prove the effectiveness of dialogue\nstructure guidance. Finally, we discuss the current issues of TODSum and\npotential development directions for future work.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Lulu Zhao",
      "Fujia Zheng",
      "Keqing He",
      "Weihao Zeng",
      "Yuejie Lei",
      "Huixing Jiang",
      "Wei Wu",
      "Weiran Xu",
      "Jun Guo",
      "Fanyu Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12680"
  },
  {
    "id": "arXiv:2110.12681",
    "title": "Content Filtering Enriched GNN Framework for News Recommendation",
    "abstract": "Learning accurate users and news representations is critical for news\nrecommendation. Despite great progress, existing methods seem to have a strong\nbias towards content representation or just capture collaborative filtering\nrelationship. However, these approaches may suffer from the data sparsity\nproblem (user-news interactive behavior sparsity problem) or maybe affected\nmore by news (or user) with high popularity. In this paper, to address such\nlimitations, we propose content filtering enriched GNN framework for news\nrecommendation, ConFRec in short. It is compatible with existing GNN-based\napproaches for news recommendation and can capture both collaborative and\ncontent filtering information simultaneously. Comprehensive experiments are\nconducted to demonstrate the effectiveness of ConFRec over the state-of-the-art\nbaseline models for news recommendation on real-world datasets for news\nrecommendation.",
    "descriptor": "",
    "authors": [
      "Yong Gao",
      "Huifeng Guo",
      "Dandan Lin",
      "Yingxue Zhang",
      "Ruiming Tang",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12681"
  },
  {
    "id": "arXiv:2110.12683",
    "title": "Information-Theoretic Limits of Integrated Sensing and Communication  with Correlated Sensing and Channel States",
    "abstract": "Integrated sensing and communication (ISAC) emerges as a new design paradigm\nthat combines both sensing and communication systems to jointly utilize their\nresources and to pursue mutual benefits for future B5G and 6G networks. In\nISAC, the hardware and spectrum co-sharing leads to a fundamental tradeoff\nbetween sensing and communication performance, which is not well understood\nexcept for very simple cases with the same sensing and channel states, and\nperfect channel state information at the receiver (CSIR). In this paper, a more\ngeneral point-to-point ISAC model is proposed to account for the scenarios that\nthe sensing state is different from but correlated with the channel state, and\nthe CSIR is not necessarily perfect. For the model considered, the optimal\ntradeoff is characterized by a capacity-distortion function that quantifies the\nbest communication rate for a given sensing distortion constraint requirement.\nAn iterative algorithm is proposed to compute such tradeoff, and a few\nnon-trivial examples are constructed to demonstrate the benefits of ISAC as\ncompared to the separation-based approach.",
    "descriptor": "",
    "authors": [
      "Yao Liu",
      "Min Li",
      "An Liu",
      "Jianmin Lu",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12683"
  },
  {
    "id": "arXiv:2110.12684",
    "title": "Automatic Extraction of Road Networks from Satellite Images by using  Adaptive Structural Deep Belief Network",
    "abstract": "In our research, an adaptive structural learning method of Restricted\nBoltzmann Machine (RBM) and Deep Belief Network (DBN) has been developed as one\nof prominent deep learning models. The neuron generation-annihilation in RBM\nand layer generation algorithms in DBN make an optimal network structure for\ngiven input during the learning. In this paper, our model is applied to an\nautomatic recognition method of road network system, called RoadTracer.\nRoadTracer can generate a road map on the ground surface from aerial photograph\ndata. In the iterative search algorithm, a CNN is trained to find network graph\nconnectivities between roads with high detection capability. However, the\nsystem takes a long calculation time for not only the training phase but also\nthe inference phase, then it may not realize high accuracy. In order to improve\nthe accuracy and the calculation time, our Adaptive DBN was implemented on the\nRoadTracer instead of the CNN. The performance of our developed model was\nevaluated on a satellite image in the suburban area, Japan. Our Adaptive DBN\nhad an advantage of not only the detection accuracy but also the inference time\ncompared with the conventional CNN in the experiment results.",
    "descriptor": "\nComments: 7 pages, 9 figures, 2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)\n",
    "authors": [
      "Shin Kamada",
      "Takumi Ichimura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.12684"
  },
  {
    "id": "arXiv:2110.12685",
    "title": "Transient Synchronization Stability Analysis of Wind Farms with MMC-HVDC  Integration Under Offshore AC Grid Fault",
    "abstract": "The MMC-HVDC connected offshore wind farms (OWFs) could suffer short circuit\nfault (SCF), whereas their transient stability is not well analysed. In this\npaper, the mechanism of the loss of synchronization (LOS) of this system is\nanalysed considering the whole system state from the fault-on to the\npost-fault, and the discussion on fault type and fault clearance is addressed\nas well. A stability index is proposed to quantify the transient\nsynchronization stability (TSS) of the system, which is capable to not only\nestimate whether the wind turbine generators (WTGs) be able to get\nresynchronized with the offshore MMC after the fault is cleared, but also to\nevaluate the performance of stability improving methods as well. Finally, a\nscenario of six cases is tested on the PSCAD/EMTDC simulation platform, where\nthe performances of four existing stability improving methods are thoroughly\ncompared via both numerical simulation and the proposed stability index.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Chen Zhang",
      "Renxin Yang",
      "Jing Lyu",
      "Li Liu",
      "Xu Cai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12685"
  },
  {
    "id": "arXiv:2110.12687",
    "title": "Fine-tuning of Pre-trained Transformers for Hate, Offensive, and Profane  Content Detection in English and Marathi",
    "abstract": "This paper describes neural models developed for the Hate Speech and\nOffensive Content Identification in English and Indo-Aryan Languages Shared\nTask 2021. Our team called neuro-utmn-thales participated in two tasks on\nbinary and fine-grained classification of English tweets that contain hate,\noffensive, and profane content (English Subtasks A & B) and one task on\nidentification of problematic content in Marathi (Marathi Subtask A). For\nEnglish subtasks, we investigate the impact of additional corpora for hate\nspeech detection to fine-tune transformer models. We also apply a one-vs-rest\napproach based on Twitter-RoBERTa to discrimination between hate, profane and\noffensive posts. Our models ranked third in English Subtask A with the F1-score\nof 81.99% and ranked second in English Subtask B with the F1-score of 65.77%.\nFor the Marathi tasks, we propose a system based on the Language-Agnostic BERT\nSentence Embedding (LaBSE). This model achieved the second result in Marathi\nSubtask A obtaining an F1 of 88.08%.",
    "descriptor": "\nComments: Accepted for FIRE'21: Forum for Information Retrieval Evaluation 2021\n",
    "authors": [
      "Anna Glazkova",
      "Michael Kadantsev",
      "Maksim Glazkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12687"
  },
  {
    "id": "arXiv:2110.12690",
    "title": "Scalable Lipschitz Residual Networks with Convex Potential Flows",
    "abstract": "The Lipschitz constant of neural networks has been established as a key\nproperty to enforce the robustness of neural networks to adversarial examples.\nHowever, recent attempts to build $1$-Lipschitz Neural Networks have all shown\nlimitations and robustness have to be traded for accuracy and scalability or\nvice versa. In this work, we first show that using convex potentials in a\nresidual network gradient flow provides a built-in $1$-Lipschitz\ntransformation. From this insight, we leverage the work on Input Convex Neural\nNetworks to parametrize efficient layers with this property. A comprehensive\nset of experiments on CIFAR-10 demonstrates the scalability of our architecture\nand the benefit of our approach for $\\ell_2$ provable defenses. Indeed, we\ntrain very deep and wide neural networks (up to $1000$ layers) and reach\nstate-of-the-art results in terms of standard and certified accuracy, along\nwith empirical robustness, in comparison with other $1$-Lipschitz\narchitectures.",
    "descriptor": "",
    "authors": [
      "Laurent Meunier",
      "Blaise Delattre",
      "Alexandre Araujo",
      "Alexandre Allauzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12690"
  },
  {
    "id": "arXiv:2110.12696",
    "title": "Self-Supervised Knowledge Transfer via Loosely Supervised Auxiliary  Tasks",
    "abstract": "Knowledge transfer using convolutional neural networks (CNNs) can help\nefficiently train a CNN with fewer parameters or maximize the generalization\nperformance under limited supervision. To enable a more efficient transfer of\npretrained knowledge under relaxed conditions, we propose a simple yet powerful\nknowledge transfer methodology without any restrictions regarding the network\nstructure or dataset used, namely self-supervised knowledge transfer (SSKT),\nvia loosely supervised auxiliary tasks. For this, we devise a training\nmethodology that transfers previously learned knowledge to the current training\nprocess as an auxiliary task for the target task through self-supervision using\na soft label. The SSKT is independent of the network structure and dataset, and\nis trained differently from existing knowledge transfer methods; hence, it has\nan advantage in that the prior knowledge acquired from various tasks can be\nnaturally transferred during the training process to the target task.\nFurthermore, it can improve the generalization performance on most datasets\nthrough the proposed knowledge transfer between different problem domains from\nmultiple source networks. SSKT outperforms the other transfer learning methods\n(KD, DML, and MAXL) through experiments under various knowledge transfer\nsettings. The source code will be made available to the public.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Seungbum Hong",
      "Jihun Yoon",
      "Junmo Kim",
      "Min-Kook Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12696"
  },
  {
    "id": "arXiv:2110.12697",
    "title": "Causal Consistent Replication in Reversible Concurrent Calculi",
    "abstract": "Reversible computation is key in developing new, energy-efficient paradigms,\nbut also in providing forward-only concepts with broader definitions and finer\nframes of study.Among other fields, the algebraic specification and\nrepresentation of networks of agents have been greatly impacted by the study of\nreversible phenomena: reversible declensions of the calculus of communicating\nsystems (CCSK and RCCS) offer new semantic models, finer congruence relations,\noriginal properties, and revisits existing theories and results in a finer\nlight.However, much remains to be done: concurrency, a central notion in\nestablishing causal consistency--a crucial property for reversibly systems--,\nwas never given a clear and syntactical definition in CCSK.While recursion was\nmentioned as a possible mechanism to inject infinite behaviors into the\nsystems, replication was never studied.This work offers a solution to both\nproblems, by leveraging a definition of concurrency developed for forward-only\ncalculi using proved transition systems, by endowing CCSK with a replication\noperator, and by studying the interplay of both notions.The system we obtain is\nthe first reversible system capable of representing infinite behaviors that\nenjoys causal consistency, for our simple and purely syntactical notion of\nreversible concurrency.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Aubert"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.12697"
  },
  {
    "id": "arXiv:2110.12699",
    "title": "Temporal Team Semantics Revisited",
    "abstract": "In this paper, we study a novel approach to asynchronous hyperproperties by\nreconsidering the foundations of temporal team semantics. We consider three\nlogics: TeamLTL, TeamCTL and TeamCTL*, which are obtained by adding\nquantification over so-called time evaluation functions controlling the\nasynchronous progress of traces. We then relate synchronous TeamLTL to our new\nlogics and show how it can be embedded into them. We show that the model\nchecking problem for exTeamCTL with Boolean disjunctions is highly undecidable\nby encoding recurrent computations of non-deterministic 2-counter machines.\nFinally, we present a translation of TeamCTL* to Alternating Asynchronous\nB\\\"uchi Automata and obtain decidability results for the path checking problem\nas well as restricted variants of the model checking and satisfiability\nproblems.",
    "descriptor": "",
    "authors": [
      "Jens Oliver Gutsfeld",
      "Arne Meier",
      "Christoph Ohrem",
      "Jonni Virtema"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12699"
  },
  {
    "id": "arXiv:2110.12700",
    "title": "An Adaptive Structural Learning of Deep Belief Network for Image-based  Crack Detection in Concrete Structures Using SDNET2018",
    "abstract": "We have developed an adaptive structural Deep Belief Network (Adaptive DBN)\nthat finds an optimal network structure in a self-organizing manner during\nlearning. The Adaptive DBN is the hierarchical architecture where each layer\nemploys Adaptive Restricted Boltzmann Machine (Adaptive RBM). The Adaptive RBM\ncan find the appropriate number of hidden neurons during learning. The proposed\nmethod was applied to a concrete image benchmark data set SDNET2018 for crack\ndetection. The dataset contains about 56,000 crack images for three types of\nconcrete structures: bridge decks, walls, and paved roads. The fine-tuning\nmethod of the Adaptive DBN can show 99.7%, 99.7%, and 99.4% classification\naccuracy for three types of structures. However, we found the database included\nsome wrong annotated data which cannot be judged from images by human experts.\nThis paper discusses consideration that purses the major factor for the wrong\ncases and the removal of the adversarial examples from the dataset.",
    "descriptor": "\nComments: 6 pages, 10 figures, 2020 International Conference on Image Processing and Robotics (ICIP)\n",
    "authors": [
      "Shin Kamada",
      "Takumi Ichimura",
      "Takashi Iwasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.12700"
  },
  {
    "id": "arXiv:2110.12706",
    "title": "A Nearly Optimal Chattering Reduction Method of Sliding Mode Control  With an Application to a Two-wheeled Mobile Robot",
    "abstract": "The problem we focus on in this paper is to find a nearly optimal sliding\nmode controller of continuous-time nonlinear multiple-input multiple-output\n(MIMO) systems that can both reduce chattering and minimize the cost function,\nwhich is a measure of the performance index of dynamics systems. First, the\ndeficiency of chattering in traditional SMC and the quasi-SMC method are\nanalyzed in this paper. In quasi-SMC, the signum function of the traditional\nSMC is replaced with a continuous saturation function. Then, a chattering\nreduction algorithm based on integral reinforcement learning (IRL) is proposed.\nUnder an initial sliding mode controller, the proposed method can learn the\nnearly optimal saturation function using policy iteration. To satisfy the\nrequirement of the learned saturation function, we treat the problem of\ntraining the saturation function as the constraint of an optimization problem.\nThe online neural network implementation of the proposed algorithm is presented\nbased on symmetric radius basis functions and a regularized batch least-squares\n(BLS) algorithm to train the control law in this paper. Finally, two examples\nare simulated to verify the effectiveness of the proposed method. The second\nexample is an application to a real-world dynamics model -- a two-wheeled\nvariable structure robot.",
    "descriptor": "",
    "authors": [
      "Lei Guo",
      "Han Zhao",
      "Yuan Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12706"
  },
  {
    "id": "arXiv:2110.12710",
    "title": "On the chromatic number of a family of odd hole free graphs",
    "abstract": "A hole is an induced cycle of length at least 4, and an odd hole is a hole of\nodd length. A full house is a graph composed by a vertex adjacent to both ends\nof an edge in $K_4$ . Let $H$ be the complement of a cycle on 7 vertices.\nChudnovsky et al [6] proved that every (odd hole, $K_4$)-free graph is\n4-colorable and is 3-colorable if it does not has $H$ as an induced subgraph.\nIn this paper, we use the proving technique of Chudnovsky et al to generalize\nthis conclusion to (odd hole, full house)-free graphs, and prove that for (odd\nhole, full house)-free graph $G$, $\\chi(G)\\le \\omega(G)+1$, and the equality\nholds if and only if $\\omega(G)=3$ and $G$ has $H$ as an induced subgraph.",
    "descriptor": "",
    "authors": [
      "Jialei Song",
      "Baogang Xu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.12710"
  },
  {
    "id": "arXiv:2110.12711",
    "title": "Packing 2D disks into a 3D container",
    "abstract": "In this article, we consider the problem of finding in three dimensions a\nminimum-volume axis-parallel box into which a given set of unit-radius disks\ncan be packed under translations. The problem is neither known to be NP-hard\nnor to be in NP. We give a constant-factor approximation algorithm based on\nreduction to finding a shortest Hamiltonian path in a weighted graph. As a\nbyproduct, we can show that there is no finite size container into which all\nunit disks can be packed simultaneously.",
    "descriptor": "",
    "authors": [
      "Helmut Alt",
      "Otfried Cheong",
      "Ji-won Park",
      "Nadja Seiferth"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2110.12711"
  },
  {
    "id": "arXiv:2110.12715",
    "title": "SRT3D: A Sparse Region-Based 3D Object Tracking Approach for the Real  World",
    "abstract": "Region-based methods have become increasingly popular for model-based,\nmonocular 3D tracking of texture-less objects in cluttered scenes. However,\nwhile they achieve state-of-the-art results, most methods are computationally\nexpensive, requiring significant resources to run in real-time. In the\nfollowing, we build on our previous work and develop SRT3D, a sparse\nregion-based approach to 3D object tracking that bridges this gap in\nefficiency. Our method considers image information sparsely along so-called\ncorrespondence lines that model the probability of the object's contour\nlocation. We thereby improve on the current state of the art and introduce\nsmoothed step functions that consider a defined global and local uncertainty.\nFor the resulting probabilistic formulation, a thorough analysis is provided.\nFinally, we use a pre-rendered sparse viewpoint model to create a joint\nposterior probability for the object pose. The function is maximized using\nsecond-order Newton optimization with Tikhonov regularization. During the pose\nestimation, we differentiate between global and local optimization, using a\nnovel approximation for the first-order derivative employed in the Newton\nmethod. In multiple experiments, we demonstrate that the resulting algorithm\nimproves the current state of the art both in terms of runtime and quality,\nperforming particularly well for noisy and cluttered images encountered in the\nreal world.",
    "descriptor": "\nComments: Submitted to the International Journal of Computer Vision\n",
    "authors": [
      "Manuel Stoiber",
      "Martin Pfanne",
      "Klaus H. Strobl",
      "Rudolph Triebel",
      "Alin Albu-Sch\u00e4ffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12715"
  },
  {
    "id": "arXiv:2110.12717",
    "title": "A Distillation Learning Model of Adaptive Structural Deep Belief Network  for AffectNet: Facial Expression Image Database",
    "abstract": "Deep Learning has a hierarchical network architecture to represent the\ncomplicated feature of input patterns. We have developed the adaptive structure\nlearning method of Deep Belief Network (DBN) that can discover an optimal\nnumber of hidden neurons for given input data in a Restricted Boltzmann Machine\n(RBM) by neuron generation-annihilation algorithm, and can obtain the\nappropriate number of hidden layers in DBN. In this paper, our model is applied\nto a facial expression image data set, AffectNet. The system has higher\nclassification capability than the traditional CNN. However, our model was not\nable to classify some test cases correctly because human emotions contain many\nambiguous features or patterns leading wrong answer by two or more annotators\nwho have different subjective judgment for a facial image. In order to\nrepresent such cases, this paper investigated a distillation learning model of\nAdaptive DBN. The original trained model can be seen as a parent model and some\nchild models are trained for some mis-classified cases. For the difference\nbetween the parent model and the child one, KL divergence is monitored and then\nsome appropriate new neurons at the parent model are generated according to KL\ndivergence to improve classification accuracy. In this paper, the\nclassification accuracy was improved from 78.4% to 91.3% by the proposed\nmethod.",
    "descriptor": "\nComments: 6 pages, 8 figures, 020 9th International Congress on Advanced Applied Informatics (IIAI-AAI)\n",
    "authors": [
      "Takumi Ichimura",
      "Shin Kamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.12717"
  },
  {
    "id": "arXiv:2110.12724",
    "title": "Instance-Conditional Knowledge Distillation for Object Detection",
    "abstract": "Despite the success of Knowledge Distillation (KD) on image classification,\nit is still challenging to apply KD on object detection due to the difficulty\nin locating knowledge. In this paper, we propose an instance-conditional\ndistillation framework to find desired knowledge. To locate knowledge of each\ninstance, we use observed instances as condition information and formulate the\nretrieval process as an instance-conditional decoding process. Specifically,\ninformation of each instance that specifies a condition is encoded as query,\nand teacher's information is presented as key, we use the attention between\nquery and key to measure the correlation, formulated by the transformer\ndecoder. To guide this module, we further introduce an auxiliary task that\ndirects to instance localization and identification, which are fundamental for\ndetection. Extensive experiments demonstrate the efficacy of our method: we\nobserve impressive improvements under various settings. Notably, we boost\nRetinaNet with ResNet-50 backbone from 37.4 to 40.7 mAP (+3.3) under 1x\nschedule, that even surpasses the teacher (40.4 mAP) with ResNet-101 backbone\nunder 3x schedule. Code will be released soon.",
    "descriptor": "\nComments: To appear in NeurIPS 2021, accepted as poster presentation\n",
    "authors": [
      "Zijian Kang",
      "Peizhen Zhang",
      "Xiangyu Zhang",
      "Jian Sun",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12724"
  },
  {
    "id": "arXiv:2110.12725",
    "title": "Componentwise perturbation analysis for the generalized  Schurdecomposition",
    "abstract": "By defining two important terms called basic perturbation vectors and\nobtaining their linear bounds, we obtain the linear componentwise perturbation\nbounds for unitary factors and upper triangular factors of the generalized\nschur decomposition. The perturbation bounds for the diagonal elements of the\nupper triangular factors and the generalized invariant subspace are also\nderived. From the former, we present an upper bound and a condition number of\nthe generalized eigenvalue. Furthermore, with numerical iterative method, the\nnonlinear componentwise perturbation bounds of the generalized Schur\ndecomposition are also provided. Numerical examples are given to test the\nobtained bounds. Among them, we compare our upper bound and condition number of\nthe generalized eigenvalue with their counterparts given in the literature.\nNumerical results show that they are very close to each other but our results\ndon't need to calculate the left and right eigenvectors.",
    "descriptor": "",
    "authors": [
      "Guihua Zhang",
      "Hanyu Li",
      "Yimin Wei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12725"
  },
  {
    "id": "arXiv:2110.12727",
    "title": "Learning Stochastic Shortest Path with Linear Function Approximation",
    "abstract": "We study the stochastic shortest path (SSP) problem in reinforcement learning\nwith linear function approximation, where the transition kernel is represented\nas a linear mixture of unknown models. We call this class of SSP problems the\nlinear mixture SSP. We propose a novel algorithm for learning the linear\nmixture SSP, which can attain a $\\tilde O(d B_{\\star}^{1.5}\\sqrt{K/c_{\\min}})$\nregret. Here $K$ is the number of episodes, $d$ is the dimension of the feature\nmapping in the mixture model, $B_{\\star}$ bounds the expected cumulative cost\nof the optimal policy, and $c_{\\min}>0$ is the lower bound of the cost\nfunction. Our algorithm also applies to the case when $c_{\\min} = 0$, where a\n$\\tilde O(K^{2/3})$ regret is guaranteed. To the best of our knowledge, this is\nthe first algorithm with a sublinear regret guarantee for learning linear\nmixture SSP. In complement to the regret upper bounds, we also prove a lower\nbound of $\\Omega(d B_{\\star} \\sqrt{K})$, which nearly matches our upper bound.",
    "descriptor": "\nComments: 34 pages, 1 figure\n",
    "authors": [
      "Yifei Min",
      "Jiafan He",
      "Tianhao Wang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12727"
  },
  {
    "id": "arXiv:2110.12734",
    "title": "Fast Gradient Non-sign Methods",
    "abstract": "Adversarial attacks make their success in \\enquote{fooling} DNNs and among\nthem, gradient-based algorithms become one of the mainstreams. Based on the\nlinearity hypothesis~\\cite{fgsm}, under $\\ell_\\infty$ constraint, $sign$\noperation applied to the gradients is a good choice for generating\nperturbations. However, the side-effect from such operation exists since it\nleads to the bias of direction between the real gradients and the\nperturbations. In other words, current methods contain a gap between real\ngradients and actual noises, which leads to biased and inefficient attacks.\nTherefore in this paper, based on the Taylor expansion, the bias is analyzed\ntheoretically and the correction of $\\sign$, \\ie, Fast Gradient Non-sign Method\n(FGNM), is further proposed. Notably, FGNM is a general routine, which can\nseamlessly replace the conventional $sign$ operation in gradient-based attacks\nwith negligible extra computational cost. Extensive experiments demonstrate the\neffectiveness of our methods. Specifically, ours outperform them by\n\\textbf{27.5\\%} at most and \\textbf{9.5\\%} on average. Our anonymous code is\npublicly available: \\url{https://git.io/mm-fgnm}.",
    "descriptor": "",
    "authors": [
      "Yaya Cheng",
      "Xiaosu Zhu",
      "Qilong Zhang",
      "Lianli Gao",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12734"
  },
  {
    "id": "arXiv:2110.12737",
    "title": "Towards Organic 6G Networks: Virtualization and Live Migration of Core  Network Functions",
    "abstract": "In the context of Industry 4.0, more and more mobile use cases are appearing\non industrial factory floors. These use cases place high demands on various\nquantitative requirements, such as latency, availability, and more. In\naddition, qualitative requirements such as flexibility are arising. Since\nvirtualization technology is a key enabler for the flexibility that is required\nby novel use cases and on the way to organic networking as it is addressed by\n6G, we investigate container virtualization technology in this paper. We focus\non container technology since OS-level virtualization has multiple benefits\ncompared to hardware virtualization, such as VMs.\nThus, we discuss several aspects of container based virtualization, e.g.\nselection of suitable network drivers and orchestration tools, with respect to\nmost important 5GC functions. In addition, the functions have different\nquantitative or qualitative requirements depending on whether they are\nstateless or stateful, and whether the specific function is located at either\nthe control or user plane. Therefore, we also analyze the aforementioned live\nmigration concepts for the 5GC functions and evaluate them based on\nwell-defined metrics, such as migration time and process downtime.",
    "descriptor": "",
    "authors": [
      "Michael Gundall",
      "Julius Stegmann",
      "Christopher Huber",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.12737"
  },
  {
    "id": "arXiv:2110.12741",
    "title": "LAE : Long-tailed Age Estimation",
    "abstract": "Facial age estimation is an important yet very challenging problem in\ncomputer vision. To improve the performance of facial age estimation, we first\nformulate a simple standard baseline and build a much strong one by collecting\nthe tricks in pre-training, data augmentation, model architecture, and so on.\nCompared with the standard baseline, the proposed one significantly decreases\nthe estimation errors. Moreover, long-tailed recognition has been an important\ntopic in facial age datasets, where the samples often lack on the elderly and\nchildren. To train a balanced age estimator, we propose a two-stage training\nmethod named Long-tailed Age Estimation (LAE), which decouples the learning\nprocedure into representation learning and classification. The effectiveness of\nour approach has been demonstrated on the dataset provided by organizers of\nGuess The Age Contest 2021.",
    "descriptor": "\nComments: The 1st Place in Guess The Age Contest, CAIP2021 (The 19th International Conference on Computer Analysis of Images and Patterns)\n",
    "authors": [
      "Zenghao Bao",
      "Zichang Tan",
      "Yu Zhu",
      "Jun Wan",
      "Xibo Ma",
      "Zhen Lei",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12741"
  },
  {
    "id": "arXiv:2110.12743",
    "title": "Collapsing the Tower -- On the Complexity of Multistage Stochastic IPs",
    "abstract": "In this paper we study the computational complexity of solving a class of\nblock structured integer programs (IPs) - so called multistage stochastic IPs.\nA multistage stochastic IP is an IP of the form $\\max \\{ c^T x \\mid \\mathcal{A}\nx = b, \\,l \\leq x \\leq u,\\, x\\text{ integral} \\}$ where the constraint matrix\n$\\mathcal{A}$ consists of small block matrices ordered on the diagonal line and\nfor each stage there are larger blocks with few columns connecting the blocks\nin a tree like fashion. Over the last years there was enormous progress in the\narea of block structured IPs. For many of the known block IP classes - such as\n$n$-fold, tree-fold, and two-stage stochastic IPs, nearly matching upper and\nlower bounds are known concerning their computational complexity. One of the\nmajor gaps that remained however was the parameter dependency in the running\ntime for an algorithm solving multistage stochastic IPs. Previous algorithms\nrequire a tower of $t$ exponentials, where $t$ is the number of stages, while\nonly a double exponential lower bound was known. In this paper we show that the\ntower of $t$ exponentials is actually not necessary. We can show an improved\nrunning time for the algorithm solving multistage stochastic IPs with a running\ntime of $2^{(d\\||A||_\\infty)^{\\mathcal{O}(d^{3t+1})}} \\cdot poly(d,n)$, where\n$d$ is the sum of columns in the connecting blocks and $n$ is the number of\nblocks on the lowest stage. In contrast to previous works, our algorithm has\nonly a triple exponential dependency on the parameters and only doubly\nexponential for every constant $t$. By this we come very close the known double\nexponential bound (based on the exponential time hypothesis) that holds already\nfor two-stage stochastic IPs, i.e. multistage stochastic IPs with only two\nstages.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Kim-Manuel Klein",
      "Janina Reuter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.12743"
  },
  {
    "id": "arXiv:2110.12746",
    "title": "Lexicographic Optimisation of Conditional Value at Risk and Expected  Value for Risk-Averse Planning in MDPs",
    "abstract": "Planning in Markov decision processes (MDPs) typically optimises the expected\ncost. However, optimising the expectation does not consider the risk that for\nany given run of the MDP, the total cost received may be unacceptably high. An\nalternative approach is to find a policy which optimises a risk-averse\nobjective such as conditional value at risk (CVaR). In this work, we begin by\nshowing that there can be multiple policies which obtain the optimal CVaR. We\nformulate the lexicographic optimisation problem of minimising the expected\ncost subject to the constraint that the CVaR of the total cost is optimal. We\npresent an algorithm for this problem and evaluate our approach on three\ndomains, including a road navigation domain based on real traffic data. Our\nexperimental results demonstrate that our lexicographic approach attains\nimproved expected cost while maintaining the optimal CVaR.",
    "descriptor": "",
    "authors": [
      "Marc Rigter",
      "Paul Duckworth",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12746"
  },
  {
    "id": "arXiv:2110.12748",
    "title": "Highly Efficient Natural Image Matting",
    "abstract": "Over the last few years, deep learning based approaches have achieved\noutstanding improvements in natural image matting. However, there are still two\ndrawbacks that impede the widespread application of image matting: the reliance\non user-provided trimaps and the heavy model sizes. In this paper, we propose a\ntrimap-free natural image matting method with a lightweight model. With a\nlightweight basic convolution block, we build a two-stages framework:\nSegmentation Network (SN) is designed to capture sufficient semantics and\nclassify the pixels into unknown, foreground and background regions; Matting\nRefine Network (MRN) aims at capturing detailed texture information and\nregressing accurate alpha values. With the proposed cross-level fusion Module\n(CFM), SN can efficiently utilize multi-scale features with less computational\ncost. Efficient non-local attention module (ENA) in MRN can efficiently model\nthe relevance between different pixels and help regress high-quality alpha\nvalues. Utilizing these techniques, we construct an extremely light-weighted\nmodel, which achieves comparable performance with ~1\\% parameters (344k) of\nlarge models on popular natural image matting benchmarks.",
    "descriptor": "\nComments: Full version of BMVC2021\n",
    "authors": [
      "Yijie Zhong",
      "Bo Li",
      "Lv Tang",
      "Hao Tang",
      "Shouhong Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12748"
  },
  {
    "id": "arXiv:2110.12752",
    "title": "Adaptive Gaussian Processes on Graphs via Spectral Graph Wavelets",
    "abstract": "Graph-based models require aggregating information in the graph from\nneighbourhoods of different sizes. In particular, when the data exhibit varying\nlevels of smoothness on the graph, a multi-scale approach is required to\ncapture the relevant information. In this work, we propose a Gaussian process\nmodel using spectral graph wavelets, which can naturally aggregate\nneighbourhood information at different scales. Through maximum likelihood\noptimisation of the model hyperparameters, the wavelets automatically adapt to\nthe different frequencies in the data, and as a result our model goes beyond\ncapturing low frequency information. We achieve scalability to larger graphs by\nusing a spectrum-adaptive polynomial approximation of the filter function,\nwhich is designed to yield a low approximation error in dense areas of the\ngraph spectrum. Synthetic and real-world experiments demonstrate the ability of\nour model to infer scales accurately and produce competitive performances\nagainst state-of-the-art models in graph-based learning tasks.",
    "descriptor": "",
    "authors": [
      "Felix L. Opolka",
      "Yin-Cong Zhi",
      "Pietro Li\u00f2",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12752"
  },
  {
    "id": "arXiv:2110.12763",
    "title": "SSMF: Shifting Seasonal Matrix Factorization",
    "abstract": "Given taxi-ride counts information between departure and destination\nlocations, how can we forecast their future demands? In general, given a data\nstream of events with seasonal patterns that innovate over time, how can we\neffectively and efficiently forecast future events? In this paper, we propose\nShifting Seasonal Matrix Factorization approach, namely SSMF, that can\nadaptively learn multiple seasonal patterns (called regimes), as well as\nswitching between them. Our proposed method has the following properties: (a)\nit accurately forecasts future events by detecting regime shifts in seasonal\npatterns as the data stream evolves; (b) it works in an online setting, i.e.,\nprocesses each observation in constant time and memory; (c) it effectively\nrealizes regime shifts without human intervention by using a lossless data\ncompression scheme. We demonstrate that our algorithm outperforms\nstate-of-the-art baseline methods by accurately forecasting upcoming events on\nthree real-world data streams.",
    "descriptor": "\nComments: NeurIPS, 2021\n",
    "authors": [
      "Koki Kawabata",
      "Siddharth Bhatia",
      "Rui Liu",
      "Mohit Wadhwa",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12763"
  },
  {
    "id": "arXiv:2110.12764",
    "title": "Contrastive Learning for Neural Topic Model",
    "abstract": "Recent empirical studies show that adversarial topic models (ATM) can\nsuccessfully capture semantic patterns of the document by differentiating a\ndocument with another dissimilar sample. However, utilizing that\ndiscriminative-generative architecture has two important drawbacks: (1) the\narchitecture does not relate similar documents, which has the same\ndocument-word distribution of salient words; (2) it restricts the ability to\nintegrate external information, such as sentiments of the document, which has\nbeen shown to benefit the training of neural topic model. To address those\nissues, we revisit the adversarial topic architecture in the viewpoint of\nmathematical analysis, propose a novel approach to re-formulate discriminative\ngoal as an optimization problem, and design a novel sampling method which\nfacilitates the integration of external variables. The reformulation encourages\nthe model to incorporate the relations among similar samples and enforces the\nconstraint on the similarity among dissimilar ones; while the sampling method,\nwhich is based on the internal input and reconstructed output, helps inform the\nmodel of salient words contributing to the main topic. Experimental results\nshow that our framework outperforms other state-of-the-art neural topic models\nin three common benchmark datasets that belong to various domains, vocabulary\nsizes, and document lengths in terms of topic coherence.",
    "descriptor": "\nComments: 15 pages, 8 tables, 5 figures, published at Advances in Neural Information Processing Systems (NeurIPS), 2021\n",
    "authors": [
      "Thong Nguyen",
      "Anh Tuan Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12764"
  },
  {
    "id": "arXiv:2110.12765",
    "title": "\"So You Think You're Funny?\": Rating the Humour Quotient in Standup  Comedy",
    "abstract": "Computational Humour (CH) has attracted the interest of Natural Language\nProcessing and Computational Linguistics communities. Creating datasets for\nautomatic measurement of humour quotient is difficult due to multiple possible\ninterpretations of the content. In this work, we create a multi-modal\nhumour-annotated dataset ($\\sim$40 hours) using stand-up comedy clips. We\ndevise a novel scoring mechanism to annotate the training data with a humour\nquotient score using the audience's laughter. The normalized duration (laughter\nduration divided by the clip duration) of laughter in each clip is used to\ncompute this humour coefficient score on a five-point scale (0-4). This method\nof scoring is validated by comparing with manually annotated scores, wherein a\nquadratic weighted kappa of 0.6 is obtained. We use this dataset to train a\nmodel that provides a \"funniness\" score, on a five-point scale, given the audio\nand its corresponding text. We compare various neural language models for the\ntask of humour-rating and achieve an accuracy of $0.813$ in terms of Quadratic\nWeighted Kappa (QWK). Our \"Open Mic\" dataset is released for further research\nalong with the code.",
    "descriptor": "\nComments: Accepted at EMNLP 2021 Main Conference (short papers); 4 pages, 1 figure, 3 tables\n",
    "authors": [
      "Anirudh Mittal",
      "Pranav Jeevan",
      "Prerak Gandhi",
      "Diptesh Kanojia",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12765"
  },
  {
    "id": "arXiv:2110.12766",
    "title": "Data-Driven Resilient Predictive Control under Denial-of-Service",
    "abstract": "The study of resilient control of linear time-invariant (LTI) systems against\ndenial-of-service (DoS) attacks is gaining popularity in emerging\ncyber-physical applications. In previous works, explicit system models are\nrequired to design a predictor-based resilient controller. These models can be\neither given a priori or obtained through a prior system identification step.\nRecent research efforts have focused on data-driven control based on\npre-collected input-output trajectories (i.e., without explicit system models).\nIn this paper, we take an initial step toward data-driven stabilization of\nstochastic LTI systems under DoS attacks, and develop a resilient model\npredictive control (MPC) scheme driven purely by data-dependent conditions. The\nproposed data-driven control method achieves the same level of resilience as\nthe model-based control method. For example, local input-to-state stability\n(ISS) is achieved under mild assumptions on the noise and the DoS attacks. To\nrecover global ISS, two modifications are further suggested at the price of\nreduced resilience against DoS attacks or increased computational complexity.\nFinally, a numerical example is given to validate the effectiveness of the\nproposed control method.",
    "descriptor": "",
    "authors": [
      "Wenjie Liu",
      "Jian Sun",
      "Gang Wang",
      "Francesco Bullo",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12766"
  },
  {
    "id": "arXiv:2110.12768",
    "title": "Data-driven Control of Dynamic Event-triggered Systems with Delays",
    "abstract": "This paper studies data-driven control of unknown sampled-data systems with\ncommunication delays under an event-triggering transmission mechanism.\nData-based representations for stochastic linear systems with a known or an\nunknown system input matrix are first developed, along with a novel class of\ndynamic triggering schemes for sampled-data systems with time delays. A\nmodel-based stability condition for the resulting event-triggered time-delay\nsystem is established using a looped-functional approach. Combining this\nmodel-based condition with the data-driven representations, data-based\nstability conditions are derived. Building on the data-based conditions,\nmethods for co-designing the controller gain and the event-triggering matrix\nare subsequently provided for both cases with or without using the input\nmatrix. Finally, a numerical example is presented to corroborate the role of\nadditional prior knowledge of the input matrix in reducing the conservatism of\nstability conditions, as well as the merits of our approaches relative to\nexisting results.",
    "descriptor": "\nComments: 14 pages,3 figures\n",
    "authors": [
      "Xin Wang",
      "Jian Sun",
      "Julian Berberich",
      "Gang Wang",
      "Frank Allgower",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12768"
  },
  {
    "id": "arXiv:2110.12769",
    "title": "Multi-scale Iterative Residuals for Fast and Scalable Stereo Matching",
    "abstract": "Despite the remarkable progress of deep learning in stereo matching, there\nexists a gap in accuracy between real-time models and slower state-of-the-art\nmodels which are suitable for practical applications. This paper presents an\niterative multi-scale coarse-to-fine refinement (iCFR) framework to bridge this\ngap by allowing it to adopt any stereo matching network to make it fast, more\nefficient and scalable while keeping comparable accuracy. To reduce the\ncomputational cost of matching, we use multi-scale warped features to estimate\ndisparity residuals and push the disparity search range in the cost volume to a\nminimum limit. Finally, we apply a refinement network to recover the loss of\nprecision which is inherent in multi-scale approaches. We test our iCFR\nframework by adopting the matching networks from state-of-the art GANet and\nAANet. The result is 49$\\times$ faster inference time compared to GANetdeep and\n4$\\times$ less memory consumption, with comparable error. Our best performing\nnetwork, which we call FRSNet is scalable even up to an input resolution of 6K\non a GTX 1080Ti, with inference time still below one second and comparable\naccuracy to AANet+. It out-performs all real-time stereo methods and achieves\ncompetitive accuracy on the KITTI benchmark.",
    "descriptor": "\nComments: Accepted at CSCS21\n",
    "authors": [
      "Kumail Raza",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12769"
  },
  {
    "id": "arXiv:2110.12770",
    "title": "DP-XGBoost: Private Machine Learning at Scale",
    "abstract": "The big-data revolution announced ten years ago does not seem to have fully\nhappened at the expected scale. One of the main obstacle to this, has been the\nlack of data circulation. And one of the many reasons people and organizations\ndid not share as much as expected is the privacy risk associated with data\nsharing operations. There has been many works on practical systems to compute\nstatistical queries with Differential Privacy (DP). There have also been\npractical implementations of systems to train Neural Networks with DP, but\nrelatively little efforts have been dedicated to designing scalable classical\nMachine Learning (ML) models providing DP guarantees. In this work we describe\nand implement a DP fork of a battle tested ML model: XGBoost. Our approach\nbeats by a large margin previous attempts at the task, in terms of accuracy\nachieved for a given privacy budget. It is also the only DP implementation of\nboosted trees that scales to big data and can run in distributed environments\nsuch as: Kubernetes, Dask or Apache Spark.",
    "descriptor": "",
    "authors": [
      "Nicolas Grislain",
      "Joan Gonzalvez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12770"
  },
  {
    "id": "arXiv:2110.12773",
    "title": "Scientific Machine Learning Benchmarks",
    "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.",
    "descriptor": "",
    "authors": [
      "Jeyan Thiyagalingam",
      "Mallikarjun Shankar",
      "Geoffrey Fox",
      "Tony Hey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.12773"
  },
  {
    "id": "arXiv:2110.12777",
    "title": "An approach to optimize study programs using Discrete Event Simulation",
    "abstract": "Creating a study program for optimal academic completion is a complex\nassignment. Especially programs in the science, technology, engineering, and\nmathematics field are known for extended completion time as well as high\ndrop-out rates throughout the years. Drop-outs are caused by various reasons\nand can not be directly generalized. This leads to unnecessary costs for the\nstudents and the university. Reasons for dropping out of university could be\nstudents failing classes too often or poorly designed study programs causing a\nloss of interest in a subject. Besides dropping out of university, students are\noften having trouble with specific classes. This results in postponing certain\nclasses, which causes a bottleneck in the overall progression and delays\ngraduation. To achieve a better understanding of a general student's\nprogression as well as finding mentioned bottlenecks in an average academic\nprogression a discrete event simulation was created. The insights gained by the\nsimulation shall furthermore be used by Technische Hochschule K\\\"oln to analyze\nmentioned problems, find solutions and create a healthier environment for\noptimal academic progression.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Marcel Dr\u00f6scher",
      "Alpar G\u00fcr",
      "Nicolas Rehbach"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.12777"
  },
  {
    "id": "arXiv:2110.12778",
    "title": "A Deep Reinforcement Learning Approach for Audio-based Navigation and  Audio Source Localization in Multi-speaker Environments",
    "abstract": "In this work we apply deep reinforcement learning to the problems of\nnavigating a three-dimensional environment and inferring the locations of human\nspeaker audio sources within, in the case where the only available information\nis the raw sound from the environment, as a simulated human listener placed in\nthe environment would hear it. For this purpose we create two virtual\nenvironments using the Unity game engine, one presenting an audio-based\nnavigation problem and one presenting an audio source localization problem. We\nalso create an autonomous agent based on PPO online reinforcement learning\nalgorithm and attempt to train it to solve these environments. Our experiments\nshow that our agent achieves adequate performance and generalization ability in\nboth environments, measured by quantitative metrics, even when a limited amount\nof training data are available or the environment parameters shift in ways not\nencountered during training. We also show that a degree of agent knowledge\ntransfer is possible between the environments.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.04488\n",
    "authors": [
      "Petros Giannakopoulos",
      "Aggelos Pikrakis",
      "Yannis Cotronis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12778"
  },
  {
    "id": "arXiv:2110.12780",
    "title": "Battling Hateful Content in Indic Languages HASOC '21",
    "abstract": "The extensive rise in consumption of online social media (OSMs) by a large\nnumber of people poses a critical problem of curbing the spread of hateful\ncontent on these platforms. With the growing usage of OSMs in multiple\nlanguages, the task of detecting and characterizing hate becomes more complex.\nThe subtle variations of code-mixed texts along with switching scripts only add\nto the complexity. This paper presents a solution for the HASOC 2021\nMultilingual Twitter Hate-Speech Detection challenge by team PreCog IIIT\nHyderabad. We adopt a multilingual transformer based approach and describe our\narchitecture for all 6 sub-tasks as part of the challenge. Out of the 6 teams\nthat participated in all the sub tasks, our submissions rank 3rd overall.",
    "descriptor": "\nComments: 12 pages, 6 figures, Accepted at FIRE 2021, CEUR Workshop Proceedings (this http URL)\n",
    "authors": [
      "Aditya Kadam",
      "Anmol Goel",
      "Jivitesh Jain",
      "Jushaan Singh Kalra",
      "Mallika Subramanian",
      "Manvith Reddy",
      "Prashant Kodali",
      "T.H. Arjun",
      "Manish Shrivastava",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12780"
  },
  {
    "id": "arXiv:2110.12782",
    "title": "NetMF+: Network Embedding Based on Fast and Effective Single-Pass  Randomized Matrix Factorization",
    "abstract": "In this work, we propose NetMF+, a fast, memory-efficient, scalable, and\neffective network embedding algorithm developed for a single machine with CPU\nonly. NetMF+ is based on the theoretically grounded embedding method NetMF and\nleverages the theories from randomized matrix factorization to learn embedding\nefficiently. We firstly propose a fast randomized eigen-decomposition algorithm\nfor the modified Laplacian matrix. Then, sparse-sign randomized single-pass\nsingular value decomposition (SVD) is utilized to avoid constructing dense\nmatrix and generate promising embedding. To enhance the performance of\nembedding, we apply spectral propagation in NetMF+. Finally, A high-performance\nparallel graph processing stack GBBS is used to achieve memory-efficiency.\nExperiment results show that NetMF+ can learn a powerful embedding from a\nnetwork with more than 10^11 edges within 1.5 hours at lower memory cost than\nstate-of-the-art methods. The result on ClueWeb with 0.9 billion vertices and\n75 billion edges shows that NetMF+ saves more than half of the memory and\nruntime than the state-of-the-art and has better performance. The source code\nof NetMF+ will be publicly available after the anonymous peer review.",
    "descriptor": "",
    "authors": [
      "Yuyang Xie",
      "Jiezhong Qiu",
      "Wenjian Yu",
      "Xu Feng",
      "Yuxiang Chen",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12782"
  },
  {
    "id": "arXiv:2110.12785",
    "title": "Random Matrix based Physical Layer Secret Key Generation in Static  Channels",
    "abstract": "Physical layer secret key generation exploits the reciprocal channel\nrandomness for key generation and has proven to be an effective addition\nsecurity layer in wireless communications. However, static or scarcely random\nchannels require artificially induced dynamics to improve the secrecy\nperformance, e.g., using intelligent reflecting surface (IRS). One key\nchallenge is that the induced random phase from IRS is also reflected in the\ndirection to eavesdroppers (Eve). This leakage enables Eve nodes to estimate\nthe legitimate channels and secret key via a globally known pilot sequence. To\nmitigate the secret key leakage issue, we propose to exploit random matrix\ntheory to inform the design of a new physical layer secret key generation\n(PL-SKG) algorithm. We prove that, when sending appropriate random Gaussian\nmatrices, the singular values of Alice's and Bob's received signals follow a\nsimilar probability distribution. Leveraging these common singular values, we\npropose a random Gaussian matrix based PL-SKG (RGM PL-SKG), which avoids the\nusages of the globally known pilot and thereby prevents the aforementioned\nleakage issue. Our results show the following: (i) high noise resistance which\nleads to superior secret key rate (SKR) improvement (up to 300%) in low SNR\nregime, and (ii) general improved SKR performance against multiple colluded\nEves. We believe our combination of random matrix theory and PL-SKG shows a new\nparadigm to secure the wireless communication channels.",
    "descriptor": "",
    "authors": [
      "Zhuangkun Wei",
      "Weisi Guo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12785"
  },
  {
    "id": "arXiv:2110.12787",
    "title": "Parallel Feedforward Compensation for Output Synchronization: Fully  Distributed Control and Indefinite Laplacian",
    "abstract": "This work is associated with the use of parallel feedforward compensators\n(PFCs) for the problem of output synchronization over heterogeneous agents and\nthe benefits this approach can provide. Specifically, it addresses the addition\nof stable PFCs on agents that interact with each other using diffusive\ncouplings. The value in the application of such PFC is twofold. Firstly, it has\nbeen an issue that output synchronization among passivity-short systems\nrequires global information for the design of controllers in the cases when\ninitial conditions need to be taken into account, such as average consensus and\ndistributed optimization. We show that a stable PFC can be designed to\npassivate a passivity-short system while its output asymptotically vanishes as\nits input tends to zero. As a result, output synchronization is achieved among\nthese systems by fully distributed controls without altering the original\nconsensus results. Secondly, it is generally required in the literature that\nthe graph Laplacian be positive semidefinite, i.e., $L \\geq 0$ for undirected\ngraphs or $L + L^T \\geq 0$ for balanced directed graphs, to achieve output\nsynchronization over signed weighted graphs. We show that the PFC serves as\noutput feedback to the communication graph to enhance the robustness against\nnegative weight edges. As a result, output synchronization is achieved over a\nsigned weighted and balanced graph, even if the corresponding Laplacian is not\npositive semidefinite.",
    "descriptor": "\nComments: 10 pages, 8 figures, submitted to systems and control letters\n",
    "authors": [
      "Mengmou Li",
      "Ioannis Lestas",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.12787"
  },
  {
    "id": "arXiv:2110.12788",
    "title": "A Cost-Effective Workload Allocation Strategy for Cloud-Native Edge  Services",
    "abstract": "Nowadays IoT applications consist of a collection of loosely coupled modules,\nnamely microservices, that can be managed and placed in a heterogeneous\nenvironment consisting of private and public resources. It follows that\ndistributing the application logic introduces new challenges in guaranteeing\nperformance and reducing costs. However, most existing solutions are focused on\nreducing pay-per-use costs without considering a microservice-based\narchitecture. We propose a cost-effective workload allocation for\nmicroservice-based applications. We model the problem as an integer programming\nproblem and we formulate an efficient and near-optimal heuristic solution given\nthe NP-hardness of the original problem. Numerical results demonstrate the good\nperformance of the proposed heuristic in terms of cost reduction and\nperformance with respect to optimal and state-of-the-art solutions. Moreover,\nan evaluation conducted in a Kubernetes cluster running in an OpenStack\necosystem confirms the feasibility and the validity of the proposed solution.",
    "descriptor": "",
    "authors": [
      "Valentino Armani",
      "Francescomaria Faticanti",
      "Silvio Cretti",
      "Seungwoo Kum",
      "Domenico Siracusa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12788"
  },
  {
    "id": "arXiv:2110.12794",
    "title": "Mixed precision in Graphics Processing Unit",
    "abstract": "Modern graphics computing units (GPUs) are designed and optimized to perform\nhighly parallel numerical calculations. This parallelism has enabled (and\npromises) significant advantages, both in terms of energy performance and\ncalculation. In this document, we take stock of the different applications of\nmixed precision. We recall the standards currently used in the overwhelming\nmajority of systems in terms of numerical computation. We show that the mixed\nprecision which decreases the precision at the input of an operation does not\nnecessarily decrease the precision of its output. We show that this previous\nprinciple allows its transposition into one of the branches that most needs\ncomputing power: machine learning. The use of fixed point numbers and\nhalf-precision are two very effective ways to increase the learning ability of\ncomplex neural networks. Mixed precision still requires the use of suitable\nhardware, failing which the calculation time could on the contrary be\nlengthened. The NVIDIA Tensor Core that is found among others in their Tesla\nV100 range, is an example of implementation at the hardware level of mixed\nprecision. On the other hand, by abandoning the traditional von Neumann model,\nmixed precision can also be transposed to a lower level of abstraction, using\nphase change memories.",
    "descriptor": "\nComments: M.S dissertation\n",
    "authors": [
      "Quentin Gallou\u00e9dec"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.12794"
  },
  {
    "id": "arXiv:2110.12796",
    "title": "Data-Driven Demand-Side Flexibility Quantification: Prediction and  Approximation of Flexibility Envelopes",
    "abstract": "Real-time quantification of residential building energy flexibility is needed\nto enable a cost-efficient operation of active distribution grids. A promising\nmeans is to use the so-called flexibility envelope concept to represent the\ntime-dependent and inter-temporally coupled flexibility potential. However,\nexisting optimization-based quantification entails high computational burdens\nlimiting flexibility utilization in real-time applications, and a more\ncomputationally efficient quantification approach is desired. Additionally, the\ncommunication of a flexibility envelope to system operators in its original\nform is data-intensive. In order to address the computational burdens, this\npaper first trains several machine learning models based on historical\nquantification results for online use. Subsequently, probability distribution\nfunctions are proposed to approximate the flexibility envelopes with\nsignificantly fewer parameters, which can be communicated to system operators\ninstead of the original flexibility envelope. The results show that the most\npromising prediction and approximation approaches allow for a minimum reduction\nof the computational burden by a factor of 9 and of the communication load by a\nfactor of 6.6, respectively.",
    "descriptor": "",
    "authors": [
      "Nami Hekmat",
      "Hanmin Cai",
      "Thierry Zufferey",
      "Gabriela Hug",
      "Philipp Heer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12796"
  },
  {
    "id": "arXiv:2110.12799",
    "title": "Scalable Channel Estimation and Reflection Optimization for  Reconfigurable Intelligent Surface-Enhanced OFDM Systems",
    "abstract": "This paper proposes a scalable channel estimation and reflection optimization\nframework for reconfigurable intelligent surface (RIS)-enhanced orthogonal\nfrequency division multiplexing (OFDM) systems. Specifically, the proposed\nscheme firstly generates a training set of RIS reflection coefficient vectors\noffline. For each RIS reflection coefficient vector in the training set, the\nproposed scheme estimates only the end-to-end composite channel and then\nperforms the transmit power allocation. As a result, the RIS reflection\noptimization is simplified by searching for the optimal reflection coefficient\nvector maximizing the achievable rate from the pre-designed training set. The\nproposed scheme is capable of flexibly adjusting the training overhead\naccording to the given channel coherence time, which is in sharp contrast to\nthe conventional counterparts. Moreover, we discuss the computational\ncomplexity of the proposed scheme and analyze the theoretical scaling law of\nthe achievable rate versus the number of training slots. Finally, simulation\nresults demonstrate that the proposed scheme is superior to existing approaches\nin terms of decreasing training overhead, reducing complexity as well as\nimproving rate performance in the presence of channel estimation errors.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Jiancheng An",
      "Qingqing Wu",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12799"
  },
  {
    "id": "arXiv:2110.12800",
    "title": "RIS-aided Massive MIMO: Achieving Large Multiplexing Gains with  non-Large Arrays",
    "abstract": "This paper considers an antenna structure where a (non-large) array of\nradiating elements is placed at short distance in front of a reconfigurable\nintelligent surface (RIS). We propose a channel estimation procedure using\ndifferent configurations of the RIS elements and derive a closed-form\nexpression for an achievable downlink spectral efficiency by using the popular\nhardening lower-bound. Next, we formulate an optimization problem, with respect\nto the phase shifts of the RIS, aimed at minimizing the channels\ncross-correlations while preserving the channels individual norms. The\nnumerical analysis shows that the proposed structure is capable of overcoming\nthe performance of a conventional massive MIMO system without the RIS.",
    "descriptor": "\nComments: 6 pages, 3 figures, conference paper accepted for presentation in the 25th International ITG Workshop on Smart Antennas (WSA 2021)\n",
    "authors": [
      "Stefano Buzzi",
      "Carmen D'Andrea",
      "Giovanni Interdonato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12800"
  },
  {
    "id": "arXiv:2110.12801",
    "title": "Continuous Reset Element",
    "abstract": "This paper addresses the main goal of using reset control in precision motion\ncontrol systems, breaking of the well-known \"Waterbed effect\". A new\narchitecture for reset elements will be introduced which has a continuous\noutput signal as opposed to conventional reset elements. A steady-state\nprecision study is presented, showing the steady-state precision is preserved\nwhile the peak of sensitivity is reduced. The architecture is then used for a\n\"Constant in Gain Lead in Phase\" (CgLp) element and a numerical analysis on\ntransient response shows a significant improvement in transient response. It is\nshown that by following the presented guideline for tuning, settling time can\nbe reduced and at the same time a no-overshoot step response can be achieved. A\npractical example is presented to verify the results and also to show that the\nproposed element can achieve a complex-order behaviour.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.06268\n",
    "authors": [
      "Nima Karbasizadeh",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12801"
  },
  {
    "id": "arXiv:2110.12804",
    "title": "High-Speed Trains Access Connectivity Through RIS-Assisted FSO  Communications",
    "abstract": "Free-space optic (FSO) is a promising solution to provide broadband Internet\naccess for high-speed trains (HSTs). Besides, reconfigurable intelligent\nsurfaces (RIS) are considered as hardware technology to improve performance of\noptical wireless communication systems. In this paper, we propose a\nRIS-assisted FSO system to provide access connectivity for HTSs, as an upgrade\nfor the existing direct and relay-assisted FSO access setups. Our motivation is\nmainly based on well-proven results indicating that a RIS-assisted optical\nwireless system, with a large enough number of RIS elements, outperforms a\nrelay-assisted one thanks to its programmable structure. We firstly compute the\nstatistical expressions of the considered RIS-assisted FSO channels under weak\nand moderate-to-strong fading conditions. Then, the network's average\nsignal-to-noise ratio and outage probability are formulated based on the\nassumed fading conditions, and for two fixed- and dynamic-oriented RIS coverage\nscenarios. Our results reveal that the proposed access network offers up to\naround 44% higher data rates and 240% wider coverage area for each FSO base\nstation (FSO-BS) compared to those of the relay-assisted one. The increase of\ncoverage area, on average, reduces 67% the number of required FSO-BSs for a\ngiven distance, which results in fewer handover processes compared to the\nalternative setups. Finally, the results are verified through Monte-Carlo\nsimulations.",
    "descriptor": "\nComments: 10 pages and 8 figures; this work has been submitted for possible publication. Note: The first author's affiliation has been changed to \"EURECOM Institute\" since Oct. 15th, 2021. However, the paper was written before that time\n",
    "authors": [
      "Pouya Agheli",
      "Hamzeh Beyranvand",
      "Mohammad Javad Emadi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12804"
  },
  {
    "id": "arXiv:2110.12805",
    "title": "Algorithms for the Communication of Samples",
    "abstract": "We consider the problem of reverse channel coding, that is, how to simulate a\nnoisy channel over a digital channel efficiently. We propose two new coding\nschemes with practical advantages over previous approaches. First, we introduce\nordered random coding (ORC) which uses a simple trick to reduce the coding cost\nof previous approaches based on importance sampling. Our derivation also\nilluminates a connection between these schemes and the so-called Poisson\nfunctional representation. Second, we describe a hybrid coding scheme which\nuses dithered quantization to efficiently communicate samples from\ndistributions with bounded support.",
    "descriptor": "",
    "authors": [
      "Lucas Theis",
      "Noureldin Yosri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12805"
  },
  {
    "id": "arXiv:2110.12810",
    "title": "Learning What to Memorize: Using Intrinsic Motivation to Form Useful  Memory in Partially Observable Reinforcement Learning",
    "abstract": "Reinforcement Learning faces an important challenge in partial observable\nenvironments that has long-term dependencies. In order to learn in an ambiguous\nenvironment, an agent has to keep previous perceptions in a memory. Earlier\nmemory based approaches use a fixed method to determine what to keep in the\nmemory, which limits them to certain problems. In this study, we follow the\nidea of giving the control of the memory to the agent by allowing it to have\nmemory-changing actions. This learning mechanism is supported by an intrinsic\nmotivation to memorize rare observations that can help the agent to\ndisambiguate its state in the environment. Our approach is experimented and\nanalyzed on several partial observable tasks with long-term dependencies and\ncompared with other memory based methods.",
    "descriptor": "",
    "authors": [
      "Alper Demir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12810"
  },
  {
    "id": "arXiv:2110.12812",
    "title": "Domain Adaptation in Multi-View Embedding for Cross-Modal Video  Retrieval",
    "abstract": "Given a gallery of uncaptioned video sequences, this paper considers the task\nof retrieving videos based on their relevance to an unseen text query. To\ncompensate for the lack of annotations, we rely instead on a related video\ngallery composed of video-caption pairs, termed the source gallery, albeit with\na domain gap between its videos and those in the target gallery. We thus\nintroduce the problem of Unsupervised Domain Adaptation for Cross-modal Video\nRetrieval, along with a new benchmark on fine-grained actions. We propose a\nnovel iterative domain alignment method by means of pseudo-labelling target\nvideos and cross-domain (i.e. source-target) ranking. Our approach adapts the\nembedding space to the target gallery, consistently outperforming source-only\nas well as marginal and conditional alignment methods.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jonathan Munro",
      "Michael Wray",
      "Diane Larlus",
      "Gabriela Csurka",
      "Dima Damen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12812"
  },
  {
    "id": "arXiv:2110.12815",
    "title": "Binary Level Set Method for Variational Implicit Solvation Model",
    "abstract": "In this article, we apply the binary level set method to the Variational\nImplicit Solvent Model (VISM), which is a theoretical and computational tool to\nstudy biomolecular systems with complex topology. Central in VISM is an\neffective free energy of all possible interfaces separating solutes (e.g.,\nproteins) from solvent (e.g., water). Previously, such a functional is\nminimized numerically by the level set method to determine the stable\nequilibrium conformations and solvation free energies. We vastly improve the\nspeed by applying the binary level set method, in which the interface is\napproximated by a binary level set function that only takes value $\\pm 1$ on\nthe solute/solvent region, leading to a discrete formulation of VISM energy.\nThe surface area is approximated by convolution of an indicator function with a\ncompactly supported kernel. The VISM energy can be minimized by iteratively\n\"flipping\" the binary level set function in a steepest descent fashion.\nNumerical experiments are performed to demonstrate the accuracy and performance\nof our method.",
    "descriptor": "",
    "authors": [
      "Zirui Zhang",
      "Li-Tien Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.12815"
  },
  {
    "id": "arXiv:2110.12822",
    "title": "Restore from Restored: Single-image Inpainting",
    "abstract": "Recent image inpainting methods have shown promising results due to the power\nof deep learning, which can explore external information available from the\nlarge training dataset. However, many state-of-the-art inpainting networks are\nstill limited in exploiting internal information available in the given input\nimage at test time. To mitigate this problem, we present a novel and efficient\nself-supervised fine-tuning algorithm that can adapt the parameters of fully\npre-trained inpainting networks without using ground-truth target images. We\nupdate the parameters of the pre-trained state-of-the-art inpainting networks\nby utilizing existing self-similar patches (i.e., self-exemplars) within the\ngiven input image without changing the network architecture and improve the\ninpainting quality by a large margin. Qualitative and quantitative experimental\nresults demonstrate the superiority of the proposed algorithm, and we achieve\nstate-of-the-art inpainting results on publicly available benchmark datasets.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.08078\n",
    "authors": [
      "Eunhye Lee",
      "Jeongmu Kim",
      "Jisu Kim",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12822"
  },
  {
    "id": "arXiv:2110.12826",
    "title": "TPSNet: Thin-Plate-Spline Representation for Arbitrary Shape Scene Text  Detection",
    "abstract": "The research focus of scene text detection has shifted to arbitrary shape\ntext in recent years, in which text representation is a fundamental problem. An\nideal representation should be compact, complete, integral, and reusable for\nsubsequent recognition in our opinion. However, previous representations suffer\nfrom one or several aspects. Thin-Plate-Spline (TPS) transformation has\nachieved great success in scene text recognition. Inspired from this, we\nreversely think its usage and sophisticatedly take TPS as an exquisite\nrepresentation for arbitrary shape text detection. The TPS representation is\ncompact, complete and integral, and with the predicted TPS parameters, the\ndetected text region can be rectified to near-horizontal one which is\nbeneficial for subsequent recognition. To solve the supervision problem of TPS\ntraining without key point annotations, two novel losses including the boundary\nset loss and the shape alignment loss are proposed. Extensive evaluation and\nablation on several public benchmarks demonstrate the effectiveness and\nsuperiority of the proposed method.",
    "descriptor": "",
    "authors": [
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12826"
  },
  {
    "id": "arXiv:2110.12829",
    "title": "Spread2RML: Constructing Knowledge Graphs by Predicting RML Mappings on  Messy Spreadsheets",
    "abstract": "The RDF Mapping Language (RML) allows to map semi-structured data to RDF\nknowledge graphs. Besides CSV, JSON and XML, this also includes the mapping of\nspreadsheet tables. Since spreadsheets have a complex data model and can become\nrather messy, their mapping creation tends to be very time consuming. In order\nto reduce such efforts, this paper presents Spread2RML which predicts RML\nmappings on messy spreadsheets. This is done with an extensible set of RML\nobject map templates which are applied for each column based on heuristics. In\nour evaluation, three datasets are used ranging from very messy synthetic data\nto spreadsheets from data.gov which are less messy. We obtained first promising\nresults especially with regard to our approach being fully automatic and\ndealing with rather messy data.",
    "descriptor": "\nComments: 17 pages, 1 figure, 2 tables, accepted at K-CAP 2021\n",
    "authors": [
      "Markus Schr\u00f6der",
      "Christian Jilek",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12829"
  },
  {
    "id": "arXiv:2110.12831",
    "title": "Experimental implementation of an emission-aware prosumer with online  flexibility quantification and provision",
    "abstract": "Emission-aware and flexible building operation can play a crucial role in the\nenergy transition. On the one hand, building operation accounts for a\nsignificant portion of global energy-related emissions. On the other hand, they\nmay provide the future low-carbon energy system with flexibility to achieve\nsecure, stable, and efficient operation. This paper reports an experimental\nimplementation of an emission-aware flexible prosumer considering all\nbehind-the-meter assets of an actual occupied building by incorporating a model\npredictive control strategy into an existing building energy management system.\nThe resultant can minimize the equivalent carbon emission due to electricity\nimports and provide flexibility to the energy system. The experimental results\nindicate an emission reduction of 12.5% compared to a benchmark that maximizes\nPV self-consumption. In addition, flexibility provision is demonstrated with an\nemulated distribution system operator. The results suggest that flexibility can\nbe provided without the risk of rebound effects due to the flexibility envelope\nself-reported in advance.",
    "descriptor": "",
    "authors": [
      "Hanmin Cai",
      "Philipp Heer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12831"
  },
  {
    "id": "arXiv:2110.12838",
    "title": "Debiasing Credit Scoring using Evolutionary Algorithms",
    "abstract": "This paper investigates the application of machine learning when training a\ncredit decision model over real, publicly available data whilst accounting for\n\"bias objectives\". We use the term \"bias objective\" to describe the requirement\nthat a trained model displays discriminatory bias against a given groups of\nindividuals that doesn't exceed a prescribed level, where such level can be\nzero. This research presents an empirical study examining the tension between\ncompeting model training objectives which in all cases include one or more bias\nobjectives.\nThis work is motivated by the observation that the parties associated with\ncreditworthiness models have requirements that can not certainly be fully met\nsimultaneously. The research herein seeks to highlight the impracticality of\nsatisfying all parties' objectives, demonstrating the need for \"trade-offs\" to\nbe made. The results and conclusions presented by this paper are of particular\nimportance for all stakeholders within the credit scoring industry that rely\nupon artificial intelligence (AI) models as part of the decision-making process\nwhen determining the creditworthiness of individuals. This paper provides an\nexposition of the difficulty of training AI models that are able to\nsimultaneously satisfy multiple bias objectives whilst maintaining acceptable\nlevels of accuracy. Stakeholders should be aware of this difficulty and should\nacknowledge that some degree of discriminatory bias, across a number of\nprotected characteristics and formulations of bias, cannot be avoided.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Nigel Kingsman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.12838"
  },
  {
    "id": "arXiv:2110.12840",
    "title": "Self-Consistent Models and Values",
    "abstract": "Learned models of the environment provide reinforcement learning (RL) agents\nwith flexible ways of making predictions about the environment. In particular,\nmodels enable planning, i.e. using more computation to improve value functions\nor policies, without requiring additional environment interactions. In this\nwork, we investigate a way of augmenting model-based RL, by additionally\nencouraging a learned model and value function to be jointly\n\\emph{self-consistent}. Our approach differs from classic planning methods such\nas Dyna, which only update values to be consistent with the model. We propose\nmultiple self-consistency updates, evaluate these in both tabular and function\napproximation settings, and find that, with appropriate choices,\nself-consistency helps both policy evaluation and control.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Gregory Farquhar",
      "Kate Baumli",
      "Zita Marinho",
      "Angelos Filos",
      "Matteo Hessel",
      "Hado van Hasselt",
      "David Silver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12840"
  },
  {
    "id": "arXiv:2110.12844",
    "title": "Network compression and faster inference using spatial basis filters",
    "abstract": "We present an efficient alternative to the convolutional layer through\nutilising spatial basis filters (SBF). SBF layers exploit the spatial\nredundancy in the convolutional filters across the depth to achieve overall\nmodel compression, while maintaining the top-end accuracy of their dense\ncounter-parts. Training SBF-Nets is modelled as a simple pruning problem, but\ninstead of zeroing out the pruned channels, they are replaced with inexpensive\ntransformations from the set of non-pruned features. To enable an adoption of\nthese SBF layers, we provide a flexible training pipeline and an efficient\nimplementation in CUDA with low latency. To further demonstrate the effective\ncapacity of these models, we apply semi-supervised knowledge distillation that\nleads to significant performance improvements over the baseline networks. Our\nexperiments show that SBF-Nets are effective and achieve comparable or improved\nperformance to state-of-the-art across CIFAR10, CIFAR100, Tiny-ImageNet, and\nILSCRC-2012.",
    "descriptor": "",
    "authors": [
      "Roy Miles",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12844"
  },
  {
    "id": "arXiv:2110.12846",
    "title": "Optimal Auction Design for the Gradual Procurement of Strategic Service  Provider Agents",
    "abstract": "We consider an outsourcing problem where a software agent procures multiple\nservices from providers with uncertain reliabilities to complete a\ncomputational task before a strict deadline. The service consumer requires a\nprocurement strategy that achieves the optimal balance between success\nprobability and invocation cost. However, the service providers are\nself-interested and may misrepresent their private cost information if it\nbenefits them. For such settings, we design a novel procurement auction that\nprovides the consumer with the highest possible revenue, while giving\nsufficient incentives to providers to tell the truth about their costs. This\nauction creates a contingent plan for gradual service procurement that suggests\nrecruiting a new provider only when the success probability of the already\nhired providers drops below a time-dependent threshold. To make this auction\nincentive compatible, we propose a novel weighted threshold payment scheme\nwhich pays the minimum among all truthful mechanisms. Using the weighted\npayment scheme, we also design a low-complexity near-optimal auction that\nreduces the computational complexity of the optimal mechanism by 99% with only\nmarginal performance loss (less than 1%). We demonstrate the effectiveness and\nstrength of our proposed auctions through both game theoretical and numerical\nanalysis. The experiment results confirm that the proposed auctions exhibit 59%\nimprovement in performance over the current state-of-the-art, by increasing\nsuccess probability up to 79% and reducing invocation cost by up to 11%.",
    "descriptor": "",
    "authors": [
      "Farzaneh Farhadi",
      "Maria Chli",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12846"
  },
  {
    "id": "arXiv:2110.12855",
    "title": "Actions Speak Louder than Listening: Evaluating Music Style Transfer  based on Editing Experience",
    "abstract": "The subjective evaluation of music generation techniques has been mostly done\nwith questionnaire-based listening tests while ignoring the perspectives from\nmusic composition, arrangement, and soundtrack editing. In this paper, we\npropose an editing test to evaluate users' editing experience of music\ngeneration models in a systematic way. To do this, we design a new music style\ntransfer model combining the non-chronological inference architecture,\nautoregressive models and the Transformer, which serves as an improvement from\nthe baseline model on the same style transfer task. Then, we compare the\nperformance of the two models with a conventional listening test and the\nproposed editing test, in which the quality of generated samples is assessed by\nthe amount of effort (e.g., the number of required keyboard and mouse actions)\nspent by users to polish a music clip. Results on two target styles indicate\nthat the improvement over the baseline model can be reflected by the editing\ntest quantitatively. Also, the editing test provides profound insights which\nare not accessible from usual listening tests. The major contribution of this\npaper is the systematic presentation of the editing test and the corresponding\ninsights, while the proposed music style transfer model based on\nstate-of-the-art neural networks represents another contribution.",
    "descriptor": "\nComments: 9 pages, Proceedings of the 29th ACM International Conference on Multimedia\n",
    "authors": [
      "Wei-Tsung Lu",
      "Meng-Hsuan Wu",
      "Yuh-Ming Chiu",
      "Li Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12855"
  },
  {
    "id": "arXiv:2110.12858",
    "title": "Benchmarking the Processing of Aircraft Tracks with Triples Mode and  Self-Scheduling",
    "abstract": "As unmanned aircraft systems (UASs) continue to integrate into the U.S.\nNational Airspace System (NAS), there is a need to quantify the risk of\nairborne collisions between unmanned and manned aircraft to support regulation\nand standards development. Developing and certifying collision avoidance\nsystems often rely on the extensive use of Monte Carlo collision risk analysis\nsimulations using probabilistic models of aircraft flight. To train these\nmodels, high performance computing resources are required. We've prototyped a\nhigh performance computing workflow designed and deployed on the Lincoln\nLaboratory Supercomputing Center to process billions of observations of\naircraft. However, the prototype has various computational and storage\nbottlenecks that limited rapid or more comprehensive analyses and models. In\nresponse, we have developed a novel workflow to take advantage of various job\nlaunch and task distribution technologies to improve performance. The workflow\nwas benchmarked using two datasets of observations of aircraft, including a new\ndataset focused on the environment around aerodromes. Optimizing how the\nworkflow was parallelized drastically reduced the execution time from weeks to\ndays.",
    "descriptor": "\nComments: 8 pages, 9 figures, 2 tables, submission accepted to the 2021 IEEE High Performance Extreme Computing (HPEC) Conference\n",
    "authors": [
      "Andrew Weinert",
      "Marc Brittain",
      "Ngaire Underhill",
      "Christine Serres"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12858"
  },
  {
    "id": "arXiv:2110.12859",
    "title": "Multi-vehicle experiment platform: A Digital Twin Realization Method",
    "abstract": "With the development of V2X technology, multiple vehicles cooperative control\nhas been widely studied. However, filed testing is rarely conducted due to\nfinancial and safety considerations. To solve this problem, this study proposes\na digital twin method to carry out multi-vehicle experiments, which uses\ncombination of physical and virtual vehicles to perform coordination tasks. To\nconfirm effectiveness of this method, a prototype system is developed, which\nconsists of sand table testbed, its twin system and cloud. Several aspects are\nquantified to describe system performance, including time delay and\nlocalization accuracy. Finally, a vehicle level experiment in platoon scenario\nis carried out and experiment results confirm effectiveness of this method.",
    "descriptor": "",
    "authors": [
      "Chunying Yang",
      "Jianghong Dong",
      "Qing Xu",
      "Mengchi Cai",
      "Hongmao Qin",
      "Jianqiang Wang",
      "Keqiang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12859"
  },
  {
    "id": "arXiv:2110.12865",
    "title": "Sparsity-Specific Code Optimization using Expression Trees",
    "abstract": "We introduce a code generator that converts unoptimized C++ code operating on\nsparse data into vectorized and parallel CPU or GPU kernels. Our approach\nunrolls the computation into a massive expression graph, performs redundant\nexpression elimination, grouping, and then generates an architecture-specific\nkernel to solve the same problem, assuming that the sparsity pattern is fixed,\nwhich is a common scenario in many applications in computer graphics and\nscientific computing. We show that our approach scales to large problems and\ncan achieve speedups of two orders of magnitude on CPUs and three orders of\nmagnitude on GPUs, compared to a set of manually optimized CPU baselines. To\ndemonstrate the practical applicability of our approach, we employ it to\noptimize popular algorithms with applications to physical simulation and\ninteractive mesh deformation.",
    "descriptor": "",
    "authors": [
      "Philipp Herholz",
      "Xuan Tang",
      "Teseo Schneider",
      "Shoaib Kamil",
      "Daniele Panozzo",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.12865"
  },
  {
    "id": "arXiv:2110.12875",
    "title": "Two-dimensional mesh generator in generalized coordinates implemented in  Python",
    "abstract": "Through mathematical models, it is possible to turn a problem of the physical\ndomain into the computational domain. In this context, the paper presents a\ntwo-dimensional mesh generator in generalized coordinates, which uses the\nParametric Linear Spline method and partial differential equations. The\ngenerator is automated and able to treat real complex domains. The code was\nimplemented in Python, applying the Numpy and Matplotlib libraries to matrix\nmanipulations and graphical plots, respectively. Applications are made for\nmonoblock meshes (two-dimensional shape of a bottle) and multi-block meshes\n(geometry of Igap\\'o I lake, Londrina, Paran\\'a, Brazil).",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Gustavo Taiji Naozuka",
      "Saulo Martiello Mastelini",
      "Eliandro Rodrigues Cirilo",
      "Neyva Maria Lopes Romeiro",
      "Paulo Laerte Natti"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2110.12875"
  },
  {
    "id": "arXiv:2110.12876",
    "title": "FedParking: A Federated Learning based Parking Space Estimation with  Parked Vehicle assisted Edge Computing",
    "abstract": "As a distributed learning approach, federated learning trains a shared\nlearning model over distributed datasets while preserving the training data\nprivacy. We extend the application of federated learning to parking management\nand introduce FedParking in which Parking Lot Operators (PLOs) collaborate to\ntrain a long short-term memory model for parking space estimation without\nexchanging the raw data. Furthermore, we investigate the management of Parked\nVehicle assisted Edge Computing (PVEC) by FedParking. In PVEC, different PLOs\nrecruit PVs as edge computing nodes for offloading services through an\nincentive mechanism, which is designed according to the computation demand and\nparking capacity constraints derived from FedParking. We formulate the\ninteractions among the PLOs and vehicles as a multi-lead multi-follower\nStackelberg game. Considering the dynamic arrivals of the vehicles and\ntime-varying parking capacity constraints, we present a multi-agent deep\nreinforcement learning approach to gradually reach the Stackelberg equilibrium\nin a distributed yet privacy-preserving manner. Finally, numerical results are\nprovided to demonstrate the effectiveness and efficiency of our scheme.",
    "descriptor": "\nComments: Accepted in IEEE TVT, small bugs in Sec. V-B are corrected in this version. Copyright (c) 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses\n",
    "authors": [
      "Xumin Huang",
      "Peichun Li",
      "Rong Yu",
      "Yuan Wu",
      "Kan Xie",
      "Shengli Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12876"
  },
  {
    "id": "arXiv:2110.12879",
    "title": "Information efficient learning of complexly structured preferences:  Elicitation procedures and their application to decision making under  uncertainty",
    "abstract": "In this paper we propose efficient methods for elicitation of complexly\nstructured preferences and utilize these in problems of decision making under\n(severe) uncertainty. Based on the general framework introduced in Jansen,\nSchollmeyer and Augustin (2018, Int. J. Approx. Reason), we now design\nelicitation procedures and algorithms that enable decision makers to reveal\ntheir underlying preference system (i.e. two relations, one encoding the\nordinal, the other the cardinal part of the preferences) while having to answer\nas few as possible simple ranking questions. Here, two different approaches are\nfollowed. The first approach directly utilizes the collected ranking data for\nobtaining the ordinal part of the preferences, while their cardinal part is\nconstructed implicitly by measuring meta data on the decision maker's\nconsideration times. In contrast, the second approach explicitly elicits also\nthe cardinal part of the decision maker's preference system, however, only an\napproximate version of it. This approximation is obtained by additionally\ncollecting labels of preference strength during the elicitation procedure. For\nboth approaches, we give conditions under which they produce the decision\nmaker's true preference system and investigate how their efficiency can be\nimproved. For the latter purpose, besides data-free approaches, we also discuss\nways for effectively guiding the elicitation procedure if data from previous\nelicitation rounds is available. Finally, we demonstrate how the proposed\nelicitation methods can be utilized in problems of decision under (severe)\nuncertainty. Precisely, we show that under certain conditions optimal decisions\ncan be found without fully specifying the preference system.",
    "descriptor": "",
    "authors": [
      "Christoph Jansen",
      "Hannah Blocher",
      "Thomas Augustin",
      "Georg Schollmeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12879"
  },
  {
    "id": "arXiv:2110.12881",
    "title": "Employing chunk size adaptation to overcome concept drift",
    "abstract": "Modern analytical systems must be ready to process streaming data and\ncorrectly respond to data distribution changes. The phenomenon of changes in\ndata distributions is called concept drift, and it may harm the quality of the\nused models. Additionally, the possibility of concept drift appearance causes\nthat the used algorithms must be ready for the continuous adaptation of the\nmodel to the changing data distributions. This work focuses on non-stationary\ndata stream classification, where a classifier ensemble is used. To keep the\nensemble model up to date, the new base classifiers are trained on the incoming\ndata blocks and added to the ensemble while, at the same time, outdated models\nare removed from the ensemble. One of the problems with this type of model is\nthe fast reaction to changes in data distributions. We propose a new Chunk\nAdaptive Restoration framework that can be adapted to any block-based data\nstream classification algorithm. The proposed algorithm adjusts the data chunk\nsize in the case of concept drift detection to minimize the impact of the\nchange on the predictive performance of the used model. The conducted\nexperimental research, backed up with the statistical tests, has proven that\nChunk Adaptive Restoration significantly reduces the model's restoration time.",
    "descriptor": "",
    "authors": [
      "J\u0119drzej Kozal",
      "Filip Guzy",
      "Micha\u0142 Wo\u017aniak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12881"
  },
  {
    "id": "arXiv:2110.12884",
    "title": "DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative  Networks",
    "abstract": "Machine learning models have been criticized for reflecting unfair biases in\nthe training data. Instead of solving for this by introducing fair learning\nalgorithms directly, we focus on generating fair synthetic data, such that any\ndownstream learner is fair. Generating fair synthetic data from unfair data -\nwhile remaining truthful to the underlying data-generating process (DGP) - is\nnon-trivial. In this paper, we introduce DECAF: a GAN-based fair synthetic data\ngenerator for tabular data. With DECAF we embed the DGP explicitly as a\nstructural causal model in the input layers of the generator, allowing each\nvariable to be reconstructed conditioned on its causal parents. This procedure\nenables inference time debiasing, where biased edges can be strategically\nremoved for satisfying user-defined fairness requirements. The DECAF framework\nis versatile and compatible with several popular definitions of fairness. In\nour experiments, we show that DECAF successfully removes undesired bias and -\nin contrast to existing methods - is capable of generating high-quality\nsynthetic data. Furthermore, we provide theoretical guarantees on the\ngenerator's convergence and the fairness of downstream models.",
    "descriptor": "",
    "authors": [
      "Boris van Breugel",
      "Trent Kyono",
      "Jeroen Berrevoets",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12884"
  },
  {
    "id": "arXiv:2110.12891",
    "title": "Local Explanations for Clinical Search Engine results",
    "abstract": "Health care professionals rely on treatment search engines to efficiently\nfind adequate clinical trials and early access programs for their patients.\nHowever, doctors lose trust in the system if its underlying processes are\nunclear and unexplained. In this paper, a model-agnostic explainable method is\ndeveloped to provide users with further information regarding the reasons why a\nclinical trial is retrieved in response to a query. To accomplish this, the\nengine generates features from clinical trials using by using a knowledge\ngraph, clinical trial data and additional medical resources. and a\ncrowd-sourcing methodology is used to determine their importance. Grounded on\nthe proposed methodology, the rationale behind retrieving the clinical trials\nis explained in layman's terms so that healthcare processionals can\neffortlessly perceive them. In addition, we compute an explainability score for\neach of the retrieved items, according to which the items can be ranked. The\nexperiments validated by medical professionals suggest that the proposed\nmethodology induces trust in targeted as well as in non-targeted users, and\nprovide them with reliable explanations and ranking of retrieved items.",
    "descriptor": "",
    "authors": [
      "Edeline Contempr\u00e9",
      "Zolt\u00e1n Szl\u00e1vik",
      "Majid Mohammadi",
      "Erick Velazquez",
      "Annette ten Teije",
      "Ilaria Tiddi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12891"
  },
  {
    "id": "arXiv:2110.12894",
    "title": "The Efficiency Misnomer",
    "abstract": "Model efficiency is a critical aspect of developing and deploying machine\nlearning models. Inference time and latency directly affect the user\nexperience, and some applications have hard requirements. In addition to\ninference costs, model training also have direct financial and environmental\nimpacts. Although there are numerous well-established metrics (cost indicators)\nfor measuring model efficiency, researchers and practitioners often assume that\nthese metrics are correlated with each other and report only few of them. In\nthis paper, we thoroughly discuss common cost indicators, their advantages and\ndisadvantages, and how they can contradict each other. We demonstrate how\nincomplete reporting of cost indicators can lead to partial conclusions and a\nblurred or incomplete picture of the practical considerations of different\nmodels. We further present suggestions to improve reporting of efficiency\nmetrics.",
    "descriptor": "",
    "authors": [
      "Mostafa Dehghani",
      "Anurag Arnab",
      "Lucas Beyer",
      "Ashish Vaswani",
      "Yi Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12894"
  },
  {
    "id": "arXiv:2110.12895",
    "title": "QoS-based Trust Evaluation for Data Services as a Black Box",
    "abstract": "This paper proposes a QoS-based trust evaluation model for black box data\nservices. Under the black-box model, data services neither export (meta)-data\nabout conditions in which they are deployed and collect and process data nor\nthe quality of data they deliver. Therefore, the black-box model creates blind\nspots about the extent to which data providers can be trusted to be used to\nbuild target applications. The trust evaluation model for black box data\nservices introduced in this paper originally combines QoS indicators, like\nservice performance and data quality, to determine services trustworthiness.\nThe paper also introduces DETECT: a Data sErvice as a black box Trust\nEvaluation arChitecTure, that validates our model. The trust model and its\nassociated monitoring strategies have been assessed in experiments with\nrepresentative case studies. The results demonstrate the feasibility and\neffectiveness of our solution.",
    "descriptor": "\nComments: Long Version, short version ICWS 2021\n",
    "authors": [
      "Senda Romdhani",
      "Genoveva Vargas-Solar",
      "Nadia Bennani",
      "Chirine Ghedira-Guegan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12895"
  },
  {
    "id": "arXiv:2110.12896",
    "title": "Classification of PS and ABS Black Plastics for WEEE Recycling  Applications",
    "abstract": "Pollution and climate change are some of the biggest challenges that humanity\nis facing. In such a context, efficient recycling is a crucial tool for a\nsustainable future. This work is aimed at creating a system that can classify\ndifferent types of plastics by using picture analysis, in particular, black\nplastics of the type Polystyrene (PS) and Acrylonitrile Butadiene Styrene\n(ABS). They are two common plastics from Waste from Electrical and Electronic\nEquipment (WEEE). For this purpose, a Convolutional Neural Network has been\ntested and retrained, obtaining a validation accuracy of 95%. Using a separate\ntest set, average accuracy goes down to 86.6%, but a further look at the\nresults shows that the ABS type is correctly classified 100% of the time, so it\nis the PS type that accumulates all the errors. Overall, this demonstrates the\nfeasibility of classifying black plastics using CNN machine learning\ntechniques. It is believed that if a more diverse and extensive image dataset\nbecomes available, a system with higher reliability that generalizes well could\nbe developed using the proposed methodology.",
    "descriptor": "\nComments: Published at 8th Intl. Conference on Soft Computing & Machine Intelligence, ISCMI, Cairo, Egypt 26-27 November 2021\n",
    "authors": [
      "Anton Persson",
      "Niklas Dymne",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12896"
  },
  {
    "id": "arXiv:2110.12899",
    "title": "No One Representation to Rule Them All: Overlapping Features of Training  Methods",
    "abstract": "Despite being able to capture a range of features of the data, high accuracy\nmodels trained with supervision tend to make similar predictions. This\nseemingly implies that high-performing models share similar biases regardless\nof training methodology, which would limit ensembling benefits and render\nlow-accuracy models as having little practical use. Against this backdrop,\nrecent work has made very different training techniques, such as large-scale\ncontrastive learning, yield competitively-high accuracy on generalization and\nrobustness benchmarks. This motivates us to revisit the assumption that models\nnecessarily learn similar functions. We conduct a large-scale empirical study\nof models across hyper-parameters, architectures, frameworks, and datasets. We\nfind that model pairs that diverge more in training methodology display\ncategorically different generalization behavior, producing increasingly\nuncorrelated errors. We show these models specialize in subdomains of the data,\nleading to higher ensemble performance: with just 2 models (each with ImageNet\naccuracy ~76.5%), we can create ensembles with 83.4% (+7% boost). Surprisingly,\nwe find that even significantly low-accuracy models can be used to improve\nhigh-accuracy models. Finally, we show diverging training methodology yield\nrepresentations that capture overlapping (but not supersetting) feature sets\nwhich, when combined, lead to increased downstream performance.",
    "descriptor": "",
    "authors": [
      "Raphael Gontijo-Lopes",
      "Yann Dauphin",
      "Ekin D. Cubuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12899"
  },
  {
    "id": "arXiv:2110.12901",
    "title": "A First Polynomial Non-Clausal Class in Many-Valued Logic",
    "abstract": "The relevance of polynomial formula classes to deductive efficiency motivated\ntheir search, and currently, a great number of such classes is known.\nNonetheless, they have been exclusively sought in the setting of clausal form\nand propositional logic, which is of course expressively limiting for real\napplications. As a consequence, a first polynomial propositional class in\nnon-clausal (NC) form has recently been proposed. Along these lines and towards\nmaking NC tractability applicable beyond propositional logic, firstly, we\ndefine the Regular many-valued Horn Non-Clausal class, or RH, obtained by\nsuitably amalgamating both regular classes: Horn and NC. Secondly, we\ndemonstrate that the relationship between (1) RH and the regular Horn class is\nthat syntactically RH subsumes the Horn class but that both classes are\nequivalent semantically; and between (2) RH and the regular non-clausal class\nis that RH contains all NC formulas whose clausal form is Horn. Thirdly, we\ndefine Regular Non-Clausal Unit-Resolution, or RUR-NC , and prove both that it\nis complete for RH and that checks its satisfiability in polynomial time. The\nlatter fact shows that our intended goal is reached since RH is many-valued,\nnon-clausal and tractable. As RH and RUR-NC are, both, basic in the DPLL\nscheme, the most efficient in propositional logic, and can be extended to some\nother non-classical logics, we argue that they pave the way for efficient\nnon-clausal DPLL-based approximate reasoning.",
    "descriptor": "",
    "authors": [
      "Gonzalo E. Imaz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12901"
  },
  {
    "id": "arXiv:2110.12906",
    "title": "PPSGCN: A Privacy-Preserving Subgraph Sampling Based Distributed GCN  Training Method",
    "abstract": "Graph convolutional networks (GCNs) have been widely adopted for graph\nrepresentation learning and achieved impressive performance. For larger graphs\nstored separately on different clients, distributed GCN training algorithms\nwere proposed to improve efficiency and scalability. However, existing methods\ndirectly exchange node features between different clients, which results in\ndata privacy leakage. Federated learning was incorporated in graph learning to\ntackle data privacy, while they suffer from severe performance drop due to\nnon-iid data distribution. Besides, these approaches generally involve heavy\ncommunication and memory overhead during the training process. In light of\nthese problems, we propose a Privacy-Preserving Subgraph sampling based\ndistributed GCN training method (PPSGCN), which preserves data privacy and\nsignificantly cuts back on communication and memory overhead. Specifically,\nPPSGCN employs a star-topology client-server system. We firstly sample a local\nnode subset in each client to form a global subgraph, which greatly reduces\ncommunication and memory costs. We then conduct local computation on each\nclient with features or gradients of the sampled nodes. Finally, all clients\nsecurely communicate with the central server with homomorphic encryption to\ncombine local results while preserving data privacy. Compared with federated\ngraph learning methods, our PPSGCN model is trained on a global graph to avoid\nthe negative impact of local data distribution. We prove that our PPSGCN\nalgorithm would converge to a local optimum with probability 1. Experiment\nresults on three prevalent benchmarks demonstrate that our algorithm\nsignificantly reduces communication and memory overhead while maintaining\ndesirable performance. Further studies not only demonstrate the fast\nconvergence of PPSGCN, but discuss the trade-off between communication and\nlocal computation cost as well.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Binchi Zhang",
      "Minnan Luo",
      "Shangbin Feng",
      "Ziqi Liu",
      "Jun Zhou",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12906"
  },
  {
    "id": "arXiv:2110.12908",
    "title": "Learning to run a power network with trust",
    "abstract": "Artificial agents are promising for realtime power system operations,\nparticularly, to compute remedial actions for congestion management. Currently,\nthese agents are limited to only autonomously run by themselves. However,\nautonomous agents will not be deployed any time soon. Operators will still be\nin charge of taking action in the future. Aiming at designing an assistant for\noperators, we here consider humans in the loop and propose an original\nformulation for this problem. We first advance an agent with the ability to\nsend to the operator alarms ahead of time when the proposed actions are of low\nconfidence. We further model the operator's available attention as a budget\nthat decreases when alarms are sent. We present the design and results of our\ncompetition \"Learning to run a power network with trust\" in which we benchmark\nthe ability of submitted agents to send relevant alarms while operating the\nnetwork to their best.",
    "descriptor": "",
    "authors": [
      "Antoine Marot",
      "Benjamin Donnot",
      "Karim Chaouache",
      "Adrian Kelly",
      "Qiuhua Huang",
      "Ramij-Raja Hossain",
      "Jochen L. Cremer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12908"
  },
  {
    "id": "arXiv:2110.12909",
    "title": "Formal Verification of the Ethereum 2.0 Beacon Chain",
    "abstract": "We report our experience in the formal verification of the reference\nimplementation of the Beacon Chain. The Beacon Chain is the backbone component\nof the new Proof-of-Stake Ethereum 2.0 network: it is in charge of tracking\ninformation about the validators, their stakes, their attestations (votes) and\nif some validators are found to be dishonest, to slash them (they lose some of\ntheir stakes). The Beacon Chain is mission-critical and any bug in it could\ncompromise the whole network. The Beacon Chain reference implementation\ndeveloped by the Ethereum Foundation is written in Python, and provides a\ndetailed operational description of the state machine each Beacon Chain's\nnetwork participant (node) must implement. We have formally specified and\nverified the absence of runtime errors in (a large and critical part of) the\nBeacon Chain reference implementation using the verification-friendly language\nDafny. During the course of this work, we have uncovered several issues,\nproposed verified fixes. We have also synthesised functional correctness\nspecifications that enable us to provide guarantees beyond runtime errors. Our\nsoftware artefact is available at https://github.com/ConsenSys/eth2.0-dafny.",
    "descriptor": "",
    "authors": [
      "Franck Cassez",
      "Joanne Fuller",
      "Aditya Asgaonkar"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.12909"
  },
  {
    "id": "arXiv:2110.12911",
    "title": "Instance-Dependent Partial Label Learning",
    "abstract": "Partial label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training example is associated with a set of candidate labels among\nwhich only one is true. Most existing PLL approaches assume that the incorrect\nlabels in each training example are randomly picked as the candidate labels.\nHowever, this assumption is not realistic since the candidate labels are always\ninstance-dependent. In this paper, we consider instance-dependent PLL and\nassume that each example is associated with a latent label distribution\nconstituted by the real number of each label, representing the degree to each\nlabel describing the feature. The incorrect label with a high degree is more\nlikely to be annotated as the candidate label. Therefore, the latent label\ndistribution is the essential labeling information in partially labeled\nexamples and worth being leveraged for predictive model training. Motivated by\nthis consideration, we propose a novel PLL method that recovers the label\ndistribution as a label enhancement (LE) process and trains the predictive\nmodel iteratively in every epoch. Specifically, we assume the true posterior\ndensity of the latent label distribution takes on the variational approximate\nDirichlet density parameterized by an inference model. Then the evidence lower\nbound is deduced for optimizing the inference model and the label distributions\ngenerated from the variational posterior are utilized for training the\npredictive model. Experiments on benchmark and real-world datasets validate the\neffectiveness of the proposed method. Source code is available at\nhttps://github.com/palm-ml/valen.",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight\n",
    "authors": [
      "Ning Xu",
      "Congyu Qiao",
      "Xin Geng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12911"
  },
  {
    "id": "arXiv:2110.12914",
    "title": "SILT: Self-supervised Lighting Transfer Using Implicit Image  Decomposition",
    "abstract": "We present SILT, a Self-supervised Implicit Lighting Transfer method. Unlike\nprevious research on scene relighting, we do not seek to apply arbitrary new\nlighting configurations to a given scene. Instead, we wish to transfer the\nlighting style from a database of other scenes, to provide a uniform lighting\nstyle regardless of the input. The solution operates as a two-branch network\nthat first aims to map input images of any arbitrary lighting style to a\nunified domain, with extra guidance achieved through implicit image\ndecomposition. We then remap this unified input domain using a discriminator\nthat is presented with the generated outputs and the style reference, i.e.\nimages of the desired illumination conditions. Our method is shown to\noutperform supervised relighting solutions across two different datasets\nwithout requiring lighting supervision.",
    "descriptor": "\nComments: Accepted to BMVC 2021. The code and pre-trained models can be found at this https URL\n",
    "authors": [
      "Nikolina Kubiak",
      "Armin Mustafa",
      "Graeme Phillipson",
      "Stephen Jolly",
      "Simon Hadfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.12914"
  },
  {
    "id": "arXiv:2110.12916",
    "title": "On Slowly-varying Non-stationary Bandits",
    "abstract": "We consider minimisation of dynamic regret in non-stationary bandits with a\nslowly varying property. Namely, we assume that arms' rewards are stochastic\nand independent over time, but that the absolute difference between the\nexpected rewards of any arm at any two consecutive time-steps is at most a\ndrift limit $\\delta > 0$. For this setting that has not received enough\nattention in the past, we give a new algorithm which extends naturally the\nwell-known Successive Elimination algorithm to the non-stationary bandit\nsetting. We establish the first instance-dependent regret upper bound for\nslowly varying non-stationary bandits. The analysis in turn relies on a novel\ncharacterization of the instance as a detectable gap profile that depends on\nthe expected arm reward differences. We also provide the first minimax regret\nlower bound for this problem, enabling us to show that our algorithm is\nessentially minimax optimal. Also, this lower bound we obtain matches that of\nthe more general total variation-budgeted bandits problem, establishing that\nthe seemingly easier former problem is at least as hard as the more general\nlatter problem in the minimax sense. We complement our theoretical results with\nexperimental illustrations.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Ramakrishnan Krishnamurthy",
      "Aditya Gopalan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12916"
  },
  {
    "id": "arXiv:2110.12919",
    "title": "WOLF: A modular estimation framework for robotics based on factor graphs",
    "abstract": "This paper introduces WOLF, a C++ estimation framework based on factor graphs\nand targeted at mobile robotics. WOLF extends the applications of factor graphs\nfrom the typical problems of SLAM and odometry to a general estimation\nframework able to handle self-calibration, model identification, or the\nobservation of dynamic quantities other than localization. WOLF produces high\nthroughput estimates at sensor rates up to the kHz range, which can be used for\nfeedback control of highly dynamic robots such as humanoids, quadrupeds or\naerial manipulators. Departing from the factor graph paradigm, the architecture\nof WOLF allows for a modular yet tightly-coupled estimator. Modularity is based\non plugins that are loaded at runtime. Then, integration is achieved simply\nthrough YAML files, allowing users to configure a wide range of applications\nwithout the need of writing or compiling code. Synchronization of incoming data\nand their processing into a unique factor graph is achieved through a\ndecentralized strategy of frame creation and joining. Most algorithmic assets\nare coded as abstract algorithms in base classes with varying levels of\nspecialization. Overall, these assets allow for coherent processing and favor\ncode reusability and scalability. WOLF can be interfaced with different\nsolvers, and we provide a wrapper to Google Ceres. Likewise, we offer ROS\nintegration, providing a generic ROS node and specialized packages with\nsubscribers and publishers. WOLF is made publicly available and open to\ncollaboration.",
    "descriptor": "\nComments: 8 pages, 12 figures. v1: removed repository link\n",
    "authors": [
      "Joan Sola",
      "Joan Vallve-Navarro",
      "Joaquim Casals",
      "Jeremie Deray",
      "Mederic Fourmy",
      "Dinesh Atchuthan",
      "Juan Andrade-Cetto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12919"
  },
  {
    "id": "arXiv:2110.12923",
    "title": "Spoofing Detection on Hand Images Using Quality Assessment",
    "abstract": "Recent research on biometrics focuses on achieving a high success rate of\nauthentication and addressing the concern of various spoofing attacks. Although\nhand geometry recognition provides adequate security over unauthorized access,\nit is susceptible to presentation attack. This paper presents an anti-spoofing\nmethod toward hand biometrics. A presentation attack detection approach is\naddressed by assessing the visual quality of genuine and fake hand images. A\nthreshold-based gradient magnitude similarity quality metric is proposed to\ndiscriminate between the real and spoofed hand samples. The visual hand images\nof 255 subjects from the Bogazici University hand database are considered as\noriginal samples. Correspondingly, from each genuine sample, we acquire a\nforged image using a Canon EOS 700D camera. Such fake hand images with natural\ndegradation are considered for electronic screen display based spoofing attack\ndetection. Furthermore, we create another fake hand dataset with artificial\ndegradation by introducing additional Gaussian blur, salt and pepper, and\nspeckle noises to original images. Ten quality metrics are measured from each\nsample for classification between original and fake hand image. The\nclassification experiments are performed using the k-nearest neighbors, random\nforest, and support vector machine classifiers, as well as deep convolutional\nneural networks. The proposed gradient similarity-based quality metric achieves\n1.5% average classification er ror using the k-nearest neighbors and random\nforest classifiers. An average classification error of 2.5% is obtained using\nthe baseline evaluation with the MobileNetV2 deep network for discriminating\noriginal and different types of fake hand samples.",
    "descriptor": "",
    "authors": [
      "Asish Bera",
      "Ratnadeep Dey",
      "Debotosh Bhattacharjee",
      "Mita Nasipuri",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12923"
  },
  {
    "id": "arXiv:2110.12924",
    "title": "On Enumerating Short Projected Models",
    "abstract": "Propositional model enumeration, or All-SAT, is the task to record all models\nof a propositional formula. It is a key task in software and hardware\nverification, system engineering, and predicate abstraction, to mention a few.\nIt also provides a means to convert a CNF formula into DNF, which is relevant\nin circuit design. While in some applications enumerating models multiple times\ncauses no harm, in others avoiding repetitions is crucial. We therefore present\ntwo model enumeration algorithms, which adopt dual reasoning in order to\nshorten the found models. The first method enumerates pairwise contradicting\nmodels. Repetitions are avoided by the use of so-called blocking clauses, for\nwhich we provide a dual encoding. In our second approach we relax the\nuniqueness constraint. We present an adaptation of the standard conflict-driven\nclause learning procedure to support model enumeration without blocking\nclauses.Our procedures are expressed by means of a calculus and proofs of\ncorrectness are provided.",
    "descriptor": "",
    "authors": [
      "Sibylle M\u00f6hle",
      "Roberto Sebastiani",
      "Armin Biere"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.12924"
  },
  {
    "id": "arXiv:2110.12925",
    "title": "CoProtector: Protect Open-Source Code against Unauthorized Training  Usage with Data Poisoning",
    "abstract": "Github Copilot, trained on billions of lines of public code, has recently\nbecome the buzzword in the computer science research and practice community.\nAlthough it is designed to provide powerful intelligence to help developers\nimplement safe and effective code, practitioners and researchers raise concerns\nabout its ethical and security problems, e.g., should the copyleft licensed\ncode be freely leveraged or insecure code be considered for training in the\nfirst place? These problems pose a significant impact on Copilot and other\nsimilar products that aim to learn knowledge from large-scale source code\nthrough deep learning models, which are inevitably on the rise with the fast\ndevelopment of artificial intelligence. To mitigate such impacts, we argue that\nthere is a need to invent effective mechanisms for protecting open-source code\nfrom being exploited by deep learning models. To this end, we design and\nimplement a prototype, CoProtector, which utilizes data poisoning techniques to\narm source code repositories for defending against such exploits. Our\nlarge-scale experiments empirically show that CoProtector is effective in\nachieving its purpose, significantly reducing the performance of Copilot-like\ndeep learning models while being able to stably reveal the secretly embedded\nwatermark backdoors.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zhensu Sun",
      "Xiaoning Du",
      "Fu Song",
      "Mingze Ni",
      "Li Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12925"
  },
  {
    "id": "arXiv:2110.12932",
    "title": "A spatiotemporal two-level method for high-fidelity thermal analysis of  laserpowder bed fusion",
    "abstract": "Numerical simulation of the laser powder bed fusion (LPBF) procedure for\nadditive manufacturing (AM) is difficult due to the presence of multiple scales\nin both time and space, ranging from the part scale (order of\nmillimeters/seconds) to the powder scale (order of microns/milliseconds). This\ndifficulty is compounded by the fact that the regions of small-scale behavior\nare not fixed, but change in time as the geometry is produced. While much work\nin recent years has been focused on resolving the problem of multiple scales in\nspace, there has been less work done on multiscale approaches for the temporal\ndiscretization of LPBF problems. In the present contribution, we extend on a\npreviously introduced two-level method in space by combining it with a\nmultiscale time integration method. The unique transfer of information through\nthe transmission conditions allows for interaction between the space and time\nscales while reducing computational costs. At the same time, all of the\nadvantages of the two-level method in space (namely its geometrical flexibility\nand the ease in which one may deploy structured, uniform meshes) remain intact.\nAdopting the proposed multiscale time integration scheme, we observe a\ncomputational speed-up by a factor $\\times 2.44$ compared to the same two-level\napproach with uniform time integration, when simulating a laser source\ntraveling on a bare plate of nickel-based superalloy material following an\nalternating scan path of fifty laser tracks.",
    "descriptor": "",
    "authors": [
      "Alex Viguerie",
      "Massimo Carraturo",
      "Alessandro Reali",
      "Ferdinando Auricchio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12932"
  },
  {
    "id": "arXiv:2110.12933",
    "title": "Computing elements of certain form in ideals to prove properties of  operators",
    "abstract": "Proving statements about linear operators expressed in terms of identities\noften leads to finding elements of certain form in noncommutative polynomial\nideals. We illustrate this by examples coming from actual operator statements\nand discuss relevant algorithmic methods for finding such polynomials based on\nnoncommutative Gr\\\"obner bases. In particular, we present algorithms for\ncomputing the intersection of a two-sided ideal with a one-sided ideal as well\nas for computing homogeneous polynomials in two-sided ideals and monomials in\none-sided ideals. All methods presented in this work are implemented in the\nMathematica package OperatorGB.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Clemens Hofstadler",
      "Clemens G. Raab",
      "Georg Regensburger"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.12933"
  },
  {
    "id": "arXiv:2110.12935",
    "title": "Normative Epistemology for Lethal Autonomous Weapons Systems",
    "abstract": "The rise of human-information systems, cybernetic systems, and increasingly\nautonomous systems requires the application of epistemic frameworks to machines\nand human-machine teams. This chapter discusses higher-order design principles\nto guide the design, evaluation, deployment, and iteration of Lethal Autonomous\nWeapons Systems (LAWS) based on epistemic models. Epistemology is the study of\nknowledge. Epistemic models consider the role of accuracy, likelihoods,\nbeliefs, competencies, capabilities, context, and luck in the justification of\nactions and the attribution of knowledge. The aim is not to provide ethical\njustification for or against LAWS, but to illustrate how epistemological\nframeworks can be used in conjunction with moral apparatus to guide the design\nand deployment of future systems. The models discussed in this chapter aim to\nmake Article 36 reviews of LAWS systematic, expedient, and evaluable. A\nBayesian virtue epistemology is proposed to enable justified actions under\nuncertainty that meet the requirements of the Laws of Armed Conflict and\nInternational Humanitarian Law. Epistemic concepts can provide some of the\napparatus to meet explainability and transparency requirements in the\ndevelopment, evaluation, deployment, and review of ethical AI.",
    "descriptor": "\nComments: 30 pages, published in Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare. Oxford University Press 2021\n",
    "authors": [
      "Susannah Kate Devitt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12935"
  },
  {
    "id": "arXiv:2110.12937",
    "title": "Improving Software Engineering Research through Experimentation  Workbenches",
    "abstract": "Experimentation with software prototypes plays a fundamental role in software\nengineering research. In contrast to many other scientific disciplines,\nhowever, explicit support for this key activity in software engineering is\nrelatively small. While some approaches to improve this situation have been\nproposed by the software engineering community, experiments are still very\ndifficult and sometimes impossible to replicate. In this paper, we propose the\nconcept of an experimentation workbench as a means of explicit support for\nexperimentation in software engineering research. In particular, we discuss\ncore requirements that an experimentation workbench should satisfy in order to\nqualify as such and to offer a real benefit for researchers. Beyond their core\nbenefits for experimentation, we stipulate that experimentation workbenches\nwill also have benefits in regard to reproducibility and repeatability of\nsoftware engineering research. Further, we illustrate this concept with a\nscenario and a case study, and describe relevant challenges as well as our\nexperience with experimentation workbenches.",
    "descriptor": "",
    "authors": [
      "Klaus Schmid",
      "Sascha El-Sharkawy",
      "Christian Kr\u00f6her"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12937"
  },
  {
    "id": "arXiv:2110.12938",
    "title": "Ultra-Dense LEO Satellite-based Communication Systems: A Novel Modeling  Technique",
    "abstract": "Low earth orbit (LEO) satellite plays an indispensable role in the earth\nnetwork because of its low latency, large capacity, and seamless global\ncoverage. For such an unprecedented extensive irregular system, stochastic\ngeometry (SG) is a suitable research method. The SG model can not only cope\nwith the increasing network scale but also accurately analyze and estimate the\nnetwork's performance. Several standard satellite distribution models and\nsatellite-ground channel models are investigated in this paper. System-level\nmetrics such as coverage probability and their intermediates are introduced in\nthe non-technical description. Then, the influence of some factors on latency\nand coverage probability is studied. Finally, this paper presents the possible\nchallenges and corresponding solutions for the SG-based LEO satellite system\nanalysis.",
    "descriptor": "",
    "authors": [
      "Ruibo Wang",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12938"
  },
  {
    "id": "arXiv:2110.12940",
    "title": "CoboGuider: Haptic Potential Fields for Safe Human-Robot Interaction",
    "abstract": "Modern industry still relies on manual manufacturing operations and safe\nhuman-robot interaction is of great interest nowadays. Speed and Separation\nMonitoring (SSM) allows close and efficient collaborative scenarios by\nmaintaining a protective separation distance during robot operation. The paper\nfocuses on a novel approach to strengthen the SSM safety requirements by\nintroducing haptic feedback to a robotic cell worker. Tactile stimuli provide\nearly warning of dangerous movements and proximity to the robot, based on the\nhuman reaction time and instantaneous velocities of robot and operator. A\npreliminary experiment was performed to identify the reaction time of\nparticipants when they are exposed to tactile stimuli in a collaborative\nenvironment with controlled conditions. In a second experiment, we evaluated\nour approach into a study case where human worker and cobot performed\ncollaborative planetary gear assembly. Results show that the applied approach\nincreased the average minimum distance between the robot's end-effector and\nhand by 44% compared to the operator relying only on the visual feedback.\nMoreover, the participants without the haptic support have failed several times\nto maintain the protective separation distance.",
    "descriptor": "\nComments: Accepted paper in SMC conference 2021, IEEE copyright\n",
    "authors": [
      "Viktor Rakhmatulin",
      "Miguel Altamirano Cabrera",
      "Fikre Hagos",
      "Oleg Sautenkov",
      "Jonathan Tirado",
      "Ighor Uzhinsky",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12940"
  },
  {
    "id": "arXiv:2110.12942",
    "title": "DocTr: Document Image Transformer for Geometric Unwarping and  Illumination Correction",
    "abstract": "In this work, we propose a new framework, called Document Image Transformer\n(DocTr), to address the issue of geometry and illumination distortion of the\ndocument images. Specifically, DocTr consists of a geometric unwarping\ntransformer and an illumination correction transformer. By setting a set of\nlearned query embedding, the geometric unwarping transformer captures the\nglobal context of the document image by self-attention mechanism and decodes\nthe pixel-wise displacement solution to correct the geometric distortion. After\ngeometric unwarping, our illumination correction transformer further removes\nthe shading artifacts to improve the visual quality and OCR accuracy. Extensive\nevaluations are conducted on several datasets, and superior results are\nreported against the state-of-the-art methods. Remarkably, our DocTr achieves\n20.02% Character Error Rate (CER), a 15% absolute improvement over the\nstate-of-the-art methods. Moreover, it also shows high efficiency on running\ntime and parameter count. The results will be available at\nhttps://github.com/fh2019ustc/DocTr for further comparison.",
    "descriptor": "\nComments: This paper has been accepted by ACM Multimedia 2021\n",
    "authors": [
      "Hao Feng",
      "Yuechen Wang",
      "Wengang Zhou",
      "Jiajun Deng",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12942"
  },
  {
    "id": "arXiv:2110.12945",
    "title": "Optimal Transmit Beamforming for Secrecy Integrated Sensing and  Communication",
    "abstract": "This paper studies a secrecy integrated sensing and communication (ISAC)\nsystem, in which a multi-antenna base station (BS) aims to send confidential\nmessages to a single-antenna communication user (CU), and at the same time\nsense several targets that may be suspicious eavesdroppers. To ensure the\nsensing quality while preventing the eavesdropping, we consider that the BS\nsends dedicated sensing signals (in addition to confidential information\nsignals) that play a dual role of artificial noise (AN) for confusing the\neavesdropping targets. Under this setup, we jointly optimize the transmit\ninformation and sensing beamforming at the BS, to minimize the matching error\nbetween the transmit beampattern and a desired beampattern for sensing, subject\nto the minimum secrecy rate requirement at the CU and the transmit power\nconstraint at the BS. Although the formulated problem is non-convex, we propose\nan algorithm to obtain the globally optimal solution by using the semidefinite\nrelaxation (SDR) together with a one-dimensional (1D) search. Next, to avoid\nthe high complexity induced by the 1D search, we also present two sub-optimal\nsolutions based on zero-forcing and separate beamforming designs, respectively.\nNumerical results show that the proposed designs properly adjust the\ninformation and sensing beams to balance the tradeoffs among communicating with\nCU, sensing targets, and confusing eavesdroppers, thus achieving desirable\ntransmit beampattern for sensing while ensuring the CU's secrecy rate.",
    "descriptor": "",
    "authors": [
      "Zixiang Ren",
      "Ling Qiu",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12945"
  },
  {
    "id": "arXiv:2110.12946",
    "title": "Optimal Model Averaging: Towards Personalized Collaborative Learning",
    "abstract": "In federated learning, differences in the data or objectives between the\nparticipating nodes motivate approaches to train a personalized machine\nlearning model for each node. One such approach is weighted averaging between a\nlocally trained model and the global model. In this theoretical work, we study\nweighted model averaging for arbitrary scalar mean estimation problems under\nminimal assumptions on the distributions. In a variant of the bias-variance\ntrade-off, we find that there is always some positive amount of model averaging\nthat reduces the expected squared error compared to the local model, provided\nonly that the local model has a non-zero variance. Further, we quantify the\n(possibly negative) benefit of weighted model averaging as a function of the\nweight used and the optimal weight. Taken together, this work formalizes an\napproach to quantify the value of personalization in collaborative learning and\nprovides a framework for future research to test the findings in multivariate\nparameter estimation and under a range of assumptions.",
    "descriptor": "\nComments: 9 pages (12 pages incl. references and appendix), 1 figure, Best Paper at International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021 (FL-ICML'21) ( https://web.archive.org/web/20210908135923/this http URL )\n",
    "authors": [
      "Felix Grimberg",
      "Mary-Anne Hartley",
      "Sai P. Karimireddy",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12946"
  },
  {
    "id": "arXiv:2110.12948",
    "title": "Generating Watermarked Adversarial Texts",
    "abstract": "Adversarial example generation has been a hot spot in recent years because it\ncan cause deep neural networks (DNNs) to misclassify the generated adversarial\nexamples, which reveals the vulnerability of DNNs, motivating us to find good\nsolutions to improve the robustness of DNN models. Due to the extensiveness and\nhigh liquidity of natural language over the social networks, various natural\nlanguage based adversarial attack algorithms have been proposed in the\nliterature. These algorithms generate adversarial text examples with high\nsemantic quality. However, the generated adversarial text examples may be\nmaliciously or illegally used. In order to tackle with this problem, we present\na general framework for generating watermarked adversarial text examples. For\neach word in a given text, a set of candidate words are determined to ensure\nthat all the words in the set can be used to either carry secret bits or\nfacilitate the construction of adversarial example. By applying a word-level\nadversarial text generation algorithm, the watermarked adversarial text example\ncan be finally generated. Experiments show that the adversarial text examples\ngenerated by the proposed method not only successfully fool advanced DNN\nmodels, but also carry a watermark that can effectively verify the ownership\nand trace the source of the adversarial examples. Moreover, the watermark can\nstill survive after attacked with adversarial example generation algorithms,\nwhich has shown the applicability and superiority.",
    "descriptor": "\nComments: this https URL&hl=en\n",
    "authors": [
      "Mingjie Li",
      "Hanzhou Wu",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.12948"
  },
  {
    "id": "arXiv:2110.12949",
    "title": "Persona Authentication through Generative Dialogue",
    "abstract": "In this paper we define and investigate the problem of \\emph{persona\nauthentication}: learning a conversational policy to verify the consistency of\npersona models. We propose a learning objective and prove (under some mild\nassumptions) that local density estimators trained under this objective\nmaximize the mutual information between persona information and dialog\ntrajectory. Based on the proposed objective, we develop a method of learning an\nauthentication model that adaptively outputs personalized questions to reveal\nthe underlying persona of its partner throughout the course of multi-turn\nconversation. Experiments show that our authentication method discovers\neffective question sequences that generalize to unseen persona profiles.",
    "descriptor": "",
    "authors": [
      "Fengyi Tang",
      "Lifan Zeng",
      "Fei Wang",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12949"
  },
  {
    "id": "arXiv:2110.12951",
    "title": "Seeing biodiversity: perspectives in machine learning for wildlife  conservation",
    "abstract": "Data acquisition in animal ecology is rapidly accelerating due to inexpensive\nand accessible sensors such as smartphones, drones, satellites, audio recorders\nand bio-logging devices. These new technologies and the data they generate hold\ngreat potential for large-scale environmental monitoring and understanding, but\nare limited by current data processing approaches which are inefficient in how\nthey ingest, digest, and distill data into relevant information. We argue that\nmachine learning, and especially deep learning approaches, can meet this\nanalytic challenge to enhance our understanding, monitoring capacity, and\nconservation of wildlife species. Incorporating machine learning into\necological workflows could improve inputs for population and behavior models\nand eventually lead to integrated hybrid modeling tools, with ecological models\nacting as constraints for machine learning models and the latter providing\ndata-supported insights. In essence, by combining new machine learning\napproaches with ecological domain knowledge, animal ecologists can capitalize\non the abundance of data generated by modern sensor technologies in order to\nreliably estimate population abundances, study animal behavior and mitigate\nhuman/wildlife conflicts. To succeed, this approach will require close\ncollaboration and cross-disciplinary education between the computer science and\nanimal ecology communities in order to ensure the quality of machine learning\napproaches and train a new generation of data scientists in ecology and\nconservation.",
    "descriptor": "",
    "authors": [
      "Devis Tuia",
      "Benjamin Kellenberger",
      "Sara Beery",
      "Blair R. Costelloe",
      "Silvia Zuffi",
      "Benjamin Risse",
      "Alexander Mathis",
      "Mackenzie W. Mathis",
      "Frank van Langevelde",
      "Tilo Burghardt",
      "Roland Kays",
      "Holger Klinck",
      "Martin Wikelski",
      "Iain D. Couzin",
      "Grant van Horn",
      "Margaret C. Crofoot",
      "Charles V. Stewart",
      "Tanya Berger-Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12951"
  },
  {
    "id": "arXiv:2110.12952",
    "title": "Accelerating Compact Fractals with Tensor Core GPUs",
    "abstract": "This work presents a GPU thread mapping approach that allows doing fast\nparallel stencil-like computations on discrete fractals using their compact\nrepresentation. The intuition behind is to employ two GPU tensor-core\naccelerated thread maps, $\\lambda(\\omega)$ and $\\nu(\\omega)$, which act as\nthreadspace-to-dataspace and dataspace-to-threadspace functions, respectively.\nBy combining these maps, threads can access compact space and interact with\ntheir neighbors. The cost of the maps is $\\mathcal{O}(\\log \\log(n))$ time, with\n$n$ being the side of a $n \\times n$ embedding for the fractal in its expanded\nform. The technique works on any fractal that belongs to the\nNon-overlapping-Bounding-Boxes (NBB) class of discrete fractals, and can be\nextended to three dimensions as well. Results using an A100 GPU on the\nSierpinski Triangle as a case study show up to $\\sim11\\times$ of speedup and a\nmemory usage reduction of $234\\times$ with respect to a Bounding Box approach.\nThese results show that the proposed compact approach can allow the scientific\ncommunity to tackle larger problems that did not fit in GPU memory before, and\nrun even faster than a bounding box approach.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Felipe A. Quezada",
      "Crist\u00f3bal A. Navarro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.12952"
  },
  {
    "id": "arXiv:2110.12954",
    "title": "Fast Multimodal Journey Planning for Three Criteria",
    "abstract": "We study the journey planning problem for multimodal networks consisting of\npublic transit and a non-schedule-based transfer mode (e.g., walking, bicycle,\ne-scooter). So far, all efficient algorithms for this problem either restrict\nusage of the transfer mode or Pareto-optimize only two criteria: arrival time\nand the number of used public transit trips. However, we show that both\nlimitations must be lifted in order to obtain high-quality solutions. In\nparticular, the time spent using the (unrestricted) transfer mode must be\noptimized as a third criterion. We present McTB, the first algorithm that\noptimizes three criteria efficiently by avoiding costly data structures for\nmaintaining Pareto sets. To enable unlimited transfers, we combine it with a\nthree-criteria extension of the ULTRA preprocessing technique. Furthermore,\nsince full Pareto sets become impractically large for more than two criteria,\nwe adapt an approach by Delling et al. to restrict the Pareto set in a\nmethodical manner. Extensive experiments on real-world data show that our\nalgorithms are fast enough for interactive queries even on large country-sized\nnetworks. Compared to the state of the art for multicriteria multimodal journey\nplanning, MCR, we achieve a speedup of up to 80.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Moritz Potthoff",
      "Jonas Sauer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.12954"
  },
  {
    "id": "arXiv:2110.12962",
    "title": "Event Data Association via Robust Model Fitting for Event-based Object  Tracking",
    "abstract": "Event-based approaches, which are based on bio-inspired asynchronous event\ncameras, have achieved promising performance on various computer vision tasks.\nHowever, the study of the fundamental event data association problem is still\nin its infancy. In this paper, we propose a novel Event Data Association\napproach (called EDA) to explicitly address the data association problem. The\nproposed EDA seeks for event trajectories that best fit the event data, in\norder to perform unifying data association. In EDA, we first asynchronously\ngather the event data, based on its information entropy. Then, we introduce a\ndeterministic model hypothesis generation strategy, which effectively generates\nmodel hypotheses from the gathered events, to represent the corresponding event\ntrajectories. After that, we present a two-stage weighting algorithm, which\nrobustly weighs and selects true models from the generated model hypotheses,\nthrough multi-structural geometric model fitting. Meanwhile, we also propose an\nadaptive model selection strategy to automatically determine the number of the\ntrue models. Finally, we use the selected true models to associate the event\ndata, without being affected by sensor noise and irrelevant structures. We\nevaluate the performance of the proposed EDA on the object tracking task. The\nexperimental results show the effectiveness of EDA under challenging scenarios,\nsuch as high speed, motion blur, and high dynamic range conditions.",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Haosheng Chen",
      "Shuyuan Lin",
      "David Suter",
      "Yan Yan",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12962"
  },
  {
    "id": "arXiv:2110.12963",
    "title": "Anomaly-Based Intrusion Detection System for Cyber-Physical System  Security",
    "abstract": "Over the past decade, industrial control systems have experienced a massive\nintegration with information technologies. Industrial networks have undergone\nnumerous technical transformations to protect operational and production\nprocesses, leading today to a new industrial revolution. Information Technology\ntools are not able to guarantee confidentiality, integrity and availability in\nthe industrial domain, therefore it is of paramount importance to understand\nthe interaction of the physical components with the networks. For this reason,\nusually, the industrial control systems are an example of Cyber-Physical\nSystems (CPS). This paper aims to provide a tool for the detection of cyber\nattacks in cyber-physical systems. This method is based on Machine Learning to\nincrease the security of the system. Through the analysis of the values assumed\nby Machine Learning it is possible to evaluate the classification performance\nof the three models. The model obtained using the training set, allows to\nclassify a sample of anomalous behavior and a sample that is related to normal\nbehavior. The attack identification is implemented in water tank system, and\nthe identification approach using Machine Learning aims to avoid dangerous\nstates, such as the overflow of a tank. The results are promising,\ndemonstrating its effectiveness.",
    "descriptor": "",
    "authors": [
      "Riccardo Colelli",
      "Filippo Magri",
      "Stefano Panzieri",
      "Federica Pascucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12963"
  },
  {
    "id": "arXiv:2110.12968",
    "title": "Semantic Detection of Potential Wind-borne Debris in Construction  Jobsites: Digital Twining for Hurricane Preparedness and Jobsite Safety",
    "abstract": "In the United States, hurricanes are the most devastating natural disasters\ncausing billions of dollars worth of damage every year. More importantly,\nconstruction jobsites are classified among the most vulnerable environments to\nsevere wind events. During hurricanes, unsecured and incomplete elements of\nconstruction sites, such as scaffoldings, plywoods, and metal rods, will become\nthe potential wind-borne debris, causing cascading damages to the construction\nprojects and the neighboring communities. Thus, it is no wonder that\nconstruction firms implement jobsite emergency plans to enforce preparedness\nresponses before extreme weather events. However, relying on checklist-based\nemergency action plans to carry out a thorough hurricane preparedness is\nchallenging in large-scale and complex site environments. For enabling\nsystematic responses for hurricane preparedness, we have proposed a\nvision-based technique to identify and analyze the potential wind-borne debris\nin construction jobsites. Building on this, this paper demonstrates the\nfidelity of a new machine vision-based method to support construction site\nhurricane preparedness and further discuss its implications. The outcomes\nindicate that the convenience of visual data collection and the advantages of\nthe machine vision-based frameworks enable rapid scene understanding and thus,\nprovide critical heads up for practitioners to recognize and localize the\npotential wind-borne derbies in construction jobsites and effectively implement\nhurricane preparedness.",
    "descriptor": "\nComments: This paper has been accepted in i3CE(2021) conference\n",
    "authors": [
      "Mirsalar Kamari",
      "Youngjib Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12968"
  },
  {
    "id": "arXiv:2110.12974",
    "title": "Blockchain application in simulated environment for Cyber-Physical  Systems Security",
    "abstract": "Critical Infrastructures (CIs) such as power grid, water and gas distribution\nare controlled by Industrial Control Systems (ICS). Sensors and actuators of a\nphysical plant are managed by the ICS. Data and commands transmitted over the\nnetwork from the Programmable Logic Controllers (PLCs) are saved and parsed\nwithin the Historian. Generally, this architecture guarantees to check for any\nprocess anomalies that may occur due to component failures and cyber attacks.\nThe other use of this data allows activities such as forensic analysis. To\nsecure the network is also crucial to protect the communication between\ndevices. A cyber attack on the log devices could jeopardize any forensic\nanalysis be it for maintenance, or discovering an attack trail. In this paper\nis proposed a strategy to secure plant operational data recorded in the\nHistorian and data exchange in the network. An integrity checking mechanism, in\ncombination with blockchain, is used to ensure data integrity. Data redundancy\nis achieved by applying an efficient replication mechanism and enables data\nrecovery after an attack.",
    "descriptor": "",
    "authors": [
      "Riccardo Colelli",
      "Chiara Foglietta",
      "Roberto Fusacchia",
      "Stefano Panzieri",
      "Federica Pascucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12974"
  },
  {
    "id": "arXiv:2110.12975",
    "title": "Shape and Reflectance Reconstruction in Uncontrolled Environments by  Differentiable Rendering",
    "abstract": "Simultaneous reconstruction of geometry and reflectance properties in\nuncontrolled environments remains a challenging problem. In this paper, we\npropose an efficient method to reconstruct the scene's 3D geometry and\nreflectance from multi-view photography using conventional hand-held cameras.\nOur method automatically builds a virtual scene in a differentiable rendering\nsystem that roughly matches the real world's scene parameters, optimized by\nminimizing photometric objectives alternatingly and stochastically. With the\noptimal scene parameters evaluated, photo-realistic novel views for various\nviewing angles and distances can then be generated by our approach. We present\nthe results of captured scenes with complex geometry and various reflection\ntypes. Our method also shows superior performance compared to state-of-the-art\nalternatives in novel view synthesis visually and quantitatively.",
    "descriptor": "",
    "authors": [
      "Rui Li",
      "Guangmin Zang",
      "Miao Qi",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12975"
  },
  {
    "id": "arXiv:2110.12976",
    "title": "Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending  Against Adversarial Attacks",
    "abstract": "Deep neural networks (DNNs) are well-known to be vulnerable to adversarial\nattacks, where malicious human-imperceptible perturbations are included in the\ninput to the deep network to fool it into making a wrong classification. Recent\nstudies have demonstrated that neural Ordinary Differential Equations (ODEs)\nare intrinsically more robust against adversarial attacks compared to vanilla\nDNNs. In this work, we propose a stable neural ODE with Lyapunov-stable\nequilibrium points for defending against adversarial attacks (SODEF). By\nensuring that the equilibrium points of the ODE solution used as part of SODEF\nis Lyapunov-stable, the ODE solution for an input with a small perturbation\nconverges to the same solution as the unperturbed input. We provide theoretical\nresults that give insights into the stability of SODEF as well as the choice of\nregularizers to ensure its stability. Our analysis suggests that our proposed\nregularizers force the extracted feature points to be within a neighborhood of\nthe Lyapunov-stable equilibrium points of the ODE. SODEF is compatible with\nmany defense methods and can be applied to any neural network's final regressor\nlayer to enhance its stability against adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Qiyu Kang",
      "Yang Song",
      "Qinxu Ding",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12976"
  },
  {
    "id": "arXiv:2110.12978",
    "title": "MoDeRNN: Towards Fine-grained Motion Details for Spatiotemporal  Predictive Learning",
    "abstract": "Spatiotemporal predictive learning (ST-PL) aims at predicting the subsequent\nframes via limited observed sequences, and it has broad applications in the\nreal world. However, learning representative spatiotemporal features for\nprediction is challenging. Moreover, chaotic uncertainty among consecutive\nframes exacerbates the difficulty in long-term prediction. This paper\nconcentrates on improving prediction quality by enhancing the correspondence\nbetween the previous context and the current state. We carefully design Detail\nContext Block (DCB) to extract fine-grained details and improves the isolated\ncorrelation between upper context state and current input state. We integrate\nDCB with standard ConvLSTM and introduce Motion Details RNN (MoDeRNN) to\ncapture fine-grained spatiotemporal features and improves the expression of\nlatent states of RNNs to achieve significant quality. Experiments on Moving\nMNIST and Typhoon datasets demonstrate the effectiveness of the proposed\nmethod. MoDeRNN outperforms existing state-of-the-art techniques qualitatively\nand quantitatively with lower computation loads.",
    "descriptor": "",
    "authors": [
      "Zenghao Chai",
      "Zhengzhuo Xu",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12978"
  },
  {
    "id": "arXiv:2110.12981",
    "title": "Neural ODE and DAE Modules for Power System Dynamic Modeling",
    "abstract": "The time-domain simulation is the fundamental tool for power system transient\nstability analysis. Accurate and reliable simulations rely on accurate dynamic\ncomponent modeling. In practical power systems, dynamic component modeling has\nlong faced the challenges of model determination and model calibration,\nespecially with the rapid development of renewable generation and power\nelectronics. In this paper, based on the general framework of neural ordinary\ndifferential equations (ODEs), a modified neural ODE module and a neural\ndifferential-algebraic equations (DAEs) module for power system dynamic\ncomponent modeling are proposed. The modules adopt an autoencoder to raise the\ndimension of state variables, model the dynamics of components with artificial\nneural networks (ANNs), and keep the numerical integration structure. In the\nneural DAE module, an additional ANN is used to calculate injection currents.\nThe neural models can be easily integrated into time-domain simulations. With\ndatasets consisting of sampled curves of input variables and output variables,\nthe proposed modules can be used to fulfill the tasks of parameter inference,\nphysics-data-integrated modeling, black-box modeling, etc., and can be easily\nintegrated into power system dynamic simulations. Some simple numerical tests\nare carried out in the IEEE-39 system and prove the validity and potentiality\nof the proposed modules.",
    "descriptor": "\nComments: 8 pages, 4 figures, 1 table\n",
    "authors": [
      "Tannan Xiao",
      "Ying Chen",
      "Tirui He",
      "Huizhe Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12981"
  },
  {
    "id": "arXiv:2110.12983",
    "title": "Stochastic Rounding for Image Interpolation and Scan Conversion",
    "abstract": "The stochastic rounding (SR) function is introduced to demonstrate the\neffects of stochastically rounding row and column subscripts on image\ninterpolation quality in nearest neighbor interpolation (NNI). The introduced\nSR function is based on a pseudorandom number that enables the pseudorandom\nrounding up or down of any non-integer row and column subscripts. Also, the SR\nfunction exceptionally enables rounding up of any possible cases of subscript\ninputs that are inferior to a pseudorandom number - especially at a high\ninterpolation scaling ratio. The quality of NNI-SR interpolated images is\nevaluated against the quality of reference images - before and after applying\nsmoothing and sharpening filters, mentioned. The quality of NNI-SR interpolated\nscan conversion video frames is evaluated without using any references -\nfocusing on the quality of one frame after every 78-milliseconds for 10 000\nmilliseconds. Relevant experimental simulation results, discussions, and\nrecommendations are also provided.",
    "descriptor": "\nComments: 14 pages, 17 figures, 3 tables\n",
    "authors": [
      "Olivier Rukundo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12983"
  },
  {
    "id": "arXiv:2110.12985",
    "title": "Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning",
    "abstract": "Learning in a multi-target environment without prior knowledge about the\ntargets requires a large amount of samples and makes generalization difficult.\nTo solve this problem, it is important to be able to discriminate targets\nthrough semantic understanding. In this paper, we propose goal-aware\ncross-entropy (GACE) loss, that can be utilized in a self-supervised way using\nauto-labeled goal states alongside reinforcement learning. Based on the loss,\nwe then devise goal-discriminative attention networks (GDAN) which utilize the\ngoal-relevant information to focus on the given instruction. We evaluate the\nproposed methods on visual navigation and robot arm manipulation tasks with\nmulti-target environments and show that GDAN outperforms the state-of-the-art\nmethods in terms of task success ratio, sample efficiency, and generalization.\nAdditionally, qualitative analyses demonstrate that our proposed method can\nhelp the agent become aware of and focus on the given instruction clearly,\npromoting goal-directed behavior.",
    "descriptor": "\nComments: NeurIPS 2021 accepted, 19 pages including appendix and reference, 8 figures\n",
    "authors": [
      "Kibeom Kim",
      "Min Whoo Lee",
      "Yoonsung Kim",
      "Je-Hwan Ryu",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12985"
  },
  {
    "id": "arXiv:2110.12987",
    "title": "Optimization-Based GenQSGD for Federated Edge Learning",
    "abstract": "Optimal algorithm design for federated learning (FL) remains an open problem.\nThis paper explores the full potential of FL in practical edge computing\nsystems where workers may have different computation and communication\ncapabilities, and quantized intermediate model updates are sent between the\nserver and workers. First, we present a general quantized parallel mini-batch\nstochastic gradient descent (SGD) algorithm for FL, namely GenQSGD, which is\nparameterized by the number of global iterations, the numbers of local\niterations at all workers, and the mini-batch size. We also analyze its\nconvergence error for any choice of the algorithm parameters. Then, we optimize\nthe algorithm parameters to minimize the energy cost under the time constraint\nand convergence error constraint. The optimization problem is a challenging\nnon-convex problem with non-differentiable constraint functions. We propose an\niterative algorithm to obtain a KKT point using advanced optimization\ntechniques. Numerical results demonstrate the significant gains of GenQSGD over\nexisting FL algorithms and reveal the importance of optimally designing FL\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Yangchen Li",
      "Ying Cui",
      "Vincent Lau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12987"
  },
  {
    "id": "arXiv:2110.12989",
    "title": "RoBin: Facilitating the Reproduction of Configuration-Related  Vulnerability",
    "abstract": "Vulnerability reproduction paves a way in debugging software failures, which\nneed intensive manual efforts. However, some key factors (e.g., software\nconfiguration, trigger method) are often missing, so we can not directly\nreproduce the failure without extra attempts. Even worse, highly customized\nconfiguration options of programs create a barrier for reproducing the\nvulnerabilities that only appear under some specific combinations of\nconfigurations. In this paper, we address the problem mentioned above --\nreproducing the configuration-related vulnerability. We try to solve it by\nproposing a binary similarity-based method to infer the specific building\nconfigurations via the binary from crash report. The main challenges are as\nfollows: precise compilation option inference, program configuration inference,\nand source-code-to-binary matching. To achieve the goal, we implement RoBin, a\nbinary similarity-based building configuration inference tool. To demonstrate\nthe effectiveness, we test RoBin on 21 vulnerable cases upon 4 well-known\nopen-source programs. It shows a strong ability in pinpointing the building\nconfigurations causing the vulnerability. The result can help developers\nreproduce and diagnose the vulnerability, and finally, patch the programs.",
    "descriptor": "",
    "authors": [
      "Ligeng Chen",
      "Jian Guo",
      "Zhongling He",
      "Dongliang Mu",
      "Bing Mao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.12989"
  },
  {
    "id": "arXiv:2110.12993",
    "title": "Neural Relightable Participating Media Rendering",
    "abstract": "Learning neural radiance fields of a scene has recently allowed realistic\nnovel view synthesis of the scene, but they are limited to synthesize images\nunder the original fixed lighting condition. Therefore, they are not flexible\nfor the eagerly desired tasks like relighting, scene editing and scene\ncomposition. To tackle this problem, several recent methods propose to\ndisentangle reflectance and illumination from the radiance field. These methods\ncan cope with solid objects with opaque surfaces but participating media are\nneglected. Also, they take into account only direct illumination or at most\none-bounce indirect illumination, thus suffer from energy loss due to ignoring\nthe high-order indirect illumination. We propose to learn neural\nrepresentations for participating media with a complete simulation of global\nillumination. We estimate direct illumination via ray tracing and compute\nindirect illumination with spherical harmonics. Our approach avoids computing\nthe lengthy indirect bounces and does not suffer from energy loss. Our\nexperiments on multiple scenes show that our approach achieves superior visual\nquality and numerical performance compared to state-of-the-art methods, and it\ncan generalize to deal with solid objects with opaque surfaces as well.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Quan Zheng",
      "Gurprit Singh",
      "Hans-Peter Seidel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12993"
  },
  {
    "id": "arXiv:2110.12996",
    "title": "PREC: semantic translation of property graphs",
    "abstract": "Converting property graphs to RDF graphs allows to enhance the\ninteroperability of knowledge graphs. But existing tools perform the same\nconversion for every graph, regardless of its content. In this paper, we\npropose PREC, a user-configured conversion of property graphs to RDF graphs to\nbetter capture the semantics of the content.",
    "descriptor": "\nComments: 6 pages, 1 figure, 1st Workshop on Squaring the Circles on Graphs at SEMANTiCS 2021\n",
    "authors": [
      "Julian Bruyat",
      "Pierre-Antoine Champin",
      "Lionel M\u00e9dini",
      "Fr\u00e9d\u00e9rique Laforest"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12996"
  },
  {
    "id": "arXiv:2110.12997",
    "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in  Reinforcement Learning",
    "abstract": "Unsupervised reinforcement learning aims to acquire skills without prior goal\nrepresentations, where an agent automatically explores an open-ended\nenvironment to represent goals and learn the goal-conditioned policy. However,\nthis procedure is often time-consuming, limiting the rollout in some\npotentially expensive target environments. The intuitive approach of training\nin another interaction-rich environment disrupts the reproducibility of trained\nskills in the target environment due to the dynamics shifts and thus inhibits\ndirect transferring. Assuming free access to a source environment, we propose\nan unsupervised domain adaptation method to identify and acquire skills across\ndynamics. Particularly, we introduce a KL regularized objective to encourage\nemergence of skills, rewarding the agent for both discovering skills and\naligning its behaviors respecting dynamics shifts. This suggests that both\ndynamics (source and target) shape the reward to facilitate the learning of\nadaptive skills. We also conduct empirical experiments to demonstrate that our\nmethod can effectively learn skills that can be smoothly deployed in target.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Jinxin Liu",
      "Hao Shen",
      "Donglin Wang",
      "Yachen Kang",
      "Qiangxing Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12997"
  },
  {
    "id": "arXiv:2110.13005",
    "title": "Myelin: An asynchronous, message-driven parallel framework for  extreme-scale deep learning",
    "abstract": "In the last few years, the memory requirements to train state-of-the-art\nneural networks have far exceeded the DRAM capacities of modern hardware\naccelerators. This has necessitated the development of efficient algorithms to\ntrain these neural networks in parallel on large-scale GPU-based clusters.\nSince computation is relatively inexpensive on modern GPUs, designing and\nimplementing extremely efficient communication in these parallel training\nalgorithms is critical for extracting the maximum performance. This paper\npresents Myelin, a parallel deep learning framework that exploits asynchrony\nand message-driven execution to schedule neural network operations on each GPU,\nthereby reducing GPU idle time and maximizing hardware efficiency. By using the\nCPU memory as a scratch space for offloading data periodically during training,\nMyelin is able to reduce GPU memory consumption by four times. This allows us\nto increase the number of parameters per GPU by four times, thus reducing the\namount of communication and increasing performance by over 13%. When tested\nagainst large transformer models with 12--100 billion parameters on 48--384\nNVIDIA Tesla V100 GPUs, Myelin achieves a per-GPU throughput of 49.4--54.78% of\ntheoretical peak and reduces the training time by 22-37 days (15--25% speedup)\nas compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Siddharth Singh",
      "Abhinav Bhatele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.13005"
  },
  {
    "id": "arXiv:2110.13008",
    "title": "Logsig-RNN: a novel network for robust and efficient skeleton-based  action recognition",
    "abstract": "This paper contributes to the challenge of skeleton-based human action\nrecognition in videos. The key step is to develop a generic network\narchitecture to extract discriminative features for the spatio-temporal\nskeleton data. In this paper, we propose a novel module, namely Logsig-RNN,\nwhich is the combination of the log-signature layer and recurrent type neural\nnetworks (RNNs). The former one comes from the mathematically principled\ntechnology of signatures and log-signatures as representations for streamed\ndata, which can manage high sample rate streams, non-uniform sampling and time\nseries of variable length. It serves as an enhancement of the recurrent layer,\nwhich can be conveniently plugged into neural networks. Besides we propose two\npath transformation layers to significantly reduce path dimension while\nretaining the essential information fed into the Logsig-RNN module. Finally,\nnumerical results demonstrate that replacing the RNN module by the Logsig-RNN\nmodule in SOTA networks consistently improves the performance on both Chalearn\ngesture data and NTU RGB+D 120 action data in terms of accuracy and robustness.\nIn particular, we achieve the state-of-the-art accuracy on Chalearn2013 gesture\ndata by combining simple path transformation layers with the Logsig-RNN. Codes\nare available at \\url{https://github.com/steveliao93/GCN_LogsigRNN}.",
    "descriptor": "\nComments: This paper is accepted by British Machine Vision Conference 2021\n",
    "authors": [
      "Shujian Liao",
      "Terry Lyons",
      "Weixin Yang",
      "Kevin Schlegel",
      "Hao Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13008"
  },
  {
    "id": "arXiv:2110.13012",
    "title": "Parameterized Convexity Testing",
    "abstract": "In this work, we develop new insights into the fundamental problem of\nconvexity testing of real-valued functions over the domain $[n]$. Specifically,\nwe present a nonadaptive algorithm that, given inputs $\\eps \\in (0,1), s \\in\n\\mathbb{N}$, and oracle access to a function, $\\eps$-tests convexity in $O(\\log\n(s)/\\eps)$, where $s$ is an upper bound on the number of distinct discrete\nderivatives of the function. We also show that this bound is tight. Since $s\n\\leq n$, our query complexity bound is at least as good as that of the optimal\nconvexity tester (Ben Eliezer; ITCS 2019) with complexity $O(\\frac{\\log \\eps\nn}{\\eps})$; our bound is strictly better when $s = o(n)$. The main contribution\nof our work is to appropriately parameterize the complexity of convexity\ntesting to circumvent the worst-case lower bound (Belovs et al.; SODA 2020) of\n$\\Omega(\\frac{\\log (\\eps n)}{\\eps})$ expressed in terms of the input size and\nobtain a more efficient algorithm.",
    "descriptor": "\nComments: 11 pages, accepted in SOSA 2022\n",
    "authors": [
      "Abhiruk Lahiri",
      "Ilan Newman",
      "Nithin Varma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.13012"
  },
  {
    "id": "arXiv:2110.13014",
    "title": "A Compilation of Succinctness Results for Arithmetic Circuits",
    "abstract": "Arithmetic circuits (AC) are circuits over the real numbers with 0/1-valued\ninput variables whose gates compute the sum or the product of their inputs.\nPositive AC -- that is, AC representing non-negative functions -- subsume many\ninteresting probabilistic models such as probabilistic sentential decision\ndiagram (PSDD) or sum-product network (SPN) on indicator variables. Efficient\nalgorithms for many operations useful in probabilistic reasoning on these\nmodels critically depend on imposing structural restrictions to the underlying\nAC. Generally, adding structural restrictions yields new tractable operations\nbut increases the size of the AC. In this paper we study the relative\nsuccinctness of classes of AC with different combinations of common\nrestrictions. Building on existing results for Boolean circuits, we derive an\nunconditional succinctness map for classes of monotone AC -- that is, AC whose\nconstant labels are non-negative reals -- respecting relevant combinations of\nthe restrictions we consider. We extend a small part of the map to classes of\npositive AC. Those are known to generally be exponentially more succinct than\ntheir monotone counterparts, but we observe here that for so-called\ndeterministic circuits there is no difference between the monotone and the\npositive setting which allows us to lift some of our results. We end the paper\nwith some insights on the relative succinctness of positive AC by showing\nexponential lower bounds on the representations of certain functions in\npositive AC respecting structured decomposability.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Alexis de Colnet",
      "Stefan Mengel"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.13014"
  },
  {
    "id": "arXiv:2110.13016",
    "title": "Generating artificial texts as substitution or complement of training  data",
    "abstract": "The quality of artificially generated texts has considerably improved with\nthe advent of transformers. The question of using these models to generate\nlearning data for supervised learning tasks naturally arises. In this article,\nthis question is explored under 3 aspects: (i) are artificial data an efficient\ncomplement? (ii) can they replace the original data when those are not\navailable or cannot be distributed for confidentiality reasons? (iii) can they\nimprove the explainability of classifiers? Different experiments are carried\nout on Web-related classification tasks -- namely sentiment analysis on product\nreviews and Fake News detection -- using artificially generated data by\nfine-tuned GPT-2 models. The results show that such artificial data can be used\nin a certain extend but require pre-processing to significantly improve\nperformance. We show that bag-of-word approaches benefit the most from such\ndata augmentation.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Vincent Claveau",
      "Antoine Chaffin",
      "Ewa Kijak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13016"
  },
  {
    "id": "arXiv:2110.13023",
    "title": "ML-Based Analysis to Identify Speech Features Relevant in Predicting  Alzheimer's Disease",
    "abstract": "Alzheimer's disease (AD) is a neurodegenerative disease that affects nearly\n50 million individuals across the globe and is one of the leading causes of\ndeaths globally. It is projected that by 2050, the number of people affected by\nthe disease would more than double. Consequently, the growing advancements in\ntechnology beg the question, can technology be used to predict Alzheimer's for\na better and early diagnosis? In this paper, we focus on this very problem.\nSpecifically, we have trained both ML models and neural networks to predict and\nclassify participants based on their speech patterns. We computed a number of\nlinguistic variables using DementiaBank's Pitt Corpus, a database consisting of\ntranscripts of interviews with subjects suffering from multiple\nneurodegenerative diseases. We then trained both binary classifiers, as well as\nmulticlass classifiers to distinguish AD from normal aging and other\nneurodegenerative diseases. We also worked on establishing the link between\nspecific speech factors that can help determine the onset of AD. Confusion\nmatrices and feature importance graphs have been plotted model-wise to compare\nthe performances of our models. In both multiclass and binary classification,\nneural networks were found to outperform the other models with a testing\naccuracy of 76.44% and 92.05% respectively. For the feature importance, it was\nconcluded that '%_PRESP' (present participle), '%_3S' (3rd person present tense\nmarkers) were two of the most important speech features for our classifiers in\npredicting AD.",
    "descriptor": "",
    "authors": [
      "Yash Kumar",
      "Piyush Maheshwari",
      "Shreyansh Joshi",
      "Veeky Baths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13023"
  },
  {
    "id": "arXiv:2110.13027",
    "title": "TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part  Localization",
    "abstract": "Holistic object representation-based trackers suffer from performance drop\nunder large appearance change such as deformation and occlusion. In this work,\nwe propose a dynamic part-based tracker and constantly update the target part\nrepresentation to adapt to object appearance change. Moreover, we design an\nattention-guided part localization network to directly predict the target part\nlocations, and determine the final bounding box with the distribution of target\nparts. Our proposed tracker achieves promising results on various benchmarks:\nVOT2018, OTB100 and GOT-10k",
    "descriptor": "\nComments: Accepted by BMVC2021\n",
    "authors": [
      "Wei han",
      "Hantao Huang",
      "Xiaoxi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13027"
  },
  {
    "id": "arXiv:2110.13029",
    "title": "Fair Enough: Searching for Sufficient Measures of Fairness",
    "abstract": "Testing machine learning software for ethical bias has become a pressing\ncurrent concern. In response, recent research has proposed a plethora of new\nfairness metrics, for example, the dozens of fairness metrics in the IBM AIF360\ntoolkit. This raises the question: How can any fairness tool satisfy such a\ndiverse range of goals?\nWhile we cannot completely simplify the task of fairness testing, we can\ncertainly reduce the problem. This paper shows that many of those fairness\nmetrics effectively measure the same thing. Based on experiments using seven\nreal-world datasets, we find that (a) 26 classification metrics can be\nclustered into seven groups, and (b) four dataset metrics can be clustered into\nthree groups. Further, each reduced set may actually predict different things.\nHence, it is no longer necessary (or even possible) to satisfy all fairness\nmetrics.\nIn summary, to simplify the fairness testing problem, we recommend the\nfollowing steps: (1) determine what type of fairness is desirable (and we offer\na handful of such types); then (2) lookup those types in our clusters; then (3)\njust test for one item per cluster. To support that processing, all our scripts\n(and example datasets) are available at\nhttps://github.com/Repoanonymous/Fairness\\_Metrics.",
    "descriptor": "\nComments: 8 tables and 1 figure\n",
    "authors": [
      "Suvodeep Majumder",
      "Joymallya Chakraborty",
      "Gina R. Bai",
      "Kathryn T. Stolee",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13029"
  },
  {
    "id": "arXiv:2110.13032",
    "title": "Revisiting CNN for Highly Inflected Bengali and Hindi Language Modeling",
    "abstract": "Though there has been a large body of recent works in language modeling (LM)\nfor high resource languages such as English and Chinese, the area is still\nunexplored for low resource languages like Bengali and Hindi. We propose an end\nto end trainable memory efficient CNN architecture named CoCNN to handle\nspecific characteristics such as high inflection, morphological richness,\nflexible word order and phonetical spelling errors of Bengali and Hindi. In\nparticular, we introduce two learnable convolutional sub-models at word and at\nsentence level that are end to end trainable. We show that state-of-the-art\n(SOTA) Transformer models including pretrained BERT do not necessarily yield\nthe best performance for Bengali and Hindi. CoCNN outperforms pretrained BERT\nwith 16X less parameters, and it achieves much better performance than SOTA\nLSTM models on multiple real-world datasets. This is the first study on the\neffectiveness of different architectures drawn from three deep learning\nparadigms - Convolution, Recurrent, and Transformer neural nets for modeling\ntwo widely used languages, Bengali and Hindi.",
    "descriptor": "",
    "authors": [
      "Chowdhury Rafeed Rahman",
      "MD. Hasibur Rahman",
      "Mohammad Rafsan",
      "Samiha Zakir",
      "Mohammed Eunus Ali",
      "Rafsanjani Muhammod"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13032"
  },
  {
    "id": "arXiv:2110.13034",
    "title": "Introducing Traceability in GitHub for Medical Software Development",
    "abstract": "Assuring traceability from requirements to implementation is a key element\nwhen developing safety critical software systems. Traditionally, this\ntraceability is ensured by a waterfall-like process, where phases follow each\nother, and tracing between different phases can be managed. However, new\nsoftware development paradigms, such as continuous software engineering and\nDevOps, which encourage a steady stream of new features, committed by\ndevelopers in a seemingly uncontrolled fashion in terms of former phasing,\nchallenge this view. In this paper, we introduce our approach that adds\ntraceability capabilities to GitHub, so that the developers can act like they\nnormally do in GitHub context but produce the documentation needed by the\nregulatory purposes in the process.",
    "descriptor": "",
    "authors": [
      "Vlad Stirbu",
      "Tommi Mikkonen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13034"
  },
  {
    "id": "arXiv:2110.13039",
    "title": "Green Application Placement in the Cloud-IoT Continuum",
    "abstract": "Green software engineering aims at reducing the environmental impact due to\ndeveloping, deploying, and managing software systems. Meanwhile, Cloud-IoT\nparadigms can contribute to improving energy and carbon efficiency of\napplication deployments by (i) reducing the amount of data and the distance\nthey must travel across the network, (ii) by exploiting idle edge devices to\nsupport application deployment. In this article, we propose a declarative\nmethodology and its Prolog prototype for determining placements of application\nservices onto Cloud-IoT infrastructures so to optimise energy and carbon\nefficiency, also considering different infrastructure power sources and\noperational costs. The proposal is assessed over a motivating example.",
    "descriptor": "",
    "authors": [
      "Stefano Forti",
      "Antonio Brogi"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Networking and Internet Architecture (cs.NI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13039"
  },
  {
    "id": "arXiv:2110.13040",
    "title": "Neural Flows: Efficient Alternative to Neural ODEs",
    "abstract": "Neural ordinary differential equations describe how values change in time.\nThis is the reason why they gained importance in modeling sequential data,\nespecially when the observations are made at irregular intervals. In this paper\nwe propose an alternative by directly modeling the solution curves - the flow\nof an ODE - with a neural network. This immediately eliminates the need for\nexpensive numerical solvers while still maintaining the modeling capability of\nneural ODEs. We propose several flow architectures suitable for different\napplications by establishing precise conditions on when a function defines a\nvalid flow. Apart from computational efficiency, we also provide empirical\nevidence of favorable generalization performance via applications in time\nseries modeling, forecasting, and density estimation.",
    "descriptor": "\nComments: Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Marin Bilo\u0161",
      "Johanna Sommer",
      "Syama Sundar Rangapuram",
      "Tim Januschowski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13040"
  },
  {
    "id": "arXiv:2110.13041",
    "title": "Applications and Techniques for Fast Machine Learning in Science",
    "abstract": "In this community review report, we discuss applications and techniques for\nfast machine learning (ML) in science -- the concept of integrating power ML\nmethods into the real-time experimental data processing loop to accelerate\nscientific discovery. The material for the report builds on two workshops held\nby the Fast ML for Science community and covers three main areas: applications\nfor fast ML across a number of scientific domains; techniques for training and\nimplementing performant and resource-efficient ML algorithms; and computing\narchitectures, platforms, and technologies for deploying these algorithms. We\nalso present overlapping challenges across the multiple scientific domains\nwhere common solutions can be found. This community report is intended to give\nplenty of examples and inspiration for scientific discovery through integrated\nand accelerated ML solutions. This is followed by a high-level overview and\norganization of technical advances, including an abundance of pointers to\nsource material, which can enable these breakthroughs.",
    "descriptor": "\nComments: 66 pages, 13 figures, 5 tables\n",
    "authors": [
      "Allison McCarn Deiana",
      "Nhan Tran",
      "Joshua Agar",
      "Michaela Blott",
      "Giuseppe Di Guglielmo",
      "Javier Duarte",
      "Philip Harris",
      "Scott Hauck",
      "Mia Liu",
      "Mark S. Neubauer",
      "Jennifer Ngadiuba",
      "Seda Ogrenci-Memik",
      "Maurizio Pierini",
      "Thea Aarrestad",
      "Steffen Bahr",
      "Jurgen Becker",
      "Anne-Sophie Berthold",
      "Richard J. Bonventre",
      "Tomas E. Muller Bravo",
      "Markus Diefenthaler",
      "Zhen Dong",
      "Nick Fritzsche",
      "Amir Gholami",
      "Ekaterina Govorkova",
      "Kyle J Hazelwood",
      "Christian Herwig",
      "Babar Khan",
      "Sehoon Kim",
      "Thomas Klijnsma",
      "Yaling Liu",
      "Kin Ho Lo",
      "Tri Nguyen",
      "Gianantonio Pezzullo",
      "Seyedramin Rasoulinezhad",
      "Ryan A. Rivera",
      "Kate Scholberg",
      "Justin Selig",
      "Sougata Sen",
      "Dmitri Strukov",
      "William Tang",
      "Savannah Thais",
      "Kai Lukas Unger",
      "Ricardo Vilalta",
      "Belinavon Krosigk",
      "Thomas K. Warburton",
      "Maria Acosta Flechas",
      "Anthony Aportela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2110.13041"
  },
  {
    "id": "arXiv:2110.13042",
    "title": "Efficiently Parallelizable Strassen-Based Multiplication of a Matrix by  its Transpose",
    "abstract": "The multiplication of a matrix by its transpose, $A^T A$, appears as an\nintermediate operation in the solution of a wide set of problems. In this\npaper, we propose a new cache-oblivious algorithm (ATA) for computing this\nproduct, based upon the classical Strassen algorithm as a sub-routine. In\nparticular, we decrease the computational cost to $\\frac{2}{3}$ the time\nrequired by Strassen's algorithm, amounting to $\\frac{14}{3}n^{\\log_2 7}$\nfloating point operations. ATA works for generic rectangular matrices, and\nexploits the peculiar symmetry of the resulting product matrix for saving\nmemory. In addition, we provide an extensive implementation study of ATA in a\nshared memory system, and extend its applicability to a distributed\nenvironment. To support our findings, we compare our algorithm with\nstate-of-the-art solutions specialized in the computation of $A^T A$. Our\nexperiments highlight good scalability with respect to both the matrix size and\nthe number of involved processes, as well as favorable performance for both the\nparallel paradigms and the sequential implementation, when compared with other\nmethods in the literature.",
    "descriptor": "",
    "authors": [
      "Viviana Arrigoni",
      "Filippo Maggioli",
      "Annalisa Massini",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13042"
  },
  {
    "id": "arXiv:2110.13047",
    "title": "Drug Similarity and Link Prediction Using Graph Embeddings on Medical  Knowledge Graphs",
    "abstract": "The paper utilizes the graph embeddings generated for entities of a large\nbiomedical database to perform link prediction to capture various new\nrelationships among different entities. A novel node similarity measure is\nproposed that utilizes the graph embeddings and link prediction scores to find\nsimilarity scores among various drugs which can be used by the medical experts\nto recommend alternative drugs to avoid side effects from original one.\nUtilizing machine learning on knowledge graph for drug similarity and\nrecommendation will be less costly and less time consuming with higher\nscalability as compare to traditional biomedical methods due to the dependency\non costly medical equipment and experts by the later ones.",
    "descriptor": "",
    "authors": [
      "Prakhar Gurawa",
      "Matthias Nickles"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13047"
  },
  {
    "id": "arXiv:2110.13052",
    "title": "Can Q-Learning be Improved with Advice?",
    "abstract": "Despite rapid progress in theoretical reinforcement learning (RL) over the\nlast few years, most of the known guarantees are worst-case in nature, failing\nto take advantage of structure that may be known a priori about a given RL\nproblem at hand. In this paper we address the question of whether worst-case\nlower bounds for regret in online learning of Markov decision processes (MDPs)\ncan be circumvented when information about the MDP, in the form of predictions\nabout its optimal $Q$-value function, is given to the algorithm. We show that\nwhen the predictions about the optimal $Q$-value function satisfy a reasonably\nweak condition we call distillation, then we can improve regret bounds by\nreplacing the set of state-action pairs with the set of state-action pairs on\nwhich the predictions are grossly inaccurate. This improvement holds for both\nuniform regret bounds and gap-based ones. Further, we are able to achieve this\nproperty with an algorithm that achieves sublinear regret when given arbitrary\npredictions (i.e., even those which are not a distillation). Our work extends a\nrecent line of work on algorithms with predictions, which has typically focused\non simple online problems such as caching and scheduling, to the more complex\nand general problem of reinforcement learning.",
    "descriptor": "",
    "authors": [
      "Noah Golowich",
      "Ankur Moitra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13052"
  },
  {
    "id": "arXiv:2110.13054",
    "title": "Adaptive Data Debiasing through Bounded Exploration and Fairness",
    "abstract": "Biases in existing datasets used to train algorithmic decision rules can\nraise ethical, societal, and economic concerns due to the resulting disparate\ntreatment of different groups. We propose an algorithm for sequentially\ndebiasing such datasets through adaptive and bounded exploration. Exploration\nin this context means that at times, and to a judiciously-chosen extent, the\ndecision maker deviates from its (current) loss-minimizing rule, and instead\naccepts some individuals that would otherwise be rejected, so as to reduce\nstatistical data biases. Our proposed algorithm includes parameters that can be\nused to balance between the ultimate goal of removing data biases -- which will\nin turn lead to more accurate and fair decisions, and the exploration risks\nincurred to achieve this goal. We show, both analytically and numerically, how\nsuch exploration can help debias data in certain distributions. We further\ninvestigate how fairness measures can work in conjunction with such data\ndebiasing efforts.",
    "descriptor": "",
    "authors": [
      "Yifan Yang",
      "Yang Liu",
      "Parinaz Naghizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13054"
  },
  {
    "id": "arXiv:2110.13057",
    "title": "Robbing the Fed: Directly Obtaining Private Data in Federated Learning  with Modified Models",
    "abstract": "Federated learning has quickly gained popularity with its promises of\nincreased user privacy and efficiency. Previous works have shown that federated\ngradient updates contain information that can be used to approximately recover\nuser data in some situations. These previous attacks on user privacy have been\nlimited in scope and do not scale to gradient updates aggregated over even a\nhandful of data points, leaving some to conclude that data privacy is still\nintact for realistic training regimes. In this work, we introduce a new threat\nmodel based on minimal but malicious modifications of the shared model\narchitecture which enable the server to directly obtain a verbatim copy of user\ndata from gradient updates without solving difficult inverse problems. Even\nuser data aggregated over large batches -- where previous methods fail to\nextract meaningful content -- can be reconstructed by these minimally modified\nmodels.",
    "descriptor": "",
    "authors": [
      "Liam Fowl",
      "Jonas Geiping",
      "Wojtek Czaja",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13057"
  },
  {
    "id": "arXiv:2110.13058",
    "title": "Some like it tough: Improving model generalization via progressively  increasing the training difficulty",
    "abstract": "In this work, we propose to progressively increase the training difficulty\nduring learning a neural network model via a novel strategy which we call\nmini-batch trimming. This strategy makes sure that the optimizer puts its focus\nin the later training stages on the more difficult samples, which we identify\nas the ones with the highest loss in the current mini-batch. The strategy is\nvery easy to integrate into an existing training pipeline and does not\nnecessitate a change of the network model. Experiments on several image\nclassification problems show that mini-batch trimming is able to increase the\ngeneralization ability (measured via final test error) of the trained model.",
    "descriptor": "\nComments: Accepted for ASPAI 2021 conference\n",
    "authors": [
      "Hannes Fassold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13058"
  },
  {
    "id": "arXiv:2110.13059",
    "title": "Exploiting Redundancy: Separable Group Convolutional Networks on Lie  Groups",
    "abstract": "Group convolutional neural networks (G-CNNs) have been shown to increase\nparameter efficiency and model accuracy by incorporating geometric inductive\nbiases. In this work, we investigate the properties of representations learned\nby regular G-CNNs, and show considerable parameter redundancy in group\nconvolution kernels. This finding motivates further weight-tying by sharing\nconvolution kernels over subgroups. To this end, we introduce convolution\nkernels that are separable over the subgroup and channel dimensions. In order\nto obtain equivariance to arbitrary affine Lie groups we provide a continuous\nparameterisation of separable convolution kernels. We evaluate our approach\nacross several vision datasets, and show that our weight sharing leads to\nimproved performance and computational efficiency. In many settings, separable\nG-CNNs outperform their non-separable counterpart, while only using a fraction\nof their training time. In addition, thanks to the increase in computational\nefficiency, we are able to implement G-CNNs equivariant to the\n$\\mathrm{Sim(2)}$ group; the group of dilations, rotations and translations.\n$\\mathrm{Sim(2)}$-equivariance further improves performance on all tasks\nconsidered.",
    "descriptor": "",
    "authors": [
      "David M. Knigge",
      "David W. Romero",
      "Erik J. Bekkers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13059"
  },
  {
    "id": "arXiv:2110.13060",
    "title": "Safely Bridging Offline and Online Reinforcement Learning",
    "abstract": "A key challenge to deploying reinforcement learning in practice is exploring\nsafely. We propose a natural safety property -- \\textit{uniformly}\noutperforming a conservative policy (adaptively estimated from all data\nobserved thus far), up to a per-episode exploration budget. We then design an\nalgorithm that uses a UCB reinforcement learning policy for exploration, but\noverrides it as needed to ensure safety with high probability. We\nexperimentally validate our results on a sepsis treatment task, demonstrating\nthat our algorithm can learn while ensuring good performance compared to the\nbaseline policy for every patient.",
    "descriptor": "",
    "authors": [
      "Wanqiao Xu",
      "Kan Xu",
      "Hamsa Bastani",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13060"
  },
  {
    "id": "arXiv:2110.13061",
    "title": "Where were my keys? -- Aggregating Spatial-Temporal Instances of Objects  for Efficient Retrieval over Long Periods of Time",
    "abstract": "Robots equipped with situational awareness can help humans efficiently find\ntheir lost objects by leveraging spatial and temporal structure. Existing\napproaches to video and image retrieval do not take into account the unique\nconstraints imposed by a moving camera with a partial view of the environment.\nWe present a Detection-based 3-level hierarchical Association approach, D3A, to\ncreate an efficient query-able spatial-temporal representation of unique object\ninstances in an environment. D3A performs online incremental and hierarchical\nlearning to identify keyframes that best represent the unique objects in the\nenvironment. These keyframes are learned based on both spatial and temporal\nfeatures and once identified their corresponding spatial-temporal information\nis organized in a key-value database. D3A allows for a variety of query\npatterns such as querying for objects with/without the following: 1) specific\nattributes, 2) spatial relationships with other objects, and 3) time slices.\nFor a given set of 150 queries, D3A returns a small set of candidate keyframes\n(which occupy only 0.17% of the total sensory data) with 81.98\\% mean accuracy\nin 11.7 ms. This is 47x faster and 33% more accurate than a baseline that\nnaively stores the object matches (detections) in the database without\nassociating spatial-temporal information.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Ifrah Idrees",
      "Zahid Hasan",
      "Steven P. Reiss",
      "Stefanie Tellex"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13061"
  },
  {
    "id": "arXiv:2110.13064",
    "title": "2nd Place Solution for SODA10M Challenge 2021 -- Continual Detection  Track",
    "abstract": "In this technical report, we present our approaches for the continual object\ndetection track of the SODA10M challenge. We adapt ResNet50-FPN as the baseline\nand try several improvements for the final submission model. We find that\ntask-specific replay scheme, learning rate scheduling, model calibration, and\nusing original image scale helps to improve performance for both large and\nsmall objects in images. Our team `hypertune28' secured the second position\namong 52 participants in the challenge. This work will be presented at the ICCV\n2021 Workshop on Self-supervised Learning for Next-Generation Industry-level\nAutonomous Driving (SSLAD).",
    "descriptor": "\nComments: Published in SSLAD workshop at ICCV 2021\n",
    "authors": [
      "Manoj Acharya",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13064"
  },
  {
    "id": "arXiv:2110.13067",
    "title": "Evolutionary Optimization of High-Coverage Budgeted Classifiers",
    "abstract": "Classifiers are often utilized in time-constrained settings where labels must\nbe assigned to inputs quickly. To address these scenarios, budgeted multi-stage\nclassifiers (MSC) process inputs through a sequence of partial feature\nacquisition and evaluation steps with early-exit options until a confident\nprediction can be made. This allows for fast evaluation that can prevent\nexpensive, unnecessary feature acquisition in time-critical instances. However,\nperformance of MSCs is highly sensitive to several design aspects -- making\noptimization of these systems an important but difficult problem.\nTo approximate an initially intractable combinatorial problem, current\napproaches to MSC configuration rely on well-behaved surrogate loss functions\naccounting for two primary objectives (processing cost, error). These\napproaches have proven useful in many scenarios but are limited by analytic\nconstraints (convexity, smoothness, etc.) and do not manage additional\nperformance objectives. Notably, such methods do not explicitly account for an\nimportant aspect of real-time detection systems -- the ratio of \"accepted\"\npredictions satisfying some confidence criterion imposed by a risk-averse\nmonitor.\nThis paper proposes a problem-specific genetic algorithm, EMSCO, that\nincorporates a terminal reject option for indecisive predictions and treats MSC\ndesign as an evolutionary optimization problem with distinct objectives\n(accuracy, cost, coverage). The algorithm's design emphasizes Pareto efficiency\nwhile respecting a notion of aggregated performance via a unique scalarization.\nExperiments are conducted to demonstrate EMSCO's ability to find global optima\nin a variety of Theta(k^n) solution spaces, and multiple experiments show EMSCO\nis competitive with alternative budgeted approaches.",
    "descriptor": "",
    "authors": [
      "Nolan H. Hamilton",
      "Errin W. Fulp"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13067"
  },
  {
    "id": "arXiv:2110.13071",
    "title": "Unsupervised Source Separation By Steering Pretrained Music Models",
    "abstract": "We showcase an unsupervised method that repurposes deep models trained for\nmusic generation and music tagging for audio source separation, without any\nretraining. An audio generation model is conditioned on an input mixture,\nproducing a latent encoding of the audio used to generate audio. This generated\naudio is fed to a pretrained music tagger that creates source labels. The\ncross-entropy loss between the tag distribution for the generated audio and a\npredefined distribution for an isolated source is used to guide gradient ascent\nin the (unchanging) latent space of the generative model. This system does not\nupdate the weights of the generative model or the tagger, and only relies on\nmoving through the generative model's latent space to produce separated\nsources. We use OpenAI's Jukebox as the pretrained generative model, and we\ncouple it with four kinds of pretrained music taggers (two architectures and\ntwo tagging datasets). Experimental results on two source separation datasets,\nshow this approach can produce separation estimates for a wider variety of\nsources than any tested supervised or unsupervised system. This work points to\nthe vast and heretofore untapped potential of large pretrained music models for\naudio-to-audio tasks like source separation.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Ethan Manilow",
      "Patrick O'Reilly",
      "Prem Seetharaman",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13071"
  },
  {
    "id": "arXiv:2110.13076",
    "title": "AutoMTL: A Programming Framework for Automated Multi-Task Learning",
    "abstract": "Multi-task learning (MTL) jointly learns a set of tasks. It is a promising\napproach to reduce the training and inference time and storage costs while\nimproving prediction accuracy and generalization performance for many computer\nvision tasks. However, a major barrier preventing the widespread adoption of\nMTL is the lack of systematic support for developing compact multi-task models\ngiven a set of tasks. In this paper, we aim to remove the barrier by developing\nthe first programming framework AutoMTL that automates MTL model development.\nAutoMTL takes as inputs an arbitrary backbone convolutional neural network and\na set of tasks to learn, then automatically produce a multi-task model that\nachieves high accuracy and has small memory footprint simultaneously. As a\nprogramming framework, AutoMTL could facilitate the development of MTL-enabled\ncomputer vision applications and even further improve task performance. Code of\nAutoMTL will be available at https://github.com/zhanglijun95/AutoMTL",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Lijun Zhang",
      "Xiao Liu",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13076"
  },
  {
    "id": "arXiv:2110.13079",
    "title": "Which Model To Trust: Assessing the Influence of Models on the  Performance of Reinforcement Learning Algorithms for Continuous Control Tasks",
    "abstract": "The need for algorithms able to solve Reinforcement Learning (RL) problems\nwith few trials has motivated the advent of model-based RL methods. The\nreported performance of model-based algorithms has dramatically increased\nwithin recent years. However, it is not clear how much of the recent progress\nis due to improved algorithms or due to improved models. While different\nmodeling options are available to choose from when applying a model-based\napproach, the distinguishing traits and particular strengths of different\nmodels are not clear. The main contribution of this work lies precisely in\nassessing the model influence on the performance of RL algorithms. A set of\ncommonly adopted models is established for the purpose of model comparison.\nThese include Neural Networks (NNs), ensembles of NNs, two different\napproximations of Bayesian NNs (BNNs), that is, the Concrete Dropout NN and the\nAnchored Ensembling, and Gaussian Processes (GPs). The model comparison is\nevaluated on a suite of continuous control benchmarking tasks. Our results\nreveal that significant differences in model performance do exist. The Concrete\nDropout NN reports persistently superior performance. We summarize these\ndifferences for the benefit of the modeler and suggest that the model choice is\ntailored to the standards required by each specific application.",
    "descriptor": "",
    "authors": [
      "Giacomo Arcieri",
      "David W\u00f6lfle",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13079"
  },
  {
    "id": "arXiv:2110.13082",
    "title": "An Evolutionary Correlation-aware Feature Selection Method for  Classification Problems",
    "abstract": "The population-based optimization algorithms have provided promising results\nin feature selection problems. However, the main challenges are high time\ncomplexity. Moreover, the interaction between features is another big challenge\nin FS problems that directly affects the classification performance. In this\npaper, an estimation of distribution algorithm is proposed to meet three goals.\nFirstly, as an extension of EDA, the proposed method generates only two\nindividuals in each iteration that compete based on a fitness function and\nevolve during the algorithm, based on our proposed update procedure. Secondly,\nwe provide a guiding technique for determining the number of features for\nindividuals in each iteration. As a result, the number of selected features of\nthe final solution will be optimized during the evolution process. The two\nmentioned advantages can increase the convergence speed of the algorithm.\nThirdly, as the main contribution of the paper, in addition to considering the\nimportance of each feature alone, the proposed method can consider the\ninteraction between features. Thus, it can deal with complementary features and\nconsequently increase classification performance. To do this, we provide a\nconditional probability scheme that considers the joint probability\ndistribution of selecting two features. The introduced probabilities\nsuccessfully detect correlated features. Experimental results on a synthetic\ndataset with correlated features prove the performance of our proposed approach\nfacing these types of features. Furthermore, the results on 13 real-world\ndatasets obtained from the UCI repository show the superiority of the proposed\nmethod in comparison with some state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Motahare Namakin",
      "Modjtaba Rouhani",
      "Mostafa Sabzekar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13082"
  },
  {
    "id": "arXiv:2110.13083",
    "title": "MVT: Multi-view Vision Transformer for 3D Object Recognition",
    "abstract": "Inspired by the great success achieved by CNN in image recognition,\nview-based methods applied CNNs to model the projected views for 3D object\nunderstanding and achieved excellent performance. Nevertheless, multi-view CNN\nmodels cannot model the communications between patches from different views,\nlimiting its effectiveness in 3D object recognition. Inspired by the recent\nsuccess gained by vision Transformer in image recognition, we propose a\nMulti-view Vision Transformer (MVT) for 3D object recognition. Since each patch\nfeature in a Transformer block has a global reception field, it naturally\nachieves communications between patches from different views. Meanwhile, it\ntakes much less inductive bias compared with its CNN counterparts. Considering\nboth effectiveness and efficiency, we develop a global-local structure for our\nMVT. Our experiments on two public benchmarks, ModelNet40 and ModelNet10,\ndemonstrate the competitive performance of our MVT.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Shuo Chen",
      "Tan Yu",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13083"
  },
  {
    "id": "arXiv:2110.13090",
    "title": "SciClops: Detecting and Contextualizing Scientific Claims for Assisting  Manual Fact-Checking",
    "abstract": "This paper describes SciClops, a method to help combat online scientific\nmisinformation. Although automated fact-checking methods have gained\nsignificant attention recently, they require pre-existing ground-truth\nevidence, which, in the scientific context, is sparse and scattered across a\nconstantly-evolving scientific literature. Existing methods do not exploit this\nliterature, which can effectively contextualize and combat science-related\nfallacies. Furthermore, these methods rarely require human intervention, which\nis essential for the convoluted and critical domain of scientific\nmisinformation. SciClops involves three main steps to process scientific claims\nfound in online news articles and social media postings: extraction,\nclustering, and contextualization. First, the extraction of scientific claims\ntakes place using a domain-specific, fine-tuned transformer model. Second,\nsimilar claims extracted from heterogeneous sources are clustered together with\nrelated scientific literature using a method that exploits their content and\nthe connections among them. Third, check-worthy claims, broadcasted by popular\nyet unreliable sources, are highlighted together with an enhanced fact-checking\ncontext that includes related verified claims, news articles, and scientific\npapers. Extensive experiments show that SciClops tackles sufficiently these\nthree steps, and effectively assists non-expert fact-checkers in the\nverification of complex scientific claims, outperforming commercial\nfact-checking systems.",
    "descriptor": "\nComments: Proceedings of the 30th ACM International Conference on Information and Knowledge Management (CIKM '21). November 1-5, 2021. QLD, Australia\n",
    "authors": [
      "Panayiotis Smeros",
      "Carlos Castillo",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13090"
  },
  {
    "id": "arXiv:2110.13094",
    "title": "Gophormer: Ego-Graph Transformer for Node Classification",
    "abstract": "Transformers have achieved remarkable performance in a myriad of fields\nincluding natural language processing and computer vision. However, when it\ncomes to the graph mining area, where graph neural network (GNN) has been the\ndominant paradigm, transformers haven't achieved competitive performance,\nespecially on the node classification task. Existing graph transformer models\ntypically adopt fully-connected attention mechanism on the whole input graph\nand thus suffer from severe scalability issues and are intractable to train in\ndata insufficient cases. To alleviate these issues, we propose a novel\nGophormer model which applies transformers on ego-graphs instead of\nfull-graphs. Specifically, Node2Seq module is proposed to sample ego-graphs as\nthe input of transformers, which alleviates the challenge of scalability and\nserves as an effective data augmentation technique to boost model performance.\nMoreover, different from the feature-based attention strategy in vanilla\ntransformers, we propose a proximity-enhanced attention mechanism to capture\nthe fine-grained structural bias. In order to handle the uncertainty introduced\nby the ego-graph sampling, we further propose a consistency regularization and\na multi-sample inference strategy for stabilized training and testing,\nrespectively. Extensive experiments on six benchmark datasets are conducted to\ndemonstrate the superiority of Gophormer over existing graph transformers and\npopular GNNs, revealing the promising future of graph transformers.",
    "descriptor": "",
    "authors": [
      "Jianan Zhao",
      "Chaozhuo Li",
      "Qianlong Wen",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Xing Xie",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13094"
  },
  {
    "id": "arXiv:2110.13097",
    "title": "Rotation Equivariant Deforestation Segmentation and Driver  Classification",
    "abstract": "Deforestation has become a significant contributing factor to climate change\nand, due to this, both classifying the drivers and predicting segmentation maps\nof deforestation has attracted significant interest. In this work, we develop a\nrotation equivariant convolutional neural network model to predict the drivers\nand generate segmentation maps of deforestation events from Landsat 8 satellite\nimages. This outperforms previous methods in classifying the drivers and\npredicting the segmentation map of deforestation, offering a 9% improvement in\nclassification accuracy and a 7% improvement in segmentation map accuracy. In\naddition, this method predicts stable segmentation maps under rotation of the\ninput image, which ensures that predicted regions of deforestation are not\ndependent upon the rotational orientation of the satellite.",
    "descriptor": "\nComments: Tackling Climate Change with Machine Learning workshop at NeurIPS 2021\n",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13097"
  },
  {
    "id": "arXiv:2110.13100",
    "title": "Parameter Prediction for Unseen Deep Architectures",
    "abstract": "Deep learning has been successful in automating the design of features in\nmachine learning pipelines. However, the algorithms optimizing neural network\nparameters remain largely hand-designed and computationally inefficient. We\nstudy if we can use deep learning to directly predict these parameters by\nexploiting the past knowledge of training other networks. We introduce a\nlarge-scale dataset of diverse computational graphs of neural architectures -\nDeepNets-1M - and use it to explore parameter prediction on CIFAR-10 and\nImageNet. By leveraging advances in graph neural networks, we propose a\nhypernetwork that can predict performant parameters in a single forward pass\ntaking a fraction of a second, even on a CPU. The proposed model achieves\nsurprisingly good performance on unseen and diverse networks. For example, it\nis able to predict all 24 million parameters of a ResNet-50 achieving a 60%\naccuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks\napproaches 50%. Our task along with the model and results can potentially lead\nto a new, more computationally efficient paradigm of training networks. Our\nmodel also learns a strong representation of neural architectures enabling\ntheir analysis.",
    "descriptor": "\nComments: NeurIPS 2021 camera ready, the code is available at this https URL\n",
    "authors": [
      "Boris Knyazev",
      "Michal Drozdzal",
      "Graham W. Taylor",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13100"
  },
  {
    "id": "arXiv:2110.13101",
    "title": "Latent-Insensitive Autoencoders for Anomaly Detection and  Class-Incremental Learning",
    "abstract": "Reconstruction-based approaches to anomaly detection tend to fall short when\napplied to complex datasets with target classes that possess high inter-class\nvariance. Similar to the idea of self-taught learning used in transfer\nlearning, many domains are rich with \\textit{similar} unlabeled datasets that\ncould be leveraged as a proxy for out-of-distribution samples. In this paper we\nintroduce Latent-Insensitive Autoencoder (LIS-AE) where unlabeled data from a\nsimilar domain is utilized as negative examples to shape the latent layer\n(bottleneck) of a regular autoencoder such that it is only capable of\nreconstructing one task. Since the underlying goal of LIS-AE is to only\nreconstruct in-distribution samples, this makes it naturally applicable in the\ndomain of class-incremental learning. We treat class-incremental learning as\nmultiple anomaly detection tasks by adding a different latent layer for each\nclass and use other available classes in task as negative examples to shape\neach latent layer. We test our model in multiple anomaly detection and\nclass-incremental settings presenting quantitative and qualitative analysis\nshowcasing the accuracy and the flexibility of our model for both anomaly\ndetection and class-incremental learning.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Muhammad S. Battikh",
      "Artem A. Lenskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13101"
  },
  {
    "id": "arXiv:2110.13103",
    "title": "Shift of Pairwise Similarities for Data Clustering",
    "abstract": "Several clustering methods (e.g., Normalized Cut and Ratio Cut) divide the\nMin Cut cost function by a cluster-dependent factor (e.g., the size or the\ndegree of the clusters), in order to yield a more balanced partitioning. We,\ninstead, investigate adding such regularizations to the original cost function.\nWe first consider the case where the regularization term is the sum of the\nsquared size of the clusters, and then generalize it to adaptive regularization\nof the pairwise similarities. This leads to shifting (adaptively) the pairwise\nsimilarities which might make some of them negative. We then study the\nconnection of this method to Correlation Clustering and then propose an\nefficient local search optimization algorithm with fast theoretical convergence\nrate to solve the new clustering problem. In the following, we investigate the\nshift of pairwise similarities on some common clustering methods, and finally,\nwe demonstrate the superior performance of the method by extensive experiments\non different datasets.",
    "descriptor": "",
    "authors": [
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13103"
  },
  {
    "id": "arXiv:2110.13107",
    "title": "STransGAN: An Empirical Study on Transformer in GANs",
    "abstract": "Transformer becomes prevalent in computer vision, especially for high-level\nvision tasks. However, deploying Transformer in the generative adversarial\nnetwork (GAN) framework is still an open yet challenging problem. In this\npaper, we conduct a comprehensive empirical study to investigate the intrinsic\nproperties of Transformer in GAN for high-fidelity image synthesis. Our\nanalysis highlights the importance of feature locality in image generation. We\nfirst investigate the effective ways to implement local attention. We then\nexamine the influence of residual connections in self-attention layers and\npropose a novel way to reduce their negative impacts on learning discriminators\nand conditional generators. Our study leads to a new design of Transformers in\nGAN, a convolutional neural network (CNN)-free generator termed as STrans-G,\nwhich achieves competitive results in both unconditional and conditional image\ngenerations. The Transformer-based discriminator, STrans-D, also significantly\nreduces its gap against the CNN-based discriminators.",
    "descriptor": "\nComments: Technical Report. Project Page: this https URL\n",
    "authors": [
      "Rui Xu",
      "Xiangyu Xu",
      "Kai Chen",
      "Bolei Zhou",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13107"
  },
  {
    "id": "arXiv:2110.13110",
    "title": "Diagnosing Errors in Video Relation Detectors",
    "abstract": "Video relation detection forms a new and challenging problem in computer\nvision, where subjects and objects need to be localized spatio-temporally and a\npredicate label needs to be assigned if and only if there is an interaction\nbetween the two. Despite recent progress in video relation detection, overall\nperformance is still marginal and it remains unclear what the key factors are\ntowards solving the problem. Following examples set in the object detection and\naction localization literature, we perform a deep dive into the error diagnosis\nof current video relation detection approaches. We introduce a diagnostic tool\nfor analyzing the sources of detection errors. Our tool evaluates and compares\ncurrent approaches beyond the single scalar metric of mean Average Precision by\ndefining different error types specific to video relation detection, used for\nfalse positive analyses. Moreover, we examine different factors of influence on\nthe performance in a false negative analysis, including relation length, number\nof subject/object/predicate instances, and subject/object size. Finally, we\npresent the effect on video relation performance when considering an oracle fix\nfor each error type. On two video relation benchmarks, we show where current\napproaches excel and fall short, allowing us to pinpoint the most important\nfuture directions in the field. The tool is available at\n\\url{https://github.com/shanshuo/DiagnoseVRD}.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Shuo Chen",
      "Pascal Mettes",
      "Cees G.M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13110"
  },
  {
    "id": "arXiv:2110.13116",
    "title": "Learning-Augmented Dynamic Power Management with Multiple States via New  Ski Rental Bounds",
    "abstract": "We study the online problem of minimizing power consumption in systems with\nmultiple power-saving states. During idle periods of unknown lengths, an\nalgorithm has to choose between power-saving states of different energy\nconsumption and wake-up costs. We develop a learning-augmented online algorithm\nthat makes decisions based on (potentially inaccurate) predicted lengths of the\nidle periods. The algorithm's performance is near-optimal when predictions are\naccurate and degrades gracefully with increasing prediction error, with a\nworst-case guarantee almost identical to the optimal classical online algorithm\nfor the problem. A key ingredient in our approach is a new algorithm for the\nonline ski rental problem in the learning augmented setting with tight\ndependence on the prediction error. We support our theoretical findings with\nexperiments.",
    "descriptor": "",
    "authors": [
      "Antonios Antoniadis",
      "Christian Coester",
      "Marek Eli\u00e1\u0161",
      "Adam Polak",
      "Bertrand Simon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13116"
  },
  {
    "id": "arXiv:2110.13128",
    "title": "Detecting Wandering Behavior of People with Dementia",
    "abstract": "Wandering is a problematic behavior in people with dementia that can lead to\ndangerous situations. To alleviate this problem we design an approach for the\nreal-time automatic detection of wandering leading to getting lost. The\napproach relies on GPS data to determine frequent locations between which\nmovement occurs and a step that transforms GPS data into geohash sequences.\nThose can be used to find frequent and normal movement patterns in historical\ndata to then be able to determine whether a new on-going sequence is anomalous.\nWe conduct experiments on synthetic data to test the ability of the approach to\nfind frequent locations and to compare it against an alternative,\nstate-of-the-art approach. Our approach is able to identify frequent locations\nand to obtain good performance (up to AUC = 0.99 for certain parameter\nsettings) outperforming the state-of-the-art approach.",
    "descriptor": "",
    "authors": [
      "Nicklas Sindlev Andersen",
      "Marco Chiarandini",
      "Stefan J\u00e4nicke",
      "Panagiotis Tampakis",
      "Arthur Zimek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13128"
  },
  {
    "id": "arXiv:2110.13130",
    "title": "Multichannel Speech Enhancement without Beamforming",
    "abstract": "Deep neural networks are often coupled with traditional spatial filters, such\nas MVDR beamformers for effectively exploiting spatial information. Even though\nsingle-stage end-to-end supervised models can obtain impressive enhancement,\ncombining them with a beamformer and a DNN-based post-filter in a multistage\nprocessing provides additional improvements. In this work, we propose a\ntwo-stage strategy for multi-channel speech enhancement that does not need a\nbeamformer for additional performance. First, we propose a novel attentive\ndense convolutional network (ADCN) for predicting real and imaginary parts of\ncomplex spectrogram. ADCN obtains state-of-the-art results among single-stage\nmodels. Next, we use ADCN in the proposed strategy with a recently proposed\ntriple-path attentive recurrent network (TPARN) for predicting waveform\nsamples. The proposed strategy uses two insights; first, using different\napproaches in two stages; and second, using a stronger model in the first\nstage. We illustrate the efficacy of our strategy by evaluating multiple models\nin a two-stage approach with and without beamformer.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Asutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13130"
  },
  {
    "id": "arXiv:2110.13136",
    "title": "What Would Jiminy Cricket Do? Towards Agents That Behave Morally",
    "abstract": "When making everyday decisions, people are guided by their conscience, an\ninternal sense of right and wrong. By contrast, artificial agents are currently\nnot endowed with a moral sense. As a consequence, they may learn to behave\nimmorally when trained on environments that ignore moral concerns, such as\nviolent video games. With the advent of generally capable agents that pretrain\non many environments, it will become necessary to mitigate inherited biases\nfrom environments that teach immoral behavior. To facilitate the development of\nagents that avoid causing wanton harm, we introduce Jiminy Cricket, an\nenvironment suite of 25 text-based adventure games with thousands of diverse,\nmorally salient scenarios. By annotating every possible game state, the Jiminy\nCricket environments robustly evaluate whether agents can act morally while\nmaximizing reward. Using models with commonsense moral knowledge, we create an\nelementary artificial conscience that assesses and guides agents. In extensive\nexperiments, we find that the artificial conscience approach can steer agents\ntowards moral behavior without sacrificing performance.",
    "descriptor": "\nComments: NeurIPS 2021. Environments available here this https URL\n",
    "authors": [
      "Dan Hendrycks",
      "Mantas Mazeika",
      "Andy Zou",
      "Sahil Patel",
      "Christine Zhu",
      "Jesus Navarro",
      "Dawn Song",
      "Bo Li",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13136"
  },
  {
    "id": "arXiv:2008.10872",
    "title": "Towards a noncommutative Picard-Vessiot theory",
    "abstract": "A Chen generating series, along a path and with respect to $m$ differential\nforms,is a noncommutative series on $m$ letters and with coefficients which are\nholomorphic functionsover a simply connected manifold in other words a series\nwith variable (holomorphic) coefficients.Such a series satisfies a first order\nnoncommutative differential equation which is considered, bysome authors, as\nthe universal differential equation, (i.e.) universality can beseen by\nreplacing each letter by constant matrices (resp. analytic vector fields)and\nthen solving a system of linear (resp. nonlinear) differential equations.Via\nrational series, on noncommutative indeterminates and with coefficients in\nrings, andtheir non-trivial combinatorial Hopf algebras, we give the first step\nof a noncommutativePicard-Vessiot theory and we illustrate it with the case of\nlinear differential equationswith singular regular singularities thanks to the\nuniversal equation previously mentioned.",
    "descriptor": "",
    "authors": [
      "G. Duchamp",
      "Viincel Hoang Ngoc Minh",
      "Vu Nguyen Dinh",
      "Pierre Simonnet"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2008.10872"
  },
  {
    "id": "arXiv:2103.17238",
    "title": "PySDM v1: particle-based cloud modelling package for warm-rain  microphysics and aqueous chemistry",
    "abstract": "PySDM is an open-source Python package for simulating the dynamics of\nparticles undergoing condensational and collisional growth, interacting with a\nfluid flow and subject to chemical composition changes. It is intended to serve\nas a building block for process-level as well as computational-fluid-dynamics\nsimulation systems involving representation of a continuous phase (air) and a\ndispersed phase (aerosol), with PySDM being responsible for representation of\nthe dispersed phase. The PySDM package core is a Pythonic high-performance\nimplementation of the Super-Droplet Method (SDM) Monte-Carlo algorithm for\nrepresenting collisional growth, hence the name. PySDM has two alternative\nparallel number-crunching backends available: multi-threaded CPU backend based\non Numba and GPU-resident backend built on top of ThrustRTC. The usage examples\nare built on top of four simple atmospheric cloud modelling frameworks: box,\nadiabatic parcel, single-column and 2D prescribed flow kinematic models. In\naddition, the package ships with tutorial code depicting how PySDM can be used\nfrom Julia and Matlab.",
    "descriptor": "",
    "authors": [
      "Piotr Bartman",
      "Oleksii Bulenok",
      "Kamil G\u00f3rski",
      "Anna Jaruga",
      "Grzegorz \u0141azarski",
      "Michael Olesik",
      "Bartosz Piasecki",
      "Clare E. Singer",
      "Aleksandra Talar",
      "Sylwester Arabas"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2103.17238"
  },
  {
    "id": "arXiv:2110.11995",
    "title": "PhotoWCT$^2$: Compact Autoencoder for Photorealistic Style Transfer  Resulting from Blockwise Training and Skip Connections of High-Frequency  Residuals",
    "abstract": "Photorealistic style transfer is an image editing task with the goal to\nmodify an image to match the style of another image while ensuring the result\nlooks like a real photograph. A limitation of existing models is that they have\nmany parameters, which in turn prevents their use for larger image resolutions\nand leads to slower run-times. We introduce two mechanisms that enable our\ndesign of a more compact model that we call PhotoWCT$^2$, which preserves\nstate-of-art stylization strength and photorealism. First, we introduce\nblockwise training to perform coarse-to-fine feature transformations that\nenable state-of-art stylization strength in a single autoencoder in place of\nthe inefficient cascade of four autoencoders used in PhotoWCT. Second, we\nintroduce skip connections of high-frequency residuals in order to preserve\nimage quality when applying the sequential coarse-to-fine feature\ntransformations. Our PhotoWCT$^2$ model requires fewer parameters (e.g., 30.3\\%\nfewer) while supporting higher resolution images (e.g., 4K) and achieving\nfaster stylization than existing models.",
    "descriptor": "",
    "authors": [
      "Tai-Yin Chiu",
      "Danna Gurari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11995"
  },
  {
    "id": "arXiv:2110.11996",
    "title": "The Eigenvectors of Single-spiked Complex Wishart Matrices: Finite and  Asymptotic Analyses",
    "abstract": "Let $\\mathbf{W}\\in\\mathbb{C}^{n\\times n}$ be a {\\it single-spiked} Wishart\nmatrix in the class $\\mathbf{W}\\sim \\mathcal{CW}_n(m,\\mathbf{I}_n+ \\theta\n\\mathbf{v}\\mathbf{v}^\\dagger) $ with $m\\geq n$, where $\\mathbf{I}_n$ is the\n$n\\times n$ identity matrix, $\\mathbf{v}\\in\\mathbb{C}^{n\\times 1}$ is an\narbitrary vector with unit Euclidean norm, $\\theta\\geq 0$ is a non-random\nparameter, and $(\\cdot)^\\dagger$ represents the conjugate-transpose operator.\nLet $\\mathbf{u}_1$ and $\\mathbf{u}_n$ denote the eigenvectors corresponding to\nthe samllest and the largest eigenvalues of $\\mathbf{W}$, respectively. This\npaper investigates the probability density function (p.d.f.) of the random\nquantity\n$Z_{\\ell}^{(n)}=\\left|\\mathbf{v}^\\dagger\\mathbf{u}_\\ell\\right|^2\\in(0,1)$ for\n$\\ell=1,n$. In particular, we derive a finite dimensional closed-form p.d.f.\nfor $Z_{1}^{(n)}$ which is amenable to asymptotic analysis as $m,n$ diverges\nwith $m-n$ fixed. It turns out that, in this asymptotic regime, the scaled\nrandom variable $nZ_{1}^{(n)}$ converges in distribution to\n$\\chi^2_2/2(1+\\theta)$, where $\\chi_2^2$ denotes a chi-squared random variable\nwith two degrees of freedom. This reveals that $\\mathbf{u}_1$ can be used to\ninfer information about the spike. On the other hand, the finite dimensional\np.d.f. of $Z_{n}^{(n)}$ is expressed as a double integral in which the\nintegrand contains a determinant of a square matrix of dimension $(n-2)$.\nAlthough a simple solution to this double integral seems intractable, for\nspecial configurations of $n=2,3$, and $4$, we obtain closed-form expressions.",
    "descriptor": "",
    "authors": [
      "Prathapasinghe Dharmawansa",
      "Pasan Dissanayake",
      "Yang Chen"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11996"
  },
  {
    "id": "arXiv:2110.11998",
    "title": "Semi-Supervised Semantic Segmentation of Vessel Images using Leaking  Perturbations",
    "abstract": "Semantic segmentation based on deep learning methods can attain appealing\naccuracy provided large amounts of annotated samples. However, it remains a\nchallenging task when only limited labelled data are available, which is\nespecially common in medical imaging. In this paper, we propose to use Leaking\nGAN, a GAN-based semi-supervised architecture for retina vessel semantic\nsegmentation. Our key idea is to pollute the discriminator by leaking\ninformation from the generator. This leads to more moderate generations that\nbenefit the training of GAN. As a result, the unlabelled examples can be better\nutilized to boost the learning of the discriminator, which eventually leads to\nstronger classification performance. In addition, to overcome the variations in\nmedical images, the mean-teacher mechanism is utilized as an auxiliary\nregularization of the discriminator. Further, we modify the focal loss to fit\nit as the consistency objective for mean-teacher regularizer. Extensive\nexperiments demonstrate that the Leaking GAN framework achieves competitive\nperformance compared to the state-of-the-art methods when evaluated on\nbenchmark datasets including DRIVE, STARE and CHASE\\_DB1, using as few as 8\nlabelled images in the semi-supervised setting. It also outperforms existing\nalgorithms on cross-domain segmentation tasks.",
    "descriptor": "\nComments: To appear in WACV'22\n",
    "authors": [
      "Jinyong Hou",
      "Xuejie Ding",
      "Jeremiah D. Deng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11998"
  },
  {
    "id": "arXiv:2110.11999",
    "title": "Machine Learning in Finance-Emerging Trends and Challenges",
    "abstract": "The paradigm of machine learning and artificial intelligence has pervaded our\neveryday life in such a way that it is no longer an area for esoteric academics\nand scientists putting their effort to solve a challenging research problem.\nThe evolution is quite natural rather than accidental. With the exponential\ngrowth in processing speed and with the emergence of smarter algorithms for\nsolving complex and challenging problems, organizations have found it possible\nto harness a humongous volume of data in realizing solutions that have\nfar-reaching business values. This introductory chapter highlights some of the\nchallenges and barriers that organizations in the financial services sector at\nthe present encounter in adopting machine learning and artificial\nintelligence-based models and applications in their day-to-day operations.",
    "descriptor": "\nComments: The chapter is 12 pages long and will appear as the introductory chapter in the book titled \"Machine Learning: Algorithms, Models, and Applications\" edited by Jaydip Sen, published by IntechOpen Publishers, London, UK in November 2021. It will be published in open-access mode\n",
    "authors": [
      "Jaydip Sen",
      "Rajdeep Sen",
      "Abhishek Dutta"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11999"
  },
  {
    "id": "arXiv:2110.12000",
    "title": "Bank transactions embeddings help to uncover current macroeconomics",
    "abstract": "Macroeconomic indexes are of high importance for banks: many risk-control\ndecisions utilize these indexes. A typical workflow of these indexes evaluation\nis costly and protracted, with a lag between the actual date and available\nindex being a couple of months. Banks predict such indexes now using\nautoregressive models to make decisions in a rapidly changing environment.\nHowever, autoregressive models fail in complex scenarios related to appearances\nof crises.\nWe propose to use clients' financial transactions data from a large Russian\nbank to get such indexes. Financial transactions are long, and a number of\nclients is huge, so we develop an efficient approach that allows fast and\naccurate estimation of macroeconomic indexes based on a stream of transactions\nconsisting of millions of transactions. The approach uses a neural networks\nparadigm and a smart sampling scheme.\nThe results show that our neural network approach outperforms the baseline\nmethod on hand-crafted features based on transactions. Calculated embeddings\nshow the correlation between the client's transaction activity and bank\nmacroeconomic indexes over time.",
    "descriptor": "",
    "authors": [
      "Maria Begicheva",
      "Oleg Travkin",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12000"
  },
  {
    "id": "arXiv:2110.12003",
    "title": "Embracing advanced AI/ML to help investors achieve success: Vanguard  Reinforcement Learning for Financial Goal Planning",
    "abstract": "In the world of advice and financial planning, there is seldom one right\nanswer. While traditional algorithms have been successful in solving linear\nproblems, its success often depends on choosing the right features from a\ndataset, which can be a challenge for nuanced financial planning scenarios.\nReinforcement learning is a machine learning approach that can be employed with\ncomplex data sets where picking the right features can be nearly impossible. In\nthis paper, we will explore the use of machine learning for financial\nforecasting, predicting economic indicators, and creating a savings strategy.\nVanguard ML algorithm for goals-based financial planning is based on deep\nreinforcement learning that identifies optimal savings rates across multiple\ngoals and sources of income to help clients achieve financial success. Vanguard\nlearning algorithms are trained to identify market indicators and behaviors too\ncomplex to capture with formulas and rules, instead, it works to model the\nfinancial success trajectory of investors and their investment outcomes as a\nMarkov decision process. We believe that reinforcement learning can be used to\ncreate value for advisors and end-investors, creating efficiency, more\npersonalized plans, and data to enable customized solutions.",
    "descriptor": "",
    "authors": [
      "Shareefuddin Mohammed",
      "Rusty Bealer",
      "Jason Cohen"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12003"
  },
  {
    "id": "arXiv:2110.12006",
    "title": "Uncertainty aware anomaly detection to predict errant beam pulses in the  SNS accelerator",
    "abstract": "High-power particle accelerators are complex machines with thousands of\npieces of equipmentthat are frequently running at the cutting edge of\ntechnology. In order to improve the day-to-dayoperations and maximize the\ndelivery of the science, new analytical techniques are being exploredfor\nanomaly detection, classification, and prognostications. As such, we describe\nthe applicationof an uncertainty aware Machine Learning method, the Siamese\nneural network model, to predictupcoming errant beam pulses using the data from\na single monitoring device. By predicting theupcoming failure, we can stop the\naccelerator before damage occurs. We describe the acceleratoroperation, related\nMachine Learning research, the prediction performance required to abort\nbeamwhile maintaining operations, the monitoring device and its data, and the\nSiamese method andits results. These results show that the researched method\ncan be applied to improve acceleratoroperations.",
    "descriptor": "\nComments: 11 pages, 15 figures, for PR-AB\n",
    "authors": [
      "Willem Blokland",
      "Pradeep Ramuhalli",
      "Charles Peters",
      "Yigit Yucesan",
      "Alexander Zhukov",
      "Malachi Schram",
      "Kishansingh Rajput",
      "Torri Jeske"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12006"
  },
  {
    "id": "arXiv:2110.12046",
    "title": "Uncertainty Quantification For Low-Rank Matrix Completion With  Heterogeneous and Sub-Exponential Noise",
    "abstract": "The problem of low-rank matrix completion with heterogeneous and\nsub-exponential (as opposed to homogeneous and Gaussian) noise is particularly\nrelevant to a number of applications in modern commerce. Examples include panel\nsales data and data collected from web-commerce systems such as recommendation\nengines. An important unresolved question for this problem is characterizing\nthe distribution of estimated matrix entries under common low-rank estimators.\nSuch a characterization is essential to any application that requires\nquantification of uncertainty in these estimates and has heretofore only been\navailable under the assumption of homogenous Gaussian noise. Here we\ncharacterize the distribution of estimated matrix entries when the observation\nnoise is heterogeneous sub-exponential and provide, as an application, explicit\nformulas for this distribution when observed entries are Poisson or Binary\ndistributed.",
    "descriptor": "",
    "authors": [
      "Vivek F. Farias",
      "Andrew A. Li",
      "Tianyi Peng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12046"
  },
  {
    "id": "arXiv:2110.12058",
    "title": "Development of Semantic Web-based Imaging Database for Biological  Morphome",
    "abstract": "We introduce the RIKEN Microstructural Imaging Metadatabase, a semantic\nweb-based imaging database in which image metadata are described using the\nResource Description Framework (RDF) and detailed biological properties\nobserved in the images can be represented as Linked Open Data. The metadata are\nused to develop a large-scale imaging viewer that provides a straightforward\ngraphical user interface to visualise a large microstructural tiling image at\nthe gigabyte level. We applied the database to accumulate comprehensive\nmicrostructural imaging data produced by automated scanning electron\nmicroscopy. As a result, we have successfully managed vast numbers of images\nand their metadata, including the interpretation of morphological phenotypes\noccurring in sub-cellular components and biosamples captured in the images. We\nalso discuss advanced utilisation of morphological imaging data that can be\npromoted by this database.",
    "descriptor": "",
    "authors": [
      "Satoshi Kume",
      "Hiroshi Masuya",
      "Mitsuyo Maeda",
      "Mitsuo Suga",
      "Yosky Kataoka",
      "Norio Kobayashi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12058"
  },
  {
    "id": "arXiv:2110.12065",
    "title": "Multiplication-Avoiding Variant of Power Iteration with Applications",
    "abstract": "Power iteration is a fundamental algorithm in data analysis. It extracts the\neigenvector corresponding to the largest eigenvalue of a given matrix.\nApplications include ranking algorithms, recommendation systems, principal\ncomponent analysis (PCA), among many others. In this paper, We introduce\nmultiplication-avoiding power iteration (MAPI), which replaces the standard\n$\\ell_2$-inner products that appear at the regular power iteration (RPI) with\nmultiplication-free vector products which are Mercer-type kernel operations\nrelated with the $\\ell_1$ norm. Precisely, for an $n\\times n$ matrix, MAPI\nrequires $n$ multiplications, while RPI needs $n^2$ multiplications per\niteration. Therefore, MAPI provides a significant reduction of the number of\nmultiplication operations, which are known to be costly in terms of energy\nconsumption. We provide applications of MAPI to PCA-based image reconstruction\nas well as to graph-based ranking algorithms. When compared to RPI, MAPI not\nonly typically converges much faster, but also provides superior performance.",
    "descriptor": "",
    "authors": [
      "Hongyi Pan",
      "Diaa Badawi",
      "Runxuan Miao",
      "Erdem Koyuncu",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12065"
  },
  {
    "id": "arXiv:2110.12067",
    "title": "Gaussian Graphical Model Selection for Huge Data via Minipatch Learning",
    "abstract": "Gaussian graphical models are essential unsupervised learning techniques to\nestimate conditional dependence relationships between sets of nodes. While\ngraphical model selection is a well-studied problem with many popular\ntechniques, there are typically three key practical challenges: i) many\nexisting methods become computationally intractable in huge-data settings with\ntens of thousands of nodes; ii) the need for separate data-driven tuning\nhyperparameter selection procedures considerably adds to the computational\nburden; iii) the statistical accuracy of selected edges often deteriorates as\nthe dimension and/or the complexity of the underlying graph structures\nincrease. We tackle these problems by proposing the Minipatch Graph (MPGraph)\nestimator. Our approach builds upon insights from the latent variable graphical\nmodel problem and utilizes ensembles of thresholded graph estimators fit to\ntiny, random subsets of both the observations and the nodes, termed\nminipatches. As estimates are fit on small problems, our approach is\ncomputationally fast with integrated stability-based hyperparameter tuning.\nAdditionally, we prove that under certain conditions our MPGraph algorithm\nachieves finite-sample graph selection consistency. We compare our approach to\nstate-of-the-art computational approaches to Gaussian graphical model selection\nincluding the BigQUIC algorithm, and empirically demonstrate that our approach\nis not only more accurate but also extensively faster for huge graph selection\nproblems.",
    "descriptor": "",
    "authors": [
      "Tianyi Yao",
      "Minjie Wang",
      "Genevera I. Allen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12067"
  },
  {
    "id": "arXiv:2110.12071",
    "title": "A randomized quantum algorithm for statistical phase estimation",
    "abstract": "Phase estimation is a quantum algorithm for measuring the eigenvalues of a\nHamiltonian. We propose and rigorously analyse a randomized phase estimation\nalgorithm with two distinctive features. First, our algorithm has complexity\nindependent of the number of terms L in the Hamiltonian. Second, unlike\nprevious L-independent approaches, such as those based on qDRIFT, all sources\nof error in our algorithm can be suppressed by collecting more data samples,\nwithout increasing the circuit depth.",
    "descriptor": "\nComments: 5+18 pages, 3 figures\n",
    "authors": [
      "Kianna Wan",
      "Mario Berta",
      "Earl T. Campbell"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.12071"
  },
  {
    "id": "arXiv:2110.12096",
    "title": "Molecular Dynamics on Quantum Annealers",
    "abstract": "In this work we demonstrate a practical prospect of using quantum annealers\nfor simulation of molecular dynamics. A methodology developed for this goal,\ndubbed Quantum Differential Equations (QDE), is applied to propagate classical\ntrajectories for the vibration of the hydrogen molecule in several regimes:\nnearly harmonic, highly anharmonic, and dissociative motion. The results\nobtained using the D-Wave 2000Q quantum annealer are all consistent and quickly\nconverge to the analytical reference solution. Several alternative strategies\nfor such calculations are explored and it was found that the most accurate\nresults and the best efficiency are obtained by combining the quantum annealer\nwith classical post-processing (greedy algorithm). Importantly, the QDE\nframework developed here is entirely general and can be applied to solve any\nsystem of first-order ordinary nonlinear differential equations using a quantum\nannealer.",
    "descriptor": "",
    "authors": [
      "Igor Gayday",
      "Dmitri Babikov",
      "Alexander Teplukhin",
      "Brian K. Kendrick",
      "Susan M. Mniszewski",
      "Yu Zhang",
      "Sergei Tretiak",
      "Pavel A. Dub"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.12096"
  },
  {
    "id": "arXiv:2110.12112",
    "title": "Why Machine Learning Cannot Ignore Maximum Likelihood Estimation",
    "abstract": "The growth of machine learning as a field has been accelerating with\nincreasing interest and publications across fields, including statistics, but\npredominantly in computer science. How can we parse this vast literature for\ndevelopments that exemplify the necessary rigor? How many of these manuscripts\nincorporate foundational theory to allow for statistical inference? Which\nadvances have the greatest potential for impact in practice? One could posit\nmany answers to these queries. Here, we assert that one essential idea is for\nmachine learning to integrate maximum likelihood for estimation of functional\nparameters, such as prediction functions and conditional densities.",
    "descriptor": "\nComments: 30 pages. Forthcoming as a chapter in the Handbook of Matching and Weighting in Causal Inference\n",
    "authors": [
      "Mark J. van der Laan",
      "Sherri Rose"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12112"
  },
  {
    "id": "arXiv:2110.12114",
    "title": "Dense Dual-Attention Network for Light Field Image Super-Resolution",
    "abstract": "Light field (LF) images can be used to improve the performance of image\nsuper-resolution (SR) because both angular and spatial information is\navailable. It is challenging to incorporate distinctive information from\ndifferent views for LF image SR. Moreover, the long-term information from the\nprevious layers can be weakened as the depth of network increases. In this\npaper, we propose a dense dual-attention network for LF image SR. Specifically,\nwe design a view attention module to adaptively capture discriminative features\nacross different views and a channel attention module to selectively focus on\ninformative information across all channels. These two modules are fed to two\nbranches and stacked separately in a chain structure for adaptive fusion of\nhierarchical features and distillation of valid information. Meanwhile, a dense\nconnection is used to fully exploit multi-level information. Extensive\nexperiments demonstrate that our dense dual-attention mechanism can capture\ninformative information across views and channels to improve SR performance.\nComparative results show the advantage of our method over state-of-the-art\nmethods on public datasets.",
    "descriptor": "\nComments: Accept by IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Yu Mo",
      "Yingqian Wang",
      "Chao Xiao",
      "Jungang Yang",
      "Wei An"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12114"
  },
  {
    "id": "arXiv:2110.12121",
    "title": "On Geometric Connections of Embedded and Quotient Geometries in  Riemannian Fixed-rank Matrix Optimization",
    "abstract": "In this paper, we propose a general procedure for establishing the landscape\nconnections of a Riemannian optimization problem under the embedded and\nquotient geometries. By applying the general procedure to the fixed-rank\npositive semidefinite (PSD) and general matrix optimization, we establish an\nexact Riemannian gradient connection under two geometries at every point on the\nmanifold and sandwich inequalities between the spectra of Riemannian Hessians\nat Riemannian first-order stationary points (FOSPs). These results immediately\nimply an equivalence on the sets of Riemannian FOSPs, Riemannian second-order\nstationary points (SOSPs) and strict saddles of fixed-rank matrix optimization\nunder the embedded and the quotient geometries. To the best of our knowledge,\nthis is the first geometric landscape connection between the embedded and the\nquotient geometries for fixed-rank matrix optimization and it provides a\nconcrete example on how these two geometries are connected in Riemannian\noptimization. In addition, the effects of the Riemannian metric and quotient\nstructure on the landscape connection are discussed. We also observe an\nalgorithmic connection for fixed-rank matrix optimization under two geometries\nwith some specific Riemannian metrics. A number of novel ideas and technical\ningredients including a unified treatment for different Riemannian metrics and\nnew horizontal space representations under quotient geometries are developed to\nobtain our results. The results in this paper deepen our understanding of\ngeometric connections of Riemannian optimization under different Riemannian\ngeometries and provide a few new theoretical insights to unanswered questions\nin the literature.",
    "descriptor": "",
    "authors": [
      "Yuetian Luo",
      "Xudong Li",
      "Anru R. Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12121"
  },
  {
    "id": "arXiv:2110.12142",
    "title": "Detecting cities with high intermediacy in the African urban network",
    "abstract": "Cities play different roles depending on their location within the transport\nnetwork. Two cities of similar size might have distinct characteristics if one\nis located on a corridor between two capitals and the other is near a barrier,\nsuch as a mountain range. The level of intermediacy is a property of cities\nthat characterises their position in the urban network. We measure the level of\nintermediacy of African cities by constructing the road infrastructure network\nobtained from OpenStreetMap. The infrastructure network allows defining city\nmetrics such as degree and centrality. A proxy for the number of journeys that\nflow through each network edge is approximated using a mathematical model based\non the level of attraction or gravity between all pairs of cities. Our model\nconsiders the extra time of crossing an international border as a parameter\nthat enables us to proxy the cost of having fragmented regions with costly\npolitical barriers. Our results show that small cities have a wide range of\nintermediacy. We detect a phase transition where cities with less than one\nmillion inhabitants have a centrality that depends on the size and degree. For\ncities above one million inhabitants, centrality tends to be larger and\ndepending primarily on city size rather than degree.",
    "descriptor": "",
    "authors": [
      "Rafael Prieto Curiel",
      "Abel Schumann",
      "Inhoi Heo",
      "Philipp Heinrigs"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.12142"
  },
  {
    "id": "arXiv:2110.12149",
    "title": "On Parameter Estimation in Unobserved Components Models subject to  Linear Inequality Constraints",
    "abstract": "We propose a new quadratic-programming-based method of approximating a\nnonstandard density using a multivariate Gaussian density. Such nonstandard\ndensities usually arise while developing posterior samplers for unobserved\ncomponents models involving inequality constraints on the parameters. For\ninstance, Chat et al. (2016) propose a new model of trend inflation with linear\ninequality constraints on the stochastic trend. We implement the proposed new\nmethod for this model and compare it to the existing approximation. We observe\nthat the proposed new method works as good as the existing approximation in\nterms of the final trend estimates while achieving greater gains in terms of\nsample efficiency.",
    "descriptor": "\nComments: 9 pages, 6 figures, Accepted for a poster presentation at MLECON: Machine Learning meets Econometrics workshop. 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Abhishek K. Umrawal",
      "Joshua C.C. Chan"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12149"
  },
  {
    "id": "arXiv:2110.12163",
    "title": "Adversarial Deep Feature Extraction Network for User Independent Human  Activity Recognition",
    "abstract": "User dependence remains one of the most difficult general problems in Human\nActivity Recognition (HAR), in particular when using wearable sensors. This is\ndue to the huge variability of the way different people execute even the\nsimplest actions. In addition, detailed sensor fixtures and placement will be\ndifferent for different people or even at different times for the same users.\nIn theory, the problem can be solved by a large enough data set. However,\nrecording data sets that capture the entire diversity of complex activity sets\nis seldom practicable. Instead, models are needed that focus on features that\nare invariant across users. To this end, we present an adversarial\nsubject-independent feature extraction method with the maximum mean discrepancy\n(MMD) regularization for human activity recognition. The proposed model is\ncapable of learning a subject-independent embedding feature representation from\nmultiple subjects datasets and generalizing it to unseen target subjects. The\nproposed network is based on the adversarial encoder-decoder structure with the\nMMD realign the data distribution over multiple subjects. Experimental results\nshow that the proposed method not only outperforms state-of-the-art methods\nover the four real-world datasets but also improves the subject generalization\neffectively. We evaluate the method on well-known public data sets showing that\nit significantly improves user-independent performance and reduces variance in\nresults.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Sungho Suh",
      "Vitor Fortes Rey",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12163"
  },
  {
    "id": "arXiv:2110.12175",
    "title": "Analysis of Thompson Sampling for Partially Observable Contextual  Multi-Armed Bandits",
    "abstract": "Contextual multi-armed bandits are classical models in reinforcement learning\nfor sequential decision-making associated with individual information. A\nwidely-used policy for bandits is Thompson Sampling, where samples from a\ndata-driven probabilistic belief about unknown parameters are used to select\nthe control actions. For this computationally fast algorithm, performance\nanalyses are available under full context-observations. However, little is\nknown for problems that contexts are not fully observed. We propose a Thompson\nSampling algorithm for partially observable contextual multi-armed bandits, and\nestablish theoretical performance guarantees. Technically, we show that the\nregret of the presented policy scales logarithmically with time and the number\nof arms, and linearly with the dimension. Further, we establish rates of\nlearning unknown parameters, and provide illustrative numerical analyses.",
    "descriptor": "\nComments: 22 pages, 4 figures, submitted to L-CSS and American Control Conference\n",
    "authors": [
      "Hongju Park",
      "Mohamad Kazem Shirani Faradonbeh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12175"
  },
  {
    "id": "arXiv:2110.12177",
    "title": "Vertebrae segmentation, identification and localization using a graph  optimization and a synergistic cycle",
    "abstract": "This paper considers the segmentation, identification and localization of\nvertebrae in CT images. Although these three tasks are related, they face\nspecific problems that add up when they are addressed together. For example\nneighboring vertebrae with similar shapes perturb the identification and\nvertebrae with complex or even pathological morphologies impact the\nsegmentation. Consequently, the three tasks tend to be approached\nindependently, e.g. labelling (localization and identification) or segmenting\nonly, or, when treated globally, a sequential strategy is used. Sequential\nmethods however are prone to accumulate errors as they are not able to recover\nfrom mistakes of the previous module. In this work, we propose to combine all\nthree tasks and leverage their interdependence: locations ease the\nsegmentation, the segmentations in turn improve the locations and they all\ncontribute and benefit from the identification task. To this purpose we propose\na virtuous cycle to enforce coherence between the three tasks. Within such a\ncycle, the tasks interoperate and are iterated until a global consistency\ncriterion is satisfied. Our experiments validate this strategy with\nanatomically coherent results that outperform the state of the art on the\nVerSe20 challenge benchmark. Our code and model are openly available for\nresearch purposes at https://gitlab.inria.fr/spine/vertebrae_segmentation.",
    "descriptor": "",
    "authors": [
      "Di Meng",
      "Eslam Mohammed",
      "Edmond Boyer",
      "Sergi Pujades"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12177"
  },
  {
    "id": "arXiv:2110.12192",
    "title": "Dual Shape Guided Segmentation Network for Organs-at-Risk in Head and  Neck CT Images",
    "abstract": "The accurate segmentation of organs-at-risk (OARs) in head and neck CT images\nis a critical step for radiation therapy of head and neck cancer patients.\nHowever, manual delineation for numerous OARs is time-consuming and laborious,\neven for expert oncologists. Moreover, manual delineation results are\nsusceptible to high intra- and inter-variability. To this end, we propose a\nnovel dual shape guided network (DSGnet) to automatically delineate nine\nimportant OARs in head and neck CT images. To deal with the large shape\nvariation and unclear boundary of OARs in CT images, we represent the organ\nshape using an organ-specific unilateral inverse-distance map (UIDM) and guide\nthe segmentation task from two different perspectives: direct shape guidance by\nfollowing the segmentation prediction and across shape guidance by sharing the\nsegmentation feature. In the direct shape guidance, the segmentation prediction\nis not only supervised by the true label mask, but also by the true UIDM, which\nis implemented through a simple yet effective encoder-decoder mapping from the\nlabel space to the distance space. In the across shape guidance, UIDM is used\nto facilitate the segmentation by optimizing the shared feature maps. For the\nexperiments, we build a large head and neck CT dataset with a total of 699\nimages from different volunteers, and conduct comprehensive experiments and\ncomparisons with other state-of-the-art methods to justify the effectiveness\nand efficiency of our proposed method. The overall Dice Similarity Coefficient\n(DSC) value of 0.842 across the nine important OARs demonstrates great\npotential applications in improving the delineation quality and reducing the\ntime cost.",
    "descriptor": "",
    "authors": [
      "Shuai Wang",
      "Theodore Yanagihara",
      "Bhishamjit Chera",
      "Colette Shen",
      "Pew-Thian Yap",
      "Jun Lian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12192"
  },
  {
    "id": "arXiv:2110.12221",
    "title": "Stochastic facilitation in heteroclinic communication channels",
    "abstract": "Biological neural systems encode and transmit information as patterns of\nactivity tracing complex trajectories in high-dimensional state-spaces,\ninspiring alternative paradigms of information processing. Heteroclinic\nnetworks, naturally emerging in artificial neural systems, are networks of\nsaddles in state-space that provide a transparent approach to generate complex\ntrajectories via controlled switches among interconnected saddles. External\nsignals induce specific switching sequences, thus dynamically encoding inputs\nas trajectories. Recent works have focused either on computational aspects of\nheteroclinic networks, i.e. Heteroclinic Computing, or their stochastic\nproperties under noise. Yet, how well such systems may transmit information\nremains an open question. Here we investigate the information transmission\nproperties of heteroclinic networks, studying them as communication channels.\nChoosing a tractable but representative system exhibiting a heteroclinic\nnetwork, we investigate the mutual information rate (MIR) between input signals\nand the resulting sequences of states as the level of noise varies.\nIntriguingly, MIR does not decrease monotonically with increasing noise.\nIntermediate noise levels indeed maximize the information transmission capacity\nby promoting an increased yet controlled exploration of the underlying network\nof states. Complementing standard stochastic resonance, these results highlight\nthe constructive effect of stochastic facilitation (i.e. noise-enhanced\ninformation transfer) on heteroclinic communication channels and possibly on\nmore general dynamical systems exhibiting complex trajectories in state-space.",
    "descriptor": "",
    "authors": [
      "Giovanni Sirio Carmantini",
      "Fabio Schittler Neves",
      "Marc Timme",
      "Serafim Rodrigues"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.12221"
  },
  {
    "id": "arXiv:2110.12270",
    "title": "Benchmarking of Lightweight Deep Learning Architectures for Skin Cancer  Classification using ISIC 2017 Dataset",
    "abstract": "Skin cancer is one of the deadly types of cancer and is common in the world.\nRecently, there has been a huge jump in the rate of people getting skin cancer.\nFor this reason, the number of studies on skin cancer classification with deep\nlearning are increasing day by day. For the growth of work in this area, the\nInternational Skin Imaging Collaboration (ISIC) organization was established\nand they created an open dataset archive. In this study, images were taken from\nISIC 2017 Challenge. The skin cancer images taken were preprocessed and data\naugmented. Later, these images were trained with transfer learning and\nfine-tuning approach and deep learning models were created in this way. 3\ndifferent mobile deep learning models and 3 different batch size values were\ndetermined for each, and a total of 9 models were created. Among these models,\nthe NASNetMobile model with 16 batch size got the best result. The accuracy\nvalue of this model is 82.00%, the precision value is 81.77% and the F1 score\nvalue is 0.8038. Our method is to benchmark mobile deep learning models which\nhave few parameters and compare the results of the models.",
    "descriptor": "\nComments: 4 pages, supplementary with 9 figures\n",
    "authors": [
      "Abdurrahim Yilmaz",
      "Mucahit Kalebasi",
      "Yegor Samoylenko",
      "Mehmet Erhan Guvenilir",
      "Huseyin Uvet"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12270"
  },
  {
    "id": "arXiv:2110.12274",
    "title": "\"One-Shot\" Reduction of Additive Artifacts in Medical Images",
    "abstract": "Medical images may contain various types of artifacts with different patterns\nand mixtures, which depend on many factors such as scan setting, machine\ncondition, patients' characteristics, surrounding environment, etc. However,\nexisting deep-learning-based artifact reduction methods are restricted by their\ntraining set with specific predetermined artifact types and patterns. As such,\nthey have limited clinical adoption. In this paper, we introduce One-Shot\nmedical image Artifact Reduction (OSAR), which exploits the power of deep\nlearning but without using pre-trained general networks. Specifically, we train\na light-weight image-specific artifact reduction network using data synthesized\nfrom the input image at test-time. Without requiring any prior large training\ndata set, OSAR can work with almost any medical images that contain varying\nadditive artifacts which are not in any existing data sets. In addition,\nComputed Tomography (CT) and Magnetic Resonance Imaging (MRI) are used as\nvehicles and show that the proposed method can reduce artifacts better than\nstate-of-the-art both qualitatively and quantitatively using shorter test time.",
    "descriptor": "",
    "authors": [
      "Yu-Jen Chen",
      "Yen-Jung Chang",
      "Shao-Cheng Wen",
      "Yiyu Shi",
      "Xiaowei Xu",
      "Tsung-Yi Ho",
      "Meiping Huang",
      "Haiyun Yuan",
      "Jian Zhuang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12274"
  },
  {
    "id": "arXiv:2110.12283",
    "title": "Perineural Invasion Detection in Multiple Organ Cancer Based on Deep  Convolutional Neural Network",
    "abstract": "Perineural invasion (PNI) by malignant tumor cells has been reported as an\nindependent indicator of poor prognosis in various cancers. Assessment of PNI\nin small nerves on glass slides is a labor-intensive task. In this study, we\npropose an algorithm to detect the perineural invasions in colon, prostate, and\npancreas cancers based on a convolutional neural network (CNN).",
    "descriptor": "",
    "authors": [
      "Ramin Nateghi",
      "Fattaneh Pourakpour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12283"
  },
  {
    "id": "arXiv:2110.12285",
    "title": "Generalized Resubstitution for Classification Error Estimation",
    "abstract": "We propose the family of generalized resubstitution classifier error\nestimators based on empirical measures. These error estimators are\ncomputationally efficient and do not require re-training of classifiers. The\nplain resubstitution error estimator corresponds to choosing the standard\nempirical measure. Other choices of empirical measure lead to bolstered,\nposterior-probability, Gaussian-process, and Bayesian error estimators; in\naddition, we propose bolstered posterior-probability error estimators as a new\nfamily of generalized resubstitution estimators. In the two-class case, we show\nthat a generalized resubstitution estimator is consistent and asymptotically\nunbiased, regardless of the distribution of the features and label, if the\ncorresponding generalized empirical measure converges uniformly to the standard\nempirical measure and the classification rule has a finite VC dimension. A\ngeneralized resubstitution estimator typically has hyperparameters that can be\ntuned to control its bias and variance, which adds flexibility. Numerical\nexperiments with various classification rules trained on synthetic data assess\nthe thefinite-sample performance of several representative generalized\nresubstitution error estimators. In addition, results of an image\nclassification experiment using the LeNet-5 convolutional neural network and\nthe MNIST data set demonstrate the potential of this class of error estimators\nin deep learning for computer vision.",
    "descriptor": "",
    "authors": [
      "Parisa Ghane",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12285"
  },
  {
    "id": "arXiv:2110.12288",
    "title": "Path Signature Area-Based Causal Discovery in Coupled Time Series",
    "abstract": "Coupled dynamical systems are frequently observed in nature, but often not\nwell understood in terms of their causal structure without additional domain\nknowledge about the system. Especially when analyzing observational time series\ndata of dynamical systems where it is not possible to conduct controlled\nexperiments, for example time series of climate variables, it can be\nchallenging to determine how features causally influence each other. There are\nmany techniques available to recover causal relationships from data, such as\nGranger causality, convergent cross mapping, and causal graph structure\nlearning approaches such as PCMCI. Path signatures and their associated signed\nareas provide a new way to approach the analysis of causally linked dynamical\nsystems, particularly in informing a model-free, data-driven approach to\nalgorithmic causal discovery. With this paper, we explore the use of path\nsignatures in causal discovery and propose the application of confidence\nsequences to analyze the significance of the magnitude of the signed area\nbetween two variables. These confidence sequence regions converge with greater\nsampling length, and in conjunction with analyzing pairwise signed areas across\ntime-shifted versions of the time series, can help identify the presence of\nlag/lead causal relationships. This approach provides a new way to define the\nconfidence of a causal link existing between two time series, and ultimately\nmay provide a framework for hypothesis testing to define whether one time\nseries causes another",
    "descriptor": "",
    "authors": [
      "Will Glad",
      "Thomas Woolf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12288"
  },
  {
    "id": "arXiv:2110.12304",
    "title": "A Study of Acoustic Features in Arabic Speaker Identification under  Noisy Environmental Conditions",
    "abstract": "One of the major parts of the voice recognition field is the choice of\nacoustic features which have to be robust against the variability of the speech\nsignal, mismatched conditions, and noisy environments. Thus, different speech\nfeature extraction techniques have been developed. In this paper, we\ninvestigate the robustness of several front-end techniques in Arabic speaker\nidentification. We evaluate five different features in babble, factory and\nsubway conditions at the various signal to noise ratios (SNR). The obtained\nresults showed that two of the auditory feature i.e. gammatone frequency\ncepstral coefficient (GFCC) and power normalization cepstral coefficients\n(PNCC), unlike their combination performs substantially better than a\nconventional speaker features i.e. Mel-frequency cepstral coefficients (MFCC).",
    "descriptor": "",
    "authors": [
      "Zhor Benhafid",
      "Kawthar Yasmine Zergat",
      "Abderrahmane Amrouche"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.12304"
  },
  {
    "id": "arXiv:2110.12347",
    "title": "Acceleration in Distributed Optimization Under Similarity",
    "abstract": "We study distributed (strongly convex) optimization problems over a network\nof agents, with no centralized nodes. The loss functions of the agents are\nassumed to be similar, due to statistical data similarity or otherwise. In\norder to reduce the number of communications to reach a solution accuracy, we\nproposed a preconditioned, accelerated distributed method. An\n$\\varepsilon$-solution is achieved in\n$\\tilde{\\mathcal{O}}\\big(\\sqrt{\\frac{\\beta/\\mu}{(1-\\rho)}}\\log1/\\varepsilon\\big)$\nnumber of communications steps, where $\\beta/\\mu$ is the relative condition\nnumber between the global and local loss functions, and $\\rho$ characterizes\nthe connectivity of the network. This rate matches (up to poly-log factors) for\nthe first time lower complexity communication bounds of distributed\ngossip-algorithms applied to the class of problems of interest. Numerical\nresults show significant communication savings with respect to existing\naccelerated distributed schemes, especially when solving ill-conditioned\nproblems.",
    "descriptor": "",
    "authors": [
      "Ye Tian",
      "Gesualdo Scutari",
      "Tianyu Cao",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12347"
  },
  {
    "id": "arXiv:2110.12351",
    "title": "Integrated Conditional Estimation-Optimization",
    "abstract": "Many real-world optimization problems involve uncertain parameters with\nprobability distributions that can be estimated using contextual feature\ninformation. In contrast to the standard approach of first estimating the\ndistribution of uncertain parameters and then optimizing the objective based on\nthe estimation, we propose an integrated conditional estimation-optimization\n(ICEO) framework that estimates the underlying conditional distribution of the\nrandom parameter while considering the structure of the optimization problem.\nWe directly model the relationship between the conditional distribution of the\nrandom parameter and the contextual features, and then estimate the\nprobabilistic model with an objective that aligns with the downstream\noptimization problem. We show that our ICEO approach is asymptotically\nconsistent under moderate regularity conditions and further provide finite\nperformance guarantees in the form of generalization bounds. Computationally,\nperforming estimation with the ICEO approach is a non-convex and often\nnon-differentiable optimization problem. We propose a general methodology for\napproximating the potentially non-differentiable mapping from estimated\nconditional distribution to the optimal decision by a differentiable function,\nwhich greatly improves the performance of gradient-based algorithms applied to\nthe non-convex problem. We also provide a polynomial optimization solution\napproach in the semi-algebraic case. Numerical experiments are also conducted\nto show the empirical success of our approach in different situations including\nwith limited data samples and model mismatches.",
    "descriptor": "",
    "authors": [
      "Paul Grigas",
      "Meng Qi",
      "Zuo-Jun",
      "Shen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12351"
  },
  {
    "id": "arXiv:2110.12371",
    "title": "Neural Embeddings of Urban Big Data Reveal Emergent Structures in Cities",
    "abstract": "In this study, we propose using a neural embedding model-graph neural network\n(GNN)- that leverages the heterogeneous features of urban areas and their\ninteractions captured by human mobility network to obtain vector\nrepresentations of these areas. Using large-scale high-resolution mobility data\nsets from millions of aggregated and anonymized mobile phone users in 16\nmetropolitan counties in the United States, we demonstrate that our embeddings\nencode complex relationships among features related to urban components (such\nas distribution of facilities) and population attributes and activities. The\nspatial gradient in each direction from city center to suburbs is measured\nusing clustered representations and the shared characteristics among urban\nareas in the same cluster. Furthermore, we show that embeddings generated by a\nmodel trained on a different county can capture 50% to 60% of the emergent\nspatial structure in another county, allowing us to make cross-county\ncomparisons in a quantitative way. Our GNN-based framework overcomes the\nlimitations of previous methods used for examining spatial structures and is\nhighly scalable. The findings reveal non-linear relationships among urban\ncomponents and anisotropic spatial gradients in cities. Since the identified\nspatial structures and gradients capture the combined effects of various\nmechanisms, such as segregation, disparate facility distribution, and human\nmobility, the findings could help identify the limitations of the current city\nstructure to inform planning decisions and policies. Also, the model and\nfindings set the stage for a variety of research in urban planning, engineering\nand social science through integrated understanding of how the complex\ninteractions between urban components and population activities and attributes\nshape the spatial structures in cities.",
    "descriptor": "\nComments: 17 pages, 5 figures, 1 table\n",
    "authors": [
      "Chao Fan",
      "Yang Yang",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.12371"
  },
  {
    "id": "arXiv:2110.12372",
    "title": "Uncertainty-Aware Lung Nodule Segmentation with Multiple Annotations",
    "abstract": "Since radiologists have different training and clinical experience, they may\nprovide various segmentation maps for a lung nodule. As a result, for a\nspecific lung nodule, some regions have a higher chance of causing segmentation\nuncertainty, which brings difficulty for lung nodule segmentation with multiple\nannotations. To address this problem, this paper proposes an Uncertainty-Aware\nSegmentation Network (UAS-Net) based on multi-branch U-Net, which can learn the\nvaluable visual features from the regions that may cause segmentation\nuncertainty and contribute to a better segmentation result. Meanwhile, this\nnetwork can provide a Multi-Confidence Mask (MCM) simultaneously, pointing out\nregions with different segmentation uncertainty levels. We introduce a\nFeature-Aware Concatenation structure for different learning targets and let\neach branch have a specific learning preference. Moreover, a joint adversarial\nlearning process is also adopted to help learn discriminative features of\ncomplex structures. Experimental results show that our method can predict the\nreasonable regions with higher uncertainty and improve lung nodule segmentation\nperformance in LIDC-IDRI.",
    "descriptor": "\nComments: 6 pages, 8 figures, 29 references\n",
    "authors": [
      "Qiuli Wang",
      "Han Yang",
      "Lu Shen",
      "Mengke Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12372"
  },
  {
    "id": "arXiv:2110.12379",
    "title": "Boson sampling discrete solitons by quantum machine learning",
    "abstract": "We use a neural network variational ansatz to compute Gaussian quantum\ndiscrete solitons in an array of waveguides described by the quantum discrete\nnonlinear Schroedinger equation. By training the quantum machine learning model\nin the phase space, we find different quantum soliton solutions varying the\nnumber of particles and interaction strength. The use of Gaussian states\nenables measuring the degree of entanglement and the boson sampling patterns.\nWe compute the probability of generating different particle pairs when varying\nthe soliton features and unveil that bound states of discrete solitons emit\ncorrelated pairs of photons. These results may have a role in boson sampling\nexperiments with nonlinear systems and in developing quantum processors to\ngenerate entangled many-photon nonlinear states.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Claudio Conti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.12379"
  },
  {
    "id": "arXiv:2110.12392",
    "title": "Variation is the Norm: Brain State Dynamics Evoked By Emotional Video  Clips",
    "abstract": "For the last several decades, emotion research has attempted to identify a\n\"biomarker\" or consistent pattern of brain activity to characterize a single\ncategory of emotion (e.g., fear) that will remain consistent across all\ninstances of that category, regardless of individual and context. In this\nstudy, we investigated variation rather than consistency during emotional\nexperiences while people watched video clips chosen to evoke instances of\nspecific emotion categories. Specifically, we developed a sequential\nprobabilistic approach to model the temporal dynamics in a participant's brain\nactivity during video viewing. We characterized brain states during these clips\nas distinct state occupancy periods between state transitions in blood oxygen\nlevel dependent (BOLD) signal patterns. We found substantial variation in the\nstate occupancy probability distributions across individuals watching the same\nvideo, supporting the hypothesis that when it comes to the brain correlates of\nemotional experience, variation may indeed be the norm.",
    "descriptor": "",
    "authors": [
      "Ashutosh Singh",
      "Christiana Westlin",
      "Hedwig Eisenbarth",
      "Elizabeth A. Reynolds Losin",
      "Jessica R. Andrews-Hanna",
      "Tor D. Wager",
      "Ajay B. Satpute",
      "Lisa Feldman Barrett",
      "Dana H. Brooks",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12392"
  },
  {
    "id": "arXiv:2110.12393",
    "title": "Deep Learning Approximation of Diffeomorphisms via Linear-Control  Systems",
    "abstract": "In this paper we propose a Deep Learning architecture to approximate\ndiffeomorphisms isotopic to the identity. We consider a control system of the\nform $\\dot x = \\sum_{i=1}^lF_i(x)u_i$, with linear dependence in the controls,\nand we use the corresponding flow to approximate the action of a diffeomorphism\non a compact ensemble of points. Despite the simplicity of the control system,\nit has been recently shown that a Universal Approximation Property holds. The\nproblem of minimizing the sum of the training error and of a regularizing term\ninduces a gradient flow in the space of admissible controls. A possible\ntraining procedure for the discrete-time neural network consists in projecting\nthe gradient flow onto a finite-dimensional subspace of the admissible\ncontrols. An alternative approach relies on an iterative method based on\nPontryagin Maximum Principle for the numerical resolution of Optimal Control\nproblems. Here the maximization of the Hamiltonian can be carried out with an\nextremely low computational effort, owing to the linear dependence of the\nsystem in the control variables.",
    "descriptor": "\nComments: 30 pages, 2 figures\n",
    "authors": [
      "Alessandro Scagliotti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12393"
  },
  {
    "id": "arXiv:2110.12450",
    "title": "Pandemic model with data-driven phase detection, a study using COVID-19  data",
    "abstract": "The recent COVID-19 pandemic has promoted vigorous scientific activity in an\neffort to understand, advice and control the pandemic. Data is now freely\navailable at a staggering rate worldwide. Unfortunately, this unprecedented\nlevel of information contains a variety of data sources and formats, and the\nmodels do not always conform to the description of the data. Health officials\nhave recognized the need for more accurate models that can adjust to sudden\nchanges, such as produced by changes in behavior or social restrictions. In\nthis work we formulate a model that fits a ``SIR''-type model concurrently with\na statistical change detection test on the data. The result is a piece wise\nautonomous ordinary differential equation, whose parameters change at various\npoints in time (automatically learned from the data). The main contributions of\nour model are: (a) providing interpretation of the parameters, (b) determining\nwhich parameters of the model are more important to produce changes in the\nspread of the disease, and (c) using data-driven discovery of sudden changes in\nthe evolution of the pandemic. Together, these characteristics provide a new\nmodel that better describes the situation and thus, provides better quality of\ninformation for decision making.",
    "descriptor": "\nComments: 21 pages, 12 figures, 4 tables, Journal of the Operational Research Society\n",
    "authors": [
      "Yuansan Liu",
      "Saransh Srivastava",
      "Zuo Huang",
      "Felisa J. V\u00e1zquez-Abad"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12450"
  },
  {
    "id": "arXiv:2110.12454",
    "title": "De Novo Molecular Generation with Stacked Adversarial Model",
    "abstract": "Generating novel drug molecules with desired biological properties is a time\nconsuming and complex task. Conditional generative adversarial models have\nrecently been proposed as promising approaches for de novo drug design. In this\npaper, we propose a new generative model which extends an existing adversarial\nautoencoder (AAE) based model by stacking two models together. Our stacked\napproach generates more valid molecules, as well as molecules that are more\nsimilar to known drugs. We break down this challenging task into two\nsub-problems. A first stage model to learn primitive features from the\nmolecules and gene expression data. A second stage model then takes these\nfeatures to learn properties of the molecules and refine more valid molecules.\nExperiments and comparison to baseline methods on the LINCS L1000 dataset\ndemonstrate that our proposed model has promising performance for molecular\ngeneration.",
    "descriptor": "\nComments: 12 pages, 5 figures, AJCAI\n",
    "authors": [
      "Yuansan Liu",
      "James Bailey"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12454"
  },
  {
    "id": "arXiv:2110.12464",
    "title": "Requirement analysis for an artificial intelligence model for the  diagnosis of the COVID-19 from chest X-ray data",
    "abstract": "There are multiple papers published about different AI models for the\nCOVID-19 diagnosis with promising results. Unfortunately according to the\nreviews many of the papers do not reach the level of sophistication needed for\na clinically usable model. In this paper I go through multiple review papers,\nguidelines, and other relevant material in order to generate more comprehensive\nrequirements for the future papers proposing a AI based diagnosis of the\nCOVID-19 from chest X-ray data (CXR). Main findings are that a clinically\nusable AI needs to have an extremely good documentation, comprehensive\nstatistical analysis of the possible biases and performance, and an\nexplainability module.",
    "descriptor": "\nComments: Submitted to AI&BDvsPandemics BIBM 2021 Workshop\n",
    "authors": [
      "Tuomo Kalliokoski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12464"
  },
  {
    "id": "arXiv:2110.12487",
    "title": "A Programming Language For Quantum Oracle Construction",
    "abstract": "Many quantum programs require circuits for addition, subtraction and logical\noperations. These circuits may be packaged within routines known as oracles.\nHowever, oracles can be tedious to code with current frameworks. To solve this\nproblem the author developed Higher-Level Oracle Description Language (HODL) --\na C-style programming language for use on quantum computers -- to ease the\ncreation of such circuits. The compiler translates high-level code written in\nHODL and converts it into OpenQASM, a gate-based quantum assembly language that\nruns on IBM Quantum Systems and compatible simulators.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Ayush Tambde"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.12487"
  },
  {
    "id": "arXiv:2110.12540",
    "title": "Mathematical Modeling for Holistic Convex Optimization of Hybrid Trains",
    "abstract": "We look into modeling fuel cell hybrid trains for the purpose of optimizing\ntheir operation using convex optimization. Models and constraints necessary to\nform a physically feasible yet convex problem are reviewed. This effort is\ndescribed as holistic due to the broad consideration of train speed, energy\nmanagement system, and battery thermals. The minimized objective is hydrogen\nfuel consumption for a given target journey time. A novel battery thermal model\nis proposed to aid with battery thermal management and thus preserve battery\nlifetime. All models are derived in the space-domain which along constraint\nrelaxations guarantee a convex optimization problem. First-principle knowledge\nand real-world data justify the suitableness of the proposed models for the\nintended optimization problem.",
    "descriptor": "",
    "authors": [
      "Rabee Jibrin",
      "Stuart Hillmansen",
      "Clive Roberts"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12540"
  },
  {
    "id": "arXiv:2110.12541",
    "title": "Partially Intervenable Causal Models",
    "abstract": "Graphical causal models led to the development of complete non-parametric\nidentification theory in arbitrary structured systems, and general approaches\nto efficient inference. Nevertheless, graphical approaches to causal inference\nhave not been embraced by the statistics and public health communities. In\nthose communities causal assumptions are instead expressed in terms of\npotential outcomes, or responses to hypothetical interventions. Such\ninterventions are generally conceptualized only on a limited set of variables,\nwhere the corresponding experiment could, in principle, be performed. By\ncontrast, graphical approaches to causal inference generally assume\ninterventions on all variables are well defined - an overly restrictive and\nunrealistic assumption that may have limited the adoption of these approaches\nin applied work in statistics and public health. In this paper, we build on a\nunification of graphical and potential outcomes approaches to causality\nexemplified by Single World Intervention Graphs (SWIGs) to define graphical\nmodels with a restricted set of allowed interventions. We give a complete\nidentification theory for such models, and develop a complete calculus of\ninterventions based on a generalization of the do-calculus, and axioms that\ngovern probabilistic operations on Markov kernels. A corollary of our results\nis a complete identification theory for causal effects in another graphical\nframework with a restricted set of interventions, the decision theoretic\ngraphical formulation of causality.",
    "descriptor": "",
    "authors": [
      "AmirEmad Ghassami",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.12541"
  },
  {
    "id": "arXiv:2110.12554",
    "title": "Implementation paradigm for supervised flare forecasting studies: a deep  learning application with video data",
    "abstract": "Solar flare forecasting can be realized by means of the analysis of magnetic\ndata through artificial intelligence techniques. The aim is to predict whether\na magnetic active region (AR) will originate solar flares above a certain class\nwithin a certain amount of time. A crucial issue is concerned with the way the\nadopted machine learning method is implemented, since forecasting results\nstrongly depend on the criterion with which training, validation, and test sets\nare populated. In this paper we propose a general paradigm to generate these\nsets in such a way that they are independent from each other and internally\nwell-balanced in terms of AR flaring effectiveness. This set generation process\nprovides a ground for comparison for the performance assessment of machine\nlearning algorithms. Finally, we use this implementation paradigm in the case\nof a deep neural network, which takes as input videos of magnetograms recorded\nby the Helioseismic and Magnetic Imager on-board the Solar Dynamics Observatory\n(SDO/HMI). To our knowledge, this is the first time that the solar flare\nforecasting problem is addressed by means of a deep neural network for video\nclassification, which does not require any a priori extraction of features from\nthe HMI magnetograms.",
    "descriptor": "",
    "authors": [
      "Sabrina Guastavino",
      "Francesco Marchetti",
      "Federico Benvenuto",
      "Cristina Campi",
      "Michele Piana"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12554"
  },
  {
    "id": "arXiv:2110.12595",
    "title": "Fast Rank-1 NMF for Missing Data with KL Divergence",
    "abstract": "We propose a fast non-gradient based method of rank-1 non-negative matrix\nfactorization (NMF) for missing data, called A1GM, that minimizes the KL\ndivergence from an input matrix to the reconstructed rank-1 matrix. Our method\nis based on our new finding of an analytical closed-formula of the best rank-1\nnon-negative multiple matrix factorization (NMMF), a variety of NMF. NMMF is\nknown to exactly solve NMF for missing data if positions of missing values\nsatisfy a certain condition, and A1GM transforms a given matrix so that the\nanalytical solution to NMMF can be applied. We empirically show that A1GM is\nmore efficient than a gradient method with competitive reconstruction errors.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Kazu Ghalamkari",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12595"
  },
  {
    "id": "arXiv:2110.12616",
    "title": "Lower bounds on quantum query complexity for symmetric functions",
    "abstract": "One of the main reasons for query model's prominence in quantum complexity is\nthe presence of concrete lower bounding techniques: polynomial method and\nadversary method. There have been considerable efforts to not just give lower\nbounds using these methods but even to compare and relate them. We explore the\nvalue of these bounds on quantum query complexity for the class of symmetric\nfunctions, arguably one of the most natural and basic set of Boolean functions.\nWe show (using the recently introduced spectral sensitivity) that both these\nbounds (positive adversary and approximate degree) give the same value for\nevery total symmetric Boolean function. We also look at the quantum query\ncomplexity of Gap Majority, a partial symmetric function. It has gained\nimportance recently in regard to understanding the composition of randomized\nquery complexity. We characterize the quantum query complexity of Gap Majority\nand show a lower bound on noisy randomized query complexity (Ben-David and\nBlais, FOCS 2020) in terms of quantum query complexity. In addition, we study\nhow large certificate complexity and block sensitivity can be as compared to\nsensitivity (even up to constant factors) for symmetric functions. We show\ntight separations, i.e., give upper bound on possible separations and construct\nfunctions achieving the same.",
    "descriptor": "\nComments: 24 pages, 2 figures, To be submitted to 25th Annual Conference on Quantum Information Processing\n",
    "authors": [
      "Rajat Mittal",
      "Sanjay S Nair",
      "Sunayana Patro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12616"
  },
  {
    "id": "arXiv:2110.12634",
    "title": "Accelerated Almost-Sure Convergence Rates for Nonconvex Stochastic  Gradient Descent using Stochastic Learning Rates",
    "abstract": "Large-scale optimization problems require algorithms both effective and\nefficient. One such popular and proven algorithm is Stochastic Gradient Descent\nwhich uses first-order gradient information to solve these problems. This paper\nstudies almost-sure convergence rates of the Stochastic Gradient Descent method\nwhen instead of deterministic, its learning rate becomes stochastic. In\nparticular, its learning rate is equipped with a multiplicative stochasticity,\nproducing a stochastic learning rate scheme. Theoretical results show\naccelerated almost-sure convergence rates of Stochastic Gradient Descent in a\nnonconvex setting when using an appropriate stochastic learning rate, compared\nto a deterministic-learning-rate scheme. The theoretical results are verified\nempirically.",
    "descriptor": "",
    "authors": [
      "Theodoros Mamalis",
      "Dusan Stipanovic",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12634"
  },
  {
    "id": "arXiv:2110.12674",
    "title": "Mlr3spatiotempcv: Spatiotemporal resampling methods for machine learning  in R",
    "abstract": "Spatial and spatiotemporal machine-learning models require a suitable\nframework for their model assessment, model selection, and hyperparameter\ntuning, in order to avoid error estimation bias and over-fitting. This\ncontribution reviews the state-of-the-art in spatial and spatiotemporal CV, and\nintroduces the \\proglang{R} package mlr3spatiotempcv as an extension package of\nthe machine-learning framework \\textbf{mlr3}. Currently various \\proglang{R}\npackages implementing different spatiotemporal partitioning strategies exist:\n\\pkg{blockCV}, \\pkg{CAST}, \\pkg{kmeans} and \\pkg{sperrorest}. The goal of\n\\pkg{mlr3spatiotempcv} is to gather the available spatiotemporal resampling\nmethods in \\proglang{R} and make them available to users through a simple and\ncommon interface. This is made possible by integrating the package directly\ninto the \\pkg{mlr3} machine-learning framework, which already has support for\ngeneric non-spatiotemporal resampling methods such as random partitioning. One\nadvantage is the use of a consistent nomenclature in an overarching\nmachine-learning toolkit instead of a varying package-specific syntax, making\nit easier for users to choose from a variety of spatiotemporal resampling\nmethods. This package avoids giving recommendations which method to use in\npractice as this decision depends on the predictive task at hand, the\nautocorrelation within the data, and the spatial structure of the sampling\ndesign or geographic objects being studied.",
    "descriptor": "\nComments: 34 pages, 15 Figures, 1 Table\n",
    "authors": [
      "Patrick Schratz",
      "Marc Becker",
      "Michel Lang",
      "Alexander Brenning"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12674"
  },
  {
    "id": "arXiv:2110.12676",
    "title": "Controllable and Interpretable Singing Voice Decomposition via Assem-VC",
    "abstract": "We propose a singing decomposition system that encodes time-aligned\nlinguistic content, pitch, and source speaker identity via Assem-VC. With\ndecomposed speaker-independent information and the target speaker's embedding,\nwe could synthesize the singing voice of the target speaker. In conclusion, we\nmade a perfectly synced duet with the user's singing voice and the target\nsinger's converted singing voice.",
    "descriptor": "\nComments: Accepted to NeurIPS Workshop on ML for Creativity and Design 2021 (Oral)\n",
    "authors": [
      "Kang-wook Kim",
      "Junhyeok Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.12676"
  },
  {
    "id": "arXiv:2110.12735",
    "title": "Practical Galaxy Morphology Tools from Deep Supervised Representation  Learning",
    "abstract": "Astronomers have typically set out to solve supervised machine learning\nproblems by creating their own representations from scratch. We show that deep\nlearning models trained to answer every Galaxy Zoo DECaLS question learn\nmeaningful semantic representations of galaxies that are useful for new tasks\non which the models were never trained. We exploit these representations to\noutperform existing approaches at several practical tasks crucial for\ninvestigating large galaxy samples. The first task is identifying galaxies of\nsimilar morphology to a query galaxy. Given a single galaxy assigned a free\ntext tag by humans (e.g. `#diffuse'), we can find galaxies matching that tag\nfor most tags. The second task is identifying the most interesting anomalies to\na particular researcher. Our approach is 100\\% accurate at identifying the most\ninteresting 100 anomalies (as judged by Galaxy Zoo 2 volunteers). The third\ntask is adapting a model to solve a new task using only a small number of\nnewly-labelled galaxies. Models fine-tuned from our representation are better\nable to identify ring galaxies than models fine-tuned from terrestrial images\n(ImageNet) or trained from scratch. We solve each task with very few new\nlabels; either one (for the similarity search) or several hundred (for anomaly\ndetection or fine-tuning). This challenges the longstanding view that deep\nsupervised methods require new large labelled datasets for practical use in\nastronomy. To help the community benefit from our pretrained models, we release\nour fine-tuning code zoobot. Zoobot is accessible to researchers with no prior\nexperience in deep learning.",
    "descriptor": "\nComments: 21 pages. Submitted to MNRAS. Code, documentation, pretrained models: this https URL\n",
    "authors": [
      "Mike Walmsley",
      "Anna M. M. Scaife",
      "Chris Lintott",
      "Michelle Lochner",
      "Verlon Etsebeth",
      "Tobias G\u00e9ron",
      "Hugh Dickinson",
      "Lucy Fortson",
      "Sandor Kruk",
      "Karen L. Masters",
      "Kameswara Bharadwaj Mantha",
      "Brooke D. Simmons"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12735"
  },
  {
    "id": "arXiv:2110.12751",
    "title": "Maximum Correntropy Criterion Regression models with tending-to-zero  scale parameters",
    "abstract": "Maximum correntropy criterion regression (MCCR) models have been well studied\nwithin the frame of statistical learning when the scale parameters take fixed\nvalues or go to infinity. This paper studies the MCCR models with\ntending-to-zero scale parameters. It is revealed that the optimal learning rate\nof MCCR models is ${\\mathcal{O}}(n^{-1})$ in the asymptotic sense when the\nsample size $n$ goes to infinity. In the case of finite samples, the\nperformances on robustness of MCCR, Huber and the least square regression\nmodels are compared. The applications of these three methods on real data are\nalso displayed.",
    "descriptor": "",
    "authors": [
      "Ying Jing",
      "Lianqiang Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12751"
  },
  {
    "id": "arXiv:2110.12786",
    "title": "Dictionary Learning Using Rank-One Atomic Decomposition (ROAD)",
    "abstract": "Dictionary learning aims at seeking a dictionary under which the training\ndata can be sparsely represented. Methods in the literature typically formulate\nthe dictionary learning problem as an optimization w.r.t. two variables, i.e.,\ndictionary and sparse coefficients, and solve it by alternating between two\nstages: sparse coding and dictionary update. The key contribution of this work\nis a Rank-One Atomic Decomposition (ROAD) formulation where dictionary learning\nis cast as an optimization w.r.t. a single variable which is a set of rank one\nmatrices. The resulting algorithm is hence single-stage. Compared with\ntwo-stage algorithms, ROAD minimizes the sparsity of the coefficients whilst\nkeeping the data consistency constraint throughout the whole learning process.\nAn alternating direction method of multipliers (ADMM) is derived to solve the\noptimization problem and the lower bound of the penalty parameter is computed\nto guarantees a global convergence despite non-convexity of the optimization\nformulation. From practical point of view, ROAD reduces the number of tuning\nparameters required in other benchmark algorithms. Numerical tests demonstrate\nthat ROAD outperforms other benchmark algorithms for both synthetic data and\nreal data, especially when the number of training samples is small.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.08975\n",
    "authors": [
      "Cheng Cheng",
      "Wei Dai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12786"
  },
  {
    "id": "arXiv:2110.12793",
    "title": "Quantum Boosting using Domain-Partitioning Hypotheses",
    "abstract": "Boosting is an ensemble learning method that converts a weak learner into a\nstrong learner in the PAC learning framework. Freund and Schapire gave the\nfirst classical boosting algorithm for binary hypothesis known as AdaBoost, and\nthis was recently adapted into a quantum boosting algorithm by Arunachalam et\nal. Their quantum boosting algorithm (which we refer to as Q-AdaBoost) is\nquadratically faster than the classical version in terms of the VC-dimension of\nthe hypothesis class of the weak learner but polynomially worse in the bias of\nthe weak learner.\nIn this work we design a different quantum boosting algorithm that uses\ndomain partitioning hypotheses that are significantly more flexible than those\nused in prior quantum boosting algorithms in terms of margin calculations. Our\nalgorithm Q-RealBoost is inspired by the \"Real AdaBoost\" (aka. RealBoost)\nextension to the original AdaBoost algorithm. Further, we show that Q-RealBoost\nprovides a polynomial speedup over Q-AdaBoost in terms of both the bias of the\nweak learner and the time taken by the weak learner to learn the target concept\nclass.",
    "descriptor": "",
    "authors": [
      "Debajyoti Bera",
      "Sagnik Chatterjee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12793"
  },
  {
    "id": "arXiv:2110.12798",
    "title": "Variational Gaussian Processes: A Functional Analysis View",
    "abstract": "Variational Gaussian process (GP) approximations have become a standard tool\nin fast GP inference. This technique requires a user to select variational\nfeatures to increase efficiency. So far the common choices in the literature\nare disparate and lacking generality. We propose to view the GP as lying in a\nBanach space which then facilitates a unified perspective. This is used to\nunderstand the relationship between existing features and to draw a connection\nbetween kernel ridge regression and variational GP approximations.",
    "descriptor": "",
    "authors": [
      "Veit Wild",
      "George Wynne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.12798"
  },
  {
    "id": "arXiv:2110.12820",
    "title": "On Synchronization of Wireless Acoustic Sensor Networks in the Presence  of Time-varying Sampling Rate Offsets and Speaker Changes",
    "abstract": "A wireless acoustic sensor network records audio signals with sampling time\nand sampling rate offsets between the audio streams, if the analog-digital\nconverters (ADCs) of the network devices are not synchronized. Here, we\nintroduce a new sampling rate offset model to simulate time-varying sampling\nfrequencies caused, for example, by temperature changes of ADC crystal\noscillators, and propose an estimation algorithm to handle this dynamic aspect\nin combination with changing acoustic source positions. Furthermore, we show\nhow deep neural network based estimates of the distances between microphones\nand human speakers can be used to determine the sampling time offsets. This\nenables a synchronization of the audio streams to reflect the physical time\ndifferences of flight.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Tobias Gburrek",
      "Joerg Schmalenstroeer",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.12820"
  },
  {
    "id": "arXiv:2110.12823",
    "title": "Raw Bayer Pattern Image Synthesis with Conditional GAN",
    "abstract": "In this paper, we propose a method to generate Bayer pattern images by\nGenerative adversarial network (GANs). It is shown theoretically that using the\ntransformed data in GANs training is able to improve the generator learning of\nthe original data distribution, owing to the invariant of Jensen Shannon(JS)\ndivergence between two distributions under invertible and differentiable\ntransformation. The Bayer pattern images can be generated by configuring the\ntransformation as demosaicing, by converting the existing standard color\ndatasets to Bayer domain, the proposed method is promising in the applications\nsuch as to find the optimal ISP configuration for computer vision tasks, in the\nin sensor or near sensor computing, even in photography. Experiments show that\nthe images generated by our proposed method outperform the original Pix2PixHD\nmodel in FID score, PSNR, and SSIM, and the training process is more stable.\nFor the situation similar to in sensor or near sensor computing for object\ndetection, by using our proposed method, the model performance can be improved\nwithout the modification to the image sensor.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Zhou Wei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12823"
  },
  {
    "id": "arXiv:2110.12827",
    "title": "Automatic segmentation of novel coronavirus pneumonia lesions in CT  images utilizing deep-supervised ensemble learning network",
    "abstract": "Background: The 2019 novel coronavirus disease (COVID-19) has been spread\nwidely in the world, causing a huge threat to people's living environment.\nObjective: Under computed tomography (CT) imaging, the structure features of\nCOVID-19 lesions are complicated and varied greatly in different cases. To\naccurately locate COVID-19 lesions and assist doctors to make the best\ndiagnosis and treatment plan, a deep-supervised ensemble learning network is\npresented for COVID-19 lesion segmentation in CT images. Methods: Considering\nthe fact that a large number of COVID-19 CT images and the corresponding lesion\nannotations are difficult to obtained, a transfer learning strategy is employed\nto make up for the shortcoming and alleviate the overfitting problem. Based on\nthe reality that traditional single deep learning framework is difficult to\nextract COVID-19 lesion features effectively, which may cause some lesions to\nbe undetected. To overcome the problem, a deep-supervised ensemble learning\nnetwork is presented to combine with local and global features for COVID-19\nlesion segmentation. Results: The performance of the proposed method was\nvalidated in experiments with a publicly available dataset. Compared with\nmanual annotations, the proposed method acquired a high intersection over union\n(IoU) of 0.7279. Conclusion: A deep-supervised ensemble learning network was\npresented for coronavirus pneumonia lesion segmentation in CT images. The\neffectiveness of the proposed method was verified by visual inspection and\nquantitative evaluation. Experimental results shown that the proposed mehtod\nhas a perfect performance in COVID-19 lesion segmentation.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Peng",
      "Zixu Zhang",
      "Hongbin Tu",
      "Xiong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12827"
  },
  {
    "id": "arXiv:2110.12853",
    "title": "Cubature Method for Stochastic Volterra Integral Equations",
    "abstract": "In this paper, we introduce the cubature formulas for Stochastic Volterra\nIntegral Equations. We first derive the stochastic Taylor expansion in this\nsetting and provide its tail estimates. We then introduce the cubature measure\nfor such equations, and construct it explicitly in some special cases,\nincluding a long memory stochastic volatility model. Finally, we illustrate its\nefficiency by presenting several numerical examples.",
    "descriptor": "",
    "authors": [
      "Qi Feng",
      "Jianfeng Zhang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2110.12853"
  },
  {
    "id": "arXiv:2110.12870",
    "title": "Data-driven intrinsic localized mode detection and classification in  one-dimensional crystal lattice model",
    "abstract": "In this work we propose Support Vector Machine classification algorithms to\nclassify one-dimensional crystal lattice waves from locally sampled data. Three\ndifferent learning datasets of particle displacements, momenta and energy\ndensity values are considered. Efficiency of the classification algorithms are\nfurther improved by two dimensionality reduction techniques: Principal\nComponent Analysis and Locally Linear Embedding. Robustness of classifiers are\ninvestigated and demonstrated. Developed algorithms are successfully applied to\ndetect localized intrinsic modes in three numerical simulations considering a\ncase of two localized stationary breather solutions, a single stationary\nbreather solution in noisy background and two mobile breather collision.",
    "descriptor": "",
    "authors": [
      "J\u0101nis Baj\u0101rs",
      "Filips Kozirevs"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12870"
  },
  {
    "id": "arXiv:2110.12889",
    "title": "Anatomical and Diagnostic Bayesian Segmentation in Prostate MRI  $-$Should Different Clinical Objectives Mandate Different Loss Functions?",
    "abstract": "We hypothesize that probabilistic voxel-level classification of anatomy and\nmalignancy in prostate MRI, although typically posed as near-identical\nsegmentation tasks via U-Nets, require different loss functions for optimal\nperformance due to inherent differences in their clinical objectives. We\ninvestigate distribution, region and boundary-based loss functions for both\ntasks across 200 patient exams from the publicly-available ProstateX dataset.\nFor evaluation, we conduct a thorough comparative analysis of model predictions\nand calibration, measured with respect to multi-class volume segmentation of\nthe prostate anatomy (whole-gland, transitional zone, peripheral zone), as well\nas, patient-level diagnosis and lesion-level detection of clinically\nsignificant prostate cancer. Notably, we find that distribution-based loss\nfunctions (in particular, focal loss) are well-suited for diagnostic or\npanoptic segmentation tasks such as lesion detection, primarily due to their\nimplicit property of inducing better calibration. Meanwhile, (with the\nexception of focal loss) both distribution and region/boundary-based loss\nfunctions perform equally well for anatomical or semantic segmentation tasks,\nsuch as quantification of organ shape, size and boundaries.",
    "descriptor": "\nComments: Accepted to Medical Imaging Meets NeurIPS Workshop of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Anindo Saha",
      "Joeran Bosma",
      "Jasper Linmans",
      "Matin Hosseinzadeh",
      "Henkjan Huisman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12889"
  },
  {
    "id": "arXiv:2110.12900",
    "title": "Automated Scoring System of HER2 in Pathological Images under the  Microscope",
    "abstract": "Breast cancer is the most common cancer among women worldwide. The human\nepidermal growth factor receptor 2(HER2) with immunohistochemical(IHC) is\nwidely used for pathological evaluation to provide the appropriate therapy for\npatients with breast cancer. However, the deficiency of pathologists is\nextremely significant in the current society, and visual diagnosis of the HER2\noverexpression is subjective and susceptible to inter-observer variation.\nRecently, with the rapid development of artificial intelligence(AI) in disease\ndiagnosis, several automated HER2 scoring methods using traditional computer\nvision or machine learning methods indicate the improvement of the HER2\ndiagnostic accuracy, but the unreasonable interpretation in pathology, as well\nas the expensive and ethical issues for annotation, make these methods still\nhave a long way to deploy in hospitals to ease pathologists' burden in real. In\nthis paper, we propose a HER2 automated scoring system that strictly follows\nthe HER2 scoring guidelines simulating the real workflow of HER2 scores\ndiagnosis by pathologists. Unlike the previous work, our method takes the\npositive control of HER2 into account to make sure the assay performance for\neach slide, eliminating work for repeated comparison and checking for the\ncurrent field of view(FOV) and positive control FOV, especially for the\nborderline cases. Besides, for each selected FOV under the microscope, our\nsystem provides real-time HER2 scores analysis and visualizations of the\nmembrane staining intensity and completeness corresponding with the cell\nclassification. Our rigorous workflow along with the flexible interactive\nadjustion in demand substantially assists pathologists to finish the HER2\ndiagnosis faster and improves the robustness and accuracy. The proposed system\nwill be embedded in our Thorough Eye platform for deployment in hospitals.",
    "descriptor": "",
    "authors": [
      "Zichen Zhang",
      "Lang Wang",
      "Shuhao Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.12900"
  },
  {
    "id": "arXiv:2110.12907",
    "title": "Hamiltonian Monte Carlo with Asymmetrical Momentum Distributions",
    "abstract": "Existing rigorous convergence guarantees for the Hamiltonian Monte Carlo\n(HMC) algorithm use Gaussian auxiliary momentum variables, which are crucially\nsymmetrically distributed.\nWe present a novel convergence analysis for HMC utilizing new analytic and\nprobabilistic arguments. The convergence is rigorously established under\nsignificantly weaker conditions, which among others allow for general auxiliary\ndistributions.\nIn our framework, we show that plain HMC with asymmetrical momentum\ndistributions breaks a key self-adjointness requirement. We propose a modified\nversion that we call the Alternating Direction HMC (AD-HMC). Sufficient\nconditions are established under which AD-HMC exhibits geometric convergence in\nWasserstein distance. Numerical experiments suggest that AD-HMC can show\nimproved performance over HMC with Gaussian auxiliaries.",
    "descriptor": "",
    "authors": [
      "Soumyadip Ghosh",
      "Yingdong Lu",
      "Tomasz Nowicki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.12907"
  },
  {
    "id": "arXiv:2110.12915",
    "title": "Revealing unforeseen diagnostic image features with deep learning by  detecting cardiovascular diseases from apical four-chamber ultrasounds",
    "abstract": "Background. With the rise of highly portable, wireless, and low-cost\nultrasound devices and automatic ultrasound acquisition techniques, an\nautomated interpretation method requiring only a limited set of views as input\ncould make preliminary cardiovascular disease diagnoses more accessible. In\nthis study, we developed a deep learning (DL) method for automated detection of\nimpaired left ventricular (LV) function and aortic valve (AV) regurgitation\nfrom apical four-chamber (A4C) ultrasound cineloops and investigated which\nanatomical structures or temporal frames provided the most relevant information\nfor the DL model to enable disease classification.\nMethods and Results. A4C ultrasounds were extracted from 3,554\nechocardiograms of patients with either impaired LV function (n=928), AV\nregurgitation (n=738), or no significant abnormalities (n=1,888). Two\nconvolutional neural networks (CNNs) were trained separately to classify the\nrespective disease cases against normal cases. The overall classification\naccuracy of the impaired LV function detection model was 86%, and that of the\nAV regurgitation detection model was 83%. Feature importance analyses\ndemonstrated that the LV myocardium and mitral valve were important for\ndetecting impaired LV function, while the tip of the mitral valve anterior\nleaflet, during opening, was considered important for detecting AV\nregurgitation.\nConclusion. The proposed method demonstrated the feasibility of a 3D CNN\napproach in detection of impaired LV function and AV regurgitation using A4C\nultrasound cineloops. The current research shows that DL methods can exploit\nlarge training data to detect diseases in a different way than conventionally\nagreed upon methods, and potentially reveal unforeseen diagnostic image\nfeatures.",
    "descriptor": "",
    "authors": [
      "Li-Hsin Cheng",
      "Pablo B.J. Bosch",
      "Rutger F.H. Hofman",
      "Timo B. Brakenhoff",
      "Eline F. Bruggemans",
      "Rob J. van der Geest",
      "Eduard R. Holman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.12915"
  },
  {
    "id": "arXiv:2110.12922",
    "title": "On quantitative Laplace-type convergence results for some exponential  probability measures, with two applications",
    "abstract": "Laplace-type results characterize the limit of sequence of measures\n$(\\pi_\\varepsilon)_{\\varepsilon >0}$ with density w.r.t the Lebesgue measure\n$(\\mathrm{d} \\pi_\\varepsilon / \\mathrm{d} \\mathrm{Leb})(x) \\propto\n\\exp[-U(x)/\\varepsilon]$ when the temperature $\\varepsilon>0$ converges to $0$.\nIf a limiting distribution $\\pi_0$ exists, it concentrates on the minimizers of\nthe potential $U$. Classical results require the invertibility of the Hessian\nof $U$ in order to establish such asymptotics. In this work, we study the\nparticular case of norm-like potentials $U$ and establish quantitative bounds\nbetween $\\pi_\\varepsilon$ and $\\pi_0$ w.r.t. the Wasserstein distance of order\n$1$ under an invertibility condition of a generalized Jacobian. One key element\nof our proof is the use of geometric measure theory tools such as the coarea\nformula. We apply our results to the study of maximum entropy models\n(microcanonical/macrocanonical distributions) and to the convergence of the\niterates of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm at low\ntemperatures for non-convex minimization.",
    "descriptor": "",
    "authors": [
      "Valentin De Bortoli",
      "Agn\u00e8s Desolneux"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12922"
  },
  {
    "id": "arXiv:2110.12928",
    "title": "The diameter of caterpillar associahedra",
    "abstract": "The caterpillar associahedron $\\mathcal{A}(G)$ is a polytope arising from the\nrotation graph of search trees on a caterpillar tree $G$, generalizing the\nrotation graph of binary search trees (BSTs) and thus the conventional\nassociahedron. We show that the diameter of $\\mathcal{A}(G)$ is $\\Theta(n + m\n\\cdot (H+1))$, where $n$ is the number of vertices, $m$ is the number of\nleaves, and $H$ is the entropy of the leaf distribution of $G$.\nOur proofs reveal a strong connection between caterpillar associahedra and\nsearching in BSTs. We prove the lower bound using Wilber's first lower bound\nfor dynamic BSTs, and the upper bound by reducing the problem to searching in\nstatic BSTs.",
    "descriptor": "",
    "authors": [
      "Benjamin Aram Berendsohn"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.12928"
  },
  {
    "id": "arXiv:2110.12939",
    "title": "Interactive Segmentation via Deep Learning and B-Spline Explicit Active  Surfaces",
    "abstract": "Automatic medical image segmentation via convolutional neural networks (CNNs)\nhas shown promising results. However, they may not always be robust enough for\nclinical use. Sub-optimal segmentation would require clinician's to manually\ndelineate the target object, causing frustration. To address this problem, a\nnovel interactive CNN-based segmentation framework is proposed in this work.\nThe aim is to represent the CNN segmentation contour as B-splines by utilising\nB-spline explicit active surfaces (BEAS). The interactive element of the\nframework allows the user to precisely edit the contour in real-time, and by\nutilising BEAS it ensures the final contour is smooth and anatomically\nplausible. This framework was applied to the task of 2D segmentation of the\nlevator hiatus from 2D ultrasound (US) images, and compared to the current\nclinical tools used in pelvic floor disorder clinic (4DView, GE Healthcare;\nZipf, Austria). Experimental results show that: 1) the proposed framework is\nmore robust than current state-of-the-art CNNs; 2) the perceived workload\ncalculated via the NASA-TLX index was reduced more than half for the proposed\napproach in comparison to current clinical tools; and 3) the proposed tool\nrequires at least 13 seconds less user time than the clinical tools, which was\nsignificant (p=0.001).",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables\n",
    "authors": [
      "Helena Williams",
      "Jo\u00e3o Pedrosa",
      "Laura Cattani",
      "Susanne Housmans",
      "Tom Vercauteren",
      "Jan Deprest",
      "Jan D'hooge"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.12939"
  },
  {
    "id": "arXiv:2110.12984",
    "title": "Generative Residual Attention Network for Disease Detection",
    "abstract": "Accurate identification and localization of abnormalities from radiology\nimages serve as a critical role in computer-aided diagnosis (CAD) systems.\nBuilding a highly generalizable system usually requires a large amount of data\nwith high-quality annotations, including disease-specific global and\nlocalization information. However, in medical images, only a limited number of\nhigh-quality images and annotations are available due to annotation expenses.\nIn this paper, we explore this problem by presenting a novel approach for\ndisease generation in X-rays using a conditional generative adversarial\nlearning. Specifically, given a chest X-ray image from a source domain, we\ngenerate a corresponding radiology image in a target domain while preserving\nthe identity of the patient. We then use the generated X-ray image in the\ntarget domain to augment our training to improve the detection performance. We\nalso present a unified framework that simultaneously performs disease\ngeneration and localization.We evaluate the proposed approach on the X-ray\nimage dataset provided by the Radiological Society of North America (RSNA),\nsurpassing the state-of-the-art baseline detection algorithms.",
    "descriptor": "\nComments: The paper is about Pneumonia detection using Generative Modeling. It proposes a novel approach to construct pseudo-pair images and a GAN to generate radio-realistic Chest Xray images. Then, the paper propose to leverage the differences between the input and the generated Xray images as an additional attention-map to boost the performance in Pneumonia detection\n",
    "authors": [
      "Euyoung Kim",
      "Soochahn Lee",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12984"
  },
  {
    "id": "arXiv:2110.13006",
    "title": "Gradient-based Quadratic Multiform Separation",
    "abstract": "Classification as a supervised learning concept is an important content in\nmachine learning. It aims at categorizing a set of data into classes. There are\nseveral commonly-used classification methods nowadays such as k-nearest\nneighbors, random forest, and support vector machine. Each of them has its own\npros and cons, and none of them is invincible for all kinds of problems. In\nthis thesis, we focus on Quadratic Multiform Separation (QMS), a classification\nmethod recently proposed by Michael Fan et al. (2019). Its fresh concept, rich\nmathematical structure, and innovative definition of loss function set it apart\nfrom the existing classification methods. Inspired by QMS, we propose utilizing\na gradient-based optimization method, Adam, to obtain a classifier that\nminimizes the QMS-specific loss function. In addition, we provide suggestions\nregarding model tuning through explorations of the relationships between\nhyperparameters and accuracies. Our empirical result shows that QMS performs as\ngood as most classification methods in terms of accuracy. Its superior\nperformance almost comparable to those of gradient boosting algorithms that win\nmassive machine learning competitions.",
    "descriptor": "\nComments: 47 pages, 11 figures\n",
    "authors": [
      "Wen-Teng Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13006"
  },
  {
    "id": "arXiv:2110.13036",
    "title": "Dual Skip Connections Minimize the False Positive Rate of Lung Nodule  Detection in CT images",
    "abstract": "Pulmonary cancer is one of the most commonly diagnosed and fatal cancers and\nis often diagnosed by incidental findings on computed tomography. Automated\npulmonary nodule detection is an essential part of computer-aided diagnosis,\nwhich is still facing great challenges and difficulties to quickly and\naccurately locate the exact nodules' positions. This paper proposes a dual skip\nconnection upsampling strategy based on Dual Path network in a U-Net structure\ngenerating multiscale feature maps, which aims to minimize the ratio of false\npositives and maximize the sensitivity for lesion detection of nodules. The\nresults show that our new upsampling strategy improves the performance by\nhaving 85.3% sensitivity at 4 FROC per image compared to 84.2% for the regular\nupsampling strategy or 81.2% for VGG16-based Faster-R-CNN.",
    "descriptor": "\nComments: to be published at IEEE EMBC 2021, in IEEE Xplore\n",
    "authors": [
      "Jiahua Xu",
      "Philipp Ernst",
      "Tung Lung Liu",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13036"
  },
  {
    "id": "arXiv:2110.13048",
    "title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events  Data",
    "abstract": "We investigate the issue of parameter estimation with nonuniform negative\nsampling for imbalanced data. We first prove that, with imbalanced data, the\navailable information about unknown parameters is only tied to the relatively\nsmall number of positive instances, which justifies the usage of negative\nsampling. However, if the negative instances are subsampled to the same level\nof the positive cases, there is information loss. To maintain more information,\nwe derive the asymptotic distribution of a general inverse probability weighted\n(IPW) estimator and obtain the optimal sampling probability that minimizes its\nvariance. To further improve the estimation efficiency over the IPW method, we\npropose a likelihood-based estimator by correcting log odds for the sampled\ndata and prove that the improved estimator has the smallest asymptotic variance\namong a large class of estimators. It is also more robust to pilot\nmisspecification. We validate our approach on simulated data as well as a real\nclick-through rate dataset with more than 0.3 trillion instances, collected\nover a period of a month. Both theoretical and empirical results demonstrate\nthe effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "HaiYing Wang",
      "Aonan Zhang",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.13048"
  },
  {
    "id": "arXiv:2110.13078",
    "title": "Palindromic factorization of rich words",
    "abstract": "A finite word $w$ is called \\emph{rich} if it contains $\\vert w\\vert+1$\ndistinct palindromic factors including the empty word. For every finite rich\nword $w$ there are distinct nonempty palindromes $w_1, w_2,\\dots,w_p$ such that\n$w=w_pw_{p-1}\\cdots w_1$ and $w_i$ is the longest palindromic suffix of\n$w_pw_{p-1}\\cdots w_i$, where $1\\leq i\\leq p$. This palindromic factorization\nis called \\emph{UPS-factorization}. Let $luf(w)=p$ be \\emph{the length of\nUPS-factorization} of $w$.\nIn 2017, it was proved that there is a constant $c$ such that if $w$ is a\nfinite rich word and $n=\\vert w\\vert$ then $luf(w)\\leq c\\frac{n}{\\ln{n}}$. We\nimprove this result as follows: There are constants $\\mu, \\pi$ such that if $w$\nis a finite rich word and $n=\\vert w\\vert$ then \\[luf(w)\\leq\n\\mu\\frac{n}{e^{\\pi\\sqrt{\\ln{n}}}}\\mbox{.}\\] The constants $c,\\mu,\\pi$ depend on\nthe size of the alphabet.",
    "descriptor": "",
    "authors": [
      "Josef Rukavicka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.13078"
  },
  {
    "id": "arXiv:2110.13086",
    "title": "Quantum Algorithms and Lower Bounds for Linear Regression with Norm  Constraints",
    "abstract": "Lasso and Ridge are important minimization problems in machine learning and\nstatistics. They are versions of linear regression with squared loss where the\nvector $\\theta\\in\\mathbb{R}^d$ of coefficients is constrained in either\n$\\ell_1$-norm (for Lasso) or in $\\ell_2$-norm (for Ridge). We study the\ncomplexity of quantum algorithms for finding $\\varepsilon$-minimizers for these\nminimization problems. We show that for Lasso we can get a quadratic quantum\nspeedup in terms of $d$ by speeding up the cost-per-iteration of the\nFrank-Wolfe algorithm, while for Ridge the best quantum algorithms are linear\nin $d$, as are the best classical algorithms.",
    "descriptor": "\nComments: 32 pages LaTeX\n",
    "authors": [
      "Yanlin Chen",
      "Ronald de Wolf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13086"
  },
  {
    "id": "arXiv:2110.13125",
    "title": "Automatic Impact-sounding Acoustic Inspection of Concrete Structure",
    "abstract": "Impact sounding signal has been shown to contain information about structural\nintegrity flaws and subsurface objects from previous research. As\nnon-destructive testing (NDT) method, one of the biggest challenges in impact\nsounding based inspection is the subsurface targets detection and\nreconstruction. This paper presents the importance and practicability of using\nsolenoids to trigger impact sounding signal and using acoustic data to\nreconstruct subsurface objects to address this issue. First, by taking\nadvantage of Visual Simultaneous Localization and Mapping (V-SLAM), we could\nobtain the 3D position of the robot during the inspection. Second, our NDE\nmethod is based on Frequency Density (FD) analysis for the Fast Fourier\nTransform (FFT) of the impact sounding signal. At last, by combining the 3D\nposition data and acoustic data, this paper creates a 3D map to highlight the\npossible subsurface objects. The experimental results demonstrate the\nfeasibility of the method.",
    "descriptor": "",
    "authors": [
      "Jinglun Feng",
      "Hua Xiao",
      "Ejup Hoxha",
      "Yifeng Song",
      "Liang Yang",
      "Jizhong Xiao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13125"
  },
  {
    "id": "arXiv:1402.2741",
    "title": "Static Level Ancestors in Practice",
    "abstract": "Static Level Ancestors in Practice",
    "descriptor": "",
    "authors": [
      "Matthew Mabrey",
      "Thomas Caputi",
      "Georgios Papamichail",
      "Dimitris Papamichail"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1402.2741"
  },
  {
    "id": "arXiv:1611.00559",
    "title": "Online Algorithm for Demand Response with Inelastic Demands and Apparent  Power Constraint",
    "abstract": "Comments: An extended version of parts of this work appeared in the paper published under the title \"A Competitive Scheduling Algorithm for Online Demand Response in Islanded Microgrids\" in the IEEE Transactions on Power Systems journal",
    "descriptor": "\nComments: An extended version of parts of this work appeared in the paper published under the title \"A Competitive Scheduling Algorithm for Online Demand Response in Islanded Microgrids\" in the IEEE Transactions on Power Systems journal\n",
    "authors": [
      "Areg Karapetyan",
      "Majid Khonji",
      "Chi-Kin Chau",
      "Khaled Elbassioni"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1611.00559"
  },
  {
    "id": "arXiv:1712.00434",
    "title": "On the treewidth of triangulated 3-manifolds",
    "abstract": "Comments: 26 pages, 6 figures, 1 table. Apart from the formatting and updated references, this manuscript is identical to the final version published in the Journal of Computational Geometry",
    "descriptor": "\nComments: 26 pages, 6 figures, 1 table. Apart from the formatting and updated references, this manuscript is identical to the final version published in the Journal of Computational Geometry\n",
    "authors": [
      "Krist\u00f3f Husz\u00e1r",
      "Jonathan Spreer",
      "Uli Wagner"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1712.00434"
  },
  {
    "id": "arXiv:1802.05904",
    "title": "Error and Stability Estimates of a Least-Squares Variational  Kernel-Based Method for Second Order Elliptic PDEs",
    "abstract": "Comments: This paper includes 27 pages and 2 tables",
    "descriptor": "\nComments: This paper includes 27 pages and 2 tables\n",
    "authors": [
      "Salar Seyednazari",
      "Mehdi Tatari",
      "Davoud Mirzaei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1802.05904"
  },
  {
    "id": "arXiv:1804.02864",
    "title": "Semantic Edge Detection with Diverse Deep Supervision",
    "abstract": "Comments: International Journal of Computer Vision",
    "descriptor": "\nComments: International Journal of Computer Vision\n",
    "authors": [
      "Yun Liu",
      "Ming-Ming Cheng",
      "Deng-Ping Fan",
      "Le Zhang",
      "JiaWang Bian",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1804.02864"
  },
  {
    "id": "arXiv:1804.07706",
    "title": "SoK: Securing Email -- A Stakeholder-Based Analysis (Extended Version)",
    "abstract": "Comments: Extended version of paper published at Financial Cryptography 2021. Under submission at CSUR",
    "descriptor": "\nComments: Extended version of paper published at Financial Cryptography 2021. Under submission at CSUR\n",
    "authors": [
      "Jeremy Clark",
      "P.C. van Oorschot",
      "Scott Ruoti",
      "Kent Seamons",
      "Daniel Zappala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1804.07706"
  },
  {
    "id": "arXiv:1805.08359",
    "title": "DRESS: Dynamic RESource-reservation Scheme for Congested Data-intensive  Computing Platforms",
    "abstract": "Comments: IEEE International Conference on Cloud Computing (IEEE CLOUD 2018)",
    "descriptor": "\nComments: IEEE International Conference on Cloud Computing (IEEE CLOUD 2018)\n",
    "authors": [
      "Ying Mao",
      "Victoria Green",
      "Jiayin Wang",
      "Haoyi Xiong",
      "Zhishan Guo"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/1805.08359"
  },
  {
    "id": "arXiv:1805.11514",
    "title": "Large Multiuser MIMO Detection: Algorithms and Architectures",
    "abstract": "Comments: PhD dissertation - Hadi Sarieddeen",
    "descriptor": "\nComments: PhD dissertation - Hadi Sarieddeen\n",
    "authors": [
      "Hadi Sarieddeen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1805.11514"
  },
  {
    "id": "arXiv:1807.02735",
    "title": "Coalgebraic Tools for Randomness-Conserving Protocols",
    "abstract": "Comments: 37 pages, including references. In submission to J. Logical and Algebraic Methods in Programming",
    "descriptor": "\nComments: 37 pages, including references. In submission to J. Logical and Algebraic Methods in Programming\n",
    "authors": [
      "Dexter Kozen",
      "Matvey Soloviev"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1807.02735"
  },
  {
    "id": "arXiv:1807.09647",
    "title": "Variational Bayesian Reinforcement Learning with Regret Bounds",
    "abstract": "Variational Bayesian Reinforcement Learning with Regret Bounds",
    "descriptor": "",
    "authors": [
      "Brendan O'Donoghue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1807.09647"
  },
  {
    "id": "arXiv:1903.00226",
    "title": "A Trichotomy for Regular Trail Queries",
    "abstract": "A Trichotomy for Regular Trail Queries",
    "descriptor": "",
    "authors": [
      "Wim Martens",
      "Matthias Niewerth",
      "Tina Popp"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1903.00226"
  },
  {
    "id": "arXiv:1903.03299",
    "title": "You Only Recognize Once: Towards Fast Video Text Spotting",
    "abstract": "Comments: Accepted by ACM Multimedia 2019. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2019. Code is available at this https URL or this https URL\n",
    "authors": [
      "Zhanzhan Cheng",
      "Jing Lu",
      "Yi Niu",
      "Shiliang Pu",
      "Fei Wu",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.03299"
  },
  {
    "id": "arXiv:1903.11688",
    "title": "Rallying Adversarial Techniques against Deep Learning for Network  Security",
    "abstract": "Comments: accepted by IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)",
    "descriptor": "\nComments: accepted by IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)\n",
    "authors": [
      "Joseph Clements",
      "Yuzhe Yang",
      "Ankur Sharma",
      "Hongxin Hu",
      "Yingjie Lao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.11688"
  },
  {
    "id": "arXiv:1906.08308",
    "title": "The Complexity of Online Bribery in Sequential Elections",
    "abstract": "The Complexity of Online Bribery in Sequential Elections",
    "descriptor": "",
    "authors": [
      "Edith Hemaspaandra",
      "Lane A. Hemaspaandra",
      "Joerg Rothe"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1906.08308"
  },
  {
    "id": "arXiv:1906.10509",
    "title": "Zero-Shot Image Classification Using Coupled Dictionary Embedding",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1709.03688",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1709.03688\n",
    "authors": [
      "Mohammad Rostami",
      "Soheil Kolouri",
      "Zak Murez",
      "Yuri Owekcho",
      "Eric Eaton",
      "Kuyngnam Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.10509"
  },
  {
    "id": "arXiv:1906.12304",
    "title": "Statistical Learning from Biased Training Samples",
    "abstract": "Statistical Learning from Biased Training Samples",
    "descriptor": "",
    "authors": [
      "Stephan Cl\u00e9men\u00e7on",
      "Pierre Laforgue"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.12304"
  },
  {
    "id": "arXiv:1909.05244",
    "title": "Automatic Debiased Machine Learning for Instrumental Variable Models of  Complier Treatment Effects",
    "abstract": "Comments: 68 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 68 pages, 5 figures, 2 tables\n",
    "authors": [
      "Rahul Singh",
      "Liyang Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1909.05244"
  },
  {
    "id": "arXiv:1910.01697",
    "title": "A Henkin-style completeness proof for the modal logic S5",
    "abstract": "A Henkin-style completeness proof for the modal logic S5",
    "descriptor": "",
    "authors": [
      "Bruno Bentzen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1910.01697"
  },
  {
    "id": "arXiv:1911.04082",
    "title": "Time-Optimal Coordination for Connected and Automated Vehicles at  Adjacent Intersections",
    "abstract": "Comments: 17 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 17 pages, 7 figures, 3 tables\n",
    "authors": [
      "Behdad Chalaki",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1911.04082"
  },
  {
    "id": "arXiv:1911.12641",
    "title": "PhIT-Net: Photo-consistent Image Transform for Robust Illumination  Invariant Matching",
    "abstract": "Comments: Paper accepted for publication at BMVC 2021. This version has the same content as in the published version, including the supplementary material",
    "descriptor": "\nComments: Paper accepted for publication at BMVC 2021. This version has the same content as in the published version, including the supplementary material\n",
    "authors": [
      "Damian Kaliroff",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1911.12641"
  },
  {
    "id": "arXiv:1912.00747",
    "title": "The Transformative Potential of Artificial Intelligence",
    "abstract": "Comments: Under review, revised once. 17 pages",
    "descriptor": "\nComments: Under review, revised once. 17 pages\n",
    "authors": [
      "Ross Gruetzemacher",
      "Jess Whittlestone"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1912.00747"
  },
  {
    "id": "arXiv:1912.00931",
    "title": "Pursuing the fundamental limits for quantum communication",
    "abstract": "Comments: 14 pages, v3 close to the published version",
    "descriptor": "\nComments: 14 pages, v3 close to the published version\n",
    "authors": [
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/1912.00931"
  },
  {
    "id": "arXiv:1912.09064",
    "title": "Malware Makeover: Breaking ML-based Static Analysis by Modifying  Executable Bytes",
    "abstract": "Comments: Code for transformations at this https URL Presentation at this https URL An author of a related work [32] contacted us regarding our characterization of their defense (Sec 2.2). They point out that our attack is not within the stated scope of their defense, but agree their defense would be ineffective against our attack",
    "descriptor": "\nComments: Code for transformations at this https URL Presentation at this https URL An author of a related work [32] contacted us regarding our characterization of their defense (Sec 2.2). They point out that our attack is not within the stated scope of their defense, but agree their defense would be ineffective against our attack\n",
    "authors": [
      "Keane Lucas",
      "Mahmood Sharif",
      "Lujo Bauer",
      "Michael K. Reiter",
      "Saurabh Shintre"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.09064"
  },
  {
    "id": "arXiv:2001.00758",
    "title": "On Supergraphs Satisfying CMSO Properties",
    "abstract": "Comments: Accepted to Logical Methods in Computer Science (LMCS). A preliminary version of this work appeared at the 26th EACSL Annual Conference on Computer Science Logic, CSL 2017",
    "descriptor": "\nComments: Accepted to Logical Methods in Computer Science (LMCS). A preliminary version of this work appeared at the 26th EACSL Annual Conference on Computer Science Logic, CSL 2017\n",
    "authors": [
      "Mateus de Oliveira Oliveira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2001.00758"
  },
  {
    "id": "arXiv:2001.11845",
    "title": "Learn to Predict Sets Using Feed-Forward Neural Networks",
    "abstract": "Comments: Accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2022. arXiv admin note: substantial text overlap with arXiv:1805.00613",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2022. arXiv admin note: substantial text overlap with arXiv:1805.00613\n",
    "authors": [
      "Hamid Rezatofighi",
      "Tianyu Zhu",
      "Roman Kaskman",
      "Farbod T. Motlagh",
      "Qinfeng Shi",
      "Anton Milan",
      "Daniel Cremers",
      "Laura Leal-Taix\u00e9",
      "Ian Reid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.11845"
  },
  {
    "id": "arXiv:2002.05038",
    "title": "Robustness analytics to data heterogeneity in edge computing",
    "abstract": "Robustness analytics to data heterogeneity in edge computing",
    "descriptor": "",
    "authors": [
      "Jia Qian",
      "Lars Kai Hansen",
      "Xenofon Fafoutis",
      "Prayag Tiwari",
      "Hari Mohan Pandey"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05038"
  },
  {
    "id": "arXiv:2002.06820",
    "title": "Text Perceptron: Towards End-to-End Arbitrary-Shaped Text Spotting",
    "abstract": "Comments: Accepted by AAAI2020. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted by AAAI2020. Code is available at this https URL or this https URL\n",
    "authors": [
      "Liang Qiao",
      "Sanli Tang",
      "Zhanzhan Cheng",
      "Yunlu Xu",
      "Yi Niu",
      "Shiliang Pu",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2002.06820"
  },
  {
    "id": "arXiv:2003.01497",
    "title": "A Permutation-Equivariant Neural Network Architecture For Auction Design",
    "abstract": "A Permutation-Equivariant Neural Network Architecture For Auction Design",
    "descriptor": "",
    "authors": [
      "Jad Rahme",
      "Samy Jelassi",
      "Joan Bruna",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.01497"
  },
  {
    "id": "arXiv:2003.06534",
    "title": "Towards Causality-Aware Inferring: A Sequential Discriminative Approach  for Medical Automatic Diagnosis",
    "abstract": "Comments: Submitted to Artificial Intelligence Journal 2021. In the experiments, our trained agent achieves the new state-of-the-art under various experimental settings and possesses the advantage of sample-efficiency and robustness compared to other existing MAD methods",
    "descriptor": "\nComments: Submitted to Artificial Intelligence Journal 2021. In the experiments, our trained agent achieves the new state-of-the-art under various experimental settings and possesses the advantage of sample-efficiency and robustness compared to other existing MAD methods\n",
    "authors": [
      "Junfan Lin",
      "Keze Wang",
      "Ziliang Chen",
      "Xiaodan Liang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.06534"
  },
  {
    "id": "arXiv:2003.06883",
    "title": "Night-time Scene Parsing with a Large Real Dataset",
    "abstract": "Comments: 13 pages, 11 figures. This paper is aceepted to IEEE Transactions on Image Processing. The dataset can be accessed only by sending us requests at this stage",
    "descriptor": "\nComments: 13 pages, 11 figures. This paper is aceepted to IEEE Transactions on Image Processing. The dataset can be accessed only by sending us requests at this stage\n",
    "authors": [
      "Xin Tan",
      "Ke Xu",
      "Ying Cao",
      "Yiheng Zhang",
      "Lizhuang Ma",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.06883"
  },
  {
    "id": "arXiv:2004.01041",
    "title": "On the Optimal Feedback Law in Stochastic Optimal Nonlinear Control",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2002.10505, arXiv:2002.09478",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2002.10505, arXiv:2002.09478\n",
    "authors": [
      "Mohamed Naveed Gul Mohamed",
      "Suman Chakravorty",
      "Raman Goyal",
      "Ran Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.01041"
  },
  {
    "id": "arXiv:2004.06092",
    "title": "mFLICA: An R package for Inferring Leadership of Coordination From Time  Series",
    "abstract": "Comments: The latest version of R package can be found at this https URL",
    "descriptor": "\nComments: The latest version of R package can be found at this https URL\n",
    "authors": [
      "Chainarong Amornbunchornvej"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Econometrics (econ.EM)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2004.06092"
  },
  {
    "id": "arXiv:2004.11262",
    "title": "Supervised Domain Adaptation: A Graph Embedding Perspective and a  Rectified Experimental Protocol",
    "abstract": "Comments: 13 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 13 pages, 7 figures, 6 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Omar Ali Sheikh-Omar",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.11262"
  },
  {
    "id": "arXiv:2004.11627",
    "title": "Convolution-Weight-Distribution Assumption: Rethinking the Criteria of  Channel Pruning",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Zhongzhan Huang",
      "Wenqi Shao",
      "Xinjiang Wang",
      "Liang Lin",
      "Ping Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.11627"
  },
  {
    "id": "arXiv:2004.13912",
    "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
    "abstract": "Comments: Spotlight (Top 3%) at NeurIPS 2021",
    "descriptor": "\nComments: Spotlight (Top 3%) at NeurIPS 2021\n",
    "authors": [
      "Rishabh Agarwal",
      "Levi Melnick",
      "Nicholas Frosst",
      "Xuezhou Zhang",
      "Ben Lengerich",
      "Rich Caruana",
      "Geoffrey Hinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.13912"
  },
  {
    "id": "arXiv:2004.14455",
    "title": "Sparse Cholesky factorization by Kullback-Leibler minimization",
    "abstract": "Comments: The code used to run the numerical experiments can be found under this https URL Appeared in SIAM Journal on Scientific Computing",
    "descriptor": "\nComments: The code used to run the numerical experiments can be found under this https URL Appeared in SIAM Journal on Scientific Computing\n",
    "authors": [
      "Florian Sch\u00e4fer",
      "Matthias Katzfuss",
      "Houman Owhadi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2004.14455"
  },
  {
    "id": "arXiv:2004.14789",
    "title": "Twin-width I: tractable FO model checking",
    "abstract": "Comments: 49 pages, 9 figures",
    "descriptor": "\nComments: 49 pages, 9 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "Eun Jung Kim",
      "St\u00e9phan Thomass\u00e9",
      "R\u00e9mi Watrigant"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.14789"
  },
  {
    "id": "arXiv:2005.00942",
    "title": "Alignment-free Genomic Analysis via a Big Data Spark Platform",
    "abstract": "Alignment-free Genomic Analysis via a Big Data Spark Platform",
    "descriptor": "",
    "authors": [
      "Umberto Ferraro Petrillo",
      "Francesco Palini",
      "Giuseppe Cattaneo",
      "Raffaele Giancarlo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2005.00942"
  },
  {
    "id": "arXiv:2005.02233",
    "title": "A Survey on Dialog Management: Recent Advances and Challenges",
    "abstract": "A Survey on Dialog Management: Recent Advances and Challenges",
    "descriptor": "",
    "authors": [
      "Yinpei Dai",
      "Huihua Yu",
      "Yixuan Jiang",
      "Chengguang Tang",
      "Yongbin Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2005.02233"
  },
  {
    "id": "arXiv:2005.13117",
    "title": "SPIN: Structure-Preserving Inner Offset Network for Scene Text  Recognition",
    "abstract": "Comments: Accepted to AAAI21. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted to AAAI21. Code is available at this https URL or this https URL\n",
    "authors": [
      "Chengwei Zhang",
      "Yunlu Xu",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Yi Niu",
      "Fei Wu",
      "Futai Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.13117"
  },
  {
    "id": "arXiv:2005.13118",
    "title": "TRIE: End-to-End Text Reading and Information Extraction for Document  Understanding",
    "abstract": "Comments: Accepted to ACM MM2020. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted to ACM MM2020. Code is available at this https URL or this https URL\n",
    "authors": [
      "Peng Zhang",
      "Yunlu Xu",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Jing Lu",
      "Liang Qiao",
      "Yi Niu",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.13118"
  },
  {
    "id": "arXiv:2005.14117",
    "title": "Multimodal Feature Fusion and Knowledge-Driven Learning via Experts  Consult for Thyroid Nodule Classification",
    "abstract": "Multimodal Feature Fusion and Knowledge-Driven Learning via Experts  Consult for Thyroid Nodule Classification",
    "descriptor": "",
    "authors": [
      "Danilo Avola",
      "Luigi Cinque",
      "Alessio Fagioli",
      "Sebastiano Filetti",
      "Giorgio Grani",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.14117"
  },
  {
    "id": "arXiv:2006.05684",
    "title": "Auction learning as a two-player game",
    "abstract": "Auction learning as a two-player game",
    "descriptor": "",
    "authors": [
      "Jad Rahme",
      "Samy Jelassi",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05684"
  },
  {
    "id": "arXiv:2006.06067",
    "title": "Treewidth versus clique number. I. Graph classes with a forbidden  structure",
    "abstract": "Comments: 29 pages. Accepted for publication in SIAM Journal on Discrete Mathematics",
    "descriptor": "\nComments: 29 pages. Accepted for publication in SIAM Journal on Discrete Mathematics\n",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Martin Milani\u010d",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.06067"
  },
  {
    "id": "arXiv:2006.07073",
    "title": "Parametric solutions of turbulent incompressible flows in OpenFOAM via  the proper generalised decomposition",
    "abstract": "Comments: 44 pages, 13 figures, 2 tables",
    "descriptor": "\nComments: 44 pages, 13 figures, 2 tables\n",
    "authors": [
      "Vasileios Tsiolakis",
      "Matteo Giacomini",
      "Ruben Sevilla",
      "Carsten Othmer",
      "Antonio Huerta"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.07073"
  },
  {
    "id": "arXiv:2006.07322",
    "title": "Evaluation of Neural Architectures Trained with Square Loss vs  Cross-Entropy in Classification Tasks",
    "abstract": "Comments: An extended version of the paper published at ICLR2021. Added material includes evaluations of Transformer architectures",
    "descriptor": "\nComments: An extended version of the paper published at ICLR2021. Added material includes evaluations of Transformer architectures\n",
    "authors": [
      "Like Hui",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07322"
  },
  {
    "id": "arXiv:2006.16861",
    "title": "A time-domain preconditioner for the Helmholtz equation",
    "abstract": "Comments: 29 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 29 pages, 3 figures, 3 tables\n",
    "authors": [
      "Christiaan C. Stolk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.16861"
  },
  {
    "id": "arXiv:2007.00345",
    "title": "Distributed Linearly Separable Computation",
    "abstract": "Comments: 20 pages, 2 figures, accepted by the IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 20 pages, 2 figures, accepted by the IEEE Transactions on Information Theory\n",
    "authors": [
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.00345"
  },
  {
    "id": "arXiv:2007.02794",
    "title": "Efficient Connected and Automated Driving System with Multi-agent Graph  Reinforcement Learning",
    "abstract": "Efficient Connected and Automated Driving System with Multi-agent Graph  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Tianyu Shi",
      "Jiawei Wang",
      "Yuankai Wu",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.02794"
  },
  {
    "id": "arXiv:2007.03485",
    "title": "A discrete Weber inequality on three-dimensional hybrid spaces with  application to the HHO approximation of magnetostatics",
    "abstract": "A discrete Weber inequality on three-dimensional hybrid spaces with  application to the HHO approximation of magnetostatics",
    "descriptor": "",
    "authors": [
      "Florent Chave",
      "Daniele A. Di Pietro",
      "Simon Lemaire"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.03485"
  },
  {
    "id": "arXiv:2007.07175",
    "title": "Unsupervised Spatio-temporal Latent Feature Clustering for  Multiple-object Tracking and Segmentation",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Abubakar Siddique",
      "Reza Jalil Mozhdehi",
      "Henry Medeiros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.07175"
  },
  {
    "id": "arXiv:2007.07214",
    "title": "CenterNet3D: An Anchor Free Object Detector for Point Cloud",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Guojun Wang",
      "Jian Wu",
      "Bin Tian",
      "Siyu Teng",
      "Long Chen",
      "Dongpu Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.07214"
  },
  {
    "id": "arXiv:2007.10976",
    "title": "Interactive Inference under Information Constraints",
    "abstract": "Comments: Modifying the proof and statement of Proposition 24 to address an issue in the variance analysis",
    "descriptor": "\nComments: Modifying the proof and statement of Proposition 24 to address an issue in the variance analysis\n",
    "authors": [
      "Jayadev Acharya",
      "Cl\u00e9ment L. Canonne",
      "Yuhan Liu",
      "Ziteng Sun",
      "Himanshu Tyagi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2007.10976"
  },
  {
    "id": "arXiv:2007.12963",
    "title": "Minimum Overhead Beamforming and Resource Allocation in D2D Edge  Networks",
    "abstract": "Comments: This paper is currently under revision for possible publication",
    "descriptor": "\nComments: This paper is currently under revision for possible publication\n",
    "authors": [
      "Junghoon Kim",
      "Taejoon Kim",
      "Morteza Hashemi",
      "Christopher G. Brinton",
      "David J. Love"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.12963"
  },
  {
    "id": "arXiv:2007.13571",
    "title": "Covert Millimeter-Wave Communication: Design Strategies and Performance  Analysis",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions on Wireless Communications. arXiv admin note: substantial text overlap with arXiv:1908.07591",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Wireless Communications. arXiv admin note: substantial text overlap with arXiv:1908.07591\n",
    "authors": [
      "Mohammad Vahid Jamali",
      "Hessam Mahdavifar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.13571"
  },
  {
    "id": "arXiv:2008.01039",
    "title": "Spiking neuromorphic chip learns entangled quantum states",
    "abstract": "Comments: 9+13 pages, 4+2 figures; Submission to SciPost",
    "descriptor": "\nComments: 9+13 pages, 4+2 figures; Submission to SciPost\n",
    "authors": [
      "Stefanie Czischek",
      "Andreas Baumbach",
      "Sebastian Billaudelle",
      "Benjamin Cramer",
      "Lukas Kades",
      "Jan M. Pawlowski",
      "Markus K. Oberthaler",
      "Johannes Schemmel",
      "Mihai A. Petrovici",
      "Thomas Gasenzer",
      "Martin G\u00e4rttner"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.01039"
  },
  {
    "id": "arXiv:2008.03276",
    "title": "Total Variation Diminishing (TVD) method for Elastohydrodynamic  Lubrication (EHL) problem on Parallel Computers",
    "abstract": "Total Variation Diminishing (TVD) method for Elastohydrodynamic  Lubrication (EHL) problem on Parallel Computers",
    "descriptor": "",
    "authors": [
      "Peeyush Singh",
      "Pravir Dutt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.03276"
  },
  {
    "id": "arXiv:2008.07690",
    "title": "An a posteriori error estimate of the outer normal derivative using dual  weights",
    "abstract": "Comments: 27 pages, 13 figures, 3 tables",
    "descriptor": "\nComments: 27 pages, 13 figures, 3 tables\n",
    "authors": [
      "Silvia Bertoluzza",
      "Erik Burman",
      "Cuiyu He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.07690"
  },
  {
    "id": "arXiv:2008.11292",
    "title": "Flip Paths Between Lattice Triangulations",
    "abstract": "Comments: 24 pages (33 with appendices), 8 figures",
    "descriptor": "\nComments: 24 pages (33 with appendices), 8 figures\n",
    "authors": [
      "William Sims",
      "Meera Sitharam"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.11292"
  },
  {
    "id": "arXiv:2009.01103",
    "title": "Face Image Quality Assessment: A Literature Survey",
    "abstract": "Face Image Quality Assessment: A Literature Survey",
    "descriptor": "",
    "authors": [
      "Torsten Schlett",
      "Christian Rathgeb",
      "Olaf Henniger",
      "Javier Galbally",
      "Julian Fierrez",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.01103"
  },
  {
    "id": "arXiv:2009.02033",
    "title": "Markovian Traffic Equilibrium Assignment based on Network Generalized  Extreme Value Model",
    "abstract": "Comments: 37 pages, 14 figures",
    "descriptor": "\nComments: 37 pages, 14 figures\n",
    "authors": [
      "Yuki Oyama",
      "Yusuke Hara",
      "Takashi Akamatsu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.02033"
  },
  {
    "id": "arXiv:2009.03892",
    "title": "Neural-PDE: A RNN based neural network for solving time dependent PDEs",
    "abstract": "Neural-PDE: A RNN based neural network for solving time dependent PDEs",
    "descriptor": "",
    "authors": [
      "Yihao Hu",
      "Tong Zhao",
      "Shixin Xu",
      "Zhiliang Xu",
      "Lizhen Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03892"
  },
  {
    "id": "arXiv:2009.06924",
    "title": "360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales",
    "abstract": "360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales",
    "descriptor": "",
    "authors": [
      "Ashesh",
      "Chu-Song Chen",
      "Hsuan-Tien Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.06924"
  },
  {
    "id": "arXiv:2009.09197",
    "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "abstract": "Comments: accepted by NeurIPS2021",
    "descriptor": "\nComments: accepted by NeurIPS2021\n",
    "authors": [
      "Junjie Chen",
      "Li Niu",
      "Liu Liu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.09197"
  },
  {
    "id": "arXiv:2009.13441",
    "title": "Partially Observable Minimum-Age Scheduling: The Greedy Policy",
    "abstract": "Comments: 18 pages, 10 figures",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Yulin Shao",
      "Qi Cao",
      "Soung Chang Liew",
      "He Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.13441"
  },
  {
    "id": "arXiv:2009.14193",
    "title": "Uncertainty Sets for Image Classifiers using Conformal Prediction",
    "abstract": "Comments: ICLR 2021 Spotlight, this https URL . Project website available at this https URL . Codebase available at this https URL",
    "descriptor": "\nComments: ICLR 2021 Spotlight, this https URL . Project website available at this https URL . Codebase available at this https URL\n",
    "authors": [
      "Anastasios Angelopoulos",
      "Stephen Bates",
      "Jitendra Malik",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.14193"
  },
  {
    "id": "arXiv:2010.00163",
    "title": "Bayesian Meta-reinforcement Learning for Traffic Signal Control",
    "abstract": "Bayesian Meta-reinforcement Learning for Traffic Signal Control",
    "descriptor": "",
    "authors": [
      "Yayi Zou",
      "Zhiwei Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00163"
  },
  {
    "id": "arXiv:2010.00187",
    "title": "Who Are the `Silent Spreaders'?: Contact Tracing in Spatio-Temporal  Memory Models",
    "abstract": "Comments: 8 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Yue Hu",
      "Budhitama Subagdja",
      "Ah-Hwee Tan",
      "Chai Quek",
      "Quanjun Yin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.00187"
  },
  {
    "id": "arXiv:2010.02002",
    "title": "Enhancing Haptic Distinguishability of Surface Materials with Boosting  Technique",
    "abstract": "Enhancing Haptic Distinguishability of Surface Materials with Boosting  Technique",
    "descriptor": "",
    "authors": [
      "Priyadarshini K",
      "Subhasis Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02002"
  },
  {
    "id": "arXiv:2010.02610",
    "title": "Robust priors for regularized regression",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Sebastian Bobadilla-Suarez",
      "Matt Jones",
      "Bradley C. Love"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02610"
  },
  {
    "id": "arXiv:2010.03649",
    "title": "Calibration of Elastoplastic Constitutive Model Parameters from  Full-field Data with Automatic Differentiation-based Sensitivities",
    "abstract": "Calibration of Elastoplastic Constitutive Model Parameters from  Full-field Data with Automatic Differentiation-based Sensitivities",
    "descriptor": "",
    "authors": [
      "Daniel Thomas Seidl",
      "Brian Neal Granzow"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2010.03649"
  },
  {
    "id": "arXiv:2010.07217",
    "title": "Back to the Future: Cycle Encoding Prediction for Self-supervised  Contrastive Video Representation Learning",
    "abstract": "Comments: accepted at BMVC",
    "descriptor": "\nComments: accepted at BMVC\n",
    "authors": [
      "Xinyu Yang",
      "Majid Mirmehdi",
      "Tilo Burghardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.07217"
  },
  {
    "id": "arXiv:2010.07853",
    "title": "Selective Classification via One-Sided Prediction",
    "abstract": "Comments: v4: update to add relevant references",
    "descriptor": "\nComments: v4: update to add relevant references\n",
    "authors": [
      "Aditya Gangrade",
      "Anil Kag",
      "Venkatesh Saligrama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.07853"
  },
  {
    "id": "arXiv:2010.10670",
    "title": "Iterative Amortized Policy Optimization",
    "abstract": "Comments: Advances in Neural Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Advances in Neural Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Joseph Marino",
      "Alexandre Pich\u00e9",
      "Alessandro Davide Ialongo",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10670"
  },
  {
    "id": "arXiv:2010.10682",
    "title": "VenoMave: Targeted Poisoning Against Speech Recognition",
    "abstract": "VenoMave: Targeted Poisoning Against Speech Recognition",
    "descriptor": "",
    "authors": [
      "Hojjat Aghakhani",
      "Lea Sch\u00f6nherr",
      "Thorsten Eisenhofer",
      "Dorothea Kolossa",
      "Thorsten Holz",
      "Christopher Kruegel",
      "Giovanni Vigna"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.10682"
  },
  {
    "id": "arXiv:2010.11462",
    "title": "Linear-Delay Enumeration for Minimal Steiner Problems",
    "abstract": "Linear-Delay Enumeration for Minimal Steiner Problems",
    "descriptor": "",
    "authors": [
      "Yasuaki Kobayashi",
      "Kazuhiro Kurita",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.11462"
  },
  {
    "id": "arXiv:2010.11675",
    "title": "Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS  Measurements",
    "abstract": "Comments: 7 pages, 6 figures. Accepted by ICRA 2021",
    "descriptor": "\nComments: 7 pages, 6 figures. Accepted by ICRA 2021\n",
    "authors": [
      "Jinxu Liu",
      "Wei Gao",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.11675"
  },
  {
    "id": "arXiv:2010.13723",
    "title": "Optimal Client Sampling for Federated Learning",
    "abstract": "Comments: 13 pages, 12 pages of Appendix, 9 Figures, 3 algorithms, code available: this https URL",
    "descriptor": "\nComments: 13 pages, 12 pages of Appendix, 9 Figures, 3 algorithms, code available: this https URL\n",
    "authors": [
      "Wenlin Chen",
      "Samuel Horvath",
      "Peter Richtarik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.13723"
  },
  {
    "id": "arXiv:2010.14498",
    "title": "Implicit Under-Parameterization Inhibits Data-Efficient Deep  Reinforcement Learning",
    "abstract": "Comments: ICLR 2021. First two authors contributed equally. Website: this https URL",
    "descriptor": "\nComments: ICLR 2021. First two authors contributed equally. Website: this https URL\n",
    "authors": [
      "Aviral Kumar",
      "Rishabh Agarwal",
      "Dibya Ghosh",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.14498"
  },
  {
    "id": "arXiv:2010.15444",
    "title": "Advanced Python Performance Monitoring with Score-P",
    "abstract": "Advanced Python Performance Monitoring with Score-P",
    "descriptor": "",
    "authors": [
      "Andreas Gocht",
      "Robert Sch\u00f6ne",
      "Jan Frenzel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.15444"
  },
  {
    "id": "arXiv:2010.15596",
    "title": "Verification of Patterns",
    "abstract": "Comments: 189 pages, 100 figures, 12 tables",
    "descriptor": "\nComments: 189 pages, 100 figures, 12 tables\n",
    "authors": [
      "Yong Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.15596"
  },
  {
    "id": "arXiv:2010.16212",
    "title": "Efficient constrained sampling via the mirror-Langevin algorithm",
    "abstract": "Comments: 26 pages, 4 figures",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Kwangjun Ahn",
      "Sinho Chewi"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16212"
  },
  {
    "id": "arXiv:2011.02073",
    "title": "MBB: Model-Based Baseline for Global Guidance of Model-Free  Reinforcement Learning via Lower-Dimensional Solutions",
    "abstract": "Comments: Submitted to the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Xubo Lyu",
      "Site Li",
      "Seth Siriya",
      "Ye Pu",
      "Mo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.02073"
  },
  {
    "id": "arXiv:2011.02803",
    "title": "Intriguing Properties of Contrastive Losses",
    "abstract": "Comments: NeurIPS 2021. Code and visualization at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code and visualization at this https URL\n",
    "authors": [
      "Ting Chen",
      "Calvin Luo",
      "Lala Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.02803"
  },
  {
    "id": "arXiv:2011.05957",
    "title": "Counting Homomorphic Cycles in Degenerate Graphs",
    "abstract": "Counting Homomorphic Cycles in Degenerate Graphs",
    "descriptor": "",
    "authors": [
      "Lior Gishboliner",
      "Yevgeny Levanzov",
      "Asaf Shapira",
      "Raphael Yuster"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.05957"
  },
  {
    "id": "arXiv:2011.07464",
    "title": "Predictive Coding, Variational Autoencoders, and Biological Connections",
    "abstract": "Comments: NeurIPS NeuroAI Workshop, NAISys, Neural Computation",
    "descriptor": "\nComments: NeurIPS NeuroAI Workshop, NAISys, Neural Computation\n",
    "authors": [
      "Joseph Marino"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.07464"
  },
  {
    "id": "arXiv:2011.07793",
    "title": "MAAC: Novel Alert Correlation Method To Detect Multi-step Attack",
    "abstract": "Comments: 8 pages,5 figures, trustcom2021",
    "descriptor": "\nComments: 8 pages,5 figures, trustcom2021\n",
    "authors": [
      "Xiaoyu Wang",
      "Xiaorui Gong",
      "Lei Yu",
      "Jian Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.07793"
  },
  {
    "id": "arXiv:2011.10530",
    "title": "On barren plateaus and cost function locality in variational quantum  algorithms",
    "abstract": "Comments: 26 pages, RevTeX",
    "descriptor": "\nComments: 26 pages, RevTeX\n",
    "authors": [
      "Alexey Uvarov",
      "Jacob Biamonte"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10530"
  },
  {
    "id": "arXiv:2011.10577",
    "title": "Deep learning insights into cosmological structure formation",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Luisa Lucie-Smith",
      "Hiranya V. Peiris",
      "Andrew Pontzen",
      "Brian Nord",
      "Jeyan Thiyagalingam"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10577"
  },
  {
    "id": "arXiv:2011.13079",
    "title": "A Visual Analytics Approach for Hardware System Monitoring withStreaming  Functional Data Analysis",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Fnu Shilpika",
      "Takanori Fujiwara",
      "Naohisa Sakamoto",
      "Jorji Nonaka",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2011.13079"
  },
  {
    "id": "arXiv:2012.01244",
    "title": "General Characterization of Agents by States they Visit",
    "abstract": "Comments: Deep Reinforcement Learning Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Deep Reinforcement Learning Workshop, NeurIPS 2021\n",
    "authors": [
      "Anssi Kanervisto",
      "Tomi Kinnunen",
      "Ville Hautam\u00e4ki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.01244"
  },
  {
    "id": "arXiv:2012.01826",
    "title": "Singularity-free Guiding Vector Field for Robot Navigation",
    "abstract": "Comments: Accepted for publication in IEEE Trransactions on Robotics (T-RO)",
    "descriptor": "\nComments: Accepted for publication in IEEE Trransactions on Robotics (T-RO)\n",
    "authors": [
      "Weijia Yao",
      "Hector Garcia de Marina",
      "Bohuan Lin",
      "Ming Cao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.01826"
  },
  {
    "id": "arXiv:2012.02178",
    "title": "Steady-State Planning in Expected Reward Multichain MDPs",
    "abstract": "Steady-State Planning in Expected Reward Multichain MDPs",
    "descriptor": "",
    "authors": [
      "George K. Atia",
      "Andre Beckus",
      "Ismail Alkhouri",
      "Alvaro Velasquez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.02178"
  },
  {
    "id": "arXiv:2012.02646",
    "title": "Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with  Natural Language",
    "abstract": "Comments: Accepted By TPAMI. arXiv admin note: text overlap with arXiv:1912.03590",
    "descriptor": "\nComments: Accepted By TPAMI. arXiv admin note: text overlap with arXiv:1912.03590\n",
    "authors": [
      "Songyang Zhang",
      "Houwen Peng",
      "Jianlong Fu",
      "Yijuan Lu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.02646"
  },
  {
    "id": "arXiv:2012.04025",
    "title": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "abstract": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "descriptor": "",
    "authors": [
      "Mahsa Zarneshan",
      "Fatemeh Ghassemi",
      "Ehsan Khamespanah",
      "Marjan Sirjani",
      "John Hatcliff"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.04025"
  },
  {
    "id": "arXiv:2012.04061",
    "title": "Faster Non-Convex Federated Learning via Global and Local Momentum",
    "abstract": "Faster Non-Convex Federated Learning via Global and Local Momentum",
    "descriptor": "",
    "authors": [
      "Rudrajit Das",
      "Anish Acharya",
      "Abolfazl Hashemi",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.04061"
  },
  {
    "id": "arXiv:2012.04144",
    "title": "Improved Swarm Engineering: Aligning Intuition and Analysis",
    "abstract": "Improved Swarm Engineering: Aligning Intuition and Analysis",
    "descriptor": "",
    "authors": [
      "John Harwell",
      "Maria Gini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.04144"
  },
  {
    "id": "arXiv:2012.04350",
    "title": "MANGO: A Mask Attention Guided One-Stage Scene Text Spotter",
    "abstract": "Comments: Accepted to AAAI2021. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted to AAAI2021. Code is available at this https URL or this https URL\n",
    "authors": [
      "Liang Qiao",
      "Ying Chen",
      "Zhanzhan Cheng",
      "Yunlu Xu",
      "Yi Niu",
      "Shiliang Pu",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04350"
  },
  {
    "id": "arXiv:2012.04848",
    "title": "Constant-round Blind Classical Verification of Quantum Sampling",
    "abstract": "Comments: improved presentation. main results remain the same",
    "descriptor": "\nComments: improved presentation. main results remain the same\n",
    "authors": [
      "Kai-Min Chung",
      "Yi Lee",
      "Han-Hsuan Lin",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.04848"
  },
  {
    "id": "arXiv:2012.06304",
    "title": "The Complexity of X3SAT: P = NP = PSPACE",
    "abstract": "The Complexity of X3SAT: P = NP = PSPACE",
    "descriptor": "",
    "authors": [
      "Latif Salum"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2012.06304"
  },
  {
    "id": "arXiv:2012.07816",
    "title": "Enabling Collaborative Data Science Development with the Ballet  Framework",
    "abstract": "Enabling Collaborative Data Science Development with the Ballet  Framework",
    "descriptor": "",
    "authors": [
      "Micah J. Smith",
      "J\u00fcrgen Cito",
      "Kelvin Lu",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.07816"
  },
  {
    "id": "arXiv:2012.13331",
    "title": "Computation of Convex Hull Prices in Electricity Markets with  Non-Convexities using Dantzig-Wolfe Decomposition",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Panagiotis Andrianesis",
      "Dimitris Bertsimas",
      "Michael C. Caramanis",
      "William W. Hogan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.13331"
  },
  {
    "id": "arXiv:2012.14100",
    "title": "Exploiting Chain Rule and Bayes' Theorem to Compare Probability  Distributions",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Huangjie Zheng",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.14100"
  },
  {
    "id": "arXiv:2012.14123",
    "title": "Spectral Analysis for Semantic Segmentation with Applications on Feature  Truncation and Weak Annotation",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Li-Wei Chen",
      "Wei-Chen Chiu",
      "Chin-Tien Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.14123"
  },
  {
    "id": "arXiv:2101.00078",
    "title": "Controlled Analyses of Social Biases in Wikipedia Bios",
    "abstract": "Controlled Analyses of Social Biases in Wikipedia Bios",
    "descriptor": "",
    "authors": [
      "Anjalie Field",
      "Chan Young Park",
      "Kevin Z. Lin",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00078"
  },
  {
    "id": "arXiv:2101.00943",
    "title": "The Minimality of the Georges-Kelmans Graph",
    "abstract": "Comments: 19 pages; to appear in Mathematics of Computation",
    "descriptor": "\nComments: 19 pages; to appear in Mathematics of Computation\n",
    "authors": [
      "Gunnar Brinkmann",
      "Jan Goedgebeur",
      "Brendan D. McKay"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2101.00943"
  },
  {
    "id": "arXiv:2101.05140",
    "title": "Secure Process Algebra",
    "abstract": "Comments: 172 pages, 36 figures, 28 tables",
    "descriptor": "\nComments: 172 pages, 36 figures, 28 tables\n",
    "authors": [
      "Yong Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.05140"
  },
  {
    "id": "arXiv:2101.06380",
    "title": "Reliable GNSS Localization Against Multiple Faults Using a Particle  Filter Framework",
    "abstract": "Comments: 13 pages, 7 figures Submitted to IEEE Transactions on Intelligent Transportation Systems (T-ITS)",
    "descriptor": "\nComments: 13 pages, 7 figures Submitted to IEEE Transactions on Intelligent Transportation Systems (T-ITS)\n",
    "authors": [
      "Shubh Gupta",
      "Grace X. Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.06380"
  },
  {
    "id": "arXiv:2101.07768",
    "title": "Assets in Software Engineering: What are they after all?",
    "abstract": "Comments: Manuscript submitted to the Journal of Systems and Software",
    "descriptor": "\nComments: Manuscript submitted to the Journal of Systems and Software\n",
    "authors": [
      "Ehsan Zabardast",
      "Julian Frattini",
      "Javier Gonzalez-Huerta",
      "Tony Gorschek",
      "Daniel Mendez",
      "Krzystof Wnuk"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.07768"
  },
  {
    "id": "arXiv:2101.08919",
    "title": "Understanding the Tradeoffs in Client-side Privacy for Downstream Speech  Tasks",
    "abstract": "Understanding the Tradeoffs in Client-side Privacy for Downstream Speech  Tasks",
    "descriptor": "",
    "authors": [
      "Peter Wu",
      "Paul Pu Liang",
      "Jiatong Shi",
      "Ruslan Salakhutdinov",
      "Shinji Watanabe",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2101.08919"
  },
  {
    "id": "arXiv:2101.10953",
    "title": "Predicting the future with a scale-invariant temporal memory for the  past",
    "abstract": "Comments: 41 pages, 9 figures; authors' final version, accepted for publication in Neural Computation",
    "descriptor": "\nComments: 41 pages, 9 figures; authors' final version, accepted for publication in Neural Computation\n",
    "authors": [
      "Wei Zhong Goh",
      "Varun Ursekar",
      "Marc W. Howard"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.10953"
  },
  {
    "id": "arXiv:2101.12727",
    "title": "Surprisingly Simple Semi-Supervised Domain Adaptation with Pretraining  and Consistency",
    "abstract": "Comments: Accepted to BMVC, 2021",
    "descriptor": "\nComments: Accepted to BMVC, 2021\n",
    "authors": [
      "Samarth Mishra",
      "Kate Saenko",
      "Venkatesh Saligrama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12727"
  },
  {
    "id": "arXiv:2102.01635",
    "title": "An offline-online strategy for multiscale problems with random defects",
    "abstract": "An offline-online strategy for multiscale problems with random defects",
    "descriptor": "",
    "authors": [
      "Axel M\u00e5lqvist",
      "Barbara Verf\u00fcrth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.01635"
  },
  {
    "id": "arXiv:2102.02694",
    "title": "Invertible DenseNets with Concatenated LipSwish",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS) 2021. This is an extension of Invertible DenseNets (arXiv:2010.02125). arXiv admin note: text overlap with arXiv:2010.02125",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS) 2021. This is an extension of Invertible DenseNets (arXiv:2010.02125). arXiv admin note: text overlap with arXiv:2010.02125\n",
    "authors": [
      "Yura Perugachi-Diaz",
      "Jakub M. Tomczak",
      "Sandjai Bhulai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02694"
  },
  {
    "id": "arXiv:2102.02711",
    "title": "Fine-tuning deep learning model parameters for improved super-resolution  of dynamic MRI with prior-knowledge",
    "abstract": "Fine-tuning deep learning model parameters for improved super-resolution  of dynamic MRI with prior-knowledge",
    "descriptor": "",
    "authors": [
      "Chompunuch Sarasaen",
      "Soumick Chatterjee",
      "Mario Breitkopf",
      "Georg Rose",
      "Andreas N\u00fcrnberger",
      "Oliver Speck"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.02711"
  },
  {
    "id": "arXiv:2102.03147",
    "title": "Learning Conjoint Attentions for Graph Neural Nets",
    "abstract": "Comments: Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Tiantian He",
      "Yew-Soon Ong",
      "Lu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03147"
  },
  {
    "id": "arXiv:2102.03988",
    "title": "Ising Model Selection Using $\\ell_{1}$-Regularized Linear Regression: A  Statistical Mechanics Analysis",
    "abstract": "Comments: NeurIPS 2021, camera-ready version with supplementary materials",
    "descriptor": "\nComments: NeurIPS 2021, camera-ready version with supplementary materials\n",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03988"
  },
  {
    "id": "arXiv:2102.04081",
    "title": "VeeAlign: Multifaceted Context Representation using Dual Attention for  Ontology Alignment",
    "abstract": "Comments: Accepted as a long paper at EMNLP 2021 main conference. arXiv admin note: text overlap with arXiv:2010.11721",
    "descriptor": "\nComments: Accepted as a long paper at EMNLP 2021 main conference. arXiv admin note: text overlap with arXiv:2010.11721\n",
    "authors": [
      "Vivek Iyer",
      "Arvind Agarwal",
      "Harshit Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.04081"
  },
  {
    "id": "arXiv:2102.04159",
    "title": "Deep Residual Learning in Spiking Neural Networks",
    "abstract": "Comments: Accepted by Advances in Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Accepted by Advances in Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Wei Fang",
      "Zhaofei Yu",
      "Yanqi Chen",
      "Tiejun Huang",
      "Timoth\u00e9e Masquelier",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.04159"
  },
  {
    "id": "arXiv:2102.04196",
    "title": "Challenges in Net Neutrality Violation Detection: A Case Study of Wehe  Tool and Improvements",
    "abstract": "Challenges in Net Neutrality Violation Detection: A Case Study of Wehe  Tool and Improvements",
    "descriptor": "",
    "authors": [
      "Vinod S. Khandkar",
      "Manjesh K. Hanawal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.04196"
  },
  {
    "id": "arXiv:2102.06866",
    "title": "Understanding Negative Samples in Instance Discriminative  Self-supervised Representation Learning",
    "abstract": "Comments: NeurIPS 2021. 27 pages, 6 figures, and 6 tables",
    "descriptor": "\nComments: NeurIPS 2021. 27 pages, 6 figures, and 6 tables\n",
    "authors": [
      "Kento Nozawa",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06866"
  },
  {
    "id": "arXiv:2102.06988",
    "title": "Learning in Multi-Stage Decentralized Matching Markets",
    "abstract": "Learning in Multi-Stage Decentralized Matching Markets",
    "descriptor": "",
    "authors": [
      "Xiaowu Dai",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06988"
  },
  {
    "id": "arXiv:2102.07325",
    "title": "Cross-modal Adversarial Reprogramming",
    "abstract": "Comments: Accepted at WACV 2022",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Paarth Neekhara",
      "Shehzeen Hussain",
      "Jinglong Du",
      "Shlomo Dubnov",
      "Farinaz Koushanfar",
      "Julian McAuley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07325"
  },
  {
    "id": "arXiv:2102.07342",
    "title": "The Phase Transition of Discrepancy in Random Hypergraphs",
    "abstract": "The Phase Transition of Discrepancy in Random Hypergraphs",
    "descriptor": "",
    "authors": [
      "Calum MacRury",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Leilani Pai",
      "Xavier P\u00e9rez-Gim\u00e9nez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.07342"
  },
  {
    "id": "arXiv:2102.07521",
    "title": "Distributed Online Learning for Joint Regret with Communication  Constraints",
    "abstract": "Distributed Online Learning for Joint Regret with Communication  Constraints",
    "descriptor": "",
    "authors": [
      "Dirk van der Hoeven",
      "H\u00e9di Hadiji",
      "Tim van Erven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07521"
  },
  {
    "id": "arXiv:2102.08504",
    "title": "Label Leakage and Protection in Two-party Split Learning",
    "abstract": "Label Leakage and Protection in Two-party Split Learning",
    "descriptor": "",
    "authors": [
      "Oscar Li",
      "Jiankai Sun",
      "Xin Yang",
      "Weihao Gao",
      "Hongyi Zhang",
      "Junyuan Xie",
      "Virginia Smith",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08504"
  },
  {
    "id": "arXiv:2102.08835",
    "title": "Vote Delegation with Unknown Preferences",
    "abstract": "Vote Delegation with Unknown Preferences",
    "descriptor": "",
    "authors": [
      "Hans Gersbach",
      "Akaki Mamageishvili",
      "Manvir Schneider"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2102.08835"
  },
  {
    "id": "arXiv:2102.09811",
    "title": "Semi-analytic integration for a parallel space-time boundary element  method modeling the heat equation",
    "abstract": "Semi-analytic integration for a parallel space-time boundary element  method modeling the heat equation",
    "descriptor": "",
    "authors": [
      "Jan Zapletal",
      "Raphael Watschinger",
      "G\u00fcnther Of",
      "Michal Merta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2102.09811"
  },
  {
    "id": "arXiv:2102.10221",
    "title": "Logarithmic Regret in Feature-based Dynamic Pricing",
    "abstract": "Comments: 30 pages, 1 figures (with 2 sub-figures)",
    "descriptor": "\nComments: 30 pages, 1 figures (with 2 sub-figures)\n",
    "authors": [
      "Jianyu Xu",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10221"
  },
  {
    "id": "arXiv:2102.10283",
    "title": "Imitation Learning for Variable Speed Contact Motion for Operation up to  Control Bandwidth",
    "abstract": "Comments: 11 pages, 19 figures, submitted for IEEE Open Journal of the Industrial Electronics Society",
    "descriptor": "\nComments: 11 pages, 19 figures, submitted for IEEE Open Journal of the Industrial Electronics Society\n",
    "authors": [
      "Sho Sakaino",
      "Kazuki Fujimoto",
      "Yuki Saigusa",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.10283"
  },
  {
    "id": "arXiv:2102.10440",
    "title": "Interventional Sum-Product Networks: Causal Inference with Tractable  Probabilistic Models",
    "abstract": "Comments: Main paper: 10 pages, References: 3 pages, Appendix: 8 pages. Main paper: 6 figures, Appendix: 5 figures",
    "descriptor": "\nComments: Main paper: 10 pages, References: 3 pages, Appendix: 8 pages. Main paper: 6 figures, Appendix: 5 figures\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Athresh Karanam",
      "Sriraam Natarajan",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10440"
  },
  {
    "id": "arXiv:2102.11976",
    "title": "Learner-Private Convex Optimization",
    "abstract": "Learner-Private Convex Optimization",
    "descriptor": "",
    "authors": [
      "Jiaming Xu",
      "Kuang Xu",
      "Dana Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.11976"
  },
  {
    "id": "arXiv:2103.00397",
    "title": "Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery  Ticket Perspective",
    "abstract": "Comments: NeurIPS 21",
    "descriptor": "\nComments: NeurIPS 21\n",
    "authors": [
      "Tianlong Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Jingjing Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.00397"
  },
  {
    "id": "arXiv:2103.00702",
    "title": "Dynamic Stochastic Blockmodel Regression for Network Data: Application  to International Militarized Conflicts",
    "abstract": "Comments: 34 pages (main text), 34 pages (supplementary information), 21 figures",
    "descriptor": "\nComments: 34 pages (main text), 34 pages (supplementary information), 21 figures\n",
    "authors": [
      "Santiago Olivella",
      "Tyler Pratt",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.00702"
  },
  {
    "id": "arXiv:2103.01529",
    "title": "Coupling Stokes flow with inhomogeneous poroelasticity",
    "abstract": "Coupling Stokes flow with inhomogeneous poroelasticity",
    "descriptor": "",
    "authors": [
      "Matteo Taffetani",
      "Ricardo Ruiz-Baier",
      "Sarah Waters"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.01529"
  },
  {
    "id": "arXiv:2103.02898",
    "title": "Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field  Approximation",
    "abstract": "Comments: 19 pages, 4 figures, accepted to the 35th Annual Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 19 pages, 4 figures, accepted to the 35th Annual Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Kazu Ghalamkari",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02898"
  },
  {
    "id": "arXiv:2103.03568",
    "title": "Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream  Data? A Theoretical Analysis",
    "abstract": "Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream  Data? A Theoretical Analysis",
    "descriptor": "",
    "authors": [
      "Jiaye Teng",
      "Weiran Huang",
      "Haowei He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.03568"
  },
  {
    "id": "arXiv:2103.05204",
    "title": "A New Metric on Symmetric Group and Applications to Block Permutation  Codes",
    "abstract": "A New Metric on Symmetric Group and Applications to Block Permutation  Codes",
    "descriptor": "",
    "authors": [
      "Zihan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2103.05204"
  },
  {
    "id": "arXiv:2103.06777",
    "title": "Wandering and getting lost: the architecture of an app activating local  communities on dementia issues",
    "abstract": "Wandering and getting lost: the architecture of an app activating local  communities on dementia issues",
    "descriptor": "",
    "authors": [
      "Nicklas Sindlev Andersen",
      "Marco Chiarandini",
      "Jacopo Mauro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.06777"
  },
  {
    "id": "arXiv:2103.07576",
    "title": "A comparison of low-cost behavioral observation software applications  and recommendations for use",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Annemarie van der Marel",
      "Claire L. O'Connell",
      "Sanjay Prasher",
      "Chelsea Carminito",
      "Xavier Francis",
      "Elizabeth A. Hobson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.07576"
  },
  {
    "id": "arXiv:2103.08077",
    "title": "Distribution Privacy Under Function Recoverability",
    "abstract": "Distribution Privacy Under Function Recoverability",
    "descriptor": "",
    "authors": [
      "Ajaykrishnan Nageswaran",
      "Prakash Narayan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.08077"
  },
  {
    "id": "arXiv:2103.09382",
    "title": "SPICE: Semantic Pseudo-labeling for Image Clustering",
    "abstract": "SPICE: Semantic Pseudo-labeling for Image Clustering",
    "descriptor": "",
    "authors": [
      "Chuang Niu",
      "Hongming Shan",
      "Ge Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.09382"
  },
  {
    "id": "arXiv:2103.11949",
    "title": "Reinforcement Learning based on Scenario-tree MPC for ASVs",
    "abstract": "Comments: This paper has been accepted to 2021 American Control Conference (ACC). 6 pages, 9 figures",
    "descriptor": "\nComments: This paper has been accepted to 2021 American Control Conference (ACC). 6 pages, 9 figures\n",
    "authors": [
      "Arash Bahari Kordabad",
      "Hossein Nejatbakhsh Esfahani",
      "Anastasios M. Lekkas",
      "S\u00e9bastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.11949"
  },
  {
    "id": "arXiv:2103.14930",
    "title": "Hyperbolic Geometry is Not Necessary: Lightweight Euclidean-Based Models  for Low-Dimensional Knowledge Graph Embeddings",
    "abstract": "Comments: Accepted for publication at the Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted for publication at the Findings of EMNLP 2021\n",
    "authors": [
      "Kai Wang",
      "Yu Liu",
      "Dan Lin",
      "Quan Z. Sheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14930"
  },
  {
    "id": "arXiv:2103.14974",
    "title": "Automatic differentiation for Riemannian optimization on low-rank matrix  and tensor-train manifolds",
    "abstract": "Automatic differentiation for Riemannian optimization on low-rank matrix  and tensor-train manifolds",
    "descriptor": "",
    "authors": [
      "Alexander Novikov",
      "Maxim Rakhuba",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.14974"
  },
  {
    "id": "arXiv:2103.16411",
    "title": "Harmonic Beltrami Signature: A Novel 2D Shape Representation for Object  Classification",
    "abstract": "Harmonic Beltrami Signature: A Novel 2D Shape Representation for Object  Classification",
    "descriptor": "",
    "authors": [
      "Chenran Lin",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16411"
  },
  {
    "id": "arXiv:2103.17258",
    "title": "Co-Adaptation of Algorithmic and Implementational Innovations in  Inference-based Deep Reinforcement Learning",
    "abstract": "Comments: Accepted at NeurIPS 2021. The implementation is available at: this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2021. The implementation is available at: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Tadashi Kozuno",
      "Tatsuya Matsushima",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.17258"
  },
  {
    "id": "arXiv:2104.00170",
    "title": "An Investigation of Critical Issues in Bias Mitigation Techniques",
    "abstract": "An Investigation of Critical Issues in Bias Mitigation Techniques",
    "descriptor": "",
    "authors": [
      "Robik Shrestha",
      "Kushal Kafle",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.00170"
  },
  {
    "id": "arXiv:2104.01006",
    "title": "Data-driven balancing of linear dynamical systems",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Ion Victor Gosea",
      "Serkan Gugercin",
      "Christopher Beattie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.01006"
  },
  {
    "id": "arXiv:2104.01194",
    "title": "Physics Informed Convex Artificial Neural Networks (PICANNs) for Optimal  Transport based Density Estimation",
    "abstract": "Comments: 14 page, 6 figures, 1 table",
    "descriptor": "\nComments: 14 page, 6 figures, 1 table\n",
    "authors": [
      "Amanpreet Singh",
      "Martin Bauer",
      "Sarang Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01194"
  },
  {
    "id": "arXiv:2104.01730",
    "title": "Training Deep Neural Networks via Branch-and-Bound",
    "abstract": "Comments: 29 pages, 17 figures. arXiv admin note: substantial text overlap with arXiv:1711.06959",
    "descriptor": "\nComments: 29 pages, 17 figures. arXiv admin note: substantial text overlap with arXiv:1711.06959\n",
    "authors": [
      "Yuanwei Wu",
      "Ziming Zhang",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01730"
  },
  {
    "id": "arXiv:2104.02808",
    "title": "Robust Control Barrier-Value Functions for Safety-Critical Control",
    "abstract": "Comments: IEEE CDC 2021",
    "descriptor": "\nComments: IEEE CDC 2021\n",
    "authors": [
      "Jason J. Choi",
      "Donggun Lee",
      "Koushil Sreenath",
      "Claire J. Tomlin",
      "Sylvia L. Herbert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.02808"
  },
  {
    "id": "arXiv:2104.03369",
    "title": "Asymmetric cooperative motion in one dimension",
    "abstract": "Comments: 28 pages, to appear in Transactions of the AMS",
    "descriptor": "\nComments: 28 pages, to appear in Transactions of the AMS\n",
    "authors": [
      "Louigi Addario-Berry",
      "Erin Beckman",
      "Jessica Lin"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.03369"
  },
  {
    "id": "arXiv:2104.04215",
    "title": "Sparse Channel Estimation in Wideband Systems with Geometric Sequence  Decomposition",
    "abstract": "Sparse Channel Estimation in Wideband Systems with Geometric Sequence  Decomposition",
    "descriptor": "",
    "authors": [
      "Woong-Hee Lee",
      "Ki Won Sung"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.04215"
  },
  {
    "id": "arXiv:2104.05348",
    "title": "Quotients of Bounded Natural Functors",
    "abstract": "Comments: Extended version of homonymous IJCAR 2020 paper",
    "descriptor": "\nComments: Extended version of homonymous IJCAR 2020 paper\n",
    "authors": [
      "Basil F\u00fcrer",
      "Andreas Lochbihler",
      "Joshua Schneider",
      "Dmitriy Traytel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.05348"
  },
  {
    "id": "arXiv:2104.06703",
    "title": "Deep Permutation Equivariant Structure from Motion",
    "abstract": "Deep Permutation Equivariant Structure from Motion",
    "descriptor": "",
    "authors": [
      "Dror Moran",
      "Hodaya Koslowsky",
      "Yoni Kasten",
      "Haggai Maron",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06703"
  },
  {
    "id": "arXiv:2104.07225",
    "title": "Text Guide: Improving the quality of long text classification by a text  selection method based on feature importance",
    "abstract": "Comments: This is the reviewed and accepted for publication version of the article by the IEEE Access Journal. One of the important modifications is publication of the code along with the paper. The code can be used to apply Text Guide to a data set of ones choice. The code is available at: this https URL",
    "descriptor": "\nComments: This is the reviewed and accepted for publication version of the article by the IEEE Access Journal. One of the important modifications is publication of the code along with the paper. The code can be used to apply Text Guide to a data set of ones choice. The code is available at: this https URL\n",
    "authors": [
      "Krzysztof Fiok",
      "Waldemar Karwowski",
      "Edgar Gutierrez",
      "Mohammad Reza Davahli",
      "Maciej Wilamowski",
      "Tareq Ahram",
      "Awad Al-Juaid",
      "Jozef Zurada"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07225"
  },
  {
    "id": "arXiv:2104.07582",
    "title": "SISA: Set-Centric Instruction Set Architecture for Graph Mining on  Processing-in-Memory Systems",
    "abstract": "Comments: Proceedings of the 54th IEEE/ACM International Symposium on Microarchitecture (MICRO'21), 2021",
    "descriptor": "\nComments: Proceedings of the 54th IEEE/ACM International Symposium on Microarchitecture (MICRO'21), 2021\n",
    "authors": [
      "Maciej Besta",
      "Raghavendra Kanakagiri",
      "Grzegorz Kwasniewski",
      "Rachata Ausavarungnirun",
      "Jakub Ber\u00e1nek",
      "Konstantinos Kanellopoulos",
      "Kacper Janda",
      "Zur Vonarburg-Shmaria",
      "Lukas Gianinazzi",
      "Ioana Stefan",
      "Juan G\u00f3mez Luna",
      "Marcin Copik",
      "Lukas Kapp-Schwoerer",
      "Salvatore Di Girolamo",
      "Marek Konieczny",
      "Nils Blach",
      "Onur Mutlu",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2104.07582"
  },
  {
    "id": "arXiv:2104.09717",
    "title": "A Recursive Approach to Solving Parity Games in Quasipolynomial Time",
    "abstract": "A Recursive Approach to Solving Parity Games in Quasipolynomial Time",
    "descriptor": "",
    "authors": [
      "Karoliina Lehtinen",
      "Pawe\u0142 Parys",
      "Sven Schewe",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.09717"
  },
  {
    "id": "arXiv:2104.09967",
    "title": "Multi-target prediction for dummies using two-branch neural networks",
    "abstract": "Multi-target prediction for dummies using two-branch neural networks",
    "descriptor": "",
    "authors": [
      "Dimitrios Iliadis",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09967"
  },
  {
    "id": "arXiv:2104.09994",
    "title": "Federated Learning for Malware Detection in IoT Devices",
    "abstract": "Federated Learning for Malware Detection in IoT Devices",
    "descriptor": "",
    "authors": [
      "Valerian Rey",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Alberto Huertas Celdr\u00e1n",
      "G\u00e9r\u00f4me Bovet",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09994"
  },
  {
    "id": "arXiv:2104.10410",
    "title": "Principal Component Density Estimation for Scenario Generation Using  Normalizing Flows",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Eike Cramer",
      "Alexander Mitsos",
      "Raul Tempone",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10410"
  },
  {
    "id": "arXiv:2104.11054",
    "title": "TeraMIMO: A Channel Simulator for Wideband Ultra-Massive MIMO Terahertz  Communications",
    "abstract": "TeraMIMO: A Channel Simulator for Wideband Ultra-Massive MIMO Terahertz  Communications",
    "descriptor": "",
    "authors": [
      "Simon Tarboush",
      "Hadi Sarieddeen",
      "Hui Chen",
      "Mohamed Habib Loukil",
      "Hakim Jemaa",
      "Mohamed Slim Alouini",
      "Tareq Y. Al-Naffouri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.11054"
  },
  {
    "id": "arXiv:2104.11864",
    "title": "Membrane Fusion-Based Transmitter Design for Static and Diffusive Mobile  Molecular Communication Systems",
    "abstract": "Comments: 16 pages, 9 figures. Accepted by IEEE Transactions on Communications. This work was presented in part at 2021 IEEE International Conference on Communication arXiv:2011.00887",
    "descriptor": "\nComments: 16 pages, 9 figures. Accepted by IEEE Transactions on Communications. This work was presented in part at 2021 IEEE International Conference on Communication arXiv:2011.00887\n",
    "authors": [
      "Xinyu Huang",
      "Yuting Fang",
      "Adam Noel",
      "Nan Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2104.11864"
  },
  {
    "id": "arXiv:2104.11896",
    "title": "M3DeTR: Multi-representation, Multi-scale, Mutual-relation 3D Object  Detection with Transformers",
    "abstract": "M3DeTR: Multi-representation, Multi-scale, Mutual-relation 3D Object  Detection with Transformers",
    "descriptor": "",
    "authors": [
      "Tianrui Guan",
      "Jun Wang",
      "Shiyi Lan",
      "Rohan Chandra",
      "Zuxuan Wu",
      "Larry Davis",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11896"
  },
  {
    "id": "arXiv:2104.13916",
    "title": "Learning Synergistic Attention for Light Field Salient Object Detection",
    "abstract": "Comments: 20 pages, 12 figures; Project Page this https URL ; Accepted to BMVC-21",
    "descriptor": "\nComments: 20 pages, 12 figures; Project Page this https URL ; Accepted to BMVC-21\n",
    "authors": [
      "Yi Zhang",
      "Geng Chen",
      "Qian Chen",
      "Yujia Sun",
      "Yong Xia",
      "Olivier Deforges",
      "Wassim Hamidouche",
      "Lu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13916"
  },
  {
    "id": "arXiv:2105.01242",
    "title": "Quantum Key-length Extension",
    "abstract": "Comments: 26 pages, 10 figures",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Joseph Jaeger",
      "Fang Song",
      "Stefano Tessaro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.01242"
  },
  {
    "id": "arXiv:2105.01747",
    "title": "Information Complexity and Generalization Bounds",
    "abstract": "Comments: To appear in 2021 IEEE International Symposium on Information Theory (ISIT); 23 pages",
    "descriptor": "\nComments: To appear in 2021 IEEE International Symposium on Information Theory (ISIT); 23 pages\n",
    "authors": [
      "Pradeep Kr. Banerjee",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.01747"
  },
  {
    "id": "arXiv:2105.02472",
    "title": "XeroAlign: Zero-Shot Cross-lingual Transformer Alignment",
    "abstract": "Comments: Findings of ACL 2021 - Code: this https URL",
    "descriptor": "\nComments: Findings of ACL 2021 - Code: this https URL\n",
    "authors": [
      "Milan Gritta",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.02472"
  },
  {
    "id": "arXiv:2105.04037",
    "title": "Graph Attention Networks with Positional Embeddings",
    "abstract": "Graph Attention Networks with Positional Embeddings",
    "descriptor": "",
    "authors": [
      "Liheng Ma",
      "Reihaneh Rabbany",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04037"
  },
  {
    "id": "arXiv:2105.04780",
    "title": "Cross-Modal Generative Augmentation for Visual Question Answering",
    "abstract": "Comments: BMVC 2021",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Zixu Wang",
      "Yishu Miao",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04780"
  },
  {
    "id": "arXiv:2105.05686",
    "title": "Yes, BM25 is a Strong Baseline for Legal Case Retrieval",
    "abstract": "Yes, BM25 is a Strong Baseline for Legal Case Retrieval",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Ruan Chaves Rodrigues",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05686"
  },
  {
    "id": "arXiv:2105.06068",
    "title": "On Sparsity Awareness in Distributed Computations",
    "abstract": "Comments: To appear in SPAA 2021",
    "descriptor": "\nComments: To appear in SPAA 2021\n",
    "authors": [
      "Keren Censor-Hillel",
      "Dean Leitersdorf",
      "Volodymyr Polosukhin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.06068"
  },
  {
    "id": "arXiv:2105.06224",
    "title": "LGPMA: Complicated Table Structure Recognition with Local and Global  Pyramid Mask Alignment",
    "abstract": "Comments: Accepted by ICDAR2021. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted by ICDAR2021. Code is available at this https URL or this https URL\n",
    "authors": [
      "Liang Qiao",
      "Zaisheng Li",
      "Zhanzhan Cheng",
      "Peng Zhang",
      "Shiliang Pu",
      "Yi Niu",
      "Wenqi Ren",
      "Wenming Tan",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.06224"
  },
  {
    "id": "arXiv:2105.06229",
    "title": "Reciprocal Feature Learning via Explicit and Implicit Tasks in Scene  Text Recognition",
    "abstract": "Comments: Accepted by ICDAR 2021. Code is available at this https URL or this https URL",
    "descriptor": "\nComments: Accepted by ICDAR 2021. Code is available at this https URL or this https URL\n",
    "authors": [
      "Hui Jiang",
      "Yunlu Xu",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Yi Niu",
      "Wenqi Ren",
      "Fei Wu",
      "Wenming Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.06229"
  },
  {
    "id": "arXiv:2105.06813",
    "title": "A cost-benefit analysis of cross-lingual transfer methods",
    "abstract": "A cost-benefit analysis of cross-lingual transfer methods",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Luiz Henrique Bonifacio",
      "Leandro Rodrigues de Souza",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06813"
  },
  {
    "id": "arXiv:2105.06844",
    "title": "Predicting speech intelligibility from EEG in a non-linear  classification paradigm",
    "abstract": "Comments: 12 pages, 12 figures",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Bernd Accou",
      "Mohammad Jalilpour Monesi",
      "Hugo Van hamme",
      "Tom Francart"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2105.06844"
  },
  {
    "id": "arXiv:2105.07447",
    "title": "Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and  Challenges",
    "abstract": "Comments: Tech Report on NFT",
    "descriptor": "\nComments: Tech Report on NFT\n",
    "authors": [
      "Qin Wang",
      "Rujia Li",
      "Qi Wang",
      "Shiping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07447"
  },
  {
    "id": "arXiv:2105.08052",
    "title": "The Boombox: Visual Reconstruction from Acoustic Vibrations",
    "abstract": "Comments: CoRL 2021. Website: boombox.cs.columbia.edu",
    "descriptor": "\nComments: CoRL 2021. Website: boombox.cs.columbia.edu\n",
    "authors": [
      "Boyuan Chen",
      "Mia Chiquier",
      "Hod Lipson",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.08052"
  },
  {
    "id": "arXiv:2105.09463",
    "title": "Stochastic Buffer-Aided Relay-Assisted MEC in Time-Slotted Systems",
    "abstract": "Stochastic Buffer-Aided Relay-Assisted MEC in Time-Slotted Systems",
    "descriptor": "",
    "authors": [
      "Javad Hajipour"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.09463"
  },
  {
    "id": "arXiv:2105.09605",
    "title": "Learning Robust Recommenders through Cross-Model Agreement",
    "abstract": "Comments: 12 pages, 21 figures",
    "descriptor": "\nComments: 12 pages, 21 figures\n",
    "authors": [
      "Yu Wang",
      "Xin Xin",
      "Zaiqiao Meng",
      "Xiangnan He",
      "Joemon Jose",
      "Fuli Feng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09605"
  },
  {
    "id": "arXiv:2105.11106",
    "title": "Frequency Permutations for Joint Radar and Communications",
    "abstract": "Comments: Submitted to IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Rajitha Senanayake",
      "Peter Smith",
      "Tian Han",
      "Jamie Evans",
      "William Moran",
      "Robin Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.11106"
  },
  {
    "id": "arXiv:2105.11313",
    "title": "Verification of Dissipativity and Evaluation of Storage Function in  Economic Nonlinear MPC using Q-Learning",
    "abstract": "Comments: This paper has been accepted to be presented NMPC2021. 6 pages",
    "descriptor": "\nComments: This paper has been accepted to be presented NMPC2021. 6 pages\n",
    "authors": [
      "Arash Bahari Kordabad",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.11313"
  },
  {
    "id": "arXiv:2105.14158",
    "title": "SSCAP: Self-supervised Co-occurrence Action Parsing for Unsupervised  Temporal Action Segmentation",
    "abstract": "Comments: WACV 2022 camera ready",
    "descriptor": "\nComments: WACV 2022 camera ready\n",
    "authors": [
      "Zhe Wang",
      "Hao Chen",
      "Xinyu Li",
      "Chunhui Liu",
      "Yuanjun Xiong",
      "Joseph Tighe",
      "Charless Fowlkes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14158"
  },
  {
    "id": "arXiv:2105.14217",
    "title": "Less is More: Pay Less Attention in Vision Transformers",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Zizheng Pan",
      "Bohan Zhuang",
      "Haoyu He",
      "Jing Liu",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14217"
  },
  {
    "id": "arXiv:2105.14490",
    "title": "Ladder-GNN: Hop-Aware Representation Learning for Graph Neural Networks",
    "abstract": "Ladder-GNN: Hop-Aware Representation Learning for Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Ailing Zeng",
      "Minhao Liu",
      "Zhiwei Liu",
      "Ruiyuan Gao",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14490"
  },
  {
    "id": "arXiv:2105.14799",
    "title": "Resultant-based Elimination in Ore Algebra",
    "abstract": "Resultant-based Elimination in Ore Algebra",
    "descriptor": "",
    "authors": [
      "Raqeeb Rasheed"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.14799"
  },
  {
    "id": "arXiv:2106.00600",
    "title": "Fair Clustering Using Antidote Data",
    "abstract": "Comments: Accepted at AFCR workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted at AFCR workshop, NeurIPS 2021\n",
    "authors": [
      "Anshuman Chhabra",
      "Adish Singla",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00600"
  },
  {
    "id": "arXiv:2106.00736",
    "title": "Large-Scale Wasserstein Gradient Flows",
    "abstract": "Large-Scale Wasserstein Gradient Flows",
    "descriptor": "",
    "authors": [
      "Petr Mokrov",
      "Alexander Korotin",
      "Lingxiao Li",
      "Aude Genevay",
      "Justin Solomon",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00736"
  },
  {
    "id": "arXiv:2106.00885",
    "title": "Robustifying Algorithms of Learning Latent Trees with Vector Variables",
    "abstract": "Robustifying Algorithms of Learning Latent Trees with Vector Variables",
    "descriptor": "",
    "authors": [
      "Fengzhuo Zhang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00885"
  },
  {
    "id": "arXiv:2106.01551",
    "title": "Matching-Theory-Based Multi-User Cooperative Computing Framework",
    "abstract": "Matching-Theory-Based Multi-User Cooperative Computing Framework",
    "descriptor": "",
    "authors": [
      "Ya Zhou",
      "Guopeng Zhang",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01551"
  },
  {
    "id": "arXiv:2106.01577",
    "title": "A Provably-Efficient Model-Free Algorithm for Constrained Markov  Decision Processes",
    "abstract": "A Provably-Efficient Model-Free Algorithm for Constrained Markov  Decision Processes",
    "descriptor": "",
    "authors": [
      "Honghao Wei",
      "Xin Liu",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01577"
  },
  {
    "id": "arXiv:2106.01954",
    "title": "Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2  Benchmark",
    "abstract": "Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2  Benchmark",
    "descriptor": "",
    "authors": [
      "Alexander Korotin",
      "Lingxiao Li",
      "Aude Genevay",
      "Justin Solomon",
      "Alexander Filippov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01954"
  },
  {
    "id": "arXiv:2106.02637",
    "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning",
    "abstract": "Comments: Accepted by NeurIPS 2021 (spotlight), code is availabel at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 (spotlight), code is availabel at this https URL\n",
    "authors": [
      "Fangyun Wei",
      "Yue Gao",
      "Zhirong Wu",
      "Han Hu",
      "Stephen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02637"
  },
  {
    "id": "arXiv:2106.02684",
    "title": "Learning Policies with Zero or Bounded Constraint Violation for  Constrained MDPs",
    "abstract": "Comments: Will appear in NeurIPS 2021",
    "descriptor": "\nComments: Will appear in NeurIPS 2021\n",
    "authors": [
      "Tao Liu",
      "Ruida Zhou",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02684"
  },
  {
    "id": "arXiv:2106.02847",
    "title": "Navigating to the Best Policy in Markov Decision Processes",
    "abstract": "Navigating to the Best Policy in Markov Decision Processes",
    "descriptor": "",
    "authors": [
      "Aymen Al Marjani",
      "Aur\u00e9lien Garivier",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02847"
  },
  {
    "id": "arXiv:2106.03188",
    "title": "Combinatorial Optimization for Panoptic Segmentation: A Fully  Differentiable Approach",
    "abstract": "Comments: To be presented at NeurIPS 2021",
    "descriptor": "\nComments: To be presented at NeurIPS 2021\n",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03188"
  },
  {
    "id": "arXiv:2106.03216",
    "title": "On Memorization in Probabilistic Deep Generative Models",
    "abstract": "Comments: Accepted for publication at NeurIPS 2021",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2021\n",
    "authors": [
      "Gerrit J. J. van den Burg",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03216"
  },
  {
    "id": "arXiv:2106.03765",
    "title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation",
    "abstract": "Comments: To Appear in the Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: To Appear in the Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03765"
  },
  {
    "id": "arXiv:2106.04144",
    "title": "Adversarial Semantic Hallucination for Domain Generalized Semantic  Segmentation",
    "abstract": "Comments: Accepted in WACV 2022",
    "descriptor": "\nComments: Accepted in WACV 2022\n",
    "authors": [
      "Gabriel Tjio",
      "Ping Liu",
      "Joey Tianyi Zhou",
      "Rick Siow Mong Goh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04144"
  },
  {
    "id": "arXiv:2106.04188",
    "title": "Stability and Generalization of Bilevel Programming in Hyperparameter  Optimization",
    "abstract": "Stability and Generalization of Bilevel Programming in Hyperparameter  Optimization",
    "descriptor": "",
    "authors": [
      "Fan Bao",
      "Guoqiang Wu",
      "Chongxuan Li",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.04188"
  },
  {
    "id": "arXiv:2106.04533",
    "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tianlong Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Lu Yuan",
      "Lei Zhang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04533"
  },
  {
    "id": "arXiv:2106.04927",
    "title": "A Bi-Level Framework for Learning to Solve Combinatorial Optimization on  Graphs",
    "abstract": "Comments: NeurIPS 2021. Code at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code at this https URL\n",
    "authors": [
      "Runzhong Wang",
      "Zhigang Hua",
      "Gan Liu",
      "Jiayi Zhang",
      "Junchi Yan",
      "Feng Qi",
      "Shuang Yang",
      "Jun Zhou",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.04927"
  },
  {
    "id": "arXiv:2106.05392",
    "title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers",
    "abstract": "Comments: NeurIPS 2021 (Oral). Project page: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 (Oral). Project page: this https URL\n",
    "authors": [
      "Mandela Patrick",
      "Dylan Campbell",
      "Yuki M. Asano",
      "Ishan Misra",
      "Florian Metze",
      "Christoph Feichtenhofer",
      "Andrea Vedaldi",
      "Jo\u00e3o F. Henriques"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05392"
  },
  {
    "id": "arXiv:2106.05455",
    "title": "Effective Graph Learning with Adaptive Knowledge Exchange",
    "abstract": "Effective Graph Learning with Adaptive Knowledge Exchange",
    "descriptor": "",
    "authors": [
      "Liang Zeng",
      "Jin Xu",
      "Zijun Yao",
      "Yanqiao Zhu",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05455"
  },
  {
    "id": "arXiv:2106.05656",
    "title": "MST: Masked Self-Supervised Transformer for Visual Representation",
    "abstract": "Comments: Accepted in NeurIPS 2021",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Zhaowen Li",
      "Zhiyang Chen",
      "Fan Yang",
      "Wei Li",
      "Yousong Zhu",
      "Chaoyang Zhao",
      "Rui Deng",
      "Liwei Wu",
      "Rui Zhao",
      "Ming Tang",
      "Jinqiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05656"
  },
  {
    "id": "arXiv:2106.05960",
    "title": "Compositional Modeling of Nonlinear Dynamical Systems with ODE-based  Random Features",
    "abstract": "Comments: 19 pages, 6 figures. Accepted to NeurIPS 2021",
    "descriptor": "\nComments: 19 pages, 6 figures. Accepted to NeurIPS 2021\n",
    "authors": [
      "Thomas M. McDonald",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05960"
  },
  {
    "id": "arXiv:2106.06573",
    "title": "Understanding Deflation Process in Over-parametrized Tensor  Decomposition",
    "abstract": "Comments: NeurIPS 2021 Camera Ready",
    "descriptor": "\nComments: NeurIPS 2021 Camera Ready\n",
    "authors": [
      "Rong Ge",
      "Yunwei Ren",
      "Xiang Wang",
      "Mo Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06573"
  },
  {
    "id": "arXiv:2106.07094",
    "title": "Privacy-Preserving Federated Learning via Normalized (instead of  Clipped) Updates",
    "abstract": "Privacy-Preserving Federated Learning via Normalized (instead of  Clipped) Updates",
    "descriptor": "",
    "authors": [
      "Rudrajit Das",
      "Abolfazl Hashemi",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07094"
  },
  {
    "id": "arXiv:2106.07098",
    "title": "Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on  Autonomous Vehicles",
    "abstract": "Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on  Autonomous Vehicles",
    "descriptor": "",
    "authors": [
      "R. Spencer Hallyburton",
      "Yupei Liu",
      "Yulong Cao",
      "Z. Morley Mao",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07098"
  },
  {
    "id": "arXiv:2106.07289",
    "title": "Decentralized Personalized Federated Min-Max Problems",
    "abstract": "Decentralized Personalized Federated Min-Max Problems",
    "descriptor": "",
    "authors": [
      "Ekaterina Borodich",
      "Aleksandr Beznosikov",
      "Abdurakhmon Sadiev",
      "Vadim Sushko",
      "Nikolay Savelyev",
      "Martin Tak\u00e1\u010d",
      "Alexander Gasnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07289"
  },
  {
    "id": "arXiv:2106.07411",
    "title": "Partial success in closing the gap between human and machine vision",
    "abstract": "Comments: NeurIPS 2021 Oral, camera ready version. A preliminary version of this work was presented as Oral at the 2020 NeurIPS workshop on \"Shared Visual Representations in Human & Machine Intelligence\" (arXiv:2010.08377)",
    "descriptor": "\nComments: NeurIPS 2021 Oral, camera ready version. A preliminary version of this work was presented as Oral at the 2020 NeurIPS workshop on \"Shared Visual Representations in Human & Machine Intelligence\" (arXiv:2010.08377)\n",
    "authors": [
      "Robert Geirhos",
      "Kantharaju Narayanappa",
      "Benjamin Mitzkus",
      "Tizian Thieringer",
      "Matthias Bethge",
      "Felix A. Wichmann",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.07411"
  },
  {
    "id": "arXiv:2106.07815",
    "title": "Locally Differentially Private Frequency Estimation",
    "abstract": "Locally Differentially Private Frequency Estimation",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Anthony Wirth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07815"
  },
  {
    "id": "arXiv:2106.08041",
    "title": "The BDF3/EP3 scheme for MBE with no slope selection is stable",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Dong Li",
      "Chaoyu Quan",
      "Wen Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.08041"
  },
  {
    "id": "arXiv:2106.08613",
    "title": "FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation",
    "abstract": "Comments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022",
    "descriptor": "\nComments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Chaewon Park",
      "MyeongAh Cho",
      "Minhyeok Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08613"
  },
  {
    "id": "arXiv:2106.08630",
    "title": "HELP: Hardware-Adaptive Efficient Latency Prediction for NAS via  Meta-Learning",
    "abstract": "Comments: NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Hayeon Lee",
      "Sewoong Lee",
      "Song Chong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08630"
  },
  {
    "id": "arXiv:2106.08903",
    "title": "GemNet: Universal Directional Graph Neural Networks for Molecules",
    "abstract": "Comments: Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Johannes Klicpera",
      "Florian Becker",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08903"
  },
  {
    "id": "arXiv:2106.08918",
    "title": "Towards Automatic Actor-Critic Solutions to Continuous Control",
    "abstract": "Comments: NeurIPS Deep RL Workshop 2021",
    "descriptor": "\nComments: NeurIPS Deep RL Workshop 2021\n",
    "authors": [
      "Jake Grigsby",
      "Jin Yong Yoo",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08918"
  },
  {
    "id": "arXiv:2106.09063",
    "title": "Specializing Multilingual Language Models: An Empirical Study",
    "abstract": "Comments: Camera-ready version for the Workshop on Multilingual Representation Learning (MRL) 2021",
    "descriptor": "\nComments: Camera-ready version for the Workshop on Multilingual Representation Learning (MRL) 2021\n",
    "authors": [
      "Ethan C. Chau",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09063"
  },
  {
    "id": "arXiv:2106.09563",
    "title": "On Anytime Learning at Macroscale",
    "abstract": "On Anytime Learning at Macroscale",
    "descriptor": "",
    "authors": [
      "Lucas Caccia",
      "Jing Xu",
      "Myle Ott",
      "Marc'Aurelio Ranzato",
      "Ludovic Denoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09563"
  },
  {
    "id": "arXiv:2106.10338",
    "title": "Intersectional synergies: untangling irreducible effects of intersecting  identities via information decomposition",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Thomas F. Varley",
      "Patrick Kaminski"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.10338"
  },
  {
    "id": "arXiv:2106.10404",
    "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration",
    "abstract": "Comments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL",
    "descriptor": "\nComments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Xiaohan Chen",
      "Zahra Atashgahi",
      "Lu Yin",
      "Huanyu Kou",
      "Li Shen",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10404"
  },
  {
    "id": "arXiv:2106.10517",
    "title": "A Max-Min Entropy Framework for Reinforcement Learning",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Seungyul Han",
      "Youngchul Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10517"
  },
  {
    "id": "arXiv:2106.10543",
    "title": "Signal Processing Based Deep Learning for Blind Symbol Decoding and  Modulation Classification",
    "abstract": "Signal Processing Based Deep Learning for Blind Symbol Decoding and  Modulation Classification",
    "descriptor": "",
    "authors": [
      "Samer Hanna",
      "Chris Dick",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10543"
  },
  {
    "id": "arXiv:2106.10544",
    "title": "Learning Space Partitions for Path Planning",
    "abstract": "Learning Space Partitions for Path Planning",
    "descriptor": "",
    "authors": [
      "Kevin Yang",
      "Tianjun Zhang",
      "Chris Cummins",
      "Brandon Cui",
      "Benoit Steiner",
      "Linnan Wang",
      "Joseph E. Gonzalez",
      "Dan Klein",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10544"
  },
  {
    "id": "arXiv:2106.10773",
    "title": "Neural Spectral Marked Point Processes",
    "abstract": "Neural Spectral Marked Point Processes",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Haoyun Wang",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10773"
  },
  {
    "id": "arXiv:2106.11037",
    "title": "One Million Scenes for Autonomous Driving: ONCE Dataset",
    "abstract": "Comments: NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Jiageng Mao",
      "Minzhe Niu",
      "Chenhan Jiang",
      "Hanxue Liang",
      "Jingheng Chen",
      "Xiaodan Liang",
      "Yamin Li",
      "Chaoqiang Ye",
      "Wei Zhang",
      "Zhenguo Li",
      "Jie Yu",
      "Hang Xu",
      "Chunjing Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11037"
  },
  {
    "id": "arXiv:2106.12253",
    "title": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part I: Modelling Framework and Algorithm",
    "abstract": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part I: Modelling Framework and Algorithm",
    "descriptor": "",
    "authors": [
      "Andreas Martin Kettner",
      "Lorenzo Reyes-Chamorro",
      "Johanna Kristin Maria Becker",
      "Zhixiang Zou",
      "Marco Liserre",
      "Mario Paolone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12253"
  },
  {
    "id": "arXiv:2106.12255",
    "title": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part II: Model Library and Validation",
    "abstract": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part II: Model Library and Validation",
    "descriptor": "",
    "authors": [
      "Johanna Kristin Maria Becker",
      "Andreas Martin Kettner",
      "Lorenzo Reyes-Chamorro",
      "Zhixiang Zou",
      "Marco Liserre",
      "Mario Paolone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12255"
  },
  {
    "id": "arXiv:2106.13423",
    "title": "Federated Graph Classification over Non-IID Graphs",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Han Xie",
      "Jing Ma",
      "Li Xiong",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13423"
  },
  {
    "id": "arXiv:2106.14229",
    "title": "Over-the-Air Federated Multi-Task Learning",
    "abstract": "Over-the-Air Federated Multi-Task Learning",
    "descriptor": "",
    "authors": [
      "Haoming Ma",
      "Xiaojun Yuan",
      "Dian Fan",
      "Zhi Ding",
      "Xin Wang",
      "Jun Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.14229"
  },
  {
    "id": "arXiv:2106.14702",
    "title": "Scalable Optimal Classifiers for Adversarial Settings under Uncertainty",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Patrick Loiseau",
      "Benjamin Roussillon"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14702"
  },
  {
    "id": "arXiv:2106.14979",
    "title": "On component interactions in two-stage recommender systems",
    "abstract": "Comments: Appears in the proceedings of the NeurIPS 2021 conference",
    "descriptor": "\nComments: Appears in the proceedings of the NeurIPS 2021 conference\n",
    "authors": [
      "Jiri Hron",
      "Karl Krauth",
      "Michael I. Jordan",
      "Niki Kilbertus"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14979"
  },
  {
    "id": "arXiv:2106.15416",
    "title": "High-dimensional separability for one- and few-shot learning",
    "abstract": "Comments: Corrected and restructured version with some extensions",
    "descriptor": "\nComments: Corrected and restructured version with some extensions\n",
    "authors": [
      "Alexander N. Gorban",
      "Bogdan Grechuk",
      "Evgeny M. Mirkes",
      "Sergey V. Stasenko",
      "Ivan Y. Tyukin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15416"
  },
  {
    "id": "arXiv:2106.15610",
    "title": "An Image is Worth More Than a Thousand Words: Towards Disentanglement in  the Wild",
    "abstract": "Comments: NeurIPS 2021. Project page: this http URL",
    "descriptor": "\nComments: NeurIPS 2021. Project page: this http URL\n",
    "authors": [
      "Aviv Gabbay",
      "Niv Cohen",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15610"
  },
  {
    "id": "arXiv:2106.15728",
    "title": "Detecting Errors and Estimating Accuracy on Unlabeled Data with  Self-training Ensembles",
    "abstract": "Comments: Paper published at NeurIPS 2021",
    "descriptor": "\nComments: Paper published at NeurIPS 2021\n",
    "authors": [
      "Jiefeng Chen",
      "Frederick Liu",
      "Besim Avci",
      "Xi Wu",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15728"
  },
  {
    "id": "arXiv:2106.15911",
    "title": "A parallel fast multipole method for a space-time boundary element  method for the heat equation",
    "abstract": "A parallel fast multipole method for a space-time boundary element  method for the heat equation",
    "descriptor": "",
    "authors": [
      "Raphael Watschinger",
      "Michal Merta",
      "G\u00fcnther Of",
      "Jan Zapletal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.15911"
  },
  {
    "id": "arXiv:2106.15963",
    "title": "How does homophily shape the topology of a dynamic network?",
    "abstract": "Comments: The paper includes 12 pages and 9 figures",
    "descriptor": "\nComments: The paper includes 12 pages and 9 figures\n",
    "authors": [
      "Xiang Li",
      "Mauro Mobilia",
      "Alastair M. Rucklidge",
      "R.K.P. Zia"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15963"
  },
  {
    "id": "arXiv:2106.16100",
    "title": "Synthetic Data Are as Good as the Real for Association Knowledge  Learning in Multi-object Tracking",
    "abstract": "Synthetic Data Are as Good as the Real for Association Knowledge  Learning in Multi-object Tracking",
    "descriptor": "",
    "authors": [
      "Yuchi Liu",
      "Zhongdao Wang",
      "Xiangxin Zhou",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16100"
  },
  {
    "id": "arXiv:2106.16147",
    "title": "Nearly-Tight and Oblivious Algorithms for Explainable Clustering",
    "abstract": "Nearly-Tight and Oblivious Algorithms for Explainable Clustering",
    "descriptor": "",
    "authors": [
      "Buddhima Gamlath",
      "Xinrui Jia",
      "Adam Polak",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16147"
  },
  {
    "id": "arXiv:2107.00166",
    "title": "Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win  the Jackpot?",
    "abstract": "Comments: NeurIPS 2021 camera ready",
    "descriptor": "\nComments: NeurIPS 2021 camera ready\n",
    "authors": [
      "Xiaolong Ma",
      "Geng Yuan",
      "Xuan Shen",
      "Tianlong Chen",
      "Xuxi Chen",
      "Xiaohan Chen",
      "Ning Liu",
      "Minghai Qin",
      "Sijia Liu",
      "Zhangyang Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00166"
  },
  {
    "id": "arXiv:2107.00488",
    "title": "Differentiable Particle Filters through Conditional Normalizing Flow",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Xiongjie Chen",
      "Hao Wen",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00488"
  },
  {
    "id": "arXiv:2107.00934",
    "title": "Hybrid Supervision Learning for Pathology Whole Slide Image  Classification",
    "abstract": "Comments: Accepted in MICCAI2021",
    "descriptor": "\nComments: Accepted in MICCAI2021\n",
    "authors": [
      "Jiahui Li",
      "Wen Chen",
      "Xiaodi Huang",
      "Zhiqiang Hu",
      "Qi Duan",
      "Hongsheng Li",
      "Dimitris N. Metaxas",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00934"
  },
  {
    "id": "arXiv:2107.01076",
    "title": "DUKweb: Diachronic word representations from the UK Web Archive corpus",
    "abstract": "Comments: 24 pages, 6 figures The arXiv submission was replaced to include the following comment. This version of the article has been accepted for publication, after peer review (when applicable) but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this http URL",
    "descriptor": "\nComments: 24 pages, 6 figures The arXiv submission was replaced to include the following comment. This version of the article has been accepted for publication, after peer review (when applicable) but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this http URL\n",
    "authors": [
      "Adam Tsakalidis",
      "Pierpaolo Basile",
      "Marya Bazzi",
      "Mihai Cucuringu",
      "Barbara McGillivray"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01076"
  },
  {
    "id": "arXiv:2107.01194",
    "title": "Inter-intra Variant Dual Representations forSelf-supervised Video  Recognition",
    "abstract": "Comments: Accepted by BMVC 2021",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Lin Zhang",
      "Qi She",
      "Zhengyang Shen",
      "Changhu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01194"
  },
  {
    "id": "arXiv:2107.01372",
    "title": "Learning Debiased Representation via Disentangled Feature Augmentation",
    "abstract": "Comments: Accepted to NeurIPS 2021 as Oral Presentation",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 as Oral Presentation\n",
    "authors": [
      "Jungsoo Lee",
      "Eungyeup Kim",
      "Juyoung Lee",
      "Jihyeon Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01372"
  },
  {
    "id": "arXiv:2107.01442",
    "title": "Approximate Core Allocations for Multiple Partners Matching Games",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Han Xiao",
      "Tianhang Lu",
      "Qizhi Fang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.01442"
  },
  {
    "id": "arXiv:2107.01454",
    "title": "Stochastic Algorithms for Self-consistent Calculations of Electronic  Structures",
    "abstract": "Stochastic Algorithms for Self-consistent Calculations of Electronic  Structures",
    "descriptor": "",
    "authors": [
      "Taehee Ko",
      "Xiantao Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01454"
  },
  {
    "id": "arXiv:2107.01715",
    "title": "Improve Agents without Retraining: Parallel Tree Search with Off-Policy  Correction",
    "abstract": "Improve Agents without Retraining: Parallel Tree Search with Off-Policy  Correction",
    "descriptor": "",
    "authors": [
      "Assaf Hallak",
      "Gal Dalal",
      "Steven Dalton",
      "Iuri Frosio",
      "Shie Mannor",
      "Gal Chechik"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01715"
  },
  {
    "id": "arXiv:2107.01726",
    "title": "Protected probabilistic classification",
    "abstract": "Comments: 23 pages, 14 figures, and 4 tables",
    "descriptor": "\nComments: 23 pages, 14 figures, and 4 tables\n",
    "authors": [
      "Vladimir Vovk",
      "Ivan Petej",
      "Alex Gammerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01726"
  },
  {
    "id": "arXiv:2107.02275",
    "title": "Physics Based GNNs for Locating Faults in Power Grids",
    "abstract": "Comments: 3 pages, 1 figure",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Wenting Li",
      "Deepjyoti Deka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.02275"
  },
  {
    "id": "arXiv:2107.03054",
    "title": "EchoEA: Echo Information between Entities and Relations for Entity  Alignment",
    "abstract": "EchoEA: Echo Information between Entities and Relations for Entity  Alignment",
    "descriptor": "",
    "authors": [
      "Xueyuan Lin",
      "Haihong E",
      "Wenyu Song",
      "Haoran Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03054"
  },
  {
    "id": "arXiv:2107.03554",
    "title": "Automated Object Behavioral Feature Extraction for Potential Risk  Analysis based on Video Sensor",
    "abstract": "Comments: 6 pages, 9 figures",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Byeongjoon Noh",
      "Wonjun Noh",
      "David Lee",
      "Hwasoo Yeo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.03554"
  },
  {
    "id": "arXiv:2107.04470",
    "title": "ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with  Iterative Self-Training",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Emadeldeen Eldele",
      "Mohamed Ragab",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04470"
  },
  {
    "id": "arXiv:2107.05326",
    "title": "Learning interaction rules from multi-animal trajectories via augmented  behavioral models",
    "abstract": "Comments: 24 pages, 5 figures, to appear in NeurIPS 2021",
    "descriptor": "\nComments: 24 pages, 5 figures, to appear in NeurIPS 2021\n",
    "authors": [
      "Keisuke Fujii",
      "Naoya Takeishi",
      "Kazushi Tsutsui",
      "Emyo Fujioka",
      "Nozomi Nishiumi",
      "Ryoya Tanaka",
      "Mika Fukushiro",
      "Kaoru Ide",
      "Hiroyoshi Kohno",
      "Ken Yoda",
      "Susumu Takahashi",
      "Shizuko Hiryu",
      "Yoshinobu Kawahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05326"
  },
  {
    "id": "arXiv:2107.06307",
    "title": "HDMapNet: A Local Semantic Map Learning and Evaluation Framework",
    "abstract": "HDMapNet: A Local Semantic Map Learning and Evaluation Framework",
    "descriptor": "",
    "authors": [
      "Qi Li",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06307"
  },
  {
    "id": "arXiv:2107.06943",
    "title": "FetalNet: Multi-task deep learning framework for fetal ultrasound  biometric measurements",
    "abstract": "Comments: Accepted to 28th International Conference on Neural Information Processing (ICONIP) 2021, Bali, Indonesia, 8-12 December, 2021",
    "descriptor": "\nComments: Accepted to 28th International Conference on Neural Information Processing (ICONIP) 2021, Bali, Indonesia, 8-12 December, 2021\n",
    "authors": [
      "Szymon P\u0142otka",
      "Tomasz W\u0142odarczyk",
      "Adam Klasa",
      "Micha\u0142 Lipa",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06943"
  },
  {
    "id": "arXiv:2107.07254",
    "title": "Variable-Horizon Guidance for Autonomous Rendezvous and Docking to a  Tumbling Target",
    "abstract": "Comments: A video of the rendezvous and docking maneuver can be found at this https URL",
    "descriptor": "\nComments: A video of the rendezvous and docking maneuver can be found at this https URL\n",
    "authors": [
      "Mirko Leomanni",
      "Renato Quartullo",
      "Gianni Bianchini",
      "Andrea Garulli",
      "Antonio Giannitrapani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07254"
  },
  {
    "id": "arXiv:2107.08369",
    "title": "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised  Learning",
    "abstract": "Comments: Equal authorship. Accepted to the Tackling Climate Change with Machine Learning workshop at NeurIPS 2021. Code and models are available at this https URL",
    "descriptor": "\nComments: Equal authorship. Accepted to the Tackling Climate Change with Machine Learning workshop at NeurIPS 2021. Code and models are available at this https URL\n",
    "authors": [
      "Sayak Paul",
      "Siddha Ganju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08369"
  },
  {
    "id": "arXiv:2107.08470",
    "title": "ANFIC: Image Compression Using Augmented Normalizing Flows",
    "abstract": "ANFIC: Image Compression Using Augmented Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Yung-Han Ho",
      "Chih-Chun Chan",
      "Wen-Hsiao Peng",
      "Hsueh-Ming Hang",
      "Marek Domanski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08470"
  },
  {
    "id": "arXiv:2107.08651",
    "title": "Delay-Compensated Distributed PDE Control of Traffic with  Connected/Automated Vehicles",
    "abstract": "Delay-Compensated Distributed PDE Control of Traffic with  Connected/Automated Vehicles",
    "descriptor": "",
    "authors": [
      "Jie Qi",
      "Shurong Mo",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.08651"
  },
  {
    "id": "arXiv:2107.10801",
    "title": "Specifying a Game-Theoretic Extensive Form as an Abstract 5-ary Relation",
    "abstract": "Comments: 39 pages, 5 figures. Version 2 provides more exposition including new Sections 2 and 5. Also increases line spacing. Also streamlines Proposition 3.3 (old 2.3) and Corollary 3.4 (old 2.4) in recognition that old [Q4c] implied old [Q4a]",
    "descriptor": "\nComments: 39 pages, 5 figures. Version 2 provides more exposition including new Sections 2 and 5. Also increases line spacing. Also streamlines Proposition 3.3 (old 2.3) and Corollary 3.4 (old 2.4) in recognition that old [Q4c] implied old [Q4a]\n",
    "authors": [
      "Peter A. Streufert"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.10801"
  },
  {
    "id": "arXiv:2107.11007",
    "title": "Dynamic Proximal Unrolling Network for Compressive Imaging",
    "abstract": "Dynamic Proximal Unrolling Network for Compressive Imaging",
    "descriptor": "",
    "authors": [
      "Yixiao Yang",
      "Ran Tao",
      "Kaixuan Wei",
      "Ying Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11007"
  },
  {
    "id": "arXiv:2107.13163",
    "title": "Statistically Meaningful Approximation: a Case Study on Approximating  Turing Machines with Transformers",
    "abstract": "Statistically Meaningful Approximation: a Case Study on Approximating  Turing Machines with Transformers",
    "descriptor": "",
    "authors": [
      "Colin Wei",
      "Yining Chen",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.13163"
  },
  {
    "id": "arXiv:2107.13757",
    "title": "Bridging Gap between Image Pixels and Semantics via Supervision: A  Survey",
    "abstract": "Comments: APSIPA Transactions 2021",
    "descriptor": "\nComments: APSIPA Transactions 2021\n",
    "authors": [
      "Jiali Duan",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13757"
  },
  {
    "id": "arXiv:2107.14569",
    "title": "Can You Hear It? Backdoor Attacks via Ultrasonic Triggers",
    "abstract": "Can You Hear It? Backdoor Attacks via Ultrasonic Triggers",
    "descriptor": "",
    "authors": [
      "Stefanos Koffas",
      "Jing Xu",
      "Mauro Conti",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.14569"
  },
  {
    "id": "arXiv:2108.00808",
    "title": "Energy Efficiency Aspects of the AMD Zen 2 Architecture",
    "abstract": "Comments: supported in part by the German Research Foundation (DFG) within the CRC 912 - HAEC",
    "descriptor": "\nComments: supported in part by the German Research Foundation (DFG) within the CRC 912 - HAEC\n",
    "authors": [
      "Robert Sch\u00f6ne",
      "Thomas Ilsche",
      "Mario Bielert",
      "Markus Velten",
      "Markus Schmidl",
      "Daniel Hackenberg"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2108.00808"
  },
  {
    "id": "arXiv:2108.01470",
    "title": "FIRESTARTER 2: Dynamic Code Generation for Processor Stress Tests",
    "abstract": "Comments: supported in part by the German Research Foundation (DFG) within the CRC 912 - HAEC",
    "descriptor": "\nComments: supported in part by the German Research Foundation (DFG) within the CRC 912 - HAEC\n",
    "authors": [
      "Robert Sch\u00f6ne",
      "Markus Schmidl",
      "Mario Bielert",
      "Daniel Hackenberg"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2108.01470"
  },
  {
    "id": "arXiv:2108.02666",
    "title": "A graphical method of cumulative differences between two subpopulations",
    "abstract": "Comments: 26 pages, 15 figures, 2 tables. arXiv admin note: text overlap with arXiv:2008.01779",
    "descriptor": "\nComments: 26 pages, 15 figures, 2 tables. arXiv admin note: text overlap with arXiv:2008.01779\n",
    "authors": [
      "Mark Tygert"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.02666"
  },
  {
    "id": "arXiv:2108.03021",
    "title": "Road Scenes Segmentation Across Different Domains by Disentangling  Latent Representations",
    "abstract": "Comments: 10 pages, 3 supplementary pages, 10 figures, 3 supplementary figures, 2 tables, 1 supplementary table",
    "descriptor": "\nComments: 10 pages, 3 supplementary pages, 10 figures, 3 supplementary figures, 2 tables, 1 supplementary table\n",
    "authors": [
      "Francesco Barbato",
      "Umberto Michieli",
      "Marco Toldo",
      "Pietro Zanuttigh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03021"
  },
  {
    "id": "arXiv:2108.03995",
    "title": "Predicting Mechanically Driven Full-Field Quantities of Interest with  Deep Learning-Based Metamodels",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "S. Mohammadzadeh",
      "E. Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2108.03995"
  },
  {
    "id": "arXiv:2108.04741",
    "title": "Multi-Factors Aware Dual-Attentional Knowledge Tracing",
    "abstract": "Comments: Accepted by CIKM 2021, 10 pages, 10 figures, 6 tables",
    "descriptor": "\nComments: Accepted by CIKM 2021, 10 pages, 10 figures, 6 tables\n",
    "authors": [
      "Moyu Zhang",
      "Xinning Zhu",
      "Chunhong Zhang",
      "Yang Ji",
      "Feng Pan",
      "Changchuan Yin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04741"
  },
  {
    "id": "arXiv:2108.04879",
    "title": "Excited state, non-adiabatic dynamics of large photoswitchable molecules  using a chemically transferable machine learning potential",
    "abstract": "Excited state, non-adiabatic dynamics of large photoswitchable molecules  using a chemically transferable machine learning potential",
    "descriptor": "",
    "authors": [
      "Simon Axelrod",
      "Eugene Shakhnovich",
      "Rafael G\u00f3mez-Bombarelli"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04879"
  },
  {
    "id": "arXiv:2108.05875",
    "title": "Distributional Depth-Based Estimation of Object Articulation Models",
    "abstract": "Comments: In the proceedings of the 5th Annual Conference on Robot Learning (CoRL), 2021. Project webpage: this https URL . 18 pages, 10 figures, 4 tables",
    "descriptor": "\nComments: In the proceedings of the 5th Annual Conference on Robot Learning (CoRL), 2021. Project webpage: this https URL . 18 pages, 10 figures, 4 tables\n",
    "authors": [
      "Ajinkya Jain",
      "Stephen Giguere",
      "Rudolf Lioutikov",
      "Scott Niekum"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.05875"
  },
  {
    "id": "arXiv:2108.05946",
    "title": "The Development of Central Bank Digital Currency in China: An Analysis",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Geoffrey Goodell",
      "Hazem Danny Al Nakib"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.05946"
  },
  {
    "id": "arXiv:2108.06098",
    "title": "FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated  Learning",
    "abstract": "FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated  Learning",
    "descriptor": "",
    "authors": [
      "Nam Hyeon-Woo",
      "Moon Ye-Bin",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06098"
  },
  {
    "id": "arXiv:2108.06314",
    "title": "A Dataset for Answering Time-Sensitive Questions",
    "abstract": "Comments: Accepted to NeurIPS21 (dataset track), it contains 10 pages of main text and appendix",
    "descriptor": "\nComments: Accepted to NeurIPS21 (dataset track), it contains 10 pages of main text and appendix\n",
    "authors": [
      "Wenhu Chen",
      "Xinyi Wang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.06314"
  },
  {
    "id": "arXiv:2108.06641",
    "title": "The Information Ecosystem of Online Groups with Anti- and Pro-vaccine  Views on Facebook",
    "abstract": "The Information Ecosystem of Online Groups with Anti- and Pro-vaccine  Views on Facebook",
    "descriptor": "",
    "authors": [
      "Soojong Kim",
      "Kwanho Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.06641"
  },
  {
    "id": "arXiv:2108.08478",
    "title": "Learning Anchored Unsigned Distance Functions with Gradient Direction  Alignment for Single-view Garment Reconstruction",
    "abstract": "Comments: ICCV 2021 (Oral). Code is available at this https URL",
    "descriptor": "\nComments: ICCV 2021 (Oral). Code is available at this https URL\n",
    "authors": [
      "Fang Zhao",
      "Wenhao Wang",
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08478"
  },
  {
    "id": "arXiv:2108.09558",
    "title": "A Synthesis-Based Approach for Thermal-to-Visible Face Verification",
    "abstract": "Comments: This work has been accepted to the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2021",
    "descriptor": "\nComments: This work has been accepted to the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2021\n",
    "authors": [
      "Neehar Peri",
      "Joshua Gleason",
      "Carlos D. Castillo",
      "Thirimachos Bourlai",
      "Vishal M. Patel",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09558"
  },
  {
    "id": "arXiv:2108.11172",
    "title": "Superpixel-guided Discriminative Low-rank Representation of  Hyperspectral Images for Classification",
    "abstract": "Superpixel-guided Discriminative Low-rank Representation of  Hyperspectral Images for Classification",
    "descriptor": "",
    "authors": [
      "Shujun Yang",
      "Junhui Hou",
      "Yuheng Jia",
      "Shaohui Mei",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.11172"
  },
  {
    "id": "arXiv:2108.11449",
    "title": "A Riemannian Framework for Analysis of Human Body Surface",
    "abstract": "Comments: IEEE Workshop on Applications of Computer Vision (WACV) 2022, accepted",
    "descriptor": "\nComments: IEEE Workshop on Applications of Computer Vision (WACV) 2022, accepted\n",
    "authors": [
      "Emery Pierson",
      "Mohamed Daoudi",
      "Alice-Barbara Tumpach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11449"
  },
  {
    "id": "arXiv:2108.11694",
    "title": "PoissonSeg: Semi-Supervised Few-Shot Medical Image Segmentation via  Poisson Learning",
    "abstract": "Comments: Accepted by 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2021)",
    "descriptor": "\nComments: Accepted by 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2021)\n",
    "authors": [
      "Xiaoang Shen",
      "Guokai Zhang",
      "Huilin Lai",
      "Jihao Luo",
      "Jianwei Lu",
      "Ye Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11694"
  },
  {
    "id": "arXiv:2108.11695",
    "title": "PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal  Vessel Segmentation",
    "abstract": "Comments: IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM 2021 Short Oral)",
    "descriptor": "\nComments: IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM 2021 Short Oral)\n",
    "authors": [
      "Zhuojie Wu",
      "Muyi Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11695"
  },
  {
    "id": "arXiv:2108.11833",
    "title": "Gene Transformer: Transformers for the Gene Expression-based  Classification of Lung Cancer Subtypes",
    "abstract": "Comments: For any comments or suggestions, please contact: anwerkhan@gm.gist.ac.kr",
    "descriptor": "\nComments: For any comments or suggestions, please contact: anwerkhan@gm.gist.ac.kr\n",
    "authors": [
      "Anwar Khan",
      "Boreom Lee"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2108.11833"
  },
  {
    "id": "arXiv:2108.11887",
    "title": "Federated Reinforcement Learning: Techniques, Applications, and Open  Challenges",
    "abstract": "Federated Reinforcement Learning: Techniques, Applications, and Open  Challenges",
    "descriptor": "",
    "authors": [
      "Jiaju Qi",
      "Qihao Zhou",
      "Lei Lei",
      "Kan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.11887"
  },
  {
    "id": "arXiv:2108.12673",
    "title": "Tracing app technology: An ethical review in the COVID-19 era and  directions for post-COVID-19",
    "abstract": "Tracing app technology: An ethical review in the COVID-19 era and  directions for post-COVID-19",
    "descriptor": "",
    "authors": [
      "Saleh Afroogh",
      "Amir Esmalian",
      "Ali Mostafavi",
      "Ali Akbari",
      "Kambiz Rasoulkhani",
      "Shahriar Esmaeili",
      "Ehsan Hajiramezanali"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.12673"
  },
  {
    "id": "arXiv:2108.13897",
    "title": "mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset",
    "abstract": "mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset",
    "descriptor": "",
    "authors": [
      "Luiz Henrique Bonifacio",
      "Israel Campiotti",
      "Vitor Jeronymo",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13897"
  },
  {
    "id": "arXiv:2109.00075",
    "title": "Induced universal graphs for families of small graphs",
    "abstract": "Comments: 22 pages, 13 figures, 4 tables. This version had additional results and more detailed explanations than the previous version",
    "descriptor": "\nComments: 22 pages, 13 figures, 4 tables. This version had additional results and more detailed explanations than the previous version\n",
    "authors": [
      "James Trimble"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.00075"
  },
  {
    "id": "arXiv:2109.01745",
    "title": "A realistic approach to generate masked faces applied on two novel  masked face recognition data sets",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Tudor Mare",
      "Georgian Duta",
      "Mariana-Iuliana Georgescu",
      "Adrian Sandru",
      "Bogdan Alexe",
      "Marius Popescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01745"
  },
  {
    "id": "arXiv:2109.01902",
    "title": "Barycenteric distribution alignment and manifold-restricted  invertibility for domain generalization",
    "abstract": "Comments: Error on experiment for Office-Home dataset has been corrected and new results have been updated in Table 2. One more dataset is added for evaluation and the results have been reported in the supplementary",
    "descriptor": "\nComments: Error on experiment for Office-Home dataset has been corrected and new results have been updated in Table 2. One more dataset is added for evaluation and the results have been reported in the supplementary\n",
    "authors": [
      "Boyang Lyu",
      "Thuan Nguyen",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01902"
  },
  {
    "id": "arXiv:2109.01942",
    "title": "On the ability of monolingual models to learn language-agnostic  representations",
    "abstract": "On the ability of monolingual models to learn language-agnostic  representations",
    "descriptor": "",
    "authors": [
      "Leandro Rodrigues de Souza",
      "Rodrigo Nogueira",
      "Roberto Lotufo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01942"
  },
  {
    "id": "arXiv:2109.02431",
    "title": "Exposing Length Divergence Bias of Textual Matching Models",
    "abstract": "Comments: to correct some errors",
    "descriptor": "\nComments: to correct some errors\n",
    "authors": [
      "Lan Jiang",
      "Tianshu Lyu",
      "Chong Meng",
      "Xiaoyong Lyu",
      "Dawei Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02431"
  },
  {
    "id": "arXiv:2109.02485",
    "title": "Severity and Mortality Prediction Models to Triage Indian COVID-19  Patients",
    "abstract": "Comments: 31 pages, 6 figures, 8 tables. The first two authors (SB and YM) have equal contribution. IG is the corresponding author (ishaan@iitd.ac.in) Changes: Author List updated",
    "descriptor": "\nComments: 31 pages, 6 figures, 8 tables. The first two authors (SB and YM) have equal contribution. IG is the corresponding author (ishaan@iitd.ac.in) Changes: Author List updated\n",
    "authors": [
      "Samarth Bhatia",
      "Yukti Makhija",
      "Sneha Jayaswal",
      "Shalendra Singh",
      "Ishaan Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2109.02485"
  },
  {
    "id": "arXiv:2109.02639",
    "title": "On the Out-of-distribution Generalization of Probabilistic Image  Modelling",
    "abstract": "On the Out-of-distribution Generalization of Probabilistic Image  Modelling",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Andi Zhang",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.02639"
  },
  {
    "id": "arXiv:2109.03769",
    "title": "Training Algorithm Matters for the Performance of Neural Network  Potential",
    "abstract": "Training Algorithm Matters for the Performance of Neural Network  Potential",
    "descriptor": "",
    "authors": [
      "Yunqi Shao",
      "Florian M. Dietrich",
      "Carl Nettelblad",
      "Chao Zhang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.03769"
  },
  {
    "id": "arXiv:2109.04173",
    "title": "Relating Graph Neural Networks to Structural Causal Models",
    "abstract": "Comments: Main paper: 12 pages, References: 2 pages, Appendix: 13 pages; Main paper: 4 figures, Appendix: 2 figures",
    "descriptor": "\nComments: Main paper: 12 pages, References: 2 pages, Appendix: 13 pages; Main paper: 4 figures, Appendix: 2 figures\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Petar Veli\u010dkovi\u0107",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04173"
  },
  {
    "id": "arXiv:2109.04513",
    "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling  Approach",
    "abstract": "Comments: Accepted to EMNLP 2021 (Main Conference)",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (Main Conference)\n",
    "authors": [
      "Koren Lazar",
      "Benny Saret",
      "Asaf Yehudai",
      "Wayne Horowitz",
      "Nathan Wasserman",
      "Gabriel Stanovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04513"
  },
  {
    "id": "arXiv:2109.05391",
    "title": "Gradients and Subgradients of Buffered Failure Probability",
    "abstract": "Gradients and Subgradients of Buffered Failure Probability",
    "descriptor": "",
    "authors": [
      "Johannes O. Royset",
      "Ji-Eun Byun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05391"
  },
  {
    "id": "arXiv:2109.05473",
    "title": "Exploring Task Difficulty for Few-Shot Relation Extraction",
    "abstract": "Exploring Task Difficulty for Few-Shot Relation Extraction",
    "descriptor": "",
    "authors": [
      "Jiale Han",
      "Bo Cheng",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05473"
  },
  {
    "id": "arXiv:2109.06123",
    "title": "Knowledge Graph-based Neurodegenerative Diseases and Diet Relationship  Discovery",
    "abstract": "Comments: Accepted by CIBB 2021 (The 17th International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics)",
    "descriptor": "\nComments: Accepted by CIBB 2021 (The 17th International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics)\n",
    "authors": [
      "Yi Nian",
      "Jingcheng Du",
      "Larry Bu",
      "Fang Li",
      "Xinyue Hu",
      "Yuji Zhang",
      "Cui Tao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.06123"
  },
  {
    "id": "arXiv:2109.08270",
    "title": "Language Models as a Knowledge Source for Cognitive Agents",
    "abstract": "Comments: 16 pages, 2 figures; accepted for 2021 Advances in Cognitive Systems Conference (revised based on reviews)",
    "descriptor": "\nComments: 16 pages, 2 figures; accepted for 2021 Advances in Cognitive Systems Conference (revised based on reviews)\n",
    "authors": [
      "Robert E. Wray, III",
      "James R. Kirk",
      "John E. Laird"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08270"
  },
  {
    "id": "arXiv:2109.09129",
    "title": "Identifying Autism Spectrum Disorder Based on Individual-Aware  Down-Sampling and Multi-Modal Learning",
    "abstract": "Comments: for code and support documents, see this https URL",
    "descriptor": "\nComments: for code and support documents, see this https URL\n",
    "authors": [
      "Li Pan",
      "Jundong Liu",
      "Mingqin Shi",
      "Chi Wah Wong",
      "Kei Hang Katie Chan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09129"
  },
  {
    "id": "arXiv:2109.09506",
    "title": "Decoupling Long- and Short-Term Patterns in Spatiotemporal Inference",
    "abstract": "Decoupling Long- and Short-Term Patterns in Spatiotemporal Inference",
    "descriptor": "",
    "authors": [
      "Junfeng Hu",
      "Yuxuan Liang",
      "Zhencheng Fan",
      "Yifang Yin",
      "Ying Zhang",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09506"
  },
  {
    "id": "arXiv:2109.09818",
    "title": "Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context  of Melanoma Classification",
    "abstract": "Comments: 8 pages main, 7 pages supplementary",
    "descriptor": "\nComments: 8 pages main, 7 pages supplementary\n",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09818"
  },
  {
    "id": "arXiv:2109.10964",
    "title": "Multi-Objective Bayesian Optimization over High-Dimensional Search  Spaces",
    "abstract": "Multi-Objective Bayesian Optimization over High-Dimensional Search  Spaces",
    "descriptor": "",
    "authors": [
      "Samuel Daulton",
      "David Eriksson",
      "Maximilian Balandat",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10964"
  },
  {
    "id": "arXiv:2109.11532",
    "title": "Many nodal domains in random regular graphs",
    "abstract": "Comments: 18 pages. Minor changes to the introduction",
    "descriptor": "\nComments: 18 pages. Minor changes to the introduction\n",
    "authors": [
      "Shirshendu Ganguly",
      "Theo McKenzie",
      "Sidhanth Mohanty",
      "Nikhil Srivastava"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.11532"
  },
  {
    "id": "arXiv:2109.12068",
    "title": "AraT5: Text-to-Text Transformers for Arabic Language Understanding and  Generation",
    "abstract": "Comments: All authors contributed equally",
    "descriptor": "\nComments: All authors contributed equally\n",
    "authors": [
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.12068"
  },
  {
    "id": "arXiv:2109.12692",
    "title": "Equilibria and learning dynamics in mixed network  coordination/anti-coordination games",
    "abstract": "Equilibria and learning dynamics in mixed network  coordination/anti-coordination games",
    "descriptor": "",
    "authors": [
      "Laura Arditti",
      "Giacomo Como",
      "Fabio Fagnani",
      "Martina Vanelli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.12692"
  },
  {
    "id": "arXiv:2109.12907",
    "title": "Expressing High-Level Scientific Claims with Formal Semantics",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Cristina-Iulia Bucur",
      "Tobias Kuhn",
      "Davide Ceolin",
      "Jacco van Ossenbruggen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12907"
  },
  {
    "id": "arXiv:2109.13460",
    "title": "Self-Improving Voronoi Construction for a Hidden Mixture of Product  Distributions",
    "abstract": "Self-Improving Voronoi Construction for a Hidden Mixture of Product  Distributions",
    "descriptor": "",
    "authors": [
      "Siu-Wing Cheng",
      "Man Ting Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.13460"
  },
  {
    "id": "arXiv:2109.13559",
    "title": "A Note on Nussbaum-type Control and Lie-bracket Approximation",
    "abstract": "Comments: This is the extended version of our conference paper for CDC2021 with additional calculation steps",
    "descriptor": "\nComments: This is the extended version of our conference paper for CDC2021 with additional calculation steps\n",
    "authors": [
      "Marc Weber",
      "Christian Ebenbauer",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.13559"
  },
  {
    "id": "arXiv:2109.14247",
    "title": "Training Feedback Spiking Neural Networks by Implicit Differentiation on  the Equilibrium State",
    "abstract": "Comments: Accepted by NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Mingqing Xiao",
      "Qingyan Meng",
      "Zongpeng Zhang",
      "Yisen Wang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14247"
  },
  {
    "id": "arXiv:2110.00568",
    "title": "Conditional Deep Gaussian Processes: empirical Bayes hyperdata learning",
    "abstract": "Comments: Accepted by Special Issue \"Probabilistic Methods for Deep Learning\" of Entropy, 15 pages, reference to recent papers of finite Bayesian neural network added",
    "descriptor": "\nComments: Accepted by Special Issue \"Probabilistic Methods for Deep Learning\" of Entropy, 15 pages, reference to recent papers of finite Bayesian neural network added\n",
    "authors": [
      "Chi-Ken Lu",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00568"
  },
  {
    "id": "arXiv:2110.00737",
    "title": "A Survey of COVID-19 Misinformation: Datasets, Detection Techniques and  Open Issues",
    "abstract": "Comments: 43 pages, 6 figures",
    "descriptor": "\nComments: 43 pages, 6 figures\n",
    "authors": [
      "A.R. Sana Ullah",
      "Anupam Das",
      "Anik Das",
      "Muhammad Ashad Kabir",
      "Kai Shu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.00737"
  },
  {
    "id": "arXiv:2110.01188",
    "title": "LawSum: A weakly supervised approach for Indian Legal Document  Summarization",
    "abstract": "LawSum: A weakly supervised approach for Indian Legal Document  Summarization",
    "descriptor": "",
    "authors": [
      "Vedant Parikh",
      "Vidit Mathur",
      "Parth Mehta",
      "Namita Mittal",
      "Prasenjit Majumder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.01188"
  },
  {
    "id": "arXiv:2110.02343",
    "title": "Quantum Semi-Supervised Learning with Quantum Supremacy",
    "abstract": "Comments: 11 pages. Updated on quantum matrix product estimation",
    "descriptor": "\nComments: 11 pages. Updated on quantum matrix product estimation\n",
    "authors": [
      "Zhou Shangnan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2110.02343"
  },
  {
    "id": "arXiv:2110.02550",
    "title": "CBP: Backpropagation with constraint on weight precision using a  pseudo-Lagrange multiplier method",
    "abstract": "Comments: Accepted. NeurIPS 2021. The code is available at this https URL",
    "descriptor": "\nComments: Accepted. NeurIPS 2021. The code is available at this https URL\n",
    "authors": [
      "Guhyun Kim",
      "Doo Seok Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02550"
  },
  {
    "id": "arXiv:2110.03765",
    "title": "Spectroscopy Approaches for Food Safety Applications: Improving Data  Efficiency Using Active Learning and Semi-Supervised Learning",
    "abstract": "Spectroscopy Approaches for Food Safety Applications: Improving Data  Efficiency Using Active Learning and Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Nicharee Wisuthiphaet",
      "Hemiao Cui",
      "Nitin Nitin",
      "Xin Liu",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03765"
  },
  {
    "id": "arXiv:2110.03806",
    "title": "Toward a Theory of Programming Language and Reasoning Assistant Design:  Minimizing Cognitive Load",
    "abstract": "Comments: 8 pages. In HATRA 2021",
    "descriptor": "\nComments: 8 pages. In HATRA 2021\n",
    "authors": [
      "Michael Coblenz"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03806"
  },
  {
    "id": "arXiv:2110.03888",
    "title": "M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion  Parameter Pretraining",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Junyang Lin",
      "An Yang",
      "Jinze Bai",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Yong Li",
      "Wei Lin",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03888"
  },
  {
    "id": "arXiv:2110.04439",
    "title": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "abstract": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Xuejiao Tang",
      "Wenbin Zhang",
      "Shichao Pei",
      "Ji Zhang",
      "Wensheng Gan",
      "Mingli Zhang",
      "Zhen Liu",
      "Ruijun Chen",
      "Yiyi Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04439"
  },
  {
    "id": "arXiv:2110.04541",
    "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining  Example Design",
    "abstract": "The Inductive Bias of In-Context Learning: Rethinking Pretraining  Example Design",
    "descriptor": "",
    "authors": [
      "Yoav Levine",
      "Noam Wies",
      "Daniel Jannai",
      "Dan Navon",
      "Yedid Hoshen",
      "Amnon Shashua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04541"
  },
  {
    "id": "arXiv:2110.04545",
    "title": "Towards Data-Free Domain Generalization",
    "abstract": "Comments: Accepted at NeurIPS 2021 - DistShift Workshop",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 - DistShift Workshop\n",
    "authors": [
      "Ahmed Frikha",
      "Haokun Chen",
      "Denis Krompa\u00df",
      "Thomas Runkler",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04545"
  },
  {
    "id": "arXiv:2110.04831",
    "title": "Feature Imitating Networks",
    "abstract": "Feature Imitating Networks",
    "descriptor": "",
    "authors": [
      "Sari Saba-Sadiya",
      "Tuka Alhanai",
      "Mohammad M Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04831"
  },
  {
    "id": "arXiv:2110.04844",
    "title": "Frequency-aware SGD for Efficient Embedding Learning with Provable  Benefits",
    "abstract": "Frequency-aware SGD for Efficient Embedding Learning with Provable  Benefits",
    "descriptor": "",
    "authors": [
      "Yan Li",
      "Dhruv Choudhary",
      "Xiaohan Wei",
      "Baichuan Yuan",
      "Bhargav Bhushanam",
      "Tuo Zhao",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04844"
  },
  {
    "id": "arXiv:2110.04904",
    "title": "Modality-Guided Subnetwork for Salient Object Detection",
    "abstract": "Comments: Accepted to 3DV 2021",
    "descriptor": "\nComments: Accepted to 3DV 2021\n",
    "authors": [
      "Zongwei Wu",
      "Guillaume Allibert",
      "Christophe Stolz",
      "Chao Ma",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04904"
  },
  {
    "id": "arXiv:2110.05029",
    "title": "Internal Feedback in Biological Control: Architectures and Examples",
    "abstract": "Comments: This paper is a companion to arXiv:2109.11752 and arXiv:2109.11757. v3: updated title + author metadata to match PDF",
    "descriptor": "\nComments: This paper is a companion to arXiv:2109.11752 and arXiv:2109.11757. v3: updated title + author metadata to match PDF\n",
    "authors": [
      "Anish A. Sarma",
      "Jing Shuang Li",
      "Josefin Stenberg",
      "Gwyneth Card",
      "Elizabeth S. Heckscher",
      "Narayanan Kasthuri",
      "Terrence Sejnowski",
      "John C. Doyle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Molecular Networks (q-bio.MN)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.05029"
  },
  {
    "id": "arXiv:2110.05327",
    "title": "Compositionality as we see it, everywhere around us",
    "abstract": "Comments: 22 pages, lots of refs, lots of pictures, as usual",
    "descriptor": "\nComments: 22 pages, lots of refs, lots of pictures, as usual\n",
    "authors": [
      "Bob Coecke"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05327"
  },
  {
    "id": "arXiv:2110.05555",
    "title": "QAOAKit: A Toolkit for Reproducible Study, Application, and Verification  of the QAOA",
    "abstract": "Comments: Fixed typo",
    "descriptor": "\nComments: Fixed typo\n",
    "authors": [
      "Ruslan Shaydulin",
      "Kunal Marwaha",
      "Jonathan Wurtz",
      "Phillip C. Lotshaw"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.05555"
  },
  {
    "id": "arXiv:2110.06092",
    "title": "Quantitative spectral analysis of electromagnetic scattering. II:  Evolution semigroups and non-perturbative solutions",
    "abstract": "Comments: (v1) 22 pages, 3 TikZ figures. Continuation of arXiv:1007.4375v3. Updated from Chapter 5 and Appendix D in this https URL (v2) 22 pages, 3 TikZ figures. Accepted version with updated references",
    "descriptor": "\nComments: (v1) 22 pages, 3 TikZ figures. Continuation of arXiv:1007.4375v3. Updated from Chapter 5 and Appendix D in this https URL (v2) 22 pages, 3 TikZ figures. Accepted version with updated references\n",
    "authors": [
      "Yajun Zhou"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.06092"
  },
  {
    "id": "arXiv:2110.06211",
    "title": "Diagonalization $of$ Polynomial-Time Turing Machines Via  Nondeterministic Turing Machine",
    "abstract": "Comments: Version $4$: Remark $3$ responses to criticisms from an expert Lance Fortnow. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.05942",
    "descriptor": "\nComments: Version $4$: Remark $3$ responses to criticisms from an expert Lance Fortnow. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.05942\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.06211"
  },
  {
    "id": "arXiv:2110.06366",
    "title": "Time Masking for Temporal Language Models",
    "abstract": "Comments: 9 pages, accepted to WSDM 2022",
    "descriptor": "\nComments: 9 pages, accepted to WSDM 2022\n",
    "authors": [
      "Guy D. Rosin",
      "Ido Guy",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06366"
  },
  {
    "id": "arXiv:2110.06435",
    "title": "Dropout Prediction Variation Estimation Using Neuron Activation Strength",
    "abstract": "Dropout Prediction Variation Estimation Using Neuron Activation Strength",
    "descriptor": "",
    "authors": [
      "Haichao Yu",
      "Zhe Chen",
      "Dong Lin",
      "Gil Shamir",
      "Jie Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06435"
  },
  {
    "id": "arXiv:2110.06502",
    "title": "Prompt-tuning in ASR systems for efficient domain-adaptation",
    "abstract": "Comments: WeCNLP 2021 camera-ready",
    "descriptor": "\nComments: WeCNLP 2021 camera-ready\n",
    "authors": [
      "Saket Dingliwal",
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Ankur Gandhe",
      "Ravi Teja Gadde",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06502"
  },
  {
    "id": "arXiv:2110.06641",
    "title": "Dictionary Learning with Convex Update (ROMD)",
    "abstract": "Dictionary Learning with Convex Update (ROMD)",
    "descriptor": "",
    "authors": [
      "Cheng Cheng",
      "Wei Dai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06641"
  },
  {
    "id": "arXiv:2110.06848",
    "title": "Decoupled Contrastive Learning",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Chun-Hsiao Yeh",
      "Cheng-Yao Hong",
      "Yen-Chi Hsu",
      "Tyng-Luh Liu",
      "Yubei Chen",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06848"
  },
  {
    "id": "arXiv:2110.06892",
    "title": "TAG: Toward Accurate Social Media Content Tagging with a Concept Graph",
    "abstract": "TAG: Toward Accurate Social Media Content Tagging with a Concept Graph",
    "descriptor": "",
    "authors": [
      "Jiuding Yang",
      "Weidong Guo",
      "Bang Liu",
      "Yakun Yu",
      "Chaoyue Wang",
      "Jinwen Luo",
      "Linglong Kong",
      "Di Niu",
      "Zhen Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06892"
  },
  {
    "id": "arXiv:2110.06910",
    "title": "On the Double Descent of Random Features Models Trained with SGD",
    "abstract": "Comments: 34 pages, 2 figures",
    "descriptor": "\nComments: 34 pages, 2 figures\n",
    "authors": [
      "Fanghui Liu",
      "Johan A.K. Suykens",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06910"
  },
  {
    "id": "arXiv:2110.07403",
    "title": "A more direct and better variant of New Q-Newton's method Backtracking  for m equations in m variables",
    "abstract": "Comments: 11 pages. New algorithms and results (including avoidance of saddle points) are added. Relevant references are added. Some typos fixed",
    "descriptor": "\nComments: 11 pages. New algorithms and results (including avoidance of saddle points) are added. Relevant references are added. Some typos fixed\n",
    "authors": [
      "Tuyen Trung Truong"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Complex Variables (math.CV)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.07403"
  },
  {
    "id": "arXiv:2110.07435",
    "title": "Adaptive Differentially Private Empirical Risk Minimization",
    "abstract": "Adaptive Differentially Private Empirical Risk Minimization",
    "descriptor": "",
    "authors": [
      "Xiaoxia Wu",
      "Lingxiao Wang",
      "Irina Cristali",
      "Quanquan Gu",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07435"
  },
  {
    "id": "arXiv:2110.07521",
    "title": "Multi-objective Clustering: A Data-driven Analysis of MOCLE, MOCK and  $\u0394$-MOCK",
    "abstract": "Comments: Submitted to ICONIP 2021",
    "descriptor": "\nComments: Submitted to ICONIP 2021\n",
    "authors": [
      "Adriano Kultzak",
      "Cristina Y. Morimoto",
      "Aurora Pozo",
      "Marc\u00edlio C. P. de Souto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07521"
  },
  {
    "id": "arXiv:2110.07549",
    "title": "Time Series Clustering for Human Behavior Pattern Mining",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Rohan Kabra",
      "Divya Saxena",
      "Dhaval Patel",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07549"
  },
  {
    "id": "arXiv:2110.08164",
    "title": "Accurate Fine-grained Layout Analysis for the Historical Tibetan  Document Based on the Instance Segmentation",
    "abstract": "Comments: The manuscript contains 16 pages,14 figures, and 40 references in total",
    "descriptor": "\nComments: The manuscript contains 16 pages,14 figures, and 40 references in total\n",
    "authors": [
      "Penghai Zhao",
      "Weilan Wang",
      "Zhengqi Cai",
      "Guowei Zhang",
      "Yuqi Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08164"
  },
  {
    "id": "arXiv:2110.08393",
    "title": "A Bayesian Approach for Medical Inquiry and Disease Inference in  Automated Differential Diagnosis",
    "abstract": "A Bayesian Approach for Medical Inquiry and Disease Inference in  Automated Differential Diagnosis",
    "descriptor": "",
    "authors": [
      "Hong Guan",
      "Chitta Baral"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08393"
  },
  {
    "id": "arXiv:2110.08396",
    "title": "Comparing Human and Machine Bias in Face Recognition",
    "abstract": "Comparing Human and Machine Bias in Face Recognition",
    "descriptor": "",
    "authors": [
      "Samuel Dooley",
      "Ryan Downing",
      "George Wei",
      "Nathan Shankar",
      "Bradon Thymes",
      "Gudrun Thorkelsdottir",
      "Tiye Kurtz-Miott",
      "Rachel Mattson",
      "Olufemi Obiwumi",
      "Valeriia Cherepanova",
      "Micah Goldblum",
      "John P Dickerson",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08396"
  },
  {
    "id": "arXiv:2110.08477",
    "title": "FedMM: Saddle Point Optimization for Federated Adversarial Domain  Adaptation",
    "abstract": "FedMM: Saddle Point Optimization for Federated Adversarial Domain  Adaptation",
    "descriptor": "",
    "authors": [
      "Yan Shen",
      "Jian Du",
      "Hao Zhang",
      "Benyu Zhang",
      "Zhanghexuan Ji",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08477"
  },
  {
    "id": "arXiv:2110.08633",
    "title": "Hydra: A System for Large Multi-Model Deep Learning",
    "abstract": "Comments: 12 pages including references. Under submission at Conference on Systems and Machine Learning Foundation",
    "descriptor": "\nComments: 12 pages including references. Under submission at Conference on Systems and Machine Learning Foundation\n",
    "authors": [
      "Kabir Nagrecha",
      "Arun Kumar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08633"
  },
  {
    "id": "arXiv:2110.08733",
    "title": "LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic  Segmentation",
    "abstract": "Comments: Accepted by NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Junjue Wang",
      "Zhuo Zheng",
      "Ailong Ma",
      "Xiaoyan Lu",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08733"
  },
  {
    "id": "arXiv:2110.08975",
    "title": "Deep Transfer Learning & Beyond: Transformer Language Models in  Information Systems Research",
    "abstract": "Comments: Under review (revised once). Section 2, the literature review on deep transfer learning and transformer language models, is a valuable introduction for a broad audience (not just information systems researchers). 33 pages plus 13-page appendix",
    "descriptor": "\nComments: Under review (revised once). Section 2, the literature review on deep transfer learning and transformer language models, is a valuable introduction for a broad audience (not just information systems researchers). 33 pages plus 13-page appendix\n",
    "authors": [
      "Ross Gruetzemacher",
      "David Paradice"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08975"
  },
  {
    "id": "arXiv:2110.08996",
    "title": "Finding Everything within Random Binary Networks",
    "abstract": "Finding Everything within Random Binary Networks",
    "descriptor": "",
    "authors": [
      "Kartik Sreenivasan",
      "Shashank Rajput",
      "Jy-yong Sohn",
      "Dimitris Papailiopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08996"
  },
  {
    "id": "arXiv:2110.09295",
    "title": "Fair Tree Learning",
    "abstract": "Fair Tree Learning",
    "descriptor": "",
    "authors": [
      "Ant\u00f3nio Pereira Barata",
      "Frank W. Takes",
      "H. Jaap van den Herik",
      "Cor J. Veenman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09295"
  },
  {
    "id": "arXiv:2110.09397",
    "title": "Using Psychological Characteristics of Situations for Social Situation  Comprehension in Support Agents",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Ilir Kola",
      "Catholijn M. Jonker",
      "M. Birna van Riemsdijk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09397"
  },
  {
    "id": "arXiv:2110.09414",
    "title": "BPPChecker: An SMT-based Model Checker on Basic Parallel Processes(Full  Version)",
    "abstract": "BPPChecker: An SMT-based Model Checker on Basic Parallel Processes(Full  Version)",
    "descriptor": "",
    "authors": [
      "Ying Zhao",
      "Jinhao Tan",
      "Guoqiang Li"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.09414"
  },
  {
    "id": "arXiv:2110.09490",
    "title": "Unsupervised Image Fusion Using Deep Image Priors",
    "abstract": "Unsupervised Image Fusion Using Deep Image Priors",
    "descriptor": "",
    "authors": [
      "Xudong Ma",
      "Paul Hill",
      "Alin Achim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09490"
  },
  {
    "id": "arXiv:2110.09548",
    "title": "Path Regularization: A Convexity and Sparsity Inducing Regularization  for Parallel ReLU Networks",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2110.05518",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.05518\n",
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09548"
  },
  {
    "id": "arXiv:2110.09674",
    "title": "Adaptive Distillation: Aggregating Knowledge from Multiple Paths for  Efficient Distillation",
    "abstract": "Comments: Accepted to BMVC 2021 for publication. V2. Added more results for ImageNet-1K",
    "descriptor": "\nComments: Accepted to BMVC 2021 for publication. V2. Added more results for ImageNet-1K\n",
    "authors": [
      "Sumanth Chennupati",
      "Mohammad Mahdi Kamani",
      "Zhongwei Cheng",
      "Lin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09674"
  },
  {
    "id": "arXiv:2110.09742",
    "title": "Learning Not to Reconstruct Anomalies",
    "abstract": "Comments: Accepted in BMVC 2021",
    "descriptor": "\nComments: Accepted in BMVC 2021\n",
    "authors": [
      "Marcella Astrid",
      "Muhammad Zaigham Zaheer",
      "Jae-Yeong Lee",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09742"
  },
  {
    "id": "arXiv:2110.09766",
    "title": "Memory-Augmented Deep Unfolding Network for Compressive Sensing",
    "abstract": "Comments: 10 pages, 7 figures, ACM MM 2021",
    "descriptor": "\nComments: 10 pages, 7 figures, ACM MM 2021\n",
    "authors": [
      "Jiechong Song",
      "Bin Chen",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.09766"
  },
  {
    "id": "arXiv:2110.09823",
    "title": "An Empirical Study: Extensive Deep Temporal Point Process",
    "abstract": "Comments: 22 pages, 8 figures",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Haitao Lin",
      "Cheng Tan",
      "Lirong Wu",
      "Zhangyang Gao",
      "Stan. Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.09823"
  },
  {
    "id": "arXiv:2110.10153",
    "title": "The Creation of Puffin, the Automatic Uncertainty Compiler",
    "abstract": "Comments: 21 Pages, 10 Figures",
    "descriptor": "\nComments: 21 Pages, 10 Figures\n",
    "authors": [
      "Nicholas Gray",
      "Marco De Angelis",
      "Scott Ferson"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.10153"
  },
  {
    "id": "arXiv:2110.10278",
    "title": "Fine-Grained Control of Artistic Styles in Image Generation",
    "abstract": "Fine-Grained Control of Artistic Styles in Image Generation",
    "descriptor": "",
    "authors": [
      "Xin Miao",
      "Huayan Wang",
      "Jun Fu",
      "Jiayi Liu",
      "Shen Wang",
      "Zhenyu Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10278"
  },
  {
    "id": "arXiv:2110.10298",
    "title": "Incorporating Rich Social Interactions Into MDPs",
    "abstract": "Comments: Submitted to the 39th IEEE Conference on Robotics and Automation (ICRA 2022). Do not distribute",
    "descriptor": "\nComments: Submitted to the 39th IEEE Conference on Robotics and Automation (ICRA 2022). Do not distribute\n",
    "authors": [
      "Ravi Tejwani",
      "Yen-Ling Kuo",
      "Tianmin Shu",
      "Bennett Stankovits",
      "Dan Gutfreund",
      "Joshua B. Tenenbaum",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10298"
  },
  {
    "id": "arXiv:2110.10358",
    "title": "Hierarchical Aspect-guided Explanation Generation for Explainable  Recommendation",
    "abstract": "Hierarchical Aspect-guided Explanation Generation for Explainable  Recommendation",
    "descriptor": "",
    "authors": [
      "Yidan Hu",
      "Yong Liu",
      "Chunyan Miao",
      "Gongqi Lin",
      "Yuan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10358"
  },
  {
    "id": "arXiv:2110.10470",
    "title": "Interpreting Deep Learning Models in Natural Language Processing: A  Review",
    "abstract": "Interpreting Deep Learning Models in Natural Language Processing: A  Review",
    "descriptor": "",
    "authors": [
      "Xiaofei Sun",
      "Diyi Yang",
      "Xiaoya Li",
      "Tianwei Zhang",
      "Yuxian Meng",
      "Han Qiu",
      "Guoyin Wang",
      "Eduard Hovy",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10470"
  },
  {
    "id": "arXiv:2110.10474",
    "title": "R4: A Framework for Route Representation and Route Recommendation",
    "abstract": "R4: A Framework for Route Representation and Route Recommendation",
    "descriptor": "",
    "authors": [
      "Ran Cheng",
      "Chao Chen",
      "Longfei Xu",
      "Shen Li",
      "Lei Wang",
      "Hengbin Cui",
      "Kaikui Liu",
      "Xiaolong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10474"
  },
  {
    "id": "arXiv:2110.10482",
    "title": "Surrogate Representation Learning with Isometric Mapping for Gray-box  Graph Adversarial Attacks",
    "abstract": "Surrogate Representation Learning with Isometric Mapping for Gray-box  Graph Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Zihan Liu",
      "Yun Luo",
      "Zelin Zang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10482"
  },
  {
    "id": "arXiv:2110.10538",
    "title": "ASSANet: An Anisotropic Separable Set Abstraction for Efficient Point  Cloud Representation Learning",
    "abstract": "Comments: ASSANet gets accepted to NeurIPS'21 as a Spotlight paper. code available at this https URL",
    "descriptor": "\nComments: ASSANet gets accepted to NeurIPS'21 as a Spotlight paper. code available at this https URL\n",
    "authors": [
      "Guocheng Qian",
      "Hasan Abed Al Kader Hammoud",
      "Guohao Li",
      "Ali Thabet",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10538"
  },
  {
    "id": "arXiv:2110.10720",
    "title": "Privacy in Open Search: A Review of Challenges and Solutions",
    "abstract": "Comments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium",
    "descriptor": "\nComments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium\n",
    "authors": [
      "Samuel Sousa",
      "Christian Guetl",
      "Roman Kern"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10720"
  },
  {
    "id": "arXiv:2110.10735",
    "title": "Dynamic Bottleneck for Robust Self-Supervised Exploration",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Chenjia Bai",
      "Lingxiao Wang",
      "Lei Han",
      "Animesh Garg",
      "Jianye Hao",
      "Peng Liu",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10735"
  },
  {
    "id": "arXiv:2110.10790",
    "title": "Human-Centered Explainable AI (XAI): From Algorithms to User Experiences",
    "abstract": "Comments: draft for a book chapter",
    "descriptor": "\nComments: draft for a book chapter\n",
    "authors": [
      "Q. Vera Liao",
      "Kush R. Varshney"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10790"
  },
  {
    "id": "arXiv:2110.11013",
    "title": "Spatial Location Constraint Prototype Loss for Open Set Recognition",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Ziheng Xia",
      "Ganggang Dong",
      "Penghui Wang",
      "Hongwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11013"
  },
  {
    "id": "arXiv:2110.11072",
    "title": "Sequential Modeling with Multiple Attributes for Watchlist  Recommendation in E-Commerce",
    "abstract": "Sequential Modeling with Multiple Attributes for Watchlist  Recommendation in E-Commerce",
    "descriptor": "",
    "authors": [
      "Uriel Singer",
      "Haggai Roitman",
      "Yotam Eshel",
      "Alexander Nus",
      "Ido Guy",
      "Or Levi",
      "Idan Hasson",
      "Eliyahu Kiperwasser"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11072"
  },
  {
    "id": "arXiv:2110.11191",
    "title": "Generative Adversarial Graph Convolutional Networks for Human Action  Synthesis",
    "abstract": "Comments: Published as a conference paper at WACV 2022. Code and pretrained models available at this https URL",
    "descriptor": "\nComments: Published as a conference paper at WACV 2022. Code and pretrained models available at this https URL\n",
    "authors": [
      "Bruno Degardin",
      "Jo\u00e3o Neves",
      "Vasco Lopes",
      "Jo\u00e3o Brito",
      "Ehsan Yaghoubi",
      "Hugo Proen\u00e7a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11191"
  },
  {
    "id": "arXiv:2110.11265",
    "title": "Deep Reinforcement Learning for Online Control of Stochastic Partial  Differential Equations",
    "abstract": "Deep Reinforcement Learning for Online Control of Stochastic Partial  Differential Equations",
    "descriptor": "",
    "authors": [
      "Erfan Pirmorad",
      "Faraz Khoshbakhtian",
      "Farnam Mansouri",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11265"
  },
  {
    "id": "arXiv:2110.11291",
    "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs  Theory",
    "abstract": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs  Theory",
    "descriptor": "",
    "authors": [
      "Tianrong Chen",
      "Guan-Horng Liu",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11291"
  },
  {
    "id": "arXiv:2110.11337",
    "title": "Learning Universal User Representations via Self-Supervised Lifelong  Behaviors Modeling",
    "abstract": "Comments: during peer review",
    "descriptor": "\nComments: during peer review\n",
    "authors": [
      "Bei Yang",
      "Ke Liu",
      "Xiaoxiao Xu",
      "Renjun Xu",
      "Hong Liu",
      "Huan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11337"
  },
  {
    "id": "arXiv:2110.11347",
    "title": "Multidimensional representations in late-life depression: convergence in  neuroimaging, cognition, clinical symptomatology and genetics",
    "abstract": "Multidimensional representations in late-life depression: convergence in  neuroimaging, cognition, clinical symptomatology and genetics",
    "descriptor": "",
    "authors": [
      "Junhao Wen",
      "Cynthia H.Y. Fu",
      "Duygu Tosun",
      "Yogasudha Veturi",
      "Zhijian Yang",
      "Ahmed Abdulkadir",
      "Elizabeth Mamourian",
      "Dhivya Srinivasan",
      "Jingxuan Bao",
      "Guray Erus",
      "Haochang Shou",
      "Mohamad Habes",
      "Jimit Doshi",
      "Erdem Varol",
      "Scott R Mackin",
      "Aristeidis Sotiras",
      "Yong Fan",
      "Andrew J. Saykin",
      "Yvette I. Sheline",
      "Li Shen",
      "Marylyn D. Ritchie",
      "David A. Wolk",
      "Marilyn Albert",
      "Susan M. Resnick",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11347"
  },
  {
    "id": "arXiv:2110.11382",
    "title": "Efficient and Robust Mixed-Integer Optimization Methods for Training  Binarized Deep Neural Networks",
    "abstract": "Comments: added GitHub link for code. arXiv admin note: substantial text overlap with arXiv:2007.03326",
    "descriptor": "\nComments: added GitHub link for code. arXiv admin note: substantial text overlap with arXiv:2007.03326\n",
    "authors": [
      "Jannis Kurtz",
      "Bubacarr Bah"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11382"
  },
  {
    "id": "arXiv:2110.11416",
    "title": "Verification of Distributed Quantum Protocols",
    "abstract": "Comments: 151 pages, 23 figures, 60 tables. arXiv admin note: substantial text overlap with arXiv:1811.01070, arXiv:2107.08453, arXiv:2101.05140, arXiv:1611.09035, arXiv:1610.02500, arXiv:1810.00868, arXiv:2104.05438, arXiv:1311.2960, arXiv:1501.05260, arXiv:2109.05936",
    "descriptor": "\nComments: 151 pages, 23 figures, 60 tables. arXiv admin note: substantial text overlap with arXiv:1811.01070, arXiv:2107.08453, arXiv:2101.05140, arXiv:1611.09035, arXiv:1610.02500, arXiv:1810.00868, arXiv:2104.05438, arXiv:1311.2960, arXiv:1501.05260, arXiv:2109.05936\n",
    "authors": [
      "Yong Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11416"
  },
  {
    "id": "arXiv:2110.11420",
    "title": "Fast Graph Sampling for Short Video Summarization using Gershgorin Disc  Alignment",
    "abstract": "Comments: 5 pages, 2 figures - Remove affiliation from author list",
    "descriptor": "\nComments: 5 pages, 2 figures - Remove affiliation from author list\n",
    "authors": [
      "Sadid Sahami",
      "Gene Cheung",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11420"
  },
  {
    "id": "arXiv:2110.11474",
    "title": "AEI: Actors-Environment Interaction with Adaptive Attention for Temporal  Action Proposals Generation",
    "abstract": "Comments: Accepted in BMVC 2021 (Oral Session)",
    "descriptor": "\nComments: Accepted in BMVC 2021 (Oral Session)\n",
    "authors": [
      "Khoa Vo",
      "Hyekang Joo",
      "Kashu Yamazaki",
      "Sang Truong",
      "Kris Kitani",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11474"
  },
  {
    "id": "arXiv:2110.11571",
    "title": "Anti-Backdoor Learning: Training Clean Models on Poisoned Data",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Yige Li",
      "Xixiang Lyu",
      "Nodens Koren",
      "Lingjuan Lyu",
      "Bo Li",
      "Xingjun Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11571"
  },
  {
    "id": "arXiv:2110.11601",
    "title": "Multimodal Semi-Supervised Learning for 3D Objects",
    "abstract": "Comments: BMVC 2021 poster",
    "descriptor": "\nComments: BMVC 2021 poster\n",
    "authors": [
      "Zhimin Chen",
      "Longlong Jing",
      "Yang Liang",
      "YingLi Tian",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11601"
  },
  {
    "id": "arXiv:2110.11624",
    "title": "SciCap: Generating Captions for Scientific Figures",
    "abstract": "Comments: To Appear in EMNLP 2021 Findings. The dataset is available at: this https URL",
    "descriptor": "\nComments: To Appear in EMNLP 2021 Findings. The dataset is available at: this https URL\n",
    "authors": [
      "Ting-Yao Hsu",
      "C. Lee Giles",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11624"
  },
  {
    "id": "arXiv:2110.11681",
    "title": "Conditional Variational Autoencoder for Learned Image Reconstruction",
    "abstract": "Comments: 22 pages, preliminary version appeared as 1908.01010",
    "descriptor": "\nComments: 22 pages, preliminary version appeared as 1908.01010\n",
    "authors": [
      "Chen Zhang",
      "Riccardo Barbano",
      "Bangti Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11681"
  },
  {
    "id": "arXiv:2110.11709",
    "title": "Creating Knowledge Graphs Subsets using Shape Expressions",
    "abstract": "Creating Knowledge Graphs Subsets using Shape Expressions",
    "descriptor": "",
    "authors": [
      "Jose Emilio Labra Gayo"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11709"
  },
  {
    "id": "arXiv:2110.11758",
    "title": "The Crew: The Quest for Planet Nine is NP-Complete",
    "abstract": "Comments: 14 pages, 3 figures",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Frederick Reiber"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.11758"
  },
  {
    "id": "arXiv:2110.11856",
    "title": "L-2 Regularized maximum likelihood for $\u03b2$-model in large and sparse  networks",
    "abstract": "L-2 Regularized maximum likelihood for $\u03b2$-model in large and sparse  networks",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Qiuping Wang",
      "Yuan Zhang",
      "Ting Yan",
      "Jing Luo"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11856"
  },
  {
    "id": "arXiv:2110.11894",
    "title": "Towards Using Clothes Style Transfer for Scenario-aware Person Video  Generation",
    "abstract": "Towards Using Clothes Style Transfer for Scenario-aware Person Video  Generation",
    "descriptor": "",
    "authors": [
      "Jingning Xu",
      "Benlai Tang",
      "Mingjie Wang",
      "Siyuan Bian",
      "Wenyi Guo",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11894"
  }
]
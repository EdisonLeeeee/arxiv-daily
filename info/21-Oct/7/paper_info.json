[
  {
    "id": "arXiv:2110.02219",
    "title": "RC-Struct: A Structure-based Neural Network Approach for MIMO-OFDM  Detection",
    "abstract": "In this paper, we introduce a structure-based neural network architecture,\nnamely RC-Struct, for MIMO-OFDM symbol detection. The RC-Struct exploits the\ntemporal structure of the MIMO-OFDM signals through reservoir computing (RC). A\nbinary classifier leverages the repetitive constellation structure in the\nsystem to perform multi-class detection. The incorporation of RC allows the\nRC-Struct to be learned in a purely online fashion with extremely limited pilot\nsymbols in each OFDM subframe. The binary classifier enables the efficient\nutilization of the precious online training symbols and allows an easy\nextension to high-order modulations without a substantial increase in\ncomplexity. Experiments show that the introduced RC-Struct outperforms both the\nconventional model-based symbol detection approaches and the state-of-the-art\nlearning-based strategies in terms of bit error rate (BER). The advantages of\nRC-Struct over existing methods become more significant when rank and link\nadaptation are adopted. The introduced RC-Struct sheds light on combining\ncommunication domain knowledge and learning-based receive processing for 5G and\n5G Beyond.",
    "descriptor": "\nComments: 30 pages, 17 figures, journal submission\n",
    "authors": [
      "Jiarui Xu",
      "Zhou Zhou",
      "Lianjun Li",
      "Lizhong Zheng",
      "Lingjia Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02219"
  },
  {
    "id": "arXiv:2110.02221",
    "title": "Securing Federated Learning: A Covert Communication-based Approach",
    "abstract": "Federated Learning Networks (FLNs) have been envisaged as a promising\nparadigm to collaboratively train models among mobile devices without exposing\ntheir local privacy data. Due to the need for frequent model updates and\ncommunications, FLNs are vulnerable to various attacks (e.g., eavesdropping\nattacks, inference attacks, poisoning attacks, and backdoor attacks). Balancing\nprivacy protection with efficient distributed model training is a key challenge\nfor FLNs. Existing countermeasures incur high computation costs and are only\ndesigned for specific attacks on FLNs. In this paper, we bridge this gap by\nproposing the Covert Communication-based Federated Learning (CCFL) approach.\nBased on the emerging communication security technique of covert communication\nwhich hides the existence of wireless communication activities, CCFL can\ndegrade attackers' capability of extracting useful information from the FLN\ntraining protocol, which is a fundamental step for most existing attacks, and\nthereby holistically enhances the privacy of FLNs. We experimentally evaluate\nCCFL extensively under real-world settings in which the FL latency is optimized\nunder given security requirements. Numerical results demonstrate the\nsignificant effectiveness of the proposed approach in terms of both training\nefficiency and communication security.",
    "descriptor": "",
    "authors": [
      "Yuan-Ai Xie",
      "Jiawen Kang",
      "Dusit Niyato",
      "Nguyen Thi Thanh Van",
      "Nguyen Cong Luong",
      "Zhixin Liu",
      "Han Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02221"
  },
  {
    "id": "arXiv:2110.02223",
    "title": "CNFET-based design of efficient ternary half adder and 1-trit multiplier  circuits using dynamic logic",
    "abstract": "This paper presents a ternary half adder and a 1-trit multiplier using carbon\nnanotube transistors. The proposed circuits are designed using pass transistor\nlogic and dynamic logic. Ternary logic uses less connections than binary logic,\nand less voltage changes are required for the same amount of data transmission.\nCarbon nanotube transistors have advantages over MOSFETs, such as the same\nmobility for electrons and holes, the ability to adjust the threshold voltage\nby changing the nanotube diameter, and less leakage power. The proposed half\nadder has lower power consumption, delay, and fewer transistors compared to\nrecent ternary half adders that use similar design methods. The proposed 1-trit\nmultiplier also has a lower delay than other designs. Moreover, these\nadvantages are achieved over a wide supply voltage range, operating\ntemperatures, and output loads. The design is also more robust to process\nvariations than the nearest design in terms of PDP.",
    "descriptor": "",
    "authors": [
      "Farzin Mahboob-Sardroudi",
      "Mehdi Habibi",
      "Mohammad-Hossein Moaiyeri"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02223"
  },
  {
    "id": "arXiv:2110.02224",
    "title": "Transparent Forwarders: An Unnoticed Component of the Open DNS  Infrastructure",
    "abstract": "In this short paper, we revisit the open DNS (ODNS) infrastructure and, for\nthe first time, systematically measure and analyze transparent forwarders, DNS\ncomponents that transparently relay between stub resolvers and recursive\nresolvers. Our key findings include four takeaways. First, transparent\nforwarders contribute 26% (563k) to the current ODNS infrastructure.\nUnfortunately, common periodic scanning campaigns such as Shadowserver do not\ncapture transparent forwarders and thus underestimate the current threat\npotential of the ODNS. Second, we find an increased deployment of transparent\nforwarders in Asia and South America. In India alone, the ODNS consists of 80%\ntransparent forwarders. Third, many transparent forwarders relay to a few\nselected public resolvers such as Google and Cloudflare, which confirms a\nconsolidation trend of DNS stakeholders. Finally, we introduce DNSRoute++, a\nnew traceroute approach to understand the network infrastructure connecting\ntransparent forwarders and resolvers.",
    "descriptor": "\nComments: Proc. of ACM CoNEXT'21, pre-print\n",
    "authors": [
      "Marcin Nawrocki",
      "Maynard Koch",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02224"
  },
  {
    "id": "arXiv:2110.02226",
    "title": "Communication-Efficient Federated Learning with Binary Neural Networks",
    "abstract": "Federated learning (FL) is a privacy-preserving machine learning setting that\nenables many devices to jointly train a shared global model without the need to\nreveal their data to a central server. However, FL involves a frequent exchange\nof the parameters between all the clients and the server that coordinates the\ntraining. This introduces extensive communication overhead, which can be a\nmajor bottleneck in FL with limited communication links. In this paper, we\nconsider training the binary neural networks (BNN) in the FL setting instead of\nthe typical real-valued neural networks to fulfill the stringent delay and\nefficiency requirement in wireless edge networks. We introduce a novel FL\nframework of training BNN, where the clients only upload the binary parameters\nto the server. We also propose a novel parameter updating scheme based on the\nMaximum Likelihood (ML) estimation that preserves the performance of the BNN\neven without the availability of aggregated real-valued auxiliary parameters\nthat are usually needed during the training of the BNN. Moreover, for the first\ntime in the literature, we theoretically derive the conditions under which the\ntraining of BNN is converging. { Numerical results show that the proposed FL\nframework significantly reduces the communication cost compared to the\nconventional neural networks with typical real-valued parameters, and the\nperformance loss incurred by the binarization can be further compensated by a\nhybrid method.",
    "descriptor": "\nComments: Accepted for publication in IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Yuzhi Yang",
      "Zhaoyang Zhang",
      "Qianqian Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02226"
  },
  {
    "id": "arXiv:2110.02248",
    "title": "Contextual Combinatorial Volatile Bandits via Gaussian Processes",
    "abstract": "We consider a contextual bandit problem with a combinatorial action set and\ntime-varying base arm availability. At the beginning of each round, the agent\nobserves the set of available base arms and their contexts and then selects an\naction that is a feasible subset of the set of available base arms to maximize\nits cumulative reward in the long run. We assume that the mean outcomes of base\narms are samples from a Gaussian Process indexed by the context set ${\\cal X}$,\nand the expected reward is Lipschitz continuous in expected base arm outcomes.\nFor this setup, we propose an algorithm called Optimistic Combinatorial\nLearning and Optimization with Kernel Upper Confidence Bounds (O'CLOK-UCB) and\nprove that it incurs $\\tilde{O}(K\\sqrt{T\\overline{\\gamma}_{T}} )$ regret with\nhigh probability, where $\\overline{\\gamma}_{T}$ is the maximum information gain\nassociated with the set of base arm contexts that appeared in the first $T$\nrounds and $K$ is the maximum cardinality of any feasible action over all\nrounds. To dramatically speed up the algorithm, we also propose a variant of\nO'CLOK-UCB that uses sparse GPs. Finally, we experimentally show that both\nalgorithms exploit inter-base arm outcome correlation and vastly outperform the\nprevious state-of-the-art UCB-based algorithms in realistic setups.",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Andi Nika",
      "Sepehr Elahi",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02248"
  },
  {
    "id": "arXiv:2110.02251",
    "title": "An Exploration of the Mentorship Needs of Research Software Engineers",
    "abstract": "As a newly designated professional title, research software engineers (RSEs)\nlink the two worlds of software engineering and research science. They lack\nclear development and training opportunities, particularly in the realm of\nmentoring. In this paper, we discuss mentorship as it pertains to the unique\nneeds of RSEs and propose ways in which organizations and institutions can\nsupport mentor/mentee relationships for RSEs",
    "descriptor": "\nComments: 3 pages, Presented at Research Software Engineers in HPC (RSE-HPC-2021), co-located with Supercomputing'21 (SC'21)\n",
    "authors": [
      "Reed Milewicz",
      "Miranda Mundt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02251"
  },
  {
    "id": "arXiv:2110.02258",
    "title": "Thumb Assistance Via Active and Passive Exotendons in a Robotic Hand  Orthosis for Stroke",
    "abstract": "We present a tendon-driven, active-extension thumb exoskeleton adding\nopposition/reposition capabilities to a robotic hand orthosis designed for\nindividuals with chronic upper-limb hemiparesis after stroke. The orthosis uses\ntwo actuators to assist hand-opening, with one tendon network controlling\nsimultaneous four-finger extension and one separately driving thumb extension.\nWhen combined with a passive palmar abduction constraint, the thumb network can\ncounteract spasticity and provide stable thumb opposition for manipulating\nobjects in a range of sizes. We performed a preliminary assessment with five\nchronic stroke survivors presenting with arm-hand motor deficits and increased\nmuscle tone (spasticity). Experiments consisted of unimanual resistive-pull\ntasks and bimanual twisting tasks with simulated real-world objects; these\nexplored the effects of thumb assistance on grasp stability and functional\nrange of motion. We specifically compare functional performance of actuation\nagainst static thumb-splinting and against no device. The addition of\nactive-extension to the thumb improves positioning ability when reaching for\nobjects, and improves consistency and duration of maintaining stable grasps.",
    "descriptor": "\nComments: 7 pages, 10 figures. Submitted to ICRA 2022\n",
    "authors": [
      "Ava Chen",
      "Lauren Winterbottom",
      "Sangwoo Park",
      "Jingxi Xu",
      "Dawn Nilsen",
      "Joel Stein",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02258"
  },
  {
    "id": "arXiv:2110.02259",
    "title": "Multi-Modal Attack Detection for Cyber-Physical Additive Manufacturing",
    "abstract": "Cyber-Physical Additive Manufacturing (AM) constructs a physical 3D object\nlayer-by-layer according to its digital representation and has been vastly\napplied to fast prototyping and the manufacturing of functional end-products\nacross fields. The computerization of traditional production processes propels\nthese technological advancements; however, this also introduces new\nvulnerabilities, necessitating the study of cyberattacks on these systems. The\nAM Sabotage Attack is one kind of kinetic cyberattack that originates from the\ncyber domain and can eventually lead to physical damage, injury, or even death.\nBy introducing inconspicuous yet damaging alterations in any specific process\nof the AM digital process chain, the attackers can compromise the structural\nintegrity of a manufactured component in a manner that is invisible to a human\nobserver. If the manufactured objects are critical for their system, those\nattacks can even compromise the whole system's structural integrity and pose a\nsevere safety risk to its users. For example, an inconspicuous void (less than\n1 mm in dimension) placed in the 3D design of a tensile test specimen can\nreduce its yield load by 14%. However, security studies primarily focus on\nsecuring digital assets, overlooking the fact that AM systems are CPSs.",
    "descriptor": "",
    "authors": [
      "Shih-Yuan Yu",
      "Arnav Vaibhav Malawade",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02259"
  },
  {
    "id": "arXiv:2110.02260",
    "title": "An Overview of the Drone Open-Source Ecosystem",
    "abstract": "Unmanned aerial systems capable of beyond visual line of sight operation can\nbe organized into a top-down hierarchy of layers including flight supervision,\ncommand and control, simulation of systems, operating systems, and physical\nhardware. Flight supervision includes unmanned air traffic management, flight\nplanning, authorization, and remote identification. Command and control ensure\ndrones can be piloted safely. Simulation of systems concerns how drones may\nreact to different environments and how changing conditions and information\nprovide input to a piloting system. Electronic hardware controlling drone\noperation is typically accessed using an operating system. Each layer in the\nhierarchy has an ecosystem of open-source solutions. In this brief survey we\ndescribe representative open-source examples for each level of the hierarchy.",
    "descriptor": "",
    "authors": [
      "John Glossner",
      "Samantha Murphy",
      "Daniel Iancu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02260"
  },
  {
    "id": "arXiv:2110.02267",
    "title": "Disambiguation-BERT for N-best Rescoring in Low-Resource Conversational  ASR",
    "abstract": "We study the inclusion of past conversational context through BERT language\nmodels into a CTC-based Automatic Speech Recognition (ASR) system via N-best\nrescoring. We introduce a data-efficient strategy to fine-tune BERT on\ntranscript disambiguation without external data. Our results show word error\nrate recoveries up to 37.2% with context-augmented BERT rescoring. We do this\nin low-resource data domains, both in language (Norwegian), tone (spontaneous,\nconversational), and topics (parliament proceedings and customer service phone\ncalls). We show how the nature of the data greatly affects the performance of\ncontext-augmented N-best rescoring.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Pablo Ortiz",
      "Simen Burud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02267"
  },
  {
    "id": "arXiv:2110.02270",
    "title": "Transformer Assisted Convolutional Network for Cell Instance  Segmentation",
    "abstract": "Region proposal based methods like R-CNN and Faster R-CNN models have proven\nto be extremely successful in object detection and segmentation tasks.\nRecently, Transformers have also gained popularity in the domain of Computer\nVision, and are being utilised to improve the performance of conventional\nmodels. In this paper, we present a relatively new transformer based approach\nto enhance the performance of the conventional convolutional feature extractor\nin the existing region proposal based methods. Our approach merges the\nconvolutional feature maps with transformer-based token embeddings by applying\na projection operation similar to self-attention in transformers. The results\nof our experiments show that transformer assisted feature extractor achieves a\nsignificant improvement in mIoU (mean Intersection over Union) scores compared\nto vanilla convolutional backbone.",
    "descriptor": "",
    "authors": [
      "Deepanshu Pandey",
      "Pradyumna Gupta",
      "Sumit Bhattacharya",
      "Aman Sinha",
      "Rohit Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02270"
  },
  {
    "id": "arXiv:2110.02271",
    "title": "Networked Time Series Prediction with Incomplete Data",
    "abstract": "A networked time series (NETS) is a family of time series on a given graph,\none for each node. It has found a wide range of applications from intelligent\ntransportation, environment monitoring to mobile network management. An\nimportant task in such applications is to predict the future values of a NETS\nbased on its historical values and the underlying graph. Most existing methods\nrequire complete data for training. However, in real-world scenarios, it is not\nuncommon to have missing data due to sensor malfunction, incomplete sensing\ncoverage, etc. In this paper, we study the problem of NETS prediction with\nincomplete data. We propose NETS-ImpGAN, a novel deep learning framework that\ncan be trained on incomplete data with missing values in both history and\nfuture. Furthermore, we propose novel Graph Temporal Attention Networks by\nincorporating the attention mechanism to capture both inter-time series\ncorrelations and temporal correlations. We conduct extensive experiments on\nthree real-world datasets under different missing patterns and missing rates.\nThe experimental results show that NETS-ImpGAN outperforms existing methods\nexcept when data exhibit very low variance, in which case NETS-ImpGAN still\nachieves competitive performance.",
    "descriptor": "",
    "authors": [
      "Yichen Zhu",
      "Mengtian Zhang",
      "Bo Jiang",
      "Haiming Jin",
      "Jianqiang Huang",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02271"
  },
  {
    "id": "arXiv:2110.02274",
    "title": "Design of Spiral-Cable Forearm Exoskeleton to Provide Supination  Adjustment for Hemiparetic Stroke Subjects",
    "abstract": "We present the development of a cable-based passive forearm exoskeleton,\ndesigned to assist supination for hemiparetic stroke survivors, that uniquely\nprovides torque sufficient for counteracting spasticity within a below-elbow\napparatus. The underactuated mechanism consists of a spiral single-tendon\nrouting embedded in a rigid forearm brace and terminated at the hand and\nupper-forearm. A spool with an internal releasable-ratchet mechanism allows the\nuser to manually retract the tendon and rotate the hand to counteract\ninvoluntary pronation synergies due to stroke. We performed device\ncharacterization with two healthy subjects, and conducted a feasibility test of\nthe forearm mechanism in maintaining a neutral hand position with a single\nchronic stroke subject having no volitional supination capacity. Our\npreliminary assessment on an impaired subject suggests comparative performance\nin supination assistance between our implementation and a commercial passive\nsplint, and shows promise in improving capabilities of existing robotic\nexoskeletons for stroke.",
    "descriptor": "\nComments: 7 pages, 9 figures. Submitted to ICRA 2022\n",
    "authors": [
      "Ava Chen",
      "Lauren Winterbottom",
      "Katherine O'Reilly",
      "Sangwoo Park",
      "Dawn Nilsen",
      "Joel Stein",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02274"
  },
  {
    "id": "arXiv:2110.02276",
    "title": "SeanNet: Semantic Understanding Network for Localization Under Object  Dynamics",
    "abstract": "We aim for domestic robots to operate indoor for long-term service. Under the\nobject-level scene dynamics induced by human daily activities, a robot needs to\nrobustly localize itself in the environment subject to scene uncertainties.\nPrevious works have addressed visual-based localization in static environments,\nyet the object-level scene dynamics challenge existing methods on long-term\ndeployment of the robot. This paper proposes SEmantic understANding Network\n(SeanNet) that enables robots to measure the similarity between two scenes on\nboth visual and semantic aspects. We further develop a similarity-based\nlocalization method based on SeanNet for monitoring the progress of visual\nnavigation tasks. In our experiments, we benchmarked SeanNet against baselines\nmethods on scene similarity measures, as well as visual navigation performance\nonce integrated with a visual navigator. We demonstrate that SeanNet\noutperforms all baseline methods, by robustly localizing the robot under object\ndynamics, thus reliably informing visual navigation about the task status.",
    "descriptor": "",
    "authors": [
      "Xiao Li",
      "Yidong Du",
      "Zhen Zeng",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02276"
  },
  {
    "id": "arXiv:2110.02277",
    "title": "Scaling up instance annotation via label propagation",
    "abstract": "Manually annotating object segmentation masks is very time-consuming. While\ninteractive segmentation methods offer a more efficient alternative, they\nbecome unaffordable at a large scale because the cost grows linearly with the\nnumber of annotated masks. In this paper, we propose a highly efficient\nannotation scheme for building large datasets with object segmentation masks.\nAt a large scale, images contain many object instances with similar appearance.\nWe exploit these similarities by using hierarchical clustering on mask\npredictions made by a segmentation model. We propose a scheme that efficiently\nsearches through the hierarchy of clusters and selects which clusters to\nannotate. Humans manually verify only a few masks per cluster, and the labels\nare propagated to the whole cluster. Through a large-scale experiment to\npopulate 1M unlabeled images with object segmentation masks for 80 object\nclasses, we show that (1) we obtain 1M object segmentation masks with an total\nannotation time of only 290 hours; (2) we reduce annotation time by 76x\ncompared to manual annotation; (3) the segmentation quality of our masks is on\npar with those from manually annotated datasets. Code, data, and models are\navailable online.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Dim P. Papadopoulos",
      "Ethan Weber",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02277"
  },
  {
    "id": "arXiv:2110.02280",
    "title": "Distributed Privacy-Preserving Electric Vehicle Charging Control Based  on Secret Sharing",
    "abstract": "Cooperative electric vehicle (EV) charging control has emerged as a key\ncomponent in grid-edge resource (GER) management. However, customers' privacy\nremains a major barrier to large-scale implementation of EV charging control.\nIn this paper, we develop a distributed privacy-preserving EV charging control\nprotocol based on secret sharing (SS) that 1) achieves scalability over EV\npopulation size; 2) enjoys higher computation efficiency compared to\nhomomorphic encryption (HE) based methods; and 3) secures the privacy of the\nparticipating EVs against honest-but-curious adversaries and external\neavesdroppers. The cooperative EV charging control is formulated to achieve\novernight valley-filling and framed into the projected gradient algorithm (PGA)\nstructure as a distributed optimization problem. SS is integrated into PGA to\nachieve secure updates of both primal and dual variables. Theoretical security\nanalyses and simulations in a residential area are conducted to prove the\nprivacy preservation guarantee as well as the efficacy and efficiency of the\nproposed privacy preservation method. Broadly, the proposed method can be\nreadily extended to various GER control applications.",
    "descriptor": "",
    "authors": [
      "Xiang Huo",
      "Mingxi Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02280"
  },
  {
    "id": "arXiv:2110.02281",
    "title": "A Rate Splitting Strategy for Uplink CR-NOMA Systems",
    "abstract": "In uplink cognitive radio inspired non-orthogonal multiple access (CR-NOMA)\nsystems, the power control and successive interference cancellation (SIC) are\ncollaboratively designed to enhance the outage performance. However, existing\nPC and SIC schemes lack the capability for achieving the capacity region of\nuplink multiple access channels due to the inefficient power usage associated\nwith the SIC, which restricts the outage performance of system. In this paper,\nwe propose a rate splitting (RS) strategy for the uplink CR-NOMA system by\nutilizing the transmit power of the secondary user more efficiently along with\nthe RS-determined SIC decoding order, which achieves the allowed best outage\nperformance among the existing SIC schemes.",
    "descriptor": "\nComments: 13 pages, 5 figures, submitted to IEEE Journal\n",
    "authors": [
      "Hongwu Liu",
      "Zhiquan Bai",
      "Hongjiang Lei",
      "Gaofeng Pan",
      "Kyeong Jin Kim",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02281"
  },
  {
    "id": "arXiv:2110.02283",
    "title": "Co-training an Unsupervised Constituency Parser with Weak Supervision",
    "abstract": "We introduce a method for unsupervised parsing that relies on bootstrapping\nclassifiers to identify if a node dominates a specific span in a sentence.\nThere are two types of classifiers, an inside classifier that acts on a span,\nand an outside classifier that acts on everything outside of a given span.\nThrough self-training and co-training with the two classifiers, we show that\nthe interplay between them helps improve the accuracy of both, and as a result,\neffectively parse. A seed bootstrapping technique prepares the data to train\nthese classifiers. Our analyses further validate that such an approach in\nconjunction with weak supervision using prior branching knowledge of a known\nlanguage (left/right-branching) and minimal heuristics injects strong inductive\nbias into the parser, achieving 63.1 F$_1$ on the English (PTB) test set. In\naddition, we show the effectiveness of our architecture by evaluating on\ntreebanks for Chinese (CTB) and Japanese (KTB) and achieve new state-of-the-art\nresults.\\footnote{For code or data, please contact the authors.}",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Nickil Maveli",
      "Shay B. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02283"
  },
  {
    "id": "arXiv:2110.02284",
    "title": "An explorative study on how human-robot interaction is taken into  account by robot developers in praxis",
    "abstract": "How is human-robot interaction considered within the development of new\nrobotic systems by practitioners? This study sets out to inquire, whether the\ndevelopment teams of robotic products have been considering human factor\nmethods in their design and implementation process. We were specifically\ninterested in the non-verbal communication methods they were aiming to\nimplement, and how they have approached the design process for these. Although\nvaluable insights on tasks and communication needs during the different phases\nof robot operation could be gathered, the results of this study indicate, that\nthe perspective of the human user or bystander is very often neglected and that\nknowledge on methods for engineering human-robot interaction is missing. The\nstudy was conducted with eleven development teams consisting of robot\nmanufacturers and students within a robot building course representing overall\n68 individual participants.",
    "descriptor": "\nComments: HRI '21 Workshop : Exploring Applications for Autonomous Non-Verbal Human-Robot Interactions at the ACM/IEEE International Conference on Human Robot Interactions\n",
    "authors": [
      "Doris Aschenbrenner",
      "Danielle van Tol",
      "Pak Long Cheung",
      "Zoltan Rusak"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02284"
  },
  {
    "id": "arXiv:2110.02288",
    "title": "Evolutionary Algorithms for Solving Unconstrained, Constrained and  Multi-objective Noisy Combinatorial Optimisation Problems",
    "abstract": "We present an empirical study of a range of evolutionary algorithms applied\nto various noisy combinatorial optimisation problems. There are three sets of\nexperiments. The first looks at several toy problems, such as OneMax and other\nlinear problems. We find that UMDA and the Paired-Crossover Evolutionary\nAlgorithm (PCEA) are the only ones able to cope robustly with noise, within a\nreasonable fixed time budget. In the second stage, UMDA and PCEA are then\ntested on more complex noisy problems: SubsetSum, Knapsack and SetCover. Both\nperform well under increasing levels of noise, with UMDA being the better of\nthe two. In the third stage, we consider two noisy multi-objective problems\n(CountingOnesCountingZeros and a multi-objective formulation of SetCover). We\ncompare several adaptations of UMDA for multi-objective problems with the\nSimple Evolutionary Multi-objective Optimiser (SEMO) and NSGA-II. We conclude\nthat UMDA, and its variants, can be highly effective on a variety of noisy\ncombinatorial optimisation, outperforming many other evolutionary algorithms.",
    "descriptor": "\nComments: An extended version of the version already published in Proceedings of the Genetic and Evolutionary Computation Conference Companion 2019\n",
    "authors": [
      "Aishwaryaprajna",
      "Jonathan E. Rowe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.02288"
  },
  {
    "id": "arXiv:2110.02291",
    "title": "FedDQ: Communication-Efficient Federated Learning with Descending  Quantization",
    "abstract": "Federated learning (FL) is an emerging privacy-preserving distributed\nlearning scheme. Due to the large model size and frequent model aggregation, FL\nsuffers from critical communication bottleneck. Many techniques have been\nproposed to reduce the communication volume, including model compression and\nquantization, where quantization with increasing number of levels has been\nproposed. This paper proposes an opposite approach to do adaptive quantization.\nFirst, we present the drawback of ascending-trend quantization based on the\ncharacteristics of training. Second, we formulate the quantization optimization\nproblem and theoretical analysis shows that quantization with decreasing number\nof levels is preferred. Then we propose two strategies to guide the adaptive\nquantization process by using the change in training loss and the range of\nmodel update. Experimental results on three sets of benchmarks show that\ndescending-trend quantization not only saves more communication bits but also\nhelps FL converge faster, when compares with current ascending-trend\nquantization.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Linping Qu",
      "Shenghui Song",
      "Chi-Ying Tsui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02291"
  },
  {
    "id": "arXiv:2110.02300",
    "title": "Complexity of Traveling Tournament Problem with Trip Length More Than  Three",
    "abstract": "The Traveling Tournament Problem is a sports-scheduling problem where the\ngoal is to minimize the total travel distance of teams playing a double\nround-robin tournament. The constraint 'k' is an imposed upper bound on the\nnumber of consecutive home or away matches. It is known that TTP is NP-Hard for\nk=3 as well as k=infinity. In this work, the general case has been settled by\nproving that TTP-k is NP-Complete for any fixed k>3.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Diptendu Chatterjee"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.02300"
  },
  {
    "id": "arXiv:2110.02304",
    "title": "You Only Evaluate Once: a Simple Baseline Algorithm for Offline RL",
    "abstract": "The goal of offline reinforcement learning (RL) is to find an optimal policy\ngiven prerecorded trajectories. Many current approaches customize existing\noff-policy RL algorithms, especially actor-critic algorithms in which policy\nevaluation and improvement are iterated. However, the convergence of such\napproaches is not guaranteed due to the use of complex non-linear function\napproximation and an intertwined optimization process. By contrast, we propose\na simple baseline algorithm for offline RL that only performs the policy\nevaluation step once so that the algorithm does not require complex\nstabilization schemes. Since the proposed algorithm is not likely to converge\nto an optimal policy, it is an appropriate baseline for actor-critic algorithms\nthat ought to be outperformed if there is indeed value in iterative\noptimization in the offline setting. Surprisingly, we empirically find that the\nproposed algorithm exhibits competitive and sometimes even state-of-the-art\nperformance in a subset of the D4RL offline RL benchmark. This result suggests\nthat future work is needed to fully exploit the potential advantages of\niterative optimization in order to justify the reduced stability of such\nmethods.",
    "descriptor": "\nComments: In proceedings of 5th Annual Conference on Robot Learning (CoRL) 2021\n",
    "authors": [
      "Wonjoon Goo",
      "Scott Niekum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02304"
  },
  {
    "id": "arXiv:2110.02307",
    "title": "Coarsening Optimization for Differentiable Programming",
    "abstract": "This paper presents a novel optimization for differentiable programming named\ncoarsening optimization. It offers a systematic way to synergize symbolic\ndifferentiation and algorithmic differentiation (AD). Through it, the\ngranularity of the computations differentiated by each step in AD can become\nmuch larger than a single operation, and hence lead to much reduced runtime\ncomputations and data allocations in AD. To circumvent the difficulties that\ncontrol flow creates to symbolic differentiation in coarsening, this work\nintroduces phi-calculus, a novel method to allow symbolic reasoning and\ndifferentiation of computations that involve branches and loops. It further\navoids \"expression swell\" in symbolic differentiation and balance reuse and\ncoarsening through the design of reuse-centric segment of interest\nidentification. Experiments on a collection of real-world applications show\nthat coarsening optimization is effective in speeding up AD, producing several\ntimes to two orders of magnitude speedups.",
    "descriptor": "\nComments: This is the preprint of a paper to be published at OOPSLA'2021\n",
    "authors": [
      "Xipeng Shen",
      "Guoqiang Zhang",
      "Irene Dea",
      "Samantha Andow",
      "Emilio Arroyo-Fang",
      "Neal Gafter",
      "Johann George",
      "Melissa Grueter",
      "Erik Meijer",
      "Steffi Stumpos",
      "Alanna Tempest",
      "Christy Warden",
      "Shannon Yang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02307"
  },
  {
    "id": "arXiv:2110.02311",
    "title": "COVID-19 India Dataset: Parsing Detailed COVID-19 Data in Daily Health  Bulletins from States in India",
    "abstract": "While India remains one of the hotspots of the COVID-19 pandemic, data about\nthe pandemic from the country has proved to be largely inaccessible for use at\nscale. Much of the data exists in an unstructured form on the web, and limited\naspects of such data are available through public APIs maintained manually\nthrough volunteer efforts. This has proved to be difficult both in terms of\nease of access to detailed data as well as with regards to the maintenance of\nmanual data-keeping over time. This paper reports on a recently launched\nproject aimed at automating the extraction of such data from public health\nbulletins with the help of a combination of classical PDF parsers as well as\nstate-of-the-art ML-based documents extraction APIs. In this paper, we will\ndescribe the automated data-extraction technique, the nature of the generated\ndata, and exciting avenues of ongoing work.",
    "descriptor": "\nComments: Project page: ibm.biz/covid-data-india\n",
    "authors": [
      "Mayank Agarwal",
      "Tathagata Chakraborti",
      "Sachin Grover"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02311"
  },
  {
    "id": "arXiv:2110.02313",
    "title": "Phoebe: A Learning-based Checkpoint Optimizer",
    "abstract": "Easy-to-use programming interfaces paired with cloud-scale processing engines\nhave enabled big data system users to author arbitrarily complex analytical\njobs over massive volumes of data. However, as the complexity and scale of\nanalytical jobs increase, they encounter a number of unforeseen problems,\nhotspots with large intermediate data on temporary storage, longer job recovery\ntime after failures, and worse query optimizer estimates being examples of\nissues that we are facing at Microsoft.\nTo address these issues, we propose Phoebe, an efficient learning-based\ncheckpoint optimizer. Given a set of constraints and an objective function at\ncompile-time, Phoebe is able to determine the decomposition of job plans, and\nthe optimal set of checkpoints to preserve their outputs to durable global\nstorage. Phoebe consists of three machine learning predictors and one\noptimization module. For each stage of a job, Phoebe makes accurate predictions\nfor: (1) the execution time, (2) the output size, and (3) the start/end time\ntaking into account the inter-stage dependencies. Using these predictions, we\nformulate checkpoint optimization as an integer programming problem and propose\na scalable heuristic algorithm that meets the latency requirement of the\nproduction environment.\nWe demonstrate the effectiveness of Phoebe in production workloads, and show\nthat we can free the temporary storage on hotspots by more than 70% and restart\nfailed jobs 68% faster on average with minimum performance impact. Phoebe also\nillustrates that adding multiple sets of checkpoints is not cost-efficient,\nwhich dramatically reduces the complexity of the optimization.",
    "descriptor": "",
    "authors": [
      "Yiwen Zhu",
      "Matteo Interlandi",
      "Abhishek Roy",
      "Krishnadhan Das",
      "Hiren Patel",
      "Malay Bag",
      "Hitesh Sharma",
      "Alekh Jindal"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02313"
  },
  {
    "id": "arXiv:2110.02316",
    "title": "Prediction of the Facial Growth Direction is Challenging",
    "abstract": "Facial dysmorphology or malocclusion is frequently associated with abnormal\ngrowth of the face. The ability to predict facial growth (FG) direction would\nallow clinicians to prepare individualized therapy to increase the chance for\nsuccessful treatment. Prediction of FG direction is a novel problem in the\nmachine learning (ML) domain. In this paper, we perform feature selection and\npoint the attribute that plays a central role in the abovementioned problem.\nThen we successfully apply data augmentation (DA) methods and improve the\npreviously reported classification accuracy by 2.81%. Finally, we present the\nresults of two experienced clinicians that were asked to solve a similar task\nto ours and show how tough is solving this problem for human experts.",
    "descriptor": "",
    "authors": [
      "Stanis\u0142aw Ka\u017amierczak",
      "Zofia Juszka",
      "Vaska Vandevska-Radunovic",
      "Thomas JJ Maal",
      "Piotr Fudalej",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02316"
  },
  {
    "id": "arXiv:2110.02325",
    "title": "Unifying AI Algorithms with Probabilistic Programming using Implicitly  Defined Representations",
    "abstract": "We introduce Scruff, a new framework for developing AI systems using\nprobabilistic programming. Scruff enables a variety of representations to be\nincluded, such as code with stochastic choices, neural networks, differential\nequations, and constraint systems. These representations are defined implicitly\nusing a set of standardized operations that can be performed on them.\nGeneral-purpose algorithms are then implemented using these operations,\nenabling generalization across different representations. Zero, one, or more\noperation implementations can be provided for any given representation, giving\nalgorithms the flexibility to use the most appropriate available\nimplementations for their purposes and enabling representations to be used in\nways that suit their capabilities. In this paper, we explain the general\napproach of implicitly defined representations and provide a variety of\nexamples of representations at varying degrees of abstraction. We also show how\na relatively small set of operations can serve to unify a variety of AI\nalgorithms. Finally, we discuss how algorithms can use policies to choose which\noperation implementations to use during execution.",
    "descriptor": "",
    "authors": [
      "Avi Pfeffer",
      "Michael Harradon",
      "Joseph Campolongo",
      "Sanja Cvijic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02325"
  },
  {
    "id": "arXiv:2110.02329",
    "title": "Task-aware Privacy Preservation for Multi-dimensional Data",
    "abstract": "Local differential privacy (LDP), a state-of-the-art technique for privacy\npreservation, has been successfully deployed in a few real-world applications.\nIn the future, LDP can be adopted to anonymize richer user data attributes that\nwill be input to more sophisticated machine learning (ML) tasks. However,\ntoday's LDP approaches are largely task-agnostic and often lead to sub-optimal\nperformance -- they will simply inject noise to all data attributes according\nto a given privacy budget, regardless of what features are most relevant for an\nultimate task. In this paper, we address how to significantly improve the\nultimate task performance for multi-dimensional user data by considering a\ntask-aware privacy preservation problem. The key idea is to use an\nencoder-decoder framework to learn (and anonymize) a task-relevant latent\nrepresentation of user data, which gives an analytical near-optimal solution\nfor a linear setting with mean-squared error (MSE) task loss. We also provide\nan approximate solution through a learning algorithm for general nonlinear\ncases. Extensive experiments demonstrate that our task-aware approach\nsignificantly improves ultimate task accuracy compared to a standard benchmark\nLDP approach while guaranteeing the same level of privacy.",
    "descriptor": "",
    "authors": [
      "Jiangnan Cheng",
      "Ao Tang",
      "Sandeep Chinchali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02329"
  },
  {
    "id": "arXiv:2110.02330",
    "title": "Shape-aware Multi-Person Pose Estimation from Multi-View Images",
    "abstract": "In this paper we contribute a simple yet effective approach for estimating 3D\nposes of multiple people from multi-view images. Our proposed coarse-to-fine\npipeline first aggregates noisy 2D observations from multiple camera views into\n3D space and then associates them into individual instances based on a\nconfidence-aware majority voting technique. The final pose estimates are\nattained from a novel optimization scheme which links high-confidence\nmulti-view 2D observations and 3D joint candidates. Moreover, a statistical\nparametric body model such as SMPL is leveraged as a regularizing prior for\nthese 3D joint candidates. Specifically, both 3D poses and SMPL parameters are\noptimized jointly in an alternating fashion. Here the parametric models help in\ncorrecting implausible 3D pose estimates and filling in missing joint\ndetections while updated 3D poses in turn guide obtaining better SMPL\nestimations. By linking 2D and 3D observations, our method is both accurate and\ngeneralizes to different data sources because it better decouples the final 3D\npose from the inter-person constellation and is more robust to noisy 2D\ndetections. We systematically evaluate our method on public datasets and\nachieve state-of-the-art performance. The code and video will be available on\nthe project page: https://ait.ethz.ch/projects/2021/multi-human-pose/.",
    "descriptor": "\nComments: ICCV'2021; Video: this https URL | Project page: this https URL\n",
    "authors": [
      "Zijian Dong",
      "Jie Song",
      "Xu Chen",
      "Chen Guo",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02330"
  },
  {
    "id": "arXiv:2110.02331",
    "title": "A Formal Characterization of Black-Box System Safety Performance with  Scenario Sampling",
    "abstract": "A typical scenario-based evaluation framework seeks to characterize a\nblack-box system's safety performance (e.g., failure rate) through repeatedly\nsampling initialization configurations (scenario sampling) and executing a\ncertain test policy for scenario propagation (scenario testing) with the\nblack-box system involved as the test subject. In this letter, we first present\na novel safety evaluation criterion that seeks to characterize the actual\noperational domain within which the test subject would remain safe indefinitely\nwith high probability. By formulating the black-box testing scenario as a\ndynamic system, we show that the presented problem is equivalent to finding a\ncertain \"almost\" robustly forward invariant set for the given system. Second,\nfor an arbitrary scenario testing strategy, we propose a scenario sampling\nalgorithm that is provably asymptotically optimal in obtaining the safe\ninvariant set with arbitrarily high accuracy. Moreover, as one considers\ndifferent testing strategies (e.g., biased sampling of safety-critical cases),\nwe show that the proposed algorithm still converges to the unbiased\napproximation of the safety characterization outcome if the scenario testing\nsatisfies a certain condition. Finally, the effectiveness of the presented\nscenario sampling algorithms and various theoretical properties are\ndemonstrated in a case study of the safety evaluation of a control barrier\nfunction-based mobile robot collision avoidance system.",
    "descriptor": "\nComments: A shorter version of this manuscript has been accepted to be published at IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Bowen Weng",
      "Linda Capito",
      "Umit Ozguner",
      "Keith Redmill"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02331"
  },
  {
    "id": "arXiv:2110.02332",
    "title": "OTTR: Off-Road Trajectory Tracking using Reinforcement Learning",
    "abstract": "In this work, we present a novel Reinforcement Learning (RL) algorithm for\nthe off-road trajectory tracking problem. Off-road environments involve varying\nterrain types and elevations, and it is difficult to model the interaction\ndynamics of specific off-road vehicles with such a diverse and complex\nenvironment. Standard RL policies trained on a simulator will fail to operate\nin such challenging real-world settings. Instead of using a naive domain\nrandomization approach, we propose an innovative supervised-learning based\napproach for overcoming the sim-to-real gap problem. Our approach efficiently\nexploits the limited real-world data available to adapt the baseline RL policy\nobtained using a simple kinematics simulator. This avoids the need for modeling\nthe diverse and complex interaction of the vehicle with off-road environments.\nWe evaluate the performance of the proposed algorithm using two different\noff-road vehicles, Warthog and Moose. Compared to the standard ILQR approach,\nour proposed approach achieves a 30% and 50% reduction in cross track error in\nWarthog and Moose, respectively, by utilizing only 30 minutes of real-world\ndriving data.",
    "descriptor": "",
    "authors": [
      "Akhil Nagariya",
      "Dileep Kalathil",
      "Srikanth Saripalli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02332"
  },
  {
    "id": "arXiv:2110.02333",
    "title": "On the Impact of Stable Ranks in Deep Nets",
    "abstract": "A recent line of work has established intriguing connections between the\ngeneralization/compression properties of a deep neural network (DNN) model and\nthe so-called layer weights' stable ranks. Intuitively, the latter are\nindicators of the effective number of parameters in the net. In this work, we\naddress some natural questions regarding the space of DNNs conditioned on the\nlayers' stable rank, where we study feed-forward dynamics, initialization,\ntraining and expressivity. To this end, we first propose a random DNN model\nwith a new sampling scheme based on stable rank. Then, we show how feed-forward\nmaps are affected by the constraint and how training evolves in the\noverparametrized regime (via Neural Tangent Kernels). Our results imply that\nstable ranks appear layerwise essentially as linear factors whose effect\naccumulates exponentially depthwise. Moreover, we provide empirical analysis\nsuggesting that stable rank initialization alone can lead to convergence speed\nups.",
    "descriptor": "\nComments: 24 pages, 8 figures, comments welcome!\n",
    "authors": [
      "Bogdan Georgiev",
      "Lukas Franken",
      "Mayukh Mukherjee",
      "Georgios Arvanitidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.02333"
  },
  {
    "id": "arXiv:2110.02334",
    "title": "Exploring Conditional Text Generation for Aspect-Based Sentiment  Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) is an NLP task that entails processing\nuser-generated reviews to determine (i) the target being evaluated, (ii) the\naspect category to which it belongs, and (iii) the sentiment expressed towards\nthe target and aspect pair. In this article, we propose transforming ABSA into\nan abstract summary-like conditional text generation task that uses targets,\naspects, and polarities to generate auxiliary statements. To demonstrate the\nefficacy of our task formulation and a proposed system, we fine-tune a\npre-trained model for conditional text generation tasks to get new\nstate-of-the-art results on a few restaurant domains and urban neighborhoods\ndomain benchmark datasets.",
    "descriptor": "\nComments: This paper is accepted at the PACLIC35 conference on September 30, 2021. It will be published in November, 2021\n",
    "authors": [
      "Siva Uday Sampreeth Chebolu",
      "Franck Dernoncourt",
      "Nedim Lipka",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02334"
  },
  {
    "id": "arXiv:2110.02341",
    "title": "How to Query An Oracle? Efficient Strategies to Label Data",
    "abstract": "We consider the basic problem of querying an expert oracle for labeling a\ndataset in machine learning. This is typically an expensive and time consuming\nprocess and therefore, we seek ways to do so efficiently. The conventional\napproach involves comparing each sample with (the representative of) each class\nto find a match. In a setting with $N$ equally likely classes, this involves\n$N/2$ pairwise comparisons (queries per sample) on average. We consider a\n$k$-ary query scheme with $k\\ge 2$ samples in a query that identifies\n(dis)similar items in the set while effectively exploiting the associated\ntransitive relations. We present a randomized batch algorithm that operates on\na round-by-round basis to label the samples and achieves a query rate of\n$O(\\frac{N}{k^2})$. In addition, we present an adaptive greedy query scheme,\nwhich achieves an average rate of $\\approx 0.2N$ queries per sample with\ntriplet queries. For the proposed algorithms, we investigate the query rate\nperformance analytically and with simulations. Empirical studies suggest that\neach triplet query takes an expert at most 50\\% more time compared with a\npairwise query, indicating the effectiveness of the proposed $k$-ary query\nschemes. We generalize the analyses to nonuniform class distributions when\npossible.",
    "descriptor": "\nComments: To Appear in IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Farshad Lahouti",
      "Victoria Kostina",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02341"
  },
  {
    "id": "arXiv:2110.02344",
    "title": "HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and  Adaptive Sampling",
    "abstract": "Modeling multi-modal high-level intent is important for ensuring diversity in\ntrajectory prediction. Existing approaches explore the discrete nature of human\nintent before predicting continuous trajectories, to improve accuracy and\nsupport explainability. However, these approaches often assume the intent to\nremain fixed over the prediction horizon, which is problematic in practice,\nespecially over longer horizons. To overcome this limitation, we introduce\nHYPER, a general and expressive hybrid prediction framework that models\nevolving human intent. By modeling traffic agents as a hybrid\ndiscrete-continuous system, our approach is capable of predicting discrete\nintent changes over time. We learn the probabilistic hybrid model via a maximum\nlikelihood estimation problem and leverage neural proposal distributions to\nsample adaptively from the exponentially growing discrete space. The overall\napproach affords a better trade-off between accuracy and coverage. We train and\nvalidate our model on the Argoverse dataset, and demonstrate its effectiveness\nthrough comprehensive ablation studies and comparisons with state-of-the-art\nmodels.",
    "descriptor": "\nComments: 12 pages, 10 figures, 4 tables\n",
    "authors": [
      "Xin Huang",
      "Guy Rosman",
      "Igor Gilitschenski",
      "Ashkan Jasour",
      "Stephen G. McGill",
      "John J. Leonard",
      "Brian C. Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02344"
  },
  {
    "id": "arXiv:2110.02348",
    "title": "Anisotropic Raviart--Thomas interpolation error estimates using a new  geometric parameter",
    "abstract": "This paper presents delicate Raviart--Thomas interpolation error estimates on\nanisotropic meshes. The novel aspect of our theory is the introduction of a new\ngeometric parameter of simplices, and we show the stability of global\nRaviart--Thomas interpolation in terms of the geometric parameter. We also\ninclude corrections to an error in \"General theory of interpolation error\nestimates on anisotropic meshes\" (Japan Journal of Industrial and Applied\nMathematics, 38 (2021) 163-191), in which Theorem 3 was incorrect.",
    "descriptor": "\nComments: 28 pages. arXiv admin note: text overlap with arXiv:2106.03339\n",
    "authors": [
      "Hiroki Ishizaka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02348"
  },
  {
    "id": "arXiv:2110.02352",
    "title": "Reconstruction of Sets of Strings from Prefix/Suffix Compositions",
    "abstract": "The problem of reconstructing strings from substring information has found\nmany applications due to its importance in genomic data sequencing and DNA- and\npolymer-based data storage. One practically important and challenging paradigm\nrequires reconstructing mixtures of strings based on the union of compositions\nof their prefixes and suffixes, generated by mass spectrometry devices. We\ndescribe new coding methods that allow for unique joint reconstruction of\nsubsets of strings selected from a code and provide upper and lower bounds on\nthe asymptotic rate of the underlying codebooks. Our code constructions combine\nproperties of binary Bh and Dyck strings and that can be extended to\naccommodate missing substrings in the pool. As auxiliary results, we obtain the\nfirst known bounds on binary Bh sequences for arbitrary even parameters h, and\nalso describe various error models inherent to mass spectrometry analysis. This\npaper contains a correction of the prior work by the authors, published in\n[24]. In particular, the bounds on the prefix codes are now corrected.",
    "descriptor": "",
    "authors": [
      "Ryan Gabrys",
      "Srilakshmi Pattabiraman",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02352"
  },
  {
    "id": "arXiv:2110.02355",
    "title": "Robustness and sample complexity of model-based MARL for general-sum  Markov games",
    "abstract": "Multi-agent reinfocement learning (MARL) is often modeled using the framework\nof Markov games (also called stochastic games or dynamic games). Most of the\nexisting literature on MARL concentrates on zero-sum Markov games but is not\napplicable to general-sum Markov games. It is known that the best-response\ndynamics in general-sum Markov games are not a contraction. Therefore,\ndifferent equilibrium in general-sum Markov games can have different values.\nMoreover, the Q-function is not sufficient to completely characterize the\nequilibrium. Given these challenges, model based learning is an attractive\napproach for MARL in general-sum Markov games. In this paper, we investigate\nthe fundamental question of \\emph{sample complexity} for model-based MARL\nalgorithms in general-sum Markov games and show that\n$\\tilde{\\mathcal{O}}(|\\mathcal{S}|\\,|\\mathcal{A}| (1-\\gamma)^{-2} \\alpha^{-2})$\nsamples are sufficient to obtain a $\\alpha$-approximate Markov perfect\nequilibrium with high probability, where $\\mathcal{S}$ is the state space,\n$\\mathcal{A}$ is the joint action space of all players, and $\\gamma$ is the\ndiscount factor, and the $\\tilde{\\mathcal{O}}(\\cdot)$ notation hides\nlogarithmic terms. To obtain these results, we study the robustness of Markov\nperfect equilibrium to model approximations. We show that the Markov perfect\nequilibrium of an approximate (or perturbed) game is always an approximate\nMarkov perfect equilibrium of the original game and provide explicit bounds on\nthe approximation error. We illustrate the results via a numerical example.",
    "descriptor": "",
    "authors": [
      "Jayakumar Subramanian",
      "Amit Sinha",
      "Aditya Mahajan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02355"
  },
  {
    "id": "arXiv:2110.02364",
    "title": "Adversarial defenses via a mixture of generators",
    "abstract": "In spite of the enormous success of neural networks, adversarial examples\nremain a relatively weakly understood feature of deep learning systems. There\nis a considerable effort in both building more powerful adversarial attacks and\ndesigning methods to counter the effects of adversarial examples. We propose a\nmethod to transform the adversarial input data through a mixture of generators\nin order to recover the correct class obfuscated by the adversarial attack. A\ncanonical set of images is used to generate adversarial examples through\npotentially multiple attacks. Such transformed images are processed by a set of\ngenerators, which are trained adversarially as a whole to compete in inverting\nthe initial transformations. To our knowledge, this is the first use of a\nmixture-based adversarially trained system as a defense mechanism. We show that\nit is possible to train such a system without supervision, simultaneously on\nmultiple adversarial attacks. Our system is able to recover class information\nfor previously-unseen examples with neither attack nor data labels on the MNIST\ndataset. The results demonstrate that this multi-attack approach is competitive\nwith adversarial defenses tested in single-attack settings.",
    "descriptor": "",
    "authors": [
      "Maciej \u017belaszczyk",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02364"
  },
  {
    "id": "arXiv:2110.02369",
    "title": "EntQA: Entity Linking as Question Answering",
    "abstract": "A conventional approach to entity linking is to first find mentions in a\ngiven document and then infer their underlying entities in the knowledge base.\nA well-known limitation of this approach is that it requires finding mentions\nwithout knowing their entities, which is unnatural and difficult. We present a\nnew model that does not suffer from this limitation called EntQA, which stands\nfor Entity linking as Question Answering. EntQA first proposes candidate\nentities with a fast retrieval module, and then scrutinizes the document to\nfind mentions of each candidate with a powerful reader module. Our approach\ncombines progress in entity linking with that in open-domain question answering\nand capitalizes on pretrained models for dense entity retrieval and reading\ncomprehension. Unlike in previous works, we do not rely on a mention-candidates\ndictionary or large-scale weak supervision. EntQA achieves strong results on\nthe GERBIL benchmarking platform.",
    "descriptor": "",
    "authors": [
      "Wenzheng Zhang",
      "Wenyue Hua",
      "Karl Stratos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02369"
  },
  {
    "id": "arXiv:2110.02370",
    "title": "Leveraging the Inductive Bias of Large Language Models for Abstract  Textual Reasoning",
    "abstract": "Large natural language models (such as GPT-3 or T5) demonstrate impressive\nabilities across a range of general NLP tasks. Here, we show that the knowledge\nembedded in such models provides a useful inductive bias, not just on\ntraditional NLP tasks, but also in the nontraditional task of training a\nsymbolic reasoning engine. We observe that these engines learn quickly and\ngeneralize in a natural way that reflects human intuition. For example,\ntraining such a system to model block-stacking might naturally generalize to\nstacking other types of objects because of structure in the real world that has\nbeen partially captured by the language describing it. We study several\nabstract textual reasoning tasks, such as object manipulation and navigation,\nand demonstrate multiple types of generalization to novel scenarios and the\nsymbols that comprise them. We also demonstrate the surprising utility of\n\\textit{compositional learning}, where a learner dedicated to mastering a\ncomplicated task gains an advantage by training on relevant simpler tasks\ninstead of jumping straight to the complicated task.",
    "descriptor": "",
    "authors": [
      "Christopher Michael Rytting",
      "David Wingate"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02370"
  },
  {
    "id": "arXiv:2110.02372",
    "title": "NOMA-Aided Joint Radar and Multicast-Unicast Communication Systems",
    "abstract": "The novel concept of non-orthogonal multiple access (NOMA) aided joint radar\nand multicast-unicast communication (Rad-MU-Com) is investigated. Employing the\nsame spectrum resource, a multi-input-multi-output (MIMO) dual-functional\nradar-communication (DFRC) base station detects the radar-centric users\n(R-user), while transmitting mixed multicast-unicast messages both to the\nR-user and to the communication-centric user (C-user). In particular, the\nmulticast information is intended for both the R- and C-users, whereas the\nunicast information is only intended for the C-user. More explicitly, NOMA is\nemployed to facilitate this double spectrum sharing, where the multicast and\nunicast signals are superimposed in the power domain and the superimposed\ncommunication signals are also exploited as radar probing waveforms. First, a\nbeamformer-based NOMA-aided joint Rad-MU-Com framework is proposed for the\nsystem having a single R-user and a single C-user. Based on this framework, the\nunicast rate maximization problem is formulated by optimizing the beamformers\nemployed, while satisfying the rate requirement of multicast and the predefined\naccuracy of the radar beam pattern. The resultant non-convex optimization\nproblem is solved by a penalty-based iterative algorithm to find a high-quality\nnear-optimal solution. Next, the system is extended to the scenario of multiple\npairs of R- and C-users, where a cluster-based NOMA-aided joint Rad-MU-Com\nframework is proposed. A joint beamformer design and power allocation\noptimization problem is formulated for the maximization of the sum of the\nunicast rate at each C-user, subject to the constraints on both the minimum\nmulticast rate for each R&C pair and on accuracy of the radar beam pattern for\ndetecting multiple R-users. The resultant joint optimization problem is\nefficiently solved by another penalty-based iterative algorithm developed.",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Xidong Mu",
      "Yuanwei Liu",
      "Li Guo",
      "Jiaru Lin",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02372"
  },
  {
    "id": "arXiv:2110.02374",
    "title": "Simultaneously Transmitting and Reflecting (STAR)-RISs: A Coupled  Phase-Shift Model",
    "abstract": "A simultaneously transmitting and reflecting reconfigurable intelligent\nsurface (STAR-RIS) aided communication system is investigated, where an access\npoint sends information to two users located on each side of the STAR-RIS.\nDifferent from current works assuming that the phase-shift coefficients for\ntransmission and reflection can be independently adjusted, which is non-trivial\nto realize for purely passive STAR-RISs, a coupled transmission and reflection\nphase-shift model is considered. Based on this model, a power consumption\nminimization problem is formulated for both non-orthogonal multiple access\n(NOMA) and orthogonal multiple access (OMA). In particular, the amplitude and\nphase-shift coefficients for transmission and reflection are jointly optimized,\nsubject to the rate constraints of the users. To solve this non-convex problem,\nan efficient element-wise alternating optimization algorithm is developed to\nfind a high-quality suboptimal solution, whose complexity scales only linearly\nwith the number of STAR elements. Finally, numerical results are provided for\nboth NOMA and OMA to validate the effectiveness of the proposed algorithm by\ncomparing its performance with that of STAR-RISs using the independent\nphase-shift model and conventional reflecting/transmitting-only RISs.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Yuanwei Liu",
      "Xidong Mu",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02374"
  },
  {
    "id": "arXiv:2110.02375",
    "title": "Interpreting intermediate convolutional layers in unsupervised acoustic  word classification",
    "abstract": "Understanding how deep convolutional neural networks classify data has been\nsubject to extensive research. This paper proposes a technique to visualize and\ninterpret intermediate layers of unsupervised deep convolutional neural\nnetworks by averaging over individual feature maps in each convolutional layer\nand inferring underlying distributions of words with non-linear regression\ntechniques. A GAN-based architecture (ciwGAN arXiv:2006.02951) that includes\nthree convolutional networks (a Generator, a Discriminator, and a classifier)\nwas trained on unlabeled sliced lexical items from TIMIT. The training results\nin a deep convolutional network that learns to classify words into discrete\nclasses only from the requirement of the Generator to output informative data.\nThe classifier network has no access to the training data -- only to the\ngenerated data -- which means lexical learning needs to emerge in a fully\nunsupervised manner. We propose a technique to visualize individual\nconvolutional layers in the classifier that yields highly informative\ntime-series data for each convolutional layer and apply it to unobserved test\ndata. Using non-linear regression, we infer underlying distributions for each\nword which allows us to analyze both absolute values and shapes of individual\nwords at different convolutional layers as well as perform hypothesis testing\non their acoustic properties. The technique also allows us to tests individual\nphone contrasts and how they are represented at each layer.",
    "descriptor": "",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02375"
  },
  {
    "id": "arXiv:2110.02376",
    "title": "Foundations of Symbolic Languages for Model Interpretability",
    "abstract": "Several queries and scores have recently been proposed to explain individual\npredictions over ML models. Given the need for flexible, reliable, and\neasy-to-apply interpretability methods for ML models, we foresee the need for\ndeveloping declarative languages to naturally specify different explainability\nqueries. We do this in a principled way by rooting such a language in a logic,\ncalled FOIL, that allows for expressing many simple but important\nexplainability queries, and might serve as a core for more expressive\ninterpretability languages. We study the computational complexity of FOIL\nqueries over two classes of ML models often deemed to be easily interpretable:\ndecision trees and OBDDs. Since the number of possible inputs for an ML model\nis exponential in its dimension, the tractability of the FOIL evaluation\nproblem is delicate but can be achieved by either restricting the structure of\nthe models or the fragment of FOIL being evaluated. We also present a prototype\nimplementation of FOIL wrapped in a high-level declarative language and perform\nexperiments showing that such a language can be used in practice.",
    "descriptor": "\nComments: Accepted as Spotlight for NeurIPS'2021\n",
    "authors": [
      "Marcelo Arenas",
      "Daniel Baez",
      "Pablo Barcel\u00f3",
      "Jorge P\u00e9rez",
      "Bernardo Subercaseaux"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.02376"
  },
  {
    "id": "arXiv:2110.02378",
    "title": "High-rate storage codes on triangle-free graphs",
    "abstract": "Consider an assignment of bits to the vertices of a connected graph $G(V,E)$\nwith the property that the value of each vertex is a function of the values of\nits neighbors. A collection of such assignments is called a {\\em storage code}\nof length $|V|$ on $G$. The storage code problem can be equivalently formulated\nas maximizing the probability of success in a {\\em guessing game} on graphs, or\nconstructing {\\em index codes} of small rate.\nIf $G$ contains many cliques, it is easy to construct codes of rate close to\n1, so a natural problem is to construct high-rate codes on triangle-free\ngraphs, where constructing codes of rate $>1/2$ is a nontrivial task, with few\nknown results. In this work we construct infinite families of linear storage\ncodes with high rate relying on coset graphs of binary linear codes. We also\nderive necessary conditions for such codes to have high rate, and even rate\npotentially close to one.\nWe also address correction of multiple erasures in the codeword, deriving\nrecovery guarantees based on expansion properties of the graph.\nFinally, we point out connections between linear storage codes and quantum\nCSS codes, a link to bootstrap percolation and contagion spread in graphs, and\nformulate a number of open problems.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Alexander Barg",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.02378"
  },
  {
    "id": "arXiv:2110.02379",
    "title": "Minimum Symbol Error Probability Low-Resolution Precoding for MU-MIMO  Systems With PSK Modulation",
    "abstract": "We propose an optimal low-resolution precoding technique that minimizes the\nsymbol error probability of the users. Unlike existing approaches that rely on\nQPSK modulation, for the derivation of the minimum symbol error probability\nobjective function the current approach allows for any PSK modulation order.\nMoreover, the proposed method solves the corresponding discrete optimization\nproblem optimally via a sophisticated branch-and-bound method. Moreover, we\npropose different approaches based on the greedy search method to compute\npractical solutions. Numerical simulations confirm the superiority of the\nproposed minimum symbol error probability criteria in terms of symbol error\nrate when compared with the established MMDDT and MMSE approaches.",
    "descriptor": "",
    "authors": [
      "Erico S. P. Lopes",
      "Lukas T. N. Landau",
      "Amine Mezghani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02379"
  },
  {
    "id": "arXiv:2110.02386",
    "title": "Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer  Performance",
    "abstract": "Multilingual language models achieve impressive zero-shot accuracies in many\nlanguages in complex tasks such as Natural Language Inference (NLI). Examples\nin NLI (and equivalent complex tasks) often pertain to various types of\nsub-tasks, requiring different kinds of reasoning. Certain types of reasoning\nhave proven to be more difficult to learn in a monolingual context, and in the\ncrosslingual context, similar observations may shed light on zero-shot transfer\nefficiency and few-shot sample selection. Hence, to investigate the effects of\ntypes of reasoning on transfer performance, we propose a category-annotated\nmultilingual NLI dataset and discuss the challenges to scale monolingual\nannotations to multiple languages. We statistically observe interesting effects\nthat the confluence of reasoning types and language similarities have on\ntransfer performance.",
    "descriptor": "\nComments: Workshop on Multilingual Representation Learning (MRL 2021), at Empirical Methods in Natural Language Processing (EMNLP 2021)\n",
    "authors": [
      "Karthikeyan K",
      "Aalok Sathe",
      "Somak Aditya",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02386"
  },
  {
    "id": "arXiv:2110.02387",
    "title": "Approximate $\\mathrm{CVP}$ in time $2^{0.802 \\, n}$ -- now in any norm!",
    "abstract": "We show that a constant factor approximation of the shortest and closest\nlattice vector problem in any norm can be computed in time $2^{0.802\\, n}$.\nThis contrasts the corresponding $2^n$ time, (gap)-SETH based lower bounds for\nthese problems that even apply for small constant approximation. For both\nproblems, $\\mathrm{SVP}$ and $\\mathrm{CVP}$, we reduce to the case of the\nEuclidean norm. A key technical ingredient in that reduction is a twist of\nMilman's construction of an $M$-ellipsoid which approximates any symmetric\nconvex body $K$ with an ellipsoid $\\mathcal{E}$ so that $2^{\\varepsilon n}$\ntranslates of a constant scaling of $\\mathcal{E}$ can cover $K$ and vice versa.",
    "descriptor": "",
    "authors": [
      "Thomas Rothvoss",
      "Moritz Venzin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02387"
  },
  {
    "id": "arXiv:2110.02393",
    "title": "Geometric Algebra Attention Networks for Small Point Clouds",
    "abstract": "Much of the success of deep learning is drawn from building architectures\nthat properly respect underlying symmetry and structure in the data on which\nthey operate - a set of considerations that have been united under the banner\nof geometric deep learning. Often problems in the physical sciences deal with\nrelatively small sets of points in two- or three-dimensional space wherein\ntranslation, rotation, and permutation equivariance are important or even vital\nfor models to be useful in practice. In this work, we present rotation- and\npermutation-equivariant architectures for deep learning on these small point\nclouds, composed of a set of products of terms from the geometric algebra and\nreductions over those products using an attention mechanism. The geometric\nalgebra provides valuable mathematical structure by which to combine vector,\nscalar, and other types of geometric inputs in a systematic way to account for\nrotation invariance or covariance, while attention yields a powerful way to\nimpose permutation equivariance. We demonstrate the usefulness of these\narchitectures by training models to solve sample problems relevant to physics,\nchemistry, and biology.",
    "descriptor": "",
    "authors": [
      "Matthew Spellings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02393"
  },
  {
    "id": "arXiv:2110.02395",
    "title": "Structural Causal Interpretation Theorem",
    "abstract": "Human mental processes allow for qualitative reasoning about causality in\nterms of mechanistic relations of the variables of interest, which we argue are\nnaturally described by structural causal model (SCM). Since interpretations are\nbeing derived from mental models, the same applies for SCM. By defining a\nmetric space on SCM, we provide a theoretical perspective on the comparison of\nmental models and thereby conclude that interpretations can be used for guiding\na learning system towards true causality. To this effect, we present a\ntheoretical analysis from first principles that results in a human-readable\ninterpretation scheme consistent with the provided causality that we name\nstructural causal interpretations (SCI). Going further, we prove that any\nexisting neural induction method (NIM) is in fact interpretable. Our first\nexperiment (E1) assesses the quality of such NIM-based SCI. In (E2) we observe\nevidence for our conjecture on improved sample-efficiency for SCI-based\nlearning. After conducting a small user study, in (E3) we observe superiority\nin human-based over NIM-based SCI in support of our initial hypothesis.",
    "descriptor": "\nComments: Main paper: 9.5 pages, References: 2.5 pages, Supplement: 18 pages. Main paper: 5 figures, Supplement: 10 figures\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Constantin A. Rothkopf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02395"
  },
  {
    "id": "arXiv:2110.02396",
    "title": "An Online Scheduling Algorithm for a Community Energy Storage System",
    "abstract": "In this paper, we consider a community energy storage (CES) system that is\nshared by various electricity consumers who want to charge and discharge the\nCES throughout a given time span. We study the problem facing the manager of\nsuch a CES who must schedule the charging, discharging, and capacity\nreservations for numerous users. Moreover, we consider the case where requests\nto charge/discharge the CES arrive in an online fashion and the CES manager\nmust immediately allocate charging power and energy capacity to fulfill the\nrequest or reject the request altogether. The objective of the CES manager is\nto maximize the total value gained by all of the users of the CES while\naccounting for the operational constraints of the CES. We discuss an algorithm\ntitled \\textsc{CommunityEnergyScheduling} that acts as a pricing mechanism\nbased on online primal-dual optimization as a solution to the CES manager's\nproblem. The online algorithm estimates the dual variables (prices) in\nreal-time to allow for requests to be allocated or rejected immediately as they\narrive. Furthermore, the proposed method promotes charging and discharging\ncancellations to reduce the CES's usage at popular times and is able to handle\nthe inherent stochastic nature of the requests to charge/discharge stemming\nfrom randomness in users' net load patterns and weather uncertainties.\nAdditionally, we are able to show that the algorithm is able to handle any\nadversarially chosen request sequence and will always yield total welfare\nwithin a factor of 1/a of the offline optimal welfare.",
    "descriptor": "\nComments: 12 pages, 10 body, 2 supplementary material\n",
    "authors": [
      "Nathaniel Tucker",
      "Mahnoosh Alizadeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02396"
  },
  {
    "id": "arXiv:2110.02398",
    "title": "Quasi-Newton policy gradient algorithms",
    "abstract": "Policy gradient algorithms have been widely applied to reinforcement learning\n(RL) problems in recent years. Regularization with various entropy functions is\noften used to encourage exploration and improve stability. In this paper, we\npropose a quasi-Newton method for the policy gradient algorithm with entropy\nregularization. In the case of Shannon entropy, the resulting algorithm\nreproduces the natural policy gradient (NPG) algorithm. For other entropy\nfunctions, this method results in brand new policy gradient algorithms. We\nprovide a simple proof that all these algorithms enjoy the Newton-type\nquadratic convergence near the optimal policy. Using synthetic and\nindustrial-scale examples, we demonstrate that the proposed quasi-Newton method\ntypically converges in single-digit iterations, often orders of magnitude\nfaster than other state-of-the-art algorithms.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Haoya Li",
      "Samarth Gupta",
      "Hsiangfu Yu",
      "Lexing Ying",
      "Inderjit Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02398"
  },
  {
    "id": "arXiv:2110.02399",
    "title": "Task Affinity with Maximum Bipartite Matching in Few-Shot Learning",
    "abstract": "We propose an asymmetric affinity score for representing the complexity of\nutilizing the knowledge of one task for learning another one. Our method is\nbased on the maximum bipartite matching algorithm and utilizes the Fisher\nInformation matrix. We provide theoretical analyses demonstrating that the\nproposed score is mathematically well-defined, and subsequently use the\naffinity score to propose a novel algorithm for the few-shot learning problem.\nIn particular, using this score, we find relevant training data labels to the\ntest data and leverage the discovered relevant data for episodically\nfine-tuning a few-shot model. Results on various few-shot benchmark datasets\ndemonstrate the efficacy of the proposed approach by improving the\nclassification accuracy over the state-of-the-art methods even when using\nsmaller models.",
    "descriptor": "",
    "authors": [
      "Cat P. Le",
      "Juncheng Dong",
      "Mohammadreza Soltani",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02399"
  },
  {
    "id": "arXiv:2110.02400",
    "title": "Periodic Reranking for Online Matching of Reusable Resources",
    "abstract": "We consider a generalization of the vertex weighted online bipartite matching\nproblem where the offline vertices, called resources, are reusable. In\nparticular, when a resource is matched it is unavailable for a deterministic\ntime duration $d$ after which it becomes available for a re-match. Thus, a\nresource can be matched to many different online vertices over a period of\ntime. While recent work on the problem has resolved the asymptotic case where\nwe have large starting inventory (i.e., many copies) of every resource, we\nconsider the (more general) case of unit inventory and give the first algorithm\nthat is provably better than the na\\\"ive greedy approach which has a\ncompetitive ratio of (exactly) 0.5. In particular, we achieve a competitive\nratio of 0.589 against an LP relaxation of the offline problem.",
    "descriptor": "",
    "authors": [
      "Rajan Udwani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02400"
  },
  {
    "id": "arXiv:2110.02402",
    "title": "Language Modeling using LMUs: 10x Better Data Efficiency or Improved  Scaling Compared to Transformers",
    "abstract": "Recent studies have demonstrated that the performance of transformers on the\ntask of language modeling obeys a power-law relationship with model size over\nsix orders of magnitude. While transformers exhibit impressive scaling, their\nperformance hinges on processing large amounts of data, and their computational\nand memory requirements grow quadratically with sequence length. Motivated by\nthese considerations, we construct a Legendre Memory Unit based model that\nintroduces a general prior for sequence processing and exhibits an $O(n)$ and\n$O(n \\ln n)$ (or better) dependency for memory and computation respectively.\nOver three orders of magnitude, we show that our new architecture attains the\nsame accuracy as transformers with 10x fewer tokens. We also show that for the\nsame amount of training our model improves the loss over transformers about as\nmuch as transformers improve over LSTMs. Additionally, we demonstrate that\nadding global self-attention complements our architecture and the augmented\nmodel improves performance even further.",
    "descriptor": "",
    "authors": [
      "Narsimha Chilkuri",
      "Eric Hunsberger",
      "Aaron Voelker",
      "Gurshaant Malik",
      "Chris Eliasmith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02402"
  },
  {
    "id": "arXiv:2110.02403",
    "title": "Tradeoffs in Streaming Binary Classification under Limited Inspection  Resources",
    "abstract": "Institutions are increasingly relying on machine learning models to identify\nand alert on abnormal events, such as fraud, cyber attacks and system failures.\nThese alerts often need to be manually investigated by specialists. Given the\noperational cost of manual inspections, the suspicious events are selected by\nalerting systems with carefully designed thresholds. In this paper, we consider\nan imbalanced binary classification problem, where events arrive sequentially\nand only a limited number of suspicious events can be inspected. We model the\nevent arrivals as a non-homogeneous Poisson process, and compare various\nsuspicious event selection methods including those based on static and adaptive\nthresholds. For each method, we analytically characterize the tradeoff between\nthe minority-class detection rate and the inspection capacity as a function of\nthe data class imbalance and the classifier confidence score densities. We\nimplement the selection methods on a real public fraud detection dataset and\ncompare the empirical results with analytical bounds. Finally, we investigate\nhow class imbalance and the choice of classifier impact the tradeoff.",
    "descriptor": "\nComments: To appear in Proceedings of the ACM International Conference on AI in Finance (ICAIF '21) - Full version with supplementary material\n",
    "authors": [
      "Parisa Hassanzadeh",
      "Danial Dervovic",
      "Samuel Assefa",
      "Prashant Reddy",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02403"
  },
  {
    "id": "arXiv:2110.02404",
    "title": "3D-MOV: Audio-Visual LSTM Autoencoder for 3D Reconstruction of Multiple  Objects from Video",
    "abstract": "3D object reconstructions of transparent and concave structured objects, with\ninferred material properties, remains an open research problem for robot\nnavigation in unstructured environments. In this paper, we propose a multimodal\nsingle- and multi-frame neural network for 3D reconstructions using\naudio-visual inputs. Our trained reconstruction LSTM autoencoder 3D-MOV accepts\nmultiple inputs to account for a variety of surface types and views. Our neural\nnetwork produces high-quality 3D reconstructions using voxel representation.\nBased on Intersection-over-Union (IoU), we evaluate against other baseline\nmethods using synthetic audio-visual datasets ShapeNet and Sound20K with impact\nsounds and bounding box annotations. To the best of our knowledge, our single-\nand multi-frame model is the first audio-visual reconstruction neural network\nfor 3D geometry and material representation.",
    "descriptor": "",
    "authors": [
      "Justin Wilson",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02404"
  },
  {
    "id": "arXiv:2110.02405",
    "title": "Echo-Reconstruction: Audio-Augmented 3D Scene Reconstruction",
    "abstract": "Reflective and textureless surfaces such as windows, mirrors, and walls can\nbe a challenge for object and scene reconstruction. These surfaces are often\npoorly reconstructed and filled with depth discontinuities and holes, making it\ndifficult to cohesively reconstruct scenes that contain these planar\ndiscontinuities. We propose Echoreconstruction, an audio-visual method that\nuses the reflections of sound to aid in geometry and audio reconstruction for\nvirtual conferencing, teleimmersion, and other AR/VR experience. The mobile\nphone prototype emits pulsed audio, while recording video for RGB-based 3D\nreconstruction and audio-visual classification. Reflected sound and images from\nthe video are input into our audio (EchoCNN-A) and audio-visual (EchoCNN-AV)\nconvolutional neural networks for surface and sound source detection, depth\nestimation, and material classification. The inferences from these\nclassifications enhance scene 3D reconstructions containing open spaces and\nreflective surfaces by depth filtering, inpainting, and placement of unmixed\nsound sources in the scene. Our prototype, VR demo, and experimental results\nfrom real-world and virtual scenes with challenging surfaces and sound indicate\nhigh success rates on classification of material, depth estimation, and\nclosed/open surfaces, leading to considerable visual and audio improvement in\n3D scenes (see Figure 1).",
    "descriptor": "",
    "authors": [
      "Justin Wilson",
      "Nicholas Rewkowski",
      "Ming C. Lin",
      "Henry Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02405"
  },
  {
    "id": "arXiv:2110.02406",
    "title": "Word Acquisition in Neural Language Models",
    "abstract": "We investigate how neural language models acquire individual words during\ntraining, extracting learning curves and ages of acquisition for over 600 words\non the MacArthur-Bates Communicative Development Inventory (Fenson et al.,\n2007). Drawing on studies of word acquisition in children, we evaluate multiple\npredictors for words' ages of acquisition in LSTMs, BERT, and GPT-2. We find\nthat the effects of concreteness, word length, and lexical class are pointedly\ndifferent in children and language models, reinforcing the importance of\ninteraction and sensorimotor experience in child language acquisition. Language\nmodels rely far more on word frequency than children, but like children, they\nexhibit slower learning of words in longer utterances. Interestingly, models\nfollow consistent patterns during training for both unidirectional and\nbidirectional models, and for both LSTM and Transformer architectures. Models\npredict based on unigram token frequencies early in training, before\ntransitioning loosely to bigram probabilities, eventually converging on more\nnuanced predictions. These results shed light on the role of distributional\nlearning mechanisms in children, while also providing insights for more\nhuman-like language acquisition in language models.",
    "descriptor": "\nComments: Accepted to TACL (pre-MIT Press version)\n",
    "authors": [
      "Tyler A. Chang",
      "Benjamin K. Bergen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02406"
  },
  {
    "id": "arXiv:2110.02407",
    "title": "A Multi-Scale A Contrario method for Unsupervised Image Anomaly  Detection",
    "abstract": "Anomalies can be defined as any non-random structure which deviates from\nnormality. Anomaly detection methods reported in the literature are numerous\nand diverse, as what is considered anomalous usually varies depending on\nparticular scenarios and applications. In this work we propose an a contrario\nframework to detect anomalies in images applying statistical analysis to\nfeature maps obtained via convolutions. We evaluate filters learned from the\nimage under analysis via patch PCA, Gabor filters and the feature maps obtained\nfrom a pre-trained deep neural network (Resnet). The proposed method is\nmulti-scale and fully unsupervised and is able to detect anomalies in a wide\nvariety of scenarios. While the end goal of this work is the detection of\nsubtle defects in leather samples for the automotive industry, we show that the\nsame algorithm achieves state of the art results in public anomalies datasets.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Matias Tailanian",
      "Pablo Mus\u00e9",
      "\u00c1lvaro Pardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02407"
  },
  {
    "id": "arXiv:2110.02411",
    "title": "Voice Aging with Audio-Visual Style Transfer",
    "abstract": "Face aging techniques have used generative adversarial networks (GANs) and\nstyle transfer learning to transform one's appearance to look younger/older.\nIdentity is maintained by conditioning these generative networks on a learned\nvector representation of the source content. In this work, we apply a similar\napproach to age a speaker's voice, referred to as voice aging. We first analyze\nthe classification of a speaker's age by training a convolutional neural\nnetwork (CNN) on the speaker's voice and face data from Common Voice and\nVoxCeleb datasets. We generate aged voices from style transfer to transform an\ninput spectrogram to various ages and demonstrate our method on a mobile app.",
    "descriptor": "",
    "authors": [
      "Justin Wilson",
      "Sunyeong Park",
      "Seunghye J. Wilson",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02411"
  },
  {
    "id": "arXiv:2110.02414",
    "title": "Imaginary Hindsight Experience Replay: Curious Model-based Learning for  Sparse Reward Tasks",
    "abstract": "Model-based reinforcement learning is a promising learning strategy for\npractical robotic applications due to its improved data-efficiency versus\nmodel-free counterparts. However, current state-of-the-art model-based methods\nrely on shaped reward signals, which can be difficult to design and implement.\nTo remedy this, we propose a simple model-based method tailored for\nsparse-reward multi-goal tasks that foregoes the need for complicated reward\nengineering. This approach, termed Imaginary Hindsight Experience Replay,\nminimises real-world interactions by incorporating imaginary data into policy\nupdates. To improve exploration in the sparse-reward setting, the policy is\ntrained with standard Hindsight Experience Replay and endowed with\ncuriosity-based intrinsic rewards. Upon evaluation, this approach provides an\norder of magnitude increase in data-efficiency on average versus the\nstate-of-the-art model-free method in the benchmark OpenAI Gym Fetch Robotics\ntasks.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Robert McCarthy",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02414"
  },
  {
    "id": "arXiv:2110.02421",
    "title": "Explaining Off-Policy Actor-Critic From A Bias-Variance Perspective",
    "abstract": "Off-policy Actor-Critic algorithms have demonstrated phenomenal experimental\nperformance but still require better explanations. To this end, we show its\npolicy evaluation error on the distribution of transitions decomposes into: a\nBellman error, a bias from policy mismatch, and a variance term from sampling.\nBy comparing the magnitude of bias and variance, we explain the success of the\nEmphasizing Recent Experience sampling and 1/age weighted sampling. Both\nsampling strategies yield smaller bias and variance and are hence preferable to\nuniform sampling.",
    "descriptor": "",
    "authors": [
      "Ting-Han Fan",
      "Peter J. Ramadge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02421"
  },
  {
    "id": "arXiv:2110.02423",
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "abstract": "Computational methods for predicting the interface contacts between proteins\ncome highly sought after for drug discovery as they can significantly advance\nthe accuracy of alternative approaches, such as protein-protein docking,\nprotein function analysis tools, and other computational methods for protein\nbioinformatics. In this work, we present the Geometric Transformer, a novel\ngeometry-evolving graph transformer for rotation and translation-invariant\nprotein interface contact prediction, packaged within DeepInteract, an\nend-to-end prediction pipeline. DeepInteract predicts partner-specific protein\ninterface contacts (i.e., inter-protein residue-residue contacts) given the 3D\ntertiary structures of two proteins as input. In rigorous benchmarks,\nDeepInteract, on challenging protein complex targets from the new Enhanced\nDatabase of Interacting Protein Structures (DIPS-Plus) and the 13th and 14th\nCASP-CAPRI experiments, achieves 17% and 13% top L/5 precision (L: length of a\nprotein unit in a complex), respectively. In doing so, DeepInteract, with the\nGeometric Transformer as its graph-based backbone, outperforms existing methods\nfor interface contact prediction in addition to other graph-based neural\nnetwork backbones compatible with DeepInteract, thereby validating the\neffectiveness of the Geometric Transformer for learning rich\nrelational-geometric features for downstream tasks on 3D protein structures.",
    "descriptor": "\nComments: 16 pages, 5 figures, and 6 tables. Under review\n",
    "authors": [
      "Alex Morehead",
      "Chen Chen",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.02423"
  },
  {
    "id": "arXiv:2110.02424",
    "title": "Spectral Bias in Practice: The Role of Function Frequency in  Generalization",
    "abstract": "Despite their ability to represent highly expressive functions, deep learning\nmodels trained with SGD seem to find simple, constrained solutions that\ngeneralize surprisingly well. Spectral bias - the tendency of neural networks\nto prioritize learning low frequency functions - is one possible explanation\nfor this phenomenon, but so far spectral bias has only been observed in\ntheoretical models and simplified experiments. In this work, we propose\nmethodologies for measuring spectral bias in modern image classification\nnetworks. We find that these networks indeed exhibit spectral bias, and that\nnetworks that generalize well strike a balance between having enough\ncomplexity(i.e. high frequencies) to fit the data while being simple enough to\navoid overfitting. For example, we experimentally show that larger models learn\nhigh frequencies faster than smaller ones, but many forms of regularization,\nboth explicit and implicit, amplify spectral bias and delay the learning of\nhigh frequencies. We also explore the connections between function frequency\nand image frequency and find that spectral bias is sensitive to the low\nfrequencies prevalent in natural images. Our work enables measuring and\nultimately controlling the spectral behavior of neural networks used for image\nclassification, and is a step towards understanding why deep models generalize\nwell",
    "descriptor": "",
    "authors": [
      "Sara Fridovich-Keil",
      "Raphael Gontijo-Lopes",
      "Rebecca Roelofs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02424"
  },
  {
    "id": "arXiv:2110.02427",
    "title": "Impact of Motor Stator Winding Faults on Common-Mode Current",
    "abstract": "This paper investigates the influence of different motor stator failures on\nthe common-mode (CM) current. The stator winding failures will affect the\nmotor's CM impedance, and also increase the unbalance of the differential-mode\n(DM) noise path. The experimental results show that the former will increase\nthe CM current induced by the CM noise source, while the latter will cause the\nDM current induced by the DM noise source to be converted into the CM current.",
    "descriptor": "\nComments: The conference paper has been accepted by APEMC 2021, which is to be published in IEEE Xplore soon\n",
    "authors": [
      "Fei Fan",
      "Zhenyu Zhao",
      "Pengfei Tu",
      "Huamin Jie",
      "Kye Yak See"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.02427"
  },
  {
    "id": "arXiv:2110.02429",
    "title": "Autonomous Aerial Delivery Vehicles, a Survey of Techniques on how  Aerial Package Delivery is Achieved",
    "abstract": "Autonomous aerial delivery vehicles have gained significant interest in the\nlast decade. This has been enabled by technological advancements in aerial\nmanipulators and novel grippers with enhanced force to weight ratios.\nFurthermore, improved control schemes and vehicle dynamics are better able to\nmodel the payload and improved perception algorithms to detect key features\nwithin the unmanned aerial vehicle's (UAV) environment. In this survey, a\nsystematic review of the technological advancements and open research problems\nof autonomous aerial delivery vehicles is conducted. First, various types of\nmanipulators and grippers are discussed in detail, along with dynamic modelling\nand control methods. Then, landing on static and dynamic platforms is\ndiscussed. Subsequently, risks such as weather conditions, state estimation and\ncollision avoidance to ensure safe transit is considered. Finally, delivery UAV\nrouting is investigated which categorises the topic into two areas: drone\noperations and drone-truck collaborative operations.",
    "descriptor": "\nComments: Submitted for review in the Journal of Field Robotics\n",
    "authors": [
      "Jack Saunders",
      "Sajad Saeedi",
      "Wenbin Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02429"
  },
  {
    "id": "arXiv:2110.02432",
    "title": "Federated Distillation of Natural Language Understanding with Confident  Sinkhorns",
    "abstract": "Enhancing the user experience is an essential task for application service\nproviders. For instance, two users living wide apart may have different tastes\nof food. A food recommender mobile application installed on an edge device\nmight want to learn from user feedback (reviews) to satisfy the client's needs\npertaining to distinct domains. Retrieving user data comes at the cost of\nprivacy while asking for model parameters trained on a user device becomes\nspace inefficient at a large scale. In this work, we propose an approach to\nlearn a central (global) model from the federation of (local) models which are\ntrained on user-devices, without disclosing the local data or model parameters\nto the server. We propose a federation mechanism for the problems with natural\nsimilarity metric between the labels which commonly appear in natural language\nunderstanding (NLU) tasks. To learn the global model, the objective is to\nminimize the optimal transport cost of the global model's predictions from the\nconfident sum of soft-targets assigned by local models. The confidence (a model\nweighting scheme) score of a model is defined as the L2 distance of a model's\nprediction from its probability bias. The method improves the global model's\nperformance over the baseline designed on three NLU tasks with intrinsic label\nspace semantics, i.e., fine-grained sentiment analysis, emotion recognition in\nconversation, and natural language inference. We make our codes public at\nhttps://github.com/declare-lab/sinkhorn-loss.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Rishabh Bhardwaj",
      "Tushar Vaidya",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02432"
  },
  {
    "id": "arXiv:2110.02436",
    "title": "A Deep Learning-based Audio-in-Image Watermarking Scheme",
    "abstract": "This paper presents a deep learning-based audio-in-image watermarking scheme.\nAudio-in-image watermarking is the process of covertly embedding and extracting\naudio watermarks on a cover-image. Using audio watermarks can open up\npossibilities for different downstream applications. For the purpose of\nimplementing an audio-in-image watermarking that adapts to the demands of\nincreasingly diverse situations, a neural network architecture is designed to\nautomatically learn the watermarking process in an unsupervised manner. In\naddition, a similarity network is developed to recognize the audio watermarks\nunder distortions, therefore providing robustness to the proposed method.\nExperimental results have shown high fidelity and robustness of the proposed\nblind audio-in-image watermarking scheme.",
    "descriptor": "\nComments: This paper has been accepted for publication by the 2021 IEEE Visual Communications and Image Processing. The copyright is with the IEEE\n",
    "authors": [
      "Arjon Das",
      "Xin Zhong"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02436"
  },
  {
    "id": "arXiv:2110.02439",
    "title": "Replay-Guided Adversarial Environment Design",
    "abstract": "Deep reinforcement learning (RL) agents may successfully generalize to new\nsettings if trained on an appropriately diverse set of environment and task\nconfigurations. Unsupervised Environment Design (UED) is a promising\nself-supervised RL paradigm, wherein the free parameters of an underspecified\nenvironment are automatically adapted during training to the agent's\ncapabilities, leading to the emergence of diverse training environments. Here,\nwe cast Prioritized Level Replay (PLR), an empirically successful but\ntheoretically unmotivated method that selectively samples randomly-generated\ntraining levels, as UED. We argue that by curating completely random levels,\nPLR, too, can generate novel and complex levels for effective training. This\ninsight reveals a natural class of UED methods we call Dual Curriculum Design\n(DCD). Crucially, DCD includes both PLR and a popular UED algorithm, PAIRED, as\nspecial cases and inherits similar theoretical guarantees. This connection\nallows us to develop novel theory for PLR, providing a version with a\nrobustness guarantee at Nash equilibria. Furthermore, our theory suggests a\nhighly counterintuitive improvement to PLR: by stopping the agent from updating\nits policy on uncurated levels (training on less data), we can improve the\nconvergence to Nash equilibria. Indeed, our experiments confirm that our new\nmethod, PLR$^{\\perp}$, obtains better results on a suite of\nout-of-distribution, zero-shot transfer tasks, in addition to demonstrating\nthat PLR$^{\\perp}$ improves the performance of PAIRED, from which it inherited\nits theoretical framework.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Minqi Jiang",
      "Michael Dennis",
      "Jack Parker-Holder",
      "Jakob Foerster",
      "Edward Grefenstette",
      "Tim Rockt\u00e4schel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02439"
  },
  {
    "id": "arXiv:2110.02442",
    "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
    "abstract": "Transformer-based models have achieved great success in various NLP, vision,\nand speech tasks. However, the core of Transformer, the self-attention\nmechanism, has a quadratic time and memory complexity with respect to the\nsequence length, which hinders applications of Transformer-based models to long\nsequences. Many approaches have been proposed to mitigate this problem, such as\nsparse attention mechanisms, low-rank matrix approximations and scalable\nkernels, and token mixing alternatives to self-attention. We propose a novel\nPooling Network (PoNet) for token mixing in long sequences with linear\ncomplexity. We design multi-granularity pooling and pooling fusion to capture\ndifferent levels of contextual information and combine their interactions with\ntokens. On the Long Range Arena benchmark, PoNet significantly outperforms\nTransformer and achieves competitive accuracy, while being only slightly slower\nthan the fastest model, FNet, across all sequence lengths measured on GPUs. We\nalso conduct systematic studies on the transfer learning capability of PoNet\nand observe that PoNet achieves 96.0% of the accuracy of BERT on the GLUE\nbenchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis\ndemonstrates effectiveness of the designed multi-granularity pooling and\npooling fusion for token mixing in long sequences and efficacy of the designed\npre-training tasks for PoNet to learn transferable contextualized language\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Chao-Hong Tan",
      "Qian Chen",
      "Wen Wang",
      "Qinglin Zhang",
      "Siqi Zheng",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02442"
  },
  {
    "id": "arXiv:2110.02443",
    "title": "Pedestrian Wind Factor Estimation in Complex Urban Environments",
    "abstract": "Urban planners and policy makers face the challenge of creating livable and\nenjoyable cities for larger populations in much denser urban conditions. While\nthe urban microclimate holds a key role in defining the quality of urban spaces\ntoday and in the future, the integration of wind microclimate assessment in\nearly urban design and planning processes remains a challenge due to the\ncomplexity and high computational expense of computational fluid dynamics (CFD)\nsimulations. This work develops a data-driven workflow for real-time pedestrian\nwind comfort estimation in complex urban environments which may enable\ndesigners, policy makers and city residents to make informed decisions about\nmobility, health, and energy choices. We use a conditional generative\nadversarial network (cGAN) architecture to reduce the computational computation\nwhile maintaining high confidence levels and interpretability, adequate\nrepresentation of urban complexity, and suitability for pedestrian comfort\nestimation. We demonstrate high quality wind field approximations while\nreducing computation time from days to seconds.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Sarah Mokhtar",
      "Matthew Beveridge",
      "Yumeng Cao",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02443"
  },
  {
    "id": "arXiv:2110.02444",
    "title": "Influence-Balanced Loss for Imbalanced Visual Classification",
    "abstract": "In this paper, we propose a balancing training method to address problems in\nimbalanced data learning. To this end, we derive a new loss used in the\nbalancing training phase that alleviates the influence of samples that cause an\noverfitted decision boundary. The proposed loss efficiently improves the\nperformance of any type of imbalance learning methods. In experiments on\nmultiple benchmark data sets, we demonstrate the validity of our method and\nreveal that the proposed loss outperforms the state-of-the-art cost-sensitive\nloss methods. Furthermore, since our loss is not restricted to a specific task,\nmodel, or training method, it can be easily used in combination with other\nrecent re-sampling, meta-learning, and cost-sensitive learning methods for\nclass-imbalance problems.",
    "descriptor": "\nComments: Published in ICCV 2021\n",
    "authors": [
      "Seulki Park",
      "Jongin Lim",
      "Younghan Jeon",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02444"
  },
  {
    "id": "arXiv:2110.02450",
    "title": "Reward-Punishment Symmetric Universal Intelligence",
    "abstract": "Can an agent's intelligence level be negative? We extend the Legg-Hutter\nagent-environment framework to include punishments and argue for an affirmative\nanswer to that question. We show that if the background encodings and Universal\nTuring Machine (UTM) admit certain Kolmogorov complexity symmetries, then the\nresulting Legg-Hutter intelligence measure is symmetric about the origin. In\nparticular, this implies reward-ignoring agents have Legg-Hutter intelligence 0\naccording to such UTMs.",
    "descriptor": "\nComments: 11 pages, accepted to AGI-21\n",
    "authors": [
      "Samuel Allen Alexander",
      "Marcus Hutter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02450"
  },
  {
    "id": "arXiv:2110.02453",
    "title": "Ripple Attention for Visual Perception with Sub-quadratic Complexity",
    "abstract": "Transformer architectures are now central to modeling in natural language\nprocessing tasks. At its heart is the attention mechanism, which enables\neffective modeling of long-term dependencies in a sequence. Recently,\ntransformers have been successfully applied in the computer vision domain,\nwhere 2D images are first segmented into patches and then treated as 1D\nsequences. Such linearization, however, impairs the notion of spatial locality\nin images, which bears important visual clues. To bridge the gap, we propose\nripple attention, a sub-quadratic attention mechanism for visual perception. In\nripple attention, contributions of different tokens to a query are weighted\nwith respect to their relative spatial distances in the 2D space. To favor\ncorrelations with vicinal tokens yet permit long-term dependencies, we derive\nthe spatial weights through a stick-breaking transformation. We further design\na dynamic programming algorithm that computes weighted contributions for all\nqueries in linear observed time, taking advantage of the summed-area table and\nrecent advances in linearized attention. Extensive experiments and analyses\ndemonstrate the effectiveness of ripple attention on various visual tasks.",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Lin Zheng",
      "Huijie Pan",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02453"
  },
  {
    "id": "arXiv:2110.02454",
    "title": "Sum-rate Maximization in Uplink CRAN with a Massive MIMO Fronthaul",
    "abstract": "The limited fronthaul capacity is known to be one of the main problems in\ncloud radio access networks (CRANs), especially in the wireless fronthaul\nlinks. In this paper, we consider the uplink of a CRAN system, where massive\nmultiple-input multiple-output (MIMO) is utilized in the fronthaul link.\nConsidering multi-antenna user equipment (UEs) and multi-antenna remote radio\nheads (RRHs), we maximize the system sum-rate by jointly optimizing the\nprecoders at the UEs and the quantization noise covariance matrices and\ntransmit powers at the RRHs. To solve the resulting nonconvex problem, an\niterative algorithm based on the majorization-minimization (MM) method is\nproposed. Two schemes at the central unit are considered, namely maximum ratio\n(MR) and zero-forcing (ZF) combining. Numerical results show that the sum-rate\nhas an asymptotic behaviour with respect to the maximum available power at RRHs\nand that the MR scheme goes to its asymptote faster than the ZF scheme.",
    "descriptor": "\nComments: accepted by IEEE GLOBECOM 2021 Workshop\n",
    "authors": [
      "Dick Maryopi",
      "Yingjia Huang",
      "Aissa Ikhlef"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02454"
  },
  {
    "id": "arXiv:2110.02457",
    "title": "Solve Minimax Optimization by Anderson Acceleration",
    "abstract": "Many modern machine learning algorithms such as generative adversarial\nnetworks (GANs) and adversarial training can be formulated as minimax\noptimization. Gradient descent ascent (GDA) is the most commonly used algorithm\ndue to its simplicity. However, GDA can converge to non-optimal minimax points.\nWe propose a new minimax optimization framework, GDA-AM, that views the\nGDAdynamics as a fixed-point iteration and solves it using Anderson Mixing to\ncon-verge to the local minimax. It addresses the diverging issue of\nsimultaneous GDAand accelerates the convergence of alternating GDA. We show\ntheoretically that the algorithm can achieve global convergence for bilinear\nproblems under mild conditions. We also empirically show that GDA-AMsolves a\nvariety of minimax problems and improves GAN training on several datasets",
    "descriptor": "\nComments: 21 Pages\n",
    "authors": [
      "Huan He",
      "Shifan Zhao",
      "Yuanzhe Xi",
      "Joyce C Ho",
      "Yousef Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02457"
  },
  {
    "id": "arXiv:2110.02459",
    "title": "Post-hoc Models for Performance Estimation of Machine Learning Inference",
    "abstract": "Estimating how well a machine learning model performs during inference is\ncritical in a variety of scenarios (for example, to quantify uncertainty, or to\nchoose from a library of available models). However, the standard accuracy\nestimate of softmax confidence is not versatile and cannot reliably predict\ndifferent performance metrics (e.g., F1-score, recall) or the performance in\ndifferent application scenarios or input domains. In this work, we\nsystematically generalize performance estimation to a diverse set of metrics\nand scenarios and discuss generalized notions of uncertainty calibration. We\npropose the use of post-hoc models to accomplish this goal and investigate\ndesign parameters, including the model type, feature engineering, and\nperformance metric, to achieve the best estimation quality. Emphasis is given\nto object detection problems and, unlike prior work, our approach enables the\nestimation of per-image metrics such as recall and F1-score. Through extensive\nexperiments with computer vision models and datasets in three use cases --\nmobile edge offloading, model selection, and dataset shift -- we find that\nproposed post-hoc models consistently outperform the standard calibrated\nconfidence baselines. To the best of our knowledge, this is the first work to\ndevelop a unified framework to address different performance estimation\nproblems for machine learning inference.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Xuechen Zhang",
      "Samet Oymak",
      "Jiasi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02459"
  },
  {
    "id": "arXiv:2110.02467",
    "title": "BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation  Models",
    "abstract": "Pre-trained Natural Language Processing (NLP) models can be easily adapted to\na variety of downstream language tasks. This significantly accelerates the\ndevelopment of language models. However, NLP models have been shown to be\nvulnerable to backdoor attacks, where a pre-defined trigger word in the input\ntext causes model misprediction. Previous NLP backdoor attacks mainly focus on\nsome specific tasks. This makes those attacks less general and applicable to\nother kinds of NLP models and tasks. In this work, we propose \\Name, the first\ntask-agnostic backdoor attack against the pre-trained NLP models. The key\nfeature of our attack is that the adversary does not need prior information\nabout the downstream tasks when implanting the backdoor to the pre-trained\nmodel. When this malicious model is released, any downstream models transferred\nfrom it will also inherit the backdoor, even after the extensive transfer\nlearning process. We further design a simple yet effective strategy to bypass a\nstate-of-the-art defense. Experimental results indicate that our approach can\ncompromise a wide range of downstream NLP tasks in an effective and stealthy\nway.",
    "descriptor": "",
    "authors": [
      "Kangjie Chen",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Shangwei Guo",
      "Tianwei Zhang",
      "Jiwei Li",
      "Chun Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02467"
  },
  {
    "id": "arXiv:2110.02470",
    "title": "SSFL: Tackling Label Deficiency in Federated Learning via Personalized  Self-Supervision",
    "abstract": "Federated Learning (FL) is transforming the ML training ecosystem from a\ncentralized over-the-cloud setting to distributed training over edge devices in\norder to strengthen data privacy. An essential but rarely studied challenge in\nFL is label deficiency at the edge. This problem is even more pronounced in FL\ncompared to centralized training due to the fact that FL users are often\nreluctant to label their private data. Furthermore, due to the heterogeneous\nnature of the data at edge devices, it is crucial to develop personalized\nmodels. In this paper we propose self-supervised federated learning (SSFL), a\nunified self-supervised and personalized federated learning framework, and a\nseries of algorithms under this framework which work towards addressing these\nchallenges. First, under the SSFL framework, we demonstrate that the standard\nFedAvg algorithm is compatible with recent breakthroughs in centralized\nself-supervised learning such as SimSiam networks. Moreover, to deal with data\nheterogeneity at the edge devices in this framework, we have innovated a series\nof algorithms that broaden existing supervised personalization algorithms into\nthe setting of self-supervised learning. We further propose a novel\npersonalized federated self-supervised learning algorithm, Per-SSFL, which\nbalances personalization and consensus by carefully regulating the distance\nbetween the local and global representations of data. To provide a\ncomprehensive comparative analysis of all proposed algorithms, we also develop\na distributed training system and related evaluation protocol for SSFL. Our\nfindings show that the gap of evaluation accuracy between supervised learning\nand unsupervised learning in FL is both small and reasonable. The performance\ncomparison indicates the representation regularization-based personalization\nmethod is able to outperform other variants.",
    "descriptor": "",
    "authors": [
      "Chaoyang He",
      "Zhengyu Yang",
      "Erum Mushtaq",
      "Sunwoo Lee",
      "Mahdi Soltanolkotabi",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02470"
  },
  {
    "id": "arXiv:2110.02472",
    "title": "What is A Wireless UAV? A Design Blueprint for 6G Flying Wireless Nodes",
    "abstract": "Wireless Unmanned Aerial Vehicles (UAVs) were introduced in the world of 4th\ngeneration networks (4G) as cellular users, and have attracted the interest of\nthe wireless community ever since. In~5G, UAVs operate also as flying Base\nStations providing service to ground users. They can also implement independent\noff-the-grid UAV networks. In~6G networks, wireless UAVs will connect ground\nusers to in-orbit wireless infrastructure. As the design and prototyping of\nwireless UAVs are on the rise, the time is ripe for introducing a more precise\ndefinition of what is a wireless UAV. In doing so, we revise the major design\nchallenges in the prototyping of wireless UAVs for future 6G spectrum research.\nWe then introduce a new wireless UAV prototype that addresses these challenges.\nThe design of our wireless UAV prototype will be made public and freely\navailable to other researchers.",
    "descriptor": "\nComments: This paper has been accepted at WiNTECH'21: Proceedings of the 15th ACM Workshop on Wireless Network Testbeds, Experimental evaluation & CHaracterization. Copyright may be transferred without notice\n",
    "authors": [
      "John Buczek",
      "Lorenzo Bertizzolo",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02472"
  },
  {
    "id": "arXiv:2110.02473",
    "title": "The Power of Contrast for Feature Learning: A Theoretical Analysis",
    "abstract": "Contrastive learning has achieved state-of-the-art performance in various\nself-supervised learning tasks and even outperforms its supervised counterpart.\nDespite its empirical success, theoretical understanding of why contrastive\nlearning works is still limited. In this paper, (i) we provably show that\ncontrastive learning outperforms autoencoder, a classical unsupervised learning\nmethod, for both feature recovery and downstream tasks; (ii) we also illustrate\nthe role of labeled data in supervised contrastive learning. This provides\ntheoretical support for recent findings that contrastive learning with labels\nimproves the performance of learned representations in the in-domain downstream\ntask, but it can harm the performance in transfer learning. We verify our\ntheory with numerical experiments.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Wenlong Ji",
      "Zhun Deng",
      "Ryumei Nakada",
      "James Zou",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02473"
  },
  {
    "id": "arXiv:2110.02478",
    "title": "Blind Super-resolution via Projected Gradient Descent",
    "abstract": "Blind super-resolution can be cast as low rank matrix recovery problem by\nexploiting the inherent simplicity of the signal. In this paper, we develop a\nsimple yet efficient nonconvex method for this problem based on the low rank\nstructure of the vectorized Hankel matrix associated with the target matrix.\nTheoretical guarantees have been established under the similar conditions as\nconvex approaches. Numerical experiments are also conducted to demonstrate its\nperformance.",
    "descriptor": "",
    "authors": [
      "Sihan Mao",
      "Jinchi Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02478"
  },
  {
    "id": "arXiv:2110.02480",
    "title": "Efficient Multi-agent Epistemic Planning: Teaching Planners About Nested  Belief",
    "abstract": "Many AI applications involve the interaction of multiple autonomous agents,\nrequiring those agents to reason about their own beliefs, as well as those of\nother agents. However, planning involving nested beliefs is known to be\ncomputationally challenging. In this work, we address the task of synthesizing\nplans that necessitate reasoning about the beliefs of other agents. We plan\nfrom the perspective of a single agent with the potential for goals and actions\nthat involve nested beliefs, non-homogeneous agents, co-present observations,\nand the ability for one agent to reason as if it were another. We formally\ncharacterize our notion of planning with nested belief, and subsequently\ndemonstrate how to automatically convert such problems into problems that\nappeal to classical planning technology for solving efficiently. Our approach\nrepresents an important step towards applying the well-established field of\nautomated planning to the challenging task of planning involving nested beliefs\nof multiple agents.",
    "descriptor": "\nComments: Published in Special Issue of the Artificial Intelligence Journal (AIJ) on Epistemic Planning\n",
    "authors": [
      "Christian Muise",
      "Vaishak Belle",
      "Paolo Felli",
      "Sheila McIlraith",
      "Tim Miller",
      "Adrian R. Pearce",
      "Liz Sonenberg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02480"
  },
  {
    "id": "arXiv:2110.02481",
    "title": "Massively Parallel Probabilistic Computing with Sparse Ising Machines",
    "abstract": "Inspired by the developments in quantum computing, building quantum-inspired\nclassical hardware to solve computationally hard problems has been receiving\nincreasing attention. By introducing systematic sparsification techniques, we\npropose and demonstrate a massively parallel architecture, termed sIM or the\nsparse Ising Machine. Exploiting the sparsity of the resultant problem graphs,\nthe sIM achieves ideal parallelism: the key figure of merit $-$ flips per\nsecond $-$ scales linearly with the total number of probabilistic bits (p-bit)\nin the system. This makes sIM up to 6 orders of magnitude faster than a CPU\nimplementing standard Gibbs sampling. When compared to optimized\nimplementations in TPUs and GPUs, the sIM delivers up to ~ 5 - 18x measured\nspeedup. In benchmark combinatorial optimization problems such as integer\nfactorization, the sIM can reliably factor semi-primes up to 32-bits, far\nlarger than previous attempts from D-Wave and other probabilistic solvers.\nStrikingly, the sIM beats competition-winning SAT solvers (by up to ~ 4 - 700x\nin runtime to reach 95% accuracy) in solving hard instances of the 3SAT\nproblem. A surprising observation is that even when the asynchronous sampling\nis made inexact with simultaneous updates using faster clocks, sIM can find the\ncorrect ground state with further speedup. The problem encoding and\nsparsification techniques we introduce can be readily applied to other Ising\nMachines (classical and quantum) and the asynchronous architecture we present\ncan be used for scaling the demonstrated 5,000$-$10,000 p-bits to 1,000,000 or\nmore through CMOS or emerging nanodevices.",
    "descriptor": "",
    "authors": [
      "Navid Anjum Aadit",
      "Andrea Grimaldi",
      "Mario Carpentieri",
      "Luke Theogarajan",
      "John M. Martinis",
      "Giovanni Finocchio",
      "Kerem Y. Camsari"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.02481"
  },
  {
    "id": "arXiv:2110.02482",
    "title": "$O\\left(1/T\\right)$ Time-Average Convergence in a Generalization of  Multiagent Zero-Sum Games",
    "abstract": "We introduce a generalization of zero-sum network multiagent matrix games and\nprove that alternating gradient descent converges to the set of Nash equilibria\nat rate $O(1/T)$ for this set of games. Alternating gradient descent obtains\nthis convergence guarantee while using fixed learning rates that are four times\nlarger than the optimistic variant of gradient descent. Experimentally, we show\nwith 97.5% confidence that, on average, these larger learning rates result in\ntime-averaged strategies that are 2.585 times closer to the set of Nash\nequilibria than optimistic gradient descent.",
    "descriptor": "",
    "authors": [
      "James P. Bailey"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.02482"
  },
  {
    "id": "arXiv:2110.02484",
    "title": "Shapley variable importance clouds for interpretable machine learning",
    "abstract": "Interpretable machine learning has been focusing on explaining final models\nthat optimize performance. The current state-of-the-art is the Shapley additive\nexplanations (SHAP) that locally explains variable impact on individual\npredictions, and it is recently extended for a global assessment across the\ndataset. Recently, Dong and Rudin proposed to extend the investigation to\nmodels from the same class as the final model that are \"good enough\", and\nidentified a previous overclaim of variable importance based on a single model.\nHowever, this method does not directly integrate with existing Shapley-based\ninterpretations. We close this gap by proposing a Shapley variable importance\ncloud that pools information across good models to avoid biased assessments in\nSHAP analyses of final models, and communicate the findings via novel\nvisualizations. We demonstrate the additional insights gain compared to\nconventional explanations and Dong and Rudin's method using criminal justice\nand electronic medical records data.",
    "descriptor": "",
    "authors": [
      "Yilin Ning",
      "Marcus Eng Hock Ong",
      "Bibhas Chakraborty",
      "Benjamin Alan Goldstein",
      "Daniel Shu Wei Ting",
      "Roger Vaughan",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02484"
  },
  {
    "id": "arXiv:2110.02485",
    "title": "Tensor regularization by truncated iteration: a comparison of some  solution methods for large-scale linear discrete ill-posed problem with a  t-product",
    "abstract": "This paper describes and compares some structure preserving techniques for\nthe solution of linear discrete ill-posed problems with the t-product. A new\nrandomized tensor singular value decomposition (R-tSVD) with a t-product is\npresented for low tubal rank tensor approximations. Regularization of linear\ninverse problems by truncated tensor eigenvalue decomposition (T-tEVD),\ntruncated tSVD (T-tSVD), randomized T-tSVD (RT-tSVD), t-product Golub-Kahan\nbidiagonalization (tGKB) process, and t-product Lanczos (t-Lanczos) process are\nconsidered. A solution method that is based on reusing tensor Krylov subspaces\ngenerated by the tGKB process is described. The regularization parameter is the\nnumber of iterations required by each method. The discrepancy principle is used\nto determine this parameter. Solution methods that are based on truncated\niterations are compared with solution methods that combine Tikhonov\nregularization with the tGKB and t-Lanczos processes. Computed examples\nillustrate the performance of these methods when applied to image and\ngray-scale video restorations. Our new RT-tSVD method is seen to require less\nCPU time and yields restorations of higher quality than the T-tSVD method.",
    "descriptor": "",
    "authors": [
      "Ugochukwu O. Ugwu",
      "Lothar Reichel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02485"
  },
  {
    "id": "arXiv:2110.02488",
    "title": "ABC: Attention with Bounded-memory Control",
    "abstract": "Transformer architectures have achieved state-of-the-art results on a variety\nof sequence modeling tasks. However, their attention mechanism comes with a\nquadratic complexity in sequence lengths, making the computational overhead\nprohibitive, especially for long sequences. Attention context can be seen as a\nrandom-access memory with each token taking a slot. Under this perspective, the\nmemory size grows linearly with the sequence length, and so does the overhead\nof reading from it. One way to improve the efficiency is to bound the memory\nsize. We show that disparate approaches can be subsumed into one abstraction,\nattention with bounded-memory control (ABC), and they vary in their\norganization of the memory. ABC reveals new, unexplored possibilities. First,\nit connects several efficient attention variants that would otherwise seem\napart. Second, this abstraction gives new insights--an established approach\n(Wang et al., 2020b) previously thought to be not applicable in causal\nattention, actually is. Last, we present a new instance of ABC, which draws\ninspiration from existing ABC approaches, but replaces their heuristic\nmemory-organizing functions with a learned, contextualized one. Our experiments\non language modeling, machine translation, and masked language model finetuning\nshow that our approach outperforms previous efficient attention models;\ncompared to the strong transformer baselines, it significantly improves the\ninference time and space efficiency with no or negligible accuracy loss.",
    "descriptor": "",
    "authors": [
      "Hao Peng",
      "Jungo Kasai",
      "Nikolaos Pappas",
      "Dani Yogatama",
      "Zhaofeng Wu",
      "Lingpeng Kong",
      "Roy Schwartz",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02488"
  },
  {
    "id": "arXiv:2110.02490",
    "title": "The Variability of Model Specification",
    "abstract": "It's regarded as an axiom that a good model is one that compromises between\nbias and variance. The bias is measured in training cost, while the variance of\na (say, regression) model is measure by the cost associated with a validation\nset. If reducing bias is the goal, one will strive to fetch as complex a model\nas necessary, but complexity is invariably coupled with variance: greater\ncomplexity implies greater variance. In practice, driving training cost to near\nzero does not pose a fundamental problem; in fact, a sufficiently complex\ndecision tree is perfectly capable of driving training cost to zero; however,\nthe problem is often with controlling the model's variance. We investigate\nvarious regression model frameworks, including generalized linear models, Cox\nproportional hazard models, ARMA, and illustrate how misspecifying a model\naffects the variance.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Joseph R. Barr",
      "Peter Shaw",
      "Marcus Sobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.02490"
  },
  {
    "id": "arXiv:2110.02491",
    "title": "Data-Centric AI Requires Rethinking Data Notion",
    "abstract": "The transition towards data-centric AI requires revisiting data notions from\nmathematical and implementational standpoints to obtain unified data-centric\nmachine learning packages. Towards this end, this work proposes unifying\nprinciples offered by categorical and cochain notions of data, and discusses\nthe importance of these principles in data-centric AI transition. In the\ncategorical notion, data is viewed as a mathematical structure that we act upon\nvia morphisms to preserve this structure. As for cochain notion, data can be\nviewed as a function defined in a discrete domain of interest and acted upon\nvia operators. While these notions are almost orthogonal, they provide a\nunifying definition to view data, ultimately impacting the way machine learning\npackages are developed, implemented, and utilized by practitioners.",
    "descriptor": "",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Karthikeyan Natesan Ramamurthy",
      "Aldo Guzman Saenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02491"
  },
  {
    "id": "arXiv:2110.02493",
    "title": "Tight Bounds on the Optimal UL Sum-Rate of MU RIS-aided Wireless Systems",
    "abstract": "The objective of this paper is to develop simple techniques to bound the\noptimal uplink sum-rate of multi-user RIS-aided wireless systems. Specifically,\nwe develop a novel technique called \\textit{channel separation} which provides\na new understanding as to how the RIS phases affect the sum-rate. Leveraging\nchannel separation, we derive upper and lower bounds on the optimal sum-rate.\nIn addition, we propose a low-complexity alternating optimization algorithm to\nobtain near-optimal sum-rate results. Numerical results demonstrate the\ntightness of the bounds and show that the alternating optimization approach\ndelivers sum-rate values similar to the results of a full numerical\noptimization procedure. Furthermore, in practical scenarios where hardware\nlimitations cause the RIS phases to be quantized, our lower bound can still be\napplied and shows that the sum-rate is robust to quantization, even with low\nresolution.",
    "descriptor": "\nComments: reconfigurable intelligent surface, intelligent reflecting surface, RIS, optimal sum rate tight bound, optimal sum rate\n",
    "authors": [
      "Ikram Singh",
      "Peter J. Smith",
      "Pawel A. Dmochowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02493"
  },
  {
    "id": "arXiv:2110.02495",
    "title": "Deep Random Forest with Ferroelectric Analog Content Addressable Memory",
    "abstract": "Deep random forest (DRF), which incorporates the core features of deep\nlearning and random forest (RF), exhibits comparable classification accuracy,\ninterpretability, and low memory and computational overhead when compared with\ndeep neural networks (DNNs) in various information processing tasks for edge\nintelligence. However, the development of efficient hardware to accelerate DRF\nis lagging behind its DNN counterparts. The key for hardware acceleration of\nDRF lies in efficiently realizing the branch-split operation at decision nodes\nwhen traversing a decision tree. In this work, we propose to implement DRF\nthrough simple associative searches realized with ferroelectric analog content\naddressable memory (ACAM). Utilizing only two ferroelectric field effect\ntransistors (FeFETs), the ultra-compact ACAM cell can perform a branch-split\noperation with an energy-efficient associative search by storing the decision\nboundaries as the analog polarization states in an FeFET. The DRF accelerator\narchitecture and the corresponding mapping of the DRF model to the ACAM arrays\nare presented. The functionality, characteristics, and scalability of the FeFET\nACAM based DRF and its robustness against FeFET device non-idealities are\nvalidated both in experiments and simulations. Evaluation results show that the\nFeFET ACAM DRF accelerator exhibits 10^6x/16x and 10^6x/2.5x improvements in\nterms of energy and latency when compared with other deep random forest\nhardware implementations on the state-of-the-art CPU/ReRAM, respectively.",
    "descriptor": "\nComments: 44 pages, 16 figures\n",
    "authors": [
      "Xunzhao Yin",
      "Franz M\u00fcller",
      "Ann Franchesca Laguna",
      "Chao Li",
      "Wenwen Ye",
      "Qingrong Huang",
      "Qinming Zhang",
      "Zhiguo Shi",
      "Maximilian Lederer",
      "Nellie Laleni",
      "Shan Deng",
      "Zijian Zhao",
      "Michael Niemier",
      "Xiaobo Sharon Hu",
      "Cheng Zhuo",
      "Thomas K\u00e4mpfe",
      "Kai Ni"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02495"
  },
  {
    "id": "arXiv:2110.02497",
    "title": "Pretraining & Reinforcement Learning: Sharpening the Axe Before Cutting  the Tree",
    "abstract": "Pretraining is a common technique in deep learning for increasing performance\nand reducing training time, with promising experimental results in deep\nreinforcement learning (RL). However, pretraining requires a relevant dataset\nfor training. In this work, we evaluate the effectiveness of pretraining for RL\ntasks, with and without distracting backgrounds, using both large, publicly\navailable datasets with minimal relevance, as well as case-by-case generated\ndatasets labeled via self-supervision. Results suggest filters learned during\ntraining on less relevant datasets render pretraining ineffective, while\nfilters learned during training on the in-distribution datasets reliably reduce\nRL training time and improve performance after 80k RL training steps. We\nfurther investigate, given a limited number of environment steps, how to\noptimally divide the available steps into pretraining and RL training to\nmaximize RL performance. Our code is available on GitHub",
    "descriptor": "",
    "authors": [
      "Saurav Kadavath",
      "Samuel Paradis",
      "Brian Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02497"
  },
  {
    "id": "arXiv:2110.02498",
    "title": "Adversarial Attacks on Machinery Fault Diagnosis",
    "abstract": "Despite the great progress of neural network-based (NN-based) machinery fault\ndiagnosis methods, their robustness has been largely neglected, for they can be\neasily fooled through adding imperceptible perturbation to the input. For fault\ndiagnosis problems, in this paper, we reformulate various adversarial attacks\nand intensively investigate them under untargeted and targeted conditions.\nExperimental results on six typical NN-based models show that accuracies of the\nmodels are greatly reduced by adding small perturbations. We further propose a\nsimple, efficient and universal scheme to protect the victim models. This work\nprovides an in-depth look at adversarial examples of machinery vibration\nsignals for developing protection methods against adversarial attack and\nimproving the robustness of NN-based models.",
    "descriptor": "\nComments: 5 pages, 5 figures. Submitted to ICASSP 2022\n",
    "authors": [
      "Jiahao Chen",
      "Diqun Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02498"
  },
  {
    "id": "arXiv:2110.02501",
    "title": "Sharp Learning Bounds for Contrastive Unsupervised Representation  Learning",
    "abstract": "Contrastive unsupervised representation learning (CURL) encourages data\nrepresentation to make semantically similar pairs closer than randomly drawn\nnegative samples, which has been successful in various domains such as vision,\nlanguage, and graphs. Although recent theoretical studies have attempted to\nexplain its success by upper bounds of a downstream classification loss by the\ncontrastive loss, they are still not sharp enough to explain an experimental\nfact: larger negative samples improve the classification performance. This\nstudy establishes a downstream classification loss bound with a tight intercept\nin the negative sample size. By regarding the contrastive loss as a downstream\nloss estimator, our theory not only improves the existing learning bounds\nsubstantially but also explains why downstream classification empirically\nimproves with larger negative samples -- because the estimation variance of the\ndownstream loss decays with larger negative samples. We verify that our theory\nis consistent with experiments on synthetic, vision, and language datasets.",
    "descriptor": "",
    "authors": [
      "Han Bao",
      "Yoshihiro Nagano",
      "Kento Nozawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02501"
  },
  {
    "id": "arXiv:2110.02503",
    "title": "More on Change-Making and Related Problems",
    "abstract": "Given a set of $n$ integer-valued coin types and a target value $t$, the\nwell-known change-making problem asks for the minimum number of coins that sum\nto $t$, assuming an unlimited number of coins in each type. In the more general\nall-targets version of the problem, we want the minimum number of coins summing\nto $j$, for every $j=0,\\ldots,t$. For example, the textbook dynamic programming\nalgorithms can solve the all-targets problem in $O(nt)$ time. Recently, Chan\nand He (SOSA'20) described a number of $O(t\\,\\textrm{polylog}\\,t)$-time\nalgorithms for the original (single-target) version of the change-making\nproblem, but not the all-targets version.\nWe obtain a number of new results on change-making and related problems,\nincluding:\n1. A new algorithm for the all-targets change-making problem with running\ntime $\\tilde{O}(t^{4/3})$, improving a previous $\\tilde{O}(t^{3/2})$-time\nalgorithm.\n2. A very simple $\\tilde{O}(u^2+t)$-time algorithm for the all-targets\nchange-making problem, where $u$ denotes the maximum coin value. The analysis\nof the algorithm uses a theorem of Erd\\H{o}s and Graham (1972) on the Frobenius\nproblem. This algorithm can be extended to solve the all-capacities version of\nthe unbounded knapsack problem (for integer item weights bounded by $u$).\n3. For the original (single-target) coin changing problem, we describe a\nsimple modification of one of Chan and He's algorithms that runs in\n$\\tilde{O}(u)$ time (instead of $\\tilde{O}(t)$).\n4. For the original (single-capacity) unbounded knapsack problem, we describe\na simple algorithm that runs in $\\tilde{O}(nu)$ time, improving previous\nnear-$u^2$-time algorithms.\n5. We also observe how one of our ideas implies a new result on the minimum\nword break problem, an optimization version of a string problem studied by\nBringmann et al. (FOCS'17), generalizing change-making (which corresponds to\nthe unary special case).",
    "descriptor": "\nComments: This is the full version of our ESA 2020 paper\n",
    "authors": [
      "Timothy M. Chan",
      "Qizheng He"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02503"
  },
  {
    "id": "arXiv:2110.02504",
    "title": "Stegomalware: A Systematic Survey of MalwareHiding and Detection in  Images, Machine LearningModels and Research Challenges",
    "abstract": "Malware distribution to the victim network is commonly performed through file\nattachments in phishing email or from the internet, when the victim interacts\nwith the source of infection. To detect and prevent the malware distribution in\nthe victim machine, the existing end device security applications may leverage\ntechniques such as signature or anomaly-based, machine learning techniques. The\nwell-known file formats Portable Executable (PE) for Windows and Executable and\nLinkable Format (ELF) for Linux based operating system are used for malware\nanalysis, and the malware detection capabilities of these files has been well\nadvanced for real-time detection. But the malware payload hiding in multimedia\nusing steganography detection has been a challenge for enterprises, as these\nare rarely seen and usually act as a stager in sophisticated attacks. In this\narticle, to our knowledge, we are the first to try to address the knowledge gap\nbetween the current progress in image steganography and steganalysis academic\nresearch focusing on data hiding and the review of the stegomalware (malware\npayload hiding in images) targeting enterprises with cyberattacks current\nstatus. We present the stegomalware history, generation tools, file format\nspecification description. Based on our findings, we perform the detail review\nof the image steganography techniques including the recent Generative\nAdversarial Networks (GAN) based models and the image steganalysis methods\nincluding the Deep Learning(DL) models for hiding data detection. Additionally,\nthe stegomalware detection framework for enterprise is proposed for anomaly\nbased stegomalware detection emphasizing the architecture details for different\nnetwork environments. Finally, the research opportunities and challenges in\nstegomalware generation and detection are also presented.",
    "descriptor": "",
    "authors": [
      "Rajasekhar Chaganti",
      "Vinayakumar Ravi",
      "Mamoun Alazab",
      "Tuan D. Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02504"
  },
  {
    "id": "arXiv:2110.02508",
    "title": "Online Hyperparameter Meta-Learning with Hypergradient Distillation",
    "abstract": "Many gradient-based meta-learning methods assume a set of parameters that do\nnot participate in inner-optimization, which can be considered as\nhyperparameters. Although such hyperparameters can be optimized using the\nexisting gradient-based hyperparameter optimization (HO) methods, they suffer\nfrom the following issues. Unrolled differentiation methods do not scale well\nto high-dimensional hyperparameters or horizon length, Implicit Function\nTheorem (IFT) based methods are restrictive for online optimization, and short\nhorizon approximations suffer from short horizon bias. In this work, we propose\na novel HO method that can overcome these limitations, by approximating the\nsecond-order term with knowledge distillation. Specifically, we parameterize a\nsingle Jacobian-vector product (JVP) for each HO step and minimize the distance\nfrom the true second-order term. Our method allows online optimization and also\nis scalable to the hyperparameter dimension and the horizon length. We\ndemonstrate the effectiveness of our method on two different meta-learning\nmethods and three benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Hae Beom Lee",
      "Hayeon Lee",
      "Jaewoong Shin",
      "Eunho Yang",
      "Timothy Hospedales",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02508"
  },
  {
    "id": "arXiv:2110.02509",
    "title": "Design and Implementation of 5.8GHz RF Wireless PowerTransfer System",
    "abstract": "In this paper, we present a 5.8 GHz radio-frequency (RF) wireless power\ntransfer (WPT) system that consists of 64 transmit antennas and 16 receive\nantennas. Unlike the inductive or resonant coupling-based near-field WPT, RF\nWPT has a great advantage in powering low-power internet of things (IoT)\ndevices with its capability of long-range wireless power transfer. We also\npropose a beam scanning algorithm that can effectively transfer the power no\nmatter whether the receiver is located in the radiative near-field zone or\nfar-field zone. The proposed beam scanning algorithm is verified with a\nreal-life WPT testbed implemented by ourselves. By experiments, we confirm that\nthe implemented 5.8 GHz RF WPT system is able to transfer 3.67 mW at a distance\nof 25 meters with the proposed beam scanning algorithm. Moreover, the results\nshow that the proposed algorithm can effectively cover radiative near-field\nregion differently from the conventional scanning schemes which are designed\nunder the assumption of the far-field WPT.",
    "descriptor": "",
    "authors": [
      "Je Hyeon Park",
      "Nguyen Minh Tran",
      "Sa Il Hwang",
      "Dong In Kim",
      "Kae Won Choi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02509"
  },
  {
    "id": "arXiv:2110.02510",
    "title": "A Topological View of Rule Learning in Knowledge Graphs",
    "abstract": "Inductive relation prediction is an important learning task for knowledge\ngraph completion. One can use the existence of rules, namely a sequence of\nrelations, to predict the relation between two entities. Previous works view\nrules as paths and primarily focus on the searching of paths between entities.\nThe space of paths is huge, and one has to sacrifice either efficiency or\naccuracy. In this paper, we consider rules in knowledge graphs as cycles and\nshow that the space of cycles has a unique structure based on the theory of\nalgebraic topology. By exploring the linear structure of the cycle space, we\ncan improve the searching efficiency of rules. We propose to collect cycle\nbases that span the space of cycles. We build a novel GNN framework on the\ncollected cycles to learn the representations of cycles, and to predict the\nexistence/non-existence of a relation. Our method achieves state-of-the-art\nperformance on benchmarks.",
    "descriptor": "",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02510"
  },
  {
    "id": "arXiv:2110.02513",
    "title": "UGV-assisted Wireless Powered Backscatter Communications for Large-Scale  IoT Networks",
    "abstract": "Wireless powered backscatter communications (WPBC) is capable of implementing\nultra-low-power communication, thus promising in the Internet of Things (IoT)\nnetworks. In practice, however, it is challenging to apply WPBC in large-scale\nIoT networks because of its short communication range. To address this\nchallenge, this paper exploits an unmanned ground vehicle (UGV) to assist WPBC\nin large-scale IoT networks. In particular, we investigate the joint design of\nnetwork planning and dynamic resource allocation of the access point (AP), tag\nreader, and UGV to minimize the total energy consumption. Also, the AP can\noperate in either half-duplex (HD) or full-duplex (FD) multiplexing mode. Under\nHD mode, the optimal cell radius is derived and the optimal power allocation\nand transmit/receive beamforming are obtained in closed form. Under FD mode,\nthe optimal resource allocation, as well as two suboptimal ones with low\ncomputational complexity, is developed. Simulation results disclose that\ndynamic power allocation at the tag reader rather than at the AP dominates the\nnetwork energy efficiency while the AP operating in FD mode outperforms that in\nHD mode concerning energy efficienc",
    "descriptor": "\nComments: 15 pages, 7 figures, to appear in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Erhu Chen",
      "Peiran Wu",
      "Yik-Chung Wu",
      "Minghua Xia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02513"
  },
  {
    "id": "arXiv:2110.02514",
    "title": "ViewfinderVR: Configurable Viewfinder for Selection of Distant Objects  in VR",
    "abstract": "Selection is one of the fundamental user interactions in virtual reality (VR)\nand 3D user interaction, and raycasting has been one of the most popular object\nselection techniques in VR. However, the selection of small or distant objects\nthrough raycasting has been known to be difficult. To overcome this limitation,\nthis study proposed a new technique called ViewfinderVR for improved selection\nof distant objects in VR, utilizing a virtual viewfinder panel with a modern\nadaptation of the through-the-lens metaphor. ViewfinderVR enables faster and\nmore accurate target selection by allowing customization of the interaction\nspace projected onto a virtual panel within reach, and users can select objects\nreflected on the panel with either ray-based or touch interaction. Experimental\nresults of Fitts' law-based tests with 20 participants showed that ViewfinderVR\noutperformed traditional raycasting in terms of task performance (movement\ntime, error rate, and throughput) and perceived workload (NASA-TLX ratings),\nwhere touch interaction was superior to ray-based interaction. The associated\nuser behavior was also recorded and analyzed to understand the underlying\nreasons for the improved task performance and reduced workload. The proposed\ntechnique can be used in VR applications to enhance the selection of distant\nobjects.",
    "descriptor": "",
    "authors": [
      "Woojoo Kim",
      "Shuping Xiong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02514"
  },
  {
    "id": "arXiv:2110.02515",
    "title": "A Sparsity Adaptive Algorithm to Recover NB-IoT Signal from Legacy LTE  Interference",
    "abstract": "As a forerunner in 5G technologies, Narrowband Internet of Things (NB-IoT)\nwill be inevitably coexisting with the legacy Long-Term Evolution (LTE) system.\nThus, it is imperative for NB-IoT to mitigate LTE interference. By virtue of\nthe strong temporal correlation of the NB-IoT signal, this letter develops a\nsparsity adaptive algorithm to recover the NB-IoT signal from legacy LTE\ninterference, by combining $K$-means clustering and sparsity adaptive matching\npursuit (SAMP). In particular, the support of the NB-IoT signal is first\nestimated coarsely by $K$-means clustering and SAMP algorithm without sparsity\nlimitation. Then, the estimated support is refined by a repeat mechanism.\nSimulation results demonstrate the effectiveness of the developed algorithm in\nterms of recovery probability and bit error rate, compared with competing\nalgorithms.",
    "descriptor": "\nComments: 5 pages, 7 figures, to appear in IEEE Wireless Communications Letters\n",
    "authors": [
      "Yijia Guo",
      "Wenkun Wen",
      "Peiran Wu",
      "Minghua Xia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02515"
  },
  {
    "id": "arXiv:2110.02516",
    "title": "Attack as the Best Defense: Nullifying Image-to-image Translation GANs  via Limit-aware Adversarial Attack",
    "abstract": "With the successful creation of high-quality image-to-image (Img2Img)\ntranslation GANs comes the non-ethical applications of DeepFake and DeepNude.\nSuch misuses of img2img techniques present a challenging problem for society.\nIn this work, we tackle the problem by introducing the Limit-Aware Self-Guiding\nGradient Sliding Attack (LaS-GSA). LaS-GSA follows the Nullifying Attack to\ncancel the img2img translation process under a black-box setting. In other\nwords, by processing input images with the proposed LaS-GSA before publishing,\nany targeted img2img GANs can be nullified, preventing the model from\nmaliciously manipulating the images. To improve efficiency, we introduce the\nlimit-aware random gradient-free estimation and the gradient sliding mechanism\nto estimate the gradient that adheres to the adversarial limit, i.e., the pixel\nvalue limitations of the adversarial example. Theoretical justifications\nvalidate how the above techniques prevent inefficiency caused by the\nadversarial limit in both the direction and the step length. Furthermore, an\neffective self-guiding prior is extracted solely from the threat model and the\ntarget image to efficiently leverage the prior information and guide the\ngradient estimation process. Extensive experiments demonstrate that LaS-GSA\nrequires fewer queries to nullify the image translation process with higher\nsuccess rates than 4 state-of-the-art black-box methods.",
    "descriptor": "",
    "authors": [
      "Chin-Yuan Yeh",
      "Hsi-Wen Chen",
      "Hong-Han Shuai",
      "De-Nian Yang",
      "Ming-Syan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02516"
  },
  {
    "id": "arXiv:2110.02521",
    "title": "ActiveMatch: End-to-end Semi-supervised Active Representation Learning",
    "abstract": "Semi-supervised learning (SSL) is an efficient framework that can train\nmodels with both labeled and unlabeled data. However, constrained by the\nlimited number of labels, the learned representations of SSL are ambiguous and\nnot distinguishable for inter-class samples. Moreover, the performance of SSL\nis also largely dependent on the model initialization. To deal with the\ndrawbacks of SSL, in this paper, we propose a novel end-to-end representation\nlearning method, namely ActiveMatch, which combines SSL with contrastive\nlearning and active learning to fully leverage the limited labels. Starting\nfrom a small amount of labeled data with unsupervised contrastive learning as a\nwarm-up, ActiveMatch then combines SSL and supervised contrastive learning, and\nactively selects the most representative samples for labeling during the\ntraining, resulting in better representations towards the classification.\nCompared with MixMatch and FixMatch, we show that ActiveMatch achieves the\nstate-of-the-art performance, with 89.24 accuracy on CIFAR-10 with 100\ncollected labels, and 92.20 accuracy with 200 collected labels.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to ICASSP 2022\n",
    "authors": [
      "Xinkai Yuan",
      "Zilinghan Li",
      "Gaoang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02521"
  },
  {
    "id": "arXiv:2110.02523",
    "title": "KNN-BERT: Fine-Tuning Pre-Trained Models with KNN Classifier",
    "abstract": "Pre-trained models are widely used in fine-tuning downstream tasks with\nlinear classifiers optimized by the cross-entropy loss, which might face\nrobustness and stability problems. These problems can be improved by learning\nrepresentations that focus on similarities in the same class and contradictions\nin different classes when making predictions. In this paper, we utilize the\nK-Nearest Neighbors Classifier in pre-trained model fine-tuning. For this KNN\nclassifier, we introduce a supervised momentum contrastive learning framework\nto learn the clustered representations of the supervised downstream tasks.\nExtensive experiments on text classification tasks and robustness tests show\nthat by incorporating KNNs with the traditional fine-tuning process, we can\nobtain significant improvements on the clean accuracy in both rich-source and\nfew-shot settings and can improve the robustness against adversarial attacks.\n\\footnote{all codes is available at https://github.com/LinyangLee/KNN-BERT}",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Linyang Li",
      "Demin Song",
      "Ruotian Ma",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02523"
  },
  {
    "id": "arXiv:2110.02525",
    "title": "User Scheduling and Power Allocation for Precoded Multi-Beam High  Throughput Satellite Systems with Individual Quality of Service Constraints",
    "abstract": "For extensive coverage areas, multi-beam high throughput satellite (MB-HTS)\ncommunication is a promising technology that plays a crucial role in delivering\nbroadband services to many users with diverse Quality of Service (QoS)\nrequirements. This paper focuses on MB-HTS systems where all beams reuse the\nsame spectrum. In particular, we propose a novel user scheduling and power\nallocation design capable of providing guarantees in terms of the individual\nQoS requirements while maximizing the system throughput under a limited power\nbudget. Precoding is employed in the forward link to mitigate mutual\ninterference at the users in multiple-access scenarios over different coherence\ntime intervals. The combinatorial optimization structure from user scheduling\nrequires an extremely high cost to obtain the global optimum even when a\nreduced number of users fit into a time slot. Therefore, we propose a heuristic\nalgorithm yielding good trade-off between performance and computational\ncomplexity, applicable to a static operation framework of geostationary (GEO)\nsatellite networks. Although the power allocation optimization is signomial\nprogramming, non-convex on a standard form, the solution can be lower bounded\nby the global optimum of a geometric program with a hidden convex structure. A\nlocal solution to the joint user scheduling and power allocation problem is\nconsequently obtained by a successive optimization approach. Numerical results\ndemonstrate the effectiveness of our algorithms on large-scale systems by\nproviding better QoS satisfaction combined with outstanding overall system\nthroughput.",
    "descriptor": "\nComments: 14 pages, 8 figures, and 1 table. Submitted to the IEEE for publication. arXiv admin note: substantial text overlap with arXiv:2106.12873\n",
    "authors": [
      "Trinh Van Chien",
      "Eva Lagunas",
      "Tung Hai Ta",
      "Symeon Chatzinotas",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02525"
  },
  {
    "id": "arXiv:2110.02526",
    "title": "Coarse-to-Fine Reasoning for Visual Question Answering",
    "abstract": "Bridging the semantic gap between image and question is an important step to\nimprove the accuracy of the Visual Question Answering (VQA) task. However, most\nof the existing VQA methods focus on attention mechanisms or visual relations\nfor reasoning the answer, while the features at different semantic levels are\nnot fully utilized. In this paper, we present a new reasoning framework to fill\nthe gap between visual features and semantic clues in the VQA task. Our method\nfirst extracts the features and predicates from the image and question. We then\npropose a new reasoning framework to effectively jointly learn these features\nand predicates in a coarse-to-fine manner. The intensively experimental results\non three large-scale VQA datasets show that our proposed approach achieves\nsuperior accuracy comparing with other state-of-the-art methods. Furthermore,\nour reasoning framework also provides an explainable way to understand the\ndecision of the deep neural network when predicting the answer.",
    "descriptor": "",
    "authors": [
      "Binh X. Nguyen",
      "Tuong Do",
      "Huy Tran",
      "Erman Tjiputra",
      "Quang D. Tran",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02526"
  },
  {
    "id": "arXiv:2110.02529",
    "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
    "abstract": "Learning accurate classifiers for novel categories from very few examples,\nknown as few-shot image classification, is a challenging task in statistical\nmachine learning and computer vision. The performance in few-shot\nclassification suffers from the bias in the estimation of classifier\nparameters; however, an effective underlying bias reduction technique that\ncould alleviate this issue in training few-shot classifiers has been\noverlooked. In this work, we demonstrate the effectiveness of Firth bias\nreduction in few-shot classification. Theoretically, Firth bias reduction\nremoves the first order term $O(N^{-1})$ from the small-sample bias of the\nMaximum Likelihood Estimator. Here we show that the general Firth bias\nreduction technique simplifies to encouraging uniform class assignment\nprobabilities for multinomial logistic classification, and almost has the same\neffect in cosine classifiers. We derive the optimization objective for Firth\npenalized multinomial logistic and cosine classifiers, and empirically evaluate\nthat it is consistently effective across the board for few-shot image\nclassification, regardless of (1) the feature representations from different\nbackbones, (2) the number of samples per class, and (3) the number of classes.\nFinally, we show the robustness of Firth bias reduction, in the case of\nimbalanced data distribution. Our implementation is available at\nhttps://github.com/ehsansaleh/firth_bias_reduction",
    "descriptor": "",
    "authors": [
      "Saba Ghaffari",
      "Ehsan Saleh",
      "David Forsyth",
      "Yu-xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02529"
  },
  {
    "id": "arXiv:2110.02531",
    "title": "3D-FCT: Simultaneous 3D Object Detection and Tracking Using Feature  Correlation",
    "abstract": "3D object detection using LiDAR data remains a key task for applications like\nautonomous driving and robotics. Unlike in the case of 2D images, LiDAR data is\nalmost always collected over a period of time. However, most work in this area\nhas focused on performing detection independent of the temporal domain. In this\npaper we present 3D-FCT, a Siamese network architecture that utilizes temporal\ninformation to simultaneously perform the related tasks of 3D object detection\nand tracking. The network is trained to predict the movement of an object based\non the correlation features of extracted keypoints across time. Calculating\ncorrelation across keypoints only allows for real-time object detection. We\nfurther extend the multi-task objective to include a tracking regression loss.\nFinally, we produce high accuracy detections by linking short-term object\ntracklets into long term tracks based on the predicted tracks. Our proposed\nmethod is evaluated on the KITTI tracking dataset where it is shown to provide\nan improvement of 5.57% mAP over a state-of-the-art approach.",
    "descriptor": "",
    "authors": [
      "Naman Sharma",
      "Hocksoon Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02531"
  },
  {
    "id": "arXiv:2110.02538",
    "title": "A Local Updating Algorithm for Personalized PageRank via Chebyshev  Polynomials",
    "abstract": "The personalized PageRank algorithm is one of the most versatile tools for\nthe analysis of networks. In spite of its ubiquity, maintaining personalized\nPageRank vectors when the underlying network constantly evolves is still a\nchallenging task. To address this limitation, this work proposes a novel\ndistributed algorithm to locally update personalized PageRank vectors when the\ngraph topology changes. The proposed algorithm is based on the use of Chebyshev\npolynomials and a novel update equation that encompasses a large family of\nPageRank-based methods. In particular, the algorithm has the following\nadvantages: (i) it has faster convergence speed than state-of-the-art\nalternatives for local PageRank updating; and (ii) it can update the solution\nof recent generalizations of PageRank for which no updating algorithms have\nbeen developed. Experiments in a real-world temporal network of an autonomous\nsystem validate the effectiveness of the proposed algorithm.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Esteban Bautista",
      "Matthieu Latapy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02538"
  },
  {
    "id": "arXiv:2110.02543",
    "title": "A logical approach for temporal and multiplex networks analysis",
    "abstract": "Many systems generate data as a set of triplets (a, b, c): they may represent\nthat user a called b at time c or that customer a purchased product b in store\nc. These datasets are traditionally studied as networks with an extra dimension\n(time or layer), for which the fields of temporal and multiplex networks have\nextended graph theory to account for the new dimension. However, such\nframeworks detach one variable from the others and allow to extend one same\nconcept in many ways, making it hard to capture patterns across all dimensions\nand to identify the best definitions for a given dataset. This extended\nabstract overrides this vision and proposes a direct processing of the set of\ntriplets. In particular, our work shows that a more general analysis is\npossible by partitioning the data and building categorical propositions that\nencode informative patterns. We show that several concepts from graph theory\ncan be framed under this formalism and leverage such insights to extend the\nconcepts to data triplets. Lastly, we propose an algorithm to list propositions\nsatisfying specific constraints and apply it to a real world dataset.",
    "descriptor": "\nComments: Extended abstract accepted at The 10th International Conference on Complex Networks and their Applications, 3 Pages\n",
    "authors": [
      "Esteban Bautista",
      "Matthieu Latapy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02543"
  },
  {
    "id": "arXiv:2110.02544",
    "title": "Learning to Iteratively Solve Routing Problems with Dual-Aspect  Collaborative Transformer",
    "abstract": "Recently, Transformer has become a prevailing deep architecture for solving\nvehicle routing problems (VRPs). However, it is less effective in learning\nimprovement models for VRP because its positional encoding (PE) method is not\nsuitable in representing VRP solutions. This paper presents a novel Dual-Aspect\nCollaborative Transformer (DACT) to learn embeddings for the node and\npositional features separately, instead of fusing them together as done in\nexisting ones, so as to avoid potential noises and incompatible correlations.\nMoreover, the positional features are embedded through a novel cyclic\npositional encoding (CPE) method to allow Transformer to effectively capture\nthe circularity and symmetry of VRP solutions (i.e., cyclic sequences). We\ntrain DACT using Proximal Policy Optimization and design a curriculum learning\nstrategy for better sample efficiency. We apply DACT to solve the traveling\nsalesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results\nshow that our DACT outperforms existing Transformer based improvement models,\nand exhibits much better generalization performance across different problem\nsizes on synthetic and benchmark instances, respectively.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yining Ma",
      "Jingwen Li",
      "Zhiguang Cao",
      "Wen Song",
      "Le Zhang",
      "Zhenghua Chen",
      "Jing Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02544"
  },
  {
    "id": "arXiv:2110.02548",
    "title": "Data-Driven Substructuring Technique for Pseudo-Dynamic Hybrid  Simulation of Steel Braced Frames",
    "abstract": "This paper proposes a new substructuring technique for hybrid simulation of\nsteel braced frame structures under seismic loading in which a new machine\nlearning-based model is used to predict the hysteretic response of steel\nbraces. Corroborating numerical data is used to train the model, referred to as\nPI-SINDy, developed with the aid of the Prandtl-Ishlinskii hysteresis model and\nsparse identification algorithm. By replacing a brace part of a prototype steel\nbuckling-restrained braced frame with the trained PI-SINDy model, a new\nsimulation technique referred to as data-driven hybrid simulation (DDHS) is\nestablished. The accuracy of DDHS is evaluated using the nonlinear response\nhistory analysis of the prototype frame subjected to an earthquake ground\nmotion. Compared to a baseline pure numerical model, the results show that the\nproposed model can accurately predict the hysteretic response of steel\nbuckling-restrained braces.",
    "descriptor": "\nComments: Submitted to STESSA 2021\n",
    "authors": [
      "Fardad Mokhtari",
      "Ali Imanpour"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.02548"
  },
  {
    "id": "arXiv:2110.02549",
    "title": "See Yourself in Others: Attending Multiple Tasks for Own Failure  Detection",
    "abstract": "Autonomous robots deal with unexpected scenarios in real environments. Given\ninput images, various visual perception tasks can be performed, e.g., semantic\nsegmentation, depth estimation and normal estimation. These different tasks\nprovide rich information for the whole robotic perception system. All tasks\nhave their own characteristics while sharing some latent correlations. However,\nsome of the task predictions may suffer from the unreliability dealing with\ncomplex scenes and anomalies. We propose an attention-based failure detection\napproach by exploiting the correlations among multiple tasks. The proposed\nframework infers task failures by evaluating the individual prediction, across\nmultiple visual perception tasks for different regions in an image. The\nformulation of the evaluations is based on an attention network supervised by\nmulti-task uncertainty estimation and their corresponding prediction errors.\nOur proposed framework generates more accurate estimations of the prediction\nerror for the different task's predictions.",
    "descriptor": "",
    "authors": [
      "Boyang Sun",
      "Jiaxu Xing",
      "Hermann Blum",
      "Roland Siegwart",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02549"
  },
  {
    "id": "arXiv:2110.02550",
    "title": "CBP: Backpropagation with constraint on weight precision using a  pseudo-Lagrange multiplier method",
    "abstract": "Backward propagation of errors (backpropagation) is a method to minimize\nobjective functions (e.g., loss functions) of deep neural networks by\nidentifying optimal sets of weights and biases. Imposing constraints on weight\nprecision is often required to alleviate prohibitive workloads on hardware.\nDespite the remarkable success of backpropagation, the algorithm itself is not\ncapable of considering such constraints unless additional algorithms are\napplied simultaneously. To address this issue, we propose the constrained\nbackpropagation (CBP) algorithm based on a pseudo-Lagrange multiplier method to\nobtain the optimal set of weights that satisfy a given set of constraints. The\ndefining characteristic of the proposed CBP algorithm is the utilization of a\nLagrangian function (loss function plus constraint function) as its objective\nfunction. We considered various types of constraints--binary, ternary, one-bit\nshift, and two-bit shift weight constraints. As a post-training method, CBP\napplied to AlexNet, ResNet-18, ResNet-50, and GoogLeNet on ImageNet, which were\npre-trained using the conventional backpropagation. For all cases, the proposed\nalgorithm outperforms the state-of-the-art methods on ImageNet, e.g., 66.6%,\n74.4%, and 64.0% top-1 accuracy for ResNet-18, ResNet-50, and GoogLeNet with\nbinary weights, respectively. This highlights CBP as a learning algorithm to\naddress diverse constraints with the minimal performance loss by employing\nappropriate constraint functions.",
    "descriptor": "\nComments: Accepted. NeurIPS 2021. The code is available at this https URL\n",
    "authors": [
      "Guhyun Kim",
      "Doo Seok Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02550"
  },
  {
    "id": "arXiv:2110.02551",
    "title": "A Review of Computer Vision Technologies for Fish Tracking",
    "abstract": "Fish tracking based on computer vision is a complex and challenging task in\nfishery production and ecological studies. Most of the applications of fish\ntracking use classic filtering algorithms, which lack in accuracy and\nefficiency. To solve this issue, deep learning methods utilized deep neural\nnetworks to extract the features, which achieve a good performance in the fish\ntracking. Some one-stage detection algorithms have gradually been adopted in\nthis area for the real-time applications. The transfer learning to fish target\nis the current development direction. At present, fish tracking technology is\nnot enough to cover actual application requirements. According to the\nliterature data collected by us, there has not been any extensive review about\nvision-based fish tracking in the community. In this paper, we introduced the\ndevelopment and application prospects of fish tracking technology in last ten\nyears. Firstly, we introduced the open source datasets of fish, and summarized\nthe preprocessing technologies of underwater images. Secondly, we analyzed the\ndetection and tracking algorithms for fish, and sorted out some transferable\nfrontier tracking model. Thirdly, we listed the actual applications, metrics\nand bottlenecks of the fish tracking such as occlusion and multi-scale.\nFinally, we give the discussion for fish tracking datasets, solutions of the\nbottlenecks, and improvements. We expect that our work can help the fish\ntracking models to achieve higher accuracy and robustness.",
    "descriptor": "\nComments: 24 Pages, 10 Figures, 4 Tables\n",
    "authors": [
      "Zhenbo Li",
      "Weiran Li",
      "Fei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02551"
  },
  {
    "id": "arXiv:2110.02553",
    "title": "A Novel Approach for Attack Tree to Attack Graph Transformation:  Extended Version",
    "abstract": "Attack trees and attack graphs are both common graphical threat models used\nby organizations to better understand possible cybersecurity threats. These\nmodels have been primarily seen as separate entities, to be used and researched\nin entirely different contexts, but recently there has emerged a new interest\nin combining the strengths of these models and in transforming models from one\nnotation into the other. The existing works in this area focus on transforming\nattack graphs into attack trees. In this paper, we propose an approach to\ntransform attack trees into attack graphs based on the fundamental\nunderstanding of how actions are represented in both structures. From this, we\nhope to enable more versatility in both structures.",
    "descriptor": "\nComments: 20 pages, 7 figures, Shortened version to be published CRiSIS 2021\n",
    "authors": [
      "Nathan Daniel Schiele",
      "Olga Gadyatskaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02553"
  },
  {
    "id": "arXiv:2110.02554",
    "title": "A Regularized Wasserstein Framework for Graph Kernels",
    "abstract": "We propose a learning framework for graph kernels, which is theoretically\ngrounded on regularizing optimal transport. This framework provides a novel\noptimal transport distance metric, namely Regularized Wasserstein (RW)\ndiscrepancy, which can preserve both features and structure of graphs via\nWasserstein distances on features and their local variations, local barycenters\nand global connectivity. Two strongly convex regularization terms are\nintroduced to improve the learning ability. One is to relax an optimal\nalignment between graphs to be a cluster-to-cluster mapping between their\nlocally connected vertices, thereby preserving the local clustering structure\nof graphs. The other is to take into account node degree distributions in order\nto better preserve the global structure of graphs. We also design an efficient\nalgorithm to enable a fast approximation for solving the optimization problem.\nTheoretically, our framework is robust and can guarantee the convergence and\nnumerical stability in optimization. We have empirically validated our method\nusing 12 datasets against 16 state-of-the-art baselines. The experimental\nresults show that our method consistently outperforms all state-of-the-art\nmethods on all benchmark databases for both graphs with discrete attributes and\ngraphs with continuous attributes.",
    "descriptor": "\nComments: 21st IEEE International Conference on Data Mining (ICDM 2021)\n",
    "authors": [
      "Asiri Wijesinghe",
      "Qing Wang",
      "Stephen Gould"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02554"
  },
  {
    "id": "arXiv:2110.02555",
    "title": "Profile-based optimal stable matchings in the Roommates problem",
    "abstract": "The stable roommates problem can admit multiple different stable matchings.\nWe have different criteria for deciding which one is optimal, but computing\nthose is often NP-hard.\nWe show that the problem of finding generous or rank-maximal stable matchings\nin an instance of the roommates problem with incomplete lists is NP-hard even\nwhen the preference lists are at most length 3. We show that just maximising\nthe number of first choices or minimising the number of last choices is NP-hard\nwith the short preference lists.\nWe show that the number of $R^{th}$ choices, where $R$ is the minimum-regret\nof a given instance of SRI, is 2-approximable among all the stable matchings.\nAdditionally, we show that the problem of finding a stable matching that\nmaximises the number of first choices does not admit a constant time\napproximation algorithm and is W[1]-hard with respect to the number of first\nchoices.\nWe implement integer programming and constraint programming formulations for\nthe optimality criteria of SRI. We find that constraint programming outperforms\ninteger programming and an earlier answer set programming approach by Erdam et.\nal. (2020) for most optimality criteria. Integer programming outperforms\nconstraint programming and answer set programming on the almost stable\nroommates problem.",
    "descriptor": "\nComments: 27 pages, 11 tables, 3 figures\n",
    "authors": [
      "Sofia Simola",
      "David Manlove"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02555"
  },
  {
    "id": "arXiv:2110.02564",
    "title": "MTCD: Cataract Detection via Near Infrared Eye Images",
    "abstract": "Globally, cataract is a common eye disease and one of the leading causes of\nblindness and vision impairment. The traditional process of detecting cataracts\ninvolves eye examination using a slit-lamp microscope or ophthalmoscope by an\nophthalmologist, who checks for clouding of the normally clear lens of the eye.\nThe lack of resources and unavailability of a sufficient number of experts pose\na burden to the healthcare system throughout the world, and researchers are\nexploring the use of AI solutions for assisting the experts. Inspired by the\nprogress in iris recognition, in this research, we present a novel algorithm\nfor cataract detection using near-infrared eye images. The NIR cameras, which\nare popularly used in iris recognition, are of relatively low cost and easy to\noperate compared to ophthalmoscope setup for data capture. However, such NIR\nimages have not been explored for cataract detection. We present deep\nlearning-based eye segmentation and multitask network classification networks\nfor cataract detection using NIR images as input. The proposed segmentation\nalgorithm efficiently and effectively detects non-ideal eye boundaries and is\ncost-effective, and the classification network yields very high classification\nperformance on the cataract dataset.",
    "descriptor": "",
    "authors": [
      "Pavani Tripathi",
      "Yasmeena Akhter",
      "Mahapara Khurshid",
      "Aditya Lakra",
      "Rohit Keshari",
      "Mayank Vatsa",
      "Richa Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02564"
  },
  {
    "id": "arXiv:2110.02565",
    "title": "A Region-based Collaborative Management Scheme for Dynamic Clustering in  Green VANET",
    "abstract": "Green Vehicular Ad-hoc Network (VANET) is a newly-emerged research area which\nfocuses on reducing harmful impacts of vehicular communication equipments on\nthe natural environment. Recent studies have shown that grouping vehicles into\nclusters for green communications in VANETs can significantly improve\nnetworking efficiency and reduce infrastructure costs. As a dynamic network\nsystem, maintaining the network connectivity and reducing the communication\noverlap are two critical challenges for green VANET clustering. However, most\nexisting work studies connectivity and overlap separately, lacking a deep\nunderstanding of the relationship between them. To address this issue, we\npresent a comprehensive analysis that jointly considers the two critical\nfactors in one model. Specifically, we first design a state resemblance\nprediction (SRP) model based on the historical trajectory feature relevance\nbetween vehicles; Combined with the SRP model, we propose the region-based\ncollaborative management scheme (RCMS) to establish the dynamic clustering;\nLastly, we take extensive experiments to verify the region-based collaborative\nmanagement scheme for dynamic clustering. The results demonstrate that the\nproposed clustering algorithm can achieve high networking efficiency and better\ncommunication stability.",
    "descriptor": "",
    "authors": [
      "Bingyi Liu",
      "Zhipeng Fang",
      "Wei Wang",
      "Xun Shao",
      "Wei Wei",
      "Dongyao Jia",
      "Enshu Wang",
      "Shengwu Xiong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02565"
  },
  {
    "id": "arXiv:2110.02566",
    "title": "Adaptive control of a mechatronic system using constrained residual  reinforcement learning",
    "abstract": "We propose a simple, practical and intuitive approach to improve the\nperformance of a conventional controller in uncertain environments using deep\nreinforcement learning while maintaining safe operation. Our approach is\nmotivated by the observation that conventional controllers in industrial motion\ncontrol value robustness over adaptivity to deal with different operating\nconditions and are suboptimal as a consequence. Reinforcement learning on the\nother hand can optimize a control signal directly from input-output data and\nthus adapt to operational conditions, but lacks safety guarantees, impeding its\nuse in industrial environments. To realize adaptive control using reinforcement\nlearning in such conditions, we follow a residual learning methodology, where a\nreinforcement learning algorithm learns corrective adaptations to a base\ncontroller's output to increase optimality. We investigate how constraining the\nresidual agent's actions enables to leverage the base controller's robustness\nto guarantee safe operation. We detail the algorithmic design and propose to\nconstrain the residual actions relative to the base controller to increase the\nmethod's robustness. Building on Lyapunov stability theory, we prove stability\nfor a broad class of mechatronic closed-loop systems. We validate our method\nexperimentally on a slider-crank setup and investigate how the constraints\naffect the safety during learning and optimality after convergence.",
    "descriptor": "",
    "authors": [
      "Tom Staessens",
      "Tom Lefebvre",
      "Guillaume Crevecoeur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02566"
  },
  {
    "id": "arXiv:2110.02571",
    "title": "Simulation of Derivatives Post-Trade Services using an Authoritative  Data Store and the ISDA Common Domain Model",
    "abstract": "In this paper, we present a summary of the design and implementation of a\nsimulation of post-trade services for interest rate swaps, from execution to\nmaturity. We use an authoritative data store (ADS) and the International Swaps\nand Derivatives Association (ISDA) Common Domain Model (CDM) to simulate a\npotential future architecture. We start by providing a brief overview of the\nCDM and the lifecycle of an interest rate swap. We then compare our simulated\nfuture state architecture with a typical current state architecture. Next, we\npresent the key requirements of the simulated system, several suitable design\npatterns, and a summary of the implementation. The simulation uses the CDM to\naddress the industry problems of inconsistent processes and inconsistent data,\nand an authoritative data store to address the industry problem of duplicated\ndata.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Vikram A. Bakshi",
      "Aishwarya Nair",
      "Lee Braine"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.02571"
  },
  {
    "id": "arXiv:2110.02573",
    "title": "T-SNE Is Not Optimized to Reveal Clusters in Data",
    "abstract": "Cluster visualization is an essential task for nonlinear dimensionality\nreduction as a data analysis tool. It is often believed that Student\nt-Distributed Stochastic Neighbor Embedding (t-SNE) can show clusters for well\nclusterable data, with a smaller Kullback-Leibler divergence corresponding to a\nbetter quality. There was even theoretical proof for the guarantee of this\nproperty. However, we point out that this is not necessarily the case -- t-SNE\nmay leave clustering patterns hidden despite strong signals present in the\ndata. Extensive empirical evidence is provided to support our claim. First,\nseveral real-world counter-examples are presented, where t-SNE fails even if\nthe input neighborhoods are well clusterable. Tuning hyperparameters in t-SNE\nor using better optimization algorithms does not help solve this issue because\na better t-SNE learning objective can correspond to a worse cluster embedding.\nSecond, we check the assumptions in the clustering guarantee of t-SNE and find\nthey are often violated for real-world data sets.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.08003\n",
    "authors": [
      "Zhirong Yang",
      "Yuwei Chen",
      "Jukka Corander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02573"
  },
  {
    "id": "arXiv:2110.02577",
    "title": "Efficient Multi-Modal Embeddings from Structured Data",
    "abstract": "Multi-modal word semantics aims to enhance embeddings with perceptual input,\nassuming that human meaning representation is grounded in sensory experience.\nMost research focuses on evaluation involving direct visual input, however,\nvisual grounding can contribute to linguistic applications as well. Another\nmotivation for this paper is the growing need for more interpretable models and\nfor evaluating model efficiency regarding size and performance. This work\nexplores the impact of visual information for semantics when the evaluation\ninvolves no direct visual input, specifically semantic similarity and\nrelatedness. We investigate a new embedding type in-between linguistic and\nvisual modalities, based on the structured annotations of Visual Genome. We\ncompare uni- and multi-modal models including structured, linguistic and image\nbased representations. We measure the efficiency of each model with regard to\ndata and model size, modality / data distribution and information gain. The\nanalysis includes an interpretation of embedding structures. We found that this\nnew embedding conveys complementary information for text based embeddings. It\nachieves comparable performance in an economic way, using orders of magnitude\nless resources than visual models.",
    "descriptor": "\nComments: 5 pages, 5 pages of appendix, 7 figures\n",
    "authors": [
      "Anita L. Ver\u0151",
      "Ann Copestake"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02577"
  },
  {
    "id": "arXiv:2110.02578",
    "title": "Decoupled Adaptation for Cross-Domain Object Detection",
    "abstract": "Cross-domain object detection is more challenging than object classification\nsince multiple objects exist in an image and the location of each object is\nunknown in the unlabeled target domain. As a result, when we adapt features of\ndifferent objects to enhance the transferability of the detector, the features\nof the foreground and the background are easy to be confused, which may hurt\nthe discriminability of the detector. Besides, previous methods focused on\ncategory adaptation but ignored another important part for object detection,\ni.e., the adaptation on bounding box regression. To this end, we propose\nD-adapt, namely Decoupled Adaptation, to decouple the adversarial adaptation\nand the training of the detector. Besides, we fill the blank of regression\ndomain adaptation in object detection by introducing a bounding box adaptor.\nExperiments show that D-adapt achieves state-of-the-art results on four\ncross-domain object detection tasks and yields 17% and 21% relative improvement\non benchmark datasets Clipart1k and Comic2k in particular.",
    "descriptor": "",
    "authors": [
      "Junguang Jiang",
      "Baixu Chen",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02578"
  },
  {
    "id": "arXiv:2110.02579",
    "title": "Anomaly Detection based on Compressed Data: an Information Theoretic  Characterization",
    "abstract": "We analyze the effect of lossy compression in the processing of sensor\nsignals that must be used to detect anomalous events in the system under\nobservation. The intuitive relationship between the quality loss at higher\ncompression and the possibility of telling anomalous behaviours from normal\nones is formalized in terms of information-theoretic quantities. Some analytic\nderivations are made within the Gaussian framework and possibly in the\nasymptotic regime for what concerns the stretch of signals considered.\nAnalytical conclusions are matched with the performance of practical detectors\nin a toy case allowing the assessment of different compression/detector\nconfigurations.",
    "descriptor": "\nComments: 13 pages, 7 figures,\n",
    "authors": [
      "Alex Marchioni",
      "Andriy Enttsel",
      "Mauro Mangia",
      "Riccardo Rovatti",
      "Gianluca Setti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02579"
  },
  {
    "id": "arXiv:2110.02580",
    "title": "Deep Transfer Learning for Land Use Land Cover Classification: A  Comparative Study",
    "abstract": "Efficiently implementing remote sensing image classification with high\nspatial resolution imagery can provide great significant value in land-use\nland-cover classification (LULC). The developments in remote sensing and deep\nlearning technologies have facilitated the extraction of spatiotemporal\ninformation for LULC classification. Moreover, the diverse disciplines of\nscience, including remote sensing, have utilised tremendous improvements in\nimage classification by CNNs with Transfer Learning. In this study, instead of\ntraining CNNs from scratch, we make use of transfer learning to fine-tune\npre-trained networks a) VGG16 and b) Wide Residual Networks (WRNs), by\nreplacing the final layer with additional layers, for LULC classification with\nEuroSAT dataset. Further, the performance and computational time were compared\nand optimized with techniques like early stopping, gradient clipping, adaptive\nlearning rates and data augmentation. With the proposed approaches we were able\nto address the limited-data problem and achieved very good accuracy.\nComprehensive comparisons over the EuroSAT RGB version benchmark have\nsuccessfully established that our method outperforms the previous best-stated\nresults, with a significant improvement over the accuracy from 98.57% to\n99.17%.",
    "descriptor": "",
    "authors": [
      "Raoof Naushad",
      "Tarunpreet Kaur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02580"
  },
  {
    "id": "arXiv:2110.02582",
    "title": "FADNet++: Real-Time and Accurate Disparity Estimation with Configurable  Networks",
    "abstract": "Deep neural networks (DNNs) have achieved great success in the area of\ncomputer vision. The disparity estimation problem tends to be addressed by DNNs\nwhich achieve much better prediction accuracy than traditional hand-crafted\nfeature-based methods. However, the existing DNNs hardly serve both efficient\ncomputation and rich expression capability, which makes them difficult for\ndeployment in real-time and high-quality applications, especially on mobile\ndevices. To this end, we propose an efficient, accurate, and configurable deep\nnetwork for disparity estimation named FADNet++. Leveraging several liberal\nnetwork design and training techniques, FADNet++ can boost its accuracy with a\nfast model inference speed for real-time applications. Besides, it enables\nusers to easily configure different sizes of models for balancing accuracy and\ninference efficiency. We conduct extensive experiments to demonstrate the\neffectiveness of FADNet++ on both synthetic and realistic datasets among six\nGPU devices varying from server to mobile platforms. Experimental results show\nthat FADNet++ and its variants achieve state-of-the-art prediction accuracy,\nand run at a significant order of magnitude faster speed than existing 3D\nmodels. With the constraint of running at above 15 frames per second (FPS) on a\nmobile GPU, FADNet++ achieves a new state-of-the-art result for the SceneFlow\ndataset.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.10758\n",
    "authors": [
      "Qiang Wang",
      "Shaohuai Shi",
      "Shizhen Zheng",
      "Kaiyong Zhao",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02582"
  },
  {
    "id": "arXiv:2110.02583",
    "title": "Deep Identification of Nonlinear Systems in Koopman Form",
    "abstract": "The present paper treats the identification of nonlinear dynamical systems\nusing Koopman-based deep state-space encoders. Through this method, the usual\ndrawback of needing to choose a dictionary of lifting functions a priori is\ncircumvented. The encoder represents the lifting function to the space where\nthe dynamics are linearly propagated using the Koopman operator. An\ninput-affine formulation is considered for the lifted model structure and we\naddress both full and partial state availability. The approach is implemented\nusing the the deepSI toolbox in Python. To lower the computational need of the\nsimulation error-based training, the data is split into subsections where\nmulti-step prediction errors are calculated independently. This formulation\nallows for efficient batch optimization of the network parameters and, at the\nsame time, excellent long term prediction capabilities of the obtained models.\nThe performance of the approach is illustrated by nonlinear benchmark examples.",
    "descriptor": "\nComments: Accepted to CDC 2021 (revised with reviewer feedback)\n",
    "authors": [
      "Lucian Cristian Iacob",
      "Gerben Izaak Beintema",
      "Maarten Schoukens",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02583"
  },
  {
    "id": "arXiv:2110.02584",
    "title": "EdiTTS: Score-based Editing for Controllable Text-to-Speech",
    "abstract": "We present EdiTTS, an off-the-shelf speech editing methodology based on\nscore-based generative modeling for text-to-speech synthesis. EdiTTS allows for\ntargeted, granular editing of audio, both in terms of content and pitch,\nwithout the need for any additional training, task-specific optimization, or\narchitectural modifications to the score-based model backbone. Specifically, we\napply coarse yet deliberate perturbations in the Gaussian prior space to induce\ndesired behavior from the diffusion model, while applying masks and softening\nkernels to ensure that iterative edits are applied only to the target region.\nListening tests demonstrate that EdiTTS is capable of reliably generating\nnatural-sounding audio that satisfies user-imposed requirements.",
    "descriptor": "",
    "authors": [
      "Jaesung Tae",
      "Hyeongju Kim",
      "Taesu Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02584"
  },
  {
    "id": "arXiv:2110.02585",
    "title": "Simplicial Convolutional Neural Networks",
    "abstract": "Graphs can model networked data by representing them as nodes and their\npairwise relationships as edges. Recently, signal processing and neural\nnetworks have been extended to process and learn from data on graphs, with\nachievements in tasks like graph signal reconstruction, graph or node\nclassifications, and link prediction. However, these methods are only suitable\nfor data defined on the nodes of a graph. In this paper, we propose a\nsimplicial convolutional neural network (SCNN) architecture to learn from data\ndefined on simplices, e.g., nodes, edges, triangles, etc. We study the SCNN\npermutation and orientation equivariance, complexity, and spectral analysis.\nFinally, we test the SCNN performance for imputing citations on a coauthorship\ncomplex.",
    "descriptor": "\nComments: 5 Pages, 2 figures, 1 table, submitted to ICASSP 2022\n",
    "authors": [
      "Maosheng Yang",
      "Elvin Isufi",
      "Geert Leus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02585"
  },
  {
    "id": "arXiv:2110.02591",
    "title": "Weakly-supervised Text Classification Based on Keyword Graph",
    "abstract": "Weakly-supervised text classification has received much attention in recent\nyears for it can alleviate the heavy burden of annotating massive data. Among\nthem, keyword-driven methods are the mainstream where user-provided keywords\nare exploited to generate pseudo-labels for unlabeled texts. However, existing\nmethods treat keywords independently, thus ignore the correlation among them,\nwhich should be useful if properly exploited. In this paper, we propose a novel\nframework called ClassKG to explore keyword-keyword correlation on keyword\ngraph by GNN. Our framework is an iterative process. In each iteration, we\nfirst construct a keyword graph, so the task of assigning pseudo labels is\ntransformed to annotating keyword subgraphs. To improve the annotation quality,\nwe introduce a self-supervised task to pretrain a subgraph annotator, and then\nfinetune it. With the pseudo labels generated by the subgraph annotator, we\nthen train a text classifier to classify the unlabeled texts. Finally, we\nre-extract keywords from the classified texts. Extensive experiments on both\nlong-text and short-text datasets show that our method substantially\noutperforms the existing ones",
    "descriptor": "\nComments: accepted in EMNLP 2021\n",
    "authors": [
      "Lu Zhang",
      "Jiandong Ding",
      "Yi Xu",
      "Yingyao Liu",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02591"
  },
  {
    "id": "arXiv:2110.02593",
    "title": "InterpolationSLAM: A Novel Robust Visual SLAM System in Rotating Scenes",
    "abstract": "In recent years, visual SLAM has achieved great progress and development, but\nin complex scenes, especially rotating scenes, the error of mapping will\nincrease significantly, and the slam system is easy to lose track. In this\narticle, we propose an InterpolationSLAM framework, which is a visual SLAM\nframework based on ORB-SLAM2. InterpolationSLAM is robust in rotating scenes\nfor Monocular and RGB-D configurations. By detecting the rotation and\nperforming interpolation processing at the rotated position, pose of the system\ncan be estimated more accurately at the rotated position, thereby improving the\naccuracy and robustness of the SLAM system in the rotating scenes. To the best\nof our knowledge, it is the first work combining the interpolation network into\na Visual SLAM system to improve SLAM system robustness in rotating scenes. We\nconduct experiments both on KITTI Monocular and TUM RGB-D datasets. The results\ndemonstrate that InterpolationSLAM outperforms the accuracy of standard Visual\nSLAM baselines.",
    "descriptor": "",
    "authors": [
      "Zhenkun Zhu",
      "Jikai Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02593"
  },
  {
    "id": "arXiv:2110.02594",
    "title": "Empowering Citizens by a Blockchain-Based Robinson List",
    "abstract": "A Robinson list protects phone subscribers against commercial spam calls. Its\nleast basic functionality is to collect the denial of the subscribers to be\ncontacted by market operators. Nowadays, Robinson lists run as centralised\nservices, which implies that citizens should trust third parties for the\nmanagement of their choices. In this paper, we show a design that allows us to\nrealise a Robinson list as a decentralised service. Our work leverages the\nexperience developed by Fondazione Ugo Bordoni as the manager of the Italian\nRobinson list. We present a general solution and a proof-of-concept (PoC)\nadopting the Algorand technology. We evaluate the performances of our PoC in\nterms of its scalability and of the latency perceived by the involved actors.\nWe also discuss aspects related to identity management and privacy.",
    "descriptor": "\nComments: This article has been accepted for publication in International Journal of Computers and Applications, published by Taylor & Francis\n",
    "authors": [
      "Albenzio Cirillo",
      "Vito Dalena",
      "Antonio Mauro",
      "Francesco Mogavero",
      "Diego Pennino",
      "Maurizio Pizzonia",
      "Andrea Vitaletti",
      "Marco Zecchini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02594"
  },
  {
    "id": "arXiv:2110.02597",
    "title": "Cookie Banners, What's the Purpose? Analyzing Cookie Banner Text Through  a Legal Lens",
    "abstract": "Online services pervasively employ manipulative designs (i.e., dark patterns)\nto influence users to purchase goods and subscriptions, spend more time\non-site, or mindlessly accept the harvesting of their personal data. To protect\nusers from the lure of such designs, we asked: are users aware of the presence\nof dark patterns? If so, are they able to resist them? By surveying 406\nindividuals, we found that they are generally aware of the influence that\nmanipulative designs can exert on their online behaviour. However, being aware\ndoes not equip users with the ability to oppose such influence. We further find\nthat respondents, especially younger ones, often recognise the \"darkness\" of\ncertain designs, but remain unsure of the actual harm they may suffer. Finally,\nwe discuss a set of interventions (e.g., bright patterns, design frictions,\ntraining games, applications to expedite legal enforcement) in the light of our\nfindings.",
    "descriptor": "",
    "authors": [
      "Cristiana Santos",
      "Arianna Rossi",
      "Lorena S\u00e1nchez Chamorro",
      "Kerstin Bongard-Blanchy",
      "Ruba Abu-Salma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02597"
  },
  {
    "id": "arXiv:2110.02600",
    "title": "Sequential Reptile: Inter-Task Gradient Alignment for Multilingual  Learning",
    "abstract": "Multilingual models jointly pretrained on multiple languages have achieved\nremarkable performance on various multilingual downstream tasks. Moreover,\nmodels finetuned on a single monolingual downstream task have shown to\ngeneralize to unseen languages. In this paper, we first show that it is crucial\nfor those tasks to align gradients between them in order to maximize knowledge\ntransfer while minimizing negative transfer. Despite its importance, the\nexisting methods for gradient alignment either have a completely different\npurpose, ignore inter-task alignment, or aim to solve continual learning\nproblems in rather inefficient ways. As a result of the misaligned gradients\nbetween tasks, the model suffers from severe negative transfer in the form of\ncatastrophic forgetting of the knowledge acquired from the pretraining. To\novercome the limitations, we propose a simple yet effective method that can\nefficiently align gradients between tasks. Specifically, we perform each\ninner-optimization by sequentially sampling batches from all the tasks,\nfollowed by a Reptile outer update. Thanks to the gradients aligned between\ntasks by our method, the model becomes less vulnerable to negative transfer and\ncatastrophic forgetting. We extensively validate our method on various\nmulti-task learning and zero-shot cross-lingual transfer tasks, where our\nmethod largely outperforms all the relevant baselines we consider.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Seanie Lee",
      "Hae Beom Lee",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02600"
  },
  {
    "id": "arXiv:2110.02605",
    "title": "Computational lower bounds of the Maxwell eigenvalues",
    "abstract": "A method to compute guaranteed lower bounds to the eigenvalues of the Maxwell\nsystem in two or three space dimensions is proposed as a generalization of the\nmethod of Liu and Oishi [SIAM J. Numer. Anal., 51, 2013] for the Laplace\noperator. The main tool is the computation of an explicit upper bound to the\nerror of the Galerkin projection. The error is split in two parts: one part is\ncontrolled by a hypercircle principle and an auxiliary eigenvalue problem. The\nsecond part requires a perturbation argument for the right-hand side replaced\nby a suitable piecewise polynomial. The latter error is controlled through the\nuse of the commuting quasi-interpolation by Falk--Winther and computational\nbounds on its stability constant. This situation is different from the Laplace\noperator where such a perturbation is easily controlled through local\nPoincar\\'e inequalities. The practical viability of the approach is\ndemonstrated in two-dimensional test cases.",
    "descriptor": "",
    "authors": [
      "Dietmar Gallistl",
      "Vladislav Olkhovskiy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02605"
  },
  {
    "id": "arXiv:2110.02610",
    "title": "Tackling the DM Challenges with cDMN: A Tight Integration of DMN and  Constraint Reasoning",
    "abstract": "Knowledge-based AI typically depends on a knowledge engineer to construct a\nformal model of domain knowledge -- but what if domain experts could do this\nthemselves? This paper describes an extension to the Decision Model and\nNotation (DMN) standard, called Constraint Decision Model and Notation (cDMN).\nDMN is a user-friendly, table-based notation for decision logic, which allows\ndomain experts to model simple decision procedures without the help of IT\nstaff. cDMN aims to enlarge the expressiveness of DMN in order to model more\ncomplex domain knowledge, while retaining DMN's goal of being understandable by\ndomain experts. We test cDMN by solving the most complex challenges posted on\nthe DM Community website. We compare our own cDMN solutions to the solutions\nthat have been submitted to the website and find that our approach is\ncompetitive. Moreover, cDMN is able to solve more challenges than any other\napproach.",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP). arXiv admin note: substantial text overlap with arXiv:2005.09998\n",
    "authors": [
      "Simon Vandevelde",
      "Bram Aerts",
      "Joost Vennekens"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02610"
  },
  {
    "id": "arXiv:2110.02619",
    "title": "Focus on the Common Good: Group Distributional Robustness Follows",
    "abstract": "We consider the problem of training a classification model with group\nannotated training data. Recent work has established that, if there is\ndistribution shift across different groups, models trained using the standard\nempirical risk minimization (ERM) objective suffer from poor performance on\nminority groups and that group distributionally robust optimization (Group-DRO)\nobjective is a better alternative. The starting point of this paper is the\nobservation that though Group-DRO performs better than ERM on minority groups\nfor some benchmark datasets, there are several other datasets where it performs\nmuch worse than ERM. Inspired by ideas from the closely related problem of\ndomain generalization, this paper proposes a new and simple algorithm that\nexplicitly encourages learning of features that are shared across various\ngroups. The key insight behind our proposed algorithm is that while Group-DRO\nfocuses on groups with worst regularized loss, focusing instead, on groups that\nenable better performance even on other groups, could lead to learning of\nshared/common features, thereby enhancing minority performance beyond what is\nachieved by Group-DRO. Empirically, we show that our proposed algorithm matches\nor achieves better performance compared to strong contemporary baselines\nincluding ERM and Group-DRO on standard benchmarks on both minority groups and\nacross all groups. Theoretically, we show that the proposed algorithm is a\ndescent method and finds first order stationary points of smooth nonconvex\nfunctions.",
    "descriptor": "\nComments: Under review; Code can be found at: this https URL\n",
    "authors": [
      "Vihari Piratla",
      "Praneeth Netrapalli",
      "Sunita Sarawagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02619"
  },
  {
    "id": "arXiv:2110.02623",
    "title": "Is An Image Worth Five Sentences? A New Look into Semantics for  Image-Text Matching",
    "abstract": "The task of image-text matching aims to map representations from different\nmodalities into a common joint visual-textual embedding. However, the most\nwidely used datasets for this task, MSCOCO and Flickr30K, are actually image\ncaptioning datasets that offer a very limited set of relationships between\nimages and sentences in their ground-truth annotations. This limited ground\ntruth information forces us to use evaluation metrics based on binary\nrelevance: given a sentence query we consider only one image as relevant.\nHowever, many other relevant images or captions may be present in the dataset.\nIn this work, we propose two metrics that evaluate the degree of semantic\nrelevance of retrieved items, independently of their annotated binary\nrelevance. Additionally, we incorporate a novel strategy that uses an image\ncaptioning metric, CIDEr, to define a Semantic Adaptive Margin (SAM) to be\noptimized in a standard triplet loss. By incorporating our formulation to\nexisting models, a \\emph{large} improvement is obtained in scenarios where\navailable training data is limited. We also demonstrate that the performance on\nthe annotated image-caption pairs is maintained while improving on other\nnon-annotated relevant items when employing the full training set. Code with\nour metrics and adaptive margin formulation will be made public.",
    "descriptor": "\nComments: Accepted WACV 2022\n",
    "authors": [
      "Ali Furkan Biten",
      "Andres Mafla",
      "Lluis Gomez",
      "Dimosthenis Karatzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02623"
  },
  {
    "id": "arXiv:2110.02624",
    "title": "CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation",
    "abstract": "While recent progress has been made in text-to-image generation,\ntext-to-shape generation remains a challenging problem due to the\nunavailability of paired text and shape data at a large scale. We present a\nsimple yet effective method for zero-shot text-to-shape generation based on a\ntwo-stage training process, which only depends on an unlabelled shape dataset\nand a pre-trained image-text network such as CLIP. Our method not only\ndemonstrates promising zero-shot generalization, but also avoids expensive\ninference time optimization and can generate multiple shapes for a given text.",
    "descriptor": "",
    "authors": [
      "Aditya Sanghi",
      "Hang Chu",
      "Joseph G. Lambourne",
      "Ye Wang",
      "Chin-Yi Cheng",
      "Marco Fumero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02624"
  },
  {
    "id": "arXiv:2110.02626",
    "title": "A multi-order smoothed particle hydrodynamics method for cardiac  electromechanics with the Purkinje network",
    "abstract": "In previous work, Zhang et al. (2021) \\cite{zhang2021integrative} developed\nan integrated smoothed particle hydrodynamics (SPH) method to simulate the\nprinciple aspects of cardiac function, including electrophysiology, passive and\nactive mechanical response of the myocardium. As the inclusion of the Purkinje\nnetwork in electrocardiology is recognized as fundamental to accurately\ndescribing the electrical activation in the right and left ventricles, in this\npaper, we present a multi-order SPH method to handle the electrical propagation\nthrough the Purkinje system and in the myocardium with monodomain/monodomain\ncoupling strategy. We first propose an efficient algorithm for network\ngeneration on arbitrarily complex surface by exploiting level-set geometry\nrepresentation and cell-linked list neighbor search algorithm. Then, a\nreduced-order SPH method is developed to solve the one-dimensional monodomain\nequation to characterize the fast electrical activation through the Purkinje\nnetwork. Finally, a multi-order coupling paradigm is introduced to capture the\ncoupled nature of potential propagation arising from the interaction between\nthe network and the myocardium. A set of numerical examples are studied to\nassess the computational performance, accuracy and versatility of the proposed\nmethods. In particular, numerical study performed in realistic left ventricle\ndemonstrates that the present method features all the physiological issues that\ncharacterize a heartbeat simulation, including the initiation of the signal in\nthe Purkinje network and the systolic and diastolic phases. As expected, the\nresults underlie the importance of using physiologically realistic Purkinje\nnetwork for modeling cardiac functions.",
    "descriptor": "\nComments: 52 pages and 15 figures\n",
    "authors": [
      "Chi Zhang",
      "Hao Gao",
      "Xiangyu Hu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.02626"
  },
  {
    "id": "arXiv:2110.02627",
    "title": "MovingFashion: a Benchmark for the Video-to-Shop Challenge",
    "abstract": "Retrieving clothes which are worn in social media videos (Instagram, TikTok)\nis the latest frontier of e-fashion, referred to as \"video-to-shop\" in the\ncomputer vision literature. In this paper we present MovingFashion, the first\npublicly available dataset to cope with this challenge. MovingFashion is\ncomposed of 14855 social videos, each one of them associated to e-commerce\n\"shop\" images where the corresponding clothing items are clearly portrayed. In\naddition, we present a network for retrieving the shop images in this scenario,\ndubbed SEAM Match-RCNN. The model is trained by image-to-video domain\nadaptation, allowing to use video sequences where only their association with a\nshop image is given, eliminating the need of millions of annotated bounding\nboxes. SEAM Match-RCNN builds an embedding, where an attention-based weighted\nsum of few frames (10) of a social video is enough to individuate the correct\nproduct within the first 5 retrieved items in a 14K+ shop element gallery with\nan accuracy of 80%. This provides the best performance on MovingFashion,\ncomparing exhaustively against the related state-of-the-art approaches and\nalternative baselines.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Marco Godi",
      "Christian Joppi",
      "Geri Skenderi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02627"
  },
  {
    "id": "arXiv:2110.02628",
    "title": "Characterizing Learning Dynamics of Deep Neural Networks via Complex  Networks",
    "abstract": "In this paper, we interpret Deep Neural Networks with Complex Network Theory.\nComplex Network Theory (CNT) represents Deep Neural Networks (DNNs) as directed\nweighted graphs to study them as dynamical systems. We efficiently adapt CNT\nmeasures to examine the evolution of the learning process of DNNs with\ndifferent initializations and architectures: we introduce metrics for\nnodes/neurons and layers, namely Nodes Strength and Layers Fluctuation. Our\nframework distills trends in the learning dynamics and separates low from high\naccurate networks. We characterize populations of neural networks (ensemble\nanalysis) and single instances (individual analysis). We tackle standard\nproblems of image recognition, for which we show that specific learning\ndynamics are indistinguishable when analysed through the solely Link-Weights\nanalysis. Further, Nodes Strength and Layers Fluctuations make unprecedented\nbehaviours emerge: accurate networks, when compared to under-trained models,\nshow substantially divergent distributions with the greater extremity of\ndeviations. On top of this study, we provide an efficient implementation of the\nCNT metrics for both Convolutional and Fully Connected Networks, to fasten the\nresearch in this direction.",
    "descriptor": "\nComments: IEEE/ICTAI2021 (full paper)\n",
    "authors": [
      "Emanuele La Malfa",
      "Gabriele La Malfa",
      "Giuseppe Nicosia",
      "Vito Latora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.02628"
  },
  {
    "id": "arXiv:2110.02629",
    "title": "Deep Reinforcement Learning for Solving the Heterogeneous Capacitated  Vehicle Routing Problem",
    "abstract": "Existing deep reinforcement learning (DRL) based methods for solving the\ncapacitated vehicle routing problem (CVRP) intrinsically cope with homogeneous\nvehicle fleet, in which the fleet is assumed as repetitions of a single\nvehicle. Hence, their key to construct a solution solely lies in the selection\nof the next node (customer) to visit excluding the selection of vehicle.\nHowever, vehicles in real-world scenarios are likely to be heterogeneous with\ndifferent characteristics that affect their capacity (or travel speed),\nrendering existing DRL methods less effective. In this paper, we tackle\nheterogeneous CVRP (HCVRP), where vehicles are mainly characterized by\ndifferent capacities. We consider both min-max and min-sum objectives for\nHCVRP, which aim to minimize the longest or total travel time of the vehicle(s)\nin the fleet. To solve those problems, we propose a DRL method based on the\nattention mechanism with a vehicle selection decoder accounting for the\nheterogeneous fleet constraint and a node selection decoder accounting for the\nroute construction, which learns to construct a solution by automatically\nselecting both a vehicle and a node for this vehicle at each step. Experimental\nresults based on randomly generated instances show that, with desirable\ngeneralization to various problem sizes, our method outperforms the\nstate-of-the-art DRL method and most of the conventional heuristics, and also\ndelivers competitive performance against the state-of-the-art heuristic method,\ni.e., SISR. Additionally, the results of extended experiments demonstrate that\nour method is also able to solve CVRPLib instances with satisfactory\nperformance.",
    "descriptor": "\nComments: This paper has been accepted at IEEE Transactions on Cybernetics\n",
    "authors": [
      "Jingwen Li",
      "Yining Ma",
      "Ruize Gao",
      "Zhiguang Cao",
      "Andrew Lim",
      "Wen Song",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02629"
  },
  {
    "id": "arXiv:2110.02631",
    "title": "Inference Attacks Against Graph Neural Networks",
    "abstract": "Graph is an important data representation ubiquitously existing in the real\nworld. However, analyzing the graph data is computationally difficult due to\nits non-Euclidean nature. Graph embedding is a powerful tool to solve the graph\nanalytics problem by transforming the graph data into low-dimensional vectors.\nThese vectors could also be shared with third parties to gain additional\ninsights of what is behind the data. While sharing graph embedding is\nintriguing, the associated privacy risks are unexplored. In this paper, we\nsystematically investigate the information leakage of the graph embedding by\nmounting three inference attacks. First, we can successfully infer basic graph\nproperties, such as the number of nodes, the number of edges, and graph\ndensity, of the target graph with up to 0.89 accuracy. Second, given a subgraph\nof interest and the graph embedding, we can determine with high confidence that\nwhether the subgraph is contained in the target graph. For instance, we achieve\n0.98 attack AUC on the DD dataset. Third, we propose a novel graph\nreconstruction attack that can reconstruct a graph that has similar graph\nstructural statistics to the target graph. We further propose an effective\ndefense mechanism based on graph embedding perturbation to mitigate the\ninference attacks without noticeable performance degradation for graph\nclassification tasks. Our code is available at\nhttps://github.com/Zhangzhk0819/GNN-Embedding-Leaks.",
    "descriptor": "\nComments: 19 pages, 18 figures. To Appear in the 31st USENIX Security Symposium\n",
    "authors": [
      "Zhikun Zhang",
      "Min Chen",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02631"
  },
  {
    "id": "arXiv:2110.02634",
    "title": "Heterogeneous Attentions for Solving Pickup and Delivery Problem via  Deep Reinforcement Learning",
    "abstract": "Recently, there is an emerging trend to apply deep reinforcement learning to\nsolve the vehicle routing problem (VRP), where a learnt policy governs the\nselection of next node for visiting. However, existing methods could not handle\nwell the pairing and precedence relationships in the pickup and delivery\nproblem (PDP), which is a representative variant of VRP. To address this\nchallenging issue, we leverage a novel neural network integrated with a\nheterogeneous attention mechanism to empower the policy in deep reinforcement\nlearning to automatically select the nodes. In particular, the heterogeneous\nattention mechanism specifically prescribes attentions for each role of the\nnodes while taking into account the precedence constraint, i.e., the pickup\nnode must precede the pairing delivery node. Further integrated with a masking\nscheme, the learnt policy is expected to find higher-quality solutions for\nsolving PDP. Extensive experimental results show that our method outperforms\nthe state-of-the-art heuristic and deep learning model, respectively, and\ngeneralizes well to different distributions and problem sizes.",
    "descriptor": "\nComments: This paper has been accepted at IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Jingwen Li",
      "Liang Xin",
      "Zhiguang Cao",
      "Andrew Lim",
      "Wen Song",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02634"
  },
  {
    "id": "arXiv:2110.02638",
    "title": "2nd Place Solution to Google Landmark Recognition Competition 2021",
    "abstract": "As Transformer-based architectures have recently shown encouraging progresses\nin computer vision. In this work, we present the solution to the Google\nLandmark Recognition 2021 Challenge held on Kaggle, which is an improvement on\nour last year's solution by changing three designs, including (1) Using Swin\nand CSWin as backbone for feature extraction, (2) Train on full GLDv2, and (3)\nUsing full GLDv2 images as index image set for kNN search.\nWith these modifications, our solution significantly improves last year\nsolution on this year competition. Our full pipeline, after ensembling Swin,\nCSWin, EfficientNet B7 models, scores 0.4907 on the private leaderboard which\nhelp us to get the 2nd place in the competition.",
    "descriptor": "",
    "authors": [
      "Shubin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02638"
  },
  {
    "id": "arXiv:2110.02639",
    "title": "On The Transferability of Deep-Q Networks",
    "abstract": "Transfer Learning (TL) is an efficient machine learning paradigm that allows\novercoming some of the hurdles that characterize the successful training of\ndeep neural networks, ranging from long training times to the needs of large\ndatasets. While exploiting TL is a well established and successful training\npractice in Supervised Learning (SL), its applicability in Deep Reinforcement\nLearning (DRL) is rarer. In this paper, we study the level of transferability\nof three different variants of Deep-Q Networks on popular DRL benchmarks as\nwell as on a set of novel, carefully designed control tasks. Our results show\nthat transferring neural networks in a DRL context can be particularly\nchallenging and is a process which in most cases results in negative transfer.\nIn the attempt of understanding why Deep-Q Networks transfer so poorly, we gain\nnovel insights into the training dynamics that characterizes this family of\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Matthia Sabatelli",
      "Pierre Geurts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02639"
  },
  {
    "id": "arXiv:2110.02640",
    "title": "Bach Style Music Authoring System based on Deep Learning",
    "abstract": "With the continuous improvement in various aspects in the field of artificial\nintelligence, the momentum of artificial intelligence with deep learning\ncapabilities into the field of music is coming. The research purpose of this\npaper is to design a Bach style music authoring system based on deep learning.\nWe use a LSTM neural network to train serialized and standardized music feature\ndata. By repeated experiments, we find the optimal LSTM model which can\ngenerate imitation of Bach music. Finally the generated music is\ncomprehensively evaluated in the form of online audition and Turing test. The\nrepertoires which the music generation system constructed in this article are\nvery close to the style of Bach's original music, and it is relatively\ndifficult for ordinary people to distinguish the musics Bach authored and AI\ncreated.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Minghe Kong",
      "Lican Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02640"
  },
  {
    "id": "arXiv:2110.02642",
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "abstract": "Unsupervisedly detecting anomaly points in time series is challenging, which\nrequires the model to learn informative representations and derive a\ndistinguishable criterion. Prior methods mainly detect anomalies based on the\nrecurrent network representation of each time point. However, the point-wise\nrepresentation is less informative for complex temporal patterns and can be\ndominated by normal patterns, making rare anomalies less distinguishable. We\nfind that in each time series, each time point can also be described by its\nassociations with all time points, presenting as a point-wise distribution that\nis more expressive for temporal modeling. We further observe that due to the\nrarity of anomalies, it is harder for anomalies to build strong associations\nwith the whole series and their associations shall mainly concentrate on the\nadjacent time points. This observation implies an inherently distinguishable\ncriterion between normal and abnormal points, which we highlight as the\n\\emph{Association Discrepancy}. Technically we propose the \\emph{Anomaly\nTransformer} with an \\emph{Anomaly-Attention} mechanism to compute the\nassociation discrepancy. A minimax strategy is devised to amplify the\nnormal-abnormal distinguishability of the association discrepancy. Anomaly\nTransformer achieves state-of-the-art performance on six unsupervised time\nseries anomaly detection benchmarks for three applications: service monitoring,\nspace \\& earth exploration, and water treatment.",
    "descriptor": "",
    "authors": [
      "Jiehui Xu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02642"
  },
  {
    "id": "arXiv:2110.02645",
    "title": "A Weighted Generalized Coherence Approach for Sensing Matrix Design",
    "abstract": "As compared to using randomly generated sensing matrices, optimizing the\nsensing matrix w.r.t. a carefully designed criterion is known to lead to better\nquality signal recovery given a set of compressive measurements. In this paper,\nwe propose generalizations of the well-known mutual coherence criterion for\noptimizing sensing matrices starting from random initial conditions. We term\nthese generalizations as bi-coherence or tri-coherence and they are based on a\ncriterion that discourages any one column of the sensing matrix from being\nclose to a sparse linear combination of other columns. We also incorporate\ntraining data to further improve the sensing matrices through weighted\ncoherence, weighted bi-coherence, or weighted tri-coherence criteria, which\nassign weights to sensing matrix columns as per their importance. An algorithm\nis also presented to solve the optimization problems. Finally, the\neffectiveness of the proposed algorithm is demonstrated through empirical\nresults.",
    "descriptor": "\nComments: 8 pages, 16 figures\n",
    "authors": [
      "Ameya Anjarlekar",
      "Ajit Rajwade"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02645"
  },
  {
    "id": "arXiv:2110.02647",
    "title": "Entropy Regularised Deterministic Optimal Control: From Path Integral  Solution to Sample-Based Trajectory Optimisation",
    "abstract": "Sample-based trajectory optimisers are a promising tool for the control of\nrobotics with non-differentiable dynamics and cost functions. Contemporary\napproaches derive from a restricted subclass of stochastic optimal control\nwhere the optimal policy can be expressed in terms of an expectation over\nstochastic paths. By estimating the expectation with Monte Carlo sampling and\nreinterpreting the process as exploration noise, a stochastic search algorithm\nis obtained tailored to (deterministic) trajectory optimisation. For the\npurpose of future algorithmic development, it is essential to properly\nunderstand the underlying theoretical foundations that allow for a principled\nderivation of such methods. In this paper we make a connection between entropy\nregularisation in optimisation and deterministic optimal control. We then show\nthat the optimal policy is given by a belief function rather than a\ndeterministic function. The policy belief is governed by a Bayesian-type update\nwhere the likelihood can be expressed in terms of a conditional expectation\nover paths induced by a prior policy. Our theoretical investigation firmly\nroots sample based trajectory optimisation in the larger family of control as\ninference. It allows us to justify a number of heuristics that are common in\nthe literature and motivate a number of new improvements that benefit\nconvergence.",
    "descriptor": "",
    "authors": [
      "Tom Lefebvre",
      "Guillaume Crevecoeur"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02647"
  },
  {
    "id": "arXiv:2110.02651",
    "title": "Weak Novel Categories without Tears: A Survey on Weak-Shot Learning",
    "abstract": "Deep learning is a data-hungry approach, which requires massive training\ndata. However, it is time-consuming and labor-intensive to collect abundant\nfully-annotated training data for all categories. Assuming the existence of\nbase categories with adequate fully-annotated training samples, different\nparadigms requiring fewer training samples or weaker annotations for novel\ncategories have attracted growing research interest. Among them, zero-shot\n(resp., few-shot) learning explores using zero (resp., a few) training samples\nfor novel categories, which lowers the quantity requirement for novel\ncategories. Instead, weak-shot learning lowers the quality requirement for\nnovel categories. Specifically, sufficient training samples are collected for\nnovel categories but they only have weak annotations. In different tasks, weak\nannotations are presented in different forms (e.g., noisy labels for image\nclassification, image labels for object detection, bounding boxes for\nsegmentation), similar to the definitions in weakly supervised learning.\nTherefore, weak-shot learning can also be treated as weakly supervised learning\nwith auxiliary fully supervised categories. In this paper, we discuss the\nexisting weak-shot learning methodologies in different tasks and summarize the\ncodes at https://github.com/bcmi/Awesome-Weak-Shot-Learning.",
    "descriptor": "",
    "authors": [
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02651"
  },
  {
    "id": "arXiv:2110.02653",
    "title": "Proactive Scheduling and Caching for Wireless VR Viewport Streaming",
    "abstract": "Virtual Reality (VR) applications require high data rate for a high-quality\nimmersive experience, in addition to low latency to avoid dizziness and motion\nsickness. One of the key wireless VR challenges is providing seamless\nconnectivity and meeting the stringent latency and bandwidth requirements. This\nwork proposes a proactive wireless VR system that utilizes information about\nthe user's future orientation for proactive scheduling and caching. This is\nachieved by leveraging deep neural networks to predict users' orientation\ntrained on a real dataset. The 360{\\deg} scene is then partitioned using an\noverlapping viewports scheme so that only portions of the scene covered by the\nusers' perceptive field-of-view are streamed. Furthermore, to minimize the\nbackhaul latency, popular viewports are cached at the edge cloud based on\nspatial popularity profiles. Through extensive simulations, we show that the\nproposed system provides significant latency and throughput performance\nimprovement, especially in fluctuating channels and heavy load conditions. The\nproactive scheduling enabled by the combination of machine learning prediction\nand the proposed viewport scheme reduces the mean latency by more than 80%\nwhile achieving successful delivery rate close to 100%.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted for presentation in the IEEE Globecom Workshops 2021\n",
    "authors": [
      "Mostafa Abdelrahman",
      "Mohammed Elbamby",
      "Vilho R\u00e4is\u00e4nen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02653"
  },
  {
    "id": "arXiv:2110.02661",
    "title": "PlumeCityNet: Multi-Resolution Air Quality Forecasting",
    "abstract": "This paper presents an engine able to forecast jointly the concentrations of\nthe main pollutants harming people's health: nitrogen dioxide (NO2), ozone (O3)\nand particulate matter (PM2.5 and PM10, which are respectively the particles\nwhose diameters are below 2.5um and 10um respectively). The engine is fed with\nair quality monitoring stations' measurements, weather forecasts, physical\nmodels' outputs and traffic estimates to produce forecasts up to 24 hours. The\nforecasts are produced with several spatial resolutions, from a few dozens of\nmeters to dozens of kilometers, fitting several use-cases needing air quality\ndata.\nWe introduce the Scale-Unit block, which enables to integrate seamlessly all\navailable inputs at a given resolution to return forecasts at the same\nresolution. Then, the engine is based on a U-Net architecture built with\nseveral of those blocks, giving it the ability to process inputs and to output\npredictions at different resolutions.\nWe have implemented and evaluated the engine on the largest cities in Europe\nand the United States, and it clearly outperforms other prediction methods. In\nparticular, the out-of-sample accuracy remains high, meaning that the engine\ncan be used in cities which are not included in the training dataset. A\nvaluable advantage of the engine is that it does not need much computing power:\nthe forecasts can be built in a few minutes on a standard CPU. Thus, they can\nbe updated very frequently, as soon as new air quality monitoring stations'\nmeasurements are available (generally every hour), which is not the case of\nphysical models traditionally used for air quality forecasting.",
    "descriptor": "\nComments: 9 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2006.09204\n",
    "authors": [
      "Thibaut Cassard",
      "Gr\u00e9goire Jauvion",
      "Antoine All\u00e9on",
      "Boris Quennehen",
      "David Lissmyr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.02661"
  },
  {
    "id": "arXiv:2110.02665",
    "title": "A structure preserving shift-invert infinite Arnoldi algorithm for a  class of delay eigenvalue problems with Hamiltonian symmetry",
    "abstract": "In this work we consider a class of non-linear eigenvalue problems that admit\na spectrum similar to that of a Hamiltonian matrix, in the sense that the\nspectrum is symmetric with respect to both the real and imaginary axis. More\nprecisely, we present a method to iteratively approximate the eigenvalues of\nsuch non-linear eigenvalue problems closest to a given purely real or imaginary\nshift, while preserving the symmetries of the spectrum. To this end the\npresented method exploits the equivalence between the considered non-linear\neigenvalue problem and the eigenvalue problem associated with a linear but\ninfinite-dimensional operator. To compute the eigenvalues closest to the given\nshift, we apply a specifically chosen shift-invert transformation to this\nlinear operator and compute the eigenvalues with the largest modulus of the new\nshifted and inverted operator using an (infinite) Arnoldi procedure. The\nadvantage of the chosen shift-invert transformation is that the spectrum of the\ntransformed operator has a \"real skew-Hamiltonian\"-like structure. Furthermore,\nit is proven that the Krylov space constructed by applying this operator,\nsatisfies an orthogonality property in terms of a specifically chosen bilinear\nform. By taking this property into account in the orthogonalization process, it\nis ensured that even in the presence of rounding errors, the obtained\napproximation for, e.g., a simple, purely imaginary eigenvalue is simple and\npurely imaginary. The presented work can thus be seen as an extension of [V.\nMehrmann and D. Watkins, \"Structure-Preserving Methods for Computing Eigenpairs\nof Large Sparse Skew-Hamiltonian/Hamiltonian Pencils\", SIAM J. Sci. Comput.\n(22.6), 2001], to the considered class of non-linear eigenvalue problems.\nAlthough the presented method is initially defined on function spaces, it can\nbe implemented using finite dimensional linear algebra operations.",
    "descriptor": "",
    "authors": [
      "Pieter Appeltans",
      "Wim Michiels"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02665"
  },
  {
    "id": "arXiv:2110.02667",
    "title": "An Analysis of Attentive Walk-Aggregating Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have been shown to possess strong representation\npower, which can be exploited for downstream prediction tasks on\ngraph-structured data, such as molecules and social networks. They typically\nlearn representations by aggregating information from the K-hop neighborhood of\nindividual vertices or from the enumerated walks in the graph. Prior studies\nhave demonstrated the effectiveness of incorporating weighting schemes into\nGNNs; however, this has been primarily limited to K-hop neighborhood GNNs so\nfar. In this paper, we aim to extensively analyze the effect of incorporating\nweighting schemes into walk-aggregating GNNs. Towards this objective, we\npropose a novel GNN model, called AWARE, that aggregates information about the\nwalks in the graph using attention schemes in a principled way to obtain an\nend-to-end supervised learning method for graph-level prediction tasks. We\nperform theoretical, empirical, and interpretability analyses of AWARE. Our\ntheoretical analysis provides the first provable guarantees for weighted GNNs,\ndemonstrating how the graph information is encoded in the representation, and\nhow the weighting schemes in AWARE affect the representation and learning\nperformance. We empirically demonstrate the superiority of AWARE over prior\nbaselines in the domains of molecular property prediction (61 tasks) and social\nnetworks (4 tasks). Our interpretation study illustrates that AWARE can\nsuccessfully learn to capture the important substructures of the input graph.",
    "descriptor": "\nComments: Preprint (36 Pages)\n",
    "authors": [
      "Mehmet F. Demirel",
      "Shengchao Liu",
      "Siddhant Garg",
      "Yingyu Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02667"
  },
  {
    "id": "arXiv:2110.02669",
    "title": "Digital Divide and Social Dilemma of Privacy Preservation",
    "abstract": "While digital divide studies primarily focused on access to information and\ncommunications technology (ICT) in the past, its influence on other associated\ndimensions such as privacy is becoming critical with a far-reaching impact on\nthe people and society. For example, the various levels of government\nlegislation and compliance on information privacy worldwide have created a new\nera of digital divide in the privacy preservation domain. In this article, the\nconcept \"digital privacy divide (DPD)\" is introduced to describe the perceived\ngap in the privacy preservation of individuals based on the geopolitical\nlocation of different countries. To better understand the DPD phenomenon, we\ncreated an online questionnaire and collected answers from more than 700\nrespondents from four different countries (the United States, Germany,\nBangladesh, and India) who come from two distinct cultural orientations as per\nHofstede's individualist vs. collectivist society. However, our results\nrevealed some interesting findings. DPD does not depend on Hofstede's cultural\norientation of the countries. For example, individuals residing in Germany and\nBangladesh share similar privacy concerns, while there is a significant\nsimilarity among individuals residing in the United States and India. Moreover,\nwhile most respondents acknowledge the importance of privacy legislation to\nprotect their digital privacy, they do not mind their governments to allow\ndomestic companies and organizations collecting personal data on individuals\nresiding outside their countries, if there are economic, employment, and crime\nprevention benefits. These results suggest a social dilemma in the perceived\nprivacy preservation, which could be dependent on many other contextual factors\nbeyond government legislation and countries' cultural orientation.",
    "descriptor": "",
    "authors": [
      "Hamoud Alhazmi",
      "Ahmed Imran",
      "Mohammad Abu Alsheikh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.02669"
  },
  {
    "id": "arXiv:2110.02670",
    "title": "S-Extension Patch: A simple and efficient way to extend an object  detection model",
    "abstract": "While building convolutional network-based systems, the toll it takes to\ntrain the network is something that cannot be ignored. In cases where we need\nto append additional capabilities to the existing model, the attention\nimmediately goes towards retraining techniques. In this paper, I show how to\nleverage knowledge about the dataset to append the class faster while\nmaintaining the speed of inference as well as the accuracies; while reducing\nthe amount of time and data required. The method can extend a class in the\nexisting object detection model in 1/10th of the time compared to the other\nexisting methods. S-Extension patch not only offers faster training but also\nspeed and ease of adaptation, as it can be appended to any existing system,\ngiven it fulfills the similarity threshold condition.",
    "descriptor": "",
    "authors": [
      "Dishant Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02670"
  },
  {
    "id": "arXiv:2110.02672",
    "title": "Physics-Informed Neural Networks for AC Optimal Power Flow",
    "abstract": "This paper introduces, for the first time to our knowledge, physics-informed\nneural networks to accurately estimate the AC-OPF result and delivers rigorous\nguarantees about their performance. Power system operators, along with several\nother actors, are increasingly using Optimal Power Flow (OPF) algorithms for a\nwide number of applications, including planning and real-time operations.\nHowever, in its original form, the AC Optimal Power Flow problem is often\nchallenging to solve as it is non-linear and non-convex. Besides the large\nnumber of approximations and relaxations, recent efforts have also been\nfocusing on Machine Learning approaches, especially neural networks. So far,\nhowever, these approaches have only partially considered the wide number of\nphysical models available during training. And, more importantly, they have\noffered no guarantees about potential constraint violations of their output.\nOur approach (i) introduces the AC power flow equations inside neural network\ntraining and (ii) integrates methods that rigorously determine and reduce the\nworst-case constraint violations across the entire input domain, while\nmaintaining the optimality of the prediction. We demonstrate how\nphysics-informed neural networks achieve higher accuracy and lower constraint\nviolations than standard neural networks, and show how we can further reduce\nthe worst-case violations for all neural networks.",
    "descriptor": "",
    "authors": [
      "Rahul Nellikkath",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02672"
  },
  {
    "id": "arXiv:2110.02673",
    "title": "Scaling Up Machine Learning For Quantum Field Theory with Equivariant  Continuous Flows",
    "abstract": "We propose a continuous normalizing flow for sampling from the\nhigh-dimensional probability distributions of Quantum Field Theories in\nPhysics. In contrast to the deep architectures used so far for this task, our\nproposal is based on a shallow design and incorporates the symmetries of the\nproblem. We test our model on the $\\phi^4$ theory, showing that it\nsystematically outperforms a realNVP baseline in sampling efficiency, with the\ndifference between the two increasing for larger lattices. On the largest\nlattice we consider, of size $32\\times 32$, we improve a key metric, the\neffective sample size, from 1% to 66% w.r.t. the realNVP baseline.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Pim de Haan",
      "Corrado Rainone",
      "Miranda Cheng",
      "Roberto Bondesan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2110.02673"
  },
  {
    "id": "arXiv:2110.02678",
    "title": "One-Dimensional Fragment over Words and Trees",
    "abstract": "One-dimensional fragment of first-order logic is obtained by restricting\nquantification to blocks of existential (universal) quantifiers that leave at\nmost one variable free. We investigate this fragment over words and trees,\npresenting a complete classification of the complexity of its satisfiability\nproblem for various navigational signatures, and comparing its expressive power\nwith other important formalisms. These include the two-variable fragment with\ncounting and the unary negation fragment.",
    "descriptor": "\nComments: Full version of [1] Emanuel Kieronski: One-Dimensional Logic over Words. CSL 2016: 38:1-38:15 [2] Emanuel Kieronski, Antti Kuusisto: One-Dimensional Logic over Trees. MFCS 2017: 64:1-64:13\n",
    "authors": [
      "Emanuel Kieronski",
      "Antti Kuusisto"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.02678"
  },
  {
    "id": "arXiv:2110.02682",
    "title": "How good does a Defect Predictor need to be to guide Search-Based  Software Testing?",
    "abstract": "Defect predictors, static bug detectors and humans inspecting the code can\nlocate the parts of the program that are buggy before they are discovered\nthrough testing. Automated test generators such as search-based software\ntesting (SBST) techniques can use this information to direct their search for\ntest cases to likely buggy code, thus speeding up the process of detecting\nexisting bugs. However, often the predictions given by these tools or humans\nare imprecise, which can misguide the SBST technique and may deteriorate its\nperformance. In this paper, we study the impact of imprecision in defect\nprediction on the bug detection effectiveness of SBST.\nOur study finds that the recall of the defect predictor, i.e., the\nprobability of correctly identifying buggy code, has a significant impact on\nbug detection effectiveness of SBST with a large effect size. On the other\nhand, the effect of precision, a measure for false alarms, is not of meaningful\npractical significance as indicated by a very small effect size. In particular,\nthe SBST technique finds 7.5 less bugs on average (out of 420 bugs) for every\n5% decrements of the recall.\nIn the context of combining defect prediction and SBST, our recommendation\nfor practice is to increase the recall of defect predictors at the expense of\nprecision, while maintaining a precision of at least 75%. To account for the\nimprecision of defect predictors, in particular low recall values, SBST\ntechniques should be designed to search for test cases that also cover the\npredicted non-buggy parts of the program, while prioritising the parts that\nhave been predicted as buggy.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Anjana Perera",
      "Burak Turhan",
      "Aldeida Aleti",
      "Marcel B\u00f6hme"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02682"
  },
  {
    "id": "arXiv:2110.02686",
    "title": "Long-tailed Distribution Adaptation",
    "abstract": "Recognizing images with long-tailed distributions remains a challenging\nproblem while there lacks an interpretable mechanism to solve this problem. In\nthis study, we formulate Long-tailed recognition as Domain Adaption (LDA), by\nmodeling the long-tailed distribution as an unbalanced domain and the general\ndistribution as a balanced domain. Within the balanced domain, we propose to\nslack the generalization error bound, which is defined upon the empirical risks\nof unbalanced and balanced domains and the divergence between them. We propose\nto jointly optimize empirical risks of the unbalanced and balanced domains and\napproximate their domain divergence by intra-class and inter-class distances,\nwith the aim to adapt models trained on the long-tailed distribution to general\ndistributions in an interpretable way. Experiments on benchmark datasets for\nimage recognition, object detection, and instance segmentation validate that\nour LDA approach, beyond its interpretability, achieves state-of-the-art\nperformance. Code is available at https://github.com/pengzhiliang/LDA.",
    "descriptor": "\nComments: Accepted in acm mm2021\n",
    "authors": [
      "Zhiliang Peng",
      "Wei Huang",
      "Zonghao Guo",
      "Xiaosong Zhang",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02686"
  },
  {
    "id": "arXiv:2110.02687",
    "title": "Objects in Semantic Topology",
    "abstract": "A more realistic object detection paradigm, Open-World Object Detection, has\narisen increasing research interests in the community recently. A qualified\nopen-world object detector can not only identify objects of known categories,\nbut also discover unknown objects, and incrementally learn to categorize them\nwhen their annotations progressively arrive. Previous works rely on independent\nmodules to recognize unknown categories and perform incremental learning,\nrespectively. In this paper, we provide a unified perspective: Semantic\nTopology. During the life-long learning of an open-world object detector, all\nobject instances from the same category are assigned to their corresponding\npre-defined node in the semantic topology, including the `unknown' category.\nThis constraint builds up discriminative feature representations and consistent\nrelationships among objects, thus enabling the detector to distinguish unknown\nobjects out of the known categories, as well as making learned features of\nknown objects undistorted when learning new categories incrementally. Extensive\nexperiments demonstrate that semantic topology, either randomly-generated or\nderived from a well-trained language model, could outperform the current\nstate-of-the-art open-world object detectors by a large margin, e.g., the\nabsolute open-set error is reduced from 7832 to 2546, exhibiting the inherent\nsuperiority of semantic topology on open-world object detection.",
    "descriptor": "",
    "authors": [
      "Shuo Yang",
      "Peize Sun",
      "Yi Jiang",
      "Xiaobo Xia",
      "Ruiheng Zhang",
      "Zehuan Yuan",
      "Changhu Wang",
      "Ping Luo",
      "Min Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02687"
  },
  {
    "id": "arXiv:2110.02688",
    "title": "Towards Non-Uniform k-Center with Constant Types of Radii",
    "abstract": "In the Non-Uniform k-Center problem we need to cover a finite metric space\nusing k balls of different radii that can be scaled uniformly. The goal is to\nminimize the scaling factor. If the number of different radii is unbounded, the\nproblem does not admit a constant-factor approximation algorithm but it has\nbeen conjectured that such an algorithm exists if the number of radii is\nconstant. Yet, this is known only for the case of two radii. Our first\ncontribution is a simple black box reduction which shows that if one can handle\nthe variant of t-1 radii with outliers, then one can also handle t radii.\nTogether with an algorithm by Chakrabarty and Negahbani for two radii with\noutliers, this immediately implies a constant-factor approximation algorithm\nfor three radii, thus making further progress on the conjecture. Furthermore,\nusing algorithms for the k-center with outliers problem, that is the one radii\nwith outliers case, we also get a simple algorithm for two radii.\nThe algorithm by Chakrabarty and Negahbani uses a top-down approach, starting\nwith the larger radius and then proceeding to the smaller one. Our reduction,\non the other hand, looks only at the smallest radius and eliminates it, which\nsuggests that a bottom-up approach is promising. In this spirit, we devise a\nmodification of the Chakrabarty and Negahbani algorithm which runs in a\nbottom-up fashion, and in this way we recover their result with the advantage\nof having a simpler analysis.",
    "descriptor": "\nComments: Accepted in SOSA 2022\n",
    "authors": [
      "Xinrui Jia",
      "Lars Rohwedder",
      "Kshiteej Sheth",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02688"
  },
  {
    "id": "arXiv:2110.02691",
    "title": "Concrete Categorical Model of a Quantum Circuit Description Language  with Measurement",
    "abstract": "In this paper, we introduce dynamic lifting to a quantum circuit-description\nlanguage, following the Proto-Quipper language approach. Dynamic lifting allows\nprograms to transfer the result of measuring quantum data -- qubits -- into\nclassical data -- booleans -- . We propose a type system and an operational\nsemantics for the language and we state safety properties. Next, we introduce a\nconcrete categorical semantics for the proposed language, basing our approach\non a recent model from Rios\\&Selinger for Proto-Quipper-M. Our approach is to\nconstruct on top of a concrete category of circuits with measurements a Kleisli\ncategory, capturing as a side effect the action of retrieving classical content\nout of a quantum memory. We then show a soundness result for this semantics.",
    "descriptor": "\nComments: accepted for publication in FSTTCS 2021\n",
    "authors": [
      "Dongho Lee",
      "Valentin Perrelle",
      "Beno\u00eet Valiron",
      "Zhaowei Xu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.02691"
  },
  {
    "id": "arXiv:2110.02692",
    "title": "Location Method for Forced Oscillation Sources Caused by Synchronous  Generators",
    "abstract": "In this article, we present a new methodology to identify if forced\noscillation sources are generated in excitation systems or in turbine\ngovernors. In this context, we propose to harness the information that the\ndynamic state estimation (DSE) provide to be able to apply a dissipating energy\nflow (DEF) method. The measurements that the phasor measurement units (PMUs)\nprovide are used to estimate the internal states of different generators\nconnected to the same bus. Here, it will be considered that the PMU at the\npoint of connection is only capable of measuring the voltage phasor and the\ntotal current phasor. Therefore, the current injection of the generator that is\ncausing the FO is an unobservable variable. To overcome this issue, event\nplayback is applied to simulate the model's response and a comparison between\nthe DSE of multiple generators is made. Finally, when the faulty generator is\nidentified, we compute energy functions for the mechanical control loop and for\nthe excitation control loop. The sign and rate of these energies determine the\nsource of the oscillation, allowing that the FO can be located. Simulated\nsignals are used to show that the proposed method provides a systematic\nmethodology for identification and location of power systems forced\noscillations than even could be non-stationary signals.",
    "descriptor": "",
    "authors": [
      "Pablo Marchi",
      "Pablo Gill Estevez",
      "Cecilia Galarza"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02692"
  },
  {
    "id": "arXiv:2110.02700",
    "title": "Reversible adversarial examples against local visual perturbation",
    "abstract": "Recently, studies have indicated that adversarial attacks pose a threat to\ndeep learning systems. However, when there are only adversarial examples,\npeople cannot get the original images, so there is research on reversible\nadversarial attacks. However, the existing strategies are aimed at invisible\nadversarial perturbation, and do not consider the case of locally visible\nadversarial perturbation. In this article, we generate reversible adversarial\nexamples for local visual adversarial perturbation, and use reversible data\nembedding technology to embed the information needed to restore the original\nimage into the adversarial examples to generate examples that are both\nadversarial and reversible. Experiments on ImageNet dataset show that our\nmethod can restore the original image losslessly while ensuring the attack\ncapability.",
    "descriptor": "",
    "authors": [
      "Zhaoxia Yin",
      "Li Chen",
      "Shaowei Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02700"
  },
  {
    "id": "arXiv:2110.02707",
    "title": "Trustworthy Artificial Intelligence and Process Mining: Challenges and  Opportunities",
    "abstract": "The premise of this paper is that compliance with Trustworthy AI governance\nbest practices and regulatory frameworks is an inherently fragmented process\nspanning across diverse organizational units, external stakeholders, and\nsystems of record, resulting in process uncertainties and in compliance gaps\nthat may expose organizations to reputational and regulatory risks. Moreover,\nthere are complexities associated with meeting the specific dimensions of\nTrustworthy AI best practices such as data governance, conformance testing,\nquality assurance of AI model behaviors, transparency, accountability, and\nconfidentiality requirements. These processes involve multiple steps,\nhand-offs, re-works, and human-in-the-loop oversight. In this paper, we\ndemonstrate that process mining can provide a useful framework for gaining\nfact-based visibility to AI compliance process execution, surfacing compliance\nbottlenecks, and providing for an automated approach to analyze, remediate and\nmonitor uncertainty in AI regulatory compliance processes.",
    "descriptor": "",
    "authors": [
      "Andrew Pery",
      "Majid Rafiei",
      "Michael Simon",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02707"
  },
  {
    "id": "arXiv:2110.02708",
    "title": "Application of the interactive Leipzig Corpus Miner as a generic  research platform for the use in the social sciences",
    "abstract": "This article introduces to the interactive Leipzig Corpus Miner (iLCM) - a\nnewly released, open-source software to perform automatic content analysis.\nSince the iLCM is based on the R-programming language, its generic text mining\nprocedures provided via a user-friendly graphical user interface (GUI) can\neasily be extended using the integrated IDE RStudio-Server or numerous other\ninterfaces in the tool. Furthermore, the iLCM offers various possibilities to\nuse quantitative and qualitative research approaches in combination. Some of\nthese possibilities will be presented in more detail in the following.",
    "descriptor": "",
    "authors": [
      "Christian Kahmann",
      "Andreas Niekler",
      "Gregor Wiedemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02708"
  },
  {
    "id": "arXiv:2110.02709",
    "title": "Subquadratic-time algorithm for the diameter and all eccentricities on  median graphs",
    "abstract": "On sparse graphs, Roditty and Williams [2013] proved that no\n$O(n^{2-\\varepsilon})$-time algorithm achieves an approximation factor smaller\nthan $\\frac{3}{2}$ for the diameter problem unless SETH fails. In this article,\nwe solve a longstanding question: can we use the structural properties of\nmedian graphs to break this global quadratic barrier?\nWe propose the first combinatiorial algorithm computing exactly all\neccentricities of a median graph in truly subquadratic time. Median graphs\nconstitute the family of graphs which is the most studied in metric graph\ntheory because their structure represent many other discrete and geometric\nconcepts, such as CAT(0) cube complexes. Our result generalizes a recent one,\nstating that there is a linear-time algorithm for all eccentricities in median\ngraphs with bounded dimension $d$, i.e. the dimension of the largest induced\nhypercube. This prerequisite on $d$ is not necessarily anymore to determine all\neccentricities in subquadratic time. The execution time of our algorithm is\n$O(n^{1.6456}\\log^{O(1)} n)$.\nWe provide also some satellite outcomes related to this general result. In\nparticular, restricted to simplex graphs, this algorithm enumerate all\neccentricities with a quasilinear running time. Moreover, an algorithm is\nproposed to compute exactly all reach centralities in time\n$O(2^{3d}n\\log^{O(1)}n)$.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Pierre Berg\u00e9",
      "Guillaume Ducoffe",
      "Michel Habib"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.02709"
  },
  {
    "id": "arXiv:2110.02710",
    "title": "Model Learning and Contextual Controller Tuning for Autonomous Racing",
    "abstract": "Model predictive control has been widely used in the field of autonomous\nracing and many data-driven approaches have been proposed to improve the\nclosed-loop performance and to minimize lap time. However, it is often\noverlooked that a change in the environmental conditions, e.g., when it starts\nraining, it is not only required to adapt the predictive model but also the\ncontroller parameters need to be adjusted. In this paper, we address this\nchallenge with the goal of requiring only few data. The key novelty of the\nproposed approach is that we leverage the learned dynamics model to encode the\nenvironmental condition as context. This insight allows us to employ contextual\nBayesian optimization, thus accelerating the controller tuning problem when the\nenvironment changes and to transfer knowledge across different cars. The\nproposed framework is validated on an experimental platform with 1:28 scale RC\nrace cars. We perform an extensive evaluation with more than 2'000 driven laps\ndemonstrating that our approach successfully optimizes the lap time across\ndifferent contexts faster compared to standard Bayesian optimization.",
    "descriptor": "",
    "authors": [
      "Lukas P. Fr\u00f6hlich",
      "Christian K\u00fcttel",
      "Elena Arcari",
      "Lukas Hewing",
      "Melanie N. Zeilinger",
      "Andrea Carron"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02710"
  },
  {
    "id": "arXiv:2110.02711",
    "title": "DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models",
    "abstract": "Diffusion models are recent generative models that have shown great success\nin image generation with the state-of-the-art performance. However, only a few\nresearches have been conducted for image manipulation with diffusion models.\nHere, we present a novel DiffusionCLIP which performs text-driven image\nmanipulation with diffusion models using Contrastive Language-Image\nPre-training (CLIP) loss. Our method has a performance comparable to that of\nthe modern GAN-based image processing methods for in and out-of-domain image\nprocessing tasks, with the advantage of almost perfect inversion even without\nadditional encoders or optimization. Furthermore, our method can be easily used\nfor various novel applications, enabling image translation from an unseen\ndomain to another unseen domain or stroke-conditioned image generation in an\nunseen domain, etc. Finally, we present a novel multiple attribute control with\nDiffusionCLIPby combining multiple fine-tuned diffusion models.",
    "descriptor": "",
    "authors": [
      "Gwanghyun Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02711"
  },
  {
    "id": "arXiv:2110.02716",
    "title": "Knothe-Rosenblatt transport for Unsupervised Domain Adaptation",
    "abstract": "Unsupervised domain adaptation (UDA) aims at exploiting related but different\ndata sources to tackle a common task in a target domain. UDA remains a central\nyet challenging problem in machine learning. In this paper, we present an\napproach tailored to moderate-dimensional tabular problems which are hugely\nimportant in industrial applications and less well-served by the plethora of\nmethods designed for image and language data. Knothe-Rosenblatt Domain\nAdaptation (KRDA) is based on the Knothe-Rosenblatt transport: we exploit\nautoregressive density estimation algorithms to accurately model the different\nsources by an autoregressive model using a mixture of Gaussians. KRDA then\ntakes advantage of the triangularity of the autoregressive models to build an\nexplicit mapping of the source samples into the target domain. We show that the\ntransfer map built by KRDA preserves each component quantiles of the\nobservations, hence aligning the representations of the different data sets in\nthe same target domain. Finally, we show that KRDA has state-of-the-art\nperformance on both synthetic and real world UDA problems.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Aladin Virmaux",
      "Illyyne Saffar",
      "Jianfeng Zhang",
      "Bal\u00e1zs K\u00e9gl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02716"
  },
  {
    "id": "arXiv:2110.02718",
    "title": "Generalizing Neural Networks by Reflecting Deviating Data in Production",
    "abstract": "Trained with a sufficiently large training and testing dataset, Deep Neural\nNetworks (DNNs) are expected to generalize. However, inputs may deviate from\nthe training dataset distribution in real deployments. This is a fundamental\nissue with using a finite dataset. Even worse, real inputs may change over time\nfrom the expected distribution. Taken together, these issues may lead deployed\nDNNs to mis-predict in production.\nIn this work, we present a runtime approach that mitigates DNN\nmis-predictions caused by the unexpected runtime inputs to the DNN. In contrast\nto previous work that considers the structure and parameters of the DNN itself,\nour approach treats the DNN as a blackbox and focuses on the inputs to the DNN.\nOur approach has two steps. First, it recognizes and distinguishes \"unseen\"\nsemantically-preserving inputs. For this we use a distribution analyzer based\non the distance metric learned by a Siamese network. Second, our approach\ntransforms those unexpected inputs into inputs from the training set that are\nidentified as having similar semantics. We call this process input reflection\nand formulate it as a search problem over the embedding space on the training\nset. This embedding space is learned by a Quadruplet network as an auxiliary\nmodel for the subject model to improve the generalization.\nWe implemented a tool called InputReflector based on the above two-step\napproach and evaluated it with experiments on three DNN models trained on\nCIFAR-10, MNIST, and FMINST image datasets. The results show that\nInputReflector can effectively distinguish inputs that retain semantics of the\ndistribution (e.g., blurred, brightened, contrasted, and zoomed images) and\nout-of-distribution inputs from normal inputs.",
    "descriptor": "",
    "authors": [
      "Yan Xiao",
      "Yun Lin",
      "Ivan Beschastnikh",
      "Changsheng Sun",
      "David S. Rosenblum",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02718"
  },
  {
    "id": "arXiv:2110.02719",
    "title": "The Information Geometry of Unsupervised Reinforcement Learning",
    "abstract": "How can a reinforcement learning (RL) agent prepare to solve downstream tasks\nif those tasks are not known a priori? One approach is unsupervised skill\ndiscovery, a class of algorithms that learn a set of policies without access to\na reward function. Such algorithms bear a close resemblance to representation\nlearning algorithms (e.g., contrastive learning) in supervised learning, in\nthat both are pretraining algorithms that maximize some approximation to a\nmutual information objective. While prior work has shown that the set of skills\nlearned by such methods can accelerate downstream RL tasks, prior work offers\nlittle analysis into whether these skill learning algorithms are optimal, or\neven what notion of optimality would be appropriate to apply to them. In this\nwork, we show that unsupervised skill discovery algorithms based on mutual\ninformation maximization do not learn skills that are optimal for every\npossible reward function. However, we show that the distribution over skills\nprovides an optimal initialization minimizing regret against\nadversarially-chosen reward functions, assuming a certain type of adaptation\nprocedure. Our analysis also provides a geometric perspective on these skill\nlearning methods.",
    "descriptor": "",
    "authors": [
      "Benjamin Eysenbach",
      "Ruslan Salakhutdinov",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02719"
  },
  {
    "id": "arXiv:2110.02720",
    "title": "Efficient learning methods for large-scale optimal inversion design",
    "abstract": "In this work, we investigate various approaches that use learning from\ntraining data to solve inverse problems, following a bi-level learning\napproach. We consider a general framework for optimal inversion design, where\ntraining data can be used to learn optimal regularization parameters, data\nfidelity terms, and regularizers, thereby resulting in superior variational\nregularization methods. In particular, we describe methods to learn optimal $p$\nand $q$ norms for ${\\rm L}^p-{\\rm L}^q$ regularization and methods to learn\noptimal parameters for regularization matrices defined by covariance kernels.\nWe exploit efficient algorithms based on Krylov projection methods for solving\nthe regularized problems, both at training and validation stages, making these\nmethods well-suited for large-scale problems. Our experiments show that the\nlearned regularization methods perform well even when there is some inexactness\nin the forward operator, resulting in a mixture of model and measurement error.",
    "descriptor": "",
    "authors": [
      "Julianne Chung",
      "Matthias Chung",
      "Silvia Gazzola",
      "Mirjeta Pasha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02720"
  },
  {
    "id": "arXiv:2110.02722",
    "title": "Graphon based Clustering and Testing of Networks: Algorithms and Theory",
    "abstract": "Network-valued data are encountered in a wide range of applications and pose\nchallenges in learning due to their complex structure and absence of vertex\ncorrespondence. Typical examples of such problems include classification or\ngrouping of protein structures and social networks. Various methods, ranging\nfrom graph kernels to graph neural networks, have been proposed that achieve\nsome success in graph classification problems. However, most methods have\nlimited theoretical justification, and their applicability beyond\nclassification remains unexplored. In this work, we propose methods for\nclustering multiple graphs, without vertex correspondence, that are inspired by\nthe recent literature on estimating graphons -- symmetric functions\ncorresponding to infinite vertex limit of graphs. We propose a novel graph\ndistance based on sorting-and-smoothing graphon estimators. Using the proposed\ngraph distance, we present two clustering algorithms and show that they achieve\nstate-of-the-art results. We prove the statistical consistency of both\nalgorithms under Lipschitz assumptions on the graph degrees. We further study\nthe applicability of the proposed distance for graph two-sample testing\nproblems.",
    "descriptor": "",
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Leena Chennuru Vankadara",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02722"
  },
  {
    "id": "arXiv:2110.02724",
    "title": "ParaDiS: Parallelly Distributable Slimmable Neural Networks",
    "abstract": "When several limited power devices are available, one of the most efficient\nways to make profit of these resources, while reducing the processing latency\nand communication load, is to run in parallel several neural sub-networks and\nto fuse the result at the end of processing. However, such a combination of\nsub-networks must be trained specifically for each particular configuration of\ndevices (characterized by number of devices and their capacities) which may\nvary over different model deployments and even within the same deployment. In\nthis work we introduce parallelly distributable slimmable (ParaDiS) neural\nnetworks that are splittable in parallel among various device configurations\nwithout retraining. While inspired by slimmable networks allowing instant\nadaptation to resources on just one device, ParaDiS networks consist of several\nmulti-device distributable configurations or switches that strongly share the\nparameters between them. We evaluate ParaDiS framework on MobileNet v1 and\nResNet-50 architectures on ImageNet classification task. We show that ParaDiS\nswitches achieve similar or better accuracy than the individual models, i.e.,\ndistributed models of the same structure trained individually. Moreover, we\nshow that, as compared to universally slimmable networks that are not\ndistributable, the accuracy of distributable ParaDiS switches either does not\ndrop at all or drops by a maximum of 1 % only in the worst cases.",
    "descriptor": "",
    "authors": [
      "Alexey Ozerov",
      "Anne Lambert",
      "Suresh Kirthi Kumaraswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02724"
  },
  {
    "id": "arXiv:2110.02730",
    "title": "Tight bounds for counting colorings and connected edge sets  parameterized by cutwidth",
    "abstract": "We study the fine-grained complexity of counting the number of colorings and\nconnected spanning edge sets parameterized by the cutwidth and treewidth of the\ngraph. Let $p,q \\in \\mathbb{N}$ such that $p$ is a prime and $q \\geq 3$. We\nshow:\n- If $p$ divides $q-1$, there is a $(q-1)^{{\\text{ctw}}}n^{O(1)}$ time\nalgorithm for counting list $q$-colorings modulo $p$ of $n$-vertex graphs of\ncutwidth ${\\text{ctw}}$. Furthermore, no algorithm can count the number of\ndistinct $q$-colorings modulo $p$ in time $(q-1-\\varepsilon)^{\\text{ctw}}\nn^{O(1)}$ for some $\\varepsilon>0$, assuming the Strong Exponential Time\nHypothesis (SETH).\n- If $p$ does not divide $q-1$, no algorithm can count the number of distinct\n$q$-colorings modulo $p$ in time $(q-\\varepsilon)^{\\text{ctw}} n^{O(1)}$ for\nsome $\\varepsilon>0$, assuming SETH.\nThe lower bounds are in stark contrast with the existing\n$2^{{\\text{ctw}}}n^{O(1)}$ time algorithm to compute the chromatic number of a\ngraph by Jansen and Nederlof~[Theor. Comput. Sci.'18]. Furthermore, by building\nupon the above lower bounds, we obtain the following lower bound for counting\nconnected spanning edge sets: there is no $\\varepsilon>0$ for which there is an\nalgorithm that, given a graph $G$ and a cutwidth ordering of cutwidth\n${\\text{ctw}}$, counts the number of spanning connected edge sets of $G$ modulo\n$p$ in time $(p - \\varepsilon)^{\\text{ctw}} n^{O(1)}$, assuming SETH. We also\ngive an algorithm with matching running time for this problem. Before our work,\neven for the treewidth parameterization, the best conditional lower bound by\nDell et al.~[ACM Trans. Algorithms'14] only excluded\n$2^{o({\\text{tw}})}n^{O(1)}$ time algorithms for this problem. Both our\nalgorithms and lower bounds employ use of the matrix rank method.",
    "descriptor": "",
    "authors": [
      "Carla Groenland",
      "Jesper Nederlof",
      "Isja Mannens",
      "Krisztina Szil\u00e1gyi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.02730"
  },
  {
    "id": "arXiv:2110.02732",
    "title": "On Margin Maximization in Linear and ReLU Networks",
    "abstract": "The implicit bias of neural networks has been extensively studied in recent\nyears. Lyu and Li [2019] showed that in homogeneous networks trained with the\nexponential or the logistic loss, gradient flow converges to a KKT point of the\nmax margin problem in the parameter space. However, that leaves open the\nquestion of whether this point will generally be an actual optimum of the max\nmargin problem. In this paper, we study this question in detail, for several\nneural network architectures involving linear and ReLU activations. Perhaps\nsurprisingly, we show that in many cases, the KKT point is not even a local\noptimum of the max margin problem. On the flip side, we identify multiple\nsettings where a local or global optimum can be guaranteed. Finally, we answer\na question posed in Lyu and Li [2019] by showing that for non-homogeneous\nnetworks, the normalized margin may strictly decrease over time.",
    "descriptor": "",
    "authors": [
      "Gal Vardi",
      "Ohad Shamir",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02732"
  },
  {
    "id": "arXiv:2110.02736",
    "title": "A Deep Reinforcement Learning Framework for Contention-Based Spectrum  Sharing",
    "abstract": "The increasing number of wireless devices operating in unlicensed spectrum\nmotivates the development of intelligent adaptive approaches to spectrum\naccess. We consider decentralized contention-based medium access for base\nstations (BSs) operating on unlicensed shared spectrum, where each BS\nautonomously decides whether or not to transmit on a given resource. The\ncontention decision attempts to maximize not its own downlink throughput, but\nrather a network-wide objective. We formulate this problem as a decentralized\npartially observable Markov decision process with a novel reward structure that\nprovides long term proportional fairness in terms of throughput. We then\nintroduce a two-stage Markov decision process in each time slot that uses\ninformation from spectrum sensing and reception quality to make a medium access\ndecision. Finally, we incorporate these features into a distributed\nreinforcement learning framework for contention-based spectrum access. Our\nformulation provides decentralized inference, online adaptability and also\ncaters to partial observability of the environment through recurrent\nQ-learning. Empirically, we find its maximization of the proportional fairness\nmetric to be competitive with a genie-aided adaptive energy detection\nthreshold, while being robust to channel fading and small contention windows.",
    "descriptor": "\nComments: 14 pages, 11 figures, 4 tables\n",
    "authors": [
      "Akash Doshi",
      "Srinivas Yerramalli",
      "Lorenzo Ferrari",
      "Taesang Yoo",
      "Jeffrey G. Andrews"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02736"
  },
  {
    "id": "arXiv:2110.02737",
    "title": "Analysis of Trade-offs in RF Photonic Links based on Multi-Bias Tuning  of Silicon Photonic Ring-Assisted Mach Zehnder Modulators",
    "abstract": "Recent progress in silicon-based photonic integrated circuits (PICs) have\nopened new avenues for analog circuit designers to explore hybrid integration\nof photonics with CMOS ICs. Traditionally, optoelectronic systems are designed\nusing discrete optics and electronics. Silicon photonic (SiP) platforms provide\nthe opportunity to realize these systems in a compact chip-scale form factor\nand alleviate long-standing challenges in optoelectronics. In this work, we\nanalyze multi-bias tuning in Ring-Assisted Mach Zehnder Modulator (RAMZM) and\nresulting trade-offs in analog RF photonic links realized using RAMZMs.\nMulti-bias tuning in the rings and the Mach-Zehnder arms allow informed\ntrade-offs between link noise figure and linearity. We derive performance\nmetrics including gain, noise figure, and linearity metrics associated with\ntuning of multiple bias settings in RAMZM based links and present resulting\ndesign optimization. Compared to MZM, an improvement of 18\ndB/Hz$^{\\frac{2}{3}}$ in SFDR is noted when RAMZM is linearized. We also\npropose a biasing scheme for RAMZM that provides 6x improvement in slope\nefficiency, or equivalently, 15.56dB in power Gain over MZMs (single drive)\nwhile still providing similar SFDR performance ($\\sim$ 109\ndB/Hz$^{\\frac{2}{3}}$) as MZMs. Moreover, a method to improve gain in\nphotodiode saturation limited links is presented and studied.",
    "descriptor": "\nComments: 11 pages, 21 figures, Updated version of this work with more experimental results will be published in other relevant journals\n",
    "authors": [
      "Md Jubayer Shawon",
      "Vishal Saxena"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.02737"
  },
  {
    "id": "arXiv:2110.02738",
    "title": "Blind Coherent Preamble Detection via Neural Networks",
    "abstract": "In wireless communications systems, the user equipment (UE) transmits a\nrandom access preamble sequence to the base station (BS) to be detected and\nsynchronized. In standardized cellular communications systems Zadoff-Chu\nsequences has been proposed due to their constant amplitude zero\nautocorrelation (CAZAC) properties. The conventional approach is to use matched\nfilters to detect the sequence. Sequences arrived from different antennas and\ntime instances are summed up to reduce the noise variance. Since the knowledge\nof the channel is unknown at this stage, a coherent combining scheme would be\nvery difficult to implement.\nIn this work, we leverage the system design knowledge and propose a neural\nnetwork (NN) sequence detector and timing advanced estimator. We do not replace\nthe whole process of preamble detection by a NN. Instead, we propose to use NN\nonly for \\textit{blind} coherent combining of the signals in the detector to\ncompensate for the channel effect, thus maximize the signal to noise ratio. We\nhave further reduced the problem's complexity using Kronecker approximation\nmodel for channel covariance matrices, thereby, reducing the size of required\nNN. The analysis on timing advanced estimation and sequences detection has been\nperformed and compared with the matched filter baseline.",
    "descriptor": "\nComments: 6 pages, 5 figures, conference\n",
    "authors": [
      "Jafar Mohammadi",
      "Gerhard Schreiber",
      "Thorsten Wild",
      "Yejian Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02738"
  },
  {
    "id": "arXiv:2110.02739",
    "title": "A Step Towards Efficient Evaluation of Complex Perception Tasks in  Simulation",
    "abstract": "There has been increasing interest in characterising the error behaviour of\nsystems which contain deep learning models before deploying them into any\nsafety-critical scenario. However, characterising such behaviour usually\nrequires large-scale testing of the model that can be extremely computationally\nexpensive for complex real-world tasks. For example, tasks involving compute\nintensive object detectors as one of their components. In this work, we propose\nan approach that enables efficient large-scale testing using simplified\nlow-fidelity simulators and without the computational cost of executing\nexpensive deep learning models. Our approach relies on designing an efficient\nsurrogate model corresponding to the compute intensive components of the task\nunder test. We demonstrate the efficacy of our methodology by evaluating the\nperformance of an autonomous driving task in the Carla simulator with reduced\ncomputational expense by training efficient surrogate models for PIXOR and\nCenterPoint LiDAR detectors, whilst demonstrating that the accuracy of the\nsimulation is maintained.",
    "descriptor": "",
    "authors": [
      "Jonathan Sadeghi",
      "Blaine Rogers",
      "James Gunn",
      "Thomas Saunders",
      "Sina Samangooei",
      "Puneet Kumar Dokania",
      "John Redford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02739"
  },
  {
    "id": "arXiv:2110.02740",
    "title": "Cluster Analysis on Jester Dataset: A Review",
    "abstract": "Unsupervised Machine Learning Paradigms are often the only methodology to\nrely on, given a Pattern Recognition Task with no target label or annotations\nbeing present. In such scenarios, data preparation is a crucial step to be\nperformed so that the Unsupervised Paradigms work with as much perfection as\npossible. But, when there is no sufficient or missing data being present in\neach and every instance of a dataset, data preparation becomes a challenge\nitself. One such case-study is the Jester Dataset that has missing values which\nare basically ratings given by Joke-Readers to a specified set of 100 jokes. In\norder to perform a Cluster Analysis on such a dataset, the data preparation\nstep should involve filling the missing ratings with appropriate values\nfollowed by cluster analysis using an Unsupervised ML Paradigm. In this study,\nthe most recent and probably the only work that involves Cluster Analysis on\nthe Jester Dataset of Jokes is reviewed and validated with corrections and\nfuture scope.",
    "descriptor": "\nComments: Accepted at 2nd International Conference on Communication, Computing & Industry 4.0-2021 (C2I4-2021)\n",
    "authors": [
      "Navoneel Chakrabarty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02740"
  },
  {
    "id": "arXiv:2110.02744",
    "title": "Contrastive Learning for Unsupervised Radar Place Recognition",
    "abstract": "We learn, in an unsupervised way, an embedding from sequences of radar images\nthat is suitable for solving the place recognition problem with complex radar\ndata. Our method is based on invariant instance feature learning but is\ntailored for the task of re-localisation by exploiting for data augmentation\nthe temporal successivity of data as collected by a mobile platform moving\nthrough the scene smoothly. We experiment across two prominent urban radar\ndatasets totalling over 400 km of driving and show that we achieve a new radar\nplace recognition state-of-the-art. Specifically, the proposed system proves\ncorrect for 98.38% of the queries that it is presented with over a challenging\nre-localisation sequence, using only the single nearest neighbour in the\nlearned metric space. We also find that our learned model shows better\nunderstanding of out-of-lane loop closures at arbitrary orientation than\nnon-learned radar scan descriptors.",
    "descriptor": "\nComments: accepted for publication at the IEEE International Conference on Advanced Robotics (ICAR) 2021. arXiv admin note: substantial text overlap with arXiv:2106.06703\n",
    "authors": [
      "Matthew Gadd",
      "Daniele De Martini",
      "Paul Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02744"
  },
  {
    "id": "arXiv:2110.02747",
    "title": "On the Application of Uplink/Downlink Decoupled Access in Heterogeneous  Mobile Edge Computing",
    "abstract": "Mobile edge computing (MEC) is a key player in low latency 5G networks with\nthe task to resolve the conflict between computationally-intensive mobile\napplications and resource-limited mobile devices (MDs). As such, there has been\nintense interest in this topic, especially in multi-user single-server and\nhomogeneous multi-server scenarios. However, the research in the heterogeneous\nmulti-server scenario is limited, where the servers are located at small\nbase-stations (SBSs), macro base-stations (MBSs), or the cloud with different\ncomputing and communication capabilities. On the other hand,\ncomputational-tasks offloading is limited by the type of MD-BS association with\nalmost all previous works focusing on offloading the MD's computational tasks\nto the MEC servers/cloudlets at its serving BS. However, in multi-BS\nassociation, or downlink/uplink decoupled (DUDe) scenarios, an MD can be served\nby multiple BSs and hence has multiple offloading choices. Motivated by this,\nwe proposed a joint BS association and subchannel allocation algorithm based on\na student-project allocation (SPA) matching approach to minimize the network\nsum-latency, which break the constraint that one MD must connect to the same BS\nin the UL and DL, and jointly consider the communication and computational\ndisparity of SBS and MBS cloudlets in heterogeneous MEC networks. Moreover, an\noptimal power allocation scheme is proposed to optimize the system performance\nsubject to the predefined quality of service constraints. Our results show that\nthe proposed scheme is superior to benchmark techniques in enabling effective\nuse of the computational and communication resources in heterogeneous MEC\nnetworks.",
    "descriptor": "",
    "authors": [
      "Yao Shi",
      "Emad Alsusa",
      "Mohammed W. Baidas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02747"
  },
  {
    "id": "arXiv:2110.02750",
    "title": "Extensions of Karger's Algorithm: Why They Fail in Theory and How They  Are Useful in Practice",
    "abstract": "The minimum graph cut and minimum $s$-$t$-cut problems are important\nprimitives in the modeling of combinatorial problems in computer science,\nincluding in computer vision and machine learning. Some of the most efficient\nalgorithms for finding global minimum cuts are randomized algorithms based on\nKarger's groundbreaking contraction algorithm. Here, we study whether Karger's\nalgorithm can be successfully generalized to other cut problems. We first prove\nthat a wide class of natural generalizations of Karger's algorithm cannot\nefficiently solve the $s$-$t$-mincut or the normalized cut problem to\noptimality. However, we then present a simple new algorithm for seeded\nsegmentation / graph-based semi-supervised learning that is closely based on\nKarger's original algorithm, showing that for these problems, extensions of\nKarger's algorithm can be useful. The new algorithm has linear asymptotic\nruntime and yields a potential that can be interpreted as the posterior\nprobability of a sample belonging to a given seed / class. We clarify its\nrelation to the random walker algorithm / harmonic energy minimization in terms\nof distributions over spanning forests. On classical problems from seeded image\nsegmentation and graph-based semi-supervised learning on image data, the method\nperforms at least as well as the random walker / harmonic energy minimization /\nGaussian processes.",
    "descriptor": "\nComments: Oral at ICCV 2021\n",
    "authors": [
      "Erik Jenner",
      "Enrique Fita Sanmart\u00edn",
      "Fred A. Hamprecht"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02750"
  },
  {
    "id": "arXiv:2110.02753",
    "title": "Semi-relaxed Gromov Wasserstein divergence with applications on graphs",
    "abstract": "Comparing structured objects such as graphs is a fundamental operation\ninvolved in many learning tasks. To this end, the Gromov-Wasserstein (GW)\ndistance, based on Optimal Transport (OT), has proven to be successful in\nhandling the specific nature of the associated objects. More specifically,\nthrough the nodes connectivity relations, GW operates on graphs, seen as\nprobability measures over specific spaces. At the core of OT is the idea of\nconservation of mass, which imposes a coupling between all the nodes from the\ntwo considered graphs. We argue in this paper that this property can be\ndetrimental for tasks such as graph dictionary or partition learning, and we\nrelax it by proposing a new semi-relaxed Gromov-Wasserstein divergence. Aside\nfrom immediate computational benefits, we discuss its properties, and show that\nit can lead to an efficient graph dictionary learning algorithm. We empirically\ndemonstrate its relevance for complex tasks on graphs such as partitioning,\nclustering and completion.",
    "descriptor": "\nComments: preprint under review\n",
    "authors": [
      "C\u00e9dric Vincent-Cuaz",
      "R\u00e9mi Flamary",
      "Marco Corneli",
      "Titouan Vayer",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02753"
  },
  {
    "id": "arXiv:2110.02754",
    "title": "Donoho Starks and Hardys Uncertainty Principles for the Shortotime  Quaternion Offset Linear Canonical Transform Donoho-Stark's and Hardy's  Uncertainty Principles for the Short-time Quaternion Offset Linear Canonical  Transform",
    "abstract": "The quaternion offset linear canonical transform (QOLCT) which is time\nshifted and frequency modulated version of the quaternion linear canonical\ntransform (QLCT) provides a more general framework of most existing signal\nprocessing tools. For the generalized QOLCT, the classical Heisenbergs and\nLiebs uncertainty principles have been studied recently. In this paper, we\nfirst define the shorttime quaternion offset linear canonical transform\n(STQOLCT) and drive its relationship with the quaternion Fourier transform\n(QFT). The crux of the paper lies in the generalization of several well known\nuncertainty principles for the STQOLCT, including Donoho Starks uncertainty\nprinciple, Hardys uncertainty principle, Beurlings uncertainty principle, and\nLogarithmic uncertainty principle.",
    "descriptor": "",
    "authors": [
      "Mohammad Younus Bhat",
      "Aamir Hamid Dar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2110.02754"
  },
  {
    "id": "arXiv:2110.02758",
    "title": "Mismatched No More: Joint Model-Policy Optimization for Model-Based RL",
    "abstract": "Many model-based reinforcement learning (RL) methods follow a similar\ntemplate: fit a model to previously observed data, and then use data from that\nmodel for RL or planning. However, models that achieve better training\nperformance (e.g., lower MSE) are not necessarily better for control: an RL\nagent may seek out the small fraction of states where an accurate model makes\nmistakes, or it might act in ways that do not expose the errors of an\ninaccurate model. As noted in prior work, there is an objective mismatch:\nmodels are useful if they yield good policies, but they are trained to maximize\ntheir accuracy, rather than the performance of the policies that result from\nthem. In this work, we propose a single objective for jointly training the\nmodel and the policy, such that updates to either component increases a lower\nbound on expected return. This joint optimization mends the objective mismatch\nin prior work. Our objective is a global lower bound on expected return, and\nthis bound becomes tight under certain assumptions. The resulting algorithm\n(MnM) is conceptually similar to a GAN: a classifier distinguishes between real\nand fake transitions, the model is updated to produce transitions that look\nrealistic, and the policy is updated to avoid states where the model\npredictions are unrealistic.",
    "descriptor": "",
    "authors": [
      "Benjamin Eysenbach",
      "Alexander Khazatsky",
      "Sergey Levine",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02758"
  },
  {
    "id": "arXiv:2110.02768",
    "title": "Posture Recognition in the Critical Care Settings using Wearable Devices",
    "abstract": "Low physical activity levels in the intensive care units (ICU) patients have\nbeen linked to adverse clinical outcomes. Therefore, there is a need for\ncontinuous and objective measurement of physical activity in the ICU to\nquantify the association between physical activity and patient outcomes. This\nmeasurement would also help clinicians evaluate the efficacy of proposed\nrehabilitation and physical therapy regimens in improving physical activity. In\nthis study, we examined the feasibility of posture recognition in an ICU\npopulation using data from wearable sensors.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Anis Davoudi",
      "Patrick J. Tighe",
      "Azra Bihorac",
      "Parisa Rashidi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.02768"
  },
  {
    "id": "arXiv:2110.02769",
    "title": "Visibility Reasoning for Concurrent Snapshot Algorithms",
    "abstract": "Visibility relations have been proposed by Henzinger et al. as an abstraction\nfor proving linearizability of concurrent algorithms that obtains modular and\nreusable proofs. This is in contrast to the customary approach based on\nexhibiting the algorithm's linearization points. In this paper we apply\nvisibility relations to develop modular proofs for three elegant concurrent\nsnapshot algorithms of Jayanti. The proofs are divided into components of\nincreasing level of abstraction, using type-theoretic notions of signatures and\nfunctors (i.e., dependent $\\Sigma$ and $\\Pi$ types) as interfaces. The proofs\nare modular because the components at higher abstraction levels are shared,\ni.e., they apply to all three algorithms simultaneously. Importantly, the\ninterface properties mathematically capture Jayanti's original intuitions that\nhave previously been given only informally.",
    "descriptor": "\nComments: 39 pages, 12 figures\n",
    "authors": [
      "Joakim \u00d6hman",
      "Aleksandar Nanevski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.02769"
  },
  {
    "id": "arXiv:2110.02771",
    "title": "DNN-assisted Particle-based Bayesian Joint Synchronization and  Localization",
    "abstract": "In this work, we propose a Deep neural network-assisted Particle Filter-based\n(DePF) approach to address the Mobile User (MU) joint synchronization and\nlocalization (sync\\&loc) problem in ultra dense networks. In particular, DePF\ndeploys an asymmetric time-stamp exchange mechanism between the MUs and the\nAccess Points (APs), which, traditionally, provides us with information about\nthe MUs' clock offset and skew. However, information about the distance between\nan AP and an MU is also intrinsic to the propagation delay experienced by\nexchanged time-stamps. In addition, to estimate the angle of arrival of the\nreceived synchronization packet, DePF draws on the multiple signal\nclassification algorithm that is fed by Channel Impulse Response (CIR)\nexperienced by the sync packets. The CIR is also leveraged on to determine the\nlink condition, i.e. Line-of-Sight (LoS) or Non-LoS. Finally, to perform joint\nsync\\&loc, DePF capitalizes on particle Gaussian mixtures that allow for a\nhybrid particle-based and parametric Bayesian Recursive Filtering (BRF) fusion\nof the aforementioned pieces of information and thus jointly estimate the\nposition and clock parameters of the MUs. The simulation results verifies the\nsuperiority of the proposed algorithm over the state-of-the-art schemes,\nespecially that of Extended Kalman filter- and linearized BRF-based joint\nsync\\&loc. In particular, only drawing on the synchronization time-stamp\nexchange and CIRs, for 90$\\%$of the cases, the absolute position and clock\noffset estimation error remain below 1 meter and 2 nanoseconds, respectively.",
    "descriptor": "",
    "authors": [
      "Meysam Goodarzi",
      "Vladica Sark",
      "Nebojsa Maletic",
      "Jes\u00fas Guti\u00e9rrez",
      "Giuseppe Caire",
      "Eckhard Grass"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02771"
  },
  {
    "id": "arXiv:2110.02772",
    "title": "The Challenge of Appearance-Free Object Tracking with Feedforward Neural  Networks",
    "abstract": "Nearly all models for object tracking with artificial neural networks depend\non appearance features extracted from a \"backbone\" architecture, designed for\nobject recognition. Indeed, significant progress on object tracking has been\nspurred by introducing backbones that are better able to discriminate objects\nby their appearance. However, extensive neurophysiology and psychophysics\nevidence suggests that biological visual systems track objects using both\nappearance and motion features. Here, we introduce $\\textit{PathTracker}$, a\nvisual challenge inspired by cognitive psychology, which tests the ability of\nobservers to learn to track objects solely by their motion. We find that\nstandard 3D-convolutional deep network models struggle to solve this task when\nclutter is introduced into the generated scenes, or when objects travel long\ndistances. This challenge reveals that tracing the path of object motion is a\nblind spot of feedforward neural networks. We expect that strategies for\nappearance-free object tracking from biological vision can inspire solutions\nthese failures of deep neural networks.",
    "descriptor": "\nComments: Accepted at CVPR Workshop on Dynamic Neural Networks Meet Computer Vision\n",
    "authors": [
      "Girik Malik",
      "Drew Linsley",
      "Thomas Serre",
      "Ennio Mingolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.02772"
  },
  {
    "id": "arXiv:2110.02775",
    "title": "NEWRON: A New Generalization of the Artificial Neuron to Enhance the  Interpretability of Neural Networks",
    "abstract": "In this work, we formulate NEWRON: a generalization of the McCulloch-Pitts\nneuron structure. This new framework aims to explore additional desirable\nproperties of artificial neurons. We show that some specializations of NEWRON\nallow the network to be interpretable with no change in their expressiveness.\nBy just inspecting the models produced by our NEWRON-based networks, we can\nunderstand the rules governing the task. Extensive experiments show that the\nquality of the generated models is better than traditional interpretable models\nand in line or better than standard neural networks.",
    "descriptor": "",
    "authors": [
      "Federico Siciliano",
      "Maria Sofia Bucarelli",
      "Gabriele Tolomei",
      "Fabrizio Silvestri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02775"
  },
  {
    "id": "arXiv:2110.02776",
    "title": "SIRe-Networks: Skip Connections over Interlaced Multi-Task Learning and  Residual Connections for Structure Preserving Object Classification",
    "abstract": "Improving existing neural network architectures can involve several design\nchoices such as manipulating the loss functions, employing a diverse learning\nstrategy, exploiting gradient evolution at training time, optimizing the\nnetwork hyper-parameters, or increasing the architecture depth. The latter\napproach is a straightforward solution, since it directly enhances the\nrepresentation capabilities of a network; however, the increased depth\ngenerally incurs in the well-known vanishing gradient problem. In this paper,\nborrowing from different methods addressing this issue, we introduce an\ninterlaced multi-task learning strategy, defined SIRe, to reduce the vanishing\ngradient in relation to the object classification task. The presented\nmethodology directly improves a convolutional neural network (CNN) by enforcing\nthe input image structure preservation through interlaced auto-encoders, and\nfurther refines the base network architecture by means of skip and residual\nconnections. To validate the presented methodology, a simple CNN and various\nimplementations of famous networks are extended via the SIRe strategy and\nextensively tested on the CIFAR100 dataset; where the SIRe-extended\narchitectures achieve significantly increased performances across all models,\nthus confirming the presented approach effectiveness.",
    "descriptor": "",
    "authors": [
      "Danilo Avola",
      "Luigi Cinque",
      "Alessio Fagioli",
      "Gian Luca Foresti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02776"
  },
  {
    "id": "arXiv:2110.02781",
    "title": "FTPipeHD: A Fault-Tolerant Pipeline-Parallel Distributed Training  Framework for Heterogeneous Edge Devices",
    "abstract": "With the increased penetration and proliferation of Internet of Things (IoT)\ndevices, there is a growing trend towards distributing the power of deep\nlearning (DL) across edge devices rather than centralizing it in the cloud.\nThis development enables better privacy preservation, real-time responses, and\nuser-specific models. To deploy deep and complex models to edge devices with\nlimited resources, model partitioning of deep neural networks (DNN) model is\nnecessary, and has been widely studied. However, most of the existing\nliterature only considers distributing the inference model while still relying\ncentralized cloud infrastructure to generate this model through training. In\nthis paper, we propose FTPipeHD, a novel DNN training framework that trains DNN\nmodels across distributed heterogeneous devices with fault tolerance mechanism.\nTo accelerate the training with time-varying computing power of each device, we\noptimize the partition points dynamically according to real-time computing\ncapacities. We also propose a novel weight redistribution approach that\nreplicates the weights to both the neighboring nodes and the central node\nperiodically, which combats the failure of multiple devices during training\nwhile incurring limited communication cost. Our numerical results demonstrate\nthat FTPipeHD is 6.8x faster in training than the state of the art method when\nthe computing capacity of the best device is 10x greater than the worst one. It\nis also shown that the proposed method is able to accelerate the training even\nwith the existence of device failures.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Yuhao Chen",
      "Qianqian Yang",
      "Shibo He",
      "Zhiguo Shi",
      "Jiming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.02781"
  },
  {
    "id": "arXiv:2110.02782",
    "title": "How BPE Affects Memorization in Transformers",
    "abstract": "Training data memorization in NLP can both be beneficial (e.g., closed-book\nQA) and undesirable (personal data extraction). In any case, successful model\ntraining requires a non-trivial amount of memorization to store word spellings,\nvarious linguistic idiosyncrasies and common knowledge. However, little is\nknown about what affects the memorization behavior of NLP models, as the field\ntends to focus on the equally important question of generalization. In this\nwork, we demonstrate that the size of the subword vocabulary learned by\nByte-Pair Encoding (BPE) greatly affects both ability and tendency of standard\nTransformer models to memorize training data, even when we control for the\nnumber of learned parameters. We find that with a large subword vocabulary\nsize, Transformer models fit random mappings more easily and are more\nvulnerable to membership inference attacks. Similarly, given a prompt,\nTransformer-based language models with large subword vocabularies reproduce the\ntraining data more often. We conjecture this effect is caused by reduction in\nthe sequences' length that happens as the BPE vocabulary grows. Our findings\ncan allow a more informed choice of hyper-parameters, that is better tailored\nfor a particular use-case.",
    "descriptor": "",
    "authors": [
      "Eugene Kharitonov",
      "Marco Baroni",
      "Dieuwke Hupkes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02782"
  },
  {
    "id": "arXiv:2110.02783",
    "title": "Active Learning for Sound Negotiations",
    "abstract": "We present two active learning algorithms for sound deterministic\nnegotiations. Sound deterministic negotiations are models of distributed\nsystems, a kind of Petri nets or Zielonka automata with additional structure.\nWe show that this additional structure allows to minimize such negotiations.\nThe two active learning algorithms differ in the type of membership queries\nthey use. Both have similar complexity to Angluin's L* algorithm, in\nparticular, the number of queries is polynomial in the size of the negotiation,\nand not in the number of configurations.",
    "descriptor": "",
    "authors": [
      "Anca Muscholl",
      "Igor Walukiewicz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.02783"
  },
  {
    "id": "arXiv:2110.02784",
    "title": "Cooperative Multi-Agent Actor-Critic for Privacy-Preserving Load  Scheduling in a Residential Microgrid",
    "abstract": "As a scalable data-driven approach, multi-agent reinforcement learning (MARL)\nhas made remarkable advances in solving the cooperative residential load\nscheduling problems. However, the common centralized training strategy of MARL\nalgorithms raises privacy risks for involved households. In this work, we\npropose a privacy-preserving multi-agent actor-critic framework where the\ndecentralized actors are trained with distributed critics, such that both the\ndecentralized execution and the distributed training do not require the global\nstate information. The proposed framework can preserve the privacy of the\nhouseholds while simultaneously learn the multi-agent credit assignment\nmechanism implicitly. The simulation experiments demonstrate that the proposed\nframework significantly outperforms the existing privacy-preserving\nactor-critic framework, and can achieve comparable performance to the\nstate-of-the-art actor-critic framework without privacy constraints.",
    "descriptor": "",
    "authors": [
      "Zhaoming Qin",
      "Nanqing Dong",
      "Eric P. Xing",
      "Junwei Cao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02784"
  },
  {
    "id": "arXiv:2110.02788",
    "title": "The Impact of Blocking Cars on Pathloss Within a Platoon: Measurements  for 26 GHz Band",
    "abstract": "Platooning is considered to be one of the possible prospective\nimplementations of the autonomous driving concept, where the train-of-cars\nmoves together following the platoon leader's commands. However, the practical\nrealization of this scheme assumes the use of reliable communications between\nplatoon members. In this paper, the results of the measurement experiment have\nbeen presented showing the impact of the blocking cars on the signal\nattenuation. The tests have been carried out for the high-frequency band, i.e.\nfor 26.555 GHz. It has been observed that on one hand side, the attenuation can\nreach even tens of dB for 2 or 3 blocking cars, but in some locations, the\nimpact of a two-ray propagation mitigates the presence of obstructing vehicles.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Kryszkiewicz",
      "Adrian Kliks",
      "Pawe\u0142 Sroka",
      "Micha\u0142 Sybis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02788"
  },
  {
    "id": "arXiv:2110.02791",
    "title": "Spell my name: keyword boosted speech recognition",
    "abstract": "Recognition of uncommon words such as names and technical terminology is\nimportant to understanding conversations in context. However, the ability to\nrecognise such words remains a challenge in modern automatic speech recognition\n(ASR) systems.\nIn this paper, we propose a simple but powerful ASR decoding method that can\nbetter recognise these uncommon keywords, which in turn enables better\nreadability of the results. The method boosts the probabilities of given\nkeywords in a beam search based on acoustic model predictions. The method does\nnot require any training in advance.\nWe demonstrate the effectiveness of our method on the LibriSpeeech test sets\nand also internal data of real-world conversations. Our method significantly\nboosts keyword accuracy on the test sets, while maintaining the accuracy of the\nother words, and as well as providing significant qualitative improvements.\nThis method is applicable to other tasks such as machine translation, or\nwherever unseen and difficult keywords need to be recognised in beam search.",
    "descriptor": "",
    "authors": [
      "Namkyu Jung",
      "Geonmin Kim",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02791"
  },
  {
    "id": "arXiv:2110.02792",
    "title": "From STL Rulebooks to Rewards",
    "abstract": "The automatic synthesis of neural-network controllers for autonomous agents\nthrough reinforcement learning has to simultaneously optimize many, possibly\nconflicting, objectives of various importance. This multi-objective\noptimization task is reflected in the shape of the reward function, which is\nmost often the result of an ad-hoc and crafty-like activity.\nIn this paper we propose a principled approach to shaping rewards for\nreinforcement learning from multiple objectives that are given as a\npartially-ordered set of signal-temporal-logic (STL) rules. To this end, we\nfirst equip STL with a novel quantitative semantics allowing to automatically\nevaluate individual requirements. We then develop a method for systematically\ncombining evaluations of multiple requirements into a single reward that takes\ninto account the priorities defined by the partial order. We finally evaluate\nour approach on several case studies, demonstrating its practical\napplicability.",
    "descriptor": "\nComments: 7 pages main, 4 pages appendix\n",
    "authors": [
      "Edgar A. Aguilar",
      "Luigi Berducci",
      "Axel Brunnbauer",
      "Radu Grosu",
      "Dejan Ni\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02792"
  },
  {
    "id": "arXiv:2110.02793",
    "title": "Multi-Agent Constrained Policy Optimisation",
    "abstract": "Developing reinforcement learning algorithms that satisfy safety constraints\nis becoming increasingly important in real-world applications. In multi-agent\nreinforcement learning (MARL) settings, policy optimisation with safety\nawareness is particularly challenging because each individual agent has to not\nonly meet its own safety constraints, but also consider those of others so that\ntheir joint behaviour can be guaranteed safe. Despite its importance, the\nproblem of safe multi-agent learning has not been rigorously studied; very few\nsolutions have been proposed, nor a sharable testing environment or benchmarks.\nTo fill these gaps, in this work, we formulate the safe MARL problem as a\nconstrained Markov game and solve it with policy optimisation methods. Our\nsolutions -- Multi-Agent Constrained Policy Optimisation (MACPO) and\nMAPPO-Lagrangian -- leverage the theories from both constrained policy\noptimisation and multi-agent trust region learning. Crucially, our methods\nenjoy theoretical guarantees of both monotonic improvement in reward and\nsatisfaction of safety constraints at every iteration. To examine the\neffectiveness of our methods, we develop the benchmark suite of Safe\nMulti-Agent MuJoCo that involves a variety of MARL baselines. Experimental\nresults justify that MACPO/MAPPO-Lagrangian can consistently satisfy safety\nconstraints, meanwhile achieving comparable performance to strong baselines.",
    "descriptor": "",
    "authors": [
      "Shangding Gu",
      "Jakub Grudzien Kuba",
      "Munning Wen",
      "Ruiqing Chen",
      "Ziyan Wang",
      "Zheng Tian",
      "Jun Wang",
      "Alois Knoll",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.02793"
  },
  {
    "id": "arXiv:2110.02794",
    "title": "3rd Place Solution to Google Landmark Recognition Competition 2021",
    "abstract": "In this paper, we show our solution to the Google Landmark Recognition 2021\nCompetition. Firstly, embeddings of images are extracted via various\narchitectures (i.e. CNN-, Transformer- and hybrid-based), which are optimized\nby ArcFace loss. Then we apply an efficient pipeline to re-rank predictions by\nadjusting the retrieval score with classification logits and non-landmark\ndistractors. Finally, the ensembled model scores 0.489 on the private\nleaderboard, achieving the 3rd place in the 2021 edition of the Google Landmark\nRecognition Competition.",
    "descriptor": "",
    "authors": [
      "Cheng Xu",
      "Weimin Wang",
      "Shuai Liu",
      "Yong Wang",
      "Yuxiang Tang",
      "Tianling Bian",
      "Yanyu Yan",
      "Qi She",
      "Cheng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02794"
  },
  {
    "id": "arXiv:2110.02796",
    "title": "An Unconstrained Layer-Peeled Perspective on Neural Collapse",
    "abstract": "Neural collapse is a highly symmetric geometric pattern of neural networks\nthat emerges during the terminal phase of training, with profound implications\non the generalization performance and robustness of the trained networks. To\nunderstand how the last-layer features and classifiers exhibit this recently\ndiscovered implicit bias, in this paper, we introduce a surrogate model called\nthe unconstrained layer-peeled model (ULPM). We prove that gradient flow on\nthis model converges to critical points of a minimum-norm separation problem\nexhibiting neural collapse in its global minimizer. Moreover, we show that the\nULPM with the cross-entropy loss has a benign global landscape for its loss\nfunction, which allows us to prove that all the critical points are strict\nsaddle points except the global minimizers that exhibit the neural collapse\nphenomenon. Empirically, we show that our results also hold during the training\nof neural networks in real-world tasks when explicit regularization or weight\ndecay is not used.",
    "descriptor": "",
    "authors": [
      "Wenlong Ji",
      "Yiping Lu",
      "Yiliang Zhang",
      "Zhun Deng",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02796"
  },
  {
    "id": "arXiv:2110.02797",
    "title": "Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to  CNNs",
    "abstract": "Convolutional Neural Networks (CNNs) have become the de facto gold standard\nin computer vision applications in the past years. Recently, however, new model\narchitectures have been proposed challenging the status quo. The Vision\nTransformer (ViT) relies solely on attention modules, while the MLP-Mixer\narchitecture substitutes the self-attention modules with Multi-Layer\nPerceptrons (MLPs). Despite their great success, CNNs have been widely known to\nbe vulnerable to adversarial attacks, causing serious concerns for\nsecurity-sensitive applications. Thus, it is critical for the community to know\nwhether the newly proposed ViT and MLP-Mixer are also vulnerable to adversarial\nattacks. To this end, we empirically evaluate their adversarial robustness\nunder several adversarial attack setups and benchmark them against the widely\nused CNNs. Overall, we find that the two architectures, especially ViT, are\nmore robust than their CNN models. Using a toy example, we also provide\nempirical evidence that the lower adversarial robustness of CNNs can be\npartially attributed to their shift-invariant property. Our frequency analysis\nsuggests that the most robust ViT architectures tend to rely more on\nlow-frequency features compared with CNNs. Additionally, we have an intriguing\nfinding that MLP-Mixer is extremely vulnerable to universal adversarial\nperturbations.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Philipp Benz",
      "Soomin Ham",
      "Chaoning Zhang",
      "Adil Karjauv",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02797"
  },
  {
    "id": "arXiv:2110.02799",
    "title": "Real-time Optimal Landing Control of the MIT Mini Cheetah",
    "abstract": "Quadrupedal landing is a complex process involving large impacts, elaborate\ncontact transitions, and is a crucial recovery behavior observed in many\nbiological animals. This work presents a real-time, optimal landing controller\nthat is free of pre-specified contact schedules. The controller determines\noptimal touchdown postures and reaction force profiles and is able to recover\nfrom a variety of falling configurations. The quadrupedal platform used, the\nMIT Mini Cheetah, recovered safely from drops of up to 8 m in simulation, as\nwell as from a range of orientations and planar velocities. The controller is\nalso tested on hardware, successfully recovering from drops of up to 2 m.",
    "descriptor": "\nComments: ICRA 2022 conference submission\n",
    "authors": [
      "Se Hwan Jeon",
      "Sangbae Kim",
      "Donghyun Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02799"
  },
  {
    "id": "arXiv:2110.02802",
    "title": "Self-conditioning pre-trained language models",
    "abstract": "We study the presence of expert units in pre-trained Transformer-based\nLanguage Models (TLMs), and how they can be used to condition text generation\nto contain specific concepts. We define expert units to be neurons that are\nable to detect a concept in the input with a given average precision. A concept\nis represented with a set of sentences that either do or do not contain the\nconcept. Leveraging the OneSec dataset, we compile a dataset of 1344 concepts\nthat allows diverse expert units in TLMs to be discovered. Our experiments\ndemonstrate that off-the-shelf pre-trained TLMs can be conditioned on their own\nknowledge (self-conditioning) to generate text that contains a given concept.\nTo this end, we intervene on the top expert units by fixing their output during\ninference, and we show experimentally that this is an effective method to\ncondition TLMs. Our method does not require fine-tuning the model or using\nadditional parameters, which allows conditioning large TLM with minimal compute\nresources. Furthermore, by intervening on a small number of experts in GPT2, we\ncan achieve parity with respect to two concepts at generation time. The\nspecific case of gender bias is explored, and we show that, for given contexts,\ngender parity is achieved while maintaining the model's perplexity.",
    "descriptor": "\nComments: 8 pages and supplementary material\n",
    "authors": [
      "Xavier Suau",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02802"
  },
  {
    "id": "arXiv:2110.02807",
    "title": "Fitting Distances by Tree Metrics Minimizing the Total Error within a  Constant Factor",
    "abstract": "We consider the numerical taxonomy problem of fitting a positive distance\nfunction ${D:{S\\choose 2}\\rightarrow \\mathbb R_{>0}}$ by a tree metric. We want\na tree $T$ with positive edge weights and including $S$ among the vertices so\nthat their distances in $T$ match those in $D$. A nice application is in\nevolutionary biology where the tree $T$ aims to approximate the branching\nprocess leading to the observed distances in $D$ [Cavalli-Sforza and Edwards\n1967]. We consider the total error, that is the sum of distance errors over all\npairs of points. We present a deterministic polynomial time algorithm\nminimizing the total error within a constant factor. We can do this both for\ngeneral trees, and for the special case of ultrametrics with a root having the\nsame distance to all vertices in $S$.\nThe problems are APX-hard, so a constant factor is the best we can hope for\nin polynomial time. The best previous approximation factor was $O((\\log n)(\\log\n\\log n))$ by Ailon and Charikar [2005] who wrote \"Determining whether an $O(1)$\napproximation can be obtained is a fascinating question\".",
    "descriptor": "\nComments: Accepted to FOCS 2021\n",
    "authors": [
      "Vincent Cohen-Addad",
      "Debarati Das",
      "Evangelos Kipouridis",
      "Nikos Parotsidis",
      "Mikkel Thorup"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02807"
  },
  {
    "id": "arXiv:2110.02809",
    "title": "Partial order alignment by adjacencies and breakpoints",
    "abstract": "Linearizing two partial orders to maximize the number of adjacencies and\nminimize the number of breakpoints is APX-hard. This holds even if one of the\ntwo partial orders is already a linear order and the other is an interval\norder, or if both partial orders are weak orders.",
    "descriptor": "",
    "authors": [
      "Rain Jiang",
      "Kai Jiang",
      "Minghui Jiang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.02809"
  },
  {
    "id": "arXiv:2110.02813",
    "title": "Accelerated First Order Methods for Variational Imaging",
    "abstract": "In this thesis, we offer a thorough investigation of different regularisation\nterms used in variational imaging problems, together with detailed optimisation\nprocesses of these problems. We begin by studying smooth problems and partially\nnon-smooth problems in the form of Tikhonov denoising and Total Variation (TV)\ndenoising, respectively.\nFor Tikhonov denoising, we study an accelerated gradient method with adaptive\nrestart, which shows a very rapid convergence rate. However, it is not\nstraightforward to apply this fast algorithm to TV denoising, due to the\nnon-smoothness of its built-in regularisation. To tackle this issue, we propose\nto utilise duality to convert such a non-smooth problem into a smooth one so\nthat the accelerated gradient method with restart applies naturally.\nHowever, we notice that both Tikhonov and TV regularisations have drawbacks,\nin the form of blurred image edges and staircase artefacts, respectively. To\novercome these drawbacks, we propose a novel adaption to Total Generalised\nVariation (TGV) regularisation called Total Smooth Variation (TSV), which\nretains edges and meanwhile does not produce results which contain staircase\nartefacts. To optimise TSV effectively, we then propose the Accelerated\nProximal Gradient Algorithm (APGA) which also utilises adaptive restart\ntechniques. Compared to existing state-of-the-art regularisations (e.g. TV),\nTSV is shown to obtain more effective results on denoising problems as well as\nadvanced imaging applications such as magnetic resonance imaging (MRI)\nreconstruction and optical flow. TSV removes the staircase artefacts observed\nwhen using TV regularisation, but has the added advantage over TGV that it can\nbe efficiently optimised using gradient based methods with Nesterov\nacceleration and adaptive restart. Code is available at\nhttps://github.com/Jbartlett6/Accelerated-First-Order-Method-for-Variational-Imaging.",
    "descriptor": "",
    "authors": [
      "Joseph Bartlett",
      "Jinming Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02813"
  },
  {
    "id": "arXiv:2110.02814",
    "title": "Efficient and High-quality Prehensile Rearrangement in Cluttered and  Confined Spaces",
    "abstract": "Prehensile object rearrangement in cluttered and confined spaces has broad\napplications but is also challenging. For instance, rearranging products in a\ngrocery or home shelf means that the robot cannot directly access all objects\nand has limited free space. This is harder than tabletop rearrangement where\nobjects are easily accessible with top-down grasps, which simplifies\nrobot-object interactions. This work focuses on problems where such\ninteractions are critical for completing tasks and extends state-of-the-art\nresults in rearrangement planning. It proposes a new efficient and complete\nsolver under general constraints for monotone instances, which can be solved by\nmoving each object at most once. The monotone solver reasons about robot-object\nconstraints and uses them to effectively prune the search space. The new\nmonotone solver is integrated with a global planner to solve non-monotone\ninstances with high-quality solutions fast. Furthermore, this work contributes\nan effective pre-processing tool to speed up arm motion planning for\nrearrangement in confined spaces. The pre-processing tool provide significant\nspeed-ups (49.1% faster on average) in online query resolution. Comparisons in\nsimulations further demonstrate that the proposed monotone solver, equipped\nwith the pre-processing tool, results in 57.3% faster computation and 3 times\nhigher success rate than alternatives. Similarly, the resulting global planner\nis computationally more efficient and has a higher success rate given the more\npowerful monotone solver and the pre-processing tool, while producing\nhigh-quality solutions for non-monotone instances (i.e., only 1.3 buffers are\nneeded on average). Videos of demonstrating solutions on a real robotic system\nand codes can be found at\nhttps://github.com/Rui1223/uniform_object_rearrangement.",
    "descriptor": "\nComments: ICRA 2022\n",
    "authors": [
      "Rui Wang",
      "Yinglong Miao",
      "Kostas E. Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02814"
  },
  {
    "id": "arXiv:2110.02817",
    "title": "Combined Regularization and Discretization of Equilibrium Problems and  Primal-Dual Gap Estimators",
    "abstract": "The present work aims at the application of finite element discretizations to\na class of equilibrium problems involving moving constraints. Therefore, a\nMoreau--Yosida based regularization technique, controlled by a parameter, is\ndiscussed and, using a generalized $\\Gamma$-convergence concept, a priori\nconvergence results are derived. The latter technique is applied to the\ndiscretization of the regularized problems and is used to prove the convergence\nto the orginal equilibrium problem, when both -- regularization and\ndiscretization -- are imposed simultaneously. In addition, a primal-dual gap\ntechnique is used for the derivation of error estimators suitable for adaptive\nmesh refinement. A strategy for balancing between a refinement of the mesh and\nan update of the regularization parameter is established, too. The theoretical\nfindings are illustrated for the obstacle problem as well as numerical\nexperiments are performed for two quasi-variational inequalities with\napplication to thermoforming and biomedicine, respectively.",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Steven-Marian Stengl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02817"
  },
  {
    "id": "arXiv:2110.02819",
    "title": "Explicit numerical method for highly non-linear time-changed stochastic  differential equations",
    "abstract": "An explicit numerical method is developed for a class of time-changed\nstochastic differential equations, whose the coefficients obey H\\\"older's\ncontinuity in terms of the time variable and are allowed to grow super-linearly\nin terms of the state variable. The strong convergence of the method in a\nfinite time interval is proved and the convergence rate is obtained. Numerical\nsimulations are provided, which are in line with those theoretical results.",
    "descriptor": "\nComments: 29 pages, 2 figures\n",
    "authors": [
      "Xiaotong Li",
      "Wei Liu",
      "Tianjiao Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.02819"
  },
  {
    "id": "arXiv:2110.02820",
    "title": "Randomized Nystr\u00f6m Preconditioning",
    "abstract": "This paper introduces the Nystr\\\"om PCG algorithm for solving a symmetric\npositive-definite linear system. The algorithm applies the randomized Nystr\\\"om\nmethod to form a low-rank approximation of the matrix, which leads to an\nefficient preconditioner that can be deployed with the conjugate gradient\nalgorithm. Theoretical analysis shows that preconditioned system has constant\ncondition number as soon as the rank of the approximation is comparable with\nthe number of effective degrees of freedom in the matrix. The paper also\ndevelops adaptive methods for achieving similar performance without knowledge\nof the effective dimension. Numerical tests show that Nystr\\\"om PCG can rapidly\nsolve large linear systems that arise in data analysis problems, and it\nsurpasses several competing methods from the literature.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Zachary Frangella",
      "Joel A. Tropp",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02820"
  },
  {
    "id": "arXiv:2110.02827",
    "title": "Colmena: Scalable Machine-Learning-Based Steering of Ensemble  Simulations for High Performance Computing",
    "abstract": "Scientific applications that involve simulation ensembles can be accelerated\ngreatly by using experiment design methods to select the best simulations to\nperform. Methods that use machine learning (ML) to create proxy models of\nsimulations show particular promise for guiding ensembles but are challenging\nto deploy because of the need to coordinate dynamic mixes of simulation and\nlearning tasks. We present Colmena, an open-source Python framework that allows\nusers to steer campaigns by providing just the implementations of individual\ntasks plus the logic used to choose which tasks to execute when. Colmena\nhandles task dispatch, results collation, ML model invocation, and ML model\n(re)training, using Parsl to execute tasks on HPC systems. We describe the\ndesign of Colmena and illustrate its capabilities by applying it to electrolyte\ndesign, where it both scales to 65536 CPUs and accelerates the discovery rate\nfor high-performance molecules by a factor of 100 over unguided searches.",
    "descriptor": "\nComments: camera-ready version for ML in HPC Environments 2021\n",
    "authors": [
      "Logan Ward",
      "Ganesh Sivaraman",
      "J. Gregory Pauloski",
      "Yadu Babuji",
      "Ryan Chard",
      "Naveen Dandu",
      "Paul C. Redfern",
      "Rajeev S. Assary",
      "Kyle Chard",
      "Larry A. Curtiss",
      "Rajeev Thakur",
      "Ian Foster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02827"
  },
  {
    "id": "arXiv:2110.02829",
    "title": "Semantic Prediction: Which One Should Come First, Recognition or  Prediction?",
    "abstract": "The ultimate goal of video prediction is not forecasting future pixel-values\ngiven some previous frames. Rather, the end goal of video prediction is to\ndiscover valuable internal representations from the vast amount of available\nunlabeled video data in a self-supervised fashion for downstream tasks. One of\nthe primary downstream tasks is interpreting the scene's semantic composition\nand using it for decision-making. For example, by predicting human movements,\nan observer can anticipate human activities and collaborate in a shared\nworkspace. There are two main ways to achieve the same outcome, given a\npre-trained video prediction and pre-trained semantic extraction model; one can\nfirst apply predictions and then extract semantics or first extract semantics\nand then predict. We investigate these configurations using the Local Frequency\nDomain Transformer Network (LFDTN) as the video prediction model and U-Net as\nthe semantic extraction model on synthetic and real datasets.",
    "descriptor": "",
    "authors": [
      "Hafez Farazi",
      "Jan Nogga",
      "and Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02829"
  },
  {
    "id": "arXiv:2110.02830",
    "title": "Parameterized Algorithms for the Steiner Tree Problem on a Directed  Hypercube",
    "abstract": "We address the problem of computing a Steiner Arborescence on a directed\nhypercube, that enjoys a special connectivity structure among its node set but\nis exponential in $m$ size rendering traditional Steiner tree algorithms\ninefficient. Even though the problem was known to be NP-complete, parameterized\ncomplexity of the problem was unknown. With applications in evolutionary tree\nreconstruction algorithms and incremental algorithms for computing a property\non multiple input graphs, any algorithm for this problem would open up new ways\nto study these applications. In this paper, we present the first algorithms, to\nthe best our knowledge, that prove the problem to be fixed parameter tractable\n(FPT) wrt two natural parameters -- number of input terminals and penalty of\nthe arborescence. These parameters along with the special structure of the\nhypercube offer different trade-offs in terms of running time tractability vs.\napproximation guarantees that are interestingly additive in nature.\nGiven any directed $m$-dimensional hypercube, rooted at the zero node, and a\nset of input terminals $R$ that needs to be spanned by the Steiner\narborescence, we prove that the problem is FPT wrt the penalty parameter $q$,\nby providing a randomized algorithm that computes an optimal arborescence $T$\nin $O\\left(q^44^{q\\left(q+1\\right)}+q\\left|R\\right|m^2\\right)$ with probability\nat least $4^{-q}$. If we trade-off exact solution for an additive approximation\none, then we can design a parameterized approximation algorithm with better\nrunning time - computing an arborescence $T$ with cost at most\n$OPT+(\\left|R\\right|-4)(q_{opt}-1)$ in time\n$O\\left|R\\right|m^2+1.2738^{q_{opt}})$. We also present a dynamic programming\nalgorithm that computes an optimal arborescence in\n$O(3^{\\left|R\\right|}\\left|R\\right|m)$ time, thus proving that the problem is\nFPT on the parameter $\\left|R\\right|$.",
    "descriptor": "",
    "authors": [
      "Sugyani Mahapatra",
      "Manikandan Narayanan",
      "N S Narayanaswamy",
      "Vijayaragunathan Ramamoorthi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02830"
  },
  {
    "id": "arXiv:2110.02833",
    "title": "Shallow Features Guide Unsupervised Domain Adaptation for Semantic  Segmentation at Class Boundaries",
    "abstract": "Although deep neural networks have achieved remarkable results for the task\nof semantic segmentation, they usually fail to generalize towards new domains,\nespecially when performing synthetic-to-real adaptation. Such domain shift is\nparticularly noticeable along class boundaries, invalidating one of the main\ngoals of semantic segmentation that consists in obtaining sharp segmentation\nmasks. In this work, we specifically address this core problem in the context\nof Unsupervised Domain Adaptation and present a novel low-level adaptation\nstrategy that allows us to obtain sharp predictions. Moreover, inspired by\nrecent self-training techniques, we introduce an effective data augmentation\nthat alleviates the noise typically present at semantic boundaries when\nemploying pseudo-labels for self-training. Our contributions can be easily\nintegrated into other popular adaptation frameworks, and extensive experiments\nshow that they effectively improve performance along class boundaries.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Adriano Cardace",
      "Pierluigi Zama Ramirez",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02833"
  },
  {
    "id": "arXiv:2110.02834",
    "title": "Relation Prediction as an Auxiliary Training Objective for Improving  Multi-Relational Graph Representations",
    "abstract": "Learning good representations on multi-relational graphs is essential to\nknowledge base completion (KBC). In this paper, we propose a new\nself-supervised training objective for multi-relational graph representation\nlearning, via simply incorporating relation prediction into the commonly used\n1vsAll objective. The new training objective contains not only terms for\npredicting the subject and object of a given triple, but also a term for\npredicting the relation type. We analyse how this new objective impacts\nmulti-relational learning in KBC: experiments on a variety of datasets and\nmodels show that relation prediction can significantly improve entity ranking,\nthe most widely used evaluation task for KBC, yielding a 6.1% increase in MRR\nand 9.9% increase in Hits@1 on FB15k-237 as well as a 3.1% increase in MRR and\n3.4% in Hits@1 on Aristo-v4. Moreover, we observe that the proposed objective\nis especially effective on highly multi-relational datasets, i.e. datasets with\na large number of predicates, and generates better representations when larger\nembedding sizes are used.",
    "descriptor": "\nComments: AKBC 2021\n",
    "authors": [
      "Yihong Chen",
      "Pasquale Minervini",
      "Sebastian Riedel",
      "Pontus Stenetorp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02834"
  },
  {
    "id": "arXiv:2110.02835",
    "title": "Characterizing the Experience of Subjects in Software Engineering  Studies",
    "abstract": "Context: Empirical studies in software engineering are typically centered on\nhuman subjects, ranging from novice to experienced developers. The experience\nof these individuals is a key context factor that should be properly\ncharacterized for supporting the design of empirical studies and interpreting\ntheir results. However, the criteria adopted for characterizing the experience\nof subjects do not follow a standard and are frequently limited. Goal: Our\nresearch aims at establishing an optimized and comprehensive scheme to\ncharacterize the subjects' experience for studies in software engineering.\nMethod: Based on previous work, we defined the first version of this scheme,\ncomposed of three experience attributes, including time, number of projects,\nand self-perception. In the last years, we applied the characterization scheme\nover four empirical studies, reaching the characterization of 79 subjects in\nthree different skills. Results: We found that the attributes from our scheme\nare positively but moderately correlated. This finding suggests these\nattributes play a complementary role in characterizing the subjects'\nexperience. Besides, we found that study subjects tend to enumerate the\ntechnical diversity of their background when summarizing their professional\nexperience. Conclusion: The scheme proposed represents a feasible alternative\nfor characterizing subjects of empirical studies in the field. However, we\nintend to conduct additional investigations with developers to evolve it.",
    "descriptor": "",
    "authors": [
      "Rafael de Mello",
      "Matheus Coelho"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02835"
  },
  {
    "id": "arXiv:2110.02839",
    "title": "Census-Independent Population Estimation using Representation Learning",
    "abstract": "Knowledge of population distribution is critical for building infrastructure,\ndistributing resources, and monitoring the progress of sustainable development\ngoals. Although censuses can provide this information, they are typically\nconducted every ten years with some countries having forgone the process for\nseveral decades. Population can change in the intercensal period due to rapid\nmigration, development, urbanisation, natural disasters, and conflicts.\nCensus-independent population estimation approaches using alternative data\nsources, such as satellite imagery, have shown promise in providing frequent\nand reliable population estimates locally. Existing approaches, however,\nrequire significant human supervision, for example annotating buildings and\naccessing various public datasets, and therefore, are not easily reproducible.\nWe explore recent representation learning approaches, and assess the\ntransferability of representations to population estimation in Mozambique.\nUsing representation learning reduces required human supervision, since\nfeatures are extracted automatically, making the process of population\nestimation more sustainable and likely to be transferable to other regions or\ncountries. We compare the resulting population estimates to existing population\nproducts from GRID3, Facebook (HRSL) and WorldPop. We observe that our approach\nmatches the most accurate of these maps, and is interpretable in the sense that\nit recognises built-up areas to be an informative indicator of population.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Isaac Neal",
      "Sohan Seth",
      "Gary Watmough",
      "Mamadou S. Diallo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02839"
  },
  {
    "id": "arXiv:2110.02842",
    "title": "WHO-Hand Hygiene Gesture Classification System",
    "abstract": "The recent ongoing coronavirus pandemic highlights the importance of hand\nhygiene practices in our daily lives, with governments and worldwide health\nauthorities promoting good hand hygiene practices. More than one million cases\nof hospital-acquired infections occur in Europe annually. Hand hygiene\ncompliance may reduce the risk of transmission by reducing the number of\ninfections as well as healthcare expenditures. In this paper, the World Health\nOrganization, hand hygiene gestures are recorded and analyzed with the\nconstruction of an aluminum frame, placed at the laboratory sink. The hand\nhygiene gestures are recorded for thirty participants after conducting a\ntraining session about hand hygiene gestures demonstration. The video\nrecordings are converted into image files and are organized into six different\nhand hygiene classes. The Resnet50 framework selection for the classification\nof multiclass hand hygiene stages. The model is trained with the first set of\nclasses; Fingers Interlaced, P2PFingers Interlaced, and Rotational Rub for 25\nepochs. An accuracy of 44 percent for the first set of experiments with a loss\nscore greater than 1.5 in the validation set is achieved. The training steps\nfor the second set of classes; Rub hands palm to palm, Fingers Interlocked,\nThumb Rub are 50 epochs. An accuracy of 72 percent is achieved for the second\nset with a loss score of less than 0.8 for the validation set. In this work, a\npreliminary analysis of a robust hand hygiene dataset with transfer learning\ntakes place. The future aim for deploying a hand hygiene prediction system for\nhealthcare workers in real-time.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.08127\n",
    "authors": [
      "Rashmi Bakshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.02842"
  },
  {
    "id": "arXiv:2110.02843",
    "title": "Improving Generalization of Deep Reinforcement Learning-based TSP  Solvers",
    "abstract": "Recent work applying deep reinforcement learning (DRL) to solve traveling\nsalesman problems (TSP) has shown that DRL-based solvers can be fast and\ncompetitive with TSP heuristics for small instances, but do not generalize well\nto larger instances. In this work, we propose a novel approach named MAGIC that\nincludes a deep learning architecture and a DRL training method. Our\narchitecture, which integrates a multilayer perceptron, a graph neural network,\nand an attention model, defines a stochastic policy that sequentially generates\na TSP solution. Our training method includes several innovations: (1) we\ninterleave DRL policy gradient updates with local search (using a new local\nsearch technique), (2) we use a novel simple baseline, and (3) we apply\ncurriculum learning. Finally, we empirically demonstrate that MAGIC is superior\nto other DRL-based methods on random TSP instances, both in terms of\nperformance and generalizability. Moreover, our method compares favorably\nagainst TSP heuristics and other state-of-the-art approach in terms of\nperformance and computational time.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Wenbin Ouyang",
      "Yisen Wang",
      "Shaochen Han",
      "Zhejian Jin",
      "Paul Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02843"
  },
  {
    "id": "arXiv:2110.02846",
    "title": "Seed Classification using Synthetic Image Datasets Generated from  Low-Altitude UAV Imagery",
    "abstract": "Plant breeding programs extensively monitor the evolution of seed kernels for\nseed certification, wherein lies the need to appropriately label the seed\nkernels by type and quality. However, the breeding environments are large where\nthe monitoring of seed kernels can be challenging due to the minuscule size of\nseed kernels. The use of unmanned aerial vehicles aids in seed monitoring and\nlabeling since they can capture images at low altitudes whilst being able to\naccess even the remotest areas in the environment. A key bottleneck in the\nlabeling of seeds using UAV imagery is drone altitude i.e. the classification\naccuracy decreases as the altitude increases due to lower image detail.\nConvolutional neural networks are a great tool for multi-class image\nclassification when there is a training dataset that closely represents the\ndifferent scenarios that the network might encounter during evaluation. The\narticle addresses the challenge of training data creation using Domain\nRandomization wherein synthetic image datasets are generated from a meager\nsample of seeds captured by the bottom camera of an autonomously driven Parrot\nAR Drone 2.0. Besides, the article proposes a seed classification framework as\na proof-of-concept using the convolutional neural networks of Microsoft's\nResNet-100, Oxford's VGG-16, and VGG-19. To enhance the classification accuracy\nof the framework, an ensemble model is developed resulting in an overall\naccuracy of 94.6%.",
    "descriptor": "",
    "authors": [
      "Venkat Margapuri",
      "Niketa Penumajji",
      "Mitchell Neilsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02846"
  },
  {
    "id": "arXiv:2110.02848",
    "title": "Parallel Composition of Weighted Finite-State Transducers",
    "abstract": "Finite-state transducers (FSTs) are frequently used in speech recognition.\nTransducer composition is an essential operation for combining different\nsources of information at different granularities. However, composition is also\none of the more computationally expensive operations. Due to the heterogeneous\nstructure of FSTs, parallel algorithms for composition are suboptimal in\nefficiency, generality, or both. We propose an algorithm for parallel\ncomposition and implement it on graphics processing units. We benchmark our\nparallel algorithm on the composition of random graphs and the composition of\ngraphs commonly used in speech recognition. The parallel composition scales\nbetter with the size of the input graphs and for large graphs can be as much as\n10 to 30 times faster than a sequential CPU algorithm.",
    "descriptor": "",
    "authors": [
      "Shubho Sengupta",
      "Vineel Pratap",
      "Awni Hannun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02848"
  },
  {
    "id": "arXiv:2110.02852",
    "title": "PSG HASOC-Dravidian CodeMixFIRE2021: Pretrained Transformers for  Offensive Language Identification in Tanglish",
    "abstract": "This paper describes the system submitted to Dravidian-Codemix-HASOC2021:\nHate Speech and Offensive Language Identification in Dravidian Languages\n(Tamil-English and Malayalam-English). This task aims to identify offensive\ncontent in code-mixed comments/posts in Dravidian Languages collected from\nsocial media. Our approach utilizes pooling the last layers of pretrained\ntransformer multilingual BERT for this task which helped us achieve rank nine\non the leaderboard with a weighted average score of 0.61 for the Tamil-English\ndataset in subtask B. After the task deadline, we sampled the dataset uniformly\nand used the MuRIL pretrained model, which helped us achieve a weighted average\nscore of 0.67, the top score in the leaderboard. Furthermore, our approach to\nutilizing the pretrained models helps reuse our models for the same task with a\ndifferent dataset. Our code and models are available in GitHub 1",
    "descriptor": "\nComments: Under review for FIRE 2021\n",
    "authors": [
      "Sean Benhur",
      "Kanchana Sivanraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02852"
  },
  {
    "id": "arXiv:2110.02855",
    "title": "Fully Convolutional Cross-Scale-Flows for Image-based Defect Detection",
    "abstract": "In industrial manufacturing processes, errors frequently occur at\nunpredictable times and in unknown manifestations. We tackle the problem of\nautomatic defect detection without requiring any image samples of defective\nparts. Recent works model the distribution of defect-free image data, using\neither strong statistical priors or overly simplified data representations. In\ncontrast, our approach handles fine-grained representations incorporating the\nglobal and local image context while flexibly estimating the density. To this\nend, we propose a novel fully convolutional cross-scale normalizing flow\n(CS-Flow) that jointly processes multiple feature maps of different scales.\nUsing normalizing flows to assign meaningful likelihoods to input samples\nallows for efficient defect detection on image-level. Moreover, due to the\npreserved spatial arrangement the latent space of the normalizing flow is\ninterpretable which enables to localize defective regions in the image. Our\nwork sets a new state-of-the-art in image-level defect detection on the\nbenchmark datasets Magnetic Tile Defects and MVTec AD showing a 100% AUROC on 4\nout of 15 classes.",
    "descriptor": "",
    "authors": [
      "Marco Rudolph",
      "Tom Wehrbein",
      "Bodo Rosenhahn",
      "Bastian Wandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02855"
  },
  {
    "id": "arXiv:2110.02857",
    "title": "Joint Maneuver and Beamforming Design for UAV-Enabled Integrated Sensing  and Communication",
    "abstract": "This paper studies the UAV-enabled integrated sensing and communication\n(ISAC), in which UAVs are dispatched as aerial dual-functional access points\n(APs) for efficient ISAC. In particular, we consider a scenario with one UAV-AP\nequipped with a vertically placed uniform linear array (ULA), which sends\ncombined information and sensing signals to communicate with multiple users and\nsense potential targets at interested areas on the ground simultaneously. Our\nobjective is to jointly design the UAV maneuver with the transmit beamforming\nfor optimizing the communication performance while ensuring the sensing\nrequirements. First, we consider the quasi-stationary UAV scenario, in which\nthe UAV is deployed at an optimizable location over the whole ISAC mission\nperiod. In this case, we jointly optimize the UAV deployment location, as well\nas the transmit information and sensing beamforming to maximize the weighted\nsum-rate throughput, subject to the sensing beampattern gain requirements and\ntransmit power constraint. Although the above problem is non-convex, we find a\nhigh-quality solution by using the techniques of SCA and SDR, together with a\n2D location search. Next, we consider the fully mobile UAV scenario, in which\nthe UAV can fly over different locations during the ISAC mission period. In\nthis case, we optimize the UAV flight trajectory, jointly with the transmit\nbeamforming over time, to maximize the average weighted sum-rate throughput,\nsubject to the sensing beampattern gain requirements and transmit power\nconstraints as well as practical flight constraints. While the joint UAV\ntrajectory and beamforming problem is more challenging to solve, we propose an\nefficient algorithm by adopting the alternating optimization together with SCA.\nFinally, numerical results are provided to validate the superiority of our\nproposed designs as compared to various benchmark schemes.",
    "descriptor": "\nComments: 30 pages, 19 figures\n",
    "authors": [
      "Zhonghao Lyu",
      "Guangxu Zhu",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02857"
  },
  {
    "id": "arXiv:2110.02858",
    "title": "Distribution Preserving Multiple Hypotheses Prediction for Uncertainty  Modeling",
    "abstract": "Many supervised machine learning tasks, such as future state prediction in\ndynamical systems, require precise modeling of a forecast's uncertainty. The\nMultiple Hypotheses Prediction (MHP) approach addresses this problem by\nproviding several hypotheses that represent possible outcomes. Unfortunately,\nwith the common $l_2$ loss function, these hypotheses do not preserve the data\ndistribution's characteristics. We propose an alternative loss for distribution\npreserving MHP and review relevant theorems supporting our claims. Furthermore,\nwe empirically show that our approach yields more representative hypotheses on\na synthetic and a real-world motion prediction data set. The outputs of the\nproposed method can directly be used in sampling-based Monte-Carlo methods.",
    "descriptor": "\nComments: Presented at the European Symposium of Artificial Neural Networks (ESANN) 2021\n",
    "authors": [
      "Tobias Leemann",
      "Moritz Sackmann",
      "J\u00f6rn Thielecke",
      "Ulrich Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02858"
  },
  {
    "id": "arXiv:2110.02861",
    "title": "8-bit Optimizers via Block-wise Quantization",
    "abstract": "Stateful optimizers maintain gradient statistics over time, e.g., the\nexponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past\ngradient values. This state can be used to accelerate optimization compared to\nplain stochastic gradient descent but uses memory that might otherwise be\nallocated to model parameters, thereby limiting the maximum size of models\ntrained in practice. In this paper, we develop the first optimizers that use\n8-bit statistics while maintaining the performance levels of using 32-bit\noptimizer states. To overcome the resulting computational, quantization, and\nstability challenges, we develop block-wise dynamic quantization. Block-wise\nquantization divides input tensors into smaller blocks that are independently\nquantized. Each block is processed in parallel across cores, yielding faster\noptimization and high precision quantization. To maintain stability and\nperformance, we combine block-wise quantization with two additional changes:\n(1) dynamic quantization, a form of non-linear optimization that is precise for\nboth large and small magnitude values, and (2) a stable embedding layer to\nreduce gradient variance that comes from the highly non-uniform distribution of\ninput tokens in language models. As a result, our 8-bit optimizers maintain\n32-bit performance with a small fraction of the memory footprint on a range of\ntasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet\nclassification, WMT'14 machine translation, MoCo v2 contrastive ImageNet\npretraining+finetuning, and RoBERTa pretraining, without changes to the\noriginal optimizer hyperparameters. We open-source our 8-bit optimizers as a\ndrop-in replacement that only requires a two-line code change.",
    "descriptor": "\nComments: ICLR2022 submission with appendix\n",
    "authors": [
      "Tim Dettmers",
      "Mike Lewis",
      "Sam Shleifer",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02861"
  },
  {
    "id": "arXiv:2110.02862",
    "title": "RevASIDE: Assignment of Suitable Reviewer Sets for Publications from  Fixed Candidate Pools (Extended Version)",
    "abstract": "Scientific publishing heavily relies on the assessment of quality of\nsubmitted manuscripts by peer reviewers. Assigning a set of matching reviewers\nto a submission is a highly complex task which can be performed only by domain\nexperts. We introduce RevASIDE, a reviewer recommendation system that assigns\nsuitable sets of complementing reviewers from a predefined candidate pool\nwithout requiring manually defined reviewer profiles. Here, suitability\nincludes not only reviewers' expertise, but also their authority in the target\ndomain, their diversity in their areas of expertise and experience, and their\ninterest in the topics of the manuscript. We present three new data sets for\nthe expert search and reviewer set assignment tasks and compare the usefulness\nof simple text similarity methods to document embeddings for expert search.\nFurthermore, an quantitative evaluation demonstrates significantly better\nresults in reviewer set assignment compared to baselines. A qualitative\nevaluation also shows their superior perceived quality.",
    "descriptor": "",
    "authors": [
      "Christin Katharina Kreutz",
      "Ralf Schenkel"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.02862"
  },
  {
    "id": "arXiv:2110.02863",
    "title": "Exploring the Common Principal Subspace of Deep Features in Neural  Networks",
    "abstract": "We find that different Deep Neural Networks (DNNs) trained with the same\ndataset share a common principal subspace in latent spaces, no matter in which\narchitectures (e.g., Convolutional Neural Networks (CNNs), Multi-Layer\nPreceptors (MLPs) and Autoencoders (AEs)) the DNNs were built or even whether\nlabels have been used in training (e.g., supervised, unsupervised, and\nself-supervised learning). Specifically, we design a new metric\n$\\mathcal{P}$-vector to represent the principal subspace of deep features\nlearned in a DNN, and propose to measure angles between the principal subspaces\nusing $\\mathcal{P}$-vectors. Small angles (with cosine close to $1.0$) have\nbeen found in the comparisons between any two DNNs trained with different\nalgorithms/architectures. Furthermore, during the training procedure from\nrandom scratch, the angle decrease from a larger one ($70^\\circ-80^\\circ$\nusually) to the small one, which coincides the progress of feature space\nlearning from scratch to convergence. Then, we carry out case studies to\nmeasure the angle between the $\\mathcal{P}$-vector and the principal subspace\nof training dataset, and connect such angle with generalization performance.\nExtensive experiments with practically-used Multi-Layer Perceptron (MLPs), AEs\nand CNNs for classification, image reconstruction, and self-supervised learning\ntasks on MNIST, CIFAR-10 and CIFAR-100 datasets have been done to support our\nclaims with solid evidences.\nInterpretability of Deep Learning, Feature Learning, and Subspaces of Deep\nFeatures",
    "descriptor": "\nComments: Main Text with Appendix, accepted by Machine Learning\n",
    "authors": [
      "Haoran Liu",
      "Haoyi Xiong",
      "Yaqing Wang",
      "Haozhe An",
      "Dongrui Wu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02863"
  },
  {
    "id": "arXiv:2110.02865",
    "title": "Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural  Networks",
    "abstract": "Biological spiking neural networks (SNNs) can temporally encode information\nin their outputs, e.g. in the rank order in which neurons fire, whereas\nartificial neural networks (ANNs) conventionally do not. As a result, models of\nSNNs for neuromorphic computing are regarded as potentially more rapid and\nefficient than ANNs when dealing with temporal input. On the other hand, ANNs\nare simpler to train, and usually achieve superior performance. Here we show\nthat temporal coding such as rank coding (RC) inspired by SNNs can also be\napplied to conventional ANNs such as LSTMs, and leads to computational savings\nand speedups. In our RC for ANNs, we apply backpropagation through time using\nthe standard real-valued activations, but only from a strategically early time\nstep of each sequential input example, decided by a threshold-crossing event.\nLearning then incorporates naturally also _when_ to produce an output, without\nother changes to the model or the algorithm. Both the forward and the backward\ntraining pass can be significantly shortened by skipping the remaining input\nsequence after that first event. RC-training also significantly reduces\ntime-to-insight during inference, with a minimal decrease in accuracy. The\ndesired speed-accuracy trade-off is tunable by varying the threshold or a\nregularization parameter that rewards output entropy. We demonstrate these in\ntwo toy problems of sequence classification, and in a temporally-encoded MNIST\ndataset where our RC model achieves 99.19% accuracy after the first input\ntime-step, outperforming the state of the art in temporal coding with SNNs, as\nwell as in spoken-word classification of Google Speech Commands, outperforming\nnon-RC-trained early inference with LSTMs.",
    "descriptor": "",
    "authors": [
      "Alan Jeffares",
      "Qinghai Guo",
      "Pontus Stenetorp",
      "Timoleon Moraitis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.02865"
  },
  {
    "id": "arXiv:2110.02868",
    "title": "Coded Shotgun Sequencing",
    "abstract": "Most DNA sequencing technologies are based on the shotgun paradigm: many\nshort reads are obtained from random unknown locations in the DNA sequence. A\nfundamental question, studied in arXiv:1203.6233, is what read length and\ncoverage depth (i.e., the total number of reads) are needed to guarantee\nreliable sequence reconstruction. Motivated by DNA-based storage, we study the\ncoded version of this problem;i.e., the scenario where the DNA molecule being\nsequenced is a codeword from a predefined codebook. Our main result is an exact\ncharacterization of the capacity of the resulting shotgun sequencing channel as\na function of the read length and coverage depth. In particular, our results\nimply that, while in the uncoded case, $O(n)$ reads of length greater than\n$2\\log{n}$ are needed for reliable reconstruction of a length-$n$ binary\nsequence, in the coded case, only $O(n/\\log{n})$ reads of length greater than\n$\\log{n}$ are needed for the capacity to be arbitrarily close to $1$.",
    "descriptor": "\nComments: 35 pages, 4 figures, 8 appendices\n",
    "authors": [
      "Aditya Narayan Ravi",
      "Alireza Vahid",
      "Ilan Shomorony"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.02868"
  },
  {
    "id": "arXiv:2110.02869",
    "title": "Sequence-to-Sequence Lexical Normalization with Multilingual  Transformers",
    "abstract": "Current benchmark tasks for natural language processing contain text that is\nqualitatively different from the text used in informal day to day digital\ncommunication. This discrepancy has led to severe performance degradation of\nstate-of-the-art NLP models when fine-tuned on real-world data. One way to\nresolve this issue is through lexical normalization, which is the process of\ntransforming non-standard text, usually from social media, into a more\nstandardized form. In this work, we propose a sentence-level\nsequence-to-sequence model based on mBART, which frames the problem as a\nmachine translation problem. As the noisy text is a pervasive problem across\nlanguages, not just English, we leverage the multi-lingual pre-training of\nmBART to fine-tune it to our data. While current approaches mainly operate at\nthe word or subword level, we argue that this approach is straightforward from\na technical standpoint and builds upon existing pre-trained transformer\nnetworks. Our results show that while word-level, intrinsic, performance\nevaluation is behind other methods, our model improves performance on\nextrinsic, downstream tasks through normalization compared to models operating\non raw, unprocessed, social media text.",
    "descriptor": "\nComments: Accepted to Proceedings of the 7th Workshop on Noisy User-generated Text (WNUT 2021), EMNLP 2021\n",
    "authors": [
      "Ana-Maria Bucur",
      "Adrian Cosma",
      "Liviu P. Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02869"
  },
  {
    "id": "arXiv:2110.02870",
    "title": "Capturing Structural Locality in Non-parametric Language Models",
    "abstract": "Structural locality is a ubiquitous feature of real-world datasets, wherein\ndata points are organized into local hierarchies. Some examples include topical\nclusters in text or project hierarchies in source code repositories. In this\npaper, we explore utilizing this structural locality within non-parametric\nlanguage models, which generate sequences that reference retrieved examples\nfrom an external source. We propose a simple yet effective approach for adding\nlocality information into such models by adding learned parameters that improve\nthe likelihood of retrieving examples from local neighborhoods. Experiments on\ntwo different domains, Java source code and Wikipedia text, demonstrate that\nlocality features improve model efficacy over models without access to these\nfeatures, with interesting differences. We also perform an analysis of how and\nwhere locality features contribute to improved performance and why the\ntraditionally used contextual similarity metrics alone are not enough to grasp\nthe locality structure.",
    "descriptor": "",
    "authors": [
      "Frank F. Xu",
      "Junxian He",
      "Graham Neubig",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02870"
  },
  {
    "id": "arXiv:2110.02871",
    "title": "ClimateGAN: Raising Climate Change Awareness by Generating Images of  Floods",
    "abstract": "Climate change is a major threat to humanity, and the actions required to\nprevent its catastrophic consequences include changes in both policy-making and\nindividual behaviour. However, taking action requires understanding the effects\nof climate change, even though they may seem abstract and distant. Projecting\nthe potential consequences of extreme climate events such as flooding in\nfamiliar places can help make the abstract impacts of climate change more\nconcrete and encourage action. As part of a larger initiative to build a\nwebsite that projects extreme climate events onto user-chosen photos, we\npresent our solution to simulate photo-realistic floods on authentic images. To\naddress this complex task in the absence of suitable training data, we propose\nClimateGAN, a model that leverages both simulated and real data for\nunsupervised domain adaptation and conditional image generation. In this paper,\nwe describe the details of our framework, thoroughly evaluate components of our\narchitecture and demonstrate that our model is capable of robustly generating\nphoto-realistic flooding.",
    "descriptor": "",
    "authors": [
      "Victor Schmidt",
      "Alexandra Sasha Luccioni",
      "M\u00e9lisande Teng",
      "Tianyu Zhang",
      "Alexia Reynaud",
      "Sunand Raghupathi",
      "Gautier Cosne",
      "Adrien Juraver",
      "Vahe Vardanyan",
      "Alex Hernandez-Garcia",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.02871"
  },
  {
    "id": "arXiv:2110.02873",
    "title": "SDA-GAN: Unsupervised Image Translation Using Spectral Domain  Attention-Guided Generative Adversarial Network",
    "abstract": "This work introduced a novel GAN architecture for unsupervised image\ntranslation on the task of face style transform. A spectral attention-based\nmechanism is embedded into the design along with spatial attention on the image\ncontents. We proved that neural network has the potential of learning complex\ntransformations such as Fourier transform, within considerable computational\ncost. The model is trained and tested in comparison to the baseline model,\nwhich only uses spatial attention. The performance improvement of our approach\nis significant especially when the source and target domain include different\ncomplexity (reduced FID to 49.18 from 142.84). In the translation process, a\nspectra filling effect was introduced due to the implementation of FFT and\nspectral attention. Another style transfer task and real-world object\ntranslation are also studied in this paper.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Qizhou Wang",
      "Maksim Makarenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02873"
  },
  {
    "id": "arXiv:2110.02878",
    "title": "An Investigation of the Effectiveness of Phase for Audio Classification",
    "abstract": "While log-amplitude mel-spectrogram has widely been used as the feature\nrepresentation for processing speech based on deep learning, the effectiveness\nof another aspect of speech spectrum, i.e., phase information, was shown\nrecently for tasks such as speech enhancement and source separation. In this\nstudy, we extensively investigated the effectiveness of including phase\ninformation of signals for eight audio classification tasks. We constructed a\nlearnable front-end that can compute the phase and its derivatives based on a\ntime-frequency representation with mel-like frequency axis. As a result,\nexperimental results showed significant performance improvement for musical\npitch detection, musical instrument detection, language identification, speaker\nidentification, and birdsong detection. On the other hand, overfitting to the\nrecording condition was observed for some tasks when the instantaneous\nfrequency was used. The results implied that the relationship between the phase\nvalues of adjacent elements is more important than the phase itself in audio\nclassification.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shunsuke Hidaka",
      "Kohei Wakamiya",
      "Tokihiko Kaburaki"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02878"
  },
  {
    "id": "arXiv:2110.02879",
    "title": "Nested Policy Reinforcement Learning",
    "abstract": "Off-policy reinforcement learning (RL) has proven to be a powerful framework\nfor guiding agents' actions in environments with stochastic rewards and unknown\nor noisy state dynamics. In many real-world settings, these agents must operate\nin multiple environments, each with slightly different dynamics. For example,\nwe may be interested in developing policies to guide medical treatment for\npatients with and without a given disease, or policies to navigate curriculum\ndesign for students with and without a learning disability. Here, we introduce\nnested policy fitted Q-iteration (NFQI), an RL framework that finds optimal\npolicies in environments that exhibit such a structure. Our approach develops a\nnested $Q$-value function that takes advantage of the shared structure between\ntwo groups of observations from two separate environments while allowing their\npolicies to be distinct from one another. We find that NFQI yields policies\nthat rely on relevant features and perform at least as well as a policy that\ndoes not consider group structure. We demonstrate NFQI's performance using an\nOpenAI Gym environment and a clinical decision making RL task. Our results\nsuggest that NFQI can develop policies that are better suited to many\nreal-world clinical environments.",
    "descriptor": "",
    "authors": [
      "Aishwarya Mandyam",
      "Andrew Jones",
      "Krzysztof Laudanski",
      "Barbara Engelhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02879"
  },
  {
    "id": "arXiv:2110.02880",
    "title": "Space-Time Graph Neural Networks",
    "abstract": "We introduce space-time graph neural network (ST-GNN), a novel GNN\narchitecture, tailored to jointly process the underlying space-time topology of\ntime-varying network data. The cornerstone of our proposed architecture is the\ncomposition of time and graph convolutional filters followed by pointwise\nnonlinear activation functions. We introduce a generic definition of\nconvolution operators that mimic the diffusion process of signals over its\nunderlying support. On top of this definition, we propose space-time graph\nconvolutions that are built upon a composition of time and graph shift\noperators. We prove that ST-GNNs with multivariate integral Lipschitz filters\nare stable to small perturbations in the underlying graphs as well as small\nperturbations in the time domain caused by time warping. Our analysis shows\nthat small variations in the network topology and time evolution of a system\ndoes not significantly affect the performance of ST-GNNs. Numerical experiments\nwith decentralized control systems showcase the effectiveness and stability of\nthe proposed ST-GNNs.",
    "descriptor": "",
    "authors": [
      "Samar Hadou",
      "Charilaos I. Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02880"
  },
  {
    "id": "arXiv:2110.02884",
    "title": "Human-in-the-Loop Refinement of Word Embeddings",
    "abstract": "Word embeddings are a fixed, distributional representation of the context of\nwords in a corpus learned from word co-occurrences. Despite their proven\nutility in machine learning tasks, word embedding models may capture uneven\nsemantic and syntactic representations, and can inadvertently reflect various\nkinds of bias present within corpora upon which they were trained. It has been\ndemonstrated that post-processing of word embeddings to apply information found\nin lexical dictionaries can improve the semantic associations, thus improving\ntheir quality. Building on this idea, we propose a system that incorporates an\nadaptation of word embedding post-processing, which we call \"interactive\nrefitting\", to address some of the most daunting qualitative problems found in\nword embeddings. Our approach allows a human to identify and address potential\nquality issues with word embeddings interactively. This has the advantage of\nnegating the question of who decides what constitutes bias or what other\nquality issues may affect downstream tasks. It allows each organization or\nentity to address concerns they may have at a fine grained level and to do so\nin an iterative and interactive fashion. It also allows for better insight into\nwhat effect word embeddings, and refinements to word embeddings, have on\nmachine learning pipelines.",
    "descriptor": "",
    "authors": [
      "James Powell",
      "Kari Sentz",
      "Martin Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02884"
  },
  {
    "id": "arXiv:2110.02886",
    "title": "Modifying and optimizing the inverse of the frequency response circulant  matrix as an iterative learning control compensator",
    "abstract": "Feedback control systems do not do what you ask. The concept of bandwidth is\ndefined to tell what components of a command are reasonably well handled.\nIterative Learning Control (ILC) seeks to converge to zero error following any\ngiven finite time desired trajectory as iterations progress. The approach can\nbe used to achieve high precision tracking in spacecraft sensors performing\nrepeated highly accurate sensor scanning. ILC asks for zero error for a finite\ntime tracking maneuver, containing initial transients each iteration. The\npurpose of this paper is to create a method of designing ILC compensators based\non steady state frequency response, and have the ILC converge to zero error in\nspite of transients and bandwidth. In this work the inverse of the circulant\nmatrix of Markov parameters is used as a learning gain matrix. One can show\nthat this matrix gives the steady state frequency response of the system at the\nfinite number of frequencies observable in the finite data sequence of an\niteration or run. Methods are used to adjust the steady state frequency\nresponse gains to address the transient part of the error signal. Numerical\nsimulations compare the design approach to common time domain ILC design\napproaches, and one observes much faster convergence.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Shuo Liu",
      "Richard W. Longman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02886"
  },
  {
    "id": "arXiv:2110.02887",
    "title": "Using Optimal Transport as Alignment Objective for fine-tuning  Multilingual Contextualized Embeddings",
    "abstract": "Recent studies have proposed different methods to improve multilingual word\nrepresentations in contextualized settings including techniques that align\nbetween source and target embedding spaces. For contextualized embeddings,\nalignment becomes more complex as we additionally take context into\nconsideration. In this work, we propose using Optimal Transport (OT) as an\nalignment objective during fine-tuning to further improve multilingual\ncontextualized representations for downstream cross-lingual transfer. This\napproach does not require word-alignment pairs prior to fine-tuning that may\nlead to sub-optimal matching and instead learns the word alignments within\ncontext in an unsupervised manner. It also allows different types of mappings\ndue to soft matching between source and target sentences. We benchmark our\nproposed method on two tasks (XNLI and XQuAD) and achieve improvements over\nbaselines as well as competitive results compared to similar recent works.",
    "descriptor": "",
    "authors": [
      "Sawsan Alqahtani",
      "Garima Lalwani",
      "Yi Zhang",
      "Salvatore Romeo",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02887"
  },
  {
    "id": "arXiv:2110.02891",
    "title": "Style Equalization: Unsupervised Learning of Controllable Generative  Sequence Models",
    "abstract": "Controllable generative sequence models with the capability to extract and\nreplicate the style of specific examples enable many applications, including\nnarrating audiobooks in different voices, auto-completing and auto-correcting\nwritten handwriting, and generating missing training samples for downstream\nrecognition tasks. However, typical training algorithms for these controllable\nsequence generative models suffer from the training-inference mismatch, where\nthe same sample is used as content and style input during training but\ndifferent samples are given during inference. In this paper, we tackle the\ntraining-inference mismatch encountered during unsupervised learning of\ncontrollable generative sequence models. By introducing a style transformation\nmodule that we call style equalization, we enable training using different\ncontent and style samples and thereby mitigate the training-inference mismatch.\nTo demonstrate its generality, we applied style equalization to text-to-speech\nand text-to-handwriting synthesis on three datasets. Our models achieve\nstate-of-the-art style replication with a similar mean style opinion score as\nthe real data. Moreover, the proposed method enables style interpolation\nbetween sequences and generates novel styles.",
    "descriptor": "",
    "authors": [
      "Jen-Hao Rick Chang",
      "Ashish Shrivastava",
      "Hema Swetha Koppula",
      "Xiaoshuai Zhang",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02891"
  },
  {
    "id": "arXiv:2110.02892",
    "title": "Probabilistic Metamodels for an Efficient Characterization of Complex  Driving Scenarios",
    "abstract": "To systematically validate the safe behavior of automated vehicles (AV), the\naim of scenario-based testing is to cluster the infinite situations an AV might\nencounter into a finite set of functional scenarios. Every functional scenario,\nhowever, can still manifest itself in a vast amount of variations. Thus,\nmetamodels are often used to perform analyses or to select specific variations\nfor examination. However, despite the safety criticalness of AV testing,\nmetamodels are usually seen as a part of an overall approach, and their\npredictions are not further examined. In this paper, we analyze the predictive\nperformance of Gaussian processes (GP), deep Gaussian processes, extra-trees\n(ET), and Bayesian neural networks (BNN), considering four scenarios with 5 to\n20 inputs. Building on this, we introduce and evaluate an iterative approach to\nefficiently select test cases. Our results show that regarding predictive\nperformance, the appropriate selection of test cases is more important than the\nchoice of metamodels. While their great flexibility allows BNNs to benefit from\nlarge amounts of data and to model even the most complex scenarios, less\nflexible models like GPs can convince with higher reliability. This implies\nthat relevant test cases have to be explored using scalable virtual\nenvironments and flexible models so that more realistic test environments and\nmore trustworthy models can be used for targeted testing and validation.",
    "descriptor": "\nComments: 10 pages, 15 figures, 1 table, associated dataset at this https URL\n",
    "authors": [
      "Max Winkelmann",
      "Mike Kohlhoff",
      "Hadj Hamma Tadjine",
      "Steffen M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02892"
  },
  {
    "id": "arXiv:2110.02894",
    "title": "Revisiting Dimensionality Reduction Techniques for Visual Cluster  Analysis: An Empirical Study",
    "abstract": "Dimensionality Reduction (DR) techniques can generate 2D projections and\nenable visual exploration of cluster structures of high-dimensional datasets.\nHowever, different DR techniques would yield various patterns, which\nsignificantly affect the performance of visual cluster analysis tasks. We\npresent the results of a user study that investigates the influence of\ndifferent DR techniques on visual cluster analysis. Our study focuses on the\nmost concerned property types, namely the linearity and locality, and evaluates\ntwelve representative DR techniques that cover the concerned properties. Four\ncontrolled experiments were conducted to evaluate how the DR techniques\nfacilitate the tasks of 1) cluster identification, 2) membership\nidentification, 3) distance comparison, and 4) density comparison,\nrespectively. We also evaluated users' subjective preference of the DR\ntechniques regarding the quality of projected clusters. The results show that:\n1) Non-linear and Local techniques are preferred in cluster identification and\nmembership identification; 2) Linear techniques perform better than non-linear\ntechniques in density comparison; 3) UMAP (Uniform Manifold Approximation and\nProjection) and t-SNE (t-Distributed Stochastic Neighbor Embedding) perform the\nbest in cluster identification and membership identification; 4) NMF\n(Nonnegative Matrix Factorization) has competitive performance in distance\ncomparison; 5) t-SNLE (t-Distributed Stochastic Neighbor Linear Embedding) has\ncompetitive performance in density comparison.",
    "descriptor": "\nComments: IEEE VIS 2021, to appear in IEEE Transactions on Visualization & Computer Graphics\n",
    "authors": [
      "Jiazhi Xia",
      "Yuchen Zhang",
      "Jie Song",
      "Yang Chen",
      "Yunhai Wang",
      "Shixia Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02894"
  },
  {
    "id": "arXiv:2110.02895",
    "title": "On designing finite time iterative learning control based on steady  state frequency response",
    "abstract": "Iterative Learning Control (ILC) is useful in spacecraft application for\nrepeated high precision scanning maneuvers. Repetitive Control (RC) produces\neffective active vibration isolation based on frequency response. This paper\nconsiders ILC designed from frequency response, comparing two methods recently\ndeveloped. One adapts for ILC the FIR filter design in RC that mimics the\nsystems steady state frequency response inverse, creating a filter designed for\nall frequencies from zero to Nyquist. Adjustment of gains must near the\nbeginning of the matrix need to be made because FIR gains are truncated there.\nThe other approach uses a circulant matrix obtained from the Toeplitz matrix of\nMarkov parameters. It is shown to give steady state frequency response for the\ndiscrete frequencies that can be seen in the number of time steps in the ILC\ntracking problem. The main aim is to compare their performance and ease of use.\nA second aim is to learn from successful ILC designs to enhances stability\nrobustness of the two methods. Finally, the use of an ILC frequency cutoff is\nstudied as an alternative method to eliminate instability of the control action\nin the converged zero tracking error solution of many ILC problems.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Shuo Liu",
      "Richard W. Longman",
      "Benjamas Panomruttanarug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02895"
  },
  {
    "id": "arXiv:2110.02896",
    "title": "Predicting the Popularity of Games on Steam",
    "abstract": "The video game industry has seen rapid growth over the last decade. Thousands\nof video games are released and played by millions of people every year,\ncreating a large community of players. Steam is a leading gaming platform and\nsocial networking site, which allows its users to purchase and store games. A\nby-product of Steam is a large database of information about games, players,\nand gaming behavior. In this paper, we take recent video games released on\nSteam and aim to discover the relation between game popularity and a game's\nfeatures that can be acquired through Steam. We approach this task by\npredicting the popularity of Steam games in the early stages after their\nrelease and we use a Bayesian approach to understand the influence of a game's\nprice, size, supported languages, release date, and genres on its player count.\nWe implement several models and discover that a genre-based hierarchical\napproach achieves the best performance. We further analyze the model and\ninterpret its coefficients, which indicate that games released at the beginning\nof the month and games of certain genres correlate with game popularity.",
    "descriptor": "",
    "authors": [
      "Andra\u017e De Luisa",
      "Jan Hartman",
      "David Nabergoj",
      "Samo Pahor",
      "Marko Rus",
      "Bozhidar Stevanoski",
      "Jure Dem\u0161ar",
      "Erik \u0160trumbelj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02896"
  },
  {
    "id": "arXiv:2110.02898",
    "title": "Coresets for Kernel Clustering",
    "abstract": "We devise the first coreset for kernel $k$-Means, and use it to obtain new,\nmore efficient, algorithms. Kernel $k$-Means has superior clustering capability\ncompared to classical $k$-Means particularly when clusters are separable\nnon-linearly, but it also introduces significant computational challenges. We\naddress this computational issue by constructing a coreset, which is a reduced\ndataset that accurately preserves the clustering costs.\nOur main result is the first coreset for kernel $k$-Means, whose size is\nindependent of the number of input points $n$, and moreover is constructed in\ntime near-linear in $n$. This result immediately implies new algorithms for\nkernel $k$-Means, such as a $(1+\\epsilon)$-approximation in time near-linear in\n$n$, and a streaming algorithm using space and update time $\\mathrm{poly}(k\n\\epsilon^{-1} \\log n)$.\nWe validate our coreset on various datasets with different kernels. Our\ncoreset performs consistently well, achieving small errors while using very few\npoints. We show that our coresets can speed up kernel $k$-Means++ (the\nkernelized version of the widely used $k$-Means++ algorithm), and we further\nuse this faster kernel $k$-Means++ for spectral clustering. In both\napplications, we achieve up to 1000x speedup while the error is comparable to\nbaselines that do not use coresets.",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Jianing Lou",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02898"
  },
  {
    "id": "arXiv:2110.02900",
    "title": "Meta Internal Learning",
    "abstract": "Internal learning for single-image generation is a framework, where a\ngenerator is trained to produce novel images based on a single image. Since\nthese models are trained on a single image, they are limited in their scale and\napplication. To overcome these issues, we propose a meta-learning approach that\nenables training over a collection of images, in order to model the internal\nstatistics of the sample image more effectively. In the presented meta-learning\napproach, a single-image GAN model is generated given an input image, via a\nconvolutional feedforward hypernetwork $f$. This network is trained over a\ndataset of images, allowing for feature sharing among different models, and for\ninterpolation in the space of generative models. The generated single-image\nmodel contains a hierarchy of multiple generators and discriminators. It is\ntherefore required to train the meta-learner in an adversarial manner, which\nrequires careful design choices that we justify by a theoretical analysis. Our\nresults show that the models obtained are as suitable as single-image GANs for\nmany common image applications, significantly reduce the training time per\nimage without loss in performance, and introduce novel capabilities, such as\ninterpolation and feedforward modeling of novel images.",
    "descriptor": "",
    "authors": [
      "Raphael Bensadoun",
      "Shir Gur",
      "Tomer Galanti",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02900"
  },
  {
    "id": "arXiv:2110.02902",
    "title": "SAIC_Cambridge-HuPBA-FBK Submission to the EPIC-Kitchens-100 Action  Recognition Challenge 2021",
    "abstract": "This report presents the technical details of our submission to the\nEPIC-Kitchens-100 Action Recognition Challenge 2021. To participate in the\nchallenge we deployed spatio-temporal feature extraction and aggregation models\nwe have developed recently: GSF and XViT. GSF is an efficient spatio-temporal\nfeature extracting module that can be plugged into 2D CNNs for video action\nrecognition. XViT is a convolution free video feature extractor based on\ntransformer architecture. We design an ensemble of GSF and XViT model families\nwith different backbones and pretraining to generate the prediction scores. Our\nsubmission, visible on the public leaderboard, achieved a top-1 action\nrecognition accuracy of 44.82%, using only RGB.",
    "descriptor": "\nComments: Ranked third in the EPIC-Kitchens-100 Action Recognition Challenge @ CVPR 2021\n",
    "authors": [
      "Swathikiran Sudhakaran",
      "Adrian Bulat",
      "Juan-Manuel Perez-Rua",
      "Alex Falcon",
      "Sergio Escalera",
      "Oswald Lanz",
      "Brais Martinez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02902"
  },
  {
    "id": "arXiv:2110.02903",
    "title": "Grasp-Oriented Fine-grained Cloth Segmentation without Real Supervision",
    "abstract": "Automatically detecting graspable regions from a single depth image is a key\ningredient in cloth manipulation. The large variability of cloth deformations\nhas motivated most of the current approaches to focus on identifying specific\ngrasping points rather than semantic parts, as the appearance and depth\nvariations of local regions are smaller and easier to model than the larger\nones. However, tasks like cloth folding or assisted dressing require\nrecognising larger segments, such as semantic edges that carry more information\nthan points. The first goal of this paper is therefore to tackle the problem of\nfine-grained region detection in deformed clothes using only a depth image. As\na proof of concept, we implement an approach for T-shirts, and define up to 6\nsemantic regions of varying extent, including edges on the neckline, sleeve\ncuffs, and hem, plus top and bottom grasping points. We introduce a U-net based\nnetwork to segment and label these parts. The second contribution of our work\nis concerned with the level of supervision that we require to train the\nproposed network. While most approaches learn to detect grasping points by\ncombining real and synthetic annotations, in this work we defy the limitations\nof the synthetic data, and propose a multilayered domain adaptation (DA)\nstrategy that does not use real annotations at all. We thoroughly evaluate our\napproach on real depth images of a T-shirt annotated with fine-grained labels.\nWe show that training our network solely with synthetic data and the proposed\nDA yields results competitive with models trained on real data.",
    "descriptor": "\nComments: 6 pages, 4 figures. Submitted to International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Ruijie Ren",
      "Mohit Gurnani Rajesh",
      "Jordi Sanchez-Riera",
      "Fan Zhang",
      "Yurun Tian",
      "Antonio Agudo",
      "Yiannis Demiris",
      "Krystian Mikolajczyk",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02903"
  },
  {
    "id": "arXiv:2110.02904",
    "title": "CCO-VOXEL: Chance Constrained Optimization over Uncertain Voxel-Grid  Representation for Safe Trajectory Planning",
    "abstract": "We present CCO-VOXEL: the very first chance-constrained optimization (CCO)\nalgorithm that can compute trajectory plans with probabilistic safety\nguarantees in real-time directly on the voxel-grid representation of the world.\nCCO-VOXEL maps the distribution over the distance to the closest obstacle to a\ndistribution over collision-constraint violation and computes an optimal\ntrajectory that minimizes the violation probability. Importantly, unlike\nexisting works, we never assume the nature of the sensor uncertainty or the\nprobability distribution of the resulting collision-constraint violations. We\nleverage the notion of Hilbert Space embedding of distributions and Maximum\nMean Discrepancy (MMD) to compute a tractable surrogate for the original\nchance-constrained optimization problem and employ a combination of A* based\ngraph-search and Cross-Entropy Method for obtaining its minimum. We show\ntangible performance gain in terms of collision avoidance and trajectory\nsmoothness as a consequence of our probabilistic formulation vis a vis\nstate-of-the-art planning methods that do not account for such nonparametric\nnoise. Finally, we also show how a combination of low-dimensional feature\nembedding and pre-caching of Kernel Matrices of MMD allows us to achieve\nreal-time performance in simulations as well as in implementations on on-board\ncommodity hardware that controls the quadrotor flight",
    "descriptor": "\nComments: Submitted to ICRA 2022 , Code available at this https URL\n",
    "authors": [
      "Sudarshan S Harithas",
      "Rishabh Dev Yadav",
      "Deepak Singh",
      "Arun Kumar Singh",
      "K Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02904"
  },
  {
    "id": "arXiv:2110.02905",
    "title": "Geometric and Physical Quantities improve E(3) Equivariant Message  Passing",
    "abstract": "Including covariant information, such as position, force, velocity or spin is\nimportant in many tasks in computational physics and chemistry. We introduce\nSteerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise\nequivariant graph networks, such that node and edge attributes are not\nrestricted to invariant scalars, but can contain covariant information, such as\nvectors or tensors. This model, composed of steerable MLPs, is able to\nincorporate geometric and physical information in both the message and update\nfunctions. Through the definition of steerable node attributes, the MLPs\nprovide a new class of activation functions for general use with steerable\nfeature fields. We discuss ours and related work through the lens of\nequivariant non-linear convolutions, which further allows us to pin-point the\nsuccessful components of SEGNNs: non-linear message aggregation improves upon\nclassic linear (steerable) point convolutions; steerable messages improve upon\nrecent equivariant graph networks that send invariant messages. We demonstrate\nthe effectiveness of our method on several tasks in computational physics and\nchemistry and provide extensive ablation studies.",
    "descriptor": "",
    "authors": [
      "Johannes Brandstetter",
      "Rob Hesselink",
      "Elise van der Pol",
      "Erik Bekkers",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02905"
  },
  {
    "id": "arXiv:2110.02907",
    "title": "Resolution-Optimal Motion Planning for Steerable Needles",
    "abstract": "Medical steerable needles can follow 3D curvilinear trajectories inside body\ntissue, enabling them to move around critical anatomical structures and\nprecisely reach clinically significant targets in a minimally invasive way.\nAutomating needle steering, with motion planning as a key component, has the\npotential to maximize the accuracy, precision, speed, and safety of steerable\nneedle procedures. In this paper, we introduce the first resolution-optimal\nmotion planner for steerable needles that offers excellent practical\nperformance in terms of runtime while simultaneously providing strong\ntheoretical guarantees on completeness and the global optimality of the motion\nplan in finite time. Compared to state-of-the-art steerable needle motion\nplanners, simulation experiments on realistic scenarios of lung biopsy\ndemonstrate that our proposed planner is faster in generating higher-quality\nplans while incorporating clinically relevant cost functions. This indicates\nthat the theoretical guarantees of the proposed planner have a practical impact\non the motion plan quality, which is valuable for computing motion plans that\nminimize patient trauma.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.04939\n",
    "authors": [
      "Mengyu Fu",
      "Kiril Solovey",
      "Oren Salzman",
      "Ron Alterovitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02907"
  },
  {
    "id": "arXiv:2110.02910",
    "title": "Equivariant Subgraph Aggregation Networks",
    "abstract": "Message-passing neural networks (MPNNs) are the leading architecture for deep\nlearning on graph-structured data, in large part due to their simplicity and\nscalability. Unfortunately, it was shown that these architectures are limited\nin their expressive power. This paper proposes a novel framework called\nEquivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our\nmain observation is that while two graphs may not be distinguishable by an\nMPNN, they often contain distinguishable subgraphs. Thus, we propose to\nrepresent each graph as a set of subgraphs derived by some predefined policy,\nand to process it using a suitable equivariant architecture. We develop novel\nvariants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph\nisomorphism, and prove lower bounds on the expressiveness of ESAN in terms of\nthese new WL variants. We further prove that our approach increases the\nexpressive power of both MPNNs and more expressive architectures. Moreover, we\nprovide theoretical results that describe how design choices such as the\nsubgraph selection policy and equivariant neural architecture affect our\narchitecture's expressive power. To deal with the increased computational cost,\nwe propose a subgraph sampling scheme, which can be viewed as a stochastic\nversion of our framework. A comprehensive set of experiments on real and\nsynthetic datasets demonstrates that our framework improves the expressive\npower and overall performance of popular GNN architectures.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Beatrice Bevilacqua",
      "Fabrizio Frasca",
      "Derek Lim",
      "Balasubramaniam Srinivasan",
      "Chen Cai",
      "Gopinath Balamurugan",
      "Michael M. Bronstein",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02910"
  },
  {
    "id": "arXiv:2110.02911",
    "title": "Shifting Capsule Networks from the Cloud to the Deep Edge",
    "abstract": "Capsule networks (CapsNets) are an emerging trend in image processing. In\ncontrast to a convolutional neural network, CapsNets are not vulnerable to\nobject deformation, as the relative spatial information of the objects is\npreserved across the network. However, their complexity is mainly related with\nthe capsule structure and the dynamic routing mechanism, which makes it almost\nunreasonable to deploy a CapsNet, in its original form, in a\nresource-constrained device powered by a small microcontroller (MCU). In an era\nwhere intelligence is rapidly shifting from the cloud to the edge, this high\ncomplexity imposes serious challenges to the adoption of CapsNets at the very\nedge. To tackle this issue, we present an API for the execution of quantized\nCapsNets in Cortex-M and RISC-V MCUs. Our software kernels extend the Arm\nCMSIS-NN and RISC-V PULP-NN, to support capsule operations with 8-bit integers\nas operands. Along with it, we propose a framework to perform post training\nquantization of a CapsNet. Results show a reduction in memory footprint of\nalmost 75%, with a maximum accuracy loss of 1%. In terms of throughput, our\nsoftware kernels for the Arm Cortex-M are, at least, 5.70x faster than a\npre-quantized CapsNet running on an NVIDIA GTX 980 Ti graphics card. For\nRISC-V, the throughout gain increases to 26.28x and 56.91x for a single- and\nocta-core configuration, respectively.",
    "descriptor": "",
    "authors": [
      "Miguel Costa",
      "Diogo Costa",
      "Tiago Gomes",
      "Sandro Pinto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02911"
  },
  {
    "id": "arXiv:2110.02912",
    "title": "Generative Optimization Networks for Memory Efficient Data Generation",
    "abstract": "In standard generative deep learning models, such as autoencoders or GANs,\nthe size of the parameter set is proportional to the complexity of the\ngenerated data distribution. A significant challenge is to deploy\nresource-hungry deep learning models in devices with limited memory to prevent\nsystem upgrade costs. To combat this, we propose a novel framework called\ngenerative optimization networks (GON) that is similar to GANs, but does not\nuse a generator, significantly reducing its memory footprint. GONs use a single\ndiscriminator network and run optimization in the input space to generate new\ndata samples, achieving an effective compromise between training time and\nmemory consumption. GONs are most suited for data generation problems in\nlimited memory settings. Here we illustrate their use for the problem of\nanomaly detection in memory-constrained edge devices arising from attacks or\nintrusion events. Specifically, we use a GON to calculate a\nreconstruction-based anomaly score for input time-series windows. Experiments\non a Raspberry-Pi testbed with two existing and a new suite of datasets show\nthat our framework gives up to 32% higher detection F1 scores and 58% lower\nmemory consumption, with only 5% higher training overheads compared to the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Shreshth Tuli",
      "Shikhar Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02912"
  },
  {
    "id": "arXiv:2110.02915",
    "title": "Unrolling Particles: Unsupervised Learning of Sampling Distributions",
    "abstract": "Particle filtering is used to compute good nonlinear estimates of complex\nsystems. It samples trajectories from a chosen distribution and computes the\nestimate as a weighted average. Easy-to-sample distributions often lead to\ndegenerate samples where only one trajectory carries all the weight, negatively\naffecting the resulting performance of the estimate. While much research has\nbeen done on the design of appropriate sampling distributions that would lead\nto controlled degeneracy, in this paper our objective is to \\emph{learn}\nsampling distributions. Leveraging the framework of algorithm unrolling, we\nmodel the sampling distribution as a multivariate normal, and we use neural\nnetworks to learn both the mean and the covariance. We carry out unsupervised\ntraining of the model to minimize weight degeneracy, relying only on the\nobserved measurements of the system. We show in simulations that the resulting\nparticle filter yields good estimates in a wide range of scenarios.",
    "descriptor": "",
    "authors": [
      "Fernando Gama",
      "Nicolas Zilberstein",
      "Richard G. Baraniuk",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.02915"
  },
  {
    "id": "arXiv:2110.02916",
    "title": "Towards Heuristics for Supporting the Validation of Code Smells",
    "abstract": "The identification of code smells is largely recognized as a subjective task.\nConsequently, the automated detection tools available are insufficient to deal\nwith the whole subjectivity involved in the task, requiring human validation.\nHowever, developers may follow different but complementary perspectives for\nmanually validating the same code smell. Based on this scenario, our research\naims at characterizing a comprehensive and optimized set of heuristics for\nguiding developers to validate the incidence of code smells reported by\nautomated detection tools. For this purpose, we conducted an empirical study\nwith 12 experienced software developers. In this study, we invited developers\nto individually validate the incidence of code smells in 24 code snippets from\nopen-source Java projects. For each validation, developers should provide\narguments for supporting their decisions. The study findings revealed that\ndevelopers tend to look from different perspectives even when they agree about\nthe incidence of a code smell. After coding the 303 arguments given into\nheuristics and refining them, we composed an optimized set of validation items\nfor guiding developers on manually validating the incidence of eight types of\ncode smells: data class, god class, speculative generality, middle man, refused\nbequest, primitive obsession, long parameter list, and feature envy. We are\ncurrently planning a survey with specialists for identifying opportunities for\nevolving the set of validation items proposed.",
    "descriptor": "",
    "authors": [
      "Luiz Felipi Junionello",
      "Rafael de Mello"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02916"
  },
  {
    "id": "arXiv:2110.02918",
    "title": "Boosting RANSAC via Dual Principal Component Pursuit",
    "abstract": "In this paper, we revisit the problem of local optimization in RANSAC. Once a\nso-far-the-best model has been found, we refine it via Dual Principal Component\nPursuit (DPCP), a robust subspace learning method with strong theoretical\nsupport and efficient algorithms. The proposed DPCP-RANSAC has far fewer\nparameters than existing methods and is scalable. Experiments on estimating\ntwo-view homographies, fundamental and essential matrices, and three-view\nhomographic tensors using large-scale datasets show that our approach\nconsistently has higher accuracy than state-of-the-art alternatives.",
    "descriptor": "",
    "authors": [
      "Yunchen Yang",
      "Xinyue Zhang",
      "Tianjiao Ding",
      "Daniel P. Robinson",
      "Rene Vidal",
      "Manolis C. Tsakiris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02918"
  },
  {
    "id": "arXiv:2110.02919",
    "title": "Residual Overfit Method of Exploration",
    "abstract": "Exploration is a crucial aspect of bandit and reinforcement learning\nalgorithms. The uncertainty quantification necessary for exploration often\ncomes from either closed-form expressions based on simple models or resampling\nand posterior approximations that are computationally intensive. We propose\ninstead an approximate exploration methodology based on fitting only two point\nestimates, one tuned and one overfit. The approach, which we term the residual\noverfit method of exploration (ROME), drives exploration towards actions where\nthe overfit model exhibits the most overfitting compared to the tuned model.\nThe intuition is that overfitting occurs the most at actions and contexts with\ninsufficient data to form accurate predictions of the reward. We justify this\nintuition formally from both a frequentist and a Bayesian information theoretic\nperspective. The result is a method that generalizes to a wide variety of\nmodels and avoids the computational overhead of resampling or posterior\napproximations. We compare ROME against a set of established contextual bandit\nmethods on three datasets and find it to be one of the best performing.",
    "descriptor": "\nComments: 13 pages, 16 figures\n",
    "authors": [
      "James McInerney",
      "Nathan Kallus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02919"
  },
  {
    "id": "arXiv:2110.02922",
    "title": "SNEAK: Faster Interactive Search-based Software Engineering (using  Semi-Supervised Learning)",
    "abstract": "When reasoning over complex models, AI tools can generate too many solutions\nfor humans to read and understand. In this case, \\textit{interactive\nsearch-based software engineering} techniques might use human preferences to\nselect relevant solutions (and discard the rest). Often, iSBSE methods rely on\nevolutionary methods that need to score thousands of mutants. Generating those\nscores can be overwhelming for humans or impractically slow (e.g. if some\nautomated process required extensive CPU to computer those scores).\nTo address that problem, this paper introduces SNEAK, a semi-supervised\nlearner (SSL) that uses the structure of the data to label a very small number\nof points, then propagates those labels over its neighbors. Whereas standard\nSSL addresses single goal problems (classification, regression),\n\\sffamily{SNEAK} is unique in that it can handle multi-goal problems. As shown\nby the experiments of this paper, SNEAK asks for very few labels (30, or even\nless) even for models with 1000 variables and state spaces of $2^{1000}$\npossibilities. Also, the optimization solutions found in this way were within\nthe best 1\\% of the entire space of solutions. Further, due to the logarithmic\nnature of its search, in theory, SNEAK should scale well to very large\nproblems. Accordingly, we recommend SNEAKing since, at the very least, it is a\nbaseline architecture against which other iSBSE work can be compared. To enable\nthat comparison, all of ours scripts are available at\nhttps://github.com/zxcv123456qwe/sneak.",
    "descriptor": "",
    "authors": [
      "Andre Lustosa",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02922"
  },
  {
    "id": "arXiv:2110.02924",
    "title": "No-Press Diplomacy from Scratch",
    "abstract": "Prior AI successes in complex games have largely focused on settings with at\nmost hundreds of actions at each decision point. In contrast, Diplomacy is a\ngame with more than 10^20 possible actions per turn. Previous attempts to\naddress games with large branching factors, such as Diplomacy, StarCraft, and\nDota, used human data to bootstrap the policy or used handcrafted reward\nshaping. In this paper, we describe an algorithm for action exploration and\nequilibrium approximation in games with combinatorial action spaces. This\nalgorithm simultaneously performs value iteration while learning a policy\nproposal network. A double oracle step is used to explore additional actions to\nadd to the policy proposals. At each state, the target state value and policy\nfor the model training are computed via an equilibrium search procedure. Using\nthis algorithm, we train an agent, DORA, completely from scratch for a popular\ntwo-player variant of Diplomacy and show that it achieves superhuman\nperformance. Additionally, we extend our methods to full-scale no-press\nDiplomacy and for the first time train an agent from scratch with no human\ndata. We present evidence that this agent plays a strategy that is incompatible\nwith human-data bootstrapped agents. This presents the first strong evidence of\nmultiple equilibria in Diplomacy and suggests that self play alone may be\ninsufficient for achieving superhuman performance in Diplomacy.",
    "descriptor": "",
    "authors": [
      "Anton Bakhtin",
      "David Wu",
      "Adam Lerer",
      "Noam Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.02924"
  },
  {
    "id": "arXiv:2110.02926",
    "title": "On the Global Convergence of Gradient Descent for multi-layer ResNets in  the mean-field regime",
    "abstract": "Finding the optimal configuration of parameters in ResNet is a nonconvex\nminimization problem, but first-order methods nevertheless find the global\noptimum in the overparameterized regime. We study this phenomenon with\nmean-field analysis, by translating the training process of ResNet to a\ngradient-flow partial differential equation (PDE) and examining the convergence\nproperties of this limiting process. The activation function is assumed to be\n$2$-homogeneous or partially $1$-homogeneous; the regularized ReLU satisfies\nthe latter condition. We show that if the ResNet is sufficiently large, with\ndepth and width depending algebraically on the accuracy and confidence levels,\nfirst-order optimization methods can find global minimizers that fit the\ntraining data.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.14417\n",
    "authors": [
      "Zhiyan Ding",
      "Shi Chen",
      "Qin Li",
      "Stephen Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02926"
  },
  {
    "id": "arXiv:2110.02929",
    "title": "Adversarial Attacks on Spiking Convolutional Networks for Event-based  Vision",
    "abstract": "Event-based sensing using dynamic vision sensors is gaining traction in\nlow-power vision applications. Spiking neural networks work well with the\nsparse nature of event-based data and suit deployment on low-power neuromorphic\nhardware. Being a nascent field, the sensitivity of spiking neural networks to\npotentially malicious adversarial attacks has received very little attention so\nfar. In this work, we show how white-box adversarial attack algorithms can be\nadapted to the discrete and sparse nature of event-based visual data, and to\nthe continuous-time setting of spiking neural networks. We test our methods on\nthe N-MNIST and IBM Gestures neuromorphic vision datasets and show adversarial\nperturbations achieve a high success rate, by injecting a relatively small\nnumber of appropriately placed events. We also verify, for the first time, the\neffectiveness of these perturbations directly on neuromorphic hardware.\nFinally, we discuss the properties of the resulting perturbations and possible\nfuture directions.",
    "descriptor": "\nComments: 16 pages, preprint, submitted to ICLR 2022\n",
    "authors": [
      "Julian B\u00fcchel",
      "Gregor Lenz",
      "Yalun Hu",
      "Sadique Sheik",
      "Martino Sorbaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02929"
  },
  {
    "id": "arXiv:2110.02930",
    "title": "\"What Artists Want\": Elicitation of Artist Requirements to Feed the  Design on a New Collaboration Platform for Creative Work",
    "abstract": "Aiming at designing a decentralized platform to support grassroot initiatives\nfor self-organized creative work, the present work solicited feedback from a\ngroup of visual artists regarding their work processes and concerns. The paper\npresents the qualitative methodology followed for collecting requirements from\nthe target audience of the envisioned software solution. The data gathered from\nthe focus group is analyzed and we conclude with a set of important\nrequirements that the future platform needs to fulfill.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Angeliki Antoniou",
      "Ioanna Lykourentzou",
      "Antonios Liapis",
      "Dimitra Nikolou",
      "Marily Konstantinopoulou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02930"
  },
  {
    "id": "arXiv:2110.02932",
    "title": "Machine Learning Practices Outside Big Tech: How Resource Constraints  Challenge Responsible Development",
    "abstract": "Practitioners from diverse occupations and backgrounds are increasingly using\nmachine learning (ML) methods. Nonetheless, studies on ML Practitioners\ntypically draw populations from Big Tech and academia, as researchers have\neasier access to these communities. Through this selection bias, past research\noften excludes the broader, lesser-resourced ML community -- for example,\npractitioners working at startups, at non-tech companies, and in the public\nsector. These practitioners share many of the same ML development difficulties\nand ethical conundrums as their Big Tech counterparts; however, their\nexperiences are subject to additional under-studied challenges stemming from\ndeploying ML with limited resources, increased existential risk, and absent\naccess to in-house research teams. We contribute a qualitative analysis of 17\ninterviews with stakeholders from organizations which are less represented in\nprior studies. We uncover a number of tensions which are introduced or\nexacerbated by these organizations' resource constraints -- tensions between\nprivacy and ubiquity, resource management and performance optimization, and\naccess and monopolization. Increased academic focus on these practitioners can\nfacilitate a more holistic understanding of ML limitations, and so is useful\nfor prescribing a research agenda to facilitate responsible ML development for\nall.",
    "descriptor": "",
    "authors": [
      "Aspen Hopkins",
      "Serena Booth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.02932"
  },
  {
    "id": "arXiv:2110.02933",
    "title": "On Cropped versus Uncropped Training Sets in Tabular Structure Detection",
    "abstract": "Automated document processing for tabular information extraction is highly\ndesired in many organizations, from industry to government. Prior works have\naddressed this problem under table detection and table structure detection\ntasks. Proposed solutions leveraging deep learning approaches have been giving\npromising results in these tasks. However, the impact of dataset structures on\ntable structure detection has not been investigated. In this study, we provide\na comparison of table structure detection performance with cropped and\nuncropped datasets. The cropped set consists of only table images that are\ncropped from documents assuming tables are detected perfectly. The uncropped\nset consists of regular document images. Experiments show that deep learning\nmodels can improve the detection performance by up to 9% in average precision\nand average recall on the cropped versions. Furthermore, the impact of cropped\nimages is negligible under the Intersection over Union (IoU) values of 50%-70%\nwhen compared to the uncropped versions. However, beyond 70% IoU thresholds,\ncropped datasets provide significantly higher detection performance.",
    "descriptor": "",
    "authors": [
      "Yakup Akkaya",
      "Murat Simsek",
      "Burak Kantarci",
      "Shahzad Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02933"
  },
  {
    "id": "arXiv:2110.02938",
    "title": "Deployment of Polar Codes for Mission-Critical Machine-Type  Communication Over Wireless Networks",
    "abstract": "Mission critical Machine-type Communication, also referred to as\nUltra-reliable Low Latency Communication is primarily characterized by\ncommunication that provides ultra-high reliability and very low latency to\nconcurrently transmit short commands to a massive number of connected devices.\nWhile the reduction in PHY layer overhead and improvement in channel coding\ntechniques are pivotal in reducing latency and improving reliability, the\ncurrent wireless standards dedicated to support mcMTC rely heavily on adopting\nthe bottom layers of general-purpose wireless standards and customizing only\nthe upper layers. The mcMTC has a significant technical impact on the design of\nall layers of the communication protocol stack. In this paper, an innovative\nbottom-up approach has been proposed for mcMTC applications through PHY layer\ntargeted at improving the transmission reliability by implementing\nultra-reliable channel coding scheme in the PHY layer of IEEE 802.11a bearing\nin mind short packet transmission system. To achieve this aim, we analyzed and\ncompared the channel coding performance of convolutional codes, LDPC codes, and\npolar codes in wireless network on the condition of short data packet\ntransmission. The Viterbi decoding algorithm, logarithmic belief propagation\nalgorithm, and cyclic redundancy check - successive cancellation list decoding\nalgorithm were adopted to CC, LDPC codes, and polar codes, respectively.\nConsequently, a new PHY layer for mcMTC has been proposed. The reliability of\nthe proposed approach has been validated by simulation in terms of Bit error\nrate vs. SNR. The simulation results demonstrate that the reliability of IEEE\n802.11a standard has been significantly improved to be at PER less 10e-5 with\nthe implementation of polar codes. The results also show that the\ngeneral-purpose wireless networks are prominent in providing short packet mcMTC\nwith the modification needed.",
    "descriptor": "\nComments: Cited under CMC journal and paper id: 20462\n",
    "authors": [
      "Najib Ahmed Mohammed",
      "Ali Mohammed Mansoor",
      "Rodina Binti Ahmad",
      "Saaidal Razalli Bin Azzuhri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02938"
  },
  {
    "id": "arXiv:2110.02940",
    "title": "Secure Byzantine-Robust Distributed Learning via Clustering",
    "abstract": "Federated learning systems that jointly preserve Byzantine robustness and\nprivacy have remained an open problem. Robust aggregation, the standard defense\nfor Byzantine attacks, generally requires server access to individual updates\nor nonlinear computation -- thus is incompatible with privacy-preserving\nmethods such as secure aggregation via multiparty computation. To this end, we\npropose SHARE (Secure Hierarchical Robust Aggregation), a distributed learning\nframework designed to cryptographically preserve client update privacy and\nrobustness to Byzantine adversaries simultaneously. The key idea is to\nincorporate secure averaging among randomly clustered clients before filtering\nmalicious updates through robust aggregation. Experiments show that SHARE has\nsimilar robustness guarantees as existing techniques while enhancing privacy.",
    "descriptor": "\nComments: 18 pages, 9 Figures\n",
    "authors": [
      "Raj Kiriti Velicheti",
      "Derek Xia",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02940"
  },
  {
    "id": "arXiv:2110.02948",
    "title": "Topologically Consistent Multi-View Face Inference Using Volumetric  Sampling",
    "abstract": "High-fidelity face digitization solutions often combine multi-view stereo\n(MVS) techniques for 3D reconstruction and a non-rigid registration step to\nestablish dense correspondence across identities and expressions. A common\nproblem is the need for manual clean-up after the MVS step, as 3D scans are\ntypically affected by noise and outliers and contain hairy surface regions that\nneed to be cleaned up by artists. Furthermore, mesh registration tends to fail\nfor extreme facial expressions. Most learning-based methods use an underlying\n3D morphable model (3DMM) to ensure robustness, but this limits the output\naccuracy for extreme facial expressions. In addition, the global bottleneck of\nregression architectures cannot produce meshes that tightly fit the ground\ntruth surfaces. We propose ToFu, Topologically consistent Face from multi-view,\na geometry inference framework that can produce topologically consistent meshes\nacross facial identities and expressions using a volumetric representation\ninstead of an explicit underlying 3DMM. Our novel progressive mesh generation\nnetwork embeds the topological structure of the face in a feature volume,\nsampled from geometry-aware local features. A coarse-to-fine architecture\nfacilitates dense and accurate facial mesh predictions in a consistent mesh\ntopology. ToFu further captures displacement maps for pore-level geometric\ndetails and facilitates high-quality rendering in the form of albedo and\nspecular reflectance maps. These high-quality assets are readily usable by\nproduction studios for avatar creation, animation and physically-based skin\nrendering. We demonstrate state-of-the-art geometric and correspondence\naccuracy, while only taking 0.385 seconds to compute a mesh with 10K vertices,\nwhich is three orders of magnitude faster than traditional techniques. The code\nand the model are available for research purposes at\nhttps://tianyeli.github.io/tofu.",
    "descriptor": "\nComments: International Conference on Computer Vision (ICCV)\n",
    "authors": [
      "Tianye Li",
      "Shichen Liu",
      "Timo Bolkart",
      "Jiayi Liu",
      "Hao Li",
      "Yajie Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02948"
  },
  {
    "id": "arXiv:2110.02950",
    "title": "Self-Supervised Knowledge Assimilation for Expert-Layman Text Style  Transfer",
    "abstract": "Expert-layman text style transfer technologies have the potential to improve\ncommunication between members of scientific communities and the general public.\nHigh-quality information produced by experts is often filled with difficult\njargon laypeople struggle to understand. This is a particularly notable issue\nin the medical domain, where layman are often confused by medical text online.\nAt present, two bottlenecks interfere with the goal of building high-quality\nmedical expert-layman style transfer systems: a dearth of pretrained\nmedical-domain language models spanning both expert and layman terminologies\nand a lack of parallel corpora for training the transfer task itself. To\nmitigate the first issue, we propose a novel language model (LM) pretraining\ntask, Knowledge Base Assimilation, to synthesize pretraining data from the\nedges of a graph of expert- and layman-style medical terminology terms into an\nLM during self-supervised learning. To mitigate the second issue, we build a\nlarge-scale parallel corpus in the medical expert-layman domain using a\nmargin-based criterion. Our experiments show that transformer-based models\npretrained on knowledge base assimilation and other well-established\npretraining tasks fine-tuning on our new parallel corpus leads to considerable\nimprovement against expert-layman transfer benchmarks, gaining an average\nrelative improvement of our human evaluation, the Overall Success Rate (OSR),\nby 106%.",
    "descriptor": "\nComments: 12 pages, 8 tables, 3 figures\n",
    "authors": [
      "Wenda Xu",
      "Michael Saxon",
      "Misha Sra",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02950"
  },
  {
    "id": "arXiv:2110.02951",
    "title": "Video Autoencoder: self-supervised disentanglement of static 3D  structure and motion",
    "abstract": "A video autoencoder is proposed for learning disentan- gled representations\nof 3D structure and camera pose from videos in a self-supervised manner.\nRelying on temporal continuity in videos, our work assumes that the 3D scene\nstructure in nearby video frames remains static. Given a sequence of video\nframes as input, the video autoencoder extracts a disentangled representation\nof the scene includ- ing: (i) a temporally-consistent deep voxel feature to\nrepresent the 3D structure and (ii) a 3D trajectory of camera pose for each\nframe. These two representations will then be re-entangled for rendering the\ninput video frames. This video autoencoder can be trained directly using a\npixel reconstruction loss, without any ground truth 3D or camera pose\nannotations. The disentangled representation can be applied to a range of\ntasks, including novel view synthesis, camera pose estimation, and video\ngeneration by motion following. We evaluate our method on several large- scale\nnatural video datasets, and show generalization results on out-of-domain\nimages.",
    "descriptor": "\nComments: Accepted to ICCV 2021. Project page: this https URL\n",
    "authors": [
      "Zihang Lai",
      "Sifei Liu",
      "Alexei A. Efros",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02951"
  },
  {
    "id": "arXiv:2110.01866",
    "title": "Social physics",
    "abstract": "Recent decades have seen a rise in the use of physics-inspired or\nphysics-like methods in attempts to resolve diverse societal problems. Such a\nrise is driven both by physicists venturing outside of their traditional domain\nof interest, but also by scientists from other domains who wish to mimic the\nenormous success of physics throughout the 19th and 20th century. Here, we dub\nthe physics-inspired and physics-like work on societal problems \"social\nphysics\", and pay our respect to intellectual mavericks who nurtured the field\nto its maturity. We do so by comprehensively (but not exhaustively) reviewing\nthe current state of the art. Starting with a set of topics that pertain to the\nmodern way of living and factors that enable humankind's prosperous existence,\nwe discuss urban development and traffic, the functioning of financial markets,\ncooperation as a basis for civilised life, the structure of (social) networks,\nand the integration of intelligent machines in such networks. We then shift\nfocus to a set of topics that explore potential threats to humanity. These\ninclude criminal behaviour, massive migrations, contagions, environmental\nproblems, and finally climate change. The coverage of each topic is ended with\nideas for future progress. Based on the number of ideas laid out, but also on\nthe fact that the field is already too big for an exhaustive review despite our\nbest efforts, we are forced to conclude that the future for social physics is\nbright. Physicists tackling societal problems are no longer a curiosity, but\nrather a force to be reckoned with, yet for reckoning to be truly productive,\nit is necessary to build dialog and mutual understanding with social\nscientists, environmental scientists, philosophers, and more.",
    "descriptor": "\nComments: 358 pages, 78 figures; submitted to Physics Reports\n",
    "authors": [
      "Marko Jusup",
      "Petter Holme",
      "Kiyoshi Kanazawa",
      "Misako Takayasu",
      "Ivan Romic",
      "Zhen Wang",
      "Suncana Gecek",
      "Tomislav Lipic",
      "Boris Podobnik",
      "Lin Wang",
      "Wei Luo",
      "Tin Klanjscek",
      "Jingfang Fan",
      "Stefano Boccaletti",
      "Matjaz Perc"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2110.01866"
  },
  {
    "id": "arXiv:2110.02220",
    "title": "Fast Contextual Adaptation with Neural Associative Memory for On-Device  Personalized Speech Recognition",
    "abstract": "Fast contextual adaptation has shown to be effective in improving Automatic\nSpeech Recognition (ASR) of rare words and when combined with an on-device\npersonalized training, it can yield an even better recognition result. However,\nthe traditional re-scoring approaches based on an external language model is\nprone to diverge during the personalized training. In this work, we introduce a\nmodel-based end-to-end contextual adaptation approach that is decoder-agnostic\nand amenable to on-device personalization. Our on-device simulation experiments\ndemonstrate that the proposed approach outperforms the traditional re-scoring\ntechnique by 12% relative WER and 15.7% entity mention specific F1-score in a\ncontinues personalization scenario.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Tsendsuren Munkhdalai",
      "Khe Chai Sim",
      "Angad Chandorkar",
      "Fan Gao",
      "Mason Chua",
      "Trevor Strohman",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.02220"
  },
  {
    "id": "arXiv:2110.02222",
    "title": "Hybrid Classical-Quantum method for Diabetic Foot Ulcer Classification",
    "abstract": "Diabetes is a raising problem that affects many people globally. Diabetic\npatients are at risk of developing foot ulcer that usually leads to limb\namputation, causing significant morbidity, and psychological distress. In order\nto develop a self monitoring mobile application, it is necessary to be able to\nclassify such ulcers into either of the following classes: Infection,\nIschaemia, None, or Both. In this work, we compare the performance of a\nclassical transfer-learning-based method, with the performance of a hybrid\nclassical-quantum Classifier on diabetic foot ulcer classification task. As\nsuch, we merge the pre-trained Xception network with a multi-class variational\nclassifier. Thus, after modifying and re-training the Xception network, we\nextract the output of a mid-layer and employ it as deep-features presenters of\nthe given images. Finally, we use those deep-features to train multi-class\nvariational classifier, where each classifier is implemented on an individual\nvariational circuit. The method is then evaluated on the blind test set\nDFUC2021. The results proves that our proposed hybrid classical-quantum\nClassifier leads to considerable improvement compared to solely relying on\ntransfer learning concept through training the modified version of Xception\nnetwork.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.01795\n",
    "authors": [
      "Azadeh Alavi",
      "Hossein Akhoundi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02222"
  },
  {
    "id": "arXiv:2110.02250",
    "title": "Measuring chemical likeness of stars with RSCA",
    "abstract": "Identification of chemically similar stars using elemental abundances is core\nto many pursuits within Galactic archaeology. However, measuring the chemical\nlikeness of stars using abundances directly is limited by systematic imprints\nof imperfect synthetic spectra in abundance derivation. We present a novel\ndata-driven model that is capable of identifying chemically similar stars from\nspectra alone. We call this Relevant Scaled Component Analysis (RSCA). RSCA\nfinds a mapping from stellar spectra to a representation that optimizes\nrecovery of known open clusters. By design, RSCA amplifies factors of chemical\nabundance variation and minimizes those of non-chemical parameters, such as\ninstrument systematics. The resultant representation of stellar spectra can\ntherefore be used for precise measurements of chemical similarity between\nstars. We validate RSCA using 185 cluster stars in 22 open clusters in the\nAPOGEE survey. We quantify our performance in measuring chemical similarity\nusing a reference set of 151,145 field stars. We find that our representation\nidentifies known stellar siblings more effectively than stellar abundance\nmeasurements. Using RSCA, 1.8% of pairs of field stars are as similar as birth\nsiblings, compared to 2.3% when using stellar abundance labels. We find that\nalmost all of the information within spectra leveraged by RSCA fits into a\ntwo-dimensional basis, which we link to [Fe/H] and alpha-element abundances. We\nconclude that chemical tagging of stars to their birth clusters remains\nprohibitive. However, using the spectra has noticeable gain, and our approach\nis poised to benefit from larger datasets and improved algorithm designs.",
    "descriptor": "\nComments: submitted to ApJ, 16 pages, code:this https URL\n",
    "authors": [
      "Damien de Mijolla",
      "Melissa K. Ness"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02250"
  },
  {
    "id": "arXiv:2110.02273",
    "title": "Bilevel Imaging Learning Problems as Mathematical Programs with  Complementarity Constraints",
    "abstract": "We investigate a family of bilevel imaging learning problems where the\nlower-level instance corresponds to a convex variational model involving first-\nand second-order nonsmooth regularizers. By using geometric properties of the\nprimal-dual reformulation of the lower-level problem and introducing suitable\nchanges of variables, we are able to reformulate the original bilevel problems\nas Mathematical Programs with Complementarity Constraints (MPCC). For the\nlatter, we prove tight constraint qualification conditions (MPCC-MFCQ and\npartial MPCC-LICQ) and derive Mordukovich (M-) and Strong (S-) stationarity\nconditions. The S-stationarity system for the MPCC turns also into\nS-stationarity conditions for the original formulation. Second-order sufficient\noptimality conditions are derived as well. The proposed reformulation may be\nextended to problems in function spaces, leading to MPCC's with additional\nconstraints on the gradient of the state. Finally, we report on some numerical\nresults obtained by using the proposed MPCC reformulations together with\navailable large-scale nonlinear programming solvers.",
    "descriptor": "",
    "authors": [
      "Juan Carlos De los Reyes",
      "David Villac\u00eds"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02273"
  },
  {
    "id": "arXiv:2110.02279",
    "title": "Turing approximations, toric isometric embeddings & manifold  convolutions",
    "abstract": "Convolutions are fundamental elements in deep learning architectures. Here,\nwe present a theoretical framework for combining extrinsic and intrinsic\napproaches to manifold convolution through isometric embeddings into tori. In\nthis way, we define a convolution operator for a manifold of arbitrary topology\nand dimension. We also explain geometric and topological conditions that make\nsome local definitions of convolutions which rely on translating filters along\ngeodesic paths on a manifold, computationally intractable. A result of Alan\nTuring from 1938 underscores the need for such a toric isometric embedding\napproach to achieve a global definition of convolution on computable, finite\nmetric space approximations to a smooth manifold.",
    "descriptor": "\nComments: 31 pages, 5 figures\n",
    "authors": [
      "P. Su\u00e1rez-Serrato"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02279"
  },
  {
    "id": "arXiv:2110.02285",
    "title": "Modelling of the Fender Bassman 5F6-A Tone Stack",
    "abstract": "This paper outlines the procedure for the effective modelling of a complex\nanalogue filter circuit. The Fender Bassman 5F6-A is a circuit commonly\nemployed in guitar amplifiers to shape the tonal characteristics of the\namplifier output. On first inspection this circuit may look rather simple,\nhowever the controls are not orthogonal, resulting in complicated filter\ncoefficients as the controls are varied. This in turn can make the circuit\ndifficult to analyse without the use of mathematical emulation tools such as\nPSPICE or MATLAB. First the circuit is described, a method of analysis is\nproposed and general expressions for continuous-time coefficients are given. A\nMATLAB model is then produced and the frequency responses of which are shown.",
    "descriptor": "\nComments: 5 pages, 6 figues. General Reference Paper\n",
    "authors": [
      "Steven Fenton"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02285"
  },
  {
    "id": "arXiv:2110.02296",
    "title": "On the Correspondence between Gaussian Processes and Geometric Harmonics",
    "abstract": "We discuss the correspondence between Gaussian process regression and\nGeometric Harmonics, two similar kernel-based methods that are typically used\nin different contexts. Research communities surrounding the two concepts often\npursue different goals. Results from both camps can be successfully combined,\nproviding alternative interpretations of uncertainty in terms of error\nestimation, or leading towards accelerated Bayesian Optimization due to\ndimensionality reduction.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Felix Dietrich",
      "Juan M. Bello-Rivas",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02296"
  },
  {
    "id": "arXiv:2110.02297",
    "title": "Robustness modularity in complex networks",
    "abstract": "A basic question in network community detection is how modular a given\nnetwork is. This is usually addressed by evaluating the quality of partitions\ndetected in the network. The Girvan-Newman (GN) modularity function is the\nstandard way to make this assessment, but it has a number of drawbacks. Most\nimportantly, it is not clearly interpretable, given that the measure can take\nrelatively large values on partitions of random networks without communities.\nHere we propose a new measure based on the concept of robustness: modularity is\nthe probability to find trivial partitions when the structure of the network is\nrandomly perturbed. This concept can be implemented for any clustering\nalgorithm capable of telling when a group structure is absent. Tests on\nartificial and real graphs reveal that robustness modularity can be used to\nassess and compare the strength of the community structure of different\nnetworks. We also introduce two other quality functions: modularity difference,\na suitably normalized version of the GN modularity; information modularity, a\nmeasure of distance based on information compression. Both measures are\nstrongly correlated with robustness modularity, and are promising options as\nwell.",
    "descriptor": "\nComments: 17 pages, 16 figures. Code to calculated the proposed measures is freely available here: this https URL\n",
    "authors": [
      "Filipi N. Silva",
      "Aiiad Albeshri",
      "Vijey Thayananthan",
      "Wadee Alhalabi",
      "Santo Fortunato"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2110.02297"
  },
  {
    "id": "arXiv:2110.02298",
    "title": "Tradeoffs in Hierarchical Voting Systems",
    "abstract": "Condorcet's jury theorem states that the correct outcome is reached in direct\nmajority voting systems with sufficiently large electorates as long as each\nvoter's independent probability of voting for that outcome is greater than 0.5.\nYet, in situations where direct voting systems are infeasible, such as due to\nhigh implementation and infrastructure costs, hierarchical voting systems\nprovide a reasonable alternative. We study differences in outcome precision\nbetween hierarchical and direct voting systems for varying group sizes,\nabstention rates, and voter competencies. Using asymptotic expansions of the\nderivative of the reliability function (or Banzhaf number), we first prove that\nindirect systems differ most from their direct counterparts when group size and\nnumber are equal to each other, and therefore to $\\sqrt{N_{\\rm d}}$, where\n$N_{\\rm d}$ is the total number of voters in the direct system. In multitier\nsystems, we prove that this difference is maximized when group size equals\n$\\sqrt[n]{N_{\\rm d}}$, where $n$ is the number of hierarchical levels. Second,\nwe show that while direct majority rule always outperforms hierarchical voting\nfor homogeneous electorates that vote with certainty, as group numbers and size\nincrease, hierarchical majority voting gains in its ability to represent all\neligible voters. Furthermore, when voter abstention and competency are\ncorrelated within groups, hierarchical systems often outperform direct voting,\nwhich we show by using a generating function approach that is able to\nanalytically characterize heterogeneous voting systems.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Georgia Kernell"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.02298"
  },
  {
    "id": "arXiv:2110.02321",
    "title": "Enhancement of Anime Imaging Enlargement using Modified Super-Resolution  CNN",
    "abstract": "Anime is a storytelling medium similar to movies and books. Anime images are\na kind of artworks, which are almost entirely drawn by hand. Hence, reproducing\nexisting Anime with larger sizes and higher quality images is expensive.\nTherefore, we proposed a model based on convolutional neural networks to\nextract outstanding features of images, enlarge those images, and enhance the\nquality of Anime images. We trained the model with a training set of 160 images\nand a validation set of 20 images. We tested the trained model with a testing\nset of 20 images. The experimental results indicated that our model\nsuccessfully enhanced the image quality with a larger image-size when compared\nwith the common existing image enlargement and the original SRCNN method.",
    "descriptor": "\nComments: 6 pages, 11 figures, to be published in The 11th Joint Symposium on Computational Intelligence (JSCI11)\n",
    "authors": [
      "Tanakit Intaniyom",
      "Warinthorn Thananporn",
      "Kuntpong Woraratpanya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02321"
  },
  {
    "id": "arXiv:2110.02337",
    "title": "Reactive Power Markets for the Future Grid",
    "abstract": "As pressures to decarbonize the electricity grid increase, the grid edge is\nwitnessing a rapid adoption of distributed and renewable generation. As a\nresult, traditional methods for reactive power management and compensation may\nbecome ineffective. Current state of art for reactive power compensation, which\nrely primarily on capacity payments, exclude distributed generation (DG). We\npropose an alternative: a reactive power market at the distribution level. The\nproposed market uses variable payments to compensate DGs equipped with smart\ninverters, at an increased spatial and temporal granularity, through a\ndistribution-level Locational Marginal Price (d-LMP). We validate our proposed\nmarket with a case study of the New England grid on a modified IEEE-123 bus,\nwhile varying DG penetration from 5% to 160%. Results show that our market can\naccommodate such a large penetration, with stable reactive power revenue\nstreams. The market can leverage the considerable flexibility afforded by\ninverter-based resources to meet over 40% of reactive power load when operating\nin a power factor range of 0.6 to 0.95. DGs participating in the market can\nearn up to 11% of their total revenue from reactive power payments. Finally,\nthe corresponding daily d-LMPs determined from the proposed market were\nobserved to exhibit limited volatility.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Adam Potter",
      "Rabab Haider",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02337"
  },
  {
    "id": "arXiv:2110.02343",
    "title": "Quantum Semi-Supervised Learning with Quantum Supremacy",
    "abstract": "Quantum machine learning promises to efficiently solve important problems.\nThere are two persistent challenges in classical machine learning: the lack of\nlabeled data, and the limit of computational power. We propose a novel\nframework that resolves both issues: quantum semi-supervised learning.\nMoreover, we provide a protocol in systematically designing quantum machine\nlearning algorithms with quantum supremacy, which can be extended beyond\nquantum semi-supervised learning. We showcase two concrete quantum\nsemi-supervised learning algorithms: a quantum self-training algorithm named\nthe propagating nearest-neighbor classifier, and the quantum semi-supervised\nK-means clustering algorithm. By doing time complexity analysis, we conclude\nthat they indeed possess quantum supremacy.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zhou Shangnan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2110.02343"
  },
  {
    "id": "arXiv:2110.02345",
    "title": "Unsupervised Speech Segmentation and Variable Rate Representation  Learning using Segmental Contrastive Predictive Coding",
    "abstract": "Typically, unsupervised segmentation of speech into the phone and word-like\nunits are treated as separate tasks and are often done via different methods\nwhich do not fully leverage the inter-dependence of the two tasks. Here, we\nunify them and propose a technique that can jointly perform both, showing that\nthese two tasks indeed benefit from each other. Recent attempts employ\nself-supervised learning, such as contrastive predictive coding (CPC), where\nthe next frame is predicted given past context. However, CPC only looks at the\naudio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework to model the signal\nstructure at a higher level, e.g., phone level. A convolutional neural network\nlearns frame-level representation from the raw waveform via noise-contrastive\nestimation (NCE). A differentiable boundary detector finds variable-length\nsegments, which are then used to optimize a segment encoder via NCE to learn\nsegment representations. The differentiable boundary detector allows us to\ntrain frame-level and segment-level encoders jointly. Experiments show that our\nsingle model outperforms existing phone and word segmentation methods on TIMIT\nand Buckeye datasets. We discover that phone class impacts the boundary\ndetection performance, and the boundaries between successive vowels or\nsemivowels are the most difficult to identify. Finally, we use SCPC to extract\nspeech features at the segment level rather than at uniformly spaced frame\nlevel (e.g., 10 ms) and produce variable rate representations that change\naccording to the contents of the utterance. We can lower the feature extraction\nrate from the typical 100 Hz to as low as 14.5 Hz on average while still\noutperforming the MFCC features on the linear phone classification task.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.02170\n",
    "authors": [
      "Saurabhchand Bhati",
      "Jes\u00fas Villalba",
      "Piotr \u017belasko",
      "Laureano Moro-Velazquez",
      "Najim Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02345"
  },
  {
    "id": "arXiv:2110.02360",
    "title": "Neural Pitch-Shifting and Time-Stretching with Controllable LPCNet",
    "abstract": "Modifying the pitch and timing of an audio signal are fundamental audio\nediting operations with applications in speech manipulation, audio-visual\nsynchronization, and singing voice editing and synthesis. Thus far, methods for\npitch-shifting and time-stretching that use digital signal processing (DSP)\nhave been favored over deep learning approaches due to their speed and\nrelatively higher quality. However, even existing DSP-based methods for\npitch-shifting and time-stretching induce artifacts that degrade audio quality.\nIn this paper, we propose Controllable LPCNet (CLPCNet), an improved LPCNet\nvocoder capable of pitch-shifting and time-stretching of speech. For objective\nevaluation, we show that CLPCNet performs pitch-shifting of speech on unseen\ndatasets with high accuracy relative to prior neural methods. For subjective\nevaluation, we demonstrate that the quality and naturalness of pitch-shifting\nand time-stretching with CLPCNet on unseen datasets meets or exceeds\ncompetitive neural- or DSP-based approaches.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Max Morrison",
      "Zeyu Jin",
      "Nicholas J. Bryan",
      "Juan-Pablo Caceres",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02360"
  },
  {
    "id": "arXiv:2110.02381",
    "title": "Robust Peak Detection for Holter ECGs by Self-Organized Operational  Neural Networks",
    "abstract": "Although numerous R-peak detectors have been proposed in the literature,\ntheir robustness and performance levels may significantly deteriorate in low\nquality and noisy signals acquired from mobile ECG sensors such as Holter\nmonitors. Recently, this issue has been addressed by deep 1D Convolutional\nNeural Networks (CNNs) that have achieved state-of-the-art performance levels\nin Holter monitors; however, they pose a high complexity level that requires\nspecial parallelized hardware setup for real-time processing. On the other\nhand, their performance deteriorates when a compact network configuration is\nused instead. This is an expected outcome as recent studies have demonstrated\nthat the learning performance of CNNs is limited due to their strictly\nhomogenous configuration with the sole linear neuron model. This has been\naddressed by Operational Neural Networks (ONNs) with their heterogenous network\nconfiguration encapsulating neurons with various non-linear operators. In this\nstudy, to further boost the peak detection performance along with an elegant\ncomputational efficiency, we propose 1D Self-Organized Operational Neural\nNetworks (Self-ONNs) with generative neurons. The most crucial advantage of 1D\nSelf-ONNs over the ONNs is their self-organization capability that voids the\nneed to search for the best operator set per neuron since each generative\nneuron has the ability to create the optimal operator during training. The\nexperimental results over the China Physiological Signal Challenge-2020 (CPSC)\ndataset with more than one million ECG beats show that the proposed 1D\nSelf-ONNs can significantly surpass the state-of-the-art deep CNN with less\ncomputational complexity. Results demonstrate that the proposed solution\nachieves 99.10% F1-score, 99.79% sensitivity, and 98.42% positive predictivity\nin the CPSC dataset which is the best R-peak detection performance ever\nachieved.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.02215\n",
    "authors": [
      "Serkan Kiranyaz",
      "Junaid Malik",
      "Muhammad Uzair Zahid",
      "Turker Ince",
      "Muhammad Chowdhury",
      "Amith Khandakar",
      "Anas Tahir",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02381"
  },
  {
    "id": "arXiv:2110.02388",
    "title": "Fast and Interpretable Consensus Clustering via Minipatch Learning",
    "abstract": "Consensus clustering has been widely used in bioinformatics and other\napplications to improve the accuracy, stability and reliability of clustering\nresults. This approach ensembles cluster co-occurrences from multiple\nclustering runs on subsampled observations. For application to large-scale\nbioinformatics data, such as to discover cell types from single-cell sequencing\ndata, for example, consensus clustering has two significant drawbacks: (i)\ncomputational inefficiency due to repeatedly applying clustering algorithms,\nand (ii) lack of interpretability into the important features for\ndifferentiating clusters. In this paper, we address these two challenges by\ndeveloping IMPACC: Interpretable MiniPatch Adaptive Consensus Clustering. Our\napproach adopts three major innovations. We ensemble cluster co-occurrences\nfrom tiny subsets of both observations and features, termed minipatches, thus\ndramatically reducing computation time. Additionally, we develop adaptive\nsampling schemes for observations, which result in both improved reliability\nand computational savings, as well as adaptive sampling schemes of features,\nwhich leads to interpretable solutions by quickly learning the most relevant\nfeatures that differentiate clusters. We study our approach on synthetic data\nand a variety of real large-scale bioinformatics data sets; results show that\nour approach not only yields more accurate and interpretable cluster solutions,\nbut it also substantially improves computational efficiency compared to\nstandard consensus clustering approaches.",
    "descriptor": "",
    "authors": [
      "Luqin Gan",
      "Genevera I. Allen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.02388"
  },
  {
    "id": "arXiv:2110.02417",
    "title": "CADA: Multi-scale Collaborative Adversarial Domain Adaptation for  Unsupervised Optic Disc and Cup Segmentation",
    "abstract": "The diversity of retinal imaging devices poses a significant challenge:\ndomain shift, which leads to performance degradation when applying the deep\nlearning models trained on one domain to new testing domains. In this paper, we\npropose a multi-scale input along with multiple domain adaptors applied\nhierarchically in both feature and output spaces. The proposed training\nstrategy and novel unsupervised domain adaptation framework, called\nCollaborative Adversarial Domain Adaptation (CADA), can effectively overcome\nthe challenge. Multi-scale inputs can reduce the information loss due to the\npooling layers used in the network for feature extraction, while our proposed\nCADA is an interactive paradigm that presents an exquisite collaborative\nadaptation through both adversarial learning and ensembling weights at\ndifferent network layers. In particular, to produce a better prediction for the\nunlabeled target domain data, we simultaneously achieve domain invariance and\nmodel generalizability via adversarial learning at multi-scale outputs from\ndifferent levels of network layers and maintaining an exponential moving\naverage (EMA) of the historical weights during training. Without annotating any\nsample from the target domain, multiple adversarial losses in encoder and\ndecoder layers guide the extraction of domain-invariant features to confuse the\ndomain classifier. Meanwhile, the ensembling of weights via EMA reduces the\nuncertainty of adapting multiple discriminator learning. Comprehensive\nexperimental results demonstrate that our CADA model incorporating multi-scale\ninput training can overcome performance degradation and outperform\nstate-of-the-art domain adaptation methods in segmenting retinal optic disc and\ncup from fundus images stemming from the REFUGE, Drishti-GS, and Rim-One-r3\ndatasets.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1910.07638\n",
    "authors": [
      "Peng Liu",
      "Charlie T. Tran",
      "Bin Kong",
      "Ruogu Fang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02417"
  },
  {
    "id": "arXiv:2110.02419",
    "title": "Feature Selection by a Mechanism Design",
    "abstract": "In constructing an econometric or statistical model, we pick relevant\nfeatures or variables from many candidates. A coalitional game is set up to\nstudy the selection problem where the players are the candidates and the payoff\nfunction is a performance measurement in all possible modeling scenarios. Thus,\nin theory, an irrelevant feature is equivalent to a dummy player in the game,\nwhich contributes nothing to all modeling situations. The hypothesis test of\nzero mean contribution is the rule to decide a feature is irrelevant or not. In\nour mechanism design, the end goal perfectly matches the expected model\nperformance with the expected sum of individual marginal effects. Within a\nclass of noninformative likelihood among all modeling opportunities, the\nmatching equation results in a specific valuation for each feature. After\nestimating the valuation and its standard deviation, we drop any candidate\nfeature if its valuation is not significantly different from zero. In the\nsimulation studies, our new approach significantly outperforms several popular\nmethods used in practice, and its accuracy is robust to the choice of the\npayoff function.",
    "descriptor": "\nComments: 15 pages, 2 figures, 1 table\n",
    "authors": [
      "Xingwei Hu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.02419"
  },
  {
    "id": "arXiv:2110.02456",
    "title": "VC dimension of partially quantized neural networks in the  overparametrized regime",
    "abstract": "Vapnik-Chervonenkis (VC) theory has so far been unable to explain the small\ngeneralization error of overparametrized neural networks. Indeed, existing\napplications of VC theory to large networks obtain upper bounds on VC dimension\nthat are proportional to the number of weights, and for a large class of\nnetworks, these upper bound are known to be tight. In this work, we focus on a\nclass of partially quantized networks that we refer to as hyperplane\narrangement neural networks (HANNs). Using a sample compression analysis, we\nshow that HANNs can have VC dimension significantly smaller than the number of\nweights, while being highly expressive. In particular, empirical risk\nminimization over HANNs in the overparametrized regime achieves the minimax\nrate for classification with Lipschitz posterior class probability. We further\ndemonstrate the expressivity of HANNs empirically. On a panel of 121 UCI\ndatasets, overparametrized HANNs match the performance of state-of-the-art\nfull-precision models.",
    "descriptor": "",
    "authors": [
      "Yutong Wang",
      "Clayton D. Scott"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02456"
  },
  {
    "id": "arXiv:2110.02474",
    "title": "Can an AI agent hit a moving target?",
    "abstract": "As the economies we live in are evolving over time, it is imperative that\neconomic agents in models form expectations that can adjust to changes in the\nenvironment. This exercise offers a plausible expectation formation model that\nconnects to computer science, psychology and neural science research on\nlearning and decision-making, and applies it to an economy with a policy regime\nchange. Employing the actor-critic model of reinforcement learning, the agent\nborn in a fresh environment learns through first interacting with the\nenvironment. This involves taking exploratory actions and observing the\ncorresponding stimulus signals. This interactive experience is then used to\nupdate its subjective belief about the world. I show, through several\nsimulation experiments, that the agent adjusts its subjective belief facing an\nincrease of inflation target. Moreover, the subjective belief evolves according\nto the agent's experience in the world.",
    "descriptor": "",
    "authors": [],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02474"
  },
  {
    "id": "arXiv:2110.02477",
    "title": "TSN-CA: A Two-Stage Network with Channel Attention for Low-Light Image  Enhancement",
    "abstract": "Low-light image enhancement is a challenging low-level computer vision task\nbecause after we enhance the brightness of the image, we have to deal with\namplified noise, color distortion, detail loss, blurred edges, shadow blocks\nand halo artifacts. In this paper, we propose a Two-Stage Network with Channel\nAttention (denoted as TSN-CA) to enhance the brightness of the low-light image\nand restore the enhanced images from various kinds of degradation. In the first\nstage, we enhance the brightness of the low-light image in HSV space and use\nthe information of H and S channels to help the recovery of details in V\nchannel. In the second stage, we integrate Channel Attention (CA) mechanism\ninto the skip connection of U-Net in order to restore the brightness-enhanced\nimage from severe kinds of degradation in RGB space. We train and evaluate the\nperformance of our proposed model on the LOL real-world and synthetic datasets.\nIn addition, we test our model on several other commonly used datasets without\nGround-Truth. We conduct extensive experiments to demonstrate that our method\nachieves excellent effect on brightness enhancement as well as denoising,\ndetails preservation and halo artifacts elimination. Our method outperforms\nmany other state-of-the-art methods qualitatively and quantitatively.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Xinxu Wei",
      "Xianshi Zhang",
      "Shisen Wang",
      "Yanlin Huang",
      "Yongjie Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02477"
  },
  {
    "id": "arXiv:2110.02479",
    "title": "Exponentially Many Local Minima in Quantum Neural Networks",
    "abstract": "Quantum Neural Networks (QNNs), or the so-called variational quantum\ncircuits, are important quantum applications both because of their similar\npromises as classical neural networks and because of the feasibility of their\nimplementation on near-term intermediate-size noisy quantum machines (NISQ).\nHowever, the training task of QNNs is challenging and much less understood. We\nconduct a quantitative investigation on the landscape of loss functions of QNNs\nand identify a class of simple yet extremely hard QNN instances for training.\nSpecifically, we show for typical under-parameterized QNNs, there exists a\ndataset that induces a loss function with the number of spurious local minima\ndepending exponentially on the number of parameters. Moreover, we show the\noptimality of our construction by providing an almost matching upper bound on\nsuch dependence. While local minima in classical neural networks are due to\nnon-linear activations, in quantum neural networks local minima appear as a\nresult of the quantum interference phenomenon. Finally, we empirically confirm\nthat our constructions can indeed be hard instances in practice with typical\ngradient-based optimizers, which demonstrates the practical value of our\nfindings.",
    "descriptor": "\nComments: 27 pages, 10 figures\n",
    "authors": [
      "Xuchen You",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02479"
  },
  {
    "id": "arXiv:2110.02483",
    "title": "Detecting and Quantifying Malicious Activity with Simulation-based  Inference",
    "abstract": "We propose the use of probabilistic programming techniques to tackle the\nmalicious user identification problem in a recommendation algorithm.\nProbabilistic programming provides numerous advantages over other techniques,\nincluding but not limited to providing a disentangled representation of how\nmalicious users acted under a structured model, as well as allowing for the\nquantification of damage caused by malicious users. We show experiments in\nmalicious user identification using a model of regular and malicious users\ninteracting with a simple recommendation algorithm, and provide a novel\nsimulation-based measure for quantifying the effects of a user or group of\nusers on its dynamics.",
    "descriptor": "\nComments: Short version, appeared at ICML workshop on Socially Responsible Machine Learning 2021\n",
    "authors": [
      "Andrew Gambardella",
      "Bogdan State",
      "Naemullah Khan",
      "Leo Tsourides",
      "Philip H. S. Torr",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.02483"
  },
  {
    "id": "arXiv:2110.02487",
    "title": "An Improved Approximation for Maximum $k$-Dependent Set on Bipartite  Graphs",
    "abstract": "We present a $(1+\\frac{k}{k+2})$-approximation algorithm for the Maximum\n$k$-dependent Set problem on bipartite graphs for any $k\\ge1$. For a graph with\n$n$ vertices and $m$ edges, the algorithm runs in $O(k m \\sqrt{n})$ time and\nimproves upon the previously best-known approximation ratio of\n$1+\\frac{k}{k+1}$ established by Kumar et al. [Theoretical Computer Science,\n526: 90--96 (2014)]. Our proof also indicates that the algorithm retains its\napproximation ratio when applied to the (more general) class of\nK\\\"{o}nig-Egerv\\'{a}ry graphs.",
    "descriptor": "",
    "authors": [
      "Seyedmohammadhossein Hosseinian",
      "Sergiy Butenko"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02487"
  },
  {
    "id": "arXiv:2110.02552",
    "title": "Policy iteration method for time-dependent Mean Field Games systems with  non-separable Hamiltonians",
    "abstract": "We introduce two algorithms based on a policy iteration method to numerically\nsolve time-dependent Mean Field Game systems of partial differential equations\nwith non-separable Hamiltonians. We prove the convergence of such algorithms in\nsufficiently small time intervals with Banach fixed point method. Moreover, we\nprove that the convergence rates are linear. We illustrate our theoretical\nresults by numerical examples, and we discuss the performance of the proposed\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Mathieu Lauri\u00e8re",
      "Jiahao Song",
      "Qing Tang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02552"
  },
  {
    "id": "arXiv:2110.02592",
    "title": "Improving Real-time Score Following in Opera by Combining Music with  Lyrics Tracking",
    "abstract": "Fully automatic opera tracking is challenging because of the acoustic\ncomplexity of the genre, combining musical and linguistic information (singing,\nspeech) in complex ways. In this paper, we propose a new pipeline for complete\nopera tracking. The pipeline is based on two trackers. A music tracker that has\nproven to be effective at tracking orchestral parts, will lead the tracking\nprocess. In addition, a lyrics tracker, that has recently been shown to\nreliably track the lyrics of opera songs, will correct the music tracker when\ntracking parts that have a text dominance over the music. We will demonstrate\nthe efficiency of this method on the opera Don Giovanni, showing that this\ntechnique helps improving accuracy and robustness of a complete opera tracker.",
    "descriptor": "\nComments: 5 pages, In Proceedings of the 2nd Workshop on NLP for Music and Audio (NLP4MusA), Online, 2021\n",
    "authors": [
      "Charles Brazier",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02592"
  },
  {
    "id": "arXiv:2110.02609",
    "title": "Deep Classifiers with Label Noise Modeling and Distance Awareness",
    "abstract": "Uncertainty estimation in deep learning has recently emerged as a crucial\narea of interest to advance reliability and robustness in safety-critical\napplications. While there have been many proposed methods that either focus on\ndistance-aware model uncertainties for out-of-distribution detection or on\ninput-dependent label uncertainties for in-distribution calibration, both of\nthese types of uncertainty are often necessary. In this work, we propose the\nHetSNGP method for jointly modeling the model and data uncertainty. We show\nthat our proposed model affords a favorable combination between these two\ncomplementary types of uncertainty and thus outperforms the baseline methods on\nsome challenging out-of-distribution datasets, including CIFAR-100C,\nImagenet-C, and Imagenet-A. Moreover, we propose HetSNGP Ensemble, an ensembled\nversion of our method which adds an additional type of uncertainty and also\noutperforms other ensemble baselines.",
    "descriptor": "",
    "authors": [
      "Vincent Fortuin",
      "Mark Collier",
      "Florian Wenzel",
      "James Allingham",
      "Jeremiah Liu",
      "Dustin Tran",
      "Balaji Lakshminarayanan",
      "Jesse Berent",
      "Rodolphe Jenatton",
      "Effrosyni Kokiopoulou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02609"
  },
  {
    "id": "arXiv:2110.02630",
    "title": "A New Conjecture About Identity of Proofs",
    "abstract": "A central problem in proof-theory is that of finding criteria for identity of\nproofs, that is, for when two distinct formal derivations can be taken as\ndenoting the same logical argument. In the literature one finds criteria which\nare either based on proof normalization (two derivations denote the same proofs\nwhen they have the same normal form) or on the association of formal\nderivations with graph-theoretic structures (two derivations denote they same\nproof when they are associated with the same graph). In this paper we argue for\na new criterion for identity of proofs which arises from the interpretation of\nformal rules and derivations as natural transformations of a suitable kind. We\nshow that the naturality conditions arising from this interpretation capture in\na uniform and elegant ways several forms of \"rule-permutations\" which are found\nin proof-systems for propositional, first- and second-order logic.",
    "descriptor": "",
    "authors": [
      "Paolo Pistone"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.02630"
  },
  {
    "id": "arXiv:2110.02636",
    "title": "Learning Sparse Masks for Diffusion-based Image Inpainting",
    "abstract": "Diffusion-based inpainting is a powerful tool for the reconstruction of\nimages from sparse data. Its quality strongly depends on the choice of known\ndata. Optimising their spatial location -- the inpainting mask -- is\nchallenging. A commonly used tool for this task are stochastic optimisation\nstrategies. However, they are slow as they compute multiple inpainting results.\nWe provide a remedy in terms of a learned mask generation model. By emulating\nthe complete inpainting pipeline with two networks for mask generation and\nneural surrogate inpainting, we obtain a model for highly efficient adaptive\nmask generation. Experiments indicate that our model can achieve competitive\nquality with an acceleration by as much as four orders of magnitude. Our\nfindings serve as a basis for making diffusion-based inpainting more attractive\nfor various applications such as image compression, where fast encoding is\nhighly desirable.",
    "descriptor": "",
    "authors": [
      "Tobias Alt",
      "Pascal Peter",
      "Joachim Weickert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02636"
  },
  {
    "id": "arXiv:2110.02657",
    "title": "Towards Robotic Knee Arthroscopy: Multi-Scale Network for Tissue-Tool  Segmentation",
    "abstract": "Tissue awareness has a great demand to improve surgical accuracy in minimally\ninvasive procedures. In arthroscopy, it is one of the challenging tasks due to\nsurgical sites exhibit limited features and textures. Moreover, arthroscopic\nsurgical video shows high intra-class variations. Arthroscopic videos are\nrecorded with endoscope known as arthroscope which records tissue structures at\nproximity, therefore, frames contain minimal joint structure. As consequences,\nfully conventional network-based segmentation model suffers from long- and\nshort- term dependency problems. In this study, we present a densely connected\nshape aware multi-scale segmentation model which captures multi-scale features\nand integrates shape features to achieve tissue-tool segmentations. The model\nhas been evaluated with three distinct datasets. Moreover, with the publicly\navailable polyp dataset our proposed model achieved 5.09 % accuracy\nimprovement.",
    "descriptor": "",
    "authors": [
      "Shahnewaz Ali",
      "Prof. Ross Crawford",
      "Dr. Frederic Maire",
      "Assoc. Prof. Ajay K. Pandey"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02657"
  },
  {
    "id": "arXiv:2110.02690",
    "title": "Tuning Confidence Bound for Stochastic Bandits with Bandit Distance",
    "abstract": "We propose a novel modification of the standard upper confidence bound (UCB)\nmethod for the stochastic multi-armed bandit (MAB) problem which tunes the\nconfidence bound of a given bandit based on its distance to others. Our UCB\ndistance tuning (UCB-DT) formulation enables improved performance as measured\nby expected regret by preventing the MAB algorithm from focusing on non-optimal\nbandits which is a well-known deficiency of standard UCB. \"Distance tuning\" of\nthe standard UCB is done using a proposed distance measure, which we call\nbandit distance, that is parameterizable and which therefore can be optimized\nto control the transition rate from exploration to exploitation based on\nproblem requirements. We empirically demonstrate increased performance of\nUCB-DT versus many existing state-of-the-art methods which use the UCB\nformulation for the MAB problem. Our contribution also includes the development\nof a conceptual tool called the \"Exploration Bargain Point\" which gives\ninsights into the tradeoffs between exploration and exploitation. We argue that\nthe Exploration Bargain Point provides an intuitive perspective that is useful\nfor comparatively analyzing the performance of UCB-based methods.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Srinjoy Das",
      "Ken Kreutz-Delgado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02690"
  },
  {
    "id": "arXiv:2110.02695",
    "title": "Interaural Coherence Across Frequency Channels Accounts for Binaural  Detection in Complex Maskers",
    "abstract": "Differences in interaural phase configuration between a target and a masker\ncan lead to substantial binaural unmasking. This effect is decreased for\nmasking noise having an interaural time difference (ITD). Adding a second noise\nwith the opposite ITD further reduces binaural unmasking. Thus far, simulation\nof the detection threshold required both a mechanism for internal ITD\ncompensation and an increased binaural processing bandwidth. An alternative\nexplanation for the reduction is that unmasking is impaired by the lower\ninteraural coherence in off-frequency regions caused by the second masker\n(Marquardt and McAlpine 2009, JASA pp. EL177 - EL182). Based on this hypothesis\nthe current work proposes a quantitative multi-channel model using monaurally\nderived peripheral filter bandwidths and an across-channel incoherence\ninterference mechanism. This mechanism differs from wider filters since it is\nmoot when the masker coherence is constant across frequency bands. Combined\nwith a monaural energy discrimination pathway, the model predicts the\ndifferences between single- and double-delayed noise, as well as four other\ndata sets. It can help resolving the inconsistency that simulation of some data\nsets requires wide filters while others require narrow filters.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Bernhard Eurich",
      "J\u00f6rg Encke",
      "Stephan D. Ewert",
      "Mathias Dietz"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02695"
  },
  {
    "id": "arXiv:2110.02715",
    "title": "Variance function estimation in regression model via aggregation  procedures",
    "abstract": "In the regression problem, we consider the problem of estimating the variance\nfunction by the means of aggregation methods. We focus on two particular\naggregation setting: Model Selection aggregation (MS) and Convex aggregation\n(C) where the goal is to select the best candidate and to build the best convex\ncombination of candidates respectively among a collection of candidates. In\nboth cases, the construction of the estimator relies on a two-step procedure\nand requires two independent samples. The first step exploits the first sample\nto build the candidate estimators for the variance function by the\nresidual-based method and then the second dataset is used to perform the\naggregation step. We show the consistency of the proposed method with respect\nto the L 2error both for MS and C aggregations. We evaluate the performance of\nthese two methods in the heteroscedastic model and illustrate their interest in\nthe regression problem with reject option.",
    "descriptor": "",
    "authors": [
      "Ahmed Zaoui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02715"
  },
  {
    "id": "arXiv:2110.02743",
    "title": "Towards efficient end-to-end speech recognition with  biologically-inspired neural networks",
    "abstract": "Automatic speech recognition (ASR) is a capability which enables a program to\nprocess human speech into a written form. Recent developments in artificial\nintelligence (AI) have led to high-accuracy ASR systems based on deep neural\nnetworks, such as the recurrent neural network transducer (RNN-T). However, the\ncore components and the performed operations of these approaches depart from\nthe powerful biological counterpart, i.e., the human brain. On the other hand,\nthe current developments in biologically-inspired ASR models, based on spiking\nneural networks (SNNs), lag behind in terms of accuracy and focus primarily on\nsmall scale applications. In this work, we revisit the incorporation of\nbiologically-plausible models into deep learning and we substantially enhance\ntheir capabilities, by taking inspiration from the diverse neural and synaptic\ndynamics found in the brain. In particular, we introduce neural connectivity\nconcepts emulating the axo-somatic and the axo-axonic synapses. Based on this,\nwe propose novel deep learning units with enriched neuro-synaptic dynamics and\nintegrate them into the RNN-T architecture. We demonstrate for the first time,\nthat a biologically realistic implementation of a large-scale ASR model can\nyield competitive performance levels compared to the existing deep learning\nmodels. Specifically, we show that such an implementation bears several\nadvantages, such as a reduced computational cost and a lower latency, which are\ncritical for speech recognition applications.",
    "descriptor": "",
    "authors": [
      "Thomas Bohnstingl",
      "Ayush Garg",
      "Stanis\u0142aw Wo\u017aniak",
      "George Saon",
      "Evangelos Eleftheriou",
      "Angeliki Pantazi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.02743"
  },
  {
    "id": "arXiv:2110.02780",
    "title": "Study on Transfer Learning Capabilities for Pneumonia Classification in  Chest-X-Rays Image",
    "abstract": "Over the last year, the severe acute respiratory syndrome coronavirus-2\n(SARS-CoV-2) and its variants have highlighted the importance of screening\ntools with high diagnostic accuracy for new illnesses such as COVID-19. To that\nregard, deep learning approaches have proven as effective solutions for\npneumonia classification, especially when considering chest-x-rays images.\nHowever, this lung infection can also be caused by other viral, bacterial or\nfungi pathogens. Consequently, efforts are being poured toward distinguishing\nthe infection source to help clinicians to diagnose the correct disease origin.\nFollowing this tendency, this study further explores the effectiveness of\nestablished neural network architectures on the pneumonia classification task\nthrough the transfer learning paradigm. To present a comprehensive comparison,\n12 well-known ImageNet pre-trained models were fine-tuned and used to\ndiscriminate among chest-x-rays of healthy people, and those showing pneumonia\nsymptoms derived from either a viral (i.e., generic or SARS-CoV-2) or bacterial\nsource. Furthermore, since a common public collection distinguishing between\nsuch categories is currently not available, two distinct datasets of\nchest-x-rays images, describing the aforementioned sources, were combined and\nemployed to evaluate the various architectures. The experiments were performed\nusing a total of 6330 images split between train, validation and test sets. For\nall models, common classification metrics were computed (e.g., precision,\nf1-score) and most architectures obtained significant performances, reaching,\namong the others, up to 84.46% average f1-score when discriminating the 4\nidentified classes. Moreover, confusion matrices and activation maps computed\nvia the Grad-CAM algorithm were also reported to present an informed discussion\non the networks classifications.",
    "descriptor": "",
    "authors": [
      "Danilo Avola",
      "Andrea Bacciu",
      "Luigi Cinque",
      "Alessio Fagioli",
      "Marco Raoul Marini",
      "Riccardo Taiello"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02780"
  },
  {
    "id": "arXiv:2110.02785",
    "title": "A case study on profiling of an EEG-based brain decoding interface on  Cloud and Edge servers",
    "abstract": "Brain-Computer Interfaces (BCIs) enable converting the brain electrical\nactivity of an interface user to the user commands. BCI research studies\ndemonstrated encouraging results in different areas such as\nneurorehabilitation, control of artificial limbs, control of computer\nenvironments, communication and detection of diseases. Most of BCIs use\nscalp-electroencephalography (EEG), which is a non-invasive method to capture\nthe brain activity. Although EEG monitoring devices are available in the\nmarket, these devices are generally lab-oriented and expensive. Day-to-day use\nof BCIs is impractical at this time due to the complex techniques required for\ndata preprocessing and signal analysis. This implies that BCI technologies\nshould be improved to facilitate its widespread adoption in Cloud and Edge\ndatacenters. This paper presents a case study on profiling the accuracy and\nperformance of a brain-computer interface which runs on typical Cloud and Edge\nservers. In particular, we investigate how the accuracy and execution time of\nthe preprocessing phase, i.e. the brain signal filtering phase, of a\nbrain-computer interface varies when processing static and live streaming data\nobtained in real time BCI devices. We identify the optimal size of the packets\nfor sampling brain signals which provides the best trade-off between the\naccuracy and performance. Finally, we discuss the pros and cons of using\ntypical Cloud and Edge servers to perform the BCI filtering phase.",
    "descriptor": "",
    "authors": [
      "Alexandra Samsonova",
      "Barry J. Devereux",
      "Georgios Karakonstantis",
      "Lev Mukhanov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.02785"
  },
  {
    "id": "arXiv:2110.02787",
    "title": "Relative Entropy Gradient Sampler for Unnormalized Distributions",
    "abstract": "We propose a relative entropy gradient sampler (REGS) for sampling from\nunnormalized distributions. REGS is a particle method that seeks a sequence of\nsimple nonlinear transforms iteratively pushing the initial samples from a\nreference distribution into the samples from an unnormalized target\ndistribution. To determine the nonlinear transforms at each iteration, we\nconsider the Wasserstein gradient flow of relative entropy. This gradient flow\ndetermines a path of probability distributions that interpolates the reference\ndistribution and the target distribution. It is characterized by an ODE system\nwith velocity fields depending on the density ratios of the density of evolving\nparticles and the unnormalized target density. To sample with REGS, we need to\nestimate the density ratios and simulate the ODE system with particle\nevolution. We propose a novel nonparametric approach to estimating the\nlogarithmic density ratio using neural networks. Extensive simulation studies\non challenging multimodal 1D and 2D mixture distributions and Bayesian logistic\nregression on real datasets demonstrate that the REGS outperforms the\nstate-of-the-art sampling methods included in the comparison.",
    "descriptor": "",
    "authors": [
      "Xingdong Feng",
      "Yuan Gao",
      "Jian Huang",
      "Yuling Jiao",
      "Xu Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.02787"
  },
  {
    "id": "arXiv:2110.02798",
    "title": "Dynamics of hot random hyperbolic graphs",
    "abstract": "We derive the most basic dynamical properties of random hyperbolic graphs\n(the distributions of contact and intercontact durations) in the hot regime\n(network temperature $T > 1$). We show that in the thermodynamic limit the\ncontact distribution decays as a power law with exponent $2+T > 3$ for\ndurations $t > T$, while for $t < T$ it exhibits exponential-like decays. This\nresult holds irrespective of the expected degree distribution, as long as it\nhas a finite $T^{\\text{th}}$ moment. Otherwise, the contact distribution\ndepends on the expected degree distribution and we show that if the latter is a\npower law with exponent $\\gamma \\in (2, T+1]$, then the former decays as a\npower law with exponent $\\gamma+1 > 3$. On the other hand, the intercontact\ndistribution exhibits power-law decays with exponent $2-T \\in (0, 1)$ for $T\n\\in (1,2)$, while for $T > 2$ it displays linear decays with a slope that\ndepends on the observation interval. This result holds irrespective of the\nexpected degree distribution as long as it has a finite $T^{\\text{th}}$ moment\nif $T \\in (1,2)$, or a finite second moment if $T > 2$. Otherwise, the\nintercontact distribution depends on the expected degree distribution and if\nthe latter is a power law with exponent $\\gamma \\in (2, 3)$, then the former\ndecays as a power law with exponent $3-\\gamma \\in (0,1)$. Thus, hot random\nhyperbolic graphs can give rise to contact and intercontact distributions that\nboth decay as power laws. These power laws however are unrealistic for the case\nof the intercontact distribution, as their exponent is always less than one.\nThese results suggest that hot random hyperbolic graphs are not adequate null\nmodels for real temporal networks, in stark contrast to cold random hyperbolic\ngraphs ($T < 1$). Since the configuration model emerges at $T \\to \\infty$,\nthese results also suggest that this is not an adequate null temporal network\nmodel either.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Fragkiskos Papadopoulos",
      "Sofoclis Zambirinis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.02798"
  },
  {
    "id": "arXiv:2110.02800",
    "title": "Unital Qubit Queue-channels: Classical Capacity and Product Decoding",
    "abstract": "Quantum queue-channels arise naturally in the context of buffering in quantum\nnetworks. It has been shown that the upper-bound on the classical capacity of\nan additive queue-channel has a simple expression and is achievable for the\nerasure channel, depolarizing [IEEE JSAIT, 1(2):432-444, Aug 2020] channel and\nsymmetric generalized amplitude damping channel [arXiv:2107.13486]. In this\npaper, using a simple product (non-entangled) decoding (measurement) strategy,\nwe show that the same upper-bound is also achievable for a large class of\nunital qubit queue-channels. As an intermediate result, we derive an explicit\ncapacity achieving product decoding strategy for any i.i.d. unital qubit\nchannel, which could be of independent interest.",
    "descriptor": "\nComments: 8 pages, extends our prior submission arXiv:2107.13486, comments are welcome\n",
    "authors": [
      "Vikesh Siddhu",
      "Avhishek Chatterjee",
      "Krishna Jagannathan",
      "Prabha Mandayam",
      "Sridhar Tayur"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02800"
  },
  {
    "id": "arXiv:2110.02801",
    "title": "Besov regularity for the Dirichlet integral fractional Laplacian in  Lipschitz domains",
    "abstract": "We prove Besov regularity estimates for the solution of the Dirichlet problem\ninvolving the integral fractional Laplacian of order $s$ in bounded Lipschitz\ndomains $\\Omega$: \\[ \\|u\\|_{\\dot{B}^{s+r}_{2,\\infty}(\\Omega)} \\le C\n\\|f\\|_{L^2(\\Omega)}\n\\quad r = \\min\\{s,1/2\\}. \\] This estimate is consistent with the regularity\non smooth domains and shows that there is no loss of regularity due to\nLipschitz boundaries. The proof uses elementary ingredients, such as the\nvariational structure of the problem and the difference quotient technique.",
    "descriptor": "",
    "authors": [
      "Juan Pablo Borthagaray",
      "Ricardo H. Nochetto"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02801"
  },
  {
    "id": "arXiv:2110.02831",
    "title": "Lattice paths with a first return decomposition constrained by the  maximal height of a pattern",
    "abstract": "We consider the system of equations $A_k(x)=p(x)A_{k-1}(x)(q(x)+\\sum_{i=0}^k\nA_i(x))$ for $k\\geq r+1$ where $A_i(x)$, $0\\leq i \\leq r$, are some given\nfunctions and show how to obtain a close form for $A(x)=\\sum_{k\\geq 0}A_k(x)$.\nWe apply this general result to the enumeration of certain subsets of Dyck,\nMotzkin, skew Dyck, and skew Motzkin paths, defined recursively according to\nthe first return decomposition with a monotonically non-increasing condition\nrelative to the maximal ordinate reached by an occurrence of a given pattern\n$\\pi$.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Jean-Luc Baril",
      "Sergey Kirgizov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.02831"
  },
  {
    "id": "arXiv:2110.02836",
    "title": "Beyond quadratic speedups in quantum attacks on symmetric schemes",
    "abstract": "In this paper, we report the first quantum key-recovery attack on a symmetric\nblock cipher design, using classical queries only, with a more than quadratic\ntime speedup compared to the best classical attack.\nWe study the 2XOR-Cascade construction of Ga\\v{z}i and Tessaro\n(EUROCRYPT~2012). It is a key length extension technique which provides an\nn-bit block cipher with 5n/2 bits of security out of an n-bit block cipher with\n2n bits of key, with a security proof in the ideal model. We show that the\noffline-Simon algorithm of Bonnetain et al. (ASIACRYPT~2019) can be extended\nto, in particular, attack this construction in quantum time \\~O($2^n$),\nproviding a 2.5 quantum speedup over the best classical attack.\nRegarding post-quantum security of symmetric ciphers, it is commonly assumed\nthat doubling the key sizes is a sufficient precaution. This is because\nGrover's quantum search algorithm, and its derivatives, can only reach a\nquadratic speedup at most. Our attack shows that the structure of some\nsymmetric constructions can be exploited to overcome this limit. In particular,\nthe 2XOR-Cascade cannot be used to generically strengthen block ciphers against\nquantum adversaries, as it would offer only the same security as the block\ncipher itself.",
    "descriptor": "",
    "authors": [
      "Xavier Bonnetain",
      "Andr\u00e9 Schrottenloher",
      "Ferdinand Sibleyras"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.02836"
  },
  {
    "id": "arXiv:2110.02844",
    "title": "Automatic Identification of the End-Diastolic and End-Systolic Cardiac  Frames from Invasive Coronary Angiography Videos",
    "abstract": "Automatic identification of proper image frames at the end-diastolic (ED) and\nend-systolic (ES) frames during the review of invasive coronary angiograms\n(ICA) is important to assess blood flow during a cardiac cycle, reconstruct the\n3D arterial anatomy from bi-planar views, and generate the complementary fusion\nmap with myocardial images. The current identification method primarily relies\non visual interpretation, making it not only time-consuming but also less\nreproducible. In this paper, we propose a new method to automatically identify\nangiographic image frames associated with the ED and ES cardiac phases by using\nthe trajectories of key vessel points (i.e. landmarks). More specifically, a\ndetection algorithm is first used to detect the key points of coronary\narteries, and then an optical flow method is employed to track the trajectories\nof the selected key points. The ED and ES frames are identified based on all\nthese trajectories. Our method was tested with 62 ICA videos from two separate\nmedical centers (22 and 9 patients in sites 1 and 2, respectively). Comparing\nconsensus interpretations by two human expert readers, excellent agreement was\nachieved by the proposed algorithm: the agreement rates within a one-frame\nrange were 92.99% and 92.73% for the automatic identification of the ED and ES\nimage frames, respectively. In conclusion, the proposed automated method showed\ngreat potential for being an integral part of automated ICA image analysis.",
    "descriptor": "",
    "authors": [
      "Yinghui Meng",
      "Minghao Dong",
      "Xumin Dai",
      "Haipeng Tang",
      "Chen Zhao",
      "Jingfeng Jiang",
      "Shun Xu",
      "Ying Zhou",
      "Fubao Zhu1",
      "Zhihui Xu",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02844"
  },
  {
    "id": "arXiv:2110.02885",
    "title": "Bayesian neural network unit priors and generalized Weibull-tail  property",
    "abstract": "The connection between Bayesian neural networks and Gaussian processes gained\na lot of attention in the last few years. Hidden units are proven to follow a\nGaussian process limit when the layer width tends to infinity. Recent work has\nsuggested that finite Bayesian neural networks may outperform their infinite\ncounterparts because they adapt their internal representations flexibly. To\nestablish solid ground for future research on finite-width neural networks, our\ngoal is to study the prior induced on hidden units. Our main result is an\naccurate description of hidden units tails which shows that unit priors become\nheavier-tailed going deeper, thanks to the introduced notion of generalized\nWeibull-tail. This finding sheds light on the behavior of hidden units of\nfinite Bayesian neural networks.",
    "descriptor": "\nComments: 16 pages, 2 figures, ACML 2021\n",
    "authors": [
      "Mariia Vladimirova",
      "Julyan Arbel",
      "St\u00e9phane Girard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02885"
  },
  {
    "id": "arXiv:2110.02914",
    "title": "Foolish Crowds Support Benign Overfitting",
    "abstract": "We prove a lower bound on the excess risk of sparse interpolating procedures\nfor linear regression with Gaussian data in the overparameterized regime. We\nwork in a setting where the covariance structure has previously been shown to\nbe compatible with benign overfitting with fast convergence to the Bayes risk.\nWe apply the general bound to obtain a lower bound for basis pursuit (the\nminimum $\\ell_1$-norm interpolant) that implies that its excess risk can\nconverge at an exponentially slower rate than OLS (the minimum $\\ell_2$-norm\ninterpolant), even when the ground truth is sparse. Our analysis exposes the\nbenefit of an effect analogous to the \"wisdom of the crowd\", except here the\nharm arising from fitting the noise is ameliorated by spreading it among many\ndirections - the variance reduction arises from a foolish crowd.",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.02914"
  },
  {
    "id": "arXiv:2110.02927",
    "title": "Data Twinning",
    "abstract": "In this work, we develop a method named Twinning, for partitioning a dataset\ninto statistically similar twin sets. Twinning is based on SPlit, a recently\nproposed model-independent method for optimally splitting a dataset into\ntraining and testing sets. Twinning is orders of magnitude faster than the\nSPlit algorithm, which makes it applicable to Big Data problems such as data\ncompression. Twinning can also be used for generating multiple splits of a\ngiven dataset to aid divide-and-conquer procedures and $k$-fold cross\nvalidation.",
    "descriptor": "",
    "authors": [
      "Akhil Vakayil",
      "V. Roshan Joseph"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02927"
  },
  {
    "id": "arXiv:2110.02952",
    "title": "Hierarchical prosody modeling and control in non-autoregressive parallel  neural TTS",
    "abstract": "Neural text-to-speech (TTS) synthesis can generate speech that is\nindistinguishable from natural speech. However, the synthetic speech often\nrepresents the average prosodic style of the database instead of having more\nversatile prosodic variation. Moreover, many models lack the ability to control\nthe output prosody, which does not allow for different styles for the same text\ninput. In this work, we train a non-autoregressive parallel neural TTS model\nhierarchically conditioned on both coarse and fine-grained acoustic speech\nfeatures to learn a latent prosody space with intuitive and meaningful\ndimensions. Experiments show that a non-autoregressive TTS model hierarchically\nconditioned on utterance-wise pitch, pitch range, duration, energy, and\nspectral tilt can effectively control each prosodic dimension, generate a wide\nvariety of speaking styles, and provide word-wise emphasis control, while\nmaintaining equal or better quality to the baseline model.",
    "descriptor": "\nComments: 5 pages, 5 figures, preprint to be submitted to ICASSP 2022. arXiv admin note: text overlap with arXiv:2009.06775\n",
    "authors": [
      "Tuomo Raitio",
      "Jiangchuan Li",
      "Shreyas Seshadri"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02952"
  },
  {
    "id": "arXiv:1710.06611",
    "title": "On community structure validation in real networks",
    "abstract": "Comments: The article is now published in Computational Statistics (with Open Access), see this https URL",
    "descriptor": "\nComments: The article is now published in Computational Statistics (with Open Access), see this https URL\n",
    "authors": [
      "Mirko Signorelli",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1710.06611"
  },
  {
    "id": "arXiv:1809.04128",
    "title": "On learning an interpreted language with recurrent models",
    "abstract": "Comments: Accepted to Computational Linguistics with minor revisions",
    "descriptor": "\nComments: Accepted to Computational Linguistics with minor revisions\n",
    "authors": [
      "Denis Paperno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1809.04128"
  },
  {
    "id": "arXiv:1901.10371",
    "title": "On the Effect of Low-Rank Weights on Adversarial Robustness of Neural  Networks",
    "abstract": "On the Effect of Low-Rank Weights on Adversarial Robustness of Neural  Networks",
    "descriptor": "",
    "authors": [
      "Peter Langenberg",
      "Emilio Rafael Balda",
      "Arash Behboodi",
      "Rudolf Mathar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.10371"
  },
  {
    "id": "arXiv:1904.03271",
    "title": "Optimal Communication Rates and Combinatorial Properties for Common  Randomness Generation",
    "abstract": "Comments: 17 pages, 10 figures",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Yanjun Han",
      "Kedar Tatwawadi",
      "Gowtham R. Kurri",
      "Zhengqing Zhou",
      "Vinod M. Prabhakaran",
      "Tsachy Weissman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1904.03271"
  },
  {
    "id": "arXiv:1912.07168",
    "title": "A Control-Theoretic Perspective on Optimal High-Order Optimization",
    "abstract": "Comments: Accepted by Mathematical Programming Series A; 45 pages",
    "descriptor": "\nComments: Accepted by Mathematical Programming Series A; 45 pages\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1912.07168"
  },
  {
    "id": "arXiv:1912.07773",
    "title": "MEDIRL: Predicting the Visual Attention of Drivers via Maximum Entropy  Deep Inverse Reinforcement Learning",
    "abstract": "Comments: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021",
    "descriptor": "\nComments: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021\n",
    "authors": [
      "Sonia Baee",
      "Erfan Pakdamanian",
      "Inki Kim",
      "Lu Feng",
      "Vicente Ordonez",
      "Laura Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1912.07773"
  },
  {
    "id": "arXiv:2001.05964",
    "title": "Isogeometric continuity constraints for multi-patch shells governed by  fourth-order deformation and phase field models",
    "abstract": "Comments: In this version, typos in the list of references were fixed, floating pictures in Chapter 6 were reduced, and the sign of the bending moments was changed (see text passages after Eqs. (63) and (71), footnotes 13-14 and 23, and Appendix A",
    "descriptor": "\nComments: In this version, typos in the list of references were fixed, floating pictures in Chapter 6 were reduced, and the sign of the bending moments was changed (see text passages after Eqs. (63) and (71), footnotes 13-14 and 23, and Appendix A\n",
    "authors": [
      "Karsten Paul",
      "Christopher Zimmermann",
      "Thang X. Duong",
      "Roger A. Sauer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2001.05964"
  },
  {
    "id": "arXiv:2002.01080",
    "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for  Sequential Decision-Making Problems with Inscrutable Representations",
    "abstract": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for  Sequential Decision-Making Problems with Inscrutable Representations",
    "descriptor": "",
    "authors": [
      "Sarath Sreedharan",
      "Utkarsh Soni",
      "Mudit Verma",
      "Siddharth Srivastava",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2002.01080"
  },
  {
    "id": "arXiv:2002.09028",
    "title": "A general kernelization technique for domination and independence  problems in sparse classes",
    "abstract": "A general kernelization technique for domination and independence  problems in sparse classes",
    "descriptor": "",
    "authors": [
      "Carl Einarson",
      "Felix Reidl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.09028"
  },
  {
    "id": "arXiv:2003.03658",
    "title": "Securing LSB embedding against structural steganalysis",
    "abstract": "Comments: 23 pages, 6 figures. Section 3 added; revisions made to Section 6.3. Version accepted by Journal of Computer Security",
    "descriptor": "\nComments: 23 pages, 6 figures. Section 3 added; revisions made to Section 6.3. Version accepted by Journal of Computer Security\n",
    "authors": [
      "Brian A. Powell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2003.03658"
  },
  {
    "id": "arXiv:2003.06321",
    "title": "Micro-supervised Disturbance Learning: A Perspective of Representation  Probability Distribution",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Jielei Chu",
      "Jing Liu",
      "Hongjun Wang",
      "Meng Hua",
      "Zhiguo Gong",
      "Tianrui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.06321"
  },
  {
    "id": "arXiv:2003.06658",
    "title": "From SCAN to Real Data: Systematic Generalization via Meaningful  Learning",
    "abstract": "Comments: 19 pages, 4 figures, 14 tables",
    "descriptor": "\nComments: 19 pages, 4 figures, 14 tables\n",
    "authors": [
      "Ning Shi",
      "Boxin Wang",
      "Wei Wang",
      "Xiangyu Liu",
      "Rong Zhang",
      "Hui Xue",
      "Xinbing Wang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.06658"
  },
  {
    "id": "arXiv:2003.09402",
    "title": "Multiple projection MCMC algorithms on submanifolds",
    "abstract": "Multiple projection MCMC algorithms on submanifolds",
    "descriptor": "",
    "authors": [
      "Tony Leli\u00e8vre",
      "Gabriel Stoltz",
      "Wei Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2003.09402"
  },
  {
    "id": "arXiv:2004.09590",
    "title": "Almost-Reed--Muller Codes Achieve Constant Rates for Random Errors",
    "abstract": "Almost-Reed--Muller Codes Achieve Constant Rates for Random Errors",
    "descriptor": "",
    "authors": [
      "Emmanuel Abbe",
      "Jan H\u0105z\u0142a",
      "Ido Nachum"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.09590"
  },
  {
    "id": "arXiv:2004.12141",
    "title": "Church Synthesis on Register Automata over Linearly Ordered Data Domains",
    "abstract": "Comments: v5: added the proof of Thm8. Small fixes",
    "descriptor": "\nComments: v5: added the proof of Thm8. Small fixes\n",
    "authors": [
      "L\u00e9o Exibard",
      "Emmanuel Filiot",
      "Ayrat Khalimov"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2004.12141"
  },
  {
    "id": "arXiv:2005.09874",
    "title": "An Incremental Clustering Method for Anomaly Detection in Flight Data",
    "abstract": "An Incremental Clustering Method for Anomaly Detection in Flight Data",
    "descriptor": "",
    "authors": [
      "Weizun Zhao",
      "Lishuai Li",
      "Sameer Alam",
      "Yanjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.09874"
  },
  {
    "id": "arXiv:2006.03986",
    "title": "Online Advertising Security: Issues, Taxonomy, and Future Directions",
    "abstract": "Comments: 31 pages, 13 figures, 4 tables, IEEE Communications Surveys & Tutorials",
    "descriptor": "\nComments: 31 pages, 13 figures, 4 tables, IEEE Communications Surveys & Tutorials\n",
    "authors": [
      "Zahra Pooranian",
      "Mauro Conti",
      "Hamed Haddadi",
      "Rahim Tafazolli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.03986"
  },
  {
    "id": "arXiv:2006.05624",
    "title": "Adjoined Networks: A Training Paradigm with Applications to Network  Compression",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Utkarsh Nath",
      "Shrinu Kushagra",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05624"
  },
  {
    "id": "arXiv:2006.07676",
    "title": "EchoIA: Implicit Authentication System Based on User Feedback",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Yingyuan Yang",
      "Xueli Huang",
      "Jiangnan Li",
      "Jinyuan Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.07676"
  },
  {
    "id": "arXiv:2007.15478",
    "title": "Quadratic Word Equations with Length Constraints, Counter Systems, and  Presburger Arithmetic with Divisibility",
    "abstract": "Comments: 19 pages, 3 figures, journal submission of ATVA'18 paper (to be published@LMCS) [arXiv:1805.06701]. arXiv admin note: substantial text overlap with arXiv:1805.06701",
    "descriptor": "\nComments: 19 pages, 3 figures, journal submission of ATVA'18 paper (to be published@LMCS) [arXiv:1805.06701]. arXiv admin note: substantial text overlap with arXiv:1805.06701\n",
    "authors": [
      "Anthony W. Lin",
      "Rupak Majumdar"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2007.15478"
  },
  {
    "id": "arXiv:2008.00584",
    "title": "Optimal rates of convergence and error localization of Gegenbauer  projections",
    "abstract": "Comments: The original submission is corrected",
    "descriptor": "\nComments: The original submission is corrected\n",
    "authors": [
      "Haiyong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2008.00584"
  },
  {
    "id": "arXiv:2008.10066",
    "title": "Learning Off-Policy with Online Planning",
    "abstract": "Comments: 30 pages, Conference of Robot Learning (CoRL) 2021",
    "descriptor": "\nComments: 30 pages, Conference of Robot Learning (CoRL) 2021\n",
    "authors": [
      "Harshit Sikchi",
      "Wenxuan Zhou",
      "David Held"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.10066"
  },
  {
    "id": "arXiv:2008.12198",
    "title": "Inf-sup stability implies quasi-orthogonality",
    "abstract": "Inf-sup stability implies quasi-orthogonality",
    "descriptor": "",
    "authors": [
      "Michael Feischl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.12198"
  },
  {
    "id": "arXiv:2008.12813",
    "title": "HittER: Hierarchical Transformers for Knowledge Graph Embeddings",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Sanxing Chen",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Jian Jiao",
      "Ruofei Zhang",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.12813"
  },
  {
    "id": "arXiv:2009.00576",
    "title": "MORPH-DSLAM: Model Order Reduction for PHysics-based Deformable SLAM",
    "abstract": "MORPH-DSLAM: Model Order Reduction for PHysics-based Deformable SLAM",
    "descriptor": "",
    "authors": [
      "Alberto Badias",
      "Iciar Alfaro",
      "David Gonzalez",
      "Francisco Chinesta",
      "Elias Cueto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.00576"
  },
  {
    "id": "arXiv:2009.07834",
    "title": "Immutable Log Storage as a Service on Private and Public Blockchains",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Services Computing",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Services Computing\n",
    "authors": [
      "William Pourmajidi",
      "Lei Zhang",
      "John Steinbacher",
      "Tony Erwin",
      "Andriy Miranskyy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2009.07834"
  },
  {
    "id": "arXiv:2009.08574",
    "title": "Linear Convergence of Generalized Mirror Descent with Time-Dependent  Mirrors",
    "abstract": "Linear Convergence of Generalized Mirror Descent with Time-Dependent  Mirrors",
    "descriptor": "",
    "authors": [
      "Adityanarayanan Radhakrishnan",
      "Mikhail Belkin",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08574"
  },
  {
    "id": "arXiv:2010.11292",
    "title": "Decentralized optimization over noisy, rate-constrained networks:  Achieving consensus by communicating differences",
    "abstract": "Comments: 15 pages, 6 figures (To be published in the \"IEEE Journal on Selected Areas in Communications (JSAC) Special Issue on Distributed Learning over Wireless Edge Networks\")",
    "descriptor": "\nComments: 15 pages, 6 figures (To be published in the \"IEEE Journal on Selected Areas in Communications (JSAC) Special Issue on Distributed Learning over Wireless Edge Networks\")\n",
    "authors": [
      "Rajarshi Saha",
      "Stefano Rini",
      "Milind Rao",
      "Andrea Goldsmith"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.11292"
  },
  {
    "id": "arXiv:2010.11918",
    "title": "AdapterDrop: On the Efficiency of Adapters in Transformers",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Andreas R\u00fcckl\u00e9",
      "Gregor Geigle",
      "Max Glockner",
      "Tilman Beck",
      "Jonas Pfeiffer",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.11918"
  },
  {
    "id": "arXiv:2011.04728",
    "title": "Similarity-Based Clustering for Enhancing Image Classification  Architectures",
    "abstract": "Similarity-Based Clustering for Enhancing Image Classification  Architectures",
    "descriptor": "",
    "authors": [
      "Dishant Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.04728"
  },
  {
    "id": "arXiv:2011.11734",
    "title": "Learnable Gabor modulated complex-valued networks for orientation  robustness",
    "abstract": "Comments: Submitted to Pattern Recognition",
    "descriptor": "\nComments: Submitted to Pattern Recognition\n",
    "authors": [
      "Felix Richards",
      "Adeline Paiement",
      "Xianghua Xie",
      "Elisabeth Sola",
      "Pierre-Alain Duc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11734"
  },
  {
    "id": "arXiv:2011.13336",
    "title": "Reconfigurable Intelligent Surface (RIS) Aided Multi-User Networks:  Interplay Between NOMA and RIS",
    "abstract": "Comments: 14 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 14 pages, 5 figures, 1 table\n",
    "authors": [
      "Yuanwei Liu",
      "Xidong Mu",
      "Xiao Liu",
      "Marco Di Renzo",
      "Zhiguo Ding",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.13336"
  },
  {
    "id": "arXiv:2012.01362",
    "title": "$DA^3$:Dynamic Additive Attention Adaption for Memory-EfficientOn-Device  Multi-Domain Learning",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Li Yang",
      "Adnan Siraj Rakin",
      "Deliang Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01362"
  },
  {
    "id": "arXiv:2012.02821",
    "title": "MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs",
    "abstract": "MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs",
    "descriptor": "",
    "authors": [
      "Fangda Han",
      "Guoyao Hao",
      "Ricardo Guerrero",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.02821"
  },
  {
    "id": "arXiv:2012.03741",
    "title": "Stability of discrete-time feed-forward neural networks in NARX  configuration",
    "abstract": "Comments: Copyright 2021 by the authors. This work has been accepted to IFAC (19th IFAC Symposium on System Identification: learning models for decision and control) for publication under a Creative Commons Licence CC-BY-NC-ND. Published article: this https URL",
    "descriptor": "\nComments: Copyright 2021 by the authors. This work has been accepted to IFAC (19th IFAC Symposium on System Identification: learning models for decision and control) for publication under a Creative Commons Licence CC-BY-NC-ND. Published article: this https URL\n",
    "authors": [
      "Fabio Bonassi",
      "Marcello Farina",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.03741"
  },
  {
    "id": "arXiv:2012.04932",
    "title": "Semantically Robust Unpaired Image Translation for Data with Unmatched  Semantics Statistics",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Zhiwei Jia",
      "Bodi Yuan",
      "Kangkang Wang",
      "Hong Wu",
      "David Clifford",
      "Zhiqiang Yuan",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04932"
  },
  {
    "id": "arXiv:2012.15524",
    "title": "Fast WordPiece Tokenization",
    "abstract": "Comments: Accepted to EMNLP 2021 as an oral paper",
    "descriptor": "\nComments: Accepted to EMNLP 2021 as an oral paper\n",
    "authors": [
      "Xinying Song",
      "Alex Salcianu",
      "Yang Song",
      "Dave Dopson",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15524"
  },
  {
    "id": "arXiv:2101.00512",
    "title": "Fast solution of fully implicit Runge-Kutta and discontinuous Galerkin  in time for numerical PDEs, Part I: the linear setting",
    "abstract": "Comments: 30 pages, accepted to SISC",
    "descriptor": "\nComments: 30 pages, accepted to SISC\n",
    "authors": [
      "Ben S. Southworth",
      "Oliver Krzysik",
      "Will Pazner",
      "Hans De Sterck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.00512"
  },
  {
    "id": "arXiv:2101.01776",
    "title": "Fast solution of fully implicit Runge-Kutta and discontinuous Galerkin  in time for numerical PDEs, Part II: nonlinearities and DAEs",
    "abstract": "Comments: 30 pages, accepted to SISC",
    "descriptor": "\nComments: 30 pages, accepted to SISC\n",
    "authors": [
      "Ben S. Southworth",
      "Oliver Krzysik",
      "Will Pazner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.01776"
  },
  {
    "id": "arXiv:2101.04041",
    "title": "Evaluating Disentanglement of Structured Latent Representations",
    "abstract": "Evaluating Disentanglement of Structured Latent Representations",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Dang-Nhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04041"
  },
  {
    "id": "arXiv:2101.04348",
    "title": "Phase Retrieval using Expectation Consistent Signal Recovery Algorithm  based on Hypernetwork",
    "abstract": "Comments: 14 pages, 9 figures, accepted in IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: 14 pages, 9 figures, accepted in IEEE Transactions on Signal Processing\n",
    "authors": [
      "Chang-Jen Wang",
      "Chao-Kai Wen",
      "Shang-Ho",
      "Tsai",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.04348"
  },
  {
    "id": "arXiv:2101.05303",
    "title": "Understanding the Effect of Out-of-distribution Examples and Interactive  Explanations on Human-AI Decision Making",
    "abstract": "Comments: 45 pages, 24 figures, accepted to CSCW 2021",
    "descriptor": "\nComments: 45 pages, 24 figures, accepted to CSCW 2021\n",
    "authors": [
      "Han Liu",
      "Vivian Lai",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.05303"
  },
  {
    "id": "arXiv:2101.06291",
    "title": "Lissy: Experimenting with on-chain order books",
    "abstract": "Lissy: Experimenting with on-chain order books",
    "descriptor": "",
    "authors": [
      "Mahsa Moosavi",
      "Jeremy Clark"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.06291"
  },
  {
    "id": "arXiv:2101.08448",
    "title": "Noisy intermediate-scale quantum (NISQ) algorithms",
    "abstract": "Comments: Added new content, Modified certain parts and the paper structure",
    "descriptor": "\nComments: Added new content, Modified certain parts and the paper structure\n",
    "authors": [
      "Kishor Bharti",
      "Alba Cervera-Lierta",
      "Thi Ha Kyaw",
      "Tobias Haug",
      "Sumner Alperin-Lea",
      "Abhinav Anand",
      "Matthias Degroote",
      "Hermanni Heimonen",
      "Jakob S. Kottmann",
      "Tim Menke",
      "Wai-Keong Mok",
      "Sukin Sim",
      "Leong-Chuan Kwek",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08448"
  },
  {
    "id": "arXiv:2101.09145",
    "title": "Intelligent Reflecting Surface Enhanced Multi-UAV NOMA Networks",
    "abstract": "Comments: 31 pages, 6 figures",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Xidong Mu",
      "Yuanwei Liu",
      "Li Guo",
      "Jiaru Lin",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.09145"
  },
  {
    "id": "arXiv:2101.09983",
    "title": "Adversarial Text-to-Image Synthesis: A Review",
    "abstract": "Comments: Published at Neural Networks Journal, available at this https URL",
    "descriptor": "\nComments: Published at Neural Networks Journal, available at this https URL\n",
    "authors": [
      "Stanislav Frolov",
      "Tobias Hinz",
      "Federico Raue",
      "J\u00f6rn Hees",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09983"
  },
  {
    "id": "arXiv:2102.01881",
    "title": "Analysis and Design of Analog Fountain Codes for Short Packet  Communications",
    "abstract": "Comments: 13 pages, 15 figures",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Wen Jun Lim",
      "Rana Abbas",
      "Yonghui Li",
      "Branka Vucetic",
      "Mahyar Shirvanimoghaddam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.01881"
  },
  {
    "id": "arXiv:2102.02340",
    "title": "MUFASA: Multimodal Fusion Architecture Search for Electronic Health  Records",
    "abstract": "Comments: Accepted for publication at the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)",
    "descriptor": "\nComments: Accepted for publication at the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)\n",
    "authors": [
      "Zhen Xu",
      "David R. So",
      "Andrew M. Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.02340"
  },
  {
    "id": "arXiv:2102.02551",
    "title": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine  Learning Models",
    "abstract": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine  Learning Models",
    "descriptor": "",
    "authors": [
      "Yugeng Liu",
      "Rui Wen",
      "Xinlei He",
      "Ahmed Salem",
      "Zhikun Zhang",
      "Michael Backes",
      "Emiliano De Cristofaro",
      "Mario Fritz",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02551"
  },
  {
    "id": "arXiv:2102.02828",
    "title": "Scattering Networks on the Sphere for Scalable and Rotationally  Equivariant Spherical CNNs",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Jason D. McEwen",
      "Christopher G. R. Wallis",
      "Augustine N. Mavor-Parker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.02828"
  },
  {
    "id": "arXiv:2102.05313",
    "title": "Conditional Loss and Deep Euler Scheme for Time Series Generation",
    "abstract": "Comments: 14 page, 9 Figures",
    "descriptor": "\nComments: 14 page, 9 Figures\n",
    "authors": [
      "Carl Remlinger",
      "Joseph Mikael",
      "Romuald Elie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.05313"
  },
  {
    "id": "arXiv:2102.05912",
    "title": "On Transportation of Mini-batches: A Hierarchical Approach",
    "abstract": "Comments: 43 pages, 17 figures",
    "descriptor": "\nComments: 43 pages, 17 figures\n",
    "authors": [
      "Khai Nguyen",
      "Dang Nguyen",
      "Quoc Nguyen",
      "Tung Pham",
      "Hung Bui",
      "Dinh Phung",
      "Trung Le",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05912"
  },
  {
    "id": "arXiv:2102.06571",
    "title": "Bayesian Neural Network Priors Revisited",
    "abstract": "Bayesian Neural Network Priors Revisited",
    "descriptor": "",
    "authors": [
      "Vincent Fortuin",
      "Adri\u00e0 Garriga-Alonso",
      "Florian Wenzel",
      "Gunnar R\u00e4tsch",
      "Richard Turner",
      "Mark van der Wilk",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06571"
  },
  {
    "id": "arXiv:2102.07559",
    "title": "Certifiably Robust Variational Autoencoders",
    "abstract": "Comments: 12 pages and appendix",
    "descriptor": "\nComments: 12 pages and appendix\n",
    "authors": [
      "Ben Barrett",
      "Alexander Camuto",
      "Matthew Willetts",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07559"
  },
  {
    "id": "arXiv:2102.12317",
    "title": "Learning-Augmented Sketches for Hessians",
    "abstract": "Learning-Augmented Sketches for Hessians",
    "descriptor": "",
    "authors": [
      "Yi Li",
      "Honghao Lin",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.12317"
  },
  {
    "id": "arXiv:2102.12855",
    "title": "Modular Deep Reinforcement Learning for Continuous Motion Planning with  Temporal Logic",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.06797",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.06797\n",
    "authors": [
      "Mingyu Cai",
      "Mohammadhosein Hasanbeig",
      "Shaoping Xiao",
      "Alessandro Abate",
      "Zhen Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.12855"
  },
  {
    "id": "arXiv:2103.03113",
    "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization  Perspective",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Wei Huang",
      "Yayong Li",
      "Weitao Du",
      "Richard Yi Da Xu",
      "Jie Yin",
      "Ling Chen",
      "Miao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.03113"
  },
  {
    "id": "arXiv:2103.05674",
    "title": "Synthesizing Computable Functions from Rational Specifications over  Infinite Words",
    "abstract": "Synthesizing Computable Functions from Rational Specifications over  Infinite Words",
    "descriptor": "",
    "authors": [
      "Emmanuel Filiot",
      "Sarah Winter"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.05674"
  },
  {
    "id": "arXiv:2103.09801",
    "title": "Real-Time Fault-Tolerance Node-to-Node Disjoint Paths Algorithm for  Symmetric Networks",
    "abstract": "Comments: There will be no replacement since maximum flow solves the problem in better way, also the paper contains typos and errors",
    "descriptor": "\nComments: There will be no replacement since maximum flow solves the problem in better way, also the paper contains typos and errors\n",
    "authors": [
      "Hesham AlMansouri",
      "Zaid Hussain"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.09801"
  },
  {
    "id": "arXiv:2103.09888",
    "title": "Numerical analysis of the Landau-Lifshitz-Gilbert equation with inertial  effects",
    "abstract": "Numerical analysis of the Landau-Lifshitz-Gilbert equation with inertial  effects",
    "descriptor": "",
    "authors": [
      "Michele Ruggeri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.09888"
  },
  {
    "id": "arXiv:2103.11257",
    "title": "Robust Models Are More Interpretable Because Attributions Look Normal",
    "abstract": "Robust Models Are More Interpretable Because Attributions Look Normal",
    "descriptor": "",
    "authors": [
      "Zifan Wang",
      "Matt Fredrikson",
      "Anupam Datta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11257"
  },
  {
    "id": "arXiv:2103.11636",
    "title": "Optimization for Arbitrary-Oriented Object Detection via Representation  Invariance Loss",
    "abstract": "Comments: Accepted by IEEE Geoscience and Remote Sensing Letters.The code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE Geoscience and Remote Sensing Letters.The code is available at this https URL\n",
    "authors": [
      "Qi Ming",
      "Lingjuan Miao",
      "Zhiqiang Zhou",
      "Xue Yang",
      "Yunpeng Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11636"
  },
  {
    "id": "arXiv:2103.15087",
    "title": "Learning a Sketch Tensor Space for Image Inpainting of Man-made Scenes",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Chenjie Cao",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15087"
  },
  {
    "id": "arXiv:2104.00065",
    "title": "Force-and-moment-based Model Predictive Control for Achieving Highly  Dynamic Locomotion on Bipedal Robots",
    "abstract": "Comments: 7 pages, 12 figures. In proceedings of Conference on Decision and Control (CDC) 2021",
    "descriptor": "\nComments: 7 pages, 12 figures. In proceedings of Conference on Decision and Control (CDC) 2021\n",
    "authors": [
      "Junheng Li",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.00065"
  },
  {
    "id": "arXiv:2104.00820",
    "title": "LatentCLR: A Contrastive Learning Approach for Unsupervised Discovery of  Interpretable Directions",
    "abstract": "LatentCLR: A Contrastive Learning Approach for Unsupervised Discovery of  Interpretable Directions",
    "descriptor": "",
    "authors": [
      "O\u011fuz Kaan Y\u00fcksel",
      "Enis Simsar",
      "Ezgi G\u00fclperi Er",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00820"
  },
  {
    "id": "arXiv:2104.01421",
    "title": "Simultaneously Transmitting And Reflecting (STAR) RIS Aided Wireless  Communications",
    "abstract": "Comments: 31 pages, 8 figures, this work is accepted for the publication in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 31 pages, 8 figures, this work is accepted for the publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Xidong Mu",
      "Yuanwei Liu",
      "Li Guo",
      "Jiaru Lin",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.01421"
  },
  {
    "id": "arXiv:2104.01541",
    "title": "Attention Back-end for Automatic Speaker Verification with Multiple  Enrollment Utterances",
    "abstract": "Attention Back-end for Automatic Speaker Verification with Multiple  Enrollment Utterances",
    "descriptor": "",
    "authors": [
      "Chang Zeng",
      "Xin Wang",
      "Erica Cooper",
      "Xiaoxiao Miao",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.01541"
  },
  {
    "id": "arXiv:2104.01732",
    "title": "Semantically Stealthy Adversarial Attacks against Segmentation Models",
    "abstract": "Semantically Stealthy Adversarial Attacks against Segmentation Models",
    "descriptor": "",
    "authors": [
      "Zhenhua Chen",
      "Chuhua Wang",
      "David J. Crandall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01732"
  },
  {
    "id": "arXiv:2104.04448",
    "title": "Relating Adversarially Robust Generalization to Flat Minima",
    "abstract": "Comments: ICCV'21",
    "descriptor": "\nComments: ICCV'21\n",
    "authors": [
      "David Stutz",
      "Matthias Hein",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.04448"
  },
  {
    "id": "arXiv:2104.04572",
    "title": "Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next  Frontier for Intelligent Safe-Driving Assessment",
    "abstract": "Comments: 8 pages, 6 figures, and the newest version of paper has been submitted to IEEE Network for second review",
    "descriptor": "\nComments: 8 pages, 6 figures, and the newest version of paper has been submitted to IEEE Network for second review\n",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Rafiq Swash",
      "Lina Mohjazi",
      "Lei Zhang",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.04572"
  },
  {
    "id": "arXiv:2104.04968",
    "title": "Knowledge-Augmented Contrastive Learning for Abnormality Classification  and Localization in Chest X-rays with Radiomics using a Feedback Loop",
    "abstract": "Comments: Accepted by WACV 2022",
    "descriptor": "\nComments: Accepted by WACV 2022\n",
    "authors": [
      "Yan Han",
      "Chongyan Chen",
      "Ahmed Tewfik",
      "Benjamin Glicksberg",
      "Ying Ding",
      "Yifan Peng",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04968"
  },
  {
    "id": "arXiv:2104.06069",
    "title": "1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training  with LAMB's Convergence Speed",
    "abstract": "1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training  with LAMB's Convergence Speed",
    "descriptor": "",
    "authors": [
      "Conglong Li",
      "Ammar Ahmad Awan",
      "Hanlin Tang",
      "Samyam Rajbhandari",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.06069"
  },
  {
    "id": "arXiv:2104.07012",
    "title": "Sparse Attention with Linear Units",
    "abstract": "Comments: EMNLP2021, code is available at this https URL",
    "descriptor": "\nComments: EMNLP2021, code is available at this https URL\n",
    "authors": [
      "Biao Zhang",
      "Ivan Titov",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07012"
  },
  {
    "id": "arXiv:2104.07886",
    "title": "Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural  Networks",
    "abstract": "Comments: Accepted by ACM TOIS. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by ACM TOIS. Code is available at this https URL\n",
    "authors": [
      "Hao Peng",
      "Ruitong Zhang",
      "Yingtong Dou",
      "Renyu Yang",
      "Jingyi Zhang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.07886"
  },
  {
    "id": "arXiv:2104.08717",
    "title": "The hidden label-marginal biases of segmentation losses",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Bingyuan Liu",
      "Jose Dolz",
      "Adrian Galdran",
      "Riadh Kobbi",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08717"
  },
  {
    "id": "arXiv:2104.12888",
    "title": "Backscatter-Assisted Wireless Powered Communication Networks Empowered  by Intelligent Reflecting Surface",
    "abstract": "Comments: This work has been accepted for publication in IEEE TVT",
    "descriptor": "\nComments: This work has been accepted for publication in IEEE TVT\n",
    "authors": [
      "Parisa Ramezani",
      "Abbas Jamalipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.12888"
  },
  {
    "id": "arXiv:2104.13225",
    "title": "Visually grounded models of spoken language: A survey of datasets,  architectures and evaluation techniques",
    "abstract": "Visually grounded models of spoken language: A survey of datasets,  architectures and evaluation techniques",
    "descriptor": "",
    "authors": [
      "Grzegorz Chrupa\u0142a"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.13225"
  },
  {
    "id": "arXiv:2104.13667",
    "title": "A Survey on User-Centric Cell-Free Massive MIMO Systems",
    "abstract": "Comments: Version 1 was submitted on 28 Apr 2021. This is version 2, where we removed many intermediate equations and only kept the ones that are essential for understanding the described schemes. Also, we added some comments and a table to highlight the conceptual differences between cell-free massive MIMO and the other related technologies. Further detailed revisions can be found in the paper",
    "descriptor": "\nComments: Version 1 was submitted on 28 Apr 2021. This is version 2, where we removed many intermediate equations and only kept the ones that are essential for understanding the described schemes. Also, we added some comments and a table to highlight the conceptual differences between cell-free massive MIMO and the other related technologies. Further detailed revisions can be found in the paper\n",
    "authors": [
      "Shuaifei Chen",
      "Jiayi Zhang",
      "Jing Zhang",
      "Emil Bj\u00f6rnson",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.13667"
  },
  {
    "id": "arXiv:2104.13888",
    "title": "One-to-Two-Player Lifting for Mildly Growing Memory",
    "abstract": "Comments: 36 pages, 3 figures. The abstract is reduced due to arXiv restrictions",
    "descriptor": "\nComments: 36 pages, 3 figures. The abstract is reduced due to arXiv restrictions\n",
    "authors": [
      "Alexander Kozachinskiy"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2104.13888"
  },
  {
    "id": "arXiv:2105.00794",
    "title": "Robust 3D Cell Segmentation: Extending the View of Cellpose",
    "abstract": "Robust 3D Cell Segmentation: Extending the View of Cellpose",
    "descriptor": "",
    "authors": [
      "Dennis Eschweiler",
      "Richard S. Smith",
      "Johannes Stegmaier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00794"
  },
  {
    "id": "arXiv:2105.01713",
    "title": "A Fast Partial Video Copy Detection Using KNN and Global Feature  Database",
    "abstract": "A Fast Partial Video Copy Detection Using KNN and Global Feature  Database",
    "descriptor": "",
    "authors": [
      "Weijun Tan",
      "Hongwei Guo",
      "Rushuai Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01713"
  },
  {
    "id": "arXiv:2105.05381",
    "title": "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference  Perspective",
    "abstract": "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference  Perspective",
    "descriptor": "",
    "authors": [
      "Shahbaz Rezaei",
      "Zubair Shafiq",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.05381"
  },
  {
    "id": "arXiv:2105.06187",
    "title": "On information rates over a binary input channel",
    "abstract": "Comments: in IEEE Open Journal of the Communications Society, 2021",
    "descriptor": "\nComments: in IEEE Open Journal of the Communications Society, 2021\n",
    "authors": [
      "Michael Peleg",
      "Tomer Michaeli",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06187"
  },
  {
    "id": "arXiv:2105.06872",
    "title": "Revizor: Testing Black-box CPUs against Speculation Contracts",
    "abstract": "Revizor: Testing Black-box CPUs against Speculation Contracts",
    "descriptor": "",
    "authors": [
      "Oleksii Oleksenko",
      "Christof Fetzer",
      "Boris K\u00f6pf",
      "Mark Silberstein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.06872"
  },
  {
    "id": "arXiv:2105.08551",
    "title": "Improved Ackermannian lower bound for the Petri nets reachability  problem",
    "abstract": "Improved Ackermannian lower bound for the Petri nets reachability  problem",
    "descriptor": "",
    "authors": [
      "S\u0142awomir Lasota"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.08551"
  },
  {
    "id": "arXiv:2105.11998",
    "title": "A Closed-Loop Linear Covariance Framework for Vehicle Path Planning in a  Static Uncertain Obstacle Fiel",
    "abstract": "Comments: 41 pages, 21 figures",
    "descriptor": "\nComments: 41 pages, 21 figures\n",
    "authors": [
      "Randall Christensen",
      "Greg Droge",
      "Robert Leishman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.11998"
  },
  {
    "id": "arXiv:2105.14328",
    "title": "Transfer Learning under High-dimensional Generalized Linear Models",
    "abstract": "Comments: 68 pages, 8 figures",
    "descriptor": "\nComments: 68 pages, 8 figures\n",
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.14328"
  },
  {
    "id": "arXiv:2105.14785",
    "title": "Adversarial Training with Rectified Rejection",
    "abstract": "Adversarial Training with Rectified Rejection",
    "descriptor": "",
    "authors": [
      "Tianyu Pang",
      "Huishuai Zhang",
      "Di He",
      "Yinpeng Dong",
      "Hang Su",
      "Wei Chen",
      "Jun Zhu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14785"
  },
  {
    "id": "arXiv:2105.15013",
    "title": "SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning",
    "abstract": "SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning",
    "descriptor": "",
    "authors": [
      "Jianhong Wang",
      "Jinxin Wang",
      "Yuan Zhang",
      "Yunjie Gu",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.15013"
  },
  {
    "id": "arXiv:2106.00266",
    "title": "Did I do that? Blame as a means to identify controlled effects in  reinforcement learning",
    "abstract": "Did I do that? Blame as a means to identify controlled effects in  reinforcement learning",
    "descriptor": "",
    "authors": [
      "Oriol Corcoll",
      "Youssef Mohamed",
      "Raul Vicente"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00266"
  },
  {
    "id": "arXiv:2106.00563",
    "title": "IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse",
    "abstract": "IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse",
    "descriptor": "",
    "authors": [
      "Liangliang Shi",
      "Yang Li",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00563"
  },
  {
    "id": "arXiv:2106.01216",
    "title": "Evidential Turing Processes",
    "abstract": "Comments: updated version; currrently under submission",
    "descriptor": "\nComments: updated version; currrently under submission\n",
    "authors": [
      "Melih Kandemir",
      "Abdullah Akg\u00fcl",
      "Manuel Haussmann",
      "Gozde Unal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01216"
  },
  {
    "id": "arXiv:2106.02229",
    "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning",
    "abstract": "Comments: 21 pages total, 18 figures",
    "descriptor": "\nComments: 21 pages total, 18 figures\n",
    "authors": [
      "Yingjie Miao",
      "Xingyou Song",
      "Daiyi Peng",
      "Summer Yue",
      "John D. Co-Reyes",
      "Eugene Brevdo",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02229"
  },
  {
    "id": "arXiv:2106.02489",
    "title": "Long-Horizon Multi-Robot Rearrangement Planning for Construction  Assembly",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Valentin Noah Hartmann",
      "Andreas Orthey",
      "Danny Driess",
      "Ozgur S. Oguz",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02489"
  },
  {
    "id": "arXiv:2106.02938",
    "title": "Energy-Based Learning for Cooperative Games, with Applications to  Valuation Problems in Machine Learning",
    "abstract": "Energy-Based Learning for Cooperative Games, with Applications to  Valuation Problems in Machine Learning",
    "descriptor": "",
    "authors": [
      "Yatao Bian",
      "Yu Rong",
      "Tingyang Xu",
      "Jiaxiang Wu",
      "Andreas Krause",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02938"
  },
  {
    "id": "arXiv:2106.03269",
    "title": "Itihasa: A large-scale corpus for Sanskrit to English translation",
    "abstract": "Comments: Fixed typo",
    "descriptor": "\nComments: Fixed typo\n",
    "authors": [
      "Rahul Aralikatte",
      "Miryam de Lhoneux",
      "Anoop Kunchukuttan",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.03269"
  },
  {
    "id": "arXiv:2106.03498",
    "title": "Identifiability in inverse reinforcement learning",
    "abstract": "Identifiability in inverse reinforcement learning",
    "descriptor": "",
    "authors": [
      "Haoyang Cao",
      "Samuel N. Cohen",
      "Lukasz Szpruch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.03498"
  },
  {
    "id": "arXiv:2106.03719",
    "title": "Incremental False Negative Detection for Contrastive Learning",
    "abstract": "Incremental False Negative Detection for Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Tsai-Shien Chen",
      "Wei-Chih Hung",
      "Hung-Yu Tseng",
      "Shao-Yi Chien",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03719"
  },
  {
    "id": "arXiv:2106.04144",
    "title": "Adversarial Semantic Hallucination for Domain Generalized Semantic  Segmentation",
    "abstract": "Comments: Accepted in WACV 2022",
    "descriptor": "\nComments: Accepted in WACV 2022\n",
    "authors": [
      "Gabriel Tjio",
      "Ping Liu",
      "Joey Tianyi Zhou",
      "Rick Siow Mong Goh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04144"
  },
  {
    "id": "arXiv:2106.04289",
    "title": "Morphing tree drawings in a small 3D grid",
    "abstract": "Comments: 43 pages, corrected version, multiple figures",
    "descriptor": "\nComments: 43 pages, corrected version, multiple figures\n",
    "authors": [
      "Elena Arseneva",
      "Rahul Gangopadhyay",
      "Aleksandra Istomina"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.04289"
  },
  {
    "id": "arXiv:2106.05194",
    "title": "DIGRAC: Digraph Clustering Based on Flow Imbalance",
    "abstract": "Comments: 36 pages (10 pages for main text, 3 pages for references)",
    "descriptor": "\nComments: 36 pages (10 pages for main text, 3 pages for references)\n",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05194"
  },
  {
    "id": "arXiv:2106.05424",
    "title": "Fair Disaster Containment via Graph-Cut Problems",
    "abstract": "Fair Disaster Containment via Graph-Cut Problems",
    "descriptor": "",
    "authors": [
      "Michael Dinitz",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05424"
  },
  {
    "id": "arXiv:2106.05907",
    "title": "DAIR: Disentangled Attention Intrinsic Regularization for Safe and  Efficient Bimanual Manipulation",
    "abstract": "Comments: Webpage: this https URL",
    "descriptor": "\nComments: Webpage: this https URL\n",
    "authors": [
      "Minghao Zhang",
      "Pingcheng Jian",
      "Yi Wu",
      "Huazhe Xu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.05907"
  },
  {
    "id": "arXiv:2106.07704",
    "title": "Text Generation with Efficient (Soft) Q-Learning",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Han Guo",
      "Bowen Tan",
      "Zhengzhong Liu",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07704"
  },
  {
    "id": "arXiv:2106.08627",
    "title": "A consistent second-order hydrodynamic model in the time domain for  floating structures with large horizontal motions",
    "abstract": "A consistent second-order hydrodynamic model in the time domain for  floating structures with large horizontal motions",
    "descriptor": "",
    "authors": [
      "Yanlin Shao",
      "Zhiping Zheng",
      "Hui Liang",
      "Jikang Chen"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08627"
  },
  {
    "id": "arXiv:2106.08759",
    "title": "OpenSSLNTRU: Faster post-quantum TLS key exchange",
    "abstract": "Comments: 18 pages, 5 figures; accepted at USENIX Security 2022; reduced number of pages compressing appendices into main body and editing figures, reorganized some content into a revised \"Related works\" section and comparison table in Background to improve comparison of our contributions with existing works",
    "descriptor": "\nComments: 18 pages, 5 figures; accepted at USENIX Security 2022; reduced number of pages compressing appendices into main body and editing figures, reorganized some content into a revised \"Related works\" section and comparison table in Background to improve comparison of our contributions with existing works\n",
    "authors": [
      "Daniel J. Bernstein",
      "Billy Bob Brumley",
      "Ming-Shing Chen",
      "Nicola Tuveri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08759"
  },
  {
    "id": "arXiv:2106.08774",
    "title": "Analysis and Optimisation of Bellman Residual Errors with Neural  Function Approximation",
    "abstract": "Comments: 29 pages, 8 figures",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Martin Gottwald",
      "Sven Gronauer",
      "Hao Shen",
      "Klaus Diepold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08774"
  },
  {
    "id": "arXiv:2106.09369",
    "title": "Wavelet-Packet Powered Deepfake Image Detection",
    "abstract": "Comments: Source code is available at this https URL and this https URL",
    "descriptor": "\nComments: Source code is available at this https URL and this https URL\n",
    "authors": [
      "Moritz Wolter",
      "Felix Blanke",
      "Charles Tapley Hoyt",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09369"
  },
  {
    "id": "arXiv:2106.09534",
    "title": "Adversarial Visual Robustness by Causal Intervention",
    "abstract": "Comments: Codes are available at the following Github project: this https URL",
    "descriptor": "\nComments: Codes are available at the following Github project: this https URL\n",
    "authors": [
      "Kaihua Tang",
      "Mingyuan Tao",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09534"
  },
  {
    "id": "arXiv:2106.09711",
    "title": "Visual Correspondence Hallucination",
    "abstract": "Visual Correspondence Hallucination",
    "descriptor": "",
    "authors": [
      "Hugo Germain",
      "Vincent Lepetit",
      "Guillaume Bourmaud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09711"
  },
  {
    "id": "arXiv:2106.10561",
    "title": "EMG Signal Classification Using Reflection Coefficients and Extreme  Value Machine",
    "abstract": "Comments: Accepted for presentation in IEEE Biomedical Circuits and Systems Conference (BioCAS 2021)",
    "descriptor": "\nComments: Accepted for presentation in IEEE Biomedical Circuits and Systems Conference (BioCAS 2021)\n",
    "authors": [
      "Reza Bagherian Azhiri",
      "Mohammad Esmaeili",
      "Mohsen Jafarzadeh",
      "Mehrdad Nourani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10561"
  },
  {
    "id": "arXiv:2106.10800",
    "title": "Lossy Compression for Lossless Prediction",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yann Dubois",
      "Benjamin Bloem-Reddy",
      "Karen Ullrich",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10800"
  },
  {
    "id": "arXiv:2106.12112",
    "title": "Bregman Gradient Policy Optimization",
    "abstract": "Comments: 25 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 25 pages, 3 figures, 3 tables\n",
    "authors": [
      "Feihu Huang",
      "Shangqian Gao",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.12112"
  },
  {
    "id": "arXiv:2106.12307",
    "title": "Should You Go Deeper? Optimizing Convolutional Neural Network  Architectures without Training by Receptive Field Analysis",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Mats L. Richter",
      "Julius Sch\u00f6ning",
      "Anna Wiedenroth",
      "Ulf Krumnack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12307"
  },
  {
    "id": "arXiv:2106.13863",
    "title": "Fully Steerable 3D Spherical Neurons",
    "abstract": "Fully Steerable 3D Spherical Neurons",
    "descriptor": "",
    "authors": [
      "Pavlo Melnyk",
      "Michael Felsberg",
      "M\u00e5rten Wadenb\u00e4ck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13863"
  },
  {
    "id": "arXiv:2106.13891",
    "title": "Test Case Selection and Prioritization Using Machine Learning: A  Systematic Literature Review",
    "abstract": "Test Case Selection and Prioritization Using Machine Learning: A  Systematic Literature Review",
    "descriptor": "",
    "authors": [
      "Rongqi Pan",
      "Mojtaba Bagherzadeh",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.13891"
  },
  {
    "id": "arXiv:2106.14269",
    "title": "Deep Learning for Technical Document Classification",
    "abstract": "Comments: 21 pages, 8 figures, 9 tables",
    "descriptor": "\nComments: 21 pages, 8 figures, 9 tables\n",
    "authors": [
      "Shuo Jiang",
      "Jianxi Luo",
      "Jie Hu",
      "Christopher L. Magee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.14269"
  },
  {
    "id": "arXiv:2106.14879",
    "title": "Modeling Clothing as a Separate Layer for an Animatable Human Avatar",
    "abstract": "Comments: Camera ready for SIGGRAPH Asia 2021 Technical Papers. this https URL",
    "descriptor": "\nComments: Camera ready for SIGGRAPH Asia 2021 Technical Papers. this https URL\n",
    "authors": [
      "Donglai Xiang",
      "Fabian Prada",
      "Timur Bagautdinov",
      "Weipeng Xu",
      "Yuan Dong",
      "He Wen",
      "Jessica Hodgins",
      "Chenglei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.14879"
  },
  {
    "id": "arXiv:2106.15078",
    "title": "Don't Take It Literally: An Edit-Invariant Sequence Loss for Text  Generation",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Guangyi Liu",
      "Zichao Yang",
      "Tianhua Tao",
      "Xiaodan Liang",
      "Zhen Li",
      "Bowen Zhou",
      "Shuguang Cui",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15078"
  },
  {
    "id": "arXiv:2106.15531",
    "title": "The Power of Alignment-Free Histogram-based Functions: a Comprehensive  Genome Scale Experimental Analysis -- Version 2",
    "abstract": "The Power of Alignment-Free Histogram-based Functions: a Comprehensive  Genome Scale Experimental Analysis -- Version 2",
    "descriptor": "",
    "authors": [
      "Giuseppe Cattaneo",
      "Umberto Ferraro Petrillo",
      "Raffaele Giancarlo",
      "Francesco Palini",
      "Chiara Romualdi"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.15531"
  },
  {
    "id": "arXiv:2107.00166",
    "title": "Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win  the Jackpot?",
    "abstract": "Comments: Accept in NeurIPS 2021",
    "descriptor": "\nComments: Accept in NeurIPS 2021\n",
    "authors": [
      "Xiaolong Ma",
      "Geng Yuan",
      "Xuan Shen",
      "Tianlong Chen",
      "Xuxi Chen",
      "Xiaohan Chen",
      "Ning Liu",
      "Minghai Qin",
      "Sijia Liu",
      "Zhangyang Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00166"
  },
  {
    "id": "arXiv:2107.00948",
    "title": "From Personalized Medicine to Population Health: A Survey of mHealth  Sensing Techniques",
    "abstract": "Comments: Submitted to a journal for review",
    "descriptor": "\nComments: Submitted to a journal for review\n",
    "authors": [
      "Zhiyuan Wang",
      "Haoyi Xiong",
      "Jie Zhang",
      "Sijia Yang",
      "Mehdi Boukhechba",
      "Laura E. Barnes",
      "Daqing Zhang",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00948"
  },
  {
    "id": "arXiv:2107.01983",
    "title": "Gradient Importance Learning for Incomplete Observations",
    "abstract": "Gradient Importance Learning for Incomplete Observations",
    "descriptor": "",
    "authors": [
      "Qitong Gao",
      "Dong Wang",
      "Joshua D. Amason",
      "Siyang Yuan",
      "Chenyang Tao",
      "Ricardo Henao",
      "Majda Hadziahmetovic",
      "Lawrence Carin",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01983"
  },
  {
    "id": "arXiv:2107.02451",
    "title": "Integrating Large Circular Kernels into CNNs through Neural Architecture  Search",
    "abstract": "Comments: 16 pages, 7 figures, submitted to a conference",
    "descriptor": "\nComments: 16 pages, 7 figures, submitted to a conference\n",
    "authors": [
      "Kun He",
      "Chao Li",
      "Yixiao Yang",
      "Gao Huang",
      "John E. Hopcroft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02451"
  },
  {
    "id": "arXiv:2107.02790",
    "title": "iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis",
    "abstract": "Comments: ICCV 2021, Project page is available at this https URL",
    "descriptor": "\nComments: ICCV 2021, Project page is available at this https URL\n",
    "authors": [
      "Andreas Blattmann",
      "Timo Milbich",
      "Michael Dorkenwald",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02790"
  },
  {
    "id": "arXiv:2107.05747",
    "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft  winner-take-all networks",
    "abstract": "SoftHebb: Bayesian inference in unsupervised Hebbian soft  winner-take-all networks",
    "descriptor": "",
    "authors": [
      "Timoleon Moraitis",
      "Dmitry Toichkin",
      "Yansong Chua",
      "Qinghai Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.05747"
  },
  {
    "id": "arXiv:2107.09133",
    "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space  oscillations, and anomalous diffusion",
    "abstract": "Comments: 30 pages, 8 figures",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Daniel Kunin",
      "Javier Sagastuy-Brena",
      "Lauren Gillespie",
      "Eshed Margalit",
      "Hidenori Tanaka",
      "Surya Ganguli",
      "Daniel L. K. Yamins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09133"
  },
  {
    "id": "arXiv:2107.09598",
    "title": "Learning Altruistic Behaviours in Reinforcement Learning without  External Rewards",
    "abstract": "Learning Altruistic Behaviours in Reinforcement Learning without  External Rewards",
    "descriptor": "",
    "authors": [
      "Tim Franzmeyer",
      "Mateusz Malinowski",
      "Jo\u00e3o F. Henriques"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.09598"
  },
  {
    "id": "arXiv:2107.09783",
    "title": "Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with  Self-Supervision and Gated Adapters",
    "abstract": "Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with  Self-Supervision and Gated Adapters",
    "descriptor": "",
    "authors": [
      "Mrigank Rochan",
      "Shubhra Aich",
      "Eduardo R. Corral-Soto",
      "Amir Nabatchian",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09783"
  },
  {
    "id": "arXiv:2107.09990",
    "title": "CL4AC: A Contrastive Loss for Audio Captioning",
    "abstract": "Comments: The first two authors contributed equally, 5 pages, 3 figures, accepted by DCASE2021 Workshop",
    "descriptor": "\nComments: The first two authors contributed equally, 5 pages, 3 figures, accepted by DCASE2021 Workshop\n",
    "authors": [
      "Xubo Liu",
      "Qiushi Huang",
      "Xinhao Mei",
      "Tom Ko",
      "H Lilian Tang",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.09990"
  },
  {
    "id": "arXiv:2107.09998",
    "title": "Conditional Sound Generation Using Neural Discrete Time-Frequency  Representation Learning",
    "abstract": "Comments: Accepted by IEEE 31st International Worlshop on Machine Learning for Signal Processing (MLSP) 2021, 6 pages, 1 figure",
    "descriptor": "\nComments: Accepted by IEEE 31st International Worlshop on Machine Learning for Signal Processing (MLSP) 2021, 6 pages, 1 figure\n",
    "authors": [
      "Xubo Liu",
      "Turab Iqbal",
      "Jinzheng Zhao",
      "Qiushi Huang",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.09998"
  },
  {
    "id": "arXiv:2107.13068",
    "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation",
    "abstract": "Comments: Major revision",
    "descriptor": "\nComments: Major revision\n",
    "authors": [
      "Mohammad Taha Bahadori",
      "Eric Tchetgen Tchetgen",
      "David E. Heckerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.13068"
  },
  {
    "id": "arXiv:2107.13280",
    "title": "Second-order phase-field formulations for anisotropic brittle fracture",
    "abstract": "Second-order phase-field formulations for anisotropic brittle fracture",
    "descriptor": "",
    "authors": [
      "Tymofiy Gerasimov",
      "Laura De Lorenzis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.13280"
  },
  {
    "id": "arXiv:2107.14638",
    "title": "An automated domain-independent text reading, interpreting and  extracting approach for reviewing the scientific literature",
    "abstract": "An automated domain-independent text reading, interpreting and  extracting approach for reviewing the scientific literature",
    "descriptor": "",
    "authors": [
      "Amauri J Paula"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.14638"
  },
  {
    "id": "arXiv:2108.03834",
    "title": "Bob and Alice Go to a Bar: Reasoning About Future With Probabilistic  Programs",
    "abstract": "Comments: 31 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: 31 pages, 9 figures, 2 tables\n",
    "authors": [
      "David Tolpin",
      "Tomer Dobkin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03834"
  },
  {
    "id": "arXiv:2108.04623",
    "title": "Learning to Maximize Influence",
    "abstract": "Comments: 23",
    "descriptor": "\nComments: 23\n",
    "authors": [
      "George Panagopoulos",
      "Nikolaos Tziortziotis",
      "Fragkiskos D. Malliaros",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.04623"
  },
  {
    "id": "arXiv:2108.04893",
    "title": "How Self-Supervised Learning Can be Used for Fine-Grained Head Pose  Estimation?",
    "abstract": "How Self-Supervised Learning Can be Used for Fine-Grained Head Pose  Estimation?",
    "descriptor": "",
    "authors": [
      "Mahdi Pourmirzaei",
      "Gholam Ali Montazer",
      "Farzaneh Esmaili"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04893"
  },
  {
    "id": "arXiv:2108.05099",
    "title": "Does Explicit Prediction Matter in Deep Reinforcement Learning-Based  Energy Management?",
    "abstract": "Comments: Fifth IEEE International Conference on Energy Internet (ICEI 2021)",
    "descriptor": "\nComments: Fifth IEEE International Conference on Energy Internet (ICEI 2021)\n",
    "authors": [
      "Zhaoming Qin",
      "Huaying Zhang",
      "Yuzhou Zhao",
      "Hong Xie",
      "Junwei Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05099"
  },
  {
    "id": "arXiv:2108.06084",
    "title": "Curriculum Learning: A Regularization Method for Efficient and Stable  Billion-Scale GPT Model Pre-Training",
    "abstract": "Curriculum Learning: A Regularization Method for Efficient and Stable  Billion-Scale GPT Model Pre-Training",
    "descriptor": "",
    "authors": [
      "Conglong Li",
      "Minjia Zhang",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.06084"
  },
  {
    "id": "arXiv:2108.06891",
    "title": "Efficient Network Analysis Under Single Link Deletion",
    "abstract": "Efficient Network Analysis Under Single Link Deletion",
    "descriptor": "",
    "authors": [
      "Max Ward",
      "Amitava Datta",
      "Hung X. Nguyen",
      "Jason Eshraghian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.06891"
  },
  {
    "id": "arXiv:2108.07063",
    "title": "Multistream Graph Attention Networks for Wind Speed Forecasting",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Dogan Aykas",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07063"
  },
  {
    "id": "arXiv:2108.07183",
    "title": "Improving Self-supervised Learning with Hardness-aware Dynamic  Curriculum Learning: An Application to Digital Pathology",
    "abstract": "Comments: Accepted at ICCV 2021 CDpath workshop",
    "descriptor": "\nComments: Accepted at ICCV 2021 CDpath workshop\n",
    "authors": [
      "Chetan L Srinidhi",
      "Anne L Martel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07183"
  },
  {
    "id": "arXiv:2108.09645",
    "title": "Improving Mini-batch Optimal Transport via Partial Transportation",
    "abstract": "Comments: 35 pages, 14 figures",
    "descriptor": "\nComments: 35 pages, 14 figures\n",
    "authors": [
      "Khai Nguyen",
      "Dang Nguyen",
      "Tung Pham",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09645"
  },
  {
    "id": "arXiv:2108.11015",
    "title": "Quantum Algorithms for Variants of Average-Case Lattice Problems via  Filtering",
    "abstract": "Comments: 41 pages, 1 figure",
    "descriptor": "\nComments: 41 pages, 1 figure\n",
    "authors": [
      "Yilei Chen",
      "Qipeng Liu",
      "Mark Zhandry"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.11015"
  },
  {
    "id": "arXiv:2108.12659",
    "title": "DKM: Differentiable K-Means Clustering Layer for Neural Network  Compression",
    "abstract": "DKM: Differentiable K-Means Clustering Layer for Neural Network  Compression",
    "descriptor": "",
    "authors": [
      "Minsik Cho",
      "Keivan A. Vahid",
      "Saurabh Adya",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12659"
  },
  {
    "id": "arXiv:2108.12777",
    "title": "Searching for an Effective Defender: Benchmarking Defense against  Adversarial Word Substitution",
    "abstract": "Comments: Accepted by EMNLP2021 main conference",
    "descriptor": "\nComments: Accepted by EMNLP2021 main conference\n",
    "authors": [
      "Zongyi Li",
      "Jianhan Xu",
      "Jiehang Zeng",
      "Linyang Li",
      "Xiaoqing Zheng",
      "Qi Zhang",
      "Kai-Wei Chang",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12777"
  },
  {
    "id": "arXiv:2108.13161",
    "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot  Learners",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ningyu Zhang",
      "Luoqiu Li",
      "Xiang Chen",
      "Shumin Deng",
      "Zhen Bi",
      "Chuanqi Tan",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13161"
  },
  {
    "id": "arXiv:2108.13264",
    "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "abstract": "Comments: NeurIPS 2021 (Oral). Website: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 (Oral). Website: this https URL\n",
    "authors": [
      "Rishabh Agarwal",
      "Max Schwarzer",
      "Pablo Samuel Castro",
      "Aaron Courville",
      "Marc G. Bellemare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13264"
  },
  {
    "id": "arXiv:2108.13783",
    "title": "Synbit: Synthesizing Bidirectional Programs using Unidirectional  Sketches",
    "abstract": "Comments: The is the full version of a paper \"Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches\" accepted by OOPSLA 2021. The accepted paper is available at this https URL",
    "descriptor": "\nComments: The is the full version of a paper \"Synbit: Synthesizing Bidirectional Programs using Unidirectional Sketches\" accepted by OOPSLA 2021. The accepted paper is available at this https URL\n",
    "authors": [
      "Masaomi Yamaguchi",
      "Kazutaka Matsuda",
      "Cristina David",
      "Meng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13783"
  },
  {
    "id": "arXiv:2108.13837",
    "title": "Towards a Common Testing Terminology for Software Engineering and Data  Science Experts",
    "abstract": "Comments: Accepted for publication at 22nd International Conference on Product-Focused Software Process Improvement (Profes 2021), this https URL",
    "descriptor": "\nComments: Accepted for publication at 22nd International Conference on Product-Focused Software Process Improvement (Profes 2021), this https URL\n",
    "authors": [
      "Lisa J\u00f6ckel",
      "Thomas Bauer",
      "Michael Kl\u00e4s",
      "Marc P. Hauer",
      "Janek Gro\u00df"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13837"
  },
  {
    "id": "arXiv:2109.00969",
    "title": "Reference Publication Year Spectroscopy (RPYS) in practice: Three RPYS  analyses in the course of Workshop III \"Cited References Analysis Using  CRExplorer\" at the 18th ISSI conference",
    "abstract": "Comments: 24 pages, 6 figures, and 5 tables",
    "descriptor": "\nComments: 24 pages, 6 figures, and 5 tables\n",
    "authors": [
      "Robin Haunschild",
      "Lutz Bornmann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.00969"
  },
  {
    "id": "arXiv:2109.01104",
    "title": "The Far Side of DNS Amplification: Tracing the DDoS Attack Ecosystem  from the Internet Core",
    "abstract": "Comments: Proc. of ACM IMC'21, camera-ready",
    "descriptor": "\nComments: Proc. of ACM IMC'21, camera-ready\n",
    "authors": [
      "Marcin Nawrocki",
      "Mattijs Jonker",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.01104"
  },
  {
    "id": "arXiv:2109.01451",
    "title": "Impact of GPU uncertainty on the training of predictive deep neural  networks",
    "abstract": "Comments: The results obtained in Chainer did not replicate with a different python library, pointing to a software bug rather than hardware cause. The title and discussion of the paper are therefore irrelevant to the real cause",
    "descriptor": "\nComments: The results obtained in Chainer did not replicate with a different python library, pointing to a software bug rather than hardware cause. The title and discussion of the paper are therefore irrelevant to the real cause\n",
    "authors": [
      "Maciej Pietrowski",
      "Andrzej Gajda",
      "Takuto Yamamoto",
      "Taisuke Kobayashi",
      "Lana Sinapayen",
      "Eiji Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.01451"
  },
  {
    "id": "arXiv:2109.02979",
    "title": "POW-HOW: An enduring timing side-channel to evade online malware  sandboxes",
    "abstract": "POW-HOW: An enduring timing side-channel to evade online malware  sandboxes",
    "descriptor": "",
    "authors": [
      "Antonio Nappa",
      "Panagiotis Papadopoulos",
      "Matteo Varvello",
      "Daniel Aceituno Gomez",
      "Juan Tapiador",
      "Andrea Lanzi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.02979"
  },
  {
    "id": "arXiv:2109.07826",
    "title": "Directed degree corrected mixed membership model and estimating  community memberships in directed networks",
    "abstract": "Directed degree corrected mixed membership model and estimating  community memberships in directed networks",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07826"
  },
  {
    "id": "arXiv:2109.08722",
    "title": "Efficient Variational Graph Autoencoders for Unsupervised Cross-domain  Prerequisite Chains",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Irene Li",
      "Vanessa Yan",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08722"
  },
  {
    "id": "arXiv:2109.08884",
    "title": "Design and Results of ICCMA 2021",
    "abstract": "Comments: 14 pages. Part of ICCMA 2021 proceedings",
    "descriptor": "\nComments: 14 pages. Part of ICCMA 2021 proceedings\n",
    "authors": [
      "Jean-Marie Lagniez",
      "Emmanuel Lonca",
      "Jean-Guy Mailly",
      "Julien Rossit"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.08884"
  },
  {
    "id": "arXiv:2109.09901",
    "title": "Modeling Adversarial Noise for Adversarial Defense",
    "abstract": "Modeling Adversarial Noise for Adversarial Defense",
    "descriptor": "",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Bo Han",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09901"
  },
  {
    "id": "arXiv:2109.11641",
    "title": "Turn-to-Diarize: Online Speaker Diarization Constrained by Transformer  Transducer Speaker Turn Detection",
    "abstract": "Turn-to-Diarize: Online Speaker Diarization Constrained by Transformer  Transducer Speaker Turn Detection",
    "descriptor": "",
    "authors": [
      "Wei Xia",
      "Han Lu",
      "Quan Wang",
      "Anshuman Tripathi",
      "Yiling Huang",
      "Ignacio Lopez Moreno",
      "Hasim Sak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.11641"
  },
  {
    "id": "arXiv:2109.11735",
    "title": "On the Robustness of \"Robust reversible data hiding scheme based on  two-layer embedding strategy\"",
    "abstract": "On the Robustness of \"Robust reversible data hiding scheme based on  two-layer embedding strategy\"",
    "descriptor": "",
    "authors": [
      "Wen Yin",
      "Longfei Ke",
      "Zhaoxia Yin",
      "Jin Tang",
      "Bin Luo"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.11735"
  },
  {
    "id": "arXiv:2109.12298",
    "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch",
    "abstract": "Opacus: User-Friendly Differential Privacy Library in PyTorch",
    "descriptor": "",
    "authors": [
      "Ashkan Yousefpour",
      "Igor Shilov",
      "Alexandre Sablayrolles",
      "Davide Testuggine",
      "Karthik Prasad",
      "Mani Malek",
      "John Nguyen",
      "Sayan Ghosh",
      "Akash Bharadwaj",
      "Jessica Zhao",
      "Graham Cormode",
      "Ilya Mironov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.12298"
  },
  {
    "id": "arXiv:2109.12827",
    "title": "Experimental symmetric private information retrieval with  measurement-device-independent quantum network",
    "abstract": "Experimental symmetric private information retrieval with  measurement-device-independent quantum network",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Wen Yu Kon",
      "Hong Jie Ng",
      "Charles C.-W. Lim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.12827"
  },
  {
    "id": "arXiv:2109.13392",
    "title": "The Tensor Brain: A Unified Theory of Perception, Memory and Semantic  Decoding",
    "abstract": "The Tensor Brain: A Unified Theory of Perception, Memory and Semantic  Decoding",
    "descriptor": "",
    "authors": [
      "Volker Tresp",
      "Sahand Sharifzadeh",
      "Hang Li",
      "Dario Konopatzki",
      "Yunpu Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.13392"
  },
  {
    "id": "arXiv:2109.14788",
    "title": "Tipping the Scales: A Corpus-Based Reconstruction of Adjective Scales in  the McGill Pain Questionnaire",
    "abstract": "Comments: 16 pages, 1 figure",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Miriam Stern"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.14788"
  },
  {
    "id": "arXiv:2109.14904",
    "title": "Opportunistic Federation of CubeSat Constellations: a Game-Changing  Paradigm Enabling Enhanced IoT Services in the Sky",
    "abstract": "Opportunistic Federation of CubeSat Constellations: a Game-Changing  Paradigm Enabling Enhanced IoT Services in the Sky",
    "descriptor": "",
    "authors": [
      "G. Araniti",
      "A. Iera",
      "A. Molinaro",
      "S. Pizzi",
      "F. Rinaldi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.14904"
  },
  {
    "id": "arXiv:2109.15095",
    "title": "Third Time's Not a Charm: Exploiting SNMPv3 for Router Fingerprinting",
    "abstract": "Comments: Visit this https URL for up-to-date SNMPv3 measurement results",
    "descriptor": "\nComments: Visit this https URL for up-to-date SNMPv3 measurement results\n",
    "authors": [
      "Taha Albakour",
      "Oliver Gasser",
      "Robert Beverly",
      "Georgios Smaragdakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.15095"
  },
  {
    "id": "arXiv:2109.15113",
    "title": "Learning generalized Nash equilibria in monotone games: A hybrid  adaptive extremum seeking control approach",
    "abstract": "Learning generalized Nash equilibria in monotone games: A hybrid  adaptive extremum seeking control approach",
    "descriptor": "",
    "authors": [
      "Suad Krila\u0161evi\u0107",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.15113"
  },
  {
    "id": "arXiv:2109.15139",
    "title": "High-Availability Clusters: A Taxonomy, Survey, and Future Directions",
    "abstract": "High-Availability Clusters: A Taxonomy, Survey, and Future Directions",
    "descriptor": "",
    "authors": [
      "Premathas Somasekaram",
      "Radu Calinescu",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.15139"
  },
  {
    "id": "arXiv:2109.15296",
    "title": "Electronic Observables for Relaxed Bilayer 2D Heterostructures in  Momentum Space",
    "abstract": "Comments: 29 pages, 9 figures",
    "descriptor": "\nComments: 29 pages, 9 figures\n",
    "authors": [
      "Daniel Massatt",
      "Stephen Carr",
      "Mitchell Luskin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.15296"
  },
  {
    "id": "arXiv:2110.00071",
    "title": "PIETS: Parallelised Irregularity Encoders for Forecasting with  Heterogeneous Time-Series",
    "abstract": "Comments: Accepted to ICDM2021",
    "descriptor": "\nComments: Accepted to ICDM2021\n",
    "authors": [
      "Futoon M. Abushaqra",
      "Hao Xue",
      "Yongli Ren",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00071"
  },
  {
    "id": "arXiv:2110.00165",
    "title": "Large-scale ASR Domain Adaptation using Self- and Semi-supervised  Learning",
    "abstract": "Comments: ICASSP 2022 submitted, 5 pages, 2 figures, 5 tables",
    "descriptor": "\nComments: ICASSP 2022 submitted, 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Dongseong Hwang",
      "Ananya Misra",
      "Zhouyuan Huo",
      "Nikhil Siddhartha",
      "Shefali Garg",
      "David Qiu",
      "Khe Chai Sim",
      "Trevor Strohman",
      "Fran\u00e7oise Beaufays",
      "Yanzhang He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.00165"
  },
  {
    "id": "arXiv:2110.00296",
    "title": "Powerpropagation: A sparsity inducing weight reparameterisation",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Jonathan Schwarz",
      "Siddhant M. Jayakumar",
      "Razvan Pascanu",
      "Peter E. Latham",
      "Yee Whye Teh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00296"
  },
  {
    "id": "arXiv:2110.00495",
    "title": "Fixed-Parameter Algorithms for Longest Heapable Subsequence and Maximum  Binary Tree",
    "abstract": "Comments: Accepted by IPEC 2020. arXiv admin note: substantial text overlap with arXiv:1909.07915",
    "descriptor": "\nComments: Accepted by IPEC 2020. arXiv admin note: substantial text overlap with arXiv:1909.07915\n",
    "authors": [
      "Karthekeyan Chandrasekaran",
      "Elena Grigorescu",
      "Gabriel Istrate",
      "Shubhang Kulkarni",
      "Young-San Lin",
      "Minshen Zhu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00495"
  },
  {
    "id": "arXiv:2110.00629",
    "title": "Factored couplings in multi-marginal optimal transport via difference of  convex programming",
    "abstract": "Comments: Correct the relation between COOT and TLB of GW distance",
    "descriptor": "\nComments: Correct the relation between COOT and TLB of GW distance\n",
    "authors": [
      "Quang Huy Tran",
      "Hicham Janati",
      "Ievgen Redko",
      "R\u00e9mi Flamary",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.00629"
  },
  {
    "id": "arXiv:2110.00918",
    "title": "Does deep learning model calibration improve performance in  class-imbalanced medical image classification?",
    "abstract": "Comments: 33 pages, 16 figures, and 11 tables",
    "descriptor": "\nComments: 33 pages, 16 figures, and 11 tables\n",
    "authors": [
      "Sivaramakrishnan Rajaraman",
      "Prasanth Ganesan",
      "Sameer Antani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.00918"
  },
  {
    "id": "arXiv:2110.00949",
    "title": "Unsupervised paradigm for information extraction from transcripts using  BERT",
    "abstract": "Unsupervised paradigm for information extraction from transcripts using  BERT",
    "descriptor": "",
    "authors": [
      "Aravind Chandramouli",
      "Siddharth Shukla",
      "Neeti Nair",
      "Shiven Purohit",
      "Shubham Pandey",
      "Murali Krishna"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.00949"
  },
  {
    "id": "arXiv:2110.00984",
    "title": "Adaptive Unfolding Total Variation Network for Low-Light Image  Enhancement",
    "abstract": "Comments: Accepted by ICCV 2020",
    "descriptor": "\nComments: Accepted by ICCV 2020\n",
    "authors": [
      "Chuanjun Zheng",
      "Daming Shi",
      "Wentian Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00984"
  },
  {
    "id": "arXiv:2110.00993",
    "title": "On monoid graphs",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Kolja Knauer",
      "Gil Puig i Surroca"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00993"
  },
  {
    "id": "arXiv:2110.01208",
    "title": "HyGain: High Performance, Energy-Efficient Hybrid Gain Cell based Cache  Hierarchy",
    "abstract": "HyGain: High Performance, Energy-Efficient Hybrid Gain Cell based Cache  Hierarchy",
    "descriptor": "",
    "authors": [
      "Sarabjeet Singh",
      "Neelam Surana",
      "Pranjali Jain",
      "Joycee Mekie",
      "Manu Awasthi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.01208"
  },
  {
    "id": "arXiv:2110.01434",
    "title": "A curated, ontology-based, large-scale knowledge graph of artificial  intelligence tasks and benchmarks",
    "abstract": "A curated, ontology-based, large-scale knowledge graph of artificial  intelligence tasks and benchmarks",
    "descriptor": "",
    "authors": [
      "Kathrin Blagec",
      "Adriano Barbosa-Silva",
      "Simon Ott",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.01434"
  },
  {
    "id": "arXiv:2110.01458",
    "title": "Designing Complex Experiments by Applying Unsupervised Machine Learning",
    "abstract": "Comments: 18 pages, 17 figures, and 2 tables",
    "descriptor": "\nComments: 18 pages, 17 figures, and 2 tables\n",
    "authors": [
      "Alex Glushkovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01458"
  },
  {
    "id": "arXiv:2110.01462",
    "title": "A new weakly supervised approach for ALS point cloud semantic  segmentation",
    "abstract": "A new weakly supervised approach for ALS point cloud semantic  segmentation",
    "descriptor": "",
    "authors": [
      "Puzuo Wang",
      "Wei Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01462"
  },
  {
    "id": "arXiv:2110.01500",
    "title": "Factorized Neural Transducer for Efficient Language Model Adaptation",
    "abstract": "Factorized Neural Transducer for Efficient Language Model Adaptation",
    "descriptor": "",
    "authors": [
      "Xie Chen",
      "Zhong Meng",
      "Sarangarajan Parthasarathy",
      "Jinyu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.01500"
  },
  {
    "id": "arXiv:2110.01606",
    "title": "Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained  EfficientNet-Based Convolutional Network",
    "abstract": "Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained  EfficientNet-Based Convolutional Network",
    "descriptor": "",
    "authors": [
      "Daniel G.P. Petrini",
      "Carlos Shimizu",
      "Rosimeire A. Roela",
      "Gabriel V. Valente",
      "Maria A.A.K. Folgueira",
      "Hae Yong Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01606"
  },
  {
    "id": "arXiv:2110.01659",
    "title": "Cross-Modal Virtual Sensing for Combustion Instability Monitoring",
    "abstract": "Cross-Modal Virtual Sensing for Combustion Instability Monitoring",
    "descriptor": "",
    "authors": [
      "Tryambak Gangopadhyay",
      "Vikram Ramanan",
      "Satyanarayanan R Chakravarthy",
      "Soumik Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01659"
  },
  {
    "id": "arXiv:2110.01661",
    "title": "Rerunning OCR -- A Machine Learning Approach to Quality Assessment and  Enhancement Prediction",
    "abstract": "Comments: Journal of Data Mining and Digital Humanities; Small title adjustment",
    "descriptor": "\nComments: Journal of Data Mining and Digital Humanities; Small title adjustment\n",
    "authors": [
      "Pit Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01661"
  },
  {
    "id": "arXiv:2110.01742",
    "title": "Seizure Classification Using Parallel Genetic Naive Bayes Classifiers",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Scot Davidson",
      "Niamh McCallan",
      "Kok Yew Ng",
      "Pardis Biglarbeigi",
      "Dewar Finlay",
      "Boon Leong Lan",
      "James McLaughlin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.01742"
  },
  {
    "id": "arXiv:2110.01805",
    "title": "Self-Supervised Learning of Perceptually Optimized Block Motion  Estimates for Video Compression",
    "abstract": "Self-Supervised Learning of Perceptually Optimized Block Motion  Estimates for Video Compression",
    "descriptor": "",
    "authors": [
      "Somdyuti Paul",
      "Andrey Norkin",
      "Alan C. Bovik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01805"
  },
  {
    "id": "arXiv:2110.01900",
    "title": "DistilHuBERT: Speech Representation Learning by Layer-wise Distillation  of Hidden-unit BERT",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Heng-Jui Chang",
      "Shu-wen Yang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.01900"
  },
  {
    "id": "arXiv:2110.02058",
    "title": "Interactively Generating Explanations for Transformer Language Models",
    "abstract": "Interactively Generating Explanations for Transformer Language Models",
    "descriptor": "",
    "authors": [
      "Patrick Schramowski",
      "Felix Friedrich",
      "Christopher Tauchmann",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02058"
  },
  {
    "id": "arXiv:2110.02176",
    "title": "Machine learning attack on copy detection patterns: are 1x1 patterns  cloneable?",
    "abstract": "Machine learning attack on copy detection patterns: are 1x1 patterns  cloneable?",
    "descriptor": "",
    "authors": [
      "Roman Chaban",
      "Olga Taran",
      "Joakim Tutt",
      "Taras Holotyak",
      "Slavi Bonev",
      "Slava Voloshynovskiy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02176"
  },
  {
    "id": "arXiv:2110.02204",
    "title": "Learning Sense-Specific Static Embeddings using Contextualised Word  Embeddings as a Proxy",
    "abstract": "Comments: Accepted to PACLIC 35",
    "descriptor": "\nComments: Accepted to PACLIC 35\n",
    "authors": [
      "Yi Zhou",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02204"
  }
]
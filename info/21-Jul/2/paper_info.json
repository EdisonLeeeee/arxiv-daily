[
  {
    "id": "arXiv:2107.00001",
    "title": "Background Knowledge in Schema Matching: Strategy vs. Data",
    "abstract": "The use of external background knowledge can be beneficial for the task of\nmatching schemas or ontologies automatically. In this paper, we exploit six\ngeneral-purpose knowledge graphs as sources of background knowledge for the\nmatching task. The background sources are evaluated by applying three different\nexploitation strategies. We find that explicit strategies still outperform\nlatent ones and that the choice of the strategy has a greater impact on the\nfinal alignment than the actual background dataset on which the strategy is\napplied. While we could not identify a universally superior resource, BabelNet\nachieved consistently good results. Our best matcher configuration with\nBabelNet performs very competitively when compared to other matching systems\neven though no dataset-specific optimizations were made.",
    "descriptor": "\nComments: accepted at the International Semantic Web Conference '21 (ISWC 2021)\n",
    "authors": [
      "Jan Portisch",
      "Michael Hladik",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00001"
  },
  {
    "id": "arXiv:2107.00002",
    "title": "Cascade Decoders-Based Autoencoders for Image Reconstruction",
    "abstract": "Autoencoders are composed of coding and decoding units, hence they hold the\ninherent potential of high-performance data compression and signal compressed\nsensing. The main disadvantages of current autoencoders comprise the following\nseveral aspects: the research objective is not data reconstruction but feature\nrepresentation; the performance evaluation of data recovery is neglected; it is\nhard to achieve lossless data reconstruction by pure autoencoders, even by pure\ndeep learning. This paper aims for image reconstruction of autoencoders,\nemploys cascade decoders-based autoencoders, perfects the performance of image\nreconstruction, approaches gradually lossless image recovery, and provides\nsolid theory and application basis for autoencoders-based image compression and\ncompressed sensing. The proposed serial decoders-based autoencoders include the\narchitectures of multi-level decoders and the related optimization algorithms.\nThe cascade decoders consist of general decoders, residual decoders,\nadversarial decoders and their combinations. It is evaluated by the\nexperimental results that the proposed autoencoders outperform the classical\nautoencoders in the performance of image reconstruction.",
    "descriptor": "",
    "authors": [
      "Honggui Li",
      "Dimitri Galayko",
      "Maria Trocan",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00002"
  },
  {
    "id": "arXiv:2107.00003",
    "title": "Understanding Adversarial Examples Through Deep Neural Network's  Response Surface and Uncertainty Regions",
    "abstract": "Deep neural network (DNN) is a popular model implemented in many systems to\nhandle complex tasks such as image classification, object recognition, natural\nlanguage processing etc. Consequently DNN structural vulnerabilities become\npart of the security vulnerabilities in those systems. In this paper we study\nthe root cause of DNN adversarial examples. We examine the DNN response surface\nto understand its classification boundary. Our study reveals the structural\nproblem of DNN classification boundary that leads to the adversarial examples.\nExisting attack algorithms can generate from a handful to a few hundred\nadversarial examples given one clean image. We show there are infinitely many\nadversarial images given one clean sample, all within a small neighborhood of\nthe clean sample. We then define DNN uncertainty regions and show\ntransferability of adversarial examples is not universal. We also argue that\ngeneralization error, the large sample theoretical guarantee established for\nDNN, cannot adequately capture the phenomenon of adversarial examples. We need\nnew theory to measure DNN robustness.",
    "descriptor": "",
    "authors": [
      "Juan Shu",
      "Bowei Xi",
      "Charles Kamhoua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00003"
  },
  {
    "id": "arXiv:2107.00005",
    "title": "Extraction of Key-frames of Endoscopic Videos by using Depth Information",
    "abstract": "A deep learning-based monocular depth estimation (MDE) technique is proposed\nfor selection of most informative frames (key frames) of an endoscopic video.\nIn most of the cases, ground truth depth maps of polyps are not readily\navailable and that is why the transfer learning approach is adopted in our\nmethod. An endoscopic modalities generally capture thousands of frames. In this\nscenario, it is quite important to discard low-quality and clinically\nirrelevant frames of an endoscopic video while the most informative frames\nshould be retained for clinical diagnosis. In this view, a key-frame selection\nstrategy is proposed by utilizing the depth information of polyps. In our\nmethod, image moment, edge magnitude, and key-points are considered for\nadaptively selecting the key frames. One important application of our proposed\nmethod could be the 3D reconstruction of polyps with the help of extracted key\nframes. Also, polyps are localized with the help of extracted depth maps.",
    "descriptor": "",
    "authors": [
      "Pradipta Sasmal",
      "Avinash Paul",
      "M.K. Bhuyan",
      "Yuji Iwahori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00005"
  },
  {
    "id": "arXiv:2107.00032",
    "title": "Agree to Disagree: Subjective Fairness in Privacy-Restricted  Decentralised Conflict Resolution",
    "abstract": "Fairness is commonly seen as a property of the global outcome of a system and\nassumes centralisation and complete knowledge. However, in real decentralised\napplications, agents only have partial observation capabilities. Under limited\ninformation, agents rely on communication to divulge some of their private (and\nunobservable) information to others. When an agent deliberates to resolve\nconflicts, limited knowledge may cause its perspective of a correct outcome to\ndiffer from the actual outcome of the conflict resolution. This is subjective\nunfairness.\nTo enable decentralised, fairness-aware conflict resolution under privacy\nconstraints, we have two contributions: (1) a novel interaction approach and\n(2) a formalism of the relationship between privacy and fairness. Our proposed\ninteraction approach is an architecture for privacy-aware explainable conflict\nresolution where agents engage in a dialogue of hypotheses and facts. To\nmeasure the privacy-fairness relationship, we define subjective and objective\nfairness on both the local and global scope and formalise the impact of partial\nobservability due to privacy in these different notions of fairness.\nWe first study our proposed architecture and the privacy-fairness\nrelationship in the abstract, testing different argumentation strategies on a\nlarge number of randomised cultures. We empirically demonstrate the trade-off\nbetween privacy, objective fairness, and subjective fairness and show that\nbetter strategies can mitigate the effects of privacy in distributed systems.\nIn addition to this analysis across a broad set of randomised abstract\ncultures, we analyse a case study for a specific scenario: we instantiate our\narchitecture in a multi-agent simulation of prioritised rule-aware collision\navoidance with limited information disclosure.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Alex Raymond",
      "Matthew Malencia",
      "Guilherme Paulino-Passos",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00032"
  },
  {
    "id": "arXiv:2107.00042",
    "title": "Zipf's laws of meaning in Catalan",
    "abstract": "In his pioneering research, G. K. Zipf formulated a couple of statistical\nlaws on the relationship between the frequency of a word with its number of\nmeanings: the law of meaning distribution, relating the frequency of a word and\nits frequency rank, and the meaning-frequency law, relating the frequency of a\nword with its number of meanings. Although these laws were formulated more than\nhalf a century ago, they have been only investigated in a few languages. Here\nwe present the first study of these laws in Catalan.\nWe verify these laws in Catalan via the relationship among their exponents\nand that of the rank-frequency law. We present a new protocol for the analysis\nof these Zipfian laws that can be extended to other languages. We report the\nfirst evidence of two marked regimes for these laws in written language and\nspeech, paralleling the two regimes in Zipf's rank-frequency law in large\nmulti-author corpora discovered in early 2000s. Finally, the implications of\nthese two regimes will be discussed.",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Neus Catal\u00e0",
      "Jaume Baixeries",
      "Ramon Ferrer-Cancho",
      "Llu\u00eds Padr\u00f3",
      "Antoni Hern\u00e1ndez-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00042"
  },
  {
    "id": "arXiv:2107.00045",
    "title": "Performance of OpenBCI EEG Binary Intent Classification with Laryngeal  Imagery",
    "abstract": "One of the greatest goals of neuroscience in recent decades has been to\nrehabilitate individuals who no longer have a functional relationship between\ntheir mind and their body. Although neuroscience has produced technologies\nwhich allow the brains of paralyzed patients to accomplish tasks such as spell\nwords or control a motorized wheelchair, these technologies utilize parts of\nthe brain which may not be optimal for simultaneous use. For example, if you\nneeded to look at flashing lights to spell words for communication, it would be\ndifficult to simultaneously look at where you are moving. To improve upon this\nissue, this study developed and tested the foundation for a speech prosthesis\nparadigm which would utilize the innate neurophysiology of the human brain's\nspeech system. In this experiment, two participants were asked to respond to a\nyes or no question via an EEG-based BCI of three different types; SSVEP-based,\nmotor imagery-based, and laryngeal-imagery-based. By comparing the accuracy of\nthe two established BCI paradigms to the novel laryngeal-imagery paradigm, we\ncan establish the relative effectiveness of the novel paradigm. Machine\nlearning algorithms were used to classify the EEG signals which had been\ntransformed into frequency space (spectrograms) and common spatial pattern\n(CSP) dimensions. The SSVEP control task was able to be classified with better\naccuracy (62.5\\%) than the no information rate of 50\\% on the test set, but\nmotor activity/imagery and laryngeal activity/imagery control tasks were not.\nAlthough the laryngeal methods did not produce accuracies above the no\ninformation rate, it is possible that with a larger amount of higher-quality\ndata, this could prove otherwise. In the future, similar research should focus\non reproducing the methods used here with better quality and more data.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Samuel Kuhn",
      "Nathan George"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00045"
  },
  {
    "id": "arXiv:2107.00051",
    "title": "Global Knowledge Distillation in Federated Learning",
    "abstract": "Knowledge distillation has caught a lot of attention in Federated Learning\n(FL) recently. It has the advantage for FL to train on heterogeneous clients\nwhich have different data size and data structure. However, data samples across\nall devices are usually not independent and identically distributed\n(non-i.i.d), posing additional challenges to the convergence and speed of\nfederated learning. As FL randomly asks the clients to join the training\nprocess and each client only learns from local non-i.i.d data, which makes\nlearning processing even slower. In order to solve this problem, an intuitive\nidea is using the global model to guide local training. In this paper, we\npropose a novel global knowledge distillation method, named FedGKD, which\nlearns the knowledge from past global models to tackle down the local bias\ntraining problem. By learning from global knowledge and consistent with current\nlocal models, FedGKD learns a global knowledge model in FL. To demonstrate the\neffectiveness of the proposed method, we conduct extensive experiments on\nvarious CV datasets (CIFAR-10/100) and settings (non-i.i.d data). The\nevaluation results show that FedGKD outperforms previous state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Wanning Pan",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00051"
  },
  {
    "id": "arXiv:2107.00052",
    "title": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth  Games: Convergence Analysis under Expected Co-coercivity",
    "abstract": "Two of the most prominent algorithms for solving unconstrained smooth games\nare the classical stochastic gradient descent-ascent (SGDA) and the recently\nintroduced stochastic consensus optimization (SCO) (Mescheder et al., 2017).\nSGDA is known to converge to a stationary point for specific classes of games,\nbut current convergence analyses require a bounded variance assumption. SCO is\nused successfully for solving large-scale adversarial problems, but its\nconvergence guarantees are limited to its deterministic variant. In this work,\nwe introduce the expected co-coercivity condition, explain its benefits, and\nprovide the first last-iterate convergence guarantees of SGDA and SCO under\nthis condition for solving a class of stochastic variational inequality\nproblems that are potentially non-monotone. We prove linear convergence of both\nmethods to a neighborhood of the solution when they use constant step-size, and\nwe propose insightful stepsize-switching rules to guarantee convergence to the\nexact solution. In addition, our convergence guarantees hold under the\narbitrary sampling paradigm, and as such, we give insights into the complexity\nof minibatching.",
    "descriptor": "\nComments: 35 pages, 3 figures, 1 table\n",
    "authors": [
      "Nicolas Loizou",
      "Hugo Berard",
      "Gauthier Gidel",
      "Ioannis Mitliagkas",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00052"
  },
  {
    "id": "arXiv:2107.00055",
    "title": "Which Echo Chamber? Regions of Attraction in Learning with  Decision-Dependent Distributions",
    "abstract": "As data-driven methods are deployed in real-world settings, the processes\nthat generate the observed data will often react to the decisions of the\nlearner. For example, a data source may have some incentive for the algorithm\nto provide a particular label (e.g. approve a bank loan), and manipulate their\nfeatures accordingly. Work in strategic classification and decision-dependent\ndistributions seeks to characterize the closed-loop behavior of deploying\nlearning algorithms by explicitly considering the effect of the classifier on\nthe underlying data distribution. More recently, works in performative\nprediction seek to classify the closed-loop behavior by considering general\nproperties of the mapping from classifier to data distribution, rather than an\nexplicit form. Building on this notion, we analyze repeated risk minimization\nas the perturbed trajectories of the gradient flows of performative risk\nminimization. We consider the case where there may be multiple local minimizers\nof performative risk, motivated by real world situations where the initial\nconditions may have significant impact on the long-term behavior of the system.\nAs a motivating example, we consider a company whose current employee\ndemographics affect the applicant pool they interview: the initial demographics\nof the company can affect the long-term hiring policies of the company. We\nprovide sufficient conditions to characterize the region of attraction for the\nvarious equilibria in this settings. Additionally, we introduce the notion of\nperformative alignment, which provides a geometric condition on the convergence\nof repeated risk minimization to performative risk minimizers.",
    "descriptor": "",
    "authors": [
      "Roy Dong",
      "Lillian J. Ratliff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00055"
  },
  {
    "id": "arXiv:2107.00057",
    "title": "Simple Training Strategies and Model Scaling for Object Detection",
    "abstract": "The speed-accuracy Pareto curve of object detection systems have advanced\nthrough a combination of better model architectures, training and inference\nmethods. In this paper, we methodically evaluate a variety of these techniques\nto understand where most of the improvements in modern detection systems come\nfrom. We benchmark these improvements on the vanilla ResNet-FPN backbone with\nRetinaNet and RCNN detectors. The vanilla detectors are improved by 7.7% in\naccuracy while being 30% faster in speed. We further provide simple scaling\nstrategies to generate family of models that form two Pareto curves, named\nRetinaNet-RS and Cascade RCNN-RS. These simple rescaled detectors explore the\nspeed-accuracy trade-off between the one-stage RetinaNet detectors and\ntwo-stage RCNN detectors. Our largest Cascade RCNN-RS models achieve 52.9% AP\nwith a ResNet152-FPN backbone and 53.6% with a SpineNet143L backbone. Finally,\nwe show the ResNet architecture, with three minor architectural changes,\noutperforms EfficientNet as the backbone for object detection and instance\nsegmentation systems.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xianzhi Du",
      "Barret Zoph",
      "Wei-Chih Hung",
      "Tsung-Yi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00057"
  },
  {
    "id": "arXiv:2107.00059",
    "title": "A Fair Method for Distributing Collective Assets in the Stellar  Blockchain Financial Network",
    "abstract": "The financial industry is a pioneer in Blockchain technology. One of the most\npopular platforms in Token-based banking is the flexible Stellar platform. This\nplatform is open-source, and today, its wide range of features makes it\npossible for many countries and companies to use it in cryptocurrency and\nToken-based modern banking. This network charges a fee for each transaction. As\nwell, a percentage of the net amount is generated as the inflation rate of the\nnetwork due to the increased number of tokens. These fees and inflationary\namounts are aggregated into a general account and ultimately distributed among\nmembers of the network on a collective vote basis. In this mechanism, network\nusers select an account as the destination for which they wish to transfer\nassets using their user interface, which is generally a wallet. This account\ncould be the account of charities that need this help. It is then determined\nthe target distribution network based on the voting results of all members. One\nof the challenges in this network is the purposeful and fair distribution of\nthese funds between accounts. In this paper, the first step is a complete\ninfrastructure of a Stellar financial network that will consist of three\nnetwork-based segments of the core network, off-chain server, and wallet\ninterface. In the second step, a context-aware recommendation system will be\nexplored and implemented as a solution for the purposeful management of payroll\naccount selection. The results of this study concerning the importance of the\npurposeful division of collective assets and showing a context-aware\nrecommendation system as a solution to improve the process of stellar users'\nparticipation in the voting process by effectively helping them in choosing an\neligible destination",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Shayegan",
      "Kiarash Shamsi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.00059"
  },
  {
    "id": "arXiv:2107.00061",
    "title": "All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated  Text",
    "abstract": "Human evaluations are typically considered the gold standard in natural\nlanguage generation, but as models' fluency improves, how well can evaluators\ndetect and judge machine-generated text? We run a study assessing non-experts'\nability to distinguish between human- and machine-authored text (GPT2 and GPT3)\nin three domains (stories, news articles, and recipes). We find that, without\ntraining, evaluators distinguished between GPT3- and human-authored text at\nrandom chance level. We explore three approaches for quickly training\nevaluators to better identify GPT3-authored text (detailed instructions,\nannotated examples, and paired examples) and find that while evaluators'\naccuracy improved up to 55%, it did not significantly improve across the three\ndomains. Given the inconsistent results across text domains and the often\ncontradictory reasons evaluators gave for their judgments, we examine the role\nuntrained human evaluations play in NLG evaluation and provide recommendations\nto NLG researchers for improving human evaluations of text generated from\nstate-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Elizabeth Clark",
      "Tal August",
      "Sofia Serrano",
      "Nikita Haduong",
      "Suchin Gururangan",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00061"
  },
  {
    "id": "arXiv:2107.00063",
    "title": "Visualizing The Intermediate Representation of Just-in-Time Compilers",
    "abstract": "Just-in-Time (JIT) compilers are used by many modern programming systems in\norder to improve performance. Bugs in JIT compilers provide exploitable\nsecurity vulnerabilities and debugging them is difficult as they are large,\ncomplex, and dynamic. Current debugging and visualization tools deal with\nstatic code and are not suitable in this domain. We describe a new approach for\nsimplifying the large and complex intermediate representation, generated by a\nJIT compiler and visualize it with a metro map metaphor to aid developers in\ndebugging. Experiments using our prototype implementation on Google's V8\nJavaScript interpreter and TurboFan JIT compiler demonstrate that it can help\nidentify and localize buggy code.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "HeuiChan Lim",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00063"
  },
  {
    "id": "arXiv:2107.00064",
    "title": "Toward Efficient Interactions between Python and Native Libraries",
    "abstract": "Python has become a popular programming language because of its excellent\nprogrammability. Many modern software packages utilize Python for high-level\nalgorithm design and depend on native libraries written in C/C++/Fortran for\nefficient computation kernels. Interaction between Python code and native\nlibraries introduces performance losses because of the abstraction lying on the\nboundary of Python and native libraries. On the one side, Python code,\ntypically run with interpretation, is disjoint from its execution behavior. On\nthe other side, native libraries do not include program semantics to understand\nalgorithm defects.\nTo understand the interaction inefficiencies, we extensively study a large\ncollection of Python software packages and categorize them according to the\nroot causes of inefficiencies. We extract two inefficiency patterns that are\ncommon in interaction inefficiencies. Based on these patterns, we develop\nPieProf, a lightweight profiler, to pinpoint interaction inefficiencies in\nPython applications. The principle of PieProf is to measure the inefficiencies\nin the native execution and associate inefficiencies with high-level Python\ncode to provide a holistic view. Guided by PieProf, we optimize 17 real-world\napplications, yielding speedups up to 6.3$\\times$ on application level.",
    "descriptor": "\nComments: In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021), August 23-27, 2021, Athens, Greece. ACM, New York,NY, USA, 12 pages\n",
    "authors": [
      "Jialiang Tan",
      "Yu Chen",
      "Zhenming Liu",
      "Bin Ren",
      "Shuaiwen Leon Song",
      "Xipeng Shen",
      "Xu Liu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.00064"
  },
  {
    "id": "arXiv:2107.00065",
    "title": "Design and Evaluation of Scalable Representations of Communication in  Gantt Charts for Large-scale Execution Traces",
    "abstract": "Gantt charts are frequently used to explore execution traces of large-scale\nparallel programs found in high-performance computing (HPC). In these\nvisualizations, each parallel processor is assigned a row showing the\ncomputation state of a processor at a particular time. Lines are drawn between\nrows to show communication between these processors. When drawn to align\nequivalent calls across rows, structures can emerge reflecting communication\npatterns employed by the executing code. However, though these structures have\nthe same definition at any scale, they are obscured by the density of rendered\nlines when displaying more than a few hundred processors. A more scalable\nmetaphor is necessary to aid HPC experts in understanding communication in\nlarge-scale traces. To address this issue, we first conduct an exploratory\nstudy to identify what visual features are critical for determining similarity\nbetween structures shown at different scales. Based on these findings, we\ndesign a set of glyphs for displaying these structures in dense charts. We then\nconduct a pre-registered user study evaluating how well people interpret\ncommunication using our new representation versus their base depictions in\nlarge-scale Gantt charts. Through our evaluation, we find that our\nrepresentation enables users to more accurately identify communication patterns\ncompared to full renderings of dense charts. We discuss the results of our\nevaluation and findings regarding the design of metaphors for extensible\nstructures.",
    "descriptor": "",
    "authors": [
      "Connor Scully-Allison",
      "Katherine E. Isaacs"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00065"
  },
  {
    "id": "arXiv:2107.00067",
    "title": "Fair Visual Recognition in Limited Data Regime using Self-Supervision  and Self-Distillation",
    "abstract": "Deep learning models generally learn the biases present in the training data.\nResearchers have proposed several approaches to mitigate such biases and make\nthe model fair. Bias mitigation techniques assume that a sufficiently large\nnumber of training examples are present. However, we observe that if the\ntraining data is limited, then the effectiveness of bias mitigation methods is\nseverely degraded. In this paper, we propose a novel approach to address this\nproblem. Specifically, we adapt self-supervision and self-distillation to\nreduce the impact of biases on the model in this setting. Self-supervision and\nself-distillation are not used for bias mitigation. However, through this work,\nwe demonstrate for the first time that these techniques are very effective in\nbias mitigation. We empirically show that our approach can significantly reduce\nthe biases learned by the model. Further, we experimentally demonstrate that\nour approach is complementary to other bias mitigation strategies. Our approach\nsignificantly improves their performance and further reduces the model biases\nin the limited data regime. Specifically, on the L-CIFAR-10S skewed dataset,\nour approach significantly reduces the bias score of the baseline model by\n78.22% and outperforms it in terms of accuracy by a significant absolute margin\nof 8.89%. It also significantly reduces the bias score for the state-of-the-art\ndomain independent bias mitigation method by 59.26% and improves its\nperformance by a significant absolute margin of 7.08%.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Pratik Mazumder",
      "Pravendra Singh",
      "Vinay P. Namboodiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00067"
  },
  {
    "id": "arXiv:2107.00068",
    "title": "Robust Coreset for Continuous-and-Bounded Learning (with Outliers)",
    "abstract": "In this big data era, we often confront large-scale data in many machine\nlearning tasks. A common approach for dealing with large-scale data is to build\na small summary, {\\em e.g.,} coreset, that can efficiently represent the\noriginal input. However, real-world datasets usually contain outliers and most\nexisting coreset construction methods are not resilient against outliers (in\nparticular, the outliers can be located arbitrarily in the space by an\nadversarial attacker). In this paper, we propose a novel robust coreset method\nfor the {\\em continuous-and-bounded learning} problem (with outliers) which\nincludes a broad range of popular optimization objectives in machine learning,\nlike logistic regression and $ k $-means clustering. Moreover, our robust\ncoreset can be efficiently maintained in fully-dynamic environment. To the best\nof our knowledge, this is the first robust and fully-dynamic coreset\nconstruction method for these optimization problems. We also conduct the\nexperiments to evaluate the effectiveness of our robust coreset in practice.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Zixiu Wang",
      "Yiwen Guo",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00068"
  },
  {
    "id": "arXiv:2107.00069",
    "title": "A uniform reaching phase strategy in adaptive sliding mode control",
    "abstract": "In adaptive sliding mode control methods, an updating gain strategy\nassociated with finite-time convergence to the sliding set is essential to deal\nwith matched bounded perturbations with unknown upper-bound. However, the\nestimation of the finite time of any adaptive design is a complicated task\nsince it depends not only on the upper-bound of unknown perturbation but also\non the size of initial conditions. This brief proposes a uniform adaptive\nreaching phase strategy (ARPS) within a predefined reaching-time. Moreover, as\na case of study, the barrier function approach is extended for perturbed MIMO\nsystems with uncertain control matrix. The usage of proposed ARPS in the MIMO\ncase solves simultaneously two issues: giving a uniform reaching phase with a\npredefined reaching-time and adapting to the perturbation norm while in a\npredefined vicinity of the sliding manifold.",
    "descriptor": "\nComments: 7 pages, 4 figures, submitted to Automatica for possible publication\n",
    "authors": [
      "Christopher D. Cruz-Ancona",
      "Leonid Fridman",
      "Hussein Obeid",
      "Salah Laghrouche"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00069"
  },
  {
    "id": "arXiv:2107.00070",
    "title": "Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency  Modeling",
    "abstract": "Training deep neural networks with an $L_0$ regularization is one of the\nprominent approaches for network pruning or sparsification. The method prunes\nthe network during training by encouraging weights to become exactly zero.\nHowever, recent work of Gale et al. reveals that although this method yields\nhigh compression rates on smaller datasets, it performs inconsistently on\nlarge-scale learning tasks, such as ResNet50 on ImageNet. We analyze this\nphenomenon through the lens of variational inference and find that it is likely\ndue to the independent modeling of binary gates, the mean-field approximation,\nwhich is known in Bayesian statistics for its poor performance due to the crude\napproximation. To mitigate this deficiency, we propose a dependency modeling of\nbinary gates, which can be modeled effectively as a multi-layer perceptron\n(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a\ndependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,\nCIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$\noutperforms the original $L_0$-HC algorithm of Louizos et al. by a significant\nmargin, especially on ImageNet. Compared with the state-of-the-arts network\nsparsification algorithms, our dependency modeling makes the $L_0$-based\nsparsification once again very competitive on large-scale learning tasks. Our\nsource code is available at https://github.com/leo-yangli/dep-l0.",
    "descriptor": "\nComments: Published as a conference paper at ECML 2021\n",
    "authors": [
      "Yang Li",
      "Shihao Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00070"
  },
  {
    "id": "arXiv:2107.00072",
    "title": "A Linear-Time Algorithm for the Common Refinement of Rooted Phylogenetic  Trees on a Common Leaf Set",
    "abstract": "The problem of finding a common refinement of a set of rooted trees with\ncommon leaf set $L$ appears naturally in mathematical phylogenetics whenever\npoorly resolved information on the same taxa from different sources is to be\nreconciled. This constitutes a special case of the well-studied supertree\nproblem, where the leaf sets of the input trees may differ. Algorithms that\nsolve the rooted tree compatibility problem are of course applicable to this\nspecial case. However, they require sophisticated auxiliary data structures and\nhave a running time of at least $O(k|L|\\log^2(k|L|))$ for $k$ input trees.\nHere, we show that the problem can be solved in $O(k|L|)$ time using a simple\nbottom-up algorithm called LinCR. An implementation of LinCR in Python is\nfreely available at https://github.com/david-schaller/tralda.",
    "descriptor": "",
    "authors": [
      "David Schaller",
      "Marc Hellmuth",
      "Peter F. Stadler"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2107.00072"
  },
  {
    "id": "arXiv:2107.00073",
    "title": "SATDBailiff- Mining and Tracking Self-Admitted Technical Debt",
    "abstract": "Self-Admitted Technical Debt (SATD) is a metaphorical concept to describe the\nself-documented addition of technical debt to a software project in the form of\nsource code comments. SATD can linger in projects and degrade source-code\nquality, but it can also be more visible than unintentionally added or\nundocumented technical debt. Understanding the implications of adding SATD to a\nsoftware project is important because developers can benefit from a better\nunderstanding of the quality trade-offs they are making. However, empirical\nstudies, analyzing the survivability and removal of SATD comments, are\nchallenged by potential code changes or SATD comment updates that may interfere\nwith properly tracking their appearance, existence, and removal. In this paper,\nwe propose SATDBailiff, a tool that uses an existing state-of-the-art SATD\ndetection tool, to identify SATD in method comments, then properly track their\nlifespan. SATDBailiff is given as input links to open source projects, and its\noutput is a list of all identified SATDs, and for each detected SATD,\nSATDBailiff reports all its associated changes, including any updates to its\ntext, all the way to reporting its removal. The goal of SATDBailiff is to aid\nresearchers and practitioners in better tracking SATDs instances and providing\nthem with a reliable tool that can be easily extended. SATDBailiff was\nvalidated using a dataset of previously detected and manually validated SATD\ninstances.\nSATDBailiff is publicly available as an open-source, along with the manual\nanalysis of SATD instances associated with its validation, on the project\nwebsite",
    "descriptor": "",
    "authors": [
      "Eman Abdullah AlOmar",
      "Ben Christians",
      "Mihal Busho",
      "Ahmed Hamad AlKhalid",
      "Ali Ouni",
      "Christian Newman",
      "Mohamed Wiem Mkaouer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00073"
  },
  {
    "id": "arXiv:2107.00075",
    "title": "Parallel Graph Coloring Algorithms for Distributed GPU Environments",
    "abstract": "Graph coloring is often used in parallelizing scientific computations that\nrun in distributed and multi-GPU environments; it identifies sets of\nindependent data that can be updated in parallel. Many algorithms exist for\ngraph coloring on a single GPU or in distributed memory, but to the best of our\nknowledge, hybrid MPI+GPU algorithms have been unexplored until this work. We\npresent several MPI+GPU coloring approaches based on the distributed coloring\nalgorithms of Gebremedhin et al. and the shared-memory algorithms of Deveci et\nal. . The on-node parallel coloring uses implementations in KokkosKernels,\nwhich provide parallelization for both multicore CPUs and GPUs. We further\nextend our approaches to compute distance-2 and partial distance-2 colorings,\ngiving the first known distributed, multi-GPU algorithm for these problems. In\naddition, we propose a novel heuristic to reduce communication for recoloring\nin distributed graph coloring. Our experiments show that our approaches operate\nefficiently on inputs too large to fit on a single GPU and scale up to graphs\nwith 76.7 billion edges running on 128 GPUs.",
    "descriptor": "\nComments: Submitted to Parallel Computing\n",
    "authors": [
      "Ian Bogle",
      "Erik G Boman",
      "Karen D Devine",
      "Sivasankaran Rajamanickam",
      "George M Slota"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.00075"
  },
  {
    "id": "arXiv:2107.00077",
    "title": "Learning to communicate about shared procedural abstractions",
    "abstract": "Many real-world tasks require agents to coordinate their behavior to achieve\nshared goals. Successful collaboration requires not only adopting the same\ncommunicative conventions, but also grounding these conventions in the same\ntask-appropriate conceptual abstractions. We investigate how humans use natural\nlanguage to collaboratively solve physical assembly problems more effectively\nover time. Human participants were paired up in an online environment to\nreconstruct scenes containing two block towers. One participant could see the\ntarget towers, and sent assembly instructions for the other participant to\nreconstruct. Participants provided increasingly concise instructions across\nrepeated attempts on each pair of towers, using higher-level referring\nexpressions that captured each scene's hierarchical structure. To explain these\nfindings, we extend recent probabilistic models of ad-hoc convention formation\nwith an explicit perceptual learning mechanism. These results shed light on the\ninductive biases that enable intelligent agents to coordinate upon shared\nprocedural abstractions.",
    "descriptor": "",
    "authors": [
      "William P. McCarthy",
      "Robert D. Hawkins",
      "Haoliang Wang",
      "Cameron Holdaway",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00077"
  },
  {
    "id": "arXiv:2107.00079",
    "title": "Using AntiPatterns to avoid MLOps Mistakes",
    "abstract": "We describe lessons learned from developing and deploying machine learning\nmodels at scale across the enterprise in a range of financial analytics\napplications. These lessons are presented in the form of antipatterns. Just as\ndesign patterns codify best software engineering practices, antipatterns\nprovide a vocabulary to describe defective practices and methodologies. Here we\ncatalog and document numerous antipatterns in financial ML operations (MLOps).\nSome antipatterns are due to technical errors, while others are due to not\nhaving sufficient knowledge of the surrounding context in which ML results are\nused. By providing a common vocabulary to discuss these situations, our intent\nis that antipatterns will support better documentation of issues, rapid\ncommunication between stakeholders, and faster resolution of problems. In\naddition to cataloging antipatterns, we describe solutions, best practices, and\nfuture directions toward MLOps maturity.",
    "descriptor": "",
    "authors": [
      "Nikhil Muralidhar",
      "Sathappah Muthiah",
      "Patrick Butler",
      "Manish Jain",
      "Yu Yu",
      "Katy Burne",
      "Weipeng Li",
      "David Jones",
      "Prakash Arunachalam",
      "Hays 'Skip' McCormick",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00079"
  },
  {
    "id": "arXiv:2107.00080",
    "title": "Regressing Location on Text for Probabilistic Geocoding",
    "abstract": "Text data are an important source of detailed information about social and\npolitical events. Automated systems parse large volumes of text data to infer\nor extract structured information that describes actors, actions, dates, times,\nand locations. One of these sub-tasks is geocoding: predicting the geographic\ncoordinates associated with events or locations described by a given text. We\npresent an end-to-end probabilistic model for geocoding text data.\nAdditionally, we collect a novel data set for evaluating the performance of\ngeocoding systems. We compare the model-based solution, called ELECTRo-map, to\nthe current state-of-the-art open source system for geocoding texts for event\ndata. Finally, we discuss the benefits of end-to-end model-based geocoding,\nincluding principled uncertainty estimation and the ability of these models to\nleverage contextual information.",
    "descriptor": "\nComments: 5 pages, 4 figures. Proceedings of the CASE Workshop at ACL-IJCNLP 2021\n",
    "authors": [
      "Benjamin J. Radford"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00080"
  },
  {
    "id": "arXiv:2107.00082",
    "title": "A Search Engine for Scientific Publications: a Cybersecurity Case Study",
    "abstract": "Cybersecurity is a very challenging topic of research nowadays, as\ndigitalization increases the interaction of people, software and services on\nthe Internet by means of technology devices and networks connected to it. The\nfield is broad and has a lot of unexplored ground under numerous disciplines\nsuch as management, psychology, and data science. Its large disciplinary\nspectrum and many significant research topics generate a considerable amount of\ninformation, making it hard for us to find what we are looking for when\nresearching a particular subject. This work proposes a new search engine for\nscientific publications which combines both information retrieval and reading\ncomprehension algorithms to extract answers from a collection of\ndomain-specific documents. The proposed solution although being applied to the\ncontext of cybersecurity exhibited great generalization capabilities and can be\neasily adapted to perform under other distinct knowledge domains.",
    "descriptor": "",
    "authors": [
      "Nuno Oliveira",
      "Norberto Sousa",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.00082"
  },
  {
    "id": "arXiv:2107.00085",
    "title": "CLDA: Contrastive Learning for Semi-Supervised Domain Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA) aims to align the labeled source\ndistribution with the unlabeled target distribution to obtain domain invariant\npredictive models. However, the application of well-known UDA approaches does\nnot generalize well in Semi-Supervised Domain Adaptation (SSDA) scenarios where\nfew labeled samples from the target domain are available. In this paper, we\npropose a simple Contrastive Learning framework for semi-supervised Domain\nAdaptation (CLDA) that attempts to bridge the intra-domain gap between the\nlabeled and unlabeled target distributions and inter-domain gap between source\nand unlabeled target distribution in SSDA. We suggest employing class-wise\ncontrastive learning to reduce the inter-domain gap and instance-level\ncontrastive alignment between the original (input image) and strongly augmented\nunlabeled target images to minimize the intra-domain discrepancy. We have shown\nempirically that both of these modules complement each other to achieve\nsuperior performance. Experiments on three well-known domain adaptation\nbenchmark datasets namely DomainNet, Office-Home, and Office31 demonstrate the\neffectiveness of our approach. CLDA achieves state-of-the-art results on all\nthe above datasets.",
    "descriptor": "",
    "authors": [
      "Ankit Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00085"
  },
  {
    "id": "arXiv:2107.00086",
    "title": "An extended and more practical mwp flow analysis",
    "abstract": "We improve and refine a method for certifying that the values' sizes computed\nby an imperative program will be bounded by polynomials in the program's\ninputs' sizes. Our work ''tames'' the non-determinism of the original analysis,\nand offers an innovative way of completing the analysis when a non-polynomial\ngrowth is found. We furthermore enrich the analyzed language by adding function\ndefinitions and calls, allowing to compose the analysis of different libraries\nand offering generally more modularity. The implementation of our improved\nmethod, discussed in a tool paper [2], also required to reason about the\nefficiency of some of the needed operations on the matrices produced by the\nanalysis. It is our hope that this work will enable and facilitate static\nanalysis of source code to guarantee its correctness with respect to resource\nusages.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Aubert",
      "Thomas Rubiano",
      "Neea Rusch",
      "Thomas Seiller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00086"
  },
  {
    "id": "arXiv:2107.00090",
    "title": "Mesh-based graph convolutional neural network models of processes with  complex initial states",
    "abstract": "Predicting the evolution of a representative sample of a material with\nmicrostructure is a fundamental problem in homogenization. In this work we\npropose a graph convolutional neural network that utilizes the discretized\nrepresentation of the initial microstructure directly, without segmentation or\nclustering. Compared to feature-based and pixel-based convolutional neural\nnetwork models, the proposed method has a number of advantages: (a) it is deep\nin that it does not require featurization but can benefit from it, (b) it has a\nsimple implementation with standard convolutional filters and layers, (c) it\nworks natively on unstructured and structured grid data without interpolation\n(unlike pixel-based convolutional neural networks), and (d) it preserves\nrotational invariance like other graph-based convolutional neural networks. We\ndemonstrate the performance of the proposed network and compare it to\ntraditional pixel-based convolution neural network models and feature-based\ngraph convolutional neural networks on three large datasets.",
    "descriptor": "\nComments: 38 pages, 14 figures\n",
    "authors": [
      "Ari Frankel",
      "Cosmin Safta",
      "Coleman Alleman",
      "Reese Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00090"
  },
  {
    "id": "arXiv:2107.00092",
    "title": "From DNNs to GANs: Review of efficient hardware architectures for deep  learning",
    "abstract": "In recent times, the trend in very large scale integration (VLSI) industry is\nmulti-dimensional, for example, reduction of energy consumption, occupancy of\nless space, precise result, less power dissipation, faster response. To meet\nthese needs, the hardware architecture should be reliable and robust to these\nproblems. Recently, neural network and deep learning has been started to impact\nthe present research paradigm significantly which consists of parameters in the\norder of millions, nonlinear function for activation, convolutional operation\nfor feature extraction, regression for classification, generative adversarial\nnetworks. These operations involve huge calculation and memory overhead.\nPresently available DSP processors are incapable of performing these operations\nand they mostly face the problems, for example, memory overhead, performance\ndrop and compromised accuracy. Moreover, if a huge silicon area is powered to\naccelerate the operation using parallel computation, the ICs will be having\nsignificant chance of burning out due to the considerable generation of heat.\nHence, novel dark silicon constraint is developed to reduce the heat\ndissipation without sacrificing the accuracy. Similarly, different algorithms\nhave been adapted to design a DSP processor compatible for fast performance in\nneural network, activation function, convolutional neural network and\ngenerative adversarial network. In this review, we illustrate the recent\ndevelopments in hardware for accelerating the efficient implementation of deep\nlearning networks with enhanced performance. The techniques investigated in\nthis review are expected to direct future research challenges of hardware\noptimization for high-performance computations.",
    "descriptor": "",
    "authors": [
      "Gaurab Bhattacharya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.00092"
  },
  {
    "id": "arXiv:2107.00093",
    "title": "Automatic Synthesis of Experiment Designs from Probabilistic Environment  Specifications",
    "abstract": "This paper presents an extension to the probabilistic programming language\nProbRobScene, allowing users to automatically synthesize uniform experiment\ndesigns directly from environment specifications. We demonstrate its\neffectiveness on a number of environment specification snippets from tabletop\nmanipulation, and show that our method generates reliably low-discrepancy\ndesigns.",
    "descriptor": "",
    "authors": [
      "Craig Innes",
      "Yordan Hristov",
      "Georgios Kamaras",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00093"
  },
  {
    "id": "arXiv:2107.00094",
    "title": "Super Twisting based Lyapunov Redesign for Uncertain Linear Delay  Systems",
    "abstract": "We present a new continuous Lyapunov Redesign (LR) methodology for the robust\nstabilization of a class of uncertain time-delay systems that is based on the\nso-called Super Twisting Algorithm. The main feature of the proposed approach\nis that allows one to simultaneously adjust the chattering effect and achieve\nasymptotic stabilization of the uncertain system, which is lost when continuous\napproximation of the unit control is considered. At the basis of the Super\nTwisting based LR methodology is a class of Lyapunov-Krasovskii functionals,\nwhose particular form of its time derivative allows one to define a delay-free\nsliding manifold on which some class of smooth uncertainties are compensated.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Marco A. Gomez",
      "Christopher D. Cruz-Ancona",
      "Leonid Fridman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00094"
  },
  {
    "id": "arXiv:2107.00096",
    "title": "Improving black-box optimization in VAE latent space using decoder  uncertainty",
    "abstract": "Optimization in the latent space of variational autoencoders is a promising\napproach to generate high-dimensional discrete objects that maximize an\nexpensive black-box property (e.g., drug-likeness in molecular generation,\nfunction approximation with arithmetic expressions). However, existing methods\nlack robustness as they may decide to explore areas of the latent space for\nwhich no data was available during training and where the decoder can be\nunreliable, leading to the generation of unrealistic or invalid objects. We\npropose to leverage the epistemic uncertainty of the decoder to guide the\noptimization process. This is not trivial though, as a naive estimation of\nuncertainty in the high-dimensional and structured settings we consider would\nresult in high estimator variance. To solve this problem, we introduce an\nimportance sampling-based estimator that provides more robust estimates of\nepistemic uncertainty. Our uncertainty-guided optimization approach does not\nrequire modifications of the model architecture nor the training process. It\nproduces samples with a better trade-off between black-box objective and\nvalidity of the generated samples, sometimes improving both simultaneously. We\nillustrate these advantages across several experimental settings in digit\ngeneration, arithmetic expression approximation and molecule generation for\ndrug design.",
    "descriptor": "",
    "authors": [
      "Pascal Notin",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00096"
  },
  {
    "id": "arXiv:2107.00097",
    "title": "An implementation of flow calculus for complexity analysis (tool paper)",
    "abstract": "Abstract. We present a tool to automatically perform the data-size analysis\nof imperative programs written in C. This tool, called pymwp, is inspired by a\nclassical work on complexity analysis [10], and allows to certify that the size\nof the values computed by a program will be bounded by a polynomial in the\nprogram's inputs. Strategies to provide meaningful feedback on non-polynomial\nprograms and to ``tame'' the non-determinism of the original analysis were\nimplemented following recent progresses [3], but required particular care to\naccommodate thegrowing complexity of the analysis. The Python source code is\nintensively documented, and our numerous example files encompass the original\nexamples as well as multiple test cases. A pip package should make it easy to\ninstall pymwp on any plat-form, but an on-line demo is also available for\nconvenience.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Aubert",
      "Thomas Rubiano",
      "Neea Rusch",
      "Thomas Seiller"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00097"
  },
  {
    "id": "arXiv:2107.00100",
    "title": "FCMI: Feature Correlation based Missing Data Imputation",
    "abstract": "Processed data are insightful, and crude data are obtuse. A serious threat to\ndata reliability is missing values. Such data leads to inaccurate analysis and\nwrong predictions. We propose an efficient technique to impute the missing\nvalue in the dataset based on correlation called FCMI (Feature Correlation\nbased Missing Data Imputation). We have considered the correlation of the\nattributes of the dataset, and that is our central idea. Our proposed algorithm\npicks the highly correlated attributes of the dataset and uses these attributes\nto build a regression model whose parameters are optimized such that the\ncorrelation of the dataset is maintained. Experiments conducted on both\nclassification and regression datasets show that the proposed imputation\ntechnique outperforms existing imputation algorithms.",
    "descriptor": "",
    "authors": [
      "Prateek Mishra",
      "Kumar Divya Mani",
      "Prashant Johri",
      "Dikhsa Arya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00100"
  },
  {
    "id": "arXiv:2107.00101",
    "title": "Latent Execution for Neural Program Synthesis Beyond Domain-Specific  Languages",
    "abstract": "Program synthesis from input-output examples has been a long-standing\nchallenge, and recent works have demonstrated some success in designing deep\nneural networks for program synthesis. However, existing efforts in\ninput-output neural program synthesis have been focusing on domain-specific\nlanguages, thus the applicability of previous approaches to synthesize code in\nfull-fledged popular programming languages, such as C, remains a question. The\nmain challenges lie in two folds. On the one hand, the program search space\ngrows exponentially when the syntax and semantics of the programming language\nbecome more complex, which poses higher requirements on the synthesis\nalgorithm. On the other hand, increasing the complexity of the programming\nlanguage also imposes more difficulties on data collection, since building a\nlarge-scale training set for input-output program synthesis require random\nprogram generators to sample programs and input-output examples. In this work,\nwe take the first step to synthesize C programs from input-output examples. In\nparticular, we propose LaSynth, which learns the latent representation to\napproximate the execution of partially generated programs, even if their\nsemantics are not well-defined. We demonstrate the possibility of synthesizing\nelementary C code from input-output examples, and leveraging learned execution\nsignificantly improves the prediction performance over existing approaches.\nMeanwhile, compared to the randomly generated ground-truth programs, LaSynth\nsynthesizes more concise programs that resemble human-written code. We show\nthat training on these synthesized programs further improves the prediction\nperformance for both Karel and C program synthesis, indicating the promise of\nleveraging the learned program synthesizer to improve the dataset quality for\ninput-output program synthesis.",
    "descriptor": "",
    "authors": [
      "Xinyun Chen",
      "Dawn Song",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00101"
  },
  {
    "id": "arXiv:2107.00105",
    "title": "Transit-Gym: A Simulation and Evaluation Engine for Analysis of Bus  Transit Systems",
    "abstract": "Public-transit systems face a number of operational challenges: (a) changing\nridership patterns requiring optimization of fixed line services, (b)\noptimizing vehicle-to-trip assignments to reduce maintenance and operation\ncodes, and (c) ensuring equitable and fair coverage to areas with low\nridership. Optimizing these objectives presents a hard computational problem\ndue to the size and complexity of the decision space. State-of-the-art methods\nformulate these problems as variants of the vehicle routing problem and use\ndata-driven heuristics for optimizing the procedures. However, the evaluation\nand training of these algorithms require large datasets that provide realistic\ncoverage of various operational uncertainties. This paper presents a dynamic\nsimulation platform, called Transit-Gym, that can bridge this gap by providing\nthe ability to simulate scenarios, focusing on variation of demand models,\nvariations of route networks, and variations of vehicle-to-trip assignments.\nThe central contribution of this work is a domain-specific language and\nassociated experimentation tool-chain and infrastructure to enable\nsubject-matter experts to intuitively specify, simulate, and analyze\nlarge-scale transit scenarios and their parametric variations. Of particular\nsignificance is an integrated microscopic energy consumption model that also\nhelps to analyze the energy cost of various transit decisions made by the\ntransportation agency of a city.",
    "descriptor": "\nComments: Both Rongze Gui and Ruixiao Sun contributed to the paper equally\n",
    "authors": [
      "Ruixiao Sun",
      "Rongze Gui",
      "Himanshu Neema",
      "Yuche Chen",
      "Juliette Ugirumurera",
      "Joseph Severino",
      "Philip Pugliese",
      "Aron Laszka",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00105"
  },
  {
    "id": "arXiv:2107.00110",
    "title": "Classical Planning in Deep Latent Space",
    "abstract": "Current domain-independent, classical planners require symbolic models of the\nproblem domain and instance as input, resulting in a knowledge acquisition\nbottleneck. Meanwhile, although deep learning has achieved significant success\nin many fields, the knowledge is encoded in a subsymbolic representation which\nis incompatible with symbolic systems such as planners. We propose Latplan, an\nunsupervised architecture combining deep learning and classical planning. Given\nonly an unlabeled set of image pairs showing a subset of transitions allowed in\nthe environment (training inputs), Latplan learns a complete propositional PDDL\naction model of the environment. Later, when a pair of images representing the\ninitial and the goal states (planning inputs) is given, Latplan finds a plan to\nthe goal state in a symbolic latent space and returns a visualized plan\nexecution. We evaluate Latplan using image-based versions of 6 planning\ndomains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of\nLightsOut.",
    "descriptor": "\nComments: Under review at Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Masataro Asai",
      "Hiroshi Kajino",
      "Alex Fukunaga",
      "Christian Muise"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00110"
  },
  {
    "id": "arXiv:2107.00111",
    "title": "A Logic for Reasoning About LF Specifications",
    "abstract": "We present a logic named L_{LF} whose intended use is to formalize properties\nof specifications developed in the dependently typed lambda calculus LF. The\nlogic is parameterized by the LF signature that constitutes the specification.\nAtomic formulas correspond to typing derivations relative to this signature.\nThe logic includes a collection of propositional connectives and quantifiers.\nQuantification ranges over expressions that denote LF terms and LF contexts.\nQuantifiers of the first variety are qualified by simple types that describe\nthe functional structure associated with the variables they bind; deeper,\ndependency related properties are expressed by the body of the formula.\nContext-level quantifiers are qualified by context schemas that identify\npatterns of declarations out of which actual contexts may be constructed. The\nsemantics of variable-free atomic formulas is articulated via the derivability\nin LF of the judgements they encode. Propositional constants and connectives\nare understood in the usual manner and the meaning of quantifiers is explicated\nthrough substitutions of expressions that adhere to the type qualifications.\nThe logic is complemented by a proof system that enables reasoning that is\nsound with respect to the described semantics. The main novelties of the proof\nsystem are the provision for case-analysis style reasoning about LF judgements,\nsupport for inductive reasoning over the heights of LF derivations and the\nencoding of LF meta-theorems. The logic is motivated by the paradigmatic\nexample of type assignment in the simply-typed lambda calculus and the proof\nsystem is illustrated through the formalization of a proof of type uniqueness\nfor this calculus.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.04110\n",
    "authors": [
      "Gopalan Nadathur",
      "Mary Southern"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00111"
  },
  {
    "id": "arXiv:2107.00114",
    "title": "{QuickFlex: a Fast Algorithm for Flexible Region Construction for the  TSO-DSO Coordination",
    "abstract": "Most of the new technological changes in power systems are expected to take\nplace in distribution grids. The enormous potential for distribution\nflexibility could meet the transmission system's needs, changing the paradigm\nof generator-centric energy and ancillary services provided to a demand-centric\none, by placing more importance on smaller resources, such as flexible demands\nand electric vehicles. For unlocking such capabilities, it is essential to\nunderstand the aggregated flexibility that can be harvested from the large\npopulation of new technologies located in distribution grids. Distribution\ngrids, therefore, could provide aggregated flexibility at the transmission\nlevel. To date, most computational methods for estimating the aggregated\nflexibility at the interface between distribution grids and transmission grids\nhave the drawback of requiring significant computational time, which hinders\ntheir applicability. This paper presents a new algorithm, coined as QuickFlex}\nfor constructing the flexibility domain of distribution grids. Contrary to\nprevious methods, a priory flexibility domain accuracy can be selected. Our\nmethod requires few iterations for constructing the flexibility region. The\nnumber of iterations needed is mainly independent of the distribution grid's\ninput size and flexible elements. Numerical experiments are performed in four\ngrids ranging from 5 nodes to 123 nodes. It is shown that QuickFlex outperforms\nexisting proposals in the literature in both speed and accuracy.",
    "descriptor": "",
    "authors": [
      "Luis Lopez",
      "Alvaro Gonzalez-Castellanos",
      "David Pozo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00114"
  },
  {
    "id": "arXiv:2107.00116",
    "title": "Robust Generative Adversarial Imitation Learning via Local Lipschitzness",
    "abstract": "We explore methodologies to improve the robustness of generative adversarial\nimitation learning (GAIL) algorithms to observation noise. Towards this\nobjective, we study the effect of local Lipschitzness of the discriminator and\nthe generator on the robustness of policies learned by GAIL. In many robotics\napplications, the learned policies by GAIL typically suffer from a degraded\nperformance at test time since the observations from the environment might be\ncorrupted by noise. Hence, robustifying the learned policies against the\nobservation noise is of critical importance. To this end, we propose a\nregularization method to induce local Lipschitzness in the generator and the\ndiscriminator of adversarial imitation learning methods. We show that the\nmodified objective leads to learning significantly more robust policies.\nMoreover, we demonstrate -- both theoretically and experimentally -- that\ntraining a locally Lipschitz discriminator leads to a locally Lipschitz\ngenerator, thereby improving the robustness of the resultant policy. We perform\nextensive experiments on simulated robot locomotion environments from the\nMuJoCo suite that demonstrate the proposed method learns policies that\nsignificantly outperform the state-of-the-art generative adversarial imitation\nlearning algorithm when applied to test scenarios with noise-corrupted\nobservations.",
    "descriptor": "",
    "authors": [
      "Farzan Memarian",
      "Abolfazl Hashemi",
      "Scott Niekum",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00116"
  },
  {
    "id": "arXiv:2107.00123",
    "title": "If you Cheat, I Cheat: Cheating on a Collaborative Task with a Social  Robot",
    "abstract": "Robots may soon play a role in higher education by augmenting learning\nenvironments and managing interactions between instructors and learners.\nLittle, however, is known about how the presence of robots in the learning\nenvironment will influence academic integrity. This study therefore\ninvestigates if and how college students cheat while engaged in a collaborative\nsorting task with a robot. We employed a 2x2 factorial design to examine the\neffects of cheating exposure (exposure to cheating or no exposure) and task\nclarity (clear or vague rules) on college student cheating behaviors while\ninteracting with a robot. Our study finds that prior exposure to cheating on\nthe task significantly increases the likelihood of cheating. Yet, the tendency\nto cheat was not impacted by the clarity of the task rules. These results\nsuggest that normative behavior by classmates may strongly influence the\ndecision to cheat while engaged in an instructional experience with a robot.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Robot and Human Interactive Communication (ROMAN), 2021\n",
    "authors": [
      "Ali Ayub",
      "Huiqing Hu",
      "Guangwei Zhou",
      "Carter Fendley",
      "Crystal Ramsay",
      "Kathy Lou Jackson",
      "Alan R. Wagner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00123"
  },
  {
    "id": "arXiv:2107.00124",
    "title": "Learning a Reversible Embedding Mapping using Bi-Directional Manifold  Alignment",
    "abstract": "We propose a Bi-Directional Manifold Alignment (BDMA) that learns a\nnon-linear mapping between two manifolds by explicitly training it to be\nbijective. We demonstrate BDMA by training a model for a pair of languages\nrather than individual, directed source and target combinations, reducing the\nnumber of models by 50%. We show that models trained with BDMA in the \"forward\"\n(source to target) direction can successfully map words in the \"reverse\"\n(target to source) direction, yielding equivalent (or better) performance to\nstandard unidirectional translation models where the source and target language\nis flipped. We also show how BDMA reduces the overall size of the model.",
    "descriptor": "",
    "authors": [
      "Ashwinkumar Ganesan",
      "Francis Ferraro",
      "Tim Oates"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00124"
  },
  {
    "id": "arXiv:2107.00126",
    "title": "Global Systems Performance Analysis For Mobile Communications (GSM)  using Cellular Network CODECS",
    "abstract": "Global System for Mobile Communications (GSM) is a cellular network that is\npopular and has been growing in recent years. It was developed to solve\nfragmentation issues of the first cellular system, and it addresses digital\nmodulation methods, level of the network structure, and services. It is\nfundamental for organizations to become learning organizations to keep up with\nthe technology changes for network services to be at a competitive level. A\nsimulation analysis using the NetSim tool in this paper is presented for\ncomparing different cellular network codecs for GSM network performance. These\nparameters such as throughput, delay, and jitter are analyzed for the quality\nof service provided by each network codec. Unicast application for the cellular\nnetwork is modeled for different network scenarios. Depending on the evaluation\nand simulation, it was discovered that G.711, GSM_FR, and GSM-EFR performed\nbetter than the other codecs, and they are considered to be the best codecs for\ncellular networks. These codecs will be of best use to better the performance\nof the network in the near future.",
    "descriptor": "",
    "authors": [
      "Maphuthego Etu Maditsi",
      "Thulani Phakathi",
      "Francis Lugayizi",
      "Michael Esiefarienrhe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.00126"
  },
  {
    "id": "arXiv:2107.00127",
    "title": "SQRP: Sensing Quality-aware Robot Programming System for Non-expert  Programmers",
    "abstract": "Robot programming typically makes use of a set of mechanical skills that is\nacquired by machine learning. Because there is in general no guarantee that\nmachine learning produces robot programs that are free of surprising behavior,\nthe safe execution of a robot program must utilize monitoring modules that take\nsensor data as inputs in real time to ensure the correctness of the skill\nexecution. Owing to the fact that sensors and monitoring algorithms are usually\nsubject to physical restrictions and that effective robot programming is\nsensitive to the selection of skill parameters, these considerations may lead\nto different sensor input qualities such as the view coverage of a vision\nsystem that determines whether a skill can be successfully deployed in\nperforming a task. Choosing improper skill parameters may cause the monitoring\nmodules to delay or miss the detection of important events such as a mechanical\nfailure. These failures may reduce the throughput in robotic manufacturing and\ncould even cause a destructive system crash. To address above issues, we\npropose a sensing quality-aware robot programming system that automatically\ncomputes the sensing qualities as a function of the robot's environment and\nuses the information to guide non-expert users to select proper skill\nparameters in the programming phase. We demonstrate our system framework on a\n6DOF robot arm for an object pick-up task.",
    "descriptor": "\nComments: 7 pages, 9 figures, 1 table; accepted for presentation in IEEE ICRA 2021(IEEE International Conference on Robotics and Automation)\n",
    "authors": [
      "Yi-Hsuan Hsieh",
      "Pei-Chi Huang",
      "Aloysius K Mok"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00127"
  },
  {
    "id": "arXiv:2107.00133",
    "title": "On electrical gates on fungal colony",
    "abstract": "Mycelium networks are promising substrates for designing unconventional\ncomputing devices providing rich topologies and geometries where signals\npropagate and interact. Fulfilling our long-term objectives of prototyping\nelectrical analog computers from living mycelium networks, including networks\nhybridised with nanoparticles, we explore the possibility of implementing\nBoolean logical gates based on electrical properties of fungal colonies. We\nconverted a 3D image-data stack of \\emph{Aspergillus niger} fungal colony to an\nEuclidean graph and modelled the colony as resistive and capacitive (RC)\nnetworks, where electrical parameters of edges were functions of the edges'\nlengths. We found that {\\sc and}, {\\sc or} and {\\sc and-not} gates are\nimplementable in RC networks derived from the geometrical structure of the real\nfungal colony.",
    "descriptor": "",
    "authors": [
      "Alexander E. Beasley",
      "Phil Ayres",
      "Martin Tegelaar",
      "Michail-Antisthenis Tsompanas",
      "Andrew Adamatzky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.00133"
  },
  {
    "id": "arXiv:2107.00135",
    "title": "Attention Bottlenecks for Multimodal Fusion",
    "abstract": "Humans perceive the world by concurrently processing and fusing\nhigh-dimensional inputs from multiple modalities such as vision and audio.\nMachine perception models, in stark contrast, are typically modality-specific\nand optimised for unimodal benchmarks, and hence late-stage fusion of final\nrepresentations or predictions from each modality (`late-fusion') is still a\ndominant paradigm for multimodal video classification. Instead, we introduce a\nnovel transformer based architecture that uses `fusion bottlenecks' for\nmodality fusion at multiple layers. Compared to traditional pairwise\nself-attention, our model forces information between different modalities to\npass through a small number of bottleneck latents, requiring the model to\ncollate and condense the most relevant information in each modality and only\nshare what is necessary. We find that such a strategy improves fusion\nperformance, at the same time reducing computational cost. We conduct thorough\nablation studies, and achieve state-of-the-art results on multiple audio-visual\nclassification benchmarks including Audioset, Epic-Kitchens and VGGSound. All\ncode and models will be released.",
    "descriptor": "",
    "authors": [
      "Arsha Nagrani",
      "Shan Yang",
      "Anurag Arnab",
      "Aren Jansen",
      "Cordelia Schmid",
      "Chen Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00135"
  },
  {
    "id": "arXiv:2107.00140",
    "title": "Applications of the Free Energy Principle to Machine Learning and  Neuroscience",
    "abstract": "In this PhD thesis, we explore and apply methods inspired by the free energy\nprinciple to two important areas in machine learning and neuroscience. The free\nenergy principle is a general mathematical theory of the necessary\ninformation-theoretic behaviours of systems that maintain a separation from\ntheir environment. A core postulate of the theory is that complex systems can\nbe seen as performing variational Bayesian inference and minimizing an\ninformation-theoretic quantity called the variational free energy. The thesis\nis structured into three independent sections. Firstly, we focus on predictive\ncoding, a neurobiologically plausible process theory derived from the free\nenergy principle which argues that the primary function of the brain is to\nminimize prediction errors, showing how predictive coding can be scaled up and\nextended to be more biologically plausible, and elucidating its close links\nwith other methods such as Kalman Filtering. Secondly, we study active\ninference, a neurobiologically grounded account of action through variational\nmessage passing, and investigate how these methods can be scaled up to match\nthe performance of deep reinforcement learning methods. We additionally provide\na detailed mathematical understanding of the nature and origin of the\ninformation-theoretic objectives that underlie exploratory behaviour. Finally,\nwe investigate biologically plausible methods of credit assignment in the\nbrain. We first demonstrate a close link between predictive coding and the\nbackpropagation of error algorithm. We go on to propose novel and simpler\nalgorithms which allow for backprop to be implemented in purely local,\nbiologically plausible computations.",
    "descriptor": "\nComments: 30-06-21 initial upload\n",
    "authors": [
      "Beren Millidge"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00140"
  },
  {
    "id": "arXiv:2107.00143",
    "title": "One-class Steel Detector Using Patch GAN Discriminator for Visualising  Anomalous Feature Map",
    "abstract": "For steel product manufacturing in indoor factories, steel defect detection\nis important for quality control. For example, a steel sheet is extremely\ndelicate, and must be accurately inspected. However, to maintain the painted\nsteel parts of the infrastructure around a severe outdoor environment,\ncorrosion detection is critical for predictive maintenance. In this paper, we\npropose a general-purpose application for steel anomaly detection that consists\nof the following four components. The first, a learner, is a unit image\nclassification network to determine whether the region of interest or\nbackground has been recognised, after dividing the original large sized image\ninto 256 square unit images. The second, an extractor, is a discriminator\nfeature encoder based on a pre-trained steel generator with a patch generative\nadversarial network discriminator(GAN). The third, an anomaly detector, is a\none-class support vector machine(SVM) to predict the anomaly score using the\ndiscriminator feature. The fourth, an indicator, is an anomalous probability\nmap used to visually explain the anomalous features. Furthermore, we\ndemonstrated our method through the inspection of steel sheet defects with\n13,774 unit images using high-speed cameras, and painted steel corrosion with\n19,766 unit images based on an eye inspection of the photographs. Finally, we\nvisualise anomalous feature maps of steel using a strip and painted steel\ninspection dataset",
    "descriptor": "\nComments: 14 pages, 8 figures, 7 tables\n",
    "authors": [
      "Takato Yasuno",
      "Junichiro Fujii",
      "Sakura Fukami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.00143"
  },
  {
    "id": "arXiv:2107.00144",
    "title": "Greedy Decentralized Auction-based Task Allocation for Multi-Agent  Systems",
    "abstract": "We propose a decentralized auction-based algorithm for the solution of\ndynamic task allocation problems for spatially distributed multi-agent systems.\nIn our approach, each member of the multi-agent team is assigned to at most one\ntask from a set of spatially distributed tasks, while several agents can be\nallocated to the same task. The task assignment is dynamic since it is updated\nat discrete time stages (iterations) to account for the current states of the\nagents as the latter move towards the tasks assigned to them at the previous\nstage. Our proposed methods can find applications in problems of resource\nallocation by intelligent machines such as the delivery of packages by a fleet\nof unmanned or semi-autonomous aerial vehicles. In our approach, the task\nallocation accounts for both the cost incurred by the agents for the completion\nof their assigned tasks (e.g., energy or fuel consumption) and the rewards\nearned for their completion (which may reflect, for instance, the agents'\nsatisfaction). We propose a Greedy Coalition Auction Algorithm (GCAA) in which\nthe agents possess bid vectors representing their best evaluations of the task\nutilities. The agents propose bids, deduce an allocation based on their bid\nvectors and update them after each iteration. The solution estimate of the\nproposed task allocation algorithm converges after a finite number of\niterations which cannot exceed the number of agents. Finally, we use numerical\nsimulations to illustrate the effectiveness of the proposed task allocation\nalgorithm (in terms of performance and computation time) in several scenarios\ninvolving multiple agents and tasks distributed over a spatial 2D domain.",
    "descriptor": "\nComments: 8 pages, conference\n",
    "authors": [
      "Martin Braquet",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00144"
  },
  {
    "id": "arXiv:2107.00145",
    "title": "Improved Analysis of Online Balanced Clustering",
    "abstract": "In the online balanced graph repartitioning problem, one has to maintain a\nclustering of $n$ nodes into $\\ell$ clusters, each having $k = n / \\ell$ nodes.\nDuring runtime, an online algorithm is given a stream of communication requests\nbetween pairs of nodes: an inter-cluster communication costs one unit, while\nthe intra-cluster communication is free. An algorithm can change the\nclustering, paying unit cost for each moved node.\nThis natural problem admits a simple $O(\\ell^2 \\cdot k^2)$-competitive\nalgorithm COMP, whose performance is far apart from the best known lower bound\nof $\\Omega(\\ell \\cdot k)$. One of open questions is whether the dependency on\n$\\ell$ can be made linear; this question is of practical importance as in the\ntypical datacenter application where virtual machines are clustered on physical\nservers, $\\ell$ is of several orders of magnitude larger than $k$. We answer\nthis question affirmatively, proving that a simple modification of COMP is\n$(\\ell \\cdot 2^{O(k)})$-competitive.\nOn the technical level, we achieve our bound by translating the problem to a\nsystem of linear integer equations and using Graver bases to show the existence\nof a ``small'' solution.",
    "descriptor": "",
    "authors": [
      "Marcin Bienkowski",
      "Martin B\u00f6hm",
      "Martin Kouteck\u00fd",
      "Thomas Rothvo\u00df",
      "Ji\u0159\u00ed Sgall",
      "Pavel Vesel\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00145"
  },
  {
    "id": "arXiv:2107.00151",
    "title": "Intelligent Anomaly Mitigation in Cyber-Physical Inverter-based Systems",
    "abstract": "The distributed cooperative controllers for inverter-based systems rely on\ncommunication networks that make them vulnerable to cyber anomalies. In\naddition, the distortion effects of such anomalies may also propagate\nthroughout inverter-based cyber-physical systems due to the cooperative cyber\nlayer. In this paper, an intelligent anomaly mitigation technique for such\nsystems is presented utilizing data driven artificial intelligence tools that\nemploy artificial neural networks. The proposed technique is implemented in\nsecondary voltage control of distributed cooperative control-based microgrid,\nand results are validated by comparison with existing distributed secondary\ncontrol and real-time simulations on real-time simulator OPAL-RT.",
    "descriptor": "\nComments: Accepted at: 2021 IEEE Energy Conversion Congress and Exposition (ECCE)\n",
    "authors": [
      "Asad Ali Khan",
      "Omar A. Beg",
      "Sara Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00151"
  },
  {
    "id": "arXiv:2107.00152",
    "title": "Controllable Open-ended Question Generation with A New Question Type  Ontology",
    "abstract": "We investigate the less-explored task of generating open-ended questions that\nare typically answered by multiple sentences. We first define a new question\ntype ontology which differentiates the nuanced nature of questions better than\nwidely used question words. A new dataset with 4,959 questions is labeled based\non the new ontology. We then propose a novel question type-aware question\ngeneration framework, augmented by a semantic graph representation, to jointly\npredict question focuses and produce the question. Based on this framework, we\nfurther use both exemplars and automatically generated templates to improve\ncontrollability and diversity. Experiments on two newly collected large-scale\ndatasets show that our model improves question quality over competitive\ncomparisons based on automatic metrics. Human judges also rate our model\noutputs highly in answerability, coverage of scope, and overall quality.\nFinally, our model variants with templates can produce questions with enhanced\ncontrollability and diversity.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Shuyang Cao",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00152"
  },
  {
    "id": "arXiv:2107.00156",
    "title": "A Study of the Quality of Wikidata",
    "abstract": "Wikidata has been increasingly adopted by many communities for a wide variety\nof applications, which demand high-quality knowledge to deliver successful\nresults. In this paper, we develop a framework to detect and analyze\nlow-quality statements in Wikidata by shedding light on the current practices\nexercised by the community. We explore three indicators of data quality in\nWikidata, based on: 1) community consensus on the currently recorded knowledge,\nassuming that statements that have been removed and not added back are\nimplicitly agreed to be of low quality; 2) statements that have been\ndeprecated; and 3) constraint violations in the data. We combine these\nindicators to detect low-quality statements, revealing challenges with\nduplicate entities, missing triples, violated type rules, and taxonomic\ndistinctions. Our findings complement ongoing efforts by the Wikidata community\nto improve data quality, aiming to make it easier for users and editors to find\nand correct mistakes.",
    "descriptor": "",
    "authors": [
      "Kartik Shenoy",
      "Filip Ilievski",
      "Daniel Garijo",
      "Daniel Schwabe",
      "Pedro Szekely"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00156"
  },
  {
    "id": "arXiv:2107.00157",
    "title": "Cross-Lingual Adaptation for Type Inference",
    "abstract": "Deep learning-based techniques have been widely applied to the program\nanalysis tasks, in fields such as type inference, fault localization, and code\nsummarization. Hitherto deep learning-based software engineering systems rely\nthoroughly on supervised learning approaches, which require laborious manual\neffort to collect and label a prohibitively large amount of data. However, most\nTuring-complete imperative languages share similar control- and data-flow\nstructures, which make it possible to transfer knowledge learned from one\nlanguage to another. In this paper, we propose cross-lingual adaptation of\nprogram analysis, which allows us to leverage prior knowledge learned from the\nlabeled dataset of one language and transfer it to the others. Specifically, we\nimplemented a cross-lingual adaptation framework, PLATO, to transfer a deep\nlearning-based type inference procedure across weakly typed languages, e.g.,\nPython to JavaScript and vice versa. PLATO incorporates a novel joint graph\nkernelized attention based on abstract syntax tree and control flow graph, and\napplies anchor word augmentation across different languages. Besides, by\nleveraging data from strongly typed languages, PLATO improves the perplexity of\nthe backbone cross-programming-language model and the performance of downstream\ncross-lingual transfer for type inference. Experimental results illustrate that\nour framework significantly improves the transferability over the baseline\nmethod by a large margin.",
    "descriptor": "",
    "authors": [
      "Zhiming Li",
      "Xiaofei Xie",
      "Haoliang Li",
      "Zhengzi Xu",
      "Yi Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00157"
  },
  {
    "id": "arXiv:2107.00159",
    "title": "A New Algorithm for Equivalence of Cyclic Codes and Its Applications",
    "abstract": "Cyclic codes are among the most important families of codes in coding theory\nfor both theoretical and practical reasons. Despite their prominence and\nintensive research on cyclic codes for over a half century, there are still\nopen problems related to cyclic codes. In this work, we use recent results on\nthe equivalence of cyclic codes to create a more efficient algorithm to\npartition cyclic codes by equivalence based on cyclotomic cosets. This\nalgorithm is then implemented to carry out computer searches for both cyclic\ncodes and quasi-cyclic (QC) codes with good parameters. We also generalize\nthese results to repeated-root cases. We have found several new linear codes\nthat are cyclic or QC as an application of the new approach, as well as more\ndesirable constructions for linear codes with best known parameters. With the\nadditional new codes obtained through standard constructions, we have found a\ntotal of 14 new linear codes.",
    "descriptor": "",
    "authors": [
      "Nuh Aydin",
      "R. Oliver VandenBerg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00159"
  },
  {
    "id": "arXiv:2107.00160",
    "title": "Hierarchical Control of Utility-Scale Solar PV Plants for Mitigation of  Generation Variability and Ancillary Service Provision",
    "abstract": "Renewable energy technologies including solar and wind inevitably play a\nleading role in meeting the growing demand for a decarbonized and clean power\ngrid. However, these technologies are highly dependent of meteorological\nconditions of power plant site and the challenge remains on how to cope with\ntheir short-term and momentarily variability. This paper presents a\nhierarchical control system to provide ancillary services from a solar PV power\nplant to the grid without the need for additional non-solar resources. With\ncoordinated management of each inverter in the system, the control system\ncommands the power plant to proactively curtail a fraction of its instantaneous\nmaximum power potential, which gives the plant enough headroom to ramp up or\ndown power production from the overall power plant, for a service such as\nregulation reserve, even under changing cloud cover conditions. A case study\nfrom a site in Hawaii with one-second resolution solar irradiance data is used\nto verify the efficacy of the proposed control system. The algorithm is\nsubsequently compared with an alternative control technology from the\nliterature, the grouping control algorithm; the results show that the proposed\nhierarchical control system is over 10 times more effective in reducing\ngenerator mileage to support power fluctuations from solar PV power plants.",
    "descriptor": "",
    "authors": [
      "Simon Julien",
      "Amirhossein Sajadi",
      "Bri-Mathias Hodge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00160"
  },
  {
    "id": "arXiv:2107.00161",
    "title": "The Use of Bandit Algorithms in Intelligent Interactive Recommender  Systems",
    "abstract": "In today's business marketplace, many high-tech Internet enterprises\nconstantly explore innovative ways to provide optimal online user experiences\nfor gaining competitive advantages. The great needs of developing intelligent\ninteractive recommendation systems are indicated, which could sequentially\nsuggest users the most proper items by accurately predicting their preferences,\nwhile receiving the up-to-date feedback to refine the recommendation results,\ncontinuously. Multi-armed bandit algorithms, which have been widely applied\ninto various online systems, are quite capable of delivering such efficient\nrecommendation services. However, few existing bandit models are able to adapt\nto new changes introduced by the modern recommender systems.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00161"
  },
  {
    "id": "arXiv:2107.00164",
    "title": "MIND: In-Network Memory Management for Disaggregated Data Centers",
    "abstract": "Memory-compute disaggregation promises transparent elasticity, high\nutilization and balanced usage for resources in data centers by physically\nseparating memory and compute into network-attached resource \"blades\". However,\nexisting designs achieve performance at the cost of resource elasticity,\nrestricting memory sharing to a single compute blade to avoid costly memory\ncoherence traffic over the network.\nIn this work, we show that emerging programmable network switches can enable\nan efficient shared memory abstraction for disaggregated architectures by\nplacing memory management logic in the network fabric. We find that\ncentralizing memory management in the network permits bandwidth and\nlatency-efficient realization of in-network cache coherence protocols, while\nprogrammable switch ASICs support other memory management logic at line-rate.\nWe realize these insights into MIND, an in-network memory management unit for\nrack-scale memory disaggregation. MIND enables transparent resource elasticity\nwhile matching the performance of prior memory disaggregation proposals for\nreal-world workloads.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Seung-seob Lee",
      "Yanpeng Yu",
      "Yupeng Tang",
      "Anurag Khandelwal",
      "Lin Zhong",
      "Abhishek Bhattacharjee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00164"
  },
  {
    "id": "arXiv:2107.00165",
    "title": "Joint Optimization of Autonomous Electric Vehicle Fleet Operations and  Charging Station Siting",
    "abstract": "Charging infrastructure is the coupling link between power and transportation\nnetworks, thus determining charging station siting is necessary for planning of\npower and transportation systems. While previous works have either optimized\nfor charging station siting given historic travel behavior, or optimized fleet\nrouting and charging given an assumed placement of the stations, this paper\nintroduces a linear program that optimizes for station siting and macroscopic\nfleet operations in a joint fashion. Given an electricity retail rate and a set\nof travel demand requests, the optimization minimizes total cost for an\nautonomous EV fleet comprising of travel costs, station procurement costs,\nfleet procurement costs, and electricity costs, including demand charges.\nSpecifically, the optimization returns the number of charging plugs for each\ncharging rate (e.g., Level 2, DC fast charging) at each candidate location, as\nwell as the optimal routing and charging of the fleet. From a case-study of an\nelectric vehicle fleet operating in San Francisco, our results show that,\nalbeit with range limitations, small EVs with low procurement costs and high\nenergy efficiencies are the most cost-effective in terms of total ownership\ncosts. Furthermore, the optimal siting of charging stations is more spatially\ndistributed than the current siting of stations, consisting mainly of\nhigh-power Level 2 AC stations (16.8 kW) with a small share of DC fast charging\nstations and no standard 7.7kW Level 2 stations. Optimal siting reduces the\ntotal costs, empty vehicle travel, and peak charging load by up to 10%.",
    "descriptor": "\nComments: 9 pages, 7 figures. A version of this submission, with minor formatting changes, is to be published in the proceedings of the 24th IEEE International Conference on Intelligent Transportation Systems (ITSC 2021)\n",
    "authors": [
      "Justin Luke",
      "Mauro Salazar",
      "Ram Rajagopal",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00165"
  },
  {
    "id": "arXiv:2107.00166",
    "title": "Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win  the Jackpot?",
    "abstract": "There have been long-standing controversies and inconsistencies over the\nexperiment setup and criteria for identifying the \"winning ticket\" in\nliterature. To reconcile such, we revisit the definition of lottery ticket\nhypothesis, with comprehensive and more rigorous conditions. Under our new\ndefinition, we show concrete evidence to clarify whether the winning ticket\nexists across the major DNN architectures and/or applications. Through\nextensive experiments, we perform quantitative analysis on the correlations\nbetween winning tickets and various experimental factors, and empirically study\nthe patterns of our observations. We find that the key training\nhyperparameters, such as learning rate and training epochs, as well as the\narchitecture characteristics such as capacities and residual connections, are\nall highly correlated with whether and when the winning tickets can be\nidentified. Based on our analysis, we summarize a guideline for parameter\nsettings in regards of specific architecture characteristics, which we hope to\ncatalyze the research progress on the topic of lottery ticket hypothesis.",
    "descriptor": "",
    "authors": [
      "Xiaolong Ma",
      "Geng Yuan",
      "Xuan Shen",
      "Tianlong Chen",
      "Xuxi Chen",
      "Xiaohan Chen",
      "Ning Liu",
      "Minghai Qin",
      "Sijia Liu",
      "Zhangyang Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00166"
  },
  {
    "id": "arXiv:2107.00175",
    "title": "Elbert: Fast Albert with Confidence-Window Based Early Exit",
    "abstract": "Despite the great success in Natural Language Processing (NLP) area, large\npre-trained language models like BERT are not well-suited for\nresource-constrained or real-time applications owing to the large number of\nparameters and slow inference speed. Recently, compressing and accelerating\nBERT have become important topics. By incorporating a parameter-sharing\nstrategy, ALBERT greatly reduces the number of parameters while achieving\ncompetitive performance. Nevertheless, ALBERT still suffers from a long\ninference time. In this work, we propose the ELBERT, which significantly\nimproves the average inference speed compared to ALBERT due to the proposed\nconfidence-window based early exit mechanism, without introducing additional\nparameters or extra training overhead. Experimental results show that ELBERT\nachieves an adaptive inference speedup varying from 2$\\times$ to 10$\\times$\nwith negligible accuracy degradation compared to ALBERT on various datasets.\nBesides, ELBERT achieves higher accuracy than existing early exit methods used\nfor accelerating BERT under the same computation cost. Furthermore, to\nunderstand the principle of the early exit mechanism, we also visualize the\ndecision-making process of it in ELBERT.",
    "descriptor": "",
    "authors": [
      "Keli Xie",
      "Siyuan Lu",
      "Meiqi Wang",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00175"
  },
  {
    "id": "arXiv:2107.00176",
    "title": "Reinforcement Learning for Abstractive Question Summarization with  Question-aware Semantic Rewards",
    "abstract": "The growth of online consumer health questions has led to the necessity for\nreliable and accurate question answering systems. A recent study showed that\nmanual summarization of consumer health questions brings significant\nimprovement in retrieving relevant answers. However, the automatic\nsummarization of long questions is a challenging task due to the lack of\ntraining data and the complexity of the related subtasks, such as the question\nfocus and type recognition. In this paper, we introduce a reinforcement\nlearning-based framework for abstractive question summarization. We propose two\nnovel rewards obtained from the downstream tasks of (i) question-type\nidentification and (ii) question-focus recognition to regularize the question\ngeneration model. These rewards ensure the generation of semantically valid\nquestions and encourage the inclusion of key medical entities/foci in the\nquestion summary. We evaluated our proposed method on two benchmark datasets\nand achieved higher performance over state-of-the-art models. The manual\nevaluation of the summaries reveals that the generated questions are more\ndiverse and have fewer factual inconsistencies than the baseline summaries",
    "descriptor": "\nComments: To appear at ACL 2021\n",
    "authors": [
      "Shweta Yadav",
      "Deepak Gupta",
      "Asma Ben Abacha",
      "Dina Demner-Fushman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00176"
  },
  {
    "id": "arXiv:2107.00178",
    "title": "Attention-based multi-channel speaker verification with ad-hoc  microphone arrays",
    "abstract": "Recently, ad-hoc microphone array has been widely studied. Unlike traditional\nmicrophone array settings, the spatial arrangement and number of microphones of\nad-hoc microphone arrays are not known in advance, which hinders the adaptation\nof traditional speaker verification technologies to ad-hoc microphone arrays.\nTo overcome this weakness, in this paper, we propose attention-based\nmulti-channel speaker verification with ad-hoc microphone arrays. Specifically,\nwe add an inter-channel processing layer and a global fusion layer after the\npooling layer of a single-channel speaker verification system. The\ninter-channel processing layer applies a so-called residual self-attention\nalong the channel dimension for allocating weights to different microphones.\nThe global fusion layer integrates all channels in a way that is independent to\nthe number of the input channels. We further replace the softmax operator in\nthe residual self-attention with sparsemax, which forces the channel weights of\nvery noisy channels to zero. Experimental results with ad-hoc microphone arrays\nof over 30 channels demonstrate the effectiveness of the proposed methods. For\nexample, the multi-channel speaker verification with sparsemax achieves an\nequal error rate (EER) of over 20% lower than oracle one-best system on\nsemi-real data sets, and over 30% lower on simulation data sets, in test\nscenarios with both matched and mismatched channel numbers.",
    "descriptor": "\nComments: Submitted to APSIPA ASC 2021\n",
    "authors": [
      "Chengdong Liang",
      "Junqi Chen",
      "Shanzheng Guan",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00178"
  },
  {
    "id": "arXiv:2107.00181",
    "title": "Revisiting Knowledge Distillation: An Inheritance and Exploration  Framework",
    "abstract": "Knowledge Distillation (KD) is a popular technique to transfer knowledge from\na teacher model or ensemble to a student model. Its success is generally\nattributed to the privileged information on similarities/consistency between\nthe class distributions or intermediate feature representations of the teacher\nmodel and the student model. However, directly pushing the student model to\nmimic the probabilities/features of the teacher model to a large extent limits\nthe student model in learning undiscovered knowledge/features. In this paper,\nwe propose a novel inheritance and exploration knowledge distillation framework\n(IE-KD), in which a student model is split into two parts - inheritance and\nexploration. The inheritance part is learned with a similarity loss to transfer\nthe existing learned knowledge from the teacher model to the student model,\nwhile the exploration part is encouraged to learn representations different\nfrom the inherited ones with a dis-similarity loss. Our IE-KD framework is\ngeneric and can be easily combined with existing distillation or mutual\nlearning methods for training deep neural networks. Extensive experiments\ndemonstrate that these two parts can jointly push the student model to learn\nmore diversified and effective representations, and our IE-KD can be a general\ntechnique to improve the student network to achieve SOTA performance.\nFurthermore, by applying our IE-KD to the training of two networks, the\nperformance of both can be improved w.r.t. deep mutual learning. The code and\nmodels of IE-KD will be make publicly available at\nhttps://github.com/yellowtownhz/IE-KD.",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Zhen Huang",
      "Xu Shen",
      "Jun Xing",
      "Tongliang Liu",
      "Xinmei Tian",
      "Houqiang Li",
      "Bing Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00181"
  },
  {
    "id": "arXiv:2107.00183",
    "title": "Stochastic Performance Modeling for Practical Byzantine Fault Tolerance  Consensus in Blockchain",
    "abstract": "The practical Byzantine fault tolerant (PBFT) consensus mechanism is one of\nthe most basic consensus algorithms (or protocols) in blockchain technologies,\nthus its performance evaluation is an interesting and challenging topic due to\na higher complexity of its consensus work in the peer-to-peer network. This\npaper describes a simple stochastic performance model of the PBFT consensus\nmechanism, which is refined as not only a queueing system with complicated\nservice times but also a level-independent quasi-birth-and-death (QBD) process.\nFrom the level-independent QBD process, we apply the matrix-geometric solution\nto obtain a necessary and sufficient condition under which the PBFT consensus\nsystem is stable, and to be able to numerically compute the stationary\nprobability vector of the QBD process. Thus we provide four useful performance\nmeasures of the PBFT consensus mechanism, and can numerically calculate the\nfour performance measures. Finally, we use some numerical examples to verify\nthe validity of our theoretical results, and show how the four performance\nmeasures are influenced by some key parameters of the PBFT consensus. By means\nof the theory of multi-dimensional Markov processes, we are optimistic that the\nmethodology and results given in this paper are applicable in a wide range\nresearch of PBFT consensus mechanism and even other types of consensus\nmechanisms.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Fan-Qi Ma",
      "Quan-Lin Li",
      "Yi-Han Liu",
      "Yan-Xia Chang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.00183"
  },
  {
    "id": "arXiv:2107.00184",
    "title": "AutoSF+: Towards Automatic Scoring Function Design for Knowledge Graph  Embedding",
    "abstract": "Scoring functions, which measure the plausibility of triples, have become the\ncrux of knowledge graph embedding (KGE). Plenty of scoring functions, targeting\nat capturing different kinds of relations in KGs, have been designed by experts\nin recent years. However, as relations can exhibit intricate patterns that are\nhard to infer before training, none of them can consistently perform the best\non existing benchmark tasks. AutoSF has shown the significance of using\nautomated machine learning (AutoML) to design KG- dependent scoring functions.\nIn this paper, we propose AutoSF+ as an extension of AutoSF. First, we improve\nthe search algorithm with the evolutionary search, which can better explore the\nsearch space. Second, we evaluate AutoSF+ on the recently developed benchmark\nOGB. Besides, we apply AutoSF+ to the new task, i.e., entity classification, to\nshow that it can improve the task beyond KG completion.",
    "descriptor": "",
    "authors": [
      "Yongqi Zhang",
      "Zhanke Zhou",
      "Quanming Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00184"
  },
  {
    "id": "arXiv:2107.00185",
    "title": "A Blockchain-based Carbon Credit Ecosystem",
    "abstract": "Climate change and global warming are the significant challenges of the new\ncentury. A viable solution to mitigate greenhouse gas emissions is via a\nglobally incentivized market mechanism proposed in the Kyoto protocol. In this\nview, the carbon dioxide (or other greenhouse gases) emission is considered a\ncommodity, forming a carbon trading system. There have been attempts in\ndeveloping this idea in the past decade with limited success. The main\nchallenges of current systems are fragmented implementations, lack of\ntransparency leading to over-crediting and double-spending, and substantial\ntransaction costs that transfer wealth to brokers and agents. We aim to create\na Carbon Credit Ecosystem using smart contracts that operate in conjunction\nwith blockchain technology in order to bring more transparency, accessibility,\nliquidity, and standardization to carbon markets. This ecosystem includes a\ntokenization mechanism to securely digitize carbon credits with clear minting\nand burning protocols, a transparent mechanism for distribution of tokens, a\nfree automated market maker for trading the carbon tokens, and mechanisms to\nengage all stakeholders, including the energy industry, project verifiers,\nliquidity providers, NGOs, concerned citizens, and governments. This approach\ncould be used in a variety of other credit/trading systems.",
    "descriptor": "",
    "authors": [
      "Soheil Saraji",
      "Mike Borowczak"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00185"
  },
  {
    "id": "arXiv:2107.00186",
    "title": "Word-Free Spoken Language Understanding for Mandarin-Chinese",
    "abstract": "Spoken dialogue systems such as Siri and Alexa provide great convenience to\npeople's everyday life. However, current spoken language understanding (SLU)\npipelines largely depend on automatic speech recognition (ASR) modules, which\nrequire a large amount of language-specific training data. In this paper, we\npropose a Transformer-based SLU system that works directly on phones. This\nacoustic-based SLU system consists of only two blocks and does not require the\npresence of ASR module. The first block is a universal phone recognition\nsystem, and the second block is a Transformer-based language model for phones.\nWe verify the effectiveness of the system on an intent classification dataset\nin Mandarin Chinese.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Guo",
      "Yuexin Li",
      "Guo Chen",
      "Xingyu Chen",
      "Akshat Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00186"
  },
  {
    "id": "arXiv:2107.00187",
    "title": "Context-aware Execution Migration Tool for Data Science Jupyter  Notebooks on Hybrid Clouds",
    "abstract": "Interactive computing notebooks, such as Jupyter notebooks, have become a\npopular tool for developing and improving data-driven models. Such notebooks\ntend to be executed either in the user's own machine or in a cloud environment,\nhaving drawbacks and benefits in both approaches. This paper presents a\nsolution developed as a Jupyter extension that automatically selects which\ncells, as well as in which scenarios, such cells should be migrated to a more\nsuitable platform for execution. We describe how we reduce the execution state\nof the notebook to decrease migration time and we explore the knowledge of user\ninteractivity patterns with the notebook to determine which blocks of cells\nshould be migrated. Using notebooks from Earth science (remote sensing), image\nrecognition, and hand written digit identification (machine learning), our\nexperiments show notebook state reductions of up to 55x and migration decisions\nleading to performance gains of up to 3.25x when the user interactivity with\nthe notebook is taken into consideration.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Renato L. F. Cunha",
      "Lucas V. Real",
      "Renan Souza",
      "Bruno Silva",
      "Marco A. S. Netto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00187"
  },
  {
    "id": "arXiv:2107.00189",
    "title": "Capturing Event Argument Interaction via A Bi-Directional Entity-Level  Recurrent Decoder",
    "abstract": "Capturing interactions among event arguments is an essential step towards\nrobust event argument extraction (EAE). However, existing efforts in this\ndirection suffer from two limitations: 1) The argument role type information of\ncontextual entities is mainly utilized as training signals, ignoring the\npotential merits of directly adopting it as semantically rich input features;\n2) The argument-level sequential semantics, which implies the overall\ndistribution pattern of argument roles over an event mention, is not well\ncharacterized. To tackle the above two bottlenecks, we formalize EAE as a\nSeq2Seq-like learning problem for the first time, where a sentence with a\nspecific event trigger is mapped to a sequence of event argument roles. A\nneural architecture with a novel Bi-directional Entity-level Recurrent Decoder\n(BERD) is proposed to generate argument roles by incorporating contextual\nentities' argument role predictions, like a word-by-word text generation\nprocess, thereby distinguishing implicit argument distribution patterns within\nan event more accurately.",
    "descriptor": "",
    "authors": [
      "Xiangyu Xi",
      "Wei Ye",
      "Shikun Zhang",
      "Quanxiu Wang",
      "Huixing Jiang",
      "Wei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00189"
  },
  {
    "id": "arXiv:2107.00191",
    "title": "Unsupervised Model Drift Estimation with Batch Normalization Statistics  for Dataset Shift Detection and Model Selection",
    "abstract": "While many real-world data streams imply that they change frequently in a\nnonstationary way, most of deep learning methods optimize neural networks on\ntraining data, and this leads to severe performance degradation when dataset\nshift happens. However, it is less possible to annotate or inspect newly\nstreamed data by humans, and thus it is desired to measure model drift at\ninference time in an unsupervised manner. In this paper, we propose a novel\nmethod of model drift estimation by exploiting statistics of batch\nnormalization layer on unlabeled test data. To remedy possible sampling error\nof streamed input data, we adopt low-rank approximation to each\nrepresentational layer. We show the effectiveness of our method not only on\ndataset shift detection but also on model selection when there are multiple\ncandidate models among model zoo or training trajectories in an unsupervised\nway. We further demonstrate the consistency of our method by comparing model\ndrift scores between different network architectures.",
    "descriptor": "\nComments: 11 pages, 5 figures, 2 tables\n",
    "authors": [
      "Wonju Lee",
      "Seok-Yong Byun",
      "Jooeun Kim",
      "Minje Park",
      "Kirill Chechil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00191"
  },
  {
    "id": "arXiv:2107.00194",
    "title": "Adaptive Control for Robotic Manipulation of Deformable Linear Objects  with Offline and Online Learning of Unknown Models",
    "abstract": "The deformable linear objects (DLOs) are common in both industrial and\ndomestic applications, such as wires, cables, ropes. Because of its highly\ndeformable nature, it is difficult for the robot to reproduce human's dexterous\nskills on DLOs. In this paper, the unknown deformation model is estimated in\nboth the offline and online manners. The offline learning aims to provide a\ngood approximation prior to the manipulation task, while the online learning\naims to compensate the errors due to insufficient training (e.g. limited\ndatasets) in the offline phase. The offline module works by constructing a\nseries of supervised neural networks (NNs), then the online module receives the\nlearning results directly and further updates them with the technique of\nadaptive NNs. A new adaptive controller is also proposed to allow the robot to\nperform manipulation tasks concurrently in the online phase. The stability of\nthe closed-loop system and the convergence of task errors are rigorously proved\nwith Lyapunov method. Simulation studies are presented to illustrate the\nperformance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Mingrui Yu",
      "Hanzhong Zhong",
      "Fangxun Zhong",
      "Xiang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00194"
  },
  {
    "id": "arXiv:2107.00197",
    "title": "Few-Shot Learning with a Strong Teacher",
    "abstract": "Few-shot learning (FSL) aims to train a strong classifier using limited\nlabeled examples. Many existing works take the meta-learning approach, sampling\nfew-shot tasks in turn and optimizing the few-shot learner's performance on\nclassifying the query examples. In this paper, we point out two potential\nweaknesses of this approach. First, the sampled query examples may not provide\nsufficient supervision for the few-shot learner. Second, the effectiveness of\nmeta-learning diminishes sharply with increasing shots (i.e., the number of\ntraining examples per class). To resolve these issues, we propose a novel\nobjective to directly train the few-shot learner to perform like a strong\nclassifier. Concretely, we associate each sampled few-shot task with a strong\nclassifier, which is learned with ample labeled examples. The strong classifier\nhas a better generalization ability and we use it to supervise the few-shot\nlearner. We present an efficient way to construct the strong classifier, making\nour proposed objective an easily plug-and-play term to existing meta-learning\nbased FSL methods. We validate our approach in combinations with many\nrepresentative meta-learning methods. On several benchmark datasets including\nminiImageNet and tiredImageNet, our approach leads to a notable improvement\nacross a variety of tasks. More importantly, with our approach, meta-learning\nbased FSL methods can consistently outperform non-meta-learning based ones,\neven in a many-shot setting, greatly strengthening their applicability.",
    "descriptor": "",
    "authors": [
      "Han-Jia Ye",
      "Lu Ming",
      "De-Chuan Zhan",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00197"
  },
  {
    "id": "arXiv:2107.00200",
    "title": "Social Coordination and Altruism in Autonomous Driving",
    "abstract": "Despite the leaps in the autonomous driving domain, autonomous vehicles (AVs)\nare still inefficient and limited in terms of cooperating with each other or\ncoordinating with vehicles operated by humans. A group of autonomous and\nhuman-driven vehicles (HVs) which work together to optimize an altruistic\nsocial utility -- as opposed to the egoistic individual utility -- can co-exist\nseamlessly and assure safety and efficiency on the road. Achieving this mission\nis challenging in the absence of explicit coordination among agents.\nAdditionally, existence of humans in mixed-autonomy environments create social\ndilemmas as they are known to be heterogeneous in social preference and their\nbehavior is hard to predict by nature. Formally, we model an AV's maneuver\nplanning in mixed-autonomy traffic as a partially-observable stochastic game\nand attempt to derive optimal policies that lead to socially-desirable outcomes\nusing our multi-agent reinforcement learning framework. We introduce a\nquantitative representation of the AVs' social value orientation and design a\ndistributed reward structure that induces altruism into their decision making\nprocess. Our trained altruistic AVs are able to form alliances, guide the\ntraffic, and affect the behavior of the HVs to handle conflictive and\ncompetitive driving scenarios. As a case study, we compare egoistic AVs to our\naltruistic autonomous agents in a highway merging case study and demonstrate a\nsignificant improvement in the number of successful merges as well as the\noverall traffic flow and safety.",
    "descriptor": "\nComments: This paper is submitted to IEEE Transactions on Intelligent Transportation Systems on June 2021\n",
    "authors": [
      "Behrad Toghi",
      "Rodolfo Valiente",
      "Dorsa Sadigh",
      "Ramtin Pedarsani",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00200"
  },
  {
    "id": "arXiv:2107.00204",
    "title": "Markov Decision Process modeled with Bandits for Sequential Decision  Making in Linear-flow",
    "abstract": "In membership/subscriber acquisition and retention, we sometimes need to\nrecommend marketing content for multiple pages in sequence. Different from\ngeneral sequential decision making process, the use cases have a simpler flow\nwhere customers per seeing recommended content on each page can only return\nfeedback as moving forward in the process or dropping from it until a\ntermination state. We refer to this type of problems as sequential decision\nmaking in linear--flow. We propose to formulate the problem as an MDP with\nBandits where Bandits are employed to model the transition probability matrix.\nAt recommendation time, we use Thompson sampling (TS) to sample the transition\nprobabilities and allocate the best series of actions with analytical solution\nthrough exact dynamic programming. The way that we formulate the problem allows\nus to leverage TS's efficiency in balancing exploration and exploitation and\nBandit's convenience in modeling actions' incompatibility. In the simulation\nstudy, we observe the proposed MDP with Bandits algorithm outperforms\nQ-learning with $\\epsilon$-greedy and decreasing $\\epsilon$, independent\nBandits, and interaction Bandits. We also find the proposed algorithm's\nperformance is the most robust to changes in the across-page interdependence\nstrength.",
    "descriptor": "\nComments: Accepted by 2021 KDD Multi-Armed Bandits and Reinforcement Learning Workshop: this https URL\n",
    "authors": [
      "Wenjun Zeng",
      "Yi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00204"
  },
  {
    "id": "arXiv:2107.00206",
    "title": "Multi-modal Graph Learning for Disease Prediction",
    "abstract": "Benefiting from the powerful expressive capability of graphs, graph-based\napproaches have achieved impressive performance in various biomedical\napplications. Most existing methods tend to define the adjacency matrix among\nsamples manually based on meta-features, and then obtain the node embeddings\nfor downstream tasks by Graph Representation Learning (GRL). However, it is not\neasy for these approaches to generalize to unseen samples. Meanwhile, the\ncomplex correlation between modalities is also ignored. As a result, these\nfactors inevitably yield the inadequacy of providing valid information about\nthe patient's condition for a reliable diagnosis. In this paper, we propose an\nend-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.\nTo effectively exploit the rich information across multi-modality associated\nwith diseases, amodal-attentional multi-modal fusion is proposed to integrate\nthe features of each modality by leveraging the correlation and complementarity\nbetween the modalities. Furthermore, instead of defining the adjacency matrix\nmanually as existing methods, the latent graph structure can be captured\nthrough a novel way of adaptive graph learning. It could be jointly optimized\nwith the prediction model, thus revealing the intrinsic connections among\nsamples. Unlike the previous transductive methods, our model is also applicable\nto the scenario of inductive learning for those unseen data. An extensive group\nof experiments on two disease prediction problems is then carefully designed\nand presented, demonstrating that MMGL obtains more favorable performances. In\naddition, we also visualize and analyze the learned graph structure to provide\nmore reliable decision support for doctors in real medical applications and\ninspiration for disease research.",
    "descriptor": "\nComments: 10 pages, 4 figures, 2 tables\n",
    "authors": [
      "Shuai Zheng",
      "Zhenfeng Zhu",
      "Zhizhe Liu",
      "Zhenyu Guo",
      "Yang Liu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00206"
  },
  {
    "id": "arXiv:2107.00209",
    "title": "Binary Neural Network in Robotic Manipulation: Flexible Object  Manipulation for Humanoid Robot Using Partially Binarized Auto-Encoder on  FPGA",
    "abstract": "A neural network based flexible object manipulation system for a humanoid\nrobot on FPGA is proposed. Although the manipulations of flexible objects using\nrobots attract ever increasing attention since these tasks are the basic and\nessential activities in our daily life, it has been put into practice only\nrecently with the help of deep neural networks. However such systems have\nrelied on GPU accelerators, which cannot be implemented into the space limited\nrobotic body. Although field programmable gate arrays (FPGAs) are known to be\nenergy efficient and suitable for embedded systems, the model size should be\ndrastically reduced since FPGAs have limited on-chip memory. To this end, we\npropose ``partially'' binarized deep convolutional auto-encoder technique,\nwhere only an encoder part is binarized to compress model size without\ndegrading the inference accuracy. The model implemented on Xilinx ZCU102\nachieves 41.1 frames per second with a power consumption of 3.1W, {\\awano{which\ncorresponds to 10x and 3.7x improvements from the systems implemented on Core\ni7 6700K and RTX 2080 Ti, respectively.",
    "descriptor": "\nComments: Accepted to IROS2021\n",
    "authors": [
      "Satoshi Ohara",
      "Tetsuya Ogata",
      "Hiromitsu Awano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00209"
  },
  {
    "id": "arXiv:2107.00211",
    "title": "A Few Interactions Improve Distributed Nonparametric Estimation,  Optimally",
    "abstract": "Consider the problem of nonparametric estimation of an unknown\n$\\beta$-H\\\"older smooth density $p_{XY}$ at a given point, where $X$ and $Y$\nare both $d$ dimensional. An infinite sequence of i.i.d.\\ samples $(X_i,Y_i)$\nare generated according to this distribution, and Alice and Bob observe $(X_i)$\nand $(Y_i)$, respectively. They are allowed to exchange $k$ bits either in\noneway or interactively in order for Bob to estimate the unknown density. For\n$\\beta\\in(0,2]$, we show that the minimax mean square risk is order\n$\\left(\\frac{k}{\\log k} \\right)^{-\\frac{2\\beta}{d+2\\beta}}$ for one-way\nprotocols and $k^{-\\frac{2\\beta}{d+2\\beta}}$ for interactive protocols. The\nlogarithmic improvement is nonexistent in the parametric counterparts, and\ntherefore can be regarded as a consequence of nonparametric nature of the\nproblem. Moreover, a few rounds of interactions achieve the interactive minimax\nrate: we show that the number of rounds can grow as slowly as the\nsuper-logarithm (i.e., inverse tetration) of $k$.",
    "descriptor": "",
    "authors": [
      "Jingbo Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00211"
  },
  {
    "id": "arXiv:2107.00212",
    "title": "Identifying the Prevalence of Gender Biases among the Computing  Organizations",
    "abstract": "We have designed an online survey to understand the status quo of four\ndimensions of gender biases among the contemporary computing organizations. Our\npreliminary results found almost one-third of the respondents have reported\nfirst-hand experiences of encountering gender biases at their jobs.",
    "descriptor": "",
    "authors": [
      "Sayma Sultana",
      "London Ariel Cavaletto",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00212"
  },
  {
    "id": "arXiv:2107.00214",
    "title": "Proof of Reference(PoR): A unified informetrics based consensus  mechanism",
    "abstract": "Bibliometrics is useful to analyze the research impact for measuring the\nresearch quality. Different bibliographic databases like Scopus, Web of\nScience, Google Scholar etc. are accessed for evaluating the trend of\npublications and citations from time to time. Some of these databases are free\nand some are subscription based. Its always debatable that which bibliographic\ndatabase is better and in what terms. To provide an optimal solution to\navailability of multiple bibliographic databases, we have implemented a single\nauthentic database named as ``conflate'' which can be used for fetching\npublication and citation trend of an author. To further strengthen the\ngenerated database and to provide the transparent system to the stakeholders, a\nconsensus mechanism ``proof of reference (PoR)'' is proposed. Due to three\nconsent based checks implemented in PoR, we feel that it could be considered as\na authentic and honest citation data source for the calculation of unified\ninformetrics for an author.",
    "descriptor": "\nComments: 6 Pages, 3 Figures\n",
    "authors": [
      "Parul Khurana",
      "Geetha Ganesan",
      "Gulshan Kumar",
      "Kiran Sharma"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.00214"
  },
  {
    "id": "arXiv:2107.00218",
    "title": "Comparing Example-Based Collaborative Reflection to Problem Solving  Practice for Learning during Team-Based Software Engineering Projects",
    "abstract": "Contributing to the literature on aptitude-treatment interactions between\nworked examples and problem-solving, this paper addresses differential learning\nfrom the two approaches when students are positioned as domain experts learning\nnew concepts. Our evaluation is situated in a team project that is part of an\nadvanced software engineering course. In this course, students who possess\nfoundational domain knowledge but are learning new concepts engage\nalternatively in programming followed by worked example-based reflection. They\nare either allowed to finish programming or are curtailed after a pre-specified\ntime to participate in a longer worked example-based reflection. We find\nsignificant pre- to post-test learning gains in both conditions. Then, we not\nonly find significantly more learning when students participated in longer\nworked example-based reflections but also a significant performance improvement\non a problem-solving transfer task. These findings suggest that domain experts\nlearning new concepts benefit more from worked example-based reflections than\nfrom problem-solving.",
    "descriptor": "\nComments: 4 pages, 1 image, 1 table, 14th Computer Supported Collaborative Learning (CSCL) Proceedings at the Annual Meeting of the International Society of the Learning Sciences (ISLS)\n",
    "authors": [
      "Sreecharan Sankaranarayanan",
      "Siddharth Reddy Kandimalla",
      "Christopher Bogart",
      "R. Charles Murray",
      "Haokang An",
      "Michael Hilton",
      "Majd Sakr",
      "Carolyn Ros\u00e9"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00218"
  },
  {
    "id": "arXiv:2107.00219",
    "title": "ControlBurn: Feature Selection by Sparse Forests",
    "abstract": "Tree ensembles distribute feature importance evenly amongst groups of\ncorrelated features. The average feature ranking of the correlated group is\nsuppressed, which reduces interpretability and complicates feature selection.\nIn this paper we present ControlBurn, a feature selection algorithm that uses a\nweighted LASSO-based feature selection method to prune unnecessary features\nfrom tree ensembles, just as low-intensity fire reduces overgrown vegetation.\nLike the linear LASSO, ControlBurn assigns all the feature importance of a\ncorrelated group of features to a single feature. Moreover, the algorithm is\nefficient and only requires a single training iteration to run, unlike\niterative wrapper-based feature selection methods. We show that ControlBurn\nperforms substantially better than feature selection methods with comparable\ncomputational costs on datasets with correlated features.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Brian Liu",
      "Miaolan Xie",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.00219"
  },
  {
    "id": "arXiv:2107.00221",
    "title": "Embedding-based Recommender System for Job to Candidate Matching on  Scale",
    "abstract": "The online recruitment matching system has been the core technology and\nservice platform in CareerBuilder. One of the major challenges in an online\nrecruitment scenario is to provide good matches between job posts and\ncandidates using a recommender system on the scale. In this paper, we discussed\nthe techniques for applying an embedding-based recommender system for the large\nscale of job to candidates matching. To learn the comprehensive and effective\nembedding for job posts and candidates, we have constructed a fused-embedding\nvia different levels of representation learning from raw text, semantic\nentities and location information. The clusters of fused-embedding of job and\ncandidates are then used to build and train the Faiss index that supports\nruntime approximate nearest neighbor search for candidate retrieval. After the\nfirst stage of candidate retrieval, a second stage reranking model that\nutilizes other contextual information was used to generate the final matching\nresult. Both offline and online evaluation results indicate a significant\nimprovement of our proposed two-staged embedding-based system in terms of\nclick-through rate (CTR), quality and normalized discounted accumulated gain\n(nDCG), compared to those obtained from our baseline system. We further\ndescribed the deployment of the system that supports the million-scale job and\ncandidate matching process at CareerBuilder. The overall improvement of our job\nto candidate matching system has demonstrated its feasibility and scalability\nat a major online recruitment site.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jing Zhao",
      "Jingya Wang",
      "Madhav Sigdel",
      "Bopeng Zhang",
      "Phuong Hoang",
      "Mengshu Liu",
      "Mohammed Korayem"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.00221"
  },
  {
    "id": "arXiv:2107.00222",
    "title": "Deep auxiliary learning for visual localization using colorization task",
    "abstract": "Visual localization is one of the most important components for robotics and\nautonomous driving. Recently, inspiring results have been shown with CNN-based\nmethods which provide a direct formulation to end-to-end regress 6-DoF absolute\npose. Additional information like geometric or semantic constraints is\ngenerally introduced to improve performance. Especially, the latter can\naggregate high-level semantic information into localization task, but it\nusually requires enormous manual annotations. To this end, we propose a novel\nauxiliary learning strategy for camera localization by introducing\nscene-specific high-level semantics from self-supervised representation\nlearning task. Viewed as a powerful proxy task, image colorization task is\nchosen as complementary task that outputs pixel-wise color version of grayscale\nphotograph without extra annotations. In our work, feature representations from\ncolorization network are embedded into localization network by design to\nproduce discriminative features for pose regression. Meanwhile an attention\nmechanism is introduced for the benefit of localization performance. Extensive\nexperiments show that our model significantly improve localization accuracy\nover state-of-the-arts on both indoor and outdoor datasets.",
    "descriptor": "",
    "authors": [
      "Mi Tian",
      "Qiong Nie",
      "Hao Shen",
      "Xiahua Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00222"
  },
  {
    "id": "arXiv:2107.00223",
    "title": "Circuit Complexity of Visual Search",
    "abstract": "We study computational hardness of feature and conjunction search through the\nlens of circuit complexity. Let $x = (x_1, ... , x_n)$ (resp., $y = (y_1, ... ,\ny_n)$) be Boolean variables each of which takes the value one if and only if a\nneuron at place $i$ detects a feature (resp., another feature). We then simply\nformulate the feature and conjunction search as Boolean functions ${\\rm\nFTR}_n(x) = \\bigvee_{i=1}^n x_i$ and ${\\rm CONJ}_n(x, y) = \\bigvee_{i=1}^n x_i\n\\wedge y_i$, respectively. We employ a threshold circuit or a discretized\ncircuit (such as a sigmoid circuit or a ReLU circuit with discretization) as\nour models of neural networks, and consider the following four computational\nresources: [i] the number of neurons (size), [ii] the number of levels (depth),\n[iii] the number of active neurons outputting non-zero values (energy), and\n[iv] synaptic weight resolution (weight).\nWe first prove that any threshold circuit $C$ of size $s$, depth $d$, energy\n$e$ and weight $w$ satisfies $\\log rk(M_C) \\le ed (\\log s + \\log w + \\log n)$,\nwhere $rk(M_C)$ is the rank of the communication matrix $M_C$ of a\n$2n$-variable Boolean function that $C$ computes. Since ${\\rm CONJ}_n$ has rank\n$2^n$, we have $n \\le ed (\\log s + \\log w + \\log n)$. Thus, an exponential\nlower bound on the size of even sublinear-depth threshold circuits exists if\nthe energy and weight are sufficiently small. Since ${\\rm FTR}_n$ is computable\nindependently of $n$, our result suggests that computational capacity for the\nfeature and conjunction search are different. We also show that the inequality\nis tight up to a constant factor if $ed = o(n/ \\log n)$. We next show that a\nsimilar inequality holds for any discretized circuit. Thus, if we regard the\nnumber of gates outputting non-zero values as a measure for sparse activity,\nour results suggest that larger depth helps neural networks to acquire sparse\nactivity.",
    "descriptor": "",
    "authors": [
      "Kei Uchizawa",
      "Haruki Abe"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.00223"
  },
  {
    "id": "arXiv:2107.00226",
    "title": "Multi-Access Coded Caching with Demand Privacy",
    "abstract": "The demand private coded caching problem in a multi-access network with $K$\nusers and $K$ caches, where each user has access to $L$ neighbouring caches in\na cyclic wrap-around manner, is studied. The additional constraint imposed is\nthat one user should not get any information regarding the demands of the\nremaining users. A lifting construction of demand private multi-access coded\ncaching scheme from conventional, non-private multi-access scheme is\nintroduced. The demand-privacy for a user is ensured by placing some additional\n\\textit{keys} in a set of caches called the \\textit{private set} of that user.\nFor a given $K$ and $L$, a technique is also devised to find the private sets\nof the users.",
    "descriptor": "\nComments: Communicated to IEEE Communications Letters on 21st June 2021. 5 pages, 2 figures\n",
    "authors": [
      "K. K. Krishnan Namboodiri",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00226"
  },
  {
    "id": "arXiv:2107.00227",
    "title": "UrbanVR: An immersive analytics system for context-aware urban design",
    "abstract": "Urban design is a highly visual discipline that requires visualization for\ninformed decision making. However, traditional urban design tools are mostly\nlimited to representations on 2D displays that lack intuitive awareness. The\npopularity of head-mounted displays (HMDs) promotes a promising alternative\nwith consumer-grade 3D displays. We introduce UrbanVR, an immersive analytics\nsystem with effective visualization and interaction techniques, to enable\narchitects to assess designs in a virtual reality (VR) environment.\nSpecifically, UrbanVR incorporates 1) a customized parallel coordinates plot\n(PCP) design to facilitate quantitative assessment of high-dimensional design\nmetrics, 2) a series of egocentric interactions, including gesture interactions\nand handle-bar metaphors, to facilitate user interactions, and 3) a viewpoint\noptimization algorithm to help users explore both the PCP for quantitative\nanalysis, and objects of interest for context awareness. Effectiveness and\nfeasibility of the system are validated through quantitative user studies and\nqualitative expert feedbacks.",
    "descriptor": "",
    "authors": [
      "Chi Zhang",
      "Wei Zeng",
      "Ligang Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.00227"
  },
  {
    "id": "arXiv:2107.00228",
    "title": "Scalable Certified Segmentation via Randomized Smoothing",
    "abstract": "We present a new certification method for image and point cloud segmentation\nbased on randomized smoothing. The method leverages a novel scalable algorithm\nfor prediction and certification that correctly accounts for multiple testing,\nnecessary for ensuring statistical guarantees. The key to our approach is\nreliance on established multiple-testing correction mechanisms as well as the\nability to abstain from classifying single pixels or points while still\nrobustly segmenting the overall input. Our experimental evaluation on synthetic\ndata and challenging datasets, such as Pascal Context, Cityscapes, and\nShapeNet, shows that our algorithm can achieve, for the first time, competitive\naccuracy and certification guarantees on real-world segmentation tasks. We\nprovide an implementation at https://github.com/eth-sri/segmentation-smoothing.",
    "descriptor": "\nComments: ICML'21\n",
    "authors": [
      "Marc Fischer",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00228"
  },
  {
    "id": "arXiv:2107.00229",
    "title": "E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with  Transformer-based Stereoscopic Depth Perception",
    "abstract": "Reconstructing the scene of robotic surgery from the stereo endoscopic video\nis an important and promising topic in surgical data science, which potentially\nsupports many applications such as surgical visual perception, robotic surgery\neducation and intra-operative context awareness. However, current methods are\nmostly restricted to reconstructing static anatomy assuming no tissue\ndeformation, tool occlusion and de-occlusion, and camera movement. However,\nthese assumptions are not always satisfied in minimal invasive robotic\nsurgeries. In this work, we present an efficient reconstruction pipeline for\nhighly dynamic surgical scenes that runs at 28 fps. Specifically, we design a\ntransformer-based stereoscopic depth perception for efficient depth estimation\nand a light-weight tool segmentor to handle tool occlusion. After that, a\ndynamic reconstruction algorithm which can estimate the tissue deformation and\ncamera movement, and aggregate the information over time is proposed for\nsurgical scene reconstruction. We evaluate the proposed pipeline on two\ndatasets, the public Hamlyn Centre Endoscopic Video Dataset and our in-house\nDaVinci robotic surgery dataset. The results demonstrate that our method can\nrecover the scene obstructed by the surgical tool and handle the movement of\ncamera in realistic surgical scenarios effectively at real-time speed.",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Yonghao Long",
      "Zhaoshuo Li",
      "Chi Hang Yee",
      "Chi Fai Ng",
      "Russell H. Taylor",
      "Mathias Unberath",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00229"
  },
  {
    "id": "arXiv:2107.00230",
    "title": "Boosting Certified $\\ell_\\infty$ Robustness with EMA Method and Ensemble  Model",
    "abstract": "The neural network with $1$-Lipschitz property based on $\\ell_\\infty$-dist\nneuron has a theoretical guarantee in certified $\\ell_\\infty$ robustness.\nHowever, due to the inherent difficulties in the training of the network, the\ncertified accuracy of previous work is limited. In this paper, we propose two\napproaches to deal with these difficuties. Aiming at the characteristics of the\ntraining process based on $\\ell_\\infty$-norm neural network, we introduce the\nEMA method to improve the training process. Considering the randomness of the\ntraining algorithm, we propose an ensemble method based on trained base models\nthat have the $1$-Lipschitz property and gain significant improvement in the\nsmall parameter network. Moreover, we give the theoretical analysis of the\nensemble method based on the $1$-Lipschitz property on the certified\nrobustness, which ensures the effectiveness and stability of the algorithm. Our\ncode is available at\nhttps://github.com/Theia-4869/EMA-and-Ensemble-Lip-Networks.",
    "descriptor": "",
    "authors": [
      "Binghui Li",
      "Shiji Xin",
      "Qizhe Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00230"
  },
  {
    "id": "arXiv:2107.00231",
    "title": "Audiovisual Singing Voice Separation",
    "abstract": "Separating a song into vocal and accompaniment components is an active\nresearch topic, and recent years witnessed an increased performance from\nsupervised training using deep learning techniques. We propose to apply the\nvisual information corresponding to the singers' vocal activities to further\nimprove the quality of the separated vocal signals. The video frontend model\ntakes the input of mouth movement and fuses it into the feature embeddings of\nan audio-based separation framework. To facilitate the network to learn\naudiovisual correlation of singing activities, we add extra vocal signals\nirrelevant to the mouth movement to the audio mixture during training. We\ncreate two audiovisual singing performance datasets for training and\nevaluation, respectively, one curated from audition recordings on the Internet,\nand the other recorded in house. The proposed method outperforms audio-based\nmethods in terms of separation quality on most test recordings. This advantage\nis especially pronounced when there are backing vocals in the accompaniment,\nwhich poses a great challenge for audio-only methods.",
    "descriptor": "",
    "authors": [
      "Bochen Li",
      "Yuxuan Wang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00231"
  },
  {
    "id": "arXiv:2107.00233",
    "title": "FedMix: Approximation of Mixup under Mean Augmented Federated Learning",
    "abstract": "Federated learning (FL) allows edge devices to collectively learn a model\nwithout directly sharing data within each device, thus preserving privacy and\neliminating the need to store data globally. While there are promising results\nunder the assumption of independent and identically distributed (iid) local\ndata, current state-of-the-art algorithms suffer from performance degradation\nas the heterogeneity of local data across clients increases. To resolve this\nissue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),\nwhere clients send and receive averaged local data, subject to the privacy\nrequirements of target applications. Under our framework, we propose a new\naugmentation algorithm, named FedMix, which is inspired by a phenomenal yet\nsimple data augmentation method, Mixup, but does not require local raw data to\nbe directly shared among devices. Our method shows greatly improved performance\nin the standard benchmark datasets of FL, under highly non-iid federated\nsettings, compared to conventional algorithms.",
    "descriptor": "",
    "authors": [
      "Tehrim Yoon",
      "Sumin Shin",
      "Sung Ju Hwang",
      "Eunho Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00233"
  },
  {
    "id": "arXiv:2107.00238",
    "title": "Optimal Power Allocation for Rate Splitting Communications with Deep  Reinforcement Learning",
    "abstract": "This letter introduces a novel framework to optimize the power allocation for\nusers in a Rate Splitting Multiple Access (RSMA) network. In the network,\nmessages intended for users are split into different parts that are a single\ncommon part and respective private parts. This mechanism enables RSMA to\nflexibly manage interference and thus enhance energy and spectral efficiency.\nAlthough possessing outstanding advantages, optimizing power allocation in RSMA\nis very challenging under the uncertainty of the communication channel and the\ntransmitter has limited knowledge of the channel information. To solve the\nproblem, we first develop a Markov Decision Process framework to model the\ndynamic of the communication channel. The deep reinforcement algorithm is then\nproposed to find the optimal power allocation policy for the transmitter\nwithout requiring any prior information of the channel. The simulation results\nshow that the proposed scheme can outperform baseline schemes in terms of\naverage sum-rate under different power and QoS requirements.",
    "descriptor": "",
    "authors": [
      "Nguyen Quang Hieu",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Dong In Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.00238"
  },
  {
    "id": "arXiv:2107.00239",
    "title": "Generic Event Boundary Detection Challenge at CVPR 2021 Technical  Report: Cascaded Temporal Attention Network (CASTANET)",
    "abstract": "This report presents the approach used in the submission of Generic Event\nBoundary Detection (GEBD) Challenge at CVPR21. In this work, we design a\nCascaded Temporal Attention Network (CASTANET) for GEBD, which is formed by\nthree parts, the backbone network, the temporal attention module, and the\nclassification module. Specifically, the Channel-Separated Convolutional\nNetwork (CSN) is used as the backbone network to extract features, and the\ntemporal attention module is designed to enforce the network to focus on the\ndiscriminative features. After that, the cascaded architecture is used in the\nclassification module to generate more accurate boundaries. In addition, the\nensemble strategy is used to further improve the performance of the proposed\nmethod. The proposed method achieves 83.30% F1 score on Kinetics-GEBD test set,\nwhich improves 20.5% F1 score compared to the baseline method. Code is\navailable at https://github.com/DexiangHong/Cascade-PC.",
    "descriptor": "",
    "authors": [
      "Dexiang Hong",
      "Congcong Li",
      "Longyin Wen",
      "Xinyao Wang",
      "Libo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00239"
  },
  {
    "id": "arXiv:2107.00241",
    "title": "Secretive Coded Caching with Shared Caches",
    "abstract": "We consider the problem of \\emph{secretive coded caching} in a shared cache\nsetup where the number of users accessing a particular \\emph{helper cache} is\nmore than one, and every user can access exactly one helper cache. In secretive\ncoded caching, the constraint of \\emph{perfect secrecy} must be satisfied. It\nrequires that the users should not gain, either from their caches or from the\ntransmissions, any information about the content of the files that they did not\nrequest from the server. In order to accommodate the secrecy constraint, our\nproblem setup requires, in addition to a helper cache, a dedicated \\emph{user\ncache} of minimum capacity of 1 unit to every user. This is where our\nformulation differs from the original work on shared caches (``Fundamental\nLimits of Coded Caching With Multiple Antennas, Shared Caches and Uncoded\nPrefetching'' by E.~Parrinello, A.~{\\\"{U}}nsal and P.~Elia in Trans. Inf.\nTheory, 2020). In this work, we propose a secretively achievable coded caching\nscheme with shared caches under centralized placement. When our scheme is\napplied to the dedicated cache setting, it matches the scheme by Ravindrakumar\n\\emph{et al.} (``Private Coded Caching'', in Trans. Inf. Forensics and\nSecurity, 2018).",
    "descriptor": "\nComments: To appear in IEEE Communications Letters. 5 pages, 3 figures, 1 table\n",
    "authors": [
      "Shreya Shrestha Meel",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00241"
  },
  {
    "id": "arXiv:2107.00243",
    "title": "Reducing the Variance of Gaussian Process Hyperparameter Optimization  with Preconditioning",
    "abstract": "Gaussian processes remain popular as a flexible and expressive model class,\nbut the computational cost of kernel hyperparameter optimization stands as a\nmajor limiting factor to their scaling and broader adoption. Recent work has\nmade great strides combining stochastic estimation with iterative numerical\ntechniques, essentially boiling down GP inference to the cost of (many)\nmatrix-vector multiplies. Preconditioning -- a highly effective step for any\niterative method involving matrix-vector multiplication -- can be used to\naccelerate convergence and thus reduce bias in hyperparameter optimization.\nHere, we prove that preconditioning has an additional benefit that has been\npreviously unexplored. It not only reduces the bias of the $\\log$-marginal\nlikelihood estimator and its derivatives, but it also simultaneously can reduce\nvariance at essentially negligible cost. We leverage this result to derive\nsample-efficient algorithms for GP hyperparameter optimization requiring as few\nas $\\mathcal{O}(\\log(\\varepsilon^{-1}))$ instead of\n$\\mathcal{O}(\\varepsilon^{-2})$ samples to achieve error $\\varepsilon$. Our\ntheoretical results enable provably efficient and scalable optimization of\nkernel hyperparameters, which we validate empirically on a set of large-scale\nbenchmark problems. There, variance reduction via preconditioning results in an\norder of magnitude speedup in hyperparameter optimization of exact GPs.",
    "descriptor": "",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Philipp Hennig",
      "John P. Cunningham",
      "Jacob R. Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00243"
  },
  {
    "id": "arXiv:2107.00246",
    "title": "Distributed Multi-agent Navigation Based on Reciprocal Collision  Avoidance and Locally Confined Multi-agent Path Finding",
    "abstract": "Avoiding collisions is the core problem in multi-agent navigation. In\ndecentralized settings, when agents have limited communication and sensory\ncapabilities, collisions are typically avoided in a reactive fashion, relying\non local observations/communications. Prominent collision avoidance techniques,\ne.g. ORCA, are computationally efficient and scale well to a large number of\nagents. However, in numerous scenarios, involving navigation through the tight\npassages or confined spaces, deadlocks are likely to occur due to the egoistic\nbehaviour of the agents and as a result, the latter can not achieve their\ngoals. To this end, we suggest an application of the locally confined\nmulti-agent path finding (MAPF) solvers that coordinate sub-groups of the\nagents that appear to be in a deadlock (to detect the latter we suggest a\nsimple, yet efficient ad-hoc routine). We present a way to build a grid-based\nMAPF instance, typically required by modern MAPF solvers. We evaluate two of\nthem in our experiments, i.e. Push and Rotate and a bounded-suboptimal version\nof Conflict Based Search (ECBS), and show that their inclusion into the\nnavigation pipeline significantly increases the success rate, from 15% to 99%\nin certain cases.",
    "descriptor": "\nComments: This is a preprint of the paper accepted to CASE'21. It contains 5 pages, 4 figures, 1 table\n",
    "authors": [
      "Stepan Dergachev",
      "Konstantin Yakovlev"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.00246"
  },
  {
    "id": "arXiv:2107.00247",
    "title": "The Interplay between Distribution Parameters and the  Accuracy-Robustness Tradeoff in Classification",
    "abstract": "Adversarial training tends to result in models that are less accurate on\nnatural (unperturbed) examples compared to standard models. This can be\nattributed to either an algorithmic shortcoming or a fundamental property of\nthe training data distribution, which admits different solutions for optimal\nstandard and adversarial classifiers. In this work, we focus on the latter case\nunder a binary Gaussian mixture classification problem. Unlike earlier work, we\naim to derive the natural accuracy gap between the optimal Bayes and\nadversarial classifiers, and study the effect of different distributional\nparameters, namely separation between class centroids, class proportions, and\nthe covariance matrix, on the derived gap. We show that under certain\nconditions, the natural error of the optimal adversarial classifier, as well as\nthe gap, are locally minimized when classes are balanced, contradicting the\nperformance of the Bayes classifier where perfect balance induces the worst\naccuracy. Moreover, we show that with an $\\ell_\\infty$ bounded perturbation and\nan adversarial budget of $\\epsilon$, this gap is $\\Theta(\\epsilon^2)$ for the\nworst-case parameters, which for suitably small $\\epsilon$ indicates the\ntheoretical possibility of achieving robust classifiers with near-perfect\naccuracy, which is rarely reflected in practical algorithms.",
    "descriptor": "\nComments: Accepted for presentation in AML ICML workshop 2021\n",
    "authors": [
      "Alireza Mousavi Hosseini",
      "Amir Mohammad Abouei",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00247"
  },
  {
    "id": "arXiv:2107.00249",
    "title": "OPT: Omni-Perception Pre-Trainer for Cross-Modal Understanding and  Generation",
    "abstract": "In this paper, we propose an Omni-perception Pre-Trainer (OPT) for\ncross-modal understanding and generation, by jointly modeling visual, text and\naudio resources. OPT is constructed in an encoder-decoder framework, including\nthree single-modal encoders to generate token-based embeddings for each\nmodality, a cross-modal encoder to encode the correlations among the three\nmodalities, and two cross-modal decoders to generate text and image\nrespectively. For the OPT's pre-training, we design a multi-task pretext\nlearning scheme to model multi-modal resources from three different data\ngranularities, \\ie, token-, modality-, and sample-level modeling, through which\nOPT learns to align and translate among different modalities. The pre-training\ntask is carried out on a large amount of image-text-audio triplets from Open\nImages. Experimental results show that OPT can learn strong image-text-audio\nmulti-modal representations and achieve promising results on a variety of\ncross-modal understanding and generation tasks.",
    "descriptor": "",
    "authors": [
      "Jing Liu",
      "Xinxin Zhu",
      "Fei Liu",
      "Longteng Guo",
      "Zijia Zhao",
      "Mingzhen Sun",
      "Weining Wang",
      "Jinqiao Wang",
      "Hanqing Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00249"
  },
  {
    "id": "arXiv:2107.00251",
    "title": "$L_p$ Isotonic Regression Algorithms Using an $L_0$ Approach",
    "abstract": "Significant advances in maximum flow algorithms have changed the relative\nperformance of various approaches to isotonic regression. If the transitive\nclosure is given then the standard approach used for $L_0$ (Hamming distance)\nisotonic regression (finding anti-chains in the transitive closure of the\nviolator graph), combined with new flow algorithms, gives an $L_1$ algorithm\ntaking $\\tilde{\\Theta}(n^2+n^\\frac{3}{2} \\log U )$ time, where $U$ is the\nmaximum vertex weight. The previous fastest was $\\Theta(n^3)$. Similar results\nare obtained for $L_2$ and for $L_p$ approximations, $1 < p < \\infty$. For\nweighted points in $d$-dimensional space with coordinate-wise ordering, $d \\geq\n3$, $L_0, L_1$ and $L_2$ regressions can be found in only $o(n^\\frac{3}{2}\n\\log^d n \\log U)$ time, improving on the previous best of $\\tilde{\\Theta}(n^2\n\\log^d n)$, and for unweighted points the time is $O(n^{\\frac{4}{3}+o(1)}\n\\log^d n)$.",
    "descriptor": "",
    "authors": [
      "Quentin F. Stout"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00251"
  },
  {
    "id": "arXiv:2107.00254",
    "title": "AdaXpert: Adapting Neural Architecture for Growing Data",
    "abstract": "In real-world applications, data often come in a growing manner, where the\ndata volume and the number of classes may increase dynamically. This will bring\na critical challenge for learning: given the increasing data volume or the\nnumber of classes, one has to instantaneously adjust the neural model capacity\nto obtain promising performance. Existing methods either ignore the growing\nnature of data or seek to independently search an optimal architecture for a\ngiven dataset, and thus are incapable of promptly adjusting the architectures\nfor the changed data. To address this, we present a neural architecture\nadaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust\nprevious architectures on the growing data. Specifically, we introduce an\narchitecture adjuster to generate a suitable architecture for each data\nsnapshot, based on the previous architecture and the different extent between\ncurrent and previous data distributions. Furthermore, we propose an adaptation\ncondition to determine the necessity of adjustment, thereby avoiding\nunnecessary and time-consuming adjustments. Extensive experiments on two growth\nscenarios (increasing data volume and number of classes) demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "\nComments: accepted by ICML 2021\n",
    "authors": [
      "Shuaicheng Niu",
      "Jiaxiang Wu",
      "Guanghui Xu",
      "Yifan Zhang",
      "Yong Guo",
      "Peilin Zhao",
      "Peng Wang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00254"
  },
  {
    "id": "arXiv:2107.00266",
    "title": "Performance evaluation of gust load alleviation systems for flexible  aircraft via optimal control",
    "abstract": "The dynamical response of an aircraft subject to gust perturbations is a key\nelement in a preliminary design phase. In particular, the loads induced by\ngusts along the wing should not exceed some limit values and should even\nideally be decreased. Active control is one lever to address this problem.\nHowever, evaluating the benefit that active control may bring considering some\nactuators characteristics or some delay in the loop is a difficult task,\nespecially in the early design phase. This problem is addressed in this paper\nwith an open-loop optimal control framework and more specifically with a direct\ntranscription method resulting in a linear optimisation problem. The approach\nis illustrated on a realistic aeroelastic aircraft model built with a coupled\nfluid-structure solver which order is reduced to decrease the number of\noptimisation variables.",
    "descriptor": "",
    "authors": [
      "Pierre Vuillemin",
      "David Quero Martin",
      "Charles Poussot-Vassal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00266"
  },
  {
    "id": "arXiv:2107.00271",
    "title": "On the (Non-)Applicability of a Small Model Theorem to Model Checking  STMs",
    "abstract": "Software Transactional Memory (STM) algorithms provide programmers with a\nsynchronisation mechanism for concurrent access to shared variables. Basically,\nprogrammers can specify transactions (reading from and writing to shared state)\nwhich execute \"seemingly\" atomic. This property is captured in a correctness\ncriterion called opacity. For model checking opacity of an STM algorithm, we --\nin principle -- need to check opacity for all possible combinations of\ntransactions writing to and reading from potentially unboundedly many\nvariables.\nTo still apply automatic model checking techniques to opacity checking, a so\ncalled small model theorem has been proven which states that model checking on\ntwo variables and two transactions is sufficient for correctness verification\nof STMs. In this paper, we take a fresh look at this small model theorem and\ninvestigate its applicability to opacity checking of STM algorithms.",
    "descriptor": "",
    "authors": [
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00271"
  },
  {
    "id": "arXiv:2107.00272",
    "title": "A Survey on Graph-Based Deep Learning for Computational Histopathology",
    "abstract": "With the remarkable success of representation learning for prediction\nproblems, we have witnessed a rapid expansion of the use of machine learning\nand deep learning for the analysis of digital pathology and biopsy image\npatches. However, traditional learning over patch-wise features using\nconvolutional neural networks limits the model when attempting to capture\nglobal contextual information. The phenotypical and topological distribution of\nconstituent histological entities play a critical role in tissue diagnosis. As\nsuch, graph data representations and deep learning have attracted significant\nattention for encoding tissue representations, and capturing intra- and inter-\nentity level interactions. In this review, we provide a conceptual grounding of\ngraph-based deep learning and discuss its current success for tumor\nlocalization and classification, tumor invasion and staging, image retrieval,\nand survival prediction. We provide an overview of these methods in a\nsystematic manner organized by the graph representation of the input image\nincluding whole slide images and tissue microarrays. We also outline the\nlimitations of existing techniques, and suggest potential future advances in\nthis domain.",
    "descriptor": "",
    "authors": [
      "David Ahmedt-Aristizabal",
      "Mohammad Ali Armin",
      "Simon Denman",
      "Clinton Fookes",
      "Lars Petersson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2107.00272"
  },
  {
    "id": "arXiv:2107.00275",
    "title": "Adaptive Hyperparameter Tuning for Black-box LiDAR Odometry",
    "abstract": "This study proposes an adaptive data-driven hyperparameter tuning framework\nfor black-box 3D LiDAR odometry algorithms. The proposed framework comprises\noffline parameter-error function modeling and online adaptive parameter\nselection. In the offline step, we run the odometry estimation algorithm for\ntuning with different parameters and environments and evaluate the accuracy of\nthe estimated trajectories to build a surrogate function that predicts the\ntrajectory estimation error for the given parameters and environments.\nSubsequently, we select the parameter set that is expected to result in good\naccuracy in the given environment based on trajectory error prediction with the\nsurrogate function. The proposed framework does not require detailed\ninformation on the inner working of the algorithm to be tuned, and improves its\naccuracy by adaptively optimizing the parameter set. We first demonstrate the\nrole of the proposed framework in improving the accuracy of odometry estimation\nacross different environments with a simulation-based toy example. Further, an\nevaluation on the public dataset KITTI shows that the proposed framework can\nimprove the accuracy of several odometry estimation algorithms in practical\nsituations.",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (to appear) Video: this https URL\n",
    "authors": [
      "Kenji Koide",
      "Masashi Yokozuka",
      "Shuji Oishi",
      "Atsuhiko Banno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00275"
  },
  {
    "id": "arXiv:2107.00279",
    "title": "The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at  IWSLT 2021",
    "abstract": "This paper describes USTC-NELSLIP's submissions to the IWSLT2021 Simultaneous\nSpeech Translation task. We proposed a novel simultaneous translation model,\nCross Attention Augmented Transducer (CAAT), which extends conventional RNN-T\nto sequence-to-sequence tasks without monotonic constraints, e.g., simultaneous\ntranslation. Experiments on speech-to-text (S2T) and text-to-text (T2T)\nsimultaneous translation tasks shows CAAT achieves better quality-latency\ntrade-offs compared to \\textit{wait-k}, one of the previous state-of-the-art\napproaches. Based on CAAT architecture and data augmentation, we build S2T and\nT2T simultaneous translation systems in this evaluation campaign. Compared to\nlast year's optimal systems, our S2T simultaneous translation system improves\nby an average of 11.3 BLEU for all latency regimes, and our T2T simultaneous\ntranslation system improves by an average of 4.6 BLEU.",
    "descriptor": "",
    "authors": [
      "Dan Liu",
      "Mengge Du",
      "Xiaoxi Li",
      "Yuchen Hu",
      "Lirong Dai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00279"
  },
  {
    "id": "arXiv:2107.00281",
    "title": "Scientia Potentia Est -- On the Role of Knowledge in Computational  Argumentation",
    "abstract": "Despite extensive research in the past years, the computational modeling of\nargumentation remains challenging. The primary reason lies in the inherent\ncomplexity of the human processes behind, which commonly requires the\nintegration of extensive knowledge far beyond what is needed for many other\nnatural language understanding tasks. Existing work on the mining, assessment,\nreasoning, and generation of arguments acknowledges this issue, calling for\nmore research on the integration of common sense and world knowledge into\ncomputational models. However, a systematic effort to collect and organize the\ntypes of knowledge needed is still missing, hindering targeted progress in the\nfield. In this opinionated survey paper, we address the issue by (1) proposing\na pyramid of types of knowledge required in computational argumentation, (2)\nbriefly discussing the state of the art on the role and integration of these\ntypes in the field, and (3) outlining the main challenges for future work.",
    "descriptor": "",
    "authors": [
      "Anne Lauscher",
      "Henning Wachsmuth",
      "Iryna Gurevych",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00281"
  },
  {
    "id": "arXiv:2107.00284",
    "title": "SA-MATD3:Self-attention-based multi-agent continuous control method in  cooperative environments",
    "abstract": "Cooperative problems under continuous control have always been the focus of\nmulti-agent reinforcement learning. Existing algorithms suffer from the problem\nof uneven learning degree with the increase of the number of agents. In this\npaper, a new structure for a multi-agent actor critic is proposed, and the\nself-attention mechanism is applied in the critic network and the value\ndecomposition method used to solve the uneven problem. The proposed algorithm\nmakes full use of the samples in the replay memory buffer to learn the behavior\nof a class of agents. First, a new update method is proposed for policy\nnetworks that promotes learning efficiency. Second, the utilization of samples\nis improved, at the same time reflecting the ability of perspective-taking\namong groups. Finally, the \"deceptive signal\" in training is eliminated and the\nlearning degree among agents is more uniform than in the existing methods.\nMultiple experiments were conducted in two typical scenarios of a multi-agent\nparticle environment. Experimental results show that the proposed algorithm can\nperform better than the state-of-the-art ones, and that it exhibits higher\nlearning efficiency with an increasing number of agents.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Kai Liu",
      "Yuyang Zhao",
      "Gang Wang",
      "Bei Peng"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00284"
  },
  {
    "id": "arXiv:2107.00285",
    "title": "iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding  and Emotion Analysis",
    "abstract": "We introduce a new dataset for the emotional artificial intelligence\nresearch: identity-free video dataset for Micro-Gesture Understanding and\nEmotion analysis (iMiGUE). Different from existing public datasets, iMiGUE\nfocuses on nonverbal body gestures without using any identity information,\nwhile the predominant researches of emotion analysis concern sensitive\nbiometric data, like face and speech. Most importantly, iMiGUE focuses on\nmicro-gestures, i.e., unintentional behaviors driven by inner feelings, which\nare different from ordinary scope of gestures from other gesture datasets which\nare mostly intentionally performed for illustrative purposes. Furthermore,\niMiGUE is designed to evaluate the ability of models to analyze the emotional\nstates by integrating information of recognized micro-gesture, rather than just\nrecognizing prototypes in the sequences separately (or isolatedly). This is\nbecause the real need for emotion AI is to understand the emotional states\nbehind gestures in a holistic way. Moreover, to counter for the challenge of\nimbalanced sample distribution of this dataset, an unsupervised learning method\nis proposed to capture latent representations from the micro-gesture sequences\nthemselves. We systematically investigate representative methods on this\ndataset, and comprehensive experimental results reveal several interesting\ninsights from the iMiGUE, e.g., micro-gesture-based analysis can promote\nemotion understanding. We confirm that the new iMiGUE dataset could advance\nstudies of micro-gesture and emotion AI.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Xin Liu",
      "Henglin Shi",
      "Haoyu Chen",
      "Zitong Yu",
      "Xiaobai Li",
      "Guoying Zhaoz?"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00285"
  },
  {
    "id": "arXiv:2107.00289",
    "title": "Efficient Analysis of Chemical Reaction Networks Dynamics based on  Input-Output Monotonicity",
    "abstract": "Motivation: A Chemical Reaction Network (CRN) is a set of chemical reactions,\nwhich can be very complex and difficult to analyze. Indeed, dynamical\nproperties of CRNs can be described by a set of non-linear differential\nequations that rarely can be solved in closed-form, but that can instead be\nused to reason on the system dynamics. In this context, one of the possible\napproaches is to perform numerical simulations, which may require a high\ncomputational effort. In particular, in order to investigate some dynamical\nproperties, such as robustness or global sensitivity, many simulations have to\nbe performed by varying the initial concentration of chemical species. Results:\nIn order to reduce the computational effort required when many simulations are\nneeded to assess a property, we exploit a new notion of monotonicity of the\noutput of the system (the concentration of a target chemical species at the\nsteady-state) with respect to the input (the initial concentration of another\nchemical species). To assess such monotonicity behavior, we propose a new\ngraphical approach that allows us to state sufficient conditions for ensuring\nthat the monotonicity property holds. Our sufficient conditions allow us to\nefficiently verify the monotonicity property by exploring a graph constructed\non the basis of the reactions involved in the network. Once established, our\nmonotonicity property allows us to drastically reduce the number of simulations\nrequired to assess some dynamical properties of the CRN.",
    "descriptor": "",
    "authors": [
      "Lucia Nasti",
      "Roberta Gori",
      "Paolo Milazzo",
      "Federico Poloni"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.00289"
  },
  {
    "id": "arXiv:2107.00297",
    "title": "Sonority Measurement Using System, Source, and Suprasegmental  Information",
    "abstract": "Sonorant sounds are characterized by regions with prominent formant\nstructure, high energy and high degree of periodicity. In this work, the\nvocal-tract system, excitation source and suprasegmental features derived from\nthe speech signal are analyzed to measure the sonority information present in\neach of them. Vocal-tract system information is extracted from the Hilbert\nenvelope of numerator of group delay function. It is derived from zero time\nwindowed speech signal that provides better resolution of the formants. A\nfive-dimensional feature set is computed from the estimated formants to measure\nthe prominence of the spectral peaks. A feature representing strength of\nexcitation is derived from the Hilbert envelope of linear prediction residual,\nwhich represents the source information. Correlation of speech over ten\nconsecutive pitch periods is used as the suprasegmental feature representing\nperiodicity information. The combination of evidences from the three different\naspects of speech provides better discrimination among different sonorant\nclasses, compared to the baseline MFCC features. The usefulness of the proposed\nsonority feature is demonstrated in the tasks of phoneme recognition and\nsonorant classification.",
    "descriptor": "",
    "authors": [
      "Bidisha Sharma",
      "S. R. Mahadeva Prasanna"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00297"
  },
  {
    "id": "arXiv:2107.00306",
    "title": "MHER: Model-based Hindsight Experience Replay",
    "abstract": "Solving multi-goal reinforcement learning (RL) problems with sparse rewards\nis generally challenging. Existing approaches have utilized goal relabeling on\ncollected experiences to alleviate issues raised from sparse rewards. However,\nthese methods are still limited in efficiency and cannot make full use of\nexperiences. In this paper, we propose Model-based Hindsight Experience Replay\n(MHER), which exploits experiences more efficiently by leveraging environmental\ndynamics to generate virtual achieved goals. Replacing original goals with\nvirtual goals generated from interaction with a trained dynamics model leads to\na novel relabeling method, \\emph{model-based relabeling} (MBR). Based on MBR,\nMHER performs both reinforcement learning and supervised learning for efficient\npolicy improvement. Theoretically, we also prove the supervised part in MHER,\ni.e., goal-conditioned supervised learning with MBR data, optimizes a lower\nbound on the multi-goal RL objective. Experimental results in several\npoint-based tasks and simulated robotics environments show that MHER achieves\nsignificantly higher sample efficiency than previous state-of-the-art methods.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Rui Yang",
      "Meng Fang",
      "Lei Han",
      "Yali Du",
      "Feng Luo",
      "Xiu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00306"
  },
  {
    "id": "arXiv:2107.00308",
    "title": "An Objective Evaluation Framework for Pathological Speech Synthesis",
    "abstract": "The development of pathological speech systems is currently hindered by the\nlack of a standardised objective evaluation framework. In this work, (1) we\nutilise existing detection and analysis techniques to propose a general\nframework for the consistent evaluation of synthetic pathological speech. This\nframework evaluates the voice quality and the intelligibility aspects of speech\nand is shown to be complementary using our experiments. (2) Using our proposed\nevaluation framework, we develop and test a dysarthric voice conversion system\n(VC) using CycleGAN-VC and a PSOLA-based speech rate modification technique. We\nshow that the developed system is able to synthesise dysarthric speech with\ndifferent levels of speech intelligibility.",
    "descriptor": "\nComments: 4 pages, 4 figures. Accepted to the ITG Conference on Speech Communication | 29.09.2021 - 01.10.2021 | Kiel\n",
    "authors": [
      "Bence Mark Halpern",
      "Julian Fritsch",
      "Enno Hermann",
      "Rob van Son",
      "Odette Scharenborg",
      "Mathew Magimai.-Doss"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00308"
  },
  {
    "id": "arXiv:2107.00309",
    "title": "Spotting adversarial samples for speaker verification by neural vocoders",
    "abstract": "Automatic speaker verification (ASV), one of the most important technology\nfor biometric identification, has been widely adopted in security-critic\napplications, including transaction authentication and access control. However,\nprevious works have shown ASV is seriously vulnerable to recently emerged\nadversarial attacks, yet effective countermeasures against them are limited. In\nthis paper, we adopt neural vocoders to spot adversarial samples for ASV. We\nuse neural vocoder to re-synthesize audio and find that the difference between\nthe ASV scores for the original and re-synthesized audio is a good indicator to\ndistinguish genuine and adversarial samples. As the very beginning work in this\ndirection of detecting adversarial samples for ASV, there is no reliable\nbaseline for comparison. So we first implement Griffin-Lim for detection and\nset it as our baseline. The proposed method accomplishes effective detection\nperformance and outperforms all the baselines in all the settings. We also show\nthe neural vocoder adopted in the detection framework is dataset independent.\nOur codes will be made open-source for future works to do comparison.",
    "descriptor": "\nComments: Submitted to ASRU 2021\n",
    "authors": [
      "Haibin Wu",
      "Po-chun Hsu",
      "Ji Gao",
      "Shanshan Zhang",
      "Shen Huang",
      "Jian Kang",
      "Zhiyong Wu",
      "Helen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00309"
  },
  {
    "id": "arXiv:2107.00314",
    "title": "Backtracking (the) Algorithms on the Hamiltonian Cycle Problem",
    "abstract": "Even though the Hamiltonian cycle problem is NP-complete, many of its problem\ninstances aren't. In fact, almost all the hard instances reside in one area:\nnear the Koml\\'os-Szemer\\'edi bound, of $\\frac{1}{2}\\ v\\cdot ln(v) +\n\\frac{1}{2}\\ v\\cdot ln( ln(v))$ edges, where randomly generated graphs have an\napproximate 50\\% chance of being Hamiltonian. If the number of edges is either\nmuch higher or much lower, the problem is not hard -- most backtracking\nalgorithms decide such instances in (near) polynomial time. Recently however,\ntargeted search efforts have identified very hard Hamiltonian cycle problem\ninstances very far away from the Koml\\'os-Szemer\\'edi bound. In that study, the\nused backtracking algorithm was Vandegriend-Culberson's, which was supposedly\nthe most efficient of all Hamiltonian backtracking algorithms.\nIn this paper, we make a unified large scale quantitative comparison for the\nbest known backtracking algorithms described between 1877 and 2016. We confirm\nthe suspicion that the Koml\\'os-Szemer\\'edi bound is a hard area for all\nbacktracking algorithms, but also that Vandegriend-Culberson is indeed the most\nefficient algorithm, when expressed in consumed computing time. When measured\nin recursive effectiveness however, the algorithm by Frank Rubin, almost half a\ncentury old, performs best. In a more general algorithmic assessment, we\nconjecture that edge pruning and non-Hamiltonicity checks might be largely\nresponsible for these recursive savings. When expressed in system time however,\ndenser problem instances require much more time per recursion. This is most\nlikely due to the costliness of the extra search pruning procedures, which are\nrelatively elaborate. We supply large amounts of experimental data, and a\nunified single-program implementation for all six algorithms. All data and\nalgorithmic source code is made public for further use by our colleagues.",
    "descriptor": "\nComments: Not yet peer-reviewed\n",
    "authors": [
      "Joeri Sleegers",
      "Daan van den Berg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00314"
  },
  {
    "id": "arXiv:2107.00315",
    "title": "Interviewer-Candidate Role Play: Towards Developing Real-World NLP  Systems",
    "abstract": "Standard NLP tasks do not incorporate several common real-world scenarios\nsuch as seeking clarifications about the question, taking advantage of clues,\nabstaining in order to avoid incorrect answers, etc. This difference in task\nformulation hinders the adoption of NLP systems in real-world settings. In this\nwork, we take a step towards bridging this gap and present a multi-stage task\nthat simulates a typical human-human questioner-responder interaction such as\nan interview. Specifically, the system is provided with question\nsimplifications, knowledge statements, examples, etc. at various stages to\nimprove its prediction when it is not sufficiently confident. We instantiate\nthe proposed task in Natural Language Inference setting where a system is\nevaluated on both in-domain and out-of-domain (OOD) inputs. We conduct\ncomprehensive experiments and find that the multi-stage formulation of our task\nleads to OOD generalization performance improvement up to 2.29% in Stage 1,\n1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard\nunguided prediction. However, our task leaves a significant challenge for NLP\nresearchers to further improve OOD performance at each stage.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00315"
  },
  {
    "id": "arXiv:2107.00316",
    "title": "Leveraging Domain Agnostic and Specific Knowledge for Acronym  Disambiguation",
    "abstract": "An obstacle to scientific document understanding is the extensive use of\nacronyms which are shortened forms of long technical phrases. Acronym\ndisambiguation aims to find the correct meaning of an ambiguous acronym in a\ngiven text. Recent efforts attempted to incorporate word embeddings and deep\nlearning architectures, and achieved significant effects in this task. In\ngeneral domains, kinds of fine-grained pretrained language models have sprung\nup, thanks to the largescale corpora which can usually be obtained through\ncrowdsourcing. However, these models based on domain agnostic knowledge might\nachieve insufficient performance when directly applied to the scientific\ndomain. Moreover, obtaining large-scale high-quality annotated data and\nrepresenting high-level semantics in the scientific domain is challenging and\nexpensive. In this paper, we consider both the domain agnostic and specific\nknowledge, and propose a Hierarchical Dual-path BERT method coined hdBERT to\ncapture the general fine-grained and high-level specific representations for\nacronym disambiguation. First, the context-based pretrained models, RoBERTa and\nSciBERT, are elaborately involved in encoding these two kinds of knowledge\nrespectively. Second, multiple layer perceptron is devised to integrate the\ndualpath representations simultaneously and outputs the prediction. With a\nwidely adopted SciAD dataset contained 62,441 sentences, we investigate the\neffectiveness of hdBERT. The experimental results exhibit that the proposed\napproach outperforms state-of-the-art methods among various evaluation metrics.\nSpecifically, its macro F1 achieves 93.73%.",
    "descriptor": "\nComments: Second Place Solution, Accepted to SDU@AAAI-21\n",
    "authors": [
      "Qiwei Zhong",
      "Guanxiong Zeng",
      "Danqing Zhu",
      "Yang Zhang",
      "Wangli Lin",
      "Ben Chen",
      "Jiayu Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00316"
  },
  {
    "id": "arXiv:2107.00317",
    "title": "Towards Utilitarian Combinatorial Assignment with Deep Neural Networks  and Heuristic Algorithms",
    "abstract": "This paper presents preliminary work on using deep neural networks to guide\ngeneral-purpose heuristic algorithms for performing utilitarian combinatorial\nassignment. In more detail, we use deep learning in an attempt to produce\nheuristics that can be used together with e.g., search algorithms to generate\nfeasible solutions of higher quality more quickly. Our results indicate that\nour approach could be a promising future method for constructing such\nheuristics.",
    "descriptor": "\nComments: 7 pages, 4 figures, presented at the ECAI 2020 TAILOR workshop\n",
    "authors": [
      "Fredrik Pr\u00e4ntare",
      "Mattias Tiger",
      "David Bergstr\u00f6m",
      "Herman Appelgren",
      "Fredrik Heintz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00317"
  },
  {
    "id": "arXiv:2107.00318",
    "title": "Zero-pronoun Data Augmentation for Japanese-to-English Translation",
    "abstract": "For Japanese-to-English translation, zero pronouns in Japanese pose a\nchallenge, since the model needs to infer and produce the corresponding pronoun\nin the target side of the English sentence. However, although fully resolving\nzero pronouns often needs discourse context, in some cases, the local context\nwithin a sentence gives clues to the inference of the zero pronoun. In this\nstudy, we propose a data augmentation method that provides additional training\nsignals for the translation model to learn correlations between local context\nand zero pronouns. We show that the proposed method significantly improves the\naccuracy of zero pronoun translation with machine translation experiments in\nthe conversational domain.",
    "descriptor": "\nComments: WAT2021\n",
    "authors": [
      "Ryokan Ri",
      "Toshiaki Nakazawa",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00318"
  },
  {
    "id": "arXiv:2107.00319",
    "title": "Addressing Machines as models of lambda-calculus",
    "abstract": "Turing machines and register machines have been used for decades in\ntheoretical computer science as abstract models of computation. Also the\n$\\lambda$-calculus has played a central role in this domain as it allows to\nfocus on the notion of functional computation, based on the substitution\nmechanism, while abstracting away from implementation details. The present\narticle starts from the observation that the equivalence between these\nformalisms is based on the Church-Turing Thesis rather than an actual encoding\nof $\\lambda$-terms into Turing (or register) machines. The reason is that these\nmachines are not well-suited for modelling \\lam-calculus programs.\nWe study a class of abstract machines that we call \\emph{addressing machine}\nsince they are only able to manipulate memory addresses of other machines. The\noperations performed by these machines are very elementary: load an address in\na register, apply a machine to another one via their addresses, and call the\naddress of another machine. We endow addressing machines with an operational\nsemantics based on leftmost reduction and study their behaviour. The set of\naddresses of these machines can be easily turned into a combinatory algebra. In\norder to obtain a model of the full untyped $\\lambda$-calculus, we need to\nintroduce a rule that bares similarities with the $\\omega$-rule and the rule\n$\\zeta_\\beta$ from combinatory logic.",
    "descriptor": "",
    "authors": [
      "Giuseppe Della Penna",
      "Benedetto Intrigila",
      "Giulio Manzonetto"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00319"
  },
  {
    "id": "arXiv:2107.00323",
    "title": "Combining Feature and Instance Attribution to Detect Artifacts",
    "abstract": "Training the large deep neural networks that dominate NLP requires large\ndatasets. Many of these are collected automatically or via crowdsourcing, and\nmay exhibit systematic biases or annotation artifacts. By the latter, we mean\ncorrelations between inputs and outputs that are spurious, insofar as they do\nnot represent a generally held causal relationship between features and\nclasses; models that exploit such correlations may appear to perform a given\ntask well, but fail on out of sample data. In this paper we propose methods to\nfacilitate identification of training data artifacts, using new hybrid\napproaches that combine saliency maps (which highlight important input\nfeatures) with instance attribution methods (which retrieve training samples\ninfluential to a given prediction). We show that this proposed training-feature\nattribution approach can be used to uncover artifacts in training data, and use\nit to identify previously unreported artifacts in a few standard NLP datasets.\nWe execute a small user study to evaluate whether these methods are useful to\nNLP researchers in practice, with promising results. We make code for all\nmethods and experiments in this paper available.",
    "descriptor": "",
    "authors": [
      "Pouya Pezeshkpour",
      "Sarthak Jain",
      "Sameer Singh",
      "Byron C. Wallace"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00323"
  },
  {
    "id": "arXiv:2107.00324",
    "title": "Robotic Template Library",
    "abstract": "Robotic Template Library (RTL) is a set of tools for dealing with geometry\nand point cloud processing, especially in robotic applications. The software\npackage covers basic objects such as vectors, line segments, quaternions, rigid\ntransformations, etc., however, its main contribution lies in the more advanced\nmodules: The segmentation module for batch or stream clustering of point\nclouds, the fast vectorization module for approximation of continuous point\nclouds by geometric objects of higher grade and the LaTeX export module\nenabling automated generation of high-quality visual outputs. It is a\nheader-only library written in C++17, uses the Eigen library as a linear\nalgebra back-end, and is designed with high computational performance in mind.\nRTL can be used in all robotic tasks such as motion planning, map building,\nobject recognition and many others, but the point cloud processing utilities\nare general enough to be employed in any field touching object reconstruction\nand computer vision applications as well.",
    "descriptor": "",
    "authors": [
      "Ales Jelinek",
      "Adam Ligocki",
      "Ludek Zalud"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00324"
  },
  {
    "id": "arXiv:2107.00327",
    "title": "Orthonormal Product Quantization Network for Scalable Face Image  Retrieval",
    "abstract": "Recently, deep hashing with Hamming distance metric has drawn increasing\nattention for face image retrieval tasks. However, its counterpart deep\nquantization methods, which learn binary code representations with\ndictionary-related distance metrics, have seldom been explored for the task.\nThis paper makes the first attempt to integrate product quantization into an\nend-to-end deep learning framework for face image retrieval. Unlike prior deep\nquantization methods where the codewords for quantization are learned from\ndata, we propose a novel scheme using predefined orthonormal vectors as\ncodewords, which aims to enhance the quantization informativeness and reduce\nthe codewords' redundancy. To make the most of the discriminative information,\nwe design a tailored loss function that maximizes the identity discriminability\nin each quantization subspace for both the quantized and the original features.\nFurthermore, an entropy-based regularization term is imposed to reduce the\nquantization error. We conduct experiments on three commonly-used datasets\nunder the settings of both single-domain and cross-domain retrieval. It shows\nthat the proposed method outperforms all the compared deep hashing/quantization\nmethods under both settings with significant superiority. The proposed\ncodewords scheme consistently improves both regular model performance and model\ngeneralization ability, verifying the importance of codewords' distribution for\nthe quantization quality. Besides, our model's better generalization ability\nthan deep hashing models indicates that it is more suitable for scalable face\nimage retrieval tasks.",
    "descriptor": "",
    "authors": [
      "Ming Zhang",
      "Xuefei Zhe",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00327"
  },
  {
    "id": "arXiv:2107.00328",
    "title": "End-to-end Compression Towards Machine Vision: Network Architecture  Design and Optimization",
    "abstract": "The research of visual signal compression has a long history. Fueled by deep\nlearning, exciting progress has been made recently. Despite achieving better\ncompression performance, existing end-to-end compression algorithms are still\ndesigned towards better signal quality in terms of rate-distortion\noptimization. In this paper, we show that the design and optimization of\nnetwork architecture could be further improved for compression towards machine\nvision. We propose an inverted bottleneck structure for end-to-end compression\ntowards machine vision, which specifically accounts for efficient\nrepresentation of the semantic information. Moreover, we quest the capability\nof optimization by incorporating the analytics accuracy into the optimization\nprocess, and the optimality is further explored with generalized rate-accuracy\noptimization in an iterative manner. We use object detection as a showcase for\nend-to-end compression towards machine vision, and extensive experiments show\nthat the proposed scheme achieves significant BD-rate savings in terms of\nanalysis performance. Moreover, the promise of the scheme is also demonstrated\nwith strong generalization capability towards other machine vision tasks, due\nto the enabling of signal-level reconstruction.",
    "descriptor": "",
    "authors": [
      "Shurun Wang",
      "Zhao Wang",
      "Shiqi Wang",
      "Yan Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.00328"
  },
  {
    "id": "arXiv:2107.00329",
    "title": "Real-time Dispatchable Region of Active Distribution Networks Based on a  Tight Convex Relaxation Model",
    "abstract": "The uncertainty in distributed renewable generation poses security threats to\nthe real-time operation of distribution systems. The real-time dispatchable\nregion (RTDR) can be used to assess the ability of power systems to accommodate\nrenewable generation at a given base point. DC and linearized AC power flow\nmodels are typically used for bulk power systems, but they are not suitable for\nlow-voltage distribution networks with large r/x ratios. To balance accuracy\nand computational efficiency, this paper proposes an RTDR model of AC\ndistribution networks using tight convex relaxation. Convex hull relaxation is\nadopted to reformulate the AC power flow equations, and the convex hull is\napproximated by a polyhedron without much loss of accuracy. Furthermore, an\nefficient adaptive constraint generation algorithm is employed to construct an\napproximate RTDR to meet the requirements of real-time dispatch. Case studies\non the modified IEEE 33-bus distribution system validate the computational\nefficiency and accuracy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Wenjing Huang",
      "Zhigang Li",
      "Mohammad Shahidehpour",
      "J. H. Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00329"
  },
  {
    "id": "arXiv:2107.00332",
    "title": "Learned Global Optimization for Inverse Scattering Problems -- Matching  Global Search with Computational Efficiency",
    "abstract": "The computationally-efficient solution of fully non-linear microwave inverse\nscattering problems (ISPs) is addressed. An innovative System-by-Design (SbD)\nbased method is proposed to enable, for the first time to the best of the\nauthors knowledge, an effective, robust, and time-efficient exploitation of an\nevolutionary algorithm (EA) to perform the global minimization of the\ndata-mismatch cost function. According to the SbD paradigm as suitably applied\nto ISPs, the proposed approach founds on (i) a smart re-formulation of the ISP\nbased on the definition of a minimum-dimensionality and representative set of\ndegrees-of-freedom (DoFs) and on (ii) the artificial-intelligence (AI)-driven\nintegration of a customized global search technique with a digital twin (DT)\npredictor based on the Gaussian Process (GP) theory. Representative numerical\nand experimental results are provided to assess the effectiveness and the\nefficiency of the proposed approach also in comparison with competitive\nstate-of-the-art inversion techniques.",
    "descriptor": "",
    "authors": [
      "Marco Salucci",
      "Lorenzo Poli",
      "Paolo Rocca",
      "Andrea Massa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00332"
  },
  {
    "id": "arXiv:2107.00333",
    "title": "Multilingual Central Repository: a Cross-lingual Framework for  Developing Wordnets",
    "abstract": "Language resources are necessary for language processing,but building them is\ncostly, involves many researches from different areas and needs constant\nupdating. In this paper, we describe the crosslingual framework used for\ndeveloping the Multilingual Central Repository (MCR), a multilingual knowledge\nbase that includes wordnets of Basque, Catalan, English, Galician, Portuguese,\nSpanish and the following ontologies: Base Concepts, Top Ontology, WordNet\nDomains and Suggested Upper Merged Ontology. We present the story of MCR, its\nstate in 2017 and the developed tools.",
    "descriptor": "\nComments: 11 pages, 1 figure. To appear in Special Issue on Linking, Integrating and Extending Wordnets, Linguistic Issues in Language Technology (LiLT) Volume 10, Issue 4, Sep 2017\n",
    "authors": [
      "Xavier G\u00f3mez Guinovart",
      "Itziar Gonzalez-Dios",
      "Antoni Oliver",
      "German Rigau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00333"
  },
  {
    "id": "arXiv:2107.00334",
    "title": "Modeling Target-side Inflection in Placeholder Translation",
    "abstract": "Placeholder translation systems enable the users to specify how a specific\nphrase is translated in the output sentence. The system is trained to output\nspecial placeholder tokens, and the user-specified term is injected into the\noutput through the context-free replacement of the placeholder token. However,\nthis approach could result in ungrammatical sentences because it is often the\ncase that the specified term needs to be inflected according to the context of\nthe output, which is unknown before the translation. To address this problem,\nwe propose a novel method of placeholder translation that can inflect specified\nterms according to the grammatical construction of the output sentence. We\nextend the sequence-to-sequence architecture with a character-level decoder\nthat takes the lemma of a user-specified term and the words generated from the\nword-level decoder to output the correct inflected form of the lemma. We\nevaluate our approach with a Japanese-to-English translation task in the\nscientific writing domain, and show that our model can incorporate specified\nterms in the correct form more successfully than other comparable models.",
    "descriptor": "\nComments: MT Summit 2021\n",
    "authors": [
      "Ryokan Ri",
      "Toshiaki Nakazawa",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00334"
  },
  {
    "id": "arXiv:2107.00337",
    "title": "PoliTO-IIT Submission to the EPIC-KITCHENS-100 Unsupervised Domain  Adaptation Challenge for Action Recognition",
    "abstract": "In this report, we describe the technical details of our submission to the\nEPIC-Kitchens-100 Unsupervised Domain Adaptation (UDA) Challenge in Action\nRecognition. To tackle the domain-shift which exists under the UDA setting, we\nfirst exploited a recent Domain Generalization (DG) technique, called Relative\nNorm Alignment (RNA). It consists in designing a model able to generalize well\nto any unseen domain, regardless of the possibility to access target data at\ntraining time. Then, in a second phase, we extended the approach to work on\nunlabelled target data, allowing the model to adapt to the target distribution\nin an unsupervised fashion. For this purpose, we included in our framework\nexisting UDA algorithms, such as Temporal Attentive Adversarial Adaptation\nNetwork (TA3N), jointly with new multi-stream consistency losses, namely\nTemporal Hard Norm Alignment (T-HNA) and Min-Entropy Consistency (MEC). Our\nsubmission (entry 'plnet') is visible on the leaderboard and it achieved the\n1st position for 'verb', and the 3rd position for both 'noun' and 'action'.",
    "descriptor": "\nComments: 3rd place in the 2021 EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition\n",
    "authors": [
      "Chiara Plizzari",
      "Mirco Planamente",
      "Emanuele Alberti",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00337"
  },
  {
    "id": "arXiv:2107.00339",
    "title": "Policy Transfer across Visual and Dynamics Domain Gaps via Iterative  Grounding",
    "abstract": "The ability to transfer a policy from one environment to another is a\npromising avenue for efficient robot learning in realistic settings where task\nsupervision is not available. This can allow us to take advantage of\nenvironments well suited for training, such as simulators or laboratories, to\nlearn a policy for a real robot in a home or office. To succeed, such policy\ntransfer must overcome both the visual domain gap (e.g. different illumination\nor background) and the dynamics domain gap (e.g. different robot calibration or\nmodelling error) between source and target environments. However, prior policy\ntransfer approaches either cannot handle a large domain gap or can only address\none type of domain gap at a time. In this paper, we propose a novel policy\ntransfer method with iterative \"environment grounding\", IDAPT, that alternates\nbetween (1) directly minimizing both visual and dynamics domain gaps by\ngrounding the source environment in the target environment domains, and (2)\ntraining a policy on the grounded source environment. This iterative training\nprogressively aligns the domains between the two environments and adapts the\npolicy to the target environment. Once trained, the policy can be directly\nexecuted on the target environment. The empirical results on locomotion and\nrobotic manipulation tasks demonstrate that our approach can effectively\ntransfer a policy across visual and dynamics domain gaps with minimal\nsupervision and interaction with the target environment. Videos and code are\navailable at https://clvrai.com/idapt .",
    "descriptor": "\nComments: Robotics: Science and Systems (RSS), 2021\n",
    "authors": [
      "Grace Zhang",
      "Linghan Zhong",
      "Youngwoon Lee",
      "Joseph J. Lim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00339"
  },
  {
    "id": "arXiv:2107.00340",
    "title": "AoI Minimization in Energy Harvesting and Spectrum Sharing Enabled 6G  Networks",
    "abstract": "Spectrum sharing is a method to solve the problem of frequency spectrum\ndeficiency. This paper studies a novel AI based spectrum sharing and energy\nharvesting system in which the freshness of information (AoI) is guaranteed.\nThe system includes a primary user with access rights to the spectrum and a\nsecondary user. The secondary user is an energy harvesting sensor that intends\nto use the primary user spectrum opportunistically. The problem is formulated\nas partially observable Markov decision processes (POMDPs) and solved using two\nmethods: a deep Q-network (DQN) and dueling double deep Q-Network (D3QN) to\nachieve the optimal policy. The purpose is to choose the best action adaptively\nin every time slot based on its situation in both overlay and underlay modes to\nminimize the average AoI of the secondary user. Finally, simulation experiments\nare performed to evaluate the effectiveness of the proposed scheme compared to\nthe overlay mode. According to the results, the average AoI in the proposed\nsystem is less than that of the existing models, including only overlay mode.\nThe average user access improved from 30% in the overlay mode to 45% in the DQN\nand 48% in the D3QN.",
    "descriptor": "",
    "authors": [
      "Amir Hossein Zarif",
      "Paeiz Azmi",
      "Nader Mokari",
      "Mohammad Reza Javan",
      "Eduard Jorswieck"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00340"
  },
  {
    "id": "arXiv:2107.00341",
    "title": "Technical Report: Anti-unification of Unordered Goals",
    "abstract": "Anti-unification in logic programming refers to the process of capturing\ncommon syntactic structure among given goals, computing as such a single new\ngoal that is more general and hence called a generalization of the given goals.\nFinding an arbitrary common generalization for two goals is trivial, but\nlooking for those common generalizations that are either as large as possible\n(called largest common generalizations) or as specific as possible (called most\nspecific generalizations) is a non-trivial optimization problem, in particular\nwhen goals are considered to be unordered sets of atoms. In this work we\nprovide an in-depth study of the problem by defining two different\ngeneralization relations. We formulate a characterization of what constitutes a\nmost specific generalization in both settings. While these generalizations can\nbe computed in polynomial time, we show that when the number of variables in\nthe generalization needs to be minimized, the problem becomes NP-hard. We\nsubsequently revisit an abstraction of the largest common generalization when\nanti-unification is based on injective variable renamings, and prove that it\ncan be computed in polynomially bounded time.",
    "descriptor": "\nComments: Submitted to CSL 2022\n",
    "authors": [
      "Gonzague Yernaux",
      "Wim Vanhoof"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00341"
  },
  {
    "id": "arXiv:2107.00346",
    "title": "MASS: Multi-Attentional Semantic Segmentation of LiDAR Data for Dense  Top-View Understanding",
    "abstract": "At the heart of all automated driving systems is the ability to sense the\nsurroundings, e.g., through semantic segmentation of LiDAR sequences, which\nexperienced a remarkable progress due to the release of large datasets such as\nSemanticKITTI and nuScenes-LidarSeg. While most previous works focus on sparse\nsegmentation of the LiDAR input, dense output masks provide self-driving cars\nwith almost complete environment information. In this paper, we introduce MASS\n- a Multi-Attentional Semantic Segmentation model specifically built for dense\ntop-view understanding of the driving scenes. Our framework operates on pillar-\nand occupancy features and comprises three attention-based building blocks: (1)\na keypoint-driven graph attention, (2) an LSTM-based attention computed from a\nvector embedding of the spatial input, and (3) a pillar-based attention,\nresulting in a dense 360-degree segmentation mask. With extensive experiments\non both, SemanticKITTI and nuScenes-LidarSeg, we quantitatively demonstrate the\neffectiveness of our model, outperforming the state of the art by 19.0% on\nSemanticKITTI and reaching 32.7% in mIoU on nuScenes-LidarSeg, where MASS is\nthe first work addressing the dense segmentation task. Furthermore, our\nmulti-attention model is shown to be very effective for 3D object detection\nvalidated on the KITTI-3D dataset, showcasing its high generalizability to\nother tasks related to 3D vision.",
    "descriptor": "\nComments: 14 pages, 7 figures, 4 tables. Code will be made publicly available at this https URL\n",
    "authors": [
      "Kunyu Peng",
      "Juncong Fei",
      "Kailun Yang",
      "Alina Roitberg",
      "Jiaming Zhang",
      "Frank Bieder",
      "Philipp Heidenreich",
      "Christoph Stiller",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00346"
  },
  {
    "id": "arXiv:2107.00347",
    "title": "Information Security Analysis in the Passenger-Autonomous Vehicle  Interaction",
    "abstract": "Autonomous vehicles (AV) are becoming a part of humans' everyday life. There\nare numerous pilot projects of driverless public buses; some car manufacturers\ndeliver their premium-level automobiles with advanced self-driving features.\nThus, assuring the security of a Passenger-Autonomous Vehicle interaction\narises as an important research topic, as along with opportunities, new\ncybersecurity risks and challenges occur that potentially may threaten\nPassenger's privacy and safety on the roads. This study proposes an approach of\nthe security requirements elicitation based on the developed threat model.\nThus, information security risk management helps to fulfil one of the\nprinciples needed to protect data privacy - information security. We\ndemonstrate the process of security requirements elicitation to mitigate\narising security risks. The findings of the paper are case-oriented and are\nbased on the literature review. They are applicable for AV system\nimplementation used by ride-hailing service providers that enable supervisory\nAV control.",
    "descriptor": "",
    "authors": [
      "Mariia Bakhtina",
      "Raimundas Matulevi\u010dius"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.00347"
  },
  {
    "id": "arXiv:2107.00349",
    "title": "Modelling Moral Traits with Music Listening Preferences and Demographics",
    "abstract": "Music is an essential component in our everyday lives and experiences, as it\nis a way that we use to express our feelings, emotions and cultures. In this\nstudy, we explore the association between music genre preferences, demographics\nand moral values by exploring self-reported data from an online survey\nadministered in Canada. Participants filled in the moral foundations\nquestionnaire, while they also provided their basic demographic information,\nand music preferences. Here, we predict the moral values of the participants\ninferring on their musical preferences employing classification and regression\ntechniques. We also explored the predictive power of features estimated from\nfactor analysis on the music genres, as well as the generalist/specialist (GS)\nscore for revealing the diversity of musical choices for each user. Our results\nshow the importance of music in predicting a person's moral values (.55-.69\nAUROC); while knowledge of basic demographic features such as age and gender is\nenough to increase the performance (.58-.71 AUROC).",
    "descriptor": "",
    "authors": [
      "Vjosa Preniqi",
      "Kyriaki Kalimeri",
      "Charalampos Saitis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.00349"
  },
  {
    "id": "arXiv:2107.00353",
    "title": "Stability and Robustness Analysis of Plug-Pulling using an Aerial  Manipulator",
    "abstract": "In this paper, an autonomous aerial manipulation task of pulling a plug out\nof an electric socket is conducted, where maintaining the stability and\nrobustness is challenging due to sudden disappearance of a large interaction\nforce. The abrupt change in the dynamical model before and after the separation\nof the plug can cause destabilization or mission failure. To accomplish aerial\nplug-pulling, we employ the concept of hybrid automata to divide the task into\nthree operative modes, i.e, wire-pulling, stabilizing, and free-flight. Also, a\nstrategy for trajectory generation and a design of disturbance-observer-based\ncontrollers for each operative mode are presented. Furthermore, the theory of\nhybrid automata is used to prove the stability and robustness during the mode\ntransition. We validate the proposed trajectory generation and control method\nby an actual wire-pulling experiment with a multirotor-based aerial\nmanipulator.",
    "descriptor": "\nComments: to be presented in 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Prague, Czech Republic, 2020\n",
    "authors": [
      "Jeonghyun Byun",
      "Dongjae Lee",
      "Hoseong Seo",
      "Inkyu Jang",
      "Jeongjun Choi",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00353"
  },
  {
    "id": "arXiv:2107.00357",
    "title": "Prophet Inequality with Competing Agents",
    "abstract": "We introduce a model of competing agents in a prophet setting, where rewards\narrive online, and decisions are made immediately and irrevocably. The rewards\nare unknown from the outset, but they are drawn from a known probability\ndistribution. In the standard prophet setting, a single agent makes selection\ndecisions in an attempt to maximize her expected reward. The novelty of our\nmodel is the introduction of a competition setting, where multiple agents\ncompete over the arriving rewards, and make online selection decisions\nsimultaneously, as rewards arrive. If a given reward is selected by more than a\nsingle agent, ties are broken either randomly or by a fixed ranking of the\nagents. The consideration of competition turns the prophet setting from an\nonline decision making scenario to a multi-agent game.\nFor both random and ranked tie-breaking rules, we present simple threshold\nstrategies for the agents that give them high guarantees, independent of the\nstrategies taken by others. In particular, for random tie-breaking, every agent\ncan guarantee herself at least $\\frac{1}{k+1}$ of the highest reward, and at\nleast $\\frac{1}{2k}$ of the optimal social welfare. For ranked tie-breaking,\nthe $i$th ranked agent can guarantee herself at least a half of the $i$th\nhighest reward. We complement these results by matching upper bounds, even with\nrespect to equilibrium profiles. For ranked tie-breaking rule, we also show a\ncorrespondence between the equilibrium of the $k$-agent game and the optimal\nstrategy of a single decision maker who can select up to $k$ rewards.",
    "descriptor": "",
    "authors": [
      "Tomer Ezra",
      "Michal Feldman",
      "Ron Kupfer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.00357"
  },
  {
    "id": "arXiv:2107.00358",
    "title": "Improving Task Adaptation for Cross-domain Few-shot Learning",
    "abstract": "In this paper, we look at the problem of cross-domain few-shot classification\nthat aims to learn a classifier from previously unseen classes and domains with\nfew labeled samples. We study several strategies including various adapter\ntopologies and operations in terms of their performance and efficiency that can\nbe easily attached to existing methods with different meta-training strategies\nand adapt them for a given task during meta-test phase. We show that parametric\nadapters attached to convolutional layers with residual connections performs\nthe best, and significantly improves the performance of the state-of-the-art\nmodels in the Meta-Dataset benchmark with minor additional cost. Our code will\nbe available at https://github.com/VICO-UoE/URL.",
    "descriptor": "\nComments: Code will be available at this https URL\n",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00358"
  },
  {
    "id": "arXiv:2107.00359",
    "title": "Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time  Delays Using Reinforcement Learning",
    "abstract": "Telerobotic systems must adapt to new environmental conditions and deal with\nhigh uncertainty caused by long-time delays. As one of the best alternatives to\nhuman-level intelligence, Reinforcement Learning (RL) may offer a solution to\ncope with these issues. This paper proposes to integrate RL with the Model\nMediated Teleoperation (MMT) concept. The teleoperator interacts with a\nsimulated virtual environment, which provides instant feedback. Whereas\nfeedback from the real environment is delayed, feedback from the model is\ninstantaneous, leading to high transparency. The MMT is realized in combination\nwith an intelligent system with two layers. The first layer utilizes Dynamic\nMovement Primitives (DMP) which accounts for certain changes in the avatar\nenvironment. And, the second layer addresses the problems caused by uncertainty\nin the model using RL methods. Augmented reality was also provided to fuse the\navatar device and virtual environment models for the teleoperator. Implemented\non DLR's Exodex Adam hand-arm haptic exoskeleton, the results show RL methods\nare able to find different solutions when changes are applied to the object\nposition after the demonstration. The results also show DMPs to be effective at\nadapting to new conditions where there is no uncertainty involved.",
    "descriptor": "",
    "authors": [
      "Hadi Beik-Mohammadi",
      "Matthias Kerzel",
      "Benedikt Pleintinger",
      "Thomas Hulin",
      "Philipp Reisich",
      "Annika Schmidt",
      "Aaron Pereira",
      "Stefan Wermter",
      "Neal Y. Lii"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00359"
  },
  {
    "id": "arXiv:2107.00360",
    "title": "Towards Measuring Bias in Image Classification",
    "abstract": "Convolutional Neural Networks (CNN) have become de fact state-of-the-art for\nthe main computer vision tasks. However, due to the complex underlying\nstructure their decisions are hard to understand which limits their use in some\ncontext of the industrial world. A common and hard to detect challenge in\nmachine learning (ML) tasks is data bias. In this work, we present a systematic\napproach to uncover data bias by means of attribution maps. For this purpose,\nfirst an artificial dataset with a known bias is created and used to train\nintentionally biased CNNs. The networks' decisions are then inspected using\nattribution maps. Finally, meaningful metrics are used to measure the\nattribution maps' representativeness with respect to the known bias. The\nproposed study shows that some attribution map techniques highlight the\npresence of bias in the data better than others and metrics can support the\nidentification of bias.",
    "descriptor": "\nComments: Accepted for publication at the 30th International Conference on Artificial Neural Networks (ICANN)\n",
    "authors": [
      "Nina Schaaf",
      "Omar de Mitri",
      "Hang Beom Kim",
      "Alexander Windberger",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00360"
  },
  {
    "id": "arXiv:2107.00361",
    "title": "Coded Caching with Shared Caches from Generalized Placement Delivery  Arrays",
    "abstract": "We consider the coded caching problem with shared caches where several users\nshare a cache, but each user has access to only a single cache. For this\nnetwork, the fundamental limits of coded caching are known for centralized and\ndecentralized settings under uncoded placement. In the centralized case, to\nachieve the gains offered by coded caching, one requires a sub-packetization\nwhich increases exponentially with the number of caches. The dedicated cache\nnetworks had a similar issue, and placement delivery arrays (PDAs) were\nintroduced as a solution to it. Using the PDA framework, we propose a procedure\nto obtain new coded caching schemes for shared caches with lower\nsub-packetization requirements. The advantage of this procedure is that we can\ntransform all the existing PDA structures into coded caching schemes for shared\ncaches, thus resulting in low sub-packetization schemes. We also show that the\noptimal scheme given by Parrinello, Unsal and Elia (Fundamental Limits of Coded\nCaching with Multiple Antennas, Shared Caches and Uncoded Prefetching) can be\nrecovered using a Maddah-Ali Niesen PDA.",
    "descriptor": "\nComments: Accepted for presentation in IEEE PIMRC 2021. 7 pages, 1 figure\n",
    "authors": [
      "Elizabath Peter",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00361"
  },
  {
    "id": "arXiv:2107.00362",
    "title": "Drone swarm patrolling with uneven coverage requirements",
    "abstract": "Swarms of drones are being more and more used in many practical scenarios,\nsuch as surveillance, environmental monitoring, search and rescue in\nhardly-accessible areas, etc.. While a single drone can be guided by a human\noperator, the deployment of a swarm of multiple drones requires proper\nalgorithms for automatic task-oriented control. In this paper, we focus on\nvisual coverage optimization with drone-mounted camera sensors. In particular,\nwe consider the specific case in which the coverage requirements are uneven,\nmeaning that different parts of the environment have different coverage\npriorities. We model these coverage requirements with relevance maps and\npropose a deep reinforcement learning algorithm to guide the swarm. The paper\nfirst defines a proper learning model for a single drone, and then extends it\nto the case of multiple drones both with greedy and cooperative strategies.\nExperimental results show the performance of the proposed method, also compared\nwith a standard patrolling algorithm.",
    "descriptor": "\nComments: This paper has been published on IET Computer Vision. Please cite it accordingly (see journal reference below)\n",
    "authors": [
      "Claudio Piciarelli",
      "Gian Luca Foresti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00362"
  },
  {
    "id": "arXiv:2107.00364",
    "title": "Implicit Acceleration and Feature Learning inInfinitely Wide Neural  Networks with Bottlenecks",
    "abstract": "We analyze the learning dynamics of infinitely wide neural networks with a\nfinite sized bottle-neck. Unlike the neural tangent kernel limit, a bottleneck\nin an otherwise infinite width network al-lows data dependent feature learning\nin its bottle-neck representation. We empirically show that a single bottleneck\nin infinite networks dramatically accelerates training when compared to purely\nin-finite networks, with an improved overall performance. We discuss the\nacceleration phenomena by drawing similarities to infinitely wide deep linear\nmodels, where the acceleration effect of a bottleneck can be understood\ntheoretically.",
    "descriptor": "",
    "authors": [
      "Etai Littwin",
      "Omid Saremi",
      "Shuangfei Zhai",
      "Vimal Thilak",
      "Hanlin Goh",
      "Joshua M. Susskind",
      "Greg Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00364"
  },
  {
    "id": "arXiv:2107.00366",
    "title": "A Consistency-Based Loss for Deep Odometry Through Uncertainty  Propagation",
    "abstract": "The incremental poses computed through odometry can be integrated over time\nto calculate the pose of a device with respect to an initial location. The\nresulting global pose may be used to formulate a second, consistency based,\nloss term in a deep odometry setting. In such cases where multiple losses are\nimposed on a network, the uncertainty over each output can be derived to weigh\nthe different loss terms in a maximum likelihood setting. However, when\nimposing a constraint on the integrated transformation, due to how only\nodometry is estimated at each iteration of the algorithm, there is no\ninformation about the uncertainty associated with the global pose to weigh the\nglobal loss term. In this paper, we associate uncertainties with the output\nposes of a deep odometry network and propagate the uncertainties through each\niteration. Our goal is to use the estimated covariance matrix at each\nincremental step to weigh the loss at the corresponding step while weighting\nthe global loss term using the compounded uncertainty. This formulation\nprovides an adaptive method to weigh the incremental and integrated loss terms\nagainst each other, noting the increase in uncertainty as new estimates arrive.\nWe provide quantitative and qualitative analysis of pose estimates and show\nthat our method surpasses the accuracy of the state-of-the-art Visual Odometry\napproaches. Then, uncertainty estimates are evaluated and comparisons against\nfixed baselines are provided. Finally, the uncertainty values are used in a\nrealistic example to show the effectiveness of uncertainty quantification for\nlocalization.",
    "descriptor": "\nComments: 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Hamed Damirchi",
      "Rooholla Khorrambakht",
      "Hamid D. Taghirad",
      "Behzad Moshiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00366"
  },
  {
    "id": "arXiv:2107.00368",
    "title": "Ensemble Learning-Based Approach for Improving Generalization Capability  of Machine Reading Comprehension Systems",
    "abstract": "Machine Reading Comprehension (MRC) is an active field in natural language\nprocessing with many successful developed models in recent years. Despite their\nhigh in-distribution accuracy, these models suffer from two issues: high\ntraining cost and low out-of-distribution accuracy. Even though some approaches\nhave been presented to tackle the generalization problem, they have high,\nintolerable training costs. In this paper, we investigate the effect of\nensemble learning approach to improve generalization of MRC systems without\nretraining a big model. After separately training the base models with\ndifferent structures on different datasets, they are ensembled using weighting\nand stacking approaches in probabilistic and non-probabilistic settings. Three\nconfigurations are investigated including heterogeneous, homogeneous, and\nhybrid on eight datasets and six state-of-the-art models. We identify the\nimportant factors in the effectiveness of ensemble methods. Also, we compare\nthe robustness of ensemble and fine-tuned models against data distribution\nshifts. The experimental results show the effectiveness and robustness of the\nensemble approach in improving the out-of-distribution accuracy of MRC systems,\nespecially when the base models are similar in accuracies.",
    "descriptor": "",
    "authors": [
      "Razieh Baradaran",
      "Hossein Amirkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00368"
  },
  {
    "id": "arXiv:2107.00369",
    "title": "Computing CQ lower-bounds over OWL 2 through approximation to RSA",
    "abstract": "Conjunctive query (CQ) answering over knowledge bases is an important\nreasoning task. However, with expressive ontology languages such as OWL, query\nanswering is computationally very expensive. The PAGOdA system addresses this\nissue by using a tractable reasoner to compute lower and upper-bound\napproximations, falling back to a fully-fledged OWL reasoner only when these\nbounds don't coincide. The effectiveness of this approach critically depends on\nthe quality of the approximations, and in this paper we explore a technique for\ncomputing closer approximations via RSA, an ontology language that subsumes all\nthe OWL 2 profiles while still maintaining tractability. We present a novel\napproximation of OWL 2 ontologies into RSA, and an algorithm to compute a\ncloser (than PAGOdA) lower bound approximation using the RSA combined approach.\nWe have implemented these algorithms in a prototypical CQ answering system, and\nwe present a preliminary evaluation of our system that shows significant\nperformance improvements w.r.t. PAGOdA.",
    "descriptor": "\nComments: 26 pages, 1 figure\n",
    "authors": [
      "Federico Igne",
      "Stefano Germano",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00369"
  },
  {
    "id": "arXiv:2107.00372",
    "title": "Egocentric Image Captioning for Privacy-Preserved Passive Dietary Intake  Monitoring",
    "abstract": "Camera-based passive dietary intake monitoring is able to continuously\ncapture the eating episodes of a subject, recording rich visual information,\nsuch as the type and volume of food being consumed, as well as the eating\nbehaviours of the subject. However, there currently is no method that is able\nto incorporate these visual clues and provide a comprehensive context of\ndietary intake from passive recording (e.g., is the subject sharing food with\nothers, what food the subject is eating, and how much food is left in the\nbowl). On the other hand, privacy is a major concern while egocentric wearable\ncameras are used for capturing. In this paper, we propose a privacy-preserved\nsecure solution (i.e., egocentric image captioning) for dietary assessment with\npassive monitoring, which unifies food recognition, volume estimation, and\nscene understanding. By converting images into rich text descriptions,\nnutritionists can assess individual dietary intake based on the captions\ninstead of the original images, reducing the risk of privacy leakage from\nimages. To this end, an egocentric dietary image captioning dataset has been\nbuilt, which consists of in-the-wild images captured by head-worn and\nchest-worn cameras in field studies in Ghana. A novel transformer-based\narchitecture is designed to caption egocentric dietary images. Comprehensive\nexperiments have been conducted to evaluate the effectiveness and to justify\nthe design of the proposed architecture for egocentric dietary image\ncaptioning. To the best of our knowledge, this is the first work that applies\nimage captioning to dietary intake assessment in real life settings.",
    "descriptor": "",
    "authors": [
      "Jianing Qiu",
      "Frank P.-W. Lo",
      "Xiao Gu",
      "Modou L. Jobarteh",
      "Wenyan Jia",
      "Tom Baranowski",
      "Matilda Steiner-Asiedu",
      "Alex K. Anderson",
      "Megan A McCrory",
      "Edward Sazonov",
      "Mingui Sun",
      "Gary Frost",
      "Benny Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00372"
  },
  {
    "id": "arXiv:2107.00376",
    "title": "PlanSys2: A Planning System Framework for ROS2",
    "abstract": "Autonomous robots need to plan the tasks they carry out to fulfill their\nmissions. The missions' increasing complexity does not let human designers\nanticipate all the possible situations, so traditional control systems based on\nstate machines are not enough. This paper contains a description of the ROS2\nPlanning System (PlanSys2 in short), a framework for symbolic planning that\nincorporates novel approaches for execution on robots working in demanding\nenvironments. PlanSys2 aims to be the reference task planning framework in\nROS2, the latest version of the {\\em de facto} standard in robotics software\ndevelopment. Among its main features, it can be highlighted the optimized\nexecution, based on Behavior Trees, of plans through a new actions auction\nprotocol and its multi-robot planning capabilities. It already has a small but\ngrowing community of users and developers, and this document is a summary of\nthe design and capabilities of this project.",
    "descriptor": "\nComments: Preprint of the accepted paper at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Francisco Mart\u00edn",
      "Jonatan Gin\u00e9s",
      "Vicente Matell\u00e1n",
      "Francisco J. Rodr\u00edguez"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00376"
  },
  {
    "id": "arXiv:2107.00377",
    "title": "VREUD -- An End-User Development Tool to Simplify the Creation of  Interactive VR Scenes",
    "abstract": "Recent advances in Virtual Reality (VR) technology and the increased\navailability of VR-equipped devices enable a wide range of consumer-oriented\napplications. For novice developers, however, creating interactive scenes for\nVR applications is a complex and cumbersome task that requires high technical\nknowledge which is often missing. This hinders the potential of enabling\nnovices to create, modify, and execute their own interactive VR scenes.\nAlthough recent authoring tools for interactive VR scenes are promising, most\nof them focus on expert professionals as the target group and neglect the\nnovices with low programming knowledge. To lower the entry barrier, we provide\nan open-source web-based End-User Development (EUD) tool, called VREUD, that\nsupports the rapid construction and execution of interactive VR scenes.\nConcerning construction, VREUD enables the specification of the VR scene\nincluding interactions and tasks. Furthermore, VREUD supports the execution and\nimmersive experience of the created interactive VR scenes on VR head-mounted\ndisplays. Based on a user study, we have analyzed the effectiveness,\nefficiency, and user satisfaction of VREUD which shows promising results to\nempower novices in creating their interactive VR scenes.",
    "descriptor": "\nComments: Preprint - accepted at IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2021)\n",
    "authors": [
      "Enes Yigitbas",
      "Jonas Klauke",
      "Sebastian Gottschalk",
      "Gregor Engels"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00377"
  },
  {
    "id": "arXiv:2107.00378",
    "title": "Evidence for Long-Tails in SLS Algorithms",
    "abstract": "Stochastic local search (SLS) is a successful paradigm for solving the\nsatisfiability problem of propositional logic. A recent development in this\narea involves solving not the original instance, but a modified, yet logically\nequivalent one. Empirically, this technique was found to be promising as it\nimproves the performance of state-of-the-art SLS solvers.\nCurrently, there is only a shallow understanding of how this modification\ntechnique affects the runtimes of SLS solvers. Thus, we model this modification\nprocess and conduct an empirical analysis of the hardness of logically\nequivalent formulas. Our results are twofold. First, if the modification\nprocess is treated as a random process, a lognormal distribution perfectly\ncharacterizes the hardness; implying that the hardness is long-tailed. This\nmeans that the modification technique can be further improved by implementing\nan additional restart mechanism. Thus, as a second contribution, we\ntheoretically prove that all algorithms exhibiting this long-tail property can\nbe further improved by restarts. Consequently, all SAT solvers employing this\nmodification technique can be enhanced.",
    "descriptor": "\nComments: To appear at ESA 2021\n",
    "authors": [
      "Florian W\u00f6rz",
      "Jan-Hendrik Lorenz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00378"
  },
  {
    "id": "arXiv:2107.00382",
    "title": "SSC: Semantic Scan Context for Large-Scale Place Recognition",
    "abstract": "Place recognition gives a SLAM system the ability to correct cumulative\nerrors. Unlike images that contain rich texture features, point clouds are\nalmost pure geometric information which makes place recognition based on point\nclouds challenging. Existing works usually encode low-level features such as\ncoordinate, normal, reflection intensity, etc., as local or global descriptors\nto represent scenes. Besides, they often ignore the translation between point\nclouds when matching descriptors. Different from most existing methods, we\nexplore the use of high-level features, namely semantics, to improve the\ndescriptor's representation ability. Also, when matching descriptors, we try to\ncorrect the translation between point clouds to improve accuracy. Concretely,\nwe propose a novel global descriptor, Semantic Scan Context, which explores\nsemantic information to represent scenes more effectively. We also present a\ntwo-step global semantic ICP to obtain the 3D pose (x, y, yaw) used to align\nthe point cloud to improve matching performance. Our experiments on the KITTI\ndataset show that our approach outperforms the state-of-the-art methods with a\nlarge margin. Our code is available at: https://github.com/lilin-hitcrt/SSC.",
    "descriptor": "\nComments: 8 pages, Accepted by IROS-2021\n",
    "authors": [
      "Lin Li",
      "Xin Kong",
      "Xiangrui Zhao",
      "Tianxin Huang",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00382"
  },
  {
    "id": "arXiv:2107.00384",
    "title": "A variational non-linear constrained model for the inversion of FDEM  data",
    "abstract": "Reconstructing the structure of the soil using non invasive techniques is a\nvery relevant problem in many scientific fields, like geophysics and\narchaeology. This can be done, for instance, with the aid of Frequency Domain\nElectromagnetic (FDEM) induction devices. Inverting FDEM data is a very\nchallenging inverse problem, as the problem is extremely ill-posed, i.e.,\nsensible to the presence of noise in the measured data, and non-linear.\nRegularization methods aim at reducing this sensitivity. In this paper we\ndevelop a regularization method to invert FDEM data. We propose to determine\nthe electrical conductivity of the ground by solving a variational problem. The\nminimized functional is made up by the sum of two terms, the data fitting term\nensures that the recovered solution fits the measured data, while the\nregularization term enforces sparsity on the Laplacian of the solution. The\ntrade-off between the two terms is determined by the regularization parameter.\nThis is achieved by minimizing an $\\ell_2 - \\ell_q$ functional with $0 < q \\leq\n2$. Since the functional we wish to minimize is nonconvex, we show that the\nvariational problem admits a solution. Moreover, we prove that, if the\nregularization parameter is tuned accordingly to the amount of noise present in\nthe data, this model induces a regularization method. Some selected numerical\nexamples show the good performances of our proposal.",
    "descriptor": "",
    "authors": [
      "Alessandro Buccini",
      "Patricia D\u00edaz de Alba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00384"
  },
  {
    "id": "arXiv:2107.00387",
    "title": "Modified sampling method with near field measurements",
    "abstract": "This paper investigates the inverse scattering problems using sampling\nmethods with near field measurements. The near field measurements appear in two\nclassical inverse scattering problems: the inverse scattering for obstacles and\nthe interior inverse scattering for cavities. We propose modified sampling\nmethods to treat these two classical problems using near field measurements\nwithout making any asymptotic assumptions on the distance between the\nmeasurement surface and the scatterers. We provide theoretical justifications\nbased on the factorization of the near field operator in both symmetric\nfactorization case and non-symmetric factorization case. Furthermore, we\nintroduce a data completion algorithm which allows us to apply the modified\nsampling methods to treat the limited-aperture inverse scattering problems.\nFinally numerical examples are provided to illustrate the modified sampling\nmethods with both full- and limited- aperture near field measurements.",
    "descriptor": "",
    "authors": [
      "Xiaodong Liu",
      "Shixu Meng",
      "Bo Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.00387"
  },
  {
    "id": "arXiv:2107.00389",
    "title": "Investigating the Reliability of Self-report Survey in the Wild: The  Quest for Ground Truth",
    "abstract": "Inferring human mental state (e.g., emotion, depression, engagement) with\nsensing technology is one of the most valuable challenges in the affective\ncomputing area, which has a profound impact in all industries interacting with\nhumans. The self-report survey is the most common way to quantify how people\nthink, but prone to subjectivity and various responses bias. It is usually used\nas the ground truth for human mental state prediction. In recent years, many\ndata-driven machine learning models are built based on self-report annotations\nas the target value. In this research, we investigate the reliability of\nself-report surveys in the wild by studying the confidence level of responses\nand survey completion time. We conduct a case study (i.e., student engagement\ninference) by recruiting 23 students in a high school setting over a period of\n4 weeks. Our participants volunteered 488 self-reported responses and data from\ntheir wearable sensors. We also find the physiologically measured student\nengagement and perceived student engagement are not always consistent. The\nfindings from this research have great potential to benefit future studies in\npredicting engagement, depression, stress, and other emotion-related states in\nthe field of affective computing and sensing technologies.",
    "descriptor": "",
    "authors": [
      "Nan Gao",
      "Mohammad Saiedur Rahaman",
      "Wei Shao",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00389"
  },
  {
    "id": "arXiv:2107.00395",
    "title": "GlyphCRM: Bidirectional Encoder Representation for Chinese Character  with its Glyph",
    "abstract": "Previous works indicate that the glyph of Chinese characters contains rich\nsemantic information and has the potential to enhance the representation of\nChinese characters. The typical method to utilize the glyph features is by\nincorporating them into the character embedding space. Inspired by previous\nmethods, we innovatively propose a Chinese pre-trained representation model\nnamed as GlyphCRM, which abandons the ID-based character embedding method yet\nsolely based on sequential character images. We render each character into a\nbinary grayscale image and design two-channel position feature maps for it.\nFormally, we first design a two-layer residual convolutional neural network,\nnamely HanGlyph to generate the initial glyph representation of Chinese\ncharacters, and subsequently adopt multiple bidirectional encoder Transformer\nblocks as the superstructure to capture the context-sensitive information.\nMeanwhile, we feed the glyph features extracted from each layer of the HanGlyph\nmodule into the underlying Transformer blocks by skip-connection method to\nfully exploit the glyph features of Chinese characters. As the HanGlyph module\ncan obtain a sufficient glyph representation of any Chinese character, the\nlong-standing out-of-vocabulary problem could be effectively solved. Extensive\nexperimental results indicate that GlyphCRM substantially outperforms the\nprevious BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has\nstrong transferability and generalization on specialized fields and\nlow-resource tasks. We hope this work could spark further research beyond the\nrealms of well-established representation of Chinese texts.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Yunxin Li",
      "Yu Zhao",
      "Baotian Hu",
      "Qingcai Chen",
      "Yang Xiang",
      "Xiaolong Wang",
      "Yuxin Ding",
      "Lin Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00395"
  },
  {
    "id": "arXiv:2107.00396",
    "title": "MIDV-2020: A Comprehensive Benchmark Dataset for Identity Document  Analysis",
    "abstract": "Identity documents recognition is an important sub-field of document\nanalysis, which deals with tasks of robust document detection, type\nidentification, text fields recognition, as well as identity fraud prevention\nand document authenticity validation given photos, scans, or video frames of an\nidentity document capture. Significant amount of research has been published on\nthis topic in recent years, however a chief difficulty for such research is\nscarcity of datasets, due to the subject matter being protected by security\nrequirements. A few datasets of identity documents which are available lack\ndiversity of document types, capturing conditions, or variability of document\nfield values. In addition, the published datasets were typically designed only\nfor a subset of document recognition problems, not for a complex identity\ndocument analysis. In this paper, we present a dataset MIDV-2020 which consists\nof 1000 video clips, 2000 scanned images, and 1000 photos of 1000 unique mock\nidentity documents, each with unique text field values and unique artificially\ngenerated faces, with rich annotation. For the presented benchmark dataset\nbaselines are provided for such tasks as document location and identification,\ntext fields recognition, and face detection. With 72409 annotated images in\ntotal, to the date of publication the proposed dataset is the largest publicly\navailable identity documents dataset with variable artificially generated data,\nand we believe that it will prove invaluable for advancement of the field of\ndocument analysis and recognition. The dataset is available for download at\nthis ftp URL and this http URL .",
    "descriptor": "",
    "authors": [
      "Konstantin Bulatov",
      "Ekaterina Emelianova",
      "Daniil Tropin",
      "Natalya Skoryukina",
      "Yulia Chernyshova",
      "Alexander Sheshkus",
      "Sergey Usilin",
      "Zuheng Ming",
      "Jean-Christophe Burie",
      "Muhammad Muzzamil Luqman",
      "Vladimir V. Arlazarov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.00396"
  },
  {
    "id": "arXiv:2107.00397",
    "title": "Learning-based pose edition for efficient and interactive design",
    "abstract": "Authoring an appealing animation for a virtual character is a challenging\ntask. In computer-aided keyframe animation artists define the key poses of a\ncharacter by manipulating its underlying skeletons. To look plausible, a\ncharacter pose must respect many ill-defined constraints, and so the resulting\nrealism greatly depends on the animator's skill and knowledge. Animation\nsoftware provide tools to help in this matter, relying on various algorithms to\nautomatically enforce some of these constraints. The increasing availability of\nmotion capture data has raised interest in data-driven approaches to pose\ndesign, with the potential of shifting more of the task of assessing realism\nfrom the artist to the computer, and to provide easier access to nonexperts. In\nthis article, we propose such a method, relying on neural networks to\nautomatically learn the constraints from the data. We describe an efficient\ntool for pose design, allowing na{\\\"i}ve users to intuitively manipulate a pose\nto create character animations.",
    "descriptor": "",
    "authors": [
      "L\u00e9on Victor",
      "Alexandre Meyer",
      "Sa\u00efda Bouakaz"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.00397"
  },
  {
    "id": "arXiv:2107.00399",
    "title": "Secretive Coded Caching from PDAs",
    "abstract": "The coded caching problem with secrecy constraint i.e., the users should not\nbe able to gain any information about the content of the files that they did\nnot demand, is known as the secretive coded caching problem. This was proposed\nby Ravindrakumar et al. in the paper titled ``Private Coded Caching'' that\nappeared in \\emph{ IEEE Transactions on Information Forensics and Security},\n2018 and is characterised by subpacketization levels growing exponentially with\nthe number of users. In the context of coded caching without secrecy, coded\ncaching schemes at subexponential subpacketization levels are feasible by\nrepresenting the caching system in the form of a Placement Delivery Array (PDA)\nand designing placement and delivery policies from it. Motivated by this, we\npropose a secretive coded caching scheme with low subpacketization using PDA,\nfor users with dedicated caches in the centralized setting. When our scheme is\napplied to a special class of PDA known as MN PDA, the scheme proposed by\nRavindrakumar et al. is recovered.",
    "descriptor": "\nComments: Accepted for presentation in IEEE PIMRC 2021\n",
    "authors": [
      "Shreya Shrestha Meel",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00399"
  },
  {
    "id": "arXiv:2107.00401",
    "title": "CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous  Cars on the Loihi Neuromorphic Research Processor",
    "abstract": "Autonomous Driving (AD) related features provide new forms of mobility that\nare also beneficial for other kind of intelligent and autonomous systems like\nrobots, smart transportation, and smart industries. For these applications, the\ndecisions need to be made fast and in real-time. Moreover, in the quest for\nelectric mobility, this task must follow low power policy, without affecting\nmuch the autonomy of the mean of transport or the robot. These two challenges\ncan be tackled using the emerging Spiking Neural Networks (SNNs). When deployed\non a specialized neuromorphic hardware, SNNs can achieve high performance with\nlow latency and low power consumption. In this paper, we use an SNN connected\nto an event-based camera for facing one of the key problems for AD, i.e., the\nclassification between cars and other objects. To consume less power than\ntraditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The\nexperiments are made following an offline supervised learning rule, followed by\nmapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our\nbest experiment achieves an accuracy on offline implementation of 86%, that\ndrops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware\nimplementation has maximum 0.72 ms of latency for every sample, and consumes\nonly 310 mW. To the best of our knowledge, this work is the first\nimplementation of an event-based car classifier on a Neuromorphic Chip.",
    "descriptor": "\nComments: Accepted for publication at IJCNN 2021\n",
    "authors": [
      "Alberto Viale",
      "Alberto Marchisio",
      "Maurizio Martina",
      "Guido Masera",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00401"
  },
  {
    "id": "arXiv:2107.00403",
    "title": "On Variants of Facility Location Problem with Outliers",
    "abstract": "In this work, we study the extension of two variants of the facility location\nproblem (FL) to make them robust towards a few distantly located clients.\nFirst, $k$-facility location problem ($k$FL), a common generalization of FL and\n$k$ median problems, is a well studied problem in literature. In the second\nvariant, lower bounded facility location (LBFL), we are given a bound on the\nminimum number of clients that an opened facility must serve. Lower bounds are\nrequired in many applications like profitability in commerce and load balancing\nin transportation problem. In both the cases, the cost of the solution may be\nincreased grossly by a few distantly located clients, called the outliers.\nThus, in this work, we extend $k$FL and LBFL to make them robust towards the\noutliers. For $k$FL with outliers ($k$FLO) we present the first (constant)\nfactor approximation violating the cardinality requirement by +1. As a\nby-product, we also obtain the first approximation for FLO based on\nLP-rounding. For LBFLO, we present a tri-criteria solution with a trade-off\nbetween the violations in lower bounds and the number of outliers. With a\nviolation of $1/2$ in lower bounds, we get a violation of $2$ in outliers.",
    "descriptor": "",
    "authors": [
      "Rajni Dabas",
      "Neelima Gupta"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00403"
  },
  {
    "id": "arXiv:2107.00411",
    "title": "Knowledge Distillation for Quality Estimation",
    "abstract": "Quality Estimation (QE) is the task of automatically predicting Machine\nTranslation quality in the absence of reference translations, making it\napplicable in real-time settings, such as translating online social media\nconversations. Recent success in QE stems from the use of multilingual\npre-trained representations, where very large models lead to impressive\nresults. However, the inference time, disk and memory requirements of such\nmodels do not allow for wide usage in the real world. Models trained on\ndistilled pre-trained representations remain prohibitively large for many usage\nscenarios. We instead propose to directly transfer knowledge from a strong QE\nteacher model to a much smaller model with a different, shallower architecture.\nWe show that this approach, in combination with data augmentation, leads to\nlight-weight QE models that perform competitively with distilled pre-trained\nrepresentations with 8x fewer parameters.",
    "descriptor": "\nComments: ACL Findings 2021\n",
    "authors": [
      "Amit Gajbhiye",
      "Marina Fomicheva",
      "Fernando Alva-Manchego",
      "Fr\u00e9d\u00e9ric Blain",
      "Abiola Obamuyide",
      "Nikolaos Aletras",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00411"
  },
  {
    "id": "arXiv:2107.00414",
    "title": "MultiCite: Modeling realistic citations requires moving beyond the  single-sentence single-label setting",
    "abstract": "Citation context analysis (CCA) is an important task in natural language\nprocessing that studies how and why scholars discuss each others' work. Despite\nbeing studied for decades, traditional frameworks for CCA have largely relied\non overly-simplistic assumptions of how authors cite, which ignore several\nimportant phenomena. For instance, scholarly papers often contain rich\ndiscussions of cited work that span multiple sentences and express multiple\nintents concurrently. Yet, CCA is typically approached as a single-sentence,\nsingle-label classification task, and thus existing datasets fail to capture\nthis interesting discourse. In our work, we address this research gap by\nproposing a novel framework for CCA as a document-level context extraction and\nlabeling task. We release MultiCite, a new dataset of 12,653 citation contexts\nfrom over 1,200 computational linguistics papers. Not only is it the largest\ncollection of expert-annotated citation contexts to-date, MultiCite contains\nmulti-sentence, multi-label citation contexts within full paper texts. Finally,\nwe demonstrate how our dataset, while still usable for training classic CCA\nmodels, also supports the development of new types of models for CCA beyond\nfixed-width text classification. We release our code and dataset at\nhttps://github.com/allenai/multicite.",
    "descriptor": "",
    "authors": [
      "Anne Lauscher",
      "Brandon Ko",
      "Bailey Kuhl",
      "Sophie Johnson",
      "David Jurgens",
      "Arman Cohan",
      "Kyle Lo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00414"
  },
  {
    "id": "arXiv:2107.00415",
    "title": "DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking  Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs), despite being energy-efficient when\nimplemented on neuromorphic hardware and coupled with event-based Dynamic\nVision Sensors (DVS), are vulnerable to security threats, such as adversarial\nattacks, i.e., small perturbations added to the input for inducing a\nmisclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet\nefficient adversarial attack methodologies targeted to perturb the event\nsequences that compose the input of the SNNs. First, we show that noise filters\nfor DVS can be used as defense mechanisms against adversarial attacks.\nAfterwards, we implement several attacks and test them in the presence of two\ntypes of noise filters for DVS cameras. The experimental results show that the\nfilters can only partially defend the SNNs against our proposed DVS-Attacks.\nUsing the best settings for the noise filters, our proposed Mask Filter-Aware\nDash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset\nand by more than 65% on the MNIST dataset, compared to the original clean\nframes. The source code of all the proposed DVS-Attacks and noise filters is\nreleased at https://github.com/albertomarchisio/DVS-Attacks.",
    "descriptor": "\nComments: Accepted for publication at IJCNN 2021\n",
    "authors": [
      "Alberto Marchisio",
      "Giacomo Pira",
      "Maurizio Martina",
      "Guido Masera",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00415"
  },
  {
    "id": "arXiv:2107.00416",
    "title": "Scrooge Attack: Undervolting ARM Processors for Profit",
    "abstract": "Latest ARM processors are approaching the computational power of x86\narchitectures while consuming much less energy. Consequently, supply follows\ndemand with Amazon EC2, Equinix Metal and Microsoft Azure offering ARM-based\ninstances, while Oracle Cloud Infrastructure is about to add such support. We\nexpect this trend to continue, with an increasing number of cloud providers\noffering ARM-based cloud instances.\nARM processors are more energy-efficient leading to substantial electricity\nsavings for cloud providers. However, a malicious cloud provider could\nintentionally reduce the CPU voltage to further lower its costs. Running\napplications malfunction when the undervolting goes below critical thresholds.\nBy avoiding critical voltage regions, a cloud provider can run undervolted\ninstances in a stealthy manner.\nThis practical experience report describes a novel attack scenario: an attack\nlaunched by the cloud provider against its users to aggressively reduce the\nprocessor voltage for saving energy to the last penny. We call it the Scrooge\nAttack and show how it could be executed using ARM-based computing instances.\nWe mimic ARM-based cloud instances by deploying our own ARM-based devices using\ndifferent generations of Raspberry Pi. Using realistic and synthetic workloads,\nwe demonstrate to which degree of aggressiveness the attack is relevant. The\nattack is unnoticeable by our detection method up to an offset of -50mV. We\nshow that the attack may even remain completely stealthy for certain workloads.\nFinally, we propose a set of client-based detection methods that can identify\nundervolted instances. We support experimental reproducibility and provide\ninstructions to reproduce our results.",
    "descriptor": "\nComments: European Commission Project: LEGaTO - Low Energy Toolset for Heterogeneous Computing (EC-H2020-780681)\n",
    "authors": [
      "Christian G\u00f6ttel",
      "Konstantinos Parasyris",
      "Osman Unsal",
      "Pascal Felber",
      "Marcelo Pasin",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00416"
  },
  {
    "id": "arXiv:2107.00417",
    "title": "Toward Interoperable Cyberinfrastructure: Common Descriptions for  Computational Resources and Applications",
    "abstract": "The user-facing components of the Cyberinfrastructure (CI) ecosystem, science\ngateways and scientific workflow systems, share a common need of interfacing\nwith physical resources (storage systems and execution environments) to manage\ndata and execute codes (applications). However, there is no uniform,\nplatform-independent way to describe either the resources or the applications.\nTo address this, we propose uniform semantics for describing resources and\napplications that will be relevant to a diverse set of stakeholders. We sketch\na solution to the problem of a common description and catalog of resources: we\ndescribe an approach to implementing a resource registry for use by the\ncommunity and discuss potential approaches to some long-term challenges. We\nconclude by looking ahead to the application description language.",
    "descriptor": "",
    "authors": [
      "Joe Stubbs",
      "Suresh Marru",
      "Daniel Mejia",
      "Daniel S. Katz",
      "Kyle Chard",
      "Maytal Dahan",
      "Marlon Pierce",
      "Michael Zentner"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00417"
  },
  {
    "id": "arXiv:2107.00420",
    "title": "CBNetV2: A Composite Backbone Network Architecture for Object Detection",
    "abstract": "Modern top-performing object detectors depend heavily on backbone networks,\nwhose advances bring consistent performance gains through exploring more\neffective network structures. However, designing or searching for a new\nbackbone and pre-training it on ImageNet may require a large number of\ncomputational resources, making it costly to obtain better detection\nperformance. In this paper, we propose a novel backbone network, namely\nCBNetV2, by constructing compositions of existing open-sourced pre-trained\nbackbones. In particular, CBNetV2 architecture groups multiple identical\nbackbones, which are connected through composite connections. We also propose a\nbetter training strategy with the Assistant Supervision for CBNet-based\ndetectors. Without additional pre-training, CBNetV2 can be integrated into\nmainstream detectors, including one-stage and two-stage detectors, as well as\nanchor-based and anchor-free-based ones, and significantly improve their\nperformance by more than 3.0% AP over the baseline on COCO. Also, experiments\nprovide strong evidence showing that composite backbones are more efficient and\nresource-friendly than pre-trained wider and deeper networks, including\nmanual-based and NAS-based, as well as CNN-based and Transformer-based ones.\nParticularly, with single-model and single-scale testing, our HTC Dual-Swin-B\nachieves 58.6% box AP and 51.1% mask AP on COCO test-dev, which is\nsignificantly better than the state-of-the-art result (i.e., 57.7% box AP and\n50.2% mask AP) achieved by a stronger baseline HTC++ with a larger backbone\nSwin-L. Code will be released at https://github.com/VDIGPKU/CBNetV2.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Tingting Liang",
      "Xiaojie Chu",
      "Yudong Liu",
      "Yongtao Wang",
      "Zhi Tang",
      "Wei Chu",
      "Jingdong Chen",
      "Haibing Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00420"
  },
  {
    "id": "arXiv:2107.00421",
    "title": "Machine learning based iterative learning control for non-repetitive  time-varying systems",
    "abstract": "The repetitive tracking task for time-varying systems (TVSs) with\nnon-repetitive time-varying parameters, which is also called non-repetitive\nTVSs, is realized in this paper using iterative learning control (ILC). A\nmachine learning (ML) based nominal model update mechanism, which utilizes the\nlinear regression technique to update the nominal model at each ILC trial only\nusing the current trial information, is proposed for non-repetitive TVSs in\norder to enhance the ILC performance. Given that the ML mechanism forces the\nmodel uncertainties to remain within the ILC robust tolerance, an ILC update\nlaw is proposed to deal with non-repetitive TVSs. How to tune parameters inside\nML and ILC algorithms to achieve the desired aggregate performance is also\nprovided. The robustness and reliability of the proposed method are verified by\nsimulations. Comparison with current state-of-the-art demonstrates its superior\ncontrol performance in terms of controlling precision. This paper broadens ILC\napplications from time-invariant systems to non-repetitive TVSs, adopts ML\nregression technique to estimate non-repetitive time-varying parameters between\ntwo ILC trials and proposes a detailed parameter tuning mechanism to achieve\ndesired performance, which are the main contributions.",
    "descriptor": "",
    "authors": [
      "Yiyang Chen",
      "Wei Jiang",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00421"
  },
  {
    "id": "arXiv:2107.00422",
    "title": "Generating Synthetic Training Data for Deep Learning-Based UAV  Trajectory Prediction",
    "abstract": "Deep learning-based models, such as recurrent neural networks (RNNs), have\nbeen applied to various sequence learning tasks with great success. Following\nthis, these models are increasingly replacing classic approaches in object\ntracking applications for motion prediction. On the one hand, these models can\ncapture complex object dynamics with less modeling required, but on the other\nhand, they depend on a large amount of training data for parameter tuning.\nTowards this end, we present an approach for generating synthetic trajectory\ndata of unmanned-aerial-vehicles (UAVs) in image space. Since UAVs, or rather\nquadrotors are dynamical systems, they can not follow arbitrary trajectories.\nWith the prerequisite that UAV trajectories fulfill a smoothness criterion\ncorresponding to a minimal change of higher-order motion, methods for planning\naggressive quadrotors flights can be utilized to generate optimal trajectories\nthrough a sequence of 3D waypoints. By projecting these maneuver trajectories,\nwhich are suitable for controlling quadrotors, to image space, a versatile\ntrajectory data set is realized. To demonstrate the applicability of the\nsynthetic trajectory data, we show that an RNN-based prediction model solely\ntrained on the generated data can outperform classic reference models on a\nreal-world UAV tracking dataset. The evaluation is done on the publicly\navailable ANTI-UAV dataset.",
    "descriptor": "",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00422"
  },
  {
    "id": "arXiv:2107.00425",
    "title": "Online learning of windmill time series using Long Short-term Cognitive  Networks",
    "abstract": "Forecasting windmill time series is often the basis of other processes such\nas anomaly detection, health monitoring, or maintenance scheduling. The amount\nof data generated on windmill farms makes online learning the most viable\nstrategy to follow. Such settings require retraining the model each time a new\nbatch of data is available. However, update the model with the new information\nis often very expensive to perform using traditional Recurrent Neural Networks\n(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to\nforecast windmill time series in online settings. These recently introduced\nneural systems consist of chained Short-term Cognitive Network blocks, each\nprocessing a temporal data chunk. The learning algorithm of these blocks is\nbased on a very fast, deterministic learning rule that makes LSTCNs suitable\nfor online learning tasks. The numerical simulations using a case study with\nfour windmills showed that our approach reported the lowest forecasting errors\nwith respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,\nand a Hidden Markov Model. What is perhaps more important is that the LSTCN\napproach is significantly faster than these state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Alejandro Morales-Hern\u00e1ndez",
      "Gonzalo N\u00e1poles",
      "Agnieszka Jastrzebska",
      "Yamisleydi Salgueiro",
      "Koen Vanhoof"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00425"
  },
  {
    "id": "arXiv:2107.00429",
    "title": "Neural Network Training with Highly Incomplete Datasets",
    "abstract": "Neural network training and validation rely on the availability of large\nhigh-quality datasets. However, in many cases only incomplete datasets are\navailable, particularly in health care applications, where each patient\ntypically undergoes different clinical procedures or can drop out of a study.\nSince the data to train the neural networks need to be complete, most studies\ndiscard the incomplete datapoints, which reduces the size of the training data,\nor impute the missing features, which can lead to artefacts. Alas, both\napproaches are inadequate when a large portion of the data is missing. Here, we\nintroduce GapNet, an alternative deep-learning training approach that can use\nhighly incomplete datasets. First, the dataset is split into subsets of samples\ncontaining all values for a certain cluster of features. Then, these subsets\nare used to train individual neural networks. Finally, this ensemble of neural\nnetworks is combined into a single neural network whose training is fine-tuned\nusing all complete datapoints. Using two highly incomplete real-world medical\ndatasets, we show that GapNet improves the identification of patients with\nunderlying Alzheimer's disease pathology and of patients at risk of\nhospitalization due to Covid-19. By distilling the information available in\nincomplete datasets without having to reduce their size or to impute missing\nvalues, GapNet will permit to extract valuable information from a wide range of\ndatasets, benefiting diverse fields from medicine to engineering.",
    "descriptor": "\nComments: 11 pages, 3 figures, 1 table\n",
    "authors": [
      "Yu-Wei Chang",
      "Laura Natali",
      "Oveis Jamialahmadi",
      "Stefano Romeo",
      "Joana B. Pereira",
      "Giovanni Volpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00429"
  },
  {
    "id": "arXiv:2107.00430",
    "title": "Segmenting 3D Hybrid Scenes via Zero-Shot Learning",
    "abstract": "This work is to tackle the problem of point cloud semantic segmentation for\n3D hybrid scenes under the framework of zero-shot learning. Here by hybrid, we\nmean the scene consists of both seen-class and unseen-class 3D objects, a more\ngeneral and realistic setting in application. To our knowledge, this problem\nhas not been explored in the literature. To this end, we propose a network to\nsynthesize point features for various classes of objects by leveraging the\nsemantic features of both seen and unseen object classes, called PFNet. The\nproposed PFNet employs a GAN architecture to synthesize point features, where\nthe semantic relationship between seen-class and unseen-class features is\nconsolidated by adapting a new semantic regularizer, and the synthesized\nfeatures are used to train a classifier for predicting the labels of the\ntesting 3D scene points. Besides we also introduce two benchmarks for\nalgorithmic evaluation by re-organizing the public S3DIS and ScanNet datasets\nunder six different data splits. Experimental results on the two benchmarks\nvalidate our proposed method, and we hope our introduced two benchmarks and\nmethodology could be of help for more research on this new direction.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Bo Liu",
      "Qiulei Dong",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00430"
  },
  {
    "id": "arXiv:2107.00431",
    "title": "A Discrete-time Reputation-based Resilient Consensus Algorithm for  Synchronous or Asynchronous Communications",
    "abstract": "We tackle the problem of a set of agents achieving resilient consensus in the\npresence of attacked agents. We present a discrete-time reputation-based\nconsensus algorithm for synchronous and asynchronous networks by developing a\nlocal strategy where, at each time, each agent assigns a reputation (between\nzero and one) to each neighbor. The reputation is then used to weigh the\nneighbors' values in the update of its state. Under mild assumptions, we show\nthat: (i) the proposed method converges exponentially to the consensus of the\nregular agents; (ii) if a regular agent identifies a neighbor as an attacked\nnode, then it is indeed an attacked node; (iii) if the consensus value of the\nnormal nodes differs from that of any of the attacked nodes' values, then the\nreputation that a regular agent assigns to the attacked neighbors goes to zero.\nFurther, we extend our method to achieve resilience in the scenarios where\nthere are noisy nodes, dynamic networks and stochastic node selection. Finally,\nwe illustrate our algorithm with several examples, and we delineate some\nattacking scenarios that can be dealt by the current proposal but not by the\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Guilherme Ramos",
      "Daniel Silvestre",
      "Carlos Silvestre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.00431"
  },
  {
    "id": "arXiv:2107.00434",
    "title": "Learning to Disambiguate Strongly Interacting Hands via Probabilistic  Per-pixel Part Segmentation",
    "abstract": "In natural conversation and interaction, our hands often overlap or are in\ncontact with each other. Due to the homogeneous appearance of hands, this makes\nestimating the 3D pose of interacting hands from images difficult. In this\npaper we demonstrate that self-similarity, and the resulting ambiguities in\nassigning pixel observations to the respective hands and their parts, is a\nmajor cause of the final 3D pose error. Motivated by this insight, we propose\nDIGIT, a novel method for estimating the 3D poses of two interacting hands from\na single monocular image. The method consists of two interwoven branches that\nprocess the input imagery into a per-pixel semantic part segmentation mask and\na visual feature volume. In contrast to prior work, we do not decouple the\nsegmentation from the pose estimation stage, but rather leverage the per-pixel\nprobabilities directly in the downstream pose estimation task. To do so, the\npart probabilities are merged with the visual features and processed via\nfully-convolutional layers. We experimentally show that the proposed approach\nachieves new state-of-the-art performance on the InterHand2.6M dataset for both\nsingle and interacting hands across all metrics. We provide detailed ablation\nstudies to demonstrate the efficacy of our method and to provide insights into\nhow the modelling of pixel ownership affects single and interacting hand pose\nestimation. Our code will be released for research purposes.",
    "descriptor": "",
    "authors": [
      "Zicong Fan",
      "Adrian Spurr",
      "Muhammed Kocabas",
      "Siyu Tang",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00434"
  },
  {
    "id": "arXiv:2107.00436",
    "title": "Overhead-MNIST: Machine Learning Baselines for Image Classification",
    "abstract": "Twenty-three machine learning algorithms were trained then scored to\nestablish baseline comparison metrics and to select an image classification\nalgorithm worthy of embedding into mission-critical satellite imaging systems.\nThe Overhead-MNIST dataset is a collection of satellite images similar in style\nto the ubiquitous MNIST hand-written digits found in the machine learning\nliterature. The CatBoost classifier, Light Gradient Boosting Machine, and\nExtreme Gradient Boosting models produced the highest accuracies, Areas Under\nthe Curve (AUC), and F1 scores in a PyCaret general comparison. Separate\nevaluations showed that a deep convolutional architecture was the most\npromising. We present results for the overall best performing algorithm as a\nbaseline for edge deployability and future performance improvement: a\nconvolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen\ntest data.",
    "descriptor": "\nComments: 6 pages; 8 figures\n",
    "authors": [
      "Erik Larsen",
      "David Noever",
      "Korey MacVittie",
      "John Lilly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00436"
  },
  {
    "id": "arXiv:2107.00439",
    "title": "What do End-to-End Speech Models Learn about Speaker, Language and  Channel Information? A Layer-wise and Neuron-level Analysis",
    "abstract": "End-to-end DNN architectures have pushed the state-of-the-art in speech\ntechnologies, as well as in other spheres of AI, leading researchers to train\nmore complex and deeper models. These improvements came at the cost of\ntransparency. DNNs are innately opaque and difficult to interpret. We no longer\nunderstand what features are learned, where they are preserved, and how they\ninter-operate. Such an analysis is important for better model understanding,\ndebugging and to ensure fairness in ethical decision making. In this work, we\nanalyze the representations trained within deep speech models, towards the task\nof speaker recognition, dialect identification and reconstruction of masked\nsignals. We carry a layer- and neuron-level analysis on the utterance-level\nrepresentations captured within pretrained speech models for speaker, language\nand channel properties. We study: is this information captured in the learned\nrepresentations? where is it preserved? how is it distributed? and can we\nidentify a minimal subset of network that posses this information. Using\ndiagnostic classifiers, we answered these questions. Our results reveal: (i)\nchannel and gender information is omnipresent and is redundantly distributed\n(ii) complex properties such as dialectal information is encoded only in the\ntask-oriented pretrained network and is localised in the upper layers (iii) a\nminimal subset of neurons can be extracted to encode the predefined property\n(iv) salient neurons are sometimes shared between properties and can highlights\npresence of biases in the network. Our cross-architectural comparison indicates\nthat (v) the pretrained models captures speaker-invariant information and (vi)\nthe pretrained CNNs models are competitive to the Transformers for encoding\ninformation for the studied properties. To the best of our knowledge, this is\nthe first study to investigate neuron analysis on the speech models.",
    "descriptor": "\nComments: Submitted to CSL. Keywords: Speech, Neuron Analysis, Interpretibility, Diagnostic Classifier, AI explainability, End-to-End Architecture\n",
    "authors": [
      "Shammur Absar Chowdhury",
      "Nadir Durrani",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00439"
  },
  {
    "id": "arXiv:2107.00440",
    "title": "CLINE: Contrastive Learning with Semantic Negative Examples for Natural  Language Understanding",
    "abstract": "Despite pre-trained language models have proven useful for learning\nhigh-quality semantic representations, these models are still vulnerable to\nsimple perturbations. Recent works aimed to improve the robustness of\npre-trained models mainly focus on adversarial training from perturbed examples\nwith similar semantics, neglecting the utilization of different or even\nopposite semantics. Different from the image processing field, the text is\ndiscrete and few word substitutions can cause significant semantic changes. To\nstudy the impact of semantics caused by small perturbations, we conduct a\nseries of pilot experiments and surprisingly find that adversarial training is\nuseless or even harmful for the model to detect these semantic changes. To\naddress this problem, we propose Contrastive Learning with semantIc Negative\nExamples (CLINE), which constructs semantic negative examples unsupervised to\nimprove the robustness under semantically adversarial attacking. By comparing\nwith similar and opposite semantic examples, the model can effectively perceive\nthe semantic changes caused by small perturbations. Empirical results show that\nour approach yields substantial improvements on a range of sentiment analysis,\nreasoning, and reading comprehension tasks. And CLINE also ensures the\ncompactness within the same semantics and separability across different\nsemantics in sentence-level.",
    "descriptor": "\nComments: ACL 2021, Main Conference, Long Paper\n",
    "authors": [
      "Dong Wang",
      "Ning Ding",
      "Piji Li",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00440"
  },
  {
    "id": "arXiv:2107.00441",
    "title": "When Curation Becomes Creation: Algorithms, Microcontent, and the  Vanishing Distinction between Platforms and Creators",
    "abstract": "Ever since social activity on the Internet began migrating from the wilds of\nthe open web to the walled gardens erected by so-called platforms, debates have\nraged about the responsibilities that these platforms ought to bear. And yet,\ndespite intense scrutiny from the news media and grassroots movements of\noutraged users, platforms continue to operate, from a legal standpoint, on the\nfriendliest terms. Under the current regulatory framework, platforms\nsimultaneously benefit from: (1) broad discretion to organize (and censor)\ncontent however they choose; (2) powerful algorithms for curating a practically\nlimitless supply of user-posted microcontent according to whatever ends they\nwish; and (3) absolution from the sorts of liability born by creators of the\nunderlying content. In this paper, we contest the very validity of the\nplatform-creator distinction, arguing that it is ill-adapted to the modern\nsocial media landscape where, in a real sense, platforms are creating\nderivative media products. We argue that any coherent regulatory framework must\nadapt to this reality, recognizing the subtle continuum of activities that span\nthe curation-creation spectrum, providing a finer system of categorization and\nclearer guidance for precisely when platforms assume the responsibilities\nassociated with content creation.",
    "descriptor": "",
    "authors": [
      "Liu Leqi",
      "Dylan Hadfield-Menell",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.00441"
  },
  {
    "id": "arXiv:2107.00443",
    "title": "Test Framework for a Virtual Competition Testbed",
    "abstract": "Virtual environments have been utilised in robotics research as a tool to\nassess systems before deploying them in the field. The COVID-19 pandemic has\nbrought about additional motivation for the development of virtual benchmarks\nin order to aid in safe and productive development. In-person robotics\ncompetitions have also halted, thus limiting the scope of opportunities for\nstudents and researchers. We implemented the structure of a service robotics\ncompetition into an extendable and adaptable virtual scoring environment. The\ncompetition challenges the state of the art in home service robotics by\npresenting realistic household tasks for robots to complete. The virtual\nenvironment provides a foundation for competition teams to assess their systems\nwhen accessing the physical environment is not possible. We believe that\nutilising virtual environments as a means of assessment will lead to other\nbenefits such as increased access and generalisation.",
    "descriptor": "",
    "authors": [
      "Liam Wellacott",
      "Emilyann Nault",
      "Ioannis Skottis",
      "Alexandre Colle",
      "Shreyank N Gowda",
      "Pierre Nicolay",
      "Emily Rolley-Parnell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00443"
  },
  {
    "id": "arXiv:2107.00446",
    "title": "Compression by Contracting Straight-Line Programs",
    "abstract": "In grammar-based compression a string is represented by a context-free\ngrammar, also called a straight-line program (SLP), that generates only that\nstring. We refine a recent balancing result stating that one can transform an\nSLP of size $g$ in linear time into an equivalent SLP of size $O(g)$ so that\nthe height of the unique derivation tree is $O(\\log N)$ where $N$ is the length\nof the represented string (FOCS 2019). We introduce a new class of balanced\nSLPs, called contracting SLPs, where for every rule $A \\to \\beta_1 \\dots\n\\beta_k$ the string length of every variable $\\beta_i$ on the right-hand side\nis smaller by a constant factor than the string length of $A$. In particular,\nthe derivation tree of a contracting SLP has the property that every subtree\nhas logarithmic height in its leaf size. We show that a given SLP of size $g$\ncan be transformed in linear time into an equivalent contracting SLP of size\n$O(g)$ with rules of constant length.\nWe present an application to the navigation problem in compressed unranked\ntrees, represented by forest straight-line programs (FSLPs). We extend a linear\nspace data structure by Reh and Sieber (2020) by the operation of moving to the\n$i$-th child in time $O(\\log d)$ where $d$ is the degree of the current node.\nContracting SLPs are also applied to the finger search problem over\nSLP-compressed strings where one wants to access positions near to a\npre-specified finger position, ideally in $O(\\log d)$ time where $d$ is the\ndistance between the accessed position and the finger. We give a linear space\nsolution where one can access symbols or move the finger in time $O(\\log d +\n\\log^{(t)} N)$ for any constant $t$ where $\\log^{(t)} N$ is the $t$-fold\nlogarithm of $N$. This improves a previous solution by Bille, Christiansen,\nCording, and G{\\o}rtz (2018) with access/move time $O(\\log d + \\log \\log N)$.",
    "descriptor": "",
    "authors": [
      "Moses Ganardi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00446"
  },
  {
    "id": "arXiv:2107.00451",
    "title": "VideoLightFormer: Lightweight Action Recognition using Transformers",
    "abstract": "Efficient video action recognition remains a challenging problem. One large\nmodel after another takes the place of the state-of-the-art on the Kinetics\ndataset, but real-world efficiency evaluations are often lacking. In this work,\nwe fill this gap and investigate the use of transformers for efficient action\nrecognition. We propose a novel, lightweight action recognition architecture,\nVideoLightFormer. In a factorized fashion, we carefully extend the 2D\nconvolutional Temporal Segment Network with transformers, while maintaining\nspatial and temporal video structure throughout the entire model. Existing\nmethods often resort to one of the two extremes, where they either apply huge\ntransformers to video features, or minimal transformers on highly pooled video\nfeatures. Our method differs from them by keeping the transformer models small,\nbut leveraging full spatiotemporal feature structure. We evaluate\nVideoLightFormer in a high-efficiency setting on the temporally-demanding\nEPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it\nachieves a better mix of efficiency and accuracy than existing state-of-the-art\nmodels, apart from the Temporal Shift Module on SSV2.",
    "descriptor": "",
    "authors": [
      "Raivo Koot",
      "Haiping Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00451"
  },
  {
    "id": "arXiv:2107.00456",
    "title": "Crowdsourcing Evaluation of Saliency-based XAI Methods",
    "abstract": "Understanding the reasons behind the predictions made by deep neural networks\nis critical for gaining human trust in many important applications, which is\nreflected in the increasing demand for explainability in AI (XAI) in recent\nyears. Saliency-based feature attribution methods, which highlight important\nparts of images that contribute to decisions by classifiers, are often used as\nXAI methods, especially in the field of computer vision. In order to compare\nvarious saliency-based XAI methods quantitatively, several approaches for\nautomated evaluation schemes have been proposed; however, there is no guarantee\nthat such automated evaluation metrics correctly evaluate explainability, and a\nhigh rating by an automated evaluation scheme does not necessarily mean a high\nexplainability for humans. In this study, instead of the automated evaluation,\nwe propose a new human-based evaluation scheme using crowdsourcing to evaluate\nXAI methods. Our method is inspired by a human computation game, \"Peek-a-boom\",\nand can efficiently compare different XAI methods by exploiting the power of\ncrowds. We evaluate the saliency maps of various XAI methods on two datasets\nwith automated and crowd-based evaluation schemes. Our experiments show that\nthe result of our crowd-based evaluation scheme is different from those of\nautomated evaluation schemes. In addition, we regard the crowd-based evaluation\nresults as ground truths and provide a quantitative performance measure to\ncompare different automated evaluation schemes. We also discuss the impact of\ncrowd workers on the results and show that the varying ability of crowd workers\ndoes not significantly impact the results.",
    "descriptor": "\nComments: 16 pages, 7 figures, 2 tables, Accepted for ECML-PKDD 2021\n",
    "authors": [
      "Xiaotian Lu",
      "Arseny Tolmachev",
      "Tatsuya Yamamoto",
      "Koh Takeuchi",
      "Seiji Okajima",
      "Tomoyoshi Takebayashi",
      "Koji Maruhashi",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00456"
  },
  {
    "id": "arXiv:2107.00465",
    "title": "Physics-Informed Neural Networks for Minimising Worst-Case Violations in  DC Optimal Power Flow",
    "abstract": "Physics-informed neural networks exploit the existing models of the\nunderlying physical systems to generate higher accuracy results with fewer\ndata. Such approaches can help drastically reduce the computation time and\ngenerate a good estimate of computationally intensive processes in power\nsystems, such as dynamic security assessment or optimal power flow. Combined\nwith the extraction of worst-case guarantees for the neural network\nperformance, such neural networks can be applied in safety-critical\napplications in power systems and build a high level of trust among power\nsystem operators. This paper takes the first step and applies, for the first\ntime to our knowledge, Physics-Informed Neural Networks with Worst-Case\nGuarantees for the DC Optimal Power Flow problem. We look for guarantees\nrelated to (i) maximum constraint violations, (ii) maximum distance between\npredicted and optimal decision variables, and (iii) maximum sub-optimality in\nthe entire input domain. In a range of PGLib-OPF networks, we demonstrate how\nphysics-informed neural networks can be supplied with worst-case guarantees and\nhow they can lead to reduced worst-case violations compared with conventional\nneural networks.",
    "descriptor": "\nComments: The code to reproduce all simulation results is available online in this https URL\n",
    "authors": [
      "Rahul Nellikkath",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00465"
  },
  {
    "id": "arXiv:2107.00480",
    "title": "EmoGen: Quantifiable Emotion Generation and Analysis for Experimental  Psychology",
    "abstract": "3D facial modelling and animation in computer vision and graphics\ntraditionally require either digital artist's skill or complex pipelines with\nobjective-function-based solvers to fit models to motion capture. This\ninaccessibility of quality modelling to a non-expert is an impediment to\neffective quantitative study of facial stimuli in experimental psychology. The\nEmoGen methodology we present in this paper solves the issue democratising\nfacial modelling technology. EmoGen is a robust and configurable framework\nletting anyone author arbitrary quantifiable facial expressions in 3D through a\nuser-guided genetic algorithm search. Beyond sample generation, our methodology\nis made complete with techniques to analyse distributions of these expressions\nin a principled way. This paper covers the technical aspects of expression\ngeneration, specifically our production-quality facial blendshape model,\nautomatic corrective mechanisms of implausible facial configurations in the\nabsence of artist's supervision and the genetic algorithm implementation\nemployed in the model space search. Further, we provide a comparative\nevaluation of ways to quantify generated facial expressions in the blendshape\nand geometric domains and compare them theoretically and empirically. The\npurpose of this analysis is 1. to define a similarity cost function to simulate\nmodel space search for convergence and parameter dependence assessment of the\ngenetic algorithm and 2. to inform the best practices in the data distribution\nanalysis for experimental psychology.",
    "descriptor": "",
    "authors": [
      "Nadejda Roubtsova",
      "Martin Parsons",
      "Nicola Binetti",
      "Isabelle Mareschal",
      "Essi Viding",
      "Darren Cosker"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00480"
  },
  {
    "id": "arXiv:2107.00481",
    "title": "Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in  Edge Industrial IoT",
    "abstract": "Edge computing provides a promising paradigm to support the implementation of\nIndustrial Internet of Things (IIoT) by offloading tasks to nearby edge nodes.\nMeanwhile, the increasing network size makes it impractical for centralized\ndata processing due to limited bandwidth, and consequently a decentralized\nlearning scheme is preferable. Reinforcement learning (RL) has been widely\ninvestigated and shown to be a promising solution for decision-making and\noptimal control processes. For RL in a decentralized setup, edge nodes (agents)\nconnected through a communication network aim to work collaboratively to find a\npolicy to optimize the global reward as the sum of local rewards. However,\ncommunication costs, scalability and adaptation in complex environments with\nheterogeneous agents may significantly limit the performance of decentralized\nRL. Alternating direction method of multipliers (ADMM) has a structure that\nallows for decentralized implementation, and has shown faster convergence than\ngradient descent based methods. Therefore, we propose an adaptive stochastic\nincremental ADMM (asI-ADMM) algorithm and apply the asI-ADMM to decentralized\nRL with edge-computing-empowered IIoT networks. We provide convergence\nproperties for proposed algorithms by designing a Lyapunov function and prove\nthat the asI-ADMM has $O(\\frac{1}{k}) +O(\\frac{1}{M})$ convergence rate where\n$k$ and $ M$ are the number of iterations and batch samples, respectively.\nThen, we test our algorithm with two supervised learning problems. For\nperformance evaluation, we simulate two applications in decentralized RL\nsettings with homogeneous and heterogeneous agents. The experiment results show\nthat our proposed algorithms outperform the state of the art in terms of\ncommunication costs and scalability, and can well adapt to complex IoT\nenvironments.",
    "descriptor": "",
    "authors": [
      "Wanlu Lei",
      "Yu Ye",
      "Ming Xiao",
      "Mikael Skoglund",
      "Zhu Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00481"
  },
  {
    "id": "arXiv:2107.00488",
    "title": "Differentiable Particle Filters through Conditional Normalizing Flow",
    "abstract": "Differentiable particle filters provide a flexible mechanism to adaptively\ntrain dynamic and measurement models by learning from observed data. However,\nmost existing differentiable particle filters are within the bootstrap particle\nfiltering framework and fail to incorporate the information from latest\nobservations to construct better proposals. In this paper, we utilize\nconditional normalizing flows to construct proposal distributions for\ndifferentiable particle filters, enriching the distribution families that the\nproposal distributions can represent. In addition, normalizing flows are\nincorporated in the construction of the dynamic model, resulting in a more\nexpressive dynamic model. We demonstrate the performance of the proposed\nconditional normalizing flow-based differentiable particle filters in a visual\ntracking task.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Xiongjie Chen",
      "Hao Wen",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00488"
  },
  {
    "id": "arXiv:2107.00490",
    "title": "Data Deduplication with Random Substitutions",
    "abstract": "Data deduplication saves storage space by identifying and removing repeats in\nthe data stream. Compared with traditional compression methods, data\ndeduplication schemes are more time efficient and are thus widely used in large\nscale storage systems. In this paper, we provide an information-theoretic\nanalysis on the performance of deduplication algorithms on data streams in\nwhich repeats are not exact. We introduce a source model in which probabilistic\nsubstitutions are considered. More precisely, each symbol in a repeated string\nis substituted with a given edit probability. Deduplication algorithms in both\nthe fixed-length scheme and the variable-length scheme are studied. The\nfixed-length deduplication algorithm is shown to be unsuitable for the proposed\nsource model as it does not take into account the edit probability. Two\nmodifications are proposed and shown to have performances within a constant\nfactor of optimal with the knowledge of source model parameters. We also study\nthe conventional variable-length deduplication algorithm and show that as\nsource entropy becomes smaller, the size of the compressed string vanishes\nrelative to the length of the uncompressed string, leading to high compression\nratios.",
    "descriptor": "",
    "authors": [
      "Hao Lou",
      "Farzad Farnoud"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.00490"
  },
  {
    "id": "arXiv:2107.00495",
    "title": "VeriDL: Integrity Verification of Outsourced Deep Learning Services  (Extended Version)",
    "abstract": "Deep neural networks (DNNs) are prominent due to their superior performance\nin many fields. The deep-learning-as-a-service (DLaaS) paradigm enables\nindividuals and organizations (clients) to outsource their DNN learning tasks\nto the cloud-based platforms. However, the DLaaS server may return incorrect\nDNN models due to various reasons (e.g., Byzantine failures). This raises the\nserious concern of how to verify if the DNN models trained by potentially\nuntrusted DLaaS servers are indeed correct. To address this concern, in this\npaper, we design VeriDL, a framework that supports efficient correctness\nverification of DNN models in the DLaaS paradigm. The key idea of VeriDL is the\ndesign of a small-size cryptographic proof of the training process of the DNN\nmodel, which is associated with the model and returned to the client. Through\nthe proof, VeriDL can verify the correctness of the DNN model returned by the\nDLaaS server with a deterministic guarantee and cheap overhead. Our experiments\non four real-world datasets demonstrate the efficiency and effectiveness of\nVeriDL.",
    "descriptor": "",
    "authors": [
      "Boxiang Dong",
      "Bo Zhang",
      "Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.00495"
  },
  {
    "id": "arXiv:2107.00500",
    "title": "On the detection-to-track association for online multi-object tracking",
    "abstract": "Driven by recent advances in object detection with deep neural networks, the\ntracking-by-detection paradigm has gained increasing prevalence in the research\ncommunity of multi-object tracking (MOT). It has long been known that\nappearance information plays an essential role in the detection-to-track\nassociation, which lies at the core of the tracking-by-detection paradigm.\nWhile most existing works consider the appearance distances between the\ndetections and the tracks, they ignore the statistical information implied by\nthe historical appearance distance records in the tracks, which can be\nparticularly useful when a detection has similar distances with two or more\ntracks. In this work, we propose a hybrid track association (HTA) algorithm\nthat models the historical appearance distances of a track with an incremental\nGaussian mixture model (IGMM) and incorporates the derived statistical\ninformation into the calculation of the detection-to-track association cost.\nExperimental results on three MOT benchmarks confirm that HTA effectively\nimproves the target identification performance with a small compromise to the\ntracking speed. Additionally, compared to many state-of-the-art trackers, the\nDeepSORT tracker equipped with HTA achieves better or comparable performance in\nterms of the balance of tracking quality and speed.",
    "descriptor": "",
    "authors": [
      "Xufeng Lin",
      "Chang-Tsun Li",
      "Victor Sanchez",
      "Carsten Maple"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00500"
  },
  {
    "id": "arXiv:2107.00501",
    "title": "Secure Quantized Training for Deep Learning",
    "abstract": "We have implemented training of neural networks in secure multi-party\ncomputation (MPC) using quantization commonly used in the said setting. To the\nbest of our knowledge, we are the first to present an MNIST classifier purely\ntrained in MPC that comes within 0.2 percent of the accuracy of the same\nconvolutional neural network trained via plaintext computation. More\nconcretely, we have trained a network with two convolution and two dense layers\nto 99.2% accuracy in 25 epochs. This took 3.5 hours in our MPC implementation\n(under one hour for 99% accuracy).",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Marcel Keller",
      "Ke Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00501"
  },
  {
    "id": "arXiv:2107.00504",
    "title": "A new Lagrange multiplier approach for constructing positivity  preserving schemes",
    "abstract": "We propose a new Lagrange multiplier approach to construct positivity\npreserving schemes for parabolic type equations. The new approach is based on\nexpanding a generic spatial discretization, which is not necessarily positivity\npreserving, by introducing a space-time Lagrange multiplier coupled with\nKarush-Kuhn-Tucker (KKT) conditions to preserve positivity. The key for an\nefficient and accurate time discretization of the expanded system is to adopt\nan operator-splitting or predictor-corrector approach in such a way that (i)\nthe correction step can be implemented with negligible cost, and (ii) it\npreserves the order of schemes at the prediction step. We establish some\nstability results under a general setting, and carry out error estimates for\nfirst-order versions of our approach and linear parabolic equation. We also\npresent ample numerical results to validate the new approach.",
    "descriptor": "",
    "authors": [
      "Qing Cheng",
      "Jie Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.00504"
  },
  {
    "id": "arXiv:2107.00507",
    "title": "Machine Learning and Deep Learning for Fixed-Text Keystroke Dynamics",
    "abstract": "Keystroke dynamics can be used to analyze the way that users type by\nmeasuring various aspects of keyboard input. Previous work has demonstrated the\nfeasibility of user authentication and identification utilizing keystroke\ndynamics. In this research, we consider a wide variety of machine learning and\ndeep learning techniques based on fixed-text keystroke-derived features, we\noptimize the resulting models, and we compare our results to those obtained in\nrelated research. We find that models based on extreme gradient boosting\n(XGBoost) and multi-layer perceptrons (MLP)perform well in our experiments. Our\nbest models outperform previous comparable research.",
    "descriptor": "",
    "authors": [
      "Han-Chih Chang",
      "Jianwei Li",
      "Ching-Seh Wu",
      "Mark Stamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00507"
  },
  {
    "id": "arXiv:2107.00511",
    "title": "TransSC: Transformer-based Shape Completion for Grasp Evaluation",
    "abstract": "Currently, robotic grasping methods based on sparse partial point clouds have\nattained a great grasping performance on various objects while they often\ngenerate wrong grasping candidates due to the lack of geometric information on\nthe object. In this work, we propose a novel and robust shape completion model\n(TransSC). This model has a transformer-based encoder to explore more\npoint-wise features and a manifold-based decoder to exploit more object details\nusing a partial point cloud as input.\nQuantitative experiments verify the effectiveness of the proposed shape\ncompletion network and demonstrate it outperforms existing methods. Besides,\nTransSC is integrated into a grasp evaluation network to generate a set of\ngrasp candidates. The simulation experiment shows that TransSC improves the\ngrasping generation result compared to the existing shape completion baselines.\nFurthermore, our robotic experiment shows that with TransSC the robot is more\nsuccessful in grasping objects that are randomly placed on a support surface.",
    "descriptor": "",
    "authors": [
      "Wenkai Chen",
      "Hongzhuo Liang",
      "Zhaopeng Chen",
      "Fuchun Sun",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00511"
  },
  {
    "id": "arXiv:2107.00516",
    "title": "Automatic Metadata Extraction Incorporating Visual Features from Scanned  Electronic Theses and Dissertations",
    "abstract": "Electronic Theses and Dissertations (ETDs) contain domain knowledge that can\nbe used for many digital library tasks, such as analyzing citation networks and\npredicting research trends. Automatic metadata extraction is important to build\nscalable digital library search engines. Most existing methods are designed for\nborn-digital documents, so they often fail to extract metadata from scanned\ndocuments such as for ETDs. Traditional sequence tagging methods mainly rely on\ntext-based features. In this paper, we propose a conditional random field (CRF)\nmodel that combines text-based and visual features. To verify the robustness of\nour model, we extended an existing corpus and created a new ground truth corpus\nconsisting of 500 ETD cover pages with human validated metadata. Our\nexperiments show that CRF with visual features outperformed both a heuristic\nand a CRF model with only text-based features. The proposed model achieved\n81.3%-96% F1 measure on seven metadata fields. The data and source code are\npublicly available on Google Drive (https://tinyurl.com/y8kxzwrp) and a GitHub\nrepository (https://github.com/lamps-lab/ETDMiner/tree/master/etd_crf),\nrespectively.",
    "descriptor": "\nComments: 7 pages, 4 figures, 1 table. Accepted by JCDL '21 as a short paper\n",
    "authors": [
      "Muntabir Hasan Choudhury",
      "Himarsha R. Jayanetti",
      "Jian Wu",
      "William A. Ingram",
      "Edward A. Fox"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00516"
  },
  {
    "id": "arXiv:2107.00520",
    "title": "Predictive Modeling in the Presence of Nuisance-Induced Spurious  Correlations",
    "abstract": "Deep predictive models often make use of spurious correlations between the\nlabel and the covariates that differ between training and test distributions.\nIn many classification tasks, spurious correlations are induced by a changing\nrelationship between the label and some nuisance variables correlated with the\ncovariates. For example, in classifying animals in natural images, the\nbackground, which is the nuisance, can predict the type of animal, but this\nnuisance label relationship does not always hold. This nuisance-label\nrelationship does not always hold. We formalize a family of distributions that\nonly differ in the nuisance-label relationship and and introduce a distribution\nwhere this relationship is broken called the nuisance-randomized distribution.\nWe introduce a set of predictive models built from the nuisance-randomized\ndistribution with representations, that when conditioned on, do not correlate\nthe label and the nuisance. For models in this set, we lower bound the\nperformance for any member of the family with the mutual information between\nthe representation and the label under the nuisance-randomized distribution. To\nbuild predictive models that maximize the performance lower bound, we develop\nNuisance-Randomized Distillation (NURD). We evaluate NURD on a synthetic\nexample, colored-MNIST, and classifying chest X-rays. When using non-lung\npatches as the nuisance in classifying chest X-rays, NURD produces models that\npredict pneumonia under strong spurious correlations.",
    "descriptor": "",
    "authors": [
      "Aahlad Puli",
      "Lily H. Zhang",
      "Eric K. Oermann",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00520"
  },
  {
    "id": "arXiv:2107.00522",
    "title": "Efficient Tree-Traversals: Reconciling Parallelism and Dense Data  Representations",
    "abstract": "Recent work showed that compiling functional programs to use dense,\nserialized memory representations for recursive algebraic datatypes can yield\nsignificant constant-factor speedups for sequential programs. But serializing\ndata in a maximally dense format consequently serializes the processing of that\ndata, yielding a tension between density and parallelism. This paper shows that\na disciplined, practical compromise is possible. We present Parallel Gibbon, a\ncompiler that obtains the benefits of dense data formats and parallelism. We\nformalize the semantics of the parallel location calculus underpinning this\nnovel implementation strategy, and show that it is type-safe. Parallel Gibbon\nexceeds the parallel performance of existing compilers for purely functional\nprograms that use recursive algebraic datatypes, including, notably,\nabstract-syntax-tree traversals as in compilers.",
    "descriptor": "",
    "authors": [
      "Chaitanya Koparkar",
      "Mike Rainey",
      "Michael Vollmer",
      "Milind Kulkarni",
      "Ryan R. Newton"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00522"
  },
  {
    "id": "arXiv:2107.00525",
    "title": "SearchGCN: Powering Embedding Retrieval by Graph Convolution Networks  for E-Commerce Search",
    "abstract": "Graph convolution networks (GCN), which recently becomes new state-of-the-art\nmethod for graph node classification, recommendation and other applications,\nhas not been successfully applied to industrial-scale search engine yet. In\nthis proposal, we introduce our approach, namely SearchGCN, for embedding-based\ncandidate retrieval in one of the largest e-commerce search engine in the\nworld. Empirical studies demonstrate that SearchGCN learns better embedding\nrepresentations than existing methods, especially for long tail queries and\nitems. Thus, SearchGCN has been deployed into JD.com's search production since\nJuly 2020.",
    "descriptor": "\nComments: 2 pages, 1 figure; accepted by SIGIR2021 industry track\n",
    "authors": [
      "Xinlin Xia",
      "Shang Wang",
      "Han Zhang",
      "Songlin Wang",
      "Sulong Xu",
      "Yun Xiao",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.00525"
  },
  {
    "id": "arXiv:2107.00526",
    "title": "Asymptotically Optimal Welfare of Posted Pricing for Multiple Items with  MHR Distributions",
    "abstract": "We consider the problem of posting prices for unit-demand buyers if all $n$\nbuyers have identically distributed valuations drawn from a distribution with\nmonotone hazard rate. We show that even with multiple items asymptotically\noptimal welfare can be guaranteed.\nOur main results apply to the case that either a buyer's value for different\nitems are independent or that they are perfectly correlated. We give mechanisms\nusing dynamic prices that obtain a $1 - \\Theta \\left( \\frac{1}{\\log\nn}\\right)$-fraction of the optimal social welfare in expectation. Furthermore,\nwe devise mechanisms that only use static item prices and are $1 - \\Theta\n\\left( \\frac{\\log\\log\\log n}{\\log n}\\right)$-competitive compared to the\noptimal social welfare. As we show, both guarantees are asymptotically optimal,\neven for a single item and exponential distributions.",
    "descriptor": "\nComments: To appear at the 29th Annual European Symposium on Algorithms (ESA 2021)\n",
    "authors": [
      "Alexander Braun",
      "Matthias Buttkus",
      "Thomas Kesselheim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00526"
  },
  {
    "id": "arXiv:2107.00528",
    "title": "Visualising Argumentation Graphs with Graph Embeddings and t-SNE",
    "abstract": "This paper applies t-SNE, a visualisation technique familiar from Deep Neural\nNetwork research to argumentation graphs by applying it to the output of graph\nembeddings generated using several different methods. It shows that such a\nvisualisation approach can work for argumentation and show interesting\nstructural properties of argumentation graphs, opening up paths for further\nresearch in the area.",
    "descriptor": "",
    "authors": [
      "Lars Malmqvist",
      "Tommy Yuan",
      "Suresh Manandhar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00528"
  },
  {
    "id": "arXiv:2107.00529",
    "title": "Multistage Stochastic Model Predictive Control for Urban Automated  Driving",
    "abstract": "Trajectory planning in urban automated driving is challenging because of the\nhigh uncertainty resulting from the unknown future motion of other traffic\nparticipants. Robust approaches guarantee safety, but tend to result in overly\nconservative motion planning. Hence, we propose to use Stochastic Model\nPredictive Control for vehicle control in urban driving, allowing to\nefficiently plan the vehicle trajectory, while maintaining the risk probability\nsufficiently low. For motion optimization, we propose to use a two-stage\nhierarchical structure that plans the trajectory and the maneuver separately. A\nhigh-level layer takes advantage of a long prediction horizon and of an\nabstract model to plan the optimal maneuver, and a lower level is in charge of\nexecuting the selected maneuver by properly planning the vehicle's trajectory.\nNumerical simulations are included, showing the potential of our proposal.",
    "descriptor": "\nComments: This work has been accepted to the IEEE 2021 International Conference on Intelligent Transportation Systems\n",
    "authors": [
      "Tommaso Benciolini",
      "Tim Br\u00fcdigam",
      "Marion Leibold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00529"
  },
  {
    "id": "arXiv:2107.00530",
    "title": "Testing a Battery Management System via Criticality-based Rare Event  Simulation",
    "abstract": "For the validation of safety-critical systems regarding safety and comfort,\ne.g., in the context of automated driving, engineers often have to cope with\nlarge (parametric) test spaces for which it is infeasible to test through all\npossible parameter configurations. At the same time, critical behavior of a\nwell-engineered system with respect to prescribed safety and comfort\nrequirements tends to be extremely rare, speaking of probabilities of order\n$10^{-6}$ or less, but clearly has to be examined carefully for valid\nargumentation. Hence, common approaches such as boundary value analysis are\ninsufficient while methods based on random sampling from the parameter space\n(simple Monte Carlo) lack the ability to detect these rare critical events\nefficiently, i.e., with appropriate simulation budget. For this reason, a more\nsophisticated simulation-based approach is proposed which employs optimistic\noptimization on an objective function called \"criticality\" in order to identify\neffectively the set of critical parameter configurations. Within the scope of\nthe ITEA 3 TESTOMAT project (this http URL) the collaboration\npartners OFFIS e.V. and AKKA Germany GmbH conducted a case study on applying\ncriticality-based rare event simulation to the charging process of an\nautomotive battery management system given as a model. The present technical\nreport documents the industrial use case, the approach, application and\nexperimental results, as well as lessons learned from the case study.",
    "descriptor": "\nComments: A more cohensive version of this technical report has been presented at the MSCPES 2021 workshop and will be published by ACM, available at this https URL\n",
    "authors": [
      "Daniel Grujic",
      "Tabea Henning",
      "Emilio Jos\u00e9 Calleja Garc\u00eda",
      "Andre Bergmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00530"
  },
  {
    "id": "arXiv:2107.00531",
    "title": "Towards a fairer reimbursement system for burn patients using  cost-sensitive classification",
    "abstract": "The adoption of the Prospective Payment System (PPS) in the UK National\nHealth Service (NHS) has led to the creation of patient groups called Health\nResource Groups (HRG). HRGs aim to identify groups of clinically similar\npatients that share similar resource usage for reimbursement purposes. These\ngroups are predominantly identified based on expert advice, with homogeneity\nchecked using the length of stay (LOS). However, for complex patients such as\nthose encountered in burn care, LOS is not a perfect proxy of resource usage,\nleading to incomplete homogeneity checks. To improve homogeneity in resource\nusage and severity, we propose a data-driven model and the inclusion of\npatient-level costing. We investigate whether a data-driven approach that\nconsiders additional measures of resource usage can lead to a more\ncomprehensive model. In particular, a cost-sensitive decision tree model is\nadopted to identify features of importance and rules that allow for a focused\nsegmentation on resource usage (LOS and patient-level cost) and clinical\nsimilarity (severity of burn). The proposed approach identified groups with\nincreased homogeneity compared to the current HRG groups, allowing for a more\nequitable reimbursement of hospital care costs if adopted.",
    "descriptor": "\nComments: Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied Data Science for Healthcare: State of XAI and trustworthiness in Health\n",
    "authors": [
      "Chimdimma Noelyn Onah",
      "Richard Allmendinger",
      "Julia Handl",
      "Ken W. Dunn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00531"
  },
  {
    "id": "arXiv:2107.00540",
    "title": "Using Terminal Circuit for Power System Electromagnetic Transient  Simulation",
    "abstract": "The modern power system is evolving with increasing penetration of power\nelectronics introducing complicated electromagnetic phenomenon. Electromagnetic\ntransient (EMT) simulation is essential to understand power system behavior\nunder disturbance which however is one of the most sophisticated and\ntime-consuming applications in power system. To improve the electromagnetic\ntransient simulation efficiency while keeping the simulation accuracy, this\npaper proposes to model and simulate power system electromagnetic transients by\nvery large-scale integrated circuit (VLSI) as a preliminary exploration to\neventually represent power system by VLSI circuit chip avoiding numerical\ncalculation. To proof the concept, a simple 5 bus system is modeled and\nsimulated to verify the feasibility of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Yijing Liu",
      "Xiang Zhang",
      "Renchang Dai",
      "Guangyi Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.00540"
  },
  {
    "id": "arXiv:2107.00541",
    "title": "Goal-Conditioned Reinforcement Learning with Imagined Subgoals",
    "abstract": "Goal-conditioned reinforcement learning endows an agent with a large variety\nof skills, but it often struggles to solve tasks that require more temporally\nextended reasoning. In this work, we propose to incorporate imagined subgoals\ninto policy learning to facilitate learning of complex tasks. Imagined subgoals\nare predicted by a separate high-level policy, which is trained simultaneously\nwith the policy and its critic. This high-level policy predicts intermediate\nstates halfway to the goal using the value function as a reachability metric.\nWe don't require the policy to reach these subgoals explicitly. Instead, we use\nthem to define a prior policy, and incorporate this prior into a KL-constrained\npolicy iteration scheme to speed up and regularize learning. Imagined subgoals\nare used during policy learning, but not during test time, where we only apply\nthe learned policy. We evaluate our approach on complex robotic navigation and\nmanipulation tasks and show that it outperforms existing methods by a large\nmargin.",
    "descriptor": "\nComments: ICML 2021. See the project webpage at this https URL\n",
    "authors": [
      "Elliot Chane-Sane",
      "Cordelia Schmid",
      "Ivan Laptev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00541"
  },
  {
    "id": "arXiv:2107.00544",
    "title": "Improving Human Motion Prediction Through Continual Learning",
    "abstract": "Human motion prediction is an essential component for enabling closer\nhuman-robot collaboration. The task of accurately predicting human motion is\nnon-trivial. It is compounded by the variability of human motion, both at a\nskeletal level due to the varying size of humans and at a motion level due to\nindividual movement's idiosyncrasies. These variables make it challenging for\nlearning algorithms to obtain a general representation that is robust to the\ndiverse spatio-temporal patterns of human motion. In this work, we propose a\nmodular sequence learning approach that allows end-to-end training while also\nhaving the flexibility of being fine-tuned. Our approach relies on the\ndiversity of training samples to first learn a robust representation, which can\nthen be fine-tuned in a continual learning setup to predict the motion of new\nsubjects. We evaluated the proposed approach by comparing its performance\nagainst state-of-the-art baselines. The results suggest that our approach\noutperforms other methods over all the evaluated temporal horizons, using a\nsmall amount of data for fine-tuning. The improved performance of our approach\nopens up the possibility of using continual learning for personalized and\nreliable motion prediction.",
    "descriptor": "",
    "authors": [
      "Mohammad Samin Yasar",
      "Tariq Iqbal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00544"
  },
  {
    "id": "arXiv:2107.00549",
    "title": "Scalar conservation laws with stochastic discontinuous flux function",
    "abstract": "A variety of real-world applications are modeled via hyperbolic conservation\nlaws. To account for uncertainties or insufficient measurements, random\ncoefficients may be incorporated. These random fields may depend\ndiscontinuously on the state space, e.g., to represent permeability in a\nheterogeneous or fractured medium. We introduce a suitable admissibility\ncriterion for the resulting stochastic discontinuous-flux conservation law and\nprove its well-posedness. Therefore, we ensure the pathwise existence and\nuniqueness of the corresponding deterministic setting and present a novel proof\nfor the measurability of the solution, since classical approaches fail in the\ndiscontinuous-flux case. As an example of the developed theory, we present a\nspecific advection coefficient, which is modeled as a sum of a continuous\nrandom field and a pure jump field. This random field is employed in the\nstochastic conservation law, in particular a stochastic Burgers' equation, for\nnumerical experiments. We approximate the solution to this problem via the\nFinite Volume method and introduce a new meshing strategy that accounts for the\nresulting standing wave profiles caused by the flux-discontinuities. The\nability of this new meshing method to reduce the sample-wise variance is\ndemonstrated in numerous numerical investigations.",
    "descriptor": "",
    "authors": [
      "Lukas Brencher",
      "Andrea Barth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.00549"
  },
  {
    "id": "arXiv:2107.00552",
    "title": "IsiSPL: An Automated Reactive Approach to Build Software Product Lines",
    "abstract": "Over the last decades, Software Product Lines (SPL) have demonstrated the\nadvantages of a systematic reuse, to increase the productivity of the software\ndevelopment and the quality of the software products. Nonetheless, it is clear\nthat despite these advantages, the construction of an SPL remains a real\nchallenge for many companies. Of the three adoption approaches, i.e.\nextractive, proactive and reactive, only the reactive approach is close to the\nreality of software development in practice.\nHowever, the difficulty of an iterative SPL re-engineering prevents the\nreactive approach from rising in popularity, and thus it limits its widespread\nadoption. We note in the literature an absence of works related to the\nautomation of this approach, from the successive SPL re-engineering process to\nthe SPL evolution by the developers.\nIn this paper, we propose isiSPL: a reactive-based approach that automates\nthe entire SPL re-engineering, from the identification of the artefact to the\nfeatures location. Moreover, isiSPL builds a concrete and accessible\nrepresentation of an SPL implementation, which facilitates its maintenance and\nevolution by developers. We have implemented isiSPL as a prototype and\nevaluated it over ArgoUML-SPL and Soduko-SPL. We observe promising results, as\nwe were able to automate the full integration of products without losing their\nfeatures, or modifying their features' behaviors.",
    "descriptor": "",
    "authors": [
      "Nicolas Hlad",
      "Seriai Abdelhak-Djamel",
      "Dony Christophe"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00552"
  },
  {
    "id": "arXiv:2107.00555",
    "title": "Productivity, Portability, Performance: Data-Centric Python",
    "abstract": "Python has become the de facto language for scientific computing. Programming\nin Python is highly productive, mainly due to its rich science-oriented\nsoftware ecosystem built around the NumPy module. As a result, the demand for\nPython support in High Performance Computing (HPC) has skyrocketed. However,\nthe Python language itself does not necessarily offer high performance. In this\nwork, we present a workflow that retains Python's high productivity while\nachieving portable performance across different architectures. The workflow's\nkey features are HPC-oriented language extensions and a set of automatic\noptimizations powered by a data-centric intermediate representation. We show\nperformance results and scaling across CPU, GPU, FPGA, and the Piz Daint\nsupercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups over\nprevious-best solutions, first-ever Xilinx and Intel FPGA results of annotated\nPython, and up to 93.16% scaling efficiency on 512 nodes.",
    "descriptor": "",
    "authors": [
      "Alexandros Nikolaos Ziogas",
      "Timo Schneider",
      "Tal Ben-Nun",
      "Alexandru Calotoiu",
      "Tiziano De Matteis",
      "Johannes de Fine Licht",
      "Luca Lavarini",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.00555"
  },
  {
    "id": "arXiv:2107.00559",
    "title": "SALYPATH: A Deep-Based Architecture for visual attention prediction",
    "abstract": "Human vision is naturally more attracted by some regions within their field\nof view than others. This intrinsic selectivity mechanism, so-called visual\nattention, is influenced by both high- and low-level factors; such as the\nglobal environment (illumination, background texture, etc.), stimulus\ncharacteristics (color, intensity, orientation, etc.), and some prior visual\ninformation. Visual attention is useful for many computer vision applications\nsuch as image compression, recognition, and captioning. In this paper, we\npropose an end-to-end deep-based method, so-called SALYPATH (SALiencY and\nscanPATH), that efficiently predicts the scanpath of an image through features\nof a saliency model. The idea is predict the scanpath by exploiting the\ncapacity of a deep-based model to predict the saliency. The proposed method was\nevaluated through 2 well-known datasets. The results obtained showed the\nrelevance of the proposed framework comparing to state-of-the-art models.",
    "descriptor": "\nComments: Accepted at ICIP, 5 pages, 2 figures and 3 tables\n",
    "authors": [
      "Mohamed Amine Kerkouri",
      "Marouane Tliba",
      "Aladine Chetouani",
      "Rachid Harba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00559"
  },
  {
    "id": "arXiv:2107.00561",
    "title": "Using Anomaly Feature Vectors for Detecting, Classifying and Warning of  Outlier Adversarial Examples",
    "abstract": "We present DeClaW, a system for detecting, classifying, and warning of\nadversarial inputs presented to a classification neural network. In contrast to\ncurrent state-of-the-art methods that, given an input, detect whether an input\nis clean or adversarial, we aim to also identify the types of adversarial\nattack (e.g., PGD, Carlini-Wagner or clean). To achieve this, we extract\nstatistical profiles, which we term as anomaly feature vectors, from a set of\nlatent features. Preliminary findings suggest that AFVs can help distinguish\namong several types of adversarial attacks (e.g., PGD versus Carlini-Wagner)\nwith close to 93% accuracy on the CIFAR-10 dataset. The results open the door\nto using AFV-based methods for exploring not only adversarial attack detection\nbut also classification of the attack type and then design of attack-specific\nmitigation strategies.",
    "descriptor": "\nComments: ICML 2021 workshop on A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning\n",
    "authors": [
      "Nelson Manohar-Alers",
      "Ryan Feng",
      "Sahib Singh",
      "Jiguo Song",
      "Atul Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.00561"
  },
  {
    "id": "arXiv:2107.00564",
    "title": "A Note on Exhaustive State Space Search for Efficient Code Generation",
    "abstract": "This note explores state space search to find efficient instruction sequences\nthat perform particular data manipulations. Once found, the instruction\nsequences are hard-wired in the code generator that needs these data\nmanipulations. Since state space is only searched while developing the\ncompiler, search time is not at a premium, which allows exhaustively searching\nfor the best possible instruction sequences.",
    "descriptor": "\nComments: white paper\n",
    "authors": [
      "Aart J.C. Bik"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00564"
  },
  {
    "id": "arXiv:2107.00565",
    "title": "Data-Enhanced Process Models in Process Mining",
    "abstract": "Understanding and improving business processes have become important success\nfactors for organizations. Process mining has proven very successful with a\nvariety of methods and techniques, including discovering process models based\non event logs. Process mining has traditionally focussed on control flow and\ntiming aspects. However, getting insights about a process is not only based on\nactivities and their orderings, but also on the data generated and manipulated\nduring process executions. Today, almost every process activity generates data;\nthese data do not play the role in process mining that it deserves. This paper\nintroduces a visualization technique for enhancing discovered process models\nwith domain data, thereby allowing data-based exploration of processes.\nData-enhanced process models aim at supporting domain experts to explore the\nprocess, where they can select attributes of interest and observe their\ninfluence on the process. The visualization technique is illustrated by the\nMIMIC-IV real-world data set on hospitalizations in the US.",
    "descriptor": "",
    "authors": [
      "Jonas Cremerius",
      "Mathias Weske"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2107.00565"
  },
  {
    "id": "arXiv:2107.00567",
    "title": "Hippocampal Spatial Mapping As Fast Graph Learning",
    "abstract": "The hippocampal formation is thought to learn spatial maps of environments,\nand in many models this learning process consists of forming a sensory\nassociation for each location in the environment. This is inefficient, akin to\nlearning a large lookup table for each environment. Spatial maps can be learned\nmuch more efficiently if the maps instead consist of arrangements of sparse\nenvironment parts. In this work, I approach spatial mapping as a problem of\nlearning graphs of environment parts. Each node in the learned graph,\nrepresented by hippocampal engram cells, is associated with feature information\nin lateral entorhinal cortex (LEC) and location information in medial\nentorhinal cortex (MEC) using empirically observed neuron types. Each edge in\nthe graph represents the relation between two parts, and it is associated with\ncoarse displacement information. This core idea of associating arbitrary\ninformation with nodes and edges is not inherently spatial, so this proposed\nfast-relation-graph-learning algorithm can expand to incorporate many spatial\nand non-spatial tasks.",
    "descriptor": "\nComments: 9 pages, 4 figures, writeup of poster for 30th Annual Computational Neuroscience Meeting (CNS 2021)\n",
    "authors": [
      "Marcus Lewis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.00567"
  },
  {
    "id": "arXiv:2107.00570",
    "title": "Proposed new dynamic power insertion method for stabilized power  generation based on battery energy storage system",
    "abstract": "The solar energy is clean and future energy for electricity generation. Its\nenergy has enormous potential but do not optimal to utilized caused by\nintermittent energy. The intermittent radiance and ambient temperature\ninfluence the energy produced fluctuates and unstable. These power fluctuations\naffect system stability and frequency. To overcome this problem, several\nmethods for PV power stabilization have been developed. One of them is the\nStabilized Power Generation where PV output power is to a certain power value.\nThe result of SPG method is reducing in PV power fluctuations but still\nunstable. For reaching the stable condition of PV Power output, the Dynamic\nPower Insertion method is proposed which is a modification of the SPG method\nwith energy storage batteries. DPI improve the SPG method and make PV power\nstable with active power management with charge and discharge action. The\nbattery is using as energy storage when PV power is larger than Power limit. On\nthe other hand battery as an energy source for active power insertion at PV\npower is smaller than Power limit. Thus the output power in each condition can\nbe maintained as Power PV equals to P limit. For test this method, DPI modules\nare built on ARM lpc1768 NXP and monitored with the Thing speak webserver\n(simulated with Simulink MatLab Software). The experimental results of DPI can\nstabilize PV power fluctuation at its setting power with an error of 5 percent.",
    "descriptor": "\nComments: 9 pages, 9 figures, 3 Tables ,uses Thingspeak software\n",
    "authors": [
      "Amirhossein Khosravipour"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00570"
  },
  {
    "id": "arXiv:2107.00571",
    "title": "Learning Large DAGs by Combining Continuous Optimization and Feedback  Arc Set Heuristics",
    "abstract": "Bayesian networks represent relations between variables using a directed\nacyclic graph (DAG). Learning the DAG is an NP-hard problem and exact learning\nalgorithms are feasible only for small sets of variables. We propose two\nscalable heuristics for learning DAGs in the linear structural equation case.\nOur methods learn the DAG by alternating between unconstrained gradient\ndescent-based step to optimize an objective function and solving a maximum\nacyclic subgraph problem to enforce acyclicity. Thanks to this decoupling, our\nmethods scale up beyond thousands of variables.",
    "descriptor": "",
    "authors": [
      "Pierre Gillot",
      "Pekka Parviainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00571"
  },
  {
    "id": "arXiv:2107.00572",
    "title": "Orienting (hyper)graphs under explorable stochastic uncertainty",
    "abstract": "Given a hypergraph with uncertain node weights following known probability\ndistributions, we study the problem of querying as few nodes as possible until\nthe identity of a node with minimum weight can be determined for each\nhyperedge. Querying a node has a cost and reveals the precise weight of the\nnode, drawn from the given probability distribution. Using competitive\nanalysis, we compare the expected query cost of an algorithm with the expected\ncost of an optimal query set for the given instance. For the general case, we\ngive a polynomial-time $f(\\alpha)$-competitive algorithm, where $f(\\alpha)\\in\n[1.618+\\epsilon,2]$ depends on the approximation ratio $\\alpha$ for an\nunderlying vertex cover problem. We also show that no algorithm using a similar\napproach can be better than $1.5$-competitive. Furthermore, we give\npolynomial-time $4/3$-competitive algorithms for bipartite graphs with\narbitrary query costs and for hypergraphs with a single hyperedge and uniform\nquery costs, with matching lower bounds.",
    "descriptor": "\nComments: An extended abstract appears in the proceedings of the 29th Annual European Symposium on Algorithms (ESA 2021)\n",
    "authors": [
      "Evripidis Bampis",
      "Christoph D\u00fcrr",
      "Thomas Erlebach",
      "Murilo S. de Lima",
      "Nicole Megow",
      "Jens Schl\u00f6ter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00572"
  },
  {
    "id": "arXiv:2107.00577",
    "title": "How many FIDO protocols are needed? Surveying the design, security and  market perspectives",
    "abstract": "Unequivocally, a single man in possession of a strong password is not enough\nto solve the issue of security. Studies indicate that passwords have been\nsubjected to various attacks, regardless of the applied protection mechanisms\ndue to the human factor. The keystone for the adoption of more efficient\nauthentication methods by the different markets is the trade-off between\nsecurity and usability. To bridge the gap between user-friendly interfaces and\nadvanced security features, the Fast Identity Online (FIDO) alliance defined\nseveral authentication protocols. Although FIDO's biometric-based\nauthentication is not a novel concept, still daunts end users and developers,\nwhich may be a contributor factor obstructing FIDO's complete dominance of the\ndigital authentication market. This paper traces the evolution of FIDO\nprotocols, by identifying the technical characteristics and security\nrequirements of the FIDO protocols throughout the different versions while\nproviding a comprehensive study on the different markets (e.g., digital\nbanking, social networks, e-government, etc.), applicability, ease of use,\nextensibility and future security considerations. From the analysis, we\nconclude that there is currently no dominant version of a FIDO protocol and\nmore importantly, earlier FIDO protocols are still applicable to emerging\nvertical services.",
    "descriptor": "\nComments: This paper is submitted for publication to ACM Computing Surveys\n",
    "authors": [
      "Anna Angelogianni",
      "Ilias Politis",
      "Christos Xenakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.00577"
  },
  {
    "id": "arXiv:2107.00580",
    "title": "Mission Impossible: Securing Master Keys",
    "abstract": "Securing a secret master key is a non-trivial task, we even argue it is\nimpossible to fully secure it, hence we must make it as difficult as possible\nfor any powerful adversary to steal or use the key. We introduce the reader to\ninteresting cryptography which is starting to get more attention in terms of\naddressing the above problem, and we briefly overview some commercial and\nopen-source products that can be used. Finally, we propose a set of solutions\non how to secure master keys, more as guidelines rather than exact technical\nspecifications, with aim to inspire and raise awareness of how to increase the\nsecurity as much as possible.",
    "descriptor": "",
    "authors": [
      "Hannes Salin",
      "Dennis Fokin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.00580"
  },
  {
    "id": "arXiv:2107.00583",
    "title": "Inter Extreme Points Geodesics for Weakly Supervised Segmentation",
    "abstract": "We introduce $\\textit{InExtremIS}$, a weakly supervised 3D approach to train\na deep image segmentation network using particularly weak train-time\nannotations: only 6 extreme clicks at the boundary of the objects of interest.\nOur fully-automatic method is trained end-to-end and does not require any\ntest-time annotations. From the extreme points, 3D bounding boxes are extracted\naround objects of interest. Then, deep geodesics connecting extreme points are\ngenerated to increase the amount of \"annotated\" voxels within the bounding\nboxes. Finally, a weakly supervised regularised loss derived from a Conditional\nRandom Field formulation is used to encourage prediction consistency over\nhomogeneous regions. Extensive experiments are performed on a large open\ndataset for Vestibular Schwannoma segmentation. $\\textit{InExtremIS}$ obtained\ncompetitive performance, approaching full supervision and outperforming\nsignificantly other weakly supervised techniques based on bounding boxes.\nMoreover, given a fixed annotation time budget, $\\textit{InExtremIS}$\noutperforms full supervision. Our code and data are available online.",
    "descriptor": "\nComments: Early accept at MICCAI 2021 - code available at: this https URL\n",
    "authors": [
      "Reuben Dorent",
      "Samuel Joutard",
      "Jonathan Shapey",
      "Aaron Kujawa",
      "Marc Modat",
      "Sebastien Ourselin",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00583"
  },
  {
    "id": "arXiv:2107.00584",
    "title": "On the functional graph of the power map over finite groups",
    "abstract": "In this paper we study the description of the digraph associated with the\npower map over finite groups. Our main motivation comes from the nice\ndescription of such digraphs in the case of cyclic groups. In particular, we\nderive results on abelian groups, and also on flower groups, which are\nintroduced in this paper. The class of flower groups includes many non abelian\ngroups such as dihedral and generalized quaternion groups, and the projective\ngeneral linear group of order two over a finite field. In particular, we\nprovide improvements on past works.",
    "descriptor": "\nComments: Comments are welcome\n",
    "authors": [
      "Claudio Qureshi",
      "Lucas Reis"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.00584"
  },
  {
    "id": "arXiv:2107.00590",
    "title": "3D Iterative Spatiotemporal Filtering for Classification of  Multitemporal Satellite Data Sets",
    "abstract": "The current practice in land cover/land use change analysis relies heavily on\nthe individually classified maps of the multitemporal data set. Due to varying\nacquisition conditions (e.g., illumination, sensors, seasonal differences), the\nclassification maps yielded are often inconsistent through time for robust\nstatistical analysis. 3D geometric features have been shown to be stable for\nassessing differences across the temporal data set. Therefore, in this article\nwe investigate he use of a multitemporal orthophoto and digital surface model\nderived from satellite data for spatiotemporal classification. Our approach\nconsists of two major steps: generating per-class probability distribution maps\nusing the random-forest classifier with limited training samples, and making\nspatiotemporal inferences using an iterative 3D spatiotemporal filter operating\non per-class probability maps. Our experimental results demonstrate that the\nproposed methods can consistently improve the individual classification results\nby 2%-6% and thus can be an important postclassification refinement approach.",
    "descriptor": "",
    "authors": [
      "Hessah Albanwan",
      "Rongjun Qin",
      "Xiaohu Lu",
      "Mao Li",
      "Desheng Liu",
      "Jean-Michel Guldmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00590"
  },
  {
    "id": "arXiv:2107.00591",
    "title": "Offline-to-Online Reinforcement Learning via Balanced Replay and  Pessimistic Q-Ensemble",
    "abstract": "Recent advance in deep offline reinforcement learning (RL) has made it\npossible to train strong robotic agents from offline datasets. However,\ndepending on the quality of the trained agents and the application being\nconsidered, it is often desirable to fine-tune such agents via further online\ninteractions. In this paper, we observe that state-action distribution shift\nmay lead to severe bootstrap error during fine-tuning, which destroys the good\ninitial policy obtained via offline RL. To address this issue, we first propose\na balanced replay scheme that prioritizes samples encountered online while also\nencouraging the use of near-on-policy samples from the offline dataset.\nFurthermore, we leverage multiple Q-functions trained pessimistically offline,\nthereby preventing overoptimism concerning unfamiliar actions at novel states\nduring the initial training phase. We show that the proposed method improves\nsample-efficiency and final performance of the fine-tuned robotic agents on\nvarious locomotion and manipulation tasks. Our code is available at:\nhttps://github.com/shlee94/Off2OnRL.",
    "descriptor": "",
    "authors": [
      "Seunghyun Lee",
      "Younggyo Seo",
      "Kimin Lee",
      "Pieter Abbeel",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00591"
  },
  {
    "id": "arXiv:2107.00592",
    "title": "Individual Tree Detection and Crown Delineation with 3D Information from  Multi-view Satellite Images",
    "abstract": "Individual tree detection and crown delineation (ITDD) are critical in forest\ninventory management and remote sensing based forest surveys are largely\ncarried out through satellite images. However, most of these surveys only use\n2D spectral information which normally has not enough clues for ITDD. To fully\nexplore the satellite images, we propose a ITDD method using the orthophoto and\ndigital surface model (DSM) derived from the multi-view satellite data. Our\nalgorithm utilizes the top-hat morphological operation to efficiently extract\nthe local maxima from DSM as treetops, and then feed them to a modi-fied\nsuperpixel segmentation that combines both 2D and 3D information for tree crown\ndelineation. In subsequent steps, our method incorporates the biological\ncharacteristics of the crowns through plant allometric equation to falsify\npotential outliers. Experiments against manually marked tree plots on three\nrepresentative regions have demonstrated promising results - the best overall\ndetection accuracy can be 89%.",
    "descriptor": "",
    "authors": [
      "Changlin Xiao",
      "Rongjun Qin",
      "Xiao Xie",
      "Xu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00592"
  },
  {
    "id": "arXiv:2107.00593",
    "title": "Impact Remediation: Optimal Interventions to Reduce Inequality",
    "abstract": "A significant body of research in the data sciences considers unfair\ndiscrimination against social categories such as race or gender that could\noccur or be amplified as a result of algorithmic decisions. Simultaneously,\nreal-world disparities continue to exist, even before algorithmic decisions are\nmade. In this work, we draw on insights from the social sciences and humanistic\nstudies brought into the realm of causal modeling and constrained optimization,\nand develop a novel algorithmic framework for tackling pre-existing real-world\ndisparities. The purpose of our framework, which we call the \"impact\nremediation framework,\" is to measure real-world disparities and discover the\noptimal intervention policies that could help improve equity or access to\nopportunity for those who are underserved with respect to an outcome of\ninterest. We develop a disaggregated approach to tackling pre-existing\ndisparities that relaxes the typical set of assumptions required for the use of\nsocial categories in structural causal models. Our approach flexibly\nincorporates counterfactuals and is compatible with various ontological\nassumptions about the nature of social categories. We demonstrate impact\nremediation with a real-world case study and compare our disaggregated approach\nto an existing state-of-the-art approach, comparing its structure and resulting\npolicy recommendations. In contrast to most work on optimal policy learning, we\nexplore disparity reduction itself as an objective, explicitly focusing the\npower of algorithms on reducing inequality.",
    "descriptor": "",
    "authors": [
      "Lucius E.J. Bynum",
      "Joshua R. Loftus",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00593"
  },
  {
    "id": "arXiv:2107.00595",
    "title": "Fast Margin Maximization via Dual Acceleration",
    "abstract": "We present and analyze a momentum-based gradient method for training linear\nclassifiers with an exponentially-tailed loss (e.g., the exponential or\nlogistic loss), which maximizes the classification margin on separable data at\na rate of $\\widetilde{\\mathcal{O}}(1/t^2)$. This contrasts with a rate of\n$\\mathcal{O}(1/\\log(t))$ for standard gradient descent, and $\\mathcal{O}(1/t)$\nfor normalized gradient descent. This momentum-based method is derived via the\nconvex dual of the maximum-margin problem, and specifically by applying\nNesterov acceleration to this dual, which manages to result in a simple and\nintuitive method in the primal. This dual view can also be used to derive a\nstochastic variant, which performs adaptive non-uniform sampling via the dual\nvariables.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Ziwei Ji",
      "Nathan Srebro",
      "Matus Telgarsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00595"
  },
  {
    "id": "arXiv:2107.00596",
    "title": "Multimodal Graph-based Transformer Framework for Biomedical Relation  Extraction",
    "abstract": "The recent advancement of pre-trained Transformer models has propelled the\ndevelopment of effective text mining models across various biomedical tasks.\nHowever, these models are primarily learned on the textual data and often lack\nthe domain knowledge of the entities to capture the context beyond the\nsentence. In this study, we introduced a novel framework that enables the model\nto learn multi-omnics biological information about entities (proteins) with the\nhelp of additional multi-modal cues like molecular structure. Towards this,\nrather developing modality-specific architectures, we devise a generalized and\noptimized graph based multi-modal learning mechanism that utilizes the\nGraphBERT model to encode the textual and molecular structure information and\nexploit the underlying features of various modalities to enable end-to-end\nlearning. We evaluated our proposed method on ProteinProtein Interaction task\nfrom the biomedical corpus, where our proposed generalized approach is observed\nto be benefited by the additional domain-specific modality.",
    "descriptor": "\nComments: To appear in Findings of ACL 2021\n",
    "authors": [
      "Sriram Pingali",
      "Shweta Yadav",
      "Pratik Dutta",
      "Sriparna Saha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00596"
  },
  {
    "id": "arXiv:2107.00598",
    "title": "A Unified Framework of Bundle Adjustment and Feature Matching for  High-Resolution Satellite Images",
    "abstract": "Bundle adjustment (BA) is a technique for refining sensor orientations of\nsatellite images, while adjustment accuracy is correlated with feature matching\nresults. Feature match-ing often contains high uncertainties in weak/repeat\ntextures, while BA results are helpful in reducing these uncertainties. To\ncompute more accurate orientations, this article incorpo-rates BA and feature\nmatching in a unified framework and formulates the union as the optimization of\na global energy function so that the solutions of the BA and feature matching\nare constrained with each other. To avoid a degeneracy in the optimization, we\npropose a comprised solution by breaking the optimization of the global energy\nfunction into two-step suboptimizations and compute the local minimums of each\nsuboptimization in an incremental manner. Experiments on multi-view\nhigh-resolution satellite images show that our proposed method outperforms\nstate-of-the-art orientation techniques with or without accurate least-squares\nmatching.",
    "descriptor": "",
    "authors": [
      "Xiao Ling",
      "Xu Huang",
      "Rongjun Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00598"
  },
  {
    "id": "arXiv:2107.00606",
    "title": "Action Transformer: A Self-Attention Model for Short-Time Human Action  Recognition",
    "abstract": "Deep neural networks based purely on attention have been successful across\nseveral domains, relying on minimal architectural priors from the designer. In\nHuman Action Recognition (HAR), attention mechanisms have been primarily\nadopted on top of standard convolutional or recurrent layers, improving the\noverall generalization capability. In this work, we introduce Action\nTransformer (AcT), a simple, fully self-attentional architecture that\nconsistently outperforms more elaborated networks that mix convolutional,\nrecurrent, and attentive layers. In order to limit computational and energy\nrequests, building on previous human action recognition research, the proposed\napproach exploits 2D pose representations over small temporal windows,\nproviding a low latency solution for accurate and effective real-time\nperformance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as\nan attempt to build a formal training and evaluation benchmark for real-time\nshort-time human action recognition. Extensive experimentation on MPOSE2021\nwith our proposed methodology and several previous architectural solutions\nproves the effectiveness of the AcT model and poses the base for future work on\nHAR.",
    "descriptor": "",
    "authors": [
      "Vittorio Mazzia",
      "Simone Angarano",
      "Francesco Salvetti",
      "Federico Angelini",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00606"
  },
  {
    "id": "arXiv:2107.00612",
    "title": "Formal verification of octorotor flight envelope using barrier functions  and SMT solving",
    "abstract": "This paper introduces an approach for formally verifying the safety of the\nflight controller of an octorotor platform. Our method involves finding regions\nof the octorotor's state space that are considered safe, and which can be\nproven to be invariant with respect to the dynamics. Specifically, exponential\nbarrier functions are used to construct candidate invariant regions near\ndesired commanded states. The proof that these regions are invariant is\ndiscovered automatically using the dReal SMT solver, which ensures the accurate\ncommand tracking of the octorotor to within a certain margin of error. Rotor\nfailures in which rotor thrusts become stuck at fixed values are considered and\naccounted for via a pseudo-inverse control allocator. The safety of the control\nallocator is verified in dReal by checking that the thrusts demanded by the\nallocator never exceed the capability of the rotors. We apply our approach on a\nspecific octorotor example and verify the desired command tracking properties\nof the controller under normal conditions and various combinations of rotor\nfailures.",
    "descriptor": "",
    "authors": [
      "Byron Heersink",
      "Pape Sylla",
      "Michael A. Warren"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00612"
  },
  {
    "id": "arXiv:2107.00613",
    "title": "EqFix: Fixing LaTeX Equation Errors by Examples",
    "abstract": "LaTeX is a widely-used document preparation system. Its powerful ability in\nmathematical equation editing is perhaps the main reason for its popularity in\nacademia. Sometimes, however, even an expert user may spend much time on fixing\nan erroneous equation. In this paper, we present EqFix, a synthesis-based\nrepairing system for LaTeX equations. It employs a set of fixing rules, and can\nsuggest possible repairs for common errors in LaTeX equations. A domain\nspecific language is proposed for formally expressing the fixing rules. The\nfixing rules can be automatically synthesized from a set of input-output\nexamples. An extension of relaxer is also introduced to enhance the\npracticality of EqFix. We evaluate EqFix on real-world examples and find that\nit can synthesize rules with high generalization ability. Compared with a\nstate-of-the-art string transformation synthesizer, EqFix solved 37% more cases\nand spent only one third of their synthesis time.",
    "descriptor": "",
    "authors": [
      "Fengmin Zhu",
      "Fei He"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.00613"
  },
  {
    "id": "arXiv:2107.00618",
    "title": "Resilient and Latency-aware Orchestration of Network Slices Using  Multi-connectivity in MEC-enabled 5G Networks",
    "abstract": "Network slicing (NS) and multi-access edge computing (MEC) are new paradigms\nwhich play key roles in 5G and beyond networks. NS allows network operators\n(NOs) to divide the available network resources into multiple logical NSs for\nproviding dedicated virtual networks tailored to the specific service/business\nrequirements. MEC enables NOs to provide diverse ultra-low latency services for\nsupporting the needs of different industry verticals by moving computing\nfacilities to the network edge. NS can be constructed by instantiating a set of\nvirtual network functions (VNFs) on top of MEC cloud servers for provisioning\ndiverse latency-sensitive communication services (e.g., autonomous driving and\naugmented reality) on demand at a lesser cost and time. However, VNFs, MEC\ncloud servers, and communication links are subject to failures due to software\nbugs, misconfiguration, overloading, hardware faults, cyber attacks, power\noutage, and natural/man-made disaster. Failure of a critical network component\ndisrupts services abruptly and leads to users' dissatisfaction, which may\nresult in revenue loss for the NOs. In this paper, we present a novel approach\nbased on multi-connectivity in 5G networks to tackle this problem and our\nproposed approach is resilient against i) failure of VNFs, ii) failure of local\nservers within MEC, iii) failure of communication links, and iv) failure of an\nentire MEC cloud facility in regional level. To this end, we formulate the\nproblem as a binary integer programming (BIP) model in order to optimally\ndeploy NSs with the minimum cost, and prove it is NP-hard. To overcome time\ncomplexity, we propose an efficient genetic algorithm based heuristic to obtain\nnear-optimal solution in polynomial time. By extensive simulations, we show\nthat our proposed approach not only reduces resource wastage, but also improves\nthroughput while providing high resiliency against failures.",
    "descriptor": "",
    "authors": [
      "Prabhu Kaliyammal Thiruvasagam",
      "Abhishek Chakraborty",
      "C Siva Ram Murthy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.00618"
  },
  {
    "id": "arXiv:2107.00621",
    "title": "Design, Modelling and Control of SPIROS: The Six Propellers and  Intermeshing Rotors Based Omnidirectional Spherical Robot",
    "abstract": "Since the past few decades, several designs and control methods have been\ndeveloped for the Spherical Robots (SRs) with thoroughly analyzed mechanics on\ngeneralized 3D terrains. But the vertical motion and the steep inclination\nmaneuver has been an unsolved problem with the existing SR's driving\nmechanisms. Also, the possibilities of wind-powered or air-propelled SRs have\nnot been fully explored. This paper introduces the new Omnidirectional\nSpherical Robot mechanism named SPIROS: The Six Propeller and Intermeshed Rotor\nbased Omnidirectional Spherical Robot. The SPIROS is driven by a novel\noctahedral arrangement of six intermeshed rotary air thrusters placed in the\nGoldberg Polyhedral shaped spherical gridshell. The advantage of the proposed\ndesign lies in its air-powered propulsion, which improves on the obstacle\navoidance and the slope climbing abilities. The robot's dynamic models are\nderived using the existing kinematical models of the Continuous Rolling\nSpherical Robots (CR-SR), with subcategories, triple axes rolling (3R-SR), dual\naxes rolling (2R-SR) and rolling and turning (RT-SR) spherical robots. The path\ntracking control scheme based on the pure pursuit algorithm is presented.\nSimulations are carried out in MATLAB and Simulink to validate the developed\nmodels and the effectiveness of the proposed control schemes.",
    "descriptor": "\nComments: 10 pages, 13 figures, 1 table\n",
    "authors": [
      "Yogesh Phalak"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00621"
  },
  {
    "id": "arXiv:2107.00623",
    "title": "Improving Sound Event Classification by Increasing Shift Invariance in  Convolutional Neural Networks",
    "abstract": "Recent studies have put into question the commonly assumed shift invariance\nproperty of convolutional networks, showing that small shifts in the input can\naffect the output predictions substantially. In this paper, we ask whether lack\nof shift invariance is a problem in sound event classification, and whether\nthere are benefits in addressing it. Specifically, we evaluate two pooling\nmethods to improve shift invariance in CNNs, based on low-pass filtering and\nadaptive sampling of incoming feature maps. These methods are implemented via\nsmall architectural modifications inserted into the pooling layers of CNNs. We\nevaluate the effect of these architectural changes on the FSD50K dataset using\nmodels of different capacity and in presence of strong regularization. We show\nthat these modifications consistently improve sound event classification in all\ncases considered, without adding any (or adding very few) trainable parameters,\nwhich makes them an appealing alternative to conventional pooling layers. The\noutcome is a new state-of-the-art mAP of 0.541 on the FSD50K classification\nbenchmark.",
    "descriptor": "",
    "authors": [
      "Eduardo Fonseca",
      "Andres Ferraro",
      "Xavier Serra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00623"
  },
  {
    "id": "arXiv:2107.00627",
    "title": "Semi-Sparsity for Smoothing Filters",
    "abstract": "In this paper, we propose an interesting semi-sparsity smoothing algorithm\nbased on a novel sparsity-inducing optimization framework. This method is\nderived from the multiple observations, that is, semi-sparsity prior knowledge\nis more universally applicable, especially in areas where sparsity is not fully\nadmitted, such as polynomial-smoothing surfaces. We illustrate that this\nsemi-sparsity can be identified into a generalized $L_0$-norm minimization in\nhigher-order gradient domains, thereby giving rise to a new ``feature-aware''\nfiltering method with a powerful simultaneous-fitting ability in both sparse\nfeatures (singularities and sharpening edges) and non-sparse regions\n(polynomial-smoothing surfaces). Notice that a direct solver is always\nunavailable due to the non-convexity and combinatorial nature of $L_0$-norm\nminimization. Instead, we solve the model based on an efficient half-quadratic\nsplitting minimization with fast Fourier transforms (FFTs) for acceleration. We\nfinally demonstrate its versatility and many benefits to a series of\nsignal/image processing and computer vision applications.",
    "descriptor": "",
    "authors": [
      "Junqing Huang",
      "Haihui Wang",
      "Xuechao Wang",
      "Michael Ruzhansky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00627"
  },
  {
    "id": "arXiv:2107.00629",
    "title": "Modular counting of subgraphs: Matchings, matching-splittable graphs,  and paths",
    "abstract": "We systematically investigate the complexity of counting subgraph patterns\nmodulo fixed integers. For example, it is known that the parity of the number\nof $k$-matchings can be determined in polynomial time by a simple reduction to\nthe determinant. We generalize this to an $n^{f(t,s)}$-time algorithm to\ncompute modulo $2^t$ the number of subgraph occurrences of patterns that are\n$s$ vertices away from being matchings. This shows that the known\npolynomial-time cases of subgraph detection (Jansen and Marx, SODA 2015) carry\nover into the setting of counting modulo $2^t$.\nComplementing our algorithm, we also give a simple and self-contained proof\nthat counting $k$-matchings modulo odd integers $q$ is Mod_q-W[1]-complete and\nprove that counting $k$-paths modulo $2$ is Parity-W[1]-complete, answering an\nopen question by Bj\\\"orklund, Dell, and Husfeldt (ICALP 2015).",
    "descriptor": "\nComments: 23 pages, to appear at ESA 2021\n",
    "authors": [
      "Radu Curticapean",
      "Holger Dell",
      "Thore Husfeldt"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00629"
  },
  {
    "id": "arXiv:2107.00630",
    "title": "Variational Diffusion Models",
    "abstract": "Diffusion-based generative models have demonstrated a capacity for\nperceptually impressive synthesis, but can they also be great likelihood-based\nmodels? We answer this in the affirmative, and introduce a family of\ndiffusion-based generative models that obtain state-of-the-art likelihoods on\nstandard image density estimation benchmarks. Unlike other diffusion-based\nmodels, our method allows for efficient optimization of the noise schedule\njointly with the rest of the model. We show that the variational lower bound\n(VLB) simplifies to a remarkably short expression in terms of the\nsignal-to-noise ratio of the diffused data, thereby improving our theoretical\nunderstanding of this model class. Using this insight, we prove an equivalence\nbetween several models proposed in the literature. In addition, we show that\nthe continuous-time VLB is invariant to the noise schedule, except for the\nsignal-to-noise ratio at its endpoints. This enables us to learn a noise\nschedule that minimizes the variance of the resulting VLB estimator, leading to\nfaster optimization. Combining these advances with architectural improvements,\nwe obtain state-of-the-art likelihoods on image density estimation benchmarks,\noutperforming autoregressive models that have dominated these benchmarks for\nmany years, with often significantly faster optimization. In addition, we show\nhow to turn the model into a bits-back compression scheme, and demonstrate\nlossless compression rates close to the theoretical optimum.",
    "descriptor": "",
    "authors": [
      "Diederik P. Kingma",
      "Tim Salimans",
      "Ben Poole",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00630"
  },
  {
    "id": "arXiv:2107.00637",
    "title": "Generalization and Robustness Implications in Object-Centric Learning",
    "abstract": "The idea behind object-centric representation learning is that natural scenes\ncan better be modeled as compositions of objects and their relations as opposed\nto distributed representations. This inductive bias can be injected into neural\nnetworks to potentially improve systematic generalization and learning\nefficiency of downstream tasks in scenes with multiple objects. In this paper,\nwe train state-of-the-art unsupervised models on five common multi-object\ndatasets and evaluate segmentation accuracy and downstream object property\nprediction. In addition, we study systematic generalization and robustness by\ninvestigating the settings where either single objects are out-of-distribution\n-- e.g., having unseen colors, textures, and shapes -- or global properties of\nthe scene are altered -- e.g., by occlusions, cropping, or increasing the\nnumber of objects. From our experimental study, we find object-centric\nrepresentations to be generally useful for downstream tasks and robust to\nshifts in the data distribution, especially if shifts affect single objects.",
    "descriptor": "",
    "authors": [
      "Andrea Dittadi",
      "Samuele Papa",
      "Michele De Vita",
      "Bernhard Sch\u00f6lkopf",
      "Ole Winther",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00637"
  },
  {
    "id": "arXiv:2107.00641",
    "title": "Focal Self-attention for Local-Global Interactions in Vision  Transformers",
    "abstract": "Recently, Vision Transformer and its variants have shown great promise on\nvarious computer vision tasks. The ability of capturing short- and long-range\nvisual dependencies through self-attention is arguably the main source for the\nsuccess. But it also brings challenges due to quadratic computational overhead,\nespecially for the high-resolution vision tasks (e.g., object detection). In\nthis paper, we present focal self-attention, a new mechanism that incorporates\nboth fine-grained local and coarse-grained global interactions. Using this new\nmechanism, each token attends the closest surrounding tokens at fine\ngranularity but the tokens far away at coarse granularity, and thus can capture\nboth short- and long-range visual dependencies efficiently and effectively.\nWith focal self-attention, we propose a new variant of Vision Transformer\nmodels, called Focal Transformer, which achieves superior performance over the\nstate-of-the-art vision Transformers on a range of public image classification\nand object detection benchmarks. In particular, our Focal Transformer models\nwith a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8\nTop-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.\nUsing Focal Transformers as the backbones, we obtain consistent and substantial\nimprovements over the current state-of-the-art Swin Transformers for 6\ndifferent object detection methods trained with standard 1x and 3x schedules.\nOur largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs\non COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,\ncreating new SoTA on three of the most challenging computer vision tasks.",
    "descriptor": "",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Pengchuan Zhang",
      "Xiyang Dai",
      "Bin Xiao",
      "Lu Yuan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00641"
  },
  {
    "id": "arXiv:2107.00643",
    "title": "Mandoline: Model Evaluation under Distribution Shift",
    "abstract": "Machine learning models are often deployed in different settings than they\nwere trained and validated on, posing a challenge to practitioners who wish to\npredict how well the deployed model will perform on a target distribution. If\nan unlabeled sample from the target distribution is available, along with a\nlabeled sample from a possibly different source distribution, standard\napproaches such as importance weighting can be applied to estimate performance\non the target. However, importance weighting struggles when the source and\ntarget distributions have non-overlapping support or are high-dimensional.\nTaking inspiration from fields such as epidemiology and polling, we develop\nMandoline, a new evaluation framework that mitigates these issues. Our key\ninsight is that practitioners may have prior knowledge about the ways in which\nthe distribution shifts, which we can use to better guide the importance\nweighting procedure. Specifically, users write simple \"slicing functions\" -\nnoisy, potentially correlated binary functions intended to capture possible\naxes of distribution shift - to compute reweighted performance estimates. We\nfurther describe a density ratio estimation framework for the slices and show\nhow its estimation error scales with slice quality and dataset size. Empirical\nvalidation on NLP and vision tasks shows that \\name can estimate performance on\nthe target distribution up to $3\\times$ more accurately compared to standard\nbaselines.",
    "descriptor": "\nComments: 32 pages. Published as a conference paper at ICML 2021\n",
    "authors": [
      "Mayee Chen",
      "Karan Goel",
      "Nimit Sohoni",
      "Fait Poms",
      "Kayvon Fatahalian",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00643"
  },
  {
    "id": "arXiv:2107.00644",
    "title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under  Data Augmentation",
    "abstract": "While agents trained by Reinforcement Learning (RL) can solve increasingly\nchallenging tasks directly from visual observations, generalizing learned\nskills to novel environments remains very challenging. Extensive use of data\naugmentation is a promising technique for improving generalization in RL, but\nit is often found to decrease sample efficiency and can even lead to\ndivergence. In this paper, we investigate causes of instability when using data\naugmentation in common off-policy RL algorithms. We identify two problems, both\nrooted in high-variance Q-targets. Based on our findings, we propose a simple\nyet effective technique for stabilizing this class of algorithms under\naugmentation. We perform extensive empirical evaluation of image-based RL using\nboth ConvNets and Vision Transformers (ViT) on a family of benchmarks based on\nDeepMind Control Suite, as well as in robotic manipulation tasks. Our method\ngreatly improves stability and sample efficiency of ConvNets under\naugmentation, and achieves generalization results competitive with\nstate-of-the-art methods for image-based RL. We further show that our method\nscales to RL with ViT-based architectures, and that data augmentation may be\nespecially important in this setting.",
    "descriptor": "\nComments: Code and videos are available at this https URL\n",
    "authors": [
      "Nicklas Hansen",
      "Hao Su",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.00644"
  },
  {
    "id": "arXiv:2107.00645",
    "title": "Global Filter Networks for Image Classification",
    "abstract": "Recent advances in self-attention and pure multi-layer perceptrons (MLP)\nmodels for vision have shown great potential in achieving promising performance\nwith fewer inductive biases. These models are generally based on learning\ninteraction among spatial locations from raw data. The complexity of\nself-attention and MLP grows quadratically as the image size increases, which\nmakes these models hard to scale up when high-resolution features are required.\nIn this paper, we present the Global Filter Network (GFNet), a conceptually\nsimple yet computationally efficient architecture, that learns long-term\nspatial dependencies in the frequency domain with log-linear complexity. Our\narchitecture replaces the self-attention layer in vision transformers with\nthree key operations: a 2D discrete Fourier transform, an element-wise\nmultiplication between frequency-domain features and learnable global filters,\nand a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity\ntrade-offs of our models on both ImageNet and downstream tasks. Our results\ndemonstrate that GFNet can be a very competitive alternative to\ntransformer-style models and CNNs in efficiency, generalization ability and\nrobustness. Code is available at https://github.com/raoyongming/GFNet",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Zheng Zhu",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00645"
  },
  {
    "id": "arXiv:2107.00646",
    "title": "Learning to See before Learning to Act: Visual Pre-training for  Manipulation",
    "abstract": "Does having visual priors (e.g. the ability to detect objects) facilitate\nlearning to perform vision-based manipulation (e.g. picking up objects)? We\nstudy this problem under the framework of transfer learning, where the model is\nfirst trained on a passive vision task, and adapted to perform an active\nmanipulation task. We find that pre-training on vision tasks significantly\nimproves generalization and sample efficiency for learning to manipulate\nobjects. However, realizing these gains requires careful selection of which\nparts of the model to transfer. Our key insight is that outputs of standard\nvision models highly correlate with affordance maps commonly used in\nmanipulation. Therefore, we explore directly transferring model parameters from\nvision networks to affordance prediction networks, and show that this can\nresult in successful zero-shot adaptation, where a robot can pick up certain\nobjects with zero robotic experience. With just a small amount of robotic\nexperience, we can further fine-tune the affordance model to achieve better\nresults. With just 10 minutes of suction experience or 1 hour of grasping\nexperience, our method achieves ~80% success rate at picking up novel objects.",
    "descriptor": "\nComments: Accepted to ICRA 2020. Porject page: this http URL\n",
    "authors": [
      "Lin Yen-Chen",
      "Andy Zeng",
      "Shuran Song",
      "Phillip Isola",
      "Tsung-Yi Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00646"
  },
  {
    "id": "arXiv:2107.00648",
    "title": "Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery  Integrating Radiology, Pathology, Genomic, and Clinical Data",
    "abstract": "Clinical decision-making in oncology involves multimodal data such as\nradiology scans, molecular profiling, histopathology slides, and clinical\nfactors. Despite the importance of these modalities individually, no deep\nlearning framework to date has combined them all to predict patient prognosis.\nHere, we predict the overall survival (OS) of glioma patients from diverse\nmultimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to\ncombine information from multiparametric MRI exams, biopsy-based modalities\n(such as H&E slide images and/or DNA sequencing), and clinical variables into a\ncomprehensive multimodal risk score. Prognostic embeddings from each modality\nare learned and combined via attention-gated tensor fusion. To maximize the\ninformation gleaned from each modality, we introduce a multimodal\northogonalization (MMO) loss term that increases model performance by\nincentivizing constituent embeddings to be more complementary. DOF predicts OS\nin glioma patients with a median C-index of 0.788 +/- 0.067, significantly\noutperforming (p=0.023) the best performing unimodal model with a median\nC-index of 0.718 +/- 0.064. The prognostic model significantly stratifies\nglioma patients by OS within clinical subsets, adding further granularity to\nprognostic clinical grading and molecular subtyping.",
    "descriptor": "\nComments: Accepted for presentation at MICCAI 2021\n",
    "authors": [
      "Nathaniel Braman",
      "Jacob W. H. Gordon",
      "Emery T. Goossens",
      "Caleb Willis",
      "Martin C. Stumpe",
      "Jagadish Venkataraman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.00648"
  },
  {
    "id": "arXiv:2107.00649",
    "title": "On the Practicality of Deterministic Epistemic Uncertainty",
    "abstract": "A set of novel approaches for estimating epistemic uncertainty in deep neural\nnetworks with a single forward pass has recently emerged as a valid alternative\nto Bayesian Neural Networks. On the premise of informative representations,\nthese deterministic uncertainty methods (DUMs) achieve strong performance on\ndetecting out-of-distribution (OOD) data while adding negligible computational\ncosts at inference time. However, it remains unclear whether DUMs are well\ncalibrated and can seamlessly scale to real-world applications - both\nprerequisites for their practical deployment. To this end, we first provide a\ntaxonomy of DUMs, evaluate their calibration under continuous distributional\nshifts and their performance on OOD detection for image classification tasks.\nThen, we extend the most promising approaches to semantic segmentation. We find\nthat, while DUMs scale to realistic vision tasks and perform well on OOD\ndetection, the practicality of current methods is undermined by poor\ncalibration under realistic distributional shifts.",
    "descriptor": "",
    "authors": [
      "Janis Postels",
      "Mattia Segu",
      "Tao Sun",
      "Luc Van Gool",
      "Fisher Yu",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00649"
  },
  {
    "id": "arXiv:2107.00650",
    "title": "CLIP-It! Language-Guided Video Summarization",
    "abstract": "A generic video summary is an abridged version of a video that conveys the\nwhole story and features the most important scenes. Yet the importance of\nscenes in a video is often subjective, and users should have the option of\ncustomizing the summary by using natural language to specify what is important\nto them. Further, existing models for fully automatic generic summarization\nhave not exploited available language models, which can serve as an effective\nprior for saliency. This work introduces CLIP-It, a single framework for\naddressing both generic and query-focused video summarization, typically\napproached separately in the literature. We propose a language-guided\nmultimodal transformer that learns to score frames in a video based on their\nimportance relative to one another and their correlation with a user-defined\nquery (for query-focused summarization) or an automatically generated dense\nvideo caption (for generic video summarization). Our model can be extended to\nthe unsupervised setting by training without ground-truth supervision. We\noutperform baselines and prior work by a significant margin on both standard\nvideo summarization datasets (TVSum and SumMe) and a query-focused video\nsummarization dataset (QFVS). Particularly, we achieve large improvements in\nthe transfer setting, attesting to our method's strong generalization\ncapabilities.",
    "descriptor": "\nComments: Website at this https URL\n",
    "authors": [
      "Medhini Narasimhan",
      "Anna Rohrbach",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.00650"
  },
  {
    "id": "arXiv:2107.00651",
    "title": "AutoFormer: Searching Transformers for Visual Recognition",
    "abstract": "Recently, pure transformer-based models have shown great potentials for\nvision tasks such as image classification and detection. However, the design of\ntransformer networks is challenging. It has been observed that the depth,\nembedding dimension, and number of heads can largely affect the performance of\nvision transformers. Previous models configure these dimensions based upon\nmanual crafting. In this work, we propose a new one-shot architecture search\nframework, namely AutoFormer, dedicated to vision transformer search.\nAutoFormer entangles the weights of different blocks in the same layers during\nsupernet training. Benefiting from the strategy, the trained supernet allows\nthousands of subnets to be very well-trained. Specifically, the performance of\nthese subnets with weights inherited from the supernet is comparable to those\nretrained from scratch. Besides, the searched models, which we refer to\nAutoFormers, surpass the recent state-of-the-arts such as ViT and DeiT. In\nparticular, AutoFormer-tiny/small/base achieve 74.7%/81.7%/82.4% top-1 accuracy\non ImageNet with 5.7M/22.9M/53.7M parameters, respectively. Lastly, we verify\nthe transferability of AutoFormer by providing the performance on downstream\nbenchmarks and distillation experiments. Code and models are available at\nhttps://github.com/microsoft/AutoML.",
    "descriptor": "\nComments: Github: this https URL\n",
    "authors": [
      "Minghao Chen",
      "Houwen Peng",
      "Jianlong Fu",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00651"
  },
  {
    "id": "arXiv:2107.00652",
    "title": "CSWin Transformer: A General Vision Transformer Backbone with  Cross-Shaped Windows",
    "abstract": "We present CSWin Transformer, an efficient and effective Transformer-based\nbackbone for general-purpose vision tasks. A challenging issue in Transformer\ndesign is that global self-attention is very expensive to compute whereas local\nself-attention often limits the field of interactions of each token. To address\nthis issue, we develop the Cross-Shaped Window self-attention mechanism for\ncomputing self-attention in the horizontal and vertical stripes in parallel\nthat form a cross-shaped window, with each stripe obtained by splitting the\ninput feature into stripes of equal width. We provide a detailed mathematical\nanalysis of the effect of the stripe width and vary the stripe width for\ndifferent layers of the Transformer network which achieves strong modeling\ncapability while limiting the computation cost. We also introduce\nLocally-enhanced Positional Encoding (LePE), which handles the local positional\ninformation better than existing encoding schemes. LePE naturally supports\narbitrary input resolutions, and is thus especially effective and friendly for\ndownstream tasks. Incorporated with these designs and a hierarchical structure,\nCSWin Transformer demonstrates competitive performance on common vision tasks.\nSpecifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra\ntraining data or label, 53.9 box AP and 46.4 mask AP on the COCO detection\ntask, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing\nprevious state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and\n+2.0 respectively under the similar FLOPs setting. By further pretraining on\nthe larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K\nand state-of-the-art segmentation performance on ADE20K with 55.2 mIoU. The\ncode and models will be available at\nhttps://github.com/microsoft/CSWin-Transformer.",
    "descriptor": "\nComments: The code and models will be available at this https URL\n",
    "authors": [
      "Xiaoyi Dong",
      "Jianmin Bao",
      "Dongdong Chen",
      "Weiming Zhang",
      "Nenghai Yu",
      "Lu Yuan",
      "Dong Chen",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00652"
  },
  {
    "id": "arXiv:2106.08775",
    "title": "Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained  SDPs",
    "abstract": "We present a novel, practical, and provable approach for solving diagonally\nconstrained semi-definite programming (SDP) problems at scale using accelerated\nnon-convex programming. Our algorithm non-trivially combines acceleration\nmotions from convex optimization with coordinate power iteration and matrix\nfactorization techniques. The algorithm is extremely simple to implement, and\nadds only a single extra hyperparameter -- momentum. We prove that our method\nadmits local linear convergence in the neighborhood of the optimum and always\nconverges to a first-order critical point. Experimentally, we showcase the\nmerits of our method on three major application domains: MaxCut, MaxSAT, and\nMIMO signal detection. In all cases, our methodology provides significant\nspeedups over non-convex and convex SDP solvers -- 5X faster than\nstate-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP\nsolvers -- with comparable or improved solution quality.",
    "descriptor": "\nComments: 10 pages, 8 figures, preprint under review\n",
    "authors": [
      "Junhyung Lyle Kim",
      "Jose Antonio Lara Benitez",
      "Mohammad Taha Toghani",
      "Cameron Wolfe",
      "Zhiwei Zhang",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08775"
  },
  {
    "id": "arXiv:2106.15963",
    "title": "How does homophily shape the topology of a dynamic network?",
    "abstract": "We consider a dynamic network of individuals that may hold one of two\ndifferent opinions in a two-party society. As a dynamical model, agents can\nendlessly create and delete links to satisfy a preferred degree, and the\nnetwork is shaped by homophily, a form of social interaction. Characterized by\nthe parameter $J \\in [-1,1]$, the latter plays a role similar to Ising spins:\nagents create links to others of the same opinion with probability $(1+J)/2$,\nand delete them with probability $(1-J)/2$. Using Monte Carlo simulations and\nmean field theory, we focus on the network structure in the steady state. We\nstudy the effects of $J$ on degree distributions and the fraction of\ncross-party links. While the extreme cases of homophily or heterophily ($J= \\pm\n1$) are easily understood to result in complete polarization or\nanti-polarization, intermediate values of $J$ lead to interesting behavior of\nthe network. Our model exhibits the intriguing feature of an \"overwhelming\ntransition\" occurring when communities of different sizes are subject to\nsufficient heterophily: agents of the minority group are oversubscribed and\ntheir average degree greatly exceeds that of the majority group. In addition,\nwe introduce a novel measure of polarization which displays distinct advantages\nover the commonly used average edge homogeneity.",
    "descriptor": "\nComments: The paper includes 12 pages and 9 figures\n",
    "authors": [
      "Xiang Li",
      "Mauro Mobilia",
      "Alastair M. Rucklidge",
      "R.K.P. Zia"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15963"
  },
  {
    "id": "arXiv:2107.00004",
    "title": "Computationally efficient spatial rendering of late reverberation in  virtual acoustic environments",
    "abstract": "For 6-DOF (degrees of freedom) interactive virtual acoustic environments\n(VAEs), the spatial rendering of diffuse late reverberation in addition to\nearly (specular) reflections is important. In the interest of computational\nefficiency, the acoustic simulation of the late reverberation can be simplified\nby using a limited number of spatially distributed virtual reverb sources (VRS)\neach radiating incoherent signals. A sufficient number of VRS is needed to\napproximate spatially anisotropic late reverberation, e.g., in a room with\ninhomogeneous distribution of absorption at the boundaries. Here, a highly\nefficient and perceptually plausible method to generate and spatially render\nlate reverberation is suggested, extending the room acoustics simulator RAZR\n[Wendt et al., J. Audio Eng. Soc., 62, 11 (2014)]. The room dimensions and\nfrequency-dependent absorption coefficients at the wall boundaries are used to\ndetermine the parameters of a physically-based feedback delay network (FDN) to\ngenerate the incoherent VRS signals. The VRS are spatially distributed around\nthe listener with weighting factors representing the spatially subsampled\ndistribution of absorption coefficients on the wall boundaries. The minimum\nnumber of VRS required to be perceptually distinguishable from the maximum\n(reference) number of 96 VRS was assessed in a listening test conducted with a\nspherical loudspeaker array within an anechoic room. For the resulting low\nnumbers of VRS suited for spatial rendering, optimal physically-based parameter\nchoices for the FDN are discussed.",
    "descriptor": "\nComments: submitted to the I3DA 2021 International Conference(IEEE Xplore Digital Library). arXiv admin note: text overlap with arXiv:2106.15888\n",
    "authors": [
      "Christoph Kirsch",
      "Josef Poppitz",
      "Torben Wendt",
      "Steven van de Par",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00004"
  },
  {
    "id": "arXiv:2107.00048",
    "title": "Uncertainty-Aware Learning for Improvements in Image Quality of the  Canada-France-Hawaii Telescope",
    "abstract": "We leverage state-of-the-art machine learning methods and a decade's worth of\narchival data from the Canada-France-Hawaii Telescope (CFHT) to predict\nobservatory image quality (IQ) from environmental conditions and observatory\noperating parameters. Specifically, we develop accurate and interpretable\nmodels of the complex dependence between data features and observed IQ for\nCFHT's wide field camera, MegaCam. Our contributions are several-fold. First,\nwe collect, collate and reprocess several disparate data sets gathered by CFHT\nscientists. Second, we predict probability distribution functions (PDFs) of IQ,\nand achieve a mean absolute error of $\\sim0.07''$ for the predicted medians.\nThird, we explore data-driven actuation of the 12 dome ``vents'', installed in\n2013-14 to accelerate the flushing of hot air from the dome. We leverage\nepistemic and aleatoric uncertainties in conjunction with probabilistic\ngenerative modeling to identify candidate vent adjustments that are\nin-distribution (ID) and, for the optimal configuration for each ID sample, we\npredict the reduction in required observing time to achieve a fixed SNR. On\naverage, the reduction is $\\sim15\\%$. Finally, we rank sensor data features by\nShapley values to identify the most predictive variables for each observation.\nOur long-term goal is to construct reliable and real-time models that can\nforecast optimal observatory operating parameters for optimization of IQ. Such\nforecasts can then be fed into scheduling protocols and predictive maintenance\nroutines. We anticipate that such approaches will become standard in automating\nobservatory operations and maintenance by the time CFHT's successor, the\nMaunakea Spectroscopic Explorer (MSE), is installed in the next decade.",
    "descriptor": "\nComments: 25 pages, 1 appendix, 12 figures. To be submitted to MNRAS. Comments and feedback welcome\n",
    "authors": [
      "Sankalp Gilda",
      "Stark C. Draper",
      "Sebastien Fabbro",
      "William Mahoney",
      "Simon Prunet",
      "Kanoa Withington",
      "Matthew Wilson",
      "Yuan-Sen Ting",
      "Andrew Sheinis"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00048"
  },
  {
    "id": "arXiv:2107.00088",
    "title": "Inverse Design of Grating Couplers Using the Policy Gradient Method from  Reinforcement Learning",
    "abstract": "We present a proof-of-concept technique for the inverse design of\nelectromagnetic devices motivated by the policy gradient method in\nreinforcement learning, named PHORCED (PHotonic Optimization using REINFORCE\nCriteria for Enhanced Design). This technique uses a probabilistic generative\nneural network interfaced with an electromagnetic solver to assist in the\ndesign of photonic devices, such as grating couplers. We show that PHORCED\nobtains better performing grating coupler designs than local gradient-based\ninverse design via the adjoint method, while potentially providing faster\nconvergence over competing state-of-the-art generative methods. Furthermore, we\nimplement transfer learning with PHORCED, demonstrating that a neural network\ntrained to optimize 8$^\\circ$ grating couplers can then be re-trained on\ngrating couplers with alternate scattering angles while requiring >$10\\times$\nfewer simulations than control cases.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Sean Hooten",
      "Thomas Van Vaerenbergh",
      "Raymond G. Beausoleil"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.00088"
  },
  {
    "id": "arXiv:2107.00099",
    "title": "Sequence-level Confidence Classifier for ASR Utterance Accuracy and  Application to Acoustic Models",
    "abstract": "Scores from traditional confidence classifiers (CCs) in automatic speech\nrecognition (ASR) systems lack universal interpretation and vary with updates\nto the underlying confidence or acoustic models (AMs). In this work, we build\ninterpretable confidence scores with an objective to closely align with ASR\naccuracy. We propose a new sequence-level CC with a richer context providing CC\nscores highly correlated with ASR accuracy and scores stable across CC updates.\nHence, expanding CC applications. Recently, AM customization has gained\ntraction with the widespread use of unified models. Conventional adaptation\nstrategies that customize AM expect well-matched data for the target domain\nwith gold-standard transcriptions. We propose a cost-effective method of using\nCC scores to select an optimal adaptation data set, where we maximize ASR gains\nfrom minimal data. We study data in various confidence ranges and optimally\nchoose data for AM adaptation with KL-Divergence regularization. On the\nMicrosoft voice search task, data selection for supervised adaptation using the\nsequence-level confidence scores achieves word error rate reduction (WERR) of\n8.5% for row-convolution LSTM (RC-LSTM) and 5.2% for latency-controlled\nbidirectional LSTM (LC-BLSTM). In the semi-supervised case, with ASR hypotheses\nas labels, our method provides WERR of 5.9% and 2.8% for RC-LSTM and LC-BLSTM,\nrespectively.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Amber Afshan",
      "Kshitiz Kumar",
      "Jian Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.00099"
  },
  {
    "id": "arXiv:2107.00108",
    "title": "Convex Optimization for Parameter Synthesis in MDPs",
    "abstract": "Probabilistic model checking aims to prove whether a Markov decision process\n(MDP) satisfies a temporal logic specification. The underlying methods rely on\nan often unrealistic assumption that the MDP is precisely known. Consequently,\nparametric MDPs (pMDPs) extend MDPs with transition probabilities that are\nfunctions over unspecified parameters. The parameter synthesis problem is to\ncompute an instantiation of these unspecified parameters such that the\nresulting MDP satisfies the temporal logic specification. We formulate the\nparameter synthesis problem as a quadratically constrained quadratic program\n(QCQP), which is nonconvex and is NP-hard to solve in general. We develop two\napproaches that iteratively obtain locally optimal solutions. The first\napproach exploits the so-called convex-concave procedure (CCP), and the second\napproach utilizes a sequential convex programming (SCP) method. The techniques\nimprove the runtime and scalability by multiple orders of magnitude compared to\nblack-box CCP and SCP by merging ideas from convex optimization and\nprobabilistic model checking. We demonstrate the approaches on a satellite\ncollision avoidance problem with hundreds of thousands of states and tens of\nthousands of parameters and their scalability on a wide range of commonly used\nbenchmarks.",
    "descriptor": "\nComments: Submitted to IEEE TAC\n",
    "authors": [
      "Murat Cubuktepe",
      "Nils Jansen",
      "Sebastian Junges",
      "Joost-Pieter Katoen",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00108"
  },
  {
    "id": "arXiv:2107.00112",
    "title": "Using Self-Supervised Feature Extractors with Attention for Automatic  COVID-19 Detection from Speech",
    "abstract": "The ComParE 2021 COVID-19 Speech Sub-challenge provides a test-bed for the\nevaluation of automatic detectors of COVID-19 from speech. Such models can be\nof value by providing test triaging capabilities to health authorities, working\nalongside traditional testing methods. Herein, we leverage the usage of\npre-trained, problem agnostic, speech representations and evaluate their use\nfor this task. We compare the obtained results against a CNN architecture\ntrained from scratch and traditional frequency-domain representations. We also\nevaluate the usage of Self-Attention Pooling as an utterance-level information\naggregation method. Experimental results demonstrate that models trained on\nfeatures extracted from self-supervised models perform similarly or outperform\nfully-supervised models and models based on handcrafted features. Our best\nmodel improves the Unweighted Average Recall (UAR) from 69.0\\% to 72.3\\% on a\ndevelopment set comprised of only full-band examples and achieves 64.4\\% on the\ntest set. Furthermore, we study where the network is attending, attempting to\ndraw some conclusions regarding its explainability. In this relatively small\ndataset, we find the network attends especially to vowels and aspirates.",
    "descriptor": "\nComments: Submitted to Interspeech2021\n",
    "authors": [
      "John Mendon\u00e7a",
      "Rub\u00e9n Solera-Ure\u00f1a",
      "Alberto Abad",
      "Isabel Trancoso"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00112"
  },
  {
    "id": "arXiv:2107.00115",
    "title": "Automated Detection and Diagnosis of Diabetic Retinopathy: A  Comprehensive Survey",
    "abstract": "Diabetic Retinopathy (DR) is a leading cause of vision loss in the world,. In\nthe past few Diabetic Retinopathy (DR) is a leading cause of vision loss in the\nworld. In the past few years, Artificial Intelligence (AI) based approaches\nhave been used to detect and grade DR. Early detection enables appropriate\ntreatment and thus prevents vision loss, Both fundus and optical coherence\ntomography (OCT) images are used to image the retina. With deep\nlearning/machine learning apprroaches it is possible to extract features from\nthe images and detect the presence of DR. Multiple strategies are implemented\nto detect and grade the presence of DR using classification, segmentation, and\nhybrid techniques. This review covers the literature dealing with AI approaches\nto DR that have been published in the open literature over a five year span\n(2016-2021). In addition a comprehensive list of available DR datasets is\nreported. Both the PICO (P-patient, I-intervention, C-control O-outcome) and\nPreferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA)2009\nsearch strategies were employed. We summarize a total of 114 published articles\nwhich conformed to the scope of the review. In addition a list of 43 major\ndatasets is presented.",
    "descriptor": "\nComments: Submitted to MDPI Journal of Imaging special issue \"Frontiers In Retinal Image Processing\"2021\n",
    "authors": [
      "Vasudevan Lakshminarayanan",
      "Hoda Kherdfallah",
      "Arya Sarkar",
      "J. Jothi Balaji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00115"
  },
  {
    "id": "arXiv:2107.00179",
    "title": "Distributed Nonparametric Function Estimation: Optimal Rate of  Convergence and Cost of Adaptation",
    "abstract": "Distributed minimax estimation and distributed adaptive estimation under\ncommunication constraints for Gaussian sequence model and white noise model are\nstudied. The minimax rate of convergence for distributed estimation over a\ngiven Besov class, which serves as a benchmark for the cost of adaptation, is\nestablished. We then quantify the exact communication cost for adaptation and\nconstruct an optimally adaptive procedure for distributed estimation over a\nrange of Besov classes. The results demonstrate significant differences between\nnonparametric function estimation in the distributed setting and the\nconventional centralized setting. For global estimation, adaptation in general\ncannot be achieved for free in the distributed setting. The new technical tools\nto obtain the exact characterization for the cost of adaptation can be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "T. Tony Cai",
      "Hongji Wei"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00179"
  },
  {
    "id": "arXiv:2107.00195",
    "title": "Non-parametric Active Learning and Rate Reduction in Many-body Hilbert  Space with Rescaled Logarithmic Fidelity",
    "abstract": "In quantum and quantum-inspired machine learning, the very first step is to\nembed the data in quantum space known as Hilbert space. Developing quantum\nkernel function (QKF), which defines the distances among the samples in the\nHilbert space, belongs to the fundamental topics for machine learning. In this\nwork, we propose the rescaled logarithmic fidelity (RLF) and a non-parametric\nactive learning in the quantum space, which we name as RLF-NAL. The rescaling\ntakes advantage of the non-linearity of the kernel to tune the mutual distances\nof samples in the Hilbert space, and meanwhile avoids the exponentially-small\nfidelities between quantum many-qubit states. We compare RLF-NAL with several\nwell-known non-parametric algorithms including naive Bayes classifiers,\n$k$-nearest neighbors, and spectral clustering. Our method exhibits excellent\naccuracy particularly for the unsupervised case with no labeled samples and the\nfew-shot cases with small numbers of labeled samples. With the visualizations\nby t-SNE, our results imply that the machine learning in the Hilbert space\ncomplies with the principles of maximal coding rate reduction, where the\nlow-dimensional data exhibit within-class compressibility, between-class\ndiscrimination, and overall diversity. Our proposals can be applied to other\nquantum and quantum-inspired machine learning, including the methods using the\nparametric models such as tensor networks, quantum circuits, and quantum neural\nnetworks.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Wei-Ming Li",
      "Shi-Ju Ran"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00195"
  },
  {
    "id": "arXiv:2107.00203",
    "title": "Travel Cadence and Epidemic Spread",
    "abstract": "In this paper, we study how interactions between populations impact epidemic\nspread. We extend the classical SEIR model to include both integration-based\ndisease transmission simulation and population flow. Our model differs from\nexisting ones by having a more detailed representation of travel patterns,\nwithout losing tractability. This allows us to study the epidemic consequence\nof inter-regional travel with high fidelity. In particular, we define\n\\emph{travel cadence} as a two-dimensional measure of inter-regional travel,\nand show that both dimensions modulate epidemic spread. This technical insight\nleads to policy recommendations, pointing to a family of simple policy\ntrajectories that can effectively curb epidemic spread while maintaining a\nbasic level of mobility.",
    "descriptor": "",
    "authors": [
      "Lauren Streitmatter",
      "Peter Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.00203"
  },
  {
    "id": "arXiv:2107.00216",
    "title": "Almost-Orthogonal Bases for Inner Product Polynomials",
    "abstract": "In this paper, we consider low-degree polynomials of inner products between a\ncollection of random vectors. We give an almost orthogonal basis for this\nvector space of polynomials when the random vectors are Gaussian, spherical, or\nBoolean. In all three cases, our basis admits an interesting combinatorial\ndescription based on the topology of the underlying graph of inner products.\nWe also analyze the expected value of the product of two polynomials in our\nbasis. In all three cases, we show that this expected value can be expressed in\nterms of collections of matchings on the underlying graph of inner products. In\nthe Gaussian and Boolean cases, we show that this expected value is always\nnon-negative. In the spherical case, we show that this expected value can be\nnegative but we conjecture that if the underlying graph of inner products is\nplanar then this expected value will always be non-negative.\nWe hope that these polynomials will be a useful analytical tool in settings\nwhere one has a symmetric function of a collection of random or pseudorandom\nvectors.",
    "descriptor": "\nComments: Comments welcome\n",
    "authors": [
      "Chris Jones",
      "Aaron Potechin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.00216"
  },
  {
    "id": "arXiv:2107.00235",
    "title": "Feasibility of Haralick's Texture Features for the Classification of  Chromogenic In-situ Hybridization Images",
    "abstract": "This paper presents a proof of concept for the usefulness of second-order\ntexture features for the qualitative analysis and classification of chromogenic\nin-situ hybridization whole slide images in high-throughput imaging\nexperiments. The challenge is that currently, the gold standard for gene\nexpression grading in such images is expert assessment. The idea of the\nresearch team is to use different approaches in the analysis of these images\nthat will be used for structural segmentation and functional analysis in gene\nexpression. The article presents such perspective idea to select a number of\ntextural features that are going to be used for classification. In our\nexperiment, natural grouping of image samples (tiles) depending on their local\ntexture properties was explored in an unsupervised classification procedure.\nThe features are reduced to two dimensions with fuzzy c-means clustering. The\noverall conclusion of this experiment is that Haralick features are a viable\nchoice for classification and analysis of chromogenic in-situ hybridization\nimage data. The principal component analysis approach produced slightly more\n\"understandable\" from an annotator's point of view classes.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Stoyan Pavlov",
      "Galina Momcheva",
      "Pavlina Burlakova",
      "Simeon Atanasov",
      "Dimo Stoyanov",
      "Martin Ivanov",
      "Anton Tonchev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.00235"
  },
  {
    "id": "arXiv:2107.00283",
    "title": "DivergentNets: Medical Image Segmentation by Network Ensemble",
    "abstract": "Detection of colon polyps has become a trending topic in the intersecting\nfields of machine learning and gastrointestinal endoscopy. The focus has mainly\nbeen on per-frame classification. More recently, polyp segmentation has gained\nattention in the medical community. Segmentation has the advantage of being\nmore accurate than per-frame classification or object detection as it can show\nthe affected area in greater detail. For our contribution to the EndoCV 2021\nsegmentation challenge, we propose two separate approaches. First, a\nsegmentation model named TriUNet composed of three separate UNet models.\nSecond, we combine TriUNet with an ensemble of well-known segmentation models,\nnamely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called\nDivergentNets to produce more generalizable medical image segmentation masks.\nIn addition, we propose a modified Dice loss that calculates loss only for a\nsingle class when performing multiclass segmentation, forcing the model to\nfocus on what is most important. Overall, the proposed methods achieved the\nbest average scores for each respective round in the challenge, with TriUNet\nbeing the winning model in Round I and DivergentNets being the winning model in\nRound II of the segmentation generalization challenge at EndoCV 2021. The\nimplementation of our approach is made publicly available on GitHub.",
    "descriptor": "\nComments: the winning model of the segmentation generalization challenge at EndoCV 2021\n",
    "authors": [
      "Vajira Thambawita",
      "Steven A. Hicks",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00283"
  },
  {
    "id": "arXiv:2107.00296",
    "title": "Explainable Diabetic Retinopathy Detection and Retinal Image Generation",
    "abstract": "Though deep learning has shown successful performance in classifying the\nlabel and severity stage of certain diseases, most of them give few\nexplanations on how to make predictions. Inspired by Koch's Postulates, the\nfoundation in evidence-based medicine (EBM) to identify the pathogen, we\npropose to exploit the interpretability of deep learning application in medical\ndiagnosis. By determining and isolating the neuron activation patterns on which\ndiabetic retinopathy (DR) detector relies to make decisions, we demonstrate the\ndirect relation between the isolated neuron activation and lesions for a\npathological explanation. To be specific, we first define novel pathological\ndescriptors using activated neurons of the DR detector to encode both spatial\nand appearance information of lesions. Then, to visualize the symptom encoded\nin the descriptor, we propose Patho-GAN, a new network to synthesize medically\nplausible retinal images. By manipulating these descriptors, we could even\narbitrarily control the position, quantity, and categories of generated\nlesions. We also show that our synthesized images carry the symptoms directly\nrelated to diabetic retinopathy diagnosis. Our generated images are both\nqualitatively and quantitatively superior to the ones by previous methods.\nBesides, compared to existing methods that take hours to generate an image, our\nsecond level speed endows the potential to be an effective solution for data\naugmentation.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Yuhao Niu",
      "Lin Gu",
      "Yitian Zhao",
      "Feng Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00296"
  },
  {
    "id": "arXiv:2107.00320",
    "title": "Prediction of tone detection thresholds in interaurally delayed noise  based on interaural phase difference fluctuations",
    "abstract": "Differences between the interaural phase of a noise and a target tone improve\ndetection thresholds. The maximum masking release is obtained for detecting an\nantiphasic tone (S$\\pi$) in diotic noise (N0). It has been shown in several\nstudies that this benefit gradually declines as an interaural delay is applied\nto the N0S$\\pi$ complex. This decline has been attributed to the reduced\ninteraural coherence of the noise. Here, we report detection thresholds for a\n500 Hz tone in masking noise with up to 8 ms interaural delay and bandwidths\nfrom 25 to 1000 Hz. When reducing the noise bandwidth from 100 to 50 and 25 Hz,\nthe masking release at 8 ms delay increases, as expected for increasing\ntemporal coherence with decreasing bandwidth. For bandwidths of 100 to 1000 Hz,\nno significant difference was observed and detection thresholds with these\nnoises have a delay dependence that is fully described by the temporal\ncoherence imposed by the typical monaurally determined auditory filter\nbandwidth. A minimalistic binaural model is suggested based on interaural phase\ndifference fluctuations without the assumption of delay lines.",
    "descriptor": "\nComments: This work has been submitted to Acta Acustica for possible publication\n",
    "authors": [
      "Mathias Dietz",
      "J\u00f6rg Encke",
      "Kristin I. Bracklo",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00320"
  },
  {
    "id": "arXiv:2107.00352",
    "title": "Reparameterized Sampling for Generative Adversarial Networks",
    "abstract": "Recently, sampling methods have been successfully applied to enhance the\nsample quality of Generative Adversarial Networks (GANs). However, in practice,\nthey typically have poor sample efficiency because of the independent proposal\nsampling from the generator. In this work, we propose REP-GAN, a novel sampling\nmethod that allows general dependent proposals by REParameterizing the Markov\nchains into the latent space of the generator. Theoretically, we show that our\nreparameterized proposal admits a closed-form Metropolis-Hastings acceptance\nratio. Empirically, extensive experiments on synthetic and real datasets\ndemonstrate that our REP-GAN largely improves the sample efficiency and obtains\nbetter sample quality simultaneously.",
    "descriptor": "\nComments: ECML PKDD 2021\n",
    "authors": [
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00352"
  },
  {
    "id": "arXiv:2107.00363",
    "title": "Well-calibrated prediction intervals for regression problems",
    "abstract": "Over the last few decades, various methods have been proposed for estimating\nprediction intervals in regression settings, including Bayesian methods,\nensemble methods, direct interval estimation methods and conformal prediction\nmethods. An important issue is the calibration of these methods: the generated\nprediction intervals should have a predefined coverage level, without being\noverly conservative. In this work, we review the above four classes of methods\nfrom a conceptual and experimental point of view. Results on benchmark data\nsets from various domains highlight large fluctuations in performance from one\ndata set to another. These observations can be attributed to the violation of\ncertain assumptions that are inherent to some classes of methods. We illustrate\nhow conformal prediction can be used as a general calibration procedure for\nmethods that deliver poor results without a calibration step.",
    "descriptor": "\nComments: submitted to AI Review\n",
    "authors": [
      "Nicolas Dewolf",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00363"
  },
  {
    "id": "arXiv:2107.00371",
    "title": "Sparse GCA and Thresholded Gradient Descent",
    "abstract": "Generalized correlation analysis (GCA) is concerned with uncovering linear\nrelationships across multiple datasets. It generalizes canonical correlation\nanalysis that is designed for two datasets. We study sparse GCA when there are\npotentially multiple generalized correlation tuples in data and the loading\nmatrix has a small number of nonzero rows. It includes sparse CCA and sparse\nPCA of correlation matrices as special cases. We first formulate sparse GCA as\ngeneralized eigenvalue problems at both population and sample levels via a\ncareful choice of normalization constraints. Based on a Lagrangian form of the\nsample optimization problem, we propose a thresholded gradient descent\nalgorithm for estimating GCA loading vectors and matrices in high dimensions.\nWe derive tight estimation error bounds for estimators generated by the\nalgorithm with proper initialization. We also demonstrate the prowess of the\nalgorithm on a number of synthetic datasets.",
    "descriptor": "",
    "authors": [
      "Sheng Gao",
      "Zongming Ma"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00371"
  },
  {
    "id": "arXiv:2107.00379",
    "title": "On the Expected Complexity of Maxout Networks",
    "abstract": "Learning with neural networks relies on the complexity of the representable\nfunctions, but more importantly, the particular assignment of typical\nparameters to functions of different complexity. Taking the number of\nactivation regions as a complexity measure, recent works have shown that the\npractical complexity of deep ReLU networks is often far from the theoretical\nmaximum. In this work we show that this phenomenon also occurs in networks with\nmaxout (multi-argument) activation functions and when considering the decision\nboundaries in classification tasks. We also show that the parameter space has a\nmultitude of full-dimensional regions with widely different complexity, and\nobtain nontrivial lower bounds on the expected complexity. Finally, we\ninvestigate different parameter initialization procedures and show that they\ncan increase the speed of convergence in training.",
    "descriptor": "\nComments: 41 pages, 18 figures\n",
    "authors": [
      "Hanna Tseran",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00379"
  },
  {
    "id": "arXiv:2107.00385",
    "title": "Morphological classification of compact and extended radio galaxies  using convolutional neural networks and data augmentation techniques",
    "abstract": "Machine learning techniques have been increasingly used in astronomical\napplications and have proven to successfully classify objects in image data\nwith high accuracy. The current work uses archival data from the Faint Images\nof the Radio Sky at Twenty Centimeters (FIRST) to classify radio galaxies into\nfour classes: Fanaroff-Riley Class I (FRI), Fanaroff-Riley Class II (FRII),\nBent-Tailed (BENT), and Compact (COMPT). The model presented in this work is\nbased on Convolutional Neural Networks (CNNs). The proposed architecture\ncomprises three parallel blocks of convolutional layers combined and processed\nfor final classification by two feed-forward layers. Our model classified\nselected classes of radio galaxy sources on an independent testing subset with\nan average of 96\\% for precision, recall, and F1 score. The best selected\naugmentation techniques were rotations, horizontal or vertical flips, and\nincrease of brightness. Shifts, zoom and decrease of brightness worsened the\nperformance of the model. The current results show that model developed in this\nwork is able to identify different morphological classes of radio galaxies with\na high efficiency and performance",
    "descriptor": "\nComments: 12 pages, 7 figures, 9 tables, published in Monthly Notices of the Royal Astronomical Society\n",
    "authors": [
      "Viera Maslej-Kre\u0161\u0148\u00e1kov\u00e1",
      "Khadija El Bouchefry",
      "Peter Butka"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.00385"
  },
  {
    "id": "arXiv:2107.00391",
    "title": "Explainable nonlinear modelling of multiple time series with invertible  neural networks",
    "abstract": "A method for nonlinear topology identification is proposed, based on the\nassumption that a collection of time series are generated in two steps: i) a\nvector autoregressive process in a latent space, and ii) a nonlinear,\ncomponent-wise, monotonically increasing observation mapping. The latter\nmappings are assumed invertible, and are modelled as shallow neural networks,\nso that their inverse can be numerically evaluated, and their parameters can be\nlearned using a technique inspired in deep learning. Due to the function\ninversion, the back-propagation step is not straightforward, and this paper\nexplains the steps needed to calculate the gradients applying implicit\ndifferentiation. Whereas the model explainability is the same as that for\nlinear VAR processes, preliminary numerical tests show that the prediction\nerror becomes smaller.",
    "descriptor": "\nComments: 4 figures, 13 pages (original submission 12 pages) Dubmitted to: 4th International Conference on Intelligent Technologies and Applications (INTAP 2021)\n",
    "authors": [
      "Luis Miguel Lopez-Ramos",
      "Kevin Roy",
      "Baltasar Beferull-Lozano"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00391"
  },
  {
    "id": "arXiv:2107.00392",
    "title": "Coherent information of a quantum channel or its complement is  generically positive",
    "abstract": "The task of determining whether a given quantum channel has positive capacity\nto transmit quantum information is a fundamental open problem in quantum\ninformation theory. In general, the coherent information needs to be computed\nfor an unbounded number of copies of a channel in order to detect a positive\nvalue of its quantum capacity. However, in this Letter, we show that the\ncoherent information of a single copy of a randomly selected channel is\npositive almost surely if the channel's output space is larger than its\nenvironment. Hence, in this case, a single copy of the channel typically\nsuffices to determine positivity of its quantum capacity. Put differently,\nchannels with zero coherent information have measure zero in the subset of\nchannels for which the output space is larger than the environment. On the\nother hand, if the environment is larger than the channel's output space,\nidentical results hold for the channel's complement.",
    "descriptor": "",
    "authors": [
      "Satvik Singh",
      "Nilanjana Datta"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.00392"
  },
  {
    "id": "arXiv:2107.00394",
    "title": "Global sensitivity analysis using derivative-based sparse Poincar\u00e9  chaos expansions",
    "abstract": "Variance-based global sensitivity analysis, in particular Sobol' analysis, is\nwidely used for determining the importance of input variables to a\ncomputational model. Sobol' indices can be computed cheaply based on spectral\nmethods like polynomial chaos expansions (PCE). Another choice are the recently\ndeveloped Poincar\\'e chaos expansions (PoinCE), whose orthonormal\ntensor-product basis is generated from the eigenfunctions of one-dimensional\nPoincar\\'e differential operators. In this paper, we show that the Poincar\\'e\nbasis is the unique orthonormal basis with the property that partial\nderivatives of the basis form again an orthogonal basis with respect to the\nsame measure as the original basis. This special property makes PoinCE ideally\nsuited for incorporating derivative information into the surrogate modelling\nprocess. Assuming that partial derivative evaluations of the computational\nmodel are available, we compute spectral expansions in terms of Poincar\\'e\nbasis functions or basis partial derivatives, respectively, by sparse\nregression. We show on two numerical examples that the derivative-based\nexpansions provide accurate estimates for Sobol' indices, even outperforming\nPCE in terms of bias and variance. In addition, we derive an analytical\nexpression based on the PoinCE coefficients for a second popular sensitivity\nindex, the derivative-based sensitivity measure (DGSM), and explore its\nperformance as upper bound to the corresponding total Sobol' indices.",
    "descriptor": "",
    "authors": [
      "Nora L\u00fcthen",
      "Olivier Roustant",
      "Fabrice Gamboa",
      "Bertrand Iooss",
      "Stefano Marelli",
      "Bruno Sudret"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00394"
  },
  {
    "id": "arXiv:2107.00400",
    "title": "Lossless Coding of Point Cloud Geometry using a Deep Generative Model",
    "abstract": "This paper proposes a lossless point cloud (PC) geometry compression method\nthat uses neural networks to estimate the probability distribution of voxel\noccupancy. First, to take into account the PC sparsity, our method adaptively\npartitions a point cloud into multiple voxel block sizes. This partitioning is\nsignalled via an octree. Second, we employ a deep auto-regressive generative\nmodel to estimate the occupancy probability of each voxel given the previously\nencoded ones. We then employ the estimated probabilities to code efficiently a\nblock using a context-based arithmetic coder. Our context has variable size and\ncan expand beyond the current block to learn more accurate probabilities. We\nalso consider using data augmentation techniques to increase the generalization\ncapability of the learned probability models, in particular in the presence of\nnoise and lower-density point clouds. Experimental evaluation, performed on a\nvariety of point clouds from four different datasets and with diverse\ncharacteristics, demonstrates that our method reduces significantly (by up to\n30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.",
    "descriptor": "\nComments: This paper has been submitted to the IEEE Transactions on Circuits and Systems for Video Technology (TCSVT). arXiv admin note: text overlap with arXiv:2011.14700\n",
    "authors": [
      "Dat Thanh Nguyen",
      "Maurice Quach",
      "Giuseppe Valenzise",
      "Pierre Duhamel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00400"
  },
  {
    "id": "arXiv:2107.00418",
    "title": "Supervised Segmentation with Domain Adaptation for Small Sampled Orbital  CT Images",
    "abstract": "Deep neural networks (DNNs) have been widely used for medical image analysis.\nHowever, the lack of access a to large-scale annotated dataset poses a great\nchallenge, especially in the case of rare diseases, or new domains for the\nresearch society. Transfer of pre-trained features, from the relatively large\ndataset is a considerable solution. In this paper, we have explored supervised\nsegmentation using domain adaptation for optic nerve and orbital tumor, when\nonly small sampled CT images are given. Even the lung image database consortium\nimage collection (LIDC-IDRI) is a cross-domain to orbital CT, but the proposed\ndomain adaptation method improved the performance of attention U-Net for the\nsegmentation in public optic nerve dataset and our clinical orbital tumor\ndataset. The code and dataset are available at https://github.com/cmcbigdata.",
    "descriptor": "",
    "authors": [
      "Sungho Suh",
      "Sojeong Cheon",
      "Wonseo Choi",
      "Yeon Woong Chung",
      "Won-Kyung Cho",
      "Ji-Sun Paik",
      "Sung Eun Kim",
      "Dong-Jin Chang",
      "Yong Oh Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00418"
  },
  {
    "id": "arXiv:2107.00462",
    "title": "Deep Hierarchical Super-Resolution for Scientific Data Reduction and  Visualization",
    "abstract": "We present an approach for hierarchical super resolution (SR) using neural\nnetworks on an octree data representation. We train a hierarchy of neural\nnetworks, each capable of 2x upscaling in each spatial dimension between two\nlevels of detail, and use these networks in tandem to facilitate large scale\nfactor super resolution, scaling with the number of trained networks. We\nutilize these networks in a hierarchical super resolution algorithm that\nupscales multiresolution data to a uniform high resolution without introducing\nseam artifacts on octree node boundaries. We evaluate application of this\nalgorithm in a data reduction framework by dynamically downscaling input data\nto an octree-based data structure to represent the multiresolution data before\ncompressing for additional storage reduction. We demonstrate that our approach\navoids seam artifacts common to multiresolution data formats, and show how\nneural network super resolution assisted data reduction can preserve global\nfeatures better than compressors alone at the same compression ratios.",
    "descriptor": "",
    "authors": [
      "Skylar W. Wurster",
      "Han-Wei Shen",
      "Hanqi Guo",
      "Thomas Peterka",
      "Mukund Raj",
      "Jiayi Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00462"
  },
  {
    "id": "arXiv:2107.00464",
    "title": "On the Convergence of Stochastic Extragradient for Bilinear Games with  Restarted Iteration Averaging",
    "abstract": "We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the Stochastic ExtraGradient (SEG) method with constant step size,\nand presenting variations of the method that yield favorable convergence. We\nfirst note that the last iterate of the basic SEG method only contracts to a\nfixed neighborhood of the Nash equilibrium, independent of the step size. This\ncontrasts sharply with the standard setting of minimization where standard\nstochastic algorithms converge to a neighborhood that vanishes in proportion to\nthe square-root (constant) step size. Under the same setting, however, we prove\nthat when augmented with iteration averaging, SEG provably converges to the\nNash equilibrium, and such a rate is provably accelerated by incorporating a\nscheduled restarting procedure. In the interpolation setting, we achieve an\noptimal convergence rate up to tight constants. We present numerical\nexperiments that validate our theoretical findings and demonstrate the\neffectiveness of the SEG method when equipped with iteration averaging and\nrestarting.",
    "descriptor": "",
    "authors": [
      "Chris Junchi Li",
      "Yaodong Yu",
      "Nicolas Loizou",
      "Gauthier Gidel",
      "Yi Ma",
      "Nicolas Le Roux",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00464"
  },
  {
    "id": "arXiv:2107.00469",
    "title": "Never Go Full Batch (in Stochastic Convex Optimization)",
    "abstract": "We study the generalization performance of $\\text{full-batch}$ optimization\nalgorithms for stochastic convex optimization: these are first-order methods\nthat only access the exact gradient of the empirical risk (rather than\ngradients with respect to individual data points), that include a wide range of\nalgorithms such as gradient descent, mirror descent, and their regularized\nand/or accelerated variants. We provide a new separation result showing that,\nwhile algorithms such as stochastic gradient descent can generalize and\noptimize the population risk to within $\\epsilon$ after $O(1/\\epsilon^2)$\niterations, full-batch methods either need at least $\\Omega(1/\\epsilon^4)$\niterations or exhibit a dimension-dependent sample complexity.",
    "descriptor": "",
    "authors": [
      "Idan Amir",
      "Yair Carmon",
      "Tomer Koren",
      "Roi Livni"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00469"
  },
  {
    "id": "arXiv:2107.00471",
    "title": "SinGAN-Seg: Synthetic Training Data Generation for Medical Image  Segmentation",
    "abstract": "Processing medical data to find abnormalities is a time-consuming and costly\ntask, requiring tremendous efforts from medical experts. Therefore, Ai has\nbecome a popular tool for the automatic processing of medical data, acting as a\nsupportive tool for doctors. AI tools highly depend on data for training the\nmodels. However, there are several constraints to access to large amounts of\nmedical data to train machine learning algorithms in the medical domain, e.g.,\ndue to privacy concerns and the costly, time-consuming medical data annotation\nprocess. To address this, in this paper we present a novel synthetic data\ngeneration pipeline called SinGAN-Seg to produce synthetic medical data with\nthe corresponding annotated ground truth masks. We show that these synthetic\ndata generation pipelines can be used as an alternative to bypass privacy\nconcerns and as an alternative way to produce artificial segmentation datasets\nwith corresponding ground truth masks to avoid the tedious medical data\nannotation process. As a proof of concept, we used an open polyp segmentation\ndataset. By training UNet++ using both the real polyp segmentation dataset and\nthe corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we\nshow that the synthetic data can achieve a very close performance to the real\ndata when the real segmentation datasets are large enough. In addition, we show\nthat synthetic data generated from the SinGAN-Seg pipeline improving the\nperformance of segmentation algorithms when the training dataset is very small.\nSince our SinGAN-Seg pipeline is applicable for any medical dataset, this\npipeline can be used with any other segmentation datasets.",
    "descriptor": "",
    "authors": [
      "Vajira Thambawita",
      "Pegah Salehi",
      "Sajad Amouei Sheshkal",
      "Steven A. Hicks",
      "Hugo L.Hammer",
      "Sravanthi Parasa",
      "Thomas de Lange",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00471"
  },
  {
    "id": "arXiv:2107.00472",
    "title": "Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets",
    "abstract": "In this paper, we propose approximate Frank-Wolfe (FW) algorithms to solve\nconvex optimization problems over graph-structured support sets where the\n\\textit{linear minimization oracle} (LMO) cannot be efficiently obtained in\ngeneral. We first demonstrate that two popular approximation assumptions\n(\\textit{additive} and \\textit{multiplicative gap errors)}, are not valid for\nour problem, in that no cheap gap-approximate LMO oracle exists in general.\nInstead, a new \\textit{approximate dual maximization oracle} (DMO) is proposed,\nwhich approximates the inner product rather than the gap. When the objective is\n$L$-smooth, we prove that the standard FW method using a $\\delta$-approximate\nDMO converges as $\\mathcal{O}(L / \\delta t + (1-\\delta)(\\delta^{-1} +\n\\delta^{-2}))$ in general, and as $\\mathcal{O}(L/(\\delta^2(t+2)))$ over a\n$\\delta$-relaxation of the constraint set. Additionally, when the objective is\n$\\mu$-strongly convex and the solution is unique, a variant of FW converges to\n$\\mathcal{O}(L^2\\log(t)/(\\mu \\delta^6 t^2))$ with the same per-iteration\ncomplexity. Our empirical results suggest that even these improved bounds are\npessimistic, with significant improvement in recovering real-world images with\ngraph-structured sparsity.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Baojian Zhou",
      "Yifan Sun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00472"
  },
  {
    "id": "arXiv:2107.00534",
    "title": "The Limit Order Book Recreation Model (LOBRM): An Extended Analysis",
    "abstract": "The limit order book (LOB) depicts the fine-grained demand and supply\nrelationship for financial assets and is widely used in market microstructure\nstudies. Nevertheless, the availability and high cost of LOB data restrict its\nwider application. The LOB recreation model (LOBRM) was recently proposed to\nbridge this gap by synthesizing the LOB from trades and quotes (TAQ) data.\nHowever, in the original LOBRM study, there were two limitations: (1)\nexperiments were conducted on a relatively small dataset containing only one\nday of LOB data; and (2) the training and testing were performed in a\nnon-chronological fashion, which essentially re-frames the task as\ninterpolation and potentially introduces lookahead bias. In this study, we\nextend the research on LOBRM and further validate its use in real-world\napplication scenarios. We first advance the workflow of LOBRM by (1) adding a\ntime-weighted z-score standardization for the LOB and (2) substituting the\nordinary differential equation kernel with an exponential decay kernel to lower\ncomputation complexity. Experiments are conducted on the extended LOBSTER\ndataset in a chronological fashion, as it would be used in a real-world\napplication. We find that (1) LOBRM with decay kernel is superior to\ntraditional non-linear models, and module ensembling is effective; (2)\nprediction accuracy is negatively related to the volatility of order volumes\nresting in the LOB; (3) the proposed sparse encoding method for TAQ exhibits\ngood generalization ability and can facilitate manifold tasks; and (4) the\ninfluence of stochastic drift on prediction accuracy can be alleviated by\nincreasing historical samples.",
    "descriptor": "\nComments: 16 pages, preprint accepted for publication in the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD 2021)\n",
    "authors": [
      "Zijian Shi",
      "John Cartlidge"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00534"
  },
  {
    "id": "arXiv:2107.00594",
    "title": "Pretext Tasks selection for multitask self-supervised speech  representation learning",
    "abstract": "Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In various application domains, including\ncomputer vision, natural language processing and audio/speech signal\nprocessing, a wide range of features where engineered through decades of\nresearch efforts. As it turns out, learning to predict such features has proven\nto be a particularly relevant pretext task leading to building useful\nself-supervised representations that prove to be effective for downstream\ntasks. However, methods and common practices for combining such pretext tasks,\nwhere each task targets a different group of features for better performance on\nthe downstream task have not been explored and understood properly. In fact,\nthe process relies almost exclusively on a computationally heavy experimental\nprocedure, which becomes intractable with the increase of the number of pretext\ntasks. This paper introduces a method to select a group of pretext tasks among\na set of candidates. The method we propose estimates properly calibrated\nweights for the partial losses corresponding to the considered pretext tasks\nduring the self-supervised training process. The experiments conducted on\nspeaker recognition and automatic speech recognition validate our approach, as\nthe groups selected and weighted with our method perform better than classic\nbaselines, thus facilitating the selection and combination of relevant\npseudo-labels for self-supervised representation learning.",
    "descriptor": "",
    "authors": [
      "Salah Zaiem",
      "Titouan Parcollet",
      "Slim Essid"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00594"
  },
  {
    "id": "arXiv:2107.00615",
    "title": "A linear phase evolution model for reduction of temporal unwrapping and  field estimation errors in multi-echo GRE",
    "abstract": "This article aims at developing a model based optimization for reduction of\ntemporal unwrapping and field estimation errors in multi-echo acquisition of\nGradient Echo sequence. Using the assumption that the phase is linear along the\ntemporal dimension, the field estimation is performed by application of unity\nrank approximation to the Hankel matrix formed using the complex exponential of\nthe channel combined phase at each echo time. For the purpose of maintaining\nconsistency with the observed complex data, the linear phase evolution model is\nformulated as an optimization problem with a cost function that involves a\nfidelity term and a unity rank prior, implemented using alternating\nminimization. Itoh s algorithm applied to the multi-echo phase estimated from\nthis linear phase evolution model is able to reduce the unwrapping errors as\ncompared to the unwrapping when directly applied to the measured phase.\nSecondly, the improved accuracy of the frequency fit in comparison to\nestimation using weighted least-square regression and penalized maximum\nlikelihood is demonstrated using numerical simulation of field perturbation due\nto magnetic susceptibility effect. It is shown that the field can be estimated\nwith 80 percent reduction in mean absolute error in comparison to wLSR and 66\npercent reduction with respect to penalized maximum likelihood. The improvement\nin performance becomes more pronounced with increasing strengths of field\ngradient magnitudes and echo spacing.",
    "descriptor": "\nComments: 29pages, 8 figures\n",
    "authors": [
      "Joseph Suresh Paul",
      "Sreekanth Madhusoodhanan"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.00615"
  },
  {
    "id": "arXiv:2107.00635",
    "title": "StableEmit: Selection Probability Discount for Reducing Emission Latency  of Streaming Monotonic Attention ASR",
    "abstract": "While attention-based encoder-decoder (AED) models have been successfully\nextended to the online variants for streaming automatic speech recognition\n(ASR), such as monotonic chunkwise attention (MoChA), the models still have a\nlarge label emission latency because of the unconstrained end-to-end training\nobjective. Previous works tackled this problem by leveraging alignment\ninformation to control the timing to emit tokens during training. In this work,\nwe propose a simple alignment-free regularization method, StableEmit, to\nencourage MoChA to emit tokens earlier. StableEmit discounts the selection\nprobabilities in hard monotonic attention for token boundary detection by a\nconstant factor and regularizes them to recover the total attention mass during\ntraining. As a result, the scale of the selection probabilities is increased,\nand the values can reach a threshold for token emission earlier, leading to a\nreduction of emission latency and deletion errors. Moreover, StableEmit can be\ncombined with methods that constraint alignments to further improve the\naccuracy and latency. Experimental evaluations with LSTM and Conformer encoders\ndemonstrate that StableEmit significantly reduces the recognition errors and\nthe emission latency simultaneously. We also show that the use of alignment\ninformation is complementary in both metrics.",
    "descriptor": "\nComments: Accepted at Interspeech 2021\n",
    "authors": [
      "Hirofumi Inaguma",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00635"
  },
  {
    "id": "arXiv:2107.00636",
    "title": "ESPnet-ST IWSLT 2021 Offline Speech Translation System",
    "abstract": "This paper describes the ESPnet-ST group's IWSLT 2021 submission in the\noffline speech translation track. This year we made various efforts on training\ndata, architecture, and audio segmentation. On the data side, we investigated\nsequence-level knowledge distillation (SeqKD) for end-to-end (E2E) speech\ntranslation. Specifically, we used multi-referenced SeqKD from multiple\nteachers trained on different amounts of bitext. On the architecture side, we\nadopted the Conformer encoder and the Multi-Decoder architecture, which equips\ndedicated decoders for speech recognition and translation tasks in a unified\nencoder-decoder model and enables search in both source and target language\nspaces during inference. We also significantly improved audio segmentation by\nusing the pyannote.audio toolkit and merging multiple short segments for long\ncontext modeling. Experimental evaluations showed that each of them contributed\nto large improvements in translation performance. Our best E2E system combined\nall the above techniques with model ensembling and achieved 31.4 BLEU on the\n2-ref of tst2021 and 21.2 BLEU and 19.3 BLEU on the two single references of\ntst2021.",
    "descriptor": "\nComments: IWSLT 2021\n",
    "authors": [
      "Hirofumi Inaguma",
      "Brian Yan",
      "Siddharth Dalmia",
      "Pengcheng Gu",
      "Jiatong Shi",
      "Kevin Duh",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00636"
  },
  {
    "id": "arXiv:1703.06021",
    "title": "Causal Consistency for Reversible Multiparty Protocols",
    "abstract": "Comments: Extended, revised version of a PPDP'17 paper (this https URL)",
    "descriptor": "\nComments: Extended, revised version of a PPDP'17 paper (this https URL)\n",
    "authors": [
      "Claudio Antares Mezzina",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1703.06021"
  },
  {
    "id": "arXiv:1802.03122",
    "title": "Delay-Dependent Distributed Kalman Fusion Estimation with Dimensionality  Reduction in Cyber-Physical Systems",
    "abstract": "Delay-Dependent Distributed Kalman Fusion Estimation with Dimensionality  Reduction in Cyber-Physical Systems",
    "descriptor": "",
    "authors": [
      "Bo Chen",
      "Daniel W. C. Ho",
      "Guoqiang Hu",
      "Li Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1802.03122"
  },
  {
    "id": "arXiv:1803.06258",
    "title": "Online Controlled Experiments for Personalised e-Commerce Strategies:  Design, Challenges, and Pitfalls",
    "abstract": "Comments: Not peer-reviewed but retained for historic interest. Removed an erroneous statement on Welch's t-test assumptions in Section 3.2. 9 pages, 7 figures",
    "descriptor": "\nComments: Not peer-reviewed but retained for historic interest. Removed an erroneous statement on Welch's t-test assumptions in Section 3.2. 9 pages, 7 figures\n",
    "authors": [
      "C. H. Bryan Liu",
      "Benjamin Paul Chamberlain"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Discrete Mathematics (cs.DM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/1803.06258"
  },
  {
    "id": "arXiv:1811.02676",
    "title": "Oblivious Set-maxima for Intersection of Convex Polygons",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Avah Banerjee",
      "Dana Richards"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1811.02676"
  },
  {
    "id": "arXiv:1901.11331",
    "title": "Generalized Dirichlet-process-means for $f$-separable distortion  measures",
    "abstract": "Generalized Dirichlet-process-means for $f$-separable distortion  measures",
    "descriptor": "",
    "authors": [
      "Masahiro Kobayashi",
      "Kazuho Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.11331"
  },
  {
    "id": "arXiv:1904.12928",
    "title": "Some preliminary results on a high order asymptotic preserving  computationally explicit kinetic scheme",
    "abstract": "Some preliminary results on a high order asymptotic preserving  computationally explicit kinetic scheme",
    "descriptor": "",
    "authors": [
      "Remi Abgrall",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1904.12928"
  },
  {
    "id": "arXiv:1905.02515",
    "title": "Guided Visual Exploration of Relations in Data Sets",
    "abstract": "Comments: 32 pages, 13 figures. This article extends arXiv:1804.03194 and arXiv:1805.07725",
    "descriptor": "\nComments: 32 pages, 13 figures. This article extends arXiv:1804.03194 and arXiv:1805.07725\n",
    "authors": [
      "Kai Puolam\u00e4ki",
      "Emilia Oikarinen",
      "Andreas Henelius"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.02515"
  },
  {
    "id": "arXiv:1905.11797",
    "title": "A New Theoretical Framework for Fast and Accurate Online Decision-Making",
    "abstract": "A New Theoretical Framework for Fast and Accurate Online Decision-Making",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Tommaso R. Cesari",
      "Yishay Mansour",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11797"
  },
  {
    "id": "arXiv:1909.03773",
    "title": "Imitation Learning from Pixel-Level Demonstrations by HashReward",
    "abstract": "Comments: Accepted by AAMAS-2021",
    "descriptor": "\nComments: Accepted by AAMAS-2021\n",
    "authors": [
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Yuan Jiang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.03773"
  },
  {
    "id": "arXiv:1910.03201",
    "title": "Differentiable Sparsification for Deep Neural Networks",
    "abstract": "Differentiable Sparsification for Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Yognjin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.03201"
  },
  {
    "id": "arXiv:1910.04952",
    "title": "Demon: Improved Neural Network Training with Momentum Decay",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "John Chen",
      "Cameron Wolfe",
      "Zhao Li",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.04952"
  },
  {
    "id": "arXiv:1910.11390",
    "title": "Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and  Graph Prediction",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1806.08804 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1806.08804 by other authors\n",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/1910.11390"
  },
  {
    "id": "arXiv:1911.01297",
    "title": "Cooperative Manipulation via Internal Force Regulation: A Rigidity  Theory Perspective",
    "abstract": "Cooperative Manipulation via Internal Force Regulation: A Rigidity  Theory Perspective",
    "descriptor": "",
    "authors": [
      "Christos K. Verginis",
      "Daniel Zelazo",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1911.01297"
  },
  {
    "id": "arXiv:1911.01670",
    "title": "RobustECD: Enhancement of Network Structure for Robust Community  Detection",
    "abstract": "Comments: Under review. 21 pages, 14 figures",
    "descriptor": "\nComments: Under review. 21 pages, 14 figures\n",
    "authors": [
      "Jiajun Zhou",
      "Zhi Chen",
      "Min Du",
      "Lihong Chen",
      "Shanqing Yu",
      "Guanrong Chen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1911.01670"
  },
  {
    "id": "arXiv:1911.02728",
    "title": "Auto-encoding brain networks with applications to analyzing large-scale  brain imaging datasets",
    "abstract": "Comments: 31 pages, 12 figures, 5 tables",
    "descriptor": "\nComments: 31 pages, 12 figures, 5 tables\n",
    "authors": [
      "Meimei Liu",
      "Zhengwu Zhang",
      "David B. Dunson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/1911.02728"
  },
  {
    "id": "arXiv:1912.05081",
    "title": "Neural Networks as Geometric Chaotic Maps",
    "abstract": "Comments: in IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: in IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Ziwei Li",
      "Sai Ravela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.05081"
  },
  {
    "id": "arXiv:2002.04788",
    "title": "To Split or Not to Split: The Impact of Disparate Treatment in  Classification",
    "abstract": "To Split or Not to Split: The Impact of Disparate Treatment in  Classification",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Hsiang Hsu",
      "Mario Diaz",
      "Flavio P. Calmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.04788"
  },
  {
    "id": "arXiv:2002.05245",
    "title": "Maximin Fairness with Mixed Divisible and Indivisible Goods",
    "abstract": "Comments: Appears in the 35th AAAI Conference on Artificial Intelligence (AAAI), 2021",
    "descriptor": "\nComments: Appears in the 35th AAAI Conference on Artificial Intelligence (AAAI), 2021\n",
    "authors": [
      "Xiaohui Bei",
      "Shengxin Liu",
      "Xinhang Lu",
      "Hongao Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2002.05245"
  },
  {
    "id": "arXiv:2003.00937",
    "title": "BASGD: Buffered Asynchronous SGD for Byzantine Learning",
    "abstract": "BASGD: Buffered Asynchronous SGD for Byzantine Learning",
    "descriptor": "",
    "authors": [
      "Yi-Rui Yang",
      "Wu-Jun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00937"
  },
  {
    "id": "arXiv:2003.06148",
    "title": "PointINS: Point-based Instance Segmentation",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Lu Qi",
      "Yi Wang",
      "Yukang Chen",
      "Yingcong Chen",
      "Xiangyu Zhang",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.06148"
  },
  {
    "id": "arXiv:2003.08089",
    "title": "Solving Inverse Problems with a Flow-based Noise Model",
    "abstract": "Solving Inverse Problems with a Flow-based Noise Model",
    "descriptor": "",
    "authors": [
      "Jay Whang",
      "Qi Lei",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08089"
  },
  {
    "id": "arXiv:2003.13314",
    "title": "Decentralized Learning for Channel Allocation in IoT Networks over  Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game",
    "abstract": "Comments: 32 pages, 10 figures, submitted to IEEE TWC",
    "descriptor": "\nComments: 32 pages, 10 figures, submitted to IEEE TWC\n",
    "authors": [
      "Wenbo Wang",
      "Amir Leshem",
      "Dusit Niyato",
      "Zhu Han"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2003.13314"
  },
  {
    "id": "arXiv:2004.00601",
    "title": "Parallel Predictive Entropy Search for Multi-objective Bayesian  Optimization with Constraints",
    "abstract": "Parallel Predictive Entropy Search for Multi-objective Bayesian  Optimization with Constraints",
    "descriptor": "",
    "authors": [
      "Eduardo C. Garrido-Merch\u00e1n",
      "Daniel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.00601"
  },
  {
    "id": "arXiv:2004.01685",
    "title": "Uncertain Multi-Agent Systems with Distributed Constrained Optimization  Missions and Event-Triggered Communications: Application to Resource  Allocation",
    "abstract": "Uncertain Multi-Agent Systems with Distributed Constrained Optimization  Missions and Event-Triggered Communications: Application to Resource  Allocation",
    "descriptor": "",
    "authors": [
      "Mohammad Saeed Sarafraz",
      "Mohammad Saleh Tavazoei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.01685"
  },
  {
    "id": "arXiv:2004.10178",
    "title": "Forecasting directional movements of stock prices for intraday trading  using LSTM and random forests",
    "abstract": "Forecasting directional movements of stock prices for intraday trading  using LSTM and random forests",
    "descriptor": "",
    "authors": [
      "Pushpendu Ghosh",
      "Ariel Neufeld",
      "Jajati Keshari Sahoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.10178"
  },
  {
    "id": "arXiv:2005.00642",
    "title": "Spatial Dependency Parsing for Semi-Structured Document Information  Extraction",
    "abstract": "Comments: Accepted at Findings of ACL 2021",
    "descriptor": "\nComments: Accepted at Findings of ACL 2021\n",
    "authors": [
      "Wonseok Hwang",
      "Jinyeong Yim",
      "Seunghyun Park",
      "Sohee Yang",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.00642"
  },
  {
    "id": "arXiv:2005.06605",
    "title": "POSNoise: An Effective Countermeasure Against Topic Biases in Authorship  Analysis",
    "abstract": "Comments: Paper has been accepted for publication in: The 16th International Conference on Availability, Reliability and Security (ARES 2021)",
    "descriptor": "\nComments: Paper has been accepted for publication in: The 16th International Conference on Availability, Reliability and Security (ARES 2021)\n",
    "authors": [
      "Oren Halvani",
      "Lukas Graner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.06605"
  },
  {
    "id": "arXiv:2006.00695",
    "title": "Random Hyperboxes",
    "abstract": "Random Hyperboxes",
    "descriptor": "",
    "authors": [
      "Thanh Tung Khuat",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.00695"
  },
  {
    "id": "arXiv:2006.08812",
    "title": "Augmented Sliced Wasserstein Distances",
    "abstract": "Comments: 28 pages, 14 figures",
    "descriptor": "\nComments: 28 pages, 14 figures\n",
    "authors": [
      "Xiongjie Chen",
      "Yongxin Yang",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08812"
  },
  {
    "id": "arXiv:2006.09365",
    "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Resampling",
    "abstract": "Comments: v3 is a major overhaul of the paper and has significantly stronger theory and experiments",
    "descriptor": "\nComments: v3 is a major overhaul of the paper and has significantly stronger theory and experiments\n",
    "authors": [
      "Sai Praneeth Karimireddy",
      "Lie He",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09365"
  },
  {
    "id": "arXiv:2006.16039",
    "title": "Game Comonads & Generalised Quantifiers",
    "abstract": "Game Comonads & Generalised Quantifiers",
    "descriptor": "",
    "authors": [
      "Adam \u00d3 Conghaile",
      "Anuj Dawar"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.16039"
  },
  {
    "id": "arXiv:2007.00062",
    "title": "Deep Feature Space: A Geometrical Perspective",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Ioannis Kansizoglou",
      "Loukas Bampis",
      "Antonios Gasteratos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.00062"
  },
  {
    "id": "arXiv:2007.00451",
    "title": "Improvement on Extrapolation of Species Abundance Distribution Across  Scales from Moments Across Scales",
    "abstract": "Comments: This work is done within 2017-2019. On the date of publishing on ArXiv, Saeid Alirezazadeh is with C4 - Cloud Computing Competence Centre (C4-UBI), Universidade da Beira Interior, Covilh\\~{a}, Portugal, and Khadijeh Alibabaei is with C-MAST Center for Mechanical and Aerospace Science and Technologies, University of Beira Interior, Covilh\\~{a}, Portugal",
    "descriptor": "\nComments: This work is done within 2017-2019. On the date of publishing on ArXiv, Saeid Alirezazadeh is with C4 - Cloud Computing Competence Centre (C4-UBI), Universidade da Beira Interior, Covilh\\~{a}, Portugal, and Khadijeh Alibabaei is with C-MAST Center for Mechanical and Aerospace Science and Technologies, University of Beira Interior, Covilh\\~{a}, Portugal\n",
    "authors": [
      "Saeid Alirezazadeh",
      "Khadijeh Alibabaei"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2007.00451"
  },
  {
    "id": "arXiv:2007.06098",
    "title": "Graph Connectivity and Single Element Recovery via Linear and OR Queries",
    "abstract": "Graph Connectivity and Single Element Recovery via Linear and OR Queries",
    "descriptor": "",
    "authors": [
      "Sepehr Assadi",
      "Deeparnab Chakrabarty",
      "Sanjeev Khanna"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.06098"
  },
  {
    "id": "arXiv:2007.08194",
    "title": "Training Interpretable Convolutional Neural Networks by Differentiating  Class-specific Filters",
    "abstract": "Comments: European Conference on Computer Vision (ECCV), 2020",
    "descriptor": "\nComments: European Conference on Computer Vision (ECCV), 2020\n",
    "authors": [
      "Haoyu Liang",
      "Zhihao Ouyang",
      "Yuyuan Zeng",
      "Hang Su",
      "Zihao He",
      "Shu-Tao Xia",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08194"
  },
  {
    "id": "arXiv:2007.11885",
    "title": "Simulation of Blockchain based Power Trading with Solar Power Prediction  in Prosumer Consortium Model",
    "abstract": "Simulation of Blockchain based Power Trading with Solar Power Prediction  in Prosumer Consortium Model",
    "descriptor": "",
    "authors": [
      "Kaung Si Thu",
      "Weerakorn Ongsakul"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.11885"
  },
  {
    "id": "arXiv:2008.03534",
    "title": "A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method  using Gaussian Processes",
    "abstract": "A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method  using Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Raphael Gautier",
      "Piyush Pandita",
      "Sayan Ghosh",
      "Dimitri Mavris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.03534"
  },
  {
    "id": "arXiv:2008.11918",
    "title": "Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual  Bandits",
    "abstract": "Comments: 36 pages, 2 figures",
    "descriptor": "\nComments: 36 pages, 2 figures\n",
    "authors": [
      "Zhimei Ren",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11918"
  },
  {
    "id": "arXiv:2009.01433",
    "title": "Algebraic Neural Networks: Stability to Deformations",
    "abstract": "Algebraic Neural Networks: Stability to Deformations",
    "descriptor": "",
    "authors": [
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.01433"
  },
  {
    "id": "arXiv:2009.01673",
    "title": "Approximate Generalized Inverses with Iterative Refinement for  $\u03b5$-Accurate Preconditioning of Singular Systems",
    "abstract": "Comments: Submitted to SIAM Journal on Matrix Analysis and Applications (SIMAX); enhanced the proofs",
    "descriptor": "\nComments: Submitted to SIAM Journal on Matrix Analysis and Applications (SIMAX); enhanced the proofs\n",
    "authors": [
      "Xiangmin Jiao",
      "Qiao Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.01673"
  },
  {
    "id": "arXiv:2009.12064",
    "title": "Attention Meets Perturbations: Robust and Interpretable Attention with  Adversarial Training",
    "abstract": "Comments: 12 pages, 4 figures. Accepted by IEEE Access on Jun. 21, 2021",
    "descriptor": "\nComments: 12 pages, 4 figures. Accepted by IEEE Access on Jun. 21, 2021\n",
    "authors": [
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.12064"
  },
  {
    "id": "arXiv:2009.14005",
    "title": "Fast Gravitational Approach for Rigid Point Set Registration with  Ordinary Differential Equations",
    "abstract": "Comments: 18 pages, 18 figures and two tables",
    "descriptor": "\nComments: 18 pages, 18 figures and two tables\n",
    "authors": [
      "Sk Aziz Ali",
      "Kerem Kahraman",
      "Christian Theobalt",
      "Didier Stricker",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2009.14005"
  },
  {
    "id": "arXiv:2010.00824",
    "title": "Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds",
    "abstract": "Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds",
    "descriptor": "",
    "authors": [
      "Lirui Wang",
      "Yu Xiang",
      "Wei Yang",
      "Arsalan Mousavian",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.00824"
  },
  {
    "id": "arXiv:2010.02255",
    "title": "Temporal Difference Uncertainties as a Signal for Exploration",
    "abstract": "Comments: 9 pages, 11 figures, 5 tables",
    "descriptor": "\nComments: 9 pages, 11 figures, 5 tables\n",
    "authors": [
      "Sebastian Flennerhag",
      "Jane X. Wang",
      "Pablo Sprechmann",
      "Francesco Visin",
      "Alexandre Galashov",
      "Steven Kapturowski",
      "Diana L. Borsa",
      "Nicolas Heess",
      "Andre Barreto",
      "Razvan Pascanu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02255"
  },
  {
    "id": "arXiv:2010.08222",
    "title": "Towards Tight Communication Lower Bounds for Distributed Optimisation",
    "abstract": "Towards Tight Communication Lower Bounds for Distributed Optimisation",
    "descriptor": "",
    "authors": [
      "Dan Alistarh",
      "Janne H. Korhonen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.08222"
  },
  {
    "id": "arXiv:2010.14100",
    "title": "A Multi-task Two-stream Spatiotemporal Convolutional Neural Network for  Convective Storm Nowcasting",
    "abstract": "Comments: 14 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 14 pages, 7 figures, 3 tables\n",
    "authors": [
      "W. Zhang",
      "H. Liu",
      "P. Li",
      "L. Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.14100"
  },
  {
    "id": "arXiv:2011.01054",
    "title": "Information-theoretic Task Selection for Meta-Reinforcement Learning",
    "abstract": "Comments: Published at NeurIPS 2020",
    "descriptor": "\nComments: Published at NeurIPS 2020\n",
    "authors": [
      "Ricardo Luna Gutierrez",
      "Matteo Leonetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01054"
  },
  {
    "id": "arXiv:2011.03813",
    "title": "MAGIC: Learning Macro-Actions for Online POMDP Planning",
    "abstract": "Comments: 9 pages (+ 2 page references, + 2 page appendix)",
    "descriptor": "\nComments: 9 pages (+ 2 page references, + 2 page appendix)\n",
    "authors": [
      "Yiyuan Lee",
      "Panpan Cai",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03813"
  },
  {
    "id": "arXiv:2011.04564",
    "title": "Reduced-Rank Regression with Operator Norm Error",
    "abstract": "Comments: 38 pages. To appear at COLT 2021",
    "descriptor": "\nComments: 38 pages. To appear at COLT 2021\n",
    "authors": [
      "Praneeth Kacham",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.04564"
  },
  {
    "id": "arXiv:2011.07893",
    "title": "Multiple Random Walks on Graphs: Mixing Few to Cover Many",
    "abstract": "Comments: 48 pages, 1 table. Theorem 3.2 has been strengthened and some parts have been reworded for clarity",
    "descriptor": "\nComments: 48 pages, 1 table. Theorem 3.2 has been strengthened and some parts have been reworded for clarity\n",
    "authors": [
      "Nicol\u00e1s Rivera",
      "Thomas Sauerwald",
      "John Sylvester"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2011.07893"
  },
  {
    "id": "arXiv:2011.08091",
    "title": "Tweet Sentiment Quantification: An Experimental Re-Evaluation",
    "abstract": "Tweet Sentiment Quantification: An Experimental Re-Evaluation",
    "descriptor": "",
    "authors": [
      "Alejandro Moreo",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08091"
  },
  {
    "id": "arXiv:2011.09831",
    "title": "Interval-valued aggregation functions based on moderate deviations  applied to Motor-Imagery-Based Brain Computer Interface",
    "abstract": "Interval-valued aggregation functions based on moderate deviations  applied to Motor-Imagery-Based Brain Computer Interface",
    "descriptor": "",
    "authors": [
      "Javier Fumanal-Idocin",
      "Zdenko Tak\u00e1\u010d",
      "Javier Fern\u00e1ndez Jose Antonio Sanz",
      "Harkaitz Goyena",
      "Ching-Teng Lin",
      "Yu-Kai Wang",
      "Humberto Bustince"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.09831"
  },
  {
    "id": "arXiv:2011.10670",
    "title": "From Recognition to Prediction: Analysis of Human Action and Trajectory  Prediction in Video",
    "abstract": "Comments: Ph.D. Thesis. Version 2: Defense. See here: this https URL",
    "descriptor": "\nComments: Ph.D. Thesis. Version 2: Defense. See here: this https URL\n",
    "authors": [
      "Junwei Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.10670"
  },
  {
    "id": "arXiv:2011.12491",
    "title": "World Model as a Graph: Learning Latent Landmarks for Planning",
    "abstract": "World Model as a Graph: Learning Latent Landmarks for Planning",
    "descriptor": "",
    "authors": [
      "Lunjun Zhang",
      "Ge Yang",
      "Bradly C. Stadie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.12491"
  },
  {
    "id": "arXiv:2011.12683",
    "title": "GraphHINGE: Learning Interaction Models of Structured Neighborhood on  Heterogeneous Information Network",
    "abstract": "Comments: TOIS (Special Issue on Graph Technologies for User Modeling and Recommendation). arXiv admin note: text overlap with arXiv:2007.00216",
    "descriptor": "\nComments: TOIS (Special Issue on Graph Technologies for User Modeling and Recommendation). arXiv admin note: text overlap with arXiv:2007.00216\n",
    "authors": [
      "Jiarui Jin",
      "Kounianhua Du",
      "Weinan Zhang",
      "Jiarui Qin",
      "Yuchen Fang",
      "Yong Yu",
      "Zheng Zhang",
      "Alexander J. Smola"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2011.12683"
  },
  {
    "id": "arXiv:2011.14196",
    "title": "Lattice Fusion Networks for Image Denoising",
    "abstract": "Lattice Fusion Networks for Image Denoising",
    "descriptor": "",
    "authors": [
      "Seyed Mohsen Hosseini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.14196"
  },
  {
    "id": "arXiv:2011.14610",
    "title": "Output Feedback Consensus for Networked Heterogeneous Nonlinear  Negative-Imaginary Systems with Free Body Motion",
    "abstract": "Comments: 8 pages, 7 figures. arXiv admin note: text overlap with arXiv:2006.13505",
    "descriptor": "\nComments: 8 pages, 7 figures. arXiv admin note: text overlap with arXiv:2006.13505\n",
    "authors": [
      "Kanghong Shi",
      "Ian R. Petersen",
      "Igor G. Vladimirov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.14610"
  },
  {
    "id": "arXiv:2012.01204",
    "title": "Unsupervised Neural Domain Adaptation for Document Image Binarization",
    "abstract": "Unsupervised Neural Domain Adaptation for Document Image Binarization",
    "descriptor": "",
    "authors": [
      "Francisco J. Castellanos",
      "Antonio-Javier Gallego",
      "Jorge Calvo-Zaragoza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01204"
  },
  {
    "id": "arXiv:2012.02409",
    "title": "When does gradient descent with logistic loss find interpolating  two-layer networks?",
    "abstract": "When does gradient descent with logistic loss find interpolating  two-layer networks?",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.02409"
  },
  {
    "id": "arXiv:2012.07621",
    "title": "Intrinsic persistent homology via density-based metric learning",
    "abstract": "Comments: 30 pages. v2: minor corrections, new applications to signal analysis and a new result about robustness to outliers added",
    "descriptor": "\nComments: 30 pages. v2: minor corrections, new applications to signal analysis and a new result about robustness to outliers added\n",
    "authors": [
      "Eugenio Borghini",
      "Ximena Fern\u00e1ndez",
      "Pablo Groisman",
      "Gabriel Mindlin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2012.07621"
  },
  {
    "id": "arXiv:2012.09194",
    "title": "Nearly tight Trotterization of interacting electrons",
    "abstract": "Comments: 58 pages, 2 figures",
    "descriptor": "\nComments: 58 pages, 2 figures\n",
    "authors": [
      "Yuan Su",
      "Hsin-Yuan Huang",
      "Earl T. Campbell"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.09194"
  },
  {
    "id": "arXiv:2012.10171",
    "title": "Which Heroes to Pick? Learning to Draft in MOBA Games with Neural  Networks and Tree Search",
    "abstract": "Which Heroes to Pick? Learning to Draft in MOBA Games with Neural  Networks and Tree Search",
    "descriptor": "",
    "authors": [
      "Sheng Chen",
      "Menghui Zhu",
      "Deheng Ye",
      "Weinan Zhang",
      "Qiang Fu",
      "Wei Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.10171"
  },
  {
    "id": "arXiv:2012.12696",
    "title": "NetworkDynamics.jl -- Composing and simulating complex networks in Julia",
    "abstract": "Comments: This article may be downloaded for personal use only. Any other use requires prior permission of the author and AIP Publishing. This article appeared in Chaos 31, 063133 (2021) and may be found at this https URL",
    "descriptor": "\nComments: This article may be downloaded for personal use only. Any other use requires prior permission of the author and AIP Publishing. This article appeared in Chaos 31, 063133 (2021) and may be found at this https URL\n",
    "authors": [
      "Michael Lindner",
      "Lucas Lincoln",
      "Fenja Drauschke",
      "Julia Monika Koulen",
      "Hans W\u00fcrfel",
      "Anton Plietzsch",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.12696"
  },
  {
    "id": "arXiv:2012.15127",
    "title": "Improving Zero-Shot Translation by Disentangling Positional Information",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Danni Liu",
      "Jan Niehues",
      "James Cross",
      "Francisco Guzm\u00e1n",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15127"
  },
  {
    "id": "arXiv:2012.15566",
    "title": "Robust Asymmetric Learning in POMDPs",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Andrew Warrington",
      "J. Wilder Lavington",
      "Adam \u015acibior",
      "Mark Schmidt",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.15566"
  },
  {
    "id": "arXiv:2012.15786",
    "title": "Conditional Generation of Temporally-ordered Event Sequences",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Shih-Ting Lin",
      "Nathanael Chambers",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15786"
  },
  {
    "id": "arXiv:2101.03988",
    "title": "Identification of COVID-19 related Fake News via Neural Stacking",
    "abstract": "Comments: Published at CONSTRAIN 2021 (AAAI)",
    "descriptor": "\nComments: Published at CONSTRAIN 2021 (AAAI)\n",
    "authors": [
      "Boshko Koloski",
      "Timen Stepi\u0161nik Perdih",
      "Senja Pollak",
      "Bla\u017e \u0160krlj"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03988"
  },
  {
    "id": "arXiv:2101.09458",
    "title": "Decoupled Exploration and Exploitation Policies for Sample-Efficient  Reinforcement Learning",
    "abstract": "Decoupled Exploration and Exploitation Policies for Sample-Efficient  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "William F. Whitney",
      "Michael Bloesch",
      "Jost Tobias Springenberg",
      "Abbas Abdolmaleki",
      "Kyunghyun Cho",
      "Martin Riedmiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09458"
  },
  {
    "id": "arXiv:2102.00050",
    "title": "Sequential prediction under log-loss and misspecification",
    "abstract": "Sequential prediction under log-loss and misspecification",
    "descriptor": "",
    "authors": [
      "Meir Feder",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00050"
  },
  {
    "id": "arXiv:2102.00102",
    "title": "Adaptive Sequential Design for a Single Time-Series",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1809.00734",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1809.00734\n",
    "authors": [
      "Ivana Malenica",
      "Aurelien Bibaut",
      "Mark J. van der Laan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00102"
  },
  {
    "id": "arXiv:2102.02642",
    "title": "Asymptotically Exact and Fast Gaussian Copula Models for Imputation of  Mixed Data Types",
    "abstract": "Comments: 20 pages, 1 figures, and 4 tables",
    "descriptor": "\nComments: 20 pages, 1 figures, and 4 tables\n",
    "authors": [
      "Benjamin Christoffersen",
      "Mark Clements",
      "Keith Humphreys",
      "Hedvig Kjellstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.02642"
  },
  {
    "id": "arXiv:2102.04822",
    "title": "Learning How to Search: Generating Effective Test Cases Through Adaptive  Fitness Function Selection",
    "abstract": "Comments: Draft currently under revision",
    "descriptor": "\nComments: Draft currently under revision\n",
    "authors": [
      "Hussein Almulla",
      "Gregory Gay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.04822"
  },
  {
    "id": "arXiv:2102.04998",
    "title": "When does gradient descent with logistic loss interpolate using deep  networks with smoothed ReLU activations?",
    "abstract": "When does gradient descent with logistic loss interpolate using deep  networks with smoothed ReLU activations?",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.04998"
  },
  {
    "id": "arXiv:2102.06900",
    "title": "Segmenting two-dimensional structures with strided tensor networks",
    "abstract": "Comments: Accepted to be presented at the 27th international conference on Information Processing in Medical Imaging (IPMI-2021), Bornholm, Denmark. Source code at this https URL Version 2: Minor fixes to notation in Eq.1 and typos",
    "descriptor": "\nComments: Accepted to be presented at the 27th international conference on Information Processing in Medical Imaging (IPMI-2021), Bornholm, Denmark. Source code at this https URL Version 2: Minor fixes to notation in Eq.1 and typos\n",
    "authors": [
      "Raghavendra Selvan",
      "Erik B Dam",
      "Jens Petersen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06900"
  },
  {
    "id": "arXiv:2102.07627",
    "title": "A first look into the carbon footprint of federated learning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.06537",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.06537\n",
    "authors": [
      "Xinchi Qiu",
      "Titouan Parcollet",
      "Javier Fernandez-Marques",
      "Pedro Porto Buarque de Gusmao",
      "Daniel J. Beutel",
      "Taner Topal",
      "Akhil Mathur",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.07627"
  },
  {
    "id": "arXiv:2102.08453",
    "title": "Towards the Right Kind of Fairness in AI",
    "abstract": "Towards the Right Kind of Fairness in AI",
    "descriptor": "",
    "authors": [
      "Boris Ruf",
      "Marcin Detyniecki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.08453"
  },
  {
    "id": "arXiv:2102.10182",
    "title": "Keyboards as a new model of computation",
    "abstract": "Comments: Two versions, in French and in English",
    "descriptor": "\nComments: Two versions, in French and in English\n",
    "authors": [
      "Yoan G\u00e9ran",
      "Bastien Laboureix",
      "Corto Mascle",
      "Valentin D. Richard"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.10182"
  },
  {
    "id": "arXiv:2102.10253",
    "title": "Safety Embedded Control of Nonlinear Systems via Barrier States",
    "abstract": "Comments: Updates: Corrected typos and added clarifying equations for the examples. Added references for optimal safe control work in the literature",
    "descriptor": "\nComments: Updates: Corrected typos and added clarifying equations for the examples. Added references for optimal safe control work in the literature\n",
    "authors": [
      "Hassan Almubarak",
      "Nader Sadegh",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.10253"
  },
  {
    "id": "arXiv:2102.10424",
    "title": "GIST: Distributed Training for Large-Scale Graph Convolutional Networks",
    "abstract": "Comments: 18 pages, 4 figures, pre-print under review",
    "descriptor": "\nComments: 18 pages, 4 figures, pre-print under review\n",
    "authors": [
      "Cameron R. Wolfe",
      "Jingkang Yang",
      "Arindam Chowdhury",
      "Chen Dun",
      "Artun Bayer",
      "Santiago Segarra",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.10424"
  },
  {
    "id": "arXiv:2102.10456",
    "title": "Decaying Clipping Range in Proximal Policy Optimization",
    "abstract": "Decaying Clipping Range in Proximal Policy Optimization",
    "descriptor": "",
    "authors": [
      "M\u00f3nika Farsang",
      "Luca Szegletes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.10456"
  },
  {
    "id": "arXiv:2102.11169",
    "title": "Recent Advances in Fully Dynamic Graph Algorithms",
    "abstract": "Recent Advances in Fully Dynamic Graph Algorithms",
    "descriptor": "",
    "authors": [
      "Kathrin Hanauer",
      "Monika Henzinger",
      "Christian Schulz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.11169"
  },
  {
    "id": "arXiv:2102.11932",
    "title": "On Meritocracy in Optimal Set Selection",
    "abstract": "On Meritocracy in Optimal Set Selection",
    "descriptor": "",
    "authors": [
      "Thomas Kleine Buening",
      "Meirav Segal",
      "Debabrota Basu",
      "Christos Dimitrakakis",
      "Anne-Marie George"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11932"
  },
  {
    "id": "arXiv:2102.12871",
    "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Han Shi",
      "Jiahui Gao",
      "Xiaozhe Ren",
      "Hang Xu",
      "Xiaodan Liang",
      "Zhenguo Li",
      "James T. Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12871"
  },
  {
    "id": "arXiv:2103.01089",
    "title": "A Biased Graph Neural Network Sampler with Near-Optimal Regret",
    "abstract": "Comments: 25 pages, 15 figures",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Qingru Zhang",
      "David Wipf",
      "Quan Gan",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01089"
  },
  {
    "id": "arXiv:2103.01209",
    "title": "Generative Adversarial Transformers",
    "abstract": "Comments: Published as a conference paper at ICML 2021",
    "descriptor": "\nComments: Published as a conference paper at ICML 2021\n",
    "authors": [
      "Drew A. Hudson",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01209"
  },
  {
    "id": "arXiv:2103.06620",
    "title": "Topological Data Analysis of Korean Music in Jeongganbo: A Cycle  Structure",
    "abstract": "Topological Data Analysis of Korean Music in Jeongganbo: A Cycle  Structure",
    "descriptor": "",
    "authors": [
      "Mai Lan Tran",
      "Changbom Park",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computational Geometry (cs.CG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.06620"
  },
  {
    "id": "arXiv:2103.08364",
    "title": "Towards the evaluation of automatic simultaneous speech translation from  a communicative perspective",
    "abstract": "Comments: Accepted to IWSLT 2021",
    "descriptor": "\nComments: Accepted to IWSLT 2021\n",
    "authors": [
      "Claudio Fantinuoli",
      "Bianca Prandi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.08364"
  },
  {
    "id": "arXiv:2103.08782",
    "title": "Data to Controller for Nonlinear Systems: An Approximate Solution",
    "abstract": "Comments: in IEEE Control Systems Letters, 2021",
    "descriptor": "\nComments: in IEEE Control Systems Letters, 2021\n",
    "authors": [
      "Johannes N. Hendriks",
      "James R. Z. Holdsworth",
      "Adrian G. Wills",
      "Thomas B. Schon",
      "Brett Ninness"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08782"
  },
  {
    "id": "arXiv:2103.09953",
    "title": "Scattering and inverse scattering for the AKNS system: A rational  function approach",
    "abstract": "Scattering and inverse scattering for the AKNS system: A rational  function approach",
    "descriptor": "",
    "authors": [
      "Thomas Trogdon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.09953"
  },
  {
    "id": "arXiv:2103.11135",
    "title": "High Resolution Face Editing with Masked GAN Latent Code Optimization",
    "abstract": "Comments: The updated paper will be submitted to IEEE Transactions on Image Processing. Added more qualitative and quantitative results to the main part of the paper. This version now also includes the supplementary material",
    "descriptor": "\nComments: The updated paper will be submitted to IEEE Transactions on Image Processing. Added more qualitative and quantitative results to the main part of the paper. This version now also includes the supplementary material\n",
    "authors": [
      "Martin Pernu\u0161",
      "Vitomir \u0160truc",
      "Simon Dobri\u0161ek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11135"
  },
  {
    "id": "arXiv:2103.15181",
    "title": "The DoF Region of Order-(K-1) Messages for the K-user MIMO Broadcast  Channel with Delayed CSIT",
    "abstract": "Comments: Accpeted by IEEE/CIC International Conference on Communications in China, 2021",
    "descriptor": "\nComments: Accpeted by IEEE/CIC International Conference on Communications in China, 2021\n",
    "authors": [
      "Tong Zhang",
      "Shuai Wang",
      "Taotao Wang",
      "Rui Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.15181"
  },
  {
    "id": "arXiv:2103.15722",
    "title": "Transformer-based end-to-end speech recognition with residual  Gaussian-based self-attention",
    "abstract": "Comments: Accepted to INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Chengdong Liang",
      "Menglong Xu",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.15722"
  },
  {
    "id": "arXiv:2104.00101",
    "title": "High-order Barrier Functions: Robustness, Safety and  Performance-Critical Control",
    "abstract": "Comments: An updated version of a paper in IEEE TAC",
    "descriptor": "\nComments: An updated version of a paper in IEEE TAC\n",
    "authors": [
      "Xiao Tan",
      "Wenceslao Shaw Cortez",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.00101"
  },
  {
    "id": "arXiv:2104.01061",
    "title": "Information Geometry and Classical Cram\u00e9r-Rao Type Inequalities",
    "abstract": "Comments: 34 pages, 2 figures, 1 table. arXiv admin note: text overlap with arXiv:2001.04769",
    "descriptor": "\nComments: 34 pages, 2 figures, 1 table. arXiv admin note: text overlap with arXiv:2001.04769\n",
    "authors": [
      "Kumar Vijay Mishra",
      "M. Ashok Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Differential Geometry (math.DG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.01061"
  },
  {
    "id": "arXiv:2104.07085",
    "title": "Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary  Layers in Deep Neural Networks",
    "abstract": "Comments: The paper has been accepted to CVPR 2021 BiVision Workshop. We notice the final Conv2D is also a 1x1 convolution layer so we update the result with changing the layer in v2. In v3, we update citation 37 because its authorship changes",
    "descriptor": "\nComments: The paper has been accepted to CVPR 2021 BiVision Workshop. We notice the final Conv2D is also a 1x1 convolution layer so we update the result with changing the layer in v2. In v3, we update citation 37 because its authorship changes\n",
    "authors": [
      "Hongyi Pan",
      "Diaa Dabawi",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.07085"
  },
  {
    "id": "arXiv:2104.07388",
    "title": "Conditional independence for pretext task selection in Self-supervised  speech representation learning",
    "abstract": "Comments: 5 pages, Accepted for presentation at Interspeech2021",
    "descriptor": "\nComments: 5 pages, Accepted for presentation at Interspeech2021\n",
    "authors": [
      "Salah Zaiem",
      "Titouan Parcollet",
      "Slim Essid"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.07388"
  },
  {
    "id": "arXiv:2104.07768",
    "title": "Trust but Verify: Cryptographic Data Privacy for Mobility Management",
    "abstract": "Trust but Verify: Cryptographic Data Privacy for Mobility Management",
    "descriptor": "",
    "authors": [
      "Matthew Tsao",
      "Kaidi Yang",
      "Stephen Zoepf",
      "Marco Pavone"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.07768"
  },
  {
    "id": "arXiv:2104.08581",
    "title": "Color Variants Identification in Fashion e-commerce via Contrastive  Self-Supervised Representation Learning",
    "abstract": "Comments: Accepted In IJCAI-21 Weakly Supervised Representation Learning (WSRL) workshop",
    "descriptor": "\nComments: Accepted In IJCAI-21 Weakly Supervised Representation Learning (WSRL) workshop\n",
    "authors": [
      "Ujjal Kr Dutta",
      "Sandeep Repakula",
      "Maulik Parmar",
      "Abhinav Ravi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08581"
  },
  {
    "id": "arXiv:2104.09376",
    "title": "Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced  training",
    "abstract": "Comments: 23 pages, 13 figures, fixed typos, add authors",
    "descriptor": "\nComments: 23 pages, 13 figures, fixed typos, add authors\n",
    "authors": [
      "Chuxiong Sun",
      "Hongming Gu",
      "Jie Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.09376"
  },
  {
    "id": "arXiv:2104.12876",
    "title": "Continual Distributed Learning for Crisis Management",
    "abstract": "Comments: 6 pages, 3 figures, Accepted at 3rd Workshop on Continual and Multimodal Learning for Internet of Things and Presented at IEEESBM Manipal Paper Presentation",
    "descriptor": "\nComments: 6 pages, 3 figures, Accepted at 3rd Workshop on Continual and Multimodal Learning for Internet of Things and Presented at IEEESBM Manipal Paper Presentation\n",
    "authors": [
      "Aman Priyanshu",
      "Mudit Sinha",
      "Shreyans Mehta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.12876"
  },
  {
    "id": "arXiv:2104.13853",
    "title": "Learning deep autoregressive models for hierarchical data",
    "abstract": "Learning deep autoregressive models for hierarchical data",
    "descriptor": "",
    "authors": [
      "Carl R. Andersson",
      "Niklas Wahlstr\u00f6m",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.13853"
  },
  {
    "id": "arXiv:2105.01563",
    "title": "Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based  Action Recognition",
    "abstract": "Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based  Action Recognition",
    "descriptor": "",
    "authors": [
      "Zhenyue Qin",
      "Yang Liu",
      "Pan Ji",
      "Dongwoo Kim",
      "Lei Wang",
      "Bob McKay",
      "Saeed Anwar",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01563"
  },
  {
    "id": "arXiv:2105.07197",
    "title": "Are Convolutional Neural Networks or Transformers more like human  vision?",
    "abstract": "Comments: Accepted at CogSci 2021. Source code and fine-tuned models are available at this https URL",
    "descriptor": "\nComments: Accepted at CogSci 2021. Source code and fine-tuned models are available at this https URL\n",
    "authors": [
      "Shikhar Tuli",
      "Ishita Dasgupta",
      "Erin Grant",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07197"
  },
  {
    "id": "arXiv:2105.12182",
    "title": "Self-Calibration of the Offset Between GPS and Semantic Map Frames for  Robust Localization",
    "abstract": "Comments: Accepted for publication in CRV 2021; corrected reference 4",
    "descriptor": "\nComments: Accepted for publication in CRV 2021; corrected reference 4\n",
    "authors": [
      "Wei-Kang Tseng",
      "Angela P. Schoellig",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.12182"
  },
  {
    "id": "arXiv:2105.12247",
    "title": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg",
    "abstract": "Comments: Paper Accepted in the Weakly Supervised Representation Learning Workshop, IJCAI 2021 (IJCAI2021-WSRL)",
    "descriptor": "\nComments: Paper Accepted in the Weakly Supervised Representation Learning Workshop, IJCAI 2021 (IJCAI2021-WSRL)\n",
    "authors": [
      "Sayan Nag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12247"
  },
  {
    "id": "arXiv:2105.13010",
    "title": "An error analysis of generative adversarial networks for learning  distributions",
    "abstract": "An error analysis of generative adversarial networks for learning  distributions",
    "descriptor": "",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Zhen Li",
      "Shiao Liu",
      "Yang Wang",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13010"
  },
  {
    "id": "arXiv:2105.13807",
    "title": "Gym-$\u03bc$RTS: Toward Affordable Full Game Real-time Strategy Games  Research with Deep Reinforcement Learning",
    "abstract": "Comments: Accepted to IEEE Conference of Games (COG) 2021",
    "descriptor": "\nComments: Accepted to IEEE Conference of Games (COG) 2021\n",
    "authors": [
      "Shengyi Huang",
      "Santiago Onta\u00f1\u00f3n",
      "Chris Bamford",
      "Lukasz Grela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13807"
  },
  {
    "id": "arXiv:2105.14152",
    "title": "Radar Odometry Combining Probabilistic Estimation and Unsupervised  Feature Learning",
    "abstract": "Comments: Accepted to Robotics Science and Systems 2021",
    "descriptor": "\nComments: Accepted to Robotics Science and Systems 2021\n",
    "authors": [
      "Keenan Burnett",
      "David J. Yoon",
      "Angela P. Schoellig",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14152"
  },
  {
    "id": "arXiv:2106.01708",
    "title": "Semi-supervised Learning with Missing Values Imputation",
    "abstract": "Semi-supervised Learning with Missing Values Imputation",
    "descriptor": "",
    "authors": [
      "Buliao Huang",
      "Yunhui Zhu",
      "Muhammad Usman",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01708"
  },
  {
    "id": "arXiv:2106.03039",
    "title": "Multi-facet Contextual Bandits: A Neural Network Perspective",
    "abstract": "Comments: KDD'21, 12 pages",
    "descriptor": "\nComments: KDD'21, 12 pages\n",
    "authors": [
      "Yikun Ban",
      "Jingrui He",
      "Curtiss B. Cook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03039"
  },
  {
    "id": "arXiv:2106.04315",
    "title": "Learning Riemannian Manifolds for Geodesic Motion Skills",
    "abstract": "Learning Riemannian Manifolds for Geodesic Motion Skills",
    "descriptor": "",
    "authors": [
      "Hadi Beik-Mohammadi",
      "S\u00f8ren Hauberg",
      "Georgios Arvanitidis",
      "Gerhard Neumann",
      "Leonel Rozo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04315"
  },
  {
    "id": "arXiv:2106.05037",
    "title": "A general approach for Explanations in terms of Middle Level Features",
    "abstract": "A general approach for Explanations in terms of Middle Level Features",
    "descriptor": "",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgr\u00f2",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05037"
  },
  {
    "id": "arXiv:2106.06654",
    "title": "Disrupting Model Training with Adversarial Shortcuts",
    "abstract": "Disrupting Model Training with Adversarial Shortcuts",
    "descriptor": "",
    "authors": [
      "Ivan Evtimov",
      "Ian Covert",
      "Aditya Kusupati",
      "Tadayoshi Kohno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06654"
  },
  {
    "id": "arXiv:2106.07989",
    "title": "Compression Implies Generalization",
    "abstract": "Comments: There is a bug in the proof and that we are working on fixing it. No replacement paper at this point",
    "descriptor": "\nComments: There is a bug in the proof and that we are working on fixing it. No replacement paper at this point\n",
    "authors": [
      "Allan Gr\u00f8nlund",
      "Mikael H\u00f8gsgaard",
      "Lior Kamma",
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07989"
  },
  {
    "id": "arXiv:2106.08126",
    "title": "Dialectal Speech Recognition and Translation of Swiss German Speech to  Standard German Text: Microsoft's Submission to SwissText 2021",
    "abstract": "Comments: to be published in SwissText 2021",
    "descriptor": "\nComments: to be published in SwissText 2021\n",
    "authors": [
      "Yuriy Arabskyy",
      "Aashish Agarwal",
      "Subhadeep Dey",
      "Oscar Koller"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08126"
  },
  {
    "id": "arXiv:2106.08253",
    "title": "Syntax Guided Neural Program Repair",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qihao Zhu",
      "Zeyu Sun",
      "Yuan-an Xiao",
      "Wenjie Zhang",
      "Kang Yuan",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08253"
  },
  {
    "id": "arXiv:2106.09330",
    "title": "A Simple Generative Network",
    "abstract": "A Simple Generative Network",
    "descriptor": "",
    "authors": [
      "Daniel N. Nissani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09330"
  },
  {
    "id": "arXiv:2106.09517",
    "title": "Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D  Salient Object Detection",
    "abstract": "Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D  Salient Object Detection",
    "descriptor": "",
    "authors": [
      "Guangyu Ren",
      "Tania Stathaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09517"
  },
  {
    "id": "arXiv:2106.09997",
    "title": "SPBERT: An Efficient Pre-training BERT on SPARQL Queries for Question  Answering over Knowledge Graphs",
    "abstract": "SPBERT: An Efficient Pre-training BERT on SPARQL Queries for Question  Answering over Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Hieu Tran",
      "Long Phan",
      "James Anibal",
      "Binh T. Nguyen",
      "Truong-Son Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09997"
  },
  {
    "id": "arXiv:2106.10026",
    "title": "EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action  Recognition 2021: Team M3EM Technical Report",
    "abstract": "EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action  Recognition 2021: Team M3EM Technical Report",
    "descriptor": "",
    "authors": [
      "Lijin Yang",
      "Yifei Huang",
      "Yusuke Sugano",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10026"
  },
  {
    "id": "arXiv:2106.10420",
    "title": "Finding critical edges in complex networks through local information",
    "abstract": "Finding critical edges in complex networks through local information",
    "descriptor": "",
    "authors": [
      "En-Yu Yu",
      "Yan Fu",
      "Jun-Lin Zhou",
      "Hong-Liang Sun",
      "Duan-Bing Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10420"
  },
  {
    "id": "arXiv:2106.10712",
    "title": "Solving for best inhomogeneous linear approximations",
    "abstract": "Solving for best inhomogeneous linear approximations",
    "descriptor": "",
    "authors": [
      "Avraham Bourla"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10712"
  },
  {
    "id": "arXiv:2106.10903",
    "title": "Infinite families of linear codes supporting more $t$-designs",
    "abstract": "Comments: 26 pages, 4 tables",
    "descriptor": "\nComments: 26 pages, 4 tables\n",
    "authors": [
      "Qianqian Yan",
      "Junling Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10903"
  },
  {
    "id": "arXiv:2106.10978",
    "title": "Attribute Selection using Contranominal Scales",
    "abstract": "Comments: 17 pages, 2 figures, 3 tables, 1 algorithm, 26th International Conference on Conceptual Structures",
    "descriptor": "\nComments: 17 pages, 2 figures, 3 tables, 1 algorithm, 26th International Conference on Conceptual Structures\n",
    "authors": [
      "Dominik D\u00fcrrschnabel",
      "Maren Koyda",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10978"
  },
  {
    "id": "arXiv:2106.11251",
    "title": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xiao Wang",
      "Craig Macdonald",
      "Nicola Tonellotto",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11251"
  },
  {
    "id": "arXiv:2106.11516",
    "title": "SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure",
    "abstract": "Comments: 8 pages. Accepted by ICRA-2021",
    "descriptor": "\nComments: 8 pages. Accepted by ICRA-2021\n",
    "authors": [
      "Lin Li",
      "Xin Kong",
      "Xiangrui Zhao",
      "Wanlong Li",
      "Feng Wen",
      "Hongbo Zhang",
      "Yong Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11516"
  },
  {
    "id": "arXiv:2106.11562",
    "title": "SSUL: Semantic Segmentation with Unknown Label for Exemplar-based  Class-Incremental Learning",
    "abstract": "SSUL: Semantic Segmentation with Unknown Label for Exemplar-based  Class-Incremental Learning",
    "descriptor": "",
    "authors": [
      "Sungmin Cha",
      "Beomyoung Kim",
      "Youngjoon Yoo",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11562"
  },
  {
    "id": "arXiv:2106.11595",
    "title": "Reinforcement Learning for Physical Layer Communications",
    "abstract": "Comments: Machine Learning and Wireless Communications, In press",
    "descriptor": "\nComments: Machine Learning and Wireless Communications, In press\n",
    "authors": [
      "Philippe Mary",
      "Visa Koivunen",
      "Christophe Moy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11595"
  },
  {
    "id": "arXiv:2106.11756",
    "title": "Trinity: A No-Code AI platform for complex spatial datasets",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "C.V.Krishnakumar Iyer",
      "Feili Hou",
      "Henry Wang",
      "Yonghong Wang",
      "Kay Oh",
      "Swetava Ganguli",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11756"
  },
  {
    "id": "arXiv:2106.12387",
    "title": "Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to  Data Imbalance in Deep Learning Based Segmentation",
    "abstract": "Comments: MICCAI 2021 conference",
    "descriptor": "\nComments: MICCAI 2021 conference\n",
    "authors": [
      "Esther Puyol-Anton",
      "Bram Ruijsink",
      "Stefan K. Piechnik",
      "Stefan Neubauer",
      "Steffen E. Petersen",
      "Reza Razavi",
      "Andrew P. King"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12387"
  },
  {
    "id": "arXiv:2106.12570",
    "title": "Learning Multimodal VAEs through Mutual Supervision",
    "abstract": "Learning Multimodal VAEs through Mutual Supervision",
    "descriptor": "",
    "authors": [
      "Tom Joy",
      "Yuge Shi",
      "Philip H.S. Torr",
      "Tom Rainforth",
      "Sebastian M. Schmon",
      "N. Siddharth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12570"
  },
  {
    "id": "arXiv:2106.12689",
    "title": "A Unifying Modeling Abstraction for Infinite-Dimensional Optimization",
    "abstract": "A Unifying Modeling Abstraction for Infinite-Dimensional Optimization",
    "descriptor": "",
    "authors": [
      "Joshua L. Pulsipher",
      "Weiqi Zhang",
      "Tyler J. Hongisto",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12689"
  },
  {
    "id": "arXiv:2106.12900",
    "title": "Long-term Cross Adversarial Training: A Robust Meta-learning Method for  Few-shot Classification Tasks",
    "abstract": "Comments: Accepted by the ICML 2021 Workshop on A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning(this https URL)",
    "descriptor": "\nComments: Accepted by the ICML 2021 Workshop on A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning(this https URL)\n",
    "authors": [
      "Fan Liu",
      "Shuyu Zhao",
      "Xuelong Dai",
      "Bin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12900"
  },
  {
    "id": "arXiv:2106.13061",
    "title": "Fea2Fea: Exploring Structural Feature Correlations via Graph Neural  Networks",
    "abstract": "Comments: Submitted to ECML-PKDD 2021 Graph Embedding and Mining(GEM) workshop; fixed typos in v1",
    "descriptor": "\nComments: Submitted to ECML-PKDD 2021 Graph Embedding and Mining(GEM) workshop; fixed typos in v1\n",
    "authors": [
      "Jiaqing Xie",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13061"
  },
  {
    "id": "arXiv:2106.13353",
    "title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with  Language Models",
    "abstract": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with  Language Models",
    "descriptor": "",
    "authors": [
      "Robert L. Logan IV",
      "Ivana Bala\u017eevi\u0107",
      "Eric Wallace",
      "Fabio Petroni",
      "Sameer Singh",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13353"
  },
  {
    "id": "arXiv:2106.14007",
    "title": "Scalable Feature Subset Selection for Big Data using Parallel Hybrid  Evolutionary Algorithm based Wrapper in Apache Spark",
    "abstract": "Comments: 27 pages, 11 Tables and 5 figures",
    "descriptor": "\nComments: 27 pages, 11 Tables and 5 figures\n",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Pisipati Radhakrishna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.14007"
  },
  {
    "id": "arXiv:2106.14033",
    "title": "BiX-NAS: Searching Efficient Bi-directional Architecture for Medical  Image Segmentation",
    "abstract": "Comments: MICCAI2021",
    "descriptor": "\nComments: MICCAI2021\n",
    "authors": [
      "Xinyi Wang",
      "Tiange Xiang",
      "Chaoyi Zhang",
      "Yang Song",
      "Dongnan Liu",
      "Heng Huang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14033"
  },
  {
    "id": "arXiv:2106.14104",
    "title": "An Image Classifier Can Suffice For Video Understanding",
    "abstract": "An Image Classifier Can Suffice For Video Understanding",
    "descriptor": "",
    "authors": [
      "Quanfu Fan",
      "Chun-Fu",
      "Chen",
      "Rameswar Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14104"
  },
  {
    "id": "arXiv:2106.14334",
    "title": "Noisy-MAPPO: Noisy Advantage Values for Cooperative Multi-agent  Actor-Critic methods",
    "abstract": "Comments: fix math errors",
    "descriptor": "\nComments: fix math errors\n",
    "authors": [
      "Siyue Hu",
      "Jian Hu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.14334"
  },
  {
    "id": "arXiv:2106.14396",
    "title": "Single RGB-D Camera Teleoperation for General Robotic Manipulation",
    "abstract": "Single RGB-D Camera Teleoperation for General Robotic Manipulation",
    "descriptor": "",
    "authors": [
      "Quan Vuong",
      "Yuzhe Qin",
      "Runlin Guo",
      "Xiaolong Wang",
      "Hao Su",
      "Henrik Christensen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14396"
  },
  {
    "id": "arXiv:2106.14559",
    "title": "QM/MM Methods for Crystalline Defects. Part 3: Machine-Learned  Interatomic Potentials",
    "abstract": "Comments: 32 pages, 5 figures",
    "descriptor": "\nComments: 32 pages, 5 figures\n",
    "authors": [
      "Huajie Chen",
      "Christoph Ortner",
      "Yangshuai Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.14559"
  },
  {
    "id": "arXiv:2106.14879",
    "title": "Explicit Clothing Modeling for an Animatable Full-Body Avatar",
    "abstract": "Explicit Clothing Modeling for an Animatable Full-Body Avatar",
    "descriptor": "",
    "authors": [
      "Donglai Xiang",
      "Fabian Andres Prada",
      "Timur Bagautdinov",
      "Weipeng Xu",
      "Yuan Dong",
      "He Wen",
      "Jessica Hodgins",
      "Chenglei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.14879"
  },
  {
    "id": "arXiv:2106.14950",
    "title": "A Hybrid High-Order method for incompressible flows of non-Newtonian  fluids with power-like convective behaviour",
    "abstract": "Comments: 33 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 33 pages, 3 figures, 3 tables\n",
    "authors": [
      "Daniel Castanon Quiroz",
      "Daniele Antonio Di Pietro",
      "Andr\u00e9 Harnist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.14950"
  },
  {
    "id": "arXiv:2106.15015",
    "title": "A Survey on Trust Metrics for Autonomous Robotic Systems",
    "abstract": "A Survey on Trust Metrics for Autonomous Robotic Systems",
    "descriptor": "",
    "authors": [
      "Vincenzo DiLuoffo",
      "William R.Michalson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.15015"
  },
  {
    "id": "arXiv:2106.15314",
    "title": "The cityseer Python package for pedestrian-scale network-based urban  analysis",
    "abstract": "Comments: Adds arXiv identifiers / references for associated papers",
    "descriptor": "\nComments: Adds arXiv identifiers / references for associated papers\n",
    "authors": [
      "Gareth D. Simons"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15314"
  },
  {
    "id": "arXiv:2106.15323",
    "title": "Face Identification Proficiency Test Designed Using Item Response Theory",
    "abstract": "Comments: 17 pages (including references), 7 figures",
    "descriptor": "\nComments: 17 pages (including references), 7 figures\n",
    "authors": [
      "G\u00e9raldine Jeckeln",
      "Ying Hu",
      "Jacqueline G. Cavazos",
      "Amy N. Yates",
      "Carina A. Hahn",
      "Larry Tang",
      "P. Jonathon Phillips",
      "Alice J. O'Toole"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.15323"
  },
  {
    "id": "arXiv:2106.15366",
    "title": "TANet++: Triple Attention Network with Filtered Pointcloud on 3D  Detection",
    "abstract": "Comments: 3pages, 2 figures",
    "descriptor": "\nComments: 3pages, 2 figures\n",
    "authors": [
      "Cong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15366"
  },
  {
    "id": "arXiv:2106.15409",
    "title": "Efficient Realistic Data Generation Framework leveraging Deep  Learning-based Human Digitization",
    "abstract": "Efficient Realistic Data Generation Framework leveraging Deep  Learning-based Human Digitization",
    "descriptor": "",
    "authors": [
      "C. Symeonidis",
      "P. Nousi",
      "P. Tosidis",
      "K. Tsampazis",
      "N. Passalis",
      "A. Tefas",
      "N. Nikolaidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15409"
  },
  {
    "id": "arXiv:2106.15754",
    "title": "Looking Outside the Window: Wider-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "abstract": "Looking Outside the Window: Wider-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Lei Ding",
      "Dong Lin",
      "Shaofu Lin",
      "Jing Zhang",
      "Xiaojie Cui",
      "Yuebin Wang",
      "Hao Tang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15754"
  },
  {
    "id": "arXiv:2106.16009",
    "title": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "abstract": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "descriptor": "",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16009"
  },
  {
    "id": "arXiv:2106.16067",
    "title": "Leveraging Team Dynamics to Predict Open-source Software Projects'  Susceptibility to Social Engineering Attacks",
    "abstract": "Leveraging Team Dynamics to Predict Open-source Software Projects'  Susceptibility to Social Engineering Attacks",
    "descriptor": "",
    "authors": [
      "Huascar Sanchez",
      "Daniela Oliveira",
      "Deborah Shands",
      "Luiz Giovanini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.16067"
  },
  {
    "id": "arXiv:2106.16093",
    "title": "Multi-Source domain adaptation via supervised contrastive learning and  confident consistency regularization",
    "abstract": "Multi-Source domain adaptation via supervised contrastive learning and  confident consistency regularization",
    "descriptor": "",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16093"
  },
  {
    "id": "arXiv:2106.16116",
    "title": "PSD Representations for Effective Probability Models",
    "abstract": "Comments: 52 pages, 3 figures",
    "descriptor": "\nComments: 52 pages, 3 figures\n",
    "authors": [
      "Alessandro Rudi",
      "Carlo Ciliberto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16116"
  },
  {
    "id": "arXiv:2106.16204",
    "title": "Combinatorial generation via permutation languages. IV. Elimination  trees",
    "abstract": "Combinatorial generation via permutation languages. IV. Elimination  trees",
    "descriptor": "",
    "authors": [
      "Jean Cardinal",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16204"
  },
  {
    "id": "arXiv:2106.16225",
    "title": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps",
    "abstract": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps",
    "descriptor": "",
    "authors": [
      "Sidak Pal Singh",
      "Gregor Bachmann",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16225"
  },
  {
    "id": "arXiv:2106.16239",
    "title": "Fixed points of monotonic and (weakly) scalable neural networks",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Tomasz Piotrowski",
      "Renato L. G. Cavalcante"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16239"
  }
]
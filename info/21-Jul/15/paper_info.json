[
  {
    "id": "arXiv:2107.06302",
    "title": "Examining the Social Context of Alcohol Drinking in Young Adults with  Smartphone Sensing",
    "abstract": "According to prior work, the type of relationship between the person\nconsuming alcohol and others in the surrounding (friends, family, spouse,\netc.), and the number of those people (alone, with one person, with a group,\netc.) are related to many aspects of alcohol consumption, such as the drinking\namount, location, motives, and mood. Even though the social context is\nrecognized as an important aspect that influences the drinking behavior of\nyoung adults in alcohol research, relatively little work has been conducted in\nsmartphone sensing research on this topic. In this study, we analyze the\nweekend nightlife drinking behavior of 241 young adults in Switzerland, using a\ndataset consisting of self-reports and passive smartphone sensing data over a\nperiod of three months. Using multiple statistical analyses, we show that\nfeatures from modalities such as accelerometer, location, application usage,\nbluetooth, and proximity could be informative about different social contexts\nof drinking. We define and evaluate seven social context inference tasks using\nsmartphone sensing data, obtaining accuracies of the range 75%-86% in four\ntwo-class and three three-class inferences. Further, we discuss the possibility\nof identifying the sex composition of a group of friends using smartphone\nsensor data with accuracies over 70%. The results are encouraging towards (a)\nsupporting future interventions on alcohol consumption that incorporate users'\nsocial context more meaningfully, and (b) reducing the need for user\nself-reports when creating drink logs.",
    "descriptor": "\nComments: to be published in the proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) - ACM UbiComp 2021\n",
    "authors": [
      "Lakmal Meegahapola",
      "Florian Labhart",
      "Thanh-Trung Phan",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06302"
  },
  {
    "id": "arXiv:2107.06304",
    "title": "Deep Neural Networks are Surprisingly Reversible: A Baseline for  Zero-Shot Inversion",
    "abstract": "Understanding the behavior and vulnerability of pre-trained deep neural\nnetworks (DNNs) can help to improve them. Analysis can be performed via\nreversing the network's flow to generate inputs from internal representations.\nMost existing work relies on priors or data-intensive optimization to invert a\nmodel, yet struggles to scale to deep architectures and complex datasets. This\npaper presents a zero-shot direct model inversion framework that recovers the\ninput to the trained model given only the internal representation. The crux of\nour method is to inverse the DNN in a divide-and-conquer manner while\nre-syncing the inverted layers via cycle-consistency guidance with the help of\nsynthesized data. As a result, we obtain a single feed-forward model capable of\ninversion with a single forward pass without seeing any real data of the\noriginal task. With the proposed approach, we scale zero-shot direct inversion\nto deep architectures and complex datasets. We empirically show that modern\nclassification models on ImageNet can, surprisingly, be inverted, allowing an\napproximate recovery of the original 224x224px images from a representation\nafter more than 20 layers. Moreover, inversion of generators in GANs unveils\nlatent code of a given synthesized face image at 128x128px, which can even, in\nturn, improve defective synthesized images from GANs.",
    "descriptor": "\nComments: A new inversion method to reverse neural networks and get input from intermediate feature maps. Works without original data for classifiers and GANs\n",
    "authors": [
      "Xin Dong",
      "Hongxu Yin",
      "Jose M. Alvarez",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06304"
  },
  {
    "id": "arXiv:2107.06307",
    "title": "HDMapNet: An Online HD Map Construction and Evaluation Framework",
    "abstract": "High-definition map (HD map) construction is a crucial problem for autonomous\ndriving. This problem typically involves collecting high-quality point clouds,\nfusing multiple point clouds of the same scene, annotating map elements, and\nupdating maps constantly. This pipeline, however, requires a vast amount of\nhuman efforts and resources which limits its scalability. Additionally,\ntraditional HD maps are coupled with centimeter-level accurate localization\nwhich is unreliable in many scenarios. In this paper, we argue that online map\nlearning, which dynamically constructs the HD maps based on local sensor\nobservations, is a more scalable way to provide semantic and geometry priors to\nself-driving vehicles than traditional pre-annotated HD maps. Meanwhile, we\nintroduce an online map learning method, titled HDMapNet. It encodes image\nfeatures from surrounding cameras and/or point clouds from LiDAR, and predicts\nvectorized map elements in the bird's-eye view. We benchmark HDMapNet on the\nnuScenes dataset and show that in all settings, it performs better than\nbaseline methods. Of note, our fusion-based HDMapNet outperforms existing\nmethods by more than 50% in all metrics. To accelerate future research, we\ndevelop customized metrics to evaluate map learning performance, including both\nsemantic-level and instance-level ones. By introducing this method and metrics,\nwe invite the community to study this novel map learning problem. We will\nrelease our code and evaluation kit to facilitate future development.",
    "descriptor": "",
    "authors": [
      "Qi Li",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06307"
  },
  {
    "id": "arXiv:2107.06309",
    "title": "Tight bounds on the Fourier growth of bounded functions on the hypercube",
    "abstract": "We give tight bounds on the degree $\\ell$ homogenous parts $f_\\ell$ of a\nbounded function $f$ on the cube. We show that if $f: \\{\\pm 1\\}^n \\rightarrow\n[-1,1]$ has degree $d$, then $\\| f_\\ell \\|_\\infty$ is bounded by\n$d^\\ell/\\ell!$, and $\\| \\hat{f}_\\ell \\|_1$ is bounded by $d^\\ell\ne^{\\binom{\\ell+1}{2}} n^{\\frac{\\ell-1}{2}}$. We describe applications to\npseudorandomness and learning theory. We use similar methods to generalize the\nclassical Pisier's inequality from convex analysis. Our analysis involves\nproperties of real-rooted polynomials that may be useful elsewhere.",
    "descriptor": "",
    "authors": [
      "Siddharth Iyer",
      "Anup Rao",
      "Victor Reis",
      "Thomas Rothvoss",
      "Amir Yehudayoff"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2107.06309"
  },
  {
    "id": "arXiv:2107.06310",
    "title": "What do writing features tell us about AI papers?",
    "abstract": "As the numbers of submissions to conferences grow quickly, the task of\nassessing the quality of academic papers automatically, convincingly, and with\nhigh accuracy attracts increasing attention. We argue that studying\ninterpretable dimensions of these submissions could lead to scalable solutions.\nWe extract a collection of writing features, and construct a suite of\nprediction tasks to assess the usefulness of these features in predicting\ncitation counts and the publication of AI-related papers. Depending on the\nvenues, the writing features can predict the conference vs. workshop appearance\nwith F1 scores up to 60-90, sometimes even outperforming the content-based\ntf-idf features and RoBERTa. We show that the features describe writing style\nmore than content. To further understand the results, we estimate the causal\nimpact of the most indicative features. Our analysis on writing features\nprovides a perspective to assessing and refining the writing of academic\narticles at scale.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Zining Zhu",
      "Bai Li",
      "Yang Xu",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06310"
  },
  {
    "id": "arXiv:2107.06312",
    "title": "Information Design in Large Games",
    "abstract": "We define the notion of Bayes correlated Wardrop equilibrium for general\nnonatomic games with anonymous players and incomplete information. Bayes\ncorrelated Wardrop equilibria describe the set of equilibrium outcomes when a\nmediator, such as a traffic information system, provides information to the\nplayers. We relate this notion to Bayes Wardrop equilibrium. Then, we provide\nconditions -- existence of a convex potential and complete information -- under\nwhich mediation does not improve equilibrium outcomes. We then study full\nimplementation and, finally, information design in anonymous games with a\nfinite set of players, when the number of players tends to infinity.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Frederic Koessler",
      "Marco Scarsini",
      "Tristan Tomala"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.06312"
  },
  {
    "id": "arXiv:2107.06317",
    "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time",
    "abstract": "Understanding an agent's priorities by observing their behavior is critical\nfor transparency and accountability in decision processes, such as in\nhealthcare. While conventional approaches to policy learning almost invariably\nassume stationarity in behavior, this is hardly true in practice: Medical\npractice is constantly evolving, and clinical professionals are constantly\nfine-tuning their priorities. We desire an approach to policy learning that\nprovides (1) interpretable representations of decision-making, accounts for (2)\nnon-stationarity in behavior, as well as operating in an (3) offline manner.\nFirst, we model the behavior of learning agents in terms of contextual bandits,\nand formalize the problem of inverse contextual bandits (ICB). Second, we\npropose two algorithms to tackle ICB, each making varying degrees of\nassumptions regarding the agent's learning strategy. Finally, through both real\nand simulated data for liver transplantations, we illustrate the applicability\nand explainability of our method, as well as validating its accuracy.",
    "descriptor": "",
    "authors": [
      "Alihan H\u00fcy\u00fck",
      "Daniel Jarrett",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06317"
  },
  {
    "id": "arXiv:2107.06319",
    "title": "On the Performance Analysis of the Adversarial System Variant  Approximation Method to Quantify Process Model Generalization",
    "abstract": "Process mining algorithms discover a process model from an event log. The\nresulting process model is supposed to describe all possible event sequences of\nthe underlying system. Generalization is a process model quality dimension of\ninterest. A generalization metric should quantify the extent to which a process\nmodel represents the observed event sequences contained in the event log and\nthe unobserved event sequences of the system. Most of the available metrics in\nthe literature cannot properly quantify the generalization of a process model.\nA recently published method [1] called Adversarial System Variant Approximation\nleverages Generative Adversarial Networks to approximate the underlying event\nsequence distribution of a system from an event log. While this method\ndemonstrated performance gains over existing methods in measuring the\ngeneralization of process models, its experimental evaluations have been\nperformed under ideal conditions. This paper experimentally investigates the\nperformance of Adversarial System Variant Approximation under non-ideal\nconditions such as biased and limited event logs. Moreover, experiments are\nperformed to investigate the originally proposed sampling hyperparameter value\nof the method on its performance to measure the generalization. The results\nconfirm the need to raise awareness about the working conditions of the\nAdversarial System Variant Approximation method. The outcomes of this paper\nalso serve to initiate future research directions.\n[1] Theis, Julian, and Houshang Darabi. \"Adversarial System Variant\nApproximation to Quantify Process Model Generalization.\" IEEE Access 8 (2020):\n194410-194427.",
    "descriptor": "",
    "authors": [
      "Julian Theis",
      "Ilia Mokhtarian",
      "Houshang Darabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06319"
  },
  {
    "id": "arXiv:2107.06321",
    "title": "A New Multipoint Secant Method with a Dense Initial Matrix",
    "abstract": "Quasi-Newton methods are able to construct model of the objective function\nwithout needing second derivatives of the objective function. In large-scale\noptimization, when either forming or storing Hessian matrices are prohibitively\nexpensive, quasi-Newton methods are often used in lieu of Newton's method\nbecause they make use of first-order information to approximate the true\nHessian. Multipoint symmetric secant methods can be thought of as\ngeneralizations of quasi-Newton methods in that they have additional\nrequirements on their approximation of the Hessian. Given an initial Hessian\napproximation, the multipoint symmetric secant (MSS) method generates a\nsequence of matrices using rank-2 updates. For practical reasons, up to now,\nthe initialization has been a constant multiple of the identity matrix. In this\npaper, we propose a new limited-memory MSS method that allows for dense\ninitializations. Numerical results on the CUTEst test problems suggest that the\n\\small{MSS} method using a dense initialization outperforms the standard\ninitialization. Numerical results also suggest that this approach is\ncompetitive with a basic L-SR1 trust-region method.",
    "descriptor": "",
    "authors": [
      "Jennifer B. Erway",
      "Mostafa Rezapour"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.06321"
  },
  {
    "id": "arXiv:2107.06325",
    "title": "Graphhopper: Multi-Hop Scene Graph Reasoning for Visual Question  Answering",
    "abstract": "Visual Question Answering (VQA) is concerned with answering free-form\nquestions about an image. Since it requires a deep semantic and linguistic\nunderstanding of the question and the ability to associate it with various\nobjects that are present in the image, it is an ambitious task and requires\nmulti-modal reasoning from both computer vision and natural language\nprocessing. We propose Graphhopper, a novel method that approaches the task by\nintegrating knowledge graph reasoning, computer vision, and natural language\nprocessing techniques. Concretely, our method is based on performing\ncontext-driven, sequential reasoning based on the scene entities and their\nsemantic and spatial relationships. As a first step, we derive a scene graph\nthat describes the objects in the image, as well as their attributes and their\nmutual relationships. Subsequently, a reinforcement learning agent is trained\nto autonomously navigate in a multi-hop manner over the extracted scene graph\nto generate reasoning paths, which are the basis for deriving answers. We\nconduct an experimental study on the challenging dataset GQA, based on both\nmanually curated and automatically generated scene graphs. Our results show\nthat we keep up with a human performance on manually curated scene graphs.\nMoreover, we find that Graphhopper outperforms another state-of-the-art scene\ngraph reasoning model on both manually curated and automatically generated\nscene graphs by a significant margin.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.01072\n",
    "authors": [
      "Rajat Koner",
      "Hang Li",
      "Marcel Hildebrandt",
      "Deepan Das",
      "Volker Tresp",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06325"
  },
  {
    "id": "arXiv:2107.06327",
    "title": "Contextual Games: Multi-Agent Learning with Side Information",
    "abstract": "We formulate the novel class of contextual games, a type of repeated games\ndriven by contextual information at each round. By means of kernel-based\nregularity assumptions, we model the correlation between different contexts and\ngame outcomes and propose a novel online (meta) algorithm that exploits such\ncorrelations to minimize the contextual regret of individual players. We define\ngame-theoretic notions of contextual Coarse Correlated Equilibria (c-CCE) and\noptimal contextual welfare for this new class of games and show that c-CCEs and\noptimal welfare can be approached whenever players' contextual regrets vanish.\nFinally, we empirically validate our results in a traffic routing experiment,\nwhere our algorithm leads to better performance and higher welfare compared to\nbaselines that do not exploit the available contextual information or the\ncorrelations present in the game.",
    "descriptor": "",
    "authors": [
      "Pier Giuseppe Sessa",
      "Ilija Bogunovic",
      "Andreas Krause",
      "Maryam Kamgarpour"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06327"
  },
  {
    "id": "arXiv:2107.06329",
    "title": "Efficient exact computation of the conjunctive and disjunctive  decompositions of D-S Theory for information fusion: Translation and  extension",
    "abstract": "Dempster-Shafer Theory (DST) generalizes Bayesian probability theory,\noffering useful additional information, but suffers from a high computational\nburden. A lot of work has been done to reduce the complexity of computations\nused in information fusion with Dempster's rule. Yet, few research had been\nconducted to reduce the complexity of computations for the conjunctive and\ndisjunctive decompositions of evidence, which are at the core of other\nimportant methods of information fusion. In this paper, we propose a method\ndesigned to exploit the actual evidence (information) contained in these\ndecompositions in order to compute them. It is based on a new notion that we\ncall focal point, derived from the notion of focal set. With it, we are able to\nreduce these computations up to a linear complexity in the number of focal sets\nin some cases. In a broader perspective, our formulas have the potential to be\ntractable when the size of the frame of discernment exceeds a few dozen\npossible states, contrary to the existing litterature. This article extends\n(and translates) our work published at the french conference GRETSI in 2019.",
    "descriptor": "\nComments: Extension of an article published in the proceedings of the french conference GRETSI 2019\n",
    "authors": [
      "Maxime Chaveroche",
      "Franck Davoine",
      "V\u00e9ronique Cherfaoui"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.06329"
  },
  {
    "id": "arXiv:2107.06330",
    "title": "Multi-variance replica exchange stochastic gradient MCMC for inverse and  forward Bayesian physics-informed neural network",
    "abstract": "Physics-informed neural network (PINN) has been successfully applied in\nsolving a variety of nonlinear non-convex forward and inverse problems.\nHowever, the training is challenging because of the non-convex loss functions\nand the multiple optima in the Bayesian inverse problem. In this work, we\npropose a multi-variance replica exchange stochastic gradient Langevin\ndiffusion method to tackle the challenge of the multiple local optima in the\noptimization and the challenge of the multiple modal posterior distribution in\nthe inverse problem. Replica exchange methods are capable of escaping from the\nlocal traps and accelerating the convergence. However, it may not be efficient\nto solve mathematical inversion problems by using the vanilla replica method\ndirectly since the method doubles the computational cost in evaluating the\nforward solvers (likelihood functions) in the two chains. To address this\nissue, we propose to make different assumptions on the energy function\nestimation and this facilities one to use solvers of different fidelities in\nthe likelihood function evaluation. We give an unbiased estimate of the\nswapping rate and give an estimation of the discretization error of the scheme.\nTo verify our idea, we design and solve four inverse problems which have\nmultiple modes. The proposed method is also employed to train the Bayesian PINN\nto solve the forward and inverse problems; faster and more accurate convergence\nhas been observed when compared to the stochastic gradient Langevin diffusion\n(SGLD) method and vanila replica exchange methods.",
    "descriptor": "",
    "authors": [
      "Guang Lin",
      "Yating Wang",
      "Zecheng Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06330"
  },
  {
    "id": "arXiv:2107.06331",
    "title": "The Anarchy-Stability Tradeoff in Congestion Games",
    "abstract": "This work focuses on the design of incentive mechanisms in congestion games,\na commonly studied model for competitive resource sharing. While the majority\nof the existing literature on this topic focuses on unilaterally optimizing the\nworst case performance (i.e., price of anarchy), in this manuscript we\ninvestigate whether optimizing for the worst case has consequences on the best\ncase performance (i.e., price of stability). Perhaps surprisingly, our results\nshow that there is a fundamental tradeoff between these two measures of\nperformance. Our main result provides a characterization of this tradeoff in\nterms of upper and lower bounds on the Pareto frontier between the price of\nanarchy and the price of stability. Interestingly, we demonstrate that the\nmechanism that optimizes the price of anarchy inherits a matching price of\nstability, thereby implying that the best equilibrium is not necessarily any\nbetter than the worst equilibrium for such a design choice. Our results also\nestablish that, in several well-studied cases, the unincentivized setting does\nnot even lie on the Pareto frontier, and that any incentive with price of\nstability equal to 1 incurs a much higher price of anarchy.",
    "descriptor": "\nComments: 27 pages, 1 figure, 1 table\n",
    "authors": [
      "Rahul Chandan",
      "Dario Paccagnan",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06331"
  },
  {
    "id": "arXiv:2107.06336",
    "title": "Learnability of Learning Performance and Its Application to Data  Valuation",
    "abstract": "For most machine learning (ML) tasks, evaluating learning performance on a\ngiven dataset requires intensive computation. On the other hand, the ability to\nefficiently estimate learning performance may benefit a wide spectrum of\napplications, such as active learning, data quality management, and data\nvaluation. Recent empirical studies show that for many common ML models, one\ncan accurately learn a parametric model that predicts learning performance for\nany given input datasets using a small amount of samples. However, the\ntheoretical underpinning of the learnability of such performance prediction\nmodels is still missing. In this work, we develop the first theoretical\nanalysis of the ML performance learning problem. We propose a relaxed notion\nfor submodularity that can well describe the behavior of learning performance\nas a function of input datasets. We give a learning algorithm that achieves a\nconstant-factor approximation under certain assumptions. Further, we give a\nlearning algorithm that achieves arbitrarily small error based on a newly\nderived structural result. We then discuss a natural, important use case of\nlearning performance learning -- data valuation, which is known to suffer\ncomputational challenges due to the requirement of estimating learning\nperformance for many data combinations. We show that performance learning can\nsignificantly improve the accuracy of data valuation.",
    "descriptor": "",
    "authors": [
      "Tianhao Wang",
      "Yu Yang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06336"
  },
  {
    "id": "arXiv:2107.06341",
    "title": "Hybrid A Posteriori Error Estimators for Conforming Finite Element  Approximations to Stationary Convection-Diffusion-Reaction equations",
    "abstract": "We consider the a posteriori error estimation for\nconvection-diffusion-reaction equations in both diffusion-dominated and\nconvection/reaction-dominated regimes. We present an explicit hybrid estimator,\nwhich, in each regime, is proved to be reliable and efficient with constants\nindependent of the parameters in the underlying problem. For\nconvection-dominated problems, the norm introduced by Verf{\\\"u}rth\n\\cite{verf2005confusion} is used to measure the approximation error. Various\nnumerical experiments are performed to (1) demonstrate the robustness of the\nhybrid estimator; (2) show that the hybrid estimator is more accurate than the\nexplicit residual estimator and is less sensitive to the size of reaction, even\nthough both of them are robust.",
    "descriptor": "",
    "authors": [
      "Difeng Cai",
      "Zhiqiang Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06341"
  },
  {
    "id": "arXiv:2107.06343",
    "title": "Design of Adaptive Backstepping Control for Direct Power Control of  Three-Phase PWM Rectifier)",
    "abstract": "In this paper, we focused on the design of an adaptive backstepping\ncontroller (adaptive-BSC) for direct power control (DPC) of a three-phase PWM\nrectifier. In the proposed system, it is desired to control both the output DC\nvoltage of the rectifier and the reactive power simultaneously by making them\ntrack desired respective values. This was done by having independent virtual\ncontrol signals for both the output voltage and the reactive power. The\nadaptive control signals were gotten from the dynamic equations of the\nthree-phase system. For comparison, both the BSC and adaptive-BSC equations\nwere developed. Numerical simulations were performed on both of them on a 5kW\nsystem. The proposed adaptive-BSC was designed to work under more challenging\nsystem variations as compared with the BSC as it has to estimate the value of\nthe unknown system load. Despite this, it still performed better than its BSC\ncounterpart.",
    "descriptor": "",
    "authors": [
      "Basit Olakunle Alawode",
      "Sami El-Ferik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06343"
  },
  {
    "id": "arXiv:2107.06344",
    "title": "Inverse Reinforcement Learning Based Stochastic Driver Behavior Learning",
    "abstract": "Drivers have unique and rich driving behaviors when operating vehicles in\ntraffic. This paper presents a novel driver behavior learning approach that\ncaptures the uniqueness and richness of human driver behavior in realistic\ndriving scenarios. A stochastic inverse reinforcement learning (SIRL) approach\nis proposed to learn a distribution of cost function, which represents the\nrichness of the human driver behavior with a given set of driver-specific\ndemonstrations. Evaluations are conducted on the realistic driving data\ncollected from the 3D driver-in-the-loop driving simulation. The results show\nthat the learned stochastic driver model is capable of expressing the richness\nof the human driving strategies under different realistic driving scenarios.\nCompared to the deterministic baseline driver model, the results reveal that\nthe proposed stochastic driver behavior model can better replicate the driver's\nunique and rich driving strategies in a variety of traffic conditions.",
    "descriptor": "\nComments: Accepted to 2021 Modeling, Estimation and Control Conference (MECC)\n",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Yao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06344"
  },
  {
    "id": "arXiv:2107.06347",
    "title": "Enhancing Resilience of Distribution Networks by Coordinating Microgrids  and Demand Response Programs in Service Restoration",
    "abstract": "In case of high impact low probability events, in order to restore the\ncritical loads of the distribution network as much as possible, it is necessary\nto employ all available resources such as microgrids and distributed\ngenerations. This paper presents a two-stage method for critical load\nrestoration after an extreme event utilizing the coordination of all available\ndistributed generations, microgrids, and demand response programs. In the first\nstage, the post-disaster reconfiguration of the network is determined, and in\nthe second stage, the demand response outputs of the responsive loads and the\nrestoration status of all critical loads are ascertained. In the first stage,\nan algorithm is proposed to determine electrical islands, and in the second\nstage, a new model based on the generalized Benders decomposition algorithm is\nproposed, which considers demand response programs and all operational\nconstraints and aims to maximize the restored critical loads. The effectiveness\nof the proposed method is verified by simulating the 33-bus and 69-bus test\nsystems.",
    "descriptor": "",
    "authors": [
      "Ali Shakeri Kahnamouei",
      "Saeed Lotfifard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06347"
  },
  {
    "id": "arXiv:2107.06351",
    "title": "BRIMA: low-overhead BRowser-only IMage Annotation tool (Preprint)",
    "abstract": "Image annotation and large annotated datasets are crucial parts within the\nComputer Vision and Artificial Intelligence fields.At the same time, it is\nwell-known and acknowledged by the research community that the image annotation\nprocess is challenging, time-consuming and hard to scale. Therefore, the\nresearchers and practitioners are always seeking ways to perform the\nannotations easier, faster, and at higher quality. Even though several widely\nused tools exist and the tools' landscape evolved considerably, most of the\ntools still require intricate technical setups and high levels of technical\nsavviness from its operators and crowdsource contributors.\nIn order to address such challenges, we develop and present BRIMA -- a\nflexible and open-source browser extension that allows BRowser-only IMage\nAnnotation at considerably lower overheads. Once added to the browser, it\ninstantly allows the user to annotate images easily and efficiently directly\nfrom the browser without any installation or setup on the client-side. It also\nfeatures cross-browser and cross-platform functionality thus presenting itself\nas a neat tool for researchers within the Computer Vision, Artificial\nIntelligence, and privacy-related fields.",
    "descriptor": "",
    "authors": [
      "Tuomo Lahtinen",
      "Hannu Turtiainen",
      "Andrei Costin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06351"
  },
  {
    "id": "arXiv:2107.06353",
    "title": "Distributionally Robust Policy Learning via Adversarial Environment  Generation",
    "abstract": "Our goal is to train control policies that generalize well to unseen\nenvironments. Inspired by the Distributionally Robust Optimization (DRO)\nframework, we propose DRAGEN - Distributionally Robust policy learning via\nAdversarial Generation of ENvironments - for iteratively improving robustness\nof policies to realistic distribution shifts by generating adversarial\nenvironments. The key idea is to learn a generative model for environments\nwhose latent variables capture cost-predictive and realistic variations in\nenvironments. We perform DRO with respect to a Wasserstein ball around the\nempirical distribution of environments by generating realistic adversarial\nenvironments via gradient ascent on the latent space. We demonstrate strong\nOut-of-Distribution (OoD) generalization in simulation for (i) swinging up a\npendulum with onboard vision and (ii) grasping realistic 2D/3D objects.\nGrasping experiments on hardware demonstrate better sim2real performance\ncompared to domain randomization.",
    "descriptor": "",
    "authors": [
      "Allen Z. Ren",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06353"
  },
  {
    "id": "arXiv:2107.06356",
    "title": "Real-Time Pothole Detection Using Deep Learning",
    "abstract": "Roads are connecting line between different places, and used daily. Roads'\nperiodic maintenance keeps them safe and functional. Detecting and reporting\nthe existence of potholes to responsible departments can help in eliminating\nthem. This study deployed and tested on different deep learning architecture to\ndetect potholes. The images used for training were collected by cellphone\nmounted on the windshield of the car, in addition to many images downloaded\nfrom the internet to increase the size and variability of the database. Second,\nvarious object detection algorithms are employed and compared to detect\npotholes in real-time like SDD-TensorFlow, YOLOv3Darknet53 and YOLOv4Darknet53.\nYOLOv4 achieved the best performance with 81% recall, 85% precision and 85.39%\nmean Average Precision (mAP). The speed of processing was 20 frame per second.\nThe system was able to detect potholes from a range on 100 meters away from the\ncamera. The system can increase the safety of drivers and improve the\nperformance of self-driving cars by detecting pothole time ahead.",
    "descriptor": "\nComments: 10 pages, 16 figures\n",
    "authors": [
      "Anas Al Shaghouri",
      "Rami Alkhatib",
      "Samir Berjaoui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06356"
  },
  {
    "id": "arXiv:2107.06360",
    "title": "Developmental Stage Classification of EmbryosUsing Two-Stream Neural  Network with Linear-Chain Conditional Random Field",
    "abstract": "The developmental process of embryos follows a monotonic order. An embryo can\nprogressively cleave from one cell to multiple cells and finally transform to\nmorula and blastocyst. For time-lapse videos of embryos, most existing\ndevelopmental stage classification methods conduct per-frame predictions using\nan image frame at each time step. However, classification using only images\nsuffers from overlapping between cells and imbalance between stages. Temporal\ninformation can be valuable in addressing this problem by capturing movements\nbetween neighboring frames. In this work, we propose a two-stream model for\ndevelopmental stage classification. Unlike previous methods, our two-stream\nmodel accepts both temporal and image information. We develop a linear-chain\nconditional random field (CRF) on top of neural network features extracted from\nthe temporal and image streams to make use of both modalities. The linear-chain\nCRF formulation enables tractable training of global sequential models over\nmultiple frames while also making it possible to inject monotonic development\norder constraints into the learning process explicitly. We demonstrate our\nalgorithm on two time-lapse embryo video datasets: i) mouse and ii) human\nembryo datasets. Our method achieves 98.1 % and 80.6 % for mouse and human\nembryo stage classification, respectively. Our approach will enable more\nprofound clinical and biological studies and suggests a new direction for\ndevelopmental stage classification by utilizing temporal information.",
    "descriptor": "\nComments: 8.5 pages, to appear in MICCAI 2021\n",
    "authors": [
      "Stanislav Lukyanenko",
      "Won-Dong Jang",
      "Donglai Wei",
      "Robbert Struyven",
      "Yoon Kim",
      "Brian Leahy",
      "Helen Yang",
      "Alexander Rush",
      "Dalit Ben-Yosef",
      "Daniel Needleman",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06360"
  },
  {
    "id": "arXiv:2107.06362",
    "title": "Information Spread with Error Correction",
    "abstract": "We study the process of information dispersal in a network with communication\nerrors and local error-correction. Specifically we consider a simple model\nwhere a single bit of information initially known to a single source is\ndispersed through the network, and communication errors lead to differences in\nthe agents' opinions on this information.\nNaturally, such errors can very quickly make the communication completely\nunreliable, and in this work we study to what extent this unreliability can be\nmitigated by local error-correction, where nodes periodically correct their\nopinion based on the opinion of (some subset of) their neighbors. We analyze\nhow the error spreads in the \"early stages\" of information dispersal by\nmonitoring the average opinion, i.e., the fraction of agents that have the\ncorrect information among all nodes that hold an opinion at a given time. Our\nmain results show that even with significant effort in error-correction, tiny\namounts of noise can lead the average opinion to be nearly uncorrelated with\nthe truth in early stages. We also propose some local methods to help agents\ngauge when the information they have has stabilized.",
    "descriptor": "",
    "authors": [
      "Omri Ben-Eliezer",
      "Elchanan Mossel",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.06362"
  },
  {
    "id": "arXiv:2107.06369",
    "title": "Exploring DMD-type Algorithms for Modeling Signalised Intersections",
    "abstract": "This paper explores a novel data-driven approach based on recent developments\nin Koopman operator theory and dynamic mode decomposition (DMD) for modeling\nsignalized intersections. Vehicular flow and queue formation on signalized\nintersections have complex nonlinear dynamics, making system identification,\nmodeling, and controller design tasks challenging. We employ a Koopman\ntheoretic approach to transform the original nonlinear dynamics into locally\nlinear infinite-dimensional dynamics. The data-driven approach relies entirely\non spatio-temporal snapshots of the traffic data. We investigate several key\naspects of the approach and provide insights into the usage of DMD-type\nalgorithms for application in adaptive signalized intersections. To demonstrate\nthe utility of the obtained linearized dynamics, we perform prediction of the\nqueue lengths at the intersection; and compare the results with the\nstate-of-the-art long short term memory (LSTM) method. The case study involves\nthe morning peak vehicle movements and queue lengths at two Orlando area\nsignalized intersections. It is observed that DMD-based algorithms are able to\ncapture complex dynamics with a linear approximation to a reasonable extent.",
    "descriptor": "\nComments: 11 pages, 8 figures, Submitted to: Journal of Intelligent Transportation Systems\n",
    "authors": [
      "Kazi Redwan Shabab",
      "Shakib Mustavee",
      "Shaurya Agarwal",
      "Mohamed H. Zaki",
      "Sajal Das"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06369"
  },
  {
    "id": "arXiv:2107.06372",
    "title": "On the Analysis of MUD-Files' Interactions, Conflicts, and Configuration  Requirements Before Deployment",
    "abstract": "Manufacturer Usage Description (MUD) is an Internet Engineering Task Force\n(IETF) standard designed to protect IoT devices and networks by creating an\nout-of-the-box access control list for an IoT device. %The protocol defines a\nconceptually straightforward method to implement an isolation-based defensive\nmechanism based on the rules that are introduced by the manufacturer of the\ndevice. However, in practice, the access control list of each device is defined\nin its MUD-File and may contain possibly hundreds of access control rules. As a\nresult, reading and validating these files is a challenge; and determining how\nmultiple IoT devices interact is difficult for the developer and infeasible for\nthe consumer. To address this we introduce the MUD-Visualizer to provide a\nvisualization of any number of MUD-Files. MUD-Visualizer is designed to enable\ndevelopers to produce correct MUD-Files by providing format correction,\nintegrating them with other MUD-Files, and identifying conflicts through\nvisualization. MUD-Visualizer is scalable and its core task is to merge and\nillustrate ACEs for multiple devices; both within and beyond the local area\nnetwork. MUD-Visualizer is made publicly available and can be found on GitHub.",
    "descriptor": "\nComments: 22 pages, 6 figures, 3 algorithms, To be published in 5th EAI International Conference on Safety and Security in Internet of Things (SaSeIoT)\n",
    "authors": [
      "Vafa Andalibi",
      "Eliot Lear",
      "DongInn Kim",
      "L. Jean Camp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06372"
  },
  {
    "id": "arXiv:2107.06381",
    "title": "Fast Parallel-in-Time Quasi-Boundary Value Methods for Backward Heat  Conduction Problems",
    "abstract": "In this paper we proposed two new quasi-boundary value methods for\nregularizing the ill-posed backward heat conduction problems. With a standard\nfinite difference discretization in space and time, the obtained all-at-once\nnonsymmetric sparse linear systems have the desired block $\\omega$-circulant\nstructure, which can be utilized to design an efficient parallel-in-time (PinT)\ndirect solver that built upon an explicit FFT-based diagonalization of the time\ndiscretization matrix. Convergence analysis is presented to justify the optimal\nchoice of the regularization parameter. Numerical examples are reported to\nvalidate our analysis and illustrate the superior computational efficiency of\nour proposed PinT methods.",
    "descriptor": "\nComments: 17 pages, 3 figures, 2 tables\n",
    "authors": [
      "Jun Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.06381"
  },
  {
    "id": "arXiv:2107.06382",
    "title": "Stochastic Geometry based Interference Analysis of Multiuser mmWave  Networks with RIS",
    "abstract": "In this paper, we utilize tools from stochastic geometry to estimate the\ninterference propagation via reconfigurable intelligent surface (RIS) in the\nmillimeter wave (mmWave, 30-300 GHz) band and specifically on the D band\n(110-170 GHz). The RISs have been of great interest lately to maximize the\nchannel gains in non-line-of-sight (NLOS) communication situations. We derive\nexpressions for stochastic interference level in RIS powered systems and\nvalidate those with simulations. It will be shown that the interference levels\nvia RIS link are rather small compared to the designed RIS link or the LOS\ninterference as the random interference loses significant part of the RIS gain.\nWe also analyse the validity of far field channel and antenna gains in the near\nfield of a large array. It is shown that, while the high frequency systems\nrequire large arrays that push the far field far away from the antenna, the far\nfield equations are very accurate up to about half way of the near field.",
    "descriptor": "\nComments: 6 pages, 6 figures, accepted for PIMRC 2021 conference\n",
    "authors": [
      "Joonas Kokkoniemi",
      "Markku Juntti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06382"
  },
  {
    "id": "arXiv:2107.06383",
    "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?",
    "abstract": "Most existing Vision-and-Language (V&L) models rely on pre-trained visual\nencoders, using a relatively small set of manually-annotated data (as compared\nto web-crawled data), to perceive the visual world. However, it has been\nobserved that large-scale pretraining usually can result in better\ngeneralization performance, e.g., CLIP (Contrastive Language-Image\nPre-training), trained on a massive amount of image-caption pairs, has shown a\nstrong zero-shot capability on various vision tasks. To further study the\nadvantage brought by CLIP, we propose to use CLIP as the visual encoder in\nvarious V&L models in two typical scenarios: 1) plugging CLIP into\ntask-specific fine-tuning; 2) combining CLIP with V&L pre-training and\ntransferring to downstream tasks. We show that CLIP significantly outperforms\nwidely-used visual encoders trained with in-domain annotated data, such as\nBottomUp-TopDown. We achieve competitive or better results on diverse V&L\ntasks, while establishing new state-of-the-art results on Visual Question\nAnswering, Visual Entailment, and V&L Navigation tasks. We release our code at\nhttps://github.com/clip-vil/CLIP-ViL.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Sheng Shen",
      "Liunian Harold Li",
      "Hao Tan",
      "Mohit Bansal",
      "Anna Rohrbach",
      "Kai-Wei Chang",
      "Zhewei Yao",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06383"
  },
  {
    "id": "arXiv:2107.06386",
    "title": "Geometry and Generalization: Eigenvalues as predictors of where a  network will fail to generalize",
    "abstract": "We study the deformation of the input space by a trained autoencoder via the\nJacobians of the trained weight matrices. In doing so, we prove bounds for the\nmean squared errors for points in the input space, under assumptions regarding\nthe orthogonality of the eigenvectors. We also show that the trace and the\nproduct of the eigenvalues of the Jacobian matrices is a good predictor of the\nMSE on test points. This is a dataset independent means of testing an\nautoencoder's ability to generalize on new input. Namely, no knowledge of the\ndataset on which the network was trained is needed, only the parameters of the\ntrained model.",
    "descriptor": "",
    "authors": [
      "Susama Agarwala",
      "Benjamin Dees",
      "Andrew Gearhart",
      "Corey Lowman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2107.06386"
  },
  {
    "id": "arXiv:2107.06393",
    "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the  Discrete-Continuous Interface",
    "abstract": "Modeling complex phenomena typically involves the use of both discrete and\ncontinuous variables. Such a setting applies across a wide range of problems,\nfrom identifying trends in time-series data to performing effective\ncompositional scene understanding in images. Here, we propose Hybrid Memoised\nWake-Sleep (HMWS), an algorithm for effective inference in such hybrid\ndiscrete-continuous models. Prior approaches to learning suffer as they need to\nperform repeated expensive inner-loop discrete inference. We build on a recent\napproach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by\nmemoising discrete variables, and extend it to allow for a principled and\neffective way to handle continuous variables by learning a separate recognition\nmodel used for importance-sampling based approximate inference and\nmarginalization. We evaluate HMWS in the GP-kernel learning and 3D scene\nunderstanding domains, and show that it outperforms current state-of-the-art\ninference methods.",
    "descriptor": "",
    "authors": [
      "Tuan Anh Le",
      "Katherine M. Collins",
      "Luke Hewitt",
      "Kevin Ellis",
      "Siddharth N",
      "Samuel J. Gershman",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06393"
  },
  {
    "id": "arXiv:2107.06394",
    "title": "Compressive Representations of Weather Scenes for Strategic Air Traffic  Flow Management",
    "abstract": "Terse representation of high-dimensional weather scene data is explored, in\nsupport of strategic air traffic flow management objectives. Specifically, we\nconsider whether aviation-relevant weather scenes are compressible, in the\nsense that each scene admits a possibly-different sparse representation in a\nbasis of interest. Here, compression of weather scenes extracted from METAR\ndata (including temperature, flight categories, and visibility profiles for the\ncontiguous United States) is examined, for the graph-spectral basis. The scenes\nare found to be compressible, with 75-95% of the scene content captured using\n0.5-4% of the basis vectors. Further, the dominant basis vectors for each scene\nare seen to identify time-varying spatial characteristics of the weather, and\nreconstruction from the compressed representation is demonstrated. Finally,\npotential uses of the compressive representations in strategic TFM design are\nbriefly scoped.",
    "descriptor": "",
    "authors": [
      "Sandip Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06394"
  },
  {
    "id": "arXiv:2107.06397",
    "title": "SurgeonAssist-Net: Towards Context-Aware Head-Mounted Display-Based  Augmented Reality for Surgical Guidance",
    "abstract": "We present SurgeonAssist-Net: a lightweight framework making\naction-and-workflow-driven virtual assistance, for a set of predefined surgical\ntasks, accessible to commercially available optical see-through head-mounted\ndisplays (OST-HMDs). On a widely used benchmark dataset for laparoscopic\nsurgical workflow, our implementation competes with state-of-the-art approaches\nin prediction accuracy for automated task recognition, and yet requires 7.4x\nfewer parameters, 10.2x fewer floating point operations per second (FLOPS), is\n7.0x faster for inference on a CPU, and is capable of near real-time\nperformance on the Microsoft HoloLens 2 OST-HMD. To achieve this, we make use\nof an efficient convolutional neural network (CNN) backbone to extract\ndiscriminative features from image data, and a low-parameter recurrent neural\nnetwork (RNN) architecture to learn long-term temporal dependencies. To\ndemonstrate the feasibility of our approach for inference on the HoloLens 2 we\ncreated a sample dataset that included video of several surgical tasks recorded\nfrom a user-centric point-of-view. After training, we deployed our model and\ncataloged its performance in an online simulated surgical scenario for the\nprediction of the current surgical task. The utility of our approach is\nexplored in the discussion of several relevant clinical use-cases. Our code is\npublicly available at https://github.com/doughtmw/surgeon-assist-net.",
    "descriptor": "\nComments: Accepted at MICCAI 2021; 11 pages, 3 figures\n",
    "authors": [
      "Mitchell Doughty",
      "Karan Singh",
      "Nilesh R. Ghugre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06397"
  },
  {
    "id": "arXiv:2107.06399",
    "title": "The Perfect Matching Cut Problem Revisited",
    "abstract": "In a graph, a perfect matching cut is an edge cut that is a perfect matching.\nPerfect Matching Cut (PMC) is the problem of deciding whether a given graph has\na perfect matching cut, and is known to be NP-complete. We revisit the problem\nand show that PMC remains NP-complete when restricted to bipartite graphs of\nmaximum degree 3 and arbitrarily large girth. Complementing this hardness\nresult, we give two graph classes in which PMC is polynomial time solvable. The\nfirst one includes claw-free graphs and graphs without an induced path on five\nvertices, the second one properly contains all chordal graphs. Assuming the\nExponential Time Hypothesis, we show there is no $O^*(2^{o(n)})$-time algorithm\nfor PMC even when restricted to $n$-vertex bipartite graphs, and also show that\nPMC can be solved in $O^*(1.2721^n)$ time by means of an exact branching\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Van Bang Le",
      "Jan Arne Telle"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06399"
  },
  {
    "id": "arXiv:2107.06400",
    "title": "Using BERT Encoding to Tackle the Mad-lib Attack in SMS Spam Detection",
    "abstract": "One of the stratagems used to deceive spam filters is to substitute vocables\nwith synonyms or similar words that turn the message unrecognisable by the\ndetection algorithms. In this paper we investigate whether the recent\ndevelopment of language models sensitive to the semantics and context of words,\nsuch as Google's BERT, may be useful to overcome this adversarial attack\n(called \"Mad-lib\" as per the word substitution game). Using a dataset of 5572\nSMS spam messages, we first established a baseline of detection performance\nusing widely known document representation models (BoW and TFIDF) and the novel\nBERT model, coupled with a variety of classification algorithms (Decision Tree,\nkNN, SVM, Logistic Regression, Naive Bayes, Multilayer Perceptron). Then, we\nbuilt a thesaurus of the vocabulary contained in these messages, and set up a\nMad-lib attack experiment in which we modified each message of a held out\nsubset of data (not used in the baseline experiment) with different rates of\nsubstitution of original words with synonyms from the thesaurus. Lastly, we\nevaluated the detection performance of the three representation models (BoW,\nTFIDF and BERT) coupled with the best classifier from the baseline experiment\n(SVM). We found that the classic models achieved a 94% Balanced Accuracy (BA)\nin the original dataset, whereas the BERT model obtained 96%. On the other\nhand, the Mad-lib attack experiment showed that BERT encodings manage to\nmaintain a similar BA performance of 96% with an average substitution rate of\n1.82 words per message, and 95% with 3.34 words substituted per message. In\ncontrast, the BA performance of the BoW and TFIDF encoders dropped to chance.\nThese results hint at the potential advantage of BERT models to combat these\ntype of ingenious attacks, offsetting to some extent for the inappropriate use\nof semantic relationships in language.",
    "descriptor": "",
    "authors": [
      "Sergio Rojas-Galeano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06400"
  },
  {
    "id": "arXiv:2107.06401",
    "title": "Semantically-Aware Strategies for Stereo-Visual Robotic Obstacle  Avoidance",
    "abstract": "Mobile robots in unstructured, mapless environments must rely on an obstacle\navoidance module to navigate safely. The standard avoidance techniques estimate\nthe locations of obstacles with respect to the robot but are unaware of the\nobstacles' identities. Consequently, the robot cannot take advantage of\nsemantic information about obstacles when making decisions about how to\nnavigate. We propose an obstacle avoidance module that combines visual instance\nsegmentation with a depth map to classify and localize objects in the scene.\nThe system avoids obstacles differentially, based on the identity of the\nobjects: for example, the system is more cautious in response to unpredictable\nobjects such as humans. The system can also navigate closer to harmless\nobstacles and ignore obstacles that pose no collision danger, enabling it to\nnavigate more efficiently. We validate our approach in two simulated\nenvironments: one terrestrial and one underwater. Results indicate that our\napproach is feasible and can enable more efficient navigation strategies.",
    "descriptor": "",
    "authors": [
      "Jungseok Hong",
      "Karin de Langis",
      "Cole Wyeth",
      "Christopher Walaszek",
      "Junaed Sattar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06401"
  },
  {
    "id": "arXiv:2107.06402",
    "title": "Mining Idioms in the Wild",
    "abstract": "Existing code repositories contain numerous instances of code patterns that\nare idiomatic ways of accomplishing a particular programming task. Sometimes,\nthe programming language in use supports specific operators or APIs that can\nexpress the same idiomatic imperative code much more succinctly. However, those\ncode patterns linger in repositories because the developers may be unaware of\nthe new APIs or have not gotten around to them. Detection of idiomatic code can\nalso point to the need for new APIs.\nWe share our experiences in mine idiomatic patterns from the Hack repo at\nFacebook. We found that existing techniques either cannot identify meaningful\npatterns from syntax trees or require test-suite-based dynamic analysis to\nincorporate semantic properties to mine useful patterns. The key insight of the\napproach proposed in this paper -- \\emph{Jezero} -- is that semantic idioms\nfrom a large codebase can be learned from \\emph{canonicalized} dataflow trees.\nWe propose a scalable, lightweight static analysis-based approach to construct\nsuch a tree that is well suited to mine semantic idioms using nonparametric\nBayesian methods.\nOur experiments with Jezero on Hack code shows a clear advantage of adding\ncanonicalized dataflow information to ASTs: \\emph{Jezero} was significantly\nmore effective than a baseline that did not have the dataflow augmentation in\nbeing able to effectively find refactoring opportunities from unannotated\nlegacy code.",
    "descriptor": "",
    "authors": [
      "Aishwarya Sivaraman",
      "Rui Abreu",
      "Andrew Scott",
      "Tobi Akomolede",
      "Satish Chandra"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06402"
  },
  {
    "id": "arXiv:2107.06405",
    "title": "Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks",
    "abstract": "We propose the k-Shortest-Path (k-SP) constraint: a novel constraint on the\nagent's trajectory that improves the sample efficiency in sparse-reward MDPs.\nWe show that any optimal policy necessarily satisfies the k-SP constraint.\nNotably, the k-SP constraint prevents the policy from exploring state-action\npairs along the non-k-SP trajectories (e.g., going back and forth). However, in\npractice, excluding state-action pairs may hinder the convergence of RL\nalgorithms. To overcome this, we propose a novel cost function that penalizes\nthe policy violating SP constraint, instead of completely excluding it. Our\nnumerical experiment in a tabular RL setting demonstrates that the SP\nconstraint can significantly reduce the trajectory space of policy. As a\nresult, our constraint enables more sample efficient learning by suppressing\nredundant exploration and exploitation. Our experiments on MiniGrid, DeepMind\nLab, Atari, and Fetch show that the proposed method significantly improves\nproximal policy optimization (PPO) and outperforms existing novelty-seeking\nexploration methods including count-based exploration even in continuous\ncontrol tasks, indicating that it improves the sample efficiency by preventing\nthe agent from taking redundant actions.",
    "descriptor": "\nComments: In proceedings of ICML 2021\n",
    "authors": [
      "Sungryull Sohn",
      "Sungtae Lee",
      "Jongwook Choi",
      "Harm van Seijen",
      "Mehdi Fatemi",
      "Honglak Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06405"
  },
  {
    "id": "arXiv:2107.06409",
    "title": "The Foes of Neural Network's Data Efficiency Among Unnecessary Input  Dimensions",
    "abstract": "Datasets often contain input dimensions that are unnecessary to predict the\noutput label, e.g. background in object recognition, which lead to more\ntrainable parameters. Deep Neural Networks (DNNs) are robust to increasing the\nnumber of parameters in the hidden layers, but it is unclear whether this holds\ntrue for the input layer. In this letter, we investigate the impact of\nunnecessary input dimensions on a central issue of DNNs: their data efficiency,\nie. the amount of examples needed to achieve certain generalization\nperformance. Our results show that unnecessary input dimensions that are\ntask-unrelated substantially degrade data efficiency. This highlights the need\nfor mechanisms that remove {task-unrelated} dimensions to enable data\nefficiency gains.",
    "descriptor": "",
    "authors": [
      "Vanessa D'Amario",
      "Sanjana Srivastava",
      "Tomotake Sasaki",
      "Xavier Boix"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06409"
  },
  {
    "id": "arXiv:2107.06413",
    "title": "Monotonicity and Noise-Tolerance in Case-Based Reasoning with Abstract  Argumentation (with Appendix)",
    "abstract": "Recently, abstract argumentation-based models of case-based reasoning\n($AA{\\text -} CBR$ in short) have been proposed, originally inspired by the\nlegal domain, but also applicable as classifiers in different scenarios.\nHowever, the formal properties of $AA{\\text -} CBR$ as a reasoning system\nremain largely unexplored. In this paper, we focus on analysing the\nnon-monotonicity properties of a regular version of $AA{\\text -} CBR$ (that we\ncall $AA{\\text -} CBR_{\\succeq}$). Specifically, we prove that $AA{\\text -}\nCBR_{\\succeq}$ is not cautiously monotonic, a property frequently considered\ndesirable in the literature. We then define a variation of $AA{\\text -}\nCBR_{\\succeq}$ which is cautiously monotonic. Further, we prove that such\nvariation is equivalent to using $AA{\\text -} CBR_{\\succeq}$ with a restricted\ncasebase consisting of all \"surprising\" and \"sufficient\" cases in the original\ncasebase. As a by-product, we prove that this variation of $AA{\\text -}\nCBR_{\\succeq}$ is cumulative, rationally monotonic, and empowers a principled\ntreatment of noise in \"incoherent\" casebases. Finally, we illustrate $AA{\\text\n-} CBR$ and cautious monotonicity questions on a case study on the U.S. Trade\nSecrets domain, a legal casebase.",
    "descriptor": "\nComments: Accepted for KR2021. Includes Appendix. arXiv admin note: substantial text overlap with arXiv:2007.05284\n",
    "authors": [
      "Guilherme Paulino-Passos",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06413"
  },
  {
    "id": "arXiv:2107.06415",
    "title": "The Master and Parasite Attack",
    "abstract": "We explore a new type of malicious script attacks: the persistent parasite\nattack. Persistent parasites are stealthy scripts, which persist for a long\ntime in the browser's cache. We show to infect the caches of victims with\nparasite scripts via TCP injection.\nOnce the cache is infected, we implement methodologies for propagation of the\nparasites to other popular domains on the victim client as well as to other\ncaches on the network. We show how to design the parasites so that they stay\nlong time in the victim's cache not restricted to the duration of the user's\nvisit to the web site. We develop covert channels for communication between the\nattacker and the parasites, which allows the attacker to control which scripts\nare executed and when, and to exfiltrate private information to the attacker,\nsuch as cookies and passwords. We then demonstrate how to leverage the\nparasites to perform sophisticated attacks, and evaluate the attacks against a\nrange of applications and security mechanisms on popular browsers. Finally we\nprovide recommendations for countermeasures.",
    "descriptor": "\nComments: The paper has been accepted for publication at the 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2021)\n",
    "authors": [
      "Lukas Baumann",
      "Elias Heftrig",
      "Haya Shulman",
      "Michael Waidner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06415"
  },
  {
    "id": "arXiv:2107.06416",
    "title": "Multi-Step Critiquing User Interface for Recommender Systems",
    "abstract": "Recommendations with personalized explanations have been shown to increase\nuser trust and perceived quality and help users make better decisions.\nMoreover, such explanations allow users to provide feedback by critiquing them.\nSeveral algorithms for recommendation systems with multi-step critiquing have\ntherefore been developed. However, providing a user-friendly interface based on\npersonalized explanations and critiquing has not been addressed in the last\ndecade. In this paper, we introduce four different web interfaces (available\nunder https://lia.epfl.ch/critiquing/) helping users making decisions and\nfinding their ideal item. We have chosen the hotel recommendation domain as a\nuse case even though our approach is trivially adaptable for other domains.\nMoreover, our system is model-agnostic (for both recommender systems and\ncritiquing models) allowing a great flexibility and further extensions. Our\ninterfaces are above all a useful tool to help research in recommendation with\ncritiquing. They allow to test such systems on a real use case and also to\nhighlight some limitations of these approaches to find solutions to overcome\nthem.",
    "descriptor": "",
    "authors": [
      "Diana Petrescu",
      "Diego Antognini",
      "Boi Faltings"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06416"
  },
  {
    "id": "arXiv:2107.06419",
    "title": "ATTACC the Quadratic Bottleneck of Attention Layers",
    "abstract": "Attention mechanisms form the backbone of state-of-the-art machine learning\nmodels for a variety of tasks. Deploying them on deep neural network (DNN)\naccelerators, however, is prohibitively challenging especially under long\nsequences. Operators in attention layers exhibit limited reuse and quadratic\ngrowth in memory footprint, leading to severe memory-boundedness. This paper\nintroduces a new attention-tailored dataflow, termed FLAT, which leverages\noperator fusion, loop-nest optimizations, and interleaved execution. It\nincreases the effective memory bandwidth by efficiently utilizing the\nhigh-bandwidth, low-capacity on-chip buffer and thus achieves better run time\nand compute resource utilization. We term FLAT-compatible accelerators ATTACC.\nIn our evaluation, ATTACC achieves 1.94x and 1.76x speedup and 49% and 42% of\nenergy reduction comparing to state-of-the-art edge and cloud accelerators.",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Suvinay Subramanian",
      "Gaurav Agrawal",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.06419"
  },
  {
    "id": "arXiv:2107.06420",
    "title": "Complexity and Second Moment of the Mathematical Theory of Communication",
    "abstract": "The performance of an error correcting code is evaluated by its error\nprobability, rate, and en/decoding complexity. The performance of a series of\ncodes is evaluated by, as the block lengths approach infinity, whether their\nerror probabilities decay to zero, whether their rates converge to capacity,\nand whether their growth in complexities stays under control. Over any discrete\nmemoryless channel, I build codes such that: (1) their error probabilities and\nrates scale like random codes; and (2) their en/decoding complexities scale\nlike polar codes. Quantitatively, for any constants $p,r>0$ s.t. $p+2r<1$, I\nconstruct a series of codes with block length $N$ approaching infinity, error\nprobability $\\exp(-N^p)$, rate $N^{-r}$ less than the capacity, and en/decoding\ncomplexity $O(N\\log N)$ per block. Over any discrete memoryless channel, I also\nbuild codes such that: (1) they achieve capacity rapidly; and (2) their\nen/decoding complexities outperform all known codes over non-BEC channels.\nQuantitatively, for any constants $t,r>0$ s.t. $2r<1$, I construct a series of\ncodes with block length $N$ approaching infinity, error probability\n$\\exp(-(\\log N)^t)$, rate $N^{-r}$ less than the capacity, and en/decoding\ncomplexity $O(N\\log(\\log N))$ per block. The two aforementioned results are\nbuilt upon two pillars: a versatile framework that generates codes on the basis\nof channel polarization, and a calculus-probability machinery that evaluates\nthe performances of codes. The framework that generates codes and the machinery\nthat evaluates codes can be extended to many other scenarios in network\ninformation theory. To name a few: lossless compression, lossy compression,\nSlepian-Wolf, Wyner-Ziv, multiple access channel, wiretap channel, and\nbroadcast channel. In each scenario, the adapted notions of error probability\nand rate approach their limits at the same paces as specified above.",
    "descriptor": "\nComments: This is my PhD dissertation in single line spacing\n",
    "authors": [
      "Hsin-Po Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06420"
  },
  {
    "id": "arXiv:2107.06423",
    "title": "Learning to Recommend Items to Wikidata Editors",
    "abstract": "Wikidata is an open knowledge graph built by a global community of\nvolunteers. As it advances in scale, it faces substantial challenges around\neditor engagement. These challenges are in terms of both attracting new editors\nto keep up with the sheer amount of work and retaining existing editors.\nExperience from other online communities and peer-production systems, including\nWikipedia, suggests that personalised recommendations could help, especially\nnewcomers, who are sometimes unsure about how to contribute best to an ongoing\neffort. For this reason, we propose a recommender system WikidataRec for\nWikidata items. The system uses a hybrid of content-based and collaborative\nfiltering techniques to rank items for editors relying on both item features\nand item-editor previous interaction. A neural network, named a neural mixture\nof representations, is designed to learn fine weights for the combination of\nitem-based representations and optimize them with editor-based representation\nby item-editor interaction. To facilitate further research in this space, we\nalso create two benchmark datasets, a general-purpose one with 220,000 editors\nresponsible for 14 million interactions with 4 million items and a second one\nfocusing on the contributions of more than 8,000 more active editors. We\nperform an offline evaluation of the system on both datasets with promising\nresults. Our code and datasets are available at\nhttps://github.com/WikidataRec-developer/Wikidata_Recommender.",
    "descriptor": "",
    "authors": [
      "Kholoud AlGhamdi",
      "Miaojing Shi",
      "Elena Simperl"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06423"
  },
  {
    "id": "arXiv:2107.06424",
    "title": "Tourbillon: a Physically Plausible Neural Architecture",
    "abstract": "In a physical neural system, backpropagation is faced with a number of\nobstacles including: the need for labeled data, the violation of the locality\nlearning principle, the need for symmetric connections, and the lack of\nmodularity. Tourbillon is a new architecture that addresses all these\nlimitations. At its core, it consists of a stack of circular autoencoders\nfollowed by an output layer. The circular autoencoders are trained in\nself-supervised mode by recirculation algorithms and the top layer in\nsupervised mode by stochastic gradient descent, with the option of propagating\nerror information through the entire stack using non-symmetric connections.\nWhile the Tourbillon architecture is meant primarily to address physical\nconstraints, and not to improve current engineering applications of deep\nlearning, we demonstrate its viability on standard benchmark datasets including\nMNIST, Fashion MNIST, and CIFAR10. We show that Tourbillon can achieve\ncomparable performance to models trained with backpropagation and outperform\nmodels that are trained with other physically plausible algorithms, such as\nfeedback alignment.",
    "descriptor": "",
    "authors": [
      "Mohammadamin Tavakoli",
      "Pierre Baldi",
      "Peter Sadowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06424"
  },
  {
    "id": "arXiv:2107.06426",
    "title": "TSCAN : Dialog Structure discovery using SCAN",
    "abstract": "Can we discover dialog structure by dividing utterances into labelled\nclusters. Can these labels be generated from the data. Typically for dialogs we\nneed an ontology and use that to discover structure, however by using\nunsupervised classification and self-labelling we are able to intuit this\nstructure without any labels or ontology. In this paper we apply SCAN (Semantic\nClustering using Nearest Neighbors) to dialog data. We used BERT for pretext\ntask and an adaptation of SCAN for clustering and self labeling. These clusters\nare used to identify transition probabilities and create the dialog structure.\nThe self-labelling method used for SCAN makes these structures interpretable as\nevery cluster has a label. As the approach is unsupervised, evaluation metrics\nis a challenge, we use statistical measures as proxies for structure quality",
    "descriptor": "",
    "authors": [
      "Apurba Nath",
      "Aayush Kubba"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06426"
  },
  {
    "id": "arXiv:2107.06427",
    "title": "Sequential Recommendation for Cold-start Users with Meta Transitional  Learning",
    "abstract": "A fundamental challenge for sequential recommenders is to capture the\nsequential patterns of users toward modeling how users transit among items. In\nmany practical scenarios, however, there are a great number of cold-start users\nwith only minimal logged interactions. As a result, existing sequential\nrecommendation models will lose their predictive power due to the difficulties\nin learning sequential patterns over users with only limited interactions. In\nthis work, we aim to improve sequential recommendation for cold-start users\nwith a novel framework named MetaTL, which learns to model the transition\npatterns of users through meta-learning. Specifically, the proposed MetaTL: (i)\nformulates sequential recommendation for cold-start users as a few-shot\nlearning problem; (ii) extracts the dynamic transition patterns among users\nwith a translation-based architecture; and (iii) adopts meta transitional\nlearning to enable fast learning for cold-start users with only limited\ninteractions, leading to accurate inference of sequential interactions.",
    "descriptor": "\nComments: Accepted by SIGIR2021\n",
    "authors": [
      "Jianling Wang",
      "Kaize Ding",
      "James Caverlee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06427"
  },
  {
    "id": "arXiv:2107.06433",
    "title": "A New Parallel Algorithm for Sinkhorn Word-Movers Distance and Its  Performance on PIUMA and Xeon CPU",
    "abstract": "The Word Movers Distance (WMD) measures the semantic dissimilarity between\ntwo text documents by computing the cost of optimally moving all words of a\nsource/query document to the most similar words of a target document. Computing\nWMD between two documents is costly because it requires solving an optimization\nproblem that costs $O (V^3 \\log(V)) $ where $V$ is the number of unique words\nin the document. Fortunately, WMD can be framed as an Earth Mover's Distance\n(EMD) for which the algorithmic complexity can be reduced to $O(V^2)$ by adding\nan entropy penalty to the optimization problem and solving it using the\nSinkhorn-Knopp algorithm. Additionally, the computation can be made highly\nparallel by computing the WMD of a single query document against multiple\ntarget documents at once, for example by finding whether a given tweet is\nsimilar to any other tweets of a given day.\nIn this paper, we first present a shared-memory parallel Sinkhorn-Knopp\nalgorithm to compute the WMD of one document against many other documents by\nadopting the $ O(V^2)$ EMD algorithm. We then algorithmically transform the\noriginal $O(V^2)$ dense compute-heavy version into an equivalent sparse one\nwhich is mapped onto the new Intel Programmable Integrated Unified Memory\nArchitecture (PIUMA) system. The WMD parallel implementation achieves 67x\nspeedup on 96 cores across 4 NUMA sockets of an Intel Cascade Lake system. We\nalso show that PIUMA cores are around 1.2-2.6x faster than Xeon cores on\nSinkhorn-WMD and also provide better strong scaling.",
    "descriptor": "\nComments: 11 Pages. arXiv admin note: substantial text overlap with arXiv:2005.06727\n",
    "authors": [
      "Jesmin Jahan Tithi",
      "Fabrizio Petrini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.06433"
  },
  {
    "id": "arXiv:2107.06434",
    "title": "Centralized Model and Exploration Policy for Multi-Agent RL",
    "abstract": "Reinforcement learning (RL) in partially observable, fully cooperative\nmulti-agent settings (Dec-POMDPs) can in principle be used to address many\nreal-world challenges such as controlling a swarm of rescue robots or a\nsynchronous team of quadcopters. However, Dec-POMDPs are significantly harder\nto solve than single-agent problems, with the former being NEXP-complete and\nthe latter, MDPs, being just P-complete. Hence, current RL algorithms for\nDec-POMDPs suffer from poor sample complexity, thereby reducing their\napplicability to practical problems where environment interaction is costly.\nOur key insight is that using just a polynomial number of samples, one can\nlearn a centralized model that generalizes across different policies. We can\nthen optimize the policy within the learned model instead of the true system,\nreducing the number of environment interactions. We also learn a centralized\nexploration policy within our model that learns to collect additional data in\nstate-action regions with high model uncertainty. Finally, we empirically\nevaluate the proposed model-based algorithm, MARCO, in three cooperative\ncommunication tasks, where it improves sample efficiency by up to 20x.",
    "descriptor": "",
    "authors": [
      "Qizhen Zhang",
      "Chris Lu",
      "Animesh Garg",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06434"
  },
  {
    "id": "arXiv:2107.06440",
    "title": "Trellis BMA: Coded Trace Reconstruction on IDS Channels for DNA Storage",
    "abstract": "Sequencing a DNA strand, as part of the read process in DNA storage, produces\nmultiple noisy copies which can be combined to produce better estimates of the\noriginal strand; this is called trace reconstruction. One can reduce the error\nrate further by introducing redundancy in the write sequence and this is called\ncoded trace reconstruction. In this paper, we model the DNA storage channel as\nan insertion-deletion-substitution (IDS) channel and design both encoding\nschemes and low-complexity decoding algorithms for coded trace reconstruction.\nWe introduce Trellis BMA, a new reconstruction algorithm whose complexity is\nlinear in the number of traces, and compare its performance to previous\nalgorithms. Our results show that it reduces the error rate on both simulated\nand experimental data. The performance comparisons in this paper are based on a\nnew dataset of traces that will be publicly released with the paper. Our hope\nis that this dataset will enable research progress by allowing objective\ncomparisons between candidate algorithms.",
    "descriptor": "\nComments: Extended version of paper presented at ISIT 2021\n",
    "authors": [
      "Sundara Rajan Srinivasavaradhan",
      "Sivakanth Gopi",
      "Henry D. Pfister",
      "Sergey Yekhanin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06440"
  },
  {
    "id": "arXiv:2107.06442",
    "title": "GREN: Graph-Regularized Embedding Network for Weakly-Supervised Disease  Localization in X-ray images",
    "abstract": "Locating diseases in chest X-ray images with few careful annotations saves\nlarge human effort. Recent works approached this task with innovative\nweakly-supervised algorithms such as multi-instance learning (MIL) and class\nactivation maps (CAM), however, these methods often yield inaccurate or\nincomplete regions. One of the reasons is the neglection of the pathological\nimplications hidden in the relationship across anatomical regions within each\nimage and the relationship across images. In this paper, we argue that the\ncross-region and cross-image relationship, as contextual and compensating\ninformation, is vital to obtain more consistent and integral regions. To model\nthe relationship, we propose the Graph Regularized Embedding Network (GREN),\nwhich leverages the intra-image and inter-image information to locate diseases\non chest X-ray images. GREN uses a pre-trained U-Net to segment the lung lobes,\nand then models the intra-image relationship between the lung lobes using an\nintra-image graph to compare different regions. Meanwhile, the relationship\nbetween in-batch images is modeled by an inter-image graph to compare multiple\nimages. This process mimics the training and decision-making process of a\nradiologist: comparing multiple regions and images for diagnosis. In order for\nthe deep embedding layers of the neural network to retain structural\ninformation (important in the localization task), we use the Hash coding and\nHamming distance to compute the graphs, which are used as regularizers to\nfacilitate training. By means of this, our approach achieves the\nstate-of-the-art result on NIH chest X-ray dataset for weakly-supervised\ndisease localization. Our codes are accessible online.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Baolian Qi",
      "Gangming Zhao",
      "Xin Wei",
      "Chaowei Fang",
      "Chengwei Pan",
      "Jinpeng Li",
      "Huiguang He",
      "Licheng Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06442"
  },
  {
    "id": "arXiv:2107.06445",
    "title": "MSFNet:Multi-scale features network for monocular depth estimation",
    "abstract": "In recent years, monocular depth estimation is applied to understand the\nsurrounding 3D environment and has made great progress. However, there is an\nill-posed problem on how to gain depth information directly from a single\nimage. With the rapid development of deep learning, this problem is possible to\nbe solved. Although more and more approaches are proposed one after another,\nmost of existing methods inevitably lost details due to continuous downsampling\nwhen mapping from RGB space to depth space. To the end, we design a Multi-scale\nFeatures Network (MSFNet), which consists of Enhanced Diverse Attention (EDA)\nmodule and Upsample-Stage Fusion (USF) module. The EDA module employs the\nspatial attention method to learn significant spatial information, while USF\nmodule complements low-level detail information with high-level semantic\ninformation from the perspective of multi-scale feature fusion to improve the\npredicted effect. In addition, since the simple samples are always trained to a\nbetter effect first, the hard samples are difficult to converge. Therefore, we\ndesign a batch-loss to assign large loss factors to the harder samples in a\nbatch. Experiments on NYU-Depth V2 dataset and KITTI dataset demonstrate that\nour proposed approach is more competitive with the state-of-the-art methods in\nboth qualitative and quantitative evaluation.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Meiqi Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06445"
  },
  {
    "id": "arXiv:2107.06446",
    "title": "Hierarchical Associative Memory",
    "abstract": "Dense Associative Memories or Modern Hopfield Networks have many appealing\nproperties of associative memory. They can do pattern completion, store a large\nnumber of memories, and can be described using a recurrent neural network with\na degree of biological plausibility and rich feedback between the neurons. At\nthe same time, up until now all the models of this class have had only one\nhidden layer, and have only been formulated with densely connected network\narchitectures, two aspects that hinder their machine learning applications.\nThis paper tackles this gap and describes a fully recurrent model of\nassociative memory with an arbitrary large number of layers, some of which can\nbe locally connected (convolutional), and a corresponding energy function that\ndecreases on the dynamical trajectory of the neurons' activations. The memories\nof the full network are dynamically \"assembled\" using primitives encoded in the\nsynaptic weights of the lower layers, with the \"assembling rules\" encoded in\nthe synaptic weights of the higher layers. In addition to the bottom-up\npropagation of information, typical of commonly used feedforward neural\nnetworks, the model described has rich top-down feedback from higher layers\nthat help the lower-layer neurons to decide on their response to the input\nstimuli.",
    "descriptor": "",
    "authors": [
      "Dmitry Krotov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06446"
  },
  {
    "id": "arXiv:2107.06456",
    "title": "AID-Purifier: A Light Auxiliary Network for Boosting Adversarial Defense",
    "abstract": "We propose an AID-purifier that can boost the robustness of\nadversarially-trained networks by purifying their inputs. AID-purifier is an\nauxiliary network that works as an add-on to an already trained main\nclassifier. To keep it computationally light, it is trained as a discriminator\nwith a binary cross-entropy loss. To obtain additionally useful information\nfrom the adversarial examples, the architecture design is closely related to\ninformation maximization principles where two layers of the main classification\nnetwork are piped to the auxiliary network. To assist the iterative\noptimization procedure of purification, the auxiliary network is trained with\nAVmixup. AID-purifier can be used together with other purifiers such as\nPixelDefend for an extra enhancement. The overall results indicate that the\nbest performing adversarially-trained networks can be enhanced by the best\nperforming purification networks, where AID-purifier is a competitive candidate\nthat is light and robust.",
    "descriptor": "",
    "authors": [
      "Duhun Hwang",
      "Eunjung Lee",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06456"
  },
  {
    "id": "arXiv:2107.06459",
    "title": "Adaptive Two-Layer ReLU Neural Network: II. Ritz Approximation to  Elliptic PDEs",
    "abstract": "In this paper, we study adaptive neuron enhancement (ANE) method for solving\nself-adjoint second-order elliptic partial differential equations (PDEs). The\nANE method is a self-adaptive method generating a two-layer spline NN and a\nnumerical integration mesh such that the approximation accuracy is within the\nprescribed tolerance. Moreover, the ANE method provides a natural process for\nobtaining a good initialization which is crucial for training nonlinear\noptimization problem.\nThe underlying PDE is discretized by the Ritz method using a two-layer spline\nneural network based on either the primal or dual formulations that minimize\nthe respective energy or complimentary functionals. Essential boundary\nconditions are imposed weakly through the functionals with proper norms. It is\nproved that the Ritz approximation is the best approximation in the energy\nnorm; moreover, effect of numerical integration for the Ritz approximation is\nanalyzed as well. Two estimators for adaptive neuron enhancement method are\nintroduced, one is the so-called recovery estimator and the other is the\nleast-squares estimator. Finally, numerical results for diffusion problems with\neither corner or intersecting interface singularities are presented.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Min Liu",
      "Zhiqiang Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06459"
  },
  {
    "id": "arXiv:2107.06464",
    "title": "A class of APcN power functions over finite fields of even  characteristic",
    "abstract": "In this paper, we investigate the power functions $F(x)=x^d$ over the finite\nfield $\\mathbb{F}_{2^{4n}}$, where $n$ is a positive integer and\n$d=2^{3n}+2^{2n}+2^{n}-1$. It is proved that $F(x)=x^d$ is APcN at certain\n$c$'s in $\\mathbb{F}_{2^{4n}}$, and it is the second class of APcN power\nfunctions over finite fields of even characteristic. Further, the\n$c$-differential spectrum of these power functions is also determined.",
    "descriptor": "",
    "authors": [
      "Ziran Tu",
      "Xiangyong Zeng",
      "Yupeng Jiang",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06464"
  },
  {
    "id": "arXiv:2107.06466",
    "title": "Going Beyond Linear RL: Sample Efficient Neural Function Approximation",
    "abstract": "Deep Reinforcement Learning (RL) powered by neural net approximation of the Q\nfunction has had enormous empirical success. While the theory of RL has\ntraditionally focused on linear function approximation (or eluder dimension)\napproaches, little is known about nonlinear RL with neural net approximations\nof the Q functions. This is the focus of this work, where we study function\napproximation with two-layer neural networks (considering both ReLU and\npolynomial activation functions). Our first result is a computationally and\nstatistically efficient algorithm in the generative model setting under\ncompleteness for two-layer neural networks. Our second result considers this\nsetting but under only realizability of the neural net function class. Here,\nassuming deterministic dynamics, the sample complexity scales linearly in the\nalgebraic dimension. In all cases, our results significantly improve upon what\ncan be attained with linear (or eluder dimension) methods.",
    "descriptor": "",
    "authors": [
      "Baihe Huang",
      "Kaixuan Huang",
      "Sham M. Kakade",
      "Jason D. Lee",
      "Qi Lei",
      "Runzhe Wang",
      "Jiaqi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06466"
  },
  {
    "id": "arXiv:2107.06469",
    "title": "Model-Parallel Model Selection for Deep Learning Systems",
    "abstract": "As deep learning becomes more expensive, both in terms of time and compute,\ninefficiencies in machine learning (ML) training prevent practical usage of\nstate-of-the-art models for most users. The newest model architectures are\nsimply too large to be fit onto a single processor. To address the issue, many\nML practitioners have turned to model parallelism as a method of distributing\nthe computational requirements across several devices. Unfortunately, the\nsequential nature of neural networks causes very low efficiency and device\nutilization in model parallel training jobs. We propose a new form of \"shard\nparallelism\" combining task and model parallelism, then package it into a\nframework we name Hydra. Hydra recasts the problem of model parallelism in the\nmulti-model context to produce a fine-grained parallel workload of independent\nmodel shards, rather than independent models. This new parallel design promises\ndramatic speedups relative to the traditional model parallelism paradigm.",
    "descriptor": "\nComments: 2 pages, 3 figures. 1st place winner of ACM SIGMOD '21 Student Research Competition. Appeared in ACM SIGMOD/PODS '21 Proceedings\n",
    "authors": [
      "Kabir Nagrecha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06469"
  },
  {
    "id": "arXiv:2107.06471",
    "title": "Shock capturing schemes based on nonuniform nonlinear weighted  interpolation for conservation laws and their application as subcell limiters  for FR/CPR",
    "abstract": "A series of shock capturing schemes based on nonuniform nonlinear weighted\ninterpolation on nonuniform points are developed for conservation laws.\nSmoothness indicator and discrete conservation laws are discussed. To make fair\ncomparisons between different types of schemes, the properties of eigenvalues\nof spatial discretization matrices are proved. And the proposed schemes are\ncompared with Weighted Compact Nonlinear Schemes (WCNS) and Flux Reconstruction\nor Correction Procedure via Reconstruction (FR/CPR) in dispersion, dissipation\nproperties and numerical accuracy. Then, the proposed shock capturing schemes\nare used as subcell limiters for high-order FR/CPR and the hybrid scheme has\nsuperiority in data transformation and satisfying discrete conservation laws.\nAccuracy, discrete conservation laws and shock capturing properties are tested.\nNumerical results in one and two dimensions are provided to illustrate that the\nproposed schemes have good properties in shock capturing and can be applied as\nsubcell limiters for FR/CPR.",
    "descriptor": "",
    "authors": [
      "Huajun Zhu",
      "Huayong Liu",
      "Zhen-Guo Yan",
      "Guoquan Shi",
      "Xiaogang Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06471"
  },
  {
    "id": "arXiv:2107.06472",
    "title": "Linking Health News to Research Literature",
    "abstract": "Accurately linking news articles to scientific research works is a critical\ncomponent in a number of applications, such as measuring the social impact of a\nresearch work and detecting inaccuracies or distortions in science news.\nAlthough the lack of links between news and literature has been a challenge in\nthese applications, it is a relatively unexplored research problem. In this\npaper we designed and evaluated a new approach that consists of (1) augmenting\nlatest named-entity recognition techniques to extract various metadata, and (2)\ndesigning a new elastic search engine that can facilitate the use of enriched\nmetadata queries. To evaluate our approach, we constructed two datasets of\npaired news articles and research papers: one is used for training models to\nextract metadata, and the other for evaluation. Our experiments showed that the\nnew approach performed significantly better than a baseline approach used by\naltmetric.com (0.89 vs 0.32 in terms of top-1 accuracy). To further demonstrate\nthe effectiveness of the approach, we also conducted a study on 37,600\nhealth-related press releases published on EurekAlert!, which showed that our\napproach was able to identify the corresponding research papers with a top-1\naccuracy of at least 0.97.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Jun Wang",
      "Bei Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.06472"
  },
  {
    "id": "arXiv:2107.06475",
    "title": "Generative and reproducible benchmarks for comprehensive evaluation of  machine learning classifiers",
    "abstract": "Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.",
    "descriptor": "\nComments: 12 pages, 3 figures with subfigures\n",
    "authors": [
      "Patryk Orzechowski",
      "Jason H. Moore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06475"
  },
  {
    "id": "arXiv:2107.06476",
    "title": "Adaptability and the Pivot Penalty in Science",
    "abstract": "The ability to confront new questions, opportunities, and challenges is of\nfundamental importance to human progress and the resilience of human societies,\nyet the capacity of science to meet new demands remains poorly understood. Here\nwe deploy a new measurement framework to investigate the scientific response to\nthe COVID-19 pandemic and the adaptability of science as a whole. We find that\nscience rapidly shifted to engage COVID-19 following the advent of the virus,\nwith scientists across all fields making large jumps from their prior research\nstreams. However, this adaptive response reveals a pervasive \"pivot penalty\",\nwhere the impact of the new research steeply declines the further the\nscientists move from their prior work. The pivot penalty is severe amidst\nCOVID-19 research, but it is not unique to COVID-19. Rather it applies nearly\nuniversally across the sciences, and has been growing in magnitude over the\npast five decades. While further features condition pivoting, including a\nscientist's career stage, prior expertise and impact, collaborative scale, the\nuse of new coauthors, and funding, we find that the pivot penalty persists and\nremains substantial regardless of these features, suggesting the pivot penalty\nacts as a fundamental friction that governs science's ability to adapt. The\npivot penalty not only holds key implications for the design of the scientific\nsystem and human capacity to confront emergent challenges through scientific\nadvance, but may also be relevant to other social and economic systems, where\nshifting to meet new demands is central to survival and success.",
    "descriptor": "",
    "authors": [
      "Ryan Hill",
      "Yian Yin",
      "Carolyn Stein",
      "Dashun Wang",
      "Benjamin F. Jones"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06476"
  },
  {
    "id": "arXiv:2107.06481",
    "title": "A Convolutional Neural Network Approach to the Classification of  Engineering Models",
    "abstract": "This paper presents a deep learning approach for the classification of\nEngineering (CAD) models using Convolutional Neural Networks (CNNs). Owing to\nthe availability of large annotated datasets and also enough computational\npower in the form of GPUs, many deep learning-based solutions for object\nclassification have been proposed of late, especially in the domain of images\nand graphical models. Nevertheless, very few solutions have been proposed for\nthe task of functional classification of CAD models. Hence, for this research,\nCAD models have been collected from Engineering Shape Benchmark (ESB), National\nDesign Repository (NDR) and augmented with newer models created using a\nmodelling software to form a dataset - 'CADNET'. It is proposed to use a\nresidual network architecture for CADNET, inspired by the popular ResNet. A\nweighted Light Field Descriptor (LFD) scheme is chosen as the method of feature\nextraction, and the generated images are fed as inputs to the CNN. The problem\nof class imbalance in the dataset is addressed using a class weights approach.\nExperiments have been conducted with other signatures such as geodesic distance\netc. using deep networks as well as other network architectures on the CADNET.\nThe LFD-based CNN approach using the proposed network architecture, along with\ngradient boosting yielded the best classification accuracy on CADNET.",
    "descriptor": "",
    "authors": [
      "Bharadwaj Manda",
      "Pranjal Bhaskare",
      "Ramanathan Muthuganapathy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06481"
  },
  {
    "id": "arXiv:2107.06483",
    "title": "From Machine Translation to Code-Switching: Generating High-Quality  Code-Switched Text",
    "abstract": "Generating code-switched text is a problem of growing interest, especially\ngiven the scarcity of corpora containing large volumes of real code-switched\ntext. In this work, we adapt a state-of-the-art neural machine translation\nmodel to generate Hindi-English code-switched sentences starting from\nmonolingual Hindi sentences. We outline a carefully designed curriculum of\npretraining steps, including the use of synthetic code-switched text, that\nenable the model to generate high-quality code-switched text. Using text\ngenerated from our model as data augmentation, we show significant reductions\nin perplexity on a language modeling task, compared to using text from other\ngenerative models of CS text. We also show improvements using our text for a\ndownstream code-switched natural language inference task. Our generated text is\nfurther subjected to a rigorous evaluation using a human evaluation study and a\nrange of objective metrics, where we show performance comparable (and sometimes\neven superior) to code-switched text obtained via crowd workers who are native\nHindi speakers.",
    "descriptor": "\nComments: In Proceedings of The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Ishan Tarunesh",
      "Syamantak Kumar",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06483"
  },
  {
    "id": "arXiv:2107.06484",
    "title": "Robust and Recursively Feasible Real-Time Trajectory Planning in Unknown  Environments",
    "abstract": "Motion planners for mobile robots in unknown environments face the challenge\nof simultaneously maintaining both robustness against unmodeled uncertainties\nand persistent feasibility of the trajectory-finding problem. That is, while\ndealing with uncertainties, a motion planner must update its trajectory,\nadapting to the newly revealed environment in real-time; failing to do so may\ninvolve unsafe circumstances. Many existing planning algorithms guarantee these\nby maintaining the clearance needed to perform an emergency brake, which is\nitself a robust and persistently feasible maneuver. However, such maneuvers are\nnot applicable for systems in which braking is impossible or risky, such as\nfixed-wing aircraft. To that end, we propose a real-time robust planner that\nrecursively guarantees persistent feasibility without any need of braking. The\nplanner ensures robustness against bounded uncertainties and persistent\nfeasibility by constructing a loop of sequentially composed funnels, starting\nfrom the receding horizon local trajectory's forward reachable set. We\nimplement the proposed algorithm for a robotic car tracking a speed-fixed\nreference trajectory. The experiment results show that the proposed algorithm\ncan be run at faster than 16 Hz, while successfully keeping the system away\nfrom entering any dead-end, to maintain safety and feasibility.",
    "descriptor": "\nComments: 8 pages, 11 figures, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) accepted\n",
    "authors": [
      "Inkyu Jang",
      "Dongjae Lee",
      "Seungjae Lee",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06484"
  },
  {
    "id": "arXiv:2107.06488",
    "title": "Behavior Analysis and Design of Concrete-Filled Steel Circular-Tube  Short Columns Subjected to Axial Compression",
    "abstract": "In this paper, a new finite element (FE) model using ABAQUS software was\ndeveloped to investigate the compressive behavior of Concrete-Filled Steel\nCircular-Tube (CFSCT) columns. Experimental studies indicated that the\nconfinement offered by the circular steel tube in a CFSCT column increased both\nthe strength and ductility of the filled concrete. Base on the database of 663\ntest results CFSCT columns under axial compression are collected from the\navailable literature, a formula to determine the lateral confining pressures on\nconcrete. Concrete-Damaged Plasticity Model (CDPM) and parameters are available\nin ABAQUS are used in the analysis. From results analysis, a proposed formula\nfor predicting ultimate load by determining intensification and diminution for\nconcrete and steel. The proposed formula is then compared with the FE model,\nthe previous study, and the design code current in strength prediction of CFSCT\ncolumns under compression. The comparative result shows that the FE model, the\nproposed formula is more stable and accurate than the previous study and\ncurrent standards when using material normal or high strength.",
    "descriptor": "\nComments: 44 pages, 20 figures, an international paper, 7 tables, 2 authors, Phu-Cuong Nguyen is the corresponding author, Duc-Duy Pham is Master student\n",
    "authors": [
      "Duc-Duy Pham",
      "Phu-Cuong Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.06488"
  },
  {
    "id": "arXiv:2107.06490",
    "title": "Greedy Spanners in Euclidean Spaces Admit Sublinear Separators",
    "abstract": "The greedy spanner in a low dimensional Euclidean space is a fundamental\ngeometric construction that has been extensively studied over three decades as\nit possesses the two most basic properties of a good spanner: constant maximum\ndegree and constant lightness. Recently, Eppstein and Khodabandeh showed that\nthe greedy spanner in $\\mathbb{R}^2$ admits a sublinear separator in a strong\nsense: any subgraph of $k$ vertices of the greedy spanner in $\\mathbb{R}^2$ has\na separator of size $O(\\sqrt{k})$. Their technique is inherently planar and is\nnot extensible to higher dimensions. They left showing the existence of a small\nseparator for the greedy spanner in $\\mathbb{R}^d$ for any constant $d\\geq 3$\nas an open problem. In this paper, we resolve the problem of Eppstein and\nKhodabandeh by showing that any subgraph of $k$ vertices of the greedy spanner\nin $\\mathbb{R}^d$ has a separator of size $O(k^{1-1/d})$. We introduce a new\ntechnique that gives a simple characterization for any geometric graph to have\na sublinear separator that we dub $\\tau$-lanky: a geometric graph is\n$\\tau$-lanky if any ball of radius $r$ cuts at most $\\tau$ edges of length at\nleast $r$ in the graph. We show that any $\\tau$-lanky geometric graph of $n$\nvertices in $\\mathbb{R}^d$ has a separator of size $O(\\tau n^{1-1/d})$. We then\nderive our main result by showing that the greedy spanner is $O(1)$-lanky. We\nindeed obtain a more general result that applies to unit ball graphs and point\nsets of low fractal dimensions in $\\mathbb{R}^d$. Our technique naturally\nextends to doubling metrics. We use the $\\tau$-lanky characterization to show\nthat there exists a $(1+\\epsilon)$-spanner for doubling metrics of dimension\n$d$ with a constant maximum degree and a separator of size\n$O(n^{1-\\frac{1}{d}})$; this result resolves an open problem posed by Abam and\nHar-Peled a decade ago.",
    "descriptor": "\nComments: Abstract shorted to meet Arxiv character limit\n",
    "authors": [
      "Hung Le",
      "Cuong Than"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.06490"
  },
  {
    "id": "arXiv:2107.06492",
    "title": "RCLC: ROI-based joint conventional and learning video compression",
    "abstract": "COVID-19 leads to the high demand for remote interactive systems ever seen.\nOne of the key elements of these systems is video streaming, which requires a\nvery high network bandwidth due to its specific real-time demand, especially\nwith high-resolution video. Existing video compression methods are struggling\nin the trade-off between video quality and the speed requirement. Addressed\nthat the background information rarely changes in most remote meeting cases, we\nintroduce a Region-Of-Interests (ROI) based video compression framework (named\nRCLC) that leverages the cutting-edge learning-based and conventional\ntechnologies. In RCLC, each coming frame is marked as a background-updating\n(BU) or ROI-updating (RU) frame. By applying the conventional video codec, the\nBU frame is compressed with low-quality and high-compression, while the ROI\nfrom RU-frame is compressed with high-quality and low-compression. The\nlearning-based methods are applied to detect the ROI, blend background-ROI, and\nenhance video quality. The experimental results show that our RCLC can reduce\nup to 32.55\\% BD-rate for the ROI region compared to H.265 video codec under a\nsimilar compression time with 1080p resolution.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Trinh Man Hoang",
      "Jinjia Zhou"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06492"
  },
  {
    "id": "arXiv:2107.06493",
    "title": "Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding",
    "abstract": "This paper proposes a serialized multi-layer multi-head attention for neural\nspeaker embedding in text-independent speaker verification. In prior works,\nframe-level features from one layer are aggregated to form an utterance-level\nrepresentation. Inspired by the Transformer network, our proposed method\nutilizes the hierarchical architecture of stacked self-attention mechanisms to\nderive refined features that are more correlated with speakers. Serialized\nattention mechanism contains a stack of self-attention modules to create\nfixed-dimensional representations of speakers. Instead of utilizing multi-head\nattention in parallel, the proposed serialized multi-layer multi-head attention\nis designed to aggregate and propagate attentive statistics from one layer to\nthe next in a serialized manner. In addition, we employ an input-aware query\nfor each utterance with the statistics pooling. With more layers stacked, the\nneural network can learn more discriminative speaker embeddings. Experiment\nresults on VoxCeleb1 dataset and SITW dataset show that our proposed method\noutperforms other baseline methods, including x-vectors and other x-vectors +\nconventional attentive pooling approaches by 9.7% in EER and 8.1% in DCF0.01.",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Hongning Zhu",
      "Kong Aik Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06493"
  },
  {
    "id": "arXiv:2107.06495",
    "title": "GgViz: Accelerating Large-Scale Esports Game Analysis",
    "abstract": "Game review is crucial for teams, players and media staff in sports. Despite\nits importance, game review is work-intensive and hard to scale. Recent\nadvances in sports data collection have introduced systems that couple video\nwith clustering techniques to allow for users to query sports situations of\ninterest through sketching. However, due to data limitations, as well as\ndifferences in the sport itself, esports has seen a dearth of such systems. In\nthis paper, we leverage emerging data for Counter-Strike: Global Offensive\n(CSGO) to develop ggViz, a novel visual analytics system that allows users to\nquery a large esports data set for similar plays by drawing situations of\ninterest. Along with ggViz, we also present a performant retrieval algorithm\nthat can easily scale to hundreds of millions of game situations. We\ndemonstrate ggViz's utility through detailed cases studies and interviews with\nstaff from professional esports teams.",
    "descriptor": "",
    "authors": [
      "Peter Xenopoulos",
      "Joao Rulff",
      "Claudio Silva"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06495"
  },
  {
    "id": "arXiv:2107.06499",
    "title": "Deduplicating Training Data Makes Language Models Better",
    "abstract": "We find that existing language modeling datasets contain many near-duplicate\nexamples and long repetitive substrings. As a result, over 1% of the unprompted\noutput of language models trained on these datasets is copied verbatim from the\ntraining data. We develop two tools that allow us to deduplicate training\ndatasets -- for example removing from C4 a single 61 word English sentence that\nis repeated over 60,000 times. Deduplication allows us to train models that\nemit memorized text ten times less frequently and require fewer train steps to\nachieve the same or better accuracy. We can also reduce train-test overlap,\nwhich affects over 4% of the validation set of standard datasets, thus allowing\nfor more accurate evaluation. We release code for reproducing our work and\nperforming dataset deduplication at\nhttps://github.com/google-research/deduplicate-text-datasets.",
    "descriptor": "",
    "authors": [
      "Katherine Lee",
      "Daphne Ippolito",
      "Andrew Nystrom",
      "Chiyuan Zhang",
      "Douglas Eck",
      "Chris Callison-Burch",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06499"
  },
  {
    "id": "arXiv:2107.06501",
    "title": "AdvFilter: Predictive Perturbation-aware Filtering against Adversarial  Attack via Multi-domain Learning",
    "abstract": "High-level representation-guided pixel denoising and adversarial training are\nindependent solutions to enhance the robustness of CNNs against adversarial\nattacks by pre-processing input data and re-training models, respectively. Most\nrecently, adversarial training techniques have been widely studied and improved\nwhile the pixel denoising-based method is getting less attractive. However, it\nis still questionable whether there exists a more advanced pixel\ndenoising-based method and whether the combination of the two solutions\nbenefits each other. To this end, we first comprehensively investigate two\nkinds of pixel denoising methods for adversarial robustness enhancement (i.e.,\nexisting additive-based and unexplored filtering-based methods) under the loss\nfunctions of image-level and semantic-level restorations, respectively, showing\nthat pixel-wise filtering can obtain much higher image quality (e.g., higher\nPSNR) as well as higher robustness (e.g., higher accuracy on adversarial\nexamples) than existing pixel-wise additive-based method. However, we also\nobserve that the robustness results of the filtering-based method rely on the\nperturbation amplitude of adversarial examples used for training. To address\nthis problem, we propose predictive perturbation-aware pixel-wise filtering,\nwhere dual-perturbation filtering and an uncertainty-aware fusion module are\ndesigned and employed to automatically perceive the perturbation amplitude\nduring the training and testing process. The proposed method is termed as\nAdvFilter. Moreover, we combine adversarial pixel denoising methods with three\nadversarial training-based methods, hinting that considering data and models\njointly is able to achieve more robust CNNs. The experiments conduct on\nNeurIPS-2017DEV, SVHN, and CIFAR10 datasets and show the advantages over\nenhancing CNNs' robustness, high generalization to different models, and noise\nlevels.",
    "descriptor": "\nComments: This work has been accepted to ACM-MM 2021\n",
    "authors": [
      "Yihao Huang",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Weikai Miao",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06501"
  },
  {
    "id": "arXiv:2107.06505",
    "title": "Few-shot Neural Human Performance Rendering from Sparse RGBD Videos",
    "abstract": "Recent neural rendering approaches for human activities achieve remarkable\nview synthesis results, but still rely on dense input views or dense training\nwith all the capture frames, leading to deployment difficulty and inefficient\ntraining overload. However, existing advances will be ill-posed if the input is\nboth spatially and temporally sparse. To fill this gap, in this paper we\npropose a few-shot neural human rendering approach (FNHR) from only sparse RGBD\ninputs, which exploits the temporal and spatial redundancy to generate\nphoto-realistic free-view output of human activities. Our FNHR is trained only\non the key-frames which expand the motion manifold in the input sequences. We\nintroduce a two-branch neural blending to combine the neural point render and\nclassical graphics texturing pipeline, which integrates reliable observations\nover sparse key-frames. Furthermore, we adopt a patch-based adversarial\ntraining process to make use of the local redundancy and avoids over-fitting to\nthe key-frames, which generates fine-detailed rendering results. Extensive\nexperiments demonstrate the effectiveness of our approach to generate\nhigh-quality free view-point results for challenging human performances under\nthe sparse setting.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Anqi Pang",
      "Xin Chen",
      "Haimin Luo",
      "Minye Wu",
      "Jingyi Yu",
      "Lan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06505"
  },
  {
    "id": "arXiv:2107.06511",
    "title": "CNN-Cap: Effective Convolutional Neural Network Based Capacitance Models  for Full-Chip Parasitic Extraction",
    "abstract": "Accurate capacitance extraction is becoming more important for designing\nintegrated circuits under advanced process technology. The pattern matching\nbased full-chip extraction methodology delivers fast computational speed, but\nsuffers from large error, and tedious efforts on building capacitance models of\nthe increasing structure patterns. In this work, we propose an effective method\nfor building convolutional neural network (CNN) based capacitance models\n(called CNN-Cap) for two-dimensional (2-D) structures in full-chip capacitance\nextraction. With a novel grid-based data representation, the proposed method is\nable to model the pattern with a variable number of conductors, so that largely\nreduce the number of patterns. Based on the ability of ResNet architecture on\ncapturing spatial information and the proposed training skills, the obtained\nCNN-Cap exhibits much better performance over the multilayer perception neural\nnetwork based capacitance model while being more versatile. Extensive\nexperiments on a 55nm and a 15nm process technologies have demonstrated that\nthe error of total capacitance produced with CNN-Cap is always within 1.3% and\nthe error of produced coupling capacitance is less than 10% in over 99.5%\nprobability. CNN-Cap runs more than 4000X faster than 2-D field solver on a GPU\nserver, while it consumes negligible memory compared to the look-up table based\ncapacitance model.",
    "descriptor": "\nComments: 9 pages, 13 figures. Accepted at 2021 International Conference On Computer Aided Design (ICCAD)\n",
    "authors": [
      "Dingcheng Yang",
      "Wenjian Yu",
      "Yuanbo Guo",
      "Wenjie Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.06511"
  },
  {
    "id": "arXiv:2107.06512",
    "title": "On the Analysis of Adaptive-Rate Applications in Data-Centric Wireless  Ad-Hoc Networks",
    "abstract": "Adapting applications' data rates in multi-hop wireless ad-hoc networks is\ninherently challenging. Packet collision, channel contention, and queue buildup\ncontribute to packet loss but are difficult to manage in conventional TCP/IP\narchitecture. This work explores a data-centric approach based on Name Data\nNetworking (NDN) architecture, which is considered more suitable for wireless\nad-hoc networks. We show that the default NDN transport offers better\nperformance in linear topologies but struggles in more extensive networks due\nto high collision and contention caused by excessive Interests from\nout-of-order data retrieval and redundant data transmission from improper\nInterest lifetime setting as well as in-network caching. To fix these, we use\nround-trip hop count to limit Interest rate and Dynamic Interest Lifetime to\nminimize the negative effect of improper Interest lifetime. Finally, we analyze\nthe effect of in-network caching on transport performance and which scenarios\nmay benefit or suffer from it.",
    "descriptor": "\nComments: Accepted at The 2021 IEEE 46th Conference on Local Computer Networks (LCN)\n",
    "authors": [
      "Md Ashiqur Rahman",
      "Beichuan Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06512"
  },
  {
    "id": "arXiv:2107.06516",
    "title": "Learning Algebraic Recombination for Compositional Generalization",
    "abstract": "Neural sequence models exhibit limited compositional generalization ability\nin semantic parsing tasks. Compositional generalization requires algebraic\nrecombination, i.e., dynamically recombining structured expressions in a\nrecursive manner. However, most previous studies mainly concentrate on\nrecombining lexical units, which is an important but not sufficient part of\nalgebraic recombination. In this paper, we propose LeAR, an end-to-end neural\nmodel to learn algebraic recombination for compositional generalization. The\nkey insight is to model the semantic parsing task as a homomorphism between a\nlatent syntactic algebra and a semantic algebra, thus encouraging algebraic\nrecombination. Specifically, we learn two modules jointly: a Composer for\nproducing latent syntax, and an Interpreter for assigning semantic operations.\nExperiments on two realistic and comprehensive compositional generalization\nbenchmarks demonstrate the effectiveness of our model. The source code is\npublicly available at https://github.com/microsoft/ContextualSP.",
    "descriptor": "\nComments: ACL Findings 2021\n",
    "authors": [
      "Chenyao Liu",
      "Shengnan An",
      "Zeqi Lin",
      "Qian Liu",
      "Bei Chen",
      "Jian-Guang Lou",
      "Lijie Wen",
      "Nanning Zheng",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06516"
  },
  {
    "id": "arXiv:2107.06525",
    "title": "RIS-Enhanced Spectrum Sensing: How Many Reflecting Elements Are Required  to Achieve a Detection Probability Close to 1?",
    "abstract": "In this paper, we propose an reconfigurable intelligent surface (RIS)\nenhanced spectrum sensing system, in which the primary transmitter is equipped\nwith single antenna, the secondary transmitter is equipped with multiple\nantennas, and the RIS is employed to improve the detection performance. Without\nloss of generality, we adopt the maximum eigenvalue detection approach, and\npropose a corresponding analytical framework based on large dimensional random\nmatrix theory, to evaluate the detection probability in the asymptotic regime.\nBesides, the phase shift matrix of the RIS is designed with only the\nstatistical channel state information (CSI), which is shown to be quite\neffective when the RIS-related channels are of Rician fading or line-of-sight\n(LoS). With the designed phase shift matrix, the asymptotic distributions of\nthe equivalent channel gains are derived. Then, we provide the theoretical\npredictions about the number of reflecting elements (REs) required to achieve a\ndetection probability close to 1. Finally, we present the Monte-Carlo\nsimulation results to evaluate the accuracy of the proposed asymptotic\nanalytical framework for the detection probability and the validity of the\ntheoretical predictions about the number of REs required to achieve a detection\nprobability close to 1. Moreover, the simulation results show that the proposed\nRIS-enhanced spectrum sensing system can substantially improve the detection\nperformance.",
    "descriptor": "",
    "authors": [
      "Jungang Ge",
      "Ying-Chang Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06525"
  },
  {
    "id": "arXiv:2107.06530",
    "title": "Detection of Abnormal Behavior with Self-Supervised Gaze Estimation",
    "abstract": "Due to the recent outbreak of COVID-19, many classes, exams, and meetings\nhave been conducted non-face-to-face. However, the foundation for video\nconferencing solutions is still insufficient. So this technology has become an\nimportant issue. In particular, these technologies are essential for\nnon-face-to-face testing, and technology dissemination is urgent. In this\npaper, we present a single video conferencing solution using gaze estimation in\npreparation for these problems. Gaze is an important cue for the tasks such as\nanalysis of human behavior. Hence, numerous studies have been proposed to solve\ngaze estimation using deep learning, which is one of the most prominent methods\nup to date. We use these gaze estimation methods to detect abnormal behavior of\nvideo conferencing participants. Our contribution is as follows. i) We find and\napply the optimal network for the gaze estimation method and apply a\nself-supervised method to improve accuracy. ii) For anomaly detection, we\npresent a new dataset that aggregates the values of a new gaze, head pose, etc.\niii) We train newly created data on Multi Layer Perceptron (MLP) models to\ndetect anomaly behavior based on deep learning. We demonstrate the robustness\nof our method through experiments.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Suneung-Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06530"
  },
  {
    "id": "arXiv:2107.06532",
    "title": "Graph Jigsaw Learning for Cartoon Face Recognition",
    "abstract": "Cartoon face recognition is challenging as they typically have smooth color\nregions and emphasized edges, the key to recognize cartoon faces is to\nprecisely perceive their sparse and critical shape patterns. However, it is\nquite difficult to learn a shape-oriented representation for cartoon face\nrecognition with convolutional neural networks (CNNs). To mitigate this issue,\nwe propose the GraphJigsaw that constructs jigsaw puzzles at various stages in\nthe classification network and solves the puzzles with the graph convolutional\nnetwork (GCN) in a progressive manner. Solving the puzzles requires the model\nto spot the shape patterns of the cartoon faces as the texture information is\nquite limited. The key idea of GraphJigsaw is constructing a jigsaw puzzle by\nrandomly shuffling the intermediate convolutional feature maps in the spatial\ndimension and exploiting the GCN to reason and recover the correct layout of\nthe jigsaw fragments in a self-supervised manner. The proposed GraphJigsaw\navoids training the classification model with the deconstructed images that\nwould introduce noisy patterns and are harmful for the final classification.\nSpecially, GraphJigsaw can be incorporated at various stages in a top-down\nmanner within the classification model, which facilitates propagating the\nlearned shape patterns gradually. GraphJigsaw does not rely on any extra manual\nannotation during the training process and incorporates no extra computation\nburden at inference time. Both quantitative and qualitative experimental\nresults have verified the feasibility of our proposed GraphJigsaw, which\nconsistently outperforms other face recognition or jigsaw-based methods on two\npopular cartoon face datasets with considerable improvements.",
    "descriptor": "",
    "authors": [
      "Yong Li",
      "Lingjie Lao",
      "Zhen Cui",
      "Shiguang Shan",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06532"
  },
  {
    "id": "arXiv:2107.06533",
    "title": "Accelerating Distributed K-FAC with Smart Parallelism of Computing and  Communication Tasks",
    "abstract": "Distributed training with synchronous stochastic gradient descent (SGD) on\nGPU clusters has been widely used to accelerate the training process of deep\nmodels. However, SGD only utilizes the first-order gradient in model parameter\nupdates, which may take days or weeks. Recent studies have successfully\nexploited approximate second-order information to speed up the training\nprocess, in which the Kronecker-Factored Approximate Curvature (KFAC) emerges\nas one of the most efficient approximation algorithms for training deep models.\nYet, when leveraging GPU clusters to train models with distributed KFAC\n(D-KFAC), it incurs extensive computation as well as introduces extra\ncommunications during each iteration. In this work, we propose D-KFAC\n(SPD-KFAC) with smart parallelism of computing and communication tasks to\nreduce the iteration time. Specifically, 1) we first characterize the\nperformance bottlenecks of D-KFAC, 2) we design and implement a pipelining\nmechanism for Kronecker factors computation and communication with dynamic\ntensor fusion, and 3) we develop a load balancing placement for inverting\nmultiple matrices on GPU clusters. We conduct real-world experiments on a\n64-GPU cluster with 100Gb/s InfiniBand interconnect. Experimental results show\nthat our proposed SPD-KFAC training scheme can achieve 10%-35% improvement over\nstate-of-the-art algorithms.",
    "descriptor": "\nComments: 11 pages. Accepted to IEEE ICDCS 2021\n",
    "authors": [
      "Shaohuai Shi",
      "Lin Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06533"
  },
  {
    "id": "arXiv:2107.06537",
    "title": "Age of Information in Physical-Layer Network Coding Enabled Two-Way  Relay Networks",
    "abstract": "This paper investigates the information freshness of two-way relay networks\n(TWRN) operated with physical-layer network coding (PNC). Information freshness\nis quantified by age of information (AoI), defined as the time elapsed since\nthe generation time of the latest received information update. PNC reduces\ncommunication latency of TWRNs by turning superimposed electromagnetic waves\ninto network-coded messages so that end users can send update packets to each\nother via the relay more frequently. Although sending update packets more\nfrequently is potential to reduce AoI, how to deal with packet corruption has\nnot been well investigated. Specifically, if old packets are corrupted in any\nhop of a TWRN, one needs to decide the old packets to be dropped or to be\nretransmitted, e.g., new packets have recent information, but may require more\ntime to be delivered. We study the average AoI with and without ARQ in\nPNC-enabled TWRNs. We first consider a non-ARQ scheme where old packets are\nalways dropped when corrupted, referred to once-lost-then-drop (OLTD), and a\nclassical ARQ scheme with no packet lost, referred to as reliable packet\ntransmission (RPT). Interestingly, our analysis shows that neither the non-ARQ\nscheme nor the pure ARQ scheme achieves good average AoI. We then put forth an\nuplink-lost-then-drop (ULTD) protocol that combines packet drop and ARQ.\nExperiments on software-defined radio indicate that ULTD significantly\noutperforms OLTD and RPT in terms of average AoI. Although this paper focuses\non TWRNs, we believe the insight of ULTD applies generally to other two-hop\nnetworks. Our insight is that to achieve high information freshness, when\npackets are corrupted in the first hop, new packets should be generated and\nsent (i.e., old packets are discarded); when packets are corrupted in the\nsecond hop, old packets should be retransmitted until successful reception.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Haoyuan Pan",
      "Tse-Tin Chan",
      "Victor C. M. Leung",
      "Jianqiang Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06537"
  },
  {
    "id": "arXiv:2107.06538",
    "title": "Transformer with Peak Suppression and Knowledge Guidance for  Fine-grained Image Recognition",
    "abstract": "Fine-grained image recognition is challenging because discriminative clues\nare usually fragmented, whether from a single image or multiple images. Despite\ntheir significant improvements, most existing methods still focus on the most\ndiscriminative parts from a single image, ignoring informative details in other\nregions and lacking consideration of clues from other associated images. In\nthis paper, we analyze the difficulties of fine-grained image recognition from\na new perspective and propose a transformer architecture with the peak\nsuppression module and knowledge guidance module, which respects the\ndiversification of discriminative features in a single image and the\naggregation of discriminative clues among multiple images. Specifically, the\npeak suppression module first utilizes a linear projection to convert the input\nimage into sequential tokens. It then blocks the token based on the attention\nresponse generated by the transformer encoder. This module penalizes the\nattention to the most discriminative parts in the feature learning process,\ntherefore, enhancing the information exploitation of the neglected regions. The\nknowledge guidance module compares the image-based representation generated\nfrom the peak suppression module with the learnable knowledge embedding set to\nobtain the knowledge response coefficients. Afterwards, it formalizes the\nknowledge learning as a classification problem using response coefficients as\nthe classification scores. Knowledge embeddings and image-based representations\nare updated during training so that the knowledge embedding includes\ndiscriminative clues for different images. Finally, we incorporate the acquired\nknowledge embeddings into the image-based representations as comprehensive\nrepresentations, leading to significantly higher performance. Extensive\nevaluations on the six popular datasets demonstrate the advantage of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Xinda Liu",
      "Lili Wang",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06538"
  },
  {
    "id": "arXiv:2107.06543",
    "title": "TEACHING -- Trustworthy autonomous cyber-physical applications through  human-centred intelligence",
    "abstract": "This paper discusses the perspective of the H2020 TEACHING project on the\nnext generation of autonomous applications running in a distributed and highly\nheterogeneous environment comprising both virtual and physical resources\nspanning the edge-cloud continuum. TEACHING puts forward a human-centred vision\nleveraging the physiological, emotional, and cognitive state of the users as a\ndriver for the adaptation and optimization of the autonomous applications. It\ndoes so by building a distributed, embedded and federated learning system\ncomplemented by methods and tools to enforce its dependability, security and\nprivacy preservation. The paper discusses the main concepts of the TEACHING\napproach and singles out the main AI-related research challenges associated\nwith it. Further, we provide a discussion of the design choices for the\nTEACHING system to tackle the aforementioned challenges",
    "descriptor": "",
    "authors": [
      "Davide Bacciu",
      "Siranush Akarmazyan",
      "Eric Armengaud",
      "Manlio Bacco",
      "George Bravos",
      "Calogero Calandra",
      "Emanuele Carlini",
      "Antonio Carta",
      "Pietro Cassara",
      "Massimo Coppola",
      "Charalampos Davalas",
      "Patrizio Dazzi",
      "Maria Carmela Degennaro",
      "Daniele Di Sarli",
      "J\u00fcrgen Dobaj",
      "Claudio Gallicchio",
      "Sylvain Girbal",
      "Alberto Gotta",
      "Riccardo Groppo",
      "Vincenzo Lomonaco",
      "Georg Macher",
      "Daniele Mazzei",
      "Gabriele Mencagli",
      "Dimitrios Michail",
      "Alessio Micheli",
      "Roberta Peroglio",
      "Salvatore Petroni",
      "Rosaria Potenza",
      "Farank Pourdanesh",
      "Christos Sardianos",
      "Konstantinos Tserpes",
      "Fulvio Tagliab\u00f2",
      "Jakob Valtl",
      "Iraklis Varlamis",
      "Omar Veledar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06543"
  },
  {
    "id": "arXiv:2107.06546",
    "title": "ZR-2021VG: Zero-Resource Speech Challenge, Visually-Grounded Language  Modelling track, 2021 edition",
    "abstract": "We present the visually-grounded language modelling track that was introduced\nin the Zero-Resource Speech challenge, 2021 edition, 2nd round. We motivate the\nnew track and discuss participation rules in detail. We also present the two\nbaseline systems that were developed for this track.",
    "descriptor": "",
    "authors": [
      "Afra Alishahia",
      "Grzegorz Chrupa\u0142a",
      "Alejandrina Cristia",
      "Emmanuel Dupoux",
      "Bertrand Higy",
      "Marvin Lavechin",
      "Okko R\u00e4s\u00e4nen",
      "Chen Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06546"
  },
  {
    "id": "arXiv:2107.06547",
    "title": "The I-ADOPT Interoperability Framework for FAIRer data descriptions of  biodiversity",
    "abstract": "Biodiversity, the variation within and between species and ecosystems, is\nessential for human well-being and the equilibrium of the planet. It is\ncritical for the sustainable development of human society and is an important\nglobal challenge. Biodiversity research has become increasingly data-intensive\nand it deals with heterogeneous and distributed data made available by global\nand regional initiatives, such as GBIF, ILTER, LifeWatch, BODC, PANGAEA, and\nTERN, that apply different data management practices. In particular, a variety\nof metadata and semantic resources have been produced by these initiatives to\ndescribe biodiversity observations, introducing interoperability issues across\ndata management systems. To address these challenges, the InteroperAble\nDescriptions of Observable Property Terminology WG (I-ADOPT WG) was formed by a\ngroup of international terminology providers and data center managers in 2019\nwith the aim to build a common approach to describe what is observed, measured,\ncalculated, or derived. Based on an extensive analysis of existing semantic\nrepresentations of variables, the WG has recently published the I-ADOPT\nframework ontology to facilitate interoperability between existing semantic\nresources and support the provision of machine-readable variable descriptions\nwhose components are mapped to FAIR vocabulary terms. The I-ADOPT framework\nontology defines a set of high level semantic components that can be used to\ndescribe a variety of patterns commonly found in scientific observations. This\ncontribution will focus on how the I-ADOPT framework can be applied to\nrepresent variables commonly used in the biodiversity domain.",
    "descriptor": "\nComments: submitted to S4BioDiv 2021: 3rd International Workshop on Semantics for Biodiversity, September 15, 2021, Bozen, Italy\n",
    "authors": [
      "Barbara Magagna",
      "Ilaria Rosati",
      "Maria Stoica",
      "Sirko Schindler",
      "Gwenaelle Moncoiffe",
      "Anusuriya Devaraju",
      "Johannes Peterseil",
      "Robert Huber"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06547"
  },
  {
    "id": "arXiv:2107.06548",
    "title": "Communication-Efficient Hierarchical Federated Learning for IoT  Heterogeneous Systems with Imbalanced Data",
    "abstract": "Federated learning (FL) is a distributed learning methodology that allows\nmultiple nodes to cooperatively train a deep learning model, without the need\nto share their local data. It is a promising solution for telemonitoring\nsystems that demand intensive data collection, for detection, classification,\nand prediction of future events, from different locations while maintaining a\nstrict privacy constraint. Due to privacy concerns and critical communication\nbottlenecks, it can become impractical to send the FL updated models to a\ncentralized server. Thus, this paper studies the potential of hierarchical FL\nin IoT heterogeneous systems and propose an optimized solution for user\nassignment and resource allocation on multiple edge nodes. In particular, this\nwork focuses on a generic class of machine learning models that are trained\nusing gradient-descent-based schemes while considering the practical\nconstraints of non-uniformly distributed data across different users. We\nevaluate the proposed system using two real-world datasets, and we show that it\noutperforms state-of-the-art FL solutions. In particular, our numerical results\nhighlight the effectiveness of our approach and its ability to provide 4-6%\nincrease in the classification accuracy, with respect to hierarchical FL\nschemes that consider distance-based user assignment. Furthermore, the proposed\napproach could significantly accelerate FL training and reduce communication\noverhead by providing 75-85% reduction in the communication rounds between edge\nnodes and the centralized server, for the same model accuracy.",
    "descriptor": "\nComments: A version of this work has been submitted in Transactions on Network Science and Engineering\n",
    "authors": [
      "Alaa Awad Abdellatif",
      "Naram Mhaisen",
      "Amr Mohamed",
      "Aiman Erbad",
      "Mohsen Guizani",
      "Zaher Dawy",
      "Wassim Nasreddine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06548"
  },
  {
    "id": "arXiv:2107.06550",
    "title": "FAPR: Fast and Accurate Program Repair for Introductory Programming  Courses",
    "abstract": "In introductory programming courses, it is challenging for instructors to\nprovide debugging feedback on students' incorrect programs. Some recent tools\nautomatically offer program repair feedback by identifying any differences\nbetween incorrect and correct programs, but suffer from issues related to\nscalability, accuracy, and cross-language portability. This paper presents FAPR\n-- our novel approach that suggests repairs based on program differences in a\nfast and accurate manner. FAPR is different from current tools in three\naspects. First, it encodes syntactic information into token sequences to enable\nhigh-speed comparison between incorrect and correct programs. Second, to\naccurately extract program differences, FAPR adopts a novel matching algorithm\nthat maximizes token-level matches and minimizes statement-level differences.\nThird, FAPR relies on testing instead of static/dynamic analysis to validate\nand refine candidate repairs, so it eliminates the language dependency or high\nruntime overhead incurred by complex program analysis. We implemented FAPR to\nsuggest repairs for both C and C++ programs; our experience shows the great\ncross-language portability of FAPR. More importantly, we empirically compared\nFAPR with a state-of-the-art tool Clara. FAPR suggested repairs for over 95.5%\nof incorrect solutions. We sampled 250 repairs among FAPR's suggestions, and\nfound 89.6% of the samples to be minimal and correct. FAPR outperformed Clara\nby suggesting repairs for more cases, creating smaller repairs, producing\nhigher-quality fixes, and causing lower runtime overheads. Our results imply\nthat FAPR can potentially help instructors or TAs to effectively locate bugs in\nincorrect code, and to provide debugging hints/guidelines based on those\ngenerated repairs.",
    "descriptor": "\nComments: 12 pages, 5 figures for main text; 3 pages, 5 figures for appendix\n",
    "authors": [
      "Yunlong Lu",
      "Na Meng",
      "Wenxin Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06550"
  },
  {
    "id": "arXiv:2107.06552",
    "title": "Domain Generalization with Pseudo-Domain Label for Face Anti-Spoofing",
    "abstract": "Face anti-spoofing (FAS) plays an important role in protecting face\nrecognition systems from face representation attacks. Many recent studies in\nFAS have approached this problem with domain generalization technique. Domain\ngeneralization aims to increase generalization performance to better detect\nvarious types of attacks and unseen attacks. However, previous studies in this\narea have defined each domain simply as an anti-spoofing datasets and focused\non developing learning techniques. In this paper, we proposed a method that\nenables network to judge its domain by itself with the clustered convolutional\nfeature statistics from intermediate layers of the network, without labeling\ndomains as datasets. We obtained pseudo-domain labels by not only using the\nnetwork extracting features, but also using depth estimators, which were\npreviously used only as an auxiliary task in FAS. In our experiments, we\ntrained with three datasets and evaluated the performance with the remaining\none dataset to demonstrate the effectiveness of the proposed method by\nconducting a total of four sets of experiments.",
    "descriptor": "",
    "authors": [
      "Young Eun Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06552"
  },
  {
    "id": "arXiv:2107.06553",
    "title": "On the finite element approximation of fourth order singularly perturbed  eigenvalue problems",
    "abstract": "We consider fourth order singularly perturbed eigenvalue problems in\none-dimension and the approximation of their solution by the $h$ version of the\nFinite Element Method (FEM). In particular, we use piecewise Hermite\npolynomials of degree $p\\geq 3$ defined on an {\\emph{exponentially graded}}\nmesh. We show that the method converges uniformly, with respect to the singular\nperturbation parameter, at the optimal rate when the error in the eigenvalues\nis measured in absolute value and the error in the eigenvectors is measured in\nthe energy norm. We also illustrate our theoretical findings through numerical\ncomputations for the case $p=3$.",
    "descriptor": "",
    "authors": [
      "Hans-G\u00f6rg Roos",
      "Despo Savvidou",
      "Christos Xenophontos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06553"
  },
  {
    "id": "arXiv:2107.06563",
    "title": "Multi-Label Generalized Zero Shot Learning for the Classification of  Disease in Chest Radiographs",
    "abstract": "Despite the success of deep neural networks in chest X-ray (CXR) diagnosis,\nsupervised learning only allows the prediction of disease classes that were\nseen during training. At inference, these networks cannot predict an unseen\ndisease class. Incorporating a new class requires the collection of labeled\ndata, which is not a trivial task, especially for less frequently-occurring\ndiseases. As a result, it becomes inconceivable to build a model that can\ndiagnose all possible disease classes. Here, we propose a multi-label\ngeneralized zero shot learning (CXR-ML-GZSL) network that can simultaneously\npredict multiple seen and unseen diseases in CXR images. Given an input image,\nCXR-ML-GZSL learns a visual representation guided by the input's corresponding\nsemantics extracted from a rich medical text corpus. Towards this ambitious\ngoal, we propose to map both visual and semantic modalities to a latent feature\nspace using a novel learning objective. The objective ensures that (i) the most\nrelevant labels for the query image are ranked higher than irrelevant labels,\n(ii) the network learns a visual representation that is aligned with its\nsemantics in the latent feature space, and (iii) the mapped semantics preserve\ntheir original inter-class representation. The network is end-to-end trainable\nand requires no independent pre-training for the offline feature extractor.\nExperiments on the NIH Chest X-ray dataset show that our network outperforms\ntwo strong baselines in terms of recall, precision, f1 score, and area under\nthe receiver operating characteristic curve. Our code is publicly available at:\nhttps://github.com/nyuad-cai/CXR-ML-GZSL.git",
    "descriptor": "\nComments: Accepted to the Machine Learning for Healthcare Conference 2021\n",
    "authors": [
      "Nasir Hayat",
      "Hazem Lashen",
      "Farah E. Shamout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06563"
  },
  {
    "id": "arXiv:2107.06564",
    "title": "Probabilistic Human Motion Prediction via A Bayesian Neural Network",
    "abstract": "Human motion prediction is an important and challenging topic that has\npromising prospects in efficient and safe human-robot-interaction systems.\nCurrently, the majority of the human motion prediction algorithms are based on\ndeterministic models, which may lead to risky decisions for robots. To solve\nthis problem, we propose a probabilistic model for human motion prediction in\nthis paper. The key idea of our approach is to extend the conventional\ndeterministic motion prediction neural network to a Bayesian one. On one hand,\nour model could generate several future motions when given an observed motion\nsequence. On the other hand, by calculating the Epistemic Uncertainty and the\nHeteroscedastic Aleatoric Uncertainty, our model could tell the robot if the\nobservation has been seen before and also give the optimal result among all\npossible predictions. We extensively validate our approach on a large scale\nbenchmark dataset Human3.6m. The experiments show that our approach performs\nbetter than deterministic methods. We further evaluate our approach in a\nHuman-Robot-Interaction (HRI) scenario. The experimental results show that our\napproach makes the interaction more efficient and safer.",
    "descriptor": "\nComments: Accepted at ICRA 2021\n",
    "authors": [
      "Jie Xu",
      "Xingyu Chen",
      "Xuguang Lan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06564"
  },
  {
    "id": "arXiv:2107.06566",
    "title": "MESS: Manifold Embedding Motivated Super Sampling",
    "abstract": "Many approaches in the field of machine learning and data analysis rely on\nthe assumption that the observed data lies on lower-dimensional manifolds. This\nassumption has been verified empirically for many real data sets. To make use\nof this manifold assumption one generally requires the manifold to be locally\nsampled to a certain density such that features of the manifold can be\nobserved. However, for increasing intrinsic dimensionality of a data set the\nrequired data density introduces the need for very large data sets, resulting\nin one of the many faces of the curse of dimensionality. To combat the\nincreased requirement for local data density we propose a framework to generate\nvirtual data points that faithful to an approximate embedding function\nunderlying the manifold observable in the data.",
    "descriptor": "",
    "authors": [
      "Erik Thordsen",
      "Erich Schubert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06566"
  },
  {
    "id": "arXiv:2107.06569",
    "title": "Importance-based Neuron Allocation for Multilingual Neural Machine  Translation",
    "abstract": "Multilingual neural machine translation with a single model has drawn much\nattention due to its capability to deal with multiple languages. However, the\ncurrent multilingual translation paradigm often makes the model tend to\npreserve the general knowledge, but ignore the language-specific knowledge.\nSome previous works try to solve this problem by adding various kinds of\nlanguage-specific modules to the model, but they suffer from the parameter\nexplosion problem and require specialized manual design. To solve these\nproblems, we propose to divide the model neurons into general and\nlanguage-specific parts based on their importance across languages. The general\npart is responsible for preserving the general knowledge and participating in\nthe translation of all the languages, while the language-specific part is\nresponsible for preserving the language-specific knowledge and participating in\nthe translation of some specific languages. Experimental results on several\nlanguage pairs, covering IWSLT and Europarl corpus datasets, demonstrate the\neffectiveness and universality of the proposed method.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Wanying Xie",
      "Yang Feng",
      "Shuhao Gu",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06569"
  },
  {
    "id": "arXiv:2107.06570",
    "title": "QoS-Aware Scheduling in New Radio Using Deep Reinforcement Learning",
    "abstract": "Fifth-generation (5G) New Radio (NR) cellular networks support a wide range\nof new services, many of which require an application-specific quality of\nservice (QoS), e.g. in terms of a guaranteed minimum bit-rate or a maximum\ntolerable delay. Therefore, scheduling multiple parallel data flows, each\nserving a unique application instance, is bound to become an even more\nchallenging task compared to the previous generations. Leveraging recent\nadvances in deep reinforcement learning, in this paper, we propose a QoS-Aware\nDeep Reinforcement learning Agent (QADRA) scheduler for NR networks. In\ncontrast to state-of-the-art scheduling heuristics, the QADRA scheduler\nexplicitly optimizes for the QoS satisfaction rate while simultaneously\nmaximizing the network performance. Moreover, we train our algorithm end-to-end\non these objectives. We evaluate QADRA in a full scale, near-product, system\nlevel NR simulator and demonstrate a significant boost in network performance.\nIn our particular evaluation scenario, the QADRA scheduler improves network\nthroughput by 30% while simultaneously maintaining the QoS satisfaction rate of\nVoIP users served by the network, compared to state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Jakob Stigenberg",
      "Vidit Saxena",
      "Soma Tayamon",
      "Euhanna Ghadimi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06570"
  },
  {
    "id": "arXiv:2107.06571",
    "title": "A QPTAS for stabbing rectangles",
    "abstract": "We consider the following geometric optimization problem: Given $ n $\naxis-aligned rectangles in the plane, the goal is to find a set of horizontal\nsegments of minimum total length such that each rectangle is stabbed. A segment\nstabs a rectangle if it intersects both its left and right edge. As such, this\nstabbing problem falls into the category of weighted geometric set cover\nproblems for which techniques that improve upon the general ${\\Theta}(\\log\nn)$-approximation guarantee have received a lot of attention in the literature.\nChan at al. (2018) have shown that rectangle stabbing is NP-hard and that it\nadmits a constant-factor approximation algorithm based on Varadarajan's\nquasi-uniform sampling method. In this work we make progress on rectangle\nstabbing on two fronts. First, we present a quasi-polynomial time approximation\nscheme (QPTAS) for rectangle stabbing. Furthermore, we provide a simple\n$8$-approximation algorithm that avoids the framework of Varadarajan. This\nsettles two open problems raised by Chan et al. (2018).",
    "descriptor": "",
    "authors": [
      "Friedrich Eisenbrand",
      "Martina Gallato",
      "Ola Svensson",
      "Moritz Venzin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06571"
  },
  {
    "id": "arXiv:2107.06573",
    "title": "A Note on Learning Rare Events in Molecular Dynamics using LSTM and  Transformer",
    "abstract": "Recurrent neural networks for language models like long short-term memory\n(LSTM) have been utilized as a tool for modeling and predicting long term\ndynamics of complex stochastic molecular systems. Recently successful examples\non learning slow dynamics by LSTM are given with simulation data of low\ndimensional reaction coordinate. However, in this report we show that the\nfollowing three key factors significantly affect the performance of language\nmodel learning, namely dimensionality of reaction coordinates, temporal\nresolution and state partition. When applying recurrent neural networks to\nmolecular dynamics simulation trajectories of high dimensionality, we find that\nrare events corresponding to the slow dynamics might be obscured by other\nfaster dynamics of the system, and cannot be efficiently learned. Under such\nconditions, we find that coarse graining the conformational space into\nmetastable states and removing recrossing events when estimating transition\nprobabilities between states could greatly help improve the accuracy of slow\ndynamics learning in molecular dynamics. Moreover, we also explore other models\nlike Transformer, which do not show superior performance than LSTM in\novercoming these issues. Therefore, to learn rare events of slow molecular\ndynamics by LSTM and Transformer, it is critical to choose proper temporal\nresolution (i.e., saving intervals of MD simulation trajectories) and state\npartition in high resolution data, since deep neural network models might not\nautomatically disentangle slow dynamics from fast dynamics when both are\npresent in data influencing each other.",
    "descriptor": "",
    "authors": [
      "Wenqi Zeng",
      "Siqin Cao",
      "Xuhui Huang",
      "Yuan Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06573"
  },
  {
    "id": "arXiv:2107.06578",
    "title": "A Distance Measure for Privacy-preserving Process Mining based on  Feature Learning",
    "abstract": "To enable process analysis based on an event log without compromising the\nprivacy of individuals involved in process execution, a log may be anonymized.\nSuch anonymization strives to transform a log so that it satisfies provable\nprivacy guarantees, while largely maintaining its utility for process analysis.\nExisting techniques perform anonymization using simple, syntactic measures to\nidentify suitable transformation operations. This way, the semantics of the\nactivities referenced by the events in a trace are neglected, potentially\nleading to transformations in which events of unrelated activities are merged.\nTo avoid this and incorporate the semantics of activities during anonymization,\nwe propose to instead incorporate a distance measure based on feature learning.\nSpecifically, we show how embeddings of events enable the definition of a\ndistance measure for traces to guide event log anonymization. Our experiments\nwith real-world data indicate that anonymization using this measure, compared\nto a syntactic one, yields logs that are closer to the original log in various\ndimensions and, hence, have higher utility for process analysis.",
    "descriptor": "\nComments: Accepted for 17th International Workshop on Business Process Intelligence\n",
    "authors": [
      "Fabian R\u00f6sel",
      "Stephan A. Fahrenkrog-Petersen",
      "Han van der Aa",
      "Matthias Weidlich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06578"
  },
  {
    "id": "arXiv:2107.06580",
    "title": "IFedAvg: Interpretable Data-Interoperability for Federated Learning",
    "abstract": "Recently, the ever-growing demand for privacy-oriented machine learning has\nmotivated researchers to develop federated and decentralized learning\ntechniques, allowing individual clients to train models collaboratively without\ndisclosing their private datasets. However, widespread adoption has been\nlimited in domains relying on high levels of user trust, where assessment of\ndata compatibility is essential. In this work, we define and address low\ninteroperability induced by underlying client data inconsistencies in federated\nlearning for tabular data. The proposed method, iFedAvg, builds on federated\naveraging adding local element-wise affine layers to allow for a personalized\nand granular understanding of the collaborative learning process. Thus,\nenabling the detection of outlier datasets in the federation and also learning\nthe compensation for local data distribution shifts without sharing any\noriginal data. We evaluate iFedAvg using several public benchmarks and a\npreviously unstudied collection of real-world datasets from the 2014 - 2016\nWest African Ebola epidemic, jointly forming the largest such dataset in the\nworld. In all evaluations, iFedAvg achieves competitive average performance\nwith negligible overhead. It additionally shows substantial improvement on\noutlier clients, highlighting increased robustness to individual dataset\nshifts. Most importantly, our method provides valuable client-specific insights\nat a fine-grained level to guide interoperable federated learning.",
    "descriptor": "",
    "authors": [
      "David Roschewitz",
      "Mary-Anne Hartley",
      "Luca Corinzia",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06580"
  },
  {
    "id": "arXiv:2107.06582",
    "title": "Towards a Decomposition-Optimal Algorithm for Counting and Sampling  Arbitrary Motifs in Sublinear Time",
    "abstract": "We consider the problem of sampling an arbitrary given motif $H$ in a graph\n$G$, where access to $G$ is given via queries: degree, neighbor, and pair, as\nwell as uniform edge sample queries. Previous algorithms for the uniform\nsampling task were based on a decomposition of $H$ into a collection of odd\ncycles and stars, denoted $\\mathcal{D}^*(H)=\\{O_{k_1}, \\ldots, O_{k_q},\nS_{p_1}, \\ldots, S_{p_\\ell}\\}$. These algorithms were shown to be optimal for\nthe case where $H$ is a clique or an odd-length cycle, but no other lower\nbounds were known.\nWe present a new algorithm for sampling arbitrary motifs which, up to\n$\\poly(\\log n)$ factors, for any motif $H$ whose decomposition contains at\nleast two components or at least one star, is always preferable. The main\ningredient leading to this improvement is an improved uniform algorithm for\nsampling stars, which might be of independent interest, as it allows to sample\nvertices according to the $p$-th moment of the degree distribution. We further\nshow how to use our sampling algorithm to get an approximate counting\nalgorithm, with essentially the same complexity.\nFinally, we prove that this algorithm is \\emph{decomposition-optimal} for\ndecompositions that contain at least one odd cycle. That is, we prove that for\nany decomposition $D$ that contains at least one odd cycle, there exists a\nmotif $H_{D}$ with decomposition $D$, and a family of graphs $\\mathcal{G}$, so\nthat in order to output a uniform copy of $H$ in a uniformly chosen graph in\n$\\mathcal{G}$, the number of required queries matches our upper bound. These\nare the first lower bounds for motifs $H$ with a nontrivial decomposition,\ni.e., motifs that have more than a single component in their decomposition.",
    "descriptor": "",
    "authors": [
      "Amartya Shankha Biswas",
      "Talya Eden",
      "Ronitt Rubinfeld"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06582"
  },
  {
    "id": "arXiv:2107.06589",
    "title": "Tailored Shaping, Improved Detection, Simpler Backpropagation: the Road  to Nonlinearity Mitigation",
    "abstract": "Several strategies for nonlinearity mitigation based on signal processing at\nthe transmitter and/or receiver side are analyzed and their effectiveness is\ndiscussed. Improved capacity lower bounds based on their combination are\npresented.",
    "descriptor": "\nComments: Submitted as an invited contribution to ECOC 2021\n",
    "authors": [
      "Marco Secondini",
      "Stella Civelli",
      "Enrico Forestieri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06589"
  },
  {
    "id": "arXiv:2107.06590",
    "title": "Self-Determined Reciprocal Recommender System with Strong Privacy  Guarantees",
    "abstract": "Recommender systems are widely used. Usually, recommender systems are based\non a centralized client-server architecture. However, this approach implies\ndrawbacks regarding the privacy of users. In this paper, we propose a\ndistributed reciprocal recommender system with strong, self-determined privacy\nguarantees, i.e., local differential privacy. More precisely, users randomize\ntheir profiles locally and exchange them via a peer-to-peer network.\nRecommendations are then computed and ranked locally by estimating similarities\nbetween profiles. We evaluate recommendation accuracy of a job recommender\nsystem and demonstrate that our method provides acceptable utility under strong\nprivacy requirements.",
    "descriptor": "\nComments: Accepted at The 16th International Conference on Availability, Reliability and Security (ARES 2021)\n",
    "authors": [
      "S. Nu\u00f1ez von Voigt",
      "E. Daniel",
      "F. Tschorsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06590"
  },
  {
    "id": "arXiv:2107.06591",
    "title": "Useful Open Call-by-Need",
    "abstract": "This paper studies useful sharing, which is a sophisticated optimization for\nlambda-calculi, in the context of call-by-need evaluation in presence of open\nterms. Useful sharing turns out to be harder to manipulate in call-by-need than\nin call-by-name or call-by-value, because call-by-need evaluates inside\nenvironments, making it harder to specify when a substitution step is useful.\nWe isolate the key involved concepts and prove the correctness of useful\nsharing in this setting.",
    "descriptor": "",
    "authors": [
      "Beniamino Accattoli",
      "Maico Leberle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.06591"
  },
  {
    "id": "arXiv:2107.06607",
    "title": "Uncertainty Quantification of Inclusion Boundaries in the Context of  X-ray Tomography",
    "abstract": "In this work, we describe a Bayesian framework for the X-ray computed\ntomography (CT) problem in an infinite-dimensional setting. We consider\nreconstructing piecewise smooth fields with discontinuities where the interface\nbetween regions is not known. Furthermore, we quantify the uncertainty in the\nprediction. Directly detecting the discontinuities, instead of reconstructing\nthe entire image, drastically reduces the dimension of the problem. Therefore,\nthe posterior distribution can be approximated with a relatively small number\nof samples. We show that our method provides an excellent platform for\nchallenging X-ray CT scenarios (e.g. in case of noisy data, limited angle, or\nsparse angle imaging). We investigate the accuracy and the efficiency of our\nmethod on synthetic data. Furthermore, we apply the method to the real-world\ndata, tomographic X-ray data of a lotus root filled with attenuating objects.\nThe numerical results indicate that our method provides an accurate method in\ndetecting boundaries between piecewise smooth regions and quantifies the\nuncertainty in the prediction, in the context of X-ray CT.",
    "descriptor": "",
    "authors": [
      "Babak Maboudi Afkham",
      "Yiqiu Dong",
      "Per Christian Hansen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06607"
  },
  {
    "id": "arXiv:2107.06608",
    "title": "Continuous vs. Discrete Optimization of Deep Neural Networks",
    "abstract": "Existing analyses of optimization in deep learning are either continuous,\nfocusing on (variants of) gradient flow, or discrete, directly treating\n(variants of) gradient descent. Gradient flow is amenable to theoretical\nanalysis, but is stylized and disregards computational efficiency. The extent\nto which it represents gradient descent is an open question in deep learning\ntheory. The current paper studies this question. Viewing gradient descent as an\napproximate numerical solution to the initial value problem of gradient flow,\nwe find that the degree of approximation depends on the curvature along the\nlatter's trajectory. We then show that over deep neural networks with\nhomogeneous activations, gradient flow trajectories enjoy favorable curvature,\nsuggesting they are well approximated by gradient descent. This finding allows\nus to translate an analysis of gradient flow over deep linear neural networks\ninto a guarantee that gradient descent efficiently converges to global minimum\nalmost surely under random initialization. Experiments suggest that over simple\ndeep neural networks, gradient descent with conventional step size is indeed\nclose to the continuous limit. We hypothesize that the theory of gradient flows\nwill be central to unraveling mysteries behind deep learning.",
    "descriptor": "",
    "authors": [
      "Omer Elkabetz",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06608"
  },
  {
    "id": "arXiv:2107.06613",
    "title": "Adaptive BEM for elliptic PDE systems, part II: Isogeometric analysis  with hierarchical B-splines for weakly-singular integral equations",
    "abstract": "We formulate and analyze an adaptive algorithm for isogeometric analysis with\nhierarchical B-splines for weakly-singular boundary integral equations. We\nprove that the employed weighted-residual error estimator is reliable and\nconverges at optimal algebraic rate. Numerical experiments with isogeometric\nboundary elements for the 3D Poisson problem confirm the theoretical results,\nwhich also cover general elliptic systems like linear elasticity.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2004.07762\n",
    "authors": [
      "Gregor Gantner",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06613"
  },
  {
    "id": "arXiv:2107.06614",
    "title": "Goal-Oriented A Posteriori Error Estimation for the Biharmonic Problem  Based on Equilibrated Moment Tensor",
    "abstract": "In this article, goal-oriented a posteriori error estimation for the\nbiharmonic plate bending problem is considered. The error for approximation of\ngoal functional is represented by an estimator which combines dual-weighted\nresidual method and equilibrated moment tensor. An abstract unified framework\nfor the goal-oriented a posteriori error estimation is derived. In particular,\n$C^0$ interior penalty and discontinuous Galerkin finite element methods are\nemployed for practical realization. The abstract estimation is based on\nequilibrated moment tensor and potential reconstruction that provides a\nguaranteed upper bound for the goal error. Numerical experiments are performed\nto illustrate the effectivity of the estimators.",
    "descriptor": "",
    "authors": [
      "Gouranga Mallik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06614"
  },
  {
    "id": "arXiv:2107.06615",
    "title": "Oblivious sketching for logistic regression",
    "abstract": "What guarantees are possible for solving logistic regression in one pass over\na data stream? To answer this question, we present the first data oblivious\nsketch for logistic regression. Our sketch can be computed in input sparsity\ntime over a turnstile data stream and reduces the size of a $d$-dimensional\ndata set from $n$ to only $\\operatorname{poly}(\\mu d\\log n)$ weighted points,\nwhere $\\mu$ is a useful parameter which captures the complexity of compressing\nthe data. Solving (weighted) logistic regression on the sketch gives an $O(\\log\nn)$-approximation to the original problem on the full data set. We also show\nhow to obtain an $O(1)$-approximation with slight modifications. Our sketches\nare fast, simple, easy to implement, and our experiments demonstrate their\npracticality.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Alexander Munteanu",
      "Simon Omlor",
      "David Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06615"
  },
  {
    "id": "arXiv:2107.06623",
    "title": "Financial Network Games",
    "abstract": "We study financial systems from a game-theoretic standpoint. A financial\nsystem is represented by a network, where nodes correspond to firms, and\ndirected labeled edges correspond to debt contracts between them. The existence\nof cycles in the network indicates that a payment of a firm to one of its\nlenders might result to some incoming payment. So, if a firm cannot fully repay\nits debt, then the exact (partial) payments it makes to each of its creditors\ncan affect the cash inflow back to itself. We naturally assume that the firms\nare interested in their financial well-being (utility) which is aligned with\nthe amount of incoming payments they receive from the network. This defines a\ngame among the firms, that can be seen as utility-maximizing agents who can\nstrategize over their payments.\nWe are the first to study financial network games that arise under a natural\nset of payment strategies called priority-proportional payments. We investigate\nthe existence and (in)efficiency of equilibrium strategies, under different\nassumptions on how the firms' utility is defined, on the types of debt\ncontracts allowed between the firms, and on the presence of other financial\nfeatures that commonly arise in practice. Surprisingly, even if all firms'\nstrategies are fixed, the existence of a unique payment profile is not\nguaranteed. So, we also investigate the existence and computation of valid\npayment profiles for fixed payment strategies.",
    "descriptor": "",
    "authors": [
      "Panagiotis Kanellopoulos",
      "Maria Kyropoulou",
      "Hao Zhou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.06623"
  },
  {
    "id": "arXiv:2107.06626",
    "title": "Optimality of the Johnson-Lindenstrauss Dimensionality Reduction for  Practical Measures",
    "abstract": "It is well known that the Johnson-Lindenstrauss dimensionality reduction\nmethod is optimal for worst case distortion. While in practice many other\nmethods and heuristics are used, not much is known in terms of bounds on their\nperformance. The question of whether the JL method is optimal for practical\nmeasures of distortion was recently raised in \\cite{BFN19} (NeurIPS'19). They\nprovided upper bounds on its quality for a wide range of practical measures and\nshowed that indeed these are best possible in many cases. Yet, some of the most\nimportant cases, including the fundamental case of average distortion were left\nopen. In particular, they show that the JL transform has $1+\\epsilon$ average\ndistortion for embedding into $k$-dimensional Euclidean space, where\n$k=O(1/\\eps^2)$, and for more general $q$-norms of distortion, $k =\nO(\\max\\{1/\\eps^2,q/\\eps\\})$, whereas tight lower bounds were established only\nfor large values of $q$ via reduction to the worst case.\nIn this paper we prove that these bounds are best possible for any\ndimensionality reduction method, for any $1 \\leq q \\leq O(\\frac{\\log (2\\eps^2\nn)}{\\eps})$ and $\\epsilon \\geq \\frac{1}{\\sqrt{n}}$, where $n$ is the size of\nthe subset of Euclidean space.\nOur results imply that the JL method is optimal for various distortion\nmeasures commonly used in practice, such as {\\it stress, energy} and {\\it\nrelative error}. We prove that if any of these measures is bounded by $\\eps$\nthen $k=\\Omega(1/\\eps^2)$, for any $\\epsilon \\geq \\frac{1}{\\sqrt{n}}$, matching\nthe upper bounds of \\cite{BFN19} and extending their tightness results for the\nfull range moment analysis.\nOur results may indicate that the JL dimensionality reduction method should\nbe considered more often in practical applications, and the bounds we provide\nfor its quality should be served as a measure for comparison when evaluating\nthe performance of other methods and heuristics.",
    "descriptor": "",
    "authors": [
      "Yair Bartal",
      "Ora Nova Fandina",
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06626"
  },
  {
    "id": "arXiv:2107.06627",
    "title": "AutoMCM: Maneuver Coordination Service with Abstracted Functions for  Autonomous Driving",
    "abstract": "A cooperative intelligent transport system (C-ITS) uses vehicle-to-everything\n(V2X) technology to make self-driving vehicles safer and more efficient.\nCurrent C-ITS applications have mainly focused on real-time information\nsharing, such as for cooperative perception. In addition to better real-time\nperception, self-driving vehicles need to achieve higher safety and efficiency\nby coordinating action plans. This study designs a maneuver coordination (MC)\nprotocol that uses seven messages to cover various scenarios and an abstracted\nMC support service. We implement our proposal as AutoMCM by extending two\nopen-source software tools: Autoware for autonomous driving and OpenC2X for\nC-ITS. The results show that our system effectively reduces the communication\nbandwidth by limiting message exchange in an event-driven manner. Furthermore,\nit shows that the vehicles run 15% faster when the vehicle speed is 30 km/h and\n28% faster when the vehicle speed is 50 km/h using our scheme. Our system shows\nrobustness against packet loss in experiments when the message timeout\nparameters are appropriately set.",
    "descriptor": "\nComments: Accepted to 24th IEEE International Conference on Intelligent Transportation (ITSC) 2021\n",
    "authors": [
      "Masaya Mizutani",
      "Manabu Tsukada",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06627"
  },
  {
    "id": "arXiv:2107.06629",
    "title": "Model-free Reinforcement Learning for Robust Locomotion Using Trajectory  Optimization for Exploration",
    "abstract": "In this work we present a general, two-stage reinforcement learning approach\nfor going from a single demonstration trajectory to a robust policy that can be\ndeployed on hardware without any additional training. The demonstration is used\nin the first stage as a starting point to facilitate initial exploration. In\nthe second stage, the relevant task reward is optimized directly and a policy\nrobust to environment uncertainties is computed. We demonstrate and examine in\ndetail performance and robustness of our approach on highly dynamic hopping and\nbounding tasks on a real quadruped robot.",
    "descriptor": "",
    "authors": [
      "Miroslav Bogdanovic",
      "Majid Khadiv",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06629"
  },
  {
    "id": "arXiv:2107.06630",
    "title": "Online Evaluation Methods for the Causal Effect of Recommendations",
    "abstract": "Evaluating the causal effect of recommendations is an important objective\nbecause the causal effect on user interactions can directly leads to an\nincrease in sales and user engagement. To select an optimal recommendation\nmodel, it is common to conduct A/B testing to compare model performance.\nHowever, A/B testing of causal effects requires a large number of users, making\nsuch experiments costly and risky. We therefore propose the first interleaving\nmethods that can efficiently compare recommendation models in terms of causal\neffects. In contrast to conventional interleaving methods, we measure the\noutcomes of both items on an interleaved list and items not on the interleaved\nlist, since the causal effect is the difference between outcomes with and\nwithout recommendations. To ensure that the evaluations are unbiased, we either\nselect items with equal probability or weight the outcomes using inverse\npropensity scores. We then verify the unbiasedness and efficiency of online\nevaluation methods through simulated online experiments. The results indicate\nthat our proposed methods are unbiased and that they have superior efficiency\nto A/B testing.",
    "descriptor": "\nComments: accepted at RecSys 2021\n",
    "authors": [
      "Masahiro Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06630"
  },
  {
    "id": "arXiv:2107.06632",
    "title": "ParCourE: A Parallel Corpus Explorer fora Massively Multilingual Corpus",
    "abstract": "With more than 7000 languages worldwide, multilingual natural language\nprocessing (NLP) is essential both from an academic and commercial perspective.\nResearching typological properties of languages is fundamental for progress in\nmultilingual NLP. Examples include assessing language similarity for effective\ntransfer learning, injecting inductive biases into machine learning models or\ncreating resources such as dictionaries and inflection tables. We provide\nParCourE, an online tool that allows to browse a word-aligned parallel corpus,\ncovering 1334 languages. We give evidence that this is useful for typological\nresearch. ParCourE can be set up for any parallel corpus and can thus be used\nfor typological research on other corpora as well as for exploring their\nquality and properties.",
    "descriptor": "\nComments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\n",
    "authors": [
      "Ayyoob Imani",
      "Masoud Jalili Sabet",
      "Philipp Dufter",
      "Michael Cysouw",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06632"
  },
  {
    "id": "arXiv:2107.06633",
    "title": "Jacobian-free explicit multiderivative Runge-Kutta methods for  hyperbolic conservation laws",
    "abstract": "Based on the recent development of Jacobian-free Lax-Wendroff (LW) approaches\nfor solving hyperbolic conservation laws [Zorio, Baeza and Mulet, Journal of\nScientific Computing 71:246-273, 2017], [Carrillo and Par\\'es, Journal of\nScientific Computing 80:1832-1866, 2019], a novel collection of explicit\nJacobian-free multistage multiderivative solvers for hyperbolic conservation\nlaws is presented in this work. In contrast to Taylor time-integration methods,\nmultiderivative RungeKutta (MDRK) techniques achieve higher-order of\nconsistency not only through the excessive addition of higher temporal\nderivatives, but also through the addition of Runge-Kutta-type stages. This\nadds more flexibility to the time integration in such a way that more stable\nand more efficient schemes could be identified. The novel method permits the\npractical application of MDRK schemes. In their original form, they are\ndifficult to utilize as higher-order flux derivatives have to be computed\nanalytically. Here we overcome this by adopting a Jacobian-free approximation\nof those derivatives. In this paper, we analyze the novel method with respect\nto order of consistency and stability. We show that the linear CFL number\nvaries significantly with the number of derivatives used. Results are verified\nnumerically on several representative testcases.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Jeremy Chouchoulis",
      "Jochen Sch\u00fctz",
      "Jonas Zeifang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06633"
  },
  {
    "id": "arXiv:2107.06638",
    "title": "Procedural Content Generation using Behavior Trees (PCGBT)",
    "abstract": "Behavior trees (BTs) are a popular method of modeling the behavior of NPCs\nand enemy AI and have found widespread use in a large number of commercial\ngames. In this paper, rather than use BTs to model game-playing agents, we\ndemonstrate their use for modeling game design agents, defining behaviors as\nexecuting content generation tasks rather than in-game actions. Similar to how\ntraditional BTs enable modeling behaviors in a modular and dynamic manner, BTs\nfor PCG enable simple subtrees for generating parts of levels to be combined\nmodularly to form more complex trees for generating whole levels as well as\ngenerators that can dynamically vary the generated content. We demonstrate this\napproach by using BTs to model generators for Super Mario Bros., Mega Man and\nMetroid levels as well as dungeon layouts and discuss several ways in which\nthis PCGBT paradigm could be applied and extended in the future.",
    "descriptor": "",
    "authors": [
      "Anurag Sarkar",
      "Seth Cooper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06638"
  },
  {
    "id": "arXiv:2107.06639",
    "title": "You Only Write Thrice: Creating Documents, Computational Notebooks and  Presentations From a Single Source",
    "abstract": "Academic trade requires juggling multiple variants of the same content\npublished in different formats: manuscripts, presentations, posters and\ncomputational notebooks. The need to track versions to accommodate for the\nwrite--review--rebut--revise life-cycle adds another layer of complexity. We\npropose to significantly reduce this burden by maintaining a single source\ndocument in a version-controlled environment (such as git), adding\nfunctionality to generate a collection of output formats popular in academia.\nTo this end, we utilise various open-source tools from the Jupyter scientific\ncomputing ecosystem and operationalise selected software engineering concepts.\nWe offer a proof-of-concept workflow that composes Jupyter Book (an online\ndocument), Jupyter Notebook (a computational narrative) and reveal.js slides\nfrom a single markdown source file. Hosted on GitHub, our approach supports\nchange tracking and versioning, as well as a transparent review process based\non the underlying code issue management infrastructure. An exhibit of our\nworkflow can be previewed at https://so-cool.github.io/you-only-write-thrice/.",
    "descriptor": "\nComments: Published at Rethinking ML Papers -- ICLR 2021 Workshop. OpenReview: this https URL Exhibit: this https URL\n",
    "authors": [
      "Kacper Sokol",
      "Peter Flach"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06639"
  },
  {
    "id": "arXiv:2107.06641",
    "title": "Trustworthy AI: A Computational Perspective",
    "abstract": "In the past few decades, artificial intelligence (AI) technology has\nexperienced swift developments, changing everyone's daily life and profoundly\naltering the course of human society. The intention of developing AI is to\nbenefit humans, by reducing human labor, bringing everyday convenience to human\nlives, and promoting social good. However, recent research and AI applications\nshow that AI can cause unintentional harm to humans, such as making unreliable\ndecisions in safety-critical scenarios or undermining fairness by inadvertently\ndiscriminating against one group. Thus, trustworthy AI has attracted immense\nattention recently, which requires careful consideration to avoid the adverse\neffects that AI may bring to humans, so that humans can fully trust and live in\nharmony with AI technologies.\nRecent years have witnessed a tremendous amount of research on trustworthy\nAI. In this survey, we present a comprehensive survey of trustworthy AI from a\ncomputational perspective, to help readers understand the latest technologies\nfor achieving trustworthy AI. Trustworthy AI is a large and complex area,\ninvolving various dimensions. In this work, we focus on six of the most crucial\ndimensions in achieving trustworthy AI: (i) Safety & Robustness, (ii)\nNon-discrimination & Fairness, (iii) Explainability, (iv) Privacy, (v)\nAccountability & Auditability, and (vi) Environmental Well-Being. For each\ndimension, we review the recent related technologies according to a taxonomy\nand summarize their applications in real-world systems. We also discuss the\naccordant and conflicting interactions among different dimensions and discuss\npotential aspects for trustworthy AI to investigate in the future.",
    "descriptor": "\nComments: 54 pages. arXiv admin note: text overlap with arXiv:1512.04150, arXiv:1602.04938 by other authors\n",
    "authors": [
      "Haochen Liu",
      "Yiqi Wang",
      "Wenqi Fan",
      "Xiaorui Liu",
      "Yaxin Li",
      "Shaili Jain",
      "Anil K. Jain",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06641"
  },
  {
    "id": "arXiv:2107.06645",
    "title": "The Period-Modulated Harmonic Locked Loop (PM-HLL): A low-effort  algorithm for rapid time-domain periodicity estimation",
    "abstract": "Many speech and music analysis and processing schemes rely on an estimate of\nthe fundamental frequency f0 of periodic signal components. Most established\nschemes apply rather unspecific signal models such as sinusoidal models to the\nestimation problem, which may limit time resolution and estimation accuracy.\nThis study proposes a novel time-domain locked-loop algorithm with low\ncomputational effort and low memory footprint for f0 estimation. The loop\ncontrol signal is directly derived from the input time signal, using a harmonic\nsignal model. Theoretically, this allows for a noise-robust and rapid f0\nestimation for periodic signals of arbitrary waveform, and without the\nrequirement of a prior frequency analysis. Several simulations with short\nsignals employing different types of periodicity and with added wide-band noise\nwere performed to demonstrate and evaluate the basic properties of the proposed\nalgorithm. Depending on the Signal-to-Noise Ratio (SNR), the estimator was\nfound to converge within 3-4 signal repetitions, even at SNR close to or below\n0dB. Furthermore, it was found to follow fundamental frequency sweeps with a\ndelay of less than one period and to track all tones of a three-tone musical\nchord signal simultaneously. Quasi-periodic sounds with shifted harmonics as\nwell as signals with stochastic periodicity were robustly tracked. Mean and\nstandard deviation of the estimation error, i.e., the difference between true\nand estimated f0, were at or below 1 Hz in most cases. The results suggest that\nthe proposed algorithm may be applicable to low-delay speech and music analysis\nand processing.",
    "descriptor": "",
    "authors": [
      "Volker Hohmann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06645"
  },
  {
    "id": "arXiv:2107.06649",
    "title": "Polynomial Time Algorithms to Find an Approximate Competitive  Equilibrium for Chores",
    "abstract": "Competitive equilibrium with equal income (CEEI) is considered one of the\nbest mechanisms to allocate a set of items among agents fairly and efficiently.\nIn this paper, we study the computation of CEEI when items are chores that are\ndisliked (negatively valued) by agents, under 1-homogeneous and concave utility\nfunctions which includes linear functions as a subcase. It is well-known that,\neven with linear utilities, the set of CEEI may be non-convex and disconnected,\nand the problem is PPAD-hard in the more general exchange model. In contrast to\nthese negative results, we design FPTAS: A polynomial-time algorithm to compute\n$\\epsilon$-approximate CEEI where the running-time depends polynomially on\n$1/\\epsilon$.\nOur algorithm relies on the recent characterization due to Bogomolnaia et\nal.~(2017) of the CEEI set as exactly the KKT points of a non-convex\nminimization problem that have all coordinates non-zero. Due to this non-zero\nconstraint, naive gradient-based methods fail to find the desired local minima\nas they are attracted towards zero. We develop an exterior-point method that\nalternates between guessing non-zero KKT points and maximizing the objective\nalong supporting hyperplanes at these points. We show that this procedure must\nconverge quickly to an approximate KKT point which then can be mapped to an\napproximate CEEI; this exterior point method may be of independent interest.\nWhen utility functions are linear, we give explicit procedures for finding the\nexact iterates, and as a result show that a stronger form of approximate CEEI\ncan be found in polynomial time. Finally, we note that our algorithm extends to\nthe setting of un-equal incomes (CE), and to mixed manna with linear utilities\nwhere each agent may like (positively value) some items and dislike (negatively\nvalue) others.",
    "descriptor": "",
    "authors": [
      "Shant Boodaghians",
      "Bhaskar Ray Chaudhury",
      "Ruta Mehta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06649"
  },
  {
    "id": "arXiv:2107.06650",
    "title": "An Efficient Deep Distribution Network for Bid Shading in First-Price  Auctions",
    "abstract": "Since 2019, most ad exchanges and sell-side platforms (SSPs), in the online\nadvertising industry, shifted from second to first price auctions. Due to the\nfundamental difference between these auctions, demand-side platforms (DSPs)\nhave had to update their bidding strategies to avoid bidding unnecessarily high\nand hence overpaying. Bid shading was proposed to adjust the bid price intended\nfor second-price auctions, in order to balance cost and winning probability in\na first-price auction setup. In this study, we introduce a novel deep\ndistribution network for optimal bidding in both open (non-censored) and closed\n(censored) online first-price auctions. Offline and online A/B testing results\nshow that our algorithm outperforms previous state-of-art algorithms in terms\nof both surplus and effective cost per action (eCPX) metrics. Furthermore, the\nalgorithm is optimized in run-time and has been deployed into VerizonMedia DSP\nas production algorithm, serving hundreds of billions of bid requests per day.\nOnline A/B test shows that advertiser's ROI are improved by +2.4%, +2.4%, and\n+8.6% for impression based (CPM), click based (CPC), and conversion based (CPA)\ncampaigns respectively.",
    "descriptor": "",
    "authors": [
      "Tian Zhou",
      "Hao He",
      "Shengjun Pan",
      "Niklas Karlsson",
      "Bharatbhushan Shetty",
      "Brendan Kitts",
      "Djordje Gligorijevic",
      "San Gultekin",
      "Tingyu Mao",
      "Junwei Pan",
      "Jianlong Zhang",
      "Aaron Flores"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06650"
  },
  {
    "id": "arXiv:2107.06652",
    "title": "Self-Supervised Multi-Modal Alignment for Whole Body Medical Imaging",
    "abstract": "This paper explores the use of self-supervised deep learning in medical\nimaging in cases where two scan modalities are available for the same subject.\nSpecifically, we use a large publicly-available dataset of over 20,000 subjects\nfrom the UK Biobank with both whole body Dixon technique magnetic resonance\n(MR) scans and also dual-energy x-ray absorptiometry (DXA) scans. We make three\ncontributions: (i) We introduce a multi-modal image-matching contrastive\nframework, that is able to learn to match different-modality scans of the same\nsubject with high accuracy. (ii) Without any adaption, we show that the\ncorrespondences learnt during this contrastive training step can be used to\nperform automatic cross-modal scan registration in a completely unsupervised\nmanner. (iii) Finally, we use these registrations to transfer segmentation maps\nfrom the DXA scans to the MR scans where they are used to train a network to\nsegment anatomical regions without requiring ground-truth MR examples. To aid\nfurther research, our code will be made publicly available.",
    "descriptor": "\nComments: Accepted as a full paper to MICCAI 2021. Code will be made publicly available before September 27th 2021\n",
    "authors": [
      "Rhydian Windsor",
      "Amir Jamaludin",
      "Timor Kadir",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06652"
  },
  {
    "id": "arXiv:2107.06657",
    "title": "DeepMutants: Training neural bug detectors with contextual mutations",
    "abstract": "Learning-based bug detectors promise to find bugs in large code bases by\nexploiting natural hints such as names of variables and functions or comments.\nStill, existing techniques tend to underperform when presented with realistic\nbugs. We believe bug detector learning to currently suffer from a lack of\nrealistic defective training examples. In fact, real world bugs are scarce\nwhich has driven existing methods to train on artificially created and mostly\nunrealistic mutants. In this work, we propose a novel contextual mutation\noperator which incorporates knowledge about the mutation context to dynamically\ninject natural and more realistic faults into code. Our approach employs a\nmasked language model to produce a context-dependent distribution over feasible\ntoken replacements. The evaluation shows that sampling from a language model\ndoes not only produce mutants which more accurately represent real bugs but\nalso lead to better performing bug detectors, both on artificial benchmarks and\non real world source code.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Cedric Richter",
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06657"
  },
  {
    "id": "arXiv:2107.06661",
    "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks",
    "abstract": "In high-dimensional state spaces, the usefulness of Reinforcement Learning\n(RL) is limited by the problem of exploration. This issue has been addressed\nusing potential-based reward shaping (PB-RS) previously. In the present work,\nwe introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the\nstrict optimality guarantees of PB-RS to a guarantee of preserved long-term\nbehavior. Being less restrictive, FV-RS allows for reward shaping functions\nthat are even better suited for improving the sample efficiency of RL\nalgorithms. In particular, we consider settings in which the agent has access\nto an approximate plan. Here, we use examples of simulated robotic manipulation\ntasks to demonstrate that plan-based FV-RS can indeed significantly improve the\nsample efficiency of RL over plan-based PB-RS.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2021\n",
    "authors": [
      "Ingmar Schubert",
      "Ozgur S. Oguz",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06661"
  },
  {
    "id": "arXiv:2107.06662",
    "title": "A Reputation-based Approach using Consortium Blockchain for Cyber Threat  Intelligence Sharing",
    "abstract": "The CTI (Cyber Threat Intelligence) sharing and exchange is an effective\nmethod to improve the responsiveness of the protection party. Blockchain\ntechnology enables sharing collaboration consortium to conduct a trusted CTI\nsharing and exchange without a trusted centralized institution. However, the\ndistributed connectivity of the blockchain-based CTI sharing model proposed\nbefore exposes the systems into byzantine attacks, the compromised members of\npartner organizations will further decrease the accuracy and trust level of CTI\nby generating false reporting. To address the unbalance issues of performance\nin speed, scalability and security, this paper proposes a new blockchain-based\nCTI model, which combines consortium blockchain and distributed reputation\nmanagement systems to achieve automated analysis and response of tactical\nthreat intelligence. In addition, the novel consensus algorithm of consortium\nblockchain that is fit for CTI sharing and exchange introduced in this paper.\nThe new consensus algorithm is called 'Proof-of Reputation' (PoR) consensus,\nwhich meets the requirements of transaction rate and makes the consensus in a\ncreditable network environment through constructing a reputation model.\nFinally, the effectiveness and security performance of the proposed model and\nconsensus algorithm is verified by experiments.",
    "descriptor": "\nComments: 16 pages,8 figures and 8 tables,submitted to journal\n",
    "authors": [
      "Zhang Xiaohui",
      "Miao Xianghua"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06662"
  },
  {
    "id": "arXiv:2107.06664",
    "title": "EnergySaver Software Manual",
    "abstract": "Energy efficiency is a topic that has attracted the attention of researchers\nin recent years, in order to seek sustainability solutions for energy\nproduction and reduction of its costs, aiming to provide a balance between\ndevelopment and protection of natural resources. Thus, we proposed the\nEnergySaver software that has as its objective the monitoring of electric\nenergy consumption, from data capture to consumption forecast for the following\nmonth. To create Energy Saver, we used Open Source technologies applied to the\nInternet of Things (IoT), embedded systems, and Long Short-Term Memory Neural\nNetworks (LSTM). However, in order to have harmony between the current\nresearchers and those who may manipulate this software in the future, it is\nessential to create a Software Manual, where all the details of its\nimplementation are described in detail. Therefore, this article describes all\nthe steps for the implementation of the system, from the methodological scheme\nof the system, its modeling with UML, to the modules that compose it, becoming\na Manual for its use.",
    "descriptor": "\nComments: 8 pages, in Portuguese, 21 figures\n",
    "authors": [
      "Davi Guimar\u00e3es da Silva",
      "Marla Teresinha Barbosa Geller",
      "Dalton Felipe Silva Var\u00e3o",
      "Jo\u00e3o Bentes",
      "Mauro S\u00e9rgio dos Santos Moura",
      "Yasmin Braga Teixeira",
      "Clayton Andr\u00e9 Maia dos Santos",
      "Anderson Alvarenga de Moura Meneses"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06664"
  },
  {
    "id": "arXiv:2107.06665",
    "title": "Disparity Between Batches as a Signal for Early Stopping",
    "abstract": "We propose a metric for evaluating the generalization ability of deep neural\nnetworks trained with mini-batch gradient descent. Our metric, called gradient\ndisparity, is the $\\ell_2$ norm distance between the gradient vectors of two\nmini-batches drawn from the training set. It is derived from a probabilistic\nupper bound on the difference between the classification errors over a given\nmini-batch, when the network is trained on this mini-batch and when the network\nis trained on another mini-batch of points sampled from the same dataset. We\nempirically show that gradient disparity is a very promising early-stopping\ncriterion (i) when data is limited, as it uses all the samples for training and\n(ii) when available data has noisy labels, as it signals overfitting better\nthan the validation data. Furthermore, we show in a wide range of experimental\nsettings that gradient disparity is strongly related to the generalization\nerror between the training and test sets, and that it is also very informative\nabout the level of label noise.",
    "descriptor": "",
    "authors": [
      "Mahsa Forouzesh",
      "Patrick Thiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06665"
  },
  {
    "id": "arXiv:2107.06667",
    "title": "Polarization and coherence in mean field games driven by private and  social utility",
    "abstract": "We study a mean field game in continuous time over a finite horizon, T, where\nthe state of each agent is binary and where players base their strategic\ndecisions on two, possibly competing, factors: the willingness to align with\nthe majority (conformism) and the aspiration of sticking with the own type\n(stubbornness). We also consider a quadratic cost related to the rate at which\na change in the state happens: changing opinion may be a costly operation.\nDepending on the parameters of the model, the game may have more than one Nash\nequilibrium, even though the corresponding N-player game does not. Moreover, it\nexhibits a very rich phase diagram, where polarized/unpolarized,\ncoherent/incoherent equilibria may coexist, except for T small, where the\nequilibrium is always unique. We fully describe such phase diagram in closed\nform and provide a detailed numerical analysis of the N-player counterpart of\nthe mean field game. In this finite dimensional setting, the equilibrium\nselected by the population of players is always coherent (favoring the\nsubpopulation whose type is aligned with the initial condition), but it does\nnot necessarily minimize the cost functional. Rather, it seems that, among the\ncoherent ones, the equilibrium prevailing is the one that most benefits the\nunderdog subpopulation forced to change opinion.",
    "descriptor": "",
    "authors": [
      "Dai Pra Paolo",
      "Sartori Elena",
      "Tolotti Marco"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.06667"
  },
  {
    "id": "arXiv:2107.06668",
    "title": "Thinkback: Task-SpecificOut-of-Distribution Detection",
    "abstract": "The increased success of Deep Learning (DL) has recently sparked large-scale\ndeployment of DL models in many diverse industry segments. Yet, a crucial\nweakness of supervised model is the inherent difficulty in handling\nout-of-distribution samples, i.e., samples belonging to classes that were not\npresented to the model at training time. We propose in this paper a novel way\nto formulate the out-of-distribution detection problem, tailored for DL models.\nOur method does not require fine tuning process on training data, yet is\nsignificantly more accurate than the state of the art for out-of-distribution\ndetection.",
    "descriptor": "",
    "authors": [
      "Lixuan Yang",
      "Dario Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06668"
  },
  {
    "id": "arXiv:2107.06672",
    "title": "Improved SAT models for NFA learning",
    "abstract": "Grammatical inference is concerned with the study of algorithms for learning\nautomata and grammars from words. We focus on learning Nondeterministic Finite\nAutomaton of size k from samples of words. To this end, we formulate the\nproblem as a SAT model. The generated SAT instances being enormous, we propose\nsome model improvements, both in terms of the number of variables, the number\nof clauses, and clauses size. These improvements significantly reduce the\ninstances, but at the cost of longer generation time. We thus try to balance\ninstance size vs. generation and solving time. We also achieved some\nexperimental comparisons and we analyzed our various model improvements.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Lardeux",
      "Eric Monfroy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06672"
  },
  {
    "id": "arXiv:2107.06673",
    "title": "Gradient boosting-based numerical methods for high-dimensional backward  stochastic differential equations",
    "abstract": "In this work we propose a new algorithm for solving high-dimensional backward\nstochastic differential equations (BSDEs). Based on the general\ntheta-discretization for the time-integrands, we show how to efficiently use\neXtreme Gradient Boosting (XGBoost) regression to approximate the resulting\nconditional expectations in a quite high dimension. Numerical results\nillustrate the efficiency and accuracy of our proposed algorithms for solving\nvery high-dimensional (up to $10000$ dimensions) nonlinear BSDEs.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Long Teng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06673"
  },
  {
    "id": "arXiv:2107.06676",
    "title": "Higgs Boson Classification: Brain-inspired BCPNN Learning with  StreamBrain",
    "abstract": "One of the most promising approaches for data analysis and exploration of\nlarge data sets is Machine Learning techniques that are inspired by brain\nmodels. Such methods use alternative learning rules potentially more\nefficiently than established learning rules. In this work, we focus on the\npotential of brain-inspired ML for exploiting High-Performance Computing (HPC)\nresources to solve ML problems: we discuss the BCPNN and an HPC implementation,\ncalled StreamBrain, its computational cost, suitability to HPC systems. As an\nexample, we use StreamBrain to analyze the Higgs Boson dataset from High Energy\nPhysics and discriminate between background and signal classes in collisions of\nhigh-energy particle colliders. Overall, we reach up to 69.15% accuracy and\n76.4% Area Under the Curve (AUC) performance.",
    "descriptor": "\nComments: Submitted to The 2nd Workshop on Artificial Intelligence and Machine Learning for Scientific Applications (AI4S 2021)\n",
    "authors": [
      "Martin Svedin",
      "Artur Podobas",
      "Steven W. D. Chien",
      "Stefano Markidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06676"
  },
  {
    "id": "arXiv:2107.06678",
    "title": "Optimal Power Allocation in Downlink NOMA",
    "abstract": "Power-domain non-orthogonal multiple access (NOMA) has arisen as a promising\nmultiple access technique for the next-generation wireless networks. In this\nwork, we address the problem of finding globally optimal power allocation\nstrategies for the downlink of a generic single-cell NOMA system including\nmultiple NOMA clusters each operating in an isolated resource block. Each\ncluster includes a set of users in which the well-known superposition coding\n(SC) combined with successive interference cancellation (SIC) technique (called\nSC-SIC) is applied among them. Interestingly, we prove that in both the\nsum-rate and energy efficiency maximization problems, network-NOMA can be\nequivalently transformed to a virtual network-OMA system, where the effective\nchannel gain of these virtual OMA users are obtained in closed-form. Then, the\nlatter problems are solved by using very fast water-filling and Dinkelbach\nalgorithms, respectively. The equivalent transformation of NOMA to the virtual\nOMA system brings new insights, which are discussed throughout the paper.\nExtensive numerical results are provided to show the performance gap between\nfully SC-SIC, NOMA, and OMA in terms of system outage probability, BS's power\nconsumption, users sum-rate, and system energy efficiency.",
    "descriptor": "\nComments: 15 pages, 30 figures. arXiv admin note: text overlap with arXiv:2106.08636\n",
    "authors": [
      "Sepehr Rezvani",
      "Eduard A. Jorswieck",
      "Roghayeh Joda",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06678"
  },
  {
    "id": "arXiv:2107.06679",
    "title": "Mismatched Binary Hypothesis Testing: Error Exponent Sensitivity",
    "abstract": "We study the problem of mismatched binary hypothesis testing between i.i.d.\ndistributions. We analyze the tradeoff between the pairwise error probability\nexponents when the actual distributions generating the observation are\ndifferent from the distributions used in the likelihood ratio test, sequential\nprobability ratio test, and Hoeffding's generalized likelihood ratio test in\nthe composite setting. When the real distributions are within a small\ndivergence ball of the test distributions, we find the deviation of the\nworst-case error exponent of each test with respect to the matched error\nexponent. In addition, we consider the case where an adversary tampers with the\nobservation, again within a divergence ball of the observation type. We show\nthat the tests are more sensitive to distribution mismatch than to adversarial\nobservation tampering.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2001.03917\n",
    "authors": [
      "Parham Boroumand",
      "Albert Guill\u00e9n i F\u00e0bregas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06679"
  },
  {
    "id": "arXiv:2107.06681",
    "title": "Unsupervised Neural Rendering for Image Hazing",
    "abstract": "Image hazing aims to render a hazy image from a given clean one, which could\nbe applied to a variety of practical applications such as gaming, filming,\nphotographic filtering, and image dehazing. To generate plausible haze, we\nstudy two less-touched but challenging problems in hazy image rendering,\nnamely, i) how to estimate the transmission map from a single image without\nauxiliary information, and ii) how to adaptively learn the airlight from\nexemplars, i.e., unpaired real hazy images. To this end, we propose a neural\nrendering method for image hazing, dubbed as HazeGEN. To be specific, HazeGEN\nis a knowledge-driven neural network which estimates the transmission map by\nleveraging a new prior, i.e., there exists the structure similarity (e.g.,\ncontour and luminance) between the transmission map and the input clean image.\nTo adaptively learn the airlight, we build a neural module based on another new\nprior, i.e., the rendered hazy image and the exemplar are similar in the\nairlight distribution. To the best of our knowledge, this could be the first\nattempt to deeply rendering hazy images in an unsupervised fashion. Comparing\nwith existing haze generation methods, HazeGEN renders the hazy images in an\nunsupervised, learnable, and controllable manner, thus avoiding the\nlabor-intensive efforts in paired data collection and the domain-shift issue in\nhaze generation. Extensive experiments show the promising performance of our\nmethod comparing with some baselines in both qualitative and quantitative\ncomparisons. The code will be released on GitHub after acceptance.",
    "descriptor": "",
    "authors": [
      "Boyun Li",
      "Yijie Lin",
      "Xiao Liu",
      "Peng Hu",
      "Jiancheng Lv",
      "Xi Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06681"
  },
  {
    "id": "arXiv:2107.06686",
    "title": "Safer Reinforcement Learning through Transferable Instinct Networks",
    "abstract": "Random exploration is one of the main mechanisms through which reinforcement\nlearning (RL) finds well-performing policies. However, it can lead to\nundesirable or catastrophic outcomes when learning online in safety-critical\nenvironments. In fact, safe learning is one of the major obstacles towards\nreal-world agents that can learn during deployment. One way of ensuring that\nagents respect hard limitations is to explicitly configure boundaries in which\nthey can operate. While this might work in some cases, we do not always have\nclear a-priori information which states and actions can lead dangerously close\nto hazardous states. Here, we present an approach where an additional policy\ncan override the main policy and offer a safer alternative action. In our\ninstinct-regulated RL (IR^2L) approach, an \"instinctual\" network is trained to\nrecognize undesirable situations, while guarding the learning policy against\nentering them. The instinct network is pre-trained on a single task where it is\nsafe to make mistakes, and transferred to environments in which learning a new\ntask safely is critical. We demonstrate IR^2L in the OpenAI Safety gym domain,\nin which it receives a significantly lower number of safety violations during\ntraining than a baseline RL approach while reaching similar task performance.",
    "descriptor": "\nComments: The paper was accepted in the ALIFE 2021 conference\n",
    "authors": [
      "Djordje Grbic",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06686"
  },
  {
    "id": "arXiv:2107.06692",
    "title": "Deep Adaptive Multi-Intention Inverse Reinforcement Learning",
    "abstract": "This paper presents a deep Inverse Reinforcement Learning (IRL) framework\nthat can learn an a priori unknown number of nonlinear reward functions from\nunlabeled experts' demonstrations. For this purpose, we employ the tools from\nDirichlet processes and propose an adaptive approach to simultaneously account\nfor both complex and unknown number of reward functions. Using the conditional\nmaximum entropy principle, we model the experts' multi-intention behaviors as a\nmixture of latent intention distributions and derive two algorithms to estimate\nthe parameters of the deep reward network along with the number of experts'\nintentions from unlabeled demonstrations. The proposed algorithms are evaluated\non three benchmarks, two of which have been specifically extended in this study\nfor multi-intention IRL, and compared with well-known baselines. We demonstrate\nthrough several experiments the advantages of our algorithms over the existing\napproaches and the benefits of online inferring, rather than fixing beforehand,\nthe number of expert's intentions.",
    "descriptor": "\nComments: Accepted for presentation at ECML/PKDD 2021\n",
    "authors": [
      "Ariyan Bighashdel",
      "Panagiotis Meletis",
      "Pavol Jancura",
      "Gijs Dubbelman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06692"
  },
  {
    "id": "arXiv:2107.06694",
    "title": "Polynomially tractable cases in the popular roommates problem",
    "abstract": "The input of the popular roommates problem consists of a graph $G = (V, E)$\nand for each vertex $v\\in V$, strict preferences over the neighbors of $v$.\nMatching $M$ is more popular than $M'$ if the number of vertices preferring $M$\nto $M'$ is larger than the number of vertices preferring $M'$ to $M$. A\nmatching $M$ is called popular if there is no matching $M'$ that is more\npopular than $M$.\nOnly recently Faenza et al. and Gupta et al. resolved the long-standing open\nquestion on the complexity of deciding whether a popular matching exists in a\npopular roommates instance and showed that the problem is NP-complete. In this\npaper we identify a class of instances that admit a polynomial-time algorithm\nfor the problem. We also test these theoretical findings on randomly generated\ninstances to determine the existence probability of a popular matching in them.",
    "descriptor": "",
    "authors": [
      "Erika B\u00e9rczi-Kov\u00e1cs",
      "\u00c1gnes Cseh",
      "Kata Kosztol\u00e1nyi",
      "Attila M\u00e1lyusz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.06694"
  },
  {
    "id": "arXiv:2107.06695",
    "title": "Solving discrete constrained problems on de Rham complex",
    "abstract": "The main difficulty is solving the discrete constrained problem is its poor\nand even ill condition. In this paper, we transform the discrete constrained\nproblems on de Rham complex to Laplace-like problems. This transformation not\nonly make the constrained problems solvable, but also make it easy to use the\nexisting iterative methods and preconditioning techniques to solving\nlarge-scale discrete constrained problems.",
    "descriptor": "",
    "authors": [
      "Zhongjie Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06695"
  },
  {
    "id": "arXiv:2107.06700",
    "title": "Differential-Critic GAN: Generating What You Want by a Cue of  Preferences",
    "abstract": "This paper proposes Differential-Critic Generative Adversarial Network\n(DiCGAN) to learn the distribution of user-desired data when only partial\ninstead of the entire dataset possesses the desired property, which generates\ndesired data that meets user's expectations and can assist in designing\nbiological products with desired properties. Existing approaches select the\ndesired samples first and train regular GANs on the selected samples to derive\nthe user-desired data distribution. However, the selection of the desired data\nrelies on an expert criterion and supervision over the entire dataset. DiCGAN\nintroduces a differential critic that can learn the preference direction from\nthe pairwise preferences, which is amateur knowledge and can be defined on part\nof the training data. The resultant critic guides the generation of the desired\ndata instead of the whole data. Specifically, apart from the Wasserstein GAN\nloss, a ranking loss of the pairwise preferences is defined over the critic. It\nendows the difference of critic values between each pair of samples with the\npairwise preference relation. The higher critic value indicates that the sample\nis preferred by the user. Thus training the generative model for higher critic\nvalues encourages the generation of user-preferred samples. Extensive\nexperiments show that our DiCGAN achieves state-of-the-art performance in\nlearning the user-desired data distributions, especially in the cases of\ninsufficient desired data and limited supervision.",
    "descriptor": "",
    "authors": [
      "Yinghua Yao",
      "Yuangang Pan",
      "Ivor W.Tsang",
      "Xin Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06700"
  },
  {
    "id": "arXiv:2107.06703",
    "title": "Zero-Round Active Learning",
    "abstract": "Active learning (AL) aims at reducing labeling effort by identifying the most\nvaluable unlabeled data points from a large pool. Traditional AL frameworks\nhave two limitations: First, they perform data selection in a multi-round\nmanner, which is time-consuming and impractical. Second, they usually assume\nthat there are a small amount of labeled data points available in the same\ndomain as the data in the unlabeled pool. Recent work proposes a solution for\none-round active learning based on data utility learning and optimization,\nwhich fixes the first issue but still requires the initially labeled data\npoints in the same domain. In this paper, we propose $\\mathrm{D^2ULO}$ as a\nsolution that solves both issues. Specifically, $\\mathrm{D^2ULO}$ leverages the\nidea of domain adaptation (DA) to train a data utility model which can\neffectively predict the utility for any given unlabeled data in the target\ndomain once labeled. The trained data utility model can then be used to select\nhigh-utility data and at the same time, provide an estimate for the utility of\nthe selected data. Our algorithm does not rely on any feedback from annotators\nin the target domain and hence, can be used to perform zero-round active\nlearning or warm-start existing multi-round active learning strategies. Our\nexperiments show that $\\mathrm{D^2ULO}$ outperforms the existing\nstate-of-the-art AL strategies equipped with domain adaptation over various\ndomain shift settings (e.g., real-to-real data and synthetic-to-real data).\nParticularly, $\\mathrm{D^2ULO}$ are applicable to the scenario where source and\ntarget labels have mismatches, which is not supported by the existing works.",
    "descriptor": "",
    "authors": [
      "Si Chen",
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06703"
  },
  {
    "id": "arXiv:2107.06707",
    "title": "Uncertainty-Guided Mixup for Semi-Supervised Domain Adaptation without  Source Data",
    "abstract": "Present domain adaptation methods usually perform explicit representation\nalignment by simultaneously accessing the source data and target data. However,\nthe source data are not always available due to the privacy preserving\nconsideration or bandwidth limitation. Source-free domain adaptation aims to\nsolve the above problem by performing domain adaptation without accessing the\nsource data. The adaptation paradigm is receiving more and more attention in\nrecent years, and multiple works have been proposed for unsupervised\nsource-free domain adaptation. However, without utilizing any supervised signal\nand source data at the adaptation stage, the optimization of the target model\nis unstable and fragile. To alleviate the problem, we focus on semi-supervised\ndomain adaptation under source-free setting. More specifically, we propose\nuncertainty-guided Mixup to reduce the representation's intra-domain\ndiscrepancy and perform inter-domain alignment without directly accessing the\nsource data. Finally, we conduct extensive semi-supervised domain adaptation\nexperiments on various datasets. Our method outperforms the recent\nsemi-supervised baselines and the unsupervised variant also achieves\ncompetitive performance. The experiment codes will be released in the future.",
    "descriptor": "",
    "authors": [
      "Ning Ma",
      "Jiajun Bu",
      "Zhen Zhang",
      "Sheng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06707"
  },
  {
    "id": "arXiv:2107.06708",
    "title": "MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial  Intelligence",
    "abstract": "Over the past decade, Artificial Intelligence (AI) has provided enormous new\npossibilities and opportunities, but also new demands and requirements for\nsoftware systems. In particular, Machine Learning (ML) has proven useful in\nalmost every vertical application domain. Although other sub-disciplines of AI,\nsuch as intelligent agents and Multi-Agent Systems (MAS) did not become\npromoted to the same extent, they still possess the potential to be integrated\ninto the mainstream technology stacks and ecosystems, for example, due to the\nongoing prevalence of the Internet of Things (IoT) and smart Cyber-Physical\nSystems (CPS). However, in the decade ahead, an unprecedented paradigm shift\nfrom classical computing towards Quantum Computing (QC) is expected, with\nperhaps a quantum-classical hybrid model. We expect the Model-Driven\nEngineering (MDE) paradigm to be an enabler and a facilitator, when it comes to\nthe quantum and the quantum-classical hybrid applications as it has already\nproven beneficial in the highly complex domains of IoT, smart CPS and AI with\ninherently heterogeneous hardware and software platforms, and APIs. This\nincludes not only automated code generation, but also automated model checking\nand verification, as well as model analysis in the early design phases, and\nmodel-to-model transformations both at the design-time and at the runtime. In\nthis paper, the vision is focused on MDE for Quantum AI, and a holistic\napproach integrating all of the above.",
    "descriptor": "\nComments: Preliminary Version - Vision Paper\n",
    "authors": [
      "Armin Moin",
      "Moharram Challenger",
      "Atta Badii",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06708"
  },
  {
    "id": "arXiv:2107.06709",
    "title": "DVMN: Dense Validity Mask Network for Depth Completion",
    "abstract": "LiDAR depth maps provide environmental guidance in a variety of applications.\nHowever, such depth maps are typically sparse and insufficient for complex\ntasks such as autonomous navigation. State of the art methods use image guided\nneural networks for dense depth completion. We develop a guided convolutional\nneural network focusing on gathering dense and valid information from sparse\ndepth maps. To this end, we introduce a novel layer with spatially variant and\ncontent-depended dilation to include additional data from sparse input.\nFurthermore, we propose a sparsity invariant residual bottleneck block. We\nevaluate our Dense Validity Mask Network (DVMN) on the KITTI depth completion\nbenchmark and achieve state of the art results. At the time of submission, our\nnetwork is the leading method using sparsity invariant convolution.",
    "descriptor": "\nComments: This paper has been accepted at IEEE Intelligent Transportation Systems Conference (ITSC), 2021\n",
    "authors": [
      "Laurenz Reichardt",
      "Patrick Mangat",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06709"
  },
  {
    "id": "arXiv:2107.06711",
    "title": "PDC: Piecewise Depth Completion utilizing Superpixels",
    "abstract": "Depth completion from sparse LiDAR and high-resolution RGB data is one of the\nfoundations for autonomous driving techniques. Current approaches often rely on\nCNN-based methods with several known drawbacks: flying pixel at depth\ndiscontinuities, overfitting to both a given data set as well as error metric,\nand many more. Thus, we propose our novel Piecewise Depth Completion (PDC),\nwhich works completely without deep learning. PDC segments the RGB image into\nsuperpixels corresponding the regions with similar depth value. Superpixels\ncorresponding to same objects are gathered using a cost map. At the end, we\nreceive detailed depth images with state of the art accuracy. In our\nevaluation, we can show both the influence of the individual proposed\nprocessing steps and the overall performance of our method on the challenging\nKITTI dataset.",
    "descriptor": "\nComments: This paper has been accepted at IEEE Intelligent Transportation Systems Conference (ITSC), 2021\n",
    "authors": [
      "Dennis Teutscher",
      "Patrick Mangat",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06711"
  },
  {
    "id": "arXiv:2107.06715",
    "title": "ETH Tight Algorithms for Geometric Intersection Graphs: Now in  Polynomial Space",
    "abstract": "De Berg et al. in [SICOMP 2020] gave an algorithmic framework for\nsubexponential algorithms on geometric graphs with tight (up to ETH) running\ntimes. This framework is based on dynamic programming on graphs of weighted\ntreewidth resulting in algorithms that use super-polynomial space. We introduce\nthe notion of weighted treedepth and use it to refine the framework of de Berg\net al. for obtaining polynomial space (with tight running times) on geometric\ngraphs. As a result, we prove that for any fixed dimension $d \\ge 2$ on\nintersection graphs of similarly-sized fat objects many well-known graph\nproblems including Independent Set, $r$-Dominating Set for constant $r$, Cycle\nCover, Hamiltonian Cycle, Hamiltonian Path, Steiner Tree, Connected Vertex\nCover, Feedback Vertex Set, and (Connected) Odd Cycle Transversal are solvable\nin time $2^{O(n^{1-1/d})}$ and within polynomial space.",
    "descriptor": "",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Tanmay Inamdar",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06715"
  },
  {
    "id": "arXiv:2107.06720",
    "title": "Fairness in Ranking under Uncertainty",
    "abstract": "Fairness has emerged as an important consideration in algorithmic\ndecision-making. Unfairness occurs when an agent with higher merit obtains a\nworse outcome than an agent with lower merit. Our central point is that a\nprimary cause of unfairness is uncertainty. A principal or algorithm making\ndecisions never has access to the agents' true merit, and instead uses proxy\nfeatures that only imperfectly predict merit (e.g., GPA, star ratings,\nrecommendation letters). None of these ever fully capture an agent's merit; yet\nexisting approaches have mostly been defining fairness notions directly based\non observed features and outcomes.\nOur primary point is that it is more principled to acknowledge and model the\nuncertainty explicitly. The role of observed features is to give rise to a\nposterior distribution of the agents' merits. We use this viewpoint to define a\nnotion of approximate fairness in ranking. We call an algorithm $\\phi$-fair\n(for $\\phi \\in [0,1]$) if it has the following property for all agents $x$ and\nall $k$: if agent $x$ is among the top $k$ agents with respect to merit with\nprobability at least $\\rho$ (according to the posterior merit distribution),\nthen the algorithm places the agent among the top $k$ agents in its ranking\nwith probability at least $\\phi \\rho$.\nWe show how to compute rankings that optimally trade off approximate fairness\nagainst utility to the principal. In addition to the theoretical\ncharacterization, we present an empirical analysis of the potential impact of\nthe approach in simulation studies. For real-world validation, we applied the\napproach in the context of a paper recommendation system that we built and\nfielded at a large conference.",
    "descriptor": "\nComments: Preprint under submission. 19 pages, 4 figures\n",
    "authors": [
      "Ashudeep Singh",
      "David Kempe",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06720"
  },
  {
    "id": "arXiv:2107.06724",
    "title": "Federated Mixture of Experts",
    "abstract": "Federated learning (FL) has emerged as the predominant approach for\ncollaborative training of neural network models across multiple users, without\nthe need to gather the data at a central location. One of the important\nchallenges in this setting is data heterogeneity, i.e. different users have\ndifferent data characteristics. For this reason, training and using a single\nglobal model might be suboptimal when considering the performance of each of\nthe individual user's data. In this work, we tackle this problem via Federated\nMixture of Experts, FedMix, a framework that allows us to train an ensemble of\nspecialized models. FedMix adaptively selects and trains a user-specific\nselection of the ensemble members. We show that users with similar data\ncharacteristics select the same members and therefore share statistical\nstrength while mitigating the effect of non-i.i.d data. Empirically, we show\nthrough an extensive experimental evaluation that FedMix improves performance\ncompared to using a single global model across a variety of different sources\nof non-i.i.d.-ness.",
    "descriptor": "",
    "authors": [
      "Matthias Reisser",
      "Christos Louizos",
      "Efstratios Gavves",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06724"
  },
  {
    "id": "arXiv:2107.06727",
    "title": "Composition of choreography automata",
    "abstract": "Choreography automata are an automata-based model of choreographies, that we\nshow to be a compositional one. Choreography automata represent global views of\nchoreographies (and rely on the well-known model of communicating finite-state\nmachines to model local behaviours). The projections of well-formed global\nviews are live as well as lock- and deadlock-free. In the class of choreography\nautomata we define an internal operation of {\\em composition}, which connects\ntwo global views via roles acting as interfaces. We show that under mild\nconditions the composition of well-formed choreography automata is well-formed.\nThe composition operation enables for a flexible modular mechanism at the\ndesign level.",
    "descriptor": "",
    "authors": [
      "Franco Barbanera",
      "Ivan Lanese",
      "Emilio Tuosto"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06727"
  },
  {
    "id": "arXiv:2107.06732",
    "title": "Opportunities and challenges of Blockchain-Oriented systems in the  tourism industry",
    "abstract": "The tourism industry is increasingly influenced by the evolution of\ninformation and communication technologies (ICT), which are revolutionizing the\nway people travel. In this work we want to nvestigate the use of innovative IT\ntechnologies by DMOs (Destination Management Organizations), focusing on\nblockchain technology, both from the point of view of research in the field,\nand in the study of the most relevant software projects. In particular, we\nintend to verify the benefits offered by these IT tools in the management and\nmonitoring of a destination, without forgetting the implications for the other\nstakeholders involved. These technologies, in fact, can offer a wide range of\nservices that can be useful throughout the life cycle of the destination.",
    "descriptor": "",
    "authors": [
      "Fabio Caddeo",
      "Andrea Pinna"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06732"
  },
  {
    "id": "arXiv:2107.06735",
    "title": "Semi-Supervised Hypothesis Transfer for Source-Free Domain Adaptation",
    "abstract": "Domain Adaptation has been widely used to deal with the distribution shift in\nvision, language, multimedia etc. Most domain adaptation methods learn\ndomain-invariant features with data from both domains available. However, such\na strategy might be infeasible in practice when source data are unavailable due\nto data-privacy concerns. To address this issue, we propose a novel adaptation\nmethod via hypothesis transfer without accessing source data at adaptation\nstage. In order to fully use the limited target data, a semi-supervised mutual\nenhancement method is proposed, in which entropy minimization and augmented\nlabel propagation are used iteratively to perform inter-domain and intra-domain\nalignments. Compared with state-of-the-art methods, the experimental results on\nthree public datasets demonstrate that our method gets up to 19.9% improvements\non semi-supervised adaptation tasks.",
    "descriptor": "",
    "authors": [
      "Ning Ma",
      "Jiajun Bu",
      "Lixian Lu",
      "Jun Wen",
      "Zhen Zhang",
      "Sheng Zhou",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06735"
  },
  {
    "id": "arXiv:2107.06744",
    "title": "Efficient Learning of Pinball TWSVM using Privileged Information and its  applications",
    "abstract": "In any learning framework, an expert knowledge always plays a crucial role.\nBut, in the field of machine learning, the knowledge offered by an expert is\nrarely used. Moreover, machine learning algorithms (SVM based) generally use\nhinge loss function which is sensitive towards the noise. Thus, in order to get\nthe advantage from an expert knowledge and to reduce the sensitivity towards\nthe noise, in this paper, we propose privileged information based Twin Pinball\nSupport Vector Machine classifier (Pin-TWSVMPI) where expert's knowledge is in\nthe form of privileged information. The proposed Pin-TWSVMPI incorporates\nprivileged information by using correcting function so as to obtain two\nnonparallel decision hyperplanes. Further, in order to make computations more\nefficient and fast, we use Sequential Minimal Optimization (SMO) technique for\nobtaining the classifier and have also shown its application for Pedestrian\ndetection and Handwritten digit recognition. Further, for UCI datasets, we\nfirst implement a procedure which extracts privileged information from the\nfeatures of the dataset which are then further utilized by Pin-TWSVMPI that\nleads to enhancement in classification accuracy with comparatively lesser\ncomputational time.",
    "descriptor": "",
    "authors": [
      "Reshma Rastogi",
      "Aman Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06744"
  },
  {
    "id": "arXiv:2107.06747",
    "title": "Artificial Intelligence in PET: an Industry Perspective",
    "abstract": "Artificial intelligence (AI) has significant potential to positively impact\nand advance medical imaging, including positron emission tomography (PET)\nimaging applications. AI has the ability to enhance and optimize all aspects of\nthe PET imaging chain from patient scheduling, patient setup, protocoling, data\nacquisition, detector signal processing, reconstruction, image processing and\ninterpretation. AI poses industry-specific challenges which will need to be\naddressed and overcome to maximize the future potentials of AI in PET. This\npaper provides an overview of these industry-specific challenges for the\ndevelopment, standardization, commercialization, and clinical adoption of AI,\nand explores the potential enhancements to PET imaging brought on by AI in the\nnear future. In particular, the combination of on-demand image reconstruction,\nAI, and custom designed data processing workflows may open new possibilities\nfor innovation which would positively impact the industry and ultimately\npatients.",
    "descriptor": "",
    "authors": [
      "Arkadiusz Sitek",
      "Sangtae Ahn",
      "Evren Asma",
      "Adam Chandler",
      "Alvin Ihsani",
      "Sven Prevrhal",
      "Arman Rahmim",
      "Babak Saboury",
      "Kris Thielemans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06747"
  },
  {
    "id": "arXiv:2107.06749",
    "title": "Dynamic Event Camera Calibration",
    "abstract": "Camera calibration is an important prerequisite towards the solution of 3D\ncomputer vision problems. Traditional methods rely on static images of a\ncalibration pattern. This raises interesting challenges towards the practical\nusage of event cameras, which notably require image change to produce\nsufficient measurements. The current standard for event camera calibration\ntherefore consists of using flashing patterns. They have the advantage of\nsimultaneously triggering events in all reprojected pattern feature locations,\nbut it is difficult to construct or use such patterns in the field. We present\nthe first dynamic event camera calibration algorithm. It calibrates directly\nfrom events captured during relative motion between camera and calibration\npattern. The method is propelled by a novel feature extraction mechanism for\ncalibration patterns, and leverages existing calibration tools before\noptimizing all parameters through a multi-segment continuous-time formulation.\nAs demonstrated through our results on real data, the obtained calibration\nmethod is highly convenient and reliably calibrates from data sequences\nspanning less than 10 seconds.",
    "descriptor": "\nComments: accepted in the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Kun Huang",
      "Yifu Wang",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06749"
  },
  {
    "id": "arXiv:2107.06750",
    "title": "Fast and Slow Enigmas and Parental Guidance",
    "abstract": "We describe several additions to the ENIGMA system that guides clause\nselection in the E automated theorem prover. First, we significantly speed up\nits neural guidance by adding server-based GPU evaluation. The second addition\nis motivated by fast weight-based rejection filters that are currently used in\nsystems like E and Prover9. Such systems can be made more intelligent by\ninstead training fast versions of ENIGMA that implement more intelligent\npre-filtering. This results in combinations of trainable fast and slow thinking\nthat improves over both the fast-only and slow-only methods. The third addition\nis based on \"judging the children by their parents\", i.e., possibly rejecting\nan inference before it produces a clause. This is motivated by standard\nevolutionary mechanisms, where there is always a cost to producing all possible\noffsprings in the current population. This saves time by not evaluating all\nclauses by more expensive methods and provides a complementary view of the\ngenerated clauses. The methods are evaluated on a large benchmark coming from\nthe Mizar Mathematical Library, showing good improvements over the state of the\nart.",
    "descriptor": "\nComments: 23 pages, 11 tables, 1 figure, submitted to FroCoS 2021\n",
    "authors": [
      "Zarathustra Goertzel",
      "Karel Chvalovsk\u00fd",
      "Jan Jakub\u016fv",
      "Miroslav Ol\u0161\u00e1k",
      "Josef Urban"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06750"
  },
  {
    "id": "arXiv:2107.06751",
    "title": "Tortured phrases: A dubious writing style emerging in science. Evidence  of critical issues affecting established journals",
    "abstract": "Probabilistic text generators have been used to produce fake scientific\npapers for more than a decade. Such nonsensical papers are easily detected by\nboth human and machine. Now more complex AI-powered generation techniques\nproduce texts indistinguishable from that of humans and the generation of\nscientific texts from a few keywords has been documented. Our study introduces\nthe concept of tortured phrases: unexpected weird phrases in lieu of\nestablished ones, such as 'counterfeit consciousness' instead of 'artificial\nintelligence.' We combed the literature for tortured phrases and study one\nreputable journal where these concentrated en masse. Hypothesising the use of\nadvanced language models we ran a detector on the abstracts of recent articles\nof this journal and on several control sets. The pairwise comparisons reveal a\nconcentration of abstracts flagged as 'synthetic' in the journal. We also\nhighlight irregularities in its operation, such as abrupt changes in editorial\ntimelines. We substantiate our call for investigation by analysing several\nindividual dubious articles, stressing questionable features: tortured writing\nstyle, citation of non-existent literature, and unacknowledged image reuse.\nSurprisingly, some websites offer to rewrite texts for free, generating\ngobbledegook full of tortured phrases. We believe some authors used rewritten\ntexts to pad their manuscripts. We wish to raise the awareness on publications\ncontaining such questionable AI-generated or rewritten texts that passed (poor)\npeer review. Deception with synthetic texts threatens the integrity of the\nscientific literature.",
    "descriptor": "",
    "authors": [
      "Guillaume Cabanac",
      "Cyril Labb\u00e9",
      "Alexander Magazinov"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06751"
  },
  {
    "id": "arXiv:2107.06754",
    "title": "A Particle Filter Approach to Power System Line Outage Detection Using  Load and Generator Bus Dynamics",
    "abstract": "Limited phasor measurement unit (PMU) and varying signal strength levels make\nfast real-time transmission-line outage detection challenging. Existing\napproaches focus on monitoring nodal algebraic variables, i.e., voltage phase\nangle and magnitude. Their effectiveness is predicated on both strong outage\nsignals in voltage and PMUs in the outage location's vicinity. We propose a\nunified detection framework that utilizes both generator dynamic states and\nnodal voltage information. The inclusion of generator dynamics makes detection\nfaster and more robust to a priori unknown outage locations, which we\ndemonstrate using the IEEE 39-bus test system. In particular, the scheme\nachieves an over 80% detection rate for 80% of the lines, and most outages are\ndetected within 0.2 seconds. The new approach could be implemented to improve\nsystem operators' real-time situational awareness by detecting outages faster\nand providing a breakdown of outage signals for diagnostic purposes, making\npower systems more resilient.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Xiaozhou Yang",
      "Nan Chen",
      "Chao Zhai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.06754"
  },
  {
    "id": "arXiv:2107.06755",
    "title": "DIT4BEARs Smart Roads Internship",
    "abstract": "The research internship at UiT - The Arctic University of Norway was offered\nfor our team being the winner of the 'Smart Roads - Winter Road Maintenance\n2021' Hackathon. The internship commenced on 3 May 2021 and ended on 21 May\n2021 with meetings happening twice each week. In spite of having different\nnationalities and educational backgrounds, we both interns tried to collaborate\nas a team as much as possible. The most alluring part was working on this\nproject made us realize the critical conditions faced by the arctic people,\nwhere it was hard to gain such a unique experience from our residence. We\ndeveloped and implemented several deep learning models to classify the states\n(dry, moist, wet, icy, snowy, slushy). Depending upon the best model, the\nweather forecast app will predict the state taking the Ta, Tsurf, Height,\nSpeed, Water, etc. into consideration. The crucial part was to define a safety\nmetric which is the product of the accident rates based on friction and the\naccident rates based on states. We developed a regressor that will predict the\nsafety metric depending upon the state obtained from the classifier and the\nfriction obtained from the sensor data. A pathfinding algorithm has been\ndesigned using the sensor data, open street map data, weather data.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Md. Abrar Jahin",
      "Andrii Krutsylo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06755"
  },
  {
    "id": "arXiv:2107.06768",
    "title": "BiSTF: Bilateral-Branch Self-Training Framework for Semi-Supervised  Large-scale Fine-Grained Recognition",
    "abstract": "Semi-supervised Fine-Grained Recognition is a challenge task due to the\ndifficulty of data imbalance, high inter-class similarity and domain mismatch.\nRecent years, this field has witnessed great progress and many methods has\ngained great performance. However, these methods can hardly generalize to the\nlarge-scale datasets, such as Semi-iNat, as they are prone to suffer from noise\nin unlabeled data and the incompetence for learning features from imbalanced\nfine-grained data. In this work, we propose Bilateral-Branch Self-Training\nFramework (BiSTF), a simple yet effective framework to improve existing\nsemi-supervised learning methods on class-imbalanced and domain-shifted\nfine-grained data. By adjusting the update frequency through stochastic epoch\nupdate, BiSTF iteratively retrains a baseline SSL model with a labeled set\nexpanded by selectively adding pseudo-labeled samples from an unlabeled set,\nwhere the distribution of pseudo-labeled samples are the same as the labeled\ndata. We show that BiSTF outperforms the existing state-of-the-art SSL\nalgorithm on Semi-iNat dataset.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.09559 by other authors\n",
    "authors": [
      "Hao Chang",
      "Guochen Xie",
      "Jun Yu",
      "Qiang Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06768"
  },
  {
    "id": "arXiv:2107.06771",
    "title": "Simulation of Dissemination Strategies on Temporal Networks",
    "abstract": "In distributed environments, such as distributed ledgers technologies and\nother peer-to-peer architectures, communication represents a crucial topic. The\nability to efficiently disseminate contents is strongly influenced by the type\nof system architecture, the protocol used to spread such contents over the\nnetwork and the actual dynamicity of the communication links (i.e. static vs.\ntemporal nets). In particular, the dissemination strategies either focus on\nachieving an optimal coverage, minimizing the network traffic or providing\nassurances on anonymity (that is a fundamental requirement of many\ncryptocurrencies). In this work, the behaviour of multiple dissemination\nprotocols is discussed and studied through simulation. The performance\nevaluation has been carried out on temporal networks with the help of\nLUNES-temporal, a discrete event simulator that allows to test algorithms\nrunning on a distributed environment. The experiments show that some gossip\nprotocols allow to either save a considerable number of messages or to provide\nbetter anonymity guarantees, at the cost of a little lower coverage achieved\nand/or a little increase of the delivery time.",
    "descriptor": "\nComments: To appear in the Proceedings of the 2021 Annual Modeling and Simulation Conference (ANNSIM 2021)\n",
    "authors": [
      "Luca Serena",
      "Mirko Zichichi",
      "Gabriele D'Angelo",
      "Stefano Ferretti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06771"
  },
  {
    "id": "arXiv:2107.06777",
    "title": "Synthesis in Style: Semantic Segmentation of Historical Documents using  Synthetic Data",
    "abstract": "One of the most pressing problems in the automated analysis of historical\ndocuments is the availability of annotated training data. In this paper, we\npropose a novel method for the synthesis of training data for semantic\nsegmentation of document images. We utilize clusters found in intermediate\nfeatures of a StyleGAN generator for the synthesis of RGB and label images at\nthe same time. Our model can be applied to any dataset of scanned documents\nwithout the need for manual annotation of individual images, as each model is\ncustom-fit to the dataset. In our experiments, we show that models trained on\nour synthetic data can reach competitive performance on open benchmark datasets\nfor line segmentation.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Christian Bartz",
      "Hendrik R\u00e4tz",
      "Haojin Yang",
      "Joseph Bethge",
      "Christoph Meinel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06777"
  },
  {
    "id": "arXiv:2107.06779",
    "title": "MMGCN: Multimodal Fusion via Deep Graph Convolution Network for Emotion  Recognition in Conversation",
    "abstract": "Emotion recognition in conversation (ERC) is a crucial component in affective\ndialogue systems, which helps the system understand users' emotions and\ngenerate empathetic responses. However, most works focus on modeling speaker\nand contextual information primarily on the textual modality or simply\nleveraging multimodal information through feature concatenation. In order to\nexplore a more effective way of utilizing both multimodal and long-distance\ncontextual information, we propose a new model based on multimodal fused graph\nconvolutional network, MMGCN, in this work. MMGCN can not only make use of\nmultimodal dependencies effectively, but also leverage speaker information to\nmodel inter-speaker and intra-speaker dependency. We evaluate our proposed\nmodel on two public benchmark datasets, IEMOCAP and MELD, and the results prove\nthe effectiveness of MMGCN, which outperforms other SOTA methods by a\nsignificant margin under the multimodal conversation setting.",
    "descriptor": "",
    "authors": [
      "Jingwen Hu",
      "Yuchen Liu",
      "Jinming Zhao",
      "Qin Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06779"
  },
  {
    "id": "arXiv:2107.06780",
    "title": "Person-MinkUNet: 3D Person Detection with LiDAR Point Cloud",
    "abstract": "In this preliminary work we attempt to apply submanifold sparse convolution\nto the task of 3D person detection. In particular, we present Person-MinkUNet,\na single-stage 3D person detection network based on Minkowski Engine with U-Net\narchitecture. The network achieves a 76.4% average precision (AP) on the JRDB\n3D detection benchmark.",
    "descriptor": "\nComments: accepted as an extended abstract in JRDB-ACT Workshop at CVPR21\n",
    "authors": [
      "Dan Jia",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06780"
  },
  {
    "id": "arXiv:2107.06785",
    "title": "Large-Scale News Classification using BERT Language Model: Spark NLP  Approach",
    "abstract": "The rise of big data analytics on top of NLP increases the computational\nburden for text processing at scale. The problems faced in NLP are very high\ndimensional text, so it takes a high computation resource. The MapReduce allows\nparallelization of large computations and can improve the efficiency of text\nprocessing. This research aims to study the effect of big data processing on\nNLP tasks based on a deep learning approach. We classify a big text of news\ntopics with fine-tuning BERT used pre-trained models. Five pre-trained models\nwith a different number of parameters were used in this study. To measure the\nefficiency of this method, we compared the performance of the BERT with the\npipelines from Spark NLP. The result shows that BERT without Spark NLP gives\nhigher accuracy compared to BERT with Spark NLP. The accuracy average and\ntraining time of all models using BERT is 0.9187 and 35 minutes while using\nBERT with Spark NLP pipeline is 0.8444 and 9 minutes. The bigger model will\ntake more computation resources and need a longer time to complete the tasks.\nHowever, the accuracy of BERT with Spark NLP only decreased by an average of\n5.7%, while the training time was reduced significantly by 62.9% compared to\nBERT without Spark NLP.",
    "descriptor": "",
    "authors": [
      "Kuncahyo Setyo Nugroho",
      "Kuncahyo Setyo Nugroho",
      "Novanto Yudistira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06785"
  },
  {
    "id": "arXiv:2107.06790",
    "title": "Governing Decentralized Complex Queries Through a DAO",
    "abstract": "Recently, a new generation of P2P systems capable of addressing data\nintegrity and authenticity has emerged for the development of new applications\nfor a \"more\" decentralized Internet, i.e., Distributed Ledger Technologies\n(DLT) and Decentralized File Systems (DFS). However, these technologies still\nhave some unanswered issues, mostly related to data lookup and discovery. In\nthis paper, first, we propose a Distributed Hash Table (DHT) system that\nefficiently manages decentralized keyword-based queries executed on data stored\nin DFS. Through a hypercube logical layout, queries are efficiently routed\namong the network, where each node is responsible for a specific keywords set\nand the related contents. Second, we provide a framework for the governance of\nthe above network, based on a Decentralized Autonomous Organization (DAO)\nimplementation. We show how the use of smart contracts enables organizational\ndecision making and rewards for nodes that have actively contributed to the\nDHT. Finally, we provide experimental validation of an implementation of our\nproposal, where the execution of the same protocol for different logical nodes\nof the hypercube allows us to evaluate the efficiency of communication within\nthe network.",
    "descriptor": "\nComments: To appear in the ACM International Conference on Information Technology for Social Good (GoodIT 2021)\n",
    "authors": [
      "Mirko Zichichi",
      "Luca Serena",
      "Stefano Ferretti",
      "Gabriele D'Angelo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06790"
  },
  {
    "id": "arXiv:2107.06796",
    "title": "Indonesia's Fake News Detection using Transformer Network",
    "abstract": "Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.",
    "descriptor": "",
    "authors": [
      "Aisyah Awalina",
      "Jibran Fawaid",
      "Rifky Yunus Krisnabayu",
      "Novanto Yudistira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06796"
  },
  {
    "id": "arXiv:2107.06799",
    "title": "WAccess -- A Web Accessibility Tool based on the latest WCAG 2.2  guidelines",
    "abstract": "The vision of providing access to all web content equally for all users makes\nweb accessibility a fundamental goal of todays internet. Web accessibility is\nthe practice of removing barriers from websites that could hinder functionality\nfor users with various disabilities. Web accessibility is measured against the\naccessibility guidelines such as WCAG, GIGW and so on. WCAG 2.2 is the latest\nset of guidelines for web accessibility that helps in making websites\naccessible. The web accessibility tools available in the World Wide Web\nConsortium (W3C), only conform up to WCAG 2.1 guidelines. No tools exist for\nthe latest set of guidelines. Despite the availability of several tools to\ncheck conformity of websites with WCAG 2.1 guidelines, there is scarcity of\ntools that are both open source and scalable. To support automated\naccessibility evaluation of numerous websites against WCAG 2.2 and 2.1, we\npresent here a tool, WAccess. WAccess highlights violations of 9 guidelines\nfrom WCAG 2.1 and 7 guidelines from WCAG 2.2 of a specific web page on the web\nconsole and suggests the fix for violations while specifying violating code\nsnippet simultaneously. We evaluated WAccess against 2246 government websites\nof India, and observed a total of about 2 million violations.",
    "descriptor": "\nComments: 11 pages, 4 figures, 4 tables\n",
    "authors": [
      "Kowndinya Boyalakuntla",
      "Akhila Sri Manasa Venigalla",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.06799"
  },
  {
    "id": "arXiv:2107.06801",
    "title": "Practical implementation of identification codes",
    "abstract": "Identification is a communication paradigm that promises some exponential\nadvantages over transmission for applications that do not actually require all\nmessages to be reliably transmitted, but where only few selected messages are\nimportant. Notably, the identification capacity theorems prove the\nidentification is capable of exponentially larger rates than what can be\ntransmitted, which we demonstrate with little compromise with respect to\nlatency for certain ranges of parameters. However, there exist more trade-offs\nthat are not captured by these capacity theorems, like, notably, the delay\nintroduced by computations at the encoder and decoder. Here, we implement one\nof the known identification codes using software-defined radios and show that\nunless care is taken, these factors can compromise the advantage given by the\nexponentially large identification rates. Still, there are further advantages\nprovided by identification that require future test in practical\nimplementations.",
    "descriptor": "\nComments: submitted to GLOBECOM21\n",
    "authors": [
      "Roberto Ferrara",
      "Luis Torres-Figueroa",
      "Holger Boche",
      "Christian Deppe",
      "Wafa Labidi",
      "Ullrich M\u00f6nich",
      "Andrei Vlad-Costin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06801"
  },
  {
    "id": "arXiv:2107.06802",
    "title": "BERT Fine-Tuning for Sentiment Analysis on Indonesian Mobile Apps  Reviews",
    "abstract": "User reviews have an essential role in the success of the developed mobile\napps. User reviews in the textual form are unstructured data, creating a very\nhigh complexity when processed for sentiment analysis. Previous approaches that\nhave been used often ignore the context of reviews. In addition, the relatively\nsmall data makes the model overfitting. A new approach, BERT, has been\nintroduced as a transfer learning model with a pre-trained model that has\npreviously been trained to have a better context representation. This study\nexamines the effectiveness of fine-tuning BERT for sentiment analysis using two\ndifferent pre-trained models. Besides the multilingual pre-trained model, we\nuse the pre-trained model that only has been trained in Indonesian. The dataset\nused is Indonesian user reviews of the ten best apps in 2020 in Google Play\nsites. We also perform hyper-parameter tuning to find the optimum trained\nmodel. Two training data labeling approaches were also tested to determine the\neffectiveness of the model, which is score-based and lexicon-based. The\nexperimental results show that pre-trained models trained in Indonesian have\nbetter average accuracy on lexicon-based data. The pre-trained Indonesian model\nhighest accuracy is 84%, with 25 epochs and a training time of 24 minutes.\nThese results are better than all of the machine learning and multilingual\npre-trained models.",
    "descriptor": "",
    "authors": [
      "Kuncahyo Setyo Nugroho",
      "Anantha Yullian Sukmadewa",
      "Haftittah Wuswilahaken DW",
      "Fitra Abdurrachman Bachtiar",
      "Novanto Yudistira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06802"
  },
  {
    "id": "arXiv:2107.06812",
    "title": "Deep Learning based Novel View Synthesis",
    "abstract": "Predicting novel views of a scene from real-world images has always been a\nchallenging task. In this work, we propose a deep convolutional neural network\n(CNN) which learns to predict novel views of a scene from given collection of\nimages. In comparison to prior deep learning based approaches, which can handle\nonly a fixed number of input images to predict novel view, proposed approach\nworks with different numbers of input images. The proposed model explicitly\nperforms feature extraction and matching from a given pair of input images and\nestimates, at each pixel, the probability distribution (pdf) over possible\ndepth levels in the scene. This pdf is then used for estimating the novel view.\nThe model estimates multiple predictions of novel view, one estimate per input\nimage pair, from given image collection. The model also estimates an occlusion\nmask and combines multiple novel view estimates in to a single optimal\nprediction. The finite number of depth levels used in the analysis may cause\noccasional blurriness in the estimated view. We mitigate this issue with simple\nmulti-resolution analysis which improves the quality of the estimates. We\nsubstantiate the performance on different datasets and show competitive\nperformance.",
    "descriptor": "",
    "authors": [
      "Amit More",
      "Subhasis Chaudhuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06812"
  },
  {
    "id": "arXiv:2107.06814",
    "title": "Gain and Pain of a Reliable Delay Model",
    "abstract": "State-of-the-art digital circuit design tools almost exclusively rely on pure\nand inertial delay for timing simulations. While these provide reasonable\nestimations at very low execution time in the average case, their ability to\ncover complex signal traces is limited. Research has provided the dynamic\nInvolution Delay Model (IDM) as a promising alternative, which was shown (i) to\ndepict reality more closely and recently (ii) to be compatible with modern\nsimulation suites. In this paper we complement these encouraging results by\nexperimentally exploring the behavioral coverage for more advanced circuits. In\ndetail we apply the IDM to three simple circuits (a combinatorial loop, an SR\nlatch and an adder), interpret the delivered results and evaluate the overhead\nin realistic settings. Comparisons to digital (inertial delay) and analog\n(SPICE) simulations reveal, that the IDM delivers very fine-grained results,\nwhich match analog simulations very closely. Moreover, severe shortcomings of\ninertial delay become apparent in our simulations, as it fails to depict a\nrange of malicious behaviors. Overall the Involution Delay Model hence\nrepresents a viable upgrade to the available delay models in modern digital\ntiming simulation tools.",
    "descriptor": "\nComments: 9 pages, 11 figures, 2 tables, extension of conference submission\n",
    "authors": [
      "J\u00fcrgen Maier"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.06814"
  },
  {
    "id": "arXiv:2107.06817",
    "title": "Efficient Set of Vectors Search",
    "abstract": "We consider a similarity measure between two sets $A$ and $B$ of vectors,\nthat balances the average and maximum cosine distance between pairs of vectors,\none from set $A$ and one from set $B$. As a motivation for this measure, we\npresent lineage tracking in a database. To practically realize this measure, we\nneed an approximate search algorithm that given a set of vectors $A$ and sets\nof vectors $B_1,...,B_n$, the algorithm quickly locates the set $B_i$ that\nmaximizes the similarity measure. For the case where all sets are singleton\nsets, essentially each is a single vector, there are known efficient\napproximate search algorithms, e.g., approximated versions of tree search\nalgorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and\nproximity graph algorithms. In this work, we present approximate search\nalgorithms for the general case. The underlying idea in these algorithms is\nencoding a set of vectors via a \"long\" single vector.",
    "descriptor": "\nComments: 6 pages, 0 figures\n",
    "authors": [
      "Michael Leybovich",
      "Oded Shmueli"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.06817"
  },
  {
    "id": "arXiv:2107.06820",
    "title": "Composing Conversational Negation",
    "abstract": "Negation in natural language does not follow Boolean logic and is therefore\ninherently difficult to model. In particular, it takes into account the broader\nunderstanding of what is being negated. In previous work, we proposed a\nframework for negation of words that accounts for `worldly context'. In this\npaper, we extend that proposal now accounting for the compositional structure\ninherent in language, within the DisCoCirc framework. We compose the negations\nof single words to capture the negation of sentences. We also describe how to\nmodel the negation of words whose meanings evolve in the text.",
    "descriptor": "\nComments: 14 pages, many figures, In Proceedings ACT 2020\n",
    "authors": [
      "Razin A. Shaikh",
      "Lia Yeh",
      "Benjamin Rodatz",
      "Bob Coecke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2107.06820"
  },
  {
    "id": "arXiv:2107.06825",
    "title": "A Generalized Lottery Ticket Hypothesis",
    "abstract": "We introduce a generalization to the lottery ticket hypothesis in which the\nnotion of \"sparsity\" is relaxed by choosing an arbitrary basis in the space of\nparameters. We present evidence that the original results reported for the\ncanonical basis continue to hold in this broader setting. We describe how\nstructured pruning methods, including pruning units or factorizing\nfully-connected layers into products of low-rank matrices, can be cast as\nparticular instances of this \"generalized\" lottery ticket hypothesis. The\ninvestigations reported here are preliminary and are provided to encourage\nfurther research along this direction.",
    "descriptor": "\nComments: Workshop on Sparsity in Neural Networks: Advancing Understanding and Practice (SNN'21)\n",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Larisa Markeeva",
      "Daniel Keysers",
      "Ilya Tolstikhin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06825"
  },
  {
    "id": "arXiv:2107.06829",
    "title": "FAST-LIO2: Fast Direct LiDAR-inertial Odometry",
    "abstract": "This paper presents FAST-LIO2: a fast, robust, and versatile LiDAR-inertial\nodometry framework. Building on a highly efficient tightly-coupled iterated\nKalman filter, FAST-LIO2 has two key novelties that allow fast, robust, and\naccurate LiDAR navigation (and mapping). The first one is directly registering\nraw points to the map (and subsequently update the map, i.e., mapping) without\nextracting features. This enables the exploitation of subtle features in the\nenvironment and hence increases the accuracy. The elimination of a\nhand-engineered feature extraction module also makes it naturally adaptable to\nemerging LiDARs of different scanning patterns; The second main novelty is\nmaintaining a map by an incremental k-d tree data structure, ikd-Tree, that\nenables incremental updates (i.e., point insertion, delete) and dynamic\nre-balancing. Compared with existing dynamic data structures (octree, R*-tree,\nnanoflann k-d tree), ikd-Tree achieves superior overall performance while\nnaturally supports downsampling on the tree. We conduct an exhaustive benchmark\ncomparison in 19 sequences from a variety of open LiDAR datasets. FAST-LIO2\nachieves consistently higher accuracy at a much lower computation load than\nother state-of-the-art LiDAR-inertial navigation systems. Various real-world\nexperiments on solid-state LiDARs with small FoV are also conducted. Overall,\nFAST-LIO2 is computationally-efficient (e.g., up to 100 Hz odometry and mapping\nin large outdoor environments), robust (e.g., reliable pose estimation in\ncluttered indoor environments with rotation up to 1000 deg/s), versatile (i.e.,\napplicable to both multi-line spinning and solid-state LiDARs, UAV and handheld\nplatforms, and Intel and ARM-based processors), while still achieving higher\naccuracy than existing methods. Our implementation of the system FAST-LIO2, and\nthe data structure ikd-Tree are both open-sourced on Github.",
    "descriptor": "",
    "authors": [
      "Wei Xu",
      "Yixi Cai",
      "Dongjiao He",
      "Jiarong Lin",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06829"
  },
  {
    "id": "arXiv:2107.06831",
    "title": "High-Speed and High-Quality Text-to-Lip Generation",
    "abstract": "As a key component of talking face generation, lip movements generation\ndetermines the naturalness and coherence of the generated talking face video.\nPrior literature mainly focuses on speech-to-lip generation while there is a\npaucity in text-to-lip (T2L) generation. T2L is a challenging task and existing\nend-to-end works depend on the attention mechanism and autoregressive (AR)\ndecoding manner. However, the AR decoding manner generates current lip frame\nconditioned on frames generated previously, which inherently hinders the\ninference speed, and also has a detrimental effect on the quality of generated\nlip frames due to error propagation. This encourages the research of parallel\nT2L generation. In this work, we propose a novel parallel decoding model for\nhigh-speed and high-quality text-to-lip generation (HH-T2L). Specifically, we\npredict the duration of the encoded linguistic features and model the target\nlip frames conditioned on the encoded linguistic features with their duration\nin a non-autoregressive manner. Furthermore, we incorporate the structural\nsimilarity index loss and adversarial learning to improve perceptual quality of\ngenerated lip frames and alleviate the blurry prediction problem. Extensive\nexperiments conducted on GRID and TCD-TIMIT datasets show that 1) HH-T2L\ngenerates lip movements with competitive quality compared with the\nstate-of-the-art AR T2L model DualLip and exceeds the baseline AR model\nTransformerT2L by a notable margin benefiting from the mitigation of the error\npropagation problem; and 2) exhibits distinct superiority in inference speed\n(an average speedup of 19$\\times$ than DualLip on TCD-TIMIT).",
    "descriptor": "\nComments: Author draft\n",
    "authors": [
      "Jinglin Liu",
      "Zhiying Zhu",
      "Yi Ren",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06831"
  },
  {
    "id": "arXiv:2107.06833",
    "title": "A Review-based Taxonomy for Secure Health Care Monitoring: Wireless  Smart Cameras",
    "abstract": "Health records data security is one of the main challenges in e-health\nsystems. Authentication is one of the essential security services to support\nthe stored data confidentiality, integrity, and availability. This research\nfocuses on the secure storage of patient and medical records in the healthcare\nsector where data security and unauthorized access is an ongoing issue. A\npotential solution comes from biometrics, although their use may be\ntime-consuming and can slow down data retrieval. This research aims to overcome\nthese challenges and enhance data access control in the healthcare sector\nthrough the addition of biometrics in the form of fingerprints. The proposed\nmodel for application in the healthcare sector consists of Collection, Network\ncommunication, and Authentication (CNA) using biometrics, which replaces an\nexisting password-based access control method. A sensor then collects data and\nby using a network (wireless or Zig-bee), a connection is established, after\nconnectivity analytics and data management work which processes and aggregate\nthe data. Subsequently, access is granted to authenticated users of the\napplication. This IoT-based biometric authentication system facilitates\neffective recognition and ensures confidentiality, integrity, and reliability\nof patients, records and other sensitive data. The proposed solution provides\nreliable access to healthcare data and enables secure access through the\nprocess of user and device authentication. The proposed model has been\ndeveloped for access control to data through the authentication of users in\nhealthcare to reduce data manipulation or theft.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Ravi Teja Batchu",
      "Abeer Alsadoon",
      "P.W.C. Prasad",
      "Rasha S. Ali",
      "Tarik A. Rashid",
      "Ghossoon Alsadoon",
      "Oday D. Jerew"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06833"
  },
  {
    "id": "arXiv:2107.06835",
    "title": "A Review on Edge Analytics: Issues, Challenges, Opportunities, Promises,  Future Directions, and Applications",
    "abstract": "Edge technology aims to bring Cloud resources (specifically, the compute,\nstorage, and network) to the closed proximity of the Edge devices, i.e., smart\ndevices where the data are produced and consumed. Embedding computing and\napplication in Edge devices lead to emerging of two new concepts in Edge\ntechnology, namely, Edge computing and Edge analytics. Edge analytics uses some\ntechniques or algorithms to analyze the data generated by the Edge devices.\nWith the emerging of Edge analytics, the Edge devices have become a complete\nset. Currently, Edge analytics is unable to provide full support for the\nexecution of the analytic techniques. The Edge devices cannot execute advanced\nand sophisticated analytic algorithms following various constraints such as\nlimited power supply, small memory size, limited resources, etc. This article\naims to provide a detailed discussion on Edge analytics. A clear explanation to\ndistinguish between the three concepts of Edge technology, namely, Edge\ndevices, Edge computing, and Edge analytics, along with their issues.\nFurthermore, the article discusses the implementation of Edge analytics to\nsolve many problems in various areas such as retail, agriculture, industry, and\nhealthcare. In addition, the research papers of the state-of-the-art edge\nanalytics are rigorously reviewed in this article to explore the existing\nissues, emerging challenges, research opportunities and their directions, and\napplications.",
    "descriptor": "\nComments: Submitted to Elsevier for possible publication\n",
    "authors": [
      "Sabuzima Nayak",
      "Ripon Patgiri",
      "Lilapati Waikhom",
      "Arif Ahmed"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.06835"
  },
  {
    "id": "arXiv:2107.06836",
    "title": "Consistent RDMA-Friendly Hashing on Remote Persistent Memory",
    "abstract": "Coalescing RDMA and Persistent Memory (PM) delivers high end-to-end\nperformance for networked storage systems, which requires rethinking the design\nof efficient hash structures. In general, existing hashing schemes separately\noptimize RDMA and PM, thus partially addressing the problems of RDMA Access\nAmplification and High-Overhead PM Consistency. In order to address these\nproblems, we propose a continuity hashing, which is a \"one-stone-two-birds\"\ndesign to optimize both RDMA and PM. The continuity hashing leverages a\nfine-grained contiguous shared region, called SBuckets, to provide standby\npositions for the neighbouring two buckets in case of hash collisions. In the\ncontinuity hashing, remote read only needs a single RDMA read to directly fetch\nthe home bucket and the neighbouring SBuckets, which contain all the positions\nof maintaining a key-value item, thus alleviating RDMA access amplification.\nContinuity hashing further leverages indicators that can be atomically modified\nto support log-free PM consistency for all the write operations. Evaluation\nresults demonstrate that compared with state-of-the-art schemes, continuity\nhashing achieves high throughput (i.e., 1.45X -- 2.43X improvement), low\nlatency (about 1.7X speedup) and the smallest number of PM writes with various\nworkloads, while has acceptable load factors of about 70%.",
    "descriptor": "",
    "authors": [
      "Xinxin Liu",
      "Yu Hua",
      "Rong Bai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06836"
  },
  {
    "id": "arXiv:2107.06840",
    "title": "Mixing Human Demonstrations with Self-Exploration in Experience Replay  for Deep Reinforcement Learning",
    "abstract": "We investigate the effect of using human demonstration data in the replay\nbuffer for Deep Reinforcement Learning. We use a policy gradient method with a\nmodified experience replay buffer where a human demonstration experience is\nsampled with a given probability. We analyze different ratios of using\ndemonstration data in a task where an agent attempts to reach a goal while\navoiding obstacles. Our results suggest that while the agents trained by pure\nself-exploration and pure demonstration had similar success rates, the pure\ndemonstration model converged faster to solutions with less number of steps.",
    "descriptor": "\nComments: 2 pages. Submitted to ICDL 2021 Workshop on Human aligned Reinforcement Learning for Autonomous Agents and Robots\n",
    "authors": [
      "Dylan Klein",
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06840"
  },
  {
    "id": "arXiv:2107.06846",
    "title": "Extreme Precipitation Seasonal Forecast Using a Transformer Neural  Network",
    "abstract": "An impact of climate change is the increase in frequency and intensity of\nextreme precipitation events. However, confidently predicting the likelihood of\nextreme precipitation at seasonal scales remains an outstanding challenge.\nHere, we present an approach to forecasting the quantiles of the maximum daily\nprecipitation in each week up to six months ahead using the temporal fusion\ntransformer (TFT) model. Through experiments in two regions, we compare TFT\npredictions with those of two baselines: climatology and a calibrated ECMWF\nSEAS5 ensemble forecast (S5). Our results show that, in terms of quantile risk\nat six month lead time, the TFT predictions significantly outperform those from\nS5 and show an overall small improvement compared to climatology. The TFT also\nresponds positively to departures from normal that climatology cannot.",
    "descriptor": "",
    "authors": [
      "Daniel Salles Civitarese",
      "Daniela Szwarcman",
      "Bianca Zadrozny",
      "Campbell Watson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06846"
  },
  {
    "id": "arXiv:2107.06847",
    "title": "Faces in the Wild: Efficient Gender Recognition in Surveillance  Conditions",
    "abstract": "Soft biometrics inference in surveillance scenarios is a topic of interest\nfor various applications, particularly in security-related areas. However, soft\nbiometric analysis is not extensively reported in wild conditions. In\nparticular, previous works on gender recognition report their results in face\ndatasets, with relatively good image quality and frontal poses. Given the\nuncertainty of the availability of the facial region in wild conditions, we\nconsider that these methods are not adequate for surveillance settings. To\novercome these limitations, we: 1) present frontal and wild face versions of\nthree well-known surveillance datasets; and 2) propose a model that effectively\nand dynamically combines facial and body information, which makes it suitable\nfor gender recognition in wild conditions. The frontal and wild face datasets\nderive from widely used Pedestrian Attribute Recognition (PAR) sets (PETA,\nPA-100K, and RAP), using a pose-based approach to filter the frontal samples\nand facial regions. This approach retrieves the facial region of images with\nvarying image/subject conditions, where the state-of-the-art face detectors\noften fail. Our model combines facial and body information through a learnable\nfusion matrix and a channel-attention sub-network, focusing on the most\ninfluential body parts according to the specific image/subject features. We\ncompare it with five PAR methods, consistently obtaining state-of-the-art\nresults on gender recognition, and reducing the prediction errors by up to 24%\nin frontal samples. The announced PAR datasets versions and model serve as the\nbasis for wild soft biometrics classification and are available in\nhttps://github.com/Tiago-Roxo.",
    "descriptor": "",
    "authors": [
      "Tiago Roxo",
      "Hugo Proen\u00e7a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06847"
  },
  {
    "id": "arXiv:2107.06849",
    "title": "Digital_Passport_and_Visa_Asset_Management_Using_Private_and_Permissioned_Blockchain",
    "abstract": "Blockchain is currently one of the fastest-growing technologies in the field\nof Computer Science. It has found a prevalent use in financial applications\nlike cryptocurrency, for example, Bitcoin and Ethereum. They have been able to\nbring an unforeseen disruption in the field of finance. However, permissionless\nBlockchains like these have some downsides, namely the computation cost of the\nProof of Work algorithm, maximum allowed size for a block, decrease in\nintelligibility with the increase of the number of blocks in the chain,\ndomination of nodes with higher computing power as miners and validators. These\nfactors have restricted the adoption of permissionless blockchain technology\noutside the field of finance, such as in medical or legal fields. This paper\nproposes a solution to these problems using a permissioned blockchain. It does\nnot require a computationally expensive consensus mechanism as permissioned\nchains call for trust between participating organizations which is achieved via\nexclusive invitations. We have utilized a third-party orderer to maintain the\ntrust between organizations.",
    "descriptor": "",
    "authors": [
      "Keenu Chandra",
      "Maroof Mushtaq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06849"
  },
  {
    "id": "arXiv:2107.06853",
    "title": "Localization Based Sequential Grouping for Continuous Speech Separation",
    "abstract": "This study investigates robust speaker localization for con-tinuous speech\nseparation and speaker diarization, where we use speaker directions to group\nnon-contiguous segments of the same speaker. Assuming that speakers do not move\nand are located in different directions, the direction of arrival (DOA)\ninformation provides an informative cue for accurate sequential grouping and\nspeaker diarization. Our system is block-online in the following sense. Given a\nblock of frames with at most two speakers, we apply a two-speaker separa-tion\nmodel to separate (and enhance) the speakers, estimate the DOA of each\nseparated speaker, and group the separation results across blocks based on the\nDOA estimates. Speaker diarization and speaker-attributed speech recognition\nresults on the LibriCSS corpus demonstrate the effectiveness of the proposed\nalgorithm.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Zhong-Qiu Wang",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06853"
  },
  {
    "id": "arXiv:2107.06857",
    "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting  Pot",
    "abstract": "Existing evaluation suites for multi-agent reinforcement learning (MARL) do\nnot assess generalization to novel situations as their primary objective\n(unlike supervised-learning benchmarks). Our contribution, Melting Pot, is a\nMARL evaluation suite that fills this gap, and uses reinforcement learning to\nreduce the human labor required to create novel test scenarios. This works\nbecause one agent's behavior constitutes (part of) another agent's environment.\nTo demonstrate scalability, we have created over 80 unique test scenarios\ncovering a broad range of research topics such as social dilemmas, reciprocity,\nresource sharing, and task partitioning. We apply these test scenarios to\nstandard MARL training algorithms, and demonstrate how Melting Pot reveals\nweaknesses not apparent from training performance alone.",
    "descriptor": "\nComments: Accepted to ICML 2021 and presented as a long talk; 33 pages; 9 figures\n",
    "authors": [
      "Joel Z. Leibo",
      "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Alexander Sasha Vezhnevets",
      "John P. Agapiou",
      "Peter Sunehag",
      "Raphael Koster",
      "Jayd Matyas",
      "Charles Beattie",
      "Igor Mordatch",
      "Thore Graepel"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06857"
  },
  {
    "id": "arXiv:2107.06859",
    "title": "A novel approach for modelling and classifying sit-to-stand kinematics  using inertial sensors",
    "abstract": "Sit-to-stand transitions are an important part of activities of daily living\nand play a key role in functional mobility in humans. The sit-to-stand movement\nis often affected in older adults due to frailty and in patients with motor\nimpairments such as Parkinson's disease leading to falls. Studying kinematics\nof sit-to-stand transitions can provide insight in assessment, monitoring and\ndeveloping rehabilitation strategies for the affected populations. We propose a\nthree-segment body model for estimating sit-to-stand kinematics using only two\nwearable inertial sensors, placed on the shank and back. Reducing the number of\nsensors to two instead of one per body segment facilitates monitoring and\nclassifying movements over extended periods, making it more comfortable to wear\nwhile reducing the power requirements of sensors. We applied this model on 10\nyounger healthy adults (YH), 12 older healthy adults (OH) and 12 people with\nParkinson's disease (PwP). We have achieved this by incorporating unique\nsit-to-stand classification technique using unsupervised learning in the model\nbased reconstruction of angular kinematics using extended Kalman filter. Our\nproposed model showed that it was possible to successfully estimate thigh\nkinematics despite not measuring the thigh motion with inertial sensor. We\nclassified sit-to-stand transitions, sitting and standing states with the\naccuracies of 98.67%, 94.20% and 91.41% for YH, OH and PwP respectively. We\nhave proposed a novel integrated approach of modelling and classification for\nestimating the body kinematics during sit-to-stand motion and successfully\napplied it on YH, OH and PwP groups.",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Maitreyee Wairagkar",
      "Emma Villeneuve",
      "Rachel King",
      "Balazs Janko",
      "Malcolm Burnett",
      "Ann Ashburn",
      "Veena Agarwal",
      "R. Simon Sherratt",
      "William Holderbaum",
      "William Harwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06859"
  },
  {
    "id": "arXiv:2107.06861",
    "title": "Backpropagated Neighborhood Aggregation for Accurate Training of Spiking  Neural Networks",
    "abstract": "While backpropagation (BP) has been applied to spiking neural networks (SNNs)\nachieving encouraging results, a key challenge involved is to backpropagate a\ncontinuous-valued loss over layers of spiking neurons exhibiting discontinuous\nall-or-none firing activities. Existing methods deal with this difficulty by\nintroducing compromises that come with their own limitations, leading to\npotential performance degradation. We propose a novel BP-like method, called\nneighborhood aggregation (NA), which computes accurate error gradients guiding\nweight updates that may lead to discontinuous modifications of firing\nactivities. NA achieves this goal by aggregating finite differences of the loss\nover multiple perturbed membrane potential waveforms in the neighborhood of the\npresent membrane potential of each neuron while utilizing a new membrane\npotential distance function. Our experiments show that the proposed NA\nalgorithm delivers the state-of-the-art performance for SNN training on several\ndatasets.",
    "descriptor": "",
    "authors": [
      "Yukun Yang",
      "Wenrui Zhang",
      "Peng Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06861"
  },
  {
    "id": "arXiv:2107.06862",
    "title": "Differentiable Programming of Reaction-Diffusion Patterns",
    "abstract": "Reaction-Diffusion (RD) systems provide a computational framework that\ngoverns many pattern formation processes in nature. Current RD system design\npractices boil down to trial-and-error parameter search. We propose a\ndifferentiable optimization method for learning the RD system parameters to\nperform example-based texture synthesis on a 2D plane. We do this by\nrepresenting the RD system as a variant of Neural Cellular Automata and using\ntask-specific differentiable loss functions. RD systems generated by our method\nexhibit robust, non-trivial 'life-like' behavior.",
    "descriptor": "\nComments: ALIFE 2021\n",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Eyvind Niklasson"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06862"
  },
  {
    "id": "arXiv:2107.06865",
    "title": "Exploiting Spiking Dynamics with Spatial-temporal Feature Normalization  in Graph Learning",
    "abstract": "Biological spiking neurons with intrinsic dynamics underlie the powerful\nrepresentation and learning capabilities of the brain for processing multimodal\ninformation in complex environments. Despite recent tremendous progress in\nspiking neural networks (SNNs) for handling Euclidean-space tasks, it still\nremains challenging to exploit SNNs in processing non-Euclidean-space data\nrepresented by graph data, mainly due to the lack of effective modeling\nframework and useful training techniques. Here we present a general spike-based\nmodeling framework that enables the direct training of SNNs for graph learning.\nThrough spatial-temporal unfolding for spiking data flows of node features, we\nincorporate graph convolution filters into spiking dynamics and formalize a\nsynergistic learning paradigm. Considering the unique features of spike\nrepresentation and spiking dynamics, we propose a spatial-temporal feature\nnormalization (STFN) technique suitable for SNN to accelerate convergence. We\ninstantiate our methods into two spiking graph models, including graph\nconvolution SNNs and graph attention SNNs, and validate their performance on\nthree node-classification benchmarks, including Cora, Citeseer, and Pubmed. Our\nmodel can achieve comparable performance with the state-of-the-art graph neural\nnetwork (GNN) models with much lower computation costs, demonstrating great\nbenefits for the execution on neuromorphic hardware and prompting neuromorphic\napplications in graphical scenarios.",
    "descriptor": "\nComments: Accepted by IJCAI-21\n",
    "authors": [
      "Mingkun Xu",
      "Yujie Wu",
      "Lei Deng",
      "Faqiang Liu",
      "Guoqi Li",
      "Jing Pei"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06865"
  },
  {
    "id": "arXiv:2107.06866",
    "title": "Asynchronous games on Petri nets and ATL",
    "abstract": "We define a game on distributed Petri nets, where several players interact\nwith each other, and with an environment. The players, or users, have perfect\nknowledge of the current state, and pursue a common goal. Such goal is\nexpressed by Alternating-time Temporal Logic (ATL). The users have a winning\nstrategy if they can cooperate to reach their goal, no matter how the\nenvironment behaves. We show that such a game can be translated into a game on\nconcurrent game structures (introduced in order to give a semantics to ATL). We\ncompare our game with the game on concurrent game structures and discuss the\ndifferences between the two approaches. Finally, we show that, when we consider\nmemoryless strategies and a fragment of ATL, we can construct a concurrent game\nstructure from the Petri net, such that an ATL formula is verified on the net\nif, and only if, it is verified on the game structure.",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Federica Adobbati",
      "Luca Bernardinello",
      "Lucia Pomello"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06866"
  },
  {
    "id": "arXiv:2107.06869",
    "title": "Core-set Sampling for Efficient Neural Architecture Search",
    "abstract": "Neural architecture search (NAS), an important branch of automatic machine\nlearning, has become an effective approach to automate the design of deep\nlearning models. However, the major issue in NAS is how to reduce the large\nsearch time imposed by the heavy computational burden. While most recent\napproaches focus on pruning redundant sets or developing new search\nmethodologies, this paper attempts to formulate the problem based on the data\ncuration manner. Our key strategy is to search the architecture using\nsummarized data distribution, i.e., core-set. Typically, many NAS algorithms\nseparate searching and training stages, and the proposed core-set methodology\nis only used in search stage, thus their performance degradation can be\nminimized. In our experiments, we were able to save overall computational time\nfrom 30.8 hours to 3.5 hours, 8.8x reduction, on a single RTX 3090 GPU without\nsacrificing accuracy.",
    "descriptor": "\nComments: 8 pages, 2 figures, spotlight presented at the ICML 2021 Workshop on Subset Selection in ML\n",
    "authors": [
      "Jae-hun Shim",
      "Kyeongbo Kong",
      "Suk-Ju Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06869"
  },
  {
    "id": "arXiv:2107.06870",
    "title": "Reinforced Hybrid Genetic Algorithm for the Traveling Salesman Problem",
    "abstract": "We propose a powerful Reinforced Hybrid Genetic Algorithm (RHGA) for the\nfamous NP-hard Traveling Salesman Problem (TSP). RHGA combines reinforcement\nlearning technique with the well-known Edge Assembly Crossover genetic\nalgorithm (EAX-GA) and the Lin-Kernighan-Helsgaun (LKH) local search heuristic.\nWith the help of the proposed hybrid mechanism, the genetic evolution of EAX-GA\nand the local search of LKH can boost each other's performance. And the\nreinforcement learning technique based on Q-learning further promotes the\nhybrid genetic algorithm. Experimental results on 138 well-known and widely\nused TSP benchmarks, with the number of cities ranging from 1,000 to 85,900,\ndemonstrate the excellent performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jiongzhi Zheng",
      "Menglei Chen",
      "Jialun Zhong",
      "Kun He"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06870"
  },
  {
    "id": "arXiv:2107.06871",
    "title": "Uncertainty Modeling of Emerging Device-based Computing-in-Memory Neural  Accelerators with Application to Neural Architecture Search",
    "abstract": "Emerging device-based Computing-in-memory (CiM) has been proved to be a\npromising candidate for high-energy efficiency deep neural network (DNN)\ncomputations. However, most emerging devices suffer uncertainty issues,\nresulting in a difference between actual data stored and the weight value it is\ndesigned to be. This leads to an accuracy drop from trained models to actually\ndeployed platforms. In this work, we offer a thorough analysis of the effect of\nsuch uncertainties-induced changes in DNN models. To reduce the impact of\ndevice uncertainties, we propose UAE, an uncertainty-aware Neural Architecture\nSearch scheme to identify a DNN model that is both accurate and robust against\ndevice uncertainties.",
    "descriptor": "",
    "authors": [
      "Zheyu Yan",
      "Da-Cheng Juan",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06871"
  },
  {
    "id": "arXiv:2107.06872",
    "title": "Generalisation in Neural Networks Does not Require Feature Overlap",
    "abstract": "That shared features between train and test data are required for\ngeneralisation in artificial neural networks has been a common assumption of\nboth proponents and critics of these models. Here, we show that convolutional\narchitectures avoid this limitation by applying them to two well known\nchallenges, based on learning the identity function and learning rules\ngoverning sequences of words. In each case, successful performance on the test\nset requires generalising to features that were not present in the training\ndata, which is typically not feasible for standard connectionist models.\nHowever, our experiments demonstrate that neural networks can succeed on such\nproblems when they incorporate the weight sharing employed by convolutional\narchitectures. In the image processing domain, such architectures are intended\nto reflect the symmetry under spatial translations of the natural world that\nsuch images depict. We discuss the role of symmetry in the two tasks and its\nconnection to generalisation.",
    "descriptor": "\nComments: 19 pages, 3 Figures. Submitted to Cognition\n",
    "authors": [
      "Jeff Mitchell",
      "Jeffrey S. Bowers"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06872"
  },
  {
    "id": "arXiv:2107.06875",
    "title": "DULA: A Differentiable Ergonomics Model for Postural Optimization in  Physical HRI",
    "abstract": "Ergonomics and human comfort are essential concerns in physical human-robot\ninteraction applications. Defining an accurate and easy-to-use ergonomic\nassessment model stands as an important step in providing feedback for postural\ncorrection to improve operator health and comfort. In order to enable efficient\ncomputation, previously proposed automated ergonomic assessment and correction\ntools make approximations or simplifications to gold-standard assessment tools\nused by ergonomists in practice. In order to retain assessment quality, while\nimproving computational considerations, we introduce DULA, a differentiable and\ncontinuous ergonomics model learned to replicate the popular and scientifically\nvalidated RULA assessment. We show that DULA provides assessment comparable to\nRULA while providing computational benefits. We highlight DULA's strength in a\ndemonstration of gradient-based postural optimization for a simulated\nteleoperation task.",
    "descriptor": "",
    "authors": [
      "Amir Yazdani",
      "Roya Sabbagh Novin",
      "Andrew Merryweather",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06875"
  },
  {
    "id": "arXiv:2107.06876",
    "title": "Scalable Optimal Transport in High Dimensions for Graph Distances,  Embedding Alignment, and More",
    "abstract": "The current best practice for computing optimal transport (OT) is via entropy\nregularization and Sinkhorn iterations. This algorithm runs in quadratic time\nas it requires the full pairwise cost matrix, which is prohibitively expensive\nfor large sets of objects. In this work we propose two effective log-linear\ntime approximations of the cost matrix: First, a sparse approximation based on\nlocality-sensitive hashing (LSH) and, second, a Nystr\\\"om approximation with\nLSH-based sparse corrections, which we call locally corrected Nystr\\\"om (LCN).\nThese approximations enable general log-linear time algorithms for\nentropy-regularized OT that perform well even for the complex, high-dimensional\nspaces common in deep learning. We analyse these approximations theoretically\nand evaluate them experimentally both directly and end-to-end as a component\nfor real-world applications. Using our approximations for unsupervised word\nembedding alignment enables us to speed up a state-of-the-art method by a\nfactor of 3 while also improving the accuracy by 3.1 percentage points without\nany additional model changes. For graph distance regression we propose the\ngraph transport network (GTN), which combines graph neural networks (GNNs) with\nenhanced Sinkhorn. GTN outcompetes previous models by 48% and still scales\nlog-linearly in the number of nodes.",
    "descriptor": "\nComments: Published as a conference paper at ICML 2021\n",
    "authors": [
      "Johannes Klicpera",
      "Marten Lienen",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06876"
  },
  {
    "id": "arXiv:2107.06877",
    "title": "Federated Self-Training for Semi-Supervised Audio Recognition",
    "abstract": "Federated Learning is a distributed machine learning paradigm dealing with\ndecentralized and personal datasets. Since data reside on devices like\nsmartphones and virtual assistants, labeling is entrusted to the clients, or\nlabels are extracted in an automated way. Specifically, in the case of audio\ndata, acquiring semantic annotations can be prohibitively expensive and\ntime-consuming. As a result, an abundance of audio data remains unlabeled and\nunexploited on users' devices. Most existing federated learning approaches\nfocus on supervised learning without harnessing the unlabeled data. In this\nwork, we study the problem of semi-supervised learning of audio models via\nself-training in conjunction with federated learning. We propose FedSTAR to\nexploit large-scale on-device unlabeled data to improve the generalization of\naudio recognition models. We further demonstrate that self-supervised\npre-trained models can accelerate the training of on-device models,\nsignificantly improving convergence to within fewer training rounds. We conduct\nexperiments on diverse public audio classification datasets and investigate the\nperformance of our models under varying percentages of labeled and unlabeled\ndata. Notably, we show that with as little as 3% labeled data available,\nFedSTAR on average can improve the recognition rate by 13.28% compared to the\nfully supervised federated model.",
    "descriptor": "",
    "authors": [
      "Vasileios Tsouvalas",
      "Aaqib Saeed",
      "Tanir Ozcelebi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06877"
  },
  {
    "id": "arXiv:2107.06881",
    "title": "Evolution of Non-Terrestrial Networks From 5G to 6G: A Survey",
    "abstract": "Non-terrestrial networks (NTNs) traditionally had certain limited\napplications. However, the recent technological advancements opened up myriad\napplications of NTNs for 5G and beyond networks, especially when integrated\ninto terrestrial networks (TNs). This article comprehensively surveys the\nevolution of NTNs highlighting its relevance to 5G networks and essentially,\nhow it will play a pivotal role in the development of 6G and beyond wireless\nnetworks. The survey discusses important features of NTNs integration into TNs\nby delving into the new range of services and use cases, various architectures,\nand new approaches being adopted to develop a new wireless ecosystem. Our\nsurvey includes the major progresses and outcomes from academic research as\nwell as industrial efforts. We first start with introducing the relevant 5G use\ncases and general integration challenges such as handover and deployment\ndifficulties. Then, we review the NTNs operations in mmWave and their potential\nfor the internet of things (IoT). Further, we discuss the significance of\nmobile edge computing (MEC) and machine learning (ML) in NTNs by reviewing the\nrelevant research works. Furthermore, we also discuss the corresponding higher\nlayer advancements and relevant field trials/prototyping at both academic and\nindustrial levels. Finally, we identify and review 6G and beyond application\nscenarios, novel architectures, technological enablers, and higher layer\naspects pertinent to NTNs integration.",
    "descriptor": "",
    "authors": [
      "M. Mahdi Azari",
      "Sourabh Solanki",
      "Symeon Chatzinotas",
      "Oltjon Kodheli",
      "Hazem Sallouha",
      "Achiel Colpaert",
      "Jesus Fabian Mendoza Montoya",
      "Sofie Pollin",
      "Alireza Haqiqatnejad",
      "Arsham Mostaani",
      "Eva Lagunas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06881"
  },
  {
    "id": "arXiv:2107.06882",
    "title": "Conservative Objective Models for Effective Offline Model-Based  Optimization",
    "abstract": "Computational design problems arise in a number of settings, from synthetic\nbiology to computer architectures. In this paper, we aim to solve data-driven\nmodel-based optimization (MBO) problems, where the goal is to find a design\ninput that maximizes an unknown objective function provided access to only a\nstatic dataset of prior experiments. Such data-driven optimization procedures\nare the only practical methods in many real-world domains where active data\ncollection is expensive (e.g., when optimizing over proteins) or dangerous\n(e.g., when optimizing over aircraft designs). Typical methods for MBO that\noptimize the design against a learned model suffer from distributional shift:\nit is easy to find a design that \"fools\" the model into predicting a high\nvalue. To overcome this, we propose conservative objective models (COMs), a\nmethod that learns a model of the objective function that lower bounds the\nactual value of the ground-truth objective on out-of-distribution inputs, and\nuses it for optimization. Structurally, COMs resemble adversarial training\nmethods used to overcome adversarial examples. COMs are simple to implement and\noutperform a number of existing methods on a wide range of MBO problems,\nincluding optimizing protein sequences, robot morphologies, neural network\nweights, and superconducting materials.",
    "descriptor": "\nComments: ICML 2021. First two authors contributed equally. Code at: this https URL\n",
    "authors": [
      "Brandon Trabucco",
      "Aviral Kumar",
      "Xinyang Geng",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06882"
  },
  {
    "id": "arXiv:2107.06886",
    "title": "\"How to best say it?\" : Translating Directives in Machine Language into  Natural Language in the Blocks World",
    "abstract": "We propose a method to generate optimal natural language for block placement\ndirectives generated by a machine's planner during human-agent interactions in\nthe blocks world. A non user-friendly machine directive, e.g., move(ObjId,\ntoPos), is transformed into visually and contextually grounded referring\nexpressions that are much easier for the user to comprehend. We describe an\nalgorithm that progressively and generatively transforms the machine's\ndirective in ECI (Elementary Composable Ideas)-space, generating many\nalternative versions of the directive. We then define a cost function to\nevaluate the ease of comprehension of these alternatives and select the best\noption. The parameters for this cost function were derived empirically from a\nuser study that measured utterance-to-action timings.",
    "descriptor": "",
    "authors": [
      "Sujeong Kim",
      "Amir Tamrakar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06886"
  },
  {
    "id": "arXiv:2107.06281",
    "title": "Non-isomorphic Inter-modality Graph Alignment and Synthesis for Holistic  Brain Mapping",
    "abstract": "Brain graph synthesis marked a new era for predicting a target brain graph\nfrom a source one without incurring the high acquisition cost and processing\ntime of neuroimaging data. However, existing multi-modal graph synthesis\nframeworks have several limitations. First, they mainly focus on generating\ngraphs from the same domain (intra-modality), overlooking the rich multimodal\nrepresentations of brain connectivity (inter-modality). Second, they can only\nhandle isomorphic graph generation tasks, limiting their generalizability to\nsynthesizing target graphs with a different node size and topological structure\nfrom those of the source one. More importantly, both target and source domains\nmight have different distributions, which causes a domain fracture between them\n(i.e., distribution misalignment). To address such challenges, we propose an\ninter-modality aligner of non-isomorphic graphs (IMANGraphNet) framework to\ninfer a target graph modality based on a given modality. Our three core\ncontributions lie in (i) predicting a target graph (e.g., functional) from a\nsource graph (e.g., morphological) based on a novel graph generative\nadversarial network (gGAN); (ii) using non-isomorphic graphs for both source\nand target domains with a different number of nodes, edges and structure; and\n(iii) enforcing the predicted target distribution to match that of the ground\ntruth graphs using a graph autoencoder to relax the designed loss oprimization.\nTo handle the unstable behavior of gGAN, we design a new Ground\nTruth-Preserving (GT-P) loss function to guide the generator in learning the\ntopological structure of ground truth brain graphs. Our comprehensive\nexperiments on predicting functional from morphological graphs demonstrate the\noutperformance of IMANGraphNet in comparison with its variants. This can be\nfurther leveraged for integrative and holistic brain mapping in health and\ndisease.",
    "descriptor": "",
    "authors": [
      "Islem Mhiri",
      "Ahmed Nebli",
      "Mohamed Ali Mahjoub",
      "Islem Rekik"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06281"
  },
  {
    "id": "arXiv:2107.06283",
    "title": "Analog Computing for Molecular Dynamics",
    "abstract": "Modern analog computers are ideally suited to solving large systems of\nordinary differential equations at high speed with low energy consumtion and\nlimited accuracy. In this article, we survey N-body physics, applied to a\nsimple water model inspired by force fields which are popular in molecular\ndynamics. We demonstrate a setup which simulate a single water molecule in\ntime. To the best of our knowledge such a simulation has never been done on\nanalog computers before. Important implementation aspects of the model, such as\nscaling, data range and circuit design, are highlighted. We also analyze the\nperformance and compare the solution with a numerical approach.",
    "descriptor": "\nComments: 9 pages, 9 figures, submitted to Emerging Topics in Computing, IEEE Trans\n",
    "authors": [
      "Sven K\u00f6ppel",
      "Alexandra Krause",
      "Bernd Ulmann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.06283"
  },
  {
    "id": "arXiv:2107.06334",
    "title": "A Diffuse Interface Model for Cell Blebbing Including Membrane-Cortex  Coupling with Linker Dynamics",
    "abstract": "The aim of this paper is to develop suitable models for the phenomenon of\ncell blebbing, which allow for computational predictions of mechanical effects\nincluding the crucial interaction of the cell membrane and the actin cortex.\nFor this sake we resort to a two phase-field model that uses diffuse\ndescriptions of both the membrane and the cortex, which in particular allows\nfor a suitable description of the interaction via linker protein densities.\nBesides the detailed modelling we discuss some energetic aspects of the models\nand present a numerical scheme, which allows to carry out several computational\nstudies. In those we demonstrate that several effects found in experiments can\nbe reproduced, in particular bleb formation by cortex rupture, which was not\npossible by previous models without the linker dynamics.",
    "descriptor": "",
    "authors": [
      "Philipp Werner",
      "Martin Burger",
      "Florian Frank",
      "Harald Garcke"
    ],
    "subjectives": [
      "Cell Behavior (q-bio.CB)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06334"
  },
  {
    "id": "arXiv:2107.06374",
    "title": "Bilinear Control of Convection-Cooling: From Open-Loop to Closed-Loop",
    "abstract": "This paper is concerned with a bilinear control problem for enhancing\nconvection-cooling via an incompressible velocity field. Both optimal open-loop\ncontrol and closed-loop feedback control designs are addressed. First and\nsecond order optimality conditions for characterizing the optimal solution are\ndiscussed. In particular, the method of instantaneous control is applied to\nestablish the feedback laws. Moreover, the construction of feedback laws is\nalso investigated by directly utilizing the optimality system with appropriate\nnumerical discretization schemes. Computationally, it is much easier to\nimplement the closed-loop feedback control than the optimal open-loop control,\nas the latter requires to solve the state equations forward in time, coupled\nwith the adjoint equations backward in time together with a nonlinear\noptimality condition. Rigorous analysis and numerical experiments are presented\nto demonstrate our ideas and validate the efficacy of the control designs.",
    "descriptor": "\nComments: 27 pages, 7 figures, 3 tables\n",
    "authors": [
      "Weiwei Hu",
      "Jun Liu",
      "Zhu Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06374"
  },
  {
    "id": "arXiv:2107.06396",
    "title": "Forecasting Thermoacoustic Instabilities in Liquid Propellant Rocket  Engines Using Multimodal Bayesian Deep Learning",
    "abstract": "The 100 MW cryogenic liquid oxygen/hydrogen multi-injector combustor BKD\noperated by the DLR Institute of Space Propulsion is a research platform that\nallows the study of thermoacoustic instabilities under realistic conditions,\nrepresentative of small upper stage rocket engines. We use data from BKD\nexperimental campaigns in which the static chamber pressure and fuel-oxidizer\nratio are varied such that the first tangential mode of the combustor is\nexcited under some conditions. We train an autoregressive Bayesian neural\nnetwork model to forecast the amplitude of the dynamic pressure time series,\ninputting multiple sensor measurements (injector pressure/ temperature\nmeasurements, static chamber pressure, high-frequency dynamic pressure\nmeasurements, high-frequency OH* chemiluminescence measurements) and future\nflow rate control signals. The Bayesian nature of our algorithms allows us to\nwork with a dataset whose size is restricted by the expense of each\nexperimental run, without making overconfident extrapolations. We find that the\nnetworks are able to accurately forecast the evolution of the pressure\namplitude and anticipate instability events on unseen experimental runs 500\nmilliseconds in advance. We compare the predictive accuracy of multiple models\nusing different combinations of sensor inputs. We find that the high-frequency\ndynamic pressure signal is particularly informative. We also use the technique\nof integrated gradients to interpret the influence of different sensor inputs\non the model prediction. The negative log-likelihood of data points in the test\ndataset indicates that predictive uncertainties are well-characterized by our\nBayesian model and simulating a sensor failure event results as expected in a\ndramatic increase in the epistemic component of the uncertainty.",
    "descriptor": "",
    "authors": [
      "Ushnish Sengupta",
      "G\u00fcnther Waxenegger-Wilfing",
      "Justin Hardi",
      "Matthew P. Juniper"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06396"
  },
  {
    "id": "arXiv:2107.06406",
    "title": "A Theoretical Framework for Learning from Quantum Data",
    "abstract": "Over decades traditional information theory of source and channel coding\nadvances toward learning and effective extraction of information from data. We\npropose to go one step further and offer a theoretical foundation for learning\nclassical patterns from quantum data. However, there are several roadblocks to\nlay the groundwork for such a generalization. First, classical data must be\nreplaced by a density operator over a Hilbert space. Hence, deviated from\nproblems such as state tomography, our samples are i.i.d density operators. The\nsecond challenge is even more profound since we must realize that our only\ninteraction with a quantum state is through a measurement which -- due to\nno-cloning quantum postulate -- loses information after measuring it. With this\nin mind, we present a quantum counterpart of the well-known PAC framework.\nBased on that, we propose a quantum analogous of the ERM algorithm for learning\nmeasurement hypothesis classes. Then, we establish upper bounds on the quantum\nsample complexity quantum concept classes.",
    "descriptor": "",
    "authors": [
      "Mohsen Heidari",
      "Arun Padakandla",
      "Wojciech Szpankowski"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06406"
  },
  {
    "id": "arXiv:2107.06428",
    "title": "For high-dimensional hierarchical models, consider exchangeability of  effects across covariates instead of across datasets",
    "abstract": "Hierarchical Bayesian methods enable information sharing across multiple\nrelated regression problems. While standard practice is to model regression\nparameters (effects) as (1) exchangeable across datasets and (2) correlated to\ndiffering degrees across covariates, we show that this approach exhibits poor\nstatistical performance when the number of covariates exceeds the number of\ndatasets. For instance, in statistical genetics, we might regress dozens of\ntraits (defining datasets) for thousands of individuals (responses) on up to\nmillions of genetic variants (covariates). When an analyst has more covariates\nthan datasets, we argue that it is often more natural to instead model effects\nas (1) exchangeable across covariates and (2) correlated to differing degrees\nacross datasets. To this end, we propose a hierarchical model expressing our\nalternative perspective. We devise an empirical Bayes estimator for learning\nthe degree of correlation between datasets. We develop theory that demonstrates\nthat our method outperforms the classic approach when the number of covariates\ndominates the number of datasets, and corroborate this result empirically on\nseveral high-dimensional multiple regression and classification problems.",
    "descriptor": "\nComments: 10 pages plus supplementary material\n",
    "authors": [
      "Brian L. Trippe",
      "Hilary K. Finucane",
      "Tamara Broderick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06428"
  },
  {
    "id": "arXiv:2107.06435",
    "title": "A Smoothed Impossibility Theorem on Condorcet Criterion and  Participation",
    "abstract": "In 1988, Moulin proved an insightful and surprising impossibility theorem\nthat reveals a fundamental incompatibility between two commonly-studied axioms\nof voting: no resolute voting rule (which outputs a single winner) satisfies\nCondorcet Criterion and Participation simultaneously when the number of\nalternatives m is at least four. In this paper, we prove an extension of this\nimpossibility theorem using smoothed analysis: for any fixed $m\\ge 4$ and any\nvoting rule r, under mild conditions, the smoothed likelihood for both\nCondorcet Criterion and Participation to be satisfied is at most\n$1-\\Omega(n^{-3})$, where n is the number of voters that is sufficiently large.\nOur theorem immediately implies a quantitative version of the theorem for\ni.i.d. uniform distributions, known as the Impartial Culture in social choice\ntheory.",
    "descriptor": "",
    "authors": [
      "Lirong Xia"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.06435"
  },
  {
    "id": "arXiv:2107.06449",
    "title": "End-to-end Ultrasound Frame to Volume Registration",
    "abstract": "Fusing intra-operative 2D transrectal ultrasound (TRUS) image with\npre-operative 3D magnetic resonance (MR) volume to guide prostate biopsy can\nsignificantly increase the yield. However, such a multimodal 2D/3D registration\nproblem is a very challenging task. In this paper, we propose an end-to-end\nframe-to-volume registration network (FVR-Net), which can efficiently bridge\nthe previous research gaps by aligning a 2D TRUS frame with a 3D TRUS volume\nwithout requiring hardware tracking. The proposed FVR-Net utilizes a\ndual-branch feature extraction module to extract the information from TRUS\nframe and volume to estimate transformation parameters. We also introduce a\ndifferentiable 2D slice sampling module which allows gradients backpropagating\nfrom an unsupervised image similarity loss for content correspondence learning.\nOur model shows superior efficiency for real-time interventional guidance with\nhighly competitive registration accuracy.",
    "descriptor": "\nComments: Early accepted by MICCAI-2021\n",
    "authors": [
      "Hengtao Guo",
      "Xuanang Xu",
      "Sheng Xu",
      "Bradford J. Wood",
      "Pingkun Yan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06449"
  },
  {
    "id": "arXiv:2107.06463",
    "title": "Learned Image Compression with Discretized Gaussian-Laplacian-Logistic  Mixture Model and Concatenated Residual Modules",
    "abstract": "Recently deep learning-based image compression methods have achieved\nsignificant achievements and gradually outperformed traditional approaches\nincluding the latest standard Versatile Video Coding (VVC) in both PSNR and\nMS-SSIM metrics. Two key components of learned image compression frameworks are\nthe entropy model of the latent representations and the encoding/decoding\nnetwork architectures. Various models have been proposed, such as\nautoregressive, softmax, logistic mixture, Gaussian mixture, and Laplacian.\nExisting schemes only use one of these models. However, due to the vast\ndiversity of images, it is not optimal to use one model for all images, even\ndifferent regions of one image. In this paper, we propose a more flexible\ndiscretized Gaussian-Laplacian-Logistic mixture model (GLLMM) for the latent\nrepresentations, which can adapt to different contents in different images and\ndifferent regions of one image more accurately. Besides, in the\nencoding/decoding network design part, we propose a concatenated residual\nblocks (CRB), where multiple residual blocks are serially connected with\nadditional shortcut connections. The CRB can improve the learning ability of\nthe network, which can further improve the compression performance.\nExperimental results using the Kodak and Tecnick datasets show that the\nproposed scheme outperforms all the state-of-the-art learning-based methods and\nexisting compression standards including VVC intra coding (4:4:4 and 4:2:0) in\nterms of the PSNR and MS-SSIM.",
    "descriptor": "\nComments: Submitted to IEEE Transactions On Image Processing\n",
    "authors": [
      "Haisheng Fu",
      "Feng Liang",
      "Jianping Lin",
      "Bing Li",
      "Mohammad Akbari",
      "Jie Liang",
      "Guohe Zhang",
      "Dong Liu",
      "Chengjie Tu",
      "Jingning Han"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06463"
  },
  {
    "id": "arXiv:2107.06467",
    "title": "Multi-Task Audio Source Separation",
    "abstract": "The audio source separation tasks, such as speech enhancement, speech\nseparation, and music source separation, have achieved impressive performance\nin recent studies. The powerful modeling capabilities of deep neural networks\ngive us hope for more challenging tasks. This paper launches a new multi-task\naudio source separation (MTASS) challenge to separate the speech, music, and\nnoise signals from the monaural mixture. First, we introduce the details of\nthis task and generate a dataset of mixtures containing speech, music, and\nbackground noises. Then, we propose an MTASS model in the complex domain to\nfully utilize the differences in spectral characteristics of the three audio\nsignals. In detail, the proposed model follows a two-stage pipeline, which\nseparates the three types of audio signals and then performs signal\ncompensation separately. After comparing different training targets, the\ncomplex ratio mask is selected as a more suitable target for the MTASS. The\nexperimental results also indicate that the residual signal compensation module\nhelps to recover the signals further. The proposed model shows significant\nadvantages in separation performance over several well-known separation models.",
    "descriptor": "",
    "authors": [
      "Lu Zhang",
      "Chenxing Li",
      "Feng Deng",
      "Xiaorui Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.06467"
  },
  {
    "id": "arXiv:2107.06473",
    "title": "Spectrum Gaussian Processes Based On Tunable Basis Functions",
    "abstract": "Spectral approximation and variational inducing learning for the Gaussian\nprocess are two popular methods to reduce computational complexity. However, in\nprevious research, those methods always tend to adopt the orthonormal basis\nfunctions, such as eigenvectors in the Hilbert space, in the spectrum method,\nor decoupled orthogonal components in the variational framework. In this paper,\ninspired by quantum physics, we introduce a novel basis function, which is\ntunable, local and bounded, to approximate the kernel function in the Gaussian\nprocess. There are two adjustable parameters in these functions, which control\ntheir orthogonality to each other and limit their boundedness. And we conduct\nextensive experiments on open-source datasets to testify its performance.\nCompared to several state-of-the-art methods, it turns out that the proposed\nmethod can obtain satisfactory or even better results, especially with poorly\nchosen kernel functions.",
    "descriptor": "\nComments: 10 figures\n",
    "authors": [
      "Wenqi Fang",
      "Guanlin Wu",
      "Jingjing Li",
      "Zheng Wang",
      "Jiang Cao",
      "Yang Ping"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06473"
  },
  {
    "id": "arXiv:2107.06507",
    "title": "Deep learning based parameter search for an agent based social network  model",
    "abstract": "Interactions between humans give rise to complex social networks that are\ncharacterized by heterogeneous degree distribution, weight-topology relation,\noverlapping community structure, and dynamics of links. Understanding such\nnetworks is a primary goal of science due to serving as the scaffold for many\nemergent social phenomena from disease spreading to political movements. An\nappropriate tool for studying them is agent-based modeling, in which nodes,\nrepresenting persons, make decisions about creating and deleting links, thus\nyielding various macroscopic behavioral patterns. Here we focus on studying a\ngeneralization of the weighted social network model, being one of the most\nfundamental agent-based models for describing the formation of social ties and\nsocial networks. This Generalized Weighted Social Network (GWSN) model\nincorporates triadic closure, homophilic interactions, and various link\ntermination mechanisms, which have been studied separately in the previous\nworks. Accordingly, the GWSN model has an increased number of input parameters\nand the model behavior gets excessively complex, making it challenging to\nclarify the model behavior. We have executed massive simulations with a\nsupercomputer and using the results as the training data for deep neural\nnetworks to conduct regression analysis for predicting the properties of the\ngenerated networks from the input parameters. The obtained regression model was\nalso used for global sensitivity analysis to identify which parameters are\ninfluential or insignificant. We believe that this methodology is applicable\nfor a large class of complex network models, thus opening the way for more\nrealistic quantitative agent-based modeling.",
    "descriptor": "\nComments: 12 pages, 4 figures, 3 tables, 1 pseudocode\n",
    "authors": [
      "Yohsuke Murase",
      "Hang-Hyun Jo",
      "J\u00e1nos T\u00f6r\u00f6k",
      "J\u00e1nos Kert\u00e9sz",
      "Kimmo Kaski"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06507"
  },
  {
    "id": "arXiv:2107.06509",
    "title": "The nearly singular behavior of the 3D Navier-Stokes equations",
    "abstract": "Whether the 3D incompressible Navier-Stokes equations can develop a finite\ntime singularity from smooth initial data is one of the most challenging\nproblems in nonlinear PDEs. In this paper, we present some new numerical\nevidence that the 3D incompressible axisymmetric Navier-Stokes equations with\nsmooth initial data of finite energy develop nearly singular solutions at the\norigin. This nearly singular behavior is induced by a potential finite time\nsingularity of the 3D Euler equations that we reported in\n\\cite{Hou-euler-2021}. One important feature of the potential Euler singularity\nis that the solution develops nearly self-similar scaling properties that are\ncompatible with those of the 3D Navier-Stokes equations. We will present\nnumerical evidence that the 3D Navier-Stokes equations develop nearly singular\nscaling properties with maximum vorticity increased by a factor of $10^7$.\nMoreover, the nearly self-similar profiles seem to be very stable to the small\nperturbation of the initial data. However, the 3D Navier-Stokes equations with\nour initial data do not develop a finite time singularity due to the\ndevelopment of a mild two-scale structure in the late stage, which eventually\nleads to viscous dominance over vortex stretching. To maintain the balance\nbetween the vortex stretching term and the diffusion term, we solve the 3D\nNavier-Stokes equations with a time-dependent viscosity roughly of order\n$O(|\\log(T-t)|^{-3})$ in the late stage. We present strong numerical evidence\nthat the 3D Navier-Stokes equations with such time-dependent viscosity develop\na finite time singularity.",
    "descriptor": "\nComments: 50 pages. arXiv admin note: substantial text overlap with arXiv:2107.05870; text overlap with arXiv:2102.06663\n",
    "authors": [
      "Thomas Y. Hou"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06509"
  },
  {
    "id": "arXiv:2107.06534",
    "title": "Zeroth and First Order Stochastic Frank-Wolfe Algorithms for Constrained  Optimization",
    "abstract": "This paper considers stochastic convex optimization problems with two sets of\nconstraints: (a) deterministic constraints on the domain of the optimization\nvariable, which are difficult to project onto; and (b) deterministic or\nstochastic constraints that admit efficient projection. Problems of this form\narise frequently in the context of semidefinite programming as well as when\nvarious NP-hard problems are solved approximately via semidefinite relaxation.\nSince projection onto the first set of constraints is difficult, it becomes\nnecessary to explore projection-free algorithms, such as the stochastic\nFrank-Wolfe (FW) algorithm. On the other hand, the second set of constraints\ncannot be handled in the same way, and must be incorporated as an indicator\nfunction within the objective function, thereby complicating the application of\nFW methods. Similar problems have been studied before, and solved using\nfirst-order stochastic FW algorithms by applying homotopy and Nesterov's\nsmoothing techniques to the indicator function. This work improves upon these\nexisting results and puts forth momentum-based first-order methods that yield\nimproved convergence rates, at par with the best known rates for problems\nwithout the second set of constraints. Zeroth-order variants of the proposed\nalgorithms are also developed and again improve upon the state-of-the-art rate\nresults. The efficacy of the proposed algorithms is tested on relevant\napplications of sparse matrix estimation, clustering via semidefinite\nrelaxation, and uniform sparsest cut problem.",
    "descriptor": "",
    "authors": [
      "Zeeshan Akhtar",
      "Ketan Rajawat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06534"
  },
  {
    "id": "arXiv:2107.06536",
    "title": "Multi-Attention Generative Adversarial Network for Remote Sensing Image  Super-Resolution",
    "abstract": "Image super-resolution (SR) methods can generate remote sensing images with\nhigh spatial resolution without increasing the cost, thereby providing a\nfeasible way to acquire high-resolution remote sensing images, which are\ndifficult to obtain due to the high cost of acquisition equipment and complex\nweather. Clearly, image super-resolution is a severe ill-posed problem.\nFortunately, with the development of deep learning, the powerful fitting\nability of deep neural networks has solved this problem to some extent. In this\npaper, we propose a network based on the generative adversarial network (GAN)\nto generate high resolution remote sensing images, named the multi-attention\ngenerative adversarial network (MA-GAN). We first designed a GAN-based\nframework for the image SR task. The core to accomplishing the SR task is the\nimage generator with post-upsampling that we designed. The main body of the\ngenerator contains two blocks; one is the pyramidal convolution in the\nresidual-dense block (PCRDB), and the other is the attention-based upsample\n(AUP) block. The attentioned pyramidal convolution (AttPConv) in the PCRDB\nblock is a module that combines multi-scale convolution and channel attention\nto automatically learn and adjust the scaling of the residuals for better\nresults. The AUP block is a module that combines pixel attention (PA) to\nperform arbitrary multiples of upsampling. These two blocks work together to\nhelp generate better quality images. For the loss function, we design a loss\nfunction based on pixel loss and introduce both adversarial loss and feature\nloss to guide the generator learning. We have compared our method with several\nstate-of-the-art methods on a remote sensing scene image dataset, and the\nexperimental results consistently demonstrate the effectiveness of the proposed\nMA-GAN.",
    "descriptor": "",
    "authors": [
      "Meng Xu",
      "Zhihao Wang",
      "Jiasong Zhu",
      "Xiuping Jia",
      "Sen Jia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06536"
  },
  {
    "id": "arXiv:2107.06581",
    "title": "A Granular Sieving Algorithm for Deterministic Global Optimization",
    "abstract": "A gradient-free deterministic method is developed to solve global\noptimization problems for Lipschitz continuous functions defined in arbitrary\npath-wise connected compact sets in Euclidean spaces. The method can be\nregarded as granular sieving with synchronous analysis in both the domain and\nrange of the objective function. With straightforward mathematical formulation\napplicable to both univariate and multivariate objective functions, the global\nminimum value and all the global minimizers are located through two decreasing\nsequences of compact sets in, respectively, the domain and range spaces. The\nalgorithm is easy to implement with moderate computational cost. The method is\ntested against extensive benchmark functions in the literature. The\nexperimental results show remarkable effectiveness and applicability of the\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Tao Qian",
      "Lei Dai",
      "Liming Zhang",
      "Zehua Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06581"
  },
  {
    "id": "arXiv:2107.06592",
    "title": "Is Someone Speaking? Exploring Long-term Temporal Features for  Audio-visual Active Speaker Detection",
    "abstract": "Active speaker detection (ASD) seeks to detect who is speaking in a visual\nscene of one or more speakers. The successful ASD depends on accurate\ninterpretation of short-term and long-term audio and visual information, as\nwell as audio-visual interaction. Unlike the prior work where systems make\ndecision instantaneously using short-term features, we propose a novel\nframework, named TalkNet, that makes decision by taking both short-term and\nlong-term features into consideration. TalkNet consists of audio and visual\ntemporal encoders for feature representation, audio-visual cross-attention\nmechanism for inter-modality interaction, and a self-attention mechanism to\ncapture long-term speaking evidence. The experiments demonstrate that TalkNet\nachieves 3.5\\% and 2.2\\% improvement over the state-of-the-art systems on the\nAVA-ActiveSpeaker dataset and Columbia ASD dataset, respectively. Code has been\nmade available at:\n\\textcolor{magenta}{\\url{https://github.com/TaoRuijie/TalkNet_ASD}}.",
    "descriptor": "\nComments: ACM Multimedia 2021\n",
    "authors": [
      "Ruijie Tao",
      "Zexu Pan",
      "Rohan Kumar Das",
      "Xinyuan Qian",
      "Mike Zheng Shou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06592"
  },
  {
    "id": "arXiv:2107.06617",
    "title": "Nowcasting transmission and suppression of the Delta variant of  SARS-CoV-2 in Australia",
    "abstract": "As of July 2021, there is a continuing outbreak of the B.1.617.2 (Delta)\nvariant of SARS-CoV-2 in Sydney, Australia. The outbreak is of major concern as\nthe Delta variant is estimated to have twice the reproductive number to\nprevious variants that circulated in Australia in 2020, which is worsened by\nlow levels of acquired immunity in the population. Using a re-calibrated\nagent-based model, we explored a feasible range of non-pharmaceutical\ninterventions, in terms of both mitigation (case isolation, home quarantine)\nand suppression (school closures, social distancing). Our nowcasting modelling\nindicated that the level of social distancing currently attained in Sydney is\ninadequate for the outbreak control. A counter-factual analysis suggested that\nif 80% of agents comply with social distancing, then at least a month is needed\nfor the new daily cases to reduce from their peak to below ten. A small\nreduction in social distancing compliance to 70% lengthens this period to over\ntwo months.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Sheryl L. Chang",
      "Oliver M. Cliff",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06617"
  },
  {
    "id": "arXiv:2107.06618",
    "title": "Hierarchical Analysis of Visual COVID-19 Features from Chest Radiographs",
    "abstract": "Chest radiography has been a recommended procedure for patient triaging and\nresource management in intensive care units (ICUs) throughout the COVID-19\npandemic. The machine learning efforts to augment this workflow have been long\nchallenged due to deficiencies in reporting, model evaluation, and failure mode\nanalysis. To address some of those shortcomings, we model radiological features\nwith a human-interpretable class hierarchy that aligns with the radiological\ndecision process. Also, we propose the use of a data-driven error analysis\nmethodology to uncover the blind spots of our model, providing further\ntransparency on its clinical utility. For example, our experiments show that\nmodel failures highly correlate with ICU imaging conditions and with the\ninherent difficulty in distinguishing certain types of radiological features.\nAlso, our hierarchical interpretation and analysis facilitates the comparison\nwith respect to radiologists' findings and inter-variability, which in return\nhelps us to better assess the clinical applicability of models.",
    "descriptor": "\nComments: Presented at ICML 2021 Workshop on Interpretable Machine Learning in Healthcare\n",
    "authors": [
      "Shruthi Bannur",
      "Ozan Oktay",
      "Melanie Bernhardt",
      "Anton Schwaighofer",
      "Rajesh Jena",
      "Besmira Nushi",
      "Sharan Wadhwani",
      "Aditya Nori",
      "Kal Natarajan",
      "Shazad Ashraf",
      "Javier Alvarez-Valle",
      "Daniel C. Castro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06618"
  },
  {
    "id": "arXiv:2107.06621",
    "title": "Rough McKean-Vlasov dynamics for robust ensemble Kalman filtering",
    "abstract": "Motivated by the challenge of incorporating data into misspecified and\nmultiscale dynamical models, we study a McKean-Vlasov equation that contains\nthe data stream as a common driving rough path. This setting allows us to prove\nwell-posedness as well as continuity with respect to the driver in an\nappropriate rough-path topology. The latter property is key in our subsequent\ndevelopment of a robust data assimilation methodology: We establish propagation\nof chaos for the associated interacting particle system, which in turn is\nsuggestive of a numerical scheme that can be viewed as an extension of the\nensemble Kalman filter to a rough-path framework. Finally, we discuss a\ndata-driven method based on subsampling to construct suitable rough path lifts\nand demonstrate the robustness of our scheme in a number of numerical\nexperiments related to parameter estimation problems in multiscale contexts.",
    "descriptor": "\nComments: 41 pages, 7 figures\n",
    "authors": [
      "Michele Coghi",
      "Torstein Nilssen",
      "Nikolas N\u00fcsken"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.06621"
  },
  {
    "id": "arXiv:2107.06640",
    "title": "3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018  Palu, Sulawesi Earthquake and Tsunami",
    "abstract": "We present a highly scalable 3D fully-coupled Earth & ocean model of\nearthquake rupture and tsunami generation and perform the first fully coupled\nsimulation of an actual earthquake-tsunami event and a 3D benchmark problem of\ntsunami generation by a mega-thrust dynamic earthquake rupture. Multi-petascale\nsimulations, with excellent performance demonstrated on three different\nplatforms, allow high-resolution forward modeling. Our largest mesh has\n$\\approx$261 billion degrees of freedom, resolving at least 15 Hz of the\nacoustic wave field. We self-consistently model seismic, acoustic and surface\ngravity wave propagation in elastic (Earth) and acoustic (ocean) materials\nsourced by physics-based non-linear earthquake dynamic rupture, thereby gaining\ninsight into the tsunami generation process without relying on approximations\nthat have previously been applied to permit solution of this challenging\nproblem. Complicated geometries, including high-resolution bathymetry,\ncoastlines and segmented earthquake faults are discretized by adaptive\nunstructured tetrahedral meshes. This leads inevitably to large differences in\nelement sizes and wave speeds which can be mitigated by ADER local\ntime-stepping and a Discontinuous Galerkin discretisation yielding high-order\naccuracy in time and space.",
    "descriptor": "\nComments: 13 pages, 6 figures; Accepted at the International Conference for High Performance Computing, Networking, Storage and Analysis 2021\n",
    "authors": [
      "Lukas Krenz",
      "Carsten Uphoff",
      "Thomas Ulrich",
      "Alice-Agnes Gabriel",
      "Lauren S. Abrahams",
      "Eric M. Dunham",
      "Michael Bader"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06640"
  },
  {
    "id": "arXiv:2107.06642",
    "title": "Many-to-Many Voice Conversion based Feature Disentanglement using  Variational Autoencoder",
    "abstract": "Voice conversion is a challenging task which transforms the voice\ncharacteristics of a source speaker to a target speaker without changing\nlinguistic content. Recently, there have been many works on many-to-many Voice\nConversion (VC) based on Variational Autoencoder (VAEs) achieving good results,\nhowever, these methods lack the ability to disentangle speaker identity and\nlinguistic content to achieve good performance on unseen speaker scenarios. In\nthis paper, we propose a new method based on feature disentanglement to tackle\nmany to many voice conversion. The method has the capability to disentangle\nspeaker identity and linguistic content from utterances, it can convert from\nmany source speakers to many target speakers with a single autoencoder network.\nMoreover, it naturally deals with the unseen target speaker scenarios. We\nperform both objective and subjective evaluations to show the competitive\nperformance of our proposed method compared with other state-of-the-art models\nin terms of naturalness and target speaker similarity.",
    "descriptor": "",
    "authors": [
      "Manh Luong",
      "Viet Anh Tran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.06642"
  },
  {
    "id": "arXiv:2107.06658",
    "title": "A Framework for Machine Learning of Model Error in Dynamical Systems",
    "abstract": "The development of data-informed predictive models for dynamical systems is\nof widespread interest in many disciplines. We present a unifying framework for\nblending mechanistic and machine-learning approaches to identify dynamical\nsystems from data. We compare pure data-driven learning with hybrid models\nwhich incorporate imperfect domain knowledge. We cast the problem in both\ncontinuous- and discrete-time, for problems in which the model error is\nmemoryless and in which it has significant memory, and we compare data-driven\nand hybrid approaches experimentally. Our formulation is agnostic to the chosen\nmachine learning model.\nUsing Lorenz '63 and Lorenz '96 Multiscale systems, we find that hybrid\nmethods substantially outperform solely data-driven approaches in terms of data\nhunger, demands for model complexity, and overall predictive performance. We\nalso find that, while a continuous-time framing allows for robustness to\nirregular sampling and desirable domain-interpretability, a discrete-time\nframing can provide similar or better predictive performance, especially when\ndata are undersampled and the vector field cannot be resolved.\nWe study model error from the learning theory perspective, defining excess\nrisk and generalization error; for a linear model of the error used to learn\nabout ergodic dynamical systems, both errors are bounded by terms that diminish\nwith the square-root of T. We also illustrate scenarios that benefit from\nmodeling with memory, proving that continuous-time recurrent neural networks\n(RNNs) can, in principle, learn memory-dependent model error and reconstruct\nthe original system arbitrarily well; numerical results depict challenges in\nrepresenting memory by this approach. We also connect RNNs to reservoir\ncomputing and thereby relate the learning of memory-dependent error to recent\nwork on supervised learning between Banach spaces using random features.",
    "descriptor": "",
    "authors": [
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06658"
  },
  {
    "id": "arXiv:2107.06675",
    "title": "M5 Competition Uncertainty: Overdispersion, distributional forecasting,  GAMLSS and beyond",
    "abstract": "The M5 competition uncertainty track aims for probabilistic forecasting of\nsales of thousands of Walmart retail goods. We show that the M5 competition\ndata faces strong overdispersion and sporadic demand, especially zero demand.\nWe discuss resulting modeling issues concerning adequate probabilistic\nforecasting of such count data processes. Unfortunately, the majority of\npopular prediction methods used in the M5 competition (e.g. lightgbm and\nxgboost GBMs) fails to address the data characteristics due to the considered\nobjective functions. The distributional forecasting provides a suitable\nmodeling approach for to the overcome those problems. The GAMLSS framework\nallows flexible probabilistic forecasting using low dimensional distributions.\nWe illustrate, how the GAMLSS approach can be applied for the M5 competition\ndata by modeling the location and scale parameter of various distributions,\ne.g. the negative binomial distribution. Finally, we discuss software packages\nfor distributional modeling and their drawback, like the R package gamlss with\nits package extensions, and (deep) distributional forecasting libraries such as\nTensorFlow Probability.",
    "descriptor": "",
    "authors": [
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.06675"
  },
  {
    "id": "arXiv:2107.06677",
    "title": "Hybrid Model and Data Driven Algorithm for Online Learning of Any-to-Any  Path Loss Maps",
    "abstract": "Learning any-to-any (A2A) path loss maps, where the objective is the\nreconstruction of path loss between any two given points in a map, might be a\nkey enabler for many applications that rely on device-to-device (D2D)\ncommunication. Such applications include machine-type communications (MTC) or\nvehicle-to-vehicle (V2V) communications. Current approaches for learning A2A\nmaps are either model-based methods, or pure data-driven methods. Model-based\nmethods have the advantage that they can generate reliable estimations with low\ncomputational complexity, but they cannot exploit information coming from data.\nPure data-driven methods can achieve good performance without assuming any\nphysical model, but their complexity and their lack of robustness is not\nacceptable for many applications. In this paper, we propose a novel hybrid\nmodel and data-driven approach that fuses information obtained from datasets\nand models in an online fashion. To that end, we leverage the framework of\nstochastic learning to deal with the sequential arrival of samples and propose\nan online algorithm that alternatively and sequentially minimizes the original\nnon-convex problem. A proof of convergence is presented, along with experiments\nbased firstly on synthetic data, and secondly on a more realistic dataset for\nV2X, with both experiments showing promising results.",
    "descriptor": "",
    "authors": [
      "M. A. Gutierrez-Estevez",
      "Martin Kasparick",
      "Renato L. G. Cavalvante",
      "S\u0142awomir Sta\u0144czak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06677"
  },
  {
    "id": "arXiv:2107.06696",
    "title": "Social nucleation: Group formation as a phase transition",
    "abstract": "The spontaneous formation and subsequent growth, dissolution, merger and\ncompetition of social groups bears similarities to physical phase transitions\nin metastable finite systems. We examine three different scenarios,\npercolation, spinodal decomposition and nucleation, to describe the formation\nof social groups of varying size and density. In our agent-based model, we use\na feedback between the opinions of agents and their ability to establish links.\nGroups can restrict further link formation, but agents can also leave if costs\nexceed the group benefits. We identify the critical parameters for\ncosts/benefits and social influence to obtain either one large group or the\nstable coexistence of several groups with different opinions. Analytic\ninvestigations allow to derive different critical densities that control the\nformation and coexistence of groups. Our novel approach sheds new light on the\nearly stage of network growth and the emergence of large connected components.",
    "descriptor": "",
    "authors": [
      "Frank Schweitzer",
      "Georges Andres"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06696"
  },
  {
    "id": "arXiv:2107.06701",
    "title": "Empirical Evaluation of Circuit Approximations on Noisy Quantum Devices",
    "abstract": "Noisy Intermediate-Scale Quantum (NISQ) devices fail to produce outputs with\nsufficient fidelity for deep circuits with many gates today. Such devices\nsuffer from read-out, multi-qubit gate and crosstalk noise combined with short\ndecoherence times limiting circuit depth. This work develops a methodology to\ngenerate shorter circuits with fewer multi-qubit gates whose unitary\ntransformations approximate the original reference one. It explores the benefit\nof such generated approximations under NISQ devices. Experimental results with\nGrover's algorithm, multiple-control Toffoli gates, and the Transverse Field\nIsing Model show that such approximate circuits produce higher fidelity results\nthan longer, theoretically precise circuits on NISQ devices, especially when\nthe reference circuits have many CNOT gates to begin with. With this ability to\nfine-tune circuits, it is demonstrated that quantum computations can be\nperformed for more complex problems on today's devices than was feasible\nbefore, sometimes even with a gain in overall precision by up to 60%.",
    "descriptor": "",
    "authors": [
      "Ellis Wilson",
      "Frank Mueller",
      "Lindsay Bassman",
      "Constin Iancu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.06701"
  },
  {
    "id": "arXiv:2107.06721",
    "title": "Resonant Tunnelling Diode Nano-Optoelectronic Spiking Nodes For  Neuromorphic Information Processing",
    "abstract": "In this work, we introduce an optoelectronic spiking artificial neuron\ncapable of operating at ultrafast rates ($\\approx$ 100 ps/optical spike) and\nwith low energy consumption ($<$ pJ/spike). The proposed system combines an\nexcitable resonant tunnelling diode (RTD) element exhibiting negative\ndifferential conductance, coupled to a nanoscale light source (forming a master\nnode) or a photodetector (forming a receiver node). We study numerically the\nspiking dynamical responses and information propagation functionality of an\ninterconnected master-receiver RTD node system. Using the key functionality of\npulse thresholding and integration, we utilize a single node to classify\nsequential pulse patterns and perform convolutional functionality for image\nfeature (edge) recognition. We also demonstrate an optically-interconnected\nspiking neural network model for processing of spatiotemporal data at over 10\nGbps with high inference accuracy. Finally, we demonstrate an off-chip\nsupervised learning approach utilizing spike-timing dependent plasticity for\nthe RTD-enabled photonic spiking neural network. These results demonstrate the\npotential and viability of RTD spiking nodes for low footprint, low energy,\nhigh-speed optoelectronic realization of neuromorphic hardware.",
    "descriptor": "",
    "authors": [
      "Mat\u011bj Hejda",
      "Juan Arturo Alanis",
      "Ignacio Ortega-Piwonka",
      "Jo\u00e3o Louren\u00e7o",
      "Jos\u00e9 Figueiredo",
      "Julien Javaloyes",
      "Bruno Romeira",
      "Antonio Hurtado"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.06721"
  },
  {
    "id": "arXiv:2107.06762",
    "title": "Modelling Neuronal Behaviour with Time Series Regression: Recurrent  Neural Networks on C. Elegans Data",
    "abstract": "Given the inner complexity of the human nervous system, insight into the\ndynamics of brain activity can be gained from understanding smaller and simpler\norganisms, such as the nematode C. Elegans. The behavioural and structural\nbiology of these organisms is well-known, making them prime candidates for\nbenchmarking modelling and simulation techniques. In these complex neuronal\ncollections, classical, white-box modelling techniques based on intrinsic\nstructural or behavioural information are either unable to capture the profound\nnonlinearities of the neuronal response to different stimuli or generate\nextremely complex models, which are computationally intractable. In this paper\nwe show how the nervous system of C. Elegans can be modelled and simulated with\ndata-driven models using different neural network architectures. Specifically,\nwe target the use of state of the art recurrent neural networks architectures\nsuch as LSTMs and GRUs and compare these architectures in terms of their\nproperties and their accuracy as well as the complexity of the resulting\nmodels. We show that GRU models with a hidden layer size of 4 units are able to\naccurately reproduce with high accuracy the system's response to very different\nstimuli.",
    "descriptor": "",
    "authors": [
      "Gon\u00e7alo Mestre",
      "Ruxandra Barbulescu",
      "Arlindo L. Oliveira",
      "L. Miguel Silveira"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.06762"
  },
  {
    "id": "arXiv:2107.06767",
    "title": "Correlated Stochastic Block Models: Exact Graph Matching with  Applications to Recovering Communities",
    "abstract": "We consider the task of learning latent community structure from multiple\ncorrelated networks. First, we study the problem of learning the latent vertex\ncorrespondence between two edge-correlated stochastic block models, focusing on\nthe regime where the average degree is logarithmic in the number of vertices.\nWe derive the precise information-theoretic threshold for exact recovery: above\nthe threshold there exists an estimator that outputs the true correspondence\nwith probability close to 1, while below it no estimator can recover the true\ncorrespondence with probability bounded away from 0. As an application of our\nresults, we show how one can exactly recover the latent communities using\nmultiple correlated graphs in parameter regimes where it is\ninformation-theoretically impossible to do so using just a single graph.",
    "descriptor": "\nComments: 42 pages, 4 figures\n",
    "authors": [
      "Miklos Z. Racz",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.06767"
  },
  {
    "id": "arXiv:2107.06773",
    "title": "Relational graph convolutional networks for predicting blood-brain  barrier penetration of drug molecules",
    "abstract": "The evaluation of the BBB penetrating ability of drug molecules is a critical\nstep in brain drug development. Computational prediction based on machine\nlearning has proved to be an efficient way to conduct the evaluation. However,\nperformance of the established models has been limited by their incapability of\ndealing with the interactions between drugs and proteins, which play an\nimportant role in the mechanism behind BBB penetrating behaviors. To address\nthis issue, we employed the relational graph convolutional network (RGCN) to\nhandle the drug-protein (denoted by the encoding gene) relations as well as the\nfeatures of each individual drug. In addition, drug-drug similarity was also\nintroduced to connect structurally similar drugs in the graph. The RGCN model\nwas initially trained without input of any drug features. And the performance\nwas already promising, demonstrating the significant role of the\ndrug-protein/drug-drug relations in the prediction of BBB permeability.\nMoreover, molecular embeddings from a pre-trained knowledge graph were used as\nthe drug features to further enhance the predictive ability of the model.\nFinally, the best performing RGCN model was built with a large number of\nunlabeled drugs integrated into the graph.",
    "descriptor": "",
    "authors": [
      "Yan Ding",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06773"
  },
  {
    "id": "arXiv:2107.06776",
    "title": "How to make qubits speak",
    "abstract": "This is a story about making quantum computers speak, and doing so in a\nquantum-native, compositional and meaning-aware manner. Recently we did\nquestion-answering with an actual quantum computer. We explain what we did,\nstress that this was all done in terms of pictures, and provide many pointers\nto the related literature. In fact, besides natural language, many other things\ncan be implemented in a quantum-native, compositional and meaning-aware manner,\nand we provide the reader with some indications of that broader pictorial\nlandscape, including our account on the notion of compositionality. We also\nprovide some guidance for the actual execution, so that the reader can give it\na go as well.",
    "descriptor": "\nComments: Invited contribution to \"Quantum Computing in the Arts and Humanities\"\n",
    "authors": [
      "Bob Coecke",
      "Giovanni de Felice",
      "Konstantinos Meichanetzidis",
      "Alexis Toumi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06776"
  },
  {
    "id": "arXiv:2107.06782",
    "title": "Clustering and attention model based for Intelligent Trading",
    "abstract": "The foreign exchange market has taken an important role in the global\nfinancial market. While foreign exchange trading brings high-yield\nopportunities to investors, it also brings certain risks. Since the\nestablishment of the foreign exchange market in the 20th century, foreign\nexchange rate forecasting has become a hot issue studied by scholars from all\nover the world. Due to the complexity and number of factors affecting the\nforeign exchange market, technical analysis cannot respond to administrative\nintervention or unexpected events. Our team chose several pairs of foreign\ncurrency historical data and derived technical indicators from 2005 to 2021 as\nthe dataset and established different machine learning models for event-driven\nprice prediction for oversold scenario.",
    "descriptor": "",
    "authors": [
      "Mimansa Rana",
      "Nanxiang Mao",
      "Ming Ao",
      "Xiaohui Wu",
      "Poning Liang",
      "Matloob Khushi"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06782"
  },
  {
    "id": "arXiv:2107.06800",
    "title": "Signed Barcodes for Multi-Parameter Persistence via Rank Decompositions  and Rank-Exact Resolutions",
    "abstract": "In this paper we introduce the signed barcode, a new visual representation of\nthe global structure of the rank invariant of a multi-parameter persistence\nmodule or, more generally, of a poset representation. Like its unsigned\ncounterpart in one-parameter persistence, the signed barcode encodes the rank\ninvariant as a $\\mathbb{Z}$-linear combination of rank invariants of indicator\nmodules supported on segments in the poset. It can also be enriched to encode\nthe generalized rank invariant as a $\\mathbb{Z}$-linear combination of\ngeneralized rank invariants in fixed classes of interval modules. In the paper\nwe develop the theory behind these rank invariant decompositions, showing under\nwhat conditions they exist and are unique -- so the signed barcode is\ncanonically defined. We also connect them to the line of work on generalized\npersistence diagrams via M\\\"obius inversions, deriving explicit formulas to\ncompute a rank decomposition and its associated signed barcode. Finally, we\nshow that, similarly to its unsigned counterpart, the signed barcode has its\nroots in algebra, coming from a projective resolution of the module in some\nexact category. To complete the picture, we show some experimental results that\nillustrate the contribution of the signed barcode in the exploration of\nmulti-parameter persistence modules.",
    "descriptor": "",
    "authors": [
      "Magnus Bakke Botnan",
      "Steffen Oppermann",
      "Steve Oudot"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2107.06800"
  },
  {
    "id": "arXiv:2107.06808",
    "title": "RCDNet: An Interpretable Rain Convolutional Dictionary Network for  Single Image Deraining",
    "abstract": "As a common weather, rain streaks adversely degrade the image quality. Hence,\nremoving rains from an image has become an important issue in the field. To\nhandle such an ill-posed single image deraining task, in this paper, we\nspecifically build a novel deep architecture, called rain convolutional\ndictionary network (RCDNet), which embeds the intrinsic priors of rain streaks\nand has clear interpretability. In specific, we first establish a RCD model for\nrepresenting rain streaks and utilize the proximal gradient descent technique\nto design an iterative algorithm only containing simple operators for solving\nthe model. By unfolding it, we then build the RCDNet in which every network\nmodule has clear physical meanings and corresponds to each operation involved\nin the algorithm. This good interpretability greatly facilitates an easy\nvisualization and analysis on what happens inside the network and why it works\nwell in inference process. Moreover, taking into account the domain gap issue\nin real scenarios, we further design a novel dynamic RCDNet, where the rain\nkernels can be dynamically inferred corresponding to input rainy images and\nthen help shrink the space for rain layer estimation with few rain maps so as\nto ensure a fine generalization performance in the inconsistent scenarios of\nrain types between training and testing data. By end-to-end training such an\ninterpretable network, all involved rain kernels and proximal operators can be\nautomatically extracted, faithfully characterizing the features of both rain\nand clean background layers, and thus naturally lead to better deraining\nperformance. Comprehensive experiments substantiate the superiority of our\nmethod, especially on its well generality to diverse testing scenarios and good\ninterpretability for all its modules. Code is available in\n\\emph{\\url{https://github.com/hongwang01/DRCDNet}}.",
    "descriptor": "",
    "authors": [
      "Hong Wang",
      "Qi Xie",
      "Qian Zhao",
      "Yong Liang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06808"
  },
  {
    "id": "arXiv:2107.06822",
    "title": "General-purpose preconditioning for regularized interior point methods",
    "abstract": "In this paper we present general-purpose preconditioners for regularized\naugmented systems arising from optimization problems, and their corresponding\nnormal equations. We discuss positive definite preconditioners, suitable for CG\nand MINRES. We consider \"sparsifications\" which avoid situations in which\neigenvalues of the preconditioned matrix may become complex. Special attention\nis given to systems arising from the application of regularized interior point\nmethods to linear or nonlinear convex programming problems.",
    "descriptor": "",
    "authors": [
      "Jacek Gondzio",
      "Spyridon Pougkakiotis",
      "John W. Pearson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06822"
  },
  {
    "id": "arXiv:2107.06845",
    "title": "Meta-Optimization of Deep CNN for Image Denoising Using LSTM",
    "abstract": "The recent application of deep learning (DL) to various tasks has seen the\nperformance of classical techniques surpassed by their DL-based counterparts.\nAs a result, DL has equally seen application in the removal of noise from\nimages. In particular, the use of deep feed-forward convolutional neural\nnetworks (DnCNNs) has been investigated for denoising. It utilizes advances in\nDL techniques such as deep architecture, residual learning, and batch\nnormalization to achieve better denoising performance when compared with the\nother classical state-of-the-art denoising algorithms. However, its deep\narchitecture resulted in a huge set of trainable parameters. Meta-optimization\nis a training approach of enabling algorithms to learn to train themselves by\nthemselves. Training algorithms using meta-optimizers have been shown to enable\nalgorithms to achieve better performance when compared to the classical\ngradient descent-based training approach. In this work, we investigate the\napplication of the meta-optimization training approach to the DnCNN denoising\nalgorithm to enhance its denoising capability. Our preliminary experiments on\nsimpler algorithms reveal the prospects of utilizing the meta-optimization\ntraining approach towards the enhancement of the DnCNN denoising capability.",
    "descriptor": "",
    "authors": [
      "Basit O. Alawode",
      "Motaz Alfarraj"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06845"
  },
  {
    "id": "arXiv:1806.00421",
    "title": "Solving the Kolmogorov PDE by means of deep learning",
    "abstract": "Comments: 33 pages, 1 figure Accepted for publication in the Journal of Scientific Computing",
    "descriptor": "\nComments: 33 pages, 1 figure Accepted for publication in the Journal of Scientific Computing\n",
    "authors": [
      "Christian Beck",
      "Sebastian Becker",
      "Philipp Grohs",
      "Nor Jaafari",
      "Arnulf Jentzen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1806.00421"
  },
  {
    "id": "arXiv:1901.11343",
    "title": "Algorithmic counting of nonequivalent compact Huffman codes",
    "abstract": "Algorithmic counting of nonequivalent compact Huffman codes",
    "descriptor": "",
    "authors": [
      "Christian Elsholtz",
      "Clemens Heuberger",
      "Daniel Krenn"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/1901.11343"
  },
  {
    "id": "arXiv:1903.05923",
    "title": "Highly irregular separated nets",
    "abstract": "Comments: 52 pages. A part of this work is an extensive refinement of a part of arXiv:1704.01940. v4: Changes according to referee's comments, correction of minor typos and errors, especially in the volume bound in Lemma 4.10. To appear in the Israel Journal of Mathematics",
    "descriptor": "\nComments: 52 pages. A part of this work is an extensive refinement of a part of arXiv:1704.01940. v4: Changes according to referee's comments, correction of minor typos and errors, especially in the volume bound in Lemma 4.10. To appear in the Israel Journal of Mathematics\n",
    "authors": [
      "Michael Dymond",
      "Vojt\u011bch Kalu\u017ea"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Discrete Mathematics (cs.DM)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/1903.05923"
  },
  {
    "id": "arXiv:1904.08352",
    "title": "MOSNet: Deep Learning based Objective Assessment for Voice Conversion",
    "abstract": "Comments: Accepted to Interspeech2019",
    "descriptor": "\nComments: Accepted to Interspeech2019\n",
    "authors": [
      "Chen-Chou Lo",
      "Szu-Wei Fu",
      "Wen-Chin Huang",
      "Xin Wang",
      "Junichi Yamagishi",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1904.08352"
  },
  {
    "id": "arXiv:1908.03464",
    "title": "Zero-Shot Feature Selection via Transferring Supervised Knowledge",
    "abstract": "Comments: Published in IJDWM21",
    "descriptor": "\nComments: Published in IJDWM21\n",
    "authors": [
      "Zheng Wang",
      "Qiao Wang",
      "Tingzhang Zhao",
      "Xiaojun Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.03464"
  },
  {
    "id": "arXiv:1911.03886",
    "title": "Performance Analysis on Machine Learning-Based Channel Estimation",
    "abstract": "Comments: 11 pages, 10 figures. To appear in IEEE Transactions on Communications",
    "descriptor": "\nComments: 11 pages, 10 figures. To appear in IEEE Transactions on Communications\n",
    "authors": [
      "Kai Mei",
      "Jun Liu",
      "Xiaochen Zhang",
      "Nandana Rajatheva",
      "Jibo Wei"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03886"
  },
  {
    "id": "arXiv:1912.02021",
    "title": "Derandomization and absolute reconstruction for sums of powers of linear  forms",
    "abstract": "Comments: This version takes the referee's comments into account",
    "descriptor": "\nComments: This version takes the referee's comments into account\n",
    "authors": [
      "Pascal Koiran",
      "Mateusz Skomra"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1912.02021"
  },
  {
    "id": "arXiv:1912.10419",
    "title": "Link prediction in dynamic networks using random dot product graphs",
    "abstract": "Link prediction in dynamic networks using random dot product graphs",
    "descriptor": "",
    "authors": [
      "Francesco Sanna Passino",
      "Anna S. Bertiger",
      "Joshua C. Neil",
      "Nicholas A. Heard"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1912.10419"
  },
  {
    "id": "arXiv:2002.07764",
    "title": "Sampling in Software Engineering Research: A Critical Review and  Guidelines",
    "abstract": "Comments: 38 pages, 1 figure, 8 tables, currently under review",
    "descriptor": "\nComments: 38 pages, 1 figure, 8 tables, currently under review\n",
    "authors": [
      "Sebastian Baltes",
      "Paul Ralph"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2002.07764"
  },
  {
    "id": "arXiv:2002.08318",
    "title": "Stochastic generalized Nash equilibrium seeking in merely monotone games",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1912.04165",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1912.04165\n",
    "authors": [
      "Barbara Franci",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.08318"
  },
  {
    "id": "arXiv:2002.09598",
    "title": "A characterization of proportionally representative committees",
    "abstract": "A characterization of proportionally representative committees",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Barton E. Lee"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2002.09598"
  },
  {
    "id": "arXiv:2003.11775",
    "title": "On Structural Parameterizations of Node Kayles",
    "abstract": "Comments: A preliminary version was presented at JCDCG^3 2018. Fix some errors",
    "descriptor": "\nComments: A preliminary version was presented at JCDCG^3 2018. Fix some errors\n",
    "authors": [
      "Yasuaki Kobayashi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2003.11775"
  },
  {
    "id": "arXiv:2004.09860",
    "title": "Gradient discretization of two-phase flows coupled with mechanical  deformation in fractured porous media",
    "abstract": "Gradient discretization of two-phase flows coupled with mechanical  deformation in fractured porous media",
    "descriptor": "",
    "authors": [
      "Francesco Bonaldi",
      "Konstantin Brenner",
      "J\u00e9r\u00f4me Droniou",
      "Roland Masson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.09860"
  },
  {
    "id": "arXiv:2005.07752",
    "title": "Massive MIMO Channel Estimation with Low-Resolution Spatial Sigma-Delta  ADCs",
    "abstract": "Comments: Revision",
    "descriptor": "\nComments: Revision\n",
    "authors": [
      "Shilpa Rao",
      "Gonzalo Seco-Granados",
      "Hessam Pirzadeh",
      "Josef A. Nossek",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2005.07752"
  },
  {
    "id": "arXiv:2005.07778",
    "title": "Access Control for Distributed Ledgers in the Internet of Things: A  Networking Approach",
    "abstract": "Access Control for Distributed Ledgers in the Internet of Things: A  Networking Approach",
    "descriptor": "",
    "authors": [
      "Andrew Cullen",
      "Pietro Ferraro",
      "William Sanders",
      "Luigi Vigneri",
      "Robert Shorten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2005.07778"
  },
  {
    "id": "arXiv:2005.09532",
    "title": "Scalable Privacy-Preserving Distributed Learning",
    "abstract": "Comments: Published at the 21st Privacy Enhancing Technologies Symposium (PETS 2021)",
    "descriptor": "\nComments: Published at the 21st Privacy Enhancing Technologies Symposium (PETS 2021)\n",
    "authors": [
      "David Froelicher",
      "Juan R. Troncoso-Pastoriza",
      "Apostolos Pyrgelis",
      "Sinem Sav",
      "Joao Sa Sousa",
      "Jean-Philippe Bossuat",
      "Jean-Pierre Hubaux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.09532"
  },
  {
    "id": "arXiv:2006.02804",
    "title": "Exploring the Potential of Low-bit Training of Convolutional Neural  Networks",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Kai Zhong",
      "Xuefei Ning",
      "Guohao Dai",
      "Zhenhua Zhu",
      "Tianchen Zhao",
      "Shulin Zeng",
      "Yu Wang",
      "Huazhong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02804"
  },
  {
    "id": "arXiv:2006.05732",
    "title": "Object Detection in the DCT Domain: is Luminance the Solution?",
    "abstract": "Comments: ICPR 2020",
    "descriptor": "\nComments: ICPR 2020\n",
    "authors": [
      "Benjamin Deguerre",
      "Clement Chatelain",
      "Gilles Gasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05732"
  },
  {
    "id": "arXiv:2007.06093",
    "title": "Interval Universal Approximation for Neural Networks",
    "abstract": "Interval Universal Approximation for Neural Networks",
    "descriptor": "",
    "authors": [
      "Zi Wang",
      "Aws Albarghouthi",
      "Gautam Prakriya",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06093"
  },
  {
    "id": "arXiv:2007.09071",
    "title": "A Modular End-to-End Framework for Secure Firmware Updates on Embedded  Systems",
    "abstract": "A Modular End-to-End Framework for Secure Firmware Updates on Embedded  Systems",
    "descriptor": "",
    "authors": [
      "Solon Falas",
      "Charalambos Konstantinou",
      "Maria K. Michael"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2007.09071"
  },
  {
    "id": "arXiv:2008.03564",
    "title": "Online Nash Social Welfare Maximization with Predictions",
    "abstract": "Online Nash Social Welfare Maximization with Predictions",
    "descriptor": "",
    "authors": [
      "Siddhartha Banerjee",
      "Vasilis Gkatzelis",
      "Artur Gorokh",
      "Billy Jin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.03564"
  },
  {
    "id": "arXiv:2008.05177",
    "title": "Statistical Aspects of the Quantum Supremacy Demonstration",
    "abstract": "Comments: 38 pages, 9 figures (v3. some additional analysis), to appear in Statistical Science",
    "descriptor": "\nComments: 38 pages, 9 figures (v3. some additional analysis), to appear in Statistical Science\n",
    "authors": [
      "Yosef Rinott",
      "Tomer Shoham",
      "Gil Kalai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2008.05177"
  },
  {
    "id": "arXiv:2009.01986",
    "title": "Smoothed analysis of the condition number under low-rank perturbations",
    "abstract": "Smoothed analysis of the condition number under low-rank perturbations",
    "descriptor": "",
    "authors": [
      "Rikhav Shah",
      "Sandeep Silwal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2009.01986"
  },
  {
    "id": "arXiv:2009.07884",
    "title": "(Un)clear and (In)conspicuous: The right to opt-out of sale under CCPA",
    "abstract": "(Un)clear and (In)conspicuous: The right to opt-out of sale under CCPA",
    "descriptor": "",
    "authors": [
      "Sean O'Connor",
      "Ryan Nurwono",
      "Aden Siebel",
      "Eleanor Birrell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2009.07884"
  },
  {
    "id": "arXiv:2009.08925",
    "title": "The Infinity Mirror Test for Graph Models",
    "abstract": "Comments: This was submitted to IEEE TKDE 2020, 12 pages and 8 figures",
    "descriptor": "\nComments: This was submitted to IEEE TKDE 2020, 12 pages and 8 figures\n",
    "authors": [
      "Satyaki Sikdar",
      "Daniel Gonzalez",
      "Trenton Ford",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2009.08925"
  },
  {
    "id": "arXiv:2009.13370",
    "title": "Replica Analysis of the Linear Model with Markov or Hidden Markov Signal  Priors",
    "abstract": "Comments: Add MCMC simulations",
    "descriptor": "\nComments: Add MCMC simulations\n",
    "authors": [
      "Lan V. Truong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13370"
  },
  {
    "id": "arXiv:2009.13998",
    "title": "How Do You Want Your Greedy: Simultaneous or Repeated?",
    "abstract": "Comments: Included analysis of RepeatedGreedy and open source Julia package",
    "descriptor": "\nComments: Included analysis of RepeatedGreedy and open source Julia package\n",
    "authors": [
      "Moran Feldman",
      "Christopher Harshaw",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.13998"
  },
  {
    "id": "arXiv:2010.01240",
    "title": "Proving Quantum Programs Correct",
    "abstract": "Comments: version 4 updated DOI (paper content is the same); version 3 (final version) has updated formatting and improved writing; version 2 includes updated acknowledgments and a new appendix with simple SQIR example programs",
    "descriptor": "\nComments: version 4 updated DOI (paper content is the same); version 3 (final version) has updated formatting and improved writing; version 2 includes updated acknowledgments and a new appendix with simple SQIR example programs\n",
    "authors": [
      "Kesha Hietala",
      "Robert Rand",
      "Shih-Han Hung",
      "Liyi Li",
      "Michael Hicks"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.01240"
  },
  {
    "id": "arXiv:2010.04600",
    "title": "Robust Adaptive Control of Linear Parameter-Varying Systems with  Unmatched Uncertainties",
    "abstract": "Robust Adaptive Control of Linear Parameter-Varying Systems with  Unmatched Uncertainties",
    "descriptor": "",
    "authors": [
      "Pan Zhao",
      "Steven Snyder",
      "Naira Hovakimyana",
      "Chengyu Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.04600"
  },
  {
    "id": "arXiv:2010.12570",
    "title": "Eye Tracking Data Collection Protocol for VR for Remotely Located  Subjects using Blockchain and Smart Contracts",
    "abstract": "Comments: 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR). Authors' copy, refer to the doi for more information",
    "descriptor": "\nComments: 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR). Authors' copy, refer to the doi for more information\n",
    "authors": [
      "Efe Bozkir",
      "Shahram Eivazi",
      "Mete Akg\u00fcn",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2010.12570"
  },
  {
    "id": "arXiv:2010.12876",
    "title": "Electromagnetic Source Imaging via a Data-Synthesis-Based Denoising  Autoencoder",
    "abstract": "Comments: 17 pages, 13 figures, and journal",
    "descriptor": "\nComments: 17 pages, 13 figures, and journal\n",
    "authors": [
      "Gexin Huang",
      "Zhu Liang Yu",
      "Wei Wu",
      "Ke Liu",
      "ZhengHui Gu",
      "Feifei Qi",
      "YuanQing Li",
      "Jiawen Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.12876"
  },
  {
    "id": "arXiv:2010.13275",
    "title": "Asymptotic Behavior of Adversarial Training in Binary Classification",
    "abstract": "Comments: V3: additional theoretical results, extensions to correlated features",
    "descriptor": "\nComments: V3: additional theoretical results, extensions to correlated features\n",
    "authors": [
      "Hossein Taheri",
      "Ramtin Pedarsani",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.13275"
  },
  {
    "id": "arXiv:2010.14227",
    "title": "Efficient, Simple and Automated Negative Sampling for Knowledge Graph  Embedding",
    "abstract": "Comments: VLDB Journal accepted. arXiv admin note: text overlap with arXiv:1812.06410",
    "descriptor": "\nComments: VLDB Journal accepted. arXiv admin note: text overlap with arXiv:1812.06410\n",
    "authors": [
      "Yongqi Zhang",
      "Quanming Yao",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.14227"
  },
  {
    "id": "arXiv:2011.04408",
    "title": "SeasonDepth: Cross-Season Monocular Depth Prediction Dataset and  Benchmark under Multiple Environments",
    "abstract": "Comments: 21 pages, 10 figures",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Hanjiang Hu",
      "Baoquan Yang",
      "Zhijian Qiao",
      "Ding Zhao",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.04408"
  },
  {
    "id": "arXiv:2011.05547",
    "title": "Identifying Properties of Real-World Optimisation Problems through a  Questionnaire",
    "abstract": "Comments: Book Chapter (Under review, revised version)",
    "descriptor": "\nComments: Book Chapter (Under review, revised version)\n",
    "authors": [
      "Koen van der Blom",
      "Timo M. Deist",
      "Vanessa Volz",
      "Mariapia Marchi",
      "Yusuke Nojima",
      "Boris Naujoks",
      "Akira Oyama",
      "Tea Tu\u0161ar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.05547"
  },
  {
    "id": "arXiv:2011.08694",
    "title": "Reactive Long Horizon Task Execution via Visual Skill and Precondition  Models",
    "abstract": "Comments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021\n",
    "authors": [
      "Shohin Mukherjee",
      "Chris Paxton",
      "Arsalan Mousavian",
      "Adam Fishman",
      "Maxim Likhachev",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08694"
  },
  {
    "id": "arXiv:2011.14696",
    "title": "On Initial Pools for Deep Active Learning",
    "abstract": "Comments: Accepted at NeurIPS 2020 Preregistration Workshop and included in PMLR v148. 19 pages, 9 figures",
    "descriptor": "\nComments: Accepted at NeurIPS 2020 Preregistration Workshop and included in PMLR v148. 19 pages, 9 figures\n",
    "authors": [
      "Akshay L Chandra",
      "Sai Vikas Desai",
      "Chaitanya Devaguptapu",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14696"
  },
  {
    "id": "arXiv:2012.02344",
    "title": "Perceptual error optimization for Monte Carlo rendering",
    "abstract": "Perceptual error optimization for Monte Carlo rendering",
    "descriptor": "",
    "authors": [
      "Vassillen Chizhov",
      "Iliyan Georgiev",
      "Karol Myszkowski",
      "Gurprit Singh"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2012.02344"
  },
  {
    "id": "arXiv:2012.03709",
    "title": "Reference Knowledgeable Network for Machine Reading Comprehension",
    "abstract": "Reference Knowledgeable Network for Machine Reading Comprehension",
    "descriptor": "",
    "authors": [
      "Yilin Zhao",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.03709"
  },
  {
    "id": "arXiv:2012.08681",
    "title": "Manufactured Solutions for the Method-of-Moments Implementation of the  Electric-Field Integral Equation",
    "abstract": "Manufactured Solutions for the Method-of-Moments Implementation of the  Electric-Field Integral Equation",
    "descriptor": "",
    "authors": [
      "Brian A. Freno",
      "Neil R. Matula",
      "William A. Johnson"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.08681"
  },
  {
    "id": "arXiv:2012.08791",
    "title": "MINIROCKET: A Very Fast (Almost) Deterministic Transform for Time Series  Classification",
    "abstract": "Comments: 10 pages, 11 figures; Updated to accepted version",
    "descriptor": "\nComments: 10 pages, 11 figures; Updated to accepted version\n",
    "authors": [
      "Angus Dempster",
      "Daniel F. Schmidt",
      "Geoffrey I. Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.08791"
  },
  {
    "id": "arXiv:2012.13376",
    "title": "A Physics-Informed Deep Learning Paradigm for Car-Following Models",
    "abstract": "A Physics-Informed Deep Learning Paradigm for Car-Following Models",
    "descriptor": "",
    "authors": [
      "Zhaobin Mo",
      "Xuan Di",
      "Rongye Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.13376"
  },
  {
    "id": "arXiv:2012.13869",
    "title": "Neural Closure Models for Dynamical Systems",
    "abstract": "Comments: 29 pages, 9 figures, 13 pages of supplementary information",
    "descriptor": "\nComments: 29 pages, 9 figures, 13 pages of supplementary information\n",
    "authors": [
      "Abhinav Gupta",
      "Pierre F.J. Lermusiaux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2012.13869"
  },
  {
    "id": "arXiv:2012.14236",
    "title": "Pizza Sharing is PPA-hard",
    "abstract": "Pizza Sharing is PPA-hard",
    "descriptor": "",
    "authors": [
      "Argyrios Deligkas",
      "John Fearnley",
      "Themistoklis Melissourgos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2012.14236"
  },
  {
    "id": "arXiv:2101.00512",
    "title": "Fast solution of fully implicit Runge-Kutta and discontinuous Galerkin  in time for numerical PDEs, Part I: the linear setting",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ben S. Southworth",
      "Oliver Krzysik",
      "Will Pazner",
      "Hans De Sterck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.00512"
  },
  {
    "id": "arXiv:2101.01776",
    "title": "Fast solution of fully implicit Runge-Kutta and discontinuous Galerkin  in time for numerical PDEs, Part II: nonlinearities and DAEs",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ben S. Southworth",
      "Oliver Krzysik",
      "Will Pazner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.01776"
  },
  {
    "id": "arXiv:2101.02137",
    "title": "Smoothed functional-based gradient algorithms for off-policy  reinforcement learning: A non-asymptotic viewpoint",
    "abstract": "Smoothed functional-based gradient algorithms for off-policy  reinforcement learning: A non-asymptotic viewpoint",
    "descriptor": "",
    "authors": [
      "Nithia Vijayan",
      "Prashanth L. A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.02137"
  },
  {
    "id": "arXiv:2101.04798",
    "title": "Convergence analysis of some tent-based schemes for linear hyperbolic  systems",
    "abstract": "Convergence analysis of some tent-based schemes for linear hyperbolic  systems",
    "descriptor": "",
    "authors": [
      "Dow Drake",
      "Jay Gopalakrishnan",
      "Joachim Sch\u00f6berl",
      "Christoph Wintersteiger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.04798"
  },
  {
    "id": "arXiv:2101.05129",
    "title": "Certifiable Risk-Based Engineering Design Optimization",
    "abstract": "Certifiable Risk-Based Engineering Design Optimization",
    "descriptor": "",
    "authors": [
      "Anirban Chaudhuri",
      "Boris Kramer",
      "Matthew Norton",
      "Johannes O. Royset",
      "Karen Willcox"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.05129"
  },
  {
    "id": "arXiv:2101.07067",
    "title": "Data Obsolescence Detection in the Light of Newly Acquired Valid  Observations",
    "abstract": "Data Obsolescence Detection in the Light of Newly Acquired Valid  Observations",
    "descriptor": "",
    "authors": [
      "Salma Chaieb",
      "Ali Ben Mrad",
      "Brahim Hnich",
      "V\u00e9ronique Delcroix"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.07067"
  },
  {
    "id": "arXiv:2101.11156",
    "title": "Fundamental limits and algorithms for sparse linear regression with  sublinear sparsity",
    "abstract": "Comments: 45 pages, 2 figures. Under review for publication. Add some auxiliary proofs",
    "descriptor": "\nComments: 45 pages, 2 figures. Under review for publication. Add some auxiliary proofs\n",
    "authors": [
      "Lan V. Truong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.11156"
  },
  {
    "id": "arXiv:2101.11428",
    "title": "Variational Encoders and Autoencoders : Information-theoretic Inference  and Closed-form Solutions",
    "abstract": "Variational Encoders and Autoencoders : Information-theoretic Inference  and Closed-form Solutions",
    "descriptor": "",
    "authors": [
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.11428"
  },
  {
    "id": "arXiv:2102.00904",
    "title": "Text-to-hashtag Generation using Seq2seq Learning",
    "abstract": "Text-to-hashtag Generation using Seq2seq Learning",
    "descriptor": "",
    "authors": [
      "Augusto Camargo",
      "Wesley Carvalho",
      "Felipe Peressim",
      "Alan Barzilay",
      "Marcelo Finger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.00904"
  },
  {
    "id": "arXiv:2102.04313",
    "title": "Long-time simulations with high fidelity on quantum hardware",
    "abstract": "Comments: Main text: 14 pages, 11 Figures. Appendices: 10 pages, 1 Figure",
    "descriptor": "\nComments: Main text: 14 pages, 11 Figures. Appendices: 10 pages, 1 Figure\n",
    "authors": [
      "Joe Gibbs",
      "Kaitlin Gili",
      "Zo\u00eb Holmes",
      "Benjamin Commeau",
      "Andrew Arrasmith",
      "Lukasz Cincio",
      "Patrick J. Coles",
      "Andrew Sornborger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04313"
  },
  {
    "id": "arXiv:2102.05291",
    "title": "Clusterability as an Alternative to Anchor Points When Learning with  Noisy Labels",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Zhaowei Zhu",
      "Yiwen Song",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05291"
  },
  {
    "id": "arXiv:2102.06377",
    "title": "VET: Identifying and Avoiding UI Exploration Tarpits",
    "abstract": "VET: Identifying and Avoiding UI Exploration Tarpits",
    "descriptor": "",
    "authors": [
      "Wenyu Wang",
      "Wei Yang",
      "Tianyin Xu",
      "Tao Xie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.06377"
  },
  {
    "id": "arXiv:2102.08613",
    "title": "Validation and parameter optimization of a hybrid embedded/homogenized  solid tumor perfusion model",
    "abstract": "Validation and parameter optimization of a hybrid embedded/homogenized  solid tumor perfusion model",
    "descriptor": "",
    "authors": [
      "Johannes Kremheller",
      "Sebastian Brandstaeter",
      "Bernhard A. Schrefler",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.08613"
  },
  {
    "id": "arXiv:2102.08817",
    "title": "Dissecting Supervised Contrastive Learning",
    "abstract": "Comments: ICML 2021 camera ready version",
    "descriptor": "\nComments: ICML 2021 camera ready version\n",
    "authors": [
      "Florian Graf",
      "Christoph D. Hofer",
      "Marc Niethammer",
      "Roland Kwitt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08817"
  },
  {
    "id": "arXiv:2102.11119",
    "title": "The Randomized Competitive Ratio of Weighted $k$-server is at least  Exponential",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Nikhil Ayyadevara",
      "Ashish Chiplunkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.11119"
  },
  {
    "id": "arXiv:2102.12682",
    "title": "Pantomorphic Perspective for Immersive Imagery",
    "abstract": "Comments: 7 pages, 14 figures, 3 tables",
    "descriptor": "\nComments: 7 pages, 14 figures, 3 tables\n",
    "authors": [
      "Jakub Maksymilian Fober"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2102.12682"
  },
  {
    "id": "arXiv:2103.01926",
    "title": "Slow-Growing Trees",
    "abstract": "Slow-Growing Trees",
    "descriptor": "",
    "authors": [
      "Philippe Goulet Coulombe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.01926"
  },
  {
    "id": "arXiv:2103.03158",
    "title": "A Structural Causal Model for MR Images of Multiple Sclerosis",
    "abstract": "Comments: MICCAI 2021",
    "descriptor": "\nComments: MICCAI 2021\n",
    "authors": [
      "Jacob C. Reinhold",
      "Aaron Carass",
      "Jerry L. Prince"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.03158"
  },
  {
    "id": "arXiv:2103.04217",
    "title": "Spectral Tensor Train Parameterization of Deep Learning Layers",
    "abstract": "Comments: Accepted at AISTATS 2021",
    "descriptor": "\nComments: Accepted at AISTATS 2021\n",
    "authors": [
      "Anton Obukhov",
      "Maxim Rakhuba",
      "Alexander Liniger",
      "Zhiwu Huang",
      "Stamatios Georgoulis",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.04217"
  },
  {
    "id": "arXiv:2103.05255",
    "title": "Improving Generalizability in Limited-Angle CT Reconstruction with  Sinogram Extrapolation",
    "abstract": "Improving Generalizability in Limited-Angle CT Reconstruction with  Sinogram Extrapolation",
    "descriptor": "",
    "authors": [
      "Ce Wang",
      "Haimiao Zhang",
      "Qian Li",
      "Kun Shang",
      "Yuanyuan Lyu",
      "Bin Dong",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05255"
  },
  {
    "id": "arXiv:2103.05630",
    "title": "ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis",
    "abstract": "Comments: 17 pages, 11 figures, Accepted to CVPR 2021 (Oral), project webpage: this https URL",
    "descriptor": "\nComments: 17 pages, 11 figures, Accepted to CVPR 2021 (Oral), project webpage: this https URL\n",
    "authors": [
      "Yinan He",
      "Bei Gan",
      "Siyu Chen",
      "Yichun Zhou",
      "Guojun Yin",
      "Luchuan Song",
      "Lu Sheng",
      "Jing Shao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05630"
  },
  {
    "id": "arXiv:2104.00120",
    "title": "Multi-Encoder Learning and Stream Fusion for Transformer-Based  End-to-End Automatic Speech Recognition",
    "abstract": "Comments: accepted at INTERSPEECH 2021",
    "descriptor": "\nComments: accepted at INTERSPEECH 2021\n",
    "authors": [
      "Timo Lohrenz",
      "Zhengyang Li",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.00120"
  },
  {
    "id": "arXiv:2104.03151",
    "title": "Synthesized Trust Learning from Limited Human Feedback for  Human-Load-Reduced Multi-Robot Deployments",
    "abstract": "Comments: 6 pages, 7 figures and in Proc. of RO-MAN 2021",
    "descriptor": "\nComments: 6 pages, 7 figures and in Proc. of RO-MAN 2021\n",
    "authors": [
      "Yijiang Pang",
      "Chao Huang",
      "Rui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.03151"
  },
  {
    "id": "arXiv:2104.03603",
    "title": "AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation,  Recognition and Speaker Diarization in Conference Scenario",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Yihui Fu",
      "Luyao Cheng",
      "Shubo Lv",
      "Yukai Jv",
      "Yuxiang Kong",
      "Zhuo Chen",
      "Yanxin Hu",
      "Lei Xie",
      "Jian Wu",
      "Hui Bu",
      "Xin Xu",
      "Jun Du",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.03603"
  },
  {
    "id": "arXiv:2104.08500",
    "title": "Visual Transformer Pruning",
    "abstract": "Comments: Accepted by the KDD 2021 Workshop on Model Mining",
    "descriptor": "\nComments: Accepted by the KDD 2021 Workshop on Model Mining\n",
    "authors": [
      "Mingjian Zhu",
      "Kai Han",
      "Yehui Tang",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08500"
  },
  {
    "id": "arXiv:2104.09124",
    "title": "DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning",
    "abstract": "DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Yuting Gao",
      "Jia-Xin Zhuang",
      "Ke Li",
      "Hao Cheng",
      "Xiaowei Guo",
      "Feiyue Huang",
      "Rongrong Ji",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.09124"
  },
  {
    "id": "arXiv:2104.09937",
    "title": "Gradient Matching for Domain Generalization",
    "abstract": "Gradient Matching for Domain Generalization",
    "descriptor": "",
    "authors": [
      "Yuge Shi",
      "Jeffrey Seely",
      "Philip H.S. Torr",
      "N. Siddharth",
      "Awni Hannun",
      "Nicolas Usunier",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.09937"
  },
  {
    "id": "arXiv:2104.14540",
    "title": "The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Jamie Watson",
      "Oisin Mac Aodha",
      "Victor Prisacariu",
      "Gabriel Brostow",
      "Michael Firman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14540"
  },
  {
    "id": "arXiv:2105.00769",
    "title": "Partial Information Decomposition via Deficiency for Multivariate  Gaussians",
    "abstract": "Comments: Revised for improved clarity and technical accuracy",
    "descriptor": "\nComments: Revised for improved clarity and technical accuracy\n",
    "authors": [
      "Gabriel Schamberg",
      "Praveen Venkatesh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.00769"
  },
  {
    "id": "arXiv:2105.01161",
    "title": "Approximability of all finite CSPs in the dynamic streaming setting",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.12351",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.12351\n",
    "authors": [
      "Chi-Ning Chou",
      "Alexander Golovnev",
      "Madhu Sudan",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.01161"
  },
  {
    "id": "arXiv:2105.02065",
    "title": "Auxiliary iterative schemes for the discrete operators on de Rham  complex",
    "abstract": "Auxiliary iterative schemes for the discrete operators on de Rham  complex",
    "descriptor": "",
    "authors": [
      "Zhongjie Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.02065"
  },
  {
    "id": "arXiv:2105.03857",
    "title": "Attention-Based 3D Seismic Fault Segmentation Training by a Few 2D Slice  Labels",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "YiMin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Xiao Li",
      "Yingjie Xi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03857"
  },
  {
    "id": "arXiv:2105.04019",
    "title": "Differentiable Sorting Networks for Scalable Sorting and Ranking  Supervision",
    "abstract": "Comments: Published at ICML 2021, Code @ this https URL, Video @ this https URL",
    "descriptor": "\nComments: Published at ICML 2021, Code @ this https URL, Video @ this https URL\n",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04019"
  },
  {
    "id": "arXiv:2105.06005",
    "title": "Data-Driven Strategies for Hierarchical Predictive Control in Unknown  Environments",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2005.05948",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2005.05948\n",
    "authors": [
      "Charlott Vallon",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.06005"
  },
  {
    "id": "arXiv:2105.07621",
    "title": "Style-Restricted GAN: Multi-Modal Translation with Style Restriction  Using Generative Adversarial Networks",
    "abstract": "Comments: 20 pages, 11 figures, 6 tables; Our implementation is available at this https URL",
    "descriptor": "\nComments: 20 pages, 11 figures, 6 tables; Our implementation is available at this https URL\n",
    "authors": [
      "Sho Inoue",
      "Tad Gonsalves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07621"
  },
  {
    "id": "arXiv:2105.08583",
    "title": "Machine Learning in weakly nonlinear systems: A Case study on  Significant wave heights",
    "abstract": "Comments: Significant wave heights forecasting",
    "descriptor": "\nComments: Significant wave heights forecasting\n",
    "authors": [
      "Pujan Pokhrel"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08583"
  },
  {
    "id": "arXiv:2105.08721",
    "title": "A LightGBM based Forecasting of Dominant Wave Periods in Oceanic Waters",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.08583",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.08583\n",
    "authors": [
      "Pujan Pokhrel"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08721"
  },
  {
    "id": "arXiv:2105.08971",
    "title": "Moving Object Segmentation in 3D LiDAR Data: A Learning-based Approach  Exploiting Sequential Data",
    "abstract": "Comments: Accepted by RA-L with IROS 2021",
    "descriptor": "\nComments: Accepted by RA-L with IROS 2021\n",
    "authors": [
      "Xieyuanli Chen",
      "Shijie Li",
      "Benedikt Mersch",
      "Louis Wiesmann",
      "J\u00fcrgen Gall",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.08971"
  },
  {
    "id": "arXiv:2105.11730",
    "title": "Exploring Autoencoder-based Error-bounded Compression for Scientific  Data",
    "abstract": "Exploring Autoencoder-based Error-bounded Compression for Scientific  Data",
    "descriptor": "",
    "authors": [
      "Jinyang Liu",
      "Sheng Di",
      "Kai Zhao",
      "Sian Jin",
      "Dingwen Tao",
      "Xin Liang",
      "Zizhong Chen",
      "Franck Cappello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11730"
  },
  {
    "id": "arXiv:2105.14117",
    "title": "About Explicit Variance Minimization: Training Neural Networks for  Medical Imaging With Limited Data Annotations",
    "abstract": "About Explicit Variance Minimization: Training Neural Networks for  Medical Imaging With Limited Data Annotations",
    "descriptor": "",
    "authors": [
      "Dmitrii Shubin",
      "Danny Eytan",
      "Sebastian D. Goodfellow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14117"
  },
  {
    "id": "arXiv:2105.14150",
    "title": "Annotation Inconsistency and Entity Bias in MultiWOZ",
    "abstract": "Comments: Accepted by SIGDIAL 2021",
    "descriptor": "\nComments: Accepted by SIGDIAL 2021\n",
    "authors": [
      "Kun Qian",
      "Ahmad Beirami",
      "Zhouhan Lin",
      "Ankita De",
      "Alborz Geramifard",
      "Zhou Yu",
      "Chinnadhurai Sankar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14150"
  },
  {
    "id": "arXiv:2105.14232",
    "title": "Identification and Measurement of Technical Debt Requirements in  Software Development: a Systematic Literature Review",
    "abstract": "Identification and Measurement of Technical Debt Requirements in  Software Development: a Systematic Literature Review",
    "descriptor": "",
    "authors": [
      "Ana Melo",
      "Roberta Fagundes",
      "Valentina Lenarduzzi",
      "Wylliams Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14232"
  },
  {
    "id": "arXiv:2105.14759",
    "title": "The x-index: A new citation-distance-based index to measure academic  influence",
    "abstract": "The x-index: A new citation-distance-based index to measure academic  influence",
    "descriptor": "",
    "authors": [
      "Yun Wan",
      "Feng Xiao",
      "Lu Li",
      "Zhenghao Zhong"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14759"
  },
  {
    "id": "arXiv:2106.00390",
    "title": "On the KLM properties of a fuzzy DL with Typicality",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Laura Giordano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00390"
  },
  {
    "id": "arXiv:2106.00411",
    "title": "WebMIaS on Docker: Deploying Math-Aware Search in a Single Line of Code",
    "abstract": "Comments: Accepted to be published in: Intelligent Computer Mathematics 14th International Conference, CICM 2021, Timisoara, Romania, July 26--31, 2021, Proceedings, Fairouz Kamareddine and Claudio Sacerdotti-Coen (eds.), Lecture Notes in Artificial Intelligence, Springer, Cham, 2021",
    "descriptor": "\nComments: Accepted to be published in: Intelligent Computer Mathematics 14th International Conference, CICM 2021, Timisoara, Romania, July 26--31, 2021, Proceedings, Fairouz Kamareddine and Claudio Sacerdotti-Coen (eds.), Lecture Notes in Artificial Intelligence, Springer, Cham, 2021\n",
    "authors": [
      "D\u00e1vid Lupt\u00e1k",
      "V\u00edt Novotn\u00fd",
      "Michal \u0160tef\u00e1nik",
      "Petr Sojka"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00411"
  },
  {
    "id": "arXiv:2106.00718",
    "title": "Public Goods Games in Directed Networks",
    "abstract": "Public Goods Games in Directed Networks",
    "descriptor": "",
    "authors": [
      "Christos Papadimitriou",
      "Binghui Peng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00718"
  },
  {
    "id": "arXiv:2106.01040",
    "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and  Effective Long Document Modeling",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01040"
  },
  {
    "id": "arXiv:2106.02283",
    "title": "Privacy Preference Signals: Past, Present and Future",
    "abstract": "Privacy Preference Signals: Past, Present and Future",
    "descriptor": "",
    "authors": [
      "Maximilian Hils",
      "Daniel W. Woods",
      "Rainer B\u00f6hme"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.02283"
  },
  {
    "id": "arXiv:2106.03089",
    "title": "Referring Transformer: A One-step Approach to Multi-task Visual  Grounding",
    "abstract": "Referring Transformer: A One-step Approach to Multi-task Visual  Grounding",
    "descriptor": "",
    "authors": [
      "Muchen Li",
      "Leonid Sigal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03089"
  },
  {
    "id": "arXiv:2106.03348",
    "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias",
    "abstract": "Comments: 23 pages, adding downstream task results including detection, semantic segmentation, human pose, and video object segmentation",
    "descriptor": "\nComments: 23 pages, adding downstream task results including detection, semantic segmentation, human pose, and video object segmentation\n",
    "authors": [
      "Yufei Xu",
      "Qiming Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03348"
  },
  {
    "id": "arXiv:2106.03445",
    "title": "On groups presented by inverse-closed finite convergent length-reducing  rewriting systems",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Murray Elder",
      "Adam Piggott"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.03445"
  },
  {
    "id": "arXiv:2106.03593",
    "title": "Neural Auction: End-to-End Learning of Auction Mechanisms for E-Commerce  Advertising",
    "abstract": "Comments: To appear in the Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2021",
    "descriptor": "\nComments: To appear in the Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2021\n",
    "authors": [
      "Xiangyu Liu",
      "Chuan Yu",
      "Zhilin Zhang",
      "Zhenzhe Zheng",
      "Yu Rong",
      "Hongtao Lv",
      "Da Huo",
      "Yiqing Wang",
      "Dagui Chen",
      "Jian Xu",
      "Fan Wu",
      "Guihai Chen",
      "Xiaoqiang Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03593"
  },
  {
    "id": "arXiv:2106.04887",
    "title": "Interaction-Grounded Learning",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Tengyang Xie",
      "John Langford",
      "Paul Mineiro",
      "Ida Momennejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04887"
  },
  {
    "id": "arXiv:2106.05761",
    "title": "Valued Authorization Policy Existence Problem: Theory and Experiments",
    "abstract": "Comments: 32 pages, 5 figures. Preliminary version appeared in SACMAT 2021 (this https URL). Some of the theoretical results (algorithms) have been improved. Computational experiments have been added to this version",
    "descriptor": "\nComments: 32 pages, 5 figures. Preliminary version appeared in SACMAT 2021 (this https URL). Some of the theoretical results (algorithms) have been improved. Computational experiments have been added to this version\n",
    "authors": [
      "Jason Crampton",
      "Eduard Eiben",
      "Gregory Gutin",
      "Daniel Karapetyan",
      "Diptapriyo Majumdar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.05761"
  },
  {
    "id": "arXiv:2106.07409",
    "title": "3rd Place Solution for Short-video Face Parsing Challenge",
    "abstract": "3rd Place Solution for Short-video Face Parsing Challenge",
    "descriptor": "",
    "authors": [
      "Xiao Liu",
      "Xiaofei Si",
      "Jiangtao Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07409"
  },
  {
    "id": "arXiv:2106.07900",
    "title": "Augmented Tensor Decomposition with Stochastic Optimization",
    "abstract": "Comments: Fixed some typos",
    "descriptor": "\nComments: Fixed some typos\n",
    "authors": [
      "Chaoqi Yang",
      "Cheng Qian",
      "Navjot Singh",
      "Cao Xiao",
      "M Brandon Westover",
      "Edgar Solomonik",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07900"
  },
  {
    "id": "arXiv:2106.08038",
    "title": "Mean Embeddings with Test-Time Data Augmentation for Ensembling of  Representations",
    "abstract": "Mean Embeddings with Test-Time Data Augmentation for Ensembling of  Representations",
    "descriptor": "",
    "authors": [
      "Arsenii Ashukha",
      "Andrei Atanov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08038"
  },
  {
    "id": "arXiv:2106.08960",
    "title": "Collaborative Training of Acoustic Encoders for Speech Recognition",
    "abstract": "Comments: INTERSPEECH 2021",
    "descriptor": "\nComments: INTERSPEECH 2021\n",
    "authors": [
      "Varun Nagaraja",
      "Yangyang Shi",
      "Ganesh Venkatesh",
      "Ozlem Kalinli",
      "Michael L. Seltzer",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08960"
  },
  {
    "id": "arXiv:2106.09908",
    "title": "Light Lies: Optical Adversarial Attack",
    "abstract": "Comments: 11 pages, 4 figures, author names corrected",
    "descriptor": "\nComments: 11 pages, 4 figures, author names corrected\n",
    "authors": [
      "Kyulim Kim",
      "JeongSoo Kim",
      "Seungri Song",
      "Jun-Ho Choi",
      "Chulmin Joo",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.09908"
  },
  {
    "id": "arXiv:2106.10271",
    "title": "End-to-end Temporal Action Detection with Transformer",
    "abstract": "Comments: Extended version",
    "descriptor": "\nComments: Extended version\n",
    "authors": [
      "Xiaolong Liu",
      "Qimeng Wang",
      "Yao Hu",
      "Xu Tang",
      "Song Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10271"
  },
  {
    "id": "arXiv:2106.13456",
    "title": "Interpreting Criminal Charge Prediction and Its Algorithmic Bias via  Quantum-Inspired Complex Valued Networks",
    "abstract": "Comments: First two authors alphabetically ordered",
    "descriptor": "\nComments: First two authors alphabetically ordered\n",
    "authors": [
      "Abdul Rafae Khan",
      "Jia Xu",
      "Peter Varsanyi",
      "Rachit Pabreja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13456"
  },
  {
    "id": "arXiv:2106.13853",
    "title": "Hierarchical Online Convex Optimization",
    "abstract": "Comments: 23 pages, 1 figure",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Juncheng Wang",
      "Ben Liang",
      "Min Dong",
      "Gary Boudreau",
      "Hatem Abou-zeid"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.13853"
  },
  {
    "id": "arXiv:2106.14132",
    "title": "Robust Pose Transfer with Dynamic Details using Neural Video Rendering",
    "abstract": "Comments: Video link: this https URL",
    "descriptor": "\nComments: Video link: this https URL\n",
    "authors": [
      "Yang-tian Sun",
      "Hao-zhi Huang",
      "Xuan Wang",
      "Yu-kun Lai",
      "Wei Liu",
      "Lin Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.14132"
  },
  {
    "id": "arXiv:2106.15158",
    "title": "End-to-end Waveform Learning Through Joint Optimization of Pulse and  Constellation Shaping",
    "abstract": "End-to-end Waveform Learning Through Joint Optimization of Pulse and  Constellation Shaping",
    "descriptor": "",
    "authors": [
      "Fay\u00e7al Ait Aoudia",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.15158"
  },
  {
    "id": "arXiv:2106.15499",
    "title": "Self-Contrastive Learning",
    "abstract": "Self-Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Sangmin Bae",
      "Sungnyun Kim",
      "Jongwoo Ko",
      "Gihun Lee",
      "Seungjong Noh",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15499"
  },
  {
    "id": "arXiv:2106.15754",
    "title": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "abstract": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Lei Ding",
      "Dong Lin",
      "Shaofu Lin",
      "Jing Zhang",
      "Xiaojie Cui",
      "Yuebin Wang",
      "Hao Tang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15754"
  },
  {
    "id": "arXiv:2107.00649",
    "title": "On the Practicality of Deterministic Epistemic Uncertainty",
    "abstract": "On the Practicality of Deterministic Epistemic Uncertainty",
    "descriptor": "",
    "authors": [
      "Janis Postels",
      "Mattia Segu",
      "Tao Sun",
      "Luc Van Gool",
      "Fisher Yu",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00649"
  },
  {
    "id": "arXiv:2107.01004",
    "title": "AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks",
    "abstract": "AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks",
    "descriptor": "",
    "authors": [
      "Ahmed Benfaid",
      "Nadia Adem",
      "Bassem Khalfi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01004"
  },
  {
    "id": "arXiv:2107.01253",
    "title": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate  Modeling Optimization",
    "abstract": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate  Modeling Optimization",
    "descriptor": "",
    "authors": [
      "Paulito P. Palmes",
      "Akihiro Kishimoto",
      "Radu Marinescu",
      "Parikshit Ram",
      "Elizabeth Daly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01253"
  },
  {
    "id": "arXiv:2107.02067",
    "title": "Distance-based Hyperspherical Classification for Multi-source Open-Set  Domain Adaptation",
    "abstract": "Distance-based Hyperspherical Classification for Multi-source Open-Set  Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Silvia Bucci",
      "Francesco Cappio Borlino",
      "Barbara Caputo",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02067"
  },
  {
    "id": "arXiv:2107.02266",
    "title": "Near-optimal inference in adaptive linear regression",
    "abstract": "Comments: 41 pages, 7 figures",
    "descriptor": "\nComments: 41 pages, 7 figures\n",
    "authors": [
      "Koulik Khamaru",
      "Yash Deshpande",
      "Lester Mackey",
      "Martin J. Wainwright"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02266"
  },
  {
    "id": "arXiv:2107.03158",
    "title": "A Survey on Data Augmentation for Text Classification",
    "abstract": "Comments: 35 pages, 6 figures, 8 tables",
    "descriptor": "\nComments: 35 pages, 6 figures, 8 tables\n",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03158"
  },
  {
    "id": "arXiv:2107.03374",
    "title": "Evaluating Large Language Models Trained on Code",
    "abstract": "Comments: corrected typos, added references, added authors, added acknowledgements",
    "descriptor": "\nComments: corrected typos, added references, added authors, added acknowledgements\n",
    "authors": [
      "Mark Chen",
      "Jerry Tworek",
      "Heewoo Jun",
      "Qiming Yuan",
      "Henrique Ponde de Oliveira Pinto",
      "Jared Kaplan",
      "Harri Edwards",
      "Yuri Burda",
      "Nicholas Joseph",
      "Greg Brockman",
      "Alex Ray",
      "Raul Puri",
      "Gretchen Krueger",
      "Michael Petrov",
      "Heidy Khlaaf",
      "Girish Sastry",
      "Pamela Mishkin",
      "Brooke Chan",
      "Scott Gray",
      "Nick Ryder",
      "Mikhail Pavlov",
      "Alethea Power",
      "Lukasz Kaiser",
      "Mohammad Bavarian",
      "Clemens Winter",
      "Philippe Tillet",
      "Felipe Petroski Such",
      "Dave Cummings",
      "Matthias Plappert",
      "Fotios Chantzis",
      "Elizabeth Barnes",
      "Ariel Herbert-Voss",
      "William Hebgen Guss",
      "Alex Nichol",
      "Alex Paino",
      "Nikolas Tezak",
      "Jie Tang",
      "Igor Babuschkin",
      "Suchir Balaji",
      "Shantanu Jain",
      "William Saunders",
      "Christopher Hesse",
      "Andrew N. Carr",
      "Jan Leike",
      "Josh Achiam",
      "Vedant Misra",
      "Evan Morikawa",
      "Alec Radford",
      "Matthew Knight",
      "Miles Brundage",
      "Mira Murati",
      "Katie Mayer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03374"
  },
  {
    "id": "arXiv:2107.03635",
    "title": "Sublinear Regret for Learning POMDPs",
    "abstract": "Sublinear Regret for Learning POMDPs",
    "descriptor": "",
    "authors": [
      "Yi Xiong",
      "Ningyuan Chen",
      "Xuefeng Gao",
      "Xiang Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.03635"
  },
  {
    "id": "arXiv:2107.03786",
    "title": "Deep Metric Learning Model for Imbalanced Fault Diagnosis",
    "abstract": "Deep Metric Learning Model for Imbalanced Fault Diagnosis",
    "descriptor": "",
    "authors": [
      "Xingtai Gui",
      "Jiyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03786"
  },
  {
    "id": "arXiv:2107.04347",
    "title": "An ontology for the formalization and visualization of scientific  knowledge",
    "abstract": "An ontology for the formalization and visualization of scientific  knowledge",
    "descriptor": "",
    "authors": [
      "Vincenzo Daponte",
      "Gilles Falquet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.04347"
  },
  {
    "id": "arXiv:2107.04422",
    "title": "Likelihood ratio-based policy gradient methods for distorted risk  measures: A non-asymptotic analysis",
    "abstract": "Likelihood ratio-based policy gradient methods for distorted risk  measures: A non-asymptotic analysis",
    "descriptor": "",
    "authors": [
      "Nithia Vijayan",
      "Prashanth L. A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04422"
  },
  {
    "id": "arXiv:2107.04902",
    "title": "Industry and Academic Research in Computer Vision",
    "abstract": "Comments: 8 pages, 9 Figures, 2 Tables",
    "descriptor": "\nComments: 8 pages, 9 Figures, 2 Tables\n",
    "authors": [
      "Iuliia Kotseruba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04902"
  },
  {
    "id": "arXiv:2107.04952",
    "title": "Learn from Anywhere: Rethinking Generalized Zero-Shot Learning with  Limited Supervision",
    "abstract": "Comments: Accepted at IJCAI'21 workshop on Weakly Supervised Representation Learning",
    "descriptor": "\nComments: Accepted at IJCAI'21 workshop on Weakly Supervised Representation Learning\n",
    "authors": [
      "Gaurav Bhatt",
      "Shivam Chandhok",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04952"
  },
  {
    "id": "arXiv:2107.05115",
    "title": "Details Preserving Deep Collaborative Filtering-Based Method for Image  Denoising",
    "abstract": "Details Preserving Deep Collaborative Filtering-Based Method for Image  Denoising",
    "descriptor": "",
    "authors": [
      "Basit O. Alawode",
      "Mudassir Masood",
      "Tarig Ballal",
      "Tareq Al-Naffouri"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05115"
  },
  {
    "id": "arXiv:2107.05307",
    "title": "Real-Time Super-Resolution System of 4K-Video Based on Deep Learning",
    "abstract": "Comments: 8 pages, 7 figures, ASAP",
    "descriptor": "\nComments: 8 pages, 7 figures, ASAP\n",
    "authors": [
      "Yanpeng Cao",
      "Chengcheng Wang",
      "Changjun Song",
      "Yongming Tang",
      "He Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.05307"
  },
  {
    "id": "arXiv:2107.05315",
    "title": "Contrastive Learning for Cold-Start Recommendation",
    "abstract": "Comments: Accepted by ACM Multimedia 2021",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2021\n",
    "authors": [
      "Yinwei Wei",
      "Xiang Wang",
      "Qi Li",
      "Liqiang Nie",
      "Yan Li",
      "Xuanping Li",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.05315"
  },
  {
    "id": "arXiv:2107.05326",
    "title": "Learning interaction rules from multi-animal trajectories via augmented  behavioral models",
    "abstract": "Comments: 22 pages, 4 figures",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Keisuke Fujii",
      "Naoya Takeishi",
      "Kazushi Tsutsui",
      "Emyo Fujioka",
      "Nozomi Nishiumi",
      "Ryoya Tanaka",
      "Mika Fukushiro",
      "Kaoru Ide",
      "Hiroyoshi Kohno",
      "Ken Yoda",
      "Susumu Takahashi",
      "Shizuko Hiryu",
      "Yoshinobu Kawahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05326"
  },
  {
    "id": "arXiv:2107.05348",
    "title": "Zero-shot Visual Question Answering using Knowledge Graph",
    "abstract": "Comments: accepted at the International Semantic Web Conference '21 (ISWC 2021)",
    "descriptor": "\nComments: accepted at the International Semantic Web Conference '21 (ISWC 2021)\n",
    "authors": [
      "Zhuo Chen",
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Jeff Z. Pan",
      "Zonggang Yuan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05348"
  },
  {
    "id": "arXiv:2107.05380",
    "title": "DISCO : efficient unsupervised decoding for discrete natural language  problems via convex relaxation",
    "abstract": "DISCO : efficient unsupervised decoding for discrete natural language  problems via convex relaxation",
    "descriptor": "",
    "authors": [
      "Anish Acharya",
      "Rudrajit Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05380"
  },
  {
    "id": "arXiv:2107.05585",
    "title": "Differentially Private Stochastic Optimization: New Results in Convex  and Non-Convex Settings",
    "abstract": "Differentially Private Stochastic Optimization: New Results in Convex  and Non-Convex Settings",
    "descriptor": "",
    "authors": [
      "Raef Bassily",
      "Crist\u00f3bal Guzm\u00e1n",
      "Michael Menart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05585"
  },
  {
    "id": "arXiv:2107.05722",
    "title": "COPER: a Query-adaptable Semantics-based Search Engine for Persian  COVID-19 Articles",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Reza Khanmohammadi",
      "Mitra Sadat Mirshafiee",
      "Mehdi Allahyari"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.05722"
  },
  {
    "id": "arXiv:2107.05792",
    "title": "What Evidence We Would Miss If We Do Not Use Grey Literature?",
    "abstract": "What Evidence We Would Miss If We Do Not Use Grey Literature?",
    "descriptor": "",
    "authors": [
      "Fernando Kamei",
      "Gustavo Pinto",
      "Igor Wiese",
      "M\u00e1rcio Ribeiro",
      "S\u00e9rgio Soares"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05792"
  },
  {
    "id": "arXiv:2107.05946",
    "title": "HAT: Hierarchical Aggregation Transformers for Person Re-identification",
    "abstract": "Comments: This work has been accepted by ACM International Conference on Multimedia 2021",
    "descriptor": "\nComments: This work has been accepted by ACM International Conference on Multimedia 2021\n",
    "authors": [
      "Guowen Zhang",
      "Pingping Zhang",
      "Jinqing Qi",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05946"
  },
  {
    "id": "arXiv:2107.05975",
    "title": "Detecting when pre-trained nnU-Net models fail silently for Covid-19  lung lesion segmentation",
    "abstract": "Detecting when pre-trained nnU-Net models fail silently for Covid-19  lung lesion segmentation",
    "descriptor": "",
    "authors": [
      "Camila Gonzalez",
      "Karol Gotkowski",
      "Andreas Bucher",
      "Ricarda Fischbach",
      "Isabel Kaltenborn",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05975"
  },
  {
    "id": "arXiv:2107.05992",
    "title": "Identifying Influential Users in Unknown Social Networks for Adaptive  Incentive Allocation Under Budget Restriction",
    "abstract": "Identifying Influential Users in Unknown Social Networks for Adaptive  Incentive Allocation Under Budget Restriction",
    "descriptor": "",
    "authors": [
      "Shiqing Wu",
      "Weihua Li",
      "Hao Shen",
      "Quan Bai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05992"
  },
  {
    "id": "arXiv:2107.06050",
    "title": "Force-in-domain GAN inversion",
    "abstract": "Force-in-domain GAN inversion",
    "descriptor": "",
    "authors": [
      "Guangjie Leng",
      "Yekun Zhu",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06050"
  },
  {
    "id": "arXiv:2107.06051",
    "title": "Rating Facts under Coarse-to-fine Regimes",
    "abstract": "Rating Facts under Coarse-to-fine Regimes",
    "descriptor": "",
    "authors": [
      "Guojun Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06051"
  },
  {
    "id": "arXiv:2107.06067",
    "title": "Generalized \"Square roots of Not\" matrices, their application to the  unveiling of hidden logical operators and to the definition of fully matrix  circular Euler functions",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Eduardo Mizraji"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06067"
  },
  {
    "id": "arXiv:2107.06104",
    "title": "Functional Magnetic Resonance Imaging data augmentation through  conditional ICA",
    "abstract": "Comments: 14 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 14 pages, 5 figures, 7 tables\n",
    "authors": [
      "Badr Tajini",
      "Hugo Richard",
      "Bertrand Thirion"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06104"
  },
  {
    "id": "arXiv:2107.06140",
    "title": "Efficient and Reactive Planning for High Speed Robot Air Hockey",
    "abstract": "Comments: 2021 IEEE/RJS International Conference on Intelligent RObots and Systems (IROS)",
    "descriptor": "\nComments: 2021 IEEE/RJS International Conference on Intelligent RObots and Systems (IROS)\n",
    "authors": [
      "Puze Liu",
      "Davide Tateo",
      "Haitham Bou-Ammar",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06140"
  },
  {
    "id": "arXiv:2107.06149",
    "title": "MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis",
    "abstract": "Comments: The two first authors contribute equally. Project pape: this https URL",
    "descriptor": "\nComments: The two first authors contribute equally. Project pape: this https URL\n",
    "authors": [
      "Haocheng Ren",
      "Hao Zhang",
      "Jia Zheng",
      "Jiaxiang Zheng",
      "Rui Tang",
      "Rui Wang",
      "Hujun Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06149"
  },
  {
    "id": "arXiv:2107.06265",
    "title": "Who is Looking at Whom? Visualizing Gaze Awareness for Remote  Small-Group Conversations",
    "abstract": "Comments: One column, 24 pages",
    "descriptor": "\nComments: One column, 24 pages\n",
    "authors": [
      "Zhenyi He",
      "Ruofei Du",
      "Ken Perlin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06265"
  }
]
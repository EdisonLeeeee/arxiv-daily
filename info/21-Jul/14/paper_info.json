[
  {
    "id": "arXiv:2107.05634",
    "title": "DDCNet-Multires: Effective Receptive Field Guided Multiresolution CNN  for Dense Prediction",
    "abstract": "Dense optical flow estimation is challenging when there are large\ndisplacements in a scene with heterogeneous motion dynamics, occlusion, and\nscene homogeneity. Traditional approaches to handle these challenges include\nhierarchical and multiresolution processing methods. Learning-based optical\nflow methods typically use a multiresolution approach with image warping when a\nbroad range of flow velocities and heterogeneous motion is present. Accuracy of\nsuch coarse-to-fine methods is affected by the ghosting artifacts when images\nare warped across multiple resolutions and by the vanishing problem in smaller\nscene extents with higher motion contrast. Previously, we devised strategies\nfor building compact dense prediction networks guided by the effective\nreceptive field (ERF) characteristics of the network (DDCNet). The DDCNet\ndesign was intentionally simple and compact allowing it to be used as a\nbuilding block for designing more complex yet compact networks. In this work,\nwe extend the DDCNet strategies to handle heterogeneous motion dynamics by\ncascading DDCNet based sub-nets with decreasing extents of their ERF. Our\nDDCNet with multiresolution capability (DDCNet-Multires) is compact without any\nspecialized network layers. We evaluate the performance of the DDCNet-Multires\nnetwork using standard optical flow benchmark datasets. Our experiments\ndemonstrate that DDCNet-Multires improves over the DDCNet-B0 and -B1 and\nprovides optical flow estimates with accuracy comparable to similar lightweight\nlearning-based methods.",
    "descriptor": "\nComments: 27 pages, 10 figures, 2 tables. arXiv admin note: text overlap with arXiv:2107.04715\n",
    "authors": [
      "Ali Salehi",
      "Madhusudhanan Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05634"
  },
  {
    "id": "arXiv:2107.05637",
    "title": "Locally Enhanced Self-Attention: Rethinking Self-Attention as Local and  Context Terms",
    "abstract": "Self-Attention has become prevalent in computer vision models. Inspired by\nfully connected Conditional Random Fields (CRFs), we decompose it into local\nand context terms. They correspond to the unary and binary terms in CRF and are\nimplemented by attention mechanisms with projection matrices. We observe that\nthe unary terms only make small contributions to the outputs, and meanwhile\nstandard CNNs that rely solely on the unary terms achieve great performances on\na variety of tasks. Therefore, we propose Locally Enhanced Self-Attention\n(LESA), which enhances the unary term by incorporating it with convolutions,\nand utilizes a fusion module to dynamically couple the unary and binary\noperations. In our experiments, we replace the self-attention modules with\nLESA. The results on ImageNet and COCO show the superiority of LESA over\nconvolution and self-attention baselines for the tasks of image recognition,\nobject detection, and instance segmentation. The code is made publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Chenglin Yang",
      "Siyuan Qiao",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05637"
  },
  {
    "id": "arXiv:2107.05664",
    "title": "Altruistic Maneuver Planning for Cooperative Autonomous Vehicles Using  Multi-agent Advantage Actor-Critic",
    "abstract": "With the adoption of autonomous vehicles on our roads, we will witness a\nmixed-autonomy environment where autonomous and human-driven vehicles must\nlearn to co-exist by sharing the same road infrastructure. To attain\nsocially-desirable behaviors, autonomous vehicles must be instructed to\nconsider the utility of other vehicles around them in their decision-making\nprocess. Particularly, we study the maneuver planning problem for autonomous\nvehicles and investigate how a decentralized reward structure can induce\naltruism in their behavior and incentivize them to account for the interest of\nother autonomous and human-driven vehicles. This is a challenging problem due\nto the ambiguity of a human driver's willingness to cooperate with an\nautonomous vehicle. Thus, in contrast with the existing works which rely on\nbehavior models of human drivers, we take an end-to-end approach and let the\nautonomous agents to implicitly learn the decision-making process of human\ndrivers only from experience. We introduce a multi-agent variant of the\nsynchronous Advantage Actor-Critic (A2C) algorithm and train agents that\ncoordinate with each other and can affect the behavior of human drivers to\nimprove traffic flow and safety.",
    "descriptor": "\nComments: Accepted to 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2021) - Workshop on Autonomous Driving: Perception, Prediction and Planning\n",
    "authors": [
      "Behrad Toghi",
      "Rodolfo Valiente",
      "Dorsa Sadigh",
      "Ramtin Pedarsani",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05664"
  },
  {
    "id": "arXiv:2107.05666",
    "title": "Stress Classification and Personalization: Getting the most out of the  least",
    "abstract": "Stress detection and monitoring is an active area of research with important\nimplications for the personal, professional, and social health of an\nindividual. Current approaches for affective state classification use\ntraditional machine learning algorithms with features computed from multiple\nsensor modalities. These methods are data-intensive and rely on hand-crafted\nfeatures which impede the practical applicability of these sensor systems in\ndaily lives. To overcome these shortcomings, we propose a novel Convolutional\nNeural Network (CNN) based stress detection and classification framework\nwithout any feature computation using data from only one sensor modality. Our\nmethod is competitive and outperforms current state-of-the-art techniques and\nachieves a classification accuracy of $92.85\\%$ and an $f1$ score of $0.89$.\nThrough our leave-one-subject-out analysis, we also show the importance of\npersonalizing stress models.",
    "descriptor": "\nComments: 4 pages, 4 figures, IEEE International Conference on Wearable and Implantable Body Sensor Networks\n",
    "authors": [
      "Ramesh Kumar Sah",
      "Hassan Ghasemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05666"
  },
  {
    "id": "arXiv:2107.05672",
    "title": "In-Database Regression in Input Sparsity Time",
    "abstract": "Sketching is a powerful dimensionality reduction technique for accelerating\nalgorithms for data analysis. A crucial step in sketching methods is to compute\na subspace embedding (SE) for a large matrix $\\mathbf{A} \\in \\mathbb{R}^{N\n\\times d}$. SE's are the primary tool for obtaining extremely efficient\nsolutions for many linear-algebraic tasks, such as least squares regression and\nlow rank approximation. Computing an SE often requires an explicit\nrepresentation of $\\mathbf{A}$ and running time proportional to the size of\n$\\mathbf{A}$. However, if $\\mathbf{A}= \\mathbf{T}_1 \\Join \\mathbf{T}_2 \\Join\n\\dots \\Join \\mathbf{T}_m$ is the result of a database join query on several\nsmaller tables $\\mathbf{T}_i \\in \\mathbb{R}^{n_i \\times d_i}$, then this\nrunning time can be prohibitive, as $\\mathbf{A}$ itself can have as many as\n$O(n_1 n_2 \\cdots n_m)$ rows.\nIn this work, we design subspace embeddings for database joins which can be\ncomputed significantly faster than computing the join. For the case of a two\ntable join $\\mathbf{A} = \\mathbf{T}_1 \\Join \\mathbf{T}_2$ we give\ninput-sparsity algorithms for computing subspace embeddings, with running time\nbounded by the number of non-zero entries in $\\mathbf{T}_1,\\mathbf{T}_2$. This\nresults in input-sparsity time algorithms for high accuracy regression,\nsignificantly improving upon the running time of prior FAQ-based methods for\nregression. We extend our results to arbitrary joins for the ridge regression\nproblem, also considerably improving the running time of prior methods.\nEmpirically, we apply our method to real datasets and show that it is\nsignificantly faster than existing algorithms.",
    "descriptor": "",
    "authors": [
      "Rajesh Jayaram",
      "Alireza Samadian",
      "David P. Woodruff",
      "Peng Ye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05672"
  },
  {
    "id": "arXiv:2107.05677",
    "title": "Codified audio language modeling learns useful representations for music  information retrieval",
    "abstract": "We demonstrate that language models pre-trained on codified\n(discretely-encoded) music audio learn representations that are useful for\ndownstream MIR tasks. Specifically, we explore representations from Jukebox\n(Dhariwal et al. 2020): a music generation system containing a language model\ntrained on codified audio from 1M songs. To determine if Jukebox's\nrepresentations contain useful information for MIR, we use them as input\nfeatures to train shallow models on several MIR tasks. Relative to\nrepresentations from conventional MIR models which are pre-trained on tagging,\nwe find that using representations from Jukebox as input features yields 30%\nstronger performance on average across four MIR tasks: tagging, genre\nclassification, emotion recognition, and key detection. For key detection, we\nobserve that representations from Jukebox are considerably stronger than those\nfrom models pre-trained on tagging, suggesting that pre-training via codified\naudio language modeling may address blind spots in conventional approaches. We\ninterpret the strength of Jukebox's representations as evidence that modeling\naudio instead of tags provides richer representations for MIR.",
    "descriptor": "\nComments: To appear in the proceedings of ISMIR 2021\n",
    "authors": [
      "Rodrigo Castellon",
      "Chris Donahue",
      "Percy Liang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05677"
  },
  {
    "id": "arXiv:2107.05679",
    "title": "Teaching Design by Contract using Snap!",
    "abstract": "With the progress in deductive program verification research, new tools and\ntechniques have become available to support design-by-contract reasoning about\nnon-trivial programs written in widely-used programming languages. However,\ndeductive program verification remains an activity for experts, with ample\nexperience in programming, specification and verification. We would like to\nchange this situation, by developing program verification techniques that are\navailable to a larger audience. In this paper, we present how we developed\nprototypal program verification support for Snap!. Snap! is a visual\nprogramming language, aiming in particular at high school students. We added\nspecification language constructs in a similar visual style, designed to make\nthe intended semantics clear from the look and feel of the specification\nconstructs. We provide support both for static and dynamic verification of\nSnap! programs. Special attention is given to the error messaging, to make this\nas intuitive as possible.",
    "descriptor": "",
    "authors": [
      "Marieke Huisman",
      "Ra\u00fal E. Monti"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05679"
  },
  {
    "id": "arXiv:2107.05680",
    "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models  with Closed-Form Solutions",
    "abstract": "Generative Adversarial Networks (GANs) are commonly used for modeling complex\ndistributions of data. Both the generators and discriminators of GANs are often\nmodeled by neural networks, posing a non-transparent optimization problem which\nis non-convex and non-concave over the generator and discriminator,\nrespectively. Such networks are often heuristically optimized with gradient\ndescent-ascent (GDA), but it is unclear whether the optimization problem\ncontains any saddle points, or whether heuristic methods can find them in\npractice. In this work, we analyze the training of Wasserstein GANs with\ntwo-layer neural network discriminators through the lens of convex duality, and\nfor a variety of generators expose the conditions under which Wasserstein GANs\ncan be solved exactly with convex optimization approaches, or can be\nrepresented as convex-concave games. Using this convex duality interpretation,\nwe further demonstrate the impact of different activation functions of the\ndiscriminator. Our observations are verified with numerical results\ndemonstrating the power of the convex interpretation, with applications in\nprogressive training of convex architectures corresponding to linear generators\nand quadratic-activation discriminators for CelebA image generation. The code\nfor our experiments is available at https://github.com/ardasahiner/ProCoGAN.",
    "descriptor": "\nComments: First two authors contributed equally to this work; 30 pages, 11 figures\n",
    "authors": [
      "Arda Sahiner",
      "Tolga Ergen",
      "Batu Ozturkler",
      "Burak Bartan",
      "John Pauly",
      "Morteza Mardani",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05680"
  },
  {
    "id": "arXiv:2107.05681",
    "title": "CFM: SIMT Thread Divergence Reduction by Melding Similar Control-Flow  Regions in GPGPU Programs",
    "abstract": "GPGPUs use the Single-Instruction-Multiple-Thread (SIMT) execution model\nwhere a group of threads--wavefront or war--execute instructions in lockstep.\nWhen threads in a group encounter a branching instruction, not all threads in\nthe group take the same path, a phenomenon known as control-flow divergence.\nThe control-flow divergence causes performance degradation because both paths\nof the branch must be executed one after the other. Prior research has\nprimarily addressed this issue through architectural modifications. We observe\nthat certain GPGPU kernels with control-flow divergence have similar\ncontrol-flow structures with similar instructions on both sides of a branch.\nThis structure can be exploited to reduce control-flow divergence by melding\nthe two sides of the branch allowing threads to reconverge early, reducing\ndivergence. In this work, we present CFM, a compiler analysis and\ntransformation framework that can meld divergent control-flow structures with\nsimilar instruction sequences. We show that CFM can reduce the performance\ndegradation from control-flow divergence.",
    "descriptor": "",
    "authors": [
      "Charitha Saumya",
      "Kirshanthan Sundararajah",
      "Milind Kulkarni"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.05681"
  },
  {
    "id": "arXiv:2107.05682",
    "title": "Least-Squares Linear Dilation-Erosion Regressor Trained using Stochastic  Descent Gradient or the Difference of Convex Methods",
    "abstract": "This paper presents a hybrid morphological neural network for regression\ntasks called linear dilation-erosion regression ($\\ell$-DER). In few words, an\n$\\ell$-DER model is given by a convex combination of the composition of linear\nand elementary morphological operators. As a result, they yield continuous\npiecewise linear functions and, thus, are universal approximators. Apart from\nintroducing the $\\ell$-DER models, we present three approaches for training\nthese models: one based on stochastic descent gradient and two based on the\ndifference of convex programming problems. Finally, we evaluate the performance\nof the $\\ell$-DER model using 14 regression tasks. Although the approach based\non SDG revealed faster than the other two, the $\\ell$-DER trained using a\ndisciplined convex-concave programming problem outperformed the others in terms\nof the least mean absolute error score.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Angelica Louren\u00e7o Oliveira",
      "Marcos Eduardo Valle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05682"
  },
  {
    "id": "arXiv:2107.05684",
    "title": "Accenture at CheckThat! 2021: Interesting claim identification and  ranking with contextually sensitive lexical training data augmentation",
    "abstract": "This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.",
    "descriptor": "\nComments: To Appear As: Evan Williams, Paul Rodrigues, Sieu Tran. Accenture at CheckThat! 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation. In: Faggioli et al. Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum. Bucharest, Romania. 21-24 September 2021\n",
    "authors": [
      "Evan Williams",
      "Paul Rodrigues",
      "Sieu Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.05684"
  },
  {
    "id": "arXiv:2107.05686",
    "title": "Representation Learning for Out-Of-Distribution Generalization in  Reinforcement Learning",
    "abstract": "Learning data representations that are useful for various downstream tasks is\na cornerstone of artificial intelligence. While existing methods are typically\nevaluated on downstream tasks such as classification or generative image\nquality, we propose to assess representations through their usefulness in\ndownstream control tasks, such as reaching or pushing objects. By training over\n10,000 reinforcement learning policies, we extensively evaluate to what extent\ndifferent representation properties affect out-of-distribution (OOD)\ngeneralization. Finally, we demonstrate zero-shot transfer of these policies\nfrom simulation to the real world, without any domain randomization or\nfine-tuning. This paper aims to establish the first systematic characterization\nof the usefulness of learned representations for real-world OOD downstream\ntasks.",
    "descriptor": "",
    "authors": [
      "Andrea Dittadi",
      "Frederik Tr\u00e4uble",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Peter Gehler",
      "Ole Winther",
      "Francesco Locatello",
      "Olivier Bachem",
      "Bernhard Sch\u00f6lkopf",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05686"
  },
  {
    "id": "arXiv:2107.05687",
    "title": "Uncertainty-based Query Strategies for Active Learning with Transformers",
    "abstract": "Active learning is the iterative construction of a classification model\nthrough targeted labeling, enabling significant labeling cost savings. As most\nresearch on active learning has been carried out before transformer-based\nlanguage models (\"transformers\") became popular, despite its practical\nimportance, comparably few papers have investigated how transformers can be\ncombined with active learning to date. This can be attributed to the fact that\nusing state-of-the-art query strategies for transformers induces a prohibitive\nruntime overhead, which effectively cancels out, or even outweighs\naforementioned cost savings. In this paper, we revisit uncertainty-based query\nstrategies, which had been largely outperformed before, but are particularly\nsuited in the context of fine-tuning transformers. In an extensive evaluation\non five widely used text classification benchmarks, we show that considerable\nimprovements of up to 14.4 percentage points in area under the learning curve\nare achieved, as well as a final accuracy close to the state of the art for all\nbut one benchmark, using only between 0.4% and 15% of the training data.",
    "descriptor": "",
    "authors": [
      "Christopher Schr\u00f6der",
      "Andreas Niekler",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05687"
  },
  {
    "id": "arXiv:2107.05690",
    "title": "Worst-Case Welfare of Item Pricing in the Tollbooth Problem",
    "abstract": "We study the worst-case welfare of item pricing in the tollbooth problem. The\nproblem was first introduced by Guruswami et al, and is a special case of the\ncombinatorial auction in which (i) each of the $m$ items in the auction is an\nedge of some underlying graph; and (ii) each of the $n$ buyers is single-minded\nand only interested in buying all edges of a single path. We consider the\ncompetitive ratio between the hindsight optimal welfare and the optimal\nworst-case welfare among all item-pricing mechanisms, when the order of the\narriving buyers is adversarial. On the one hand, we prove an $\\Omega(m^{1/8})$\nlower bound of the competitive ratio for general graphs. We show that an\n$m^{\\Omega(1)}$ competitive ratio is unavoidable even if the graph is a grid,\nor if the capacity of every edge is augmented by a constant $c$. On the other\nhand, we study the competitive ratio for special families of graphs. In\nparticular, we improve the ratio when the input graph $G$ is a tree, from 8\n(proved by Cheung and Swamy) to 3. We prove that the ratio is $2$ (tight) when\n$G$ is a cycle and $O(\\log^2 m)$ when $G$ is an outerplanar graph.\nAll positive results above require that the seller can choose a proper\ntie-breaking rule to maximize the welfare. In the paper we also consider the\nsetting where the tie-breaking power is on the buyers' side, i.e. the buyer can\nchoose whether or not to buy her demand path when the total price of edges in\nthe path equals her value. We show that the gap between the two settings is at\nleast a constant even when the underlying graph is a single path (this special\ncase is also known as the highway problem). Meanwhile, in this setting where\nbuyers have the tie-breaking power, we also prove an $O(1)$ upper bound of\ncompetitive ratio for special families of graphs.",
    "descriptor": "",
    "authors": [
      "Zihan Tan",
      "Yifeng Teng",
      "Mingfei Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05690"
  },
  {
    "id": "arXiv:2107.05692",
    "title": "Hidden Cosets and Applications to Unclonable Cryptography",
    "abstract": "In this work, we study a generalization of hidden subspace states to hidden\ncoset states (first introduced by Aaronson and Christiano [STOC '12]). This\nnotion was considered independently by Vidick and Zhang [Eurocrypt '21], in the\ncontext of proofs of quantum knowledge from quantum money schemes. We explore\nunclonable properties of coset states and several applications:\n- We show that assuming indistinguishability obfuscation (iO), hidden coset\nstates possess a certain direct product hardness property, which immediately\nimplies a tokenized signature scheme in the plain model. Previously, it was\nknown only relative to an oracle, from a work of Ben-David and Sattath [QCrypt\n'17].\n- Combining a tokenized signature scheme with extractable witness encryption,\nwe give a construction of an unclonable decryption scheme in the plain model.\nThe latter primitive was recently proposed by Georgiou and Zhandry [ePrint\n'20], who gave a construction relative to a classical oracle.\n- We conjecture that coset states satisfy a certain natural\n(information-theoretic) monogamy-of-entanglement property. Assuming this\nconjecture is true, we remove the requirement for extractable witness\nencryption in our unclonable decryption construction, by relying instead on\ncompute-and-compare obfuscation for the class of unpredictable distributions.\n- Finally, we give a construction of a copy-protection scheme for\npseudorandom functions (PRFs) in the plain model. Our scheme is secure either\nassuming iO, OWF, and extractable witness encryption, or assuming iO, OWF,\ncompute-and-compare obfuscation for the class of unpredictable distributions,\nand the conjectured monogamy property mentioned above. This is the first\nexample of a copy-protection scheme with provable security in the plain model\nfor a class of functions that is not evasive.",
    "descriptor": "",
    "authors": [
      "Andrea Coladangelo",
      "Jiahui Liu",
      "Qipeng Liu",
      "Mark Zhandry"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.05692"
  },
  {
    "id": "arXiv:2107.05693",
    "title": "Quantifying Explainability in NLP and Analyzing Algorithms for  Performance-Explainability Tradeoff",
    "abstract": "The healthcare domain is one of the most exciting application areas for\nmachine learning, but a lack of model transparency contributes to a lag in\nadoption within the industry. In this work, we explore the current art of\nexplainability and interpretability within a case study in clinical text\nclassification, using a task of mortality prediction within MIMIC-III clinical\nnotes. We demonstrate various visualization techniques for fully interpretable\nmethods as well as model-agnostic post hoc attributions, and we provide a\ngeneralized method for evaluating the quality of explanations using infidelity\nand local Lipschitz across model types from logistic regression to BERT\nvariants. With these metrics, we introduce a framework through which\npractitioners and researchers can assess the frontier between a model's\npredictive performance and the quality of its available explanations. We make\nour code available to encourage continued refinement of these methods.",
    "descriptor": "\nComments: To appear at Interpretable ML in Healthcare workshop at ICML 2021. 9 pages (excluding references), 6 figures\n",
    "authors": [
      "Mitchell Naylor",
      "Christi French",
      "Samantha Terker",
      "Uday Kamath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05693"
  },
  {
    "id": "arXiv:2107.05697",
    "title": "Few-shot Language Coordination by Modeling Theory of Mind",
    "abstract": "$\\textit{No man is an island.}$ Humans communicate with a large community by\ncoordinating with different interlocutors within short conversations. This\nability has been understudied by the research on building neural communicative\nagents. We study the task of few-shot $\\textit{language coordination}$: agents\nquickly adapting to their conversational partners' language abilities.\nDifferent from current communicative agents trained with self-play, we require\nthe lead agent to coordinate with a $\\textit{population}$ of agents with\ndifferent linguistic abilities, quickly adapting to communicate with unseen\nagents in the population. This requires the ability to model the partner's\nbeliefs, a vital component of human communication. Drawing inspiration from\ntheory-of-mind (ToM; Premack& Woodruff (1978)), we study the effect of the\nspeaker explicitly modeling the listeners' mental states. The speakers, as\nshown in our experiments, acquire the ability to predict the reactions of their\npartner, which helps it generate instructions that concisely express its\ncommunicative goal. We examine our hypothesis that the instructions generated\nwith ToM modeling yield better communication performance in both a referential\ngame and a language navigation task. Positive results from our experiments hint\nat the importance of explicitly modeling communication as a socio-pragmatic\nprogress.",
    "descriptor": "\nComments: Thirty-eighth International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Hao Zhu",
      "Graham Neubig",
      "Yonatan Bisk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.05697"
  },
  {
    "id": "arXiv:2107.05698",
    "title": "Bayesian Atlas Building with Hierarchical Priors for Subject-specific  Regularization",
    "abstract": "This paper presents a novel hierarchical Bayesian model for unbiased atlas\nbuilding with subject-specific regularizations of image registration. We\ndevelop an atlas construction process that automatically selects parameters to\ncontrol the smoothness of diffeomorphic transformation according to individual\nimage data. To achieve this, we introduce a hierarchical prior distribution on\nregularization parameters that allows multiple penalties on images with various\ndegrees of geometric transformations. We then treat the regularization\nparameters as latent variables and integrate them out from the model by using\nthe Monte Carlo Expectation Maximization (MCEM) algorithm. Another advantage of\nour algorithm is that it eliminates the need for manual parameter tuning, which\ncan be tedious and infeasible. We demonstrate the effectiveness of our model on\n3D brain MR images. Experimental results show that our model provides a sharper\natlas compared to the current atlas building algorithms with single-penalty\nregularizations. Our code is publicly available at\nhttps://github.com/jw4hv/HierarchicalBayesianAtlasBuild.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Jian Wang",
      "Miaomiao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.05698"
  },
  {
    "id": "arXiv:2107.05699",
    "title": "Linear and Reed Solomon Codes Against Adversarial Insertions and  Deletions",
    "abstract": "In this work, we study linear error-correcting codes against adversarial\ninsertion-deletion (insdel) errors. We focus on two different settings:\nLinear codes over small fields: We construct linear codes over\n$\\mathbb{F}_q$, for $q=\\text{poly}(1/\\varepsilon)$, that can efficiently decode\nfrom a $\\delta$ fraction of insdel errors and have rate\n$(1-4\\delta)/8-\\varepsilon$. We also show that by allowing codes over\n$\\mathbb{F}_{q^2}$ that are linear over $\\mathbb{F}_q$, we can improve the rate\nto $(1-\\delta)/4-\\varepsilon$ while not sacrificing efficiency. Using this\nlatter result, we construct fully linear codes over $\\mathbb{F}_2$ that can\nefficiently correct up to $\\delta < 1/54$ fraction of deletions and have rate\n$R = (1 - 54 \\delta)/1216$. Cheng, Guruswami, Haeupler, and Li [CGHL21]\nconstructed codes with (extremely small) rates bounded away from zero that can\ncorrect up to a $\\delta < 1/400$ fraction of insdel errors. They also posed the\nproblem of constructing linear codes that get close to the half-Singleton bound\n(proved in [CGHL21]) over small fields. Thus, our results significantly improve\ntheir construction and get much closer to the bound.\nReed-Solomon codes: We prove that over fields of size $n^{O(k)}$ there are\n$[n,k]$ Reed-Solomon codes that can decode from $n-2k+1$ insdel errors and\nhence attain the half-Singleton bound. We also give a deterministic\nconstruction of such codes over much larger fields (of size $n^{k^{O(k)}}$).\nNevertheless, for $k=O(\\log n /\\log\\log n)$ our construction runs in polynomial\ntime. For the special case $k=2$, which received a lot of attention in the\nliterature, we construct an $[n,2]$ Reed-Solomon code over a field of size\n$O(n^4)$ that can decode from $n-3$ insdel errors. Earlier construction\nrequired an exponential field size. Lastly, we prove that any such construction\nrequires a field of size $\\Omega(n^3)$.",
    "descriptor": "",
    "authors": [
      "Roni Con",
      "Amir Shpilka",
      "Itzhak Tamo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05699"
  },
  {
    "id": "arXiv:2107.05700",
    "title": "Approximating Equilibrium under Constrained Piecewise Linear Concave  Utilities with Applications to Matching Markets",
    "abstract": "We study the equilibrium computation problem in the Fisher market model with\nconstrained piecewise linear concave (PLC) utilities. This general class\ncaptures many well-studied special cases, including markets with PLC utilities,\nmarkets with satiation, and matching markets. For the special case of PLC\nutilities, although the problem is PPAD-hard, Devanur and Kannan (FOCS 2008)\ngave a polynomial-time algorithm when the number of items is constant. Our main\nresult is a fixed parameter approximation scheme for computing an approximate\nequilibrium, where the parameters are the number of agents and the\napproximation accuracy. This provides an answer to an open question by Devanur\nand Kannan for PLC utilities, and gives a simpler and faster algorithm for\nmatching markets as the one by Alaei, Jalaly and Tardos (EC 2017).\nThe main technical idea is to work with the stronger concept of thrifty\nequilibria, and approximating the input utility functions by `robust' utilities\nthat have favorable marginal properties. With some restrictions, the results\nalso extend to the Arrow--Debreu exchange market model.",
    "descriptor": "",
    "authors": [
      "Jugal Garg",
      "Yixin Tao",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.05700"
  },
  {
    "id": "arXiv:2107.05704",
    "title": "How Could Equality and Data Protection Law Shape AI Fairness for People  with Disabilities?",
    "abstract": "This article examines the concept of 'AI fairness' for people with\ndisabilities from the perspective of data protection and equality law. This\nexamination demonstrates that there is a need for a distinctive approach to AI\nfairness that is fundamentally different to that used for other protected\ncharacteristics, due to the different ways in which discrimination and data\nprotection law applies in respect of Disability. We articulate this new agenda\nfor AI fairness for people with disabilities, explaining how combining data\nprotection and equality law creates new opportunities for disabled people's\norganisations and assistive technology researchers alike to shape the use of\nAI, as well as to challenge potential harmful uses.",
    "descriptor": "",
    "authors": [
      "Reuben Binns",
      "Reuben Kirkham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05704"
  },
  {
    "id": "arXiv:2107.05707",
    "title": "Computational modelling and data-driven homogenisation of knitted  membranes",
    "abstract": "Knitting is an effective technique for producing complex three-dimensional\nsurfaces owing to the inherent flexibility of interlooped yarns and recent\nadvances in manufacturing providing better control of local stitch patterns.\nFully yarn-level modelling of large-scale knitted membranes is not feasible.\nTherefore, we consider a two-scale homogenisation approach and model the\nmembrane as a Kirchhoff-Love shell on the macroscale and as Euler-Bernoulli\nrods on the microscale. The governing equations for both the shell and the rod\nare discretised with cubic B-spline basis functions. The solution of the\nnonlinear microscale problem requires a significant amount of time due to the\nlarge deformations and the enforcement of contact constraints, rendering\nconventional online computational homogenisation approaches infeasible. To\nsidestep this problem, we use a pre-trained statistical Gaussian Process\nRegression (GPR) model to map the macroscale deformations to macroscale\nstresses. During the offline learning phase, the GPR model is trained by\nsolving the microscale problem for a sufficiently rich set of deformation\nstates obtained by either uniform or Sobol sampling. The trained GPR model\nencodes the nonlinearities and anisotropies present in the microscale and\nserves as a material model for the macroscale Kirchhoff-Love shell. After\nverifying and validating the different components of the proposed approach, we\nintroduce several examples involving membranes subjected to tension and shear\nto demonstrate its versatility and good performance.",
    "descriptor": "\nComments: 23 pages, 14 figures\n",
    "authors": [
      "Sumudu Herath",
      "Xiao Xiao",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05707"
  },
  {
    "id": "arXiv:2107.05712",
    "title": "A Closer Look at the Adversarial Robustness of Information Bottleneck  Models",
    "abstract": "We study the adversarial robustness of information bottleneck models for\nclassification. Previous works showed that the robustness of models trained\nwith information bottlenecks can improve upon adversarial training. Our\nevaluation under a diverse range of white-box $l_{\\infty}$ attacks suggests\nthat information bottlenecks alone are not a strong defense strategy, and that\nprevious results were likely influenced by gradient obfuscation.",
    "descriptor": "",
    "authors": [
      "Iryna Korshunova",
      "David Stutz",
      "Alexander A. Alemi",
      "Olivia Wiles",
      "Sven Gowal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05712"
  },
  {
    "id": "arXiv:2107.05717",
    "title": "Sparsifying, Shrinking and Splicing for Minimum Path Cover in  Parameterized Linear Time",
    "abstract": "A minimum path cover (MPC) of a directed acyclic graph (DAG) $G = (V,E)$ is a\nminimum-size set of paths that together cover all the vertices of the DAG.\nComputing an MPC is a basic polynomial problem, dating back to Dilworth's and\nFulkerson's results in the 1950s. Since the size $k$ of an MPC (also known as\nthe width) can be small in practical applications, research has also studied\nalgorithms whose complexity is parameterized on $k$. We obtain two new MPC\nparameterized algorithms for DAGs running in time $O(k^2|V|\\log{|V|} + |E|)$\nand $O(k^3|V| + |E|)$. We also obtain a parallel algorithm running in $O(k^2|V|\n+ |E|)$ parallel steps and using $O(\\log{|V|})$ processors (in the PRAM model).\nOur latter two algorithms are the first solving the problem in parameterized\nlinear time. Finally, we present an algorithm running in time $O(k^2|V|)$ for\ntransforming any MPC to another MPC using less than $2|V|$ distinct edges,\nwhich we prove to be asymptotically tight. As such, we also obtain edge\nsparsification algorithms preserving the width of the DAG with the same running\ntime as our MPC algorithms. At the core of all our algorithms we interleave the\nusage of three techniques: transitive sparsification, shrinking of a path\ncover, and the splicing of a set of paths along a given path.",
    "descriptor": "",
    "authors": [
      "Manuel C\u00e1ceres",
      "Massimo Cairo",
      "Brendan Mumey",
      "Romeo Rizzi",
      "Alexandru I. Tomescu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05717"
  },
  {
    "id": "arXiv:2107.05720",
    "title": "SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking",
    "abstract": "In neural Information Retrieval, ongoing research is directed towards\nimproving the first retriever in ranking pipelines. Learning dense embeddings\nto conduct retrieval using efficient approximate nearest neighbors methods has\nproven to work well. Meanwhile, there has been a growing interest in learning\nsparse representations for documents and queries, that could inherit from the\ndesirable properties of bag-of-words models such as the exact matching of terms\nand the efficiency of inverted indexes. In this work, we present a new\nfirst-stage ranker based on explicit sparsity regularization and a\nlog-saturation effect on term weights, leading to highly sparse representations\nand competitive results with respect to state-of-the-art dense and sparse\nmethods. Our approach is simple, trained end-to-end in a single stage. We also\nexplore the trade-off between effectiveness and efficiency, by controlling the\ncontribution of the sparsity regularization.",
    "descriptor": "\nComments: 5 pages, SIGIR'21 short paper\n",
    "authors": [
      "Thibault Formal",
      "Benjamin Piwowarski",
      "St\u00e9phane Clinchant"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.05720"
  },
  {
    "id": "arXiv:2107.05722",
    "title": "COPER a query-adaptable Semantics-based Search Engine for Persian  COVID-19 Articles",
    "abstract": "With the surge of pretrained language models, a new pathway has been opened\nto incorporate Persian text contextual information. Meanwhile, as many other\ncountries, including Iran, are fighting against COVID-19, a plethora of\nCOVID-19 related articles has been published in Iranian Healthcare magazines to\nbetter inform the public of the situation. However, finding answers in this\nsheer volume of information is an extremely difficult task. In this paper, we\ncollected a large dataset of these articles, leveraged different BERT\nvariations as well as other keyword models such as BM25 and TF-IDF, and created\na search engine to sift through these documents and rank them, given a user's\nquery. Our final search engine consists of a ranker and a re-ranker, which\nadapts itself to the query. We fine-tune our models using Semantic Textual\nSimilarity and evaluate them with standard task metrics. Our final method\noutperforms the rest by a considerable margin.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Reza Khanmohammadi",
      "Mitra Sadat Mirshafiee",
      "Mehdi Allahyari"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.05722"
  },
  {
    "id": "arXiv:2107.05727",
    "title": "Efficient edge-preserving methods for dynamic inverse problems",
    "abstract": "We consider efficient methods for computing solutions to dynamic inverse\nproblems, where both the quantities of interest and the forward operator\n(measurement process) may change at different time instances but we want to\nsolve for all the images simultaneously. We are interested in large-scale\nill-posed problems that are made more challenging by their dynamic nature and,\npossibly, by the limited amount of available data per measurement step. To\nremedy these difficulties, we apply regularization methods that enforce\nsimultaneous regularization in space and time (such as edge enhancement at each\ntime instant and proximity at consecutive time instants) and achieve this with\nlow computational cost and enhanced accuracy. More precisely, we develop\niterative methods based on a majorization-minimization (MM) strategy with\nquadratic tangent majorant, which allows the resulting least squares problem to\nbe solved with a generalized Krylov subspace (GKS) method; the regularization\nparameter can be defined automatically and efficiently at each iteration.\nNumerical examples from a wide range of applications, such as limited-angle\ncomputerized tomography (CT), space-time image deblurring, and photoacoustic\ntomography (PAT), illustrate the effectiveness of the described approaches.",
    "descriptor": "\nComments: 30 pages, 10 figure, 3 tables\n",
    "authors": [
      "Mirjeta Pasha",
      "Arvind K. Saibaba",
      "Silvia Gazzola",
      "Malena I. Espanol",
      "Eric de Sturler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05727"
  },
  {
    "id": "arXiv:2107.05728",
    "title": "Toward Efficient Transfer Learning in 6G",
    "abstract": "6G networks will greatly expand the support for data-oriented, autonomous\napplications for over the top (OTT) and networking use cases. The success of\nthese use cases will depend on the availability of big data sets which is not\npractical in many real scenarios due to the highly dynamic behavior of systems\nand the cost of data collection procedures. Transfer learning (TL) is a\npromising approach to deal with these challenges through the sharing of\nknowledge among diverse learning algorithms. with TL, the learning rate and\nlearning accuracy can be considerably improved. However, there are\nimplementation challenges to efficiently deploy and utilize TL in 6G. In this\npaper, we initiate this discussion by providing some performance metrics to\nmeasure the TL success. Then, we show how infrastructure, application,\nmanagement, and training planes of 6G can be adapted to handle TL. We provide\nexamples of TL in 6G and highlight the spatio-temporal features of data in 6G\nthat can lead to efficient TL. By simulation results, we demonstrate how\ntransferring the quantized neural network weights between two use cases can\nmake a trade-off between overheads and performance and attain more efficient TL\nin 6G. We also provide a list of future research directions in TL for 6G.",
    "descriptor": "",
    "authors": [
      "Saeedeh Parsaeefard",
      "Alberto Leon-Garcia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05728"
  },
  {
    "id": "arXiv:2107.05729",
    "title": "Generalization of graph network inferences in higher-order probabilistic  graphical models",
    "abstract": "Probabilistic graphical models provide a powerful tool to describe complex\nstatistical structure, with many real-world applications in science and\nengineering from controlling robotic arms to understanding neuronal\ncomputations. A major challenge for these graphical models is that inferences\nsuch as marginalization are intractable for general graphs. These inferences\nare often approximated by a distributed message-passing algorithm such as\nBelief Propagation, which does not always perform well on graphs with cycles,\nnor can it always be easily specified for complex continuous probability\ndistributions. Such difficulties arise frequently in expressive graphical\nmodels that include intractable higher-order interactions. In this paper we\nconstruct iterative message-passing algorithms using Graph Neural Networks\ndefined on factor graphs to achieve fast approximate inference on graphical\nmodels that involve many-variable interactions. Experimental results on several\nfamilies of graphical models demonstrate the out-of-distribution generalization\ncapability of our method to different sized graphs, and indicate the domain in\nwhich our method gains advantage over Belief Propagation.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Yicheng Fei",
      "Xaq Pitkow"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05729"
  },
  {
    "id": "arXiv:2107.05731",
    "title": "Detecting Ideal Instagram Influencer Using Social Network Analysis",
    "abstract": "Social Media is a key aspect of modern society where people share their\nthoughts, views, feelings and sentiments. Over the last few years, the\ninflation in popularity of social media has resulted in a monumental increase\nin data. Users use this medium to express their thoughts, feelings, and\nopinions on a wide variety of subjects, including politics and celebrities.\nSocial Media has thus evolved into a lucrative platform for companies to expand\ntheir scope and improve their prospects. The paper focuses on social network\nanalysis (SNA) for a real-world online marketing strategy. The study\ncontributes by comparing various centrality measures to identify the most\ncentral nodes in the network and uses a linear threshold model to understand\nthe spreading behaviour of individual users. In conclusion, the paper\ncorrelates different centrality measures and spreading behaviour to identify\nthe most influential user in the network",
    "descriptor": "",
    "authors": [
      "M.M.H Dihyat",
      "K Malik",
      "M.A Khan",
      "B Imran"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05731"
  },
  {
    "id": "arXiv:2107.05736",
    "title": "Affect Expression Behaviour Analysis in the Wild using Consensual  Collaborative Training",
    "abstract": "Facial expression recognition (FER) in the wild is crucial for building\nreliable human-computer interactive systems. However, annotations of large\nscale datasets in FER has been a key challenge as these datasets suffer from\nnoise due to various factors like crowd sourcing, subjectivity of annotators,\npoor quality of images, automatic labelling based on key word search etc. Such\nnoisy annotations impede the performance of FER due to the memorization ability\nof deep networks. During early learning stage, deep networks fit on clean data.\nThen, eventually, they start overfitting on noisy labels due to their\nmemorization ability, which limits FER performance. This report presents\nConsensual Collaborative Training (CCT) framework used in our submission to\nexpression recognition track of the Affective Behaviour Analysis in-the-wild\n(ABAW) 2021 competition. CCT co-trains three networks jointly using a convex\ncombination of supervision loss and consistency loss, without making any\nassumption about the noise distribution. A dynamic transition mechanism is used\nto move from supervision loss in early learning to consistency loss for\nconsensus of predictions among networks in the later stage. Co-training reduces\noverall error, and consistency loss prevents overfitting to noisy samples. The\nperformance of the model is validated on challenging Aff-Wild2 dataset for\ncategorical expression classification. Our code is made publicly available at\nhttps://github.com/1980x/ABAW2021DMACS.",
    "descriptor": "\nComments: 7 pages, 2 figures. arXiv admin note: substantial text overlap with arXiv:2009.14440. substantial text overlap with arXiv:2107.04746\n",
    "authors": [
      "Darshan Gera",
      "S Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05736"
  },
  {
    "id": "arXiv:2107.05738",
    "title": "Demonstration of Faceted Search on Scholarly Knowledge Graphs",
    "abstract": "Scientists always look for the most accurate and relevant answer to their\nqueries on the scholarly literature. Traditional scholarly search systems list\ndocuments instead of providing direct answers to the search queries. As data in\nknowledge graphs are not acquainted semantically, they are not\nmachine-readable. Therefore, a search on scholarly knowledge graphs ends up in\na full-text search, not a search in the content of scholarly literature. In\nthis demo, we present a faceted search system that retrieves data from a\nscholarly knowledge graph, which can be compared and filtered to better satisfy\nuser information needs. Our practice's novelty is that we use dynamic facets,\nwhich means facets are not fixed and will change according to the content of a\ncomparison.",
    "descriptor": "\nComments: 2 pages, 1 figure, WWW 2021 Demo. arXiv admin note: substantial text overlap with arXiv:2107.05447\n",
    "authors": [
      "Golsa Heidari",
      "Ahmad Ramadan",
      "Markus Stocker",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.05738"
  },
  {
    "id": "arXiv:2107.05745",
    "title": "Adapting to Misspecification in Contextual Bandits",
    "abstract": "A major research direction in contextual bandits is to develop algorithms\nthat are computationally efficient, yet support flexible, general-purpose\nfunction approximation. Algorithms based on modeling rewards have shown strong\nempirical performance, but typically require a well-specified model, and can\nfail when this assumption does not hold. Can we design algorithms that are\nefficient and flexible, yet degrade gracefully in the face of model\nmisspecification? We introduce a new family of oracle-efficient algorithms for\n$\\varepsilon$-misspecified contextual bandits that adapt to unknown model\nmisspecification -- both for finite and infinite action settings. Given access\nto an online oracle for square loss regression, our algorithm attains optimal\nregret and -- in particular -- optimal dependence on the misspecification\nlevel, with no prior knowledge. Specializing to linear contextual bandits with\ninfinite actions in $d$ dimensions, we obtain the first algorithm that achieves\nthe optimal $O(d\\sqrt{T} + \\varepsilon\\sqrt{d}T)$ regret bound for unknown\nmisspecification level $\\varepsilon$.\nOn a conceptual level, our results are enabled by a new optimization-based\nperspective on the regression oracle reduction framework of Foster and Rakhlin,\nwhich we anticipate will find broader use.",
    "descriptor": "\nComments: Appeared at NeurIPS 2020\n",
    "authors": [
      "Dylan J. Foster",
      "Claudio Gentile",
      "Mehryar Mohri",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05745"
  },
  {
    "id": "arXiv:2107.05746",
    "title": "Computational Hardness of the Hylland-Zeckhauser Scheme",
    "abstract": "We study the complexity of the classic Hylland-Zeckhauser scheme [HZ'79] for\none-sided matching markets. We show that the problem of finding an\n$\\epsilon$-approximate equilibrium in the HZ scheme is PPAD-hard, and this\nholds even when $\\epsilon$ is polynomially small and when each agent has no\nmore than four distinct utility values. Our hardness result, when combined with\nthe PPAD membership result of [VY'21], resolves the approximation complexity of\nthe HZ scheme. We also show that the problem of approximating the optimal\nsocial welfare (the weight of the matching) achievable by HZ equilibria within\na certain constant factor is NP-hard.",
    "descriptor": "",
    "authors": [
      "Thomas Chen",
      "Xi Chen",
      "Binghui Peng",
      "Mihalis Yannakakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05746"
  },
  {
    "id": "arXiv:2107.05747",
    "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft  winner-take-all networks",
    "abstract": "State-of-the-art artificial neural networks (ANNs) require labelled data or\nfeedback between layers, are often biologically implausible, and are vulnerable\nto adversarial attacks that humans are not susceptible to. On the other hand,\nHebbian learning in winner-take-all (WTA) networks, is unsupervised,\nfeed-forward, and biologically plausible. However, an objective optimization\ntheory for WTA networks has been missing, except under very limiting\nassumptions. Here we derive formally such a theory, based on biologically\nplausible but generic ANN elements. Through Hebbian learning, network\nparameters maintain a Bayesian generative model of the data. There is no\nsupervisory loss function, but the network does minimize cross-entropy between\nits activations and the input distribution. The key is a \"soft\" WTA where there\nis no absolute \"hard\" winner neuron, and a specific type of Hebbian-like\nplasticity of weights and biases. We confirm our theory in practice, where, in\nhandwritten digit (MNIST) recognition, our Hebbian algorithm, SoftHebb,\nminimizes cross-entropy without having access to it, and outperforms the more\nfrequently used, hard-WTA-based method. Strikingly, it even outperforms\nsupervised end-to-end backpropagation, under certain conditions. Specifically,\nin a two-layered network, SoftHebb outperforms backpropagation when the\ntraining dataset is only presented once, when the testing data is noisy, and\nunder gradient-based adversarial attacks. Adversarial attacks that confuse\nSoftHebb are also confusing to the human eye. Finally, the model can generate\ninterpolations of objects from its input distribution.",
    "descriptor": "",
    "authors": [
      "Timoleon Moraitis",
      "Dmitry Toichkin",
      "Yansong Chua",
      "Qinghai Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.05747"
  },
  {
    "id": "arXiv:2107.05748",
    "title": "Evaluation of an Inflated Beam Model Applied to Everted Tubes",
    "abstract": "Everted tubes have often been modeled as inflated beams to determine\ntransverse and axial buckling conditions. This paper seeks to validate the\nassumption that an everted tube can be modeled in this way. The tip deflections\nof everted and uneverted beams under transverse cantilever loads are compared\nwith a tip deflection model that was first developed for aerospace\napplications. LDPE and silicone coated nylon beams were tested; everted and\nuneverted beams showed similar tip deflection. The literature model best fit\nthe tip deflection of LDPE tubes with an average tip deflection error of 6 mm,\nwhile the nylon tubes had an average tip deflection error of 16.4 mm. Everted\nbeams of both materials buckled at 83% of the theoretical buckling condition\nwhile straight beams collapsed at 109% of the theoretical buckling condition.\nThe curvature of everted beams was estimated from a tip load and a known\ndisplacement showing relative errors of 14.2% and 17.3% for LDPE and nylon\nbeams respectively. This paper shows a numerical method for determining\ninflated beam deflection. It also provides an iterative method for computing\nstatic tip pose and applied wall forces in a known environment.",
    "descriptor": "",
    "authors": [
      "Joel Hwee",
      "Andrew Lewis",
      "Allison Raines",
      "Blake Hannaford"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05748"
  },
  {
    "id": "arXiv:2107.05749",
    "title": "Resurrecting Address Clustering in Bitcoin",
    "abstract": "Blockchain analysis is essential for understanding how cryptocurrencies like\nBitcoin are used in practice, and address clustering is a cornerstone of\nblockchain analysis. However, current techniques rely on heuristics that have\nnot been rigorously evaluated or optimized. In this paper, we tackle several\nchallenges of change address identification and clustering. First, we build a\nground truth set of transactions with known change from the Bitcoin blockchain\nthat can be used to validate the efficacy of individual change address\ndetection heuristics. Equipped with this data set, we develop new techniques to\npredict change outputs with low false positive rates. After applying our\nprediction model to the Bitcoin blockchain, we analyze the resulting clustering\nand develop ways to detect and prevent cluster collapse. Finally, we assess the\nimpact our enhanced clustering has on two exemplary applications.",
    "descriptor": "",
    "authors": [
      "Malte M\u00f6ser",
      "Arvind Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05749"
  },
  {
    "id": "arXiv:2107.05753",
    "title": "Noisy searching: simple, fast and correct",
    "abstract": "This work revisits the multiplicative weights update technique (MWU) which\nhas a variety of applications, especially in learning and searching algorithms.\nIn particular, the Bayesian update method is a well known version of MWU that\nis particularly applicable for the problem of searching in a given domain. An\nideal scenario for that method is when the input distribution is known a priori\nand each single update maximizes the information gain. In this work we consider\ntwo search domains - linear orders (sorted arrays) and graphs, where the aim of\nthe search is to locate an unknown target by performing as few queries as\npossible. Searching such domains is well understood when each query provides a\ncorrect answer and the input target distribution is uniform. Hence, we consider\ntwo generalizations: the noisy search both with arbitrary and adversarial\n(i.e., unknown) target distributions. We obtain several results providing full\ncharacterization of the query complexities in the three settings: adversarial\nMonte Carlo, adversarial Las Vegas and distributional Las Vegas. Our algorithms\neither improve, simplify or patch earlier ambiguities in the literature - see\nthe works of Emamjomeh-Zadeh et al. [STOC 2016], Dereniowski et. al. [SOSA@SODA\n2019] and Ben-Or and Hassidim [FOCS 2008]. In particular, all algorithms give\nstrategies that provide the optimal number of queries up to lower-order terms.\nOur technical contribution lies in providing generic search techniques that are\nable to deal with the fact that, in general, queries guarantee only suboptimal\ninformation gain.",
    "descriptor": "",
    "authors": [
      "Dariusz Dereniowski",
      "Aleksander \u0141ukasiewicz",
      "Przemys\u0142aw Uzna\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05753"
  },
  {
    "id": "arXiv:2107.05754",
    "title": "EvoBA: An Evolution Strategy as a Strong Baseline forBlack-Box  Adversarial Attacks",
    "abstract": "Recent work has shown how easily white-box adversarial attacks can be applied\nto state-of-the-art image classifiers. However, real-life scenarios resemble\nmore the black-box adversarial conditions, lacking transparency and usually\nimposing natural, hard constraints on the query budget.\nWe propose $\\textbf{EvoBA}$, a black-box adversarial attack based on a\nsurprisingly simple evolutionary search strategy. $\\textbf{EvoBA}$ is\nquery-efficient, minimizes $L_0$ adversarial perturbations, and does not\nrequire any form of training.\n$\\textbf{EvoBA}$ shows efficiency and efficacy through results that are in\nline with much more complex state-of-the-art black-box attacks such as\n$\\textbf{AutoZOOM}$. It is more query-efficient than $\\textbf{SimBA}$, a simple\nand powerful baseline black-box attack, and has a similar level of complexity.\nTherefore, we propose it both as a new strong baseline for black-box\nadversarial attacks and as a fast and general tool for gaining empirical\ninsight into how robust image classifiers are with respect to $L_0$ adversarial\nperturbations.\nThere exist fast and reliable $L_2$ black-box attacks, such as\n$\\textbf{SimBA}$, and $L_{\\infty}$ black-box attacks, such as\n$\\textbf{DeepSearch}$. We propose $\\textbf{EvoBA}$ as a query-efficient $L_0$\nblack-box adversarial attack which, together with the aforementioned methods,\ncan serve as a generic tool to assess the empirical robustness of image\nclassifiers. The main advantages of such methods are that they run fast, are\nquery-efficient, and can easily be integrated in image classifiers development\npipelines.\nWhile our attack minimises the $L_0$ adversarial perturbation, we also report\n$L_2$, and notice that we compare favorably to the state-of-the-art $L_2$\nblack-box attack, $\\textbf{AutoZOOM}$, and of the $L_2$ strong baseline,\n$\\textbf{SimBA}$.",
    "descriptor": "",
    "authors": [
      "Andrei Ilie",
      "Marius Popescu",
      "Alin Stefanescu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05754"
  },
  {
    "id": "arXiv:2107.05756",
    "title": "Reinforcement Learning based Proactive Control for Transmission Grid  Resilience to Wildfire",
    "abstract": "Power grid operation subject to an extreme event requires decision-making by\nhuman operators under stressful condition with high cognitive load. Decision\nsupport under adverse dynamic events, specially if forecasted, can be\nsupplemented by intelligent proactive control. Power system operation during\nwildfires require resiliency-driven proactive control for load shedding, line\nswitching and resource allocation considering the dynamics of the wildfire and\nfailure propagation. However, possible number of line- and load-switching in a\nlarge system during an event make traditional prediction-driven and stochastic\napproaches computationally intractable, leading operators to often use greedy\nalgorithms. We model and solve the proactive control problem as a Markov\ndecision process and introduce an integrated testbed for spatio-temporal\nwildfire propagation and proactive power-system operation. We transform the\nenormous wildfire-propagation observation space and utilize it as part of a\nheuristic for proactive de-energization of transmission assets. We integrate\nthis heuristic with a reinforcement-learning based proactive policy for\ncontrolling the generating assets. Our approach allows this controller to\nprovide setpoints for a part of the generation fleet, while a myopic operator\ncan determine the setpoints for the remaining set, which results in a symbiotic\naction. We evaluate our approach utilizing the IEEE 24-node system mapped on a\nhypothetical terrain. Our results show that the proposed approach can help the\noperator to reduce load loss during an extreme event, reduce power flow through\nlines that are to be de-energized, and reduce the likelihood of infeasible\npower-flow solutions, which would indicate violation of short-term thermal\nlimits of transmission lines.",
    "descriptor": "",
    "authors": [
      "Salah U. Kadir",
      "Subir Majumder",
      "Ajay D. Chhokra",
      "Abhishek Dubey",
      "Himanshu Neema",
      "Aron Laszka",
      "Anurag K. Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05756"
  },
  {
    "id": "arXiv:2107.05757",
    "title": "Kernel Continual Learning",
    "abstract": "This paper introduces kernel continual learning, a simple but effective\nvariant of continual learning that leverages the non-parametric nature of\nkernel methods to tackle catastrophic forgetting. We deploy an episodic memory\nunit that stores a subset of samples for each task to learn task-specific\nclassifiers based on kernel ridge regression. This does not require memory\nreplay and systematically avoids task interference in the classifiers. We\nfurther introduce variational random features to learn a data-driven kernel for\neach task. To do so, we formulate kernel continual learning as a variational\ninference problem, where a random Fourier basis is incorporated as the latent\nvariable. The variational posterior distribution over the random Fourier basis\nis inferred from the coreset of each task. In this way, we are able to generate\nmore informative kernels specific to each task, and, more importantly, the\ncoreset size can be reduced to achieve more compact memory, resulting in more\nefficient continual learning based on episodic memory. Extensive evaluation on\nfour benchmarks demonstrates the effectiveness and promise of kernels for\ncontinual learning.",
    "descriptor": "\nComments: accepted to ICML 2021\n",
    "authors": [
      "Mohammad Mahdi Derakhshani",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05757"
  },
  {
    "id": "arXiv:2107.05760",
    "title": "Asking Clarifying Questions Based on Negative Feedback in Conversational  Search",
    "abstract": "Users often need to look through multiple search result pages or reformulate\nqueries when they have complex information-seeking needs. Conversational search\nsystems make it possible to improve user satisfaction by asking questions to\nclarify users' search intents. This, however, can take significant effort to\nanswer a series of questions starting with \"what/why/how\". To quickly identify\nuser intent and reduce effort during interactions, we propose an intent\nclarification task based on yes/no questions where the system needs to ask the\ncorrect question about intents within the fewest conversation turns. In this\ntask, it is essential to use negative feedback about the previous questions in\nthe conversation history. To this end, we propose a Maximum-Marginal-Relevance\n(MMR) based BERT model (MMR-BERT) to leverage negative feedback based on the\nMMR principle for the next clarifying question selection. Experiments on the\nQulac dataset show that MMR-BERT outperforms state-of-the-art baselines\nsignificantly on the intent identification task and the selected questions also\nachieve significantly better performance in the associated document retrieval\ntasks.",
    "descriptor": "\nComments: In the proceedings of ICTIR'21\n",
    "authors": [
      "Keping Bi",
      "Qingyao Ai",
      "W. Bruce Croft"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.05760"
  },
  {
    "id": "arXiv:2107.05761",
    "title": "Faster Math Functions, Soundly",
    "abstract": "Standard library implementations of functions like sin and exp optimize for\naccuracy, not speed, because they are intended for general-purpose use. But\napplications tolerate inaccuracy from cancellation, rounding error, and\nsingularities-sometimes even very high error-and many application could\ntolerate error in function implementations as well. This raises an intriguing\npossibility: speeding up numerical code by tuning standard function\nimplementations. This paper thus introduces OpTuner, an automatic method for\nselecting the best implementation of mathematical functions at each use site.\nOpTuner assembles dozens of implementations for the standard mathematical\nfunctions from across the speed-accuracy spectrum. OpTuner then uses error\nTaylor series and integer linear programming to compute optimal assignments of\nfunction implementation to use site and presents the user with a speed-accuracy\nPareto curve they can use to speed up their code. In a case study on the\nPOV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a\nwhole program speedup of 9% with no change in the program output (whereas human\nefforts result in slower code and lower-quality output). On a broader study of\n37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and\ndemonstrates speed-ups of 107% for negligible decreases in accuracy and of up\nto 438% for error-tolerant applications.",
    "descriptor": "",
    "authors": [
      "Ian Briggs",
      "Pavel Panchekha"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05761"
  },
  {
    "id": "arXiv:2107.05762",
    "title": "Strategic Instrumental Variable Regression: Recovering Causal  Relationships From Strategic Responses",
    "abstract": "Machine Learning algorithms often prompt individuals to strategically modify\ntheir observable attributes to receive more favorable predictions. As a result,\nthe distribution the predictive model is trained on may differ from the one it\noperates on in deployment. While such distribution shifts, in general, hinder\naccurate predictions, our work identifies a unique opportunity associated with\nshifts due to strategic responses: We show that we can use strategic responses\neffectively to recover causal relationships between the observable features and\noutcomes we wish to predict. More specifically, we study a game-theoretic model\nin which a principal deploys a sequence of models to predict an outcome of\ninterest (e.g., college GPA) for a sequence of strategic agents (e.g., college\napplicants). In response, strategic agents invest efforts and modify their\nfeatures for better predictions. In such settings, unobserved confounding\nvariables can influence both an agent's observable features (e.g., high school\nrecords) and outcomes. Therefore, standard regression methods generally produce\nbiased estimators. In order to address this issue, our work establishes a novel\nconnection between strategic responses to machine learning models and\ninstrumental variable (IV) regression, by observing that the sequence of\ndeployed models can be viewed as an instrument that affects agents' observable\nfeatures but does not directly influence their outcomes. Therefore, two-stage\nleast squares (2SLS) regression can recover the causal relationships between\nobservable features and outcomes. Beyond causal recovery, we can build on our\n2SLS method to address two additional relevant optimization objectives: agent\noutcome maximization and predictive risk minimization. Finally, our numerical\nsimulations on semi-synthetic data show that our methods significantly\noutperform OLS regression in causal relationship estimation.",
    "descriptor": "",
    "authors": [
      "Keegan Harris",
      "Daniel Ngo",
      "Logan Stapleton",
      "Hoda Heidari",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05762"
  },
  {
    "id": "arXiv:2107.05768",
    "title": "Combiner: Full Attention Transformer with Sparse Computation Cost",
    "abstract": "Transformers provide a class of expressive architectures that are extremely\neffective for sequence modeling. However, the key limitation of transformers is\ntheir quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to\nthe sequence length in attention layers, which restricts application in\nextremely long sequences. Most existing approaches leverage sparsity or\nlow-rank assumptions in the attention matrix to reduce cost, but sacrifice\nexpressiveness. Instead, we propose Combiner, which provides full attention\ncapability in each attention head while maintaining low computation and memory\ncomplexity. The key idea is to treat the self-attention mechanism as a\nconditional expectation over embeddings at each location, and approximate the\nconditional distribution with a structured factorization. Each location can\nattend to all other locations, either via direct attention, or through indirect\nattention to abstractions, which are again conditional expectations of\nembeddings from corresponding local regions. We show that most sparse attention\npatterns used in existing sparse transformers are able to inspire the design of\nsuch factorization for full attention, resulting in the same sub-quadratic cost\n($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in\nreplacement for attention layers in existing transformers and can be easily\nimplemented in common frameworks. An experimental evaluation on both\nautoregressive and bidirectional sequence tasks demonstrates the effectiveness\nof this approach, yielding state-of-the-art results on several image and text\nmodeling tasks.",
    "descriptor": "",
    "authors": [
      "Hongyu Ren",
      "Hanjun Dai",
      "Zihang Dai",
      "Mengjiao Yang",
      "Jure Leskovec",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05768"
  },
  {
    "id": "arXiv:2107.05770",
    "title": "A conservative and energy stable discontinuous spectral element method  for the shifted wave equation in second order form",
    "abstract": "In this paper, we develop a provably energy stable and conservative\ndiscontinuous spectral element method for the shifted wave equation in second\norder form. The proposed method combines the advantages and central ideas of\nvery successful numerical techniques, the summation-by-parts finite difference\nmethod, the spectral method and the discontinuous Galerkin method. We prove\nenergy-stability, discrete conservation principle, and derive error estimates\nin the energy norm for the (1+1)-dimensions shifted wave equation in second\norder form. The energy-stability results, discrete conservation principle, and\nthe error estimates generalise to multiple dimensions using tensor products of\nquadrilateral and hexahedral elements. Numerical experiments, in\n(1+1)-dimensions and (2+1)-dimensions, verify the theoretical results and\ndemonstrate optimal convergence of $L^2$ numerical errors at subsonic, sonic\nand supersonic regimes.",
    "descriptor": "",
    "authors": [
      "Kenneth Duru",
      "Siyang Wang",
      "Kenny Wiratama"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05770"
  },
  {
    "id": "arXiv:2107.05772",
    "title": "On \u03bb-backbone coloring of cliques with tree backbones in linear  time",
    "abstract": "A $\\lambda$-backbone coloring of a graph $G$ with its subgraph (also called a\nbackbone) $H$ is a function $c \\colon V(G) \\rightarrow \\{1,\\dots, k\\}$ ensuring\nthat $c$ is a proper coloring of $G$ and for each $\\{u,v\\} \\in E(H)$ it holds\nthat $|c(u) - c(v)| \\ge \\lambda$. In this paper we propose a way to color\ncliques with tree and forest backbones in linear time that the largest color\ndoes not exceed $\\max\\{n, 2 \\lambda\\} + \\Delta(H)^2 \\lceil\\log{n} \\rceil$. This\nresult improves on the previously existing approximation algorithms as it is\n$(\\Delta(H)^2 \\lceil\\log{n} \\rceil)$-absolutely approximate, i.e. with an\nadditive error over the optimum. We also present an infinite family of trees\n$T$ with $\\Delta(T) = 3$ for which the coloring of cliques with backbones $T$\nrequire to use at least $\\max\\{n, 2 \\lambda\\} + \\Omega(\\log{n})$ colors for\n$\\lambda$ close to $\\frac{n}{2}$.",
    "descriptor": "\nComments: 22 pages, 3figures\n",
    "authors": [
      "Krzysztof Michalik",
      "Krzysztof Turowski"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.05772"
  },
  {
    "id": "arXiv:2107.05774",
    "title": "Primitive Rateless Codes",
    "abstract": "In this paper, we propose primitive rateless (PR) codes. A PR code is\ncharacterized by the message length and a primitive polynomial over\n$\\mathbf{GF}(2)$, which can generate a potentially limitless number of coded\nsymbols. We show that codewords of a PR code truncated at any arbitrary length\ncan be represented as subsequences of a maximum-length sequence ($m$-sequence).\nWe characterize the Hamming weight distribution of PR codes and their duals and\nshow that for a properly chosen primitive polynomial, the Hamming weight\ndistribution of the PR code can be well approximated by the truncated binomial\ndistribution. We further find a lower bound on the minimum Hamming weight of PR\ncodes and show that there always exists a PR code that can meet this bound for\nany desired codeword length. We provide a list of primitive polynomials for\nmessage lengths up to $40$ and show that the respective PR codes closely meet\nthe Gilbert-Varshamov bound at various rates. Simulation results show that PR\ncodes can achieve similar block error rates as their BCH counterparts at\nvarious signal-to-noise ratios (SNRs) and code rates. PR codes are\nrate-compatible and can generate as many coded symbols as required; thus,\ndemonstrating a truly rateless performance.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transaction on Communications, July 2021\n",
    "authors": [
      "Mahyar Shirvanimoghaddam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05774"
  },
  {
    "id": "arXiv:2107.05775",
    "title": "Fast and Explicit Neural View Synthesis",
    "abstract": "We study the problem of novel view synthesis of a scene comprised of 3D\nobjects. We propose a simple yet effective approach that is neither continuous\nnor implicit, challenging recent trends on view synthesis. We demonstrate that\nalthough continuous radiance field representations have gained a lot of\nattention due to their expressive power, our simple approach obtains comparable\nor even better novel view reconstruction quality comparing with\nstate-of-the-art baselines while increasing rendering speed by over 400x. Our\nmodel is trained in a category-agnostic manner and does not require\nscene-specific optimization. Therefore, it is able to generalize novel view\nsynthesis to object categories not seen during training. In addition, we show\nthat with our simple formulation, we can use view synthesis as a\nself-supervision signal for efficient learning of 3D geometry without explicit\n3D supervision.",
    "descriptor": "",
    "authors": [
      "Pengsheng Guo",
      "Miguel Angel Bautista",
      "Alex Colburn",
      "Liang Yang",
      "Daniel Ulbricht",
      "Joshua M. Susskind",
      "Qi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05775"
  },
  {
    "id": "arXiv:2107.05777",
    "title": "An active dendritic tree can mitigate fan-in limitations in  superconducting neurons",
    "abstract": "Superconducting electronic circuits have much to offer with regard to\nneuromorphic hardware. Superconducting quantum interference devices (SQUIDs)\ncan serve as an active element to perform the thresholding operation of a\nneuron's soma. However, a SQUID has a response function that is periodic in the\napplied signal. We show theoretically that if one restricts the total input to\na SQUID to maintain a monotonically increasing response, a large fraction of\nsynapses must be active to drive a neuron to threshold. We then demonstrate\nthat an active dendritic tree (also based on SQUIDs) can significantly reduce\nthe fraction of synapses that must be active to drive the neuron to threshold.\nIn this context, the inclusion of a dendritic tree provides the dual benefits\nof enhancing the computational abilities of each neuron and allowing the neuron\nto spike with sparse input activity.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Bryce A. Primavera",
      "Jeffrey M. Shainline"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.05777"
  },
  {
    "id": "arXiv:2107.05778",
    "title": "DefGraspSim: Simulation-based grasping of 3D deformable objects",
    "abstract": "Robotic grasping of 3D deformable objects (e.g., fruits/vegetables, internal\norgans, bottles/boxes) is critical for real-world applications such as food\nprocessing, robotic surgery, and household automation. However, developing\ngrasp strategies for such objects is uniquely challenging. In this work, we\nefficiently simulate grasps on a wide range of 3D deformable objects using a\nGPU-based implementation of the corotational finite element method (FEM). To\nfacilitate future research, we open-source our simulated dataset (34 objects,\n1e5 Pa elasticity range, 6800 grasp evaluations, 1.1M grasp measurements), as\nwell as a code repository that allows researchers to run our full FEM-based\ngrasp evaluation pipeline on arbitrary 3D object models of their choice. We\nalso provide a detailed analysis on 6 object primitives. For each primitive, we\nmethodically describe the effects of different grasp strategies, compute a set\nof performance metrics (e.g., deformation, stress) that fully capture the\nobject response, and identify simple grasp features (e.g., gripper\ndisplacement, contact area) measurable by robots prior to pickup and predictive\nof these performance metrics. Finally, we demonstrate good correspondence\nbetween grasps on simulated objects and their real-world counterparts.",
    "descriptor": "\nComments: 11 pages, 19 figures. For associated website and code repository, see this https URL and this https URL Published in DO-Sim: Workshop on Deformable Object Simulation in Robotics at Robotics: Science and Systems (RSS) 2021\n",
    "authors": [
      "Isabella Huang",
      "Yashraj Narang",
      "Clemens Eppner",
      "Balakumar Sundaralingam",
      "Miles Macklin",
      "Tucker Hermans",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05778"
  },
  {
    "id": "arXiv:2107.05780",
    "title": "Detect and Defense Against Adversarial Examples in Deep Learning using  Natural Scene Statistics and Adaptive Denoising",
    "abstract": "Despite the enormous performance of deepneural networks (DNNs), recent\nstudies have shown theirvulnerability to adversarial examples (AEs), i.e.,\ncare-fully perturbed inputs designed to fool the targetedDNN. Currently, the\nliterature is rich with many ef-fective attacks to craft such AEs. Meanwhile,\nmany de-fenses strategies have been developed to mitigate thisvulnerability.\nHowever, these latter showed their effec-tiveness against specific attacks and\ndoes not general-ize well to different attacks. In this paper, we proposea\nframework for defending DNN classifier against ad-versarial samples. The\nproposed method is based on atwo-stage framework involving a separate detector\nanda denoising block. The detector aims to detect AEs bycharacterizing them\nthrough the use of natural scenestatistic (NSS), where we demonstrate that\nthese statis-tical features are altered by the presence of\nadversarialperturbations. The denoiser is based on block matching3D (BM3D)\nfilter fed by an optimum threshold valueestimated by a convolutional neural\nnetwork (CNN) toproject back the samples detected as AEs into theirdata\nmanifold. We conducted a complete evaluation onthree standard datasets namely\nMNIST, CIFAR-10 andTiny-ImageNet. The experimental results show that\ntheproposed defense method outperforms the state-of-the-art defense techniques\nby improving the robustnessagainst a set of attacks under black-box, gray-box\nand white-box settings. The source code is available at:\nhttps://github.com/kherchouche-anouar/2DAE",
    "descriptor": "",
    "authors": [
      "Anouar Kherchouche",
      "Sid Ahmed Fezza",
      "Wassim Hamidouche"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.05780"
  },
  {
    "id": "arXiv:2107.05782",
    "title": "Improving Speech Translation by Understanding and Learning from the  Auxiliary Text Translation Task",
    "abstract": "Pretraining and multitask learning are widely used to improve the speech to\ntext translation performance. In this study, we are interested in training a\nspeech to text translation model along with an auxiliary text to text\ntranslation task. We conduct a detailed analysis to understand the impact of\nthe auxiliary task on the primary task within the multitask learning framework.\nOur analysis confirms that multitask learning tends to generate similar decoder\nrepresentations from different modalities and preserve more information from\nthe pretrained text translation modules. We observe minimal negative transfer\neffect between the two tasks and sharing more parameters is helpful to transfer\nknowledge from the text task to the speech task. The analysis also reveals that\nthe modality representation difference at the top decoder layers is still not\nnegligible, and those layers are critical for the translation quality. Inspired\nby these findings, we propose three methods to improve translation quality.\nFirst, a parameter sharing and initialization strategy is proposed to enhance\ninformation sharing between the tasks. Second, a novel attention-based\nregularization is proposed for the encoders and pulls the representations from\ndifferent modalities closer. Third, an online knowledge distillation is\nproposed to enhance the knowledge transfer from the text to the speech task.\nOur experiments show that the proposed approach improves translation\nperformance by more than 2 BLEU over a strong baseline and achieves\nstate-of-the-art results on the \\textsc{MuST-C} English-German, English-French\nand English-Spanish language pairs.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Yun Tang",
      "Juan Pino",
      "Xian Li",
      "Changhan Wang",
      "Dmitriy Genzel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05782"
  },
  {
    "id": "arXiv:2107.05783",
    "title": "Non-Visual Cooking: Exploring Practices and Challenges of Meal  Preparation by People with Visual Impairments",
    "abstract": "The reliance on vision for tasks related to cooking and eating healthy can\npresent barriers to cooking for oneself and achieving proper nutrition. There\nhas been little research exploring cooking practices and challenges faced by\npeople with visual impairments. We present a content analysis of 122 YouTube\nvideos to highlight the cooking practices of visually impaired people, and we\ndescribe detailed practices for 12 different cooking activities (e.g., cutting\nand chopping, measuring, testing food for doneness). Based on the cooking\npractices, we also conducted semi-structured interviews with 12 visually\nimpaired people who have cooking experience and show existing challenges,\nconcerns, and risks in cooking (e.g., tracking the status of tasks in progress,\nverifying whether things are peeled or cleaned thoroughly). We further discuss\nopportunities to support the current practices and improve the independence of\npeople with visual impairments in cooking (e.g., zero-touch interactions for\ncooking). Overall, our findings provide guidance for future research exploring\nvarious assistive technologies to help people cook without relying on vision.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Franklin Mingzhe Li",
      "Jamie Dorst",
      "Peter Cederberg",
      "Patrick Carrington"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05783"
  },
  {
    "id": "arXiv:2107.05784",
    "title": "An Interval Arithmetic for Robust Error Estimation",
    "abstract": "Interval arithmetic is a simple way to compute a mathematical expression to\nan arbitrary accuracy, widely used for verifying floating-point computations.\nYet this simplicity belies challenges. Some inputs violate preconditions or\ncause domain errors. Others cause the algorithm to enter an infinite loop and\nfail to compute a ground truth. Plus, finding valid inputs is itself a\nchallenge when invalid and unsamplable points make up the vast majority of the\ninput space. These issues can make interval arithmetic brittle and\ntemperamental.\nThis paper introduces three extensions to interval arithmetic to address\nthese challenges. Error intervals express rich notions of input validity and\nindicate whether all or some points in an interval violate implicit or explicit\npreconditions. Movability flags detect futile recomputations and prevent\ntimeouts by indicating whether a higher-precision recomputation will yield a\nmore accurate result. Andinput search restricts sampling to valid, samplable\npoints, so they are easier to find. We compare these extensions to the\nstate-of-the-art technical computing software Mathematica, and demonstrate that\nour extensions are able to resolve 60.3% more challenging inputs, return 10.2x\nfewer completely indeterminate results, and avoid 64 cases of fatal error.",
    "descriptor": "",
    "authors": [
      "Oliver Flatt",
      "Pavel Panchekha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05784"
  },
  {
    "id": "arXiv:2107.05786",
    "title": "Carle's Game: An Open-Ended Challenge in Exploratory Machine Creativity",
    "abstract": "This paper is both an introduction and an invitation. It is an introduction\nto CARLE, a Life-like cellular automata simulator and reinforcement learning\nenvironment. It is also an invitation to Carle's Game, a challenge in\nopen-ended machine exploration and creativity. Inducing machine agents to excel\nat creating interesting patterns across multiple cellular automata universes is\na substantial challenge, and approaching this challenge is likely to require\ncontributions from the fields of artificial life, AI, machine learning, and\ncomplexity, at multiple levels of interest. Carle's Game is based on machine\nagent interaction with CARLE, a Cellular Automata Reinforcement Learning\nEnvironment. CARLE is flexible, capable of simulating any of the 262,144\ndifferent rules defining Life-like cellular automaton universes. CARLE is also\nfast and can simulate automata universes at a rate of tens of thousands of\nsteps per second through a combination of vectorization and GPU acceleration.\nFinally, CARLE is simple. Compared to high-fidelity physics simulators and\nvideo games designed for human players, CARLE's two-dimensional grid world\noffers a discrete, deterministic, and atomic universal playground, despite its\ncomplexity. In combination with CARLE, Carle's Game offers an initial set of\nagent policies, learning and meta-learning algorithms, and reward wrappers that\ncan be tailored to encourage exploration or specific tasks.",
    "descriptor": "\nComments: 8 pages, 11 figures, accepted to IEEE Conference on Games 2021: 978-1-6654-3886-5/21/$31.00 \\copyright 2021 IEEE\n",
    "authors": [
      "Q. Tyrell Davis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05786"
  },
  {
    "id": "arXiv:2107.05787",
    "title": "Data-Driven Low-Rank Neural Network Compression",
    "abstract": "Despite many modern applications of Deep Neural Networks (DNNs), the large\nnumber of parameters in the hidden layers makes them unattractive for\ndeployment on devices with storage capacity constraints. In this paper we\npropose a Data-Driven Low-rank (DDLR) method to reduce the number of parameters\nof pretrained DNNs and expedite inference by imposing low-rank structure on the\nfully connected layers, while controlling for the overall accuracy and without\nrequiring any retraining. We pose the problem as finding the lowest rank\napproximation of each fully connected layer with given performance guarantees\nand relax it to a tractable convex optimization problem. We show that it is\npossible to significantly reduce the number of parameters in common DNN\narchitectures with only a small reduction in classification accuracy. We\ncompare DDLR with Net-Trim, which is another data-driven DNN compression\ntechnique based on sparsity and show that DDLR consistently produces more\ncompressed neural networks while maintaining higher accuracy.",
    "descriptor": "",
    "authors": [
      "Dimitris Papadimitriou",
      "Swayambhoo Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05787"
  },
  {
    "id": "arXiv:2107.05789",
    "title": "Kit-Net: Self-Supervised Learning to Kit Novel 3D Objects into Novel 3D  Cavities",
    "abstract": "In industrial part kitting, 3D objects are inserted into cavities for\ntransportation or subsequent assembly. Kitting is a critical step as it can\ndecrease downstream processing and handling times and enable lower storage and\nshipping costs. We present Kit-Net, a framework for kitting previously unseen\n3D objects into cavities given depth images of both the target cavity and an\nobject held by a gripper in an unknown initial orientation. Kit-Net uses\nself-supervised deep learning and data augmentation to train a convolutional\nneural network (CNN) to robustly estimate 3D rotations between objects and\nmatching concave or convex cavities using a large training dataset of simulated\ndepth images pairs. Kit-Net then uses the trained CNN to implement a controller\nto orient and position novel objects for insertion into novel prismatic and\nconformal 3D cavities. Experiments in simulation suggest that Kit-Net can\norient objects to have a 98.9% average intersection volume between the object\nmesh and that of the target cavity. Physical experiments with industrial\nobjects succeed in 18% of trials using a baseline method and in 63% of trials\nwith Kit-Net. Video, code, and data are available at\nhttps://github.com/BerkeleyAutomation/Kit-Net.",
    "descriptor": "",
    "authors": [
      "Shivin Devgon",
      "Jeffrey Ichnowski",
      "Michael Danielczuk",
      "Daniel S. Brown",
      "Ashwin Balakrishna",
      "Shirin Joshi",
      "Eduardo M. C. Rocha",
      "Eugen Solowjow",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05789"
  },
  {
    "id": "arXiv:2107.05790",
    "title": "Visual Parser: Representing Part-whole Hierarchies with Transformers",
    "abstract": "Human vision is able to capture the part-whole hierarchical information from\nthe entire scene. This paper presents the Visual Parser (ViP) that explicitly\nconstructs such a hierarchy with transformers. ViP divides visual\nrepresentations into two levels, the part level and the whole level.\nInformation of each part represents a combination of several independent\nvectors within the whole. To model the representations of the two levels, we\nfirst encode the information from the whole into part vectors through an\nattention mechanism, then decode the global information within the part vectors\nback into the whole representation. By iteratively parsing the two levels with\nthe proposed encoder-decoder interaction, the model can gradually refine the\nfeatures on both levels. Experimental results demonstrate that ViP can achieve\nvery competitive performance on three major tasks e.g. classification,\ndetection and instance segmentation. In particular, it can surpass the previous\nstate-of-the-art CNN backbones by a large margin on object detection. The tiny\nmodel of the ViP family with $7.2\\times$ fewer parameters and $10.9\\times$\nfewer FLOPS can perform comparably with the largest model\nResNeXt-101-64$\\times$4d of ResNe(X)t family. Visualization results also\ndemonstrate that the learnt parts are highly informative of the predicting\nclass, making ViP more explainable than previous fundamental architectures.\nCode is available at https://github.com/kevin-ssy/ViP.",
    "descriptor": "",
    "authors": [
      "Shuyang Sun*",
      "Xiaoyu Yue*",
      "Song Bai",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05790"
  },
  {
    "id": "arXiv:2107.05791",
    "title": "Monotonic Filtering for Distributed Collection",
    "abstract": "Distributed data collection is a fundamental task in open systems. In such\nnetworks, data is aggregated across a network to produce a single aggregated\nresult at a source device. Though self-stabilizing, algorithms performing data\ncollection can produce large overestimates in the transient phase. For example,\nin [1] we demonstrated that in a line graph, a switch of sources after initial\nstabilization may produce overestimates that are quadratic in the network\ndiameter. We also proposed monotonic filtering as a strategy for removing such\nlarge overestimates. Monotonic filtering prevents the transfer of data from\ndevice A to device B unless the distance estimate at A is more than that at B\nat the previous iteration. For a line graph, [1] shows that monotonic filtering\nprevents quadratic overestimates. This paper analyzes monotonic filtering for\nan arbitrary graph topology, showing that for an N device network, the largest\noverestimate after switching sources is at most 2N.",
    "descriptor": "",
    "authors": [
      "Hunza Zainab",
      "Giorgio Audrito",
      "Soura Dasgupta",
      "Jacob Beal"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.05791"
  },
  {
    "id": "arXiv:2107.05792",
    "title": "What Evidence We Would Miss If We Do Not Use Grey Literature?",
    "abstract": "Context: Multivocal Literature Review(MLR) searches for evidence in both\nTraditional Literature (TL) and Grey Literature (GL). Despite the growing\ninterest in MLR-based studies, the literature assessing how GL has contributed\nto MLR studies is still scarce.\nObjective: This research aims to assess how the use of GL contributed to MLR\nstudies. By contributing, we mean, understanding to what extent GL is providing\nevidence that is indeed used by an MLR to answer its research question.\nMethod: We conducted a tertiary study to identify MLR studies published\nbetween 2017 and 2019, selecting nine MLRs studies. Using qualitative and\nquantitative analysis, we identified the GL used and assessed to what extent\nthese MLRs are contributing to MLR studies.\nResults: Our analysis identified that 1) GL provided evidence not found in\nTL, 2) Most of the GL sources were used to provide recommendations to solve or\nhelp in some problem, explain a topic, classify the findings, and provide\nsolution proposals, and 3) 19 GL types, mainly produced by SE practitioners,\n(including blog posts, slides presentations, or project descriptions) were used\namong the studies. These findings show the importance of GL to MLR studies and\nincrease state of the art by pilling additional evidence on this topic.\nConclusions: We evidence how GL was used to contribute to MLR studies,\nshowing that if these studies have not used the GL, several findings derived\nfrom the practice of SE would have been omitted. We described the challenges\ninvolved when conducting this investigation, along with potential ways to deal\nwith them, which may help future SE researchers.",
    "descriptor": "",
    "authors": [
      "Fernando Kamei",
      "Gustavo Pinto",
      "Igor Wiese",
      "M\u00e1rcio Ribeiro",
      "S\u00e9rgio Soares"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05792"
  },
  {
    "id": "arXiv:2107.05793",
    "title": "A Parallel Approximation Algorithm for Maximizing Submodular  $b$-Matching",
    "abstract": "We design new serial and parallel approximation algorithms for computing a\nmaximum weight $b$-matching in an edge-weighted graph with a submodular\nobjective function. This problem is NP-hard; the new algorithms have\napproximation ratio $1/3$, and are relaxations of the Greedy algorithm that\nrely only on local information in the graph, making them parallelizable. We\nhave designed and implemented Local Lazy Greedy algorithms for both serial and\nparallel computers. We have applied the approximate submodular $b$-matching\nalgorithm to assign tasks to processors in the computation of Fock matrices in\nquantum chemistry on parallel computers. The assignment seeks to reduce the run\ntime by balancing the computational load on the processors and bounding the\nnumber of messages that each processor sends. We show that the new assignment\nof tasks to processors provides a four fold speedup over the currently used\nassignment in the NWChemEx software on $8000$ processors on the Summit\nsupercomputer at Oak Ridge National Lab.",
    "descriptor": "\nComments: 10 pages, accepted for SIAM ACDA 21\n",
    "authors": [
      "S M Ferdous",
      "Alex Pothen",
      "Arif Khan",
      "Ajay Panyala",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.05793"
  },
  {
    "id": "arXiv:2107.05796",
    "title": "Co-evolution of Opinion and Social Tie Dynamics Towards Structural  Balance",
    "abstract": "In this paper, we propose co-evolution models for both dynamics of opinions\n(people's view on a particular topic) and dynamics of social appraisals (the\napproval or disapproval towards each other). Opinion dynamics and dynamics of\nsigned networks, respectively, have been extensively studied. We propose a\nco-evolution model, where each vertex $i$ in the network has a current opinion\nvector $v_i$ and each edge $(i, j)$ has a weight $w_{ij}$ that models the\nrelationship between $i, j$. The system evolves as the opinions and edge\nweights are updated over time by the following rules, Opinion Dynamics and\nAppraisal Dynamics. We are interested in characterizing the long-time behavior\nof the dynamic model -- i.e., whether edge weights evolve to have stable signs\n(positive or negative) and structural balance (the multiplication of weights on\nany triangle is non-negative)\nOur main theoretical result solves the above dynamic system with\ntime-evolving opinions $V(t)=[v_1(t), \\cdots, v_n(t)]$ and social tie weights\n$W(t)=[w_{ij}(t)]_{n\\times n}$. For a generic initial opinion vector $V(0)$ and\nweight matrix $W(0)$, one of the two phenomena must occur at the limit. The\nfirst one is that both sign stability and structural balance (for any triangle\nwith individual $i, j, k$, $w_{ij}w_{jk}w_{ki}\\geq 0$) occur. In the special\ncase that $V(0)$ is an eigenvector of $W(0)$, we are able to obtain the\nexplicit solution to the co-evolution equation and give exact estimates on the\nblowup time and rate convergence. The second one is that all the opinions\nconverge to $0$, i.e., $\\lim_{t\\rightarrow \\infty}|V(t)|=0$.",
    "descriptor": "",
    "authors": [
      "Haotian Wang",
      "Feng Luo",
      "Jie Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.05796"
  },
  {
    "id": "arXiv:2107.05798",
    "title": "Cautious Policy Programming: Exploiting KL Regularization in Monotonic  Policy Improvement for Reinforcement Learning",
    "abstract": "In this paper, we propose cautious policy programming (CPP), a novel\nvalue-based reinforcement learning (RL) algorithm that can ensure monotonic\npolicy improvement during learning. Based on the nature of entropy-regularized\nRL, we derive a new entropy regularization-aware lower bound of policy\nimprovement that only requires estimating the expected policy advantage\nfunction. CPP leverages this lower bound as a criterion for adjusting the\ndegree of a policy update for alleviating policy oscillation. Different from\nsimilar algorithms that are mostly theory-oriented, we also propose a novel\ninterpolation scheme that makes CPP better scale in high dimensional control\nproblems. We demonstrate that the proposed algorithm can trade o? performance\nand stability in both didactic classic control problems and challenging\nhigh-dimensional Atari games.",
    "descriptor": "\nComments: 15 pages. arXiv admin note: text overlap with arXiv:2008.10806\n",
    "authors": [
      "Lingwei Zhu",
      "Toshinori Kitamura",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05798"
  },
  {
    "id": "arXiv:2107.05799",
    "title": "Deep Neural Networks Evolve Human-like Attention Distribution during  Reading Comprehension",
    "abstract": "Attention is a key mechanism for information selection in both biological\nbrains and many state-of-the-art deep neural networks (DNNs). Here, we\ninvestigate whether humans and DNNs allocate attention in comparable ways when\nreading a text passage to subsequently answer a specific question. We analyze 3\ntransformer-based DNNs that reach human-level performance when trained to\nperform the reading comprehension task. We find that the DNN attention\ndistribution quantitatively resembles human attention distribution measured by\nfixation times. Human readers fixate longer on words that are more relevant to\nthe question-answering task, demonstrating that attention is modulated by\ntop-down reading goals, on top of lower-level visual and text features of the\nstimulus. Further analyses reveal that the attention weights in DNNs are also\ninfluenced by both top-down reading goals and lower-level stimulus features,\nwith the shallow layers more strongly influenced by lower-level text features\nand the deep layers attending more to task-relevant words. Additionally, deep\nlayers' attention to task-relevant words gradually emerges when pre-trained DNN\nmodels are fine-tuned to perform the reading comprehension task, which\ncoincides with the improvement in task performance. These results demonstrate\nthat DNNs can evolve human-like attention distribution through task\noptimization, which suggests that human attention during goal-directed reading\ncomprehension is a consequence of task optimization.",
    "descriptor": "",
    "authors": [
      "Jiajie Zou",
      "Nai Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05799"
  },
  {
    "id": "arXiv:2107.05802",
    "title": "How many degrees of freedom do we need to train deep networks: a loss  landscape perspective",
    "abstract": "A variety of recent works, spanning pruning, lottery tickets, and training\nwithin random subspaces, have shown that deep neural networks can be trained\nusing far fewer degrees of freedom than the total number of parameters. We\nexplain this phenomenon by first examining the success probability of hitting a\ntraining loss sub-level set when training within a random subspace of a given\ntraining dimensionality. We find a sharp phase transition in the success\nprobability from $0$ to $1$ as the training dimension surpasses a threshold.\nThis threshold training dimension increases as the desired final loss\ndecreases, but decreases as the initial loss decreases. We then theoretically\nexplain the origin of this phase transition, and its dependence on\ninitialization and final desired loss, in terms of precise properties of the\nhigh dimensional geometry of the loss landscape. In particular, we show via\nGordon's escape theorem, that the training dimension plus the Gaussian width of\nthe desired loss sub-level set, projected onto a unit sphere surrounding the\ninitialization, must exceed the total number of parameters for the success\nprobability to be large. In several architectures and datasets, we measure the\nthreshold training dimension as a function of initialization and demonstrate\nthat it is a small fraction of the total number of parameters, thereby\nimplying, by our theory, that successful training with so few dimensions is\npossible precisely because the Gaussian width of low loss sub-level sets is\nvery large. Moreover, this threshold training dimension provides a strong null\nmodel for assessing the efficacy of more sophisticated ways to reduce training\ndegrees of freedom, including lottery tickets as well a more optimal method we\nintroduce: lottery subspaces.",
    "descriptor": "",
    "authors": [
      "Brett W. Larsen",
      "Stanislav Fort",
      "Nic Becker",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05802"
  },
  {
    "id": "arXiv:2107.05803",
    "title": "Design of a Smooth Landing Trajectory Tracking System for a Fixed-wing  Aircraft",
    "abstract": "This paper presents a landing controller for a fixed-wing aircraft during the\nlanding phase, ensuring the aircraft reaches the touchdown point smoothly. The\nlanding problem is converted to a finite-time linear quadratic tracking (LQT)\nproblem in which an aircraft needs to track the desired landing path in the\nlongitudinal-vertical plane while satisfying performance requirements and\nflight constraints. First, we design a smooth trajectory that meets flight\nperformance requirements and constraints. Then, an optimal controller is\ndesigned to minimize the tracking error, while landing the aircraft within the\ndesired time frame. For this purpose, a linearized model of an aircraft\ndeveloped under the assumption of a small flight path angle and a constant\napproach speed is used. The resulting Differential Riccati equation is solved\nbackward in time using the Dormand Prince algorithm. Simulation results show a\nsatisfactory tracking performance and the finite-time convergence of tracking\nerrors for different initial conditions of the flare-out phase of landing.",
    "descriptor": "\nComments: 6 pages, 9 figures, American Control Conference\n",
    "authors": [
      "Solomon Gudeta",
      "Ali Karimoddini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05803"
  },
  {
    "id": "arXiv:2107.05804",
    "title": "AlterSGD: Finding Flat Minima for Continual Learning by Alternative  Training",
    "abstract": "Deep neural networks suffer from catastrophic forgetting when learning\nmultiple knowledge sequentially, and a growing number of approaches have been\nproposed to mitigate this problem. Some of these methods achieved considerable\nperformance by associating the flat local minima with forgetting mitigation in\ncontinual learning. However, they inevitably need (1) tedious hyperparameters\ntuning, and (2) additional computational cost. To alleviate these problems, in\nthis paper, we propose a simple yet effective optimization method, called\nAlterSGD, to search for a flat minima in the loss landscape. In AlterSGD, we\nconduct gradient descent and ascent alternatively when the network tends to\nconverge at each session of learning new knowledge. Moreover, we theoretically\nprove that such a strategy can encourage the optimization to converge to a flat\nminima. We verify AlterSGD on continual learning benchmark for semantic\nsegmentation and the empirical results show that we can significantly mitigate\nthe forgetting and outperform the state-of-the-art methods with a large margin\nunder challenging continual learning protocols.",
    "descriptor": "",
    "authors": [
      "Zhongzhan Huang",
      "Mingfu Liang",
      "Senwei Liang",
      "Wei He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05804"
  },
  {
    "id": "arXiv:2107.05810",
    "title": "The Element Extraction Problem and the Cost of Determinism and Limited  Adaptivity in Linear Queries",
    "abstract": "Two widely-used computational paradigms for sublinear algorithms are using\nlinear measurements to perform computations on a high dimensional input and\nusing structured queries to access a massive input. Typically, algorithms in\nthe former paradigm are non-adaptive whereas those in the latter are highly\nadaptive. This work studies the fundamental search problem of\n\\textsc{element-extraction} in a query model that combines both: linear\nmeasurements with bounded adaptivity.\nIn the \\textsc{element-extraction} problem, one is given a nonzero vector\n$\\mathbf{z} = (z_1,\\ldots,z_n) \\in \\{0,1\\}^n$ and must report an index $i$\nwhere $z_i = 1$. The input can be accessed using arbitrary linear functions of\nit with coefficients in some ring. This problem admits an efficient nonadaptive\nrandomized solution (through the well known technique of $\\ell_0$-sampling) and\nan efficient fully adaptive deterministic solution (through binary search). We\nprove that when confined to only $k$ rounds of adaptivity, a deterministic\n\\textsc{element-extraction} algorithm must spend $\\Omega(k (n^{1/k} -1))$\nqueries, when working in the ring of integers modulo some fixed $q$. This\nmatches the corresponding upper bound. For queries using integer arithmetic, we\nprove a $2$-round $\\widetilde{\\Omega}(\\sqrt{n})$ lower bound, also tight up to\npolylogarithmic factors. Our proofs reduce to classic problems in\ncombinatorics, and take advantage of established results on the {\\em zero-sum\nproblem} as well as recent improvements to the {\\em sunflower lemma}.",
    "descriptor": "",
    "authors": [
      "Amit Chakrabarti",
      "Manuel Stoeckl"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.05810"
  },
  {
    "id": "arXiv:2107.05814",
    "title": "A barrier method for frictional contact on embedded interfaces",
    "abstract": "We present a barrier method for treating frictional contact on interfaces\nembedded in finite elements. The barrier treatment has several attractive\nfeatures, including: (i) it does not introduce any additional degrees of\nfreedom or iterative steps, (ii) it is free of inter-penetration, (iii) it\navoids an ill-conditioned matrix system, and (iv) it allows one to control the\nsolution accuracy directly. We derive the contact pressure from a smooth\nbarrier energy function that is designed to satisfy the non-penetration\nconstraint. Likewise, we make use of a smoothed friction law in which the\nstick-slip transition is described by a continuous function of the slip\ndisplacement. We discretize the formulation using the extended finite element\nmethod to embed interfaces inside elements, and devise an averaged surface\nintegration scheme that effectively provides stable solutions without traction\noscillations. Subsequently, we develop a way to tailor the parameters of the\nbarrier method to embedded interfaces, such that the method can be used without\nparameter tuning. We verify and investigate the proposed method through\nnumerical examples with various levels of complexity. The numerical results\ndemonstrate that the proposed method is remarkably robust for challenging\nfrictional contact problems, while requiring low cost comparable to that of the\npenalty method.",
    "descriptor": "",
    "authors": [
      "Jinhyun Choo",
      "Yidong Zhao",
      "Yupeng Jiang",
      "Minchen Li",
      "Chenfanfu Jiang",
      "Kenichi Soga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05814"
  },
  {
    "id": "arXiv:2107.05815",
    "title": "Safety and progress proofs for a reactive planner and controller for  autonomous driving",
    "abstract": "In this paper, we perform safety and performance analysis of an autonomous\nvehicle that implements reactive planner and controller for navigating a race\nlap. Unlike traditional planning algorithms that have access to a map of the\nenvironment, reactive planner generates the plan purely based on the current\ninput from sensors. Our reactive planner selects a waypoint on the local\nVoronoi diagram and we use a pure-pursuit controller to navigate towards the\nwaypoint. Our safety and performance analysis has two parts. The first part\ndemonstrates that the reactive planner computes a plan that is locally\nconsistent with the Voronoi plan computed with full map. The second part\ninvolves modeling of the evolution of vehicle navigating along the Voronoi\ndiagram as a hybrid automata. For proving the safety and performance\nspecification, we compute the reachable set of this hybrid automata and employ\nsome enhancements that make this computation easier. We demonstrate that an\nautonomous vehicle implementing our reactive planner and controller is safe and\nsuccessfully completes a lap for five different circuits. In addition, we have\nimplemented our planner and controller in a simulation environment as well as a\nscaled down autonomous vehicle and demonstrate that our planner works well for\na wide variety of circuits.",
    "descriptor": "",
    "authors": [
      "Abolfazl Karimi",
      "Manish Goyal",
      "Parasara Sridhar Duggirala"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05815"
  },
  {
    "id": "arXiv:2107.05818",
    "title": "A Hierarchical Bayesian model for Inverse RL in Partially-Controlled  Environments",
    "abstract": "Robots learning from observations in the real world using inverse\nreinforcement learning (IRL) may encounter objects or agents in the\nenvironment, other than the expert, that cause nuisance observations during the\ndemonstration. These confounding elements are typically removed in\nfully-controlled environments such as virtual simulations or lab settings. When\ncomplete removal is impossible the nuisance observations must be filtered out.\nHowever, identifying the source of observations when large amounts of\nobservations are made is difficult. To address this, we present a hierarchical\nBayesian model that incorporates both the expert's and the confounding\nelements' observations thereby explicitly modeling the diverse observations a\nrobot may receive. We extend an existing IRL algorithm originally designed to\nwork under partial occlusion of the expert to consider the diverse\nobservations. In a simulated robotic sorting domain containing both occlusion\nand confounding elements, we demonstrate the model's effectiveness. In\nparticular, our technique outperforms several other comparative methods, second\nonly to having perfect knowledge of the subject's trajectory.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Kenneth Bogert",
      "Prashant Doshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05818"
  },
  {
    "id": "arXiv:2107.05819",
    "title": "Multitask Identity-Aware Image Steganography via Minimax Optimization",
    "abstract": "High-capacity image steganography, aimed at concealing a secret image in a\ncover image, is a technique to preserve sensitive data, e.g., faces and\nfingerprints. Previous methods focus on the security during transmission and\nsubsequently run a risk of privacy leakage after the restoration of secret\nimages at the receiving end. To address this issue, we propose a framework,\ncalled Multitask Identity-Aware Image Steganography (MIAIS), to achieve direct\nrecognition on container images without restoring secret images. The key issue\nof the direct recognition is to preserve identity information of secret images\ninto container images and make container images look similar to cover images at\nthe same time. Thus, we introduce a simple content loss to preserve the\nidentity information, and design a minimax optimization to deal with the\ncontradictory aspects. We demonstrate that the robustness results can be\ntransferred across different cover datasets. In order to be flexible for the\nsecret image restoration in some cases, we incorporate an optional restoration\nnetwork into our method, providing a multitask framework. The experiments under\nthe multitask scenario show the effectiveness of our framework compared with\nother visual information hiding methods and state-of-the-art high-capacity\nimage steganography methods.",
    "descriptor": "\nComments: Accepted to Transaction of Image Processing\n",
    "authors": [
      "Jiabao Cui",
      "Pengyi Zhang",
      "Songyuan Li",
      "Liangli Zheng",
      "Cuizhu Bao",
      "Jupeng Xia",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05819"
  },
  {
    "id": "arXiv:2107.05821",
    "title": "Detect and Locate: A Face Anti-Manipulation Approach with Semantic and  Noise-level Supervision",
    "abstract": "The technological advancements of deep learning have enabled sophisticated\nface manipulation schemes, raising severe trust issues and security concerns in\nmodern society. Generally speaking, detecting manipulated faces and locating\nthe potentially altered regions are challenging tasks. Herein, we propose a\nconceptually simple but effective method to efficiently detect forged faces in\nan image while simultaneously locating the manipulated regions. The proposed\nscheme relies on a segmentation map that delivers meaningful high-level\nsemantic information clues about the image. Furthermore, a noise map is\nestimated, playing a complementary role in capturing low-level clues and\nsubsequently empowering decision-making. Finally, the features from these two\nmodules are combined to distinguish fake faces. Extensive experiments show that\nthe proposed model achieves state-of-the-art detection accuracy and remarkable\nlocalization performance.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Chenqi Kong",
      "Baoliang Chen",
      "Haoliang Li",
      "Shiqi Wang",
      "Anderson Rocha",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05821"
  },
  {
    "id": "arXiv:2107.05822",
    "title": "Markov Game with Switching Costs",
    "abstract": "We study a general Markov game with metric switching costs: in each round,\nthe player adaptively chooses one of several Markov chains to advance with the\nobjective of minimizing the expected cost for at least $k$ chains to reach\ntheir target states. If the player decides to play a different chain, an\nadditional switching cost is incurred. The special case in which there is no\nswitching cost was solved optimally by Dumitriu, Tetali, and Winkler [DTW03] by\na variant of the celebrated Gittins Index for the classical multi-armed bandit\n(MAB) problem with Markovian rewards [Gittins 74, Gittins79]. However, for\nmulti-armed bandit (MAB) with nontrivial switching cost, even if the switching\ncost is a constant, the classic paper by Banks and Sundaram [BS94] showed that\nno index strategy can be optimal.\nIn this paper, we complement their result and show there is a simple index\nstrategy that achieves a constant approximation factor if the switching cost is\nconstant and $k=1$. To the best of our knowledge, this is the first index\nstrategy that achieves a constant approximation factor for a general MAB\nvariant with switching costs. For the general metric, we propose a more\ninvolved constant-factor approximation algorithm, via a nontrivial reduction to\nthe stochastic $k$-TSP problem, in which a Markov chain is approximated by a\nrandom variable. Our analysis makes extensive use of various interesting\nproperties of the Gittins index.",
    "descriptor": "",
    "authors": [
      "Jian Li",
      "Daogao Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05822"
  },
  {
    "id": "arXiv:2107.05823",
    "title": "A First Look at Developers' Live Chat on Gitter",
    "abstract": "Modern communication platforms such as Gitter and Slack play an increasingly\ncritical role in supporting software teamwork, especially in open source\ndevelopment.Conversations on such platforms often contain intensive, valuable\ninformation that may be used for better understanding OSS developer\ncommunication and collaboration. However, little work has been done in this\nregard. To bridge the gap, this paper reports a first comprehensive empirical\nstudy on developers' live chat, investigating when they interact, what\ncommunity structures look like, which topics are discussed, and how they\ninteract. We manually analyze 749 dialogs in the first phase, followed by an\nautomated analysis of over 173K dialogs in the second phase. We find that\ndevelopers tend to converse more often on weekdays, especially on Wednesdays\nand Thursdays (UTC), that there are three common community structures observed,\nthat developers tend to discuss topics such as API usages and errors, and that\nsix dialog interaction patterns are identified in the live chat communities.\nBased on the findings, we provide recommendations for individual developers and\nOSS communities, highlight desired features for platform vendors, and shed\nlight on future research directions. We believe that the findings and insights\nwill enable a better understanding of developers' live chat, pave the way for\nother researchers, as well as a better utilization and mining of knowledge\nembedded in the massive chat history.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Lin Shi",
      "Xiao Chen",
      "Ye Yang",
      "Hanzhi Jiang",
      "Ziyou Jiang",
      "Nan Niu",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05823"
  },
  {
    "id": "arXiv:2107.05824",
    "title": "Covariance's Loss is Privacy's Gain: Computationally Efficient, Private  and Accurate Synthetic Data",
    "abstract": "The protection of private information is of vital importance in data-driven\nresearch, business, and government. The conflict between privacy and utility\nhas triggered intensive research in the computer science and statistics\ncommunities, who have developed a variety of methods for privacy-preserving\ndata release. Among the main concepts that have emerged are $k$-anonymity\n(often implemented via microaggregation) and differential privacy. Today,\nanother solution is gaining traction, synthetic data. However, the road to\nprivacy is paved with NP-hard problems. In this paper we focus on the NP-hard\nchallenge to develop a synthetic data generation method that is computationally\nefficient, comes with provable privacy guarantees, and rigorously quantifies\ndata utility. We solve a relaxed version of this problem by studying a\nfundamental, but a first glance completely unrelated, problem in probability\nconcerning the concept of covariance loss. Namely, we find a nearly optimal and\nconstructive answer to the question how much information is lost when we take\nconditional expectation. Surprisingly, this excursion into theoretical\nprobability produces mathematical techniques that allow us to derive\nconstructive, approximately optimal solutions to difficult applied problems\nconcerning microaggregation, privacy, and synthetic data.",
    "descriptor": "",
    "authors": [
      "March Boedihardjo",
      "Thomas Strohmer",
      "Roman Vershynin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.05824"
  },
  {
    "id": "arXiv:2107.05825",
    "title": "Recent Advances in Leveraging Human Guidance for Sequential  Decision-Making Tasks",
    "abstract": "A longstanding goal of artificial intelligence is to create artificial agents\ncapable of learning to perform tasks that require sequential decision making.\nImportantly, while it is the artificial agent that learns and acts, it is still\nup to humans to specify the particular task to be performed. Classical\ntask-specification approaches typically involve humans providing stationary\nreward functions or explicit demonstrations of the desired tasks. However,\nthere has recently been a great deal of research energy invested in exploring\nalternative ways in which humans may guide learning agents that may, e.g., be\nmore suitable for certain tasks or require less human effort. This survey\nprovides a high-level overview of five recent machine learning frameworks that\nprimarily rely on human guidance apart from pre-specified reward functions or\nconventional, step-by-step action demonstrations. We review the motivation,\nassumptions, and implementation of each framework, and we discuss possible\nfuture research directions.",
    "descriptor": "\nComments: Springer journal, Autonomous Agents and Multi-Agent Systems (JAAMAS)\n",
    "authors": [
      "Ruohan Zhang",
      "Faraz Torabi",
      "Garrett Warnell",
      "Peter Stone"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05825"
  },
  {
    "id": "arXiv:2107.05828",
    "title": "Dynamic Distribution of Edge Intelligence at the Node Level for Internet  of Things",
    "abstract": "In this paper, dynamic deployment of Convolutional Neural Network (CNN)\narchitecture is proposed utilizing only IoT-level devices. By partitioning and\npipelining the CNN, it horizontally distributes the computation load among\nresource-constrained devices (called horizontal collaboration), which in turn\nincreases the throughput. Through partitioning, we can decrease the computation\nand energy consumption on individual IoT devices and increase the throughput\nwithout sacrificing accuracy. Also, by processing the data at the generation\npoint, data privacy can be achieved. The results show that throughput can be\nincreased by 1.55x to 1.75x for sharing the CNN into two and three\nresource-constrained devices, respectively.",
    "descriptor": "\nComments: 5 pages, 4 figures, and 4 tables\n",
    "authors": [
      "Hawzhin Mohammed",
      "Tolulope A. Odetola",
      "Nan Guo",
      "Syed Rafay Hasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05828"
  },
  {
    "id": "arXiv:2107.05829",
    "title": "Promises and Perils of Inferring Personality on GitHub",
    "abstract": "Personality plays a pivotal role in our understanding of human actions and\nbehavior. Today, the applications of personality are widespread, built on the\nsolutions from psychology to infer personality. Aim: In software engineering,\nfor instance, one widely used solution to infer personality uses textual\ncommunication data. As studies on personality in software engineering continue\nto grow, it is imperative to understand the performance of these solutions.\nMethod: This paper compares the inferential ability of three widely studied\ntext-based personality tests against each other and the ground truth on GitHub.\nWe explore the challenges and potential solutions to improve the inferential\nability of personality tests. Results: Our study shows that solutions for\ninferring personality are far from being perfect. Software engineering\ncommunications data can infer individual developer personality with an average\nerror rate of 41%. In the best case, the error rate can be reduced up to 36% by\nfollowing our recommendations.",
    "descriptor": "",
    "authors": [
      "Frenk van Mil",
      "Ayushi Rastogi",
      "Andy Zaidman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05829"
  },
  {
    "id": "arXiv:2107.05830",
    "title": "ReLLIE: Deep Reinforcement Learning for Customized Low-Light Image  Enhancement",
    "abstract": "Low-light image enhancement (LLIE) is a pervasive yet challenging problem,\nsince: 1) low-light measurements may vary due to different imaging conditions\nin practice; 2) images can be enlightened subjectively according to diverse\npreferences by each individual. To tackle these two challenges, this paper\npresents a novel deep reinforcement learning based method, dubbed ReLLIE, for\ncustomized low-light enhancement. ReLLIE models LLIE as a markov decision\nprocess, i.e., estimating the pixel-wise image-specific curves sequentially and\nrecurrently. Given the reward computed from a set of carefully crafted\nnon-reference loss functions, a lightweight network is proposed to estimate the\ncurves for enlightening of a low-light image input. As ReLLIE learns a policy\ninstead of one-one image translation, it can handle various low-light\nmeasurements and provide customized enhanced outputs by flexibly applying the\npolicy different times. Furthermore, ReLLIE can enhance real-world images with\nhybrid corruptions, e.g., noise, by using a plug-and-play denoiser easily.\nExtensive experiments on various benchmarks demonstrate the advantages of\nReLLIE, comparing to the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by ACM MM 2021\n",
    "authors": [
      "Rongkai Zhang",
      "Lanqing Guo",
      "Siyu Huang",
      "Bihan Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05830"
  },
  {
    "id": "arXiv:2107.05833",
    "title": "Enforcing Consistency in Weakly Supervised Semantic Parsing",
    "abstract": "The predominant challenge in weakly supervised semantic parsing is that of\nspurious programs that evaluate to correct answers for the wrong reasons. Prior\nwork uses elaborate search strategies to mitigate the prevalence of spurious\nprograms; however, they typically consider only one input at a time. In this\nwork we explore the use of consistency between the output programs for related\ninputs to reduce the impact of spurious programs. We bias the program search\n(and thus the model's training signal) towards programs that map the same\nphrase in related inputs to the same sub-parts in their respective programs.\nAdditionally, we study the importance of designing logical formalisms that\nfacilitate this kind of consAistency-based training. We find that a more\nconsistent formalism leads to improved model performance even without\nconsistency-based training. When combined together, these two insights lead to\na 10% absolute improvement over the best prior result on the Natural Language\nVisual Reasoning dataset.",
    "descriptor": "\nComments: Published in ACL 2021\n",
    "authors": [
      "Nitish Gupta",
      "Sameer Singh",
      "Matt Gardner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.05833"
  },
  {
    "id": "arXiv:2107.05840",
    "title": "NucMM Dataset: 3D Neuronal Nuclei Instance Segmentation at Sub-Cubic  Millimeter Scale",
    "abstract": "Segmenting 3D cell nuclei from microscopy image volumes is critical for\nbiological and clinical analysis, enabling the study of cellular expression\npatterns and cell lineages. However, current datasets for neuronal nuclei\nusually contain volumes smaller than $10^{\\text{-}3}\\ mm^3$ with fewer than 500\ninstances per volume, unable to reveal the complexity in large brain regions\nand restrict the investigation of neuronal structures. In this paper, we have\npushed the task forward to the sub-cubic millimeter scale and curated the NucMM\ndataset with two fully annotated volumes: one $0.1\\ mm^3$ electron microscopy\n(EM) volume containing nearly the entire zebrafish brain with around 170,000\nnuclei; and one $0.25\\ mm^3$ micro-CT (uCT) volume containing part of a mouse\nvisual cortex with about 7,000 nuclei. With two imaging modalities and\nsignificantly increased volume size and instance numbers, we discover a great\ndiversity of neuronal nuclei in appearance and density, introducing new\nchallenges to the field. We also perform a statistical analysis to illustrate\nthose challenges quantitatively. To tackle the challenges, we propose a novel\nhybrid-representation learning model that combines the merits of foreground\nmask, contour map, and signed distance transform to produce high-quality 3D\nmasks. The benchmark comparisons on the NucMM dataset show that our proposed\nmethod significantly outperforms state-of-the-art nuclei segmentation\napproaches. Code and data are available at\nhttps://connectomics-bazaar.github.io/proj/nucMM/index.html.",
    "descriptor": "\nComments: The two first authors contributed equally. To be published in the proceedings of MICCAI 2021\n",
    "authors": [
      "Zudi Lin",
      "Donglai Wei",
      "Mariela D. Petkova",
      "Yuelong Wu",
      "Zergham Ahmed",
      "Krishna Swaroop K",
      "Silin Zou",
      "Nils Wendt",
      "Jonathan Boulanger-Weill",
      "Xueying Wang",
      "Nagaraju Dhanyasi",
      "Ignacio Arganda-Carreras",
      "Florian Engert",
      "Jeff Lichtman",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05840"
  },
  {
    "id": "arXiv:2107.05842",
    "title": "Motion Planning by Learning the Solution Manifold in Trajectory  Optimization",
    "abstract": "The objective function used in trajectory optimization is often non-convex\nand can have an infinite set of local optima. In such cases, there are diverse\nsolutions to perform a given task. Although there are a few methods to find\nmultiple solutions for motion planning, they are limited to generating a finite\nset of solutions. To address this issue, we presents an optimization method\nthat learns an infinite set of solutions in trajectory optimization. In our\nframework, diverse solutions are obtained by learning latent representations of\nsolutions. Our approach can be interpreted as training a deep generative model\nof collision-free trajectories for motion planning. The experimental results\nindicate that the trained model represents an infinite set of homotopic\nsolutions for motion planning problems.",
    "descriptor": "\nComments: 24 pages, to appear in the International Journal of Robotics Research\n",
    "authors": [
      "Takayuki Osa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05842"
  },
  {
    "id": "arXiv:2107.05850",
    "title": "Encoding Compositionality in Classical Planning Solutions",
    "abstract": "Classical AI planners provide solutions to planning problems in the form of\nlong and opaque text outputs. To aid in the understanding transferability of\nplanning solutions, it is necessary to have a rich and comprehensible\nrepresentation for both human and computers beyond the current line-by-line\ntext notation. In particular, it is desirable to encode the trace of literals\nthroughout the plan to capture the dependencies between actions selected. The\napproach of this paper is to view the actions as maps between literals and the\nselected plan as a composition of those maps. The mathematical theory, called\ncategory theory, provides the relevant structures for capturing maps, their\ncompositions, and maps between compositions. We employ this theory to propose\nan algorithm agnostic, model-based representation for domains, problems, and\nplans expressed in the commonly used planning description language, PDDL. This\ncategory theoretic representation is accompanied by a graphical syntax in\naddition to a linear notation, similar to algebraic expressions, that can be\nused to infer literals used at every step of the plan. This provides the\nappropriate constructive abstraction and facilitates comprehension for human\noperators. In this paper, we demonstrate this on a plan within the Blocksworld\ndomain.",
    "descriptor": "\nComments: IJCAI Generalization in Planning Workshop 2021\n",
    "authors": [
      "Angeline Aguinaldo",
      "William Regli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05850"
  },
  {
    "id": "arXiv:2107.05851",
    "title": "Precise Visual-Inertial Localization for UAV with the Aid of A 2D  Georeferenced Map",
    "abstract": "Precise geolocalization is crucial for unmanned aerial vehicles (UAVs).\nHowever, most current deployed UAVs rely on the global navigation satellite\nsystems (GNSS) or high precision inertial navigation systems (INS) for\ngeolocalization. In this paper, we propose to use a lightweight visual-inertial\nsystem with a 2D georeference map to obtain accurate and consecutive geodetic\npositions for UAVs. The proposed system firstly integrates a micro inertial\nmeasurement unit (MIMU) and a monocular camera as odometry to consecutively\nestimate the navigation states and reconstruct the 3D position of the observed\nvisual features in the local world frame. To obtain the geolocation, the visual\nfeatures tracked by the odometry are further registered to the 2D georeferenced\nmap. While most conventional methods perform image-level aerial image\nregistration, we propose to align the reconstructed points to the map points in\nthe geodetic frame; this helps to filter out the large portion of outliers and\ndecouples the negative effects from the horizontal angles. The registered\npoints are then used to relocalize the vehicle in the geodetic frame. Finally,\na pose graph is deployed to fuse the geolocation from the aerial image\nregistration and the local navigation result from the visual-inertial odometry\n(VIO) to achieve consecutive and drift-free geolocalization performance. We\nhave validated the proposed method by installing the sensors to a UAV body\nrigidly and have conducted two flights in different environments with unknown\ninitials. The results show that the proposed method can achieve less than 4m\nposition error in flight at 100m high and less than 9m position error in flight\nabout 300m high.",
    "descriptor": "",
    "authors": [
      "Jun Mao",
      "Lilian Zhang",
      "Xiaofeng He",
      "Hao Qu",
      "Xiaoping Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05851"
  },
  {
    "id": "arXiv:2107.05855",
    "title": "Automated Learning Rate Scheduler for Large-batch Training",
    "abstract": "Large-batch training has been essential in leveraging large-scale datasets\nand models in deep learning. While it is computationally beneficial to use\nlarge batch sizes, it often requires a specially designed learning rate (LR)\nschedule to achieve a comparable level of performance as in smaller batch\ntraining. Especially, when the number of training epochs is constrained, the\nuse of a large LR and a warmup strategy is critical in the final performance of\nlarge-batch training due to the reduced number of updating steps. In this work,\nwe propose an automated LR scheduling algorithm which is effective for neural\nnetwork training with a large batch size under the given epoch budget. In\nspecific, the whole schedule consists of two phases: adaptive warmup and\npredefined decay, where the LR is increased until the training loss no longer\ndecreases and decreased to zero until the end of training. Here, whether the\ntraining loss has reached the minimum value is robustly checked with Gaussian\nprocess smoothing in an online manner with a low computational burden. Coupled\nwith adaptive stochastic optimizers such as AdamP and LAMB, the proposed\nscheduler successfully adjusts the LRs without cumbersome hyperparameter tuning\nand achieves comparable or better performances than tuned baselines on various\nimage classification benchmarks and architectures with a wide range of batch\nsizes.",
    "descriptor": "\nComments: 15 pages, 7 figures, 4 tables, 8th ICML Workshop on Automated Machine Learning (2021)\n",
    "authors": [
      "Chiheon Kim",
      "Saehoon Kim",
      "Jongmin Kim",
      "Donghoon Lee",
      "Sungwoong Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05855"
  },
  {
    "id": "arXiv:2107.05856",
    "title": "eProduct: A Million-Scale Visual Search Benchmark to Address Product  Recognition Challenges",
    "abstract": "Large-scale product recognition is one of the major applications of computer\nvision and machine learning in the e-commerce domain. Since the number of\nproducts is typically much larger than the number of categories of products,\nimage-based product recognition is often cast as a visual search rather than a\nclassification problem. It is also one of the instances of super fine-grained\nrecognition, where there are many products with slight or subtle visual\ndifferences. It has always been a challenge to create a benchmark dataset for\ntraining and evaluation on various visual search solutions in a real-world\nsetting. This motivated creation of eProduct, a dataset consisting of 2.5\nmillion product images towards accelerating development in the areas of\nself-supervised learning, weakly-supervised learning, and multimodal learning,\nfor fine-grained recognition. We present eProduct as a training set and an\nevaluation set, where the training set contains 1.3M+ listing images with\ntitles and hierarchical category labels, for model development, and the\nevaluation set includes 10,000 query and 1.1 million index images for visual\nsearch evaluation. We will present eProduct's construction steps, provide\nanalysis about its diversity and cover the performance of baseline models\ntrained on it.",
    "descriptor": "\nComments: This paper was accepted at FGVC8 CVPR2021 as a competition paper (this https URL)\n",
    "authors": [
      "Jiangbo Yuan",
      "An-Ti Chiang",
      "Wen Tang",
      "Antonio Haro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05856"
  },
  {
    "id": "arXiv:2107.05858",
    "title": "Multi-Objective Graph Heuristic Search for Terrestrial Robot Design",
    "abstract": "We present methods for co-designing rigid robots over control and morphology\n(including discrete topology) over multiple objectives. Previous work has\naddressed problems in single-objective robot co-design or multi-objective\ncontrol. However, the joint multi-objective co-design problem is extremely\nimportant for generating capable, versatile, algorithmically designed robots.\nIn this work, we present Multi-Objective Graph Heuristic Search, which extends\na single-objective graph heuristic search from previous work to enable a highly\nefficient multi-objective search in a combinatorial design topology space. Core\nto this approach, we introduce a new universal, multi-objective heuristic\nfunction based on graph neural networks that is able to effectively leverage\nlearned information between different task trade-offs. We demonstrate our\napproach on six combinations of seven terrestrial locomotion and design tasks,\nincluding one three-objective example. We compare the captured Pareto fronts\nacross different methods and demonstrate that our multi-objective graph\nheuristic search quantitatively and qualitatively outperforms other techniques.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA 2021)\n",
    "authors": [
      "Jie Xu",
      "Andrew Spielberg",
      "Allan Zhao",
      "Daniela Rus",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05858"
  },
  {
    "id": "arXiv:2107.05860",
    "title": "Exponentially convergent trapezoidal rules to approximate fractional  powers of operators",
    "abstract": "In this paper we are interested in the approximation of fractional powers of\nself-adjoint positive operators. Starting from the integral representation of\nthe operators, we apply the trapezoidal rule combined with a single-exponential\nand a double-exponential transform of the integrand function. For the first\napproach our aim is only to review some theoretical aspects in order to refine\nthe choice of the parameters that allow a faster convergence. As for the double\nexponential transform, in this work we show how to improve the existing error\nestimates for the scalar case and also extend the analysis to operators. We\nreport some numerical experiments to show the reliability of the estimates\nobtained.",
    "descriptor": "",
    "authors": [
      "Lidia Aceto",
      "Paolo Novati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05860"
  },
  {
    "id": "arXiv:2107.05863",
    "title": "Toward Safe Integration of Legacy SCADA Systems in the Smart Grid",
    "abstract": "A SCADA system is a distributed network of cyber-physical devices used for\ninstrumentation and control of critical infrastructures such as a electric\npower grid. With the emergence of the smart grid, SCADA systems are\nincreasingly required to be connected to more open systems and security becomes\ncrucial. However, many of these SCADA systems have been deployed for decades\nand were initially not designed with security in mind. In particular, the field\ndevices in these systems are vulnerable to false command injection from an\nintruding or compromised device. But implementing cryptographic defence on\nthese old-generation devices is challenging due to computation constraints.\nConsequently, solutions to protect legacy SCADA systems have to be an add-on.\nThis paper discusses two add-on defence strategies for legacy SCADA systems --\nthe data diode and detect-and-respond approaches -- and compares their security\nand application scenarios. A generic architectural framework is also proposed\nto implement the detect-and-respond strategy, with an instantiation to\ndemonstrate its practicality.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Aldar C-F. Chan",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05863"
  },
  {
    "id": "arXiv:2107.05866",
    "title": "A Dialogue-based Information Extraction System for Medical Insurance  Assessment",
    "abstract": "In the Chinese medical insurance industry, the assessor's role is essential\nand requires significant efforts to converse with the claimant. This is a\nhighly professional job that involves many parts, such as identifying personal\ninformation, collecting related evidence, and making a final insurance report.\nDue to the coronavirus (COVID-19) pandemic, the previous offline insurance\nassessment has to be conducted online. However, for the junior assessor often\nlacking practical experience, it is not easy to quickly handle such a complex\nonline procedure, yet this is important as the insurance company needs to\ndecide how much compensation the claimant should receive based on the\nassessor's feedback. In order to promote assessors' work efficiency and speed\nup the overall procedure, in this paper, we propose a dialogue-based\ninformation extraction system that integrates advanced NLP technologies for\nmedical insurance assessment. With the assistance of our system, the average\ntime cost of the procedure is reduced from 55 minutes to 35 minutes, and the\ntotal human resources cost is saved 30% compared with the previous offline\nprocedure. Until now, the system has already served thousands of online claim\ncases.",
    "descriptor": "\nComments: To be published in the Findings of ACL 2021\n",
    "authors": [
      "Shuang Peng",
      "Mengdi Zhou",
      "Minghui Yang",
      "Haitao Mi",
      "Shaosheng Cao",
      "Zujie Wen",
      "Teng Xu",
      "Hongbin Wang",
      "Lei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05866"
  },
  {
    "id": "arXiv:2107.05868",
    "title": "Security and Privacy of Wireless Beacon Systems",
    "abstract": "Bluetooth Low Energy (BLE) beacons have been increasingly used in smart city\napplications, such as location-based and proximity-based services, to enable\nInternet of Things to interact with people in vicinity or enhance\ncontext-awareness. Their widespread deployment in human-centric applications\nmakes them an attractive target to adversaries for social or economic reasons.\nIn fact, beacons are reportedly exposed to various security issues and privacy\nconcerns. A characterization of attacks against beacon systems is given to help\nunderstand adversary motives, required adversarial capabilities, potential\nimpact and possible defence mechanisms for different threats, with a view to\nfacilitating security evaluation and protection formulation for beacon systems.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Aldar C-F. Chan",
      "Raymond M. H. Chung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05868"
  },
  {
    "id": "arXiv:2107.05869",
    "title": "Towards Building a Food Knowledge Graph for Internet of Food",
    "abstract": "Background: The deployment of various networks (e.g., Internet of Things\n(IoT) and mobile networks) and databases (e.g., nutrition tables and food\ncompositional databases) in the food system generates massive information silos\ndue to the well-known data harmonization problem. The food knowledge graph\nprovides a unified and standardized conceptual terminology and their\nrelationships in a structured form and thus can transform these information\nsilos across the whole food system to a more reusable globally digitally\nconnected Internet of Food, enabling every stage of the food system from\nfarm-to-fork.\nScope and approach: We review the evolution of food knowledge organization,\nfrom food classification, food ontology to food knowledge graphs. We then\ndiscuss the progress in food knowledge graphs from several representative\napplications. We finally discuss the main challenges and future directions.\nKey findings and conclusions: Our comprehensive summary of current research\non food knowledge graphs shows that food knowledge graphs play an important\nrole in food-oriented applications, including food search and Question\nAnswering (QA), personalized dietary recommendation, food analysis and\nvisualization, food traceability, and food machinery intelligent manufacturing.\nFuture directions for food knowledge graphs cover several fields such as\nmultimodal food knowledge graphs and food intelligence.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Weiqing Min",
      "Chunlin Liu",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05869"
  },
  {
    "id": "arXiv:2107.05877",
    "title": "GA and ILS for optimizing the size of NFA models",
    "abstract": "Grammatical inference consists in learning a formal grammar (as a set of\nrewrite rules or a finite state machine). We are concerned with learning\nNondeterministic Finite Automata (NFA) of a given size from samples of positive\nand negative words. NFA can naturally be modeled in SAT. The standard model [1]\nbeing enormous, we also try a model based on prefixes [2] which generates\nsmaller instances. We also propose a new model based on suffixes and a hybrid\nmodel based on prefixes and suffixes. We then focus on optimizing the size of\ngenerated SAT instances issued from the hybrid models. We present two\ntechniques to optimize this combination, one based on Iterated Local Search\n(ILS), the second one based on Genetic Algorithm (GA). Optimizing the\ncombination significantly reduces the SAT instances and their solving time, but\nat the cost of longer generation time. We, therefore, study the balance between\ngeneration time and solving time thanks to some experimental comparisons, and\nwe analyze our various model improvements.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Lardeux",
      "Eric Monfroy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05877"
  },
  {
    "id": "arXiv:2107.05878",
    "title": "Minimizing the Risk of Spreading Processes via Surveillance Schedules  and Sparse Control",
    "abstract": "In this paper, we propose an optimization framework that combines\nsurveillance schedules and sparse control to bound the risk of spreading\nprocesses such as epidemics and wildfires. Here, risk is considered the risk of\nan undetected outbreak, i.e. the product of the probability of an outbreak and\nthe impact of that outbreak, and we can bound or minimize the risk by resource\nallocation and persistent monitoring schedules. The presented framework\nutilizes the properties of positive systems and convex optimization to provide\nscalable algorithms for both surveillance and intervention purposes. We\ndemonstrate with different spreading process examples how the method can\nincorporate different parameters and scenarios such as a vaccination strategy\nfor epidemics and the effect of vegetation, wind and outbreak rate on a\nwildfire in persistent monitoring scenarios.",
    "descriptor": "\nComments: Journal submission\n",
    "authors": [
      "Vera L. J. Somers",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.05878"
  },
  {
    "id": "arXiv:2107.05884",
    "title": "Auto IV: Counterfactual Prediction via Automatic Instrumental Variable  Decomposition",
    "abstract": "Instrumental variables (IVs), sources of treatment randomization that are\nconditionally independent of the outcome, play an important role in causal\ninference with unobserved confounders. However, the existing IV-based\ncounterfactual prediction methods need well-predefined IVs, while it's an art\nrather than science to find valid IVs in many real-world scenes. Moreover, the\npredefined hand-made IVs could be weak or erroneous by violating the conditions\nof valid IVs. These thorny facts hinder the application of the IV-based\ncounterfactual prediction methods. In this paper, we propose a novel Automatic\nInstrumental Variable decomposition (AutoIV) algorithm to automatically\ngenerate representations serving the role of IVs from observed variables (IV\ncandidates). Specifically, we let the learned IV representations satisfy the\nrelevance condition with the treatment and exclusion condition with the outcome\nvia mutual information maximization and minimization constraints, respectively.\nWe also learn confounder representations by encouraging them to be relevant to\nboth the treatment and the outcome. The IV and confounder representations\ncompete for the information with their constraints in an adversarial game,\nwhich allows us to get valid IV representations for IV-based counterfactual\nprediction. Extensive experiments demonstrate that our method generates valid\nIV representations for accurate IV-based counterfactual prediction.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Junkun Yuan",
      "Anpeng Wu",
      "Kun Kuang",
      "Bo Li",
      "Runze Wu",
      "Fei Wu",
      "Lanfen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05884"
  },
  {
    "id": "arXiv:2107.05885",
    "title": "Exploiting Network Structures to Improve Semantic Representation for the  Financial Domain",
    "abstract": "This paper presents the participation of the MiniTrue team in the FinSim-3\nshared task on learning semantic similarities for the financial domain in\nEnglish language. Our approach combines contextual embeddings learned by\ntransformer-based language models with network structures embeddings extracted\non external knowledge sources, to create more meaningful representations of\nfinancial domain entities and terms. For this, two BERT based language models\nand a knowledge graph embedding model are used. Besides, we propose a voting\nfunction to joint three basic models for the final inference. Experimental\nresults show that the model with the knowledge graph embeddings has achieved a\nsuperior result than these models with only contextual embeddings.\nNevertheless, we also observe that our voting function brings an extra benefit\nto the final system.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Chao Feng",
      "Shi-jie We"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05885"
  },
  {
    "id": "arXiv:2107.05886",
    "title": "Promise Constraint Satisfaction and Width",
    "abstract": "We study the power of the bounded-width consistency algorithm in the context\nof the fixed-template Promise Constraint Satisfaction Problem (PCSP). Our main\ntechnical finding is that the template of every PCSP that is solvable in\nbounded width satisfies a certain structural condition implying that its\nalgebraic closure-properties include weak near unanimity polymorphisms of all\nlarge arities. While this parallels the standard (non-promise) CSP theory, the\nmethod of proof is quite different and applies even to the regime of sublinear\nwidth. We also show that, in contrast with the CSP world, the presence of weak\nnear unanimity polymorphisms of all large arities does not guarantee\nsolvability in bounded width. The separating example is even solvable in the\nsecond level of the Sherali-Adams (SA) hierarchy of linear programming\nrelaxations. This shows that, unlike for CSPs, linear programming can be\nstronger than bounded width. A direct application of these methods also show\nthat the problem of $q$-coloring $p$-colorable graphs is not solvable in\nbounded or even sublinear width, for any two constants $p$ and $q$ such that $3\n\\leq p \\leq q$. Turning to algorithms, we note that Wigderson's algorithm for\n$O(\\sqrt{n})$-coloring $3$-colorable graphs with $n$ vertices is implementable\nin width $4$. Indeed, by generalizing the method we see that, for any $\\epsilon\n> 0$ smaller than $1/2$, the optimal width for solving the problem of\n$O(n^\\epsilon)$-coloring $3$-colorable graphs with $n$ vertices lies between\n$n^{1-3\\epsilon}$ and $n^{1-2\\epsilon}$. The upper bound gives a simple\n$2^{\\Theta(n^{1-2\\epsilon}\\log(n))}$-time algorithm that, asymptotically, beats\nthe straightforward $2^{\\Theta(n^{1-\\epsilon})}$ bound that follows from\npartitioning the graph into $O(n^\\epsilon)$ many independent parts each of size\n$O(n^{1-\\epsilon})$.",
    "descriptor": "",
    "authors": [
      "Albert Atserias",
      "V\u00edctor Dalmau"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05886"
  },
  {
    "id": "arXiv:2107.05887",
    "title": "ST-DETR: Spatio-Temporal Object Traces Attention Detection Transformer",
    "abstract": "We propose ST-DETR, a Spatio-Temporal Transformer-based architecture for\nobject detection from a sequence of temporal frames. We treat the temporal\nframes as sequences in both space and time and employ the full attention\nmechanisms to take advantage of the features correlations over both dimensions.\nThis treatment enables us to deal with frames sequence as temporal object\nfeatures traces over every location in the space. We explore two possible\napproaches; the early spatial features aggregation over the temporal dimension,\nand the late temporal aggregation of object query spatial features. Moreover,\nwe propose a novel Temporal Positional Embedding technique to encode the time\nsequence information. To evaluate our approach, we choose the Moving Object\nDetection (MOD)task, since it is a perfect candidate to showcase the importance\nof the temporal dimension. Results show a significant 5% mAP improvement on the\nKITTI MOD dataset over the 1-step spatial baseline.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.11401\n",
    "authors": [
      "Eslam Mohamed",
      "Ahmad El-Sallab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05887"
  },
  {
    "id": "arXiv:2107.05890",
    "title": "Gamma-matrices: a new class of simultaneously diagonalizable matrices",
    "abstract": "In order to precondition Toeplitz systems, we present a new class of\nsimultaneously diagonalizable real matrices, the Gamma-matrices, which include\nboth symmetric circulant matrices and a subclass of the set of all reverse\ncirculant matrices. We define some algorithms for fast computation of the\nproduct between a Gamma-matrix and a real vector and between two\nGamma-matrices. Moreover, we illustrate a technique of approximating a real\nsymmetric Toeplitz matrix by a Gamma-matrix, and we show that the eigenvalues\nof the preconditioned matrix are clustered around zero with the exception of at\nmost a finite number of terms.",
    "descriptor": "",
    "authors": [
      "Antonio Boccuto",
      "Ivan Gerace",
      "Valentina Giorgetti",
      "Federico Greco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05890"
  },
  {
    "id": "arXiv:2107.05893",
    "title": "PU-Flow: a Point Cloud Upsampling Networkwith Normalizing Flows",
    "abstract": "Point cloud upsampling aims to generate dense point clouds from given sparse\nones, which is a challenging task due to the irregular and unordered nature of\npoint sets. To address this issue, we present a novel deep learning-based\nmodel, called PU-Flow,which incorporates normalizing flows and feature\ninterpolation techniques to produce dense points uniformly distributed on the\nunderlying surface. Specifically, we formulate the upsampling process as point\ninterpolation in a latent space, where the interpolation weights are adaptively\nlearned from local geometric context, and exploit the invertible\ncharacteristics of normalizing flows to transform points between Euclidean and\nlatent spaces. We evaluate PU-Flow on a wide range of 3D models with sharp\nfeatures and high-frequency details. Qualitative and quantitative results show\nthat our method outperforms state-of-the-art deep learning-based approaches in\nterms of reconstruction quality, proximity-to-surface accuracy, and computation\nefficiency.",
    "descriptor": "",
    "authors": [
      "Aihua Mao",
      "Zihui Du",
      "Junhui Hou",
      "Yaqi Duan",
      "Yong-jin Liu",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05893"
  },
  {
    "id": "arXiv:2107.05894",
    "title": "Automatic Seizure Detection Using the Pulse Transit Time",
    "abstract": "Documentation of epileptic seizures plays an essential role in planning\nmedical therapy. Solutions for automated epileptic seizure detection can help\nimprove the current problem of incomplete and erroneous manual documentation of\nepileptic seizures. In recent years, a number of wearable sensors have been\ntested for this purpose. However, detecting seizures with subtle symptoms\nremains difficult and current solutions tend to have a high false alarm rate.\nSeizures can also affect the patient's arterial blood pressure, which has not\nyet been studied for detection with sensors. The pulse transit time (PTT)\nprovides a noninvasive estimate of arterial blood pressure. It can be obtained\nby using to two sensors, which are measuring the time differences between\narrivals of the pulse waves. Due to separated time chips a clock drift emerges,\nwhich is strongly influencing the PTT. In this work, we present an algorithm\nwhich responds to alterations in the PTT, considering the clock drift and\nenabling the noninvasive monitoring of blood pressure alterations using\nseparated sensors. Furthermore we investigated whether seizures can be detected\nusing the PTT. Our results indicate that using the algorithm, it is possible to\ndetect seizures with a Random Forest. Using the PTT along with other signals in\na multimodal approach, the detection of seizures with subtle symptoms could\nthereby be improved.",
    "descriptor": "",
    "authors": [
      "Eric Fiege",
      "Salima Houta",
      "Pinar Bisgin",
      "Rainer Surges",
      "Falk Howar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05894"
  },
  {
    "id": "arXiv:2107.05899",
    "title": "Speech Representation Learning Combining Conformer CPC with Deep Cluster  for the ZeroSpeech Challenge 2021",
    "abstract": "We present a system for the Zero Resource Speech Challenge 2021, which\ncombines a Contrastive Predictive Coding (CPC) with deep cluster. In deep\ncluster, we first prepare pseudo-labels obtained by clustering the outputs of a\nCPC network with k-means. Then, we train an additional autoregressive model to\nclassify the previously obtained pseudo-labels in a supervised manner. Phoneme\ndiscriminative representation is achieved by executing the second-round\nclustering with the outputs of the final layer of the autoregressive model. We\nshow that replacing a Transformer layer with a Conformer layer leads to a\nfurther gain in a lexical metric. Experimental results show that a relative\nimprovement of 35% in a phonetic metric, 1.5% in the lexical metric, and 2.3%\nin a syntactic metric are achieved compared to a baseline method of CPC-small\nwhich is trained on LibriSpeech 460h data. We achieve top results in this\nchallenge with the syntactic metric.",
    "descriptor": "",
    "authors": [
      "Takashi Maekaku",
      "Xuankai Chang",
      "Yuya Fujita",
      "Li-Wei Chen",
      "Shinji Watanabe",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05899"
  },
  {
    "id": "arXiv:2107.05901",
    "title": "Fast approximations of the Jeffreys divergence between univariate  Gaussian mixture models via exponential polynomial densities",
    "abstract": "The Jeffreys divergence is a renown symmetrization of the statistical\nKullback-Leibler divergence which is often used in machine learning, signal\nprocessing, and information sciences. Since the Jeffreys divergence between the\nubiquitous Gaussian Mixture Models are not available in closed-form, many\ntechniques with various pros and cons have been proposed in the literature to\neither (i) estimate, (ii) approximate, or (iii) lower and upper bound this\ndivergence. In this work, we propose a simple yet fast heuristic to approximate\nthe Jeffreys divergence between two GMMs of arbitrary number of components. The\nheuristic relies on converting GMMs into pairs of dually parameterized\nprobability densities belonging to exponential families. In particular, we\nconsider Polynomial Exponential Densities, and design a goodness-of-fit\ncriterion to measure the dissimilarity between a GMM and a PED which is a\ngeneralization of the Hyv\\\"arinen divergence. This criterion allows one to\nselect the orders of the PEDs to approximate the GMMs. We demonstrate\nexperimentally that the computational time of our heuristic improves over the\nstochastic Monte Carlo estimation baseline by several orders of magnitude while\napproximating reasonably well the Jeffreys divergence, specially when the\nunivariate mixtures have a small number of modes.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05901"
  },
  {
    "id": "arXiv:2107.05904",
    "title": "Region attention and graph embedding network for occlusion objective  class-based micro-expression recognition",
    "abstract": "Micro-expression recognition (\\textbf{MER}) has attracted lots of\nresearchers' attention in a decade. However, occlusion will occur for MER in\nreal-world scenarios. This paper deeply investigates an interesting but\nunexplored challenging issue in MER, \\ie, occlusion MER. First, to research MER\nunder real-world occlusion, synthetic occluded micro-expression databases are\ncreated by using various mask for the community. Second, to suppress the\ninfluence of occlusion, a \\underline{R}egion-inspired \\underline{R}elation\n\\underline{R}easoning \\underline{N}etwork (\\textbf{RRRN}) is proposed to model\nrelations between various facial regions. RRRN consists of a backbone network,\nthe Region-Inspired (\\textbf{RI}) module and Relation Reasoning (\\textbf{RR})\nmodule. More specifically, the backbone network aims at extracting feature\nrepresentations from different facial regions, RI module computing an adaptive\nweight from the region itself based on attention mechanism with respect to the\nunobstructedness and importance for suppressing the influence of occlusion, and\nRR module exploiting the progressive interactions among these regions by\nperforming graph convolutions. Experiments are conducted on handout-database\nevaluation and composite database evaluation tasks of MEGC 2018 protocol.\nExperimental results show that RRRN can significantly explore the importance of\nfacial regions and capture the cooperative complementary relationship of facial\nregions for MER. The results also demonstrate RRRN outperforms the\nstate-of-the-art approaches, especially on occlusion, and RRRN acts more robust\nto occlusion.",
    "descriptor": "",
    "authors": [
      "Qirong Mao",
      "Ling Zhou",
      "Wenming Zheng",
      "Xiuyan Shao",
      "Xiaohua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05904"
  },
  {
    "id": "arXiv:2107.05907",
    "title": "Conformer-based End-to-end Speech Recognition With Rotary Position  Embedding",
    "abstract": "Transformer-based end-to-end speech recognition models have received\nconsiderable attention in recent years due to their high training speed and\nability to model a long-range global context. Position embedding in the\ntransformer architecture is indispensable because it provides supervision for\ndependency modeling between elements at different positions in the input\nsequence. To make use of the time order of the input sequence, many works\ninject some information about the relative or absolute position of the element\ninto the input sequence. In this work, we investigate various position\nembedding methods in the convolution-augmented transformer (conformer) and\nadopt a novel implementation named rotary position embedding (RoPE). RoPE\nencodes absolute positional information into the input sequence by a rotation\nmatrix, and then naturally incorporates explicit relative position information\ninto a self-attention module. To evaluate the effectiveness of the RoPE method,\nwe conducted experiments on AISHELL-1 and LibriSpeech corpora. Results show\nthat the conformer enhanced with RoPE achieves superior performance in the\nspeech recognition task. Specifically, our model achieves a relative word error\nrate reduction of 8.70% and 7.27% over the conformer on test-clean and\ntest-other sets of the LibriSpeech corpus respectively.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shengqiang Li",
      "Menglong Xu",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05907"
  },
  {
    "id": "arXiv:2107.05908",
    "title": "Experience Report: Deep Learning-based System Log Analysis for Anomaly  Detection",
    "abstract": "Logs have been an imperative resource to ensure the reliability and\ncontinuity of many software systems, especially large-scale distributed\nsystems. They faithfully record runtime information to facilitate system\ntroubleshooting and behavior understanding. Due to the large scale and\ncomplexity of modern software systems, the volume of logs has reached an\nunprecedented level. Consequently, for log-based anomaly detection,\nconventional methods of manual inspection or even traditional machine\nlearning-based methods become impractical, which serve as a catalyst for the\nrapid development of deep learning-based solutions. However, there is currently\na lack of rigorous comparison among the representative log-based anomaly\ndetectors which resort to neural network models. Moreover, the\nre-implementation process demands non-trivial efforts and bias can be easily\nintroduced. To better understand the characteristics of different anomaly\ndetectors, in this paper, we provide a comprehensive review and evaluation on\nfive popular models used by six state-of-the-art methods. Particularly, four of\nthe selected methods are unsupervised and the remaining two are supervised.\nThese methods are evaluated with two publicly-available log datasets, which\ncontain nearly 16 millions log messages and 0.4 million anomaly instances in\ntotal. We believe our work can serve as a basis in this field and contribute to\nthe future academic researches and industrial applications.",
    "descriptor": "",
    "authors": [
      "Zhuangbin Chen",
      "Jinyang Liu",
      "Wenwei Gu",
      "Yuxin Su",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05908"
  },
  {
    "id": "arXiv:2107.05911",
    "title": "Induced Domain Adaptation",
    "abstract": "We formulate the problem of induced domain adaptation (IDA) when the\nunderlying distribution/domain shift is introduced by the model being deployed.\nOur formulation is motivated by applications where the deployed machine\nlearning models interact with human agents, and will ultimately face responsive\nand interactive data distributions. We formalize the discussions of the\ntransferability of learning in our IDA setting by studying how the model\ntrained on the available source distribution (data) would translate to the\nperformance on the induced domain. We provide both upper bounds for the\nperformance gap due to the induced domain shift, as well as lower bound for the\ntrade-offs a classifier has to suffer on either the source training\ndistribution or the induced target distribution. We provide further\ninstantiated analysis for two popular domain adaptation settings with covariate\nshift and label shift. We highlight some key properties of IDA, as well as\ncomputational and learning challenges.",
    "descriptor": "\nComments: Preprint under review\n",
    "authors": [
      "Yang Liu",
      "Yatong Chen",
      "Jiaheng Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05911"
  },
  {
    "id": "arXiv:2107.05913",
    "title": "Can Less be More? When Increasing-to-Balancing Label Noise Rates  Considered Beneficial",
    "abstract": "In this paper, we answer the question when inserting label noise (less\ninformative labels) can instead return us more accurate and fair models. We are\nprimarily inspired by two observations that 1) increasing a certain class of\ninstances' label noise to balance the noise rates (increasing-to-balancing)\nresults in an easier learning problem; 2) Increasing-to-balancing improves\nfairness guarantees against label bias. In this paper, we will first quantify\nthe trade-offs introduced by increasing a certain group of instances' label\nnoise rate w.r.t. the learning difficulties and performance guarantees. We\nanalytically demonstrate when such an increase proves to be beneficial, in\nterms of either improved generalization errors or the fairness guarantees. Then\nwe present a method to leverage our idea of inserting label noise for the task\nof learning with noisy labels, either without or with a fairness constraint.\nThe primary technical challenge we face is due to the fact that we would not\nknow which data instances are suffering from higher noise, and we would not\nhave the ground truth labels to verify any possible hypothesis. We propose a\ndetection method that informs us which group of labels might suffer from higher\nnoise, without using ground truth information. We formally establish the\neffectiveness of the proposed solution and demonstrate it with extensive\nexperiments.",
    "descriptor": "\nComments: Preprint under review\n",
    "authors": [
      "Yang Liu",
      "Jialu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05913"
  },
  {
    "id": "arXiv:2107.05916",
    "title": "Towards Automatic Instrumentation by Learning to Separate Parts in  Symbolic Multitrack Music",
    "abstract": "Modern keyboards allow a musician to play multiple instruments at the same\ntime by assigning zones -- fixed pitch ranges of the keyboard -- to different\ninstruments. In this paper, we aim to further extend this idea and examine the\nfeasibility of automatic instrumentation -- dynamically assigning instruments\nto notes in solo music during performance. In addition to the online,\nreal-time-capable setting for performative use cases, automatic instrumentation\ncan also find applications in assistive composing tools in an offline setting.\nDue to the lack of paired data of original solo music and their full\narrangements, we approach automatic instrumentation by learning to separate\nparts (e.g., voices, instruments and tracks) from their mixture in symbolic\nmultitrack music, assuming that the mixture is to be played on a keyboard. We\nframe the task of part separation as a sequential multi-class classification\nproblem and adopt machine learning to map sequences of notes into sequences of\npart labels. To examine the effectiveness of our proposed models, we conduct a\ncomprehensive empirical evaluation over four diverse datasets of different\ngenres and ensembles -- Bach chorales, string quartets, game music and pop\nmusic. Our experiments show that the proposed models outperform various\nbaselines. We also demonstrate the potential for our proposed models to produce\nalternative convincing instrumentations for an existing arrangement by\nseparating its mixture into parts. All source code and audio samples can be\nfound at https://salu133445.github.io/arranger/ .",
    "descriptor": "\nComments: Accepted to ISMIR 2021\n",
    "authors": [
      "Hao-Wen Dong",
      "Chris Donahue",
      "Taylor Berg-Kirkpatrick",
      "Julian McAuley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05916"
  },
  {
    "id": "arXiv:2107.05917",
    "title": "Towards Representation Identical Privacy-Preserving Graph Neural Network  via Split Learning",
    "abstract": "In recent years, the fast rise in number of studies on graph neural network\n(GNN) has put it from the theories research to reality application stage.\nDespite the encouraging performance achieved by GNN, less attention has been\npaid to the privacy-preserving training and inference over distributed graph\ndata in the related literature. Due to the particularity of graph structure, it\nis challenging to extend the existing private learning framework to GNN.\nMotivated by the idea of split learning, we propose a \\textbf{S}erver\n\\textbf{A}ided \\textbf{P}rivacy-preserving \\textbf{GNN} (SAPGNN) for the node\nlevel task on horizontally partitioned cross-silo scenario. It offers a natural\nextension of centralized GNN to isolated graph with max/min pooling\naggregation, while guaranteeing that all the private data involved in\ncomputation still stays at local data holders. To further enhancing the data\nprivacy, a secure pooling aggregation mechanism is proposed. Theoretical and\nexperimental results show that the proposed model achieves the same accuracy as\nthe one learned over the combined data.",
    "descriptor": "",
    "authors": [
      "Chuanqiang Shan",
      "Huiyun Jiao",
      "Jie Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05917"
  },
  {
    "id": "arXiv:2107.05924",
    "title": "An Improvement of a Key Exchange Protocol Relying on Polynomial Maps",
    "abstract": "Akiyama et al. (Int. J. Math. Indust., 2019) proposed a post-quantum key\nexchange protocol that is based on the hardness of solving a system of\nmultivariate non-linear polynomial equations but has a design strategy\ndifferent from ordinary multivariate cryptography. However, their protocol has\na drawback that the probability of failing to establish a common key is\nimpractically high. In this paper, we improve the success probability of\nAkiyama et al.'s key exchange protocol significantly while keeping the\nsecurity, by restricting each component of the correct common key from the\nwhole of the coefficient field to its small subset. We give theoretical and\nexperimental evaluations showing that our proposed parameter set for our\nprotocol is expected to achieve both failure probability $2^{-120}$ and\n$128$-bit security level.",
    "descriptor": "",
    "authors": [
      "Keita Suzuki",
      "Koji Nuida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05924"
  },
  {
    "id": "arXiv:2107.05927",
    "title": "One-sided GRP Solver and Numerical Boundary Conditions for compressible  fluid flows",
    "abstract": "In the computation of compressible fluid flows, numerical boundary conditions\nare always necessary for all physical variables at computational boundaries\nwhile just partial physical variables are often prescribed as physical boundary\nconditions. Certain extrapolation technique or ghost cells are often employed\ntraditionally for this issue but spurious wave reflections often arise to cause\nnumerical instability. In this paper, we associate this issue with the\none-sided generalized Riemann problem (GRP) solver motivated by the accelerated\npiston problem in gas dynamics so that the extrapolation technique can be\nactually avoided. In fact, the compatibility arguments naturally requires to\nformulate the one-sided generalized Riemann problem and incorporate it into the\nnumerical procedure of boundary conditions. As far as the interaction of\nnonlinear waves with physical boundaries, such a one-sided GRP solver shows\nsignificant effects, as numerical experiments demonstrate, on avoiding spurious\nwave reflections at the computational boundaries.",
    "descriptor": "",
    "authors": [
      "Jiequan Li",
      "Qinglong Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05927"
  },
  {
    "id": "arXiv:2107.05928",
    "title": "First-Order Logic with Connectivity Operators",
    "abstract": "First-order logic (FO) can express many algorithmic problems on graphs, such\nas the independent set and dominating set problem, parameterized by solution\nsize. On the other hand, FO cannot express the very simple algorithmic question\nof whether two vertices are connected. We enrich FO with connectivity\npredicates that are tailored to express algorithmic graph properties that are\ncommonly studied in parameterized algorithmics. By adding the atomic predicates\n$conn_k (x, y, z_1 ,\\ldots, z_k)$ that hold true in a graph if there exists a\npath between (the valuations of) $x$ and $y$ after (the valuations of)\n$z_1,\\ldots,z_k$ have been deleted, we obtain separator logic $FO + conn$.\nWe show that separator logic can express many interesting problems such as\nthe feedback vertex set problem and elimination distance problems to\nfirst-order definable classes. We then study the limitations of separator logic\nand prove that it cannot express planarity, and, in particular, not the\ndisjoint paths problem. We obtain the stronger disjoint-paths logic $FO + DP$\nby adding the atomic predicates $disjoint-paths_k [(x_1, y_1 ),\\ldots , (x_k ,\ny_k )]$ that evaluate to true if there are internally vertex disjoint paths\nbetween (the valuations of) $x_i$ and $y_i$ for all $1 \\le i \\le k$.\nDisjoint-paths logic can express the disjoint paths problem, the problem of\n(topological) minor containment, the problem of hitting (topological) minors,\nand many more. Finally, we compare the expressive power of the new logics with\nthat of transitive closure logics and monadic second-order logic.",
    "descriptor": "",
    "authors": [
      "Nicole Schrader",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.05928"
  },
  {
    "id": "arXiv:2107.05938",
    "title": "Learning from Partially Overlapping Labels: Image Segmentation under  Annotation Shift",
    "abstract": "Scarcity of high quality annotated images remains a limiting factor for\ntraining accurate image segmentation models. While more and more annotated\ndatasets become publicly available, the number of samples in each individual\ndatabase is often small. Combining different databases to create larger amounts\nof training data is appealing yet challenging due to the heterogeneity as a\nresult of differences in data acquisition and annotation processes, often\nyielding incompatible or even conflicting information. In this paper, we\ninvestigate and propose several strategies for learning from partially\noverlapping labels in the context of abdominal organ segmentation. We find that\ncombining a semi-supervised approach with an adaptive cross entropy loss can\nsuccessfully exploit heterogeneously annotated data and substantially improve\nsegmentation accuracy compared to baseline and alternative approaches.",
    "descriptor": "",
    "authors": [
      "Gregory Filbrandt",
      "Konstantinos Kamnitsas",
      "David Bernstein",
      "Alexandra Taylor",
      "Ben Glocker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05938"
  },
  {
    "id": "arXiv:2107.05939",
    "title": "A QUIC(K) Way Through Your Firewall?",
    "abstract": "The QUIC protocol is a new approach to combine encryption and transport layer\nstream abstraction into one protocol to lower latency and improve security.\nHowever, the decision to encrypt transport layer functionality may limit the\ncapabilities of firewalls to protect networks. To identify these limitations we\ncreated a test environment and analyzed generated QUIC traffic from the\nviewpoint of a middlebox. This paper shows that QUIC indeed exposes traditional\nstateful firewalls to UDP hole punching bypass attacks. On the contrary we show\nthe robustness against censorship of QUIC through the encrypted transport layer\ndesign and analyze the capabilities to re-gain stateful tracking capabilities\nby deep packet inspection of the few exposed QUIC header fields.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Konrad Yuri Gbur",
      "Florian Tschorsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.05939"
  },
  {
    "id": "arXiv:2107.05940",
    "title": "Cats, not CAT scans: a study of dataset similarity in transfer learning  for 2D medical image classification",
    "abstract": "Transfer learning is a commonly used strategy for medical image\nclassification, especially via pretraining on source data and fine-tuning on\ntarget data. There is currently no consensus on how to choose appropriate\nsource data, and in the literature we can find both evidence of favoring large\nnatural image datasets such as ImageNet, and evidence of favoring more\nspecialized medical datasets. In this paper we perform a systematic study with\nnine source datasets with natural or medical images, and three target medical\ndatasets, all with 2D images. We find that ImageNet is the source leading to\nthe highest performances, but also that larger datasets are not necessarily\nbetter. We also study different definitions of data similarity. We show that\ncommon intuitions about similarity may be inaccurate, and therefore not\nsufficient to predict an appropriate source a priori. Finally, we discuss\nseveral steps needed for further research in this field, especially with regard\nto other types (for example 3D) medical images. Our experiments and pretrained\nmodels are available via \\url{https://www.github.com/vcheplygina/cats-scans}",
    "descriptor": "",
    "authors": [
      "Irma van den Brandt",
      "Floris Fok",
      "Bas Mulders",
      "Joaquin Vanschoren",
      "Veronika Cheplygina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05940"
  },
  {
    "id": "arXiv:2107.05941",
    "title": "Multi-Scale Label Relation Learning for Multi-Label Classification Using  1-Dimensional Convolutional Neural Networks",
    "abstract": "We present Multi-Scale Label Dependence Relation Networks (MSDN), a novel\napproach to multi-label classification (MLC) using 1-dimensional convolution\nkernels to learn label dependencies at multi-scale. Modern multi-label\nclassifiers have been adopting recurrent neural networks (RNNs) as a memory\nstructure to capture and exploit label dependency relations. The RNN-based MLC\nmodels however tend to introduce a very large number of parameters that may\ncause under-/over-fitting problems. The proposed method uses the 1-dimensional\nconvolutional neural network (1D-CNN) to serve the same purpose in a more\nefficient manner. By training a model with multiple kernel sizes, the method is\nable to learn the dependency relations among labels at multiple scales, while\nit uses a drastically smaller number of parameters. With public benchmark\ndatasets, we demonstrate that our model can achieve better accuracies with much\nsmaller number of model parameters compared to RNN-based MLC models.",
    "descriptor": "",
    "authors": [
      "Junhyung Kim",
      "Byungyoon Park",
      "Charmgil Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05941"
  },
  {
    "id": "arXiv:2107.05942",
    "title": "A Novel Deep Learning Method for Thermal to Annotated Thermal-Optical  Fused Images",
    "abstract": "Thermal Images profile the passive radiation of objects and capture them in\ngrayscale images. Such images have a very different distribution of data\ncompared to optical colored images. We present here a work that produces a\ngrayscale thermo-optical fused mask given a thermal input. This is a deep\nlearning based pioneering work since to the best of our knowledge, there exists\nno other work on thermal-optical grayscale fusion. Our method is also unique in\nthe sense that the deep learning method we are proposing here works on the\nDiscrete Wavelet Transform (DWT) domain instead of the gray level domain. As a\npart of this work, we also present a new and unique database for obtaining the\nregion of interest in thermal images based on an existing thermal visual paired\ndatabase, containing the Region of Interest on 5 different classes of data.\nFinally, we are proposing a simple low cost overhead statistical measure for\nidentifying the region of interest in the fused images, which we call as the\nRegion of Fusion (RoF). Experiments on the database show encouraging results in\nidentifying the region of interest in the fused images. We also show that they\ncan be processed better in the mixed form rather than with only thermal images.",
    "descriptor": "",
    "authors": [
      "Suranjan Goswami",
      "IEEE Student Member",
      "Satish Kumar Singh",
      "Senior Member",
      "IEEE",
      "Bidyut B. Chaudhuri",
      "Life Fellow",
      "IEEE"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05942"
  },
  {
    "id": "arXiv:2107.05944",
    "title": "The Piano Inpainting Application",
    "abstract": "Autoregressive models are now capable of generating high-quality minute-long\nexpressive MIDI piano performances. Even though this progress suggests new\ntools to assist music composition, we observe that generative algorithms are\nstill not widely used by artists due to the limited control they offer,\nprohibitive inference times or the lack of integration within musicians'\nworkflows. In this work, we present the Piano Inpainting Application (PIA), a\ngenerative model focused on inpainting piano performances, as we believe that\nthis elementary operation (restoring missing parts of a piano performance)\nencourages human-machine interaction and opens up new ways to approach music\ncomposition. Our approach relies on an encoder-decoder Linear Transformer\narchitecture trained on a novel representation for MIDI piano performances\ntermed Structured MIDI Encoding. By uncovering an interesting synergy between\nLinear Transformers and our inpainting task, we are able to efficiently inpaint\ncontiguous regions of a piano performance, which makes our model suitable for\ninteractive and responsive A.I.-assisted composition. Finally, we introduce our\nfreely-available Ableton Live PIA plugin, which allows musicians to smoothly\ngenerate or modify any MIDI clip using PIA within a widely-used professional\nDigital Audio Workstation.",
    "descriptor": "",
    "authors": [
      "Ga\u00ebtan Hadjeres",
      "L\u00e9opold Crestel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05944"
  },
  {
    "id": "arXiv:2107.05945",
    "title": "CentripetalText: An Efficient Text Instance Representation for Scene  Text Detection",
    "abstract": "Scene text detection remains a grand challenge due to the variation in text\ncurvatures, orientations, and aspect ratios. One of the most intractable\nproblems is how to represent text instances of arbitrary shapes. Although many\nstate-of-the-art methods have been proposed to model irregular texts in a\nflexible manner, most of them lose simplicity and robustness. Their complicated\npost-processings and the regression under Dirac delta distribution undermine\nthe detection performance and the generalization ability. In this paper, we\npropose an efficient text instance representation named CentripetalText (CT),\nwhich decomposes text instances into the combination of text kernels and\ncentripetal shifts. Specifically, we utilize the centripetal shifts to\nimplement the pixel aggregation, which guide the external text pixels to the\ninternal text kernels. The relaxation operation is integrated into the dense\nregression for centripetal shifts, allowing the correct prediction in a range,\nnot a specific value. The convenient reconstruction of the text contours and\nthe tolerance of the prediction errors in our method guarantee the high\ndetection accuracy and the fast inference speed respectively. Besides, we\nshrink our text detector into a proposal generation module, namely\nCentripetalText Proposal Network (CPN), replacing SPN in Mask TextSpotter v3\nand producing more accurate proposals. To validate the effectiveness of our\ndesigns, we conduct experiments on several commonly used scene text benchmarks,\nincluding both curved and multi-oriented text datasets. For the task of scene\ntext detection, our approach achieves superior or competitive performance\ncompared to other existing methods, e.g., F-measure of 86.3% at 40.0 FPS on\nTotal-Text, F-measure of 86.1% at 34.8 FPS on MSRA-TD500, etc. For the task of\nend-to-end scene text recognition, we outperform Mask TextSpotter v3 by 1.1% on\nTotal-Text.",
    "descriptor": "",
    "authors": [
      "Tao Sheng",
      "Jie Chen",
      "Zhouhui Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05945"
  },
  {
    "id": "arXiv:2107.05946",
    "title": "HAT: Hierarchical Aggregation Transformers for Person Re-identification",
    "abstract": "Recently, with the advance of deep Convolutional Neural Networks (CNNs),\nperson Re-Identification (Re-ID) has witnessed great success in various\napplications. However, with limited receptive fields of CNNs, it is still\nchallenging to extract discriminative representations in a global view for\npersons under non-overlapped cameras. Meanwhile, Transformers demonstrate\nstrong abilities of modeling long-range dependencies for spatial and sequential\ndata. In this work, we take advantages of both CNNs and Transformers, and\npropose a novel learning framework named Hierarchical Aggregation Transformer\n(HAT) for image-based person Re-ID with high performance. To achieve this goal,\nwe first propose a Deeply Supervised Aggregation (DSA) to recurrently aggregate\nhierarchical features from CNN backbones. With multi-granularity supervisions,\nthe DSA can enhance multi-scale features for person retrieval, which is very\ndifferent from previous methods. Then, we introduce a Transformer-based Feature\nCalibration (TFC) to integrate low-level detail information as the global prior\nfor high-level semantic information. The proposed TFC is inserted to each level\nof hierarchical features, resulting in great performance improvements. To our\nbest knowledge, this work is the first to take advantages of both CNNs and\nTransformers for image-based person Re-ID. Comprehensive experiments on four\nlarge-scale Re-ID benchmarks demonstrate that our method shows better results\nthan several state-of-the-art methods. The code is released at\nhttps://github.com/AI-Zhpp/HAT.",
    "descriptor": "\nComments: This work has been accepted by ACM International Conference on Multimedia 2021.To our best knowledge, this work is the very first to take advantages of both CNNs and Transformers for image-based person Re-ID\n",
    "authors": [
      "Guowen Zhang",
      "Pingping Zhang",
      "Jinqing Qi",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05946"
  },
  {
    "id": "arXiv:2107.05948",
    "title": "On Designing Good Representation Learning Models",
    "abstract": "The goal of representation learning is different from the ultimate objective\nof machine learning such as decision making, it is therefore very difficult to\nestablish clear and direct objectives for training representation learning\nmodels. It has been argued that a good representation should disentangle the\nunderlying variation factors, yet how to translate this into training\nobjectives remains unknown. This paper presents an attempt to establish direct\ntraining criterions and design principles for developing good representation\nlearning models. We propose that a good representation learning model should be\nmaximally expressive, i.e., capable of distinguishing the maximum number of\ninput configurations. We formally define expressiveness and introduce the\nmaximum expressiveness (MEXS) theorem of a general learning model. We propose\nto train a model by maximizing its expressiveness while at the same time\nincorporating general priors such as model smoothness. We present a conscience\ncompetitive learning algorithm which encourages the model to reach its MEXS\nwhilst at the same time adheres to model smoothness prior. We also introduce a\nlabel consistent training (LCT) technique to boost model smoothness by\nencouraging it to assign consistent labels to similar samples. We present\nextensive experimental results to show that our method can indeed design\nrepresentation learning models capable of developing representations that are\nas good as or better than state of the art. We also show that our technique is\ncomputationally efficient, robust against different parameter settings and can\nwork effectively on a variety of datasets.",
    "descriptor": "\nComments: 15 pages,\n",
    "authors": [
      "Qinglin Li",
      "Bin Li",
      "Jonathan M Garibaldi",
      "Guoping Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05948"
  },
  {
    "id": "arXiv:2107.05949",
    "title": "Q-SMASH: Q-Learning-based Self-Adaptation of Human-Centered Internet of  Things",
    "abstract": "As the number of Human-Centered Internet of Things (HCIoT) applications\nincreases, the self-adaptation of its services and devices is becoming a\nfundamental requirement for addressing the uncertainties of the environment in\ndecision-making processes. Self-adaptation of HCIoT aims to manage run-time\nchanges in a dynamic environment and to adjust the functionality of IoT objects\nin order to achieve desired goals during execution. SMASH is a semantic-enabled\nmulti-agent system for self-adaptation of HCIoT that autonomously adapts IoT\nobjects to uncertainties of their environment. SMASH addresses the\nself-adaptation of IoT applications only according to the human values of\nusers, while the behavior of users is not addressed. This article presents\nQ-SMASH: a multi-agent reinforcement learning-based approach for\nself-adaptation of IoT objects in human-centered environments. Q-SMASH aims to\nlearn the behaviors of users along with respecting human values. The learning\nability of Q-SMASH allows it to adapt itself to the behavioral change of users\nand make more accurate decisions in different states and situations.",
    "descriptor": "\nComments: Submitted to wi-iat2021. arXiv admin note: text overlap with arXiv:2105.14915\n",
    "authors": [
      "Hamed Rahimi",
      "Iago Felipe Trentin",
      "Fano Ramparany",
      "Olivier Boissier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05949"
  },
  {
    "id": "arXiv:2107.05954",
    "title": "MVPipe: Enabling Lightweight Updates and Fast Convergence in  Hierarchical Heavy Hitter Detection",
    "abstract": "Finding hierarchical heavy hitters (HHHs) (i.e., hierarchical aggregates with\nexceptionally huge amounts of traffic) is critical to network management, yet\nit is often challenged by the requirements of fast packet processing, real-time\nand accurate detection, as well as resource efficiency. Existing HHH detection\nschemes either incur expensive packet updates for multiple aggregation levels\nin the IP address hierarchy, or need to process sufficient packets to converge\nto the required detection accuracy. We present MVPipe, an invertible sketch\nthat achieves both lightweight updates and fast convergence in HHH detection.\nMVPipe builds on the skewness property of IP traffic to process packets via a\npipeline of majority voting executions, such that most packets can be updated\nfor only one or few aggregation levels in the IP address hierarchy. We show how\nMVPipe can be feasibly deployed in P4-based programmable switches subject to\nlimited switch resources. We also theoretically analyze the accuracy and\ncoverage properties of MVPipe. Evaluation with real-world Internet traces shows\nthat MVPipe achieves high accuracy, high throughput, and fast convergence\ncompared to six state-of-the-art HHH detection schemes. It also incurs low\nresource overhead in the Barefoot Tofino switch deployment.",
    "descriptor": "",
    "authors": [
      "Lu Tang",
      "Qun Huang",
      "Patrick P. C. Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.05954"
  },
  {
    "id": "arXiv:2107.05955",
    "title": "The Impact of Working From Home on the Success of Scrum Projects: A  Multi-Method Study",
    "abstract": "The number of companies opting for remote working has been increasing over\nthe years, and Agile methodologies, such as Scrum, were adapted to mitigate the\nchallenges caused by the distributed teams. However, the COVID-19 pandemic\nimposed a fully working from home context, which has never existed before. This\npaper investigation a two-phased Multi-Method study. In the first phase, we\nuncover how working from home impacted Scrum practitioners through a\nqualitative survey. Then, in the second phase, we propose a theoretical model\nthat we test and generalize using Partial Least Squares - Structural Equation\nModeling (PLS-SEM) through a sample study of 200 software engineers who worked\nfrom home within Scrum projects. From assessing our model, we can conclude that\nall the latent variables are reliable and all the hypotheses are significant.\nMoreover, we performed an Importance-Performance Map Analysis (IPMA),\nhighlighting the benefits of the home working environment and the use of Scrum\nfor project success. We emphasize the importance of supporting the three innate\npsychological needs of autonomy, competence, and relatedness in the home\nworking environment. We conclude that the home working environment and the use\nof Scrum both contribute to project success, with Scrum acting as a mediator.",
    "descriptor": "",
    "authors": [
      "Adrian-Alexandru Cucolas",
      "Daniel Russo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05955"
  },
  {
    "id": "arXiv:2107.05962",
    "title": "COLiER: Collaborative Editing of Raster Images",
    "abstract": "Various web-based image-editing tools and web-based collaborative tools exist\nin isolation. Research focusing to bridge the gap between these two domains is\nsparse. We respond to the above and develop a prototype groupware for real-time\ncollaborative editing of raster images in a web browser. To better understand\nthe requirements, we conduct a preliminary user study and establish\ncommunication and synchronization as key elements. The existing groupware for\ntext documents, presentations, and vector graphics handles the above through\nwell-established techniques. However, those cannot be extended as it is for\nraster graphics manipulation. To this end, we develop a document model that is\nmaintained by a server and is delivered and synchronized to multiple clients.\nOur prototypical implementation is based on a scalable client-server\narchitecture: using WebGL for interactive browser-based rendering and WebSocket\nconnections to maintain synchronization. We evaluate our work qualitatively\nthrough a post-deployment user study for three different scenarios.",
    "descriptor": "",
    "authors": [
      "Ulrike Bath",
      "Sumit Shekhar",
      "J\u00fcrgen D\u00f6llner",
      "Matthias Trapp"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05962"
  },
  {
    "id": "arXiv:2107.05965",
    "title": "Efficient Belief Propagation List Ordered Statistics Decoding of Polar  Codes",
    "abstract": "New algorithms for efficient decoding of polar codes (which may be\nCRC-augmented), transmitted over either a binary erasure channel (BEC) or an\nadditive white Gaussian noise channel (AWGNC), are presented. We start by\npresenting a new efficient exact maximum likelihood decoding algorithm for the\nBEC based on inactivation decoding and analyze its computational complexity.\nThis algorithm applies a matrix triangulation process on a sparse polar code\nparity check matrix, followed by solving a small size linear system over GF(2).\nWe then consider efficient decoding of polar codes, transmitted over the AWGNC.\nThe algorithm applies CRC-aided belief propagation list (CBPL) decoding,\nfollowed by ordered statistics decoding (OSD) of low order. Even when the\nreprocessing order of the OSD is as low as one, the new decoder is shown to\nsignificantly improve on plain CBPL. To implement the OSD efficiently, we adapt\nthe matrix triangulation algorithm from the BEC case. We also indicate how the\ndecoding algorithms can be implemented in parallel for low latency decoding.\nNumerical simulations are used to evaluate the performance and computational\ncomplexity of the new algorithms.",
    "descriptor": "\nComments: Submitted to the IEEE for possible publication. arXiv admin note: substantial text overlap with arXiv:2106.14753\n",
    "authors": [
      "Yonatan Urman",
      "Guy Mogilevsky",
      "David Burshtein"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05965"
  },
  {
    "id": "arXiv:2107.05966",
    "title": "Secure Short-Packet Communications at the Physical Layer for 5G and  Beyond",
    "abstract": "Short-packet communication is a key technology to support two emerging\napplication scenarios in 5G and beyond 5G, massive machine type communication\n(mMTC) and ultra-reliable low latency communication (uRLLC), which are\nintroduced to satisfy the broader communication requirements of potential\napplications such as the internet of vehicles and industrial internet of things\n(IoT). The sharp increase in privacy data in various IoT applications has made\nsecurity issues more prominent. The typical upper-layer encryption mechanism\ncould not fully address the security challenge considering the resource\nrestriction of IoT terminals. In this article, we investigate secure\nshort-packet communication from the perspective of physical layer security\n(PLS), which can be regarded as a promising security solution in 6G.\nSpecifically, the state-of-the-art development of fundamental information\ntheory of secure short-packet communications and corresponding performance\nevaluation criterion in fading channels are summarized. Then we review recent\nworks, which investigate short-packet communication systems (CSs) in different\ncommunication scenarios or with different security strategies from the\nperspective of PLS. Finally, we give future research directions and challenges.",
    "descriptor": "\nComments: 16 pages, 5 figures, accepted by IEEE Communications Standards Magazine\n",
    "authors": [
      "Chen Feng",
      "Hui-ming Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05966"
  },
  {
    "id": "arXiv:2107.05972",
    "title": "Polynomial delay algorithm for minimal chordal completions",
    "abstract": "Motivated by the problem of enumerating all tree decompositions of a graph,\nwe consider in this article the problem of listing all the minimal chordal\ncompletions of a graph. In \\cite{carmeli2020} (\\textsc{Pods 2017}) Carmeli\n\\emph{et al.} proved that all minimal chordal completions or equivalently all\nproper tree decompositions of a graph can be listed in incremental polynomial\ntime using exponential space. The total running time of their algorithm is\nquadratic in the number of solutions and the existence of an algorithm whose\ncomplexity depends only linearly on the number of solutions remained open. We\nclose this question by providing a polynomial delay algorithm to solve this\nproblem which, moreover, uses polynomial space.\nOur algorithm relies on \\emph{Proximity Search}, a framework recently\nintroduced by Conte \\emph{et al.} \\cite{conte-uno2019} (\\textsc{Stoc 2019})\nwhich has been shown powerful to obtain polynomial delay algorithms, but\ngenerally requires exponential space. In order to obtain a polynomial space\nalgorithm for our problem, we introduce a new general method called\n\\emph{canonical path reconstruction} to design polynomial delay and polynomial\nspace algorithms based on proximity search.",
    "descriptor": "",
    "authors": [
      "Caroline Brosse",
      "Vincent Limouzy",
      "Arnaud Mary"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05972"
  },
  {
    "id": "arXiv:2107.05978",
    "title": "DIVINE: Diverse Influential Training Points for Data Visualization and  Model Refinement",
    "abstract": "As the complexity of machine learning (ML) models increases, resulting in a\nlack of prediction explainability, several methods have been developed to\nexplain a model's behavior in terms of the training data points that most\ninfluence the model. However, these methods tend to mark outliers as highly\ninfluential points, limiting the insights that practitioners can draw from\npoints that are not representative of the training data. In this work, we take\na step towards finding influential training points that also represent the\ntraining data well. We first review methods for assigning importance scores to\ntraining points. Given importance scores, we propose a method to select a set\nof DIVerse INfluEntial (DIVINE) training points as a useful explanation of\nmodel behavior. As practitioners might not only be interested in finding data\npoints influential with respect to model accuracy, but also with respect to\nother important metrics, we show how to evaluate training data points on the\nbasis of group fairness. Our method can identify unfairness-inducing training\npoints, which can be removed to improve fairness outcomes. Our quantitative\nexperiments and user studies show that visualizing DIVINE points helps\npractitioners understand and explain model behavior better than earlier\napproaches.",
    "descriptor": "\nComments: 30 pages, 32 figures\n",
    "authors": [
      "Umang Bhatt",
      "Isabel Chien",
      "Muhammad Bilal Zafar",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.05978"
  },
  {
    "id": "arXiv:2107.05979",
    "title": "Normal Sequences with Non Maximal Automatic Complexity",
    "abstract": "This paper examines Automatic Complexity, a complexity notion introduced by\nShallit and Wang in 2001. We demonstrate that there exists a normal sequence\n$T$ such that $I(T) = 0$ and $S(T) \\leq 1/2$, where $I(T)$ and $S(T)$ are the\nlower and upper automatic complexity rates of $T$ respectively. We furthermore\nshow that there exists a Champernowne sequence $C$, i.e. a sequence formed by\nconcatenating all strings of length $1$ followed by concatenating all strings\nof length $2$ and so on, such that $S(C) \\leq 2/3$.",
    "descriptor": "",
    "authors": [
      "Liam Jordon",
      "Philippe Moser"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.05979"
  },
  {
    "id": "arXiv:2107.05987",
    "title": "Generating Gender Augmented Data for NLP",
    "abstract": "Gender bias is a frequent occurrence in NLP-based applications, especially\npronounced in gender-inflected languages. Bias can appear through associations\nof certain adjectives and animate nouns with the natural gender of referents,\nbut also due to unbalanced grammatical gender frequencies of inflected words.\nThis type of bias becomes more evident in generating conversational utterances\nwhere gender is not specified within the sentence, because most current NLP\napplications still work on a sentence-level context. As a step towards more\ninclusive NLP, this paper proposes an automatic and generalisable rewriting\napproach for short conversational sentences. The rewriting method can be\napplied to sentences that, without extra-sentential context, have multiple\nequivalent alternatives in terms of gender. The method can be applied both for\ncreating gender balanced outputs as well as for creating gender balanced\ntraining data. The proposed approach is based on a neural machine translation\n(NMT) system trained to 'translate' from one gender alternative to another.\nBoth the automatic and manual analysis of the approach show promising results\nfor automatic generation of gender alternatives for conversational sentences in\nSpanish.",
    "descriptor": "\nComments: 10 pages, 4 tables\n",
    "authors": [
      "Nishtha Jain",
      "Maja Popovic",
      "Declan Groves",
      "Eva Vanmassenhove"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.05987"
  },
  {
    "id": "arXiv:2107.05989",
    "title": "Emotion Recognition for Healthcare Surveillance Systems Using Neural  Networks: A Survey",
    "abstract": "Recognizing the patient's emotions using deep learning techniques has\nattracted significant attention recently due to technological advancements.\nAutomatically identifying the emotions can help build smart healthcare centers\nthat can detect depression and stress among the patients in order to start the\nmedication early. Using advanced technology to identify emotions is one of the\nmost exciting topics as it defines the relationships between humans and\nmachines. Machines learned how to predict emotions by adopting various methods.\nIn this survey, we present recent research in the field of using neural\nnetworks to recognize emotions. We focus on studying emotions' recognition from\nspeech, facial expressions, and audio-visual input and show the different\ntechniques of deploying these algorithms in the real world. These three emotion\nrecognition techniques can be used as a surveillance system in healthcare\ncenters to monitor patients. We conclude the survey with a presentation of the\nchallenges and the related future work to provide an insight into the\napplications of using emotion recognition.",
    "descriptor": "\nComments: conference paper accepted and presented at 17th Int. Wireless Communications & Mobile Computing Conference - IWCMC 2021, Harbin, China\n",
    "authors": [
      "Marwan Dhuheir",
      "Abdullatif Albaseer",
      "Emna Baccour",
      "Aiman Erbad",
      "Mohamed Abdallah",
      "Mounir Hamdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.05989"
  },
  {
    "id": "arXiv:2107.05992",
    "title": "Identifying Influential Users in Unknown Social Networks for Adaptive  Incentive Allocation Under Budget Restriction",
    "abstract": "In recent years, recommendation systems have been widely applied in many\ndomains. These systems are impotent in affecting users to choose the behavior\nthat the system expects. Meanwhile, providing incentives has been proven to be\na more proactive way to affect users' behaviors. Due to the budget limitation,\nthe number of users who can be incentivized is restricted. In this light, we\nintend to utilize social influence existing among users to enhance the effect\nof incentivization. Through incentivizing influential users directly, their\nfollowers in the social network are possibly incentivized indirectly. However,\nin many real-world scenarios, the topological structure of the network is\nusually unknown, which makes identifying influential users difficult. To tackle\nthe aforementioned challenges, in this paper, we propose a novel algorithm for\nexploring influential users in unknown networks, which can estimate the\ninfluential relationships among users based on their historical behaviors and\nwithout knowing the topology of the network. Meanwhile, we design an adaptive\nincentive allocation approach that determines incentive values based on users'\npreferences and their influence ability. We evaluate the performance of the\nproposed approaches by conducting experiments on both synthetic and real-world\ndatasets. The experimental results demonstrate the effectiveness of the\nproposed approaches.",
    "descriptor": "",
    "authors": [
      "Shiqing Wu",
      "Weihua Li",
      "Hao Shen",
      "Quan Bai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05992"
  },
  {
    "id": "arXiv:2107.05997",
    "title": "Scalable, Axiomatic Explanations of Deep Alzheimer's Diagnosis from  Heterogeneous Data",
    "abstract": "Deep Neural Networks (DNNs) have an enormous potential to learn from complex\nbiomedical data. In particular, DNNs have been used to seamlessly fuse\nheterogeneous information from neuroanatomy, genetics, biomarkers, and\nneuropsychological tests for highly accurate Alzheimer's disease diagnosis. On\nthe other hand, their black-box nature is still a barrier for the adoption of\nsuch a system in the clinic, where interpretability is absolutely essential. We\npropose Shapley Value Explanation of Heterogeneous Neural Networks (SVEHNN) for\nexplaining the Alzheimer's diagnosis made by a DNN from the 3D point cloud of\nthe neuroanatomy and tabular biomarkers. Our explanations are based on the\nShapley value, which is the unique method that satisfies all fundamental axioms\nfor local explanations previously established in the literature. Thus, SVEHNN\nhas many desirable characteristics that previous work on interpretability for\nmedical decision making is lacking. To avoid the exponential time complexity of\nthe Shapley value, we propose to transform a given DNN into a Lightweight\nProbabilistic Deep Network without re-training, thus achieving a complexity\nonly quadratic in the number of features. In our experiments on synthetic and\nreal data, we show that we can closely approximate the exact Shapley value with\na dramatically reduced runtime and can reveal the hidden knowledge the network\nhas learned from the data.",
    "descriptor": "\nComments: Accepted at 2021 International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)\n",
    "authors": [
      "Sebastian P\u00f6lsterl",
      "Christina Aigner",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05997"
  },
  {
    "id": "arXiv:2107.05998",
    "title": "Motion-Aware Robotic 3D Ultrasound",
    "abstract": "Robotic three-dimensional (3D) ultrasound (US) imaging has been employed to\novercome the drawbacks of traditional US examinations, such as high\ninter-operator variability and lack of repeatability. However, object movement\nremains a challenge as unexpected motion decreases the quality of the 3D\ncompounding. Furthermore, attempted adjustment of objects, e.g., adjusting\nlimbs to display the entire limb artery tree, is not allowed for conventional\nrobotic US systems. To address this challenge, we propose a vision-based\nrobotic US system that can monitor the object's motion and automatically update\nthe sweep trajectory to provide 3D compounded images of the target anatomy\nseamlessly. To achieve these functions, a depth camera is employed to extract\nthe manually planned sweep trajectory after which the normal direction of the\nobject is estimated using the extracted 3D trajectory. Subsequently, to monitor\nthe movement and further compensate for this motion to accurately follow the\ntrajectory, the position of firmly attached passive markers is tracked in\nreal-time. Finally, a step-wise compounding was performed. The experiments on a\ngel phantom demonstrate that the system can resume a sweep when the object is\nnot stationary during scanning.",
    "descriptor": "\nComments: Accepted to ICRA2021\n",
    "authors": [
      "Zhongliang Jiang",
      "Hanyu Wang",
      "Zhenyu Li",
      "Matthias Grimm",
      "Mingchuan Zhou",
      "Ulrich Eck",
      "Sandra V. Brecht",
      "Tim C. Lueth",
      "Thomas Wendler",
      "Nassir Navab"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05998"
  },
  {
    "id": "arXiv:2107.06005",
    "title": "Recent Advances in Energy Efficient Resource Management Techniques in  Cloud Computing Environments",
    "abstract": "Nowadays cloud computing adoption as a form of hosted application and\nservices is widespread due to decreasing costs of hardware, software, and\nmaintenance. Cloud enables access to a shared pool of virtual resources hosted\nin large energy-hungry data centers for diverse information and communication\nservices with dynamic workloads. The huge energy consumption of cloud data\ncenters results in high electricity bills as well as emission of a large amount\nof carbon dioxide gas. Needless to say, efficient resource management in cloud\nenvironments has become one of the most important priorities of cloud providers\nand consequently has increased the interest of researchers to propose novel\nenergy saving solutions. This chapter presents a scientific and taxonomic\nsurvey of recent energy efficient cloud resource management' solutions in cloud\nenvironments. The main objective of this study is to propose a novel complete\ntaxonomy for energy-efficient cloud resource management solutions, review\nrecent research advancements in this area, classify the existing techniques\nbased on our proposed taxonomy, and open up new research directions. Besides,\nit reviews and surveys the literature in the range of 2015 through 2021 in the\nsubject of energy-efficient cloud resource management techniques and maps them\nto its proposed taxonomy, which unveils novel research directions and\nfacilitates the conduction of future researches.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Niloofar Gholipour",
      "Ehsan Arianyan",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06005"
  },
  {
    "id": "arXiv:2107.06009",
    "title": "Automatic Classification of Error Types in Solutions to Programming  Assignments at Online Learning Platform",
    "abstract": "Online programming courses are becoming more and more popular, but they still\nhave significant drawbacks when compared to the traditional education system,\ne.g., the lack of feedback. In this study, we apply machine learning methods to\nimprove the feedback of automated verification systems for programming\nassignments. We propose an approach that provides an insight on how to fix the\ncode for a given incorrect submission. To achieve this, we detect frequent\nerror types by clustering previously submitted incorrect solutions, label these\nclusters and use this labeled dataset to identify the type of an error in a new\nsubmission. We examine and compare several approaches to the detection of\nfrequent error types and to the assignment of clusters to new submissions. The\nproposed method is evaluated on a dataset provided by a popular online learning\nplatform.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Artyom Lobanov",
      "Timofey Bryksin",
      "Alexey Shpilman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06009"
  },
  {
    "id": "arXiv:2107.06010",
    "title": "Zero-shot Speech Translation",
    "abstract": "Speech Translation (ST) is the task of translating speech in one language\ninto text in another language. Traditional cascaded approaches for ST, using\nAutomatic Speech Recognition (ASR) and Machine Translation (MT) systems, are\nprone to error propagation. End-to-end approaches use only one system to avoid\npropagating error, yet are difficult to employ due to data scarcity. We explore\nzero-shot translation, which enables translating a pair of languages that is\nunseen during training, thus avoid the use of end-to-end ST data. Zero-shot\ntranslation has been shown to work for multilingual machine translation, yet\nhas not been studied for speech translation. We attempt to build zero-shot ST\nmodels that are trained only on ASR and MT tasks but can do ST task during\ninference. The challenge is that the representation of text and audio is\nsignificantly different, thus the models learn ASR and MT tasks in different\nways, making it non-trivial to perform zero-shot. These models tend to output\nthe wrong language when performing zero-shot ST. We tackle the issues by\nincluding additional training data and an auxiliary loss function that\nminimizes the text-audio difference. Our experiment results and analysis show\nthat the methods are promising for zero-shot ST. Moreover, our methods are\nparticularly useful in the few-shot settings where a limited amount of ST data\nis available, with improvements of up to +11.8 BLEU points compared to direct\nend-to-end ST models and +3.9 BLEU points compared to ST models fine-tuned from\npre-trained ASR model.",
    "descriptor": "",
    "authors": [
      "Tu Anh Dinh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06010"
  },
  {
    "id": "arXiv:2107.06011",
    "title": "Teaching Agents how to Map: Spatial Reasoning for Multi-Object  Navigation",
    "abstract": "In the context of visual navigation, the capacity to map a novel environment\nis necessary for an agent to exploit its observation history in the considered\nplace and efficiently reach known goals. This ability can be associated with\nspatial reasoning, where an agent is able to perceive spatial relationships and\nregularities, and discover object affordances. In classical Reinforcement\nLearning (RL) setups, this capacity is learned from reward alone. We introduce\nsupplementary supervision in the form of auxiliary tasks designed to favor the\nemergence of spatial perception capabilities in agents trained for a\ngoal-reaching downstream objective. We show that learning to estimate metrics\nquantifying the spatial relationships between an agent at a given location and\na goal to reach has a high positive impact in Multi-Object Navigation settings.\nOur method significantly improves the performance of different baseline agents,\nthat either build an explicit or implicit representation of the environment,\neven matching the performance of incomparable oracle agents taking ground-truth\nmaps as input.",
    "descriptor": "",
    "authors": [
      "Pierre Marza",
      "Laetitia Matignon",
      "Olivier Simonin",
      "Christian Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06011"
  },
  {
    "id": "arXiv:2107.06015",
    "title": "A Classification of Artificial Intelligence Systems for Mathematics  Education",
    "abstract": "This chapter provides an overview of the different Artificial Intelligence\n(AI) systems that are being used in contemporary digital tools for Mathematics\nEducation (ME). It is aimed at researchers in AI and Machine Learning (ML), for\nwhom we shed some light on the specific technologies that are being used in\neducational applications; and at researchers in ME, for whom we clarify: i)\nwhat the possibilities of the current AI technologies are, ii) what is still\nout of reach and iii) what is to be expected in the near future. We start our\nanalysis by establishing a high-level taxonomy of AI tools that are found as\ncomponents in digital ME applications. Then, we describe in detail how these AI\ntools, and in particular ML, are being used in two key applications,\nspecifically AI-based calculators and intelligent tutoring systems. We finish\nthe chapter with a discussion about student modeling systems and their\nrelationship to artificial general intelligence.",
    "descriptor": "\nComments: Chapter in the upcoming book \"Mathematics Education in the Age of Artificial Intelligence: How Artificial Intelligence can serve Mathematical Human Learning\", Springer Nature, edited by P.R. Richard, P. V\\'elez, and S. Van Vaerenbergh\n",
    "authors": [
      "Steven Van Vaerenbergh",
      "Adri\u00e1n P\u00e9rez-Suay"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2107.06015"
  },
  {
    "id": "arXiv:2107.06018",
    "title": "This Person (Probably) Exists. Identity Membership Attacks Against GAN  Generated Faces",
    "abstract": "Recently, generative adversarial networks (GANs) have achieved stunning\nrealism, fooling even human observers. Indeed, the popular tongue-in-cheek\nwebsite {\\small \\url{ this http URL}}, taunts users with\nGAN generated images that seem too real to believe. On the other hand, GANs do\nleak information about their training data, as evidenced by membership attacks\nrecently demonstrated in the literature. In this work, we challenge the\nassumption that GAN faces really are novel creations, by constructing a\nsuccessful membership attack of a new kind. Unlike previous works, our attack\ncan accurately discern samples sharing the same identity as training samples\nwithout being the same samples. We demonstrate the interest of our attack\nacross several popular face datasets and GAN training procedures. Notably, we\nshow that even in the presence of significant dataset diversity, an over\nrepresented person can pose a privacy concern.",
    "descriptor": "",
    "authors": [
      "Ryan Webster",
      "Julien Rabin",
      "Loic Simon",
      "Frederic Jurie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06018"
  },
  {
    "id": "arXiv:2107.06020",
    "title": "A Deep Generative Artificial Intelligence system to decipher species  coexistence patterns",
    "abstract": "1. Deciphering coexistence patterns is a current challenge to understanding\ndiversity maintenance, especially in rich communities where the complexity of\nthese patterns is magnified through indirect interactions that prevent their\napproximation with classical experimental approaches. 2. We explore\ncutting-edge Machine Learning techniques called Generative Artificial\nIntelligence (GenAI) to decipher species coexistence patterns in vegetation\npatches, training generative adversarial networks (GAN) and variational\nAutoEncoders (VAE) that are then used to unravel some of the mechanisms behind\ncommunity assemblage. 3. The GAN accurately reproduces the species composition\nof real patches as well as the affinity of plant species to different soil\ntypes, and the VAE also reaches a high level of accuracy, above 99%. Using the\nartificially generated patches, we found that high order interactions tend to\nsuppress the positive effects of low order interactions. Finally, by\nreconstructing successional trajectories we could identify the pioneer species\nwith larger potential to generate a high diversity of distinct patches in terms\nof species composition. 4. Understanding the complexity of species coexistence\npatterns in diverse ecological communities requires new approaches beyond\nheuristic rules. Generative Artificial Intelligence can be a powerful tool to\nthis end as it allows to overcome the inherent dimensionality of this\nchallenge.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "J. Hirn",
      "J. E. Garc\u00eda",
      "A. Montesinos-Navarro",
      "R. Sanchez-Mart\u00edn",
      "V. Sanz",
      "M. Verd\u00fa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06020"
  },
  {
    "id": "arXiv:2107.06024",
    "title": "A Model-Driven Methodology for Automotive Cybersecurity Test Case  Generation",
    "abstract": "Through international regulations (most prominently the latest UNECE\nregulation) and standards, the already widely perceived higher need for\ncybersecurity in automotive systems has been recognized and will mandate higher\nefforts for cybersecurity engineering. T he UNECE also demands the\neffectiveness of these engineering to be verified and validated through\ntesting. T his requires both a significantly higher rate and more\ncomprehensiveness of cybersecurity testing that is not effectively to cope with\nusing current, predominantly manual, automotive cybersecurity testing\ntechniques. To allow for comprehensive and efficient testing at all stages of\nthe automotive life cycle, including supply chain parts not at band, and to\nfacilitate efficient third party testing, as well as to test under real-world\nconditions, also methodologies for testing the cybersecurity of vehicular\nsystems as a black box are necessary. T his paper therefore presents a model\nand attack tree-based approach to (semi-)automate automotive cybersecurity\ntesting, as well as considerations for automatically black box-deriving models\nfor the use in attack modeling.",
    "descriptor": "\nComments: 7 pages, 6 figures, accepted for the joint SRCNAS/STRIVE workshop at the 6th IEEE European Symposium on Security and Privacy\n",
    "authors": [
      "Stefan Marksteiner",
      "Peter Priller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06024"
  },
  {
    "id": "arXiv:2107.06031",
    "title": "Understanding Factors Affecting Fuel Consumption of Vehicles Through  Explainable AI: A Use Case With Explainable Boosting Machines",
    "abstract": "A significant economic cost for many companies that operate with fleets of\nvehicles is related to their fuel consumption. This consumption can be reduced\nby acting over some aspects, such as the driving behaviour style of vehicle\ndrivers. Improving driving behaviour (and other features) can save fuel on a\nfleet of vehicles without needing to change other aspects, such as the planned\nroutes or stops. This is important not only for mitigating economic costs\nwithin a company, but also for reducing the emissions associated to fuel\nconsumption, mainly when the vehicles have petrol or diesel engines. In this\npaper we show how Explainable Artificial Intelligence (XAI) can be useful for\nquantifying the impact that different feature groups have on the fuel\nconsumption of a particular fleet. For that, we use Explainable Boosting\nMachines (EBM) that are trained over different features (up to 70) in order to\nfirst model the relationship between them and the fuel consumption, and then\nexplain it. With it, we compare the explanations provided by the EBM with\ngeneral references from the literature that estimate the potential impact that\nthose features may have on the fuel consumption, in order to validate this\napproach. We work with several real-world industry datasets that represent\ndifferent types of fleets, from ones that have passenger cars to others that\ninclude heavy-duty vehicles such as trucks.",
    "descriptor": "\nComments: 29 pages, 15 Figures\n",
    "authors": [
      "Alberto Barbado",
      "\u00d3scar Corcho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06031"
  },
  {
    "id": "arXiv:2107.06038",
    "title": "A cell-centered implicit-explicit Lagrangian scheme for a unified model  of nonlinear continuum mechanics on unstructured meshes",
    "abstract": "A cell-centered implicit-explicit updated Lagrangian finite volume scheme on\nunstructured grids is proposed for a unified first order hyperbolic formulation\nof continuum fluid and solid mechanics. The scheme provably respects the stiff\nrelaxation limits of the continuous model at the fully discrete level, thus it\nis asymptotic preserving. Furthermore, the GCL is satisfied by a compatible\ndiscretization that makes use of a nodal solver to compute vertex-based fluxes\nthat are used both for the motion of the computational mesh as well as for the\ntime evolution of the governing PDEs. Second-order accuracy in space is\nachieved using a TVD piecewise linear reconstruction, while an\nimplicit-explicit (IMEX) Runge-Kutta time discretization allows the scheme to\nobtain higher accuracy also in time. Particular care is devoted to the design\nof a stiff ODE solver, based on approximate analytical solutions of the\ngoverning equations, that plays a crucial role when the visco-plastic limit of\nthe model is approached. We demonstrate the accuracy and robustness of the\nscheme on a wide spectrum of material responses covered by the unified\ncontinuum model that includes inviscid hydrodynamics, viscous heat conducting\nfluids, elastic and elasto-plastic solids in multidimensional settings.",
    "descriptor": "",
    "authors": [
      "Walter Boscheri",
      "Simone Chiocchetti",
      "Ilya Peshkov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2107.06038"
  },
  {
    "id": "arXiv:2107.06039",
    "title": "AutoScore-Imbalance: An interpretable machine learning tool for  development of clinical scores with rare events data",
    "abstract": "Background: Medical decision-making impacts both individual and public\nhealth. Clinical scores are commonly used among a wide variety of\ndecision-making models for determining the degree of disease deterioration at\nthe bedside. AutoScore was proposed as a useful clinical score generator based\non machine learning and a generalized linear model. Its current framework,\nhowever, still leaves room for improvement when addressing unbalanced data of\nrare events. Methods: Using machine intelligence approaches, we developed\nAutoScore-Imbalance, which comprises three components: training dataset\noptimization, sample weight optimization, and adjusted AutoScore. All scoring\nmodels were evaluated on the basis of their area under the curve (AUC) in the\nreceiver operating characteristic analysis and balanced accuracy (i.e., mean\nvalue of sensitivity and specificity). By utilizing a publicly accessible\ndataset from Beth Israel Deaconess Medical Center, we assessed the proposed\nmodel and baseline approaches in the prediction of inpatient mortality.\nResults: AutoScore-Imbalance outperformed baselines in terms of AUC and\nbalanced accuracy. The nine-variable AutoScore-Imbalance sub-model achieved the\nhighest AUC of 0.786 (0.732-0.839) while the eleven-variable original AutoScore\nobtained an AUC of 0.723 (0.663-0.783), and the logistic regression with 21\nvariables obtained an AUC of 0.743 (0.685-0.800). The AutoScore-Imbalance\nsub-model (using down-sampling algorithm) yielded an AUC of 0. 0.771\n(0.718-0.823) with only five variables, demonstrating a good balance between\nperformance and variable sparsity. Conclusions: The AutoScore-Imbalance tool\nhas the potential to be applied to highly unbalanced datasets to gain further\ninsight into rare medical events and to facilitate real-world clinical\ndecision-making.",
    "descriptor": "",
    "authors": [
      "Han Yuan",
      "Feng Xie",
      "Marcus Eng Hock Ong",
      "Yilin Ning",
      "Marcel Lucas Chee",
      "Seyed Ehsan Saffari",
      "Hairil Rizal Abdullah",
      "Benjamin Alan Goldstein",
      "Bibhas Chakraborty",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06039"
  },
  {
    "id": "arXiv:2107.06041",
    "title": "Tales of a City: Sentiment Analysis of Urban Green Space in Dublin",
    "abstract": "Social media services such as TripAdvisor and Foursquare can provide\nopportunities for users to exchange their opinions about urban green space\n(UGS). Visitors can exchange their experiences with parks, woods, and wetlands\nin social communities via social networks. In this work, we implement a unified\ntopic modeling approach to reveal UGS characteristics. Leveraging Artificial\nIntelligence techniques for opinion mining using the mentioned platforms (e.g.,\nTripAdvisor and Foursquare) reviews is a novel application to UGS quality\nassessments. We show how specific characteristics of different green spaces can\nbe explored by using a tailor-optimized sentiment analysis model. Such an\napplication can support local authorities and stakeholders in\nunderstanding--and justification for--future urban green space investments.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Mohammadhossein Ghahramani",
      "Nadina Galle",
      "Carlo Ratti",
      "Francesco Pilla"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06041"
  },
  {
    "id": "arXiv:2107.06042",
    "title": "Finite Model Property and Bisimulation for LFD",
    "abstract": "Recently, Baltag and van Benthem arXiv:2103.14946 [cs.LO] introduced a new\ndecidable logic of functional dependence (LFD) with local dependence formulas\nand dependence quantifiers. The language is interpreted over dependence models,\nwhich are pairs of first-order structures with a set of available variable\nassignments, also called a team. The team associated with a dependence model\ncan be seen as a labelled transition system over which LFD becomes a modal\nlogic, where the dependence quantifiers become modalities and local dependence\nformulas are treated as special atoms. In this paper, we introduce appropriate\nnotions of bisimulation characterizing LFD (and some related logics) as a\nfragment of first order logic (FOL), and show it is equivalent to a notion of\nbisimulation along more standard lines proposed in arXiv:2102.10368 [cs.LO],\nyet more efficient for bisimilarity-checking. Our main result is that LFD has\nthe finite model property (FMP), by a new application of Herwig's theorem on\nextending partial isomorphisms.",
    "descriptor": "\nComments: 15 pages, submitted for GandALF 2021 conference\n",
    "authors": [
      "Raoul Koudijs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06042"
  },
  {
    "id": "arXiv:2107.06045",
    "title": "Injecting Finiteness to Prove Completeness for Finite Linear Temporal  Logic",
    "abstract": "Temporal logics over finite traces are not the same as temporal logics over\npotentially infinite traces. Ro\\c{s}u first proved completeness for linear\ntemporal logic on finite traces (LTLf) with a novel coinductive axiom. We offer\na different proof, with fewer, more conventional axioms. Our proof is a direct\nadaptation of Kr\\\"{o}ger and Merz's Henkin-Hasenjaeger-style proof. The essence\nof our adaption is that we \"inject\" finiteness: that is, we alter the proof\nstructure to ensure that models are finite. We aim to present a thorough,\naccessible proof.",
    "descriptor": "",
    "authors": [
      "Eric Campbell",
      "Michael Greenberg"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06045"
  },
  {
    "id": "arXiv:2107.06048",
    "title": "A Graph Data Augmentation Strategy with Entropy Preserving",
    "abstract": "The Graph Convolutional Networks (GCNs) proposed by Kipf and Welling are\neffective models for semi-supervised learning, but facing the obstacle of\nover-smoothing, which will weaken the representation ability of GCNs. Recently\nsome works are proposed to tackle with above limitation by randomly perturbing\ngraph topology or feature matrix to generate data augmentations as input for\ntraining. However, these operations have to pay the price of information\nstructure integrity breaking, and inevitably sacrifice information\nstochastically from original graph. In this paper, we introduce a novel graph\nentropy definition as an quantitative index to evaluate feature information\ndiffusion among a graph. Under considerations of preserving graph entropy, we\npropose an effective strategy to generate perturbed training data using a\nstochastic mechanism but guaranteeing graph topology integrity and with only a\nsmall amount of graph entropy decaying. Extensive experiments have been\nconducted on real-world datasets and the results verify the effectiveness of\nour proposed method in improving semi-supervised node classification accuracy\ncompared with a surge of baselines. Beyond that, our proposed approach\nsignificantly enhances the robustness and generalization ability of GCNs during\nthe training process.",
    "descriptor": "",
    "authors": [
      "Xue Liu",
      "Dan Sun",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06048"
  },
  {
    "id": "arXiv:2107.06049",
    "title": "Argus: A Fully Transparent Incentive System for Anti-Piracy Campaigns  (Extended Version)",
    "abstract": "Anti-piracy is fundamentally a procedure that relies on collecting data from\nthe open anonymous population, so how to incentivize credible reporting is a\nquestion at the center of the problem. Industrial alliances and companies are\nrunning anti-piracy incentive campaigns, but their effectiveness is publicly\nquestioned due to the lack of transparency. We believe that full transparency\nof a campaign is necessary to truly incentivize people. It means that every\nrole, e.g., content owner, licensee of the content, or every person in the open\npopulation, can understand the mechanism and be assured about its execution\nwithout trusting any single role.\nWe see this as a distributed system problem. In this paper, we present Argus,\na fully transparent incentive system for anti-piracy campaigns. The groundwork\nof Argus is to formulate the objectives for fully transparent incentive\nmechanisms, which securely and comprehensively consolidate the different\ninterests of all roles. These objectives form the core of the Argus design,\nhighlighted by our innovations about a Sybil-proof incentive function, a\ncommit-and-reveal scheme, and an oblivious transfer scheme. In the\nimplementation, we overcome a set of unavoidable obstacles to ensure security\ndespite full transparency. Moreover, we effectively optimize several\ncryptographic operations so that the cost for a piracy reporting is reduced to\nan equivalent cost of sending about 14 ETH-transfer transactions to run on the\npublic Ethereum network, which would otherwise correspond to thousands of\ntransactions. With the security and practicality of Argus, we hope real-world\nanti-piracy campaigns will be truly effective by shifting to a fully\ntransparent incentive mechanism.",
    "descriptor": "\nComments: To appear in SRDS 2021. This is an extended version\n",
    "authors": [
      "Xian Zhang",
      "Xiaobing Guo",
      "Zixuan Zeng",
      "Wenyan Liu",
      "Zhongxin Guo",
      "Yang Chen",
      "Shuo Chen",
      "Qiufeng Yin",
      "Mao Yang",
      "Lidong Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06049"
  },
  {
    "id": "arXiv:2107.06050",
    "title": "Force-in-domain GAN inversion",
    "abstract": "Empirical works suggest that various semantics emerge in the latent space of\nGenerative Adversarial Networks (GANs) when being trained to generate images.\nTo perform real image editing, it requires an accurate mapping from the real\nimage to the latent space to leveraging these learned semantics, which is\nimportant yet difficult. An in-domain GAN inversion approach is recently\nproposed to constraint the inverted code within the latent space by forcing the\nreconstructed image obtained from the inverted code within the real image\nspace. Empirically, we find that the inverted code by the in-domain GAN can\ndeviate from the latent space significantly. To solve this problem, we propose\na force-in-domain GAN based on the in-domain GAN, which utilizes a\ndiscriminator to force the inverted code within the latent space. The\nforce-in-domain GAN can also be interpreted by a cycle-GAN with slight\nmodification. Extensive experiments show that our force-in-domain GAN not only\nreconstructs the target image at the pixel level, but also align the inverted\ncode with the latent space well for semantic editing.",
    "descriptor": "",
    "authors": [
      "Guangjie Leng",
      "Yeku Zhu",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06050"
  },
  {
    "id": "arXiv:2107.06051",
    "title": "Rating Facts under Coarse-to-fine Regimes",
    "abstract": "The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.",
    "descriptor": "",
    "authors": [
      "Guojun Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06051"
  },
  {
    "id": "arXiv:2107.06054",
    "title": "Parallelisable Existential Rules: a Story of Pieces",
    "abstract": "In this paper, we consider existential rules, an expressive formalism well\nsuited to the representation of ontological knowledge and data-to-ontology\nmappings in the context of ontology-based data integration. The chase is a\nfundamental tool to do reasoning with existential rules as it computes all the\nfacts entailed by the rules from a database instance. We introduce\nparallelisable sets of existential rules, for which the chase can be computed\nin a single breadth-first step from any instance. The question we investigate\nis the characterization of such rule sets. We show that parallelisable rule\nsets are exactly those rule sets both bounded for the chase and belonging to a\nnovel class of rules, called pieceful. The pieceful class includes in\nparticular frontier-guarded existential rules and (plain) datalog. We also give\nanother characterization of parallelisable rule sets in terms of rule\ncomposition based on rewriting.",
    "descriptor": "",
    "authors": [
      "Maxime Buron",
      "Marie-Laure Mugnier",
      "Micha\u00ebl Thomazo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.06054"
  },
  {
    "id": "arXiv:2107.06055",
    "title": "On the Difficulty of Translating Free-Order Case-Marking Languages",
    "abstract": "Identifying factors that make certain languages harder to model than others\nis essential to reach language equality in future Natural Language Processing\ntechnologies. Free-order case-marking languages, such as Russian, Latin or\nTamil, have proved more challenging than fixed-order languages for the tasks of\nsyntactic parsing and subject-verb agreement prediction. In this work, we\ninvestigate whether this class of languages is also more difficult to translate\nby state-of-the-art Neural Machine Translation models (NMT). Using a variety of\nsynthetic languages and a newly introduced translation challenge set, we find\nthat word order flexibility in the source language only leads to a very small\nloss of NMT quality, even though the core verb arguments become impossible to\ndisambiguate in sentences without semantic cues. The latter issue is indeed\nsolved by the addition of case marking. However, in medium- and low-resource\nsettings, the overall NMT quality of fixed-order languages remains unmatched.",
    "descriptor": "\nComments: Accepted to TACL, pre-MIT Press publication version\n",
    "authors": [
      "Arianna Bisazza",
      "Ahmet \u00dcst\u00fcn",
      "Stephan Sportel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06055"
  },
  {
    "id": "arXiv:2107.06056",
    "title": "Indian Legal NLP Benchmarks : A Survey",
    "abstract": "Availability of challenging benchmarks is the key to advancement of AI in a\nspecific field.Since Legal Text is significantly different than normal English\ntext, there is a need to create separate Natural Language Processing benchmarks\nfor Indian Legal Text which are challenging and focus on tasks specific to\nLegal Systems. This will spur innovation in applications of Natural language\nProcessing for Indian Legal Text and will benefit AI community and Legal\nfraternity. We review the existing work in this area and propose ideas to\ncreate new benchmarks for Indian Legal Natural Language Processing.",
    "descriptor": "",
    "authors": [
      "Prathamesh Kalamkar",
      "Janani Venugopalan Ph.D.",
      "Vivek Raghavan Ph.D"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06056"
  },
  {
    "id": "arXiv:2107.06057",
    "title": "Fast-Slow Streamflow Model Using Mass-Conserving LSTM",
    "abstract": "Streamflow forecasting is key to effectively managing water resources and\npreparing for the occurrence of natural calamities being exacerbated by climate\nchange. Here we use the concept of fast and slow flow components to create a\nnew mass-conserving Long Short-Term Memory (LSTM) neural network model. It uses\nhydrometeorological time series and catchment attributes to predict daily river\ndischarges. Preliminary results evidence improvement in skills for different\nscores compared to the recent literature.",
    "descriptor": "",
    "authors": [
      "Miguel Paredes Qui\u00f1ones",
      "Maciel Zortea",
      "Leonardo S. A. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06057"
  },
  {
    "id": "arXiv:2107.06061",
    "title": "Deterministic Identification Over Poisson Channels",
    "abstract": "Deterministic identification (DI) for the discrete-time Poisson channel,\nsubject to an average and a peak power constraint, is considered. It is\nestablished that the code size scales as $2^{(n\\log n)R}$, where $n$ and $R$\nare the block length and coding rate, respectively. The authors have recently\nshown a similar property for Gaussian channels [1]. Lower and upper bounds on\nthe DI capacity of the Poisson channel are developed in this scale. Those imply\nthat the DI capacity is infinite in the exponential scale, regardless of the\ndark current, i.e., the channel noise parameter.",
    "descriptor": "",
    "authors": [
      "Mohammad J. Salariseddigh",
      "Uzi Pereg",
      "Holger Boche",
      "Christian Deppe",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06061"
  },
  {
    "id": "arXiv:2107.06064",
    "title": "Model of the Weak Reset Process in HfOx Resistive Memory for Deep  Learning Frameworks",
    "abstract": "The implementation of current deep learning training algorithms is\npower-hungry, owing to data transfer between memory and logic units.\nOxide-based RRAMs are outstanding candidates to implement in-memory computing,\nwhich is less power-intensive. Their weak RESET regime, is particularly\nattractive for learning, as it allows tuning the resistance of the devices with\nremarkable endurance. However, the resistive change behavior in this regime\nsuffers many fluctuations and is particularly challenging to model, especially\nin a way compatible with tools used for simulating deep learning. In this work,\nwe present a model of the weak RESET process in hafnium oxide RRAM and\nintegrate this model within the PyTorch deep learning framework. Validated on\nexperiments on a hybrid CMOS/RRAM technology, our model reproduces both the\nnoisy progressive behavior and the device-to-device (D2D) variability. We use\nthis tool to train Binarized Neural Networks for the MNIST handwritten digit\nrecognition task and the CIFAR-10 object classification task. We simulate our\nmodel with and without various aspects of device imperfections to understand\ntheir impact on the training process and identify that the D2D variability is\nthe most detrimental aspect. The framework can be used in the same manner for\nother types of memories to identify the device imperfections that cause the\nmost degradation, which can, in turn, be used to optimize the devices to reduce\nthe impact of these imperfections.",
    "descriptor": "",
    "authors": [
      "Atreya Majumdar",
      "Marc Bocquet",
      "Tifenn Hirtzlin",
      "Axel Laborieux",
      "Jacques-Olivier Klein",
      "Etienne Nowak",
      "Elisa Vianello",
      "Jean-Michel Portal",
      "Damien Querlioz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06064"
  },
  {
    "id": "arXiv:2107.06065",
    "title": "Pattern Discovery and Validation Using Scientific Research Methods",
    "abstract": "Pattern discovery, the process of discovering previously unrecognized\npatterns, is often performed as an ad-hoc process with little resulting\ncertainty in the quality of the proposed patterns. Pattern validation, the\nprocess of validating the accuracy of proposed patterns, remains dominated by\nthe simple heuristic of \"the rule of three\". This article shows how to use\nestablished scientific research methods for the purpose of pattern discovery\nand validation. We present a specific approach, called the handbook method,\nthat uses the qualitative survey, action research, and case study research for\npattern discovery and evaluation, and we discuss the underlying principle of\nusing scientific methods in general. We evaluate the handbook method using\nthree exploratory studies and demonstrate its usefulness.",
    "descriptor": "",
    "authors": [
      "Dirk Riehle",
      "Nikolay Harutyunyan",
      "Ann Barcomb"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06065"
  },
  {
    "id": "arXiv:2107.06067",
    "title": "Generalized \"Square roots of Not\" matrices, their application to the  unveiling of hidden logical operators and to the definition of fully matrix  circular Euler functions",
    "abstract": "The square root of Not is a logical operator of importance in quantum\ncomputing theory and of interest as a mathematical object in its own right. In\nphysics, it is a square complex matrix of dimension 2. In the present work it\nis a complex square matrix of arbitrary dimension. The introduction of linear\nalgebra into logical theory has been enhanced in recent decades by the\nresearches in the field of neural networks and quantum computing. Here we will\nmake a brief description of the representation of logical operations through\nmatrices and we show how general expressions for the two square roots of the\nNot operator are obtained. Then, we explore two topics. First, we study an\nextension to a non-quantum domain of a short form of Deutsch's algorithm. Then,\nwe assume that a root of Not is a matrix extension of the imaginary unit i, and\nunder this idea we obtain fully matrix versions for the Euler expansions and\nfor the representations of circular functions by complex exponentials.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Eduardo Mizraji"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06067"
  },
  {
    "id": "arXiv:2107.06068",
    "title": "Calibrated Uncertainty for Molecular Property Prediction using Ensembles  of Message Passing Neural Networks",
    "abstract": "Data-driven methods based on machine learning have the potential to\naccelerate analysis of atomic structures. However, machine learning models can\nproduce overconfident predictions and it is therefore crucial to detect and\nhandle uncertainty carefully. Here, we extend a message passing neural network\ndesigned specifically for predicting properties of molecules and materials with\na calibrated probabilistic predictive distribution. The method presented in\nthis paper differs from the previous work by considering both aleatoric and\nepistemic uncertainty in a unified framework, and by re-calibrating the\npredictive distribution on unseen data. Through computer experiments, we show\nthat our approach results in accurate models for predicting molecular formation\nenergies with calibrated uncertainty in and out of the training data\ndistribution on two public molecular benchmark datasets, QM9 and PC9. The\nproposed method provides a general framework for training and evaluating neural\nnetwork ensemble models that are able to produce accurate predictions of\nproperties of molecules with calibrated uncertainty.",
    "descriptor": "",
    "authors": [
      "Jonas Busk",
      "Peter Bj\u00f8rn J\u00f8rgensen",
      "Arghya Bhowmik",
      "Mikkel N. Schmidt",
      "Ole Winther",
      "Tejs Vegge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06068"
  },
  {
    "id": "arXiv:2107.06071",
    "title": "aiSTROM -- A roadmap for developing a successful AI strategy",
    "abstract": "A total of 34% of AI research and development projects fails or are\nabandoned, according to a recent survey by Rackspace Technology of 1,870\ncompanies. We propose a new strategic framework, aiSTROM, that empowers\nmanagers to create a successful AI strategy based on a thorough literature\nreview. This provides a unique and integrated approach that guides managers and\nlead developers through the various challenges in the implementation process.\nIn the aiSTROM framework, we start by identifying the top n potential projects\n(typically 3-5). For each of those, seven areas of focus are thoroughly\nanalysed. These areas include creating a data strategy that takes into account\nunique cross-departmental machine learning data requirements, security, and\nlegal requirements. aiSTROM then guides managers to think about how to put\ntogether an interdisciplinary artificial intelligence (AI) implementation team\ngiven the scarcity of AI talent. Once an AI team strategy has been established,\nit needs to be positioned within the organization, either cross-departmental or\nas a separate division. Other considerations include AI as a service (AIaas),\nor outsourcing development. Looking at new technologies, we have to consider\nchallenges such as bias, legality of black-box-models, and keeping humans in\nthe loop. Next, like any project, we need value-based key performance\nindicators (KPIs) to track and validate the progress. Depending on the\ncompany's risk-strategy, a SWOT analysis (strengths, weaknesses, opportunities,\nand threats) can help further classify the shortlisted projects. Finally, we\nshould make sure that our strategy includes continuous education of employees\nto enable a culture of adoption. This unique and comprehensive framework offers\na valuable, literature supported, tool for managers and lead developers.",
    "descriptor": "",
    "authors": [
      "Dorien Herremans"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06071"
  },
  {
    "id": "arXiv:2107.06072",
    "title": "Fragility curves for power transmission towers in Odisha, India, based  on observed damage during 2019 Cyclone Fani",
    "abstract": "Lifeline infrastructure systems such as a power transmission network in\ncoastal regions are vulnerable to strong winds generated during tropical\ncyclones. Understanding the fragility of individual towers is helpful in\nimproving the resilience of such systems. Fragility curves have been developed\nin the past for some regions, but without considering relevant epistemic\nuncertainties. Further, risk and resilience studies are best performed using\nthe fragility curves specific to a region. Such studies become particularly\nimportant if the region is exposed to cyclones rather frequently. This paper\npresents the development of fragility curves for high-voltage power\ntransmission towers in the state of Odisha, India, based on macro-level damage\ndata from 2019 cyclone Fani, which was obtained through concerned government\noffices. Two types of damages were identified, namely, collapse and partial\ndamage. Accordingly, fragility curves for collapse and functionality disruption\ndamage states were developed considering relevant aleatory and epistemic\nuncertainties. The latter class of uncertainties included that associated with\nwind speed estimation at a location and the finite sample uncertainty. The most\nsignificant contribution in the epistemic uncertainty was due to the wind speed\nestimation at a location. The median and logarithmic standard deviation for the\n50th percentile fragility curve associated with collapse was close to that for\nthe functionality disruption damage state. These curves also compared\nreasonably well with those reported for similar structures in other parts of\nthe world.",
    "descriptor": "",
    "authors": [
      "Surender V Raj",
      "Manish Kumar",
      "Udit Bhatia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.06072"
  },
  {
    "id": "arXiv:2107.06073",
    "title": "Numerical approximation of statistical solutions of the incompressible  Navier-Stokes Equations",
    "abstract": "Statistical solutions, which are time-parameterized probability measures on\nspaces of square-integrable functions, have been established as a suitable\nframework for global solutions of incompressible Navier-Stokes equations (NSE).\nWe compute numerical approximations of statistical solutions of NSE on\ntwo-dimensional domains with non-periodic boundary conditions and empirically\ninvestigate the convergence of these approximations and their observables. For\nthe numerical solver, we use Monte Carlo sampling with an H(div)-FEM based\ndeterministic solver. Our numerical experiments for high Reynolds number\nturbulent flows demonstrate that the statistics and observables of the\napproximations converge. We also develop a novel algorithm to compute structure\nfunctions on unstructured meshes.",
    "descriptor": "",
    "authors": [
      "Pratyuksh Bansal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2107.06073"
  },
  {
    "id": "arXiv:2107.06074",
    "title": "On Choice of Hyper-parameter in Extreme Value Theory based on Machine  Learning Techniques",
    "abstract": "Extreme value theory (EVT) is a statistical tool for analysis of extreme\nevents. It has a strong theoretical background, however, we need to choose\nhyper-parameters\nto apply EVT. In recent studies of machine learning, techniques of choosing\nhyper-parameters have been well-studied. In this paper, we propose a new method\nof choosing hyper-parameters in EVT based on machine learning techniques. We\nalso experiment our method to real-world data and show good usability of our\nmethod.",
    "descriptor": "",
    "authors": [
      "Chikara Nakamura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06074"
  },
  {
    "id": "arXiv:2107.06075",
    "title": "A Rational Entailment for Expressive Description Logics via Description  Logic Programs",
    "abstract": "Lehmann and Magidor's rational closure is acknowledged as a landmark in the\nfield of non-monotonic logics and it has also been re-formulated in the context\nof Description Logics (DLs).\nWe show here how to model a rational form of entailment for expressive DLs,\nsuch as SROIQ, providing a novel reasoning procedure that compiles a\nnon-monotone DL knowledge base into a description logic program (dl-program).",
    "descriptor": "",
    "authors": [
      "Giovanni Casini",
      "Umberto Straccia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06075"
  },
  {
    "id": "arXiv:2107.06080",
    "title": "Practical and Configurable Network Traffic Classification Using  Probabilistic Machine Learning",
    "abstract": "Network traffic classification that is widely applicable and highly accurate\nis valuable for many network security and management tasks. A flexible and\neasily configurable classification framework is ideal, as it can be customized\nfor use in a wide variety of networks. In this paper, we propose a highly\nconfigurable and flexible machine learning traffic classification method that\nrelies only on statistics of sequences of packets to distinguish known, or\napproved, traffic from unknown traffic. Our method is based on likelihood\nestimation, provides a measure of certainty for classification decisions, and\ncan classify traffic at adjustable certainty levels. Our classification method\ncan also be applied in different classification scenarios, each prioritizing a\ndifferent classification goal. We demonstrate how our classification scheme and\nall its configurations perform well on real-world traffic from a high\nperformance computing network environment.",
    "descriptor": "\nComments: Published in the Springer Cluster Computing journal\n",
    "authors": [
      "Jiahui Chen",
      "Joe Breen",
      "Jeff M. Phillips",
      "Jacobus Van der Merwe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06080"
  },
  {
    "id": "arXiv:2107.06083",
    "title": "A New Approach for Semantic Web Matching",
    "abstract": "In this work we propose a new approach for semantic web matching to improve\nthe performance of Web Service replacement. Because in automatic systems we\nshould ensure the self-healing, self-configuration, self-optimization and\nself-management, all services should be always available and if one of them\ncrashes, it should be replaced with the most similar one. Candidate services\nare advertised in Universal Description, Discovery and Integration (UDDI) all\nin Web Ontology Language (OWL). By the help of bipartite graph, we did the\nmatching between the crashed service and a Candidate one. Then we chose the\nbest service, which had the maximum rate of matching. In fact we compare two\nservices` functionalities and capabilities to see how much they match. We found\nthat the best way for matching two web services, is comparing the\nfunctionalities of them.",
    "descriptor": "\nComments: 9 pages, 6 figures, SUComS 2010\n",
    "authors": [
      "Kamran Zamanifar",
      "Golsa Heidari",
      "Naser Nematbakhsh",
      "Farhad Mardookhi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06083"
  },
  {
    "id": "arXiv:2107.06084",
    "title": "Decentralized LTL Enforcement",
    "abstract": "We consider the runtime enforcement of Linear-time Temporal Logic formulas on\ndecentralized systems. A so-called enforcer is attached to each system\ncomponent and observes its local trace. Should the global trace violate the\nspecification, the enforcers coordinate to correct their local traces. We\nformalize the decentralized runtime enforcement problem and define the expected\nproperties of enforcers, namely soundness, transparency and optimality. We\npresent two enforcement algorithms. In the first one, the enforcers explore all\npossible local modifications to find the best global correction. Although this\nguarantees an optimal correction, it forces the system to synchronize and is\nmore costly, computation and communication wise. In the second one, each\nenforcer makes a local correction before communicating. The reduced cost of\nthis version comes at the price of the optimality of the enforcer corrections.",
    "descriptor": "",
    "authors": [
      "Florian Gallay",
      "Yli\u00e8s Falcone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.06084"
  },
  {
    "id": "arXiv:2107.06090",
    "title": "PakeMail: authentication and key management in decentralized secure  email and messaging via PAKE",
    "abstract": "We propose the use of PAKE for achieving and enhancing entity authentication\n(EA) and key management (KM) in the context of decentralized end-to-end\nencrypted email and secure messaging, i.e., where neither a public key\ninfrastructure nor trusted third parties are used. This approach not only\nsimplifies the EA process by requiring users to share only a low-entropy\nsecret, e.g., a memorable word, but it also allows us to establish a\nhigh-entropy secret key; this key enables a series of cryptographic\nenhancements and security properties, which are hard to achieve using\nout-of-band (OOB) authentication. We first study a few vulnerabilities in\nvoice-based OOB authentication, in particular a combinatorial attack against\nlazy users, which we analyze in the context of a secure email solution. We then\npropose tackling public key authentication by solving the problem of \"secure\nequality test\" using PAKE, and discuss various protocols and their properties.\nThis method enables the automation of important KM tasks (e.g. key renewal and\nfuture key pair authentications), reduces the impact of human errors, and lends\nitself to the asynchronous nature of email and modern messaging. It also\nprovides cryptographic enhancements including multi-device synchronization and\nsecure secret storage/retrieval, and paves the path for forward secrecy,\ndeniability and post-quantum security. We also discuss the use of auditable\nPAKEs for mitigating a class of online guess and abort attacks in\nauthentication protocols. To demonstrate the feasibility of our proposal, we\npresent PakeMail, an implementation of the core idea, and discuss some of its\ncryptographic details, implemented features and efficiency aspects. We conclude\nwith some design and security considerations, followed by future lines of work.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2005.10787\n",
    "authors": [
      "Itzel Vazquez Sandoval",
      "Arash Atashpendar",
      "Gabriele Lenzini",
      "Peter Y.A. Ryan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06090"
  },
  {
    "id": "arXiv:2107.06093",
    "title": "A model-agnostic hypothesis test for community structure and homophily  in networks",
    "abstract": "Networks continue to be of great interest to statisticians, with an emphasis\non community detection. Less work, however, has addressed this question: given\nsome network, does it exhibit meaningful community structure? We propose to\nanswer this question in a principled manner by framing it as a statistical\nhypothesis in terms of a formal and model-agnostic homophily metric. Homophily\nis a well-studied network property where intra-community edges are more likely\nthan between-community edges. We use the homophily metric to identify and\ndistinguish between three concepts: nominal, collateral, and intrinsic\nhomophily. We propose a simple and interpretable test statistic leveraging this\nhomophily parameter and formulate both asymptotic and bootstrap-based rejection\nthresholds. We prove its asymptotic properties and demonstrate it outperforms\nbenchmark methods on both simulated and real world data. Furthermore, the\nproposed method yields rich, provocative insights on classic data sets; namely,\nthat meany well-studied networks do not actually have intrinsic homophily.",
    "descriptor": "",
    "authors": [
      "Eric Yanchenko",
      "Srijan Sengupta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.06093"
  },
  {
    "id": "arXiv:2107.06095",
    "title": "Dynamic Modeling and Control of a Two-Reactor Metal Hydride Energy  Storage System",
    "abstract": "Metal hydrides have been studied for use in energy storage, hydrogen storage,\nand air-conditioning (A/C) systems. A common architecture for A/C and energy\nstorage systems is two metal hydride reactors connected to each other so that\nhydrogen can flow between them, allowing for cyclic use of the hydrogen. This\npaper presents a nonlinear dynamic model and multivariate control strategy of\nsuch a system. Each reactor is modelled as a shell-and-tube heat exchanger\nconnected to a circulating fluid, and a compressor drives hydrogen flow between\nthe reactors. We further develop a linear state-space version of this model\nintegrated with a model predictive controller to determine the fluid mass flow\nrates and compressor pressure difference required to achieve desired heat\ntransfer rates between the metal hydride and the fluid. A series of case\nstudies demonstrates that this controller can track desired heat transfer rates\nin each reactor, even in the presence of time-varying circulating fluid inlet\ntemperatures, thereby enabling the use of a two-reactor system for energy\nstorage or integration with a heat pump.",
    "descriptor": "\nComments: 42 pages; 14 Figures\n",
    "authors": [
      "Patrick Krane",
      "Austin L. Nash",
      "Davide Ziviani",
      "James E. Braun",
      "Amy M. Marconnet",
      "Neera Jain"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06095"
  },
  {
    "id": "arXiv:2107.06096",
    "title": "Blending search queries with social media data to improve forecasts of  economic indicators",
    "abstract": "The forecasting of political, economic, and public health indicators using\ninternet activity has demonstrated mixed results. For example, while some\nmeasures of explicitly surveyed public opinion correlate well with social media\nproxies, the opportunity for profitable investment strategies to be driven\nsolely by sentiment extracted from social media appears to have expired.\nNevertheless, the internet's space of potentially predictive input signals is\ncombinatorially vast and will continue to invite careful exploration. Here, we\ncombine unemployment related search data from Google Trends with economic\nlanguage on Twitter to attempt to nowcast and forecast: 1. State and national\nunemployment claims for the US, and 2. Consumer confidence in G7 countries.\nBuilding off of a recently developed search-query-based model, we show that\nincorporating Twitter data improves forecasting of unemployment claims, while\nthe original method remains marginally better at nowcasting. Enriching the\ninput signal with temporal statistical features (e.g., moving average and rate\nof change) further reduces errors, and improves the predictive utility of the\nproposed method when applied to other economic indices, such as consumer\nconfidence.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Yi Li",
      "Asieh Ahani",
      "Haimao Zhan",
      "Kevin Foley",
      "Thayer Alshaabi",
      "Kelsey Linnell",
      "Peter Sheridan Dodds",
      "Christopher M. Danforth",
      "Adam Fox"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.06096"
  },
  {
    "id": "arXiv:2107.06097",
    "title": "Transformer-Based Behavioral Representation Learning Enables Transfer  Learning for Mobile Sensing in Small Datasets",
    "abstract": "While deep learning has revolutionized research and applications in NLP and\ncomputer vision, this has not yet been the case for behavioral modeling and\nbehavioral health applications. This is because the domain's datasets are\nsmaller, have heterogeneous datatypes, and typically exhibit a large degree of\nmissingness. Therefore, off-the-shelf deep learning models require significant,\noften prohibitive, adaptation. Accordingly, many research applications still\nrely on manually coded features with boosted tree models, sometimes with\ntask-specific features handcrafted by experts. Here, we address these\nchallenges by providing a neural architecture framework for mobile sensing data\nthat can learn generalizable feature representations from time series and\ndemonstrates the feasibility of transfer learning on small data domains through\nfinetuning. This architecture combines benefits from CNN and Trans-former\narchitectures to (1) enable better prediction performance by learning directly\nfrom raw minute-level sensor data without the need for handcrafted features by\nup to 0.33 ROC AUC, and (2) use pretraining to outperform simpler neural models\nand boosted decision trees with data from as few a dozen participants.",
    "descriptor": "",
    "authors": [
      "Mike A. Merrill",
      "Tim Althoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06097"
  },
  {
    "id": "arXiv:2107.06098",
    "title": "Using Causal Analysis for Conceptual Deep Learning Explanation",
    "abstract": "Model explainability is essential for the creation of trustworthy Machine\nLearning models in healthcare. An ideal explanation resembles the\ndecision-making process of a domain expert and is expressed using concepts or\nterminology that is meaningful to the clinicians. To provide such an\nexplanation, we first associate the hidden units of the classifier to\nclinically relevant concepts. We take advantage of radiology reports\naccompanying the chest X-ray images to define concepts. We discover sparse\nassociations between concepts and hidden units using a linear sparse logistic\nregression. To ensure that the identified units truly influence the\nclassifier's outcome, we adopt tools from Causal Inference literature and, more\nspecifically, mediation analysis through counterfactual interventions. Finally,\nwe construct a low-depth decision tree to translate all the discovered concepts\ninto a straightforward decision rule, expressed to the radiologist. We\nevaluated our approach on a large chest x-ray dataset, where our model produces\na global explanation consistent with clinical knowledge.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Sumedha Singla",
      "Stephen Wallace",
      "Sofia Triantafillou",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06098"
  },
  {
    "id": "arXiv:2107.06100",
    "title": "Secure Charging and Payment System for Electric Land Vehicles with  Authentication Protocol",
    "abstract": "It is obvious that fossil fuels are a limited resource and will be replaced\nby other energy sources in the future considering economic and en-vironmental\nproblems. Electricity comes to the forefront among the sources that are\ncandidates to replace fossil fuels. In the near future, electric land, air and\nsea vehicles will start to take more place in daily life. For this reason,\nsystems for the charging systems of these devices and post-charge payments have\nbeen developed. There is no general standard on this issue yet. In this study,\na charge and payment system, which is safe against known cyber-attacks for use\nin electric land ve-hicles, and which prioritizes privacy, is proposed. A\nsystem has been proposed to verify each other wired or wirelessly with an\nauthentication protocol, where the data communication is encrypted, and the\npayment transactions are performed securely and invoiced to the vehicle owners.",
    "descriptor": "\nComments: in Turkish language. 4th INTERNATIONAL CONGRESS ON ECONOMICS FINANCE AND ENERGY (2020). Electric land vehicle, Authentication protocol, Encryption, Security, Payment system, Charging system\n",
    "authors": [
      "Omer Aydin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06100"
  },
  {
    "id": "arXiv:2107.06106",
    "title": "Conservative Offline Distributional Reinforcement Learning",
    "abstract": "Many reinforcement learning (RL) problems in practice are offline, learning\npurely from observational data. A key challenge is how to ensure the learned\npolicy is safe, which requires quantifying the risk associated with different\nactions. In the online setting, distributional RL algorithms do so by learning\nthe distribution over returns (i.e., cumulative rewards) instead of the\nexpected return; beyond quantifying risk, they have also been shown to learn\nbetter representations for planning. We propose Conservative Offline\nDistributional Actor Critic (CODAC), an offline RL algorithm suitable for both\nrisk-neutral and risk-averse domains. CODAC adapts distributional RL to the\noffline setting by penalizing the predicted quantiles of the return for\nout-of-distribution actions. We prove that CODAC learns a conservative return\ndistribution -- in particular, for finite MDPs, CODAC converges to an uniform\nlower bound on the quantiles of the return distribution; our proof relies on a\nnovel analysis of the distributional Bellman operator. In our experiments, on\ntwo challenging robot navigation tasks, CODAC successfully learns risk-averse\npolicies using offline data collected purely from risk-neutral agents.\nFurthermore, CODAC is state-of-the-art on the D4RL MuJoCo benchmark in terms of\nboth expected and risk-sensitive performance.",
    "descriptor": "",
    "authors": [
      "Yecheng Jason Ma",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06106"
  },
  {
    "id": "arXiv:2107.06108",
    "title": "Transitioning from file-based HPC workflows to streaming data pipelines  with openPMD and ADIOS2",
    "abstract": "This paper aims to create a transition path from file-based IO to\nstreaming-based workflows for scientific applications in an HPC environment. By\nusing the openPMP-api, traditional workflows limited by filesystem bottlenecks\ncan be overcome and flexibly extended for in situ analysis. The openPMD-api is\na library for the description of scientific data according to the Open Standard\nfor Particle-Mesh Data (openPMD). Its approach towards recent challenges posed\nby hardware heterogeneity lies in the decoupling of data description in domain\nsciences, such as plasma physics simulations, from concrete implementations in\nhardware and IO. The streaming backend is provided by the ADIOS2 framework,\ndeveloped at Oak Ridge National Laboratory. This paper surveys two\nopenPMD-based loosely coupled setups to demonstrate flexible applicability and\nto evaluate performance. In loose coupling, as opposed to tight coupling, two\n(or more) applications are executed separately, e.g. in individual MPI\ncontexts, yet cooperate by exchanging data. This way, a streaming-based\nworkflow allows for standalone codes instead of tightly-coupled plugins, using\na unified streaming-aware API and leveraging high-speed communication\ninfrastructure available in modern compute clusters for massive data exchange.\nWe determine new challenges in resource allocation and in the need of\nstrategies for a flexible data distribution, demonstrating their influence on\nefficiency and scaling on the Summit compute system. The presented setups show\nthe potential for a more flexible use of compute resources brought by streaming\nIO as well as the ability to increase throughput by avoiding filesystem\nbottlenecks.",
    "descriptor": "\nComments: 18 pages, 9 figures, SMC2021, supplementary material at this https URL\n",
    "authors": [
      "Franz Poeschel",
      "Juncheng E",
      "William F. Godoy",
      "Norbert Podhorszki",
      "Scott Klasky",
      "Greg Eisenhauer",
      "Philip E. Davis",
      "Lipeng Wan",
      "Ana Gainaru",
      "Junmin Gu",
      "Fabian Koller",
      "Ren\u00e9 Widera",
      "Michael Bussmann",
      "Axel Huebl"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06108"
  },
  {
    "id": "arXiv:2107.06111",
    "title": "Towards exact structural thresholds for parameterized complexity",
    "abstract": "Parameterized complexity seeks to use input structure to obtain faster\nalgorithms for NP-hard problems. This has been most successful for graphs of\nlow treewidth: Many problems admit fast algorithms relative to treewidth and\nmany of them are optimal under SETH. Fewer such results are known for more\ngeneral structure such as low clique-width and more restrictive structure such\nas low deletion distance to a sparse graph class.\nDespite these successes, such results remain \"islands'' within the realm of\npossible structure. Rather than adding more islands, we seek to determine the\ntransitions between them, that is, we aim for structural thresholds where the\ncomplexity increases as input structure becomes more general. Going from\ndeletion distance to treewidth, is a single deletion set to a graph with simple\ncomponents enough to yield the same lower bound as for treewidth or does it\ntake many disjoint separators? Going from treewidth to clique-width, how much\nmore density entails the same complexity as clique-width? Conversely, what is\nthe most restrictive structure that yields the same lower bound?\nFor treewidth, we obtain both refined and new lower bounds that apply already\nto graphs with a single separator $X$ such that $G-X$ has treewidth $r=O(1)$,\nwhile $G$ has treewidth $|X|+O(1)$. We rule out algorithms running in time\n$O^*((r+1-\\epsilon)^{k})$ for Deletion to $r$-Colorable parameterized by\n$k=|X|$. For clique-width, we rule out time $O^*((2^r-\\epsilon)^k)$ for\nDeletion to $r$-Colorable, where $X$ is now allowed to consist of $k$\ntwinclasses. There are further results on Vertex Cover, Dominating Set and\nMaximum Cut. All lower bounds are matched by existing and newly designed\nalgorithms.",
    "descriptor": "\nComments: 49 pages, 12 figures, shortened abstract due to character limit\n",
    "authors": [
      "Falko Hegerfeld",
      "Stefan Kratsch"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06111"
  },
  {
    "id": "arXiv:2107.06116",
    "title": "A Novel Dual Quaternion Based Dynamic Motion Primitives for Acrobatic  Flight",
    "abstract": "The realization of motion description is a challenging work for fixed-wing\nUnmanned Aerial Vehicle (UAV) acrobatic flight, due to the inherent coupling\nproblem in ranslational-rotational motion. This paper aims to develop a novel\nmaneuver description method through the idea of imitation learning, and there\nare two main contributions of our work: 1) A dual quaternion based dynamic\nmotion primitives (DQ-DMP) is proposed and the state equations of the position\nand attitude can be combined without loss of accuracy. 2) An online\nhardware-inthe-loop (HITL) training system is established. Based on the DQDMP\nmethod, the geometric features of the demonstrated maneuver can be obtained in\nreal-time, and the stability of the DQ-DMP is theoretically proved. The\nsimulation results illustrate the superiority of the proposed method compared\nto the traditional position/attitude decoupling method.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Renshan Zhang",
      "Yongyang Hu",
      "Kuang Zhao",
      "Su Cao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06116"
  },
  {
    "id": "arXiv:2107.06119",
    "title": "On SDVS Sender Privacy In The Multi-Party Setting",
    "abstract": "Strong designated verifier signature schemes rely on sender-privacy to hide\nthe identity of the creator of a signature to all but the intended recipient.\nThis property can be invaluable in, for example, the context of deniability,\nwhere the identity of a party should not be deducible from the communication\nsent during a protocol execution. In this work, we explore the technical\ndefinition of sender-privacy and extend it from a 2-party setting to an n-party\nsetting. Afterwards, we show in which cases this extension provides a stronger\nsecurity and in which cases it does not.",
    "descriptor": "",
    "authors": [
      "Jeroen van Wier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06119"
  },
  {
    "id": "arXiv:2107.06121",
    "title": "The Dynamic Complexity of Acyclic Hypergraph Homomorphisms",
    "abstract": "Finding a homomorphism from some hypergraph $\\mathcal{Q}$ (or some relational\nstructure) to another hypergraph $\\mathcal{D}$ is a fundamental problem in\ncomputer science. We show that an answer to this problem can be maintained\nunder single-edge changes of $\\mathcal{Q}$, as long as it stays acyclic, in the\nDynFO framework of Patnaik and Immerman that uses updates expressed in\nfirst-order logic. If additionally also changes of $\\mathcal{D}$ are allowed,\nwe show that it is unlikely that existence of homomorphisms can be maintained\nin DynFO.",
    "descriptor": "",
    "authors": [
      "Nils Vortmeier",
      "Ioannis Kokkinis"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06121"
  },
  {
    "id": "arXiv:2107.06125",
    "title": "MSR-Net: Multi-Scale Relighting Network for One-to-One Relighting",
    "abstract": "Deep image relighting allows photo enhancement by illumination-specific\nretouching without human effort and so it is getting much interest lately. Most\nof the existing popular methods available for relighting are run-time intensive\nand memory inefficient. Keeping these issues in mind, we propose the use of\nStacked Deep Multi-Scale Hierarchical Network, which aggregates features from\neach image at different scales. Our solution is differentiable and robust for\ntranslating image illumination setting from input image to target image.\nAdditionally, we have also shown that using a multi-step training approach to\nthis problem with two different loss functions can significantly boost\nperformance and can achieve a high quality reconstruction of a relighted image.",
    "descriptor": "\nComments: Workshop on Differentiable Vision, Graphics, and Physics in Machine Learning at NeurIPS 2020. arXiv admin note: text overlap with arXiv:2102.09242\n",
    "authors": [
      "Sourya Dipta Das",
      "Nisarg A. Shah",
      "Saikat Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06125"
  },
  {
    "id": "arXiv:2107.06126",
    "title": "DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual  Network for the DiCOVA Challenge 2021",
    "abstract": "In this paper, we propose a deep residual network-based method, namely the\nDiCOVA-Net, to identify COVID-19 infected patients based on the acoustic\nrecording of their coughs. Since there are far more healthy people than\ninfected patients, this classification problem faces the challenge of\nimbalanced data. To improve the model's ability to recognize minority class\n(the infected patients), we introduce data augmentation and cost-sensitive\nmethods into our model. Besides, considering the particularity of this task, we\ndeploy some fine-tuning techniques to adjust the pre-training ResNet50.\nFurthermore, to improve the model's generalizability, we use ensemble learning\nto integrate prediction results from multiple base classifiers generated using\ndifferent random seeds. To evaluate the proposed DiCOVA-Net's performance, we\nconducted experiments with the DiCOVA challenge dataset. The results show that\nour method has achieved 85.43\\% in AUC, among the top of all competing teams.",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Jiangeng Chang",
      "Shaoze Cui",
      "Mengling Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06126"
  },
  {
    "id": "arXiv:2107.06127",
    "title": "On the impact of Performance Antipatterns in multi-objective software  model refactoring optimization",
    "abstract": "Software quality estimation is a challenging and time-consuming activity, and\nmodels are crucial to face the complexity of such activity on modern software\napplications.\nOne main challenge is that the improvement of distinctive quality attributes\nmay require contrasting refactoring actions on an application, as for trade-off\nbetween performance and reliability. In such cases, multi-objective\noptimization can provide the designer with a wider view on these trade-offs\nand, consequently, can lead to identify suitable actions that take into account\nindependent or even competing objectives.\nIn this paper, we present an approach that exploits the NSGA-II\nmulti-objective evolutionary algorithm to search optimal Pareto solution\nfrontiers for software refactoring while considering as objectives: i)\nperformance variation, ii) reliability, iii) amount of performance\nantipatterns, and iv) architectural distance. The algorithm combines randomly\ngenerated refactoring actions into solutions (i.e., sequences of actions) and\ncompares them according to the objectives.\nWe have applied our approach on a train ticket booking service case study,\nand we have focused the analysis on the impact of performance antipatterns on\nthe quality of solutions. Indeed, we observe that the approach finds better\nsolutions when antipatterns enter the multi-objective optimization. In\nparticular, performance antipatterns objective leads to solutions improving the\nperformance by up to 15% with respect to the case where antipatterns are not\nconsidered, without affecting the solution quality on other objectives.",
    "descriptor": "",
    "authors": [
      "Vittorio Cortellessa",
      "Daniele Di Pompeo",
      "Vincenzo Stoico",
      "Michele Tucci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.06127"
  },
  {
    "id": "arXiv:2107.06129",
    "title": "Bidirectional Regression for Arbitrary-Shaped Text Detection",
    "abstract": "Arbitrary-shaped text detection has recently attracted increasing interests\nand witnessed rapid development with the popularity of deep learning\nalgorithms. Nevertheless, existing approaches often obtain inaccurate detection\nresults, mainly due to the relatively weak ability to utilize context\ninformation and the inappropriate choice of offset references. This paper\npresents a novel text instance expression which integrates both foreground and\nbackground information into the pipeline, and naturally uses the pixels near\ntext boundaries as the offset starts. Besides, a corresponding post-processing\nalgorithm is also designed to sequentially combine the four prediction results\nand reconstruct the text instance accurately. We evaluate our method on several\nchallenging scene text benchmarks, including both curved and multi-oriented\ntext datasets. Experimental results demonstrate that the proposed approach\nobtains superior or competitive performance compared to other state-of-the-art\nmethods, e.g., 83.4% F-score for Total-Text, 82.4% F-score for MSRA-TD500, etc.",
    "descriptor": "\nComments: Accepted at ICDAR 2021, 15 pages\n",
    "authors": [
      "Tao Sheng",
      "Zhouhui Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06129"
  },
  {
    "id": "arXiv:2107.06130",
    "title": "Scalable Surface Reconstruction with Delaunay-Graph Neural Networks",
    "abstract": "We introduce a novel learning-based, visibility-aware, surface reconstruction\nmethod for large-scale, defect-laden point clouds. Our approach can cope with\nthe scale and variety of point cloud defects encountered in real-life\nMulti-View Stereo (MVS) acquisitions. Our method relies on a 3D Delaunay\ntetrahedralization whose cells are classified as inside or outside the surface\nby a graph neural network and an energy model solvable with a graph cut. Our\nmodel, making use of both local geometric attributes and line-of-sight\nvisibility information, is able to learn a visibility model from a small amount\nof synthetic training data and generalizes to real-life acquisitions. Combining\nthe efficiency of deep learning methods and the scalability of energy based\nmodels, our approach outperforms both learning and non learning-based\nreconstruction algorithms on two publicly available reconstruction benchmarks.",
    "descriptor": "\nComments: The presentation of this work at SGP 2021 is available at this https URL\n",
    "authors": [
      "Raphael Sulzer",
      "Loic Landrieu",
      "Renaud Marlet",
      "Bruno Vallet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.06130"
  },
  {
    "id": "arXiv:2107.06131",
    "title": "Identification of Dynamical Systems using Symbolic Regression",
    "abstract": "We describe a method for the identification of models for dynamical systems\nfrom observational data. The method is based on the concept of symbolic\nregression and uses genetic programming to evolve a system of ordinary\ndifferential equations (ODE). The novelty is that we add a step of\ngradient-based optimization of the ODE parameters. For this we calculate the\nsensitivities of the solution to the initial value problem (IVP) using\nautomatic differentiation. The proposed approach is tested on a set of 19\nproblem instances taken from the literature which includes datasets from\nsimulated systems as well as datasets captured from mechanical systems. We find\nthat gradient-based optimization of parameters improves predictive accuracy of\nthe models. The best results are obtained when we first fit the individual\nequations to the numeric differences and then subsequently fine-tune the\nidentified parameter values by fitting the IVP solution to the observed\nvariable values.",
    "descriptor": "\nComments: The final authenticated publication is available online at this https URL\n",
    "authors": [
      "Gabriel Kronberger",
      "Lukas Kammerer",
      "Michael Kommenda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06131"
  },
  {
    "id": "arXiv:2107.06132",
    "title": "Deep learning approaches to Earth Observation change detection",
    "abstract": "The interest for change detection in the field of remote sensing has\nincreased in the last few years. Searching for changes in satellite images has\nmany useful applications, ranging from land cover and land use analysis to\nanomaly detection. In particular, urban change detection provides an efficient\ntool to study urban spread and growth through several years of observation. At\nthe same time, change detection is often a computationally challenging and\ntime-consuming task, which requires innovative methods to guarantee optimal\nresults with unquestionable value and within reasonable time. In this paper we\npresent two different approaches to change detection (semantic segmentation and\nclassification) that both exploit convolutional neural networks to achieve good\nresults, which can be further refined and used in a post-processing workflow\nfor a large variety of applications.",
    "descriptor": "",
    "authors": [
      "Antonio Di Pilato",
      "Nicol\u00f2 Taggio",
      "Alexis Pompili",
      "Michele Iacobellis",
      "Adriano Di Florio",
      "Davide Passarelli",
      "Sergio Samarelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06132"
  },
  {
    "id": "arXiv:2107.06139",
    "title": "Querying Linked Data: how to ensure user's quality requirements",
    "abstract": "In the distributed and dynamic framework of the Web, data quality is a big\nchallenge. The Linked Open Data (LOD) provides an enormous amount of data, the\nquality of which is difficult to control. Quality is intrinsically a matter of\nusage, so consumers need ways to specify quality rules that make sense for\ntheir use, in order to get only data conforming to these rules. We propose a\nuser-side query framework equipped with a checker of constraints and confidence\nlevels on data resulting from LOD providers\\' query evaluations. We detail its\ntheoretical foundations and we provide experimental results showing that the\ncheck additional cost is reasonable and that integrating the constraints in the\nqueries further improves it significantly.",
    "descriptor": "",
    "authors": [
      "Jacques Chabin",
      "Mirian Halfeld-Ferrari",
      "B\u00e9atrice Markhoff",
      "Thanh Binh Nguyen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.06139"
  },
  {
    "id": "arXiv:2107.06140",
    "title": "Efficient and Reactive Planning for High Speed Robot Air Hockey",
    "abstract": "Highly dynamic robotic tasks require high-speed and reactive robots. These\ntasks are particularly challenging due to the physical constraints, hardware\nlimitations, and the high uncertainty of dynamics and sensor measures. To face\nthese issues, it's crucial to design robotics agents that generate precise and\nfast trajectories and react immediately to environmental changes. Air hockey is\nan example of this kind of task. Due to the environment's characteristics, it\nis possible to formalize the problem and derive clean mathematical solutions.\nFor these reasons, this environment is perfect for pushing to the limit the\nperformance of currently available general-purpose robotic manipulators. Using\ntwo Kuka Iiwa 14, we show how to design a policy for general-purpose robotic\nmanipulators for the air hockey game. We demonstrate that a real robot arm can\nperform fast-hitting movements and that the two robots can play against each\nother on a medium-size air hockey table in simulation.",
    "descriptor": "\nComments: IEEE/RJS International Conference on Intelligent RObots and Systems (IROS)\n",
    "authors": [
      "Puze Liu",
      "Davide Tateo",
      "Haitham Bou-Ammar",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06140"
  },
  {
    "id": "arXiv:2107.06142",
    "title": "Error Processing of Sparse Identification of Nonlinear Dynamical Systems  via $L_\\infty$ Approximation",
    "abstract": "Sparse identification of nonlinear dynamical systems(SINDy) is a recently\npresented framework in the reverse engineering field. It soon gains general\ninterests due to its interpretability and efficiency. Error processing, as an\nimportant issue in the SINDy framework, yet remains to be an open problem. To\ndate, literature about error processing focuses on data processing methods\nwhich aim to improve the accuracy of data. However, the relationship between\ndata and the identification framework is largely ignored. In this paper, error\nprocessing is studied from an optimization perspective. In detail, $L_\\infty$\napproximation is introduced to the objective function in SINDy framework in\nplace of the former $L_2$ approximation. This is especially appropriate for\ndealing with the derivative approximation error in SINDy because the derivative\napproximation error has no exact distribution. To verify the effectiveness of\n$L_\\infty$ approximation, identification scenarios with different types of\nderivative approximation error are tested. The results indicate that $L_\\infty$\napproximation could become an alternative of $L_2$ approximation especially\nwhen lacking prior knowledge of derivative approximation error. The\nperformances of $L_\\infty$ approximation and $L_2$ approximation are evaluated\nin the cases where the measurement noise of system state is considered.\nExperimental results show that $L_\\infty$ approximation has equal performance\ncompared to $L_2$ approximation under the assumption of Gaussian measurement\nnoise, which is promising in applications.",
    "descriptor": "\nComments: 6 pages, 1 figure and 5 tables\n",
    "authors": [
      "Yuqiang Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2107.06142"
  },
  {
    "id": "arXiv:2107.06146",
    "title": "Ontology-Based Process Modelling -- Will we live to see it?",
    "abstract": "In theory, ontology-based process modelling (OBPM) bares great potential to\nextend business process management. Many works have studied OBPM and are clear\non the potential amenities, such as eliminating ambiguities or enabling\nadvanced reasoning over company processes. However, despite this approval in\nacademia, a widespread industry adoption is still nowhere to be seen. This can\nbe mainly attributed to the fact, that it still requires high amounts of manual\nlabour to initially create ontologies and annotations to process models. As\nlong as these problems are not addressed, implementing OBPM seems unfeasible in\npractice. In this work, we therefore identify requirements needed for a\nsuccessful implementation of OBPM and assess the current state of research\nw.r.t. these requirements. Our results indicate that the research progress for\nmeans to facilitate OBPM are still alarmingly low and there needs to be urgent\nwork on extending existing approaches.",
    "descriptor": "",
    "authors": [
      "Carl Corea",
      "Michael Fellmann",
      "Patrick Delfmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06146"
  },
  {
    "id": "arXiv:2107.06149",
    "title": "MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis",
    "abstract": "With the rapid development of data-driven techniques, data has played an\nessential role in various computer vision tasks. Many realistic and synthetic\ndatasets have been proposed to address different problems. However, there are\nlots of unresolved challenges: (1) the creation of dataset is usually a tedious\nprocess with manual annotations, (2) most datasets are only designed for a\nsingle specific task, (3) the modification or randomization of the 3D scene is\ndifficult, and (4) the release of commercial 3D data may encounter copyright\nissue.\nThis paper presents MINERVAS, a Massive INterior EnviRonments VirtuAl\nSynthesis system, to facilitate the 3D scene modification and the 2D image\nsynthesis for various vision tasks. In particular, we design a programmable\npipeline with Domain-Specific Language, allowing users to (1) select scenes\nfrom the commercial indoor scene database, (2) synthesize scenes for different\ntasks with customized rules, and (3) render various imagery data, such as\nvisual color, geometric structures, semantic label. Our system eases the\ndifficulty of customizing massive numbers of scenes for different tasks and\nrelieves users from manipulating fine-grained scene configurations by providing\nuser-controllable randomness using multi-level samplers. Most importantly, it\nempowers users to access commercial scene databases with millions of indoor\nscenes and protects the copyright of core data assets, e.g., 3D CAD models. We\ndemonstrate the validity and flexibility of our system by using our synthesized\ndata to improve the performance on different kinds of computer vision tasks.",
    "descriptor": "\nComments: The two first authors contribute equally. Project pape: this https URL\n",
    "authors": [
      "Haocheng Ren",
      "Hao Zhang",
      "Jia Zheng",
      "Jiaxiang Zheng",
      "Rui Tang",
      "Rui Wang",
      "Hujun Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06149"
  },
  {
    "id": "arXiv:2107.06150",
    "title": "From Identity to Difference: A Quantitative Interpretation of the  Identity Type",
    "abstract": "We explore a quantitative interpretation of 2-dimensional intuitionistic type\ntheory (ITT) in which the identity type is interpreted as a \"type of\ndifferences\". We show that a fragment of ITT, that we call difference type\ntheory (dTT), yields a general logical framework to talk about quantitative\nproperties of programs like approximate equivalence and metric preservation. To\ndemonstrate this fact, we show that dTT can be used to capture compositional\nreasoning in presence of errors, since any program can be associated with a\n\"derivative\" relating errors in input with errors in output. Moreover, after\nrelating the semantics of dTT to the standard weak factorization systems\nsemantics of ITT, we describe the interpretation of dTT in some quantitative\nmodels developed for approximate program transformations, incremental\ncomputing, program differentiation and differential privacy.",
    "descriptor": "",
    "authors": [
      "Paolo Pistone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06150"
  },
  {
    "id": "arXiv:2107.06151",
    "title": "Adaptive dynamic programming-based adaptive-gain sliding mode tracking  control for fixed-wing UAV with disturbances",
    "abstract": "This paper proposes an adaptive dynamic programming-based adaptive-gain\nsliding mode control (ADP-ASMC) scheme for a fixed-wing unmanned aerial vehicle\n(UAV) with matched and unmatched disturbances. Starting from the dynamic of\nfixed-wing UAV, the control-oriented model composed of attitude subsystem and\nairspeed subsystem is established. According to the different issues in two\nsubsystems, two novel adaptive-gain generalized super-twisting (AGST)\nalgorithms are developed to eliminate the effects of disturbances in two\nsubsystems and make the system trajectories tend to the designed integral\nsliding manifolds (ISMs) in finite time. Then, based on the expected equivalent\nsliding-mode dynamics, the modified adaptive dynamic programming (ADP) approach\nwith actor-critic (AC) structure is utilized to generate the nearly optimal\ncontrol laws and achieve the nearly optimal performance of the sliding-mode\ndynamics. Furthermore, through the Lyapunov stability theorem, the tracking\nerrors and the weight estimation errors of two neural networks (NNs) are all\nuniformly ultimately bounded (UUB). Finally, comparative simulations\ndemonstrate the superior performance of the proposed control scheme for the\nfixed-wing UAV.",
    "descriptor": "",
    "authors": [
      "Chaofan Zhang",
      "Guoshan Zhang",
      "Qi Dong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06151"
  },
  {
    "id": "arXiv:2107.06152",
    "title": "A model of systems with modes and mode transitions",
    "abstract": "We propose a method of classifying the operation of a system into finitely\nmany modes. Each mode has its own objectives for the system's behaviour and its\nown mathematical models and algorithms designed to accomplish its objectives. A\ncentral problem is deciding when to transition from one mode to some other\nmode, a decision that may be contested and involve partial or inconsistent\ninformation or evidence. We model formally the concept of modes for a system\nand derive a family of data types for analysing mode transitions. The data\ntypes are simplicial complexes, both abstract and realised in euclidean space\n$\\mathbb{R}^{n}$. In the data type, a mode is represented by a simplex. Each\nstate of a system can be evaluated relative to different modes by mapping it\ninto one or more simplices. This calibration measures the extent to which\ndistinct modes are appropriate for the state and can decide on a transition. We\nexplain this methodology based on modes, introduce the mathematical ideas about\nsimplicial objects we need and use them to build a theoretical framework for\nmodes and mode transitions. To illustrate the general model in some detail, we\nwork though a case study of an autonomous racing car.",
    "descriptor": "",
    "authors": [
      "Edwin Beggs",
      "John V. Tucker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06152"
  },
  {
    "id": "arXiv:2107.06154",
    "title": "Fast Batch Nuclear-norm Maximization and Minimization for Robust Domain  Adaptation",
    "abstract": "Due to the domain discrepancy in visual domain adaptation, the performance of\nsource model degrades when bumping into the high data density near decision\nboundary in target domain. A common solution is to minimize the Shannon Entropy\nto push the decision boundary away from the high density area. However, entropy\nminimization also leads to severe reduction of prediction diversity, and\nunfortunately brings harm to the domain adaptation. In this paper, we\ninvestigate the prediction discriminability and diversity by studying the\nstructure of the classification output matrix of a randomly selected data\nbatch. We find by theoretical analysis that the prediction discriminability and\ndiversity could be separately measured by the Frobenius-norm and rank of the\nbatch output matrix. The nuclear-norm is an upperbound of the former, and a\nconvex approximation of the latter. Accordingly, we propose Batch Nuclear-norm\nMaximization and Minimization, which performs nuclear-norm maximization on the\ntarget output matrix to enhance the target prediction ability, and nuclear-norm\nminimization on the source batch output matrix to increase applicability of the\nsource domain knowledge. We further approximate the nuclear-norm by\nL_{1,2}-norm, and design multi-batch optimization for stable solution on large\nnumber of categories. The fast approximation method achieves O(n^2)\ncomputational complexity and better convergence property. Experiments show that\nour method could boost the adaptation accuracy and robustness under three\ntypical domain adaptation scenarios. The code is available at\nhttps://github.com/cuishuhao/BNM.",
    "descriptor": "\nComments: TPAMI under revivew. arXiv admin note: text overlap with arXiv:2003.12237\n",
    "authors": [
      "Shuhao Cui",
      "Shuhui Wang",
      "Junbao Zhuo",
      "Liang Li",
      "Qingming Huang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06154"
  },
  {
    "id": "arXiv:2107.06155",
    "title": "The IWSLT 2021 BUT Speech Translation Systems",
    "abstract": "The paper describes BUT's English to German offline speech translation(ST)\nsystems developed for IWSLT2021. They are based on jointly trained Automatic\nSpeech Recognition-Machine Translation models. Their performances is evaluated\non MustC-Common test set. In this work, we study their efficiency from the\nperspective of having a large amount of separate ASR training data and MT\ntraining data, and a smaller amount of speech-translation training data. Large\namounts of ASR and MT training data are utilized for pre-training the ASR and\nMT models. Speech-translation data is used to jointly optimize ASR-MT models by\ndefining an end-to-end differentiable path from speech to translations. For\nthis purpose, we use the internal continuous representations from the\nASR-decoder as the input to MT module. We show that speech translation can be\nfurther improved by training the ASR-decoder jointly with the MT-module using\nlarge amount of text-only MT training data. We also show significant\nimprovements by training an ASR module capable of generating punctuated text,\nrather than leaving the punctuation task to the MT module.",
    "descriptor": "",
    "authors": [
      "Hari Krishna Vydana",
      "Martin Karafi'at",
      "Luk'as Burget",
      "\"Honza\" Cernock'y"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06155"
  },
  {
    "id": "arXiv:2107.06156",
    "title": "Parallel Repetition for the GHZ Game: A Simpler Proof",
    "abstract": "We give a new proof of the fact that the parallel repetition of the\n(3-player) GHZ game reduces the value of the game to zero polynomially quickly.\nThat is, we show that the value of the $n$-fold GHZ game is at most\n$n^{-\\Omega(1)}$. This was first established by Holmgren and Raz [HR20]. We\npresent a new proof of this theorem that we believe to be simpler and more\ndirect. Unlike most previous works on parallel repetition, our proof makes no\nuse of information theory, and relies on the use of Fourier analysis.\nThe GHZ game [GHZ89] has played a foundational role in the understanding of\nquantum information theory, due in part to the fact that quantum strategies can\nwin the GHZ game with probability 1. It is possible that improved parallel\nrepetition bounds may find applications in this setting.\nRecently, Dinur, Harsha, Venkat, and Yuen [DHVY17] highlighted the GHZ game\nas a simple three-player game, which is in some sense maximally far from the\nclass of multi-player games whose behavior under parallel repetition is well\nunderstood. Dinur et al. conjectured that parallel repetition decreases the\nvalue of the GHZ game exponentially quickly, and speculated that progress on\nproving this would shed light on parallel repetition for general multi-player\n(multi-prover) games.",
    "descriptor": "",
    "authors": [
      "Uma Girish",
      "Justin Holmgren",
      "Kunal Mittal",
      "Ran Raz",
      "Wei Zhan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.06156"
  },
  {
    "id": "arXiv:2107.06158",
    "title": "Correlation Analysis between the Robustness of Sparse Neural Networks  and their Random Hidden Structural Priors",
    "abstract": "Deep learning models have been shown to be vulnerable to adversarial attacks.\nThis perception led to analyzing deep learning models not only from the\nperspective of their performance measures but also their robustness to certain\ntypes of adversarial attacks. We take another step forward in relating the\narchitectural structure of neural networks from a graph theoretic perspective\nto their robustness. We aim to investigate any existing correlations between\ngraph theoretic properties and the robustness of Sparse Neural Networks. Our\nhypothesis is, that graph theoretic properties as a prior of neural network\nstructures are related to their robustness. To answer to this hypothesis, we\ndesigned an empirical study with neural network models obtained through random\ngraphs used as sparse structural priors for the networks. We additionally\ninvestigated the evaluation of a randomly pruned fully connected network as a\npoint of reference.\nWe found that robustness measures are independent of initialization methods\nbut show weak correlations with graph properties: higher graph densities\ncorrelate with lower robustness, but higher average path lengths and average\nnode eccentricities show negative correlations with robustness measures. We\nhope to motivate further empirical and analytical research to tightening an\nanswer to our hypothesis.",
    "descriptor": "",
    "authors": [
      "M. Ben Amor",
      "J. Stier",
      "M. Granitzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06158"
  },
  {
    "id": "arXiv:2107.06165",
    "title": "3D Parametric Wireframe Extraction Based on Distance Fields",
    "abstract": "We present a pipeline for parametric wireframe extraction from densely\nsampled point clouds. Our approach processes a scalar distance field that\nrepresents proximity to the nearest sharp feature curve. In intermediate\nstages, it detects corners, constructs curve segmentation, and builds a\ntopological graph fitted to the wireframe. As an output, we produce parametric\nspline curves that can be edited and sampled arbitrarily. We evaluate our\nmethod on 50 complex 3D shapes and compare it to the novel deep learning-based\ntechnique, demonstrating superior quality.",
    "descriptor": "",
    "authors": [
      "Albert Matveev",
      "Alexey Artemov",
      "Denis Zorin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.06165"
  },
  {
    "id": "arXiv:2107.06178",
    "title": "An Ecological Robustness-Oriented Approach for Power System Network  Expansion",
    "abstract": "Electric power grids are critical infrastructure that support modern society\nby supplying electric energy to critical infrastructure systems. Incidents are\nincreasing that range from natural disasters to cyber attacks. These incidents\nthreaten the reliability of power systems and create disturbances that affect\nthe whole society. While existing standards and technologies are being applied\nto proactively improve power system reliability and resilience, there are still\nwidespread electricity outages that cause billions of dollars in economic loss\nannually and threaten societal function and safety. Improving resilience in\npreparation for such events warrants strategic network design to harden the\nsystem. This paper presents an approach to strengthen power system security and\nreliability against disturbances by expanding the network structure from an\necosystems perspective.\nEcosystems have survived a wide range of disturbances over a long time\nperiod, and an ecosystem's robust structure has been identified as the key\nelement for its survivability. In this paper, we first present a study of the\ncorrelation of ecological robustness and power system structures. Then, we\npresent a mixed-integer nonlinear programming problem (MINLP) that expands the\ntransmission network structure to maximize ecological robustness with power\nsystem constraints for an improved ability to absorb disturbances. We solve the\nMINLP problem for the IEEE 24 Bus Reliability Test System and three synthetic\npower grids with 200-, 500- and 2000-buses, respectively. Our evaluation\nresults show the optimized power systems have increased the network's\nrobustness, more equally distributed power flows, and less violations under\ndifferent levels of contingencies.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Hao Huang",
      "Zeyu Mao",
      "Varuneswara Panyam",
      "Astrid Layton",
      "Katherine Davis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06178"
  },
  {
    "id": "arXiv:2107.06182",
    "title": "Predictive models for wind speed using artificial intelligence and  copula",
    "abstract": "Electricity generation from burning fossil fuels is one of the major\ncontributors to global warming. Renewable energy sources are a viable\nalternative to produce electrical energy and to reduce the emission from the\npower industry. These energy sources are the building blocks of green energy,\nwhich all have different characteristics. Their availabilities are also\ndiverse, depending on geographical locations and other parameters. Low\nimplementation cost and distributed availability all over the world uplifts\ntheir popularity exponentially. Therefore, it has unlocked opportunities for\nconsumers to produce electricity locally and use it on-site, which reduces\ndependency on centralized utility companies. The research considers two main\nobjectives: the prediction of wind speed that simplifies wind farm planning and\nfeasibility study. Secondly, the need to understand the dependency structure of\nthe wind speeds of multiple distant locations. To address the first objective,\ntwelve artificial intelligence algorithms were used for wind speed prediction\nfrom collected meteorological parameters. The model performances were compared\nto determine the wind speed prediction accuracy. The results show a deep\nlearning approach, long short-term memory (LSTM) outperforms other models with\nthe highest accuracy of 97.8%. For dependency, a multivariate cumulative\ndistribution function, Copula, was used to find the joint distribution of two\nor more distant location wind speeds, followed by a case study. We found that\nthe appropriate copula family and the parameters vary based on the distance in\nbetween. For the case study, Joe-Frank (BB8) copula shows an efficient joint\ndistribution fit for a wind speed pair with a standard error of 0.0094.\nFinally, some insights about the uncertainty aspects of wind speed dependency\nwere addressed.",
    "descriptor": "\nComments: This is a Masters thesis that compares various machine learning algorithms for wind speed prediction using weather data. It also applies Copula to model joint probability distribution of two far apart wind sites. arXiv admin note: text overlap with arXiv:2005.12401\n",
    "authors": [
      "Md Amimul Ehsan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06182"
  },
  {
    "id": "arXiv:2107.06185",
    "title": "A new method for vehicle system safety design based on data mining with  uncertainty modeling",
    "abstract": "In this research, a new data mining-based design approach has been developed\nfor designing complex mechanical systems such as a crashworthy passenger car\nwith uncertainty modeling. The method allows exploring the big crash simulation\ndataset to design the vehicle at multi-levels in a top-down manner (main energy\nabsorbing system, components, and geometric features) and derive design rules\nbased on the whole vehicle body safety requirements to make decisions towards\nthe component and sub-component level design. Full vehicle and component\nsimulation datasets are mined to build decision trees, where the\ninterrelationship among parameters can be revealed and the design rules are\nderived to produce designs with good performance. This method has been extended\nby accounting for the uncertainty in the design variables. A new decision tree\nalgorithm for uncertain data (DTUD) is developed to produce the desired designs\nand evaluate the design performance variations due to the uncertainty in design\nvariables. The framework of this method is implemented by combining the design\nof experiments (DOE) and crash finite element analysis (FEA) and then\ndemonstrated by designing a passenger car subject to front impact. The results\nshow that the new methodology could achieve the design objectives efficiently\nand effectively. By applying the new method, the reliability of the final\ndesigns is also increased greatly. This approach has the potential to be\napplied as a general design methodology for a wide range of complex structures\nand mechanical systems.",
    "descriptor": "\nComments: 38 pages, 21 figures, 6 tables\n",
    "authors": [
      "Xianping Du",
      "Binhui Jiang",
      "Feng Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06185"
  },
  {
    "id": "arXiv:2107.06187",
    "title": "Deep Ranking with Adaptive Margin Triplet Loss",
    "abstract": "We propose a simple modification from a fixed margin triplet loss to an\nadaptive margin triplet loss. While the original triplet loss is used widely in\nclassification problems such as face recognition, face re-identification and\nfine-grained similarity, our proposed loss is well suited for rating datasets\nin which the ratings are continuous values. In contrast to original triplet\nloss where we have to sample data carefully, in out method, we can generate\ntriplets using the whole dataset, and the optimization can still converge\nwithout frequently running into a model collapsing issue. The adaptive margins\nonly need to be computed once before the training, which is much less expensive\nthan generating triplets after every epoch as in the fixed margin case. Besides\nsubstantially improved training stability (the proposed model never collapsed\nin our experiments compared to a couple of times that the training collapsed on\nexisting triplet loss), we achieved slightly better performance than the\noriginal triplet loss on various rating datasets and network architectures.",
    "descriptor": "",
    "authors": [
      "Mai Lan Ha",
      "Volker Blanz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06187"
  },
  {
    "id": "arXiv:2107.06190",
    "title": "Towards Machine Learning-Enabled Context Adaption for Reliable Aerial  Mesh Routing",
    "abstract": "In this paper, we present Context-Adaptive PARRoT (CA-PARRoT) as an extension\nof our previous work Predictive Ad-hoc Routing fueled by Reinforcement learning\nand Trajectory knowledge (PARRoT). Short-term effects, as occurring in urban\nsurroundings, have shown to have a negative impact on the Reinforcement\nLearning (RL)-based routing process. Therefore, we add a timer-based\ncompensation mechanism to the update process and introduce a hybrid Machine\nLearning (ML) approach to classify Radio Environment Prototypes (REPs) with a\ndedicated ML component and enable the protocol for autonomous context adaption.\nThe performance of the novel protocol is evaluated in comprehensive network\nsimulations considering different REPs and is compared to well-known\nestablished routing protocols for Mobile Ad-hoc Networks (MANETs). The results\nshow, that CA-PARRoT is capable to compensate the challenges confronted with in\ndifferent REPs and to improve its Key Performance Indicators (KPIs) up to 23%\ncompared to PARRoT, and outperform established routing protocols by up to 50 %.",
    "descriptor": "",
    "authors": [
      "Cedrik Sch\u00fcler",
      "Benjamin Sliwa",
      "Christian Wietfeld"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.06190"
  },
  {
    "id": "arXiv:2107.06195",
    "title": "Transfer Learning in Multi-Agent Reinforcement Learning with Double  Q-Networks for Distributed Resource Sharing in V2X Communication",
    "abstract": "This paper addresses the problem of decentralized spectrum sharing in\nvehicle-to-everything (V2X) communication networks. The aim is to provide\nresource-efficient coexistence of vehicle-to-infrastructure(V2I) and\nvehicle-to-vehicle(V2V) links. A recent work on the topic proposes a\nmulti-agent reinforcement learning (MARL) approach based on deep Q-learning,\nwhich leverages a fingerprint-based deep Q-network (DQN) architecture. This\nwork considers an extension of this framework by combining Double Q-learning\n(via Double DQN) and transfer learning. The motivation behind is that Double\nQ-learning can alleviate the problem of overestimation of the action values\npresent in conventional Q-learning, while transfer learning can leverage\nknowledge acquired by an expert model to accelerate learning in the MARL\nsetting. The proposed algorithm is evaluated in a realistic V2X setting, with\nsynthetic data generated based on a geometry-based propagation model that\nincorporates location-specific geographical descriptors of the simulated\nenvironment(outlines of buildings, foliage, and vehicles). The advantages of\nthe proposed approach are demonstrated via numerical simulations.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Hammad Zafar",
      "Zoran Utkovski",
      "Martin Kasparick",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06195"
  },
  {
    "id": "arXiv:2107.06196",
    "title": "No Regrets for Learning the Prior in Bandits",
    "abstract": "We propose ${\\tt AdaTS}$, a Thompson sampling algorithm that adapts\nsequentially to bandit tasks that it interacts with. The key idea in ${\\tt\nAdaTS}$ is to adapt to an unknown task prior distribution by maintaining a\ndistribution over its parameters. When solving a bandit task, that uncertainty\nis marginalized out and properly accounted for. ${\\tt AdaTS}$ is a\nfully-Bayesian algorithm that can be implemented efficiently in several classes\nof bandit problems. We derive upper bounds on its Bayes regret that quantify\nthe loss due to not knowing the task prior, and show that it is small. Our\ntheory is supported by experiments, where ${\\tt AdaTS}$ outperforms prior\nalgorithms and works well even in challenging real-world problems.",
    "descriptor": "",
    "authors": [
      "Soumya Basu",
      "Branislav Kveton",
      "Manzil Zaheer",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06196"
  },
  {
    "id": "arXiv:2107.06197",
    "title": "Generative Adversarial Learning via Kernel Density Discrimination",
    "abstract": "We introduce Kernel Density Discrimination GAN (KDD GAN), a novel method for\ngenerative adversarial learning. KDD GAN formulates the training as a\nlikelihood ratio optimization problem where the data distributions are written\nexplicitly via (local) Kernel Density Estimates (KDE). This is inspired by the\nrecent progress in contrastive learning and its relation to KDE. We define the\nKDEs directly in feature space and forgo the requirement of invertibility of\nthe kernel feature mappings. In our approach, features are no longer optimized\nfor linear separability, as in the original GAN formulation, but for the more\ngeneral discrimination of distributions in the feature space. We analyze the\ngradient of our loss with respect to the feature representation and show that\nit is better behaved than that of the original hinge loss. We perform\nexperiments with the proposed KDE-based loss, used either as a training loss or\na regularization term, on both CIFAR10 and scaled versions of ImageNet. We use\nBigGAN/SA-GAN as a backbone and baseline, since our focus is not to design the\narchitecture of the networks. We show a boost in the quality of generated\nsamples with respect to FID from 10% to 40% compared to the baseline. Code will\nbe made available.",
    "descriptor": "",
    "authors": [
      "Abdelhak Lemkhenter",
      "Adam Bielski",
      "Alp Eren Sari",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06197"
  },
  {
    "id": "arXiv:2107.06200",
    "title": "Multistage Mixed Precision Iterative Refinement",
    "abstract": "Low precision arithmetic, in particular half precision (16-bit) floating\npoint arithmetic, is now available in commercial hardware. Using lower\nprecision can offer significant savings in computation and communication costs\nwith proportional savings in energy. Motivated by this, there have recently\nemerged a number of new iterative refinement schemes for solving linear systems\n$Ax=b$, both based on standard LU factorization and GMRES solvers, that exploit\nmultiple different precisions. Each particular algorithm and each combination\nof precisions leads to different condition number-based constraints for\nconvergence of the backward and forward errors, and each has different\nperformance costs. Given that the user may not necessarily know the condition\nnumber of their matrix a priori, it may be difficult to select the optimal\nvariant for their problem.\nIn this work, we develop a three-stage mixed precision iterative refinement\nsolver which aims to combine existing mixed precision approaches to balance\nperformance and accuracy and improve usability. For a given combination of\nprecisions, the algorithm begins with the least expensive approach and\nconvergence is monitored via inexpensive computations with quantities produced\nduring the iteration. If slow convergence or divergence is detected using\nparticular stopping criteria, the algorithm switches to use more expensive, but\nmore reliable GMRES-based refinement approaches. After presenting the algorithm\nand its details, we perform extensive numerical experiments on a variety of\nrandom dense problems and problems from real applications. Our experiments\ndemonstrate that the theoretical constraints derived in the literature are\noften overly strict in practice, further motivating the need for a multistage\napproach.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Eda Oktay",
      "Erin Carson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06200"
  },
  {
    "id": "arXiv:2107.06206",
    "title": "ML-Quest: A Game for Introducing Machine Learning Concepts to K-12  Students",
    "abstract": "Today, Machine Learning (ML) is of a great importance to society due to the\navailability of huge data and high computational resources. This ultimately led\nto the introduction of ML concepts at multiple levels of education including\nK-12 students to promote computational thinking. However, teaching these\nconcepts to K-12 through traditional methodologies such as video lectures and\nbooks is challenging. Many studies in the literature have reported that using\ninteractive environments such as games to teach computational thinking and\nprogramming improves retention capacity and motivation among students.\nTherefore, introducing ML concepts using a game might enhance students'\nunderstanding of the subject and motivate them to learn further. However, we\nare not aware of any existing game which explicitly focuses on introducing ML\nconcepts to students using game play. Hence, in this paper, we propose\nML-Quest, a 3D video game to provide conceptual overview of three ML concepts:\nSupervised Learning, Gradient Descent and K-Nearest Neighbor (KNN)\nClassification. The crux of the game is to introduce the definition and working\nof these concepts, which we call conceptual overview, in a simulated scenario\nwithout overwhelming students with the intricacies of ML. The game has been\npredominantly evaluated for its usefulness and player experience using the\nTechnology Acceptance Model (TAM) model with the help of 23 higher-secondary\nschool students. The survey result shows that around 70% of the participants\neither agree or strongly agree that the ML-Quest is quite interactive and\nuseful in introducing them to ML concepts.",
    "descriptor": "\nComments: 13 pages, 5 figures, 3 tables\n",
    "authors": [
      "Shruti Priya",
      "Shubhankar Bhadra",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06206"
  },
  {
    "id": "arXiv:2107.06207",
    "title": "Adaptive Machine Learning for Time-Varying Systems: Low Dimensional  Latent Space Tuning",
    "abstract": "Machine learning (ML) tools such as encoder-decoder convolutional neural\nnetworks (CNN) can represent incredibly complex nonlinear functions which map\nbetween combinations of images and scalars. For example, CNNs can be used to\nmap combinations of accelerator parameters and images which are 2D projections\nof the 6D phase space distributions of charged particle beams as they are\ntransported between various particle accelerator locations. Despite their\nstrengths, applying ML to time-varying systems, or systems with shifting\ndistributions, is an open problem, especially for large systems for which\ncollecting new data for re-training is impractical or interrupts operations.\nParticle accelerators are one example of large time-varying systems for which\ncollecting detailed training data requires lengthy dedicated beam measurements\nwhich may no longer be available during regular operations. We present a\nrecently developed method of adaptive ML for time-varying systems. Our approach\nis to map very high (N>100k) dimensional inputs (a combination of scalar\nparameters and images) into the low dimensional (N~2) latent space at the\noutput of the encoder section of an encoder-decoder CNN. We then actively tune\nthe low dimensional latent space-based representation of complex system\ndynamics by the addition of an adaptively tuned feedback vector directly before\nthe decoder sections builds back up to our image-based high-dimensional phase\nspace density representations. This method allows us to learn correlations\nwithin and to quickly tune the characteristics of incredibly high parameter\nsystems and to track their evolution in real time based on feedback without\nmassive new data sets for re-training.",
    "descriptor": "",
    "authors": [
      "Alexander Scheinker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06207"
  },
  {
    "id": "arXiv:2107.06209",
    "title": "Learning a Discriminant Latent Space with Neural Discriminant Analysis",
    "abstract": "Discriminative features play an important role in image and object\nclassification and also in other fields of research such as semi-supervised\nlearning, fine-grained classification, out of distribution detection. Inspired\nby Linear Discriminant Analysis (LDA), we propose an optimization called Neural\nDiscriminant Analysis (NDA) for Deep Convolutional Neural Networks (DCNNs). NDA\ntransforms deep features to become more discriminative and, therefore, improves\nthe performances in various tasks. Our proposed optimization has two primary\ngoals for inter- and intra-class variances. The first one is to minimize\nvariances within each individual class. The second goal is to maximize pairwise\ndistances between features coming from different classes. We evaluate our NDA\noptimization in different research fields: general supervised classification,\nfine-grained classification, semi-supervised learning, and out of distribution\ndetection. We achieve performance improvements in all the fields compared to\nbaseline methods that do not use NDA. Besides, using NDA, we also surpass the\nstate of the art on the four tasks on various testing datasets.",
    "descriptor": "",
    "authors": [
      "Mai Lan Ha",
      "Gianni Franchi",
      "Emanuel Aldea",
      "Volker Blanz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06209"
  },
  {
    "id": "arXiv:2107.06212",
    "title": "'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval  with Deep Neural Networks",
    "abstract": "Ongoing advancements in the fields of 3D modelling and digital archiving have\nled to an outburst in the amount of data stored digitally. Consequently,\nseveral retrieval systems have been developed depending on the type of data\nstored in these databases. However, unlike text data or images, performing a\nsearch for 3D models is non-trivial. Among 3D models, retrieving 3D\nEngineering/CAD models or mechanical components is even more challenging due to\nthe presence of holes, volumetric features, presence of sharp edges etc., which\nmake CAD a domain unto itself. The research work presented in this paper aims\nat developing a dataset suitable for building a retrieval system for 3D CAD\nmodels based on deep learning. 3D CAD models from the available CAD databases\nare collected, and a dataset of computer-generated sketch data, termed\n'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the\ncomponents are also added to CADSketchNet. Using the sketch images from this\ndataset, the paper also aims at evaluating the performance of various retrieval\nsystem or a search engine for 3D CAD models that accepts a sketch image as the\ninput query. Many experimental models are constructed and tested on\nCADSketchNet. These experiments, along with the model architecture, choice of\nsimilarity metrics are reported along with the search results.",
    "descriptor": "\nComments: Computers & Graphics Journal, Special Section on 3DOR 2021\n",
    "authors": [
      "Bharadwaj Manda",
      "Shubham Dhayarkar",
      "Sai Mitheran",
      "V.K. Viekash",
      "Ramanathan Muthuganapathy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06212"
  },
  {
    "id": "arXiv:2107.06216",
    "title": "Bag-of-Tasks Scheduling on Related Machines",
    "abstract": "We consider online scheduling to minimize weighted completion time on related\nmachines, where each job consists of several tasks that can be concurrently\nexecuted. A job gets completed when all its component tasks finish. We obtain\nan $O(K^3 \\log^2 K)$-competitive algorithm in the non-clairvoyant setting,\nwhere $K$ denotes the number of distinct machine speeds. The analysis is based\non dual-fitting on a precedence-constrained LP relaxation that may be of\nindependent interest.",
    "descriptor": "\nComments: Preliminary version in APPROX 2021\n",
    "authors": [
      "Anupam Gupta",
      "Amit Kumar",
      "Sahil Singla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06216"
  },
  {
    "id": "arXiv:2107.06217",
    "title": "What classifiers know what they don't?",
    "abstract": "Being uncertain when facing the unknown is key to intelligent decision\nmaking. However, machine learning algorithms lack reliable estimates about\ntheir predictive uncertainty. This leads to wrong and overly-confident\ndecisions when encountering classes unseen during training. Despite the\nimportance of equipping classifiers with uncertainty estimates ready for the\nreal world, prior work has focused on small datasets and little or no class\ndiscrepancy between training and testing data. To close this gap, we introduce\nUIMNET: a realistic, ImageNet-scale test-bed to evaluate predictive uncertainty\nestimates for deep image classifiers. Our benchmark provides implementations of\neight state-of-the-art algorithms, six uncertainty measures, four in-domain\nmetrics, three out-domain metrics, and a fully automated pipeline to train,\ncalibrate, ensemble, select, and evaluate models. Our test-bed is open-source\nand all of our results are reproducible from a fixed commit in our repository.\nAdding new datasets, algorithms, measures, or metrics is a matter of a few\nlines of code-in so hoping that UIMNET becomes a stepping stone towards\nrealistic, rigorous, and reproducible research in uncertainty estimation. Our\nresults show that ensembles of ERM classifiers as well as single MIMO\nclassifiers are the two best alternatives currently available to measure\nuncertainty about both in-domain and out-domain classes.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Mohamed Ishmael Belghazi",
      "David Lopez-Paz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06217"
  },
  {
    "id": "arXiv:2107.06219",
    "title": "Domain-Irrelevant Representation Learning for Unsupervised Domain  Generalization",
    "abstract": "Domain generalization (DG) aims to help models trained on a set of source\ndomains generalize better on unseen target domains. The performances of current\nDG methods largely rely on sufficient labeled data, which however are usually\ncostly or unavailable. While unlabeled data are far more accessible, we seek to\nexplore how unsupervised learning can help deep models generalizes across\ndomains. Specifically, we study a novel generalization problem called\nunsupervised domain generalization, which aims to learn generalizable models\nwith unlabeled data. Furthermore, we propose a Domain-Irrelevant Unsupervised\nLearning (DIUL) method to cope with the significant and misleading\nheterogeneity within unlabeled data and severe distribution shifts between\nsource and target data. Surprisingly we observe that DIUL can not only\ncounterbalance the scarcity of labeled data but also further strengthen the\ngeneralization ability of models when the labeled data are sufficient. As a\npretraining approach, DIUL shows superior to ImageNet pretraining protocol even\nwhen the available data are unlabeled and of a greatly smaller amount compared\nto ImageNet. Extensive experiments clearly demonstrate the effectiveness of our\nmethod compared with state-of-the-art unsupervised learning counterparts.",
    "descriptor": "",
    "authors": [
      "Xingxuan Zhang",
      "Linjun Zhou",
      "Renzhe Xu",
      "Peng Cui",
      "Zheyan Shen",
      "Haoxin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.06219"
  },
  {
    "id": "arXiv:2107.06226",
    "title": "Pessimistic Model-based Offline RL: PAC Bounds and Posterior Sampling  under Partial Coverage",
    "abstract": "We study model-based offline Reinforcement Learning with general function\napproximation. We present an algorithm named Constrained Pessimistic Policy\nOptimization (CPPO) which leverages a general function class and uses a\nconstraint to encode pessimism. Under the assumption that the ground truth\nmodel belongs to our function class, CPPO can learn with the offline data only\nproviding partial coverage, i.e., it can learn a policy that completes against\nany policy that is covered by the offline data, in polynomial sample complexity\nwith respect to the statistical complexity of the function class. We then\ndemonstrate that this algorithmic framework can be applied to many specialized\nMarkov Decision Processes where the additional structural assumptions can\nfurther refine the concept of partial coverage. One notable example is low-rank\nMDP with representation learning where the partial coverage is defined using\nthe concept of relative condition number measured by the underlying unknown\nground truth feature representation. Finally, we introduce and study the\nBayesian setting in offline RL. The key benefit of Bayesian offline RL is that\nalgorithmically, we do not need to explicitly construct pessimism or reward\npenalty which could be hard beyond models with linear structures. We present a\nposterior sampling-based incremental policy optimization algorithm (PS-PO)\nwhich proceeds by iteratively sampling a model from the posterior distribution\nand performing one-step incremental policy optimization inside the sampled\nmodel. Theoretically, in expectation with respect to the prior distribution,\nPS-PO can learn a near optimal policy under partial coverage with polynomial\nsample complexity.",
    "descriptor": "",
    "authors": [
      "Masatoshi Uehara",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06226"
  },
  {
    "id": "arXiv:2107.06231",
    "title": "Timbre Classification of Musical Instruments with a Deep Learning  Multi-Head Attention-Based Model",
    "abstract": "The aim of this work is to define a model based on deep learning that is able\nto identify different instrument timbres with as few parameters as possible.\nFor this purpose, we have worked with classical orchestral instruments played\nwith different dynamics, which are part of a few instrument families and which\nplay notes in the same pitch range. It has been possible to assess the ability\nto classify instruments by timbre even if the instruments are playing the same\nnote with the same intensity. The network employed uses a multi-head attention\nmechanism, with 8 heads and a dense network at the output taking as input the\nlog-mel magnitude spectrograms of the sound samples. This network allows the\nidentification of 20 instrument classes of the classical orchestra, achieving\nan overall F$_1$ value of 0.62. An analysis of the weights of the attention\nlayer has been performed and the confusion matrix of the model is presented,\nallowing us to assess the ability of the proposed architecture to distinguish\ntimbre and to establish the aspects on which future work should focus.",
    "descriptor": "",
    "authors": [
      "Carlos Hernandez-Olivan",
      "Jose R. Beltran"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06231"
  },
  {
    "id": "arXiv:2107.06232",
    "title": "Maintaining $\\mathsf{CMSO}_2$ properties on dynamic structures with  bounded feedback vertex number",
    "abstract": "Let $\\varphi$ be a sentence of $\\mathsf{CMSO}_2$ (monadic second-order logic\nwith quantification over edge subsets and counting modular predicates) over the\nsignature of graphs. We present a dynamic data structure that for a given graph\n$G$ that is updated by edge insertions and edge deletions, maintains whether\n$\\varphi$ is satisfied in $G$. The data structure is required to correctly\nreport the outcome only when the feedback vertex number of $G$ does not exceed\na fixed constant $k$, otherwise it reports that the feedback vertex number is\ntoo large. With this assumption, we guarantee amortized update time ${\\cal\nO}_{\\varphi,k}(\\log n)$.\nBy combining this result with a classic theorem of Erd\\H{o}s and P\\'osa, we\ngive a fully dynamic data structure that maintains whether a graph contains a\npacking of $k$ vertex-disjoint cycles with amortized update time ${\\cal\nO}_{k}(\\log n)$. Our data structure also works in a larger generality of\nrelational structures over binary signatures.",
    "descriptor": "\nComments: 80 pages, 5 figures\n",
    "authors": [
      "Konrad Majewski",
      "Micha\u0142 Pilipczuk",
      "Marek Soko\u0142owski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.06232"
  },
  {
    "id": "arXiv:2107.06235",
    "title": "Exploiting Image Translations via Ensemble Self-Supervised Learning for  Unsupervised Domain Adaptation",
    "abstract": "We introduce an unsupervised domain adaption (UDA) strategy that combines\nmultiple image translations, ensemble learning and self-supervised learning in\none coherent approach. We focus on one of the standard tasks of UDA in which a\nsemantic segmentation model is trained on labeled synthetic data together with\nunlabeled real-world data, aiming to perform well on the latter. To exploit the\nadvantage of using multiple image translations, we propose an ensemble learning\napproach, where three classifiers calculate their prediction by taking as input\nfeatures of different image translations, making each classifier learn\nindependently, with the purpose of combining their outputs by sparse\nMultinomial Logistic Regression. This regression layer known as meta-learner\nhelps to reduce the bias during pseudo label generation when performing\nself-supervised learning and improves the generalizability of the model by\ntaking into consideration the contribution of each classifier. We evaluate our\nmethod on the standard UDA benchmarks, i.e. adapting GTA V and Synthia to\nCityscapes, and achieve state-of-the-art results in the mean intersection over\nunion metric. Extensive ablation experiments are reported to highlight the\nadvantageous properties of our proposed UDA strategy.",
    "descriptor": "\nComments: Manuscript under review at Computer Vision and Image Understanding (CVIU) journal\n",
    "authors": [
      "Fabrizio J. Piva",
      "Gijs Dubbelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06235"
  },
  {
    "id": "arXiv:2107.06236",
    "title": "An FPT algorithm for the embeddability of graphs into two-dimensional  simplicial complexes",
    "abstract": "We consider the embeddability problem of a graph G into a two-dimensional\nsimplicial complex C: Given G and C, decide whether G admits a topological\nembedding into C. The problem is NP-hard, even in the restricted case where C\nis homeomorphic to a surface.\nIt is known that the problem admits an algorithm with running time\nf(c).n^{O(c)}, where n is the size of the graph G and c is the size of the\ntwo-dimensional complex C. In other words, that algorithm is polynomial when C\nis fixed, but the degree of the polynomial depends on C. We prove that the\nproblem is fixed-parameter tractable in the size of the two-dimensional\ncomplex, by providing a deterministic f(c).n^3-time algorithm. We also provide\na randomized algorithm with expected running time 2^{c^{O(1)}}.n^{O(1)}.\nOur approach is to reduce to the case where G has bounded branchwidth via an\nirrelevant vertex method, and to apply dynamic programming. We do not rely on\nany component of the existing linear-time algorithms for embedding graphs on a\nfixed surface; the only elaborated tool that we use is an algorithm to compute\ngrid minors.",
    "descriptor": "",
    "authors": [
      "\u00c9ric Colin de Verdi\u00e8re",
      "Thomas Magnard"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.06236"
  },
  {
    "id": "arXiv:2107.06239",
    "title": "Everybody Is Unique: Towards Unbiased Human Mesh Recovery",
    "abstract": "We consider the problem of obese human mesh recovery, i.e., fitting a\nparametric human mesh to images of obese people. Despite obese person mesh\nfitting being an important problem with numerous applications (e.g.,\nhealthcare), much recent progress in mesh recovery has been restricted to\nimages of non-obese people. In this work, we identify this crucial gap in the\ncurrent literature by presenting and discussing limitations of existing\nalgorithms. Next, we present a simple baseline to address this problem that is\nscalable and can be easily used in conjunction with existing algorithms to\nimprove their performance. Finally, we present a generalized human mesh\noptimization algorithm that substantially improves the performance of existing\nmethods on both obese person images as well as community-standard benchmark\ndatasets. A key innovation of this technique is that it does not rely on\nsupervision from expensive-to-create mesh parameters. Instead, starting from\nwidely and cheaply available 2D keypoints annotations, our method automatically\ngenerates mesh parameters that can in turn be used to re-train and fine-tune\nany existing mesh estimation algorithm. This way, we show our method acts as a\ndrop-in to improve the performance of a wide variety of contemporary mesh\nestimation methods. We conduct extensive experiments on multiple datasets\ncomprising both standard and obese person images and demonstrate the efficacy\nof our proposed techniques.",
    "descriptor": "\nComments: 10 pages, 5 figures, 4 tables\n",
    "authors": [
      "Ren Li",
      "Meng Zheng",
      "Srikrishna Karanam",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06239"
  },
  {
    "id": "arXiv:2107.06242",
    "title": "Low Rate Protograph-Based LDPC Codes for Continuous Variable Quantum Key  Distribution",
    "abstract": "Error correction plays a major role in the reconciliation of continuous\nvariable quantum key distribution (CV-QKD) and greatly affects the performance\nof the system. CV-QKD requires error correction codes of extremely low rates\nand high reconciliation efficiencies. There are only very few code designs\navailable in this ultra low rate regime. In this paper, we introduce a method\nfor designing protograph-based ultra low rate LDPC codes using differential\nevolution. By proposing type-based protographs, a new way of representing low\nrate protograph-based LDPC codes, we drastically reduce the complexity of the\nprotograph optimization, which enables us to quickly design codes over a wide\nrange of rates. We show that the codes resulting from our optimization\noutperform the codes from the literature both in regards to the threshold and\nin finite-length performance, validated by Monte-Carlo simulations, showing\ngains in the regime relevant for CV-QKD.",
    "descriptor": "\nComments: Accepted for publication at ISWCS 2021 (Special session on coding for communications and security)\n",
    "authors": [
      "Kadir G\u00fcm\u00fcs",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06242"
  },
  {
    "id": "arXiv:2107.06243",
    "title": "Fairness-aware Summarization for Justified Decision-Making",
    "abstract": "In many applications such as recidivism prediction, facility inspection, and\nbenefit assignment, it's important for individuals to know the\ndecision-relevant information for the model's prediction. In addition, the\nmodel's predictions should be fairly justified. Essentially, decision-relevant\nfeatures should provide sufficient information for the predicted outcome and\nshould be independent of the membership of individuals in protected groups such\nas race and gender. In this work, we focus on the problem of (un)fairness in\nthe justification of the text-based neural models. We tie the explanatory power\nof the model to fairness in the outcome and propose a fairness-aware\nsummarization mechanism to detect and counteract the bias in such models. Given\na potentially biased natural language explanation for a decision, we use a\nmulti-task neural model and an attribution mechanism based on integrated\ngradients to extract the high-utility and discrimination-free justifications in\nthe form of a summary. The extracted summary is then used for training a model\nto make decisions for individuals. Results on several real-world datasets\nsuggests that our method: (i) assists users to understand what information is\nused for the model's decision and (ii) enhances the fairness in outcomes while\nsignificantly reducing the demographic leakage.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Moniba Keymanesh",
      "Tanya Berger-Wolf",
      "Micha Elsner",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.06243"
  },
  {
    "id": "arXiv:2107.06246",
    "title": "Between Flexibility and Consistency: Joint Generation of Captions and  Subtitles",
    "abstract": "Speech translation (ST) has lately received growing interest for the\ngeneration of subtitles without the need for an intermediate source language\ntranscription and timing (i.e. captions). However, the joint generation of\nsource captions and target subtitles does not only bring potential output\nquality advantages when the two decoding processes inform each other, but it is\nalso often required in multilingual scenarios. In this work, we focus on ST\nmodels which generate consistent captions-subtitles in terms of structure and\nlexical content. We further introduce new metrics for evaluating subtitling\nconsistency. Our findings show that joint decoding leads to increased\nperformance and consistency between the generated captions and subtitles while\nstill allowing for sufficient flexibility to produce subtitles conforming to\nlanguage-specific needs and norms.",
    "descriptor": "\nComments: Accepted at IWSLT 2021\n",
    "authors": [
      "Alina Karakanta",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06246"
  },
  {
    "id": "arXiv:2107.06252",
    "title": "Dance2Music: Automatic Dance-driven Music Generation",
    "abstract": "Dance and music typically go hand in hand. The complexities in dance, music,\nand their synchronisation make them fascinating to study from a computational\ncreativity perspective. While several works have looked at generating dance for\na given music, automatically generating music for a given dance remains\nunder-explored. This capability could have several creative expression and\nentertainment applications. We present some early explorations in this\ndirection. We present a search-based offline approach that generates music\nafter processing the entire dance video and an online approach that uses a deep\nneural network to generate music on-the-fly as the video proceeds. We compare\nthese approaches to a strong heuristic baseline via human studies and present\nour findings. We have integrated our online approach in a live demo! A video of\nthe demo can be found here:\nhttps://sites.google.com/view/dance2music/live-demo.",
    "descriptor": "",
    "authors": [
      "Gunjan Aggarwal",
      "Devi Parikh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06252"
  },
  {
    "id": "arXiv:2107.06253",
    "title": "Bottom-up Synthesis of Recursive Functional Programs using Angelic  Execution",
    "abstract": "We present a novel bottom-up method for the synthesis of functional recursive\nprograms. While bottom-up synthesis techniques can work better than top-down\nmethods in certain settings, there is no prior technique for synthesizing\nrecursive programs from logical specifications in a purely bottom-up fashion.\nThe main challenge is that effective bottom-up methods need to execute\nsub-expressions of the code being synthesized, but it is impossible to execute\na recursive subexpression of a program that has not been fully constructed yet.\nIn this paper, we address this challenge using the concept of angelic\nsemantics. Specifically, our method finds a program that satisfies the\nspecification under angelic semantics (we refer to this as angelic synthesis),\nanalyzes the assumptions made during its angelic execution, uses this analysis\nto strengthen the specification, and finally reattempts synthesis with the\nstrengthened specification. Our proposed angelic synthesis algorithm is based\non version space learning and therefore deals effectively with many incremental\nsynthesis calls made during the overall algorithm. We have implemented this\napproach in a prototype called Burst and evaluate it on synthesis problems from\nprior work. Our experiments show that Burst is able to synthesize a solution to\n95% of the benchmarks in our benchmark suite, outperforming prior work.",
    "descriptor": "",
    "authors": [
      "Anders Miltner",
      "Adrian Trejo Nu\u00f1ez",
      "Ana Brendel",
      "Swarat Chaudhuri",
      "Isil Dillig"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.06253"
  },
  {
    "id": "arXiv:2107.06256",
    "title": "Retrieve in Style: Unsupervised Facial Feature Transfer and Retrieval",
    "abstract": "We present Retrieve in Style (RIS), an unsupervised framework for\nfine-grained facial feature transfer and retrieval on real images. Recent work\nshows that it is possible to learn a catalog that allows local semantic\ntransfers of facial features on generated images by capitalizing on the\ndisentanglement property of the StyleGAN latent space. RIS improves existing\nart on: 1) feature disentanglement and allows for challenging transfers (i.e.,\nhair and pose) that were not shown possible in SoTA methods. 2) eliminating the\nneed for per-image hyperparameter tuning, and for computing a catalog over a\nlarge batch of images. 3) enabling face retrieval using the proposed facial\nfeatures (e.g., eyes), and to our best knowledge, is the first work to retrieve\nface images at the fine-grained level. 4) robustness and natural application to\nreal images. Our qualitative and quantitative analyses show RIS achieves both\nhigh-fidelity feature transfers and accurate fine-grained retrievals on real\nimages. We discuss the responsible application of RIS.",
    "descriptor": "\nComments: Code is here this https URL\n",
    "authors": [
      "Min Jin Chong",
      "Wen-Sheng Chu",
      "Abhishek Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06256"
  },
  {
    "id": "arXiv:2107.06257",
    "title": "Object Tracking and Geo-localization from Street Images",
    "abstract": "Geo-localizing static objects from street images is challenging but also very\nimportant for road asset mapping and autonomous driving. In this paper we\npresent a two-stage framework that detects and geolocalizes traffic signs from\nlow frame rate street videos. Our proposed system uses a modified version of\nRetinaNet (GPS-RetinaNet), which predicts a positional offset for each sign\nrelative to the camera, in addition to performing the standard classification\nand bounding box regression. Candidate sign detections from GPS-RetinaNet are\ncondensed into geolocalized signs by our custom tracker, which consists of a\nlearned metric network and a variant of the Hungarian Algorithm. Our metric\nnetwork estimates the similarity between pairs of detections, then the\nHungarian Algorithm matches detections across images using the similarity\nscores provided by the metric network. Our models were trained using an updated\nversion of the ARTS dataset, which contains 25,544 images and 47.589 sign\nannotations ~\\cite{arts}. The proposed dataset covers a diverse set of\nenvironments gathered from a broad selection of roads. Each annotaiton contains\na sign class label, its geospatial location, an assembly label, a side of road\nindicator, and unique identifiers that aid in the evaluation. This dataset will\nsupport future progress in the field, and the proposed system demonstrates how\nto take advantage of some of the unique characteristics of a realistic\ngeolocalization dataset.",
    "descriptor": "\nComments: 28 pages, 7 figures, to be submitted to Elsevier Pattern Recognition\n",
    "authors": [
      "Daniel Wilson",
      "Thayer Alshaabi",
      "Colin Van Oort",
      "Xiaohan Zhang",
      "Jonathan Nelson",
      "Safwan Wshah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06257"
  },
  {
    "id": "arXiv:2107.06259",
    "title": "Robust Learning of Optimal Auctions",
    "abstract": "We study the problem of learning revenue-optimal multi-bidder auctions from\nsamples when the samples of bidders' valuations can be adversarially corrupted\nor drawn from distributions that are adversarially perturbed. First, we prove\ntight upper bounds on the revenue we can obtain with a corrupted distribution\nunder a population model, for both regular valuation distributions and\ndistributions with monotone hazard rate (MHR). We then propose new algorithms\nthat, given only an ``approximate distribution'' for the bidder's valuation,\ncan learn a mechanism whose revenue is nearly optimal simultaneously for all\n``true distributions'' that are $\\alpha$-close to the original distribution in\nKolmogorov-Smirnov distance. The proposed algorithms operate beyond the setting\nof bounded distributions that have been studied in prior works, and are\nguaranteed to obtain a fraction $1-O(\\alpha)$ of the optimal revenue under the\ntrue distribution when the distributions are MHR. Moreover, they are guaranteed\nto yield at least a fraction $1-O(\\sqrt{\\alpha})$ of the optimal revenue when\nthe distributions are regular. We prove that these upper bounds cannot be\nfurther improved, by providing matching lower bounds. Lastly, we derive sample\ncomplexity upper bounds for learning a near-optimal auction for both MHR and\nregular distributions.",
    "descriptor": "",
    "authors": [
      "Wenshuo Guo",
      "Michael I. Jordan",
      "Manolis Zampetakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06259"
  },
  {
    "id": "arXiv:2107.06260",
    "title": "OpenCDA:An Open Cooperative Driving Automation FrameworkIntegrated with  Co-Simulation",
    "abstract": "Although Cooperative Driving Automation (CDA) has attracted considerable\nattention in recent years, there remain numerous open challenges in this field.\nThe gap between existing simulation platforms that mainly concentrate on\nsingle-vehicle intelligence and CDA development is one of the critical\nbarriers, as it inhibits researchers from validating and comparing different\nCDA algorithms conveniently. To this end, we propose OpenCDA, a generalized\nframework and tool for developing and testing CDA systems. Specifically,\nOpenCDA is composed of three major components: a co-simulation platform with\nsimulators of different purposes and resolutions, a full-stack cooperative\ndriving system, and a scenario manager. Through the interactions of these three\ncomponents, our framework offers a straightforward way for researchers to test\ndifferent CDA algorithms at both levels of traffic and individual autonomy.\nMore importantly, OpenCDA is highly modularized and installed with benchmark\nalgorithms and test cases. Users can conveniently replace any default module\nwith customized algorithms and use other default modules of the CDA platform to\nperform evaluations of the effectiveness of new functionalities in enhancing\nthe overall CDA performance. An example of platooning implementation is used to\nillustrate the framework's capability for CDA research. The codes of OpenCDA\nare available in the https://github.com/ucla-mobility/OpenCDA.",
    "descriptor": "\nComments: Accepted by ITSC2021\n",
    "authors": [
      "Runsheng Xu",
      "Yi Guo",
      "Xu Han",
      "Xin Xia",
      "Hao Xiang",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06260"
  },
  {
    "id": "arXiv:2107.06261",
    "title": "Tight running times for minimum $\\ell_q$-norm load balancing: beyond  exponential dependencies on $1/\u03b5$",
    "abstract": "We consider a classical scheduling problem on $m$ identical machines. For an\narbitrary constant $q>1$, the aim is to assign jobs to machines such that\n$\\sum_{i=1}^m C_i^q$ is minimized, where $C_i$ is the total processing time of\njobs assigned to machine $i$. It is well known that this problem is strongly\nNP-hard.\nUnder mild assumptions, the running time of an $(1+\\epsilon)$-approximation\nalgorithm for a strongly NP-hard problem cannot be polynomial on $1/\\epsilon$,\nunless $\\text{P}=\\text{NP}$. For most problems in the literature, this\ntranslates into algorithms with running time at least as large as\n$2^{\\Omega(1/\\varepsilon)}+n^{O(1)}$. For the natural scheduling problem above,\nwe establish the existence of an algorithm which violates this threshold. More\nprecisely, we design a PTAS that runs in\n$2^{\\tilde{O}(\\sqrt{1/\\epsilon})}+n^{O(1)}$ time. This result is in sharp\ncontrast to the closely related minimum makespan variant, where an exponential\nlower bound is known under the exponential time hypothesis (ETH). We complement\nour result with an essentially matching lower bound on the running time,\nshowing that our algorithm is best-possible under ETH. The lower bound proof\nexploits new number-theoretical constructions for variants of progression-free\nsets, which might be of independent interest.\nFurthermore, we provide a fine-grained characterization on the running time\nof a PTAS for this problem depending on the relation between $\\epsilon$ and the\nnumber of machines $m$. More precisely, our lower bound only holds when\n$m=\\Theta(\\sqrt{1/\\epsilon})$. Better algorithms, that go beyond the lower\nbound, exist for other values of $m$. In particular, there even exists an\nalgorithm with running time polynomial in $1/\\epsilon$ if we restrict ourselves\nto instances with $m=\\Omega(1/\\epsilon\\log^21/\\epsilon)$.",
    "descriptor": "",
    "authors": [
      "Lin Chen",
      "Liangde Tao",
      "Jos\u00e9 Verschae"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.06261"
  },
  {
    "id": "arXiv:2107.06262",
    "title": "Learning Aesthetic Layouts via Visual Guidance",
    "abstract": "We explore computational approaches for visual guidance to aid in creating\naesthetically pleasing art and graphic design. Our work complements and builds\non previous work that developed models for how humans look at images. Our\napproach comprises three steps. First, we collected a dataset of art\nmasterpieces and labeled the visual fixations with state-of-art vision models.\nSecond, we clustered the visual guidance templates of the art masterpieces with\nunsupervised learning. Third, we developed a pipeline using generative\nadversarial networks to learn the principles of visual guidance and that can\nproduce aesthetically pleasing layouts. We show that the aesthetic visual\nguidance principles can be learned and integrated into a high-dimensional model\nand can be queried by the features of graphic elements. We evaluate our\napproach by generating layouts on various drawings and graphic designs.\nMoreover, our model considers the color and structure of graphic elements when\ngenerating layouts. Consequently, we believe our tool, which generates multiple\naesthetic layout options in seconds, can help artists create beautiful art and\ngraphic designs.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Qingyuan Zheng",
      "Zhuoru Li",
      "Adam Bargteil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.06262"
  },
  {
    "id": "arXiv:2107.06263",
    "title": "CMT: Convolutional Neural Networks Meet Vision Transformers",
    "abstract": "Vision transformers have been successfully applied to image recognition tasks\ndue to their ability to capture long-range dependencies within an image.\nHowever, there are still gaps in both performance and computational cost\nbetween transformers and existing convolutional neural networks (CNNs). In this\npaper, we aim to address this issue and develop a network that can outperform\nnot only the canonical transformers, but also the high-performance\nconvolutional models. We propose a new transformer based hybrid network by\ntaking advantage of transformers to capture long-range dependencies, and of\nCNNs to model local features. Furthermore, we scale it to obtain a family of\nmodels, called CMTs, obtaining much better accuracy and efficiency than\nprevious convolution and transformer based models. In particular, our CMT-S\nachieves 83.5% top-1 accuracy on ImageNet, while being 14x and 2x smaller on\nFLOPs than the existing DeiT and EfficientNet, respectively. The proposed CMT-S\nalso generalizes well on CIFAR10 (99.2%), CIFAR100 (91.7%), Flowers (98.7%),\nand other challenging vision datasets such as COCO (44.3% mAP), with\nconsiderably less computational cost.",
    "descriptor": "",
    "authors": [
      "Jianyuan Guo",
      "Kai Han",
      "Han Wu",
      "Chang Xu",
      "Yehui Tang",
      "Chunjing Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06263"
  },
  {
    "id": "arXiv:2107.06265",
    "title": "Who is Looking at Whom? Visualizing Gaze Awareness for Remote  Small-Group Conversations",
    "abstract": "Video conferences play a vital role in our daily lives. However, many\nnonverbal cues are missing, including gaze and spatial information. We\nintroduce LookAtChat, a web-based video conferencing system, which empowers\nremote users to identify gaze awareness and spatial relationships in\nsmall-group conversations. Leveraging real-time eye-tracking technology\navailable with ordinary webcams, LookAtChat tracks each user's gaze direction,\nidentifies who is looking at whom, and provides corresponding spatial cues.\nInformed by formative interviews with 5 participants who regularly use\nvideoconferencing software, we explored the design space of gaze visualization\nin both 2D and 3D layouts. We further conducted an exploratory user study\n(N=20) to evaluate LookAtChat in three conditions: baseline layout, 2D\ndirectional layout, and 3D perspective layout. Our findings demonstrate how\nLookAtChat engages participants in small-group conversations, how gaze and\nspatial information improve conversation quality, and the potential benefits\nand challenges to incorporating gaze awareness visualization into existing\nvideoconferencing systems.",
    "descriptor": "\nComments: One column, 24 pages\n",
    "authors": [
      "Zhenyi He",
      "Ruofei Du",
      "Ken Perlin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06265"
  },
  {
    "id": "arXiv:2107.06268",
    "title": "Smoothed Bernstein Online Aggregation for Day-Ahead Electricity Demand  Forecasting",
    "abstract": "We present a winning method of the IEEE DataPort Competition on Day-Ahead\nElectricity Demand Forecasting: Post-COVID Paradigm. The day-ahead load\nforecasting approach is based on online forecast combination of multiple point\nprediction models. It contains four steps: i) data cleaning and preprocessing,\nii) a holiday adjustment procedure, iii) training of individual forecasting\nmodels, iv) forecast combination by smoothed Bernstein Online Aggregation\n(BOA). The approach is flexible and can quickly adopt to new energy system\nsituations as they occurred during and after COVID-19 shutdowns. The pool of\nindividual prediction models ranges from rather simple time series models to\nsophisticated models like generalized additive models (GAMs) and\nhigh-dimensional linear models estimated by lasso. They incorporate\nautoregressive, calendar and weather effects efficiently. All steps contain\nnovel concepts that contribute to the excellent forecasting performance of the\nproposed method. This holds particularly for the holiday adjustment procedure\nand the fully adaptive smoothed BOA approach.",
    "descriptor": "",
    "authors": [
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06268"
  },
  {
    "id": "arXiv:2107.06277",
    "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit  Partial Observability",
    "abstract": "Generalization is a central challenge for the deployment of reinforcement\nlearning (RL) systems in the real world. In this paper, we show that the\nsequential structure of the RL problem necessitates new approaches to\ngeneralization beyond the well-studied techniques used in supervised learning.\nWhile supervised learning methods can generalize effectively without explicitly\naccounting for epistemic uncertainty, we show that, perhaps surprisingly, this\nis not the case in RL. We show that generalization to unseen test conditions\nfrom a limited number of training conditions induces implicit partial\nobservability, effectively turning even fully-observed MDPs into POMDPs.\nInformed by this observation, we recast the problem of generalization in RL as\nsolving the induced partially observed Markov decision process, which we call\nthe epistemic POMDP. We demonstrate the failure modes of algorithms that do not\nappropriately handle this partial observability, and suggest a simple\nensemble-based technique for approximately solving the partially observed\nproblem. Empirically, we demonstrate that our simple algorithm derived from the\nepistemic POMDP achieves significant gains in generalization over current\nmethods on the Procgen benchmark suite.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Dibya Ghosh",
      "Jad Rahme",
      "Aviral Kumar",
      "Amy Zhang",
      "Ryan P. Adams",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06277"
  },
  {
    "id": "arXiv:2107.06278",
    "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation",
    "abstract": "Modern approaches typically formulate semantic segmentation as a per-pixel\nclassification task, while instance-level segmentation is handled with an\nalternative mask classification. Our key insight: mask classification is\nsufficiently general to solve both semantic- and instance-level segmentation\ntasks in a unified manner using the exact same model, loss, and training\nprocedure. Following this observation, we propose MaskFormer, a simple mask\nclassification model which predicts a set of binary masks, each associated with\na single global class label prediction. Overall, the proposed mask\nclassification-based method simplifies the landscape of effective approaches to\nsemantic and panoptic segmentation tasks and shows excellent empirical results.\nIn particular, we observe that MaskFormer outperforms per-pixel classification\nbaselines when the number of classes is large. Our mask classification-based\nmethod outperforms both current state-of-the-art semantic (55.6 mIoU on ADE20K)\nand panoptic segmentation (52.7 PQ on COCO) models.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Bowen Cheng",
      "Alexander G. Schwing",
      "Alexander Kirillov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06278"
  },
  {
    "id": "arXiv:2107.05630",
    "title": "Challenges for machine learning in clinical translation of big data  imaging studies",
    "abstract": "The combination of deep learning image analysis methods and large-scale\nimaging datasets offers many opportunities to imaging neuroscience and\nepidemiology. However, despite the success of deep learning when applied to\nmany neuroimaging tasks, there remain barriers to the clinical translation of\nlarge-scale datasets and processing tools. Here, we explore the main challenges\nand the approaches that have been explored to overcome them. We focus on issues\nrelating to data availability, interpretability, evaluation and logistical\nchallenges, and discuss the challenges we believe are still to be overcome to\nenable the full success of big data deep learning approaches to be experienced\noutside of the research field.",
    "descriptor": "",
    "authors": [
      "Nicola K Dinsdale",
      "Emma Bluemke",
      "Vaanathi Sundaresan",
      "Mark Jenkinson",
      "Stephen Smith",
      "Ana IL Namburete"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05630"
  },
  {
    "id": "arXiv:2107.05675",
    "title": "Quality of Service Guarantees for Physical Unclonable Functions",
    "abstract": "We consider a secret key agreement problem in which noisy physical unclonable\nfunction (PUF) outputs facilitate reliable, secure, and private key agreement\nwith the help of public, noiseless, and authenticated storage. PUF outputs are\nhighly correlated, so transform coding methods have been combined with scalar\nquantizers to extract uncorrelated bit sequences with reliability guarantees.\nFor PUF circuits with continuous-valued outputs, the models for transformed\noutputs are made more realistic by replacing the fitted distributions with\ncorresponding truncated ones. The state-of-the-art PUF methods that provide\nreliability guarantees to each extracted bit are shown to be inadequate to\nguarantee the same reliability level for all PUF outputs. Thus, a quality of\nservice parameter is introduced to control the percentage of PUF outputs for\nwhich a target reliability level can be guaranteed. A public ring oscillator\n(RO) output dataset is used to illustrate that a truncated Gaussian\ndistribution can be fitted to transformed RO outputs that are inputs to uniform\nscalar quantizers such that reliability guarantees can be provided for each bit\nextracted from any PUF device under additive Gaussian noise components by\neliminating a small subset of PUF outputs. Furthermore, we conversely show that\nit is not possible to provide such reliability guarantees without eliminating\nany PUF output if no extra secrecy and privacy leakage is allowed.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05675"
  },
  {
    "id": "arXiv:2107.05709",
    "title": "Optimal input representation in neural systems at the edge of chaos",
    "abstract": "Shedding light onto how biological systems represent, process and store\ninformation in noisy environments is a key and challenging goal. A stimulating,\nthough controversial, hypothesis poses that operating in dynamical regimes near\nthe edge of a phase transition, i.e. at criticality or the \"edge of chaos\", can\nprovide information-processing living systems with important operational\nadvantages, creating, e.g., an optimal trade-off between robustness and\nflexibility. Here, we elaborate on a recent theoretical result, which\nestablishes that the spectrum of covariance matrices of neural networks\nrepresenting complex inputs in a robust way needs to decay as a power-law of\nthe rank, with an exponent close to unity, a result that has been indeed\nexperimentally verified in neurons of the mouse visual cortex. Aimed at\nunderstanding and mimicking these results, we construct an artificial neural\nnetwork and train it to classify images. Remarkably, we find that the best\nperformance in such a task is obtained when the network operates near the\ncritical point, at which the eigenspectrum of the covariance matrix follows the\nvery same statistics as actual neurons do. Thus, we conclude that operating\nnear criticality can also have -- besides the usually alleged virtues -- the\nadvantage of allowing for flexible, robust and efficient input representations.",
    "descriptor": "",
    "authors": [
      "Guillermo B. Morales",
      "Miguel A. Mu\u00f1oz"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.05709"
  },
  {
    "id": "arXiv:2107.05719",
    "title": "Calibrating Predictions to Decisions: A Novel Approach to Multi-Class  Calibration",
    "abstract": "When facing uncertainty, decision-makers want predictions they can trust. A\nmachine learning provider can convey confidence to decision-makers by\nguaranteeing their predictions are distribution calibrated -- amongst the\ninputs that receive a predicted class probabilities vector $q$, the actual\ndistribution over classes is $q$. For multi-class prediction problems, however,\nachieving distribution calibration tends to be infeasible, requiring sample\ncomplexity exponential in the number of classes $C$. In this work, we introduce\na new notion -- \\emph{decision calibration} -- that requires the predicted\ndistribution and true distribution to be ``indistinguishable'' to a set of\ndownstream decision-makers. When all possible decision makers are under\nconsideration, decision calibration is the same as distribution calibration.\nHowever, when we only consider decision makers choosing between a bounded\nnumber of actions (e.g. polynomial in $C$), our main result shows that\ndecisions calibration becomes feasible -- we design a recalibration algorithm\nthat requires sample complexity polynomial in the number of actions and the\nnumber of classes. We validate our recalibration algorithm empirically:\ncompared to existing methods, decision calibration improves decision-making on\nskin lesion and ImageNet classification with modern neural network predictors.",
    "descriptor": "",
    "authors": [
      "Shengjia Zhao",
      "Michael P. Kim",
      "Roshni Sahoo",
      "Tengyu Ma",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.05719"
  },
  {
    "id": "arXiv:2107.05767",
    "title": "Effects of personality traits in predicting grade retention of Brazilian  students",
    "abstract": "Student's grade retention is a key issue faced by many education systems,\nespecially those in developing countries. In this paper, we seek to gauge the\nrelevance of students' personality traits in predicting grade retention in\nBrazil. For that, we used data collected in 2012 and 2017, in the city of\nSertaozinho, countryside of the state of Sao Paulo, Brazil. The surveys taken\nin Sertaozinho included several socioeconomic questions, standardized tests,\nand a personality test. Moreover, students were in grades 4, 5, and 6 in 2012.\nOur approach was based on training machine learning models on the surveys' data\nto predict grade retention between 2012 and 2017 using information from 2012 or\nbefore, and then using some strategies to quantify personality traits'\npredictive power. We concluded that, besides proving to be fairly better than a\nrandom classifier when isolated, personality traits contribute to prediction\neven when using socioeconomic variables and standardized tests results.",
    "descriptor": "",
    "authors": [
      "Carmen Melo Toledo",
      "Guilherme Mendes Bassedon",
      "Jonathan Batista Ferreira",
      "Lucka de Godoy Gianvechio",
      "Carlos Guatimosim",
      "Felipe Maia Polo",
      "Renato Vicente"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05767"
  },
  {
    "id": "arXiv:2107.05807",
    "title": "Dendritic organic electrochemical transistors grown by  electropolymerization for 3D neuromorphic engineering",
    "abstract": "One of the major limitation of standard top-down technologies used in today's\nneuromorphic engineering is their inability to map the 3D nature of biological\nbrains. Here, we show how bipolar electropolymerization can be used to engineer\n3D networks of PEDOT:PSS dendritic fibers. By controlling the growth conditions\nof the electropolymerized material, we investigate how dendritic fibers can\nreproduce structural plasticity by creating structures of controllable shape.\nWe demonstrate gradual topologies evolution in a multi-electrode configuration.\nWe conduct a detail electrical characterization of the PEDOT:PSS dendrites\nthrough DC and impedance spectroscopy measurements and we show how organic\nelectrochemical transistors (OECT) can be realized with these structures. These\nmeasurements reveal that quasi-static and transient response of OECTs can be\nadjust by controlling dendrites' morphologies. The unique properties of organic\ndendrites are used to demonstrate short-term, long-term and structural\nplasticity, which are essential features required for future neuromorphic\nhardware development.",
    "descriptor": "\nComments: 22 pages, 4 figures. K. Janzakova, M. Ghazal and A. Kumar contributed equally to this work\n",
    "authors": [
      "Kamila Janzakova",
      "Mahdi Ghazal",
      "Ankush Kumar",
      "Yannick Coffinier",
      "S\u00e9bastien Pecqueur",
      "Fabien Alibart"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.05807"
  },
  {
    "id": "arXiv:2107.05834",
    "title": "Oversampling Divide-and-conquer for Response-skewed Kernel Ridge  Regression",
    "abstract": "The divide-and-conquer method has been widely used for estimating large-scale\nkernel ridge regression estimates. Unfortunately, when the response variable is\nhighly skewed, the divide-and-conquer kernel ridge regression (dacKRR) may\noverlook the underrepresented region and result in unacceptable results. We\ndevelop a novel response-adaptive partition strategy to overcome the\nlimitation. In particular, we propose to allocate the replicates of some\ncarefully identified informative observations to multiple nodes (local\nprocessors). The idea is analogous to the popular oversampling technique.\nAlthough such a technique has been widely used for addressing discrete label\nskewness, extending it to the dacKRR setting is nontrivial. We provide both\ntheoretical and practical guidance on how to effectively over-sample the\nobservations under the dacKRR setting. Furthermore, we show the proposed\nestimate has a smaller asymptotic mean squared error (AMSE) than that of the\nclassical dacKRR estimate under mild conditions. Our theoretical findings are\nsupported by both simulated and real-data analyses.",
    "descriptor": "",
    "authors": [
      "Jingyi Zhang",
      "Xiaoxiao Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05834"
  },
  {
    "id": "arXiv:2107.05838",
    "title": "Analytical approach to the generalized friendship paradox in networks  with correlated attributes",
    "abstract": "One of the interesting phenomena due to the topological heterogeneities in\ncomplex networks is the friendship paradox, stating that your friends have on\naverage more friends than you do. Recently, this paradox has been generalized\nfor arbitrary nodal attributes, called a generalized friendship paradox (GFP).\nIn this paper, we analyze the GFP for the networks in which the attributes of\nneighboring nodes are correlated with each other. The correlation structure\nbetween attributes of neighboring nodes is modeled by the\nFarlie-Gumbel-Morgenstern copula, enabling us to derive approximate analytical\nsolutions of the GFP for three kinds of methods summarizing the neighborhood of\nthe focal node, i.e., mean-based, median-based, and fraction-based methods. The\nanalytical solutions are comparable to simulation results, while some\nsystematic deviations between them might be attributed to the higher-order\ncorrelations between nodal attributes. These results help us get deeper insight\ninto how various summarization methods as well as the correlation structure of\nnodal attributes affect the GFP behavior, hence better understand various\nrelated phenomena in complex networks.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Hang-Hyun Jo",
      "Eun Lee",
      "Young-Ho Eom"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.05838"
  },
  {
    "id": "arXiv:2107.05847",
    "title": "Hyperparameter Optimization: Foundations, Algorithms, Best Practices and  Open Challenges",
    "abstract": "Most machine learning algorithms are configured by one or several\nhyperparameters that must be carefully chosen and often considerably impact\nperformance. To avoid a time consuming and unreproducible manual\ntrial-and-error process to find well-performing hyperparameter configurations,\nvarious automatic hyperparameter optimization (HPO) methods, e.g., based on\nresampling error estimation for supervised machine learning, can be employed.\nAfter introducing HPO from a general perspective, this paper reviews important\nHPO methods such as grid or random search, evolutionary algorithms, Bayesian\noptimization, Hyperband and racing. It gives practical recommendations\nregarding important choices to be made when conducting HPO, including the HPO\nalgorithms themselves, performance evaluation, how to combine HPO with ML\npipelines, runtime improvements, and parallelization.",
    "descriptor": "\nComments: 67 pages, 13 figures, to be published in WIREs: Data Mining and Knowledge Discovery\n",
    "authors": [
      "Bernd Bischl",
      "Martin Binder",
      "Michel Lang",
      "Tobias Pielok",
      "Jakob Richter",
      "Stefan Coors",
      "Janek Thomas",
      "Theresa Ullmann",
      "Marc Becker",
      "Anne-Laure Boulesteix",
      "Difan Deng",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05847"
  },
  {
    "id": "arXiv:2107.05849",
    "title": "Model Selection with Near Optimal Rates for Reinforcement Learning with  General Model Classes",
    "abstract": "We address the problem of model selection for the finite horizon episodic\nReinforcement Learning (RL) problem where the transition kernel $P^*$ belongs\nto a family of models $\\mathcal{P}^*$ with finite metric entropy. In the model\nselection framework, instead of $\\mathcal{P}^*$, we are given $M$ nested\nfamilies of transition kernels $\\cP_1 \\subset \\cP_2 \\subset \\ldots \\subset\n\\cP_M$. We propose and analyze a novel algorithm, namely \\emph{Adaptive\nReinforcement Learning (General)} (\\texttt{ARL-GEN}) that adapts to the\nsmallest such family where the true transition kernel $P^*$ lies.\n\\texttt{ARL-GEN} uses the Upper Confidence Reinforcement Learning\n(\\texttt{UCRL}) algorithm with value targeted regression as a blackbox and puts\na model selection module at the beginning of each epoch. Under a mild\nseparability assumption on the model classes, we show that \\texttt{ARL-GEN}\nobtains a regret of\n$\\Tilde{\\mathcal{O}}(d_{\\mathcal{E}}^*H^2+\\sqrt{d_{\\mathcal{E}}^* \\mathbb{M}^*\nH^2 T})$, with high probability, where $H$ is the horizon length, $T$ is the\ntotal number of steps, $d_{\\mathcal{E}}^*$ is the Eluder dimension and\n$\\mathbb{M}^*$ is the metric entropy corresponding to $\\mathcal{P}^*$. Note\nthat this regret scaling matches that of an oracle that knows $\\mathcal{P}^*$\nin advance. We show that the cost of model selection for \\texttt{ARL-GEN} is an\nadditive term in the regret having a weak dependence on $T$. Subsequently, we\nremove the separability assumption and consider the setup of linear mixture\nMDPs, where the transition kernel $P^*$ has a linear function approximation.\nWith this low rank structure, we propose novel adaptive algorithms for model\nselection, and obtain (order-wise) regret identical to that of an oracle with\nknowledge of the true model class.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Avishek Ghosh",
      "Sayak Ray Chowdhury",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05849"
  },
  {
    "id": "arXiv:2107.05853",
    "title": "On the Impact of Information Acquisition and Aftermarkets on Auction  Efficiency",
    "abstract": "A common assumption in auction theory is that the information available to\nthe agents is given exogenously and that the auctioneer has full control over\nthe market. In practice, agents might be able to acquire information about\ntheir competitors before the auction (by exerting some costly effort), and\nmight be able to resell acquired items in an aftermarket. The auctioneer has no\ncontrol over those aspects, yet their existence influences agents' strategic\nbehavior and the overall equilibrium welfare can strictly decrease as a result.\nWe show that if an auction is smooth (e.g., first-price auction, all-pay\nauction), then the corresponding price of anarchy bound due to smoothness\ncontinues to hold in any environment with (a) information acquisition on\nopponents' valuations, and/or (b) an aftermarket satisfying two mild conditions\n(voluntary participation and weak budget balance). We also consider the special\ncase with two ex ante symmetric bidders, where the first-price auction is known\nto be efficient in isolation. We show that information acquisition can lead to\nefficiency loss in this environment, but aftermarkets do not: any equilibrium\nof a first-price or all-pay auction combined with an aftermarket is still\nefficient.",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Nicole Immorlica",
      "Yingkai Li",
      "Brendan Lucier"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.05853"
  },
  {
    "id": "arXiv:2107.05859",
    "title": "AUC Optimization for Robust Small-footprint Keyword Spotting with  Limited Training Data",
    "abstract": "Deep neural networks provide effective solutions to small-footprint keyword\nspotting (KWS). However, if training data is limited, it remains challenging to\nachieve robust and highly accurate KWS in real-world scenarios where unseen\nsounds that are out of the training data are frequently encountered. Most\nconventional methods aim to maximize the classification accuracy on the\ntraining set, without taking the unseen sounds into account. To enhance the\nrobustness of the deep neural networks based KWS, in this paper, we introduce a\nnew loss function, named the maximization of the area under the\nreceiver-operating-characteristic curve (AUC). The proposed method not only\nmaximizes the classification accuracy of keywords on the closed training set,\nbut also maximizes the AUC score for optimizing the performance of non-keyword\nsegments detection. Experimental results on the Google Speech Commands dataset\nv1 and v2 show that our method achieves new state-of-the-art performance in\nterms of most evaluation metrics.",
    "descriptor": "\nComments: submitted to ASRU2021\n",
    "authors": [
      "Menglong Xu",
      "Shengqiang Li",
      "Chengdong Liang",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.05859"
  },
  {
    "id": "arXiv:2107.05870",
    "title": "Potential singularity of the 3D Euler equations in the interior domain",
    "abstract": "Whether the 3D incompressible Euler equations can develop a finite time\nsingularity from smooth initial data is one of the most challenging problems in\nnonlinear PDEs. In this paper, we present some new numerical evidence that the\n3D axisymmetric incompressible Euler equations with smooth initial data of\nfinite energy develop a potential finite time singularity at the origin. This\npotential singularity is different from the blowup scenario revealed by Luo-Hou\nin \\cite{luo2014potentially,luo2014toward}, which occurs on the boundary. Our\ninitial condition has a simple form and shares several attractive features of a\nmore sophisticated initial condition constructed by Hou-Huang in\n\\cite{Hou-Huang-2021}. One important difference between these two blowup\nscenarios is that the solution for our initial data has a one-scale structure\ninstead of a two-scale structure reported in \\cite{Hou-Huang-2021}. More\nimportantly, the solution seems to develop nearly self-similar scaling\nproperties that are compatible with those of the 3D Navier--Stokes equations.\nWe will present strong numerical evidence that the 3D Euler equations seem to\ndevelop a potential finite time singularity. Moreover, the nearly self-similar\nprofile seems to be very stable to the small perturbation of the initial data.\nFinally, we present some preliminary results to demonstrate that the 3D\nNavier--Stokes equations using the same initial condition develop nearly\nsingular behavior with maximum vorticity increased by a factor of $10^{7}$.",
    "descriptor": "\nComments: 39 pages. arXiv admin note: text overlap with arXiv:2102.06663\n",
    "authors": [
      "Thomas Y. Hou"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.05870"
  },
  {
    "id": "arXiv:2107.05876",
    "title": "A Configurable Multilingual Model is All You Need to Recognize All  Languages",
    "abstract": "Multilingual automatic speech recognition (ASR) models have shown great\npromise in recent years because of the simplified model training and deployment\nprocess. Conventional methods either train a universal multilingual model\nwithout taking any language information or with a 1-hot language ID (LID)\nvector to guide the recognition of the target language. In practice, the user\ncan be prompted to pre-select several languages he/she can speak. The\nmultilingual model without LID cannot well utilize the language information set\nby the user while the multilingual model with LID can only handle one\npre-selected language. In this paper, we propose a novel configurable\nmultilingual model (CMM) which is trained only once but can be configured as\ndifferent models based on users' choices by extracting language-specific\nmodules together with a universal model from the trained CMM. Particularly, a\nsingle CMM can be deployed to any user scenario where the users can pre-select\nany combination of languages. Trained with 75K hours of transcribed anonymized\nMicrosoft multilingual data and evaluated with 10-language test sets, the\nproposed CMM improves from the universal multilingual model by 26.0%, 16.9%,\nand 10.4% relative word error reduction when the user selects 1, 2, or 3\nlanguages, respectively. CMM also performs significantly better on\ncode-switching test sets.",
    "descriptor": "",
    "authors": [
      "Long Zhou",
      "Jinyu Li",
      "Eric Sun",
      "Shujie Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.05876"
  },
  {
    "id": "arXiv:2107.05891",
    "title": "Dynamic State Estimation for Integrated Natural Gas and Electric Power  Systems",
    "abstract": "A dynamic state estimation method of integrated natural gas and electric\npower systems (IGESs) in proposed. Firstly, the coupling model of gas pipeline\nnetworks and power systems by gas turbine units (GTUs) is established.\nSecondly, the Kalman filter based linear DSE model for the IGES is built. The\ngas density and mass flow rate, as well as the real and imaginary parts of bus\nvoltages are taken as states, which are predicted by the linearized fluid\ndynamic equations of gases and exponential smoothing techniques. Boundary\nconditions of pipeline networks are used as supplementary constraints in the\nsystem model. At last, the proposed method is applied to an IGES including a\n30-node pipeline network and IEEE 39-bus system coupled by two GTUs. Two\nindexes are used to evaluate the DSE performance under three measurement error\nconditions, and the results show that the DSE can obtain the accurate dynamic\nstates in different conditions.",
    "descriptor": "\nComments: Accepted by 2021 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)\n",
    "authors": [
      "Liang Chen",
      "Xinxin Hui",
      "Songlin Gu",
      "Manyun Huang",
      "Yang Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.05891"
  },
  {
    "id": "arXiv:2107.05895",
    "title": "A Theory of Spherical Diagrams",
    "abstract": "We introduce the axiomatic theory of Spherical Occlusion Diagrams as a tool\nto study certain combinatorial properties of polyhedra in $\\mathbb R^3$, which\nare of central interest in the context Art Gallery problems for polyhedra and\nother visibility-related problems in discrete and computational geometry.",
    "descriptor": "\nComments: 8 pages, 17 figures\n",
    "authors": [
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.05895"
  },
  {
    "id": "arXiv:2107.05951",
    "title": "One-Point Gradient-Free Methods for Composite Optimization with  Applications to Distributed Optimization",
    "abstract": "This work is devoted to solving the composite optimization problem with the\nmixture oracle: for the smooth part of the problem, we have access to the\ngradient, and for the non-smooth part, only to the one-point zero-order oracle.\nWe present a method based on the sliding algorithm. Our method allows to\nseparate the oracle complexities and compute the gradient for one of the\nfunction as rarely as possible. The paper also examines the applicability of\nthis method to the problems of distributed optimization and federated learning.",
    "descriptor": "",
    "authors": [
      "Ivan Stepanov",
      "Artyom Voronov",
      "Aleksandr Beznosikov",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.05951"
  },
  {
    "id": "arXiv:2107.05975",
    "title": "Detecting when pre-trained nnU-Net models fail silently for Covid-19",
    "abstract": "Automatic segmentation of lung lesions in computer tomography has the\npotential to ease the burden of clinicians during the Covid-19 pandemic. Yet\npredictive deep learning models are not trusted in the clinical routine due to\nfailing silently in out-of-distribution (OOD) data. We propose a lightweight\nOOD detection method that exploits the Mahalanobis distance in the feature\nspace. The proposed approach can be seamlessly integrated into state-of-the-art\nsegmentation pipelines without requiring changes in model architecture or\ntraining procedure, and can therefore be used to assess the suitability of\npre-trained models to new data. We validate our method with a patch-based\nnnU-Net architecture trained with a multi-institutional dataset and find that\nit effectively detects samples that the model segments incorrectly.",
    "descriptor": "",
    "authors": [
      "Camila Gonzalez",
      "Karol Gotkowski",
      "Andreas Bucher",
      "Ricarda Fischbach",
      "Isabel Kaltenborn",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05975"
  },
  {
    "id": "arXiv:2107.05984",
    "title": "Deep Autoregressive Models with Spectral Attention",
    "abstract": "Time series forecasting is an important problem across many domains, playing\na crucial role in multiple real-world applications. In this paper, we propose a\nforecasting architecture that combines deep autoregressive models with a\nSpectral Attention (SA) module, which merges global and local frequency domain\ninformation in the model's embedded space. By characterizing in the spectral\ndomain the embedding of the time series as occurrences of a random process, our\nmethod can identify global trends and seasonality patterns. Two spectral\nattention models, global and local to the time series, integrate this\ninformation within the forecast and perform spectral filtering to remove time\nseries's noise. The proposed architecture has a number of useful properties: it\ncan be effectively incorporated into well-know forecast architectures,\nrequiring a low number of parameters and producing interpretable results that\nimprove forecasting accuracy. We test the Spectral Attention Autoregressive\nModel (SAAM) on several well-know forecast datasets, consistently demonstrating\nthat our model compares favorably to state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Fernando Moreno-Pino",
      "Pablo M. Olmos",
      "Antonio Art\u00e9s-Rodr\u00edguez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05984"
  },
  {
    "id": "arXiv:2107.05990",
    "title": "Combining 3D Image and Tabular Data via the Dynamic Affine Feature Map  Transform",
    "abstract": "Prior work on diagnosing Alzheimer's disease from magnetic resonance images\nof the brain established that convolutional neural networks (CNNs) can leverage\nthe high-dimensional image information for classifying patients. However,\nlittle research focused on how these models can utilize the usually\nlow-dimensional tabular information, such as patient demographics or laboratory\nmeasurements. We introduce the Dynamic Affine Feature Map Transform (DAFT), a\ngeneral-purpose module for CNNs that dynamically rescales and shifts the\nfeature maps of a convolutional layer, conditional on a patient's tabular\nclinical information. We show that DAFT is highly effective in combining 3D\nimage and tabular information for diagnosis and time-to-dementia prediction,\nwhere it outperforms competing CNNs with a mean balanced accuracy of 0.622 and\nmean c-index of 0.748, respectively. Our extensive ablation study provides\nvaluable insights into the architectural properties of DAFT. Our implementation\nis available at https://github.com/ai-med/DAFT.",
    "descriptor": "\nComments: Accepted at 2021 International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)\n",
    "authors": [
      "Sebastian P\u00f6lsterl",
      "Tom Nuno Wolf",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05990"
  },
  {
    "id": "arXiv:2107.05991",
    "title": "Learning based E2E Energy Efficient in Joint Radio and NFV Resource  Allocation for 5G and Beyond Networks",
    "abstract": "In this paper, we propose a joint radio and core resource allocation\nframework for NFV-enabled networks. In the proposed system model, the goal is\nto maximize energy efficiency (EE), by guaranteeing end-to-end (E2E) quality of\nservice (QoS) for different service types. To this end, we formulate an\noptimization problem in which power and spectrum resources are allocated in the\nradio part. In the core part, the chaining, placement, and scheduling of\nfunctions are performed to ensure the QoS of all users. This joint optimization\nproblem is modeled as a Markov decision process (MDP), considering time-varying\ncharacteristics of the available resources and wireless channels. A soft\nactor-critic deep reinforcement learning (SAC-DRL) algorithm based on the\nmaximum entropy framework is subsequently utilized to solve the above MDP.\nNumerical results reveal that the proposed joint approach based on the SAC-DRL\nalgorithm could significantly reduce energy consumption compared to the case in\nwhich R-RA and NFV-RA problems are optimized separately.",
    "descriptor": "",
    "authors": [
      "Narges Gholipoor",
      "Ali Nouruzi",
      "Shima Salarhosseini",
      "Mohammad Reza Javan",
      "Nader Mokari",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.05991"
  },
  {
    "id": "arXiv:2107.05995",
    "title": "On the Hat Guessing Number of Graphs",
    "abstract": "The hat guessing number $HG(G)$ of a graph $G$ on $n$ vertices is defined in\nterms of the following game: $n$ players are placed on the $n$ vertices of $G$,\neach wearing a hat whose color is arbitrarily chosen from a set of $q$ possible\ncolors. Each player can see the hat colors of his neighbors, but not his own\nhat color. All of the players are asked to guess their own hat colors\nsimultaneously, according to a predetermined guessing strategy and the hat\ncolors they see, where no communication between them is allowed. The hat\nguessing number $HG(G)$ is the largest integer $q$ such that there exists a\nguessing strategy guaranteeing at least one correct guess for any hat\nassignment of $q$ possible colors.\nIn this note we construct a planar graph $G$ satisfying $HG(G)=12$, settling\na problem raised in \\cite{BDFGM}. We also improve the known lower bound of\n$(2-o(1))\\log_2 n$ for the typical hat guessing number of the random graph\n$G=G(n,1/2)$, showing that it is at least $n^{1-o(1)}$ with probability tending\nto $1$ as $n$ tends to infinity. Finally, we consider the linear hat guessing\nnumber of complete multipartite graphs.",
    "descriptor": "",
    "authors": [
      "Noga Alon",
      "Jeremy Chizewer"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05995"
  },
  {
    "id": "arXiv:2107.06008",
    "title": "Wasserstein GAN: Deep Generation applied on Bitcoins financial time  series",
    "abstract": "Modeling financial time series is challenging due to their high volatility\nand unexpected happenings on the market. Most financial models and algorithms\ntrying to fill the lack of historical financial time series struggle to perform\nand are highly vulnerable to overfitting. As an alternative, we introduce in\nthis paper a deep neural network called the WGAN-GP, a data-driven model that\nfocuses on sample generation. The WGAN-GP consists of a generator and\ndiscriminator function which utilize an LSTM architecture. The WGAN-GP is\nsupposed to learn the underlying structure of the input data, which in our\ncase, is the Bitcoin. Bitcoin is unique in its behavior; the prices fluctuate\nwhat makes guessing the price trend hardly impossible. Through adversarial\ntraining, the WGAN-GP should learn the underlying structure of the bitcoin and\ngenerate very similar samples of the bitcoin distribution. The generated\nsynthetic time series are visually indistinguishable from the real data. But\nthe numerical results show that the generated data were close to the real data\ndistribution but distinguishable. The model mainly shows a stable learning\nbehavior. However, the model has space for optimization, which could be\nachieved by adjusting the hyperparameters.",
    "descriptor": "",
    "authors": [
      "Rikli Samuel",
      "Bigler Daniel Nico",
      "Pfenninger Moritz",
      "Osterrieder Joerg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06008"
  },
  {
    "id": "arXiv:2107.06028",
    "title": "Lifting the Convex Conjugate in Lagrangian Relaxations: A Tractable  Approach for Continuous Markov Random Fields",
    "abstract": "Dual decomposition approaches in nonconvex optimization may suffer from a\nduality gap. This poses a challenge when applying them directly to nonconvex\nproblems such as MAP-inference in a Markov random field (MRF) with continuous\nstate spaces. To eliminate such gaps, this paper considers a reformulation of\nthe original nonconvex task in the space of measures. This infinite-dimensional\nreformulation is then approximated by a semi-infinite one, which is obtained\nvia a piecewise polynomial discretization in the dual. We provide a geometric\nintuition behind the primal problem induced by the dual discretization and draw\nconnections to optimization over moment spaces. In contrast to existing\ndiscretizations which suffer from a grid bias, we show that a piecewise\npolynomial discretization better preserves the continuous nature of our\nproblem. Invoking results from optimal transport theory and convex algebraic\ngeometry we reduce the semi-infinite program to a finite one and provide a\npractical implementation based on semidefinite programming. We show,\nexperimentally and in theory, that the approach successfully reduces the\nduality gap. To showcase the scalability of our approach, we apply it to the\nstereo matching problem between two images.",
    "descriptor": "",
    "authors": [
      "Hartmut Bauermeister",
      "Emanuel Laude",
      "Thomas M\u00f6llenhoff",
      "Michael Moeller",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06028"
  },
  {
    "id": "arXiv:2107.06099",
    "title": "Drug-Target Interaction Prediction with Graph Attention networks",
    "abstract": "Motivation: Predicting Drug-Target Interaction (DTI) is a well-studied topic\nin bioinformatics due to its relevance in the fields of proteomics and\npharmaceutical research. Although many machine learning methods have been\nsuccessfully applied in this task, few of them aim at leveraging the inherent\nheterogeneous graph structure in the DTI network to address the challenge. For\nbetter learning and interpreting the DTI topological structure and the\nsimilarity, it is desirable to have methods specifically for predicting\ninteractions from the graph structure.\nResults: We present an end-to-end framework, DTI-GAT (Drug-Target Interaction\nprediction with Graph Attention networks) for DTI predictions. DTI-GAT\nincorporates a deep neural network architecture that operates on\ngraph-structured data with the attention mechanism, which leverages both the\ninteraction patterns and the features of drug and protein sequences. DTI-GAT\nfacilitates the interpretation of the DTI topological structure by assigning\ndifferent attention weights to each node with the self-attention mechanism.\nExperimental evaluations show that DTI-GAT outperforms various state-of-the-art\nsystems on the binary DTI prediction problem. Moreover, the independent study\nresults further demonstrate that our model can be generalized better than other\nconventional methods.\nAvailability: The source code and all datasets are available at\nhttps://github.com/Haiyang-W/DTI-GRAPH",
    "descriptor": "",
    "authors": [
      "Haiyang Wang",
      "Guangyu Zhou",
      "Siqi Liu",
      "Jyun-Yu Jiang",
      "Wei Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06099"
  },
  {
    "id": "arXiv:2107.06104",
    "title": "Functional Magnetic Resonance Imaging data augmentation through  conditional ICA",
    "abstract": "Advances in computational cognitive neuroimaging research are related to the\navailability of large amounts of labeled brain imaging data, but such data are\nscarce and expensive to generate. While powerful data generation mechanisms,\nsuch as Generative Adversarial Networks (GANs), have been designed in the last\ndecade for computer vision, such improvements have not yet carried over to\nbrain imaging. A likely reason is that GANs training is ill-suited to the\nnoisy, high-dimensional and small-sample data available in functional\nneuroimaging.In this paper, we introduce Conditional Independent Components\nAnalysis (Conditional ICA): a fast functional Magnetic Resonance Imaging (fMRI)\ndata augmentation technique, that leverages abundant resting-state data to\ncreate images by sampling from an ICA decomposition. We then propose a\nmechanism to condition the generator on classes observed with few samples. We\nfirst show that the generative mechanism is successful at synthesizing data\nindistinguishable from observations, and that it yields gains in classification\naccuracy in brain decoding problems. In particular it outperforms GANs while\nbeing much easier to optimize and interpret. Lastly, Conditional ICA enhances\nclassification accuracy in eight datasets without further parameters tuning.",
    "descriptor": "\nComments: 14 pages, 5 figures, 7 tables\n",
    "authors": [
      "Badr Tajini",
      "Hugo Richard",
      "Bertrand Thirion"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06104"
  },
  {
    "id": "arXiv:2107.06115",
    "title": "A Deep Reinforcement Learning Approach for Traffic Signal Control  Optimization",
    "abstract": "Inefficient traffic signal control methods may cause numerous problems, such\nas traffic congestion and waste of energy. Reinforcement learning (RL) is a\ntrending data-driven approach for adaptive traffic signal control in complex\nurban traffic networks. Although the development of deep neural networks (DNN)\nfurther enhances its learning capability, there are still some challenges in\napplying deep RLs to transportation networks with multiple signalized\nintersections, including non-stationarity environment, exploration-exploitation\ndilemma, multi-agent training schemes, continuous action spaces, etc. In order\nto address these issues, this paper first proposes a multi-agent deep\ndeterministic policy gradient (MADDPG) method by extending the actor-critic\npolicy gradient algorithms. MADDPG has a centralized learning and decentralized\nexecution paradigm in which critics use additional information to streamline\nthe training process, while actors act on their own local observations. The\nmodel is evaluated via simulation on the Simulation of Urban MObility (SUMO)\nplatform. Model comparison results show the efficiency of the proposed\nalgorithm in controlling traffic lights.",
    "descriptor": "",
    "authors": [
      "Zhenning Li",
      "Chengzhong Xu",
      "Guohui Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06115"
  },
  {
    "id": "arXiv:2107.06153",
    "title": "Spontaneous Symmetry Breaking for Extreme Vorticity and Strain in the 3D  Navier-Stokes Equations",
    "abstract": "We investigate the spatio-temporal structure of the most likely\nconfigurations realising extremely high vorticity or strain in the\nstochastically forced 3D incompressible Navier-Stokes equations. Most likely\nconfigurations are computed by numerically finding the highest probability\nvelocity field realising an extreme constraint as solution of a large\noptimisation problem. High-vorticity configurations are identified as pinched\nvortex filaments with swirl, while high-strain configurations correspond to\ncounter-rotating vortex rings. We additionally observe that the most likely\nconfigurations for vorticity and strain spontaneously break their rotational\nsymmetry for extremely high observable values. Instanton calculus and large\ndeviation theory allow us to show that these maximum likelihood realisations\ndetermine the tail probabilities of the observed quantities. In particular, we\nare able to demonstrate that artificially enforcing rotational symmetry for\nlarge strain configurations leads to a severe underestimate of their\nprobability, as it is dominated in likelihood by an exponentially more likely\nsymmetry broken vortex-sheet configuration.",
    "descriptor": "\nComments: 33 pages, 5 figures\n",
    "authors": [
      "Timo Schorlepp",
      "Tobias Grafke",
      "Sandra May",
      "Rainer Grauer"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06153"
  },
  {
    "id": "arXiv:2107.06170",
    "title": "Robust Blind Source Separation by Soft Decision-Directed Non-Unitary  Joint Diagonalization",
    "abstract": "Approximate joint diagonalization of a set of matrices provides a powerful\nframework for numerous statistical signal processing applications. For\nnon-unitary joint diagonalization (NUJD) based on the least-squares (LS)\ncriterion, outliers, also referred to as anomaly or discordant observations,\nhave a negative influence on the performance, since squaring the residuals\nmagnifies the effects of them. To solve this problem, we propose a novel cost\nfunction that incorporates the soft decision-directed scheme into the\nleast-squares algorithm and develops an efficient algorithm. The influence of\nthe outliers is mitigated by applying decision-directed weights which are\nassociated with the residual error at each iterative step. Specifically, the\nmixing matrix is estimated by a modified stationary point method, in which the\nupdating direction is determined based on the linear approximation to the\ngradient function. Simulation results demonstrate that the proposed algorithm\noutperforms conventional non-unitary diagonalization algorithms in terms of\nboth convergence performance and robustness to outliers.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Wenjuan Liu",
      "Dazheng Feng",
      "Bingnan Pei",
      "Mengdao Xing",
      "Xinhong Meng",
      "Qianru Wei"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.06170"
  },
  {
    "id": "arXiv:2107.06173",
    "title": "Orthogonal and Non-Orthogonal Signal Representations Using New  Transformation Matrices Having NPM Structure",
    "abstract": "In this paper, we introduce two types of real-valued sums known as Complex\nConjugate Pair Sums (CCPSs) denoted as CCPS$^{(1)}$ and CCPS$^{(2)}$, and\ndiscuss a few of their properties. Using each type of CCPSs and their circular\nshifts, we construct two non-orthogonal Nested Periodic Matrices (NPMs). As\nNPMs are non-singular, this introduces two non-orthogonal transforms known as\nComplex Conjugate Periodic Transforms (CCPTs) denoted as CCPT$^{(1)}$ and\nCCPT$^{(2)}$. We propose another NPM, which uses both types of CCPSs such that\nits columns are mutually orthogonal, this transform is known as Orthogonal CCPT\n(OCCPT). After a brief study of a few OCCPT properties like periodicity,\ncircular shift, etc., we present two different interpretations of it. Further,\nwe propose a Decimation-In-Time (DIT) based fast computation algorithm for\nOCCPT (termed as FOCCPT), whenever the length of the signal is equal to $2^v,\\\nv{\\in} \\mathbb{N}$. The proposed sums and transforms are inspired by Ramanujan\nsums and Ramanujan Period Transform (RPT). Finally, we show that the period\n(both divisor and non-divisor) and frequency information of a signal can be\nestimated using the proposed transforms with a significant reduction in the\ncomputational complexity over Discrete Fourier Transform (DFT).",
    "descriptor": "\nComments: 13 pages, 5 figures,\n",
    "authors": [
      "Shaik Basheeruddin Shah",
      "Vijay Kumar Chakka",
      "Arikatla Satyanarayana Reddy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06173"
  },
  {
    "id": "arXiv:2107.06174",
    "title": "National-scale electricity peak load forecasting: Traditional, machine  learning, or hybrid model?",
    "abstract": "As the volatility of electricity demand increases owing to climate change and\nelectrification, the importance of accurate peak load forecasting is\nincreasing. Traditional peak load forecasting has been conducted through time\nseries-based models; however, recently, new models based on machine or deep\nlearning are being introduced. This study performs a comparative analysis to\ndetermine the most accurate peak load-forecasting model for Korea, by comparing\nthe performance of time series, machine learning, and hybrid models. Seasonal\nautoregressive integrated moving average with exogenous variables (SARIMAX) is\nused for the time series model. Artificial neural network (ANN), support vector\nregression (SVR), and long short-term memory (LSTM) are used for the machine\nlearning models. SARIMAX-ANN, SARIMAX-SVR, and SARIMAX-LSTM are used for the\nhybrid models. The results indicate that the hybrid models exhibit significant\nimprovement over the SARIMAX model. The LSTM-based models outperformed the\nothers; the single and hybrid LSTM models did not exhibit a significant\nperformance difference. In the case of Korea's highest peak load in 2019, the\npredictive power of the LSTM model proved to be greater than that of the\nSARIMAX-LSTM model. The LSTM, SARIMAX-SVR, and SARIMAX-LSTM models outperformed\nthe current time series-based forecasting model used in Korea. Thus, Korea's\npeak load-forecasting performance can be improved by including machine learning\nor hybrid models.",
    "descriptor": "",
    "authors": [
      "Juyong Lee",
      "Youngsang Cho"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06174"
  },
  {
    "id": "arXiv:2107.06179",
    "title": "A Survey of Applications of Artificial Intelligence for Myocardial  Infarction Disease Diagnosis",
    "abstract": "Myocardial infarction disease (MID) is caused to the rapid progress of\nundiagnosed coronary artery disease (CAD) that indicates the injury of a heart\ncell by decreasing the blood flow to the cardiac muscles. MID is the leading\ncause of death in middle-aged and elderly subjects all over the world. In\ngeneral, raw Electrocardiogram (ECG) signals are tested for MID identification\nby clinicians that is exhausting, time-consuming, and expensive. Artificial\nintelligence-based methods are proposed to handle the problems to diagnose MID\non the ECG signals automatically. Hence, in this survey paper, artificial\nintelligence-based methods, including machine learning and deep learning, are\nreview for MID diagnosis on the ECG signals. Using the methods demonstrate that\nthe feature extraction and selection of ECG signals required to be handcrafted\nin the ML methods. In contrast, these tasks are explored automatically in the\nDL methods. Based on our best knowledge, Deep Convolutional Neural Network\n(DCNN) methods are highly required methods developed for the early diagnosis of\nMID on the ECG signals. Most researchers have tended to use DCNN methods, and\nno studies have surveyed using artificial intelligence methods for MID\ndiagnosis on the ECG signals.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Javad Hassannataj Joloudari",
      "Sanaz Mojrian",
      "Issa Nodehi",
      "Amir Mashmool",
      "Zeynab Kiani Zadegan",
      "Sahar Khanjani Shirkharkolaie",
      "Tahereh Tamadon",
      "Samiyeh Khosravi",
      "Mitra Akbari",
      "Edris Hassannataj",
      "Roohallah Alizadehsani",
      "Danial Sharifrazi",
      "Amir Mosavi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06179"
  },
  {
    "id": "arXiv:2107.06180",
    "title": "Raspberry PI for compact autonomous home farm control",
    "abstract": "This manuscript presented an autonomous home farm for predicting metrological\ncharacteristics that can not only automate the process of growing crops but\nalso, due to a neural network, significantly increase the productivity of the\nfarm. The developed farm monitors and manages the following indicators:\nillumination, soil PH, air temperature, ground temperature, air humidity, CO2\nconcentration, and soil moisture. The presented farm can also be considered as\na device for testing various weather conditions to determine the optimal\ntemperature characteristics for different crops. This farm as a result is\ncompletely autonomous grows tomatoes at home.",
    "descriptor": "",
    "authors": [
      "R. Ildar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06180"
  },
  {
    "id": "arXiv:2107.06181",
    "title": "Intermittent Jamming against Telemetry and Telecommand of Satellite  Systems and A Learning-driven Detection Strategy",
    "abstract": "Towards sixth-generation networks (6G), satellite communication systems,\nespecially based on Low Earth Orbit (LEO) networks, become promising due to\ntheir unique and comprehensive capabilities. These advantages are accompanied\nby a variety of challenges such as security vulnerabilities, management of\nhybrid systems, and high mobility. In this paper, firstly, a security\ndeficiency in the physical layer is addressed with a conceptual framework,\nconsidering the cyber-physical nature of the satellite systems, highlighting\nthe potential attacks. Secondly, a learning-driven detection scheme is\nproposed, and the lightweight convolutional neural network (CNN) is designed.\nThe performance of the designed CNN architecture is compared with a prevalent\nmachine learning algorithm, support vector machine (SVM). The results show that\ndeficiency attacks against the satellite systems can be detected by employing\nthe proposed scheme.",
    "descriptor": "",
    "authors": [
      "Selen Gecgel",
      "Gunes Karabulut Kurt"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06181"
  },
  {
    "id": "arXiv:2107.06183",
    "title": "A Self-Regulated and Reconfigurable CMOS Physically Unclonable Function  Featuring Zero-Overhead Stabilization",
    "abstract": "This article presents a reconfigurable physically unclonable function (PUF)\ndesign fabricated using 65-nm CMOS technology. A subthreshold-inverter-based\nstatic PUF cell achieves 0.3% native bit error rate (BER) at 0.062-fJ per bit\ncore energy efficiency. A flexible, native transistor-based voltage regulation\nscheme achieves low-overhead supply regulation with 6-mV/V line sensitivity,\nmaking the PUF resistant against voltage variations. Additionally, the PUF cell\nis designed to be reconfigurable with no area overhead, which enables\nstabilization without redundancy on chip. Thanks to the highly stable and\nself-regulated PUF cell and the zero-overhead stabilization scheme, a 0.00182%\nnative BER is obtained after reconfiguration. The proposed design shows\n0.12%/10 {\\deg}C and 0.057%/0.1-V bit error across the military-grade\ntemperature range from -55 {\\deg}C to 125 {\\deg}C and supply voltage variation\nfrom 0.7 to 1.4 V. The total energy per bit is 15.3 fJ. Furthermore, the\nunstable bits can be detected by sweeping the body bias instead of temperature\nduring enrollment, thereby significantly reducing the testing costs. Last but\nnot least, the prototype exhibits almost ideal uniqueness and randomness, with\na mean inter-die Hamming distance (HD) of 0.4998 and a 1020x inter-/intra-die\nHD separation. It also passes both NIST 800-22 and 800-90B randomness tests.",
    "descriptor": "\nComments: This work has been accepted by 2020 IEEE Journal of Solid-State Circuits (JSSC)\n",
    "authors": [
      "Dai Li",
      "Kaiyuan Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06183"
  },
  {
    "id": "arXiv:2107.06184",
    "title": "AI Algorithm for Mode Classification of PCF SPR Sensor Design",
    "abstract": "Photonic Crystal Fiber design based on surface plasmon resonance phenomenon\n(PCF SPR) is optimized before it is fabricated for a particular application. An\nartificial intelligence algorithm is evaluated here to increase the ease of the\nsimulation process for common users. COMSOL MultiPhysics is used. The algorithm\nsuggests best among eight standard machine learning and one deep learning model\nto automatically select the desired mode, chosen visually by the experts\notherwise. Total seven performance indices: namely Precision, Recall, Accuracy,\nF1-Score, Specificity, Matthew correlation coefficient, are utilized to make\nthe optimal decision. Robustness towards variations in sensor geometry design\nis also considered as an optimal parameter. Several PCF-SPR based Photonic\nsensor designs are tested, and a large range optimal (based on phase matching)\ndesign is proposed. For this design algorithm has selected Support Vector\nMachine (SVM) as the best option with an accuracy of 96%, F1-Score is 95.83%,\nand MCC of 92.30%. The average sensitivity of the proposed sensor design with\nrespect to change in refractive index (1.37-1.41) is 5500 nm/RIU. Resolution is\n2.0498x10^(-5) RIU^(-1). The algorithm can be integrated into commercial\nsoftware as an add-on or as a module in academic codes. The proposed novel step\nhas saved approximately 75 minutes in the overall design process. The present\nwork is equally applicable for mode selection of sensor other than PCF-SPR\nsensing geometries.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Prasunika Khare",
      "Mayank Goswami"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.06184"
  },
  {
    "id": "arXiv:2107.06211",
    "title": "Attention-Guided Progressive Neural Texture Fusion for High Dynamic  Range Image Restoration",
    "abstract": "High Dynamic Range (HDR) imaging via multi-exposure fusion is an important\ntask for most modern imaging platforms. In spite of recent developments in both\nhardware and algorithm innovations, challenges remain over content association\nambiguities caused by saturation, motion, and various artifacts introduced\nduring multi-exposure fusion such as ghosting, noise, and blur. In this work,\nwe propose an Attention-guided Progressive Neural Texture Fusion (APNT-Fusion)\nHDR restoration model which aims to address these issues within one framework.\nAn efficient two-stream structure is proposed which separately focuses on\ntexture feature transfer over saturated regions and multi-exposure tonal and\ntexture feature fusion. A neural feature transfer mechanism is proposed which\nestablishes spatial correspondence between different exposures based on\nmulti-scale VGG features in the masked saturated HDR domain for discriminative\ncontextual clues over the ambiguous image areas. A progressive texture blending\nmodule is designed to blend the encoded two-stream features in a multi-scale\nand progressive manner. In addition, we introduce several novel attention\nmechanisms, i.e., the motion attention module detects and suppresses the\ncontent discrepancies among the reference images; the saturation attention\nmodule facilitates differentiating the misalignment caused by saturation from\nthose caused by motion; and the scale attention module ensures texture blending\nconsistency between different coder/decoder scales. We carry out comprehensive\nqualitative and quantitative evaluations and ablation studies, which validate\nthat these novel modules work coherently under the same framework and\noutperform state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Zaifeng Yang",
      "Tsz Nam Chan",
      "Hui Li",
      "Junhui Hou",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06211"
  },
  {
    "id": "arXiv:2107.06213",
    "title": "Modeling the Impact of Social Distancing and Targeted Vaccination on the  Spread of COVID-19 through a Real City-Scale Contact Network",
    "abstract": "We use mobile device data to construct empirical interpersonal physical\ncontact networks in the city of Portland, Oregon, both before and after social\ndistancing measures were enacted during the COVID-19 pandemic. These networks\nreveal how social distancing measures and the public's reaction to the\nincipient pandemic affected the connectivity patterns within the city. We find\nthat as the pandemic developed there was a substantial decrease in the number\nof individuals with many contacts. We further study the impact of these\ndifferent network topologies on the spread of COVID-19 by simulating an SEIR\nepidemic model over these networks, and find that the reduced connectivity\ngreatly suppressed the epidemic. We then investigate how the epidemic responds\nwhen part of the population is vaccinated, and we compare two vaccination\ndistribution strategies, both with and without social distancing. Our main\nresult is that the heavy-tailed degree distribution of the contact networks\ncauses a targeted vaccination strategy that prioritizes high-contact\nindividuals to reduce the number of cases far more effectively than a strategy\nthat vaccinates individuals at random. Combining both targeted vaccination and\nsocial distancing leads to the greatest reduction in cases, and we also find\nthat the marginal benefit of a targeted strategy as compared to a random\nstrategy exceeds the marginal benefit of social distancing for reducing the\nnumber of cases. These results have important implications for ongoing vaccine\ndistribution efforts worldwide.",
    "descriptor": "\nComments: 15 pages, 9 figures. This article is a RAND Working Report\n",
    "authors": [
      "Gavin S. Hartnett",
      "Edward Parker",
      "Timothy R. Gulden",
      "Raffaele Vardavas",
      "David Kravitz"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2107.06213"
  },
  {
    "id": "arXiv:2107.06264",
    "title": "Parameterization of Forced Isotropic Turbulent Flow using Autoencoders  and Generative Adversarial Networks",
    "abstract": "Autoencoders and generative neural network models have recently gained\npopularity in fluid mechanics due to their spontaneity and low processing time\ninstead of high fidelity CFD simulations. Auto encoders are used as model order\nreduction tools in applications of fluid mechanics by compressing input\nhigh-dimensional data using an encoder to map the input space into a\nlower-dimensional latent space. Whereas, generative models such as Variational\nAuto-encoders (VAEs) and Generative Adversarial Networks (GANs) are proving to\nbe effective in generating solutions to chaotic models with high 'randomness'\nsuch as turbulent flows. In this study, forced isotropic turbulence flow is\ngenerated by parameterizing into some basic statistical characteristics. The\nmodels trained on pre-simulated data from dependencies on these characteristics\nand the flow generation is then affected by varying these parameters. The\nlatent vectors pushed along the generator models like the decoders and\ngenerators contain independent entries which can be used to create different\noutputs with similar properties. The use of neural network-based architecture\nremoves the need for dependency on the classical mesh-based Navier-Stoke\nequation estimation which is prominent in many CFD softwares.",
    "descriptor": "",
    "authors": [
      "Kanishk",
      "Tanishk Nandal",
      "Prince Tyagi",
      "Raj Kumar Singh"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06264"
  },
  {
    "id": "arXiv:2107.06276",
    "title": "Attention based CNN-LSTM Network for Pulmonary Embolism Prediction on  Chest Computed Tomography Pulmonary Angiograms",
    "abstract": "With more than 60,000 deaths annually in the United States, Pulmonary\nEmbolism (PE) is among the most fatal cardiovascular diseases. It is caused by\nan artery blockage in the lung; confirming its presence is time-consuming and\nis prone to over-diagnosis. The utilization of automated PE detection systems\nis critical for diagnostic accuracy and efficiency. In this study we propose a\ntwo-stage attention-based CNN-LSTM network for predicting PE, its associated\ntype (chronic, acute) and corresponding location (leftsided, rightsided or\ncentral) on computed tomography (CT) examinations. We trained our model on the\nlargest available public Computed Tomography Pulmonary Angiogram PE dataset\n(RSNA-STR Pulmonary Embolism CT (RSPECT) Dataset, N=7279 CT studies) and tested\nit on an in-house curated dataset of N=106 studies. Our framework mirrors the\nradiologic diagnostic process via a multi-slice approach so that the accuracy\nand pathologic sequela of true pulmonary emboli may be meticulously assessed,\nenabling physicians to better appraise the morbidity of a PE when present. Our\nproposed method outperformed a baseline CNN classifier and a single-stage\nCNN-LSTM network, achieving an AUC of 0.95 on the test set for detecting the\npresence of PE in the study.",
    "descriptor": "\nComments: This work will be presented at MICCAI 2021\n",
    "authors": [
      "Sudhir Suman",
      "Gagandeep Singh",
      "Nicole Sakla",
      "Rishabh Gattu",
      "Jeremy Green",
      "Tej Phatak",
      "Dimitris Samaras",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06276"
  },
  {
    "id": "arXiv:1809.02718",
    "title": "Cost Sharing in Two-Sided Markets",
    "abstract": "Cost Sharing in Two-Sided Markets",
    "descriptor": "",
    "authors": [
      "Sreenivas Gollapudi",
      "Kostas Kollias",
      "Ali Shameli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1809.02718"
  },
  {
    "id": "arXiv:1904.08962",
    "title": "Constrained Restless Bandits for Dynamic Scheduling in Cyber-Physical  Systems",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Kesav Kaza",
      "Rahul Meshram",
      "Varun Mehta",
      "S.N.Merchant"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1904.08962"
  },
  {
    "id": "arXiv:1907.08355",
    "title": "Data Structures Meet Cryptography: 3SUM with Preprocessing",
    "abstract": "Data Structures Meet Cryptography: 3SUM with Preprocessing",
    "descriptor": "",
    "authors": [
      "Alexander Golovnev",
      "Siyao Guo",
      "Thibaut Horel",
      "Sunoo Park",
      "Vinod Vaikuntanathan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1907.08355"
  },
  {
    "id": "arXiv:1911.00773",
    "title": "Design and Challenges of Cloze-Style Reading Comprehension Tasks on  Multiparty Dialogue",
    "abstract": "Design and Challenges of Cloze-Style Reading Comprehension Tasks on  Multiparty Dialogue",
    "descriptor": "",
    "authors": [
      "Changmao Li",
      "Tianhao Liu",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.00773"
  },
  {
    "id": "arXiv:1911.07936",
    "title": "Privacy Preserving Gaze Estimation using Synthetic Images via a  Randomized Encoding Based Framework",
    "abstract": "Comments: In Symposium on Eye Tracking Research and Applications (ETRA '20). Authors' copy of the published paper, refer to the doi for the definitive version",
    "descriptor": "\nComments: In Symposium on Eye Tracking Research and Applications (ETRA '20). Authors' copy of the published paper, refer to the doi for the definitive version\n",
    "authors": [
      "Efe Bozkir",
      "Ali Burak \u00dcnal",
      "Mete Akg\u00fcn",
      "Enkelejda Kasneci",
      "Nico Pfeifer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.07936"
  },
  {
    "id": "arXiv:1911.10833",
    "title": "Near-Optimal Algorithm for Distribution-Free Junta Testing",
    "abstract": "Near-Optimal Algorithm for Distribution-Free Junta Testing",
    "descriptor": "",
    "authors": [
      "Xiaojin Zhang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1911.10833"
  },
  {
    "id": "arXiv:1911.12763",
    "title": "Dividing and Conquering Cross-Modal Recipe Retrieval: from Nearest  Neighbours Baselines to SoTA",
    "abstract": "Dividing and Conquering Cross-Modal Recipe Retrieval: from Nearest  Neighbours Baselines to SoTA",
    "descriptor": "",
    "authors": [
      "Mikhail Fain",
      "Niall Twomey",
      "Andrey Ponikar",
      "Ryan Fox",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.12763"
  },
  {
    "id": "arXiv:1912.11546",
    "title": "Fast Generation of RSA Keys using Smooth Integers",
    "abstract": "Comments: This paper contains 11 pages and 8 tables, in IEEE Transactions on Computers",
    "descriptor": "\nComments: This paper contains 11 pages and 8 tables, in IEEE Transactions on Computers\n",
    "authors": [
      "Vassil Dimitrov",
      "Luigi Vigneri",
      "Vidal Attias"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1912.11546"
  },
  {
    "id": "arXiv:2001.01088",
    "title": "Restricted Rules of Inference and Paraconsistency",
    "abstract": "Comments: The final version of this paper has been published online in Logic Journal of the IGPL (this https URL). Minor typos fixed; Theorem 3.7 has been changed to Remark 3.7; other minor rearrangements of the material done; further justification added in Remark 4.28 (now Remark 4.27)",
    "descriptor": "\nComments: The final version of this paper has been published online in Logic Journal of the IGPL (this https URL). Minor typos fixed; Theorem 3.7 has been changed to Remark 3.7; other minor rearrangements of the material done; further justification added in Remark 4.28 (now Remark 4.27)\n",
    "authors": [
      "Sankha S. Basu",
      "Mihir K. Chakraborty"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2001.01088"
  },
  {
    "id": "arXiv:2002.01129",
    "title": "Bayesian Meta-Prior Learning Using Empirical Bayes",
    "abstract": "Comments: Expanded discussions on applications and extended literature review section. Forthcoming in the Management Science Journal",
    "descriptor": "\nComments: Expanded discussions on applications and extended literature review section. Forthcoming in the Management Science Journal\n",
    "authors": [
      "Sareh Nabi",
      "Houssam Nassif",
      "Joseph Hong",
      "Hamed Mamani",
      "Guido Imbens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.01129"
  },
  {
    "id": "arXiv:2002.10516",
    "title": "Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows",
    "abstract": "Comments: Accepted to NeurIPS 2020",
    "descriptor": "\nComments: Accepted to NeurIPS 2020\n",
    "authors": [
      "Ruizhi Deng",
      "Bo Chang",
      "Marcus A. Brubaker",
      "Greg Mori",
      "Andreas Lehrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.10516"
  },
  {
    "id": "arXiv:2002.11775",
    "title": "SACBP: Belief Space Planning for Continuous-Time Dynamical Systems via  Stochastic Sequential Action Control",
    "abstract": "Comments: accepted in Internatinoal Journal of Robotics Research (IJRR)",
    "descriptor": "\nComments: accepted in Internatinoal Journal of Robotics Research (IJRR)\n",
    "authors": [
      "Haruki Nishimura",
      "Mac Schwager"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.11775"
  },
  {
    "id": "arXiv:2003.02718",
    "title": "Towards a Better Understanding of (Partial Weighted) MaxSAT Proof  Systems",
    "abstract": "Towards a Better Understanding of (Partial Weighted) MaxSAT Proof  Systems",
    "descriptor": "",
    "authors": [
      "Javier Larrosa",
      "Emma Rollon"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2003.02718"
  },
  {
    "id": "arXiv:2003.08579",
    "title": "Adaptive Batching for Gaussian Process Surrogates with Application in  Noisy Level Set Estimation",
    "abstract": "Comments: 36 pages, 6 figures",
    "descriptor": "\nComments: 36 pages, 6 figures\n",
    "authors": [
      "Xiong Lyu",
      "Mike Ludkovski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.08579"
  },
  {
    "id": "arXiv:2004.12006",
    "title": "Contextualized Representations Using Textual Encyclopedic Knowledge",
    "abstract": "Comments: Added experiments comparing linkers",
    "descriptor": "\nComments: Added experiments comparing linkers\n",
    "authors": [
      "Mandar Joshi",
      "Kenton Lee",
      "Yi Luan",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.12006"
  },
  {
    "id": "arXiv:2005.09253",
    "title": "Safe Learning for Near Optimal Scheduling",
    "abstract": "Safe Learning for Near Optimal Scheduling",
    "descriptor": "",
    "authors": [
      "Damien Busatto-Gaston",
      "Debraj Chakraborty",
      "Shibashis Guha",
      "Guillermo A. P\u00e9rez",
      "Jean-Fran\u00e7ois Raskin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.09253"
  },
  {
    "id": "arXiv:2005.13390",
    "title": "Analysis of a Helmholtz preconditioning problem motivated by uncertainty  quantification",
    "abstract": "Analysis of a Helmholtz preconditioning problem motivated by uncertainty  quantification",
    "descriptor": "",
    "authors": [
      "Ivan G. Graham",
      "Owen R. Pembery",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.13390"
  },
  {
    "id": "arXiv:2006.05585",
    "title": "A simple virtual element-based flux recovery on quadtree",
    "abstract": "A simple virtual element-based flux recovery on quadtree",
    "descriptor": "",
    "authors": [
      "Shuhao Cao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.05585"
  },
  {
    "id": "arXiv:2006.12021",
    "title": "Sampling hypergraphs with given degrees",
    "abstract": "Comments: 21 pages. This version addresses referees' comments",
    "descriptor": "\nComments: 21 pages. This version addresses referees' comments\n",
    "authors": [
      "Martin Dyer",
      "Catherine Greenhill",
      "Pieter Kleer",
      "James Ross",
      "Leen Stougie"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.12021"
  },
  {
    "id": "arXiv:2007.06631",
    "title": "T-Basis: a Compact Representation for Neural Networks",
    "abstract": "Comments: Accepted at ICML 2020",
    "descriptor": "\nComments: Accepted at ICML 2020\n",
    "authors": [
      "Anton Obukhov",
      "Maxim Rakhuba",
      "Stamatios Georgoulis",
      "Menelaos Kanakis",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06631"
  },
  {
    "id": "arXiv:2007.11117",
    "title": "Interpretable Anomaly Detection with DIFFI: Depth-based Isolation Forest  Feature Importance",
    "abstract": "Comments: Added pseudocode and overview diagram",
    "descriptor": "\nComments: Added pseudocode and overview diagram\n",
    "authors": [
      "Mattia Carletti",
      "Matteo Terzi",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.11117"
  },
  {
    "id": "arXiv:2007.15981",
    "title": "Compression and Symmetry of Small-World Graphs and Structures",
    "abstract": "Comments: 20 pages, 1 figure",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Ioannis Kontoyiannis",
      "Yi Heng Lim",
      "Katia Papakonstantinopoulou",
      "Wojtek Szpankowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2007.15981"
  },
  {
    "id": "arXiv:2008.01724",
    "title": "Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy  Blind Deconvolution under Random Designs",
    "abstract": "Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy  Blind Deconvolution under Random Designs",
    "descriptor": "",
    "authors": [
      "Yuxin Chen",
      "Jianqing Fan",
      "Bingyan Wang",
      "Yuling Yan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2008.01724"
  },
  {
    "id": "arXiv:2008.02627",
    "title": "Notes on the Behavior of MC Dropout",
    "abstract": "Comments: Presented at the ICML 2021 Workshop on \"Uncertainty and Robustness in Deep Learning\"",
    "descriptor": "\nComments: Presented at the ICML 2021 Workshop on \"Uncertainty and Robustness in Deep Learning\"\n",
    "authors": [
      "Francesco Verdoja",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.02627"
  },
  {
    "id": "arXiv:2008.08032",
    "title": "Sampling Multiple Edges Efficiently",
    "abstract": "Sampling Multiple Edges Efficiently",
    "descriptor": "",
    "authors": [
      "Talya Eden",
      "Saleet Mossel",
      "Ronitt Rubinfeld"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.08032"
  },
  {
    "id": "arXiv:2008.10895",
    "title": "Decentralized Asset Custody Scheme with Security against Rational  Adversary",
    "abstract": "Comments: 40 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 40 pages, 5 figures, 7 tables\n",
    "authors": [
      "Zhaohua Chen",
      "Guang Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.10895"
  },
  {
    "id": "arXiv:2008.13751",
    "title": "Plug-and-Play Image Restoration with Deep Denoiser Prior",
    "abstract": "Comments: An extended version of IRCNN (CVPR17). Project page: this https URL",
    "descriptor": "\nComments: An extended version of IRCNN (CVPR17). Project page: this https URL\n",
    "authors": [
      "Kai Zhang",
      "Yawei Li",
      "Wangmeng Zuo",
      "Lei Zhang",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.13751"
  },
  {
    "id": "arXiv:2009.03126",
    "title": "Finite element approximation of a phase field model for tumour growth",
    "abstract": "Finite element approximation of a phase field model for tumour growth",
    "descriptor": "",
    "authors": [
      "Joe Eyles",
      "Robert N\u00fcrnberg",
      "Vanessa Styles"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.03126"
  },
  {
    "id": "arXiv:2009.03871",
    "title": "Intraoperative Liver Surface Completion with Graph Convolutional VAE",
    "abstract": "Intraoperative Liver Surface Completion with Graph Convolutional VAE",
    "descriptor": "",
    "authors": [
      "Simone Foti",
      "Bongjin Koo",
      "Thomas Dowrick",
      "Joao Ramalhinho",
      "Moustafa Allam",
      "Brian Davidson",
      "Danail Stoyanov",
      "Matthew J. Clarkson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.03871"
  },
  {
    "id": "arXiv:2009.06117",
    "title": "The Platform Design Problem",
    "abstract": "Comments: updated with more results",
    "descriptor": "\nComments: updated with more results\n",
    "authors": [
      "Christos Papadimitriou",
      "Kiran Vodrahalli",
      "Mihalis Yannakakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2009.06117"
  },
  {
    "id": "arXiv:2009.06193",
    "title": "RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning",
    "abstract": "RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning",
    "descriptor": "",
    "authors": [
      "Hao Tan",
      "Ran Cheng",
      "Shihua Huang",
      "Cheng He",
      "Changxiao Qiu",
      "Fan Yang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.06193"
  },
  {
    "id": "arXiv:2009.08012",
    "title": "Deep Momentum Uncertainty Hashing",
    "abstract": "Deep Momentum Uncertainty Hashing",
    "descriptor": "",
    "authors": [
      "Chaoyou Fu",
      "Guoli Wang",
      "Xiang Wu",
      "Qian Zhang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.08012"
  },
  {
    "id": "arXiv:2010.00635",
    "title": "StreamSoNG: A Soft Streaming Classification Approach",
    "abstract": "StreamSoNG: A Soft Streaming Classification Approach",
    "descriptor": "",
    "authors": [
      "Wenlong Wu",
      "James M. Keller",
      "Jeffrey Dale",
      "James C. Bezdek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.00635"
  },
  {
    "id": "arXiv:2010.01919",
    "title": "Automatic Label Correction for the Accurate Edge Detection of  Overlapping Cervical Cells",
    "abstract": "Comments: code and dataset: this https URL",
    "descriptor": "\nComments: code and dataset: this https URL\n",
    "authors": [
      "Jiawei Liu",
      "Qiang Wang",
      "Huijie Fan",
      "Shuai Wang",
      "Wentao Li",
      "Yandong Tang",
      "Danbo Wang",
      "Mingyi Zhou",
      "Li Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.01919"
  },
  {
    "id": "arXiv:2010.02607",
    "title": "Structural properties of the first-order transduction quasiorder",
    "abstract": "Structural properties of the first-order transduction quasiorder",
    "descriptor": "",
    "authors": [
      "Jaroslav Nesetril",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.02607"
  },
  {
    "id": "arXiv:2010.04891",
    "title": "Online Optimal Control with Affine Constraints",
    "abstract": "Comments: Accepted by AAAI 2021",
    "descriptor": "\nComments: Accepted by AAAI 2021\n",
    "authors": [
      "Yingying Li",
      "Subhro Das",
      "Na Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.04891"
  },
  {
    "id": "arXiv:2010.06509",
    "title": "Approximation of Integral Fractional Laplacian and Fractional PDEs via  sinc-Basis",
    "abstract": "Approximation of Integral Fractional Laplacian and Fractional PDEs via  sinc-Basis",
    "descriptor": "",
    "authors": [
      "Harbir Antil",
      "Patrick Dondl",
      "Ludwig Striet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.06509"
  },
  {
    "id": "arXiv:2010.09350",
    "title": "The efficacy of Neural Planning Metrics: A meta-analysis of PKL on  nuScenes",
    "abstract": "Comments: IROS 2020 Workshop on Benchmarking Progress in Autonomous Driving",
    "descriptor": "\nComments: IROS 2020 Workshop on Benchmarking Progress in Autonomous Driving\n",
    "authors": [
      "Yiluan Guo",
      "Holger Caesar",
      "Oscar Beijbom",
      "Jonah Philion",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.09350"
  },
  {
    "id": "arXiv:2010.12970",
    "title": "Deep Denoising For Scientific Discovery: A Case Study In Electron  Microscopy",
    "abstract": "Comments: The dataset and the code used to train and evaluate and our models are available at this https URL",
    "descriptor": "\nComments: The dataset and the code used to train and evaluate and our models are available at this https URL\n",
    "authors": [
      "Sreyas Mohan",
      "Ramon Manzorro",
      "Joshua L. Vincent",
      "Binh Tang",
      "Dev Yashpal Sheth",
      "Eero P. Simoncelli",
      "David S. Matteson",
      "Peter A. Crozier",
      "Carlos Fernandez-Granda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.12970"
  },
  {
    "id": "arXiv:2010.13988",
    "title": "Toward Better Generalization Bounds with Locally Elastic Stability",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Zhun Deng",
      "Hangfeng He",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2010.13988"
  },
  {
    "id": "arXiv:2010.16011",
    "title": "POMO: Policy Optimization with Multiple Optima for Reinforcement  Learning",
    "abstract": "Comments: Accepted at NeurIPS 2020",
    "descriptor": "\nComments: Accepted at NeurIPS 2020\n",
    "authors": [
      "Yeong-Dae Kwon",
      "Jinho Choo",
      "Byoungjip Kim",
      "Iljoo Yoon",
      "Youngjune Gwon",
      "Seungjai Min"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16011"
  },
  {
    "id": "arXiv:2011.10772",
    "title": "One Metric to Measure them All: Localisation Recall Precision (LRP) for  Evaluating Visual Detection Tasks",
    "abstract": "Comments: Under review at TPAMI; revised version",
    "descriptor": "\nComments: Under review at TPAMI; revised version\n",
    "authors": [
      "Kemal Oksuz",
      "Baris Can Cam",
      "Sinan Kalkan",
      "Emre Akbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.10772"
  },
  {
    "id": "arXiv:2011.11129",
    "title": "Making mean-estimation more efficient using an MCMC trace variance  approach: DynaMITE",
    "abstract": "Making mean-estimation more efficient using an MCMC trace variance  approach: DynaMITE",
    "descriptor": "",
    "authors": [
      "Cyrus Cousins",
      "Shahrzad Haddadan",
      "Eli Upfal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.11129"
  },
  {
    "id": "arXiv:2011.11567",
    "title": "A Closed-Form Solution to Local Non-Rigid Structure-from-Motion",
    "abstract": "A Closed-Form Solution to Local Non-Rigid Structure-from-Motion",
    "descriptor": "",
    "authors": [
      "Shaifali Parashar",
      "Yuxuan Long",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11567"
  },
  {
    "id": "arXiv:2012.00759",
    "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Huiyu Wang",
      "Yukun Zhu",
      "Hartwig Adam",
      "Alan Yuille",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.00759"
  },
  {
    "id": "arXiv:2012.06154",
    "title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian",
    "abstract": "Comments: To appear on Transactions of the Association for Computational Linguistics (TACL), 2021",
    "descriptor": "\nComments: To appear on Transactions of the Association for Computational Linguistics (TACL), 2021\n",
    "authors": [
      "Daniel Khashabi",
      "Arman Cohan",
      "Siamak Shakeri",
      "Pedram Hosseini",
      "Pouya Pezeshkpour",
      "Malihe Alikhani",
      "Moin Aminnaseri",
      "Marzieh Bitaab",
      "Faeze Brahman",
      "Sarik Ghazarian",
      "Mozhdeh Gheini",
      "Arman Kabiri",
      "Rabeeh Karimi Mahabadi",
      "Omid Memarrast",
      "Ahmadreza Mosallanezhad",
      "Erfan Noury",
      "Shahab Raji",
      "Mohammad Sadegh Rasooli",
      "Sepideh Sadeghi",
      "Erfan Sadeqi Azer",
      "Niloofar Safi Samghabadi",
      "Mahsa Shafaei",
      "Saber Sheybani",
      "Ali Tazarv",
      "Yadollah Yaghoobzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.06154"
  },
  {
    "id": "arXiv:2012.09423",
    "title": "Advanced NOMA Assisted Semi-Grant-Free Transmission Schemes for Randomly  Distributed Users",
    "abstract": "Comments: 41 pages, 8 figures",
    "descriptor": "\nComments: 41 pages, 8 figures\n",
    "authors": [
      "Huabing Lu",
      "Xianzhong Xie",
      "Zhaoyuan Shi",
      "Hongjiang Lei",
      "Helin Yang",
      "Jun Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.09423"
  },
  {
    "id": "arXiv:2012.11270",
    "title": "Family Ties: Relating Poncelet 3-Periodics by their Properties",
    "abstract": "Comments: 20 pages, 10 figures, 4 tables, 18 video links",
    "descriptor": "\nComments: 20 pages, 10 figures, 4 tables, 18 video links\n",
    "authors": [
      "Ronaldo Garcia",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.11270"
  },
  {
    "id": "arXiv:2012.11619",
    "title": "Defence against adversarial attacks using classical and quantum-enhanced  Boltzmann machines",
    "abstract": "Comments: 15 pages, 1 figure. V2: Updated to match published version",
    "descriptor": "\nComments: 15 pages, 1 figure. V2: Updated to match published version\n",
    "authors": [
      "Aidan Kehoe",
      "Peter Wittek",
      "Yanbo Xue",
      "Alejandro Pozas-Kerstjens"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11619"
  },
  {
    "id": "arXiv:2101.00387",
    "title": "What all do audio transformer models hear? Probing Acoustic  Representations for Language Delivery and its Structure",
    "abstract": "What all do audio transformer models hear? Probing Acoustic  Representations for Language Delivery and its Structure",
    "descriptor": "",
    "authors": [
      "Jui Shah",
      "Yaman Kumar Singla",
      "Changyou Chen",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2101.00387"
  },
  {
    "id": "arXiv:2101.11046",
    "title": "Generalized Doubly Reparameterized Gradient Estimators",
    "abstract": "Generalized Doubly Reparameterized Gradient Estimators",
    "descriptor": "",
    "authors": [
      "Matthias Bauer",
      "Andriy Mnih"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11046"
  },
  {
    "id": "arXiv:2101.11431",
    "title": "SkillNER: Mining and Mapping Soft Skills from any Text",
    "abstract": "SkillNER: Mining and Mapping Soft Skills from any Text",
    "descriptor": "",
    "authors": [
      "Silvia Fareri",
      "Nicola Melluso",
      "Filippo Chiarello",
      "Gualtiero Fantoni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.11431"
  },
  {
    "id": "arXiv:2102.00504",
    "title": "Exact Recovery of Clusters in Finite Metric Spaces Using Oracle Queries",
    "abstract": "Comments: Accepted for presentation at the Conference on Learning Theory (COLT) 2021",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2021\n",
    "authors": [
      "Marco Bressan",
      "Nicol\u00f2 Cesa-Bianchi",
      "Silvio Lattanzi",
      "Andrea Paudice"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00504"
  },
  {
    "id": "arXiv:2102.03594",
    "title": "Online nonparametric regression with Sobolev kernels",
    "abstract": "Comments: 40 pages, 5 figures, 3 tables (version 2)",
    "descriptor": "\nComments: 40 pages, 5 figures, 3 tables (version 2)\n",
    "authors": [
      "Oleksandr Zadorozhnyi",
      "Pierre Gaillard",
      "Sebastien Gerschinovitz",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03594"
  },
  {
    "id": "arXiv:2102.04211",
    "title": "Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion",
    "abstract": "Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion",
    "descriptor": "",
    "authors": [
      "Dimitri Ognibene",
      "Davide Taibi",
      "Udo Kruschwitz",
      "Rodrigo Souza Wilkens",
      "Davinia Hernandez-Leo",
      "Emily Theophilou",
      "Lidia Scifo",
      "Rene Alejandro Lobo",
      "Francesco Lomonaco",
      "Sabrina Eimler",
      "H. Ulrich Hoppe",
      "Nils Malzahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.04211"
  },
  {
    "id": "arXiv:2102.05336",
    "title": "Understanding Instance-Level Label Noise: Disparate Impacts and  Treatments",
    "abstract": "Comments: Accepted to ICML 2021 as a long talk paper",
    "descriptor": "\nComments: Accepted to ICML 2021 as a long talk paper\n",
    "authors": [
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05336"
  },
  {
    "id": "arXiv:2102.05347",
    "title": "From Sampling to Optimization on Discrete Domains withApplications to  Determinant Maximization",
    "abstract": "Comments: Replacement, with significant new results",
    "descriptor": "\nComments: Replacement, with significant new results\n",
    "authors": [
      "Nima Anari",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05347"
  },
  {
    "id": "arXiv:2102.06798",
    "title": "Which Regular Languages can be Efficiently Indexed?",
    "abstract": "Comments: Extended version",
    "descriptor": "\nComments: Extended version\n",
    "authors": [
      "Nicola Cotumaccio",
      "Giovanna D'Agostino",
      "Alberto Policriti",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.06798"
  },
  {
    "id": "arXiv:2102.06880",
    "title": "Twin-width and permutations",
    "abstract": "Twin-width and permutations",
    "descriptor": "",
    "authors": [
      "\u00c9douard Bonnet",
      "Jaroslav Ne\u0161et\u0159il",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.06880"
  },
  {
    "id": "arXiv:2102.07868",
    "title": "GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning",
    "abstract": "GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning",
    "descriptor": "",
    "authors": [
      "Idan Achituve",
      "Aviv Navon",
      "Yochai Yemini",
      "Gal Chechik",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07868"
  },
  {
    "id": "arXiv:2102.08304",
    "title": "Speeding Up Private Distributed Matrix Multiplication via Bivariate  Polynomial Codes",
    "abstract": "Comments: To appear in IEEE International Symposium on Information Theory (ISIT) 2021",
    "descriptor": "\nComments: To appear in IEEE International Symposium on Information Theory (ISIT) 2021\n",
    "authors": [
      "Burak Hasircioglu",
      "Jesus Gomez-Vilardebo",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.08304"
  },
  {
    "id": "arXiv:2102.08655",
    "title": "Decoding EEG Brain Activity for Multi-Modal Natural Language Processing",
    "abstract": "Decoding EEG Brain Activity for Multi-Modal Natural Language Processing",
    "descriptor": "",
    "authors": [
      "Nora Hollenstein",
      "Cedric Renggli",
      "Benjamin Glaus",
      "Maria Barrett",
      "Marius Troendle",
      "Nicolas Langer",
      "Ce Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.08655"
  },
  {
    "id": "arXiv:2102.09351",
    "title": "A Comprehensive Review of Deep Learning-based Single Image  Super-resolution",
    "abstract": "Comments: 56 Pages, 11 Figures, 5 Tables",
    "descriptor": "\nComments: 56 Pages, 11 Figures, 5 Tables\n",
    "authors": [
      "Syed Muhammad Arsalan Bashir",
      "Yi Wang",
      "Mahrukh Khan",
      "Yilong Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.09351"
  },
  {
    "id": "arXiv:2102.09810",
    "title": "Design Patterns for Blockchain-Based Payment Applications",
    "abstract": "Comments: Accepted by EuroPloP 2021",
    "descriptor": "\nComments: Accepted by EuroPloP 2021\n",
    "authors": [
      "Qinghua Lu",
      "Xiwei Xu",
      "H.M.N. Dilum Bandara",
      "Shiping Chen",
      "Liming Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09810"
  },
  {
    "id": "arXiv:2102.09882",
    "title": "Characterising Alzheimer's Disease with EEG-based Energy Landscape  Analysis",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Dominik Klepl",
      "Fei He",
      "Min Wu",
      "Matteo De Marco",
      "Daniel J. Blackburn",
      "Ptolemaios Sarrigiannis"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09882"
  },
  {
    "id": "arXiv:2102.09907",
    "title": "Instrumental Variable Value Iteration for Causal Offline Reinforcement  Learning",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Luofeng Liao",
      "Zuyue Fu",
      "Zhuoran Yang",
      "Yixin Wang",
      "Mladen Kolar",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09907"
  },
  {
    "id": "arXiv:2102.10264",
    "title": "On Proximal Policy Optimization's Heavy-tailed Gradients",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Saurabh Garg",
      "Joshua Zhanson",
      "Emilio Parisotto",
      "Adarsh Prasad",
      "J. Zico Kolter",
      "Zachary C. Lipton",
      "Sivaraman Balakrishnan",
      "Ruslan Salakhutdinov",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10264"
  },
  {
    "id": "arXiv:2102.11436",
    "title": "Model-Based Domain Generalization",
    "abstract": "Model-Based Domain Generalization",
    "descriptor": "",
    "authors": [
      "Alexander Robey",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11436"
  },
  {
    "id": "arXiv:2102.13363",
    "title": "Average Rate and Error Probability Analysis in Short Packet  Communications over RIS-aided URLLC Systems",
    "abstract": "Comments: 14 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2103.12175",
    "descriptor": "\nComments: 14 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2103.12175\n",
    "authors": [
      "Ramin Hashemi",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.13363"
  },
  {
    "id": "arXiv:2102.13620",
    "title": "Towards Robust and Reliable Algorithmic Recourse",
    "abstract": "Towards Robust and Reliable Algorithmic Recourse",
    "descriptor": "",
    "authors": [
      "Sohini Upadhyay",
      "Shalmali Joshi",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.13620"
  },
  {
    "id": "arXiv:2103.00355",
    "title": "SUM: A Benchmark Dataset of Semantic Urban Meshes",
    "abstract": "Comments: 27 pages, 14 figures",
    "descriptor": "\nComments: 27 pages, 14 figures\n",
    "authors": [
      "Weixiao Gao",
      "Liangliang Nan",
      "Bas Boom",
      "Hugo Ledoux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00355"
  },
  {
    "id": "arXiv:2103.01931",
    "title": "Categorical Foundations of Gradient-Based Learning",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "G.S.H. Cruttwell",
      "Bruno Gavranovi\u0107",
      "Neil Ghani",
      "Paul Wilson",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2103.01931"
  },
  {
    "id": "arXiv:2103.03097",
    "title": "Generalizing to Unseen Domains: A Survey on Domain Generalization",
    "abstract": "Comments: 15 pages; short version (6 pages) has been accepted by IJCAI-21 survey track; codebase: this https URL",
    "descriptor": "\nComments: 15 pages; short version (6 pages) has been accepted by IJCAI-21 survey track; codebase: this https URL\n",
    "authors": [
      "Jindong Wang",
      "Cuiling Lan",
      "Chang Liu",
      "Yidong Ouyang",
      "Wenjun Zeng",
      "Tao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03097"
  },
  {
    "id": "arXiv:2103.03980",
    "title": "Revenue Maximization for Buyers with Outside Options",
    "abstract": "Revenue Maximization for Buyers with Outside Options",
    "descriptor": "",
    "authors": [
      "Yannai A. Gonczarowski",
      "Nicole Immorlica",
      "Yingkai Li",
      "Brendan Lucier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2103.03980"
  },
  {
    "id": "arXiv:2103.04167",
    "title": "Imbalance-Aware Self-Supervised Learning for 3D Radiomic Representations",
    "abstract": "Comments: camera-ready version in MICCAI 2021",
    "descriptor": "\nComments: camera-ready version in MICCAI 2021\n",
    "authors": [
      "Hongwei Li",
      "Fei-Fei Xue",
      "Krishna Chaitanya",
      "Shengda Luo",
      "Ivan Ezhov",
      "Benedikt Wiestler",
      "Jianguo Zhang",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.04167"
  },
  {
    "id": "arXiv:2103.04657",
    "title": "You Only Learn Once: Universal Anatomical Landmark Detection",
    "abstract": "Comments: Accepted for MICCAI 2021, 11 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: Accepted for MICCAI 2021, 11 pages, 2 figures, 2 tables\n",
    "authors": [
      "Heqin Zhu",
      "QingsongYao",
      "Li Xiao",
      "S.kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04657"
  },
  {
    "id": "arXiv:2103.05488",
    "title": "Smoothed counting of 0-1 points in polyhedra",
    "abstract": "Comments: 24 pages, several improvements",
    "descriptor": "\nComments: 24 pages, several improvements\n",
    "authors": [
      "Alexander Barvinok"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2103.05488"
  },
  {
    "id": "arXiv:2103.05661",
    "title": "On complementing end-to-end human behavior predictors with planning",
    "abstract": "On complementing end-to-end human behavior predictors with planning",
    "descriptor": "",
    "authors": [
      "Liting Sun",
      "Xiaogang Jia",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.05661"
  },
  {
    "id": "arXiv:2103.08417",
    "title": "Distributed Linear-Quadratic Control with Graph Neural Networks",
    "abstract": "Distributed Linear-Quadratic Control with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Fernando Gama",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.08417"
  },
  {
    "id": "arXiv:2103.08647",
    "title": "The Effect of Domain and Diacritics in Yor\u00f9b\u00e1-English Neural Machine  Translation",
    "abstract": "Comments: Accepted to MT Summit 2021",
    "descriptor": "\nComments: Accepted to MT Summit 2021\n",
    "authors": [
      "David I. Adelani",
      "Dana Ruiter",
      "Jesujoba O. Alabi",
      "Damilola Adebonojo",
      "Adesina Ayeni",
      "Mofe Adeyemi",
      "Ayodele Awokoya",
      "Cristina Espa\u00f1a-Bonet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.08647"
  },
  {
    "id": "arXiv:2103.09327",
    "title": "SoWaF: Shuffling of Weights and Feature Maps: A Novel Hardware Intrinsic  Attack (HIA) on Convolutional Neural Network (CNN)",
    "abstract": "Comments: 5 pages, 6 figures, 2 tables, ISCAS 2021 Conference",
    "descriptor": "\nComments: 5 pages, 6 figures, 2 tables, ISCAS 2021 Conference\n",
    "authors": [
      "Tolulope A. Odetola",
      "Syed Rafay Hasan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09327"
  },
  {
    "id": "arXiv:2103.09791",
    "title": "An Overflow/Underflow-Free Fixed-Point Bit-Width Optimization Method for  OS-ELM Digital Circuit",
    "abstract": "An Overflow/Underflow-Free Fixed-Point Bit-Width Optimization Method for  OS-ELM Digital Circuit",
    "descriptor": "",
    "authors": [
      "Mineto Tsukada",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09791"
  },
  {
    "id": "arXiv:2103.11133",
    "title": "Water Need Models and Irrigation Decision Systems",
    "abstract": "Comments: 10 pages, 0 figures, 1 table, survey paper",
    "descriptor": "\nComments: 10 pages, 0 figures, 1 table, survey paper\n",
    "authors": [
      "Meri\u00e7 \u00c7etin",
      "Senem Y\u0131ld\u0131z",
      "Selami Beyhan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.11133"
  },
  {
    "id": "arXiv:2103.11260",
    "title": "New Invariants of Poncelet-Jacobi Bicentric Polygons",
    "abstract": "Comments: 17 pages, 6 figures, 1 table with 18 video links",
    "descriptor": "\nComments: 17 pages, 6 figures, 1 table with 18 video links\n",
    "authors": [
      "Pedro Roitman",
      "Ronaldo Garcia",
      "Dan Reznik"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computational Geometry (cs.CG)",
      "Mathematical Physics (math-ph)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2103.11260"
  },
  {
    "id": "arXiv:2103.14082",
    "title": "Learning Stable Representations with Full Encoder",
    "abstract": "Learning Stable Representations with Full Encoder",
    "descriptor": "",
    "authors": [
      "Zhouzheng Li",
      "Kun Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14082"
  },
  {
    "id": "arXiv:2103.16111",
    "title": "A resource-efficient method for repeated HPO and NAS problems",
    "abstract": "Comments: Accepted at AutoML workshop @ ICML 2021",
    "descriptor": "\nComments: Accepted at AutoML workshop @ ICML 2021\n",
    "authors": [
      "Giovanni Zappella",
      "David Salinas",
      "C\u00e9dric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.16111"
  },
  {
    "id": "arXiv:2103.16440",
    "title": "Neural Transformation Learning for Deep Anomaly Detection Beyond Images",
    "abstract": "Neural Transformation Learning for Deep Anomaly Detection Beyond Images",
    "descriptor": "",
    "authors": [
      "Chen Qiu",
      "Timo Pfrommer",
      "Marius Kloft",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.16440"
  },
  {
    "id": "arXiv:2104.00138",
    "title": "Rapid quantification of COVID-19 pneumonia burden from computed  tomography with convolutional LSTM networks",
    "abstract": "Comments: Added a new table (Table 4) and section (Section 3.5), no other results changed",
    "descriptor": "\nComments: Added a new table (Table 4) and section (Section 3.5), no other results changed\n",
    "authors": [
      "Kajetan Grodecki",
      "Aditya Killekar",
      "Andrew Lin",
      "Sebastien Cadet",
      "Priscilla McElhinney",
      "Aryabod Razipour",
      "Cato Chan",
      "Barry D. Pressman",
      "Peter Julien",
      "Judit Simon",
      "Pal Maurovich-Horvat",
      "Nicola Gaibazzi",
      "Udit Thakur",
      "Elisabetta Mancini",
      "Cecilia Agalbato",
      "Jiro Munechika",
      "Hidenari Matsumoto",
      "Roberto Men\u00e8",
      "Gianfranco Parati",
      "Franco Cernigliaro",
      "Nitesh Nerlekar",
      "Camilla Torlasco",
      "Gianluca Pontone",
      "Damini Dey",
      "Piotr J. Slomka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00138"
  },
  {
    "id": "arXiv:2104.01874",
    "title": "Deep Learning of Conjugate Mappings",
    "abstract": "Deep Learning of Conjugate Mappings",
    "descriptor": "",
    "authors": [
      "Jason J. Bramburger",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01874"
  },
  {
    "id": "arXiv:2104.01939",
    "title": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent  Reinforcement Learning",
    "abstract": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Quanlin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.01939"
  },
  {
    "id": "arXiv:2104.02265",
    "title": "Learning from Self-Discrepancy via Multiple Co-teaching for Cross-Domain  Person Re-Identification",
    "abstract": "Learning from Self-Discrepancy via Multiple Co-teaching for Cross-Domain  Person Re-Identification",
    "descriptor": "",
    "authors": [
      "Suncheng Xiang",
      "Yuzhuo Fu",
      "Mengyuan Guan",
      "Ting Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02265"
  },
  {
    "id": "arXiv:2104.02938",
    "title": "Deep Interpretable Models of Theory of Mind",
    "abstract": "Comments: RO-MAN 2021",
    "descriptor": "\nComments: RO-MAN 2021\n",
    "authors": [
      "Ini Oguntola",
      "Dana Hughes",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.02938"
  },
  {
    "id": "arXiv:2104.03461",
    "title": "Linear and Sublinear Time Spectral Density Estimation",
    "abstract": "Linear and Sublinear Time Spectral Density Estimation",
    "descriptor": "",
    "authors": [
      "Vladimir Braverman",
      "Aditya Krishnan",
      "Christopher Musco"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.03461"
  },
  {
    "id": "arXiv:2104.03674",
    "title": "Explainability-based Backdoor Attacks Against Graph Neural Networks",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Jing Xu",
      "Minhui",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.03674"
  },
  {
    "id": "arXiv:2104.05379",
    "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic  Speech Recognition Architectures",
    "abstract": "Comments: Submitted to ASRU 2021",
    "descriptor": "\nComments: Submitted to ASRU 2021\n",
    "authors": [
      "Nick Rossenbach",
      "Mohammad Zeineldeen",
      "Benedikt Hilmes",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05379"
  },
  {
    "id": "arXiv:2104.05942",
    "title": "Recurrent Equilibrium Networks: Flexible Dynamic Models with Guaranteed  Stability and Robustness",
    "abstract": "Comments: Journal submission, extended version of conference paper (v1 of this arxiv preprint)",
    "descriptor": "\nComments: Journal submission, extended version of conference paper (v1 of this arxiv preprint)\n",
    "authors": [
      "Max Revay",
      "Ruigang Wang",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.05942"
  },
  {
    "id": "arXiv:2104.08793",
    "title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense  Reasoning",
    "abstract": "Comments: XAI Workshop at ICML 2021",
    "descriptor": "\nComments: XAI Workshop at ICML 2021\n",
    "authors": [
      "Aaron Chan",
      "Boyuan Long",
      "Jiashu Xu",
      "Soumya Sanyal",
      "Tanishq Gupta",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08793"
  },
  {
    "id": "arXiv:2104.10482",
    "title": "GraphSVX: Shapley Value Explanations for Graph Neural Networks",
    "abstract": "Comments: ECML PKDD 2021",
    "descriptor": "\nComments: ECML PKDD 2021\n",
    "authors": [
      "Alexandre Duval",
      "Fragkiskos D. Malliaros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10482"
  },
  {
    "id": "arXiv:2104.12556",
    "title": "COVID-19 Modeling: A Review",
    "abstract": "Comments: 67 pages, 3 figures, 9 tables",
    "descriptor": "\nComments: 67 pages, 3 figures, 9 tables\n",
    "authors": [
      "Longbing Cao",
      "Qing Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12556"
  },
  {
    "id": "arXiv:2104.14354",
    "title": "SoCRATES: System-on-Chip Resource Adaptive Scheduling using Deep  Reinforcement Learning",
    "abstract": "Comments: 8 pages, 8 figures",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Tegg Taekyong Sung",
      "Bo Ryu"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.14354"
  },
  {
    "id": "arXiv:2105.03693",
    "title": "On set systems definable in sparse graph classes, discrepancy, and  quantifier elimination",
    "abstract": "On set systems definable in sparse graph classes, discrepancy, and  quantifier elimination",
    "descriptor": "",
    "authors": [
      "Mario Grobler",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03693"
  },
  {
    "id": "arXiv:2105.03782",
    "title": "Construction of Sparse Suffix Trees and LCE Indexes in Optimal Time and  Space",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Dmitry Kosolobov",
      "Nikita Sivukhin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03782"
  },
  {
    "id": "arXiv:2105.03793",
    "title": "Stability and Generalization of Stochastic Gradient Methods for Minimax  Problems",
    "abstract": "Comments: To appear in ICML 2021 as Long Presentation",
    "descriptor": "\nComments: To appear in ICML 2021 as Long Presentation\n",
    "authors": [
      "Yunwen Lei",
      "Zhenhuan Yang",
      "Tianbao Yang",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03793"
  },
  {
    "id": "arXiv:2105.06186",
    "title": "Tracelet Hopf algebras and decomposition spaces",
    "abstract": "Comments: 15+9 pages; Applied Category Theory 2021 pre-proceedings version",
    "descriptor": "\nComments: 15+9 pages; Applied Category Theory 2021 pre-proceedings version\n",
    "authors": [
      "Nicolas Behr",
      "Joachim Kock"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.06186"
  },
  {
    "id": "arXiv:2105.06804",
    "title": "Locate and Label: A Two-stage Identifier for Nested Named Entity  Recognition",
    "abstract": "Comments: Accepted to ACL 2021, camera ready version",
    "descriptor": "\nComments: Accepted to ACL 2021, camera ready version\n",
    "authors": [
      "Yongliang Shen",
      "Xinyin Ma",
      "Zeqi Tan",
      "Shuai Zhang",
      "Wen Wang",
      "Weiming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06804"
  },
  {
    "id": "arXiv:2105.07620",
    "title": "APPL: Adaptive Planner Parameter Learning",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2011.00400",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.00400\n",
    "authors": [
      "Xuesu Xiao",
      "Zizhao Wang",
      "Zifan Xu",
      "Bo Liu",
      "Garrett Warnell",
      "Gauraang Dhamankar",
      "Anirudh Nair",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.07620"
  },
  {
    "id": "arXiv:2105.07671",
    "title": "Classifying variety of customer's online engagement for churn prediction  with mixed-penalty logistic regression",
    "abstract": "Comments: This version is not sufficiently exhaustive; a wrong version of validation results has been released (using a wrong part of a dataset for validation)",
    "descriptor": "\nComments: This version is not sufficiently exhaustive; a wrong version of validation results has been released (using a wrong part of a dataset for validation)\n",
    "authors": [
      "Petra Posedel \u0160imovi\u0107",
      "Davor Horvatic",
      "Edward W. Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2105.07671"
  },
  {
    "id": "arXiv:2105.11681",
    "title": "Deep Neural Networks and End-to-End Learning for Audio Compression",
    "abstract": "Deep Neural Networks and End-to-End Learning for Audio Compression",
    "descriptor": "",
    "authors": [
      "Daniela N. Rim",
      "Inseon Jang",
      "Heeyoul Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.11681"
  },
  {
    "id": "arXiv:2105.12083",
    "title": "Efficient Assignment of Identities in Anonymous Populations",
    "abstract": "Comments: 28 pages, 1 figure",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Leszek Gasieniec",
      "Jesper Jansson",
      "Christos Levcopoulos",
      "Andrzej Lingas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.12083"
  },
  {
    "id": "arXiv:2105.12827",
    "title": "Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning",
    "abstract": "Comments: The paper has been submitted to the IEEE WCL journal and has 4 pages and 9 figures",
    "descriptor": "\nComments: The paper has been submitted to the IEEE WCL journal and has 4 pages and 9 figures\n",
    "authors": [
      "Evgeny Bobrov",
      "Dmitry Kropotov",
      "Hao Lu",
      "Danila Zaev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.12827"
  },
  {
    "id": "arXiv:2105.15183",
    "title": "Efficient and Modular Implicit Differentiation",
    "abstract": "Comments: V2: some corrections and link to software",
    "descriptor": "\nComments: V2: some corrections and link to software\n",
    "authors": [
      "Mathieu Blondel",
      "Quentin Berthet",
      "Marco Cuturi",
      "Roy Frostig",
      "Stephan Hoyer",
      "Felipe Llinares-L\u00f3pez",
      "Fabian Pedregosa",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15183"
  },
  {
    "id": "arXiv:2106.01190",
    "title": "Counting Lyndon Subsequences",
    "abstract": "Counting Lyndon Subsequences",
    "descriptor": "",
    "authors": [
      "Ryo Hirakawa",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.01190"
  },
  {
    "id": "arXiv:2106.01463",
    "title": "Lightweight Adapter Tuning for Multilingual Speech Translation",
    "abstract": "Comments: Accepted at ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hang Le",
      "Juan Pino",
      "Changhan Wang",
      "Jiatao Gu",
      "Didier Schwab",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01463"
  },
  {
    "id": "arXiv:2106.02473",
    "title": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for  Classification Algorithm Test: from Linear Regression to Visual Transformer",
    "abstract": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for  Classification Algorithm Test: from Linear Regression to Visual Transformer",
    "descriptor": "",
    "authors": [
      "Weiming Hu",
      "Chen Li",
      "Xiaoyan Li",
      "Md Mamunur Rahaman",
      "Jiquan Ma",
      "Haoyuan Chen",
      "Wanli Liu",
      "Changhao Sun",
      "Yudong Yao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02473"
  },
  {
    "id": "arXiv:2106.03843",
    "title": "Equivariant Graph Neural Networks for 3D Macromolecular Structure",
    "abstract": "Comments: WCB @ ICML 2021 + link to code",
    "descriptor": "\nComments: WCB @ ICML 2021 + link to code\n",
    "authors": [
      "Bowen Jing",
      "Stephan Eismann",
      "Pratham N. Soni",
      "Ron O. Dror"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.03843"
  },
  {
    "id": "arXiv:2106.04718",
    "title": "FastSeq: Make Sequence Generation Faster",
    "abstract": "Comments: ACL 2021 Demo Track",
    "descriptor": "\nComments: ACL 2021 Demo Track\n",
    "authors": [
      "Yu Yan",
      "Fei Hu",
      "Jiusheng Chen",
      "Nikhil Bhendawade",
      "Ting Ye",
      "Yeyun Gong",
      "Nan Duan",
      "Desheng Cui",
      "Bingyu Chi",
      "Ruofei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04718"
  },
  {
    "id": "arXiv:2106.05386",
    "title": "Artificial Intelligence in Drug Discovery: Applications and Techniques",
    "abstract": "Comments: Minor text revisions",
    "descriptor": "\nComments: Minor text revisions\n",
    "authors": [
      "Jianyuan Deng",
      "Zhibo Yang",
      "Iwao Ojima",
      "Dimitris Samaras",
      "Fusheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05386"
  },
  {
    "id": "arXiv:2106.06046",
    "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability,  and Transferability for a Novel Trustworthy AI Framework",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060\n",
    "authors": [
      "Mohit Kumar",
      "Bernhard A. Moser",
      "Lukas Fischer",
      "Bernhard Freudenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06046"
  },
  {
    "id": "arXiv:2106.06080",
    "title": "Gradual Domain Adaptation in the Wild:When Intermediate Distributions  are Absent",
    "abstract": "Gradual Domain Adaptation in the Wild:When Intermediate Distributions  are Absent",
    "descriptor": "",
    "authors": [
      "Samira Abnar",
      "Rianne van den Berg",
      "Golnaz Ghiasi",
      "Mostafa Dehghani",
      "Nal Kalchbrenner",
      "Hanie Sedghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06080"
  },
  {
    "id": "arXiv:2106.06232",
    "title": "GDI: Rethinking What Makes Reinforcement Learning Different From  Supervised Learning",
    "abstract": "GDI: Rethinking What Makes Reinforcement Learning Different From  Supervised Learning",
    "descriptor": "",
    "authors": [
      "Jiajun Fan",
      "Changnan Xiao",
      "Yue Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06232"
  },
  {
    "id": "arXiv:2106.06332",
    "title": "Smart Textiles that Teach: Fabric-Based Haptic Device Improves the Rate  of Motor Learning",
    "abstract": "Smart Textiles that Teach: Fabric-Based Haptic Device Improves the Rate  of Motor Learning",
    "descriptor": "",
    "authors": [
      "Vivek Ramachandran",
      "Fabian Schilling",
      "Amy R Wu",
      "Dario Floreano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06332"
  },
  {
    "id": "arXiv:2106.08290",
    "title": "Coded Privacy-Preserving Computation at Edge Networks",
    "abstract": "Coded Privacy-Preserving Computation at Edge Networks",
    "descriptor": "",
    "authors": [
      "Elahe Vedadi",
      "Yasaman Keshtkarjahromi",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08290"
  },
  {
    "id": "arXiv:2106.12631",
    "title": "Design and engineering of a simplified workflow execution for the MG5aMC  event generator on GPUs and vector CPUs",
    "abstract": "Comments: 17 pages, 6 figures, submitted to vCHEP2021 proceedings in EPJ Web of Conferences; minor changes to address comments from the EPJWOC reviewer",
    "descriptor": "\nComments: 17 pages, 6 figures, submitted to vCHEP2021 proceedings in EPJ Web of Conferences; minor changes to address comments from the EPJWOC reviewer\n",
    "authors": [
      "Andrea Valassi",
      "Stefan Roiser",
      "Olivier Mattelaer",
      "Stephan Hageboeck"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Software Engineering (cs.SE)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.12631"
  },
  {
    "id": "arXiv:2106.13052",
    "title": "Autonomous Driving Strategies at Intersections: Scenarios,  State-of-the-Art, and Future Outlooks",
    "abstract": "Autonomous Driving Strategies at Intersections: Scenarios,  State-of-the-Art, and Future Outlooks",
    "descriptor": "",
    "authors": [
      "Lianzhen Wei",
      "Zirui Li",
      "Jianwei Gong",
      "Cheng Gong",
      "Jiachen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13052"
  },
  {
    "id": "arXiv:2106.14073",
    "title": "Interflow: Aggregating Multi-layer Feature Mappings with Attention  Mechanism",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Zhicheng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14073"
  },
  {
    "id": "arXiv:2106.14334",
    "title": "Noisy-MAPPO: Noisy Credit Assignment for Cooperative Multi-agent  Actor-Critic methods",
    "abstract": "Comments: fix errors in the proof",
    "descriptor": "\nComments: fix errors in the proof\n",
    "authors": [
      "Siyue Hu",
      "Jian Hu",
      "Shih-wei Liao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.14334"
  },
  {
    "id": "arXiv:2106.16139",
    "title": "Automated Onychomycosis Detection Using Deep Neural Networks",
    "abstract": "Comments: It was noticed that the data collection procedure was not performed in accordance with the high standards we normally follow in our studies. As such, the dataset that was described in Section II-A will be created from scratch. We may need to make changes in the methodology and reevaluate the results. Also, significance of the study need to be changed",
    "descriptor": "\nComments: It was noticed that the data collection procedure was not performed in accordance with the high standards we normally follow in our studies. As such, the dataset that was described in Section II-A will be created from scratch. We may need to make changes in the methodology and reevaluate the results. Also, significance of the study need to be changed\n",
    "authors": [
      "Abdurrahim Yilmaz",
      "Rahmetullah Varol",
      "Fatih Goktay",
      "Gulsum Gencoglan",
      "Ali Anil Demircali",
      "Berk Dilsizoglu",
      "Huseyin Uvet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16139"
  },
  {
    "id": "arXiv:2106.16190",
    "title": "A Domain-Theoretic Approach to Statistical Programming Languages",
    "abstract": "Comments: 84 pages; corrected typos, fixed an error pertaining to soundness, added references to computable probability theory",
    "descriptor": "\nComments: 84 pages; corrected typos, fixed an error pertaining to soundness, added references to computable probability theory\n",
    "authors": [
      "Jean Goubault-Larrecq",
      "Xiaodong Jia",
      "Cl\u00e9ment Th\u00e9ron"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.16190"
  },
  {
    "id": "arXiv:2107.00630",
    "title": "Variational Diffusion Models",
    "abstract": "Variational Diffusion Models",
    "descriptor": "",
    "authors": [
      "Diederik P. Kingma",
      "Tim Salimans",
      "Ben Poole",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00630"
  },
  {
    "id": "arXiv:2107.01500",
    "title": "Geometric vs Algebraic Nullity for Hyperpaths",
    "abstract": "Comments: 22 pages, 1 figure",
    "descriptor": "\nComments: 22 pages, 1 figure\n",
    "authors": [
      "Joshua Cooper",
      "Grant Fickes"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.01500"
  },
  {
    "id": "arXiv:2107.01700",
    "title": "End-to-end Neural Coreference Resolution Revisited: A Simple yet  Effective Baseline",
    "abstract": "End-to-end Neural Coreference Resolution Revisited: A Simple yet  Effective Baseline",
    "descriptor": "",
    "authors": [
      "Tuan Manh Lai",
      "Trung Bui",
      "Doo Soon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01700"
  },
  {
    "id": "arXiv:2107.02185",
    "title": "Growing Urban Bicycle Networks",
    "abstract": "Comments: Main text: 12 pages, 7 figures, SI: 14 pages, 9 figures. Website: this http URL",
    "descriptor": "\nComments: Main text: 12 pages, 7 figures, SI: 14 pages, 9 figures. Website: this http URL\n",
    "authors": [
      "Michael Szell",
      "Sayat Mimar",
      "Tyler Perlman",
      "Gourab Ghoshal",
      "Roberta Sinatra"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.02185"
  },
  {
    "id": "arXiv:2107.02381",
    "title": "An Inverse QSAR Method Based on Linear Regression and Integer  Programming",
    "abstract": "An Inverse QSAR Method Based on Linear Regression and Integer  Programming",
    "descriptor": "",
    "authors": [
      "Jianshen Zhu",
      "Naveed Ahmed Azam",
      "Kazuya Haraguchi",
      "Liang Zhao",
      "Hiroshi Nagamochi",
      "Tatsuya Akutsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.02381"
  },
  {
    "id": "arXiv:2107.02390",
    "title": "CausalRec: Causal Inference for Visual Debiasing in Visually-Aware  Recommendation",
    "abstract": "CausalRec: Causal Inference for Visual Debiasing in Visually-Aware  Recommendation",
    "descriptor": "",
    "authors": [
      "Ruihong Qiu",
      "Sen Wang",
      "Zhi Chen",
      "Hongzhi Yin",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.02390"
  },
  {
    "id": "arXiv:2107.02561",
    "title": "Rethinking Positional Encoding",
    "abstract": "Rethinking Positional Encoding",
    "descriptor": "",
    "authors": [
      "Jianqiao Zheng",
      "Sameera Ramasinghe",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02561"
  },
  {
    "id": "arXiv:2107.03006",
    "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
    "abstract": "Comments: 10 pages plus references and appendices. First two authors contributed equally",
    "descriptor": "\nComments: 10 pages plus references and appendices. First two authors contributed equally\n",
    "authors": [
      "Jacob Austin",
      "Daniel D. Johnson",
      "Jonathan Ho",
      "Daniel Tarlow",
      "Rianne van den Berg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03006"
  },
  {
    "id": "arXiv:2107.03112",
    "title": "Efficient Reduced Basis Algorithm (ERBA) for kernel-based approximation",
    "abstract": "Efficient Reduced Basis Algorithm (ERBA) for kernel-based approximation",
    "descriptor": "",
    "authors": [
      "Francesco Marchetti",
      "Emma Perracchione"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.03112"
  },
  {
    "id": "arXiv:2107.03574",
    "title": "On the 4-Adic Complexity of Quaternary Sequences with Ideal  Autocorrelation",
    "abstract": "On the 4-Adic Complexity of Quaternary Sequences with Ideal  Autocorrelation",
    "descriptor": "",
    "authors": [
      "Minghui Yang",
      "Shiyuan Qiang",
      "Xiaoyan Jing",
      "Keqin Feng",
      "Dongdai Lin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.03574"
  },
  {
    "id": "arXiv:2107.03651",
    "title": "Elastic deformation of optical coherence tomography images of diabetic  macular edema for deep-learning models training: how far to go?",
    "abstract": "Elastic deformation of optical coherence tomography images of diabetic  macular edema for deep-learning models training: how far to go?",
    "descriptor": "",
    "authors": [
      "Daniel Bar-David",
      "Laura Bar-David",
      "Yinon Shapira",
      "Rina Leibu",
      "Dalia Dori",
      "Ronit Schneor",
      "Anath Fischer",
      "Shiri Soudry"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03651"
  },
  {
    "id": "arXiv:2107.04108",
    "title": "An Integer Linear Programming Model for Tilings",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Gennaro Auricchio",
      "Luca Ferrarini",
      "Greta Lanzarotto"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.04108"
  },
  {
    "id": "arXiv:2107.04225",
    "title": "A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior  Analysis",
    "abstract": "A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior  Analysis",
    "descriptor": "",
    "authors": [
      "Lingfeng Wang",
      "Shisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.04225"
  },
  {
    "id": "arXiv:2107.04764",
    "title": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors",
    "abstract": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors",
    "descriptor": "",
    "authors": [
      "Sara Hajj Ibrahim",
      "Mohamed Nassar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.04764"
  },
  {
    "id": "arXiv:2107.04773",
    "title": "Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning for  Semantic Code Search",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Lun Du",
      "Xiaozhou Shi",
      "Yanlin Wang",
      "Ensheng Shi",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04773"
  },
  {
    "id": "arXiv:2107.04804",
    "title": "A posteriori error analysis for a distributed optimal control problem  governed by the von K\u00e1rm\u00e1n equations",
    "abstract": "Comments: 23 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: 23 pages, 3 figures, 4 tables\n",
    "authors": [
      "Sudipto Chowdhury",
      "Asha K. Dond",
      "Neela Nataraj",
      "Devika Shylaja"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.04804"
  },
  {
    "id": "arXiv:2107.04808",
    "title": "COVID Detection in Chest CTs: Improving the Baseline on COV19-CT-DB",
    "abstract": "COVID Detection in Chest CTs: Improving the Baseline on COV19-CT-DB",
    "descriptor": "",
    "authors": [
      "Radu Miron",
      "Cosmin Moisii",
      "Sergiu Dinu",
      "Mihaela Breaban"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04808"
  },
  {
    "id": "arXiv:2107.04823",
    "title": "BSDA-Net: A Boundary Shape and Distance Aware Joint Learning Framework  for Segmenting and Classifying OCTA Images",
    "abstract": "Comments: 12 pages, 4 figures, MICCAI2021 [Student Travel Award]",
    "descriptor": "\nComments: 12 pages, 4 figures, MICCAI2021 [Student Travel Award]\n",
    "authors": [
      "Li Lin",
      "Zhonghua Wang",
      "Jiewei Wu",
      "Yijin Huang",
      "Junyan Lyu",
      "Pujin Cheng",
      "Jiong Wu",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04823"
  },
  {
    "id": "arXiv:2107.04834",
    "title": "Bayesian Convolutional Neural Networks for Seven Basic Facial Expression  Classifications",
    "abstract": "Bayesian Convolutional Neural Networks for Seven Basic Facial Expression  Classifications",
    "descriptor": "",
    "authors": [
      "Yuan Tai",
      "Yihua Tan",
      "Wei Gong",
      "Hailan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04834"
  },
  {
    "id": "arXiv:2107.04997",
    "title": "Efficient and Effective Algorithms for Revenue Maximization in Social  Advertising Efficient and Effective Algorithms for Revenue Maximization in  Social Advertising",
    "abstract": "Comments: extended version of the paper in sigmod2021",
    "descriptor": "\nComments: extended version of the paper in sigmod2021\n",
    "authors": [
      "Kai Han",
      "Benwei Wu",
      "Jing Tang",
      "Shuang Cui",
      "Cigdem Aslay",
      "Laks V. S. Lakshmanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.04997"
  },
  {
    "id": "arXiv:2107.05053",
    "title": "Anomaly Detection in Smart Manufacturing with an Application Focus on  Robotic Finishing Systems: A Review",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Tareq Tayeh",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05053"
  },
  {
    "id": "arXiv:2107.05181",
    "title": "AoI-minimizing Scheduling in UAV-relayed IoT Networks",
    "abstract": "AoI-minimizing Scheduling in UAV-relayed IoT Networks",
    "descriptor": "",
    "authors": [
      "Biplav Choudhury Vijay K. Shah",
      "Aidin Ferdowsi",
      "Jeffrey H. Reed",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.05181"
  },
  {
    "id": "arXiv:2107.05348",
    "title": "Zero-shot Visual Question Answering using Knowledge Graph",
    "abstract": "Comments: accepted at the International Semantic Web Conference '21 (ISWC 2021)",
    "descriptor": "\nComments: accepted at the International Semantic Web Conference '21 (ISWC 2021)\n",
    "authors": [
      "Zhuo Chen",
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Jeff Z. Pan",
      "Zonggang Yuan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05348"
  },
  {
    "id": "arXiv:2107.05373",
    "title": "On the Evaluation of Commit Message Generation Models: An Experimental  Study",
    "abstract": "Comments: Accepted to International Conference on Software Maintenance and Evolution (ICSME) 2021",
    "descriptor": "\nComments: Accepted to International Conference on Software Maintenance and Evolution (ICSME) 2021\n",
    "authors": [
      "Wei Tao",
      "Yanlin Wang",
      "Ensheng Shi",
      "Lun Du",
      "Hongyu Zhang",
      "Dongmei Zhang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05373"
  },
  {
    "id": "arXiv:2107.05384",
    "title": "Fine-Grained AutoAugmentation for Multi-Label Classification",
    "abstract": "Fine-Grained AutoAugmentation for Multi-Label Classification",
    "descriptor": "",
    "authors": [
      "Ya Wang",
      "Hesen Chen",
      "Fangyi Zhang",
      "Yaohua Wang",
      "Xiuyu Sun",
      "Ming Lin",
      "Hao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05384"
  },
  {
    "id": "arXiv:2107.05408",
    "title": "Don't Touch Me! A Comparison of Usability on Touch and Non-Touch Inputs",
    "abstract": "Comments: To appear in INTERACT 2021 (Lecture Notes in Computer Science). 4 pages, 7 figures",
    "descriptor": "\nComments: To appear in INTERACT 2021 (Lecture Notes in Computer Science). 4 pages, 7 figures\n",
    "authors": [
      "Kieran Waugh",
      "Judy Robertson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.05408"
  },
  {
    "id": "arXiv:2107.05473",
    "title": "GPTPU: Accelerating Applications using Edge Tensor Processing Units",
    "abstract": "Comments: This paper is a pre-print of a paper in the 2021 SC, the International Conference for High Performance Computing, Networking, Storage and Analysis",
    "descriptor": "\nComments: This paper is a pre-print of a paper in the 2021 SC, the International Conference for High Performance Computing, Networking, Storage and Analysis\n",
    "authors": [
      "Kuan-Chieh Hsu",
      "Hung-Wei Tseng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.05473"
  },
  {
    "id": "arXiv:2107.05522",
    "title": "EduCOR: An Educational and Career-Oriented Recommendation Ontology",
    "abstract": "Comments: Accepted in the The 20th International Semantic Web Conference (ISWC2021)",
    "descriptor": "\nComments: Accepted in the The 20th International Semantic Web Conference (ISWC2021)\n",
    "authors": [
      "Eleni Ilkou",
      "Hasan Abu-Rasheed",
      "Mohammadreza Tavakoli",
      "Sherzod Hakimov",
      "G\u00e1bor Kismih\u00f3k",
      "S\u00f6ren Auer",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.05522"
  },
  {
    "id": "arXiv:2107.05532",
    "title": "Context-aware virtual adversarial training for anatomically-plausible  segmentation",
    "abstract": "Comments: This paper is accepted at MICCAI2021",
    "descriptor": "\nComments: This paper is accepted at MICCAI2021\n",
    "authors": [
      "Ping Wang",
      "Jizong Peng",
      "Marco Pedersoli",
      "Yuanfeng Zhou",
      "Caiming Zhang",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05532"
  },
  {
    "id": "arXiv:2107.05541",
    "title": "End-to-End Natural Language Understanding Pipeline for Bangla  Conversational Agents",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Fahim Shahriar Khan",
      "Mueeze Al Mushabbir",
      "Mohammad Sabik Irbaz",
      "MD Abdullah Al Nasim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05541"
  },
  {
    "id": "arXiv:2107.05610",
    "title": "The Fundamental Theorem of Natural Selection",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "John C. Baez"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05610"
  }
]
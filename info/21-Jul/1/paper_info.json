[
  {
    "id": "arXiv:2106.15648",
    "title": "Learning to Map for Active Semantic Goal Navigation",
    "abstract": "We consider the problem of object goal navigation in unseen environments. In\nour view, solving this problem requires learning of contextual semantic priors,\na challenging endeavour given the spatial and semantic variability of indoor\nenvironments. Current methods learn to implicitly encode these priors through\ngoal-oriented navigation policy functions operating on spatial representations\nthat are limited to the agent's observable areas. In this work, we propose a\nnovel framework that actively learns to generate semantic maps outside the\nfield of view of the agent and leverages the uncertainty over the semantic\nclasses in the unobserved areas to decide on long term goals. We demonstrate\nthat through this spatial prediction strategy, we are able to learn semantic\npriors in scenes that can be leveraged in unknown environments. Additionally,\nwe show how different objectives can be defined by balancing exploration with\nexploitation during searching for semantic targets. Our method is validated in\nthe visually realistic environments offered by the Matterport3D dataset and\nshow state of the art results on the object goal navigation task.",
    "descriptor": "",
    "authors": [
      "Georgios Georgakis",
      "Bernadette Bucher",
      "Karl Schmeckpeper",
      "Siddharth Singh",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15648"
  },
  {
    "id": "arXiv:2106.15653",
    "title": "Survivable Robotic Control through Guided Bayesian Policy Search with  Deep Reinforcement Learning",
    "abstract": "Many robot manipulation skills can be represented with deterministic\ncharacteristics and there exist efficient techniques for learning parameterized\nmotor plans for those skills. However, one of the active research challenge\nstill remains to sustain manipulation capabilities in situation of a mechanical\nfailure. Ideally, like biological creatures, a robotic agent should be able to\nreconfigure its control policy by adapting to dynamic adversaries. In this\npaper, we propose a method that allows an agent to survive in a situation of\nmechanical loss, and adaptively learn manipulation with compromised degrees of\nfreedom -- we call our method Survivable Robotic Learning (SRL). Our key idea\nis to leverage Bayesian policy gradient by encoding knowledge bias in posterior\nestimation, which in turn alleviates future policy search explorations, in\nterms of sample efficiency and when compared to random exploration based policy\nsearch methods. SRL represents policy priors as Gaussian process, which allows\ntractable computation of approximate posterior (when true gradient is\nintractable), by incorporating guided bias as proxy from prior replays. We\nevaluate our proposed method against off-the-shelf model free learning\nalgorithm (DDPG), testing on a hexapod robot platform which encounters\nincremental failure emulation, and our experiments show that our method\nimproves largely in terms of sample requirement and quantitative success ratio\nin all failure modes. A demonstration video of our experiments can be viewed\nat: https://sites.google.com/view/survivalrl",
    "descriptor": "\nComments: 6 pages, published in CASE 2021 as regular paper\n",
    "authors": [
      "Sayyed Jaffar Ali Raza",
      "Apan Dastider",
      "Mingjie Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15653"
  },
  {
    "id": "arXiv:2106.15655",
    "title": "Alternating Direction Method of Multiplier-Based Distributed Planning  Model for Natural Gas, Electricity Network, and Regional Integrated Energy  Systems",
    "abstract": "Regional integrated energy system coupling with multienergy devices, energy\nstorage devices, and renewable energy devices has been regarded as one of the\nmost promising solutions for future energy systems. Planning for existing\nnatural gas and electricity network expansion, regional integrated energy\nsystem locations, or system equipment types and capacities are urgent problems\nin infrastructure development. This article employs a joint planning model to\naddress these; however, the joint planning model ignores the potential\nownerships by three agents, for which investment decisions are generally made\nby different investors. In this work, the joint planning model is decomposed\ninto three distributed planning subproblems related to the corresponding\nstakeholders, and the alternating direction method of multipliers is adopted to\nsolve the tripartite distributed planning problem. The effectiveness of the\nplanning model is verified on an updated version of the Institute of Electrical\nand Electronics Engineers (IEEE) 24-bus electric system, the Belgian 20-node\nnatural gas system, and three assumed integrated energy systems. Simulation\nresults illustrate that a distributed planning model is more sensitive to\nindividual load differences, which is precisely the defect of the joint\nplanning model. Moreover, the algorithm performance considering rates of\nconvergence and the impacts of penalty parameters is further analyzed",
    "descriptor": "",
    "authors": [
      "Ang Xuan",
      "Yang Qiu",
      "Yang Liu",
      "Xin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15655"
  },
  {
    "id": "arXiv:2106.15661",
    "title": "A Semantic Model for Interacting Cyber-Physical Systems",
    "abstract": "We propose a component-based semantic model for Cyber-Physical Systems (CPSs)\nwherein the notion of a component abstracts the internal details of both cyber\nand physical processes, to expose a uniform semantic model of their externally\nobservable behaviors expressed as sets of sequences of observations. We\nintroduce algebraic operations on such sequences to model different kinds of\ncomponent composition. These composition operators yield the externally\nobservable behavior of their resulting composite components through\nspecifications of interactions of the behaviors of their constituent\ncomponents, as they, e.g., synchronize with or mutually exclude each other's\nalternative behaviors. Our framework is expressive enough to allow articulation\nof properties that coordinate desired interactions among composed components\nwithin the framework, also as component behavior. We demonstrate the usefulness\nof our formalism through examples of coordination properties in a CPS\nconsisting of two robots interacting through shared physical resources.",
    "descriptor": "",
    "authors": [
      "Benjamin Lion",
      "Farhad Arbab",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15661"
  },
  {
    "id": "arXiv:2106.15662",
    "title": "Exponential Weights Algorithms for Selective Learning",
    "abstract": "We study the selective learning problem introduced by Qiao and Valiant\n(2019), in which the learner observes $n$ labeled data points one at a time. At\na time of its choosing, the learner selects a window length $w$ and a model\n$\\hat\\ell$ from the model class $\\mathcal{L}$, and then labels the next $w$\ndata points using $\\hat\\ell$. The excess risk incurred by the learner is\ndefined as the difference between the average loss of $\\hat\\ell$ over those $w$\ndata points and the smallest possible average loss among all models in\n$\\mathcal{L}$ over those $w$ data points.\nWe give an improved algorithm, termed the hybrid exponential weights\nalgorithm, that achieves an expected excess risk of $O((\\log\\log|\\mathcal{L}| +\n\\log\\log n)/\\log n)$. This result gives a doubly exponential improvement in the\ndependence on $|\\mathcal{L}|$ over the best known bound of\n$O(\\sqrt{|\\mathcal{L}|/\\log n})$. We complement the positive result with an\nalmost matching lower bound, which suggests the worst-case optimality of the\nalgorithm.\nWe also study a more restrictive family of learning algorithms that are\nbounded-recall in the sense that when a prediction window of length $w$ is\nchosen, the learner's decision only depends on the most recent $w$ data points.\nWe analyze an exponential weights variant of the ERM algorithm in Qiao and\nValiant (2019). This new algorithm achieves an expected excess risk of\n$O(\\sqrt{\\log |\\mathcal{L}|/\\log n})$, which is shown to be nearly optimal\namong all bounded-recall learners. Our analysis builds on a generalized version\nof the selective mean prediction problem in Drucker (2013); Qiao and Valiant\n(2019), which may be of independent interest.",
    "descriptor": "\nComments: To appear in COLT 2021\n",
    "authors": [
      "Mingda Qiao",
      "Gregory Valiant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15662"
  },
  {
    "id": "arXiv:2106.15664",
    "title": "Is 2NF a Stable Normal Form?",
    "abstract": "Traditionally, it was accepted that a relational database can be normalized\nstep-by-step, from a set of un-normalized tables to tables in $1NF$, then to\n$2NF$, then to $3NF$, then (possibly) to $BCNF$. The rule applied to a table in\n$1NF$ in order to transform it to a set of tables in $2NF$ seems to be too\nstraightforward to pose any difficulty.\nHowever, we show that, depending on the set of functional dependencies, it is\nimpossible to reach $2NF$ and stop there; one must, in these cases, perform the\nnormalization from $1NF$ to $3NF$ as an indecomposable move. The minimal setup\nto exhibit the phenomena requires a single composite key, and two partially\noverlapping chains of transitive dependencies.",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Amir Sapir",
      "Ariel Sapir"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.15664"
  },
  {
    "id": "arXiv:2106.15671",
    "title": "Diffusion Priors In Variational Autoencoders",
    "abstract": "Among likelihood-based approaches for deep generative modelling, variational\nautoencoders (VAEs) offer scalable amortized posterior inference and fast\nsampling. However, VAEs are also more and more outperformed by competing models\nsuch as normalizing flows (NFs), deep-energy models, or the new denoising\ndiffusion probabilistic models (DDPMs). In this preliminary work, we improve\nVAEs by demonstrating how DDPMs can be used for modelling the prior\ndistribution of the latent variables. The diffusion prior model improves upon\nGaussian priors of classical VAEs and is competitive with NF-based priors.\nFinally, we hypothesize that hierarchical VAEs could similarly benefit from the\nenhanced capacity of diffusion priors.",
    "descriptor": "",
    "authors": [
      "Antoine Wehenkel",
      "Gilles Louppe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15671"
  },
  {
    "id": "arXiv:2106.15674",
    "title": "SAT Based Analogy Evaluation Framework for Persian Word Embeddings",
    "abstract": "In recent years there has been a special interest in word embeddings as a new\napproach to convert words to vectors. It has been a focal point to understand\nhow much of the semantics of the the words has been transferred into embedding\nvectors. This is important as the embedding is going to be used as the basis\nfor downstream NLP applications and it will be costly to evaluate the\napplication end-to-end in order to identify quality of the used embedding\nmodel. Generally the word embeddings are evaluated through a number of tests,\nincluding analogy test. In this paper we propose a test framework for Persian\nembedding models. Persian is a low resource language and there is no rich\nsemantic benchmark to evaluate word embedding models for this language. In this\npaper we introduce an evaluation framework including a hand crafted Persian SAT\nbased analogy dataset, a colliquial test set (specific to Persian) and a\nbenchmark to study the impact of various parameters on the semantic evaluation\ntask.",
    "descriptor": "",
    "authors": [
      "Seyyed Ehsan Mahmoudi",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15674"
  },
  {
    "id": "arXiv:2106.15681",
    "title": "SIMPL: Generating Synthetic Overhead Imagery to Address Zero-shot and  Few-Shot Detection Problems",
    "abstract": "Recently deep neural networks (DNNs) have achieved tremendous success for\nobject detection in overhead (e.g., satellite) imagery. One ongoing challenge\nhowever is the acquisition of training data, due to high costs of obtaining\nsatellite imagery and annotating objects in it. In this work we present a\nsimple approach - termed Synthetic object IMPLantation (SIMPL) - to easily and\nrapidly generate large quantities of synthetic overhead training data for\ncustom target objects. We demonstrate the effectiveness of using SIMPL\nsynthetic imagery for training DNNs in zero-shot scenarios where no real\nimagery is available; and few-shot learning scenarios, where limited real-world\nimagery is available. We also conduct experiments to study the sensitivity of\nSIMPL's effectiveness to some key design parameters, providing users for\ninsights when designing synthetic imagery for custom objects. We release a\nsoftware implementation of our SIMPL approach so that others can build upon it,\nor use it for their own custom problems.",
    "descriptor": "",
    "authors": [
      "Yang Xu",
      "Bohao Huang",
      "Xiong Luo",
      "Kyle Bradbury",
      "Jordan M. Malof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15681"
  },
  {
    "id": "arXiv:2106.15684",
    "title": "Alzheimer's Dementia Recognition Using Acoustic, Lexical, Disfluency and  Speech Pause Features Robust to Noisy Inputs",
    "abstract": "We present two multimodal fusion-based deep learning models that consume ASR\ntranscribed speech and acoustic data simultaneously to classify whether a\nspeaker in a structured diagnostic task has Alzheimer's Disease and to what\ndegree, evaluating the ADReSSo challenge 2021 data. Our best model, a BiLSTM\nwith highway layers using words, word probabilities, disfluency features, pause\ninformation, and a variety of acoustic features, achieves an accuracy of 84%\nand RSME error prediction of 4.26 on MMSE cognitive scores. While predicting\ncognitive decline is more challenging, our models show improvement using the\nmultimodal approach and word probabilities, disfluency and pause information\nover word-only models. We show considerable gains for AD classification using\nmultimodal fusion and gating, which can effectively deal with noisy inputs from\nacoustic features and ASR hypotheses.",
    "descriptor": "\nComments: INTERSPEECH 2021. arXiv admin note: substantial text overlap with arXiv:2106.09668\n",
    "authors": [
      "Morteza Rohanian",
      "Julian Hough",
      "Matthew Purver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.15684"
  },
  {
    "id": "arXiv:2106.15686",
    "title": "Attention Aware Wavelet-based Detection of Morphed Face Images",
    "abstract": "Morphed images have exploited loopholes in the face recognition checkpoints,\ne.g., Credential Authentication Technology (CAT), used by Transportation\nSecurity Administration (TSA), which is a non-trivial security concern. To\novercome the risks incurred due to morphed presentations, we propose a\nwavelet-based morph detection methodology which adopts an end-to-end trainable\nsoft attention mechanism . Our attention-based deep neural network (DNN)\nfocuses on the salient Regions of Interest (ROI) which have the most spatial\nsupport for morph detector decision function, i.e, morph class binary softmax\noutput. A retrospective of morph synthesizing procedure aids us to speculate\nthe ROI as regions around facial landmarks , particularly for the case of\nlandmark-based morphing techniques. Moreover, our attention-based DNN is\nadapted to the wavelet space, where inputs of the network are coarse-to-fine\nspectral representations, 48 stacked wavelet sub-bands to be exact. We evaluate\nperformance of the proposed framework using three datasets, VISAPP17, LMA, and\nMorGAN. In addition, as attention maps can be a robust indicator whether a\nprobe image under investigation is genuine or counterfeit, we analyze the\nestimated attention maps for both a bona fide image and its corresponding\nmorphed image. Finally, we present an ablation study on the efficacy of\nutilizing attention mechanism for the sake of morph detection.",
    "descriptor": "\nComments: IJCB 2021\n",
    "authors": [
      "Poorya Aghdaie",
      "Baaria Chaudhary",
      "Sobhan Soleymani",
      "Jeremy Dawson",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15686"
  },
  {
    "id": "arXiv:2106.15689",
    "title": "NEUKONFIG: Reducing Edge Service Downtime When Repartitioning DNNs",
    "abstract": "Deep Neural Networks (DNNs) may be partitioned across the edge and the cloud\nto improve the performance efficiency of inference. DNN partitions are\ndetermined based on operational conditions such as network speed. When\noperational conditions change DNNs will need to be repartitioned to maintain\nthe overall performance. However, repartitioning using existing approaches,\nsuch as Pause and Resume, will incur a service downtime on the edge. This paper\npresents the NEUKONFIG framework that identifies the service downtime incurred\nwhen repartitioning DNNs and proposes approaches for reducing edge service\ndowntime. The proposed approaches are based on 'Dynamic Switching' in which,\nwhen the network speed changes and given an existing edge-cloud pipeline, a new\nedge-cloud pipeline is initialised with new DNN partitions. Incoming inference\nrequests are switched to the new pipeline for processing data. Two dynamic\nswitching scenarios are considered: when a second edge-cloud pipeline is always\nrunning and when a second pipeline is only initialised when the network speed\nchanges. Experimental studies are carried out on a lab-based testbed to\ndemonstrate that Dynamic Switching reduces the downtime by at least an order of\nmagnitude when compared to a baseline using Pause and Resume that has a\ndowntime of 6 seconds. A trade-off in the edge service downtime and memory\nrequired is noted. The Dynamic Switching approach that requires the same amount\nof memory as the baseline reduces the edge service downtime to 0.6 seconds and\nto less than 1 millisecond in the best case when twice the amount of memory as\nthe baseline is available.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ayesha Abdul Majeed",
      "Peter Kilpatrick",
      "Ivor Spence",
      "Blesson Varghese"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.15689"
  },
  {
    "id": "arXiv:2106.15691",
    "title": "Multiagent Deep Reinforcement Learning: Challenges and Directions  Towards Human-Like Approaches",
    "abstract": "This paper surveys the field of multiagent deep reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on the joint actions\nof multiple players and (b) the computational complexity of functions\nincreases. We present the most common multiagent problem representations and\ntheir main challenges, and identify five research areas that address one or\nmore of these challenges: centralised training and decentralised execution,\nopponent modelling, communication, efficient coordination, and reward shaping.\nWe find that many computational studies rely on unrealistic assumptions or are\nnot generalisable to other settings; they struggle to overcome the curse of\ndimensionality or nonstationarity. Approaches from psychology and sociology\ncapture promising relevant behaviours such as communication and coordination.\nWe suggest that, for multiagent reinforcement learning to be successful, future\nresearch addresses these challenges with an interdisciplinary approach to open\nup new possibilities for more human-oriented solutions in multiagent\nreinforcement learning.",
    "descriptor": "\nComments: 37 pages, 6 figures\n",
    "authors": [
      "Annie Wong",
      "Thomas B\u00e4ck",
      "Anna V. Kononova",
      "Aske Plaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.15691"
  },
  {
    "id": "arXiv:2106.15693",
    "title": "Domain adaptation for person re-identification on new unlabeled data  using AlignedReID++",
    "abstract": "In the world where big data reigns and there is plenty of hardware prepared\nto gather a huge amount of non structured data, data acquisition is no longer a\nproblem. Surveillance cameras are ubiquitous and they capture huge numbers of\npeople walking across different scenes. However, extracting value from this\ndata is challenging, specially for tasks that involve human images, such as\nface recognition and person re-identification. Annotation of this kind of data\nis a challenging and expensive task. In this work we propose a domain\nadaptation workflow to allow CNNs that were trained in one domain to be applied\nto another domain without the need for new annotation of the target data. Our\nmethod uses AlignedReID++ as the baseline, trained using a Triplet loss with\nbatch hard. Domain adaptation is done by using pseudo-labels generated using an\nunsupervised learning strategy. Our results show that domain adaptation\ntechniques really improve the performance of the CNN when applied in the target\ndomain.",
    "descriptor": "\nComments: 9 pages; 4 figues; built upon work published in VISAPP 2020 (best student paper award)\n",
    "authors": [
      "Tiago de C. G. Pereira",
      "Teofilo E. de Campos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15693"
  },
  {
    "id": "arXiv:2106.15702",
    "title": "Bilateral Market for Distribution-level Coordination of Flexible  Resources using Volttron",
    "abstract": "Increasing penetrations of distributed energy resources (DERs) and responsive\nloads (RLs) in the electric power distribution systems calls for a mechanism\nfor joint supply-demand coordination. Recently, several transactive/bilateral\ncoordination mechanisms have been proposed for the distribution-level\ncoordination of flexible resources. Implementing a transactive market\ncoordination approach requires a secure, reliable, and computationally\nefficient multi-agent platform. An example of such a platform is VOLTTRON,\ndeveloped by the Pacific Northwest National Laboratories (PNNL). The VOLTTRON\nplatform allows the market actors to exchange information and execute proper\ncontrol actions in a decentralized way. This paper aims to provide a\nproof-of-concept of the transactive market coordination approach via a\nsmall-scale demonstration on the VOLTTRON platform. The steps needed to\nimplement the proposed market architecture using virtual machines and VOLTTRON\nare thoroughly described, and illustrative examples are provided to show the\nmarket-clearing process for different scenarios.",
    "descriptor": "",
    "authors": [
      "Mohammad Ostadijafari",
      "Juan Carlos Bedoya",
      "Anamika Dubey",
      "Chen-Ching Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15702"
  },
  {
    "id": "arXiv:2106.15703",
    "title": "Threshold Queries in Theory and in the Wild",
    "abstract": "Threshold queries are an important class of queries that only require\ncomputing or counting answers up to a specified threshold value. To the best of\nour knowledge, threshold queries have been largely disregarded in the research\nliterature, which is surprising considering how common they are in practice. In\nthis paper, we present a deep theoretical analysis of threshold query\nevaluation and show that thresholds can be used to significantly improve the\nasymptotic bounds of state-of-the-art query evaluation algorithms. We also\nempirically show that threshold queries are significant in practice. In\nsurprising contrast to conventional wisdom, we found important scenarios in\nreal-world data sets in which users are interested in computing the results of\nqueries up to a certain threshold, independent of a ranking function that\norders the query results by importance.",
    "descriptor": "",
    "authors": [
      "Angela Bonifati",
      "Stefania Dumbrava",
      "George Fletcher",
      "Jan Hidders",
      "Matthias Hofer",
      "Wim Martens",
      "Filip Murlak",
      "Joshua Shinavier",
      "S\u0142awek Staworko",
      "Dominik Tomaszuk"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.15703"
  },
  {
    "id": "arXiv:2106.15708",
    "title": "A remark on ${\\mathbb F}_{q^n}$-Linear MRD codes",
    "abstract": "In this note, we provide a description of the elements of minimum rank of a\ngeneralized Gabidulin code in terms of Grassmann coordinates. As a consequence,\na characterization of linearized polynomials of rank at most $n-k$ is obtained,\nas well as parametric equations for MRD-codes of distance $d=n-k+1$.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Luca Giuzzi",
      "Guglielmo Lunardon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.15708"
  },
  {
    "id": "arXiv:2106.15711",
    "title": "RICE: Refining Instance Masks in Cluttered Environments with Graph  Neural Networks",
    "abstract": "Segmenting unseen object instances in cluttered environments is an important\ncapability that robots need when functioning in unstructured environments.\nWhile previous methods have exhibited promising results, they still tend to\nprovide incorrect results in highly cluttered scenes. We postulate that a\nnetwork architecture that encodes relations between objects at a high-level can\nbe beneficial. Thus, in this work, we propose a novel framework that refines\nthe output of such methods by utilizing a graph-based representation of\ninstance masks. We train deep networks capable of sampling smart perturbations\nto the segmentations, and a graph neural network, which can encode relations\nbetween objects, to evaluate the perturbed segmentations. Our proposed method\nis orthogonal to previous works and achieves state-of-the-art performance when\ncombined with them. We demonstrate an application that uses uncertainty\nestimates generated by our method to guide a manipulator, leading to efficient\nunderstanding of cluttered scenes. Code, models, and video can be found at\nhttps://github.com/chrisdxie/rice .",
    "descriptor": "",
    "authors": [
      "Christopher Xie",
      "Arsalan Mousavian",
      "Yu Xiang",
      "Dieter Fox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15711"
  },
  {
    "id": "arXiv:2106.15713",
    "title": "Deep Multi-Modal Contact Estimation for Invariant Observer Design on  Quadruped Robots",
    "abstract": "This work reports on developing a deep learning-based contact estimator for\nlegged robots that bypasses the need for physical contact sensors and takes\nmulti-modal proprioceptive sensory data from joint encoders, kinematics, and an\ninertial measurement unit as input. Unlike vision-based state estimators,\nproprioceptive state estimators are agnostic to perceptually degraded\nsituations such as dark or foggy scenes. For legged robots, reliable kinematics\nand contact data are necessary to develop a proprioceptive state estimator.\nWhile some robots are equipped with dedicated contact sensors or springs to\ndetect contact, some robots do not have dedicated contact sensors, and the\naddition of such sensors is non-trivial without redesigning the hardware. The\ntrained deep network can accurately estimate contacts on different terrains and\nrobot gaits and is deployed along a contact-aided invariant extended Kalman\nfilter to generate odometry trajectories. The filter performs comparably to a\nstate-of-the-art visual SLAM system.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Tzu-Yuan Lin",
      "Ray Zhang",
      "Justin Yu",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15713"
  },
  {
    "id": "arXiv:2106.15715",
    "title": "No Calm in The Storm: Investigating QAnon Website Relationships",
    "abstract": "QAnon is a far-right conspiracy theory whose followers largely organize\nonline. In this work, we use web crawls seeded from two of the largest QAnon\nhotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use\nthis graph to identify, understand, and learn from the websites that spread\nQAnon content online. We curate the largest list of QAnon centered websites to\ndate, from which we document the types of QAnon sites, their hosting providers,\nas well as their popularity. We further analyze QAnon websites' connection to\nmainstream news and misinformation online, highlighting the outsized role\nmisinformation websites play in spreading the conspiracy. Finally, we leverage\nthe observed relationship between QAnon and misinformation sites to build a\nrandom forest classifier that distinguishes between misinformation and\nauthentic news sites, getting a performance of 0.98 AUC on a test set. Our\nresults demonstrate new and effective ways to study conspiracy and\nmisinformation on the Internet.",
    "descriptor": "",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15715"
  },
  {
    "id": "arXiv:2106.15716",
    "title": "Diff2Dist: Learning Spectrally Distinct Edge Functions, with  Applications to Cell Morphology Analysis",
    "abstract": "We present a method for learning \"spectrally descriptive\" edge weights for\ngraphs. We generalize a previously known distance measure on graphs (Graph\nDiffusion Distance), thereby allowing it to be tuned to minimize an arbitrary\nloss function. Because all steps involved in calculating this modified GDD are\ndifferentiable, we demonstrate that it is possible for a small neural network\nmodel to learn edge weights which minimize loss. GDD alone does not effectively\ndiscriminate between graphs constructed from shoot apical meristem images of\nwild-type vs. mutant \\emph{Arabidopsis thaliana} specimens. However, training\nedge weights and kernel parameters with contrastive loss produces a learned\ndistance metric with large margins between these graph categories. We\ndemonstrate this by showing improved performance of a simple\nk-nearest-neighbors classifier on the learned distance matrix. We also\ndemonstrate a further application of this method to biological image analysis:\nonce trained, we use our model to compute the distance between the biological\ngraphs and a set of graphs output by a cell division simulator. This allows us\nto identify simulation parameter regimes which are similar to each class of\ngraph in our original dataset.",
    "descriptor": "",
    "authors": [
      "Cory Braker Scott",
      "Eric Mjolsness",
      "Diane Oyen",
      "Chie Kodera",
      "David Bouchez",
      "Magalie Uyttewaal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2106.15716"
  },
  {
    "id": "arXiv:2106.15718",
    "title": "HetEng: An Improved Distributed Energy Efficient Clustering Scheme for  Heterogeneous IoT Networks",
    "abstract": "Network lifetime is always a challenging issue in battery-powered networks\ndue to the difficulty of recharging or replacing nodes in some scenarios.\nClustering methods are a promising approach to tackle this challenge and\nprolong lifetime by efficiently distributing tasks among nodes in the cluster.\nThe present study aimed to improve energy consumption in heterogeneous IoT\ndevices using an energy-aware clustering method. In a heterogeneous IoT\nnetwork, nodes (i.e., battery-powered IoT devices) can have a variety of energy\nprofiles and communication capabilities. Most of the existing clustering\nalgorithms have neglected the heterogeneity of energy capacity among nodes and\nassumed that they are of the same energy level. In this work, we present\nHetEng, a Cluster Head (CH) selection process that extended an existing\nclustering algorithm, named Smart-BEEM. To this end, we proposed a statistical\napproach that distributes energy consumption among highly energetic nodes in\nthe network topology by constantly changing the CH role between the nodes based\non their real energy levels (in joules). Experimental results showed that\nHetEng resulted in a 6.6% increase of alive nodes and 3% improvement in\nresidual energy among the nodes in comparison with SmartBEEM. Moreover, our\nmethod reduced the total number of iterations by 1% on average.",
    "descriptor": "",
    "authors": [
      "Hamed Moasses",
      "Abdulbaghi Ghaderzadeh",
      "Keyhan Khamforoosh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.15718"
  },
  {
    "id": "arXiv:2106.15728",
    "title": "Detecting Errors and Estimating Accuracy on Unlabeled Data with  Self-training Ensembles",
    "abstract": "When a deep learning model is deployed in the wild, it can encounter test\ndata drawn from distributions different from the training data distribution and\nsuffer drop in performance. For safe deployment, it is essential to estimate\nthe accuracy of the pre-trained model on the test data. However, the labels for\nthe test inputs are usually not immediately available in practice, and\nobtaining them can be expensive. This observation leads to two challenging\ntasks: (1) unsupervised accuracy estimation, which aims to estimate the\naccuracy of a pre-trained classifier on a set of unlabeled test inputs; (2)\nerror detection, which aims to identify mis-classified test inputs. In this\npaper, we propose a principled and practically effective framework that\nsimultaneously addresses the two tasks. The proposed framework iteratively\nlearns an ensemble of models to identify mis-classified data points and\nperforms self-training to improve the ensemble with the identified points.\nTheoretical analysis demonstrates that our framework enjoys provable guarantees\nfor both accuracy estimation and error detection under mild conditions readily\nsatisfied by practical deep learning models. Along with the framework, we\nproposed and experimented with two instantiations and achieved state-of-the-art\nresults on 59 tasks. For example, on iWildCam, one instantiation reduces the\nestimation error for unsupervised accuracy estimation by at least 70% and\nimproves the F1 score for error detection by at least 4.7% compared to existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Jiefeng Chen",
      "Frederick Liu",
      "Besim Avci",
      "Xi Wu",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15728"
  },
  {
    "id": "arXiv:2106.15729",
    "title": "Probabilistic Control of Heterogeneous Swarms Subject to Graph Temporal  Logic Specifications: A Decentralized and Scalable Approach",
    "abstract": "We develop a probabilistic control algorithm, $\\texttt{GTLProCo}$, for swarms\nof agents with heterogeneous dynamics and objectives, subject to high-level\ntask specifications. The resulting algorithm not only achieves decentralized\ncontrol of the swarm but also significantly improves scalability over\nstate-of-the-art existing algorithms. Specifically, we study a setting in which\nthe agents move along the nodes of a graph, and the high-level task\nspecifications for the swarm are expressed in a recently-proposed language\ncalled graph temporal logic (GTL). By constraining the distribution of the\nswarm over the nodes of the graph, GTL can specify a wide range of properties,\nincluding safety, progress, and response. $\\texttt{GTLProCo}$, agnostic to the\nnumber of agents comprising the swarm, controls the density distribution of the\nswarm in a decentralized and probabilistic manner. To this end, it synthesizes\na time-varying Markov chain modeling the time evolution of the density\ndistribution under the GTL constraints. We first identify a subset of GTL,\nnamely reach-avoid specifications, for which we can reduce the synthesis of\nsuch a Markov chain to either linear or semi-definite programs. Then, in the\ngeneral case, we formulate the synthesis of the Markov chain as a mixed-integer\nnonlinear program (MINLP). We exploit the structure of the problem to provide\nan efficient sequential mixed-integer linear programming scheme with trust\nregions to solve the MINLP. We empirically demonstrate that our sequential\nscheme is at least three orders of magnitude faster than off-the-shelf MINLP\nsolvers and illustrate the effectiveness of $\\texttt{GTLProCo}$ in several\nswarm scenarios.",
    "descriptor": "\nComments: Initial submission to TAC\n",
    "authors": [
      "Franck Djeumou",
      "Zhe Xu",
      "Murat Cubuktepe",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.15729"
  },
  {
    "id": "arXiv:2106.15731",
    "title": "Near-Optimal Deterministic Single-Source Distance Sensitivity Oracles",
    "abstract": "Given a graph with a source vertex $s$, the Single Source Replacement Paths\n(SSRP) problem is to compute, for every vertex $t$ and edge $e$, the length\n$d(s,t,e)$ of a shortest path from $s$ to $t$ that avoids $e$. A Single-Source\nDistance Sensitivity Oracle (Single-Source DSO) is a data structure that\nanswers queries of the form $(t,e)$ by returning the distance $d(s,t,e)$. We\nshow how to deterministically compress the output of the SSRP problem on\n$n$-vertex, $m$-edge graphs with integer edge weights in the range $[1,M]$ into\na Single-Source DSO of size $O(M^{1/2}n^{3/2})$ with query time\n$\\widetilde{O}(1)$. The space requirement is optimal (up to the word size) and\nour techniques can also handle vertex failures.\nChechik and Cohen [SODA 2019] presented a combinatorial, randomized\n$\\widetilde{O}(m\\sqrt{n}+n^2)$ time SSRP algorithm for undirected and\nunweighted graphs. Grandoni and Vassilevska Williams [FOCS 2012, TALG 2020]\ngave an algebraic, randomized $\\widetilde{O}(Mn^\\omega)$ time SSRP algorithm\nfor graphs with integer edge weights in the range $[1,M]$, where $\\omega<2.373$\nis the matrix multiplication exponent. We derandomize both algorithms for\nundirected graphs in the same asymptotic running time and apply our compression\nto obtain deterministic Single-Source DSOs. The $\\widetilde{O}(m\\sqrt{n}+n^2)$\nand $\\widetilde{O}(Mn^\\omega)$ preprocessing times are polynomial improvements\nover previous $o(n^2)$-space oracles.\nOn sparse graphs with $m=O(n^{5/4-\\varepsilon}/M^{7/4})$ edges, for any\nconstant $\\varepsilon > 0$, we reduce the preprocessing to randomized\n$\\widetilde{O}(M^{7/8}m^{1/2}n^{11/8})=O(n^{2-\\varepsilon/2})$ time. This is\nthe first truly subquadratic time algorithm for building Single-Source DSOs on\nsparse graphs.",
    "descriptor": "\nComments: Full version of a paper to appear at ESA 2021. Abstract shortened to meet ArXiv requirements\n",
    "authors": [
      "Davide Bil\u00f2",
      "Sarel Cohen",
      "Tobias Friedrich",
      "Martin Schirneck"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15731"
  },
  {
    "id": "arXiv:2106.15734",
    "title": "UAV-assisted Online Machine Learning over Multi-Tiered Networks: A  Hierarchical Nested Personalized Federated Learning Approach",
    "abstract": "We consider distributed machine learning (ML) through unmanned aerial\nvehicles (UAVs) for geo-distributed device clusters. We propose five new\ntechnologies/techniques: (i) stratified UAV swarms with leader, worker, and\ncoordinator UAVs, (ii) hierarchical nested personalized federated learning\n(HN-PFL): a holistic distributed ML framework for personalized model training\nacross the worker-leader-core network hierarchy, (iii) cooperative UAV resource\npooling for distributed ML using the UAVs' local computational capabilities,\n(iv) aerial data caching and relaying for efficient data relaying to conduct\nML, and (v) concept/model drift, capturing online data variations at the\ndevices. We split the UAV-enabled model training problem as two parts. (a)\nNetwork-aware HN-PFL, where we optimize a tradeoff between energy consumption\nand ML model performance by configuring data offloading among devices-UAVs and\nUAV-UAVs, UAVs' CPU frequencies, and mini-batch sizes subject to\ncommunication/computation network heterogeneity. We tackle this optimization\nproblem via the method of posynomial condensation and propose a distributed\nalgorithm with a performance guarantee. (b) Macro-trajectory and learning\nduration design, which we formulate as a sequential decision making problem,\ntackled via deep reinforcement learning. Our simulations demonstrate the\nsuperiority of our methodology with regards to the distributed ML performance,\nthe optimization of network resources, and the swarm trajectory efficiency.",
    "descriptor": "",
    "authors": [
      "Su Wang",
      "Seyyedali Hosseinalipour",
      "Maria Gorlatova",
      "Christopher G. Brinton",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15734"
  },
  {
    "id": "arXiv:2106.15739",
    "title": "On the Periodic Behavior of Neural Network Training with Batch  Normalization and Weight Decay",
    "abstract": "Despite the conventional wisdom that using batch normalization with weight\ndecay may improve neural network training, some recent works show their joint\nusage may cause instabilities at the late stages of training. Other works, in\ncontrast, show convergence to the equilibrium, i.e., the stabilization of\ntraining metrics. In this paper, we study this contradiction and show that\ninstead of converging to a stable equilibrium, the training dynamics converge\nto consistent periodic behavior. That is, the training process regularly\nexhibits instabilities which, however, do not lead to complete training\nfailure, but cause a new period of training. We rigorously investigate the\nmechanism underlying this discovered periodic behavior both from an empirical\nand theoretical point of view and show that this periodic behavior is indeed\ncaused by the interaction between batch normalization and weight decay.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Ekaterina Lobacheva",
      "Maxim Kodryan",
      "Nadezhda Chirkova",
      "Andrey Malinin",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15739"
  },
  {
    "id": "arXiv:2106.15746",
    "title": "($S$,$N$,$T$)-Implications",
    "abstract": "In this paper we introduce a new class of fuzzy implications called\n($S$,$N$,$T$)-implications inspired in the logical equivalence $p\\rightarrow q\n\\equiv \\neg(p\\wedge\\neg q)\\vee\\neg p$ and present a brief study of some of the\nmain properties that characterize this class. We present methods of obtaining\n$t$-norms and $t$-conorms from an ($S$,$N$,$T$)-implication and a fuzzy\nnegation.",
    "descriptor": "",
    "authors": [
      "Fernando Neres",
      "Benjam\u00edn Bedregal",
      "Regivan H. N. Santiago"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.15746"
  },
  {
    "id": "arXiv:2106.15754",
    "title": "Looking Outside the Window: Wider-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "abstract": "Long-range context information is crucial for the semantic segmentation of\nHigh-Resolution (HR) Remote Sensing Images (RSIs). The image cropping\noperations, commonly used for training neural networks, limit the perception of\nlong-range context information in large RSIs. To break this limitation, we\npropose a Wider-Context Network (WiCNet) for the semantic segmentation of HR\nRSIs. In the WiCNet, apart from a conventional feature extraction network to\naggregate the local information, an extra context branch is designed to\nexplicitly model the context information in a larger image area. The\ninformation between the two branches is communicated through a Context\nTransformer, which is a novel design derived from the Vision Transformer to\nmodel the long-range context correlations. Ablation studies and comparative\nexperiments conducted on several benchmark datasets prove the effectiveness of\nthe proposed method. Additionally, we present a new Beijing Land-Use (BLU)\ndataset. This is a large-scale HR satellite dataset provided with high-quality\nand fine-grained reference labels, which we hope will boost future studies in\nthis field.",
    "descriptor": "",
    "authors": [
      "Lei Ding",
      "Dong Lin",
      "Shaofu Lin",
      "Jing Zhang",
      "Xiaojie Cui",
      "Yuebin Wang",
      "Hao Tang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15754"
  },
  {
    "id": "arXiv:2106.15755",
    "title": "Dual GNNs: Graph Neural Network Learning with Limited Supervision",
    "abstract": "Graph Neural Networks (GNNs) require a relatively large number of labeled\nnodes and a reliable/uncorrupted graph connectivity structure in order to\nobtain good performance on the semi-supervised node classification task. The\nperformance of GNNs can degrade significantly as the number of labeled nodes\ndecreases or the graph connectivity structure is corrupted by adversarial\nattacks or due to noises in data measurement /collection. Therefore, it is\nimportant to develop GNN models that are able to achieve good performance when\nthere is limited supervision knowledge -- a few labeled nodes and noisy graph\nstructures. In this paper, we propose a novel Dual GNN learning framework to\naddress this challenge task. The proposed framework has two GNN based node\nprediction modules. The primary module uses the input graph structure to induce\nregular node embeddings and predictions with a regular GNN baseline, while the\nauxiliary module constructs a new graph structure through fine-grained spectral\nclusterings and learns new node embeddings and predictions. By integrating the\ntwo modules in a dual GNN learning framework, we perform joint learning in an\nend-to-end fashion. This general framework can be applied on many GNN baseline\nmodels. The experimental results validate that the proposed dual GNN framework\ncan greatly outperform the GNN baseline methods when the labeled nodes are\nscarce and the graph connectivity structure is noisy.",
    "descriptor": "",
    "authors": [
      "Abdullah Alchihabi",
      "Yuhong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15755"
  },
  {
    "id": "arXiv:2106.15760",
    "title": "A Conditional Splitting Framework for Efficient Constituency Parsing",
    "abstract": "We introduce a generic seq2seq parsing framework that casts constituency\nparsing problems (syntactic and discourse parsing) into a series of conditional\nsplitting decisions. Our parsing model estimates the conditional probability\ndistribution of possible splitting points in a given text span and supports\nefficient top-down decoding, which is linear in number of nodes. The\nconditional splitting formulation together with efficient beam search inference\nfacilitate structural consistency without relying on expensive structured\ninference. Crucially, for discourse analysis we show that in our formulation,\ndiscourse segmentation can be framed as a special case of parsing which allows\nus to perform discourse parsing without requiring segmentation as a\npre-requisite. Experiments show that our model achieves good results on the\nstandard syntactic parsing tasks under settings with/without pre-trained\nrepresentations and rivals state-of-the-art (SoTA) methods that are more\ncomputationally expensive than ours. In discourse parsing, our method\noutperforms SoTA by a good margin.",
    "descriptor": "\nComments: Accepted to ACL2021\n",
    "authors": [
      "Thanh-Tung Nguyen",
      "Xuan-Phi Nguyen",
      "Shafiq Joty",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15760"
  },
  {
    "id": "arXiv:2106.15762",
    "title": "Curvature Graph Neural Network",
    "abstract": "Graph neural networks (GNNs) have achieved great success in many graph-based\ntasks. Much work is dedicated to empowering GNNs with the adaptive locality\nability, which enables measuring the importance of neighboring nodes to the\ntarget node by a node-specific mechanism. However, the current node-specific\nmechanisms are deficient in distinguishing the importance of nodes in the\ntopology structure. We believe that the structural importance of neighboring\nnodes is closely related to their importance in aggregation. In this paper, we\nintroduce discrete graph curvature (the Ricci curvature) to quantify the\nstrength of structural connection of pairwise nodes. And we propose Curvature\nGraph Neural Network (CGNN), which effectively improves the adaptive locality\nability of GNNs by leveraging the structural property of graph curvature. To\nimprove the adaptability of curvature to various datasets, we explicitly\ntransform curvature into the weights of neighboring nodes by the necessary\nNegative Curvature Processing Module and Curvature Normalization Module. Then,\nwe conduct numerous experiments on various synthetic datasets and real-world\ndatasets. The experimental results on synthetic datasets show that CGNN\neffectively exploits the topology structure information, and the performance is\nimproved significantly. CGNN outperforms the baselines on 5 dense node\nclassification benchmark datasets. This study deepens the understanding of how\nto utilize advanced topology information and assign the importance of\nneighboring nodes from the perspective of graph curvature and encourages us to\nbridge the gap between graph theory and neural networks.",
    "descriptor": "\nComments: 16 Pages, 9 figures, 4 tables\n",
    "authors": [
      "Haifeng Li",
      "Jun Cao",
      "Jiawei Zhu",
      "Yu Liu",
      "Qing Zhu",
      "Guohua Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15762"
  },
  {
    "id": "arXiv:2106.15764",
    "title": "The Threat of Offensive AI to Organizations",
    "abstract": "AI has provided us with the ability to automate tasks, extract information\nfrom vast amounts of data, and synthesize media that is nearly\nindistinguishable from the real thing. However, positive tools can also be used\nfor negative purposes. In particular, cyber adversaries can use AI (such as\nmachine learning) to enhance their attacks and expand their campaigns.\nAlthough offensive AI has been discussed in the past, there is a need to\nanalyze and understand the threat in the context of organizations. For example,\nhow does an AI-capable adversary impact the cyber kill chain? Does AI benefit\nthe attacker more than the defender? What are the most significant AI threats\nfacing organizations today and what will be their impact on the future?\nIn this survey, we explore the threat of offensive AI on organizations.\nFirst, we present the background and discuss how AI changes the adversary's\nmethods, strategies, goals, and overall attack model. Then, through a\nliterature review, we identify 33 offensive AI capabilities which adversaries\ncan use to enhance their attacks. Finally, through a user study spanning\nindustry and academia, we rank the AI threats and provide insights on the\nadversaries.",
    "descriptor": "",
    "authors": [
      "Yisroel Mirsky",
      "Ambra Demontis",
      "Jaidip Kotak",
      "Ram Shankar",
      "Deng Gelei",
      "Liu Yang",
      "Xiangyu Zhang",
      "Wenke Lee",
      "Yuval Elovici",
      "Battista Biggio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15764"
  },
  {
    "id": "arXiv:2106.15767",
    "title": "Unaware Fairness: Hierarchical Random Forest for Protected Classes",
    "abstract": "Procedural fairness has been a public concern, which leads to controversy\nwhen making decisions with respect to protected classes, such as race, social\nstatus, and disability. Some protected classes can be inferred according to\nsome safe proxies like surname and geolocation for the race. Hence, implicitly\nutilizing the predicted protected classes based on the related proxies when\nmaking decisions is an efficient approach to circumvent this issue and seek\njust decisions. In this article, we propose a hierarchical random forest model\nfor prediction without explicitly involving protected classes. Simulation\nexperiments are conducted to show the performance of the hierarchical random\nforest model. An example is analyzed from Boston police interview records to\nillustrate the usefulness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Xian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.15767"
  },
  {
    "id": "arXiv:2106.15772",
    "title": "A Diverse Corpus for Evaluating and Developing English Math Word Problem  Solvers",
    "abstract": "We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms\nof both language patterns and problem types) English math word problem (MWP)\ncorpus for evaluating the capability of various MWP solvers. Existing MWP\ncorpora for studying AI progress remain limited either in language usage\npatterns or in problem types. We thus present a new English MWP corpus with\n2,305 MWPs that cover more text patterns and most problem types taught in\nelementary school. Each MWP is annotated with its problem type and grade level\n(for indicating the level of difficulty). Furthermore, we propose a metric to\nmeasure the lexicon usage diversity of a given MWP corpus, and demonstrate that\nASDiv is more diverse than existing corpora. Experiments show that our proposed\ncorpus reflects the true capability of MWP solvers more faithfully.",
    "descriptor": "\nComments: ACL-2020\n",
    "authors": [
      "Shen-Yun Miao",
      "Chao-Chun Liang",
      "Keh-Yih Su"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15772"
  },
  {
    "id": "arXiv:2106.15773",
    "title": "Online Offloading Scheduling for NOMA-Aided MEC Under Partial Device  Knowledge",
    "abstract": "By exploiting the superiority of non-orthogonal multiple access (NOMA),\nNOMA-aided mobile edge computing (MEC) can provide scalable and low-latency\ncomputing services for the Internet of Things. However, given the prevalent\nstochasticity of wireless networks and sophisticated signal processing of NOMA,\nit is critical but challenging to design an efficient task offloading algorithm\nfor NOMA-aided MEC, especially under a large number of devices. This paper\npresents an online algorithm that jointly optimizes offloading decisions and\nresource allocation to maximize the long-term system utility (i.e., a measure\nof throughput and fairness). Since the optimization variables are temporary\ncoupled, we first apply Lyapunov technique to decouple the long-term stochastic\noptimization into a series of per-slot deterministic subproblems, which does\nnot require any prior knowledge of network dynamics. Second, we propose to\ntransform the non-convex per-slot subproblem of optimizing NOMA power\nallocation equivalently to a convex form by introducing a set of auxiliary\nvariables, whereby the time-complexity is reduced from the exponential\ncomplexity to $\\mathcal{O} (M^{3/2})$. The proposed algorithm is proved to be\nasymptotically optimal, even under partial knowledge of the device states at\nthe base station. Simulation results validate the superiority of the proposed\nalgorithm in terms of system utility, stability improvement, and the overhead\nreduction.",
    "descriptor": "\nComments: 15 pages, 6 figures. Accepted for publication in IEEE Internet of Things Journal\n",
    "authors": [
      "Meihui Hua",
      "Hui Tian",
      "Xinchen Lyu",
      "Wanli Ni",
      "Gaofeng Nie"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.15773"
  },
  {
    "id": "arXiv:2106.15775",
    "title": "Koopman Spectrum Nonlinear Regulator and Provably Efficient Online  Learning",
    "abstract": "Most modern reinforcement learning algorithms optimize a cumulative\nsingle-step cost along a trajectory. The optimized motions are often\n'unnatural', representing, for example, behaviors with sudden accelerations\nthat waste energy and lack predictability. In this work, we present a novel\nparadigm of controlling nonlinear systems via the minimization of the Koopman\nspectrum cost: a cost over the Koopman operator of the controlled dynamics.\nThis induces a broader class of dynamical behaviors that evolve over stable\nmanifolds such as nonlinear oscillators, closed loops, and smooth movements. We\ndemonstrate that some dynamics realizations that are not possible with a\ncumulative cost are feasible in this paradigm. Moreover, we present a provably\nefficient online learning algorithm for our problem that enjoys a sub-linear\nregret bound under some structural assumptions.",
    "descriptor": "",
    "authors": [
      "Motoya Ohnishi",
      "Isao Ishikawa",
      "Kendall Lowrey",
      "Masahiro Ikeda",
      "Sham Kakade",
      "Yoshinobu Kawahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15775"
  },
  {
    "id": "arXiv:2106.15776",
    "title": "Local Reweighting for Adversarial Training",
    "abstract": "Instances-reweighted adversarial training (IRAT) can significantly boost the\nrobustness of trained models, where data being less/more vulnerable to the\ngiven attack are assigned smaller/larger weights during training. However, when\ntested on attacks different from the given attack simulated in training, the\nrobustness may drop significantly (e.g., even worse than no reweighting). In\nthis paper, we study this problem and propose our solution--locally reweighted\nadversarial training (LRAT). The rationale behind IRAT is that we do not need\nto pay much attention to an instance that is already safe under the attack. We\nargue that the safeness should be attack-dependent, so that for the same\ninstance, its weight can change given different attacks based on the same\nmodel. Thus, if the attack simulated in training is mis-specified, the weights\nof IRAT are misleading. To this end, LRAT pairs each instance with its\nadversarial variants and performs local reweighting inside each pair, while\nperforming no global reweighting--the rationale is to fit the instance itself\nif it is immune to the attack, but not to skip the pair, in order to passively\ndefend different attacks in future. Experiments show that LRAT works better\nthan both IRAT (i.e., global reweighting) and the standard AT (i.e., no\nreweighting) when trained with an attack and tested on different attacks.",
    "descriptor": "",
    "authors": [
      "Ruize Gao",
      "Feng Liu",
      "Kaiwen Zhou",
      "Gang Niu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15776"
  },
  {
    "id": "arXiv:2106.15778",
    "title": "Dense Graph Convolutional Neural Networks on 3D Meshes for 3D Object  Segmentation and Classification",
    "abstract": "This paper presents new designs of graph convolutional neural networks (GCNs)\non 3D meshes for 3D object segmentation and classification. We use the faces of\nthe mesh as basic processing units and represent a 3D mesh as a graph where\neach node corresponds to a face. To enhance the descriptive power of the graph,\nwe introduce a 1-ring face neighbourhood structure to derive novel\nmulti-dimensional spatial and structure features to represent the graph nodes.\nBased on this new graph representation, we then design a densely connected\ngraph convolutional block which aggregates local and regional features as the\nkey construction component to build effective and efficient practical GCN\nmodels for 3D object classification and segmentation. We will present\nexperimental results to show that our new technique outperforms state of the\nart where our models are shown to have the smallest number of parameters and\nconsietently achieve the highest accuracies across a number of benchmark\ndatasets. We will also present ablation studies to demonstrate the soundness of\nour design principles and the effectiveness of our practical models.",
    "descriptor": "",
    "authors": [
      "Wenming Tang Guoping Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.15778"
  },
  {
    "id": "arXiv:2106.15779",
    "title": "Dual Adversarial Variational Embedding for Robust Recommendation",
    "abstract": "Robust recommendation aims at capturing true preference of users from noisy\ndata, for which there are two lines of methods have been proposed. One is based\non noise injection, and the other is to adopt the generative model Variational\nAuto-encoder (VAE). However, the existing works still face two challenges.\nFirst, the noise injection based methods often draw the noise from a fixed\nnoise distribution given in advance, while in real world, the noise\ndistributions of different users and items may differ from each other due to\npersonal behaviors and item usage patterns. Second, the VAE based models are\nnot expressive enough to capture the true preference since VAE often yields an\nembedding space of a single modal, while in real world, user-item interactions\nusually exhibit multi-modality on user preference distribution. In this paper,\nwe propose a novel model called Dual Adversarial Variational Embedding (DAVE)\nfor robust recommendation, which can provide personalized noise reduction for\ndifferent users and items, and capture the multi-modality of the embedding\nspace, by combining the advantages of VAE and adversarial training between the\nintroduced auxiliary discriminators and the variational inference networks. The\nextensive experiments conducted on real datasets verify the effectiveness of\nDAVE on robust recommendation.",
    "descriptor": "",
    "authors": [
      "Qiaomin Yi",
      "Ning Yang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.15779"
  },
  {
    "id": "arXiv:2106.15780",
    "title": "Constructing the space of valuations of a quasi-Polish space as a space  of ideals",
    "abstract": "We construct the space of valuations on a quasi-Polish space in terms of the\ncharacterization of quasi-Polish spaces as spaces of ideals of a countable\ntransitive relation. Our construction is closely related to domain theoretical\nwork on the probabilistic powerdomain, and helps illustrate the connections\nbetween domain theory and quasi-Polish spaces. Our approach is consistent with\nprevious work on computable measures, and can be formalized within weak formal\nsystems, such as subsystems of second order arithmetic.",
    "descriptor": "",
    "authors": [
      "Matthew de Brecht"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.15780"
  },
  {
    "id": "arXiv:2106.15787",
    "title": "Long-Short Temporal Modeling for Efficient Action Recognition",
    "abstract": "Efficient long-short temporal modeling is key for enhancing the performance\nof action recognition task. In this paper, we propose a new two-stream action\nrecognition network, termed as MENet, consisting of a Motion Enhancement (ME)\nmodule and a Video-level Aggregation (VLA) module to achieve long-short\ntemporal modeling. Specifically, motion representations have been proved\neffective in capturing short-term and high-frequency action. However, current\nmotion representations are calculated from adjacent frames, which may have poor\ninterpretation and bring useless information (noisy or blank). Thus, for\nshort-term motions, we design an efficient ME module to enhance the short-term\nmotions by mingling the motion saliency among neighboring segments. As for\nlong-term aggregations, VLA is adopted at the top of the appearance branch to\nintegrate the long-term dependencies across all segments. The two components of\nMENet are complementary in temporal modeling. Extensive experiments are\nconducted on UCF101 and HMDB51 benchmarks, which verify the effectiveness and\nefficiency of our proposed MENet.",
    "descriptor": "\nComments: Accepted by ICASSP 2021\n",
    "authors": [
      "Liyu Wu",
      "Yuexian Zou",
      "Can Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15787"
  },
  {
    "id": "arXiv:2106.15788",
    "title": "Align Yourself: Self-supervised Pre-training for Fine-grained  Recognition via Saliency Alignment",
    "abstract": "Self-supervised contrastive learning has demonstrated great potential in\nlearning visual representations. Despite their success on various downstream\ntasks such as image classification and object detection, self-supervised\npre-training for fine-grained scenarios is not fully explored. In this paper,\nwe first point out that current contrastive methods are prone to memorizing\nbackground/foreground texture and therefore have a limitation in localizing the\nforeground object. Analysis suggests that learning to extract discriminative\ntexture information and localization are equally crucial for self-supervised\npre-training under fine-grained scenarios. Based on our findings, we introduce\nCross-view Saliency Alignment (CVSA), a contrastive learning framework that\nfirst crops and swaps saliency regions of images as a novel view generation and\nthen guides the model to localize on the foreground object via a cross-view\nalignment loss. Extensive experiments on four popular fine-grained\nclassification benchmarks show that CVSA significantly improves the learned\nrepresentation.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Zelin Zang",
      "Kai Wang",
      "Lei Shang",
      "Baigui Sun",
      "Hao Li",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15788"
  },
  {
    "id": "arXiv:2106.15791",
    "title": "Distributionally Robust Learning with Stable Adversarial Training",
    "abstract": "Machine learning algorithms with empirical risk minimization are vulnerable\nunder distributional shifts due to the greedy adoption of all the correlations\nfound in training data. There is an emerging literature on tackling this\nproblem by minimizing the worst-case risk over an uncertainty set. However,\nexisting methods mostly construct ambiguity sets by treating all variables\nequally regardless of the stability of their correlations with the target,\nresulting in the overwhelmingly-large uncertainty set and low confidence of the\nlearner. In this paper, we propose a novel Stable Adversarial Learning (SAL)\nalgorithm that leverages heterogeneous data sources to construct a more\npractical uncertainty set and conduct differentiated robustness optimization,\nwhere covariates are differentiated according to the stability of their\ncorrelations with the target. We theoretically show that our method is\ntractable for stochastic gradient-based optimization and provide the\nperformance guarantees for our method. Empirical studies on both simulation and\nreal datasets validate the effectiveness of our method in terms of uniformly\ngood performance across unknown distributional shifts.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.04414\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyan Shen",
      "Peng Cui",
      "Linjun Zhou",
      "Kun Kuang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15791"
  },
  {
    "id": "arXiv:2106.15792",
    "title": "Learning Bounds for Open-Set Learning",
    "abstract": "Traditional supervised learning aims to train a classifier in the closed-set\nworld, where training and test samples share the same label space. In this\npaper, we target a more challenging and realistic setting: open-set learning\n(OSL), where there exist test samples from the classes that are unseen during\ntraining. Although researchers have designed many methods from the algorithmic\nperspectives, there are few methods that provide generalization guarantees on\ntheir ability to achieve consistent performance on different training samples\ndrawn from the same distribution. Motivated by the transfer learning and\nprobably approximate correct (PAC) theory, we make a bold attempt to study OSL\nby proving its generalization error-given training samples with size n, the\nestimation error will get close to order O_p(1/\\sqrt{n}). This is the first\nstudy to provide a generalization bound for OSL, which we do by theoretically\ninvestigating the risk of the target classifier on unknown classes. According\nto our theory, a novel algorithm, called auxiliary open-set risk (AOSR) is\nproposed to address the OSL problem. Experiments verify the efficacy of AOSR.\nThe code is available at github.com/Anjin-Liu/Openset_Learning_AOSR.",
    "descriptor": "\nComments: Open-set Learning, Open-set Recognition, Machine Learning Theory\n",
    "authors": [
      "Zhen Fang",
      "Jie Lu",
      "Anjin Liu",
      "Feng Liu",
      "Guangquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15792"
  },
  {
    "id": "arXiv:2106.15793",
    "title": "Multi-Source Domain Adaptation for Object Detection",
    "abstract": "To reduce annotation labor associated with object detection, an increasing\nnumber of studies focus on transferring the learned knowledge from a labeled\nsource domain to another unlabeled target domain. However, existing methods\nassume that the labeled data are sampled from a single source domain, which\nignores a more generalized scenario, where labeled data are from multiple\nsource domains. For the more challenging task, we propose a unified Faster\nR-CNN based framework, termed Divide-and-Merge Spindle Network (DMSN), which\ncan simultaneously enhance domain invariance and preserve discriminative power.\nSpecifically, the framework contains multiple source subnets and a pseudo\ntarget subnet. First, we propose a hierarchical feature alignment strategy to\nconduct strong and weak alignments for low- and high-level features,\nrespectively, considering their different effects for object detection. Second,\nwe develop a novel pseudo subnet learning algorithm to approximate optimal\nparameters of pseudo target subset by weighted combination of parameters in\ndifferent source subnets. Finally, a consistency regularization for region\nproposal network is proposed to facilitate each subnet to learn more abstract\ninvariances. Extensive experiments on different adaptation scenarios\ndemonstrate the effectiveness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Xingxu Yao",
      "Sicheng Zhao",
      "Pengfei Xu",
      "Jufeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15793"
  },
  {
    "id": "arXiv:2106.15796",
    "title": "Monocular 3D Object Detection: An Extrinsic Parameter Free Approach",
    "abstract": "Monocular 3D object detection is an important task in autonomous driving. It\ncan be easily intractable where there exists ego-car pose change w.r.t. ground\nplane. This is common due to the slight fluctuation of road smoothness and\nslope. Due to the lack of insight in industrial application, existing methods\non open datasets neglect the camera pose information, which inevitably results\nin the detector being susceptible to camera extrinsic parameters. The\nperturbation of objects is very popular in most autonomous driving cases for\nindustrial products. To this end, we propose a novel method to capture camera\npose to formulate the detector free from extrinsic perturbation. Specifically,\nthe proposed framework predicts camera extrinsic parameters by detecting\nvanishing point and horizon change. A converter is designed to rectify\nperturbative features in the latent space. By doing so, our 3D detector works\nindependent of the extrinsic parameter variations and produces accurate results\nin realistic cases, e.g., potholed and uneven roads, where almost all existing\nmonocular detectors fail to handle. Experiments demonstrate our method yields\nthe best performance compared with the other state-of-the-arts by a large\nmargin on both KITTI 3D and nuScenes datasets.",
    "descriptor": "",
    "authors": [
      "Yunsong Zhou",
      "Yuan He",
      "Hongzi Zhu",
      "Cheng Wang",
      "Hongyang Li",
      "Qinhong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15796"
  },
  {
    "id": "arXiv:2106.15797",
    "title": "Content-Aware Convolutional Neural Networks",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved great success due to the\npowerful feature learning ability of convolution layers. Specifically, the\nstandard convolution traverses the input images/features using a sliding window\nscheme to extract features. However, not all the windows contribute equally to\nthe prediction results of CNNs. In practice, the convolutional operation on\nsome of the windows (e.g., smooth windows that contain very similar pixels) can\nbe very redundant and may introduce noises into the computation. Such\nredundancy may not only deteriorate the performance but also incur the\nunnecessary computational cost. Thus, it is important to reduce the\ncomputational redundancy of convolution to improve the performance. To this\nend, we propose a Content-aware Convolution (CAC) that automatically detects\nthe smooth windows and applies a 1x1 convolutional kernel to replace the\noriginal large kernel. In this sense, we are able to effectively avoid the\nredundant computation on similar pixels. By replacing the standard convolution\nin CNNs with our CAC, the resultant models yield significantly better\nperformance and lower computational cost than the baseline models with the\nstandard convolution. More critically, we are able to dynamically allocate\nsuitable computation resources according to the data smoothness of different\nimages, making it possible for content-aware computation. Extensive experiments\non various computer vision tasks demonstrate the superiority of our method over\nexisting methods.",
    "descriptor": "\nComments: To appear in Neural Networks\n",
    "authors": [
      "Yong Guo",
      "Yaofo Chen",
      "Mingkui Tan",
      "Kui Jia",
      "Jian Chen",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15797"
  },
  {
    "id": "arXiv:2106.15801",
    "title": "Frequency-Constrained Resilient Scheduling of Microgrid: A  Distributionally Robust Approach",
    "abstract": "In order to prevent the potential frequency instability due to the high Power\nElectronics (PE) penetration under an unintentional islanding event, this paper\npresents a novel microgrid scheduling model which explicitly models the system\nfrequency dynamics as well as the long/short term uncertainty associated with\nrenewable energy resources and load. Synthetic Inertia (SI) control is applied\nto regulating the active power output of the Inverter-Based Generators (IBGs)\nto support the post-islanding frequency evaluation. The uncertainty associated\nwith the noncritical load shedding is explicitly modeled based on the\ndistributionally robust formulation to ensure resilient operation during\nislanding events. The resulted frequency constraints are derived analytically\nand reformulated into Second-Order Cone (SOC) form, which are further\nincorporated into the microgrid scheduling model, enabling optimal SI provision\nof Renewable Energy Sources (RESs) from the micorgrid perspective. With the SOC\nrelaxation of the AC power flow constraints, the overall problem is constructed\nas a mixed-integer SOC Programming (MISOCP). The effectiveness of the proposed\nmodel is demonstrated based on modified IEEE 14-bus system.",
    "descriptor": "",
    "authors": [
      "Zhongda Chu",
      "Ning Zhang",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15801"
  },
  {
    "id": "arXiv:2106.15802",
    "title": "CityNet: A Multi-city Multi-modal Dataset for Smart City Applications",
    "abstract": "Data-driven approaches have been applied to many problems in urban computing.\nHowever, in the research community, such approaches are commonly studied under\ndata from limited sources, and are thus unable to characterize the complexity\nof urban data coming from multiple entities and the correlations among them.\nConsequently, an inclusive and multifaceted dataset is necessary to facilitate\nmore extensive studies on urban computing. In this paper, we present CityNet, a\nmulti-modal urban dataset containing data from 7 cities, each of which coming\nfrom 3 data sources. We first present the generation process of CityNet as well\nas its basic properties. In addition, to facilitate the use of CityNet, we\ncarry out extensive machine learning experiments, including spatio-temporal\npredictions, transfer learning, and reinforcement learning. The experimental\nresults not only provide benchmarks for a wide range of tasks and methods, but\nalso uncover internal correlations among cities and tasks within CityNet that,\nwith adequate leverage, can improve performances on various tasks. With the\nbenchmarking results and the correlations uncovered, we believe that CityNet\ncan contribute to the field of urban computing by supporting research on many\nadvanced topics.",
    "descriptor": "",
    "authors": [
      "Xu Geng",
      "Yilun Jin",
      "Zhengfei Zheng",
      "Yu Yang",
      "Yexin Li",
      "Han Tian",
      "Peibo Duan",
      "Leye Wang",
      "Jiannong Cao",
      "Hai Yang",
      "Qiang Yang",
      "Kai Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15802"
  },
  {
    "id": "arXiv:2106.15808",
    "title": "Optimal Epidemic Control as a Contextual Combinatorial Bandit with  Budget",
    "abstract": "In light of the COVID-19 pandemic, it is an open challenge and critical\npractical problem to find a optimal way to dynamically prescribe the best\npolicies that balance both the governmental resources and epidemic control in\ndifferent countries and regions. To solve this multi-dimensional tradeoff of\nexploitation and exploration, we formulate this technical challenge as a\ncontextual combinatorial bandit problem that jointly optimizes a multi-criteria\nreward function. Given the historical daily cases in a region and the past\nintervention plans in place, the agent should generate useful intervention\nplans that policy makers can implement in real time to minimizing both the\nnumber of daily COVID-19 cases and the stringency of the recommended\ninterventions. We prove this concept with simulations of multiple realistic\npolicy making scenarios.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1906.09384 by other authors\n",
    "authors": [
      "Baihan Lin",
      "Djallel Bouneffouf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15808"
  },
  {
    "id": "arXiv:2106.15810",
    "title": "Edge Proposal Sets for Link Prediction",
    "abstract": "Graphs are a common model for complex relational data such as social networks\nand protein interactions, and such data can evolve over time (e.g., new\nfriendships) and be noisy (e.g., unmeasured interactions). Link prediction aims\nto predict future edges or infer missing edges in the graph, and has diverse\napplications in recommender systems, experimental design, and complex systems.\nEven though link prediction algorithms strongly depend on the set of edges in\nthe graph, existing approaches typically do not modify the graph topology to\nimprove performance. Here, we demonstrate how simply adding a set of edges,\nwhich we call a \\emph{proposal set}, to the graph as a pre-processing step can\nimprove the performance of several link prediction algorithms. The underlying\nidea is that if the edges in the proposal set generally align with the\nstructure of the graph, link prediction algorithms are further guided towards\npredicting the right edges; in other words, adding a proposal set of edges is a\nsignal-boosting pre-processing step. We show how to use existing link\nprediction algorithms to generate effective proposal sets and evaluate this\napproach on various synthetic and empirical datasets. We find that proposal\nsets meaningfully improve the accuracy of link prediction algorithms based on\nboth neighborhood heuristics and graph neural networks. Code is available at\n\\url{https://github.com/CUAI/Edge-Proposal-Sets}.",
    "descriptor": "",
    "authors": [
      "Abhay Singh",
      "Qian Huang",
      "Sijia Linda Huang",
      "Omkar Bhalerao",
      "Horace He",
      "Ser-Nam Lim",
      "Austin R. Benson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15810"
  },
  {
    "id": "arXiv:2106.15814",
    "title": "Discovering Collaborative Signals for Next POI Recommendation with  Iterative Seq2Graph Augmentation",
    "abstract": "Being an indispensable component in location-based social networks, next\npoint-of-interest (POI) recommendation recommends users unexplored POIs based\non their recent visiting histories. However, existing work mainly models\ncheck-in data as isolated POI sequences, neglecting the crucial collaborative\nsignals from cross-sequence check-in information. Furthermore, the sparse\nPOI-POI transitions restrict the ability of a model to learn effective\nsequential patterns for recommendation. In this paper, we propose\nSequence-to-Graph (Seq2Graph) augmentation for each POI sequence, allowing\ncollaborative signals to be propagated from correlated POIs belonging to other\nsequences. We then devise a novel Sequence-to-Graph POI Recommender (SGRec),\nwhich jointly learns POI embeddings and infers a user's temporal preferences\nfrom the graph-augmented POI sequence. To overcome the sparsity of POI-level\ninteractions, we further infuse category-awareness into SGRec with a multi-task\nlearning scheme that captures the denser category-wise transitions. As such,\nSGRec makes full use of the collaborative signals for learning expressive POI\nrepresentations, and also comprehensively uncovers multi-level sequential\npatterns for user preference modelling. Extensive experiments on two real-world\ndatasets demonstrate the superiority of SGRec against state-of-the-art methods\nin next POI recommendation.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Tong Chen",
      "Hongzhi Yin",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.15814"
  },
  {
    "id": "arXiv:2106.15817",
    "title": "Pilot Assignment for Joint Uplink-Downlink Spectral Efficiency  Enhancement in Massive MIMO Systems with Spatial Correlation",
    "abstract": "This paper proposes a flexible pilot assignment method to jointly optimize\nthe uplink and downlink data transmission in multi-cell Massive multiple input\nmultiple output (MIMO) systems with correlated Rayleigh fading channels. By\nutilizing a closed-form expression of the ergodic spectral efficiency (SE)\nachieved with maximum ratio processing, we formulate an optimization problem\nfor maximizing the minimum weighted sum of the uplink and downlink SEs subject\nto the transmit powers and pilot assignment sets. This combinatiorial\noptimization problem is solved by two sequential algorithms: a heuristic pilot\nassignment is first proposed to obtain a good pilot reuse set and the data\npower control is then implemented. Numerical results manifest that the proposed\nalgorithm converges fast to a better minimum sum SE per user than the\nalgorithms in previous works.",
    "descriptor": "\nComments: 6 pages,5 figures, accepted by IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Tien Hoa Nguyen",
      "Trinh Van Chien",
      "Hien Quoc Ngo",
      "Xuan Nam Tran",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.15817"
  },
  {
    "id": "arXiv:2106.15818",
    "title": "What Can Unsupervised Machine Translation Contribute to High-Resource  Language Pairs?",
    "abstract": "Whereas existing literature on unsupervised machine translation (MT) focuses\non exploiting unsupervised techniques for low-resource language pairs where\nbilingual training data is scare or unavailable, we investigate whether\nunsupervised MT can also improve translation quality of high-resource language\npairs where sufficient bitext does exist. We compare the style of correct\ntranslations generated by either supervised or unsupervised MT and find that\nthe unsupervised output is less monotonic and more natural than supervised\noutput. We demonstrate a way to combine the benefits of unsupervised and\nsupervised MT into a single system, resulting in better human evaluation of\nquality and fluency. Our results open the door to discussions about the\npotential contributions of unsupervised MT in high-resource settings, and how\nsupervised and unsupervised systems might be mutually-beneficial.",
    "descriptor": "",
    "authors": [
      "Kelly Marchisio",
      "Markus Freitag",
      "David Grangier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15818"
  },
  {
    "id": "arXiv:2106.15820",
    "title": "Explanation-Guided Diagnosis of Machine Learning Evasion Attacks",
    "abstract": "Machine Learning (ML) models are susceptible to evasion attacks. Evasion\naccuracy is typically assessed using aggregate evasion rate, and it is an open\nquestion whether aggregate evasion rate enables feature-level diagnosis on the\neffect of adversarial perturbations on evasive predictions. In this paper, we\nintroduce a novel framework that harnesses explainable ML methods to guide\nhigh-fidelity assessment of ML evasion attacks. Our framework enables\nexplanation-guided correlation analysis between pre-evasion perturbations and\npost-evasion explanations. Towards systematic assessment of ML evasion attacks,\nwe propose and evaluate a novel suite of model-agnostic metrics for\nsample-level and dataset-level correlation analysis. Using malware and image\nclassifiers, we conduct comprehensive evaluations across diverse model\narchitectures and complementary feature representations. Our explanation-guided\ncorrelation analysis reveals correlation gaps between adversarial samples and\nthe corresponding perturbations performed on them. Using a case study on\nexplanation-guided evasion, we show the broader usage of our methodology for\nassessing robustness of ML models.",
    "descriptor": "\nComments: To appear in the proceedings of the 17th EAI International Conference on Security and Privacy in Communication Networks (SecureComm 2021)\n",
    "authors": [
      "Abderrahmen Amich",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15820"
  },
  {
    "id": "arXiv:2106.15821",
    "title": "Multilayer Networks for Text Analysis with Multiple Data Types",
    "abstract": "We are interested in the widespread problem of clustering documents and\nfinding topics in large collections of written documents in the presence of\nmetadata and hyperlinks. To tackle the challenge of accounting for these\ndifferent types of datasets, we propose a novel framework based on Multilayer\nNetworks and Stochastic Block Models. The main innovation of our approach over\nother techniques is that it applies the same non-parametric probabilistic\nframework to the different sources of datasets simultaneously. The key\ndifference to other multilayer complex networks is the strong unbalance between\nthe layers, with the average degree of different node types scaling differently\nwith system size. We show that the latter observation is due to generic\nproperties of text, such as Heaps' law, and strongly affects the inference of\ncommunities. We present and discuss the performance of our method in different\ndatasets (hundreds of Wikipedia documents, thousands of scientific papers, and\nthousands of E-mails) showing that taking into account multiple types of\ninformation provides a more nuanced view on topic- and document-clusters and\nincreases the ability to predict missing links.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Charles C. Hyland",
      "Yuanming Tao",
      "Lamiae Azizi",
      "Martin Gerlach",
      "Tiago P. Peixoto",
      "Eduardo G. Altmann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15821"
  },
  {
    "id": "arXiv:2106.15825",
    "title": "O2D2: Out-Of-Distribution Detector to Capture Undecidable Trials in  Authorship Verification",
    "abstract": "The PAN 2021 authorship verification (AV) challenge is part of a three-year\nstrategy, moving from a cross-topic/closed-set to a cross-topic/open-set AV\ntask over a collection of fanfiction texts. In this work, we present our\nmodified hybrid neural-probabilistic framework. It is based on our 2020 winning\nsubmission, with updates to significantly reduce sensitivities to topical\nvariations and to further improve the system's calibration by means of an\nuncertainty-adaptation layer. Our framework additionally includes an\nOut-Of-Distribution Detector (O2D2) for defining non-responses, outperforming\nall other systems that participated in the PAN 2021 AV task.",
    "descriptor": "\nComments: PAN@CLEF 2021\n",
    "authors": [
      "Benedikt Boenninghoff",
      "Robert M. Nickel",
      "Dorothea Kolossa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15825"
  },
  {
    "id": "arXiv:2106.15827",
    "title": "When Video Classification Meets Incremental Classes",
    "abstract": "With the rapid development of social media, tremendous videos with new\nclasses are generated daily, which raise an urgent demand for video\nclassification methods that can continuously update new classes while\nmaintaining the knowledge of old videos with limited storage and computing\nresources. In this paper, we summarize this task as \\textit{Class-Incremental\nVideo Classification (CIVC)} and propose a novel framework to address it. As a\nsubarea of incremental learning tasks, the challenge of \\textit{catastrophic\nforgetting} is unavoidable in CIVC. To better alleviate it, we utilize some\ncharacteristics of videos. First, we decompose the spatio-temporal knowledge\nbefore distillation rather than treating it as a whole in the knowledge\ntransfer process; trajectory is also used to refine the decomposition. Second,\nwe propose a dual granularity exemplar selection method to select and store\nrepresentative video instances of old classes and key-frames inside videos\nunder a tight storage budget. We benchmark our method and previous SOTA\nclass-incremental learning methods on Something-Something V2 and Kinetics\ndatasets, and our method outperforms previous methods significantly.",
    "descriptor": "",
    "authors": [
      "Hanbin Zhao",
      "Xin Qin",
      "Shihao Su",
      "Zibo Lin",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15827"
  },
  {
    "id": "arXiv:2106.15828",
    "title": "Semantic Segmentation of Periocular Near-Infra-Red Eye Images Under  Alcohol Effects",
    "abstract": "This paper proposes a new framework to detect, segment, and estimate the\nlocalization of the eyes from a periocular Near-Infra-Red iris image under\nalcohol consumption. The purpose of the system is to measure the fitness for\nduty. Fitness systems allow us to determine whether a person is physically or\npsychologically able to perform their tasks. Our framework is based on an\nobject detector trained from scratch to detect both eyes from a single image.\nThen, two efficient networks were used for semantic segmentation; a Criss-Cross\nattention network and DenseNet10, with only 122,514 and 210,732 parameters,\nrespectively. These networks can find the pupil, iris, and sclera. In the end,\nthe binary output eye mask is used for pupil and iris diameter estimation with\nhigh precision. Five state-of-the-art algorithms were used for this purpose. A\nmixed proposal reached the best results. A second contribution is establishing\nan alcohol behavior curve to detect the alcohol presence utilizing a stream of\nimages captured from an iris instance. Also, a manually labeled database with\nmore than 20k images was created. Our best method obtains a mean\nIntersection-over-Union of 94.54% with DenseNet10 with only 210,732 parameters\nand an error of only 1-pixel on average.",
    "descriptor": "",
    "authors": [
      "Juan Tapia",
      "Enrique Lopez Droguett",
      "Andres Valenzuela",
      "Daniel Benalcazar",
      "Leonardo Causa",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15828"
  },
  {
    "id": "arXiv:2106.15831",
    "title": "The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning",
    "abstract": "Although machine learning models typically experience a drop in performance\non out-of-distribution data, accuracies on in- versus out-of-distribution data\nare widely observed to follow a single linear trend when evaluated across a\ntestbed of models. Models that are more accurate on the out-of-distribution\ndata relative to this baseline exhibit \"effective robustness\" and are\nexceedingly rare. Identifying such models, and understanding their properties,\nis key to improving out-of-distribution performance. We conduct a thorough\nempirical investigation of effective robustness during fine-tuning and\nsurprisingly find that models pre-trained on larger datasets exhibit effective\nrobustness during training that vanishes at convergence. We study how\nproperties of the data influence effective robustness, and we show that it\nincreases with the larger size, more diversity, and higher example difficulty\nof the dataset. We also find that models that display effective robustness are\nable to correctly classify 10% of the examples that no other current testbed\nmodel gets correct. Finally, we discuss several strategies for scaling\neffective robustness to the high-accuracy regime to improve the\nout-of-distribution accuracy of state-of-the-art models.",
    "descriptor": "\nComments: 27 pages, 25 figures\n",
    "authors": [
      "Anders Andreassen",
      "Yasaman Bahri",
      "Behnam Neyshabur",
      "Rebecca Roelofs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15831"
  },
  {
    "id": "arXiv:2106.15832",
    "title": "CCID5: An implementation of the BBR Congestion Control algorithm for  DCCP and its impact over multi-path scenarios",
    "abstract": "Providing multi-connectivity services is an important goal for next\ngeneration wireless networks, where multiple access networks are available and\nneed to be integrated into a coherent solution that efficiently supports both\nreliable and non reliable traffic. Based on virtual network interfaces and per\npath congestion controlled tunnels, the MP-DCCP based multiaccess aggregation\nframework presents as a novel solution that flexibly supports different path\nschedulers and congestion control algorithms as well as reordering modules. The\nframework has been implemented within the Linux kernel space and has been\ntested over different prototypes. Experimental results have shown that the\noverall performance strongly depends upon the congestion control algorithm used\non the individual DCCP tunnels, denoted as CCID. In this paper, we present an\nimplementation of the BBR (Bottleneck Bandwidth Round Trip propagation time)\ncongestion control algorithm for DCCP in the Linux kernel. We show how BBR is\nintegrated into the MP-DCCP multi-access framework and evaluate its performance\nover both single and multi-path environments. Our evaluation results show that\nBBR improves the performance compared to CCID2 for multi-path scenarios due to\nthe faster response to changes in the available bandwidth, which reduces\nlatency and increases performance, especially for unreliable traffic. the\nMP-DCCP framework code, including the new CCID5 is available as OpenSource.",
    "descriptor": "",
    "authors": [
      "Nathalie Romo Moreno",
      "Markus Amend",
      "Anna Brunstrom",
      "Andreas Kassler",
      "Veselin Rakocevic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.15832"
  },
  {
    "id": "arXiv:2106.15835",
    "title": "Robust and Interpretable Temporal Convolution Network for Event  Detection in Lung Sound Recordings",
    "abstract": "This paper proposes a novel framework for lung sound event detection,\nsegmenting continuous lung sound recordings into discrete events and performing\nrecognition on each event. Exploiting the lightweight nature of Temporal\nConvolution Networks (TCNs) and their superior results compared to their\nrecurrent counterparts, we propose a lightweight, yet robust, and completely\ninterpretable framework for lung sound event detection. We propose the use of a\nmulti-branch TCN architecture and exploit a novel fusion strategy to combine\nthe resultant features from these branches. This not only allows the network to\nretain the most salient information across different temporal granularities and\ndisregards irrelevant information, but also allows our network to process\nrecordings of arbitrary length. Results: The proposed method is evaluated on\nmultiple public and in-house benchmarks of irregular and noisy recordings of\nthe respiratory auscultation process for the identification of numerous\nauscultation events including inhalation, exhalation, crackles, wheeze,\nstridor, and rhonchi. We exceed the state-of-the-art results in all\nevaluations. Furthermore, we empirically analyse the effect of the proposed\nmulti-branch TCN architecture and the feature fusion strategy and provide\nquantitative and qualitative evaluations to illustrate their efficiency.\nMoreover, we provide an end-to-end model interpretation pipeline that\ninterprets the operations of all the components of the proposed framework. Our\nanalysis of different feature fusion strategies shows that the proposed feature\nconcatenation method leads to better suppression of non-informative features,\nwhich drastically reduces the classifier overhead resulting in a robust\nlightweight network.The lightweight nature of our model allows it to be\ndeployed in end-user devices such as smartphones, and it has the ability to\ngenerate predictions in real-time.",
    "descriptor": "\nComments: preprint submitted to JBHI\n",
    "authors": [
      "Tharindu Fernando",
      "Sridha Sridharan",
      "Simon Denman",
      "Houman Ghaemmaghami",
      "Clinton Fookes"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.15835"
  },
  {
    "id": "arXiv:2106.15836",
    "title": "MIMO Transmission Under Discrete Input Signal Constraints",
    "abstract": "In this paper, we propose a multiple-input multipleoutput (MIMO) transmission\nstrategy that is closer to the Shannon limit than the existing strategies.\nDifferent from most existing strategies which only consider uniformly\ndistributed discrete input signals, we present a unified framework to optimize\nthe MIMO precoder and the discrete input signal distribution jointly. First, a\ngeneral model of MIMO transmission under discrete input signals and its\nequivalent formulation are established. Next, in order to maximize the mutual\ninformation between the input and output signals, we provide an algorithm that\njointly optimizes the precoder and the input distribution. Finally, we compare\nour strategy with other existing strategies in the simulation. Numerical\nresults indicate that our strategy narrows the gap between the mutual\ninformation and Shannon limit, and shows a lower frame error rate in\nsimulation.",
    "descriptor": "\nComments: This paper contains 6 pages with 5 figures and has been accepted by 2021 IEEE/CIC International Conference on Communications in China (ICCC)\n",
    "authors": [
      "Jie Feng",
      "Biqian Feng",
      "Yongpeng Wu",
      "Li Shen",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.15836"
  },
  {
    "id": "arXiv:2106.15838",
    "title": "HySPA: Hybrid Span Generation for Scalable Text-to-Graph Extraction",
    "abstract": "Text-to-Graph extraction aims to automatically extract information graphs\nconsisting of mentions and types from natural language texts. Existing\napproaches, such as table filling and pairwise scoring, have shown impressive\nperformance on various information extraction tasks, but they are difficult to\nscale to datasets with longer input texts because of their second-order\nspace/time complexities with respect to the input length. In this work, we\npropose a Hybrid Span Generator (HySPA) that invertibly maps the information\ngraph to an alternating sequence of nodes and edge types, and directly\ngenerates such sequences via a hybrid span decoder which can decode both the\nspans and the types recurrently in linear time and space complexities.\nExtensive experiments on the ACE05 dataset show that our approach also\nsignificantly outperforms state-of-the-art on the joint entity and relation\nextraction task.",
    "descriptor": "\nComments: Accepted by ACL 2021 Findings\n",
    "authors": [
      "Liliang Ren",
      "Chenkai Sun",
      "Heng Ji",
      "Julia Hockenmaier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15838"
  },
  {
    "id": "arXiv:2106.15844",
    "title": "Bounded rationality for relaxing best response and mutual consistency:  An information-theoretic model of partial self-reference",
    "abstract": "While game theory has been transformative for decision-making, the\nassumptions made can be overly restrictive in certain instances. In this work,\nwe focus on some of the assumptions underlying rationality such as mutual\nconsistency and best-response, and consider ways to relax these assumptions\nusing concepts from level-$k$ reasoning and quantal response equilibrium (QRE)\nrespectively. Specifically, we provide an information-theoretic two-parameter\nmodel that can relax both mutual consistency and best-response, but can recover\napproximations of level-$k$, QRE, or typical Nash equilibrium behaviour in the\nlimiting cases. The proposed approach is based on a recursive form of the\nvariational free energy principle, representing self-referential games as\n(pseudo) sequential decisions. Bounds in player processing abilities are\ncaptured as information costs, where future chains of reasoning are discounted,\nimplying a hierarchy of players where lower-level players have fewer processing\nresources.",
    "descriptor": "\nComments: 35 pages, 15 figures\n",
    "authors": [
      "Benjamin Patrick Evans",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.15844"
  },
  {
    "id": "arXiv:2106.15845",
    "title": "Edge Representation Learning with Hypergraphs",
    "abstract": "Graph neural networks have recently achieved remarkable success in\nrepresenting graph-structured data, with rapid progress in both the node\nembedding and graph pooling methods. Yet, they mostly focus on capturing\ninformation from the nodes considering their connectivity, and not much work\nhas been done in representing the edges, which are essential components of a\ngraph. However, for tasks such as graph reconstruction and generation, as well\nas graph classification tasks for which the edges are important for\ndiscrimination, accurately representing edges of a given graph is crucial to\nthe success of the graph representation learning. To this end, we propose a\nnovel edge representation learning framework based on Dual Hypergraph\nTransformation (DHT), which transforms the edges of a graph into the nodes of a\nhypergraph. This dual hypergraph construction allows us to apply message\npassing techniques for node representations to edges. After obtaining edge\nrepresentations from the hypergraphs, we then cluster or drop edges to obtain\nholistic graph-level edge representations. We validate our edge representation\nlearning method with hypergraphs on diverse graph datasets for graph\nrepresentation and generation performance, on which our method largely\noutperforms existing graph representation learning methods. Moreover, our edge\nrepresentation learning and pooling method also largely outperforms\nstate-of-the-art graph pooling methods on graph classification, not only\nbecause of its accurate edge representation learning, but also due to its\nlossless compression of the nodes and removal of irrelevant edges for effective\nmessage passing.",
    "descriptor": "",
    "authors": [
      "Jaehyeong Jo",
      "Jinheon Baek",
      "Seul Lee",
      "Dongki Kim",
      "Minki Kang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15845"
  },
  {
    "id": "arXiv:2106.15846",
    "title": "Automatically Select Emotion for Response via Personality-affected  Emotion Transition",
    "abstract": "To provide consistent emotional interaction with users, dialog systems should\nbe capable to automatically select appropriate emotions for responses like\nhumans. However, most existing works focus on rendering specified emotions in\nresponses or empathetically respond to the emotion of users, yet the individual\ndifference in emotion expression is overlooked. This may lead to inconsistent\nemotional expressions and disinterest users. To tackle this issue, we propose\nto equip the dialog system with personality and enable it to automatically\nselect emotions in responses by simulating the emotion transition of humans in\nconversation. In detail, the emotion of the dialog system is transitioned from\nits preceding emotion in context. The transition is triggered by the preceding\ndialog context and affected by the specified personality trait. To achieve\nthis, we first model the emotion transition in the dialog system as the\nvariation between the preceding emotion and the response emotion in the\nValence-Arousal-Dominance (VAD) emotion space. Then, we design neural networks\nto encode the preceding dialog context and the specified personality traits to\ncompose the variation. Finally, the emotion for response is selected from the\nsum of the preceding emotion and the variation. We construct a dialog dataset\nwith emotion and personality labels and conduct emotion prediction tasks for\nevaluation. Experimental results validate the effectiveness of the\npersonality-affected emotion transition.",
    "descriptor": "\nComments: Accepted by Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Wen Zhiyuan",
      "Cao Jiannong",
      "Yang Ruosong",
      "Liu Shuaiqi",
      "Shen Jiaxing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15846"
  },
  {
    "id": "arXiv:2106.15850",
    "title": "Exploring Robustness of Neural Networks through Graph Measures",
    "abstract": "Motivated by graph theory, artificial neural networks (ANNs) are\ntraditionally structured as layers of neurons (nodes), which learn useful\ninformation by the passage of data through interconnections (edges). In the\nmachine learning realm, graph structures (i.e., neurons and connections) of\nANNs have recently been explored using various graph-theoretic measures linked\nto their predictive performance. On the other hand, in network science\n(NetSci), certain graph measures including entropy and curvature are known to\nprovide insight into the robustness and fragility of real-world networks. In\nthis work, we use these graph measures to explore the robustness of various\nANNs to adversarial attacks. To this end, we (1) explore the design space of\ninter-layer and intra-layers connectivity regimes of ANNs in the graph domain\nand record their predictive performance after training under different types of\nadversarial attacks, (2) use graph representations for both inter-layer and\nintra-layers connectivity regimes to calculate various graph-theoretic\nmeasures, including curvature and entropy, and (3) analyze the relationship\nbetween these graph measures and the adversarial performance of ANNs. We show\nthat curvature and entropy, while operating in the graph domain, can quantify\nthe robustness of ANNs without having to train these ANNs. Our results suggest\nthat the real-world networks, including brain networks, financial networks, and\nsocial networks may provide important clues to the neural architecture search\nfor robust ANNs. We propose a search strategy that efficiently finds robust\nANNs amongst a set of well-performing ANNs without having a need to train all\nof these ANNs.",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Asim Waqas",
      "Ghulam Rasool",
      "Hamza Farooq",
      "Nidhal C. Bouaynaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15850"
  },
  {
    "id": "arXiv:2106.15853",
    "title": "Understanding and Improving Early Stopping for Learning with Noisy  Labels",
    "abstract": "The memorization effect of deep neural network (DNN) plays a pivotal role in\nmany state-of-the-art label-noise learning methods. To exploit this property,\nthe early stopping trick, which stops the optimization at the early stage of\ntraining, is usually adopted. Current methods generally decide the early\nstopping point by considering a DNN as a whole. However, a DNN can be\nconsidered as a composition of a series of layers, and we find that the latter\nlayers in a DNN are much more sensitive to label noise, while their former\ncounterparts are quite robust. Therefore, selecting a stopping point for the\nwhole network may make different DNN layers antagonistically affected each\nother, thus degrading the final performance. In this paper, we propose to\nseparate a DNN into different parts and progressively train them to address\nthis problem. Instead of the early stopping, which trains a whole DNN all at\nonce, we initially train former DNN layers by optimizing the DNN with a\nrelatively large number of epochs. During training, we progressively train the\nlatter DNN layers by using a smaller number of epochs with the preceding layers\nfixed to counteract the impact of noisy labels. We term the proposed method as\nprogressive early stopping (PES). Despite its simplicity, compared with the\nearly stopping, PES can help to obtain more promising and stable results.\nFurthermore, by combining PES with existing approaches on noisy label training,\nwe achieve state-of-the-art performance on image classification benchmarks.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Yingbin Bai",
      "Erkun Yang",
      "Bo Han",
      "Yanhua Yang",
      "Jiatong Li",
      "Yinian Mao",
      "Gang Niu",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15853"
  },
  {
    "id": "arXiv:2106.15860",
    "title": "Understanding Adversarial Attacks on Observations in Deep Reinforcement  Learning",
    "abstract": "Recent works demonstrate that deep reinforcement learning (DRL) models are\nvulnerable to adversarial attacks which can decrease the victim's total reward\nby manipulating the observations. Compared with adversarial attacks in\nsupervised learning, it is much more challenging to deceive a DRL model since\nthe adversary has to infer the environmental dynamics. To address this issue,\nwe reformulate the problem of adversarial attacks in function space and\nseparate the previous gradient based attacks into several subspace. Following\nthe analysis of the function space, we design a generic two-stage framework in\nthe subspace where the adversary lures the agent to a target trajectory or a\ndeceptive policy. In the first stage, we train a deceptive policy by hacking\nthe environment, and discover a set of trajectories routing to the lowest\nreward. The adversary then misleads the victim to imitate the deceptive policy\nby perturbing the observations. Our method provides a tighter theoretical upper\nbound for the attacked agent's performance than the existing approaches.\nExtensive experiments demonstrate the superiority of our method and we achieve\nthe state-of-the-art performance on both Atari and MuJoCo environments.",
    "descriptor": "",
    "authors": [
      "You Qiaoben",
      "Chengyang Ying",
      "Xinning Zhou",
      "Hang Su",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15860"
  },
  {
    "id": "arXiv:2106.15864",
    "title": "Biologically Inspired Model for Timed Motion in Robotic Systems",
    "abstract": "The goal of this work is the development of a motion model for sequentially\ntimed movement actions in robotic systems under specific consideration of\ntemporal stabilization, that is maintaining an approximately constant overall\nmovement time (isochronous behavior). This is demonstrated both in simulation\nand on a physical robotic system for the task of intercepting a moving target\nin three-dimensional space. Motivated from humanoid motion, timing plays a\nvital role to generate a naturalistic behavior in interaction with the dynamic\nenvironment as well as adaptively planning and executing action sequences\non-line. In biological systems, many of the physiological and anatomical\nfunctions follow a particular level of periodicity and stabilization, which\nexhibit a certain extent of resilience against external disturbances. A main\naspect thereof is stabilizing movement timing against limited perturbations.\nEspecially human arm movement, namely when it is tasked to reach a certain goal\npoint, pose or configuration, shows a stabilizing behavior. This work\nincorporates the utilization of an extended Kalman filter (EKF) which was\nimplemented to predict the target position while coping with non-linear system\ndynamics. The periodicity and temporal stabilization in biological systems was\nartificially generated by a Hopf oscillator, yielding a sinusoidal velocity\nprofile for smooth and repeatable motion.",
    "descriptor": "",
    "authors": [
      "Sebastian Doliwa",
      "Muhammad Ayaz Hussain",
      "Tim Sziburis",
      "Ioannis Iossifidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15864"
  },
  {
    "id": "arXiv:2106.15867",
    "title": "Finite-image property of weighted tree automata over past-finite  monotonic strong bimonoids",
    "abstract": "We consider weighted tree automata over strong bimonoids (for short: wta). A\nwta $\\mathcal{A}$ has the finite-image property if its recognized weighted tree\nlanguage $[\\![\\mathcal{A}]\\!]$ has finite image; moreover, $\\mathcal{A}$ has\nthe preimage property if the preimage under $[\\![\\mathcal{A}]\\!]$ of each\nelement of the underlying strong bimonoid is a recognizable tree language. For\neach wta $\\mathcal{A}$ over a past-finite monotonic strong bimonoid we prove\nthe following results. In terms of $\\mathcal{A}$'s structural properties, we\ncharacterize whether it has the finite-image property. We characterize those\npast-finite monotonic strong bimonoids such that for each wta $\\mathcal{A}$ it\nis decidable whether $\\mathcal{A}$ has the finite-image property. In\nparticular, the finite-image property is decidable for wta over past-finite\nmonotonic semirings. Moreover, we prove that $\\mathcal{A}$ has the preimage\nproperty. All our results also hold for weighted string automata.",
    "descriptor": "\nComments: 42 pages, 4 figures, 1 algorithm\n",
    "authors": [
      "Manfred Droste",
      "Zolt\u00e1n F\u00fcl\u00f6p",
      "D\u00e1vid K\u00f3sz\u00f3",
      "Heiko Vogler"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.15867"
  },
  {
    "id": "arXiv:2106.15868",
    "title": "Decomposing the Prediction Problem; Autonomous Navigation by neoRL  Agents",
    "abstract": "Navigating the world is a fundamental ability for any living entity.\nAccomplishing the same degree of freedom in technology has proven to be\ndifficult. The brain is the only known mechanism capable of voluntary\nnavigation, making neuroscience our best source of inspiration toward autonomy.\nAssuming that state representation is key, we explore the difference in how the\nbrain and the machine represent the navigational state. Where Reinforcement\nLearning (RL) requires a monolithic state representation in accordance with the\nMarkov property, Neural Representation of Euclidean Space (NRES) reflects\nnavigational state via distributed activation patterns. We show how\nNRES-Oriented RL (neoRL) agents are possible before verifying our theoretical\nfindings by experiments. Ultimately, neoRL agents are capable of behavior\nsynthesis across state spaces -- allowing for decomposition of the problem into\nsmaller spaces, alleviating the curse of dimensionality.",
    "descriptor": "\nComments: Accepted at A-life 2021\n",
    "authors": [
      "Per R. Leikanger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15868"
  },
  {
    "id": "arXiv:2106.15869",
    "title": "GPU Based Improved Fast Iterative Algorithm for Eikonal Equation",
    "abstract": "In this paper we propose an improved fast iterative method to solve the\nEikonal equation, which can be implemented in parallel. We improve the fast\niterative method for Eikonal equation in two novel ways, in the value update\nand in the error correction. The new value update is very similar to the fast\niterative method in that we selectively update the points in the active list\nchosen by a convergence measure. However, in order to save time, the improved\nalgorithm does not do a convergence check of the neighboring points of the\nnarrow band as the fast iterative method does. The additional error correction\nstep is to correct the errors that the previous value update step may cause.\nThe error correction step consists of finding and recalculating the point\nvalues in a separate remedy list which is quite easy to implement on a GPU. In\ncontrast to the fast marching method and the fast sweeping method for the\nEikonal equation, our improved method does not need to compute the solution\nwith any special ordering in either the remedy list or the active list so that\nit can be implemented in parallel. In our experiments, we implemented our new\nalgorithm in parallel on a GPU and compared the elapsed time with other current\nalgorithms. The improved fast iterative method runs faster than the other\nalgorithms in most cases in our experiments.",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Yuhao Huang",
      "David Chopp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15869"
  },
  {
    "id": "arXiv:2106.15872",
    "title": "Genre determining prediction: Non-standard TAM marking in football  language",
    "abstract": "German and French football language display tense-aspect-mood (TAM) forms\nwhich differ from the TAM use in other genres. In German football talk, the\npresent indicative may replace the pluperfect subjunctive. In French reports of\nfootball matches, the imperfective past may occur instead of a perfective past\ntense-aspect form. We argue that the two phenomena share a functional core and\nare licensed in the same way, which is a direct result of the genre they occur\nin. More precisely, football match reports adhere to a precise script and\nspecific events are temporally determined in terms of objective time. This\nallows speakers to exploit a secondary function of TAM forms, namely, they\nshift the temporal perspective. We argue that it is on the grounds of the genre\nthat comprehenders predict the deviating forms and are also able to decode\nthem. We present various corpus studies where we explore the functioning of\nthese phenomena in order to gain insights into their distribution,\ngrammaticalization and their functioning in discourse. Relevant factors are\nAktionsart properties, rhetorical relations and their interaction with other\nTAM forms. This allows us to discuss coping mechanisms on the part of the\ncomprehender. We broaden our understanding of the phenomena, which have only\nbeen partly covered for French and up to now seem to have been ignored in\nGerman.",
    "descriptor": "\nComments: 23 pages, submitted to Frontiers in Communication\n",
    "authors": [
      "Jakob Egetenmeyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15872"
  },
  {
    "id": "arXiv:2106.15876",
    "title": "Incorporating Domain Knowledge for Extractive Summarization of Legal  Case Documents",
    "abstract": "Automatic summarization of legal case documents is an important and practical\nchallenge. Apart from many domain-independent text summarization algorithms\nthat can be used for this purpose, several algorithms have been developed\nspecifically for summarizing legal case documents. However, most of the\nexisting algorithms do not systematically incorporate domain knowledge that\nspecifies what information should ideally be present in a legal case document\nsummary. To address this gap, we propose an unsupervised summarization\nalgorithm DELSumm which is designed to systematically incorporate guidelines\nfrom legal experts into an optimization setup. We conduct detailed experiments\nover case documents from the Indian Supreme Court. The experiments show that\nour proposed unsupervised method outperforms several strong baselines in terms\nof ROUGE scores, including both general summarization algorithms and\nlegal-specific ones. In fact, though our proposed algorithm is unsupervised, it\noutperforms several supervised summarization models that are trained over\nthousands of document-summary pairs.",
    "descriptor": "\nComments: Accepted at the 18th International Conference on Artificial Intelligence and Law (ICAIL) 2021\n",
    "authors": [
      "Paheli Bhattacharya",
      "Soham Poddar",
      "Koustav Rudra",
      "Kripabandhu Ghosh",
      "Saptarshi Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.15876"
  },
  {
    "id": "arXiv:2106.15877",
    "title": "Experience-Driven PCG via Reinforcement Learning: A Super Mario Bros  Study",
    "abstract": "We introduce a procedural content generation (PCG) framework at the\nintersections of experience-driven PCG and PCG via reinforcement learning,\nnamed ED(PCG)RL, EDRL in short. EDRL is able to teach RL designers to generate\nendless playable levels in an online manner while respecting particular\nexperiences for the player as designed in the form of reward functions. The\nframework is tested initially in the Super Mario Bros game. In particular, the\nRL designers of Super Mario Bros generate and concatenate level segments while\nconsidering the diversity among the segments. The correctness of the generation\nis ensured by a neural net-assisted evolutionary level repairer and the\nplayability of the whole level is determined through AI-based testing. Our\nagents in this EDRL implementation learn to maximise a quantification of\nKoster's principle of fun by moderating the degree of diversity across level\nsegments. Moreover, we test their ability to design fun levels that are diverse\nover time and playable. Our proposed framework is capable of generating\nendless, playable Super Mario Bros levels with varying degrees of fun,\ndeviation from earlier segments, and playability. EDRL can be generalised to\nany game that is built as a segment-based sequential process and features a\nbuilt-in compressed representation of its game content.",
    "descriptor": "\nComments: This paper is accepted by the 2021 IEEE Conference on Games\n",
    "authors": [
      "Tianye Shu",
      "Jialin Liu",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15877"
  },
  {
    "id": "arXiv:2106.15878",
    "title": "Towards establishing formal verification and inductive code synthesis in  the PLC domain",
    "abstract": "Nowadays, formal methods are used in various areas for the verification of\nprograms or for code generation from models in order to increase the quality of\nsoftware and to reduce costs. However, there are still fields in which formal\nmethods have not been widely adopted, despite the large set of possible\nbenefits offered. This is the case for the area of programmable logic\ncontrollers (PLC). This article aims to evaluate the potential of formal\nmethods in the context of PLC development. For this purpose, the general\nconcepts of formal methods are first introduced and then transferred to the PLC\narea, resulting in an engineering-oriented description of the technology that\nis based on common concepts from PLC development. Based on this description,\nPLC professionals with varying degrees of experience were interviewed for their\nperspective on the topic and to identify possible use cases within the PLC\ndomain. The survey results indicate the technology's high potential in the PLC\narea, either as a tool to directly support the developer or as a key element\nwithin a model-based systems engineering toolchain. The evaluation of the\nsurvey results is performed with the aid of a demo application that\ncommunicates with the Totally Integrated Automation Portal from Siemens and\ngenerates programs via Fastsynth, a model-based open source code generator.\nBenchmarks based on an industry-related PLC project show satisfactory synthesis\ntimes and a successful integration into the workflow of a PLC developer.",
    "descriptor": "\nComments: 8 pages, 6 figures, 1 table. Accepted for publication at IEEE INDIN 2021\n",
    "authors": [
      "Matthias Wei\u00df",
      "Philipp Marks",
      "Benjamin Maschler",
      "Dustin White",
      "Pascal Kesseli",
      "Michael Weyrich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15878"
  },
  {
    "id": "arXiv:2106.15880",
    "title": "Mixed Cross Entropy Loss for Neural Machine Translation",
    "abstract": "In neural machine translation, cross entropy (CE) is the standard loss\nfunction in two training methods of auto-regressive models, i.e., teacher\nforcing and scheduled sampling. In this paper, we propose mixed cross entropy\nloss (mixed CE) as a substitute for CE in both training approaches. In teacher\nforcing, the model trained with CE regards the translation problem as a\none-to-one mapping process, while in mixed CE this process can be relaxed to\none-to-many. In scheduled sampling, we show that mixed CE has the potential to\nencourage the training and testing behaviours to be similar to each other, more\neffectively mitigating the exposure bias problem. We demonstrate the\nsuperiority of mixed CE over CE on several machine translation datasets, WMT'16\nRo-En, WMT'16 Ru-En, and WMT'14 En-De in both teacher forcing and scheduled\nsampling setups. Furthermore, in WMT'14 En-De, we also find mixed CE\nconsistently outperforms CE on a multi-reference set as well as a challenging\nparaphrased reference set. We also found the model trained with mixed CE is\nable to provide a better probability distribution defined over the translation\noutput space. Our code is available at https://github.com/haorannlp/mix.",
    "descriptor": "",
    "authors": [
      "Haoran Li",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15880"
  },
  {
    "id": "arXiv:2106.15883",
    "title": "Tuning Mixed Input Hyperparameters on the Fly for Efficient Population  Based AutoRL",
    "abstract": "Despite a series of recent successes in reinforcement learning (RL), many RL\nalgorithms remain sensitive to hyperparameters. As such, there has recently\nbeen interest in the field of AutoRL, which seeks to automate design decisions\nto create more general algorithms. Recent work suggests that population based\napproaches may be effective AutoRL algorithms, by learning hyperparameter\nschedules on the fly. In particular, the PB2 algorithm is able to achieve\nstrong performance in RL tasks by formulating online hyperparameter\noptimization as time varying GP-bandit problem, while also providing\ntheoretical guarantees. However, PB2 is only designed to work for continuous\nhyperparameters, which severely limits its utility in practice. In this paper\nwe introduce a new (provably) efficient hierarchical approach for optimizing\nboth continuous and categorical variables, using a new time-varying bandit\nalgorithm specifically designed for the population based training regime. We\nevaluate our approach on the challenging Procgen benchmark, where we show that\nexplicitly modelling dependence between data augmentation and other\nhyperparameters improves generalization.",
    "descriptor": "",
    "authors": [
      "Jack Parker-Holder",
      "Vu Nguyen",
      "Shaan Desai",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15883"
  },
  {
    "id": "arXiv:2106.15885",
    "title": "Optimal Construction for Time-Convex Hull with Two Orthogonal Highways  in the L1-metric",
    "abstract": "We consider the time-convex hull problem in the presence of two orthogonal\nhighways H. In this problem, the travelling speed on the highway is faster than\noff the highway, and the time-convex hull of a point set P is the closure of P\nwith respect to the inclusion of shortest time-paths. In this paper, we provide\nthe algorithm for constructing the time-convex hull with two orthogonal\nhighways. We reach the optimal result of O(n log n) time for arbitrary highway\nspeed in the L1-metric. For the L2-metric with infinite highway speed, we hit\nthe goal of O(n log n) time as well.",
    "descriptor": "",
    "authors": [
      "Jyun-Yu Chen",
      "Po-Hsuan Chen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.15885"
  },
  {
    "id": "arXiv:2106.15887",
    "title": "Pressure stabilization strategies for a LES filtering Reduced Order  Model",
    "abstract": "We present a stabilized POD-Galerkin reduced order method (ROM) for a Leray\nmodel. For the implementation of the model, we combine a two-step algorithm\ncalled Evolve-Filter (EF) with a computationally efficient finite volume\nmethod. In both steps of the EF algorithm, velocity and pressure fields are\napproximated using different POD basis and coefficients. To achieve pressure\nstabilization, we consider and compare two strategies: the pressure Poisson\nequation and the supremizer enrichment of the velocity space. We show that the\nevolve and filtered velocity spaces have to be enriched with the supremizer\nsolutions related to both evolve and filter pressure fields in order to obtain\nstable and accurate solutions with the supremizer enrichment method. We test\nour ROM approach on 2D unsteady flow past a cylinder at Reynolds number 0 <= Re\n<= 100. We find that both stabilization strategies produce comparable errors in\nthe reconstruction of the lift and drag coefficients, with the pressure Poisson\nequation method being more computationally efficient.",
    "descriptor": "\nComments: 18 pages, 4 figures, 3 tables. arXiv admin note: substantial text overlap with arXiv:2009.13593\n",
    "authors": [
      "Michele Girfoglio",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15887"
  },
  {
    "id": "arXiv:2106.15889",
    "title": "A Structured Analysis of the Video Degradation Effects on the  Performance of a Machine Learning-enabled Pedestrian Detector",
    "abstract": "ML-enabled software systems have been incorporated in many public\ndemonstrations for automated driving (AD) systems. Such solutions have also\nbeen considered as a crucial approach to aim at SAE Level 5 systems, where the\npassengers in such vehicles do not have to interact with the system at all\nanymore. Already in 2016, Nvidia demonstrated a complete end-to-end approach\nfor training the complete software stack covering perception, planning and\ndecision making, and the actual vehicle control. While such approaches show the\ngreat potential of such ML-enabled systems, there have also been demonstrations\nwhere already changes to single pixels in a video frame can potentially lead to\ncompletely different decisions with dangerous consequences. In this paper, a\nstructured analysis has been conducted to explore video degradation effects on\nthe performance of an ML-enabled pedestrian detector. Firstly, a baseline of\napplying YOLO to 1,026 frames with pedestrian annotations in the KITTI Vision\nBenchmark Suite has been established. Next, video degradation candidates for\neach of these frames were generated using the leading video codecs libx264,\nlibx265, Nvidia HEVC, and AV1: 52 frames for the various compression presets\nfor color and gray-scale frames resulting in 104 degradation candidates per\noriginal KITTI frame and 426,816 images in total. YOLO was applied to each\nimage to compute the intersection-over-union (IoU) metric to compare the\nperformance with the original baseline. While aggressively lossy compression\nsettings result in significant performance drops as expected, it was also\nobserved that some configurations actually result in slightly better IoU\nresults compared to the baseline. The findings show that carefully chosen lossy\nvideo configurations preserve a decent performance of particular ML-enabled\nsystems while allowing for substantial savings when storing or transmitting\ndata.",
    "descriptor": "",
    "authors": [
      "Christian Berger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15889"
  },
  {
    "id": "arXiv:2106.15890",
    "title": "A Context-Aware Information-Based Clone Node Attack Detection Scheme in  Internet of Things",
    "abstract": "The rapidly expanding nature of the Internet of Things (IoT) networks is\nbeginning to attract interest across a range of applications, including smart\nhomes, smart transportation, smart health, and industrial contexts. This\ncutting-edge technology enables individuals to track and control their\nintegrated environment in real-time and remotely via a thousand IoT devices\ncomprised of sensors and actuators that actively participate in sensing,\nprocessing, storing, and sharing information. Nonetheless, IoT devices are\nfrequently deployed in hostile environments, wherein adversaries attempt to\ncapture and breach them in order to seize control of the entire network. One\nsuch example of potentially malicious behaviour is the cloning of IoT devices,\nin which an attacker can physically capture the devices, obtain some sensitive\ninformation, duplicate the devices, and intelligently deploy them in desired\nlocations to conduct various insider attacks. A device cloning attack on IoT\nnetworks is a significant security concern since it allows for selective\nforwarding, sink-hole, and black-hole attacks. To address this issue, this\npaper provides an efficient scheme for detecting clone node attacks on IoT\nnetworks that makes use of semantic information about IoT devices known as\ncontext information sensed from the deployed environment to locate them\nsecurely. We design a location proof mechanism by combining location proofs and\nbatch verification of the extended elliptic curve digital signature technique\nto accelerate the verification process at selected trusted nodes. We\ndemonstrate the security of our scheme and its resilience to secure clone node\nattack detection by conducting a comprehensive security analysis. The\nperformance of our proposed scheme provides a high degree of detection accuracy\nwith minimal detection time and significantly reduces the computation,\ncommunication and storage overhead.",
    "descriptor": "",
    "authors": [
      "Khizar Hameed",
      "Saurabh Garg",
      "Muhammad Bilal Amin",
      "Byeong Kang",
      "Abid Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.15890"
  },
  {
    "id": "arXiv:2106.15892",
    "title": "Determinization and Limit-determinization of Emerson-Lei automata",
    "abstract": "We study the problem of determinizing $\\omega$-automata whose acceptance\ncondition is defined on the transitions using Boolean formulas, also known as\ntransition-based Emerson-Lei automata (TELA). The standard approach to\ndeterminize TELA first constructs an equivalent generalized B\\\"uchi automaton\n(GBA), which is later determinized. We introduce three new ways of translating\nTELA to GBA. Furthermore, we give a new determinization construction which\ndeterminizes several GBA separately and combines them using a product\nconstruction. An experimental evaluation shows that the product approach is\ncompetitive when compared with state-of-the-art determinization procedures. We\nalso study limit-determinization of TELA and show that this can be done with a\nsingle-exponential blow-up, in contrast to the known double-exponential\nlower-bound for determinization. Finally, one version of the\nlimit-determinization procedure yields good-for-MDP automata which can be used\nfor quantitative probabilistic model checking.",
    "descriptor": "\nComments: 29 pages, conference version accepted at ATVA'21\n",
    "authors": [
      "Tobias John",
      "Simon Jantsch",
      "Christel Baier",
      "Sascha Kl\u00fcppelholz"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.15892"
  },
  {
    "id": "arXiv:2106.15896",
    "title": "Whose Opinions Matter? Perspective-aware Models to Identify Opinions of  Hate Speech Victims in Abusive Language Detection",
    "abstract": "Social media platforms provide users the freedom of expression and a medium\nto exchange information and express diverse opinions. Unfortunately, this has\nalso resulted in the growth of abusive content with the purpose of\ndiscriminating people and targeting the most vulnerable communities such as\nimmigrants, LGBT, Muslims, Jews and women. Because abusive language is\nsubjective in nature, there might be highly polarizing topics or events\ninvolved in the annotation of abusive contents such as hate speech (HS).\nTherefore, we need novel approaches to model conflicting perspectives and\nopinions coming from people with different personal and demographic\nbackgrounds. In this paper, we present an in-depth study to model polarized\nopinions coming from different communities under the hypothesis that similar\ncharacteristics (ethnicity, social background, culture etc.) can influence the\nperspectives of annotators on a certain phenomenon. We believe that by relying\non this information, we can divide the annotators into groups sharing similar\nperspectives. We can create separate gold standards, one for each group, to\ntrain state-of-the-art deep learning models. We can employ an ensemble approach\nto combine the perspective-aware classifiers from different groups to an\ninclusive model. We also propose a novel resource, a multi-perspective English\nlanguage dataset annotated according to different sub-categories relevant for\ncharacterising online abuse: hate speech, aggressiveness, offensiveness and\nstereotype. By training state-of-the-art deep learning models on this novel\nresource, we show how our approach improves the prediction performance of a\nstate-of-the-art supervised classifier.",
    "descriptor": "",
    "authors": [
      "Sohail Akhtar",
      "Valerio Basile",
      "Viviana Patti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15896"
  },
  {
    "id": "arXiv:2106.15901",
    "title": "Optimally rescheduling jobs with a LIFO buffer",
    "abstract": "This paper considers single-machine scheduling problems in which a given\nsolution, i.e. an ordered set of jobs, has to be improved as much as possible\nby re-sequencing the jobs. The need for rescheduling may arise in different\ncontexts, e.g. due to changes in the job data or because of the local objective\nin a stage of a supply chain \\red{that is} not aligned with the given sequence.\nA common production setting entails the movement of jobs (or parts) on a\nconveyor. This is reflected in our model by facilitating the re-sequencing of\njobs via a buffer of limited capacity accessible by a LIFO policy. We consider\nthe classical objective functions of total weighted completion time, maximum\nlateness and (weighted) number of late jobs and study their complexity. For\nthree of these problems we present strictly polynomial-time dynamic programming\nalgorithms, while for the case of minimizing the weighted number of late jobs\nNP-hardness is proven and a pseudo-polynomial algorithm is given.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Gaia Nicosia",
      "Andrea Pacifici",
      "Ulrich Pferschy",
      "Julia Resch",
      "Giovanni Righini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15901"
  },
  {
    "id": "arXiv:2106.15903",
    "title": "Learning to Ask Conversational Questions by Optimizing Levenshtein  Distance",
    "abstract": "Conversational Question Simplification (CQS) aims to simplify self-contained\nquestions into conversational ones by incorporating some conversational\ncharacteristics, e.g., anaphora and ellipsis. Existing maximum likelihood\nestimation (MLE) based methods often get trapped in easily learned tokens as\nall tokens are treated equally during training. In this work, we introduce a\nReinforcement Iterative Sequence Editing (RISE) framework that optimizes the\nminimum Levenshtein distance (MLD) through explicit editing actions. RISE is\nable to pay attention to tokens that are related to conversational\ncharacteristics. To train RISE, we devise an Iterative Reinforce Training (IRT)\nalgorithm with a Dynamic Programming based Sampling (DPS) process to improve\nexploration. Experimental results on two benchmark datasets show that RISE\nsignificantly outperforms state-of-the-art methods and generalizes well on\nunseen data.",
    "descriptor": "\nComments: 13 pages, 4 figures, Published in ACL 2021\n",
    "authors": [
      "Zhongkun Liu",
      "Pengjie Ren",
      "Zhumin Chen",
      "Zhaochun Ren",
      "Maarten de Rijke",
      "Ming Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.15903"
  },
  {
    "id": "arXiv:2106.15905",
    "title": "Faithful Edge Federated Learning: Scalability and Privacy",
    "abstract": "Federated learning enables machine learning algorithms to be trained over a\nnetwork of multiple decentralized edge devices without requiring the exchange\nof local datasets. Successfully deploying federated learning requires ensuring\nthat agents (e.g., mobile devices) faithfully execute the intended algorithm,\nwhich has been largely overlooked in the literature. In this study, we first\nuse risk bounds to analyze how the key feature of federated learning,\nunbalanced and non-i.i.d. data, affects agents' incentives to voluntarily\nparticipate and obediently follow traditional federated learning algorithms.\nTo be more specific, our analysis reveals that agents with less typical data\ndistributions and relatively more samples are more likely to opt out of or\ntamper with federated learning algorithms. To this end, we formulate the first\nfaithful implementation problem of federated learning and design two faithful\nfederated learning mechanisms which satisfy economic properties, scalability,\nand privacy. Further, the time complexity of computing all agents' payments in\nthe number of agents is $\\mathcal{O}(1)$. First, we design a Faithful Federated\nLearning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG)\npayments via an incremental computation. We show that it achieves (probably\napproximate) optimality, faithful implementation, voluntary participation, and\nsome other economic properties (such as budget balance). Second, by\npartitioning agents into several subsets, we present a scalable VCG mechanism\napproximation. We further design a scalable and Differentially Private FFL\n(DP-FFL) mechanism, the first differentially private faithful mechanism, that\nmaintains the economic properties. Our mechanism enables one to make three-way\nperformance tradeoffs among privacy, the iterations needed, and payment\naccuracy loss.",
    "descriptor": "\nComments: Under review by JSAC\n",
    "authors": [
      "Meng Zhang",
      "Ermin Wei",
      "Randall Berry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.15905"
  },
  {
    "id": "arXiv:2106.15907",
    "title": "Parameterized Complexities of Dominating and Independent Set  Reconfiguration",
    "abstract": "We settle the parameterized complexities of several variants of independent\nset reconfiguration and dominating set reconfiguration, parameterized by the\nnumber of tokens. We show that both problems are XL-complete when there is no\nlimit on the number of moves and XNL-complete when a maximum length $\\ell$ for\nthe sequence is given in binary in the input. The problems are known to be\nXNLP-complete when $\\ell$ is given in unary instead, and $W[1]$- and\n$W[2]$-hard respectively when $\\ell$ is also a parameter. We complete the\npicture by showing membership in those classes.\nMoreover, we show that for all the variants that we consider, token sliding\nand token jumping are equivalent under pl-reductions. We introduce partitioned\nvariants of token jumping and token sliding, and give pl-reductions between the\nfour variants that have precise control over the number of tokens and the\nlength of the reconfiguration sequence.",
    "descriptor": "\nComments: 31 pages, 3 figures\n",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "C\u00e9line M. F. Swennenhuis"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.15907"
  },
  {
    "id": "arXiv:2106.15911",
    "title": "A parallel fast multipole method for a space-time boundary element  method for the heat equation",
    "abstract": "We present a novel approach to the parallelization of the parabolic fast\nmultipole method for a space-time boundary element method for the heat\nequation. We exploit the special temporal structure of the involved operators\nto provide an efficient distributed parallelization with respect to time and\nwith a one-directional communication pattern. On top, we apply a task-based\nshared memory parallelization and SIMD vectorization. In the numerical tests we\nobserve high efficiencies of our parallelization approach.",
    "descriptor": "",
    "authors": [
      "Raphael Watschinger",
      "Michal Merta",
      "G\u00fcnther Of",
      "Jan Zapletal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.15911"
  },
  {
    "id": "arXiv:2106.15913",
    "title": "Zames-Falb Multipliers: don't panic",
    "abstract": "Zames-Falb multipliers are mathematical constructs which can be used to prove\nstability of so-called Lur'e systems: systems that consist of a feedback\ninterconnection of a linear element and a static nonlinear element. The main\nadvantage of Zames-Falb multipliers is that they enable \"passivity\"-like\nresults to be obtained but with a level of conservatism much lower than\n\\emph{pure} passivity results. However, some of the papers describing the\ndevelopment of the Zames-Falb multiplier machinery are somewhat abstruse and\nnot entirely clear. This article attempts to provide a relatively simple\nconstruction of Zames and Falb's main results which will hopefully be\nunderstandable to most graduate-level control engineers.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Matthew C. Turner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15913"
  },
  {
    "id": "arXiv:2106.15916",
    "title": "Communication conditions in virtual acoustic scenes in an underground  station",
    "abstract": "Underground stations are a common communication situation in towns: we talk\nwith friends or colleagues, listen to announcements or shop for titbits while\nbackground noise and reverberation are challenging communication. Here, we\nperform an acoustical analysis of two communication scenes in an underground\nstation in Munich and test speech intelligibility. The acoustical conditions\nwere measured in the station and are compared to simulations in the real-time\nSimulated Open Field Environment (rtSOFE). We compare binaural room impulse\nresponses measured with an artificial head in the station to modeled impulse\nresponses for free-field auralization via 60 loudspeakers in the rtSOFE. We\nused the image source method to model early reflections and a set of\nmulti-microphone recordings to model late reverberation. The first\ncommunication scene consists of 12 equidistant (1.6 m) horizontally spaced\nsource positions around a listener, simulating different direction-dependent\nspatial unmasking conditions. The second scene mimics an approaching speaker\nacross six radially spaced source positions (from 1 m to 10 m) with varying\ndirect sound level and thus direct-to-reverberant energy. The acoustic\nparameters of the underground station show a moderate amount of reverberation\n(T30 in octave bands was between 2.3 s and 0.6 s and early-decay times between\n1.46 s and 0.46 s). The binaural and energetic parameters of the auralization\nwere in a close match to the measurement. Measured speech reception thresholds\nwere within the error of the speech test, letting us to conclude that the\nauralized simulation reproduces acoustic and perceptually relevant parameters\nfor speech intelligibility with high accuracy.",
    "descriptor": "\nComments: I3DA conference paper, 8 figures, 9 pages\n",
    "authors": [
      "\u013dubo\u0161 Hl\u00e1dek",
      "Stephan D. Ewert",
      "Bernhard U. Seeber"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.15916"
  },
  {
    "id": "arXiv:2106.15918",
    "title": "Positive-unlabeled Learning for Cell Detection in Histopathology Images  with Incomplete Annotations",
    "abstract": "Cell detection in histopathology images is of great value in clinical\npractice. \\textit{Convolutional neural networks} (CNNs) have been applied to\ncell detection to improve the detection accuracy, where cell annotations are\nrequired for network training. However, due to the variety and large number of\ncells, complete annotations that include every cell of interest in the training\nimages can be challenging. Usually, incomplete annotations can be achieved,\nwhere positive labeling results are carefully examined to ensure their\nreliability but there can be other positive instances, i.e., cells of interest,\nthat are not included in the annotations. This annotation strategy leads to a\nlack of knowledge about true negative samples. Most existing methods simply\ntreat instances that are not labeled as positive as truly negative during\nnetwork training, which can adversely affect the network performance. In this\nwork, to address the problem of incomplete annotations, we formulate the\ntraining of detection networks as a positive-unlabeled learning problem.\nSpecifically, the classification loss in network training is revised to take\ninto account incomplete annotations, where the terms corresponding to negative\nsamples are approximated with the true positive samples and the other samples\nof which the labels are unknown. To evaluate the proposed method, experiments\nwere performed on a publicly available dataset for mitosis detection in breast\ncancer cells, and the experimental results show that our method improves the\nperformance of cell detection given incomplete annotations for training.",
    "descriptor": "\nComments: Accepted by MICCAI 2021\n",
    "authors": [
      "Zipei Zhao",
      "Fengqian Pang",
      "Zhiwen Liu",
      "Chuyang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15918"
  },
  {
    "id": "arXiv:2106.15919",
    "title": "End-to-End Spoken Language Understanding using RNN-Transducer ASR",
    "abstract": "We propose an end-to-end trained spoken language understanding (SLU) system\nthat extracts transcripts, intents and slots from an input speech utterance. It\nconsists of a streaming recurrent neural network transducer (RNNT) based\nautomatic speech recognition (ASR) model connected to a neural natural language\nunderstanding (NLU) model through a neural interface. This interface allows for\nend-to-end training using multi-task RNNT and NLU losses. Additionally, we\nintroduce semantic sequence loss training for the joint RNNT-NLU system that\nallows direct optimization of non-differentiable SLU metrics. This end-to-end\nSLU model paradigm can leverage state-of-the-art advancements and pretrained\nmodels in both ASR and NLU research communities, outperforming recently\nproposed direct speech-to-semantics models, and conventional pipelined ASR and\nNLU systems. We show that this method improves both ASR and NLU metrics on both\npublic SLU datasets and large proprietary datasets.",
    "descriptor": "",
    "authors": [
      "Anirudh Raju",
      "Gautam Tiwari",
      "Milind Rao",
      "Pranav Dheram",
      "Bryan Anderson",
      "Zhe Zhang",
      "Bach Bui",
      "Ariya Rastrow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.15919"
  },
  {
    "id": "arXiv:2106.15927",
    "title": "A Robust Classification-autoencoder to Defend Outliers and Adversaries",
    "abstract": "In this paper, we present a robust classification-autoencoder (CAE) which has\nstrong ability to recognize outliers and defend adversaries. The basic idea is\nto change the autoencoder from an unsupervised learning method into a\nclassifier. The CAE is a modified autoencoder, where the encoder is used to\ncompress samples with different labels into disjoint compression spaces and the\ndecoder is used to recover a sample with a given label from the corresponding\ncompression space. The encoder is used as a classifier and the decoder is used\nto decide whether the classification given by the encoder is correct by\ncomparing the input sample with the output. Since adversary samples are seeming\ninevitable for the current DNN framework, we introduce the list classification\nbased on CAE to defend adversaries, which outputs several labels and the\ncorresponding samples recovered by the CAE. The CAE is evaluated using the\nMNIST dataset in great detail. It is shown that the CAE network can recognize\nalmost all outliers and the list classification contains the correct label for\nalmost all adversaries.",
    "descriptor": "",
    "authors": [
      "Lijia Yu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15927"
  },
  {
    "id": "arXiv:2106.15930",
    "title": "The Performance Impact of Newton Iterations per Solver Call in  Partitioned Fluid-Structure Interaction",
    "abstract": "The cost of a partitioned fluid-structure interaction scheme is typically\nassessed by the number of coupling iterations required per time step, while\nignoring the Newton loops within the nonlinear sub-solvers. In this work, we\ndiscuss why these single-field iterations deserve more attention when\nevaluating the coupling's efficiency and how to find the optimal number of\nNewton steps per coupling iteration.",
    "descriptor": "",
    "authors": [
      "Thomas Spenke",
      "Norbert Hosters",
      "Marek Behr"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.15930"
  },
  {
    "id": "arXiv:2106.15931",
    "title": "Informed Machine Learning for Improved Similarity Assessment in  Process-Oriented Case-Based Reasoning",
    "abstract": "Currently, Deep Learning (DL) components within a Case-Based Reasoning (CBR)\napplication often lack the comprehensive integration of available domain\nknowledge. The trend within machine learning towards so-called Informed machine\nlearning can help to overcome this limitation. In this paper, we therefore\ninvestigate the potential of integrating domain knowledge into Graph Neural\nNetworks (GNNs) that are used for similarity assessment between semantic graphs\nwithin process-oriented CBR applications. We integrate knowledge in two ways:\nFirst, a special data representation and processing method is used that encodes\nstructural knowledge about the semantic annotations of each graph node and\nedge. Second, the message-passing component of the GNNs is constrained by\nknowledge on legal node mappings. The evaluation examines the quality and\ntraining time of the extended GNNs, compared to the stock models. The results\nshow that both extensions are capable of providing better quality, shorter\ntraining times, or in some configurations both advantages at once.",
    "descriptor": "\nComments: Accepted at the IJCAI-21 workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future Synergies\n",
    "authors": [
      "Maximilian Hoffmann",
      "Ralph Bergmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15931"
  },
  {
    "id": "arXiv:2106.15932",
    "title": "Fixed-Points for Quantitative Equational Logics",
    "abstract": "We develop a fixed-point extension of quantitative equational logic and give\nsemantics in one-bounded complete quantitative algebras. Unlike previous\nrelated work about fixed-points in metric spaces, we are working with the\nnotion of approximate equality rather than exact equality. The result is a\nnovel theory of fixed points which can not only provide solutions to the\ntraditional fixed-point equations but we can also define the rate of\nconvergence to the fixed point. We show that such a theory is the quantitative\nanalogue of a Conway theory and also of an iteration theory; and it reflects\nthe metric coinduction principle. We study the Bellman equation for a Markov\ndecision process as an illustrative example.",
    "descriptor": "",
    "authors": [
      "Radu Mardare",
      "Prakash Panangaden",
      "Gordon Plotkin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.15932"
  },
  {
    "id": "arXiv:2106.15934",
    "title": "Extending On-chain Trust to Off-chain - A Trustworthy Vaccine Shipping  Example",
    "abstract": "Blockchain creates a secure environment on top of strict cryptographic\nassumptions and rigorous security proofs. It permits on-chain interactions to\nachieve trustworthy properties such as traceability, transparency, and\naccountability. However, current blockchain trustworthiness is only confined to\non-chain, creating a \"trust gap\" to the physical, off-chain environment. This\nis due to the lack of a scheme that can truthfully reflect the physical world\nin a real-time and consistent manner. Such an absence hinders further\nreal-world blockchain applications, especially for security-sensitive ones.\nIn this paper, we propose a scheme to extend blockchain trust from on-chain\nto off-chain, and take trustworthy vaccine transportation as an example. Our\nscheme consists of 1) a Trusted Execution Environment (TEE)-enabled trusted\nenvironment monitoring system built with the Arm Cortex-M33 microcontroller\nthat continuously senses the inside of a vaccine box through trusted sensors\nand generates anti-forgery data; and 2) a consistency protocol to upload the\nenvironment status data from the TEE system to blockchain in a truthful,\nreal-time consistent, continuous and fault-tolerant fashion. Our security\nanalysis indicates that no adversary can tamper with the vaccine in any way\nwithout being captured. We carry out an experiment to record the internal\nstatus of a vaccine shipping box during transportation, and the results\nindicate that the proposed system incurs an average latency of 84 ms in local\nsensing and processing followed by an average latency of 130 ms to have the\nsensed data transmitted to and available in the blockchain.",
    "descriptor": "",
    "authors": [
      "Chunchi Liu",
      "Hechuan Guo",
      "Minghui Xu",
      "Shengling Wang",
      "Dongxiao Yu",
      "Jiguo Yu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.15934"
  },
  {
    "id": "arXiv:2106.15935",
    "title": "Towards Verifiable Mutability for Blockchains",
    "abstract": "Due to their immutable log of information, blockchains can be considered as a\ntransparency-enhancing technology. The immutability, however, also introduces\nthreats and challenges with respect to privacy laws and illegal content.\nIntroducing a certain degree of mutability, which enables the possibility to\nstore and remove information, can therefore increase the opportunities for\nblockchains. In this paper, we present a concept for a mutable blockchain\nstructure. Our approach enables the removal of certain blocks, while\nmaintaining the blockchain's verifiability property. Since our concept is\nagnostic to any consensus algorithms, it can be implemented with permissioned\nand permissionless blockchains.",
    "descriptor": "\nComments: Extended Abstract, IEEE Euro S&P 2021 Poster\n",
    "authors": [
      "Erik Daniel",
      "Florian Tschorsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.15935"
  },
  {
    "id": "arXiv:2106.15940",
    "title": "A preliminary approach to knowledge integrity risk assessment in  Wikipedia projects",
    "abstract": "Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n\"health\" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.",
    "descriptor": "\nComments: Accepted at MIS2'21: Misinformation and Misbehavior Mining on the Web Workshop held in conjunction with KDD 2021\n",
    "authors": [
      "Pablo Arag\u00f3n",
      "Diego S\u00e1ez-Trumper"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15940"
  },
  {
    "id": "arXiv:2106.15941",
    "title": "Augmented Shortcuts for Vision Transformers",
    "abstract": "Transformer models have achieved great progress on computer vision tasks\nrecently. The rapid development of vision transformers is mainly contributed by\ntheir high representation ability for extracting informative features from\ninput images. However, the mainstream transformer models are designed with deep\narchitectures, and the feature diversity will be continuously reduced as the\ndepth increases, i.e., feature collapse. In this paper, we theoretically\nanalyze the feature collapse phenomenon and study the relationship between\nshortcuts and feature diversity in these transformer models. Then, we present\nan augmented shortcut scheme, which inserts additional paths with learnable\nparameters in parallel on the original shortcuts. To save the computational\ncosts, we further explore an efficient approach that uses the block-circulant\nprojection to implement augmented shortcuts. Extensive experiments conducted on\nbenchmark datasets demonstrate the effectiveness of the proposed method, which\nbrings about 1% accuracy increase of the state-of-the-art visual transformers\nwithout obviously increasing their parameters and FLOPs.",
    "descriptor": "",
    "authors": [
      "Yehui Tang",
      "Kai Han",
      "Chang Xu",
      "An Xiao",
      "Yiping Deng",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15941"
  },
  {
    "id": "arXiv:2106.15942",
    "title": "On the Role of Hypocrisy in Escaping the Tragedy of the Commons",
    "abstract": "We study the emergence of cooperation in large spatial public goods games.\nWithout employing severe social-pressure against \"defectors\", or alternatively,\nsignificantly rewarding \"cooperators\", theoretical models typically predict a\nsystem collapse in a way that is reminiscent of the \"tragedy-of-the-commons\"\nmetaphor. Drawing on a dynamic network model, this paper demonstrates how\ncooperation can emerge when the social-pressure is mild. This is achieved with\nthe aid of an additional behavior called \"hypocritical\", which appears to be\ncooperative from the external observer's perspective but in fact hardly\ncontributes to the social-welfare. Our model assumes that social-pressure is\ninduced over both defectors and hypocritical players, but the extent of which\nmay differ. Our main result indicates that the emergence of cooperation highly\ndepends on the extent of social-pressure applied against hypocritical players.\nSetting it to be at some intermediate range below the one employed against\ndefectors allows a system composed almost exclusively of defectors to transform\ninto a fully cooperative one quickly. Conversely, when the social-pressure\nagainst hypocritical players is either too low or too high, the system remains\nlocked in a degenerate configuration.",
    "descriptor": "",
    "authors": [
      "Amos Korman",
      "Robin Vacus"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15942"
  },
  {
    "id": "arXiv:2106.15947",
    "title": "SOLO: A Simple Framework for Instance Segmentation",
    "abstract": "Compared to many other dense prediction tasks, e.g., semantic segmentation,\nit is the arbitrary number of instances that has made instance segmentation\nmuch more challenging. In order to predict a mask for each instance, mainstream\napproaches either follow the 'detect-then-segment' strategy (e.g., Mask R-CNN),\nor predict embedding vectors first then cluster pixels into individual\ninstances. In this paper, we view the task of instance segmentation from a\ncompletely new perspective by introducing the notion of \"instance categories\",\nwhich assigns categories to each pixel within an instance according to the\ninstance's location. With this notion, we propose segmenting objects by\nlocations (SOLO), a simple, direct, and fast framework for instance\nsegmentation with strong performance. We derive a few SOLO variants (e.g.,\nVanilla SOLO, Decoupled SOLO, Dynamic SOLO) following the basic principle. Our\nmethod directly maps a raw input image to the desired object categories and\ninstance masks, eliminating the need for the grouping post-processing or the\nbounding box detection. Our approach achieves state-of-the-art results for\ninstance segmentation in terms of both speed and accuracy, while being\nconsiderably simpler than the existing methods. Besides instance segmentation,\nour method yields state-of-the-art results in object detection (from our mask\nbyproduct) and panoptic segmentation. We further demonstrate the flexibility\nand high-quality segmentation of SOLO by extending it to perform one-stage\ninstance-level image matting. Code is available at: https://git.io/AdelaiDet",
    "descriptor": "\nComments: 20 pages. arXiv admin note: substantial text overlap with arXiv:1912.04488, arXiv:2003.10152\n",
    "authors": [
      "Xinlong Wang",
      "Rufeng Zhang",
      "Chunhua Shen",
      "Tao Kong",
      "Lei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15947"
  },
  {
    "id": "arXiv:2106.15961",
    "title": "On Tree Equilibria in Max-Distance Network Creation Games",
    "abstract": "We study the Nash equilibrium and the price of anarchy in the max-distance\nnetwork creation game. The network creation game, first introduced and studied\nby Fabrikant et al., is a classic model for real-world networks from a\ngame-theoretic point of view. In a network creation game with $n$ selfish\nvertex agents, each vertex can build undirected edges incident to a subset of\nthe other vertices. The goal of every agent is to minimize its creation cost\nplus its usage cost, where the creation cost is the unit edge cost $\\alpha$\ntimes the number of edges it builds, and the usage cost is the sum of distances\nto all other agents in the resulting network. The max-distance network creation\ngame, introduced and studied by Demaineet al., is a key variant of the original\ngame, where the usage cost takes into account the maximum distance instead. The\nmain result of this paper shows that for $\\alpha \\geq 23$ all equilibrium\ngraphs in the max-distance network creation game must be trees, while the best\nbound in previous work is $\\alpha > 129$. We also improve the constant upper\nbound on the price of anarchy to $3$ for tree equilibria. Our work brings new\ninsights into the structure of Nash equilibria and takes one step forward in\nsettling the so-called tree conjecture in the max-distance network creation\ngame.",
    "descriptor": "",
    "authors": [
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.15961"
  },
  {
    "id": "arXiv:2106.15962",
    "title": "On the Generative Utility of Cyclic Conditionals",
    "abstract": "We study whether and how can we model a joint distribution $p(x,z)$ using two\nconditional models $p(x|z)$ and $q(z|x)$ that form a cycle. This is motivated\nby the observation that deep generative models, in addition to a likelihood\nmodel $p(x|z)$, often also use an inference model $q(z|x)$ for data\nrepresentation, but they rely on a usually uninformative prior distribution\n$p(z)$ to define a joint distribution, which may render problems like posterior\ncollapse and manifold mismatch. To explore the possibility to model a joint\ndistribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and\ndeterminacy, corresponding to the existence and uniqueness of a joint\ndistribution whose conditional distributions coincide with them. We develop a\ngeneral theory for novel and operable equivalence criteria for compatibility,\nand sufficient conditions for determinacy. Based on the theory, we propose the\nCyGen framework for cyclic-conditional generative modeling, including methods\nto enforce compatibility and use the determined distribution to fit and\ngenerate data. With the prior constraint removed, CyGen better fits data and\ncaptures more representative features, supported by experiments showing better\ngeneration and downstream classification performance.",
    "descriptor": "",
    "authors": [
      "Chang Liu",
      "Haoyue Tang",
      "Tao Qin",
      "Jintao Wang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15962"
  },
  {
    "id": "arXiv:2106.15965",
    "title": "Embedded out-of-distribution detection on an autonomous robot platform",
    "abstract": "Machine learning (ML) is actively finding its way into modern cyber-physical\nsystems (CPS), many of which are safety-critical real-time systems. It is well\nknown that ML outputs are not reliable when testing data are novel with regards\nto model training and validation data, i.e., out-of-distribution (OOD) test\ndata. We implement an unsupervised deep neural network-based OOD detector on a\nreal-time embedded autonomous Duckiebot and evaluate detection performance. Our\nOOD detector produces a success rate of 87.5% for emergency stopping a\nDuckiebot on a braking test bed we designed. We also provide case analysis on\ncomputing resource challenges specific to the Robot Operating System (ROS)\nmiddleware on the Duckiebot.",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Michael Yuhas",
      "Yeli Feng",
      "Daniel Jun Xian Ng",
      "Zahra Rahiminasab",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15965"
  },
  {
    "id": "arXiv:2106.15968",
    "title": "The Impact of Disinformation on a Controversial Debate on Social Media",
    "abstract": "In this work we study how pervasive is the presence of disinformation in the\nItalian debate around immigration on Twitter and the role of automated accounts\nin the diffusion of such content. By characterising the Twitter users with an\n\\textit{Untrustworthiness} score, that tells us how frequently they engage with\ndisinformation content, we are able to see that such bad information\nconsumption habits are not equally distributed across the users; adopting a\nnetwork analysis approach, we can identify communities characterised by a very\nhigh presence of users that frequently share content from unreliable news\nsources. Within this context, social bots tend to inject in the network more\nmalicious content, that often remains confined in a limited number of clusters;\ninstead, they target reliable content in order to diversify their reach. The\nevidence we gather suggests that, at least in this particular case study, there\nis a strong interplay between social bots and users engaging with unreliable\ncontent, influencing the diffusion of the latter across the network.",
    "descriptor": "",
    "authors": [
      "Salvatore Vilella",
      "Alfonso Semeraro",
      "Daniela Paolotti",
      "Giancarlo Ruffo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15968"
  },
  {
    "id": "arXiv:2106.15969",
    "title": "On Completeness of Cost Metrics and Meta-Search Algorithms in  \\$-Calculus",
    "abstract": "In the paper we define three new complexity classes for Turing Machine\nundecidable problems inspired by the famous Cook/Levin's NP-complete complexity\nclass for intractable problems. These are U-complete (Universal complete),\nD-complete (Diagonalization complete) and H-complete (Hypercomputation\ncomplete) classes. We started the population process of these new classes. We\njustify that some super-Turing models of computation, i.e., models going beyond\nTuring machines, are tremendously expressive and they allow to accept arbitrary\nlanguages over a given alphabet including those undecidable ones. We prove also\nthat one of such super-Turing models of computation -- the \\$-Calculus,\ndesigned as a tool for automatic problem solving and automatic programming, has\nalso such tremendous expressiveness. We investigate also completeness of cost\nmetrics and meta-search algorithms in \\$-calculus.",
    "descriptor": "",
    "authors": [
      "Eugene Eberbach"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.15969"
  },
  {
    "id": "arXiv:2106.15971",
    "title": "Evaluation of Thematic Coherence in Microblogs",
    "abstract": "Collecting together microblogs representing opinions about the same topics\nwithin the same timeframe is useful to a number of different tasks and\npractitioners. A major question is how to evaluate the quality of such thematic\nclusters. Here we create a corpus of microblog clusters from three different\ndomains and time windows and define the task of evaluating thematic coherence.\nWe provide annotation guidelines and human annotations of thematic coherence by\njournalist experts. We subsequently investigate the efficacy of different\nautomated evaluation metrics for the task. We consider a range of metrics\nincluding surface level metrics, ones for topic model coherence and text\ngeneration metrics (TGMs). While surface level metrics perform well,\noutperforming topic coherence metrics, they are not as consistent as TGMs. TGMs\nare more reliable than all other metrics considered for capturing thematic\ncoherence in microblog clusters due to being less sensitive to the effect of\ntime windows.",
    "descriptor": "\nComments: ACL 2021 - Long Paper - Association for Computational Linguistics\n",
    "authors": [
      "Iman Munire Bilal",
      "Bo Wang",
      "Maria Liakata",
      "Rob Procter",
      "Adam Tsakalidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15971"
  },
  {
    "id": "arXiv:2106.15983",
    "title": "eXtended Reality for Autism Interventions: The importance of Mediation  and Sensory-Based Approaches",
    "abstract": "eXtended Reality (XR) autism research, ranging from Augmented Reality to\nVirtual Reality, focuses on socio-emotional abilities and high-functioning\nautism. However common autism interventions address the entire spectrum over\nsocial, sensory and mediation issues. To bridge the gap between autism research\nand real interventions, we compared existing literature on XR and autism with\nstakeholders' needs obtained by interviewing 34 skateholders, mainly\npractitioners. It allow us first to suggest XR use cases that could better\nsupport practitioners' interventions, and second to derive design guidelines\naccordingly. Findings demonstrate that collaborative XR sensory-based and\nmediation approaches would benefit the entire spectrum, and encourage to\nconsider the overall intervention context when designing XR protocols.",
    "descriptor": "\nComments: submitted to Journal of Autism and Developmental Disorder\n",
    "authors": [
      "Valentin Bauer",
      "Tifanie Bouchara",
      "Patrick Bourdot"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.15983"
  },
  {
    "id": "arXiv:2106.15984",
    "title": "Context-Aware Attention-Based Data Augmentation for POI Recommendation",
    "abstract": "With the rapid growth of location-based social networks (LBSNs),\nPoint-Of-Interest (POI) recommendation has been broadly studied in this decade.\nRecently, the next POI recommendation, a natural extension of POI\nrecommendation, has attracted much attention. It aims at suggesting the next\nPOI to a user in spatial and temporal context, which is a practical yet\nchallenging task in various applications. Existing approaches mainly model the\nspatial and temporal information, and memorize historical patterns through\nuser's trajectories for recommendation. However, they suffer from the negative\nimpact of missing and irregular check-in data, which significantly influences\nthe model performance. In this paper, we propose an attention-based\nsequence-to-sequence generative model, namely POI-Augmentation Seq2Seq\n(PA-Seq2Seq), to address the sparsity of training set by making check-in\nrecords to be evenly-spaced. Specifically, the encoder summarises each check-in\nsequence and the decoder predicts the possible missing check-ins based on the\nencoded information. In order to learn time-aware correlation among user\nhistory, we employ local attention mechanism to help the decoder focus on a\nspecific range of context information when predicting a certain missing\ncheck-in point. Extensive experiments have been conducted on two real-world\ncheck-in datasets, Gowalla and Brightkite, for performance and effectiveness\nevaluation.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Yadan Luo",
      "Zheng Zhang",
      "Shazia W. Sadiq",
      "Peng Cui"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.15984"
  },
  {
    "id": "arXiv:2106.15986",
    "title": "Cross-lingual alignments of ELMo contextual embeddings",
    "abstract": "Building machine learning prediction models for a specific NLP task requires\nsufficient training data, which can be difficult to obtain for low-resource\nlanguages. Cross-lingual embeddings map word embeddings from a low-resource\nlanguage to a high-resource language so that a prediction model trained on data\nfrom the high-resource language can also be used in the low-resource language.\nTo produce cross-lingual mappings of recent contextual embeddings, anchor\npoints between the embedding spaces have to be words in the same context. We\naddress this issue with a new method for creating datasets for cross-lingual\ncontextual alignments. Based on that, we propose novel cross-lingual mapping\nmethods for ELMo embeddings. Our linear mapping methods use existing vecmap and\nMUSE alignments on contextual ELMo embeddings. Our new nonlinear ELMoGAN\nmapping method is based on GANs and does not assume isomorphic embedding\nspaces. We evaluate the proposed mapping methods on nine languages, using two\ndownstream tasks, NER and dependency parsing. The ELMoGAN method performs well\non the NER task, with low cross-lingual loss compared to direct training on\nsome languages. In the dependency parsing, linear alignment variants are more\nsuccessful.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Matej Ul\u010dar",
      "Marko Robnik-\u0160ikonja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15986"
  },
  {
    "id": "arXiv:2106.15987",
    "title": "Learning without Data: Physics-Informed Neural Networks for Fast  Time-Domain Simulation",
    "abstract": "In order to drastically reduce the heavy computational burden associated with\ntime-domain simulations, this paper introduces a Physics-Informed Neural\nNetwork (PINN) to directly learn the solutions of power system dynamics. In\ncontrast to the limitations of classical model order reduction approaches,\ncommonly used to accelerate time-domain simulations, PINNs can universally\napproximate any continuous function with an arbitrary degree of accuracy. One\nof the novelties of this paper is that we avoid the need for any training data.\nWe achieve this by incorporating the governing differential equations and an\nimplicit Runge-Kutta (RK) integration scheme directly into the training process\nof the PINN; through this approach, PINNs can predict the trajectory of a\ndynamical power system at any discrete time step. The resulting\nRunge-Kutta-based physics-informed neural networks (RK-PINNs) can yield up to\n100 times faster evaluations of the dynamics compared to standard time-domain\nsimulations. We demonstrate the methodology on a single-machine infinite bus\nsystem governed by the swing equation. We show that RK-PINNs can accurately and\nquickly predict the solution trajectories.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids 2021(SmartGridComm)\n",
    "authors": [
      "Jochen Stiasny",
      "Samuel Chevalier",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15987"
  },
  {
    "id": "arXiv:2106.15989",
    "title": "Word-level Sign Language Recognition with Multi-stream Neural Networks  Focusing on Local Regions",
    "abstract": "In recent years, Word-level Sign Language Recognition (WSLR) research has\ngained popularity in the computer vision community, and thus various approaches\nhave been proposed. Among these approaches, the method using I3D network\nachieves the highest recognition accuracy on large public datasets for WSLR.\nHowever, the method with I3D only utilizes appearance information of the upper\nbody of the signers to recognize sign language words. On the other hand, in\nWSLR, the information of local regions, such as the hand shape and facial\nexpression, and the positional relationship among the body and both hands are\nimportant. Thus in this work, we utilized local region images of both hands and\nface, along with skeletal information to capture local information and the\npositions of both hands relative to the body, respectively. In other words, we\npropose a novel multi-stream WSLR framework, in which a stream with local\nregion images and a stream with skeletal information are introduced by\nextending I3D network to improve the recognition accuracy of WSLR. From the\nexperimental results on WLASL dataset, it is evident that the proposed method\nhas achieved about 15% improvement in the Top-1 accuracy than the existing\nconventional methods.",
    "descriptor": "",
    "authors": [
      "Mizuki Maruyama",
      "Shuvozit Ghose",
      "Katsufumi Inoue",
      "Partha Pratim Roy",
      "Masakazu Iwamura",
      "Michifumi Yoshioka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.15989"
  },
  {
    "id": "arXiv:2106.15991",
    "title": "Cyclist Trajectory Forecasts by Incorporation of Multi-View Video  Information",
    "abstract": "This article presents a novel approach to incorporate visual cues from\nvideo-data from a wide-angle stereo camera system mounted at an urban\nintersection into the forecast of cyclist trajectories. We extract features\nfrom image and optical flow (OF) sequences using 3D convolutional neural\nnetworks (3D-ConvNet) and combine them with features extracted from the\ncyclist's past trajectory to forecast future cyclist positions. By the use of\nadditional information, we are able to improve positional accuracy by about 7.5\n% for our test dataset and by up to 22 % for specific motion types compared to\na method solely based on past trajectories. Furthermore, we compare the use of\nimage sequences to the use of OF sequences as additional information, showing\nthat OF alone leads to significant improvements in positional accuracy. By\ntraining and testing our methods using a real-world dataset recorded at a\nheavily frequented public intersection and evaluating the methods' runtimes, we\ndemonstrate the applicability in real traffic scenarios. Our code and parts of\nour dataset are made publicly available.",
    "descriptor": "",
    "authors": [
      "Stefan Zernetsch",
      "Oliver Trupp",
      "Viktor Kress",
      "Konrad Doll",
      "Bernhard Sick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15991"
  },
  {
    "id": "arXiv:2106.15992",
    "title": "Perfect Sampling in Infinite Spin Systems via Strong Spatial Mixing",
    "abstract": "We present a simple algorithm that perfectly samples configurations from the\nunique Gibbs measure of a spin system on a potentially infinite graph $G$. The\nsampling algorithm assumes strong spatial mixing together with subexponential\ngrowth of $G$. It produces a finite window onto a perfect sample from the Gibbs\ndistribution. The run-time is linear in the size of the window.",
    "descriptor": "",
    "authors": [
      "Konrad Anand",
      "Mark Jerrum"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.15992"
  },
  {
    "id": "arXiv:2106.15998",
    "title": "Single-Step Adversarial Training for Semantic Segmentation",
    "abstract": "Even though deep neural networks succeed on many different tasks including\nsemantic segmentation, they lack on robustness against adversarial examples. To\ncounteract this exploit, often adversarial training is used. However, it is\nknown that adversarial training with weak adversarial attacks (e.g. using the\nFast Gradient Method) does not improve the robustness against stronger attacks.\nRecent research shows that it is possible to increase the robustness of such\nsingle-step methods by choosing an appropriate step size during the training.\nFinding such a step size, without increasing the computational effort of\nsingle-step adversarial training, is still an open challenge. In this work we\naddress the computationally particularly demanding task of semantic\nsegmentation and propose a new step size control algorithm that increases the\nrobustness of single-step adversarial training. The proposed algorithm does not\nincrease the computational effort of single-step adversarial training\nconsiderably and also simplifies training, because it is free of\nmeta-parameter. We show that the robustness of our approach can compete with\nmulti-step adversarial training on two popular benchmarks for semantic\nsegmentation.",
    "descriptor": "",
    "authors": [
      "Daniel Wiens",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.15998"
  },
  {
    "id": "arXiv:2106.16000",
    "title": "Mutual-GAN: Towards Unsupervised Cross-Weather Adaptation with Mutual  Information Constraint",
    "abstract": "Convolutional neural network (CNN) have proven its success for semantic\nsegmentation, which is a core task of emerging industrial applications such as\nautonomous driving. However, most progress in semantic segmentation of urban\nscenes is reported on standard scenarios, i.e., daytime scenes with favorable\nillumination conditions. In practical applications, the outdoor weather and\nillumination are changeable, e.g., cloudy and nighttime, which results in a\nsignificant drop of semantic segmentation accuracy of CNN only trained with\ndaytime data. In this paper, we propose a novel generative adversarial network\n(namely Mutual-GAN) to alleviate the accuracy decline when daytime-trained\nneural network is applied to videos captured under adverse weather conditions.\nThe proposed Mutual-GAN adopts mutual information constraint to preserve\nimage-objects during cross-weather adaptation, which is an unsolved problem for\nmost unsupervised image-to-image translation approaches (e.g., CycleGAN). The\nproposed Mutual-GAN is evaluated on two publicly available driving video\ndatasets (i.e., CamVid and SYNTHIA). The experimental results demonstrate that\nour Mutual-GAN can yield visually plausible translated images and significantly\nimprove the semantic segmentation accuracy of daytime-trained deep learning\nnetwork while processing videos under challenging weathers.",
    "descriptor": "\nComments: An extension of our MICCAI paper\n",
    "authors": [
      "Jiawei Chen",
      "Yuexiang Li",
      "Kai Ma",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.16000"
  },
  {
    "id": "arXiv:2106.16002",
    "title": "Distributed Nash Equilibrium Seeking under Quantization Communication",
    "abstract": "This paper investigates Nash equilibrium (NE) seeking problems for\nnoncooperative games over multi-agent networks with finite bandwidth\ncommunication. A distributed quantized algorithm is presented, which consists\nof local gradient play, distributed decision estimating, and adaptive\nquantization. Exponential convergence of the algorithm is established, and a\nrelationship between the convergence rate and the bandwidth is quantitatively\nanalyzed. Finally, a simulation of an energy consumption game is presented to\nvalidate the proposed results.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ziqin Chen",
      "Ji Ma",
      "Shu Liang",
      "Li Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.16002"
  },
  {
    "id": "arXiv:2106.16003",
    "title": "Adaptive Cheapest Path First Scheduling in a Transport-Layer Multi-Path  Tunnel Context",
    "abstract": "Bundling multiple access technologies increases capacity, resiliency and\nrobustness of network connections. Multi-access is currently being standardized\nin the ATSSS framework in 3GPP, supporting different access bundling\nstrategies. Within ATSSS, a multipath scheduler needs to decide which path to\nuse for each user packet based on path characteristics. The Cheapest Path First\n(CPF) scheduler aims to utilize the cheapest path (e.g. WiFi) before sending\npackets over other paths (e.g. cellular). In this paper, we demonstrate that\nusing CPF with an MP-DCCP tunnel may lead to sub-optimal performance. This is\ndue to adverse interactions between the scheduler and end-to-end and tunnel\ncongestion control. Hence, we design the Adaptive Cheapest Path First (ACPF)\nscheduler that limits queue buildup in the primary bottleneck and moves traffic\nto the secondary path earlier. We implement ACPF over both TCP and DCCP\ncongestion controlled tunnels. Our evaluation shows that ACPF improves the\naverage throughput over CPF between 24% to 86%.",
    "descriptor": "\nComments: To appear at Applied Networking Research Workshop (ANRW 2021)\n",
    "authors": [
      "Marcus Pieska",
      "Alexander Rabitsch",
      "Anna Brunstrom",
      "Andreas Kassler",
      "Markus Amend"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.16003"
  },
  {
    "id": "arXiv:2106.16004",
    "title": "What can linear interpolation of neural network loss landscapes tell us?",
    "abstract": "Studying neural network loss landscapes provides insights into the nature of\nthe underlying optimization problems. Unfortunately, loss landscapes are\nnotoriously difficult to visualize in a human-comprehensible fashion. One\ncommon way to address this problem is to plot linear slices of the landscape,\nfor example from the initial state of the network to the final state after\noptimization. On the basis of this analysis, prior work has drawn broader\nconclusions about the difficulty of the optimization problem. In this paper, we\nput inferences of this kind to the test, systematically evaluating how linear\ninterpolation and final performance vary when altering the data, choice of\ninitialization, and other optimizer and architecture design choices. Further,\nwe use linear interpolation to study the role played by individual layers and\nsubstructures of the network. We find that certain layers are more sensitive to\nthe choice of initialization and optimizer hyperparameter settings, and we\nexploit these observations to design custom optimization schemes. However, our\nresults cast doubt on the broader intuition that the presence or absence of\nbarriers when interpolating necessarily relates to the success of optimization.",
    "descriptor": "",
    "authors": [
      "Tiffany Vlaar",
      "Jonathan Frankle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16004"
  },
  {
    "id": "arXiv:2106.16006",
    "title": "Improving the Efficiency of Transformers for Resource-Constrained  Devices",
    "abstract": "Transformers provide promising accuracy and have become popular and used in\nvarious domains such as natural language processing and computer vision.\nHowever, due to their massive number of model parameters, memory and\ncomputation requirements, they are not suitable for resource-constrained\nlow-power devices. Even with high-performance and specialized devices, the\nmemory bandwidth can become a performance-limiting bottleneck. In this paper,\nwe present a performance analysis of state-of-the-art vision transformers on\nseveral devices. We propose to reduce the overall memory footprint and memory\ntransfers by clustering the model parameters. We show that by using only 64\nclusters to represent model parameters, it is possible to reduce the data\ntransfer from the main memory by more than 4x, achieve up to 22% speedup and\n39% energy savings on mobile devices with less than 0.1% accuracy loss.",
    "descriptor": "\nComments: This paper is accepted as a full paper at 24th Euromicro Conference on Digital System Design (DSD)\n",
    "authors": [
      "Hamid Tabani",
      "Ajay Balasubramaniam",
      "Shabbir Marzban",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16006"
  },
  {
    "id": "arXiv:2106.16009",
    "title": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "abstract": "In applications such as object tracking, time-series data inevitably carry\nmissing observations. Following the success of deep learning-based models for\nvarious sequence learning tasks, these models increasingly replace classic\napproaches in object tracking applications for inferring the object motions\nstate. While traditional tracking approaches can deal with missing\nobservations, most of their deep counterparts are, by default, not suited for\nthis.\nTowards this end, this paper introduces a transformer-based approach for\nhandling missing observations in variable input length trajectory data. The\nmodel is formed indirectly by successively increasing the complexity of the\ndemanded inference tasks. Starting from reproducing noise-free trajectories,\nthe model then learns to infer trajectories from noisy inputs. By providing\nmissing tokens, binary-encoded missing events, the model learns to in-attend to\nmissing data and infers a complete trajectory conditioned on the remaining\ninputs. In the case of a sequence of successive missing events, the model then\nacts as a pure prediction model. The model's abilities are demonstrated on\nsynthetic data and real-world data reflecting prototypical object tracking\nscenarios.",
    "descriptor": "",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16009"
  },
  {
    "id": "arXiv:2106.16013",
    "title": "Zero-Shot Estimation of Base Models' Weights in Ensemble of Machine  Reading Comprehension Systems for Robust Generalization",
    "abstract": "One of the main challenges of the machine reading comprehension (MRC) models\nis their fragile out-of-domain generalization, which makes these models not\nproperly applicable to real-world general-purpose question answering problems.\nIn this paper, we leverage a zero-shot weighted ensemble method for improving\nthe robustness of out-of-domain generalization in MRC models. In the proposed\nmethod, a weight estimation module is used to estimate out-of-domain weights,\nand an ensemble module aggregate several base models' predictions based on\ntheir weights. The experiments indicate that the proposed method not only\nimproves the final accuracy, but also is robust against domain changes.",
    "descriptor": "",
    "authors": [
      "Razieh Baradaran",
      "Hossein Amirkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16013"
  },
  {
    "id": "arXiv:2106.16015",
    "title": "Close relatives (of Feedback Vertex Set), revisited",
    "abstract": "At IPEC 2020, Bergougnoux, Bonnet, Brettell, and Kwon showed that a number of\nproblems related to the classic Feedback Vertex Set (FVS) problem do not admit\na $2^{o(k \\log k)} \\cdot n^{\\mathcal{O}(1)}$-time algorithm on graphs of\ntreewidth at most $k$, assuming the Exponential Time Hypothesis. This contrasts\nwith the $3^{k} \\cdot k^{\\mathcal{O}(1)} \\cdot n$-time algorithm for FVS using\nthe Cut&Count technique.\nDuring their live talk at IPEC 2020, Bergougnoux et al.~posed a number of\nopen questions, which we answer in this work.\n- Subset Even Cycle Transversal, Subset Odd Cycle Transversal, Subset\nFeedback Vertex Set can be solved in time $2^{\\mathcal{O}(k \\log k)} \\cdot n$\nin graphs of treewidth at most $k$. This matches a lower bound for Even Cycle\nTransversal of Bergougnoux et al.~and improves the polynomial factor in some of\ntheir upper bounds.\n- Subset Feedback Vertex Set and Node Multiway Cut can be solved in time\n$2^{\\mathcal{O}(k \\log k)} \\cdot n$, if the input graph is given as a\nclique-width expression of size $n$ and width $k$.\n- Odd Cycle Transversal can be solved in time $4^k \\cdot k^{\\mathcal{O}(1)}\n\\cdot n$ if the input graph is given as a clique-width expression of size $n$\nand width $k$. Furthermore, the existence of a constant $\\varepsilon > 0$ and\nan algorithm performing this task in time $(4-\\varepsilon)^k \\cdot\nn^{\\mathcal{O}(1)}$ would contradict the Strong Exponential Time Hypothesis.",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "Hugo Jacob",
      "Thomas Bellitto",
      "Oscar Defrain",
      "Marcin Pilipczuk"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16015"
  },
  {
    "id": "arXiv:2106.16016",
    "title": "EVScout2.0: Electric Vehicle Profiling Through Charging Profile",
    "abstract": "EVs (Electric Vehicles) represent a green alternative to traditional\nfuel-powered vehicles. To enforce their widespread use, both the technical\ndevelopment and the security of users shall be guaranteed. Privacy of users\nrepresents one of the possible threats impairing EVs adoption. In particular,\nrecent works showed the feasibility of identifying EVs based on the current\nexchanged during the charging phase. In fact, while the resource negotiation\nphase runs over secure communication protocols, the signal exchanged during the\nactual charging contains features peculiar to each EV. A suitable feature\nextractor can hence associate such features to each EV, in what is commonly\nknown as profiling. In this paper, we propose EVScout2.0, an extended and\nimproved version of our previously proposed framework to profile EVs based on\ntheir charging behavior. By exploiting the current and pilot signals exchanged\nduring the charging phase, our scheme is able to extract features peculiar for\neach EV, allowing hence for their profiling. We implemented and tested\nEVScout2.0 over a set of real-world measurements considering over 7500 charging\nsessions from a total of 137 EVs. In particular, numerical results show the\nsuperiority of EVScout2.0 with respect to the previous version. EVScout2.0 can\nprofile EVs, attaining a maximum of 0.88 recall and 0.88 precision. To the best\nof the authors' knowledge, these results set a new benchmark for upcoming\nprivacy research for large datasets of EVs.",
    "descriptor": "",
    "authors": [
      "Alessandro Brighente",
      "Mauro Conti",
      "Denis Donadel",
      "Federico Turrin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.16016"
  },
  {
    "id": "arXiv:2106.16020",
    "title": "Anomaly Detection: How to Artificially Increase your F1-Score with a  Biased Evaluation Protocol",
    "abstract": "Anomaly detection is a widely explored domain in machine learning. Many\nmodels are proposed in the literature, and compared through different metrics\nmeasured on various datasets. The most popular metrics used to compare\nperformances are F1-score, AUC and AVPR. In this paper, we show that F1-score\nand AVPR are highly sensitive to the contamination rate. One consequence is\nthat it is possible to artificially increase their values by modifying the\ntrain-test split procedure. This leads to misleading comparisons between\nalgorithms in the literature, especially when the evaluation protocol is not\nwell detailed. Moreover, we show that the F1-score and the AVPR cannot be used\nto compare performances on different datasets as they do not reflect the\nintrinsic difficulty of modeling such data. Based on these observations, we\nclaim that F1-score and AVPR should not be used as metrics for anomaly\ndetection. We recommend a generic evaluation procedure for unsupervised anomaly\ndetection, including the use of other metrics such as the AUC, which are more\nrobust to arbitrary choices in the evaluation protocol.",
    "descriptor": "\nComments: 16 pages, 7 figures, to be published in ECML-PKDD 2021, for official implementation see this https URL\n",
    "authors": [
      "Damien Fourure",
      "Muhammad Usama Javaid",
      "Nicolas Posocco",
      "Simon Tihon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16020"
  },
  {
    "id": "arXiv:2106.16026",
    "title": "High-order finite element methods for nonlinear convection-diffusion  equation on time-varying domain",
    "abstract": "A high-order finite element method is proposed to solve the nonlinear\nconvection-diffusion equation on a time-varying domain whose boundary is\nimplicitly driven by the solution of the equation. The method is semi-implicit\nin the sense that the boundary is traced explicitly with a high-order\nsurface-tracking algorithm, while the convection-diffusion equation is solved\nimplicitly with high-order backward differentiation formulas and\nfictitious-domain finite element methods. By two numerical experiments for\nseverely deforming domains, we show that optimal convergence orders are\nobtained in energy norm for third-order and fourth-order methods.",
    "descriptor": "",
    "authors": [
      "Chuwen Ma",
      "Weiying Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16026"
  },
  {
    "id": "arXiv:2106.16028",
    "title": "Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring",
    "abstract": "Real-time video deblurring still remains a challenging task due to the\ncomplexity of spatially and temporally varying blur itself and the requirement\nof low computational cost. To improve the network efficiency, we adopt residual\ndense blocks into RNN cells, so as to efficiently extract the spatial features\nof the current frame. Furthermore, a global spatio-temporal attention module is\nproposed to fuse the effective hierarchical features from past and future\nframes to help better deblur the current frame. Another issue needs to be\naddressed urgently is the lack of a real-world benchmark dataset. Thus, we\ncontribute a novel dataset (BSD) to the community, by collecting paired\nblurry/sharp video clips using a co-axis beam splitter acquisition system.\nExperimental results show that the proposed method (ESTRNN) can achieve better\ndeblurring performance both quantitatively and qualitatively with less\ncomputational cost against state-of-the-art video deblurring methods. In\naddition, cross-validation experiments between datasets illustrate the high\ngenerality of BSD over the synthetic datasets. The code and dataset are\nreleased at https://github.com/zzh-tech/ESTRNN.",
    "descriptor": "\nComments: Extended journal version of the ECCV2020 paper (under review)\n",
    "authors": [
      "Zhihang Zhong",
      "Ye Gao",
      "Yinqiang Zheng",
      "Bo Zheng",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16028"
  },
  {
    "id": "arXiv:2106.16032",
    "title": "Robust Inertial-aided Underwater Localization and Navigation based on  Imaging Sonar Keyframes",
    "abstract": "Imaging sonars have shown better flexibility than optical cameras in\nunderwater localization and navigation for autonomous underwater vehicles\n(AUVs). However, the sparsity of underwater acoustic features and the loss of\nelevation angle in sonar frames have imposed degeneracy cases, namely\nunder-constrained or unobservable cases according to optimization-based or\nEKF-based simultaneous localization and mapping (SLAM). In these cases, the\nrelative ambiguous sensor poses and landmarks cannot be triangulated. To handle\nthis, this paper proposes a robust imaging sonar SLAM approach based on sonar\nkeyframes (KFs) and an elastic sliding window. The degeneracy cases are further\nanalyzed and the triangulation property of 2D landmarks in arbitrary motion has\nbeen proved. These degeneracy cases are discriminated and the sonar KFs are\nselected via saliency criteria to extract and save the informative constraints\nfrom previous sonar measurements. Incorporating the inertial measurements, an\nelastic sliding windowed back-end optimization is proposed to mostly utilize\nthe past salient sonar frames and also restrain the optimization scale.\nComparative experiments validate the effectiveness of the proposed method and\nits robustness to outliers from the wrong data association, even without loop\nclosure.",
    "descriptor": "\nComments: 11 pages, 12 figures, submitted to journal\n",
    "authors": [
      "Yang Xu",
      "Ronghao Zheng",
      "Meiqin liu",
      "Senlin Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.16032"
  },
  {
    "id": "arXiv:2106.16034",
    "title": "AutoLAW: Augmented Legal Reasoning through Legal Precedent Prediction",
    "abstract": "This paper demonstrate how NLP can be used to address an unmet need of the\nlegal community and increase access to justice. The paper introduces Legal\nPrecedent Prediction (LPP), the task of predicting relevant passages from\nprecedential court decisions given the context of a legal argument. To this\nend, the paper showcases a BERT model, trained on 530,000 examples of legal\narguments made by U.S. federal judges, to predict relevant passages from\nprecedential court decisions given the context of a legal argument. In 96% of\nunseen test examples the correct target passage is among the top-10 predicted\npassages. The same model is able to predict relevant precedent given a short\nsummary of a complex and unseen legal brief, predicting the precedent that was\nactually cited by the brief's co-author, former U.S. Solicitor General and\ncurrent U.S. Supreme Court Justice Elena Kagan.",
    "descriptor": "",
    "authors": [
      "Robert Zev Mahari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16034"
  },
  {
    "id": "arXiv:2106.16036",
    "title": "A Generative Model for Raw Audio Using Transformer Architectures",
    "abstract": "This paper proposes a novel way of doing audio synthesis at the waveform\nlevel using Transformer architectures. We propose a deep neural network for\ngenerating waveforms, similar to wavenet \\cite{oord2016wavenet}. This is fully\nprobabilistic, auto-regressive, and causal, i.e. each sample generated depends\nonly on the previously observed samples. Our approach outperforms a widely used\nwavenet architecture by up to 9\\% on a similar dataset for predicting the next\nstep. Using the attention mechanism, we enable the architecture to learn which\naudio samples are important for the prediction of the future sample. We show\nhow causal transformer generative models can be used for raw waveform\nsynthesis. We also show that this performance can be improved by another 2\\% by\nconditioning samples over a wider context. The flexibility of the current model\nto synthesize audio from latent representations suggests a large number of\npotential applications. The novel approach of using generative transformer\narchitectures for raw audio synthesis is, however, still far away from\ngenerating any meaningful music, without using latent codes/meta-data to aid\nthe generation process.",
    "descriptor": "\nComments: DAFX 2021\n",
    "authors": [
      "Prateek Verma",
      "Chris Chafe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.16036"
  },
  {
    "id": "arXiv:2106.16037",
    "title": "Learning to Minimize Age of Information over an Unreliable Channel with  Energy Harvesting",
    "abstract": "The time average expected age of information (AoI) is studied for status\nupdates sent over an error-prone channel from an energy-harvesting transmitter\nwith a finite-capacity battery. Energy cost of sensing new status updates is\ntaken into account as well as the transmission energy cost better capturing\npractical systems. The optimal scheduling policy is first studied under the\nhybrid automatic repeat request (HARQ) protocol when the channel and energy\nharvesting statistics are known, and the existence of a threshold-based optimal\npolicy is shown. For the case of unknown environments, average-cost\nreinforcement-learning algorithms are proposed that learn the system parameters\nand the status update policy in real-time. The effectiveness of the proposed\nmethods is demonstrated through numerical results.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1902.09467\n",
    "authors": [
      "Elif Tugce Ceran",
      "Deniz Gunduz",
      "Andras Gyorgy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.16037"
  },
  {
    "id": "arXiv:2106.16038",
    "title": "ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin  Information",
    "abstract": "Recent pretraining models in Chinese neglect two important aspects specific\nto the Chinese language: glyph and pinyin, which carry significant syntax and\nsemantic information for language understanding. In this work, we propose\nChineseBERT, which incorporates both the {\\it glyph} and {\\it pinyin}\ninformation of Chinese characters into language model pretraining. The glyph\nembedding is obtained based on different fonts of a Chinese character, being\nable to capture character semantics from the visual features, and the pinyin\nembedding characterizes the pronunciation of Chinese characters, which handles\nthe highly prevalent heteronym phenomenon in Chinese (the same character has\ndifferent pronunciations with different meanings). Pretrained on large-scale\nunlabeled Chinese corpus, the proposed ChineseBERT model yields significant\nperformance boost over baseline models with fewer training steps. The porpsoed\nmodel achieves new SOTA performances on a wide range of Chinese NLP tasks,\nincluding machine reading comprehension, natural language inference, text\nclassification, sentence pair matching, and competitive performances in named\nentity recognition. Code and pretrained models are publicly available at\nhttps://github.com/ShannonAI/ChineseBert.",
    "descriptor": "\nComments: To appear at ACL2021\n",
    "authors": [
      "Zijun Sun",
      "Xiaoya Li",
      "Xiaofei Sun",
      "Yuxian Meng",
      "Xiang Ao",
      "Qing He",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16038"
  },
  {
    "id": "arXiv:2106.16039",
    "title": "End-to-End Learning of OFDM Waveforms with PAPR and ACLR Constraints",
    "abstract": "Orthogonal frequency-division multiplexing (OFDM) is widely used in modern\nwireless networks thanks to its efficient handling of multipath environment.\nHowever, it suffers from a poor peak-to-average power ratio (PAPR) which\nrequires a large power backoff, degrading the power amplifier (PA) efficiency.\nIn this work, we propose to use a neural network (NN) at the transmitter to\nlearn a high-dimensional modulation scheme allowing to control the PAPR and\nadjacent channel leakage ratio (ACLR). On the receiver side, a NN-based\nreceiver is implemented to carry out demapping of the transmitted bits. The two\nNNs operate on top of OFDM, and are jointly optimized in and end-to-end manner\nusing a training algorithm that enforces constraints on the PAPR and ACLR.\nSimulation results show that the learned waveforms enable higher information\nrates than a tone reservation baseline, while satisfying predefined PAPR and\nACLR targets.",
    "descriptor": "",
    "authors": [
      "Mathieu Goutay",
      "Fay\u00e7al Ait Aoudia",
      "Jakob Hoydis",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.16039"
  },
  {
    "id": "arXiv:2106.16042",
    "title": "Latent Space Model for Higher-order Networks and Generalized Tensor  Decomposition",
    "abstract": "We introduce a unified framework, formulated as general latent space models,\nto study complex higher-order network interactions among multiple entities. Our\nframework covers several popular models in recent network analysis literature,\nincluding mixture multi-layer latent space model and hypergraph latent space\nmodel. We formulate the relationship between the latent positions and the\nobserved data via a generalized multilinear kernel as the link function. While\nour model enjoys decent generality, its maximum likelihood parameter estimation\nis also convenient via a generalized tensor decomposition procedure.We propose\na novel algorithm using projected gradient descent on Grassmannians. We also\ndevelop original theoretical guarantees for our algorithm. First, we show its\nlinear convergence under mild conditions. Second, we establish finite-sample\nstatistical error rates of latent position estimation, determined by the signal\nstrength, degrees of freedom and the smoothness of link function, for both\ngeneral and specific latent space models. We demonstrate the effectiveness of\nour method on synthetic data. We also showcase the merit of our method on two\nreal-world datasets that are conventionally described by different specific\nmodels in producing meaningful and interpretable parameter estimations and\naccurate link prediction. We demonstrate the effectiveness of our method on\nsynthetic data. We also showcase the merit of our method on two real-world\ndatasets that are conventionally described by different specific models in\nproducing meaningful and interpretable parameter estimations and accurate link\nprediction.",
    "descriptor": "",
    "authors": [
      "Zhongyuan Lyu",
      "Dong Xia",
      "Yuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.16042"
  },
  {
    "id": "arXiv:2106.16046",
    "title": "Exploring Context Modeling Techniques on the Spatiotemporal Crowd Flow  Prediction",
    "abstract": "In the big data and AI era, context is widely exploited as extra information\nwhich makes it easier to learn a more complex pattern in machine learning\nsystems. However, most of the existing related studies seldom take context into\naccount. The difficulty lies in the unknown generalization ability of both\ncontext and its modeling techniques across different scenarios. To fill the\nabove gaps, we conduct a large-scale analytical and empirical study on the\nspatiotemporal crowd prediction (STCFP) problem that is a widely-studied and\nhot research topic. We mainly make three efforts:(i) we develop new taxonomy\nabout both context features and context modeling techniques based on extensive\ninvestigations in prevailing STCFP research; (ii) we conduct extensive\nexperiments on seven datasets with hundreds of millions of records to\nquantitatively evaluate the generalization ability of both distinct context\nfeatures and context modeling techniques; (iii) we summarize some guidelines\nfor researchers to conveniently utilize context in diverse applications.",
    "descriptor": "",
    "authors": [
      "Liyue Chen",
      "Leye Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.16046"
  },
  {
    "id": "arXiv:2106.16049",
    "title": "Relational VAE: A Continuous Latent Variable Model for Graph Structured  Data",
    "abstract": "Graph Networks (GNs) enable the fusion of prior knowledge and relational\nreasoning with flexible function approximations. In this work, a general\nGN-based model is proposed which takes full advantage of the relational\nmodeling capabilities of GNs and extends these to probabilistic modeling with\nVariational Bayes (VB). To that end, we combine complementary pre-existing\napproaches on VB for graph data and propose an approach that relies on\ngraph-structured latent and conditioning variables. It is demonstrated that\nNeural Processes can also be viewed through the lens of the proposed model. We\nshow applications on the problem of structured probability density modeling for\nsimulated and real wind farm monitoring data, as well as on the meta-learning\nof simulated Gaussian Process data. We release the source code, along with the\nsimulated datasets.",
    "descriptor": "\nComments: Code and simulated datasets will be released after finalization of peer review\n",
    "authors": [
      "Charilaos Mylonas",
      "Imad Abdallah",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16049"
  },
  {
    "id": "arXiv:2106.16050",
    "title": "Ethical AI-Powered Regression Test Selection",
    "abstract": "Test automation is common in software development; often one tests repeatedly\nto identify regressions. If the amount of test cases is large, one may select a\nsubset and only use the most important test cases. The regression test\nselection (RTS) could be automated and enhanced with Artificial Intelligence\n(AI-RTS). This however could introduce ethical challenges. While such\nchallenges in AI are in general well studied, there is a gap with respect to\nethical AI-RTS. By exploring the literature and learning from our experiences\nof developing an industry AI-RTS tool, we contribute to the literature by\nidentifying three challenges (assigning responsibility, bias in decision-making\nand lack of participation) and three approaches (explicability, supervision and\ndiversity). Additionally, we provide a checklist for ethical AI-RTS to help\nguide the decision-making of the stakeholders involved in the process.",
    "descriptor": "\nComments: 2 pages, 1 figure, accepted to AITest'21\n",
    "authors": [
      "Per Erik Strandberg",
      "Mirgita Frasheri",
      "Eduard Paul Enoiu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.16050"
  },
  {
    "id": "arXiv:2106.16051",
    "title": "An Experimental Analysis on Drone-Mounted Access Points for Improved  Latency-Reliability",
    "abstract": "The anticipated densification of contemporary communications infrastructure\nexpects the use of drone small cells (DSCs). Thus, we experimentally evaluate\nthe capability of providing local and personalized coverage with a drone\nmounted Wi-Fi access point that uses the nearby LTE infrastructure as a\nbackhaul in areas with mixed line of sight(LoS) and Non-LoS (NLoS) links to the\nlocal cellular infrastructure. To assess the potential of DSCs for reliable and\nlow latency communication of outdoor users, we measure the channel quality and\nthe total round trip latency of the system. For a drone following the ground\nuser, the DSC-provided network extends the coverage for an extra 6.4% when\ncompared to the classical LTE-direct link. Moreover, the DSC setup provides\nlatencies that are consistently smaller than 50 msfor 95% of the experiment.\nWithin the coverage of the LTE-direct connection, we observed a latency ceiling\nof 120ms for 95% reliability of the LTE-direct connection. The highest latency\nobserved for the DSC system was 1200ms, while the LTE-direct link never\nexceeded 500 ms. As such, DSC setups are not only essential in NLoS situations,\nbut consistently improve the latency of users in outdoor scenarios.",
    "descriptor": "\nComments: To be published in proceedings of DroNet21. Winner of DroNet21's Best Paper Award\n",
    "authors": [
      "Igor Donevski",
      "Christian Raffelsberger",
      "Micha Sende",
      "Aymen Fakhreddine",
      "Jimmy Jessen Nielsen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.16051"
  },
  {
    "id": "arXiv:2106.16052",
    "title": "Backward Euler method for the equations of motion arising in Oldroyd  model of order one with nonsmooth initial data",
    "abstract": "In this paper, a backward Euler method combined with finite element\ndiscretization in spatial direction is discussed for the equations of motion\narising in the $2D$ Oldroyd model of viscoelastic fluids of order one with the\nforcing term independent of time or in $L^{\\infty}$ in time. It is shown that\nthe estimates of the discrete solution in Dirichlet norm is bounded uniformly\nin time. Optimal {\\it a priori} error estimate in $\\textbf{L}^2$-norm is\nderived for the discrete problem with non-smooth initial data. This estimate is\nshown to be uniform in time, under the assumption of uniqueness condition.\nFinally, we present some numerical results to validate our theoretical results.",
    "descriptor": "\nComments: 30 pages, 15 figure. arXiv admin note: substantial text overlap with arXiv:1208.6343\n",
    "authors": [
      "Bikram Bir",
      "Deepjyoti Goswami",
      "Amiya K. Pani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16052"
  },
  {
    "id": "arXiv:2106.16053",
    "title": "News Article Retrieval in Context for Event-centric Narrative Creation",
    "abstract": "Writers such as journalists often use automatic tools to find relevant\ncontent to include in their narratives. In this paper, we focus on supporting\nwriters in the news domain to develop event-centric narratives. Given an\nincomplete narrative that specifies a main event and a context, we aim to\nretrieve news articles that discuss relevant events that would enable the\ncontinuation of the narrative. We formally define this task and propose a\nretrieval dataset construction procedure that relies on existing news articles\nto simulate incomplete narratives and relevant articles. Experiments on two\ndatasets derived from this procedure show that state-of-the-art lexical and\nsemantic rankers are not sufficient for this task. We show that combining those\nwith a ranker that ranks articles by reverse chronological order outperforms\nthose rankers alone. We also perform an in-depth quantitative and qualitative\nanalysis of the results that sheds light on the characteristics of this task.",
    "descriptor": "\nComments: ICTIR 2021\n",
    "authors": [
      "Nikos Voskarides",
      "Edgar Meij",
      "Sabrina Sauer",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.16053"
  },
  {
    "id": "arXiv:2106.16055",
    "title": "IMS' Systems for the IWSLT 2021 Low-Resource Speech Translation Task",
    "abstract": "This paper describes the submission to the IWSLT 2021 Low-Resource Speech\nTranslation Shared Task by IMS team. We utilize state-of-the-art models\ncombined with several data augmentation, multi-task and transfer learning\napproaches for the automatic speech recognition (ASR) and machine translation\n(MT) steps of our cascaded system. Moreover, we also explore the feasibility of\na full end-to-end speech translation (ST) model in the case of very constrained\namount of ground truth labeled data. Our best system achieves the best\nperformance among all submitted systems for Congolese Swahili to English and\nFrench with BLEU scores 7.7 and 13.7 respectively, and the second best result\nfor Coastal Swahili to English with BLEU score 14.9.",
    "descriptor": "\nComments: IWSLT 2021\n",
    "authors": [
      "Pavel Denisov",
      "Manuel Mager",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.16055"
  },
  {
    "id": "arXiv:2106.16056",
    "title": "A Survey on Adversarial Image Synthesis",
    "abstract": "Generative Adversarial Networks (GANs) have been extremely successful in\nvarious application domains. Adversarial image synthesis has drawn increasing\nattention and made tremendous progress in recent years because of its wide\nrange of applications in many computer vision and image processing problems.\nAmong the many applications of GAN, image synthesis is the most well-studied\none, and research in this area has already demonstrated the great potential of\nusing GAN in image synthesis. In this paper, we provide a taxonomy of methods\nused in image synthesis, review different models for text-to-image synthesis\nand image-to-image translation, and discuss some evaluation metrics as well as\npossible future research directions in image synthesis with GAN.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.13736, arXiv:2101.08629, arXiv:1803.04469 by other authors\n",
    "authors": [
      "William Roy",
      "Glen Kelly",
      "Robert Leer",
      "Frederick Ricardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16056"
  },
  {
    "id": "arXiv:2106.16057",
    "title": "DAEMA: Denoising Autoencoder with Mask Attention",
    "abstract": "Missing data is a recurrent and challenging problem, especially when using\nmachine learning algorithms for real-world applications. For this reason,\nmissing data imputation has become an active research area, in which recent\ndeep learning approaches have achieved state-of-the-art results. We propose\nDAEMA (Denoising Autoencoder with Mask Attention), an algorithm based on a\ndenoising autoencoder architecture with an attention mechanism. While most\nimputation algorithms use incomplete inputs as they would use complete data -\nup to basic preprocessing (e.g. mean imputation) - DAEMA leverages a mask-based\nattention mechanism to focus on the observed values of its inputs. We evaluate\nDAEMA both in terms of reconstruction capabilities and downstream prediction\nand show that it achieves superior performance to state-of-the-art algorithms\non several publicly available real-world datasets under various missingness\nsettings.",
    "descriptor": "\nComments: 12 pages, 2 figures, to be published in ICANN 2021, for official implementation see this https URL\n",
    "authors": [
      "Simon Tihon",
      "Muhammad Usama Javaid",
      "Damien Fourure",
      "Nicolas Posocco",
      "Thomas Peel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16057"
  },
  {
    "id": "arXiv:2106.16060",
    "title": "Leveraging Hidden Structure in Self-Supervised Learning",
    "abstract": "This work considers the problem of learning structured representations from\nraw images using self-supervised learning. We propose a principled framework\nbased on a mutual information objective, which integrates self-supervised and\nstructure learning. Furthermore, we devise a post-hoc procedure to interpret\nthe meaning of the learnt representations. Preliminary experiments on CIFAR-10\nshow that the proposed framework achieves higher generalization performance in\ndownstream classification tasks and provides more interpretable representations\ncompared to the ones learnt through traditional self-supervised learning.",
    "descriptor": "",
    "authors": [
      "Emanuele Sansone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16060"
  },
  {
    "id": "arXiv:2106.16064",
    "title": "Efficient Sparse Matrix Kernels based on Adaptive Workload-Balancing and  Parallel-Reduction",
    "abstract": "Sparse matrix-vector and matrix-matrix multiplication (SpMV and SpMM) are\nfundamental in both conventional (graph analytics, scientific computing) and\nemerging (sparse DNN, GNN) domains. Workload-balancing and parallel-reduction\nare widely-used design principles for efficient SpMV. However, prior work fails\nto resolve how to implement and adaptively use the two principles for SpMV/MM.\nTo overcome this obstacle, we first complete the implementation space with\noptimizations by filling three missing pieces in prior work, including: (1) We\nshow that workload-balancing and parallel-reduction can be combined through a\nsegment-reduction algorithm implemented with SIMD-shuffle primitives. (2) We\nshow that parallel-reduction can be implemented in SpMM through loading the\ndense-matrix rows with vector memory operations. (3) We show that vectorized\nloading of sparse rows, being a part of the benefit of parallel-reduction, can\nco-exist with sequential-reduction in SpMM through temporally caching\nsparse-matrix elements in the shared memory. In terms of adaptive use, we\nanalyze how the benefit of two principles change with two characteristics from\nthe input data space: the diverse sparsity pattern and dense-matrix width. We\nfind the benefit of the two principles fades along with the increased total\nworkload, i.e. the increased dense-matrix width. We also identify, for SpMV and\nSpMM, different sparse-matrix features that impact workload-balancing\neffectiveness. Our design consistently exceeds cuSPARSE by 1.07-1.57x on\ndifferent GPUs and dense matrix width, and the kernel selection rules involve\n5-12% performance loss compared with optimal choices. Our kernel is being\nintegrated into popular graph learning frameworks to accelerate GNN training.",
    "descriptor": "",
    "authors": [
      "Guyue Huang",
      "Guohao Dai",
      "Yu Wang",
      "Yufei Ding",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.16064"
  },
  {
    "id": "arXiv:2106.16067",
    "title": "Leveraging Team Dynamics to Predict Open-source Software Projects'  Susceptibility to Social Engineering Attacks",
    "abstract": "Open-source software (OSS) is a critical part of the software supply chain.\nRecent social engineering attacks against OSS development teams have enabled\nattackers to become code contributors and later inject malicious code or\nvulnerabilities into the project with the goal of compromising dependent\nsoftware. The attackers have exploited interactions among development team\nmembers and the social dynamics of team behavior to enable their attacks. We\nintroduce a security approach that leverages signatures and patterns of team\ndynamics to predict the susceptibility of a software development team to social\nengineering attacks that enable access to the OSS project code. The proposed\napproach is programming language-, platform-, and vulnerability-agnostic\nbecause it assesses the artifacts of OSS team interactions, rather than OSS\ncode.",
    "descriptor": "",
    "authors": [
      "Huascar Sanchez",
      "Daniela Oliveira",
      "Deborah Shands",
      "Luiz Giovanini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.16067"
  },
  {
    "id": "arXiv:2106.16073",
    "title": "CS decomposition and GSVD for tensors based on the T-product",
    "abstract": "This paper derives the CS decomposition for orthogonal tensors (T-CSD) and\nthe generalized singular value decomposition for two tensors (T-GSVD) via the\nT-product. The structures of the two decompositions are analyzed in detail and\nare consistent with those for matrix cases. Then the corresponding algorithms\nare proposed respectively. Finally, T-GSVD can be used to give the explicit\nexpression for the solution of tensor Tikhonov regularization. Numerical\nexamples demonstrate the effectiveness of T-GSVD in solving image restoration\nproblems.",
    "descriptor": "",
    "authors": [
      "Yating Zhang",
      "Xiaoxia Guo",
      "Pengpeng Xie",
      "Zhengbang Cao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16073"
  },
  {
    "id": "arXiv:2106.16074",
    "title": "Machine Learning-enhanced Receive Processing for MU-MIMO OFDM Systems",
    "abstract": "Machine learning (ML) can be used in various ways to improve multi-user\nmultiple-input multiple-output (MU-MIMO) receive processing. Typical approaches\neither augment a single processing step, such as symbol detection, or replace\nmultiple steps jointly by a single neural network (NN). These techniques\ndemonstrate promising results but often assume perfect channel state\ninformation (CSI) or fail to satisfy the interpretability and scalability\nconstraints imposed by practical systems. In this paper, we propose a new\nstrategy which preserves the benefits of a conventional receiver, but enhances\nspecific parts with ML components. The key idea is to exploit the orthogonal\nfrequency-division multiplexing (OFDM) signal structure to improve both the\ndemapping and the computation of the channel estimation error statistics.\nEvaluation results show that the proposed ML-enhanced receiver beats practical\nbaselines on all considered scenarios, with significant gains at high speeds.",
    "descriptor": "",
    "authors": [
      "Mathieu Goutay",
      "Fay\u00e7al Ait Aoudia",
      "Jakob Hoydis",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.16074"
  },
  {
    "id": "arXiv:2106.16078",
    "title": "Identification of Linear Systems with Multiplicative Noise from Multiple  Trajectory Data",
    "abstract": "We study identification of linear systems with multiplicative noise from\nmultiple trajectory data. A least-squares algorithm, based on exploratory\ninputs, is proposed to simultaneously estimate the parameters of the nominal\nsystem and the covariance matrix of the multiplicative noise. The algorithm\ndoes not need prior knowledge of the noise or stability of the system, but\nrequires mild conditions of inputs and relatively small length for each\ntrajectory. Identifiability of the noise covariance matrix is studied, showing\nthat there exists an equivalent class of matrices that generate the same\nsecond-moment dynamic of system states. It is demonstrated how to obtain the\nequivalent class based on estimates of the noise covariance. Asymptotic\nconsistency of the algorithm is verified under sufficiently exciting inputs and\nsystem controllability conditions. Non-asymptotic estimation performance is\nalso analyzed under the assumption that system states and noise are bounded,\nproviding vanishing high-probability bounds as the number of trajectories grows\nto infinity. The results are illustrated by numerical simulations.",
    "descriptor": "",
    "authors": [
      "Yu Xing",
      "Benjamin Gravell",
      "Xingkang He",
      "Karl Henrik Johansson",
      "Tyler Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.16078"
  },
  {
    "id": "arXiv:2106.16083",
    "title": "Arduino sensor integrated drone for weather indices: a prototype for  pre-flight preparation",
    "abstract": "Commercial weather stations can effectively collect weather data for a\nspecified area. However, their ground sensors limit the amount of data that can\nbe logged, thus failing to collect precise meteorological data in a local area\nsuch as a micro-scale region. This happens because weather conditions at a\nmicro-scale region can vary greatly even with small altitude changes. For now,\ndrone operators must check the local weather conditions to ensure a safe and\nsuccessful flight. This task is often a part of pre-flight preparations. Since\nflight conditions (and most important flight safety) are greatly affected by\nweather, drone operators need a more accurate localized weather map reading for\nthe flight area. In this paper, we present the Arduino Sensor Integrated Drone\n(ASID) with a built-in meteorological station that logs the weather conditions\nin the vertical area where the drone will be deployed. ASID is an autonomous\ndrone-based system that monitors weather conditions for pre-flight preparation.\nThe operation of the ASID system is based on the Arduino microcontroller\nrunning automatic flight profiles to record meteorological data such as\ntemperature, barometric pressure, humidity, etc. The Arduino microcontroller\nalso takes photos of the horizon for an objective assessment of the visibility,\nthe base, and the number of clouds.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Theodore Karachalios",
      "Dimitris Kanellopoulos",
      "Fotis Lazarinis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.16083"
  },
  {
    "id": "arXiv:2106.16085",
    "title": "Protecting Time Series Data with Minimal Forecast Loss",
    "abstract": "Forecasting could be negatively impacted due to anonymization requirements in\ndata protection legislation. To measure the potential severity of this problem,\nwe derive theoretical bounds for the loss to forecasts from additive\nexponential smoothing models using protected data. Following the guidelines of\nanonymization from the General Data Protection Regulation (GDPR) and California\nConsumer Privacy Act (CCPA), we develop the $k$-nearest Time Series ($k$-nTS)\nSwapping and $k$-means Time Series ($k$-mTS) Shuffling methods to create\nprotected time series data that minimizes the loss to forecasts while\npreventing a data intruder from detecting privacy issues. For efficient and\neffective decision making, we formally model an integer programming problem for\na perfect matching for simultaneous data swapping in each cluster. We call it a\ntwo-party data privacy framework since our optimization model includes the\nutilities of a data provider and data intruder. We apply our data protection\nmethods to thousands of time series and find that it maintains the forecasts\nand patterns (level, trend, and seasonality) of time series well compared to\nstandard data protection methods suggested in legislation. Substantively, our\npaper addresses the challenge of protecting time series data when used for\nforecasting. Our findings suggest the managerial importance of incorporating\nthe concerns of forecasters into the data protection itself.",
    "descriptor": "",
    "authors": [
      "Matthew J. Schneider",
      "Jinwook Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.16085"
  },
  {
    "id": "arXiv:2106.16086",
    "title": "A Comprehensive Survey on STP Approach to Finite Games",
    "abstract": "Nowadays the semi-tensor product (STP) approach to finite games has become a\npromising new direction. This paper provides a comprehensive survey on this\nprosperous field. After a brief introduction for STP and finite (networked)\ngames, a description for the principle and fundamental technique of STP\napproach to finite games is presented. Then several problems and recent results\nabout theory and applications of finite games via STP are presented. A brief\ncomment about the potential use of STP to artificial intelligence is also\nproposed.",
    "descriptor": "",
    "authors": [
      "Daizhan Cheng",
      "Yuhu Wu",
      "Guodong Zhao",
      "Shihua Fu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.16086"
  },
  {
    "id": "arXiv:2106.16091",
    "title": "Interventional Assays for the Latent Space of Autoencoders",
    "abstract": "The encoders and decoders of autoencoders effectively project the input onto\nlearned manifolds in the latent space and data space respectively. We propose a\nframework, called latent responses, for probing the learned data manifold using\ninterventions in the latent space. Using this framework, we investigate \"holes\"\nin the representation to quantitatively ascertain to what extent the latent\nspace of a trained VAE is consistent with the chosen prior. Furthermore, we use\nthe identified structure to improve interpolation between latent vectors. We\nevaluate how our analyses improve the quality of the generated samples using\nthe VAE on a variety of benchmark datasets.",
    "descriptor": "\nComments: Under review for NeurIPS 2021\n",
    "authors": [
      "Felix Leeb",
      "Stefan Bauer",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16091"
  },
  {
    "id": "arXiv:2106.16093",
    "title": "Multi-Source domain adaptation via supervised contrastive learning and  confident consistency regularization",
    "abstract": "Multi-Source Unsupervised Domain Adaptation (multi-source UDA) aims to learn\na model from several labeled source domains while performing well on a\ndifferent target domain where only unlabeled data are available at training\ntime. To align source and target features distributions, several recent works\nuse source and target explicit statistics matching such as features moments or\nclass centroids. Yet, these approaches do not guarantee class conditional\ndistributions alignment across domains. In this work, we propose a new\nframework called Contrastive Multi-Source Domain Adaptation (CMSDA) for\nmulti-source UDA that addresses this limitation. Discriminative features are\nlearned from interpolated source examples via cross entropy minimization and\nfrom target examples via consistency regularization and hard pseudo-labeling.\nSimultaneously, interpolated source examples are leveraged to align source\nclass conditional distributions through an interpolated version of the\nsupervised contrastive loss. This alignment leads to more general and\ntransferable features which further improve the generalization on the target\ndomain. Extensive experiments have been carried out on three standard\nmulti-source UDA datasets where our method reports state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16093"
  },
  {
    "id": "arXiv:2106.16095",
    "title": "Differences between preprints and journal articles : Trial using bioRxiv  data",
    "abstract": "In this paper, we attempted to obtain knowledge about how research is\nconducted, especially how journal articles are produced, by comparing preprints\nwith journal articles that are finally published.\nFirst, due to the recent trend of open journals, we were able to secure a\ncertain amount of full-text XML of preprints and journal articles, and verified\nthe technical feasibility of comparing preprints and journal articles. On the\nother hand, within the scope of this trial, in which we tried to clarify the\ndifference between them based on external criteria such as the number of\nreferences and the number of words, and simple document similarity, we could\nnot find a clear difference between preprints and journal articles, or between\npreprints that became journal articles and those that did not. Even with the\nmachine learning method, the classification accuracy was not high at about 47%.\nThe result that there is no significant difference between preprints and\njournal articles is a finding that has been shown in previous studies and has\nbeen replicated in larger and relatively recent situations. In addition to\nthese, the new findings of this paper are that the differences in many external\ncriteria, such as the number of authors, are small, and the differences with\npreprints that are not journal articles are not large.",
    "descriptor": "\nComments: 17 pages, 21 figures\n",
    "authors": [
      "Koshiba Hitoshi",
      "HayashiI Kazuhiro"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.16095"
  },
  {
    "id": "arXiv:2106.16096",
    "title": "Global Optimality of Inverter Dynamic Voltage Support",
    "abstract": "This paper investigates the dynamic voltage support (DVS) control of\ninverter-based resources (IBRs) under voltage sags to enhance the low-voltage\nride-through performance. We first revisit the prevalent droop control from an\noptimization perspective to elaborate on why it usually suffers from\nsuboptimality. Then, we formulate the DVS problem as an optimization program\nthat maximizes the positive-sequence voltage magnitude at the point of common\ncoupling (PCC) subject to the current, active power, and stability constraints.\nThe program is inherently nonconvex due to the active power limits, of which\nthe global optimality is not guaranteed by off-the-shelf solvers. In this\ncontext, we perform the optimality analysis to explore the global optimum\nanalytically. It is found that the unique global optimum has three\nscenarios/stages (S1--S3), which depends on the specific relationship among\ngrid voltage, grid strength, as well as physical limits of IBRs. The\nclosed-form solutions in S1 and S3 are derived and the optimality conditions\nfor S2 are provided, which guarantees the optimality and compatibility with the\nfast real-time control. We implement the optimum with a grid-connected\nphotovoltaic (PV) power plant by integrating a DVS controller. Dynamic\nsimulations are carried out under different scenarios to test our proposal and\ncompare it with other existing methods. Additionally, the robustness of\noptimality against model errors is discussed and numerically demonstrated.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Yifei Guo",
      "Bikash C. Pal",
      "Rabih A. Jabr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.16096"
  },
  {
    "id": "arXiv:2106.16100",
    "title": "Synthetic Data Are as Good as the Real for Association Knowledge  Learning in Multi-object Tracking",
    "abstract": "Association, aiming to link bounding boxes of the same identity in a video\nsequence, is a central component in multi-object tracking (MOT). To train\nassociation modules, e.g., parametric networks, real video data are usually\nused. However, annotating person tracks in consecutive video frames is\nexpensive, and such real data, due to its inflexibility, offer us limited\nopportunities to evaluate the system performance w.r.t changing tracking\nscenarios. In this paper, we study whether 3D synthetic data can replace\nreal-world videos for association training. Specifically, we introduce a\nlarge-scale synthetic data engine named MOTX, where the motion characteristics\nof cameras and objects are manually configured to be similar to those in\nreal-world datasets. We show that compared with real data, association\nknowledge obtained from synthetic data can achieve very similar performance on\nreal-world test sets without domain adaption techniques. Our intriguing\nobservation is credited to two factors. First and foremost, 3D engines can well\nsimulate motion factors such as camera movement, camera view and object\nmovement, so that the simulated videos can provide association modules with\neffective motion features. Second, experimental results show that the\nappearance domain gap hardly harms the learning of association knowledge. In\naddition, the strong customization ability of MOTX allows us to quantitatively\nassess the impact of motion factors on MOT, which brings new insights to the\ncommunity.",
    "descriptor": "",
    "authors": [
      "Yuchi Liu",
      "Zhongdao Wang",
      "Xiangxin Zhou",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16100"
  },
  {
    "id": "arXiv:2106.16102",
    "title": "Machine Reading of Hypotheses for Organizational Research Reviews and  Pre-trained Models via R Shiny App for Non-Programmers",
    "abstract": "The volume of scientific publications in organizational research becomes\nexceedingly overwhelming for human researchers who seek to timely extract and\nreview knowledge. This paper introduces natural language processing (NLP)\nmodels to accelerate the discovery, extraction, and organization of theoretical\ndevelopments (i.e., hypotheses) from social science publications. We illustrate\nand evaluate NLP models in the context of a systematic review of stakeholder\nvalue constructs and hypotheses. Specifically, we develop NLP models to\nautomatically 1) detect sentences in scholarly documents as hypotheses or not\n(Hypothesis Detection), 2) deconstruct the hypotheses into nodes (constructs)\nand links (causal/associative relationships) (Relationship Deconstruction ),\nand 3) classify the features of links in terms causality (versus association)\nand direction (positive, negative, versus nonlinear) (Feature Classification).\nOur models have reported high performance metrics for all three tasks. While\nour models are built in Python, we have made the pre-trained models fully\naccessible for non-programmers. We have provided instructions on installing and\nusing our pre-trained models via an R Shiny app graphic user interface (GUI).\nFinally, we suggest the next paths to extend our methodology for\ncomputer-assisted knowledge synthesis.",
    "descriptor": "",
    "authors": [
      "Victor Zitian Chen",
      "Felipe Montano-Campos",
      "Wlodek Zadrozny",
      "Evan Canfield"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.16102"
  },
  {
    "id": "arXiv:2106.16106",
    "title": "How can design help enhance trust calibration in public autonomous  vehicles?",
    "abstract": "Trust is a multilayered concept with critical relevance when it comes to\nintroducing new technologies. Understanding how humans will interact with\ncomplex vehicle systems and preparing for the functional, societal and\npsychological aspects of autonomous vehicles' entry into our cities is a\npressing concern. Design tools can help calibrate the adequate and affordable\nlevel of trust needed for a safe and positive experience. This study focuses on\npassenger interactions capable of enhancing the system trustworthiness and data\naccuracy in future shared public transportation.",
    "descriptor": "\nComments: 4 pages, 5 figures, IV 2021 Nagoya, Trust Calibration Workshop\n",
    "authors": [
      "Yuri Klebanov",
      "Romi Mikulinsky",
      "Tom Reznikov",
      "Miles Pennington",
      "Yoshihiro Suda",
      "Toshihiro Hiraoka",
      "Shoichi Kanzaki"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.16106"
  },
  {
    "id": "arXiv:2106.16107",
    "title": "A Generalized Multigrid Method for Solving Contact Problems in Lagrange  Multiplier based Unfitted Finite Element Method",
    "abstract": "Internal interfaces in a domain could exist as a material defect or they can\nappear due to propagations of cracks. Discretization of such geometries and\nsolution of the contact problem on the internal interfaces can be\ncomputationally challenging. We employ an unfitted Finite Element (FE)\nframework for the discretization of the domains and develop a tailored,\nglobally convergent, and efficient multigrid method for solving contact\nproblems on the internal interfaces. In the unfitted FE methods, structured\nbackground meshes are used and only the underlying finite element space has to\nbe modified to incorporate the discontinuities. The non-penetration conditions\non the embedded interfaces of the domains are discretized using the method of\nLagrange multipliers. We reformulate the arising variational inequality problem\nas a quadratic minimization problem with linear inequality constraints. Our\nmultigrid method can solve such problems by employing a tailored multilevel\nhierarchy of the FE spaces and a novel approach for tackling the discretized\nnon-penetration conditions. We employ pseudo-$L^2$ projection-based transfer\noperators to construct a hierarchy of nested FE spaces from the hierarchy of\nnon-nested meshes. The essential component of our multigrid method is a\ntechnique that decouples the linear constraints using an orthogonal\ntransformation of the basis. The decoupled constraints are handled by a\nmodified variant of the projected Gauss-Seidel method, which we employ as a\nsmoother in the multigrid method. These components of the multigrid method\nallow us to enforce linear constraints locally and ensure the global\nconvergence of our method. We will demonstrate the robustness, efficiency, and\nlevel independent convergence property of the proposed method for Signorini's\nproblem and two-body contact problems.",
    "descriptor": "",
    "authors": [
      "Hardik Kothari",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16107"
  },
  {
    "id": "arXiv:2106.16108",
    "title": "Zero-shot Learning with Class Description Regularization",
    "abstract": "The purpose of generative Zero-shot learning (ZSL) is to learning from seen\nclasses, transfer the learned knowledge, and create samples of unseen classes\nfrom the description of these unseen categories. To achieve better ZSL\naccuracies, models need to better understand the descriptions of unseen\nclasses. We introduce a novel form of regularization that encourages generative\nZSL models to pay more attention to the description of each category. Our\nempirical results demonstrate improvements over the performance of multiple\nstate-of-the-art models on the task of generalized zero-shot recognition and\nclassification when trained on textual description-based datasets like CUB and\nNABirds and attribute-based datasets like AWA2, aPY and SUN.",
    "descriptor": "",
    "authors": [
      "Shayan Kousha",
      "Marcus A. Brubaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16108"
  },
  {
    "id": "arXiv:2106.16112",
    "title": "Coresets for Clustering with Missing Values",
    "abstract": "We provide the first coreset for clustering points in $\\mathbb{R}^d$ that\nhave multiple missing values (coordinates). Previous coreset constructions only\nallow one missing coordinate. The challenge in this setting is that objective\nfunctions, like $k$-Means, are evaluated only on the set of available\n(non-missing) coordinates, which varies across points. Recall that an\n$\\epsilon$-coreset of a large dataset is a small proxy, usually a reweighted\nsubset of points, that $(1+\\epsilon)$-approximates the clustering objective for\nevery possible center set.\nOur coresets for $k$-Means and $k$-Median clustering have size\n$(jk)^{O(\\min(j,k))} (\\epsilon^{-1} d \\log n)^2$, where $n$ is the number of\ndata points, $d$ is the dimension and $j$ is the maximum number of missing\ncoordinates for each data point. We further design an algorithm to construct\nthese coresets in near-linear time, and consequently improve a recent\nquadratic-time PTAS for $k$-Means with missing values [Eiben et al., SODA 2021]\nto near-linear time.\nWe validate our coreset construction, which is based on importance sampling\nand is easy to implement, on various real data sets. Our coreset exhibits a\nflexible tradeoff between coreset size and accuracy, and generally outperforms\nthe uniform-sampling baseline. Furthermore, it significantly speeds up a\nLloyd's-style heuristic for $k$-Means with missing values.",
    "descriptor": "",
    "authors": [
      "Vladimir Braverman",
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Xuan Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.16112"
  },
  {
    "id": "arXiv:2106.16115",
    "title": "The Power of Adaptivity for Stochastic Submodular Cover",
    "abstract": "In the stochastic submodular cover problem, the goal is to select a subset of\nstochastic items of minimum expected cost to cover a submodular function.\nSolutions in this setting correspond to sequential decision processes that\nselect items one by one \"adaptively\" (depending on prior observations). While\nsuch adaptive solutions achieve the best objective, the inherently sequential\nnature makes them undesirable in many applications. We ask: how well can\nsolutions with only a few adaptive rounds approximate fully-adaptive solutions?\nWe give nearly tight answers for both independent and correlated settings,\nproving smooth tradeoffs between the number of adaptive rounds and the solution\nquality, relative to fully adaptive solutions. Experiments on synthetic and\nreal datasets show qualitative improvements in the solutions as we allow more\nrounds of adaptivity; in practice, solutions with a few rounds of adaptivity\nare nearly as good as fully adaptive solutions.",
    "descriptor": "\nComments: In proceedings of ICML 2021\n",
    "authors": [
      "Rohan Ghuge",
      "Anupam Gupta",
      "Viswanath Nagarajan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.16115"
  },
  {
    "id": "arXiv:2106.16116",
    "title": "PSD Representations for Effective Probability Models",
    "abstract": "Finding a good way to model probability densities is key to probabilistic\ninference. An ideal model should be able to concisely approximate any\nprobability, while being also compatible with two main operations:\nmultiplications of two models (product rule) and marginalization with respect\nto a subset of the random variables (sum rule). In this work, we show that a\nrecently proposed class of positive semi-definite (PSD) models for non-negative\nfunctions is particularly suited to this end. In particular, we characterize\nboth approximation and generalization capabilities of PSD models, showing that\nthey enjoy strong theoretical guarantees. Moreover, we show that we can perform\nefficiently both sum and product rule in closed form via matrix operations,\nenjoying the same versatility of mixture models. Our results open the way to\napplications of PSD models to density estimation, decision theory and\ninference. Preliminary empirical evaluation supports our findings.",
    "descriptor": "\nComments: 52 pages, 3 figures\n",
    "authors": [
      "Alessandro Rudi",
      "Carlo Ciliberto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16116"
  },
  {
    "id": "arXiv:2106.16118",
    "title": "SimNet: Enabling Robust Unknown Object Manipulation from Pure Synthetic  Data via Stereo",
    "abstract": "Robot manipulation of unknown objects in unstructured environments is a\nchallenging problem due to the variety of shapes, materials, arrangements and\nlighting conditions. Even with large-scale real-world data collection, robust\nperception and manipulation of transparent and reflective objects across\nvarious lighting conditions remain challenging. To address these challenges we\npropose an approach to performing sim-to-real transfer of robotic perception.\nThe underlying model, SimNet, is trained as a single multi-headed neural\nnetwork using simulated stereo data as input and simulated object segmentation\nmasks, 3D oriented bounding boxes (OBBs), object keypoints, and disparity as\noutput. A key component of SimNet is the incorporation of a learned stereo\nsub-network that predicts disparity. SimNet is evaluated on 2D car detection,\nunknown object detection, and deformable object keypoint detection and\nsignificantly outperforms a baseline that uses a structured light RGB-D sensor.\nBy inferring grasp positions using the OBB and keypoint predictions, SimNet can\nbe used to perform end-to-end manipulation of unknown objects in both easy and\nhard scenarios using our fleet of Toyota HSR robots in four home environments.\nIn unknown object grasping experiments, the predictions from the baseline RGB-D\nnetwork and SimNet enable successful grasps of most of the easy objects.\nHowever, the RGB-D baseline only grasps 35% of the hard (e.g., transparent)\nobjects, while SimNet grasps 95%, suggesting that SimNet can enable robust\nmanipulation of unknown objects, including transparent objects, in unknown\nenvironments.",
    "descriptor": "\nComments: 19 pages, 13 figures\n",
    "authors": [
      "Thomas Kollar",
      "Michael Laskey",
      "Kevin Stone",
      "Brijen Thananjeyan",
      "Mark Tjersland"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16118"
  },
  {
    "id": "arXiv:2106.16122",
    "title": "Zombies in the Loop? People are Insensitive to the Transparency of  AI-Powered Moral Advisors",
    "abstract": "Departing from the assumption that AI needs to be transparent to be trusted,\nwe find that users trustfully take ethical advice from a transparent and an\nopaque AI-powered algorithm alike. Even when transparency reveals information\nthat warns against the algorithm, they continue to accept its advice. We\nconducted online experiments where the participants took the role of\ndecision-makers who received AI-powered advice on how to deal with an ethical\ndilemma. We manipulated information about the algorithm to study its influence.\nOur findings suggest that AI is overtrusted rather than distrusted, and that\nusers need digital literacy to benefit from transparency.",
    "descriptor": "",
    "authors": [
      "Sebastian Kr\u00fcgel",
      "Andreas Ostermaier",
      "Matthias Uhl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.16122"
  },
  {
    "id": "arXiv:2106.16125",
    "title": "Affective Image Content Analysis: Two Decades Review and New  Perspectives",
    "abstract": "Images can convey rich semantics and induce various emotions in viewers.\nRecently, with the rapid advancement of emotional intelligence and the\nexplosive growth of visual data, extensive research efforts have been dedicated\nto affective image content analysis (AICA). In this survey, we will\ncomprehensively review the development of AICA in the recent two decades,\nespecially focusing on the state-of-the-art methods with respect to three main\nchallenges -- the affective gap, perception subjectivity, and label noise and\nabsence. We begin with an introduction to the key emotion representation models\nthat have been widely employed in AICA and description of available datasets\nfor performing evaluation with quantitative comparison of label noise and\ndataset bias. We then summarize and compare the representative approaches on\n(1) emotion feature extraction, including both handcrafted and deep features,\n(2) learning methods on dominant emotion recognition, personalized emotion\nprediction, emotion distribution learning, and learning from noisy data or few\nlabels, and (3) AICA based applications. Finally, we discuss some challenges\nand promising research directions in the future, such as image content and\ncontext understanding, group emotion clustering, and viewer-image interaction.",
    "descriptor": "\nComments: Accepted by IEEE TPAMI\n",
    "authors": [
      "Sicheng Zhao",
      "Xingxu Yao",
      "Jufeng Yang",
      "Guoli Jia",
      "Guiguang Ding",
      "Tat-Seng Chua",
      "Bj\u00f6rn W. Schuller",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.16125"
  },
  {
    "id": "arXiv:2106.16126",
    "title": "Recognizing Facial Expressions in the Wild using Multi-Architectural  Representations based Ensemble Learning with Distillation",
    "abstract": "Facial expressions are the most universal forms of body language and\nautomatic facial expression recognition is one of the challenging tasks due to\ndifferent uncertainties. However, it has been an active field of research for\nmany years. Nevertheless, efficiency and performance are yet essential aspects\nfor building robust systems. We proposed two models, EmoXNet which is an\nensemble learning technique for learning convoluted facial representations, and\nEmoXNetLite which is a distillation technique that is useful for transferring\nthe knowledge from our ensemble model to an efficient deep neural network using\nlabel-smoothen soft labels for able to effectively detect expressions in\nreal-time. Both of the techniques performed quite well, where the ensemble\nmodel (EmoXNet) helped to achieve 85.07% test accuracy on FER2013 with FER+\nannotations and 86.25% test accuracy on RAF-DB. Moreover, the distilled model\n(EmoXNetLite) showed 82.07% test accuracy on FER2013 with FER+ annotations and\n81.78% test accuracy on RAF-DB.",
    "descriptor": "\nComments: 5 pages, 3 figures, 4 tables\n",
    "authors": [
      "Rauf Momin",
      "Ali Shan Momin",
      "Khalid Rasheed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16126"
  },
  {
    "id": "arXiv:2106.16128",
    "title": "Dual Reweighting Domain Generalization for Face Presentation Attack  Detection",
    "abstract": "Face anti-spoofing approaches based on domain generalization (DG) have drawn\ngrowing attention due to their robustness for unseen scenarios. Previous\nmethods treat each sample from multiple domains indiscriminately during the\ntraining process, and endeavor to extract a common feature space to improve the\ngeneralization. However, due to complex and biased data distribution, directly\ntreating them equally will corrupt the generalization ability. To settle the\nissue, we propose a novel Dual Reweighting Domain Generalization (DRDG)\nframework which iteratively reweights the relative importance between samples\nto further improve the generalization. Concretely, Sample Reweighting Module is\nfirst proposed to identify samples with relatively large domain bias, and\nreduce their impact on the overall optimization. Afterwards, Feature\nReweighting Module is introduced to focus on these samples and extract more\ndomain-irrelevant features via a self-distilling mechanism. Combined with the\ndomain discriminator, the iteration of the two modules promotes the extraction\nof generalized features. Extensive experiments and visualizations are presented\nto demonstrate the effectiveness and interpretability of our method against the\nstate-of-the-art competitors.",
    "descriptor": "\nComments: accepted on IJCAI 2021\n",
    "authors": [
      "Shubao Liu",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Kekai Sheng",
      "Shouhong Ding",
      "Ying Tai",
      "Jilin Li",
      "Yuan Xie",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16128"
  },
  {
    "id": "arXiv:2106.16129",
    "title": "Recurrently Estimating Reflective Symmetry Planes from Partial  Pointclouds",
    "abstract": "Many man-made objects are characterised by a shape that is symmetric along\none or more planar directions. Estimating the location and orientation of such\nsymmetry planes can aid many tasks such as estimating the overall orientation\nof an object of interest or performing shape completion, where a partial scan\nof an object is reflected across the estimated symmetry plane in order to\nobtain a more detailed shape. Many methods processing 3D data rely on expensive\n3D convolutions. In this paper we present an alternative novel encoding that\ninstead slices the data along the height dimension and passes it sequentially\nto a 2D convolutional recurrent regression scheme. The method also comprises a\ndifferentiable least squares step, allowing for end-to-end accurate and fast\nprocessing of both full and partial scans of symmetric objects. We use this\napproach to efficiently handle 3D inputs to design a method to estimate planar\nreflective symmetries. We show that our approach has an accuracy comparable to\nstate-of-the-art techniques on the task of planar reflective symmetry\nestimation on full synthetic objects. Additionally, we show that it can be\ndeployed on partial scans of objects in a real-world pipeline to improve the\noutputs of a 3D object detector.",
    "descriptor": "\nComments: Presented at the CVPR 2021 Workshop on 3D Vision and Robotics\n",
    "authors": [
      "Mihaela C\u0103t\u0103lina Stoian",
      "Tommaso Cavallari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16129"
  },
  {
    "id": "arXiv:2106.16136",
    "title": "Weakly Supervised Temporal Adjacent Network for Language Grounding",
    "abstract": "Temporal language grounding (TLG) is a fundamental and challenging problem\nfor vision and language understanding. Existing methods mainly focus on fully\nsupervised setting with temporal boundary labels for training, which, however,\nsuffers expensive cost of annotation. In this work, we are dedicated to weakly\nsupervised TLG, where multiple description sentences are given to an untrimmed\nvideo without temporal boundary labels. In this task, it is critical to learn a\nstrong cross-modal semantic alignment between sentence semantics and visual\ncontent. To this end, we introduce a novel weakly supervised temporal adjacent\nnetwork (WSTAN) for temporal language grounding. Specifically, WSTAN learns\ncross-modal semantic alignment by exploiting temporal adjacent network in a\nmultiple instance learning (MIL) paradigm, with a whole description paragraph\nas input. Moreover, we integrate a complementary branch into the framework,\nwhich explicitly refines the predictions with pseudo supervision from the MIL\nstage. An additional self-discriminating loss is devised on both the MIL branch\nand the complementary branch, aiming to enhance semantic discrimination by\nself-supervising. Extensive experiments are conducted on three widely used\nbenchmark datasets, \\emph{i.e.}, ActivityNet-Captions, Charades-STA, and\nDiDeMo, and the results demonstrate the effectiveness of our approach.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Multimedia, 2021\n",
    "authors": [
      "Yuechen Wang",
      "Jiajun Deng",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16136"
  },
  {
    "id": "arXiv:2106.16138",
    "title": "XLM-E: Cross-lingual Language Model Pre-training via ELECTRA",
    "abstract": "In this paper, we introduce ELECTRA-style tasks to cross-lingual language\nmodel pre-training. Specifically, we present two pre-training tasks, namely\nmultilingual replaced token detection, and translation replaced token\ndetection. Besides, we pretrain the model, named as XLM-E, on both multilingual\nand parallel corpora. Our model outperforms the baseline models on various\ncross-lingual understanding tasks with much less computation cost. Moreover,\nanalysis shows that XLM-E tends to obtain better cross-lingual transferability.",
    "descriptor": "",
    "authors": [
      "Zewen Chi",
      "Shaohan Huang",
      "Li Dong",
      "Shuming Ma",
      "Saksham Singhal",
      "Payal Bajaj",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16138"
  },
  {
    "id": "arXiv:2106.16139",
    "title": "Automated Onychomycosis Detection Using Deep Neural Networks",
    "abstract": "Clinical dermatology, still relies heavily on manual introspection of fungi\nwithin a Potassium Hydroxide (KOH) solution using a brightfield microscope.\nHowever, this method takes a long time, is based on the experience of the\nclinician, and has a low accuracy. With the increase of neural network\napplications in the field of clinical microscopy it is now possible to automate\nsuch manual processes increasing both efficiency and accuracy. This study\npresents a deep neural network structure that enables the rapid solutions for\nthese problems and can perform automatic fungi detection in grayscale images\nwithout colorants. Microscopic images of 81 fungi and 235 ceratine were\ncollected. Then, smaller patches were extracted containing 2062 fungi and 2142\nceratine. In order to detect fungus and ceratine, two models were created one\nof which was a custom neural network and the other was based on the VGG16\narchitecture. The developed custom model had 99.84% accuracy, and an area under\nthe curve (AUC) value of 1.00, while the VGG16 model had 98.89% accuracy and an\nAUC value of 0.99. However, average accuracy and AUC value of clinicians is\n72.8% and 0.87 respectively. This deep learning model allows the development of\nan automated system that can detect fungi within microscopic images.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Abdurrahim Yilmaz",
      "Rahmetullah Varol",
      "Fatih Goktay",
      "Gulsum Gencoglan",
      "Ali Anil Demircali",
      "Berk Dilsizoglu",
      "Huseyin Uvet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16139"
  },
  {
    "id": "arXiv:2106.16140",
    "title": "Revisiting Time, Clocks, and Synchronization",
    "abstract": "Sub-nanosecond precision clock synchronization over the packet network has\nbeen achieved by the White Rabbit protocol for a decade. However, few computer\nsystems utilize such a technique. We try to attract more interest in the clock\nsynchronization problem. We first introduce the basics of clock and\nsynchronization in the time and frequency discipline. Then we revisit several\nrelated works, such as Google's Spanner, Huygens, FARMv2, DTP, and Sundial,\nexplain why these works could be improved. Finally, we briefly discuss an\nindependent time network approach towards low-cost and high-precision\nsynchronization.",
    "descriptor": "",
    "authors": [
      "Ying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.16140"
  },
  {
    "id": "arXiv:2106.16143",
    "title": "People Counting using Radio Irregularity in Wireless Sensor Networks --  An Experimental Study",
    "abstract": "The Internet has grown into a large cyber-physical system centered that\nconnects not just computer systems but a plethora of systems, devices, and\nobjects, collectively referred to as \"Things\", giving rise to the term\n\"Internet of Things\" (IoT). It encompasses technologies for identification and\ntracking, sensing and actuation, both wired and wireless communications, and\nalso, intelligence and cognition. Wireless communications, which is an integral\npart of IoT, suffers from radio irregularity -- a phenomenon referring to radio\nwaves being selectively absorbed, reflected or scattered by objects in their\npaths, e.g., human bodies that comprises liquid, bone and flesh. Radio\nirregularity is often regarded as a problem in wireless communications but,\nwith the envisioned pervasiveness of IoT, we aim to exploit radio irregularity\nas a means to detect and estimate the number of people. We demonstrate how\nradio signal fluctuations arising from radio irregularity, combined with\ndiscriminant analysis, can be used to provide a simple low-cost alternative to\ndedicated sensing systems for indoor people counting.",
    "descriptor": "",
    "authors": [
      "Wei-Chuan Lin",
      "Winston K.G. Seah",
      "Wei Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2106.16143"
  },
  {
    "id": "arXiv:2106.16144",
    "title": "Non-orthogonal HARQ for URLLC Design and Analysis",
    "abstract": "The fifth-generation (5G) of mobile standards is expected to provide\nultra-reliability and low-latency communications (URLLC) for various\napplications and services, such as online gaming, wireless industrial control,\naugmented reality, and self driving cars. Meeting the contradictory\nrequirements of URLLC, i.e., ultra-reliability and low-latency, is considered\nto be very challenging, especially in bandwidth-limited scenarios. Most\ncommunication strategies rely on hybrid automatic repeat request (HARQ) to\nimprove reliability at the expense of increased packet latency due to the\nretransmission of failing packets. To guarantee high-reliability and very low\nlatency simultaneously, we enhance HARQ retransmission mechanism to achieve\nreliability with guaranteed packet level latency and in-time delivery. The\nproposed non-orthogonal HARQ (N-HARQ) utilizes non-orthogonal sharing of time\nslots for conducting retransmission. The reliability and delay analysis of the\nproposed N-HARQ in the finite block length (FBL) regime shows very high\nperformance gain in packet delivery delay over conventional HARQ in both\nadditive white Gaussian noise (AWGN) and Rayleigh fading channels. We also\npropose an optimization framework to further enhance the performance of N-HARQ\nfor single and multiple retransmission cases.",
    "descriptor": "",
    "authors": [
      "Faisal Nadeem",
      "Mahyar Shirvanimoghaddam",
      "Yonghui Li",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.16144"
  },
  {
    "id": "arXiv:2106.16146",
    "title": "6G V2X Technologies and Orchestrated Sensing for Autonomous Driving",
    "abstract": "6G technology targets to revolutionize the mobility industry by revamping the\nrole of wireless connections. In this article, we draw out our vision on an\nintelligent, cooperative, and sustainable mobility environment of the future,\ndiscussing how 6G will positively impact mobility services and applications.\nThe scenario in focus is a densely populated area by smart connected entities\nthat are mutually connected over a 6G virtual bus, which enables access to an\nextensive and always up-to-date set of context-sensitive information. The\naugmented dataset is functional to let vehicles engage in adaptive and\ncooperative learning mechanisms, enabling fully automated functionalities with\nhigher communication integrity and reduced risk of accidents while being a\nsentient and collaborative processing node of the same ecosystem. Smart sensing\nand communication technologies are discussed herein, and their convergence is\ndevised by the pervasiveness of artificial intelligence in centralized or\ndistributed and federated network architectures.",
    "descriptor": "\nComments: 9 Pages and 4 figures\n",
    "authors": [
      "Marouan Mizmizi",
      "Mattia Brambilla",
      "Dario Tagliaferri",
      "Christian Mazzucco",
      "Merouane Debbah",
      "Tomasz Mach",
      "Rino Simeone",
      "Silvio Mandelli",
      "Valerio Frascolla",
      "Renato Lombardi",
      "Maurizio Magarini",
      "Monica Nicoli",
      "Umberto Spagnolini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.16146"
  },
  {
    "id": "arXiv:2106.16147",
    "title": "Nearly-Tight and Oblivious Algorithms for Explainable Clustering",
    "abstract": "We study the problem of explainable clustering in the setting first\nformalized by Moshkovitz, Dasgupta, Rashtchian, and Frost (ICML 2020). A\n$k$-clustering is said to be explainable if it is given by a decision tree\nwhere each internal node splits data points with a threshold cut in a single\ndimension (feature), and each of the $k$ leaves corresponds to a cluster. We\ngive an algorithm that outputs an explainable clustering that loses at most a\nfactor of $O(\\log^2 k)$ compared to an optimal (not necessarily explainable)\nclustering for the $k$-medians objective, and a factor of $O(k \\log^2 k)$ for\nthe $k$-means objective. This improves over the previous best upper bounds of\n$O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\\Omega(\\log\nk)$ lower bound for $k$-medians and our new $\\Omega(k)$ lower bound for\n$k$-means. The algorithm is remarkably simple. In particular, given an initial\nnot necessarily explainable clustering in $\\mathbb{R}^d$, it is oblivious to\nthe data points and runs in time $O(dk \\log^2 k)$, independent of the number of\ndata points $n$. Our upper and lower bounds also generalize to objectives given\nby higher $\\ell_p$-norms.",
    "descriptor": "",
    "authors": [
      "Buddhima Gamlath",
      "Xinrui Jia",
      "Adam Polak",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16147"
  },
  {
    "id": "arXiv:2106.16148",
    "title": "High order interpolatory Serendipity Virtual Element Method for  semilinear parabolic problems",
    "abstract": "We propose an efficient method for the numerical solution of a general class\nof two dimensional semilinear parabolic problems on polygonal meshes. The\nproposed approach takes advantage of the properties of the serendipity version\nof the Virtual Element Method (VEM), which not only significantly reduces the\nnumber of degrees of freedom compared to the classical VEM but also, under\ncertain conditions on the mesh allows to approximate the nonlinear term with an\ninterpolant in the Serendipity VEM space; which substantially improves the\nefficiency of the method. An error analysis for the semi discrete formulation\nis carried out, and an optimal estimate for the error in the $L_2$-norm is\nobtained. The accuracy and efficiency of the proposed method when combined with\na second order Strang operator splitting time discretization is illustrated in\nour numerical experiments, with high order approximations up to order $6$.",
    "descriptor": "",
    "authors": [
      "Sergio G\u00f3mez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16148"
  },
  {
    "id": "arXiv:2106.16153",
    "title": "Multi-Modal Chorus Recognition for Improving Song Search",
    "abstract": "We discuss a novel task, Chorus Recognition, which could potentially benefit\ndownstream tasks such as song search and music summarization. Different from\nthe existing tasks such as music summarization or lyrics summarization relying\non single-modal information, this paper models chorus recognition as a\nmulti-modal one by utilizing both the lyrics and the tune information of songs.\nWe propose a multi-modal Chorus Recognition model that considers diverse\nfeatures. Besides, we also create and publish the first Chorus Recognition\ndataset containing 627 songs for public use. Our empirical study performed on\nthe dataset demonstrates that our approach outperforms several baselines in\nchorus recognition. In addition, our approach also helps to improve the\naccuracy of its downstream task - song search by more than 10.6%.",
    "descriptor": "\nComments: Accepted at the 30th International Conference on Artificial Neural Networks (ICANN 2021)\n",
    "authors": [
      "Jiaan Wang",
      "Zhixu Li",
      "Binbin Gu",
      "Tingyi Zhang",
      "Qingsheng Liu",
      "Zhigang Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.16153"
  },
  {
    "id": "arXiv:2106.16157",
    "title": "The energy revolution: cyber physical advances and opportunities for  smart local energy systems",
    "abstract": "We have designed a two-stage, 10-step process to give organisations a method\nto analyse small local energy systems (SLES) projects based on their Cyber\nPhysical System components in order to develop future-proof energy systems.\nSLES are often developed for a specific range of use cases and functions, and\nthese match the specific requirements and needs of the community, location or\nsite under consideration. During the design and commissioning, new and specific\ncyber physical architectures are developed. These are the control and data\nsystems that are needed to bridge the gap between the physical assets, the\ncaptured data and the control signals. Often, the cyber physical architecture\nand infrastructure is focused on functionality and the delivery of the specific\napplications.\nBut we find that technologies and approaches have arisen from other fields\nthat, if used within SLES, could support the flexibility, scalability and\nreusability vital to their success. As these can improve the operational data\nsystems then they can also be used to enhance predictive functions If used and\ndeployed effectively, these new approaches can offer longer term improvements\nin the use and effectiveness of SLES, while allowing the concepts and designs\nto be capitalised upon through wider roll-out and the offering of commercial\nservices or products.",
    "descriptor": "\nComments: White Paper on Cyber Physical Advances relevant to Smart Local Energy Systems\n",
    "authors": [
      "Nandor Verba",
      "Elena Gaura",
      "Stephen McArthur",
      "George Konstantopoulos",
      "Jianzhoug Wu",
      "Zhong Fan",
      "Dimitrios Athanasiadis",
      "Pablo Rodolfo Baldivieso Monasterios",
      "Euan Morris",
      "Jeffrey Hardy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.16157"
  },
  {
    "id": "arXiv:2106.16158",
    "title": "Jack The Rippler: Arbitrage on the Decentralized Exchange of the XRP  Ledger",
    "abstract": "The XRP Ledger (XRPL) is a peer-to-peer cryptographic ledger. It features a\ndecentralized exchange (DEX) where network participants can issue and trade\nuser-defined digital assets and currencies. We present Jack the Rippler, a bot\nthat identifies and exploits arbitrage opportunities on the XRPL DEX. We\ndescribe the Jack's arbitrage process and discuss risks associated with using\narbitrage bots.",
    "descriptor": "",
    "authors": [
      "Gaspard Peduzzi",
      "Jason James",
      "Jiahua Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.16158"
  },
  {
    "id": "arXiv:2106.16160",
    "title": "Validation: Conceptual versus Activity Diagram Approaches",
    "abstract": "A conceptual model is used to support development and design within the area\nof systems and software modeling. The notion of validation refers to\nrepresenting a domain in a model accurately and generating results using an\nexecutable model. In UML specifications, validation verifies the correctness of\nUML diagrams against any constraints and rules defined within the model.\nCurrently, significant research has been conducted on generating test sets to\nvalidate that UML diagrams conform to requirements. UML activity diagrams are a\nspecific focus of such efforts. An activity diagram is a flexible instrument\nfor describing a system s behaviors and the internal logic of complex\noperations. This paper focuses on the notion of validation using activity\ndiagrams and contrasts that process with a proposed method that involves an\ninformal validation procedure. Accordingly, this informal validation involves\ncomparing requirements to specifications expressed by a diagram of a modeling\nlanguage called thinging machine (TM) modeling. The informal validation is a\ntype of model checking that requires the model to be small enough for the\nverification to be done in a limited space or time period. In the proposed\nmethod, the model diagram is divided into subdiagrams to achieve this purpose.\nWe claim the TM behavioral model comes with a particular dispositional\nstructure that allows a designer to carve a model into smaller components for\ninformal validation, which is shown through two case studies.",
    "descriptor": "\nComments: 11 pages, 15 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.16160"
  },
  {
    "id": "arXiv:2106.16162",
    "title": "Learning More for Free - A Multi Task Learning Approach for Improved  Pathology Classification in Capsule Endoscopy",
    "abstract": "The progress in Computer Aided Diagnosis (CADx) of Wireless Capsule Endoscopy\n(WCE) is thwarted by the lack of data. The inadequacy in richly representative\nhealthy and abnormal conditions results in isolated analyses of pathologies,\nthat can not handle realistic multi-pathology scenarios. In this work, we\nexplore how to learn more for free, from limited data through solving a WCE\nmulticentric, multi-pathology classification problem. Learning more implies to\nlearning more than full supervision would allow with the same data. This is\ndone by combining self supervision with full supervision, under multi task\nlearning. Additionally, we draw inspiration from the Human Visual System (HVS)\nin designing self supervision tasks and investigate if seemingly ineffectual\nsignals within the data itself can be exploited to gain performance, if so,\nwhich signals would be better than others. Further, we present our analysis of\nthe high level features as a stepping stone towards more robust multi-pathology\nCADx in WCE.",
    "descriptor": "\nComments: MICCAI 2021 (Provisional accept)\n",
    "authors": [
      "Anuja Vats",
      "Marius Pedersen",
      "Ahmed Mohammed",
      "\u00d8istein Hovde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16162"
  },
  {
    "id": "arXiv:2106.16163",
    "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
    "abstract": "Experiments with pretrained models such as BERT are often based on a single\ncheckpoint. While the conclusions drawn apply to the artifact (i.e., the\nparticular instance of the model), it is not always clear whether they hold for\nthe more general procedure (which includes the model architecture, training\ndata, initialization scheme, and loss function). Recent work has shown that\nre-running pretraining can lead to substantially different conclusions about\nperformance, suggesting that alternative evaluations are needed to make\nprincipled statements about procedures. To address this question, we introduce\nMultiBERTs: a set of 25 BERT-base checkpoints, trained with similar\nhyper-parameters as the original BERT model but differing in random\ninitialization and data shuffling. The aim is to enable researchers to draw\nrobust and statistically justified conclusions about pretraining procedures.\nThe full release includes 25 fully trained checkpoints, as well as statistical\nguidelines and a code library implementing our recommended hypothesis testing\nmethods. Finally, for five of these models we release a set of 28 intermediate\ncheckpoints in order to support research on learning dynamics.",
    "descriptor": "\nComments: Checkpoints and example analyses: this http URL\n",
    "authors": [
      "Thibault Sellam",
      "Steve Yadlowsky",
      "Jason Wei",
      "Naomi Saphra",
      "Alexander D'Amour",
      "Tal Linzen",
      "Jasmijn Bastings",
      "Iulia Turc",
      "Jacob Eisenstein",
      "Dipanjan Das",
      "Ian Tenney",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16163"
  },
  {
    "id": "arXiv:2106.16166",
    "title": "A Critical Analysis of Recursive Model Indexes",
    "abstract": "Learned indexes like the recursive model index (RMI) have recently been\nintroduced as a machine-learned replacement for traditional indexes with\npossibly game-changing results for how database indexes are constructed and\nused. Has the time come to discard our good old hand-crafted index structures\nthat have been invented over the past decades? We believe that such a bold\nclaim -- with substantial impact on the database world -- is worth a deep\nexamination that clarifies when RMIs have benefits and when not. We present the\nfirst inventor-independent study critically examining RMIs. To do so, we\nrevisit the original paper and carefully reimplemented RMIs. We proceed by\nreproducing the most important experiments from the original paper and\nfollow-up papers all involving the inventors. We extend the original\nexperiments by adding more baselines and considering more configurations.\nFurther, we give insight on why and when RMIs perform well. Our results show\nthat while the general observation of the original work that \"any index is a\nmodel of the underlying data\" is truly inspiring, some conclusions drawn in the\noriginal work may mislead database architects to take unfortunate and too\nradical design decisions. In particular, we show that other types of indexes\noutperform RMIs in some situations. In addition, we will show that the\nperformance of RMIs is surprisingly sensitive to different data distributions.\nWe conclude by giving a clear guideline for database architects when to use\nRMIs, other learned indexes, or traditional indexes.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Marcel Maltry",
      "Jens Dittrich"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.16166"
  },
  {
    "id": "arXiv:2106.16171",
    "title": "Revisiting the Primacy of English in Zero-shot Cross-lingual Transfer",
    "abstract": "Despite their success, large pre-trained multilingual models have not\ncompletely alleviated the need for labeled data, which is cumbersome to collect\nfor all target languages. Zero-shot cross-lingual transfer is emerging as a\npractical solution: pre-trained models later fine-tuned on one transfer\nlanguage exhibit surprising performance when tested on many target languages.\nEnglish is the dominant source language for transfer, as reinforced by popular\nzero-shot benchmarks. However, this default choice has not been systematically\nvetted. In our study, we compare English against other transfer languages for\nfine-tuning, on two pre-trained multilingual models (mBERT and mT5) and\nmultiple classification and question answering tasks. We find that other\nhigh-resource languages such as German and Russian often transfer more\neffectively, especially when the set of target languages is diverse or unknown\na priori. Unexpectedly, this can be true even when the training sets were\nautomatically translated from English. This finding can have immediate impact\non multilingual zero-shot systems, and should inform future benchmark designs.",
    "descriptor": "",
    "authors": [
      "Iulia Turc",
      "Kenton Lee",
      "Jacob Eisenstein",
      "Ming-Wei Chang",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16171"
  },
  {
    "id": "arXiv:2106.16172",
    "title": "Backgammon is Hard",
    "abstract": "We study the computational complexity of the popular board game backgammon.\nWe show that deciding whether a player can win from a given board configuration\nis NP-Hard, PSPACE-Hard, and EXPTIME-Hard under different settings of known and\nunknown opponents' strategies and dice rolls. Our work answers an open question\nposed by Erik Demaine in 2001. In particular, for the real life setting where\nthe opponent's strategy and dice rolls are unknown, we prove that determining\nwhether a player can win is EXPTIME-Hard. Interestingly, it is not clear what\ncomplexity class strictly contains each problem we consider because backgammon\ngames can theoretically continue indefinitely as a result of the capture rule.",
    "descriptor": "",
    "authors": [
      "R. Teal Witter"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.16172"
  },
  {
    "id": "arXiv:2106.16173",
    "title": "String Comparison on a Quantum Computer Using Hamming Distance",
    "abstract": "The Hamming distance is ubiquitous in computing. Its computation gets\nexpensive when one needs to compare a string against many strings. Quantum\ncomputers (QCs) may speed up the comparison.\nIn this paper, we extend an existing algorithm for computing the Hamming\ndistance. The extension can compare strings with symbols drawn from an\narbitrary-long alphabet (which the original algorithm could not). We implement\nour extended algorithm using the QisKit framework to be executed by a\nprogrammer without the knowledge of a QC (the code is publicly available). We\nthen provide four pedagogical examples: two from the field of bioinformatics\nand two from the field of software engineering. We finish by discussing\nresource requirements and the time horizon of the QCs becoming practical for\nstring comparison.",
    "descriptor": "",
    "authors": [
      "Mushahid Khan",
      "Andriy Miranskyy"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Data Structures and Algorithms (cs.DS)",
      "Biological Physics (physics.bio-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.16173"
  },
  {
    "id": "arXiv:2106.16175",
    "title": "Early Risk Detection of Pathological Gambling, Self-Harm and Depression  Using BERT",
    "abstract": "Early risk detection of mental illnesses has a massive positive impact upon\nthe well-being of people. The eRisk workshop has been at the forefront of\nenabling interdisciplinary research in developing computational methods to\nautomatically estimate early risk factors for mental issues such as depression,\nself-harm, anorexia and pathological gambling. In this paper, we present the\ncontributions of the BLUE team in the 2021 edition of the workshop, in which we\ntackle the problems of early detection of gambling addiction, self-harm and\nestimating depression severity from social media posts. We employ pre-trained\nBERT transformers and data crawled automatically from mental health subreddits\nand obtain reasonable results on all three tasks.",
    "descriptor": "\nComments: Accepted to Early Risk Prediction on the Internet Workshop, Conference and Labs of the Evaluation Forum (CLEF 2021)\n",
    "authors": [
      "Ana-Maria Bucur",
      "Adrian Cosma",
      "Liviu P. Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16175"
  },
  {
    "id": "arXiv:2106.16176",
    "title": "Integrated Vehicle Routing and Monte Carlo Scheduling Approach for the  Home Service Assignment, Routing, and Scheduling Problem",
    "abstract": "We formulate and solve the H-SARA Problem, a Vehicle Routing and Appointment\nScheduling Problem motivated by home services management. We assume that travel\ntimes, service durations, and customer cancellations are stochastic. We use a\ntwo-stage process that first generates teams and routes using a VRP Solver with\noptional extensions and then uses an MC Scheduler that determines expected\narrival times by teams at customers. We further introduce two different models\nof cancellation and their associated impacts on routing and scheduling.\nFinally, we introduce the Route Fracture Metaheuristic that iteratively\nimproves an H-SARA solution by replacing the worst-performing teams. We present\ninsights into the problem and a series of numerical experiments that illustrate\nproperties of the optimal routing, scheduling, and the impact of the Route\nFracture Metaheuristic for both models of cancellation.",
    "descriptor": "",
    "authors": [
      "Shamay G. Samuel",
      "Enrique Areyan Viqueira",
      "Serdar Kadioglu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.16176"
  },
  {
    "id": "arXiv:2106.16180",
    "title": "Grid Recognition: Classical and Parameterized Computational Perspectives",
    "abstract": "Grid graphs, and, more generally, $k\\times r$ grid graphs, form one of the\nmost basic classes of geometric graphs. Over the past few decades, a large body\nof works studied the (in)tractability of various computational problems on grid\ngraphs, which often yield substantially faster algorithms than general graphs.\nUnfortunately, the recognition of a grid graph is particularly hard -- it was\nshown to be NP-hard even on trees of pathwidth 3 already in 1987. Yet, in this\npaper, we provide several positive results in this regard in the framework of\nparameterized complexity (additionally, we present new and complementary\nhardness results). Specifically, our contribution is threefold. First, we show\nthat the problem is fixed-parameter tractable (FPT) parameterized by $k+\\mathsf\n{mcc}$ where $\\mathsf{mcc}$ is the maximum size of a connected component of\n$G$. This also implies that the problem is FPT parameterized by $\\mathtt{td}+k$\nwhere $\\mathtt{td}$ is the treedepth of $G$ (to be compared with the hardness\nfor pathwidth 2 where $k=3$). Further, we derive as a corollary that strip\npacking is FPT with respect to the height of the strip plus the maximum of the\ndimensions of the packed rectangles, which was previously only known to be in\nXP. Second, we present a new parameterization, denoted $a_G$, relating graph\ndistance to geometric distance, which may be of independent interest. We show\nthat the problem is para-NP-hard parameterized by $a_G$, but FPT parameterized\nby $a_G$ on trees, as well as FPT parameterized by $k+a_G$. Third, we show that\nthe recognition of $k\\times r$ grid graphs is NP-hard on graphs of pathwidth 2\nwhere $k=3$. Moreover, when $k$ and $r$ are unrestricted, we show that the\nproblem is NP-hard on trees of pathwidth 2, but trivially solvable in\npolynomial time on graphs of pathwidth 1.",
    "descriptor": "",
    "authors": [
      "Siddharth Gupta",
      "Guy Sa'ar",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.16180"
  },
  {
    "id": "arXiv:2106.16187",
    "title": "Reinforcement Learning based Disease Progression Model for Alzheimer's  Disease",
    "abstract": "We model Alzheimer's disease (AD) progression by combining differential\nequations (DEs) and reinforcement learning (RL) with domain knowledge. DEs\nprovide relationships between some, but not all, factors relevant to AD. We\nassume that the missing relationships must satisfy general criteria about the\nworking of the brain, for e.g., maximizing cognition while minimizing the cost\nof supporting cognition. This allows us to extract the missing relationships by\nusing RL to optimize an objective (reward) function that captures the above\ncriteria. We use our model consisting of DEs (as a simulator) and the trained\nRL agent to predict individualized 10-year AD progression using baseline (year\n0) features on synthetic and real data. The model was comparable or better at\npredicting 10-year cognition trajectories than state-of-the-art learning-based\nmodels. Our interpretable model demonstrated, and provided insights into,\n\"recovery/compensatory\" processes that mitigate the effect of AD, even though\nthose processes were not explicitly encoded in the model. Our framework\ncombines DEs with RL for modelling AD progression and has broad applicability\nfor understanding other neurological disorders.",
    "descriptor": "\nComments: 9 pages main text, 3 page references, 10 page appendix\n",
    "authors": [
      "Krishnakant V. Saboo",
      "Anirudh Choudhary",
      "Yurui Cao",
      "Gregory A. Worrell",
      "David T. Jones",
      "Ravishankar K. Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16187"
  },
  {
    "id": "arXiv:2106.16188",
    "title": "Improving Factual Consistency of Abstractive Summarization on Customer  Feedback",
    "abstract": "E-commerce stores collect customer feedback to let sellers learn about\ncustomer concerns and enhance customer order experience. Because customer\nfeedback often contains redundant information, a concise summary of the\nfeedback can be generated to help sellers better understand the issues causing\ncustomer dissatisfaction. Previous state-of-the-art abstractive text\nsummarization models make two major types of factual errors when producing\nsummaries from customer feedback, which are wrong entity detection (WED) and\nincorrect product-defect description (IPD). In this work, we introduce a set of\nmethods to enhance the factual consistency of abstractive summarization on\ncustomer feedback. We augment the training data with artificially corrupted\nsummaries, and use them as counterparts of the target summaries. We add a\ncontrastive loss term into the training objective so that the model learns to\navoid certain factual errors. Evaluation results show that a large portion of\nWED and IPD errors are alleviated for BART and T5. Furthermore, our approaches\ndo not depend on the structure of the summarization model and thus are\ngeneralizable to any abstractive summarization systems.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Yifei Sun",
      "Vincent Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16188"
  },
  {
    "id": "arXiv:2106.16190",
    "title": "A Domain-Theoretic Approach to Statistical Programming Languages",
    "abstract": "We give a domain-theoretic semantics to a statistical programming language,\nusing the plain old category of dcpos, in contrast to some more sophisticated\nrecent proposals. Remarkably, our monad of minimal valuations is commutative,\nwhich allows for program transformations that permute the order of independent\nrandom draws, as one would expect. A similar property is not known for Jones\nand Plotkin' s monad of continuous valuations. Instead of working with true\nreal numbers, we work with exact real arithmetic, providing a bridge towards\npossible implementations. (Implementations by themselves are not addressed\nhere.) Rather remarkably, we show that restricting ourselves to minimal\nvaluations does not restrict us much: all measures on the real line can be\nmodeled by minimal valuations on the domain $\\mathbf{I}\\mathbb{R}_\\bot$ of\nexact real arithmetic. We give three operational semantics for our language,\nand we show that they are all adequate with respect to the denotational\nsemantics. We also explore quite a few examples in order to demonstrate that\nour semantics computes exactly as one would expect, and in order to debunk the\nmyth that a semantics based on continuous maps would not be expressive enough\nto encode measures with non-compact support using only measures with compact\nsupport, or to encode measures via non-continuous density functions, for\ninstance.",
    "descriptor": "\nComments: 81 pages\n",
    "authors": [
      "Jean Goubault-Larrecq",
      "Xiaodong Jia",
      "Cl\u00e9ment Th\u00e9ron"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.16190"
  },
  {
    "id": "arXiv:2106.16193",
    "title": "On a sinc-type MBE model",
    "abstract": "We introduce a new sinc-type molecular beam epitaxy model which is derived\nfrom a cosine-type energy functional. The landscape of the new functional is\nremarkably similar to the classical MBE model with double well potential but\nhas the additional advantage that all its derivatives are uniformly bounded. We\nconsider first order IMEX and second order BDF2 discretization schemes. For\nboth cases we quantify explicit time step constraints for the energy\ndissipation which is in good accord with the practical numerical simulations.\nFurthermore we introduce a new theoretical framework and prove unconditional\nuniform energy boundedness with no size restrictions on the time step. This is\nthe first unconditional (i.e. independent of the time step size) result for\nsemi-implicit methods applied to the phase field models without introducing any\nartificial stabilization terms or fictitious variables.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Xinyu Cheng",
      "Dong Li",
      "Chaoyu Quan",
      "Wen Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.16193"
  },
  {
    "id": "arXiv:2106.16196",
    "title": "An Analysis of the Recent Visibility of the SigDial Conference",
    "abstract": "Automated speech and text interfaces are continuing to improve, resulting in\nincreased research in the area of dialogue systems. Moreover, conferences and\nworkshops from various fields are focusing more on language through speech and\ntext mediums as candidates for interaction with applications such as search\ninterfaces and robots. In this paper, we explore how visible the SigDial\nconference is to outside conferences by analysing papers from top Natural\nLangauge Processing conferences since 2015 to determine the popularity of\ncertain SigDial-related topics, as well as analysing what SigDial papers are\nbeing cited by others outside of SigDial. We find that despite a dramatic\nincrease in dialogue-related research, SigDial visibility has not increased. We\nconclude by offering some suggestions.",
    "descriptor": "",
    "authors": [
      "Casey Kennington",
      "McKenzie Steenson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16196"
  },
  {
    "id": "arXiv:2106.16197",
    "title": "Improved constructions for succinct affine automata",
    "abstract": "Affine finite automata (AfA) can be more succinct than probabilistic and\nquantum finite automata when recognizing some regular languages with\nbounded-error. In this paper, we improve previously known constructions given\nfor the succinctness of AfAs in three ways. First, we replace some of fixed\nerror bounds with arbitrarily small error bounds. Second, we present new\nconstructions by using less states than the previous constructions. Third, we\nshow that any language recognized by a nondeterministic finite automaton (NFA)\nis also recognized by bounded-error AfAs having one more state, and so, AfAs\ninherit all succinct results by NFAs. As a special case, we also show that any\nlanguage recognized by a NFA is recognized by AfAs with zero error if the\nnumber of accepting path(s) for each member is exactly the same number.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Abuzer Yakary\u0131lmaz"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.16197"
  },
  {
    "id": "arXiv:2106.16198",
    "title": "Small in-distribution changes in 3D perspective and lighting fool both  CNNs and Transformers",
    "abstract": "Neural networks are susceptible to small transformations including 2D\nrotations and shifts, image crops, and even changes in object colors. This is\noften attributed to biases in the training dataset, and the lack of 2D\nshift-invariance due to not respecting the sampling theorem. In this paper, we\nchallenge this hypothesis by training and testing on unbiased datasets, and\nshowing that networks are brittle to both small 3D perspective changes and\nlighting variations which cannot be explained by dataset bias or lack of\nshift-invariance. To find these in-distribution errors, we introduce an\nevolution strategies (ES) based approach, which we call CMA-Search. Despite\ntraining with a large-scale (0.5 million images), unbiased dataset of camera\nand light variations, in over 71% cases CMA-Search can find camera parameters\nin the vicinity of a correctly classified image which lead to in-distribution\nmisclassifications with < 3.6% change in parameters. With lighting changes,\nCMA-Search finds misclassifications in 33% cases with < 11.6% change in\nparameters. Finally, we extend this method to find misclassifications in the\nvicinity of ImageNet images for both ResNet and OpenAI's CLIP model.",
    "descriptor": "",
    "authors": [
      "Spandan Madan",
      "Tomotake Sasaki",
      "Tzu-Mao Li",
      "Xavier Boix",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16198"
  },
  {
    "id": "arXiv:2106.16199",
    "title": "Verifix: Verified Repair of Programming Assignments",
    "abstract": "Automated feedback generation for introductory programming assignments is\nuseful for programming education. Most works try to generate feedback to\ncorrect a student program by comparing its behavior with an instructor's\nreference program on selected tests. In this work, our aim is to generate\nverifiably correct program repairs as student feedback. The student assignment\nis aligned and composed with a reference solution in terms of control flow, and\ndifferences in data variables are automatically summarized via predicates to\nrelate the variable names. Failed verification attempts for the equivalence of\nthe two programs are exploited to obtain a collection of maxSMT queries, whose\nsolutions point to repairs of the student assignment. We have conducted\nexperiments on student assignments curated from a widely deployed intelligent\ntutoring system. Our results indicate that we can generate verified feedback in\nup to 58% of the assignments. More importantly, our system indicates when it is\nable to generate a verified feedback, which is then usable by novice students\nwith high confidence.",
    "descriptor": "",
    "authors": [
      "Umair Z. Ahmed",
      "Zhiyu Fan",
      "Jooyong Yi",
      "Omar I. Al-Bataineh",
      "Abhik Roychoudhury"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.16199"
  },
  {
    "id": "arXiv:2106.16200",
    "title": "A Unified View of Stochastic Hamiltonian Sampling",
    "abstract": "In this work, we revisit the theoretical properties of Hamiltonian stochastic\ndifferential equations (SDEs) for Bayesian posterior sampling, and we study the\ntwo types of errors that arise from numerical SDE simulation: the\ndiscretization error and the error due to noisy gradient estimates in the\ncontext of data subsampling. We consider overlooked results describing the\nergodic convergence rates of numerical integration schemes, and we produce a\nnovel analysis for the effect of mini-batches through the lens of differential\noperator splitting. In our analysis, the stochastic component of the proposed\nHamiltonian SDE is decoupled from the gradient noise, for which we make no\nnormality assumptions. This allows us to derive interesting connections among\ndifferent sampling schemes, including the original Hamiltonian Monte Carlo\n(HMC) algorithm, and explain their performance. We show that for a careful\nselection of numerical integrators, both errors vanish at a rate\n$\\mathcal{O}(\\eta^2)$, where $\\eta$ is the integrator step size. Our\ntheoretical results are supported by an empirical study on a variety of\nregression and classification tasks for Bayesian neural networks.",
    "descriptor": "",
    "authors": [
      "Giulio Franzese",
      "Dimitrios Milios",
      "Maurizio Filippone",
      "Pietro Michiardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16200"
  },
  {
    "id": "arXiv:2106.16204",
    "title": "Combinatorial generation via permutation languages. IV. Elimination  trees",
    "abstract": "An elimination tree for a connected graph $G$ is a rooted tree on the\nvertices of $G$ obtained by choosing a root $x$ and recursing on the connected\ncomponents of $G-x$ to produce the subtrees of $x$. Elimination trees appear in\nmany guises in computer science and discrete mathematics, and they encode many\ninteresting combinatorial objects, such as bitstrings, permutations and binary\ntrees. We apply the recent Hartung-Hoang-M\\\"utze-Williams combinatorial\ngeneration framework to elimination trees, and prove that all elimination trees\nfor a chordal graph $G$ can be generated by tree rotations using a simple\ngreedy algorithm. This yields a short proof for the existence of Hamilton paths\non graph associahedra of chordal graphs. Graph associahedra are a general class\nof high-dimensional polytopes introduced by Carr, Devadoss, and Postnikov,\nwhose vertices correspond to elimination trees and whose edges correspond to\ntree rotations. As special cases of our results, we recover several classical\nGray codes for bitstrings, permutations and binary trees, and we obtain a new\nGray code for partial permutations. Our algorithm for generating all\nelimination trees for a chordal graph $G$ can be implemented in time\n$\\mathcal{O}(m+n)$ per generated elimination tree, where $m$ and $n$ are the\nnumber of edges and vertices of $G$, respectively. If $G$ is a tree, we improve\nthis to a loopless algorithm running in time $\\mathcal(1)$ per generated\nelimination tree. We also prove that our algorithm produces a Hamilton cycle on\nthe graph associahedron of $G$, rather than just Hamilton path, if the graph\n$G$ is chordal and 2-connected. Moreover, our algorithm characterizes\nchordality, i.e., it computes a Hamilton path on the graph associahedron of $G$\nif and only if $G$ is chordal.",
    "descriptor": "",
    "authors": [
      "Jean Cardinal",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16204"
  },
  {
    "id": "arXiv:2106.16207",
    "title": "When the Echo Chamber Shatters: Examining the Use of Community-Specific  Language Post-Subreddit Ban",
    "abstract": "Community-level bans are a common tool against groups that enable online\nharassment and harmful speech. Unfortunately, the efficacy of community bans\nhas only been partially studied and with mixed results. Here, we provide a\nflexible unsupervised methodology to identify in-group language and track user\nactivity on Reddit both before and after the ban of a community (subreddit). We\nuse a simple word frequency divergence to identify uncommon words\noverrepresented in a given community, not as a proxy for harmful speech but as\na linguistic signature of the community. We apply our method to 15 banned\nsubreddits, and find that community response is heterogeneous between\nsubreddits and between users of a subreddit. Top users were more likely to\nbecome less active overall, while random users often reduced use of in-group\nlanguage without decreasing activity. Finally, we find some evidence that the\neffectiveness of bans aligns with the content of a community. Users of dark\nhumor communities were largely unaffected by bans while users of communities\norganized around white supremacy and fascism were the most affected.\nAltogether, our results show that bans do not affect all groups or users\nequally, and pave the way to understanding the effect of bans across\ncommunities.",
    "descriptor": "\nComments: 15 pages (including references and appendix), 5 figures\n",
    "authors": [
      "Milo Z. Trujillo",
      "Samuel F. Rosenblatt",
      "Guillermo de Anda J\u00e1uregui",
      "Emily Moog",
      "Briane Paul V. Samson",
      "Laurent H\u00e9bert-Dufresne",
      "Allison M. Roth"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.16207"
  },
  {
    "id": "arXiv:2106.16209",
    "title": "S2C2 - An orthogonal method for Semi-Supervised Learning on fuzzy labels",
    "abstract": "Semi-Supervised Learning (SSL) can decrease the amount of required labeled\nimage data and thus the cost for deep learning. Most SSL methods only consider\na clear distinction between classes but in many real-world datasets, this clear\ndistinction is not given due to intra- or interobserver variability. This\nvariability can lead to different annotations per image. Thus many images have\nambiguous annotations and their label needs to be considered \"fuzzy\". This\nfuzziness of labels must be addressed as it will limit the performance of\nSemi-Supervised Learning (SSL) and deep learning in general. We propose\nSemi-Supervised Classification & Clustering (S2C2) which can extend many deep\nSSL algorithms. S2C2 can estimate the fuzziness of a label and applies SSL as a\nclassification to certainly labeled data while creating distinct clusters for\nimages with similar but fuzzy labels. We show that S2C2 results in median 7.4%\nbetter F1-score for classifications and 5.4% lower inner distance of clusters\nacross multiple SSL algorithms and datasets while being more interpretable due\nto the fuzziness estimation of our method. Overall, a combination of\nSemi-Supervised Learning with our method S2C2 leads to better handling of the\nfuzziness of labels and thus real-world datasets.",
    "descriptor": "",
    "authors": [
      "Lars Schmarje",
      "Monty Santarossa",
      "Simon-Martin Schr\u00f6der",
      "Claudius Zelenka",
      "Rainer Kiko",
      "Jenny Stracke",
      "Nina Volkmann",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16209"
  },
  {
    "id": "arXiv:2106.16213",
    "title": "On the Power of Saturated Transformers: A View from Circuit Complexity",
    "abstract": "Transformers have become a standard architecture for many NLP problems. This\nhas motivated theoretically analyzing their capabilities as models of language,\nin order to understand what makes them successful, and what their potential\nweaknesses might be. Recent work has shown that transformers with hard\nattention are quite limited in capacity, and in fact can be simulated by\nconstant-depth circuits. However, hard attention is a restrictive assumption,\nwhich may complicate the relevance of these results for practical transformers.\nIn this work, we analyze the circuit complexity of transformers with saturated\nattention: a generalization of hard attention that more closely captures the\nattention patterns learnable in practical transformers. We show that saturated\ntransformers transcend the limitations of hard-attention transformers. With\nsome minor assumptions, we prove that the number of bits needed to represent a\nsaturated transformer memory vector is $O(\\log n)$, which implies saturated\ntransformers can be simulated by log-depth circuits. Thus, the jump from hard\nto saturated attention can be understood as increasing the transformer's\neffective circuit depth by a factor of $O(\\log n)$.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "William Merrill",
      "Yoav Goldberg",
      "Roy Schwartz",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16213"
  },
  {
    "id": "arXiv:2106.16215",
    "title": "Algorithm For 3D-Chemotaxis Using Spiking Neural Network",
    "abstract": "In this work, we aim to devise an end-to-end spiking implementation for\ncontour tracking in 3D media inspired by chemotaxis, where the worm reaches the\nregion which has the given set concentration. For a planer medium, efficient\ncontour tracking algorithms have already been devised, but a new degree of\nfreedom has quite a few challenges. Here we devise an algorithm based on\nklinokinesis - where the motion of the worm is in response to the stimuli but\nnot proportional to it. Thus the path followed is not the shortest, but we can\ntrack the set concentration successfully. We are using simple LIF neurons for\nthe neural network implementation, considering the feasibility of its\nimplementation in the neuromorphic computing hardware.",
    "descriptor": "\nComments: 12 pages, 8 figures, accepted for the '30th International Conference on Artificial Neural Networks, ICANN2021'\n",
    "authors": [
      "Jayesh Choudhary",
      "Vivek Saraswat",
      "Udayan Ganguly"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.16215"
  },
  {
    "id": "arXiv:2106.16218",
    "title": "Logarithmic Weisfeiler-Leman Identifies All Planar Graphs",
    "abstract": "The Weisfeiler-Leman (WL) algorithm is a well-known combinatorial procedure\nfor detecting symmetries in graphs and it is widely used in graph-isomorphism\ntests. It proceeds by iteratively refining a colouring of vertex tuples. The\nnumber of iterations needed to obtain the final output is crucial for the\nparallelisability of the algorithm.\nWe show that there is a constant k such that every planar graph can be\nidentified (that is, distinguished from every non-isomorphic graph) by the\nk-dimensional WL algorithm within a logarithmic number of iterations. This\ngeneralises a result due to Verbitsky (STACS 2007), who proved the same for\n3-connected planar graphs.\nThe number of iterations needed by the k-dimensional WL algorithm to identify\na graph corresponds to the quantifier depth of a sentence that defines the\ngraph in the (k+1)-variable fragment C^{k+1} of first-order logic with counting\nquantifiers. Thus, our result implies that every planar graph is definable with\na C^{k+1}-sentence of logarithmic quantifier depth.",
    "descriptor": "\nComments: 21 pages, 2 figures, accepted at ICALP 2021\n",
    "authors": [
      "Martin Grohe",
      "Sandra Kiefer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16218"
  },
  {
    "id": "arXiv:2106.16225",
    "title": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps",
    "abstract": "The Hessian of a neural network captures parameter interactions through\nsecond-order derivatives of the loss. It is a fundamental object of study,\nclosely tied to various problems in deep learning, including model design,\noptimization, and generalization. Most prior work has been empirical, typically\nfocusing on low-rank approximations and heuristics that are blind to the\nnetwork structure. In contrast, we develop theoretical tools to analyze the\nrange of the Hessian map, providing us with a precise understanding of its rank\ndeficiency as well as the structural reasons behind it. This yields exact\nformulas and tight upper bounds for the Hessian rank of deep linear networks,\nallowing for an elegant interpretation in terms of rank deficiency. Moreover,\nwe demonstrate that our bounds remain faithful as an estimate of the numerical\nHessian rank, for a larger class of models such as rectified and hyperbolic\ntangent networks. Further, we also investigate the implications of model\narchitecture (e.g.~width, depth, bias) on the rank deficiency. Overall, our\nwork provides novel insights into the source and extent of redundancy in\noverparameterized networks.",
    "descriptor": "",
    "authors": [
      "Sidak Pal Singh",
      "Gregor Bachmann",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16225"
  },
  {
    "id": "arXiv:2106.16233",
    "title": "Long Short-term Cognitive Networks",
    "abstract": "In this paper, we present a recurrent neural system named Long Short-term\nCognitive Networks (LSTCNs) as a generalisation of the Short-term Cognitive\nNetwork (STCN) model. Such a generalisation is motivated by the difficulty of\nforecasting very long time series in an efficient, greener fashion. The LSTCN\nmodel can be defined as a collection of STCN blocks, each processing a specific\ntime patch of the (multivariate) time series being modelled. In this neural\nensemble, each block passes information to the subsequent one in the form of a\nweight matrix referred to as the prior knowledge matrix. As a second\ncontribution, we propose a deterministic learning algorithm to compute the\nlearnable weights while preserving the prior knowledge resulting from previous\nlearning processes. As a third contribution, we introduce a feature influence\nscore as a proxy to explain the forecasting process in multivariate time\nseries. The simulations using three case studies show that our neural system\nreports small forecasting errors while being up to thousands of times faster\nthan state-of-the-art recurrent models.",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Isel Grau",
      "Agnieszka Jastrzebska",
      "Yamisleydi Salgueiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.16233"
  },
  {
    "id": "arXiv:2106.16237",
    "title": "Shape Completion via IMLE",
    "abstract": "Shape completion is the problem of completing partial input shapes such as\npartial scans. This problem finds important applications in computer vision and\nrobotics due to issues such as occlusion or sparsity in real-world data.\nHowever, most of the existing research related to shape completion has been\nfocused on completing shapes by learning a one-to-one mapping which limits the\ndiversity and creativity of the produced results. We propose a novel multimodal\nshape completion technique that is effectively able to learn a one-to-many\nmapping and generates diverse complete shapes. Our approach is based on the\nconditional Implicit MaximumLikelihood Estimation (IMLE) technique wherein we\ncondition our inputs on partial 3D point clouds. We extensively evaluate our\napproach by comparing it to various baselines both quantitatively and\nqualitatively. We show that our method is superior to alternatives in terms of\ncompleteness and diversity of shapes",
    "descriptor": "",
    "authors": [
      "Himanshu Arora",
      "Saurabh Mishra",
      "Shichong Peng",
      "Ke Li",
      "Ali Mahdavi-Amiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16237"
  },
  {
    "id": "arXiv:2106.16245",
    "title": "How to Train Your MAML to Excel in Few-Shot Classification",
    "abstract": "Model-agnostic meta-learning (MAML) is arguably the most popular\nmeta-learning algorithm nowadays, given its flexibility to incorporate various\nmodel architectures and to be applied to different problems. Nevertheless, its\nperformance on few-shot classification is far behind many recent algorithms\ndedicated to the problem. In this paper, we point out several key facets of how\nto train MAML to excel in few-shot classification. First, we find that a large\nnumber of gradient steps are needed for the inner loop update, which\ncontradicts the common usage of MAML for few-shot classification. Second, we\nfind that MAML is sensitive to the permutation of class assignments in\nmeta-testing: for a few-shot task of $N$ classes, there are exponentially many\nways to assign the learned initialization of the $N$-way classifier to the $N$\nclasses, leading to an unavoidably huge variance. Third, we investigate several\nways for permutation invariance and find that learning a shared classifier\ninitialization for all the classes performs the best. On benchmark datasets\nsuch as MiniImageNet and TieredImageNet, our approach, which we name\nUNICORN-MAML, performs on a par with or even outperforms state-of-the-art\nalgorithms, while keeping the simplicity of MAML without adding any extra\nsub-networks.",
    "descriptor": "",
    "authors": [
      "Han-Jia Ye",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16245"
  },
  {
    "id": "arXiv:2106.12199",
    "title": "Bayesian Joint Chance Constrained Optimization: Approximations and  Statistical Consistency",
    "abstract": "This paper considers data-driven chance-constrained stochastic optimization\nproblems in a Bayesian framework. Bayesian posteriors afford a principled\nmechanism to incorporate data and prior knowledge into stochastic optimization\nproblems. However, the computation of Bayesian posteriors is typically an\nintractable problem, and has spawned a large literature on approximate Bayesian\ncomputation. Here, in the context of chance-constrained optimization, we focus\non the question of statistical consistency (in an appropriate sense) of the\noptimal value, computed using an approximate posterior distribution. To this\nend, we rigorously prove a frequentist consistency result demonstrating the\nconvergence of the optimal value to the optimal value of a fixed, parameterized\nconstrained optimization problem. We augment this by also establishing a\nprobabilistic rate of convergence of the optimal value. We also prove the\nconvex feasibility of the approximate Bayesian stochastic optimization problem.\nFinally, we demonstrate the utility of our approach on an optimal staffing\nproblem for an M/M/c queueing model.",
    "descriptor": "",
    "authors": [
      "Prateek Jaiswal",
      "Harsha Honnappa",
      "Vinayak A. Rao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.12199"
  },
  {
    "id": "arXiv:2106.15649",
    "title": "Multi-Scale Spectrogram Modelling for Neural Text-to-Speech",
    "abstract": "We propose a novel Multi-Scale Spectrogram (MSS) modelling approach to\nsynthesise speech with an improved coarse and fine-grained prosody. We present\na generic multi-scale spectrogram prediction mechanism where the system first\npredicts coarser scale mel-spectrograms that capture the suprasegmental\ninformation in speech, and later uses these coarser scale mel-spectrograms to\npredict finer scale mel-spectrograms capturing fine-grained prosody.\nWe present details for two specific versions of MSS called Word-level MSS and\nSentence-level MSS where the scales in our system are motivated by the\nlinguistic units. The Word-level MSS models word, phoneme, and frame-level\nspectrograms while Sentence-level MSS models sentence-level spectrogram in\naddition.\nSubjective evaluations show that Word-level MSS performs statistically\nsignificantly better compared to the baseline on two voices.",
    "descriptor": "\nComments: Accepted for the 11th ISCA Speech Synthesis Workshop (SSW11)\n",
    "authors": [
      "Ammar Abbas",
      "Bajibabu Bollepalli",
      "Alexis Moinet",
      "Arnaud Joly",
      "Penny Karanasou",
      "Peter Makarov",
      "Simon Slangens",
      "Sri Karlapati",
      "Thomas Drugman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15649"
  },
  {
    "id": "arXiv:2106.15659",
    "title": "Towards a generalized monaural and binaural auditory model for  psychoacoustics and speech intelligibility",
    "abstract": "Auditory perception involves cues in the monaural auditory pathways as well\nas binaural cues based on differences between the ears. So far auditory models\nhave often focused on either monaural or binaural experiments in isolation.\nAlthough binaural models typically build upon stages of (existing) monaural\nmodels, only a few attempts have been made to extend a monaural model by a\nbinaural stage using a unified decision stage for monaural and binaural cues.\nIn such approaches, a typical prototype of binaural processing has been the\nclassical equalization-cancelation mechanism, which either involves\nsignal-adaptive delays and provides a single channel output or can be\nimplemented with tapped delays providing a high-dimensional multichannel\noutput. This contribution extends the (monaural) generalized envelope power\nspectrum model by a non-adaptive binaural stage with only a few, fixed output\nchannels. The binaural stage resembles features of physiologically motivated\nhemispheric binaural processing, as simplified signal processing stages,\nyielding a 5-channel monaural and binaural matrix feature \"decoder\" (BMFD). The\nback end of the existing monaural model is applied to the 5-channel BMFD output\nand calculates short-time envelope power and power features. The model is\nevaluated and discussed for a baseline database of monaural and binaural\npsychoacoustic experiments from the literature.",
    "descriptor": "\nComments: submitted to Acta Acustica\n",
    "authors": [
      "Thomas Biberger",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15659"
  },
  {
    "id": "arXiv:2106.15666",
    "title": "Probabilistic Graphical Models and Tensor Networks: A Hybrid Framework",
    "abstract": "We investigate a correspondence between two formalisms for discrete\nprobabilistic modeling: probabilistic graphical models (PGMs) and tensor\nnetworks (TNs), a powerful modeling framework for simulating complex quantum\nsystems. The graphical calculus of PGMs and TNs exhibits many similarities,\nwith discrete undirected graphical models (UGMs) being a special case of TNs.\nHowever, more general probabilistic TN models such as Born machines (BMs)\nemploy complex-valued hidden states to produce novel forms of correlation among\nthe probabilities. While representing a new modeling resource for capturing\nstructure in discrete probability distributions, this behavior also renders the\ndirect application of standard PGM tools impossible. We aim to bridge this gap\nby introducing a hybrid PGM-TN formalism that integrates quantum-like\ncorrelations into PGM models in a principled manner, using the\nphysically-motivated concept of decoherence. We first prove that applying\ndecoherence to the entirety of a BM model converts it into a discrete UGM, and\nconversely, that any subgraph of a discrete UGM can be represented as a\ndecohered BM. This method allows a broad family of probabilistic TN models to\nbe encoded as partially decohered BMs, a fact we leverage to combine the\nrepresentational strengths of both model families. We experimentally verify the\nperformance of such hybrid models in a sequential modeling task, and identify\npromising uses of our method within the context of existing applications of\ngraphical models.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Jacob Miller",
      "Geoffrey Roeder",
      "Tai-Danae Bradley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15666"
  },
  {
    "id": "arXiv:2106.15678",
    "title": "Data-Driven Operator Theoretic Methods for Phase Space Learning and  Analysis",
    "abstract": "This paper uses data-driven operator theoretic approaches to explore the\nglobal phase space of a dynamical system. We defined conditions for discovering\nnew invariant subspaces in the state space of a dynamical system starting from\nan invariant subspace based on the spectral properties of the Koopman operator.\nWhen the system evolution is known locally in several invariant subspaces in\nthe state space of a dynamical system, a phase space stitching result is\nderived that yields the global Koopman operator. Additionally, in the case of\nequivariant systems, a phase space stitching result is developed to identify\nthe global Koopman operator using the symmetry properties between the invariant\nsubspaces of the dynamical system and time-series data from any one of the\ninvariant subspaces. Finally, these results are extended to topologically\nconjugate dynamical systems; in particular, the relation between the Koopman\ntuple of topologically conjugate systems is established. The proposed results\nare demonstrated on several second-order nonlinear dynamical systems including\na bistable toggle switch. Our method elucidates a strategy for designing\ndiscovery experiments: experiment execution can be done in many steps, and\nmodels from different invariant subspaces can be combined to approximate the\nglobal Koopman operator.",
    "descriptor": "\nComments: 32 pages, 19 figures. This paper is currently under review\n",
    "authors": [
      "Sai Pushpak Nandanoori",
      "Subhrajit Sinha",
      "Enoch Yeung"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15678"
  },
  {
    "id": "arXiv:2106.15698",
    "title": "Emotions in Macroeconomic News and their Impact on the European Bond  Market",
    "abstract": "We show how emotions extracted from macroeconomic news can be used to explain\nand forecast future behaviour of sovereign bond yield spreads in Italy and\nSpain. We use a big, open-source, database known as Global Database of Events,\nLanguage and Tone to construct emotion indicators of bond market affective\nstates. We find that negative emotions extracted from news improve the\nforecasting power of government yield spread models during distressed periods\neven after controlling for the number of negative words present in the text. In\naddition, stronger negative emotions, such as panic, reveal useful information\nfor predicting changes in spread at the short-term horizon, while milder\nemotions, such as distress, are useful at longer time horizons. Emotions\ngenerated by the Italian political turmoil propagate to the Spanish news\naffecting this neighbourhood market.",
    "descriptor": "\nComments: Journal of International Money and Finance (to appear); 39 pages; 14 figures\n",
    "authors": [
      "Sergio Consoli",
      "Luca Tiozzo Pezzoli",
      "Elisa Tosetti"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.15698"
  },
  {
    "id": "arXiv:2106.15707",
    "title": "Recent Advances in Fibrosis and Scar Segmentation from Cardiac MRI: A  State-of-the-Art Review and Future Perspectives",
    "abstract": "Segmentation of cardiac fibrosis and scar are essential for clinical\ndiagnosis and can provide invaluable guidance for the treatment of cardiac\ndiseases. Late Gadolinium enhancement (LGE) cardiovascular magnetic resonance\n(CMR) has been successful for its efficacy in guiding the clinical diagnosis\nand treatment reliably. For LGE CMR, many methods have demonstrated success in\naccurately segmenting scarring regions. Co-registration with other\nnon-contrast-agent (non-CA) modalities, balanced steady-state free precession\n(bSSFP) and cine magnetic resonance imaging (MRI) for example, can further\nenhance the efficacy of automated segmentation of cardiac anatomies. Many\nconventional methods have been proposed to provide automated or semi-automated\nsegmentation of scars. With the development of deep learning in recent years,\nwe can also see more advanced methods that are more efficient in providing more\naccurate segmentations. This paper conducts a state-of-the-art review of\nconventional and current state-of-the-art approaches utilising different\nmodalities for accurate cardiac fibrosis and scar segmentation.",
    "descriptor": "\nComments: 3 figure, 8 tables, 46 pages\n",
    "authors": [
      "Yinzhe Wu",
      "Zeyu Tang",
      "Binghuan Li",
      "David Firmin",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15707"
  },
  {
    "id": "arXiv:2106.15717",
    "title": "The rise of populism and the reconfiguration of the German political  space",
    "abstract": "The paper explores the notion of a reconfiguration of political space in the\ncontext of the rise of populism and its effects on the political system. We\nfocus on Germany and the appearance of the new right wing party \"Alternative\nfor Germany\" (AfD). Many scholars of politics discuss the rise of the new\npopulism in Western Europe and the US with respect to a new political cleavage\nrelated to globalization, which is assumed to mainly affect the cultural\ndimension of the political space. As such, it might replace the older economic\ncleavage based on class divisions in defining the dominant dimension of\npolitical conflict. An explanation along these lines suggests a reconfiguration\nof the political space in the sense that (1) the main cleavage within the\npolitical space changes its direction from the economic axis towards the\ncultural axis, but (2) also the semantics of the cultural axis itself is\nchanging towards globalization related topics. Using the electoral manifestos\nfrom the Manifesto project database, we empirically address this\nreconfiguration of the political space by comparing political spaces for\nGermany built using topic modeling with the spaces based on the content\nanalysis of the Manifesto project and the corresponding categories of political\ngoals. We find that both spaces have a similar structure and that the AfD\nappears on a new dimension. In order to characterize this new dimension we\nemploy a novel technique, inter-issue consistency networks (IICN) that allow to\nanalyze the evolution of the correlations between the political positions on\ndifferent issues over several elections. We find that the new dimension\nintroduced by the AfD can be related to the split off of a new \"cultural right\"\nissue bundle from the previously existing center-right bundle.",
    "descriptor": "",
    "authors": [
      "Eckehard Olbrich",
      "Sven Banisch"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15717"
  },
  {
    "id": "arXiv:2106.15740",
    "title": "Importance of Diagonal Gates in Tensor Network Simulations",
    "abstract": "In this work we present two techniques that tremendously increase the\nperformance of tensor-network based quantum circuit simulations. The techniques\nare implemented in the QTensor package and benchmarked using Quantum\nApproximate Optimization Algorithm (QAOA) circuits. The techniques allowed us\nto increase the depth and size of QAOA circuits that can be simulated. In\nparticular, we increased the QAOA depth from 2 to 5 and the size of a QAOA\ncircuit from 180 to 244 qubits. Moreover, we increased the speed of simulations\nby up to 10 million times. Our work provides important insights into how\nvarious techniques can dramatically speed up the simulations of circuits.",
    "descriptor": "",
    "authors": [
      "Danylo Lykov",
      "Yuri Alexeev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15740"
  },
  {
    "id": "arXiv:2106.15753",
    "title": "RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid  Detection in Three-Dimensional Fluorescence Microscopy Images",
    "abstract": "Robust and accurate nuclei centroid detection is important for the\nunderstanding of biological structures in fluorescence microscopy images.\nExisting automated nuclei localization methods face three main challenges: (1)\nMost of object detection methods work only on 2D images and are difficult to\nextend to 3D volumes; (2) Segmentation-based models can be used on 3D volumes\nbut it is computational expensive for large microscopy volumes and they have\ndifficulty distinguishing different instances of objects; (3) Hand annotated\nground truth is limited for 3D microscopy volumes. To address these issues, we\npresent a scalable approach for nuclei centroid detection of 3D microscopy\nvolumes. We describe the RCNN-SliceNet to detect 2D nuclei centroids for each\nslice of the volume from different directions and 3D agglomerative hierarchical\nclustering (AHC) is used to estimate the 3D centroids of nuclei in a volume.\nThe model was trained with the synthetic microscopy data generated using\nSpatially Constrained Cycle-Consistent Adversarial Networks (SpCycleGAN) and\ntested on different types of real 3D microscopy data. Extensive experimental\nresults demonstrate that our proposed method can accurately count and detect\nthe nuclei centroids in a 3D microscopy volume.",
    "descriptor": "\nComments: Accepted by CVPR Workshop 2021\n",
    "authors": [
      "Liming Wu",
      "Shuo Han",
      "Alain Chen",
      "Paul Salama",
      "Kenneth W. Dunn",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15753"
  },
  {
    "id": "arXiv:2106.15765",
    "title": "10-mega pixel snapshot compressive imaging with a hybrid coded aperture",
    "abstract": "High resolution images are widely used in our daily life, whereas high-speed\nvideo capture is challenging due to the low frame rate of cameras working at\nthe high resolution mode. Digging deeper, the main bottleneck lies in the low\nthroughput of existing imaging systems. Towards this end, snapshot compressive\nimaging (SCI) was proposed as a promising solution to improve the throughput of\nimaging systems by compressive sampling and computational reconstruction.\nDuring acquisition, multiple high-speed images are encoded and collapsed to a\nsingle measurement. After this, algorithms are employed to retrieve the video\nframes from the coded snapshot. Recently developed Plug-and-Play (PnP)\nalgorithms make it possible for SCI reconstruction in large-scale problems.\nHowever, the lack of high-resolution encoding systems still precludes SCI's\nwide application. In this paper, we build a novel hybrid coded aperture\nsnapshot compressive imaging (HCA-SCI) system by incorporating a dynamic liquid\ncrystal on silicon and a high-resolution lithography mask. We further implement\na PnP reconstruction algorithm with cascaded denoisers for high quality\nreconstruction. Based on the proposed HCA-SCI system and algorithm, we achieve\na 10-mega pixel SCI system to capture high-speed scenes, leading to a high\nthroughput of 4.6G voxels per second. Both simulation and real data experiments\nverify the feasibility and performance of our proposed HCA-SCI scheme.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Zhihong Zhang",
      "Chao Deng",
      "Yang Liu",
      "Xin Yuan",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15765"
  },
  {
    "id": "arXiv:2106.15813",
    "title": "DF-Conformer: Integrated architecture of Conv-TasNet and Conformer using  linear complexity self-attention for speech enhancement",
    "abstract": "Single-channel speech enhancement (SE) is an important task in speech\nprocessing. A widely used framework combines an analysis/synthesis filterbank\nwith a mask prediction network, such as the Conv-TasNet architecture. In such\nsystems, the denoising performance and computational efficiency are mainly\naffected by the structure of the mask prediction network. In this study, we aim\nto improve the sequential modeling ability of Conv-TasNet architectures by\nintegrating Conformer layers into a new mask prediction network. To make the\nmodel computationally feasible, we extend the Conformer using linear complexity\nattention and stacked 1-D dilated depthwise convolution layers. We trained the\nmodel on 3,396 hours of noisy speech data, and show that (i) the use of linear\ncomplexity attention avoids high computational complexity, and (ii) our model\nachieves higher scale-invariant signal-to-noise ratio than the improved\ntime-dilated convolution network (TDCN++), an extended version of Conv-TasNet.",
    "descriptor": "\nComments: 5 pages, 2 figure. submitted to WASPAA 2021\n",
    "authors": [
      "Yuma Koizumi",
      "Shigeki Karita",
      "Scott Wisdom",
      "Hakan Erdogan",
      "John R. Hershey",
      "Llion Jones",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15813"
  },
  {
    "id": "arXiv:2106.15842",
    "title": "Dual Aspect Self-Attention based on Transformer for Remaining Useful  Life Prediction",
    "abstract": "Remaining useful life prediction (RUL) is one of the key technologies of\ncondition-based maintenance, which is important to maintain the reliability and\nsafety of industrial equipments. While deep learning has achieved great success\nin RUL prediction, existing methods have difficulties in processing long\nsequences and extracting information from the sensor and time step aspects. In\nthis paper, we propose Dual Aspect Self-attention based on Transformer (DAST),\na novel deep RUL prediction method. DAST consists of two encoders, which work\nin parallel to simultaneously extract features of different sensors and time\nsteps. Solely based on self-attention, the DAST encoders are more effective in\nprocessing long data sequences, and are capable of adaptively learning to focus\non more important parts of input. Moreover, the parallel feature extraction\ndesign avoids mutual influence of information from two aspects. Experimental\nresults on two real turbofan engine datasets show that our method significantly\noutperforms state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Zhizheng Zhang",
      "Wen Song",
      "Qiqiang Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15842"
  },
  {
    "id": "arXiv:2106.15888",
    "title": "Spatial resolution of late reverberation in virtual acoustic  environments",
    "abstract": "Late reverberation involves the superposition of many sound reflections\nresulting in a diffuse sound field. Since the spatially resolved perception of\nindividual diffuse reflections is impossible, simplifications can potentially\nbe made for modelling late reverberation in room acoustics simulations with\nreduced spatial resolution. Such simplifications are desired for interactive,\nreal-time virtual acoustic environments with applications in hearing research\nand for the evaluation of hearing supportive devices. In this context, the\nnumber and spatial arrangement of loudspeakers used for playback additionally\naffect spatial resolution. The current study assessed the minimum number of\nspatially evenly distributed virtual late reverberation sources required to\nperceptually approximate spatially highly resolved isotropic and anisotropic\nlate reverberation and to technically approximate a spherically isotropic\ndiffuse sound field. The spatial resolution of the rendering was systematically\nreduced by using subsets of the loudspeakers of an 86-channel spherical\nloudspeaker array in an anechoic chamber. It was tested whether listeners can\ndistinguish lower spatial resolutions for the rendering of late reverberation\nfrom the highest achievable spatial resolution in different simulated rooms.\nRendering of early reflections was kept fixed. The coherence of the sound field\nacross a pair of microphones at ear and behind-the-ear hearing device distance\nwas assessed to separate the effects of number of virtual sources and\nloudspeaker array geometry. Results show that between 12 and 24 reverberation\nsources are required.",
    "descriptor": "\nComments: Submitted to Trends in Hearing\n",
    "authors": [
      "Christoph Kirsch",
      "Josef Poppitz",
      "Torben Wendt",
      "Steven van de Par",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15888"
  },
  {
    "id": "arXiv:2106.15893",
    "title": "Fast whole-slide cartography in colon cancer histology using superpixels  and CNN classification",
    "abstract": "Whole-slide-image cartography is the process of automatically detecting and\noutlining different tissue types in digitized histological specimen. This\nsemantic segmentation provides a basis for many follow-up analyses and can\npotentially guide subsequent medical decisions. Due to their large size,\nwhole-slide-images typically have to be divided into smaller patches which are\nthen analyzed individually using machine learning-based approaches. Thereby,\nlocal dependencies of image regions get lost and since a whole-slide-image\ncomprises many thousands of such patches this process is inherently slow. We\npropose to subdivide the image into coherent regions prior to classification by\ngrouping visually similar adjacent image pixels into larger segments, i.e.\nsuperpixels. Afterwards, only a random subset of patches per superpixel is\nclassified and patch labels are combined into a single superpixel label. The\nalgorithm has been developed and validated on a dataset of 159 hand-annotated\nwhole-slide-images of colon resections and its performance has been compared to\na standard patch-based approach. The algorithm shows an average speed-up of 41%\non the test data and the overall accuracy is increased from 93.8% to 95.7%. We\nadditionally propose a metric for identifying superpixels with an uncertain\nclassification so they can be excluded from further analysis. Finally, we\nevaluate two potential medical applications, namely tumor area estimation\nincluding tumor invasive margin generation and tumor composition analysis.",
    "descriptor": "\nComments: 29 pages, 21 figures, 6 tables, submitted to Elsevier Medical Image Analysis\n",
    "authors": [
      "Frauke Wilm",
      "Michaela Benz",
      "Volker Bruns",
      "Serop Baghdadlian",
      "Jakob Dexl",
      "David Hartmann",
      "Petr Kuritcyn",
      "Martin Weidenfeller",
      "Thomas Wittenberg",
      "Susanne Merkel",
      "Arndt Hartmann",
      "Markus Eckstein",
      "Carol I. Geppert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15893"
  },
  {
    "id": "arXiv:2106.15909",
    "title": "Effect of acoustic scene complexity and visual scene representation on  auditory perception in virtual audio-visual environments",
    "abstract": "In daily life, social interaction and acoustic communication often take place\nin complex acoustic environments (CAE) with a variety of interfering sounds and\nreverberation. For hearing research and evaluation of hearing systems simulated\nCAEs using virtual reality techniques have gained interest in the context of\necologically validity. In the current study, the effect of scene complexity and\nvisual representation of the scene on psychoacoustic measures like sound source\nlocation, distance perception, loudness, speech intelligibility, and listening\neffort in a virtual audio-visual environment was investigated. A 3-dimensional,\n86-channel loudspeaker array was used to render the sound field in combination\nwith or without a head-mounted display (HMD) to create an immersive\nstereoscopic visual representation of the scene. The scene consisted of a ring\nof eight (virtual) loudspeakers which played a target speech stimulus and\nnon-sense speech interferers in several spatial conditions. Either an anechoic\n(snowy outdoor scenery) or echoic environment (loft apartment) with a\nreverberation time (T60) of about 1.5 s was simulated. In addition to varying\nthe number of interferers, scene complexity was varied by assessing the\npsychoacoustic measures in isolated consecutive measurements or simultaneously.\nResults showed no significant effect of wearing the HMD on the data. Loudness\nand distance perception showed significantly different results when they were\nmeasured simultaneously instead of consecutively in isolation. The advantage of\nthe suggested setup is that it can be directly transferred to a corresponding\nreal room, enabling a 1:1 comparison and verification of the perception\nexperiments in the real and virtual environment.",
    "descriptor": "\nComments: Submitted to 3DA 2021 International Conference on Immersive and 3D Audio\n",
    "authors": [
      "Stefan Fichna",
      "Thomas Biberger",
      "Bernhard U. Seeber",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15909"
  },
  {
    "id": "arXiv:2106.15910",
    "title": "Graph Signal Restoration Using Nested Deep Algorithm Unrolling",
    "abstract": "Graph signal processing is a ubiquitous task in many applications such as\nsensor, social, transportation and brain networks, point cloud processing, and\ngraph neural networks. Graph signals are often corrupted through sensing\nprocesses, and need to be restored for the above applications. In this paper,\nwe propose two graph signal restoration methods based on deep algorithm\nunrolling (DAU). First, we present a graph signal denoiser by unrolling\niterations of the alternating direction method of multiplier (ADMM). We then\npropose a general restoration method for linear degradation by unrolling\niterations of Plug-and-Play ADMM (PnP-ADMM). In the second method, the unrolled\nADMM-based denoiser is incorporated as a submodule. Therefore, our restoration\nmethod has a nested DAU structure. Thanks to DAU, parameters in the proposed\ndenoising/restoration methods are trainable in an end-to-end manner. Since the\nproposed restoration methods are based on iterations of a (convex) optimization\nalgorithm, the method is interpretable and keeps the number of parameters small\nbecause we only need to tune graph-independent regularization parameters. We\nsolve two main problems in existing graph signal restoration methods: 1)\nlimited performance of convex optimization algorithms due to fixed parameters\nwhich are often determined manually. 2) large number of parameters of graph\nneural networks that result in difficulty of training. Several experiments for\ngraph signal denoising and interpolation are performed on synthetic and\nreal-world data. The proposed methods show performance improvements to several\nexisting methods in terms of root mean squared error in both tasks.",
    "descriptor": "",
    "authors": [
      "Masatoshi Nagahama",
      "Koki Yamada",
      "Yuichi Tanaka",
      "Stanley H. Chan",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15910"
  },
  {
    "id": "arXiv:2106.15917",
    "title": "Explaining Caste-based Digital Divide in India",
    "abstract": "With the increasing importance of information and communication technologies\nin access to basic services like education and health, the question of the\ndigital divide based on caste assumes importance in India where large\nsocioeconomic disparities persist between different caste groups. Studies on\ncaste-based digital inequality are still scanty in India. Using nationally\nrepresentative survey data, this paper analyzes the first-level digital divide\n(ownership of computer and access to the internet) and the second-level digital\ndivide (individual's skill to use computer and the internet) between the\ndisadvantaged caste group and the others. Further, this paper identifies the\ncaste group-based differences in socioeconomic factors that contribute to the\ndigital divide between these groups using a non-linear decomposition method.\nThe results show that there exists a large first-level and second-level digital\ndivide between the disadvantaged caste groups and others in India. The\nnon-linear decomposition results indicate that the caste-based digital divide\nin India is rooted in historical socioeconomic deprivation of disadvantaged\ncaste groups. More than half of the caste-based digital gap is attributable to\ndifferences in educational attainment and income between the disadvantaged\ncaste groups and others. The findings of this study highlight the urgent need\nfor addressing educational and income inequality between the different caste\ngroups in India in order to bridge the digital divide.",
    "descriptor": "",
    "authors": [
      "R Vaidehi",
      "A Bheemeshwar Reddy",
      "Sudatta Banerjee"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15917"
  },
  {
    "id": "arXiv:2106.15921",
    "title": "Monte Carlo Variational Auto-Encoders",
    "abstract": "Variational auto-encoders (VAE) are popular deep latent variable models which\nare trained by maximizing an Evidence Lower Bound (ELBO). To obtain tighter\nELBO and hence better variational approximations, it has been proposed to use\nimportance sampling to get a lower variance estimate of the evidence. However,\nimportance sampling is known to perform poorly in high dimensions. While it has\nbeen suggested many times in the literature to use more sophisticated\nalgorithms such as Annealed Importance Sampling (AIS) and its Sequential\nImportance Sampling (SIS) extensions, the potential benefits brought by these\nadvanced techniques have never been realized for VAE: the AIS estimate cannot\nbe easily differentiated, while SIS requires the specification of carefully\nchosen backward Markov kernels. In this paper, we address both issues and\ndemonstrate the performance of the resulting Monte Carlo VAEs on a variety of\napplications.",
    "descriptor": "",
    "authors": [
      "Achille Thin",
      "Nikita Kotelevskii",
      "Arnaud Doucet",
      "Alain Durmus",
      "Eric Moulines",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15921"
  },
  {
    "id": "arXiv:2106.15933",
    "title": "Deep Linear Networks Dynamics: Low-Rank Biases Induced by Initialization  Scale and L2 Regularization",
    "abstract": "For deep linear networks (DLN), various hyperparameters alter the dynamics of\ntraining dramatically. We investigate how the rank of the linear map found by\ngradient descent is affected by (1) the initialization norm and (2) the\naddition of $L_{2}$ regularization on the parameters. For (1), we study two\nregimes: (1a) the linear/lazy regime, for large norm initialization; (1b) a\n\\textquotedbl saddle-to-saddle\\textquotedbl{} regime for small initialization\nnorm. In the (1a) setting, the dynamics of a DLN of any depth is similar to\nthat of a standard linear model, without any low-rank bias. In the (1b)\nsetting, we conjecture that throughout training, gradient descent approaches a\nsequence of saddles, each corresponding to linear maps of increasing rank,\nuntil reaching a minimal rank global minimum. We support this conjecture with a\npartial proof and some numerical experiments. For (2), we show that adding a\n$L_{2}$ regularization on the parameters corresponds to the addition to the\ncost of a $L_{p}$-Schatten (quasi)norm on the linear map with $p=\\frac{2}{L}$\n(for a depth-$L$ network), leading to a stronger low-rank bias as $L$ grows.\nThe effect of $L_{2}$ regularization on the loss surface depends on the depth:\nfor shallow networks, all critical points are either strict saddles or global\nminima, whereas for deep networks, some local minima appear. We numerically\nobserve that these local minima can generalize better than global ones in some\nsettings.",
    "descriptor": "",
    "authors": [
      "Arthur Jacot",
      "Fran\u00e7ois Ged",
      "Franck Gabriel",
      "Berfin \u015eim\u015fek",
      "Cl\u00e9ment Hongler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15933"
  },
  {
    "id": "arXiv:2106.15944",
    "title": "Learnable Reconstruction Methods from RGB Images to Hyperspectral  Imaging: A Survey",
    "abstract": "Hyperspectral imaging enables versatile applications due to its competence in\ncapturing abundant spatial and spectral information, which are crucial for\nidentifying substances. However, the devices for acquiring hyperspectral images\nare expensive and complicated. Therefore, many alternative spectral imaging\nmethods have been proposed by directly reconstructing the hyperspectral\ninformation from lower-cost, more available RGB images. We present a thorough\ninvestigation of these state-of-the-art spectral reconstruction methods from\nthe widespread RGB images. A systematic study and comparison of more than 25\nmethods has revealed that most of the data-driven deep learning methods are\nsuperior to prior-based methods in terms of reconstruction accuracy and quality\ndespite lower speeds. This comprehensive review can serve as a fruitful\nreference source for peer researchers, thus further inspiring future\ndevelopment directions in related domains.",
    "descriptor": "",
    "authors": [
      "Jingang Zhang",
      "Runmu Su",
      "Wenqi Ren",
      "Qiang Fu",
      "Yunfeng Nie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15944"
  },
  {
    "id": "arXiv:2106.15950",
    "title": "An Integrated Framework for Two-pass Personalized Voice Trigger",
    "abstract": "In this paper, we present the XMUSPEECH system for Task 1 of 2020\nPersonalized Voice Trigger Challenge (PVTC2020). Task 1 is a joint wake-up word\ndetection with speaker verification on close talking data. The whole system\nconsists of a keyword spotting (KWS) sub-system and a speaker verification (SV)\nsub-system. For the KWS system, we applied a Temporal Depthwise Separable\nConvolution Residual Network (TDSC-ResNet) to improve the system's performance.\nFor the SV system, we proposed a multi-task learning network, where phonetic\nbranch is trained with the character label of the utterance, and speaker branch\nis trained with the label of the speaker. Phonetic branch is optimized with\nconnectionist temporal classification (CTC) loss, which is treated as an\nauxiliary module for speaker branch. Experiments show that our system gets\nsignificant improvements compared with baseline system.",
    "descriptor": "",
    "authors": [
      "Dexin Liao",
      "Jing Li",
      "Yiming Zhi",
      "Song Li",
      "Qingyang Hong",
      "Lin Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15950"
  },
  {
    "id": "arXiv:2106.15953",
    "title": "BLNet: A Fast Deep Learning Framework for Low-Light Image Enhancement  with Noise Removal and Color Restoration",
    "abstract": "Images obtained in real-world low-light conditions are not only low in\nbrightness, but they also suffer from many other types of degradation, such as\ncolor bias, unknown noise, detail loss and halo artifacts. In this paper, we\npropose a very fast deep learning framework called Bringing the Lightness\n(denoted as BLNet) that consists of two U-Nets with a series of well-designed\nloss functions to tackle all of the above degradations. Based on Retinex\nTheory, the decomposition net in our model can decompose low-light images into\nreflectance and illumination and remove noise in the reflectance during the\ndecomposition phase. We propose a Noise and Color Bias Control module (NCBC\nModule) that contains a convolutional neural network and two loss functions\n(noise loss and color loss). This module is only used to calculate the loss\nfunctions during the training phase, so our method is very fast during the test\nphase. This module can smooth the reflectance to achieve the purpose of noise\nremoval while preserving details and edge information and controlling color\nbias. We propose a network that can be trained to learn the mapping between\nlow-light and normal-light illumination and enhance the brightness of images\ntaken in low-light illumination. We train and evaluate the performance of our\nproposed model over the real-world Low-Light (LOL) dataset), and we also test\nour model over several other frequently used datasets (LIME, DICM and MEF\ndatasets). We conduct extensive experiments to demonstrate that our approach\nachieves a promising effect with good rubustness and generalization and\noutperforms many other state-of-the-art methods qualitatively and\nquantitatively. Our method achieves high speed because we use loss functions\ninstead of introducing additional denoisers for noise removal and color\ncorrection. The code and model are available at\nhttps://github.com/weixinxu666/BLNet.",
    "descriptor": "\nComments: 13 pages, 12 figures, journal\n",
    "authors": [
      "Xinxu Wei",
      "Xianshi Zhang",
      "Shisen Wang",
      "Cheng Cheng",
      "Yanlin Huang",
      "Kaifu Yang",
      "Yongjie Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15953"
  },
  {
    "id": "arXiv:2106.15979",
    "title": "Hypothetical Expected Utility",
    "abstract": "This paper provides a model to analyze and identify a decision maker's (DM's)\nhypothetical reasoning. Using this model, I show that a DM's propensity to\nengage in hypothetical thinking is captured exactly by her ability to recognize\nimplications (i.e., to identify that one hypothesis implies another) and that\nthis later relation is captured by a DM's observable behavior. Thus, this\ncharacterization both provides a concrete definition of (flawed) hypothetical\nreasoning and, importantly, yields a methodology to identify these judgments\nfrom standard economic data.",
    "descriptor": "",
    "authors": [
      "Evan Piermont"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15979"
  },
  {
    "id": "arXiv:2106.15980",
    "title": "Variational Refinement for Importance Sampling Using the Forward  Kullback-Leibler Divergence",
    "abstract": "Variational Inference (VI) is a popular alternative to asymptotically exact\nsampling in Bayesian inference. Its main workhorse is optimization over a\nreverse Kullback-Leibler divergence (RKL), which typically underestimates the\ntail of the posterior leading to miscalibration and potential degeneracy.\nImportance sampling (IS), on the other hand, is often used to fine-tune and\nde-bias the estimates of approximate Bayesian inference procedures. The quality\nof IS crucially depends on the choice of the proposal distribution. Ideally,\nthe proposal distribution has heavier tails than the target, which is rarely\nachievable by minimizing the RKL. We thus propose a novel combination of\noptimization and sampling techniques for approximate Bayesian inference by\nconstructing an IS proposal distribution through the minimization of a forward\nKL (FKL) divergence. This approach guarantees asymptotic consistency and a fast\nconvergence towards both the optimal IS estimator and the optimal variational\napproximation. We empirically demonstrate on real data that our method is\ncompetitive with variational boosting and MCMC.",
    "descriptor": "\nComments: Accepted for the 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)\n",
    "authors": [
      "Ghassen Jerfel",
      "Serena Wang",
      "Clara Fannjiang",
      "Katherine A. Heller",
      "Yian Ma",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.15980"
  },
  {
    "id": "arXiv:2106.15988",
    "title": "Group Testing under Superspreading Dynamics",
    "abstract": "Testing is recommended for all close contacts of confirmed COVID-19 patients.\nHowever, existing group testing methods are oblivious to the circumstances of\ncontagion provided by contact tracing. Here, we build upon a well-known\nsemi-adaptive pool testing method, Dorfman's method with imperfect tests, and\nderive a simple group testing method based on dynamic programming that is\nspecifically designed to use the information provided by contact tracing.\nExperiments using a variety of reproduction numbers and dispersion levels,\nincluding those estimated in the context of the COVID-19 pandemic, show that\nthe pools found using our method result in a significantly lower number of\ntests than those found using standard Dorfman's method, especially when the\nnumber of contacts of an infected individual is small. Moreover, our results\nshow that our method can be more beneficial when the secondary infections are\nhighly overdispersed.",
    "descriptor": "",
    "authors": [
      "Stratis Tsirtsis",
      "Abir De",
      "Lars Lorch",
      "Manuel Gomez-Rodriguez"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2106.15988"
  },
  {
    "id": "arXiv:2106.16024",
    "title": "Fast processing explains the effect of sound reflection on binaural  unmasking",
    "abstract": "Sound reflections and late reverberation alter energetic and binaural cues of\na target source, thereby affecting it's detection in noise. Two experiments\ninvestigated detection of harmonic complex tones, centered around 500 Hz, in\nnoise in a virtual room with different modifications of simulated room impulse\nresponses (RIR). Stimuli were auralized using the SOFE's loudspeakers in\nanechoic space. The target was presented from the front or at 0$^\\circ$\nazimuth, while an anechoic noise masker was simultaneously presented at\n0$^\\circ$. In the first experiment, early reflections were progressively added\nto the RIR and detection thresholds of the reverberant target were measured.\nFor a frontal sound source, detection thresholds decreased while adding the\nfirst 45 ms of early reflections, whereas for a lateral sound source thresholds\nremained constant. In the second experiment, early reflections were cut out\nwhile late reflections were kept along with the direct sound. Results for a\ntarget at 0$^\\circ$ show that even reflections as late as 150 ms reduce\ndetection thresholds compared to only the direct sound. A binaural model with a\nsluggishness component following the computation of binaural unmasking in short\nwindows predicts measured and literature results better than when large windows\nare used.",
    "descriptor": "\nComments: Preprint from June 2nd , 2021\n",
    "authors": [
      "Norbert Kolotzek",
      "Pierre G. Aublin",
      "Bernhard U. Seeber"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.16024"
  },
  {
    "id": "arXiv:2106.16031",
    "title": "ResViT: Residual vision transformers for multi-modal medical image  synthesis",
    "abstract": "Multi-modal imaging is a key healthcare technology in the diagnosis and\nmanagement of disease, but it is often underutilized due to costs associated\nwith multiple separate scans. This limitation yields the need for synthesis of\nunacquired modalities from the subset of available modalities. In recent years,\ngenerative adversarial network (GAN) models with superior depiction of\nstructural details have been established as state-of-the-art in numerous\nmedical image synthesis tasks. However, GANs are characteristically based on\nconvolutional neural network (CNN) backbones that perform local processing with\ncompact filters. This inductive bias, in turn, compromises learning of\nlong-range spatial dependencies. While attention maps incorporated in GANs can\nmultiplicatively modulate CNN features to emphasize critical image regions,\ntheir capture of global context is mostly implicit. Here, we propose a novel\ngenerative adversarial approach for medical image synthesis, ResViT, to combine\nlocal precision of convolution operators with contextual sensitivity of vision\ntransformers. Based on an encoder-decoder architecture, ResViT employs a\ncentral bottleneck comprising novel aggregated residual transformer (ART)\nblocks that synergistically combine convolutional and transformer modules.\nComprehensive demonstrations are performed for synthesizing missing sequences\nin multi-contrast MRI and CT images from MRI. Our results indicate the\nsuperiority of ResViT against competing methods in terms of qualitative\nobservations and quantitative metrics.",
    "descriptor": "",
    "authors": [
      "Onat Dalmaz",
      "Mahmut Yurt",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16031"
  },
  {
    "id": "arXiv:2106.16044",
    "title": "Energy and Randic index of directed graphs",
    "abstract": "The concept of Randic index has been extended recently for a digraph. We\nprove that $2R(G)\\leq \\mathcal{E}(G)\\leq 2\\sqrt{\\Delta(G)} R(G)$, where $G$ is\na digraph, and $R(G)$ denotes the Randic index, $\\mathcal{E}(G)$ denotes the\nNikiforov energy and $\\Delta(G) $ denotes the maximum degree of $G$. In both\ninequalities we describe the graphs for which the equality holds.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Gerardo Arizmendi",
      "Octavio Arizmendi"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16044"
  },
  {
    "id": "arXiv:2106.16048",
    "title": "Resilient UAV Swarm Communications with Graph Convolutional Neural  Network",
    "abstract": "In this paper, we study the self-healing problem of unmanned aerial vehicle\n(UAV) swarm network (USNET) that is required to quickly rebuild the\ncommunication connectivity under unpredictable external disruptions (UEDs).\nFirstly, to cope with the one-off UEDs, we propose a graph convolutional neural\nnetwork (GCN) and find the recovery topology of the USNET in an on-line manner.\nSecondly, to cope with general UEDs, we develop a GCN based trajectory planning\nalgorithm that can make UAVs rebuild the communication connectivity during the\nself-healing process. We also design a meta learning scheme to facilitate the\non-line executions of the GCN. Numerical results show that the proposed\nalgorithms can rebuild the communication connectivity of the USNET more quickly\nthan the existing algorithms under both one-off UEDs and general UEDs. The\nsimulation results also show that the meta learning scheme can not only enhance\nthe performance of the GCN but also reduce the time complexity of the on-line\nexecutions.",
    "descriptor": "",
    "authors": [
      "Zhiyu Mou",
      "Feifei Gao",
      "Jun Liu",
      "Qihui Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16048"
  },
  {
    "id": "arXiv:2106.16061",
    "title": "Reasoning about conscious experience with axiomatic and graphical  mathematics",
    "abstract": "We cast aspects of consciousness in axiomatic mathematical terms, using the\ngraphical calculus of general process theories (a.k.a symmetric monoidal\ncategories and Frobenius algebras therein). This calculus exploits the\nontological neutrality of process theories. A toy example using the axiomatic\ncalculus is given to show the power of this approach, recovering other aspects\nof conscious experience, such as external and internal subjective distinction,\nprivacy or unreadability of personal subjective experience, and phenomenal\nunity, one of the main issues for scientific studies of consciousness. In fact,\nthese features naturally arise from the compositional nature of axiomatic\ncalculus.",
    "descriptor": "\nComments: 20 pages, accepted to Consciousness and Cognition\n",
    "authors": [
      "Camilo Miguel Signorelli",
      "Quanlong Wang",
      "Bob Coecke"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.16061"
  },
  {
    "id": "arXiv:2106.16079",
    "title": "HybridDeepRx: Deep Learning Receiver for High-EVM Signals",
    "abstract": "In this paper, we propose a machine learning (ML) based physical layer\nreceiver solution for demodulating OFDM signals that are subject to a high\nlevel of nonlinear distortion. Specifically, a novel deep learning based\nconvolutional neural network receiver is devised, containing layers in both\ntime- and frequency domains, allowing to demodulate and decode the transmitted\nbits reliably despite the high error vector magnitude (EVM) in the transmit\nsignal. Extensive set of numerical results is provided, in the context of 5G NR\nuplink incorporating also measured terminal power amplifier characteristics.\nThe obtained results show that the proposed receiver system is able to clearly\noutperform classical linear receivers as well as existing ML receiver\napproaches, especially when the EVM is high in comparison with modulation\norder. The proposed ML receiver can thus facilitate pushing the terminal power\namplifier (PA) systems deeper into saturation, and thereon improve the terminal\npower-efficiency, radiated power and network coverage.",
    "descriptor": "\nComments: To be presented in the 2021 IEEE International Symposium on Personal, Indoor and Mobile Radio Communications\n",
    "authors": [
      "Jaakko Pihlajasalo",
      "Dani Korpi",
      "Mikko Honkala",
      "Janne M.J. Huttunen",
      "Taneli Riihonen",
      "Jukka Talvitie",
      "Alberto Brihuega",
      "Mikko A. Uusitalo",
      "Mikko Valkama"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16079"
  },
  {
    "id": "arXiv:2106.16087",
    "title": "Reservoir Based Edge Training on RF Data To Deliver Intelligent and  Efficient IoT Spectrum Sensors",
    "abstract": "Current radio frequency (RF) sensors at the Edge lack the computational\nresources to support practical, in-situ training for intelligent spectrum\nmonitoring, and sensor data classification in general. We propose a solution\nvia Deep Delay Loop Reservoir Computing (DLR), a processing architecture that\nsupports general machine learning algorithms on compact mobile devices by\nleveraging delay-loop reservoir computing in combination with innovative\nelectrooptical hardware. With both digital and photonic realizations of our\ndesign of the loops, DLR delivers reductions in form factor, hardware\ncomplexity and latency, compared to the State-of-the-Art (SoA). The main impact\nof the reservoir is to project the input data into a higher dimensional space\nof reservoir state vectors in order to linearly separate the input classes.\nOnce the classes are well separated, traditionally complex, power-hungry\nclassification models are no longer needed for the learning process. Yet, even\nwith simple classifiers based on Ridge regression (RR), the complexity grows at\nleast quadratically with the input size. Hence, the hardware reduction required\nfor training on compact devices is in contradiction with the large dimension of\nstate vectors. DLR employs a RR-based classifier to exceed the SoA accuracy,\nwhile further reducing power consumption by leveraging the architecture of\nparallel (split) loops. We present DLR architectures composed of multiple\nsmaller loops whose state vectors are linearly combined to create a lower\ndimensional input into Ridge regression. We demonstrate the advantages of using\nDLR for two distinct applications: RF Specific Emitter Identification (SEI) for\nIoT authentication, and wireless protocol recognition for IoT situational\nawareness.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.00751\n",
    "authors": [
      "Silvija Kokalj-Filipovic",
      "Paul Toliver",
      "William Johnson",
      "Rob Miller"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16087"
  },
  {
    "id": "arXiv:2106.16088",
    "title": "Application of deep reinforcement learning for Indian stock trading  automation",
    "abstract": "In stock trading, feature extraction and trading strategy design are the two\nimportant tasks to achieve long-term benefits using machine learning\ntechniques. Several methods have been proposed to design trading strategy by\nacquiring trading signals to maximize the rewards. In the present paper the\ntheory of deep reinforcement learning is applied for stock trading strategy and\ninvestment decisions to Indian markets. The experiments are performed\nsystematically with three classical Deep Reinforcement Learning models Deep\nQ-Network, Double Deep Q-Network and Dueling Double Deep Q-Network on ten\nIndian stock datasets. The performance of the models are evaluated and\ncomparison is made.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Supriya Bajpai"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16088"
  },
  {
    "id": "arXiv:2106.16101",
    "title": "AdaGDA: Faster Adaptive Gradient Descent Ascent Methods for Minimax  Optimization",
    "abstract": "In the paper, we propose a class of faster adaptive gradient descent ascent\nmethods for solving the nonconvex-strongly-concave minimax problems by using\nunified adaptive matrices used in the SUPER-ADAM \\citep{huang2021super}.\nSpecifically, we propose a fast adaptive gradient decent ascent (AdaGDA) method\nbased on the basic momentum technique, which reaches a low sample complexity of\n$O(\\kappa^4\\epsilon^{-4})$ for finding an $\\epsilon$-stationary point without\nlarge batches, which improves the existing result of adaptive minimax\noptimization method by a factor of $O(\\sqrt{\\kappa})$. Moreover, we present an\naccelerated version of AdaGDA (VR-AdaGDA) method based on the momentum-based\nvariance reduced technique, which achieves the best known sample complexity of\n$O(\\kappa^3\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point without\nlarge batches. Further assume the bounded Lipschitz parameter of objective\nfunction, we prove that our VR-AdaGDA method reaches a lower sample complexity\nof $O(\\kappa^{2.5}\\epsilon^{-3})$ with the mini-batch size $O(\\kappa)$. In\nparticular, we provide an effective convergence analysis framework for our\nadaptive methods based on unified adaptive matrices, which include almost\nexisting adaptive learning rates.",
    "descriptor": "\nComments: 27 pages. arXiv admin note: text overlap with arXiv:2106.11396\n",
    "authors": [
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16101"
  },
  {
    "id": "arXiv:2106.16130",
    "title": "Bounds on the Diameter of Graph Associahedra",
    "abstract": "Graph associahedra are generalized permutohedra arising as special cases of\nnestohedra and hypergraphic polytopes. The graph associahedron of a graph $G$\nencodes the combinatorics of search trees on $G$, defined recursively by a root\n$r$ together with search trees on each of the connected components of $G-r$. In\nparticular, the skeleton of the graph associahedron is the rotation graph of\nthose search trees. We investigate the diameter of graph associahedra as a\nfunction of some graph parameters. It is known that the diameter of the\nassociahedra of paths of length $n$, the classical associahedra, is $2n-6$ for\na large enough $n$. We give a tight bound of $\\Theta(m)$ on the diameter of\ntrivially perfect graph associahedra on $m$ edges. We consider the maximum\ndiameter of associahedra of graphs on $n$ vertices and of given tree-depth,\ntreewidth, or pathwidth, and give lower and upper bounds as a function of these\nparameters. Finally, we prove that the maximum diameter of associahedra of\ngraphs of pathwidth two is $\\Theta (n\\log n)$.",
    "descriptor": "\nComments: 9 pages, 4 figures. To be published in the proceedings of the XI Latin and American Algorithms, Graphs and Optimization Symposium (LAGOS 2021)\n",
    "authors": [
      "Jean Cardinal",
      "Lionel Pournin",
      "Mario Valencia-Pabon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.16130"
  },
  {
    "id": "arXiv:2106.16174",
    "title": "Hierarchical Phenotyping and Graph Modeling of Spatial Architecture in  Lymphoid Neoplasms",
    "abstract": "The cells and their spatial patterns in the tumor microenvironment (TME) play\na key role in tumor evolution, and yet remains an understudied topic in\ncomputational pathology. This study, to the best of our knowledge, is among the\nfirst to hybrid local and global graph methods to profile orchestration and\ninteraction of cellular components. To address the challenge in hematolymphoid\ncancers where the cell classes in TME are unclear, we first implemented cell\nlevel unsupervised learning and identified two new cell subtypes. Local cell\ngraphs or supercells were built for each image by considering the individual\ncell's geospatial location and classes. Then, we applied supercell level\nclustering and identified two new cell communities. In the end, we built global\ngraphs to abstract spatial interaction patterns and extract features for\ndisease diagnosis. We evaluate the proposed algorithm on H\\&E slides of 60\nhematolymphoid neoplasm patients and further compared it with three cell level\ngraph-based algorithms, including the global cell graph, cluster cell graph,\nand FLocK. The proposed algorithm achieves a mean diagnosis accuracy of 0.703\nwith the repeated 5-fold cross-validation scheme. In conclusion, our algorithm\nshows superior performance over the existing methods and can be potentially\napplied to other cancer types.",
    "descriptor": "\nComments: Accepted by MICCAI2021\n",
    "authors": [
      "Pingjun Chen",
      "Muhammad Aminu",
      "Siba El Hussein",
      "Joseph Khoury",
      "Jia Wu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.16174"
  },
  {
    "id": "arXiv:2106.16194",
    "title": "Limited-Fronthaul Cell-Free Hybrid Beamforming with Distributed Deep  Neural Network",
    "abstract": "Cell-free massive MIMO (CF-mMIMO) systems represent a promising approach to\nincrease the spectral efficiency of wireless communication systems. However,\nnear-optimal solutions require a large amount of signaling exchange between\naccess points (APs) and the network controller (NC). In addition, the use of\nhybrid beamforming in each AP reduces the number of power hungry RF chains, but\nimposes a large computational complexity to find near-optimal precoders. In\nthis letter, we propose two unsupervised deep neural networks (DNN)\narchitectures, fully and partially distributed, that can perform coordinated\nhybrid beamforming with zero or limited communication overhead between APs and\nNC, while achieving near-optimal sum-rate with a reduced computational\ncomplexity compared to conventional near-optimal solutions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice\n",
    "authors": [
      "Hamed Hojatian",
      "Jeremy Nadal",
      "Jean-Francois Frigon",
      "Francois Leduc-Primeau"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16194"
  },
  {
    "id": "arXiv:2106.16239",
    "title": "Fixed points of monotonic and (weakly) scalable neural networks",
    "abstract": "We derive conditions for the existence of fixed points of neural networks, an\nimportant research objective to understand their behavior in modern\napplications involving autoencoders and loop unrolling techniques, among\nothers. In particular, we focus on networks with nonnegative inputs and\nnonnegative network parameters, as often considered in the literature. We show\nthat such networks can be recognized as monotonic and (weakly) scalable\nfunctions within the framework of nonlinear Perron-Frobenius theory. This fact\nenables us to derive conditions for the existence of a nonempty fixed point set\nof the neural networks, and these conditions are weaker than those obtained\nrecently using arguments in convex analysis, which are typically based on the\nassumption of nonexpansivity of the activation functions. Furthermore, we prove\nthat the shape of the fixed point set of monotonic and weakly scalable neural\nnetworks is often an interval, which degenerates to a point for the case of\nscalable networks. The chief results of this paper are verified in numerical\nsimulations, where we consider an autoencoder-type network that first\ncompresses angular power spectra in massive MIMO systems, and, second,\nreconstruct the input spectra from the compressed signal.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Tomasz Piotrowski",
      "Renato L. G. Cavalcante"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16239"
  },
  {
    "id": "arXiv:2106.16241",
    "title": "Hemodynamics of the heart's left atrium based on a Variational  Multiscale-LES numerical model",
    "abstract": "In this paper, we investigate the hemodynamics of a left atrium (LA) by\nproposing a computational model suitable to provide physically meaningful fluid\ndynamics indications and detailed blood flow characterization. In particular,\nwe consider the incompressible Navier-Stokes equations in Arbitrary Lagrangian\nEulerian (ALE) formulation to deal with the LA domain under prescribed motion.\nA Variational Multiscale (VMS) method is adopted to obtain a stable formulation\nof the Navier-Stokes equations discretized by means of the Finite Element\nmethod and to account for turbulence modeling based on Large Eddy Simulation\n(LES). The aim of this paper is twofold: on one hand to improve the general\nunderstanding of blood flow in the human LA in normal conditions; on the other,\nto analyse the effects of the turbulence VMS-LES method on a situation of blood\nflow which is neither laminar, nor fully turbulent, but rather transitional as\nin LA. Our results suggest that if relatively coarse meshes are adopted, the\nadditional stabilization terms introduced by the VMS-LES method allow to better\npredict transitional effects and cycle-to-cycle blood flow variations than the\nstandard SUPG stabilization method.",
    "descriptor": "",
    "authors": [
      "Alberto Zingaro",
      "Luca Dede'",
      "Filippo Menghini",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16241"
  },
  {
    "id": "arXiv:1301.6697",
    "title": "Parameter Priors for Directed Acyclic Graphical Models and the  Characterization of Several Probability Distributions",
    "abstract": "Comments: This version has improved pointers to the literature. arXiv admin note: substantial text overlap with arXiv:2105.03248",
    "descriptor": "\nComments: This version has improved pointers to the literature. arXiv admin note: substantial text overlap with arXiv:2105.03248\n",
    "authors": [
      "Dan Geiger",
      "David Heckerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1301.6697"
  },
  {
    "id": "arXiv:1302.4957",
    "title": "Learning Bayesian Networks: A Unification for Discrete and Gaussian  Domains",
    "abstract": "Comments: This version has improved pointers to the literature",
    "descriptor": "\nComments: This version has improved pointers to the literature\n",
    "authors": [
      "David Heckerman",
      "Dan Geiger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1302.4957"
  },
  {
    "id": "arXiv:1701.08083",
    "title": "Ensemble Estimation of Generalized Mutual Information with Applications  to Genomics",
    "abstract": "Comments: Accepted to IEEE Transactions on Information Theory; 42 pages, 3 figures; a shorter version of this paper was published at IEEE ISIT 2017 under the title \"Ensemble estimation of mutual information\"",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Information Theory; 42 pages, 3 figures; a shorter version of this paper was published at IEEE ISIT 2017 under the title \"Ensemble estimation of mutual information\"\n",
    "authors": [
      "Kevin R. Moon",
      "Kumar Sricharan",
      "Alfred O. Hero III"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1701.08083"
  },
  {
    "id": "arXiv:1801.10502",
    "title": "Learning from Informants: Relations between Learning Success Criteria",
    "abstract": "Learning from Informants: Relations between Learning Success Criteria",
    "descriptor": "",
    "authors": [
      "Martin Aschenbach",
      "Timo K\u00f6tzing",
      "Karen Seidel"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1801.10502"
  },
  {
    "id": "arXiv:1802.02718",
    "title": "General Strong Polarization",
    "abstract": "Comments: 72 pages, 2 figures",
    "descriptor": "\nComments: 72 pages, 2 figures\n",
    "authors": [
      "Jaros\u0142aw B\u0142asiok",
      "Venkatesan Guruswami",
      "Preetum Nakkiran",
      "Atri Rudra",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1802.02718"
  },
  {
    "id": "arXiv:1808.03292",
    "title": "NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo  Workspaces",
    "abstract": "NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo  Workspaces",
    "descriptor": "",
    "authors": [
      "Chathika Gunaratne",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1808.03292"
  },
  {
    "id": "arXiv:1902.02588",
    "title": "Self-Adjusting Mutation Rates with Provably Optimal Success Rules",
    "abstract": "Comments: Conference version appeared at GECCO 2019. This full version is to appear in Algorithmica",
    "descriptor": "\nComments: Conference version appeared at GECCO 2019. This full version is to appear in Algorithmica\n",
    "authors": [
      "Benjamin Doerr",
      "Carola Doerr",
      "Johannes Lengler"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1902.02588"
  },
  {
    "id": "arXiv:1905.12278",
    "title": "An Inertial Newton Algorithm for Deep Learning",
    "abstract": "Comments: To appear in Journal of Machine Learning Research (JMLR), Volume 22, acceptance date: 5/21",
    "descriptor": "\nComments: To appear in Journal of Machine Learning Research (JMLR), Volume 22, acceptance date: 5/21\n",
    "authors": [
      "Camille Castera",
      "J\u00e9r\u00f4me Bolte",
      "C\u00e9dric F\u00e9votte",
      "Edouard Pauwels"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.12278"
  },
  {
    "id": "arXiv:1907.01471",
    "title": "On Injectivity of Quantum Finite Automata",
    "abstract": "Comments: Accepted journal version (with change of name from Acceptance Ambiguity for Quantum Automata)",
    "descriptor": "\nComments: Accepted journal version (with change of name from Acceptance Ambiguity for Quantum Automata)\n",
    "authors": [
      "Paul C. Bell",
      "Mika Hirvensalo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1907.01471"
  },
  {
    "id": "arXiv:1910.06961",
    "title": "Tiny Video Networks",
    "abstract": "Tiny Video Networks",
    "descriptor": "",
    "authors": [
      "AJ Piergiovanni",
      "Anelia Angelova",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1910.06961"
  },
  {
    "id": "arXiv:1911.07192",
    "title": "Transductive Zero-Shot Hashing for Multilabel Image Retrieval",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Qin Zou",
      "Zheng Zhang",
      "Ling Cao",
      "Long Chen",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.07192"
  },
  {
    "id": "arXiv:1912.09985",
    "title": "Fundamental Limits of Device-to-Device Private Caching with a Trusted  Server under Uncoded Cache Placement and User Collusion",
    "abstract": "Comments: 64 pages, 6 figures, under review of TIT, parts of results were presented in ICC 2020 and ISIT 2020",
    "descriptor": "\nComments: 64 pages, 6 figures, under review of TIT, parts of results were presented in ICC 2020 and ISIT 2020\n",
    "authors": [
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Daniela Tuninetti",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1912.09985"
  },
  {
    "id": "arXiv:2001.00782",
    "title": "Upper bounds for stabbing simplices by a line",
    "abstract": "Comments: 18 pages, 3 figures",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Inbar Daum-Sadon",
      "Gabriel Nivasch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2001.00782"
  },
  {
    "id": "arXiv:2001.10133",
    "title": "COKE: Communication-Censored Decentralized Kernel Learning",
    "abstract": "COKE: Communication-Censored Decentralized Kernel Learning",
    "descriptor": "",
    "authors": [
      "Ping Xu",
      "Yue Wang",
      "Xiang Chen",
      "Zhi Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.10133"
  },
  {
    "id": "arXiv:2002.12785",
    "title": "On the Hardness of the Lee Syndrome Decoding Problem",
    "abstract": "Comments: Part of this work appeared as preliminary results in arXiv:2001.08425",
    "descriptor": "\nComments: Part of this work appeared as preliminary results in arXiv:2001.08425\n",
    "authors": [
      "Violetta Weger",
      "Karan Khathuria",
      "Anna-Lena Horlemann",
      "Massimo Battaglioni",
      "Paolo Santini",
      "Edoardo Persichetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.12785"
  },
  {
    "id": "arXiv:2004.05802",
    "title": "To Be Announced",
    "abstract": "To Be Announced",
    "descriptor": "",
    "authors": [
      "Hans van Ditmarsch"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2004.05802"
  },
  {
    "id": "arXiv:2004.13274",
    "title": "Exploring the contextual factors affecting multimodal emotion  recognition in videos",
    "abstract": "Comments: Accepted version at IEEE Transactions on Affective Computing",
    "descriptor": "\nComments: Accepted version at IEEE Transactions on Affective Computing\n",
    "authors": [
      "Prasanta Bhattacharya",
      "Raj Kumar Gupta",
      "Yinping Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2004.13274"
  },
  {
    "id": "arXiv:2006.01935",
    "title": "Analysis of the Schwarz domain decomposition method for the  conductor-like screening continuum model",
    "abstract": "Comments: published in SIAM Journal on Numerical Analysis",
    "descriptor": "\nComments: published in SIAM Journal on Numerical Analysis\n",
    "authors": [
      "Arnold Reusken",
      "Benjamin Stamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.01935"
  },
  {
    "id": "arXiv:2006.07441",
    "title": "On the optimal constants in the two-sided Stechkin inequalities",
    "abstract": "Comments: v2: adds the continuous inequalities and acknowledgments, v3: corrects typos in authors' addresses and enhances acknowledgments, v4: introduces major rework in Section 2, minor rework in all other parts, v4: corrects typos",
    "descriptor": "\nComments: v2: adds the continuous inequalities and acknowledgments, v3: corrects typos in authors' addresses and enhances acknowledgments, v4: introduces major rework in Section 2, minor rework in all other parts, v4: corrects typos\n",
    "authors": [
      "Thomas Jahn",
      "Tino Ullrich"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.07441"
  },
  {
    "id": "arXiv:2006.09199",
    "title": "AVLnet: Learning Audio-Visual Language Representations from  Instructional Videos",
    "abstract": "Comments: A version of this work has been accepted to Interspeech 2021",
    "descriptor": "\nComments: A version of this work has been accepted to Interspeech 2021\n",
    "authors": [
      "Andrew Rouditchenko",
      "Angie Boggust",
      "David Harwath",
      "Brian Chen",
      "Dhiraj Joshi",
      "Samuel Thomas",
      "Kartik Audhkhasi",
      "Hilde Kuehne",
      "Rameswar Panda",
      "Rogerio Feris",
      "Brian Kingsbury",
      "Michael Picheny",
      "Antonio Torralba",
      "James Glass"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2006.09199"
  },
  {
    "id": "arXiv:2006.15207",
    "title": "ATOM: Robustifying Out-of-distribution Detection Using Outlier Mining",
    "abstract": "Comments: Paper published at European Conference on Machine Learning (ECML'21)",
    "descriptor": "\nComments: Paper published at European Conference on Machine Learning (ECML'21)\n",
    "authors": [
      "Jiefeng Chen",
      "Yixuan Li",
      "Xi Wu",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15207"
  },
  {
    "id": "arXiv:2006.15334",
    "title": "Evolving Metric Learning for Incremental and Decremental Features",
    "abstract": "Comments: Accepted to IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2021)",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2021)\n",
    "authors": [
      "Jiahua Dong",
      "Yang Cong",
      "Gan Sun",
      "Tao Zhang",
      "Xu Tang",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15334"
  },
  {
    "id": "arXiv:2007.00721",
    "title": "Some i-Mark games",
    "abstract": "Comments: Minor revisions. 12 pages, 2 figures",
    "descriptor": "\nComments: Minor revisions. 12 pages, 2 figures\n",
    "authors": [
      "Oren Friman",
      "Gabriel Nivasch"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.00721"
  },
  {
    "id": "arXiv:2007.03834",
    "title": "Language Modeling with Reduced Densities",
    "abstract": "Comments: 19 pages; v2: added reference; v3: revised abstract and introduction for clarity",
    "descriptor": "\nComments: 19 pages; v2: added reference; v3: revised abstract and introduction for clarity\n",
    "authors": [
      "Tai-Danae Bradley",
      "Yiannis Vlassopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Category Theory (math.CT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.03834"
  },
  {
    "id": "arXiv:2007.09299",
    "title": "Local Convergence of an AMP Variant to the LASSO Solution in Finite  Dimensions",
    "abstract": "Comments: Accepted by IEEE ISIT",
    "descriptor": "\nComments: Accepted by IEEE ISIT\n",
    "authors": [
      "Yanting Ma",
      "Min Kang",
      "Jack W. Silverstein",
      "Dror Baron"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.09299"
  },
  {
    "id": "arXiv:2007.11752",
    "title": "Joslim: Joint Widths and Weights Optimization for Slimmable Neural  Networks",
    "abstract": "Comments: Accepted at ECML-PKDD 2021 (Research Track), 4-page abridged versions have been accepted at non-archival venues including RealML and DMMLSys workshops at ICML'20 and DLP-KDD and AdvML workshops at KDD'20",
    "descriptor": "\nComments: Accepted at ECML-PKDD 2021 (Research Track), 4-page abridged versions have been accepted at non-archival venues including RealML and DMMLSys workshops at ICML'20 and DLP-KDD and AdvML workshops at KDD'20\n",
    "authors": [
      "Ting-Wu Chin",
      "Ari S. Morcos",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.11752"
  },
  {
    "id": "arXiv:2008.00332",
    "title": "Data Oblivious Algorithms for Multicores",
    "abstract": "Data Oblivious Algorithms for Multicores",
    "descriptor": "",
    "authors": [
      "Vijaya Ramachandran",
      "Elaine Shi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.00332"
  },
  {
    "id": "arXiv:2008.08903",
    "title": "Generative Adversarial Networks for Spatio-temporal Data: A Survey",
    "abstract": "Comments: This paper has been accepted by ACM Transactions on Intelligent Systems and Technology (TIST)",
    "descriptor": "\nComments: This paper has been accepted by ACM Transactions on Intelligent Systems and Technology (TIST)\n",
    "authors": [
      "Nan Gao",
      "Hao Xue",
      "Wei Shao",
      "Sichen Zhao",
      "Kyle Kai Qin",
      "Arian Prabowo",
      "Mohammad Saiedur Rahaman",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.08903"
  },
  {
    "id": "arXiv:2008.09883",
    "title": "A Systematic Literature Review of Critical Features and General Issues  of Freely Available mHealth Apps For Dietary Assessment",
    "abstract": "A Systematic Literature Review of Critical Features and General Issues  of Freely Available mHealth Apps For Dietary Assessment",
    "descriptor": "",
    "authors": [
      "Ghalib Ahmed Tahir",
      "Chu Kiong Loo",
      "Foong Ming Moy",
      "Nadine Kong"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2008.09883"
  },
  {
    "id": "arXiv:2009.07439",
    "title": "On the Landscape of One-hidden-layer Sparse Networks and Beyond",
    "abstract": "On the Landscape of One-hidden-layer Sparse Networks and Beyond",
    "descriptor": "",
    "authors": [
      "Dachao Lin",
      "Ruoyu Sun",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.07439"
  },
  {
    "id": "arXiv:2009.10159",
    "title": "Operator-valued formulas for Riemannian Gradient and Hessian and  families of tractable metrics",
    "abstract": "Operator-valued formulas for Riemannian Gradient and Hessian and  families of tractable metrics",
    "descriptor": "",
    "authors": [
      "Du Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2009.10159"
  },
  {
    "id": "arXiv:2009.12148",
    "title": "Adaptive Multi-modal Fusion Hashing via Hadamard Matrix",
    "abstract": "Comments: There are theoretical errors in our paper",
    "descriptor": "\nComments: There are theoretical errors in our paper\n",
    "authors": [
      "Jun Yu",
      "Donglin Zhang",
      "Zhenqiu Shu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2009.12148"
  },
  {
    "id": "arXiv:2009.13503",
    "title": "Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal  Algorithm Escaping the Curse of Horizon",
    "abstract": "Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal  Algorithm Escaping the Curse of Horizon",
    "descriptor": "",
    "authors": [
      "Zihan Zhang",
      "Xiangyang Ji",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13503"
  },
  {
    "id": "arXiv:2010.03242",
    "title": "Scalable Normalizing Flows for Permutation Invariant Densities",
    "abstract": "Comments: International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Marin Bilo\u0161",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.03242"
  },
  {
    "id": "arXiv:2010.03415",
    "title": "Knowledge-Based Learning of Nonlinear Dynamics and Chaos",
    "abstract": "Comments: 8 pages, 12 figures in main text, 6 figures and 8 tables in supplement",
    "descriptor": "\nComments: 8 pages, 12 figures in main text, 6 figures and 8 tables in supplement\n",
    "authors": [
      "Tom Z. Jiahao",
      "M. Ani Hsieh",
      "Eric Forgoston"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.03415"
  },
  {
    "id": "arXiv:2010.04012",
    "title": "Invertible Manifold Learning for Dimension Reduction",
    "abstract": "Comments: ECML-PKDD 2021 camera-ready. 15 pages (main) with 10 pages appendix",
    "descriptor": "\nComments: ECML-PKDD 2021 camera-ready. 15 pages (main) with 10 pages appendix\n",
    "authors": [
      "Siyuan Li",
      "Haitao Lin",
      "Zelin Zang",
      "Lirong Wu",
      "Jun Xia",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.04012"
  },
  {
    "id": "arXiv:2010.10223",
    "title": "Generators and bases for algebras over a monad",
    "abstract": "Generators and bases for algebras over a monad",
    "descriptor": "",
    "authors": [
      "Stefan Zetzsche",
      "Alexandra Silva",
      "Matteo Sammartino"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2010.10223"
  },
  {
    "id": "arXiv:2010.10300",
    "title": "Optimal Index Assignment for Scalar Quantizers and M-PSK via a Discrete  Convolution-Rearrangement Inequality",
    "abstract": "Optimal Index Assignment for Scalar Quantizers and M-PSK via a Discrete  Convolution-Rearrangement Inequality",
    "descriptor": "",
    "authors": [
      "Yunxiang Yao",
      "Wai Ho Mow"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.10300"
  },
  {
    "id": "arXiv:2010.15502",
    "title": "Enhancing Vulnerable Road User Safety: A Survey of Existing Practices  and Consideration for Using Mobile Devices for V2X Connections",
    "abstract": "Comments: 16 pages, 5 Figures",
    "descriptor": "\nComments: 16 pages, 5 Figures\n",
    "authors": [
      "Nishanthi Dasanayaka",
      "Khondokar Fida Hasan",
      "Charles Wang",
      "Yanming Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2010.15502"
  },
  {
    "id": "arXiv:2011.00099",
    "title": "Autonomous Robotic Screening of Tubular Structures based only on  Real-Time Ultrasound Imaging Feedback",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Industrial Electronics Video: this https URL",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Industrial Electronics Video: this https URL\n",
    "authors": [
      "Zhongliang Jiang",
      "Zhenyu Li",
      "Matthias Grimm",
      "Mingchuan Zhou",
      "Marco Esposito",
      "Wolfgang Wein",
      "Walter Stechele",
      "Thomas Wendler",
      "Nassir Navab"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.00099"
  },
  {
    "id": "arXiv:2011.02451",
    "title": "Muti-view Mouse Social Behaviour Recognition with Deep Graphical Model",
    "abstract": "Comments: 17 pages, 11 figures",
    "descriptor": "\nComments: 17 pages, 11 figures\n",
    "authors": [
      "Zheheng Jiang",
      "Feixiang Zhou",
      "Aite Zhao",
      "Xin Li",
      "Ling Li",
      "Dacheng Tao",
      "Xuelong Li",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.02451"
  },
  {
    "id": "arXiv:2011.03647",
    "title": "A Reinforcement Learning Approach to the Orienteering Problem with Time  Windows",
    "abstract": "A Reinforcement Learning Approach to the Orienteering Problem with Time  Windows",
    "descriptor": "",
    "authors": [
      "Ricardo Gama",
      "Hugo L. Fernandes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03647"
  },
  {
    "id": "arXiv:2011.03813",
    "title": "MAGIC: Learning Macro-Actions for Online POMDP Planning",
    "abstract": "Comments: 9 pages (+ 2 page references, + 2 page appendix)",
    "descriptor": "\nComments: 9 pages (+ 2 page references, + 2 page appendix)\n",
    "authors": [
      "Yiyuan Lee",
      "Panpan Cai",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03813"
  },
  {
    "id": "arXiv:2011.05944",
    "title": "Asymptotically Optimal Information-Directed Sampling",
    "abstract": "Comments: Manuscript has been rewritten with improvements to the algorithm and the analysis. Numerical experimental added",
    "descriptor": "\nComments: Manuscript has been rewritten with improvements to the algorithm and the analysis. Numerical experimental added\n",
    "authors": [
      "Johannes Kirschner",
      "Tor Lattimore",
      "Claire Vernade",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05944"
  },
  {
    "id": "arXiv:2011.14317",
    "title": "FROCC: Fast Random projection-based One-Class Classification",
    "abstract": "FROCC: Fast Random projection-based One-Class Classification",
    "descriptor": "",
    "authors": [
      "Arindam Bhattacharya",
      "Sumanth Varambally",
      "Amitabha Bagchi",
      "Srikanta Bedathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.14317"
  },
  {
    "id": "arXiv:2012.00650",
    "title": "Decoder-side Cross Resolution Synthesis for Video Compression  Enhancement",
    "abstract": "Decoder-side Cross Resolution Synthesis for Video Compression  Enhancement",
    "descriptor": "",
    "authors": [
      "Ming Lu",
      "Tong Chen",
      "zhenyu Dai",
      "Dong Wang",
      "Dandan Ding",
      "Zhan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.00650"
  },
  {
    "id": "arXiv:2012.08177",
    "title": "Machine Learning for MU-MIMO Receive Processing in OFDM Systems",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Mathieu Goutay",
      "Fay\u00e7al Ait Aoudia",
      "Jakob Hoydis",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.08177"
  },
  {
    "id": "arXiv:2012.09110",
    "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of  Smart City Security, Interpretability, and Ethical Challenges",
    "abstract": "Comments: I withdraw this paper, as I uploaded it by mistake",
    "descriptor": "\nComments: I withdraw this paper, as I uploaded it by mistake\n",
    "authors": [
      "Kashif Ahmad",
      "Majdi Maabreh",
      "Mohamed Ghaly",
      "Khalil Khan",
      "Junaid Qadir",
      "Ala Al-Fuqaha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.09110"
  },
  {
    "id": "arXiv:2012.10133",
    "title": "CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth",
    "abstract": "Comments: 6 Figures",
    "descriptor": "\nComments: 6 Figures\n",
    "authors": [
      "Xingxing Zuo",
      "Nathaniel Merrill",
      "Wei Li",
      "Yong Liu",
      "Marc Pollefeys",
      "Guoquan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.10133"
  },
  {
    "id": "arXiv:2012.11280",
    "title": "Sparsity regularization for inverse problems with non-trivial nullspaces",
    "abstract": "Sparsity regularization for inverse problems with non-trivial nullspaces",
    "descriptor": "",
    "authors": [
      "Ole L\u00f8seth Elvetun",
      "Bj\u00f8rn Fredrik Nielsen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.11280"
  },
  {
    "id": "arXiv:2101.00421",
    "title": "Decoding Time Lexical Domain Adaptation for Neural Machine Translation",
    "abstract": "Decoding Time Lexical Domain Adaptation for Neural Machine Translation",
    "descriptor": "",
    "authors": [
      "Nikolay Bogoychev",
      "Pinzhen Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00421"
  },
  {
    "id": "arXiv:2101.09563",
    "title": "Pr\u00e4zi: From Package-based to Call-based Dependency Networks",
    "abstract": "Comments: 42 pages, 14 figures, journal",
    "descriptor": "\nComments: 42 pages, 14 figures, journal\n",
    "authors": [
      "Joseph Hejderup",
      "Moritz Beller",
      "Konstantinos Triantafyllou",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.09563"
  },
  {
    "id": "arXiv:2101.10657",
    "title": "Advantages and Bottlenecks of Quantum Machine Learning for Remote  Sensing",
    "abstract": "Comments: Submitted and accepted for IEEE IGARSS2021",
    "descriptor": "\nComments: Submitted and accepted for IEEE IGARSS2021\n",
    "authors": [
      "Daniela A. Zaidenberg",
      "Alessandro Sebastianelli",
      "Dario Spiller",
      "Bertrand Le Saux",
      "Silvia Liberata Ullo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10657"
  },
  {
    "id": "arXiv:2101.12722",
    "title": "On the weight distribution of the cosets of MDS codes",
    "abstract": "Comments: 32 pages, 45 references. The text is edited. The connections between distinct parts of the paper are noted. Some transformations are simplified. New results are added. Open problems are formulated",
    "descriptor": "\nComments: 32 pages, 45 references. The text is edited. The connections between distinct parts of the paper are noted. Some transformations are simplified. New results are added. Open problems are formulated\n",
    "authors": [
      "Alexander A. Davydov",
      "Stefano Marcugini",
      "Fernanda Pambianco"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.12722"
  },
  {
    "id": "arXiv:2102.00451",
    "title": "Exponential Savings in Agnostic Active Learning through Abstention",
    "abstract": "Comments: 27 pages, additional clarifications added and several typos fixed",
    "descriptor": "\nComments: 27 pages, additional clarifications added and several typos fixed\n",
    "authors": [
      "Nikita Puchkin",
      "Nikita Zhivotovskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.00451"
  },
  {
    "id": "arXiv:2102.01117",
    "title": "SGD Generalizes Better Than GD (And Regularization Doesn't Help)",
    "abstract": "SGD Generalizes Better Than GD (And Regularization Doesn't Help)",
    "descriptor": "",
    "authors": [
      "Idan Amir",
      "Tomer Koren",
      "Roi Livni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.01117"
  },
  {
    "id": "arXiv:2102.02888",
    "title": "1-bit Adam: Communication Efficient Large-Scale Training with Adam's  Convergence Speed",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2008.11343",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.11343\n",
    "authors": [
      "Hanlin Tang",
      "Shaoduo Gan",
      "Ammar Ahmad Awan",
      "Samyam Rajbhandari",
      "Conglong Li",
      "Xiangru Lian",
      "Ji Liu",
      "Ce Zhang",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.02888"
  },
  {
    "id": "arXiv:2102.04008",
    "title": "Discovering conservation laws from trajectories via machine learning",
    "abstract": "Comments: 12 pages, 9 figures",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04008"
  },
  {
    "id": "arXiv:2102.04121",
    "title": "Enhancing Human-Machine Teaming for Medical Prognosis Through Neural  Ordinary Differential Equations (NODEs)",
    "abstract": "Comments: 13 pages, accepted for publication in HISI",
    "descriptor": "\nComments: 13 pages, accepted for publication in HISI\n",
    "authors": [
      "D. Fompeyrine",
      "E. S. Vorm",
      "N. Ricka",
      "F. Rose",
      "G. Pellegrin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04121"
  },
  {
    "id": "arXiv:2102.04259",
    "title": "Concentration of Non-Isotropic Random Tensors with Applications to  Learning and Empirical Risk Minimization",
    "abstract": "Concentration of Non-Isotropic Random Tensors with Applications to  Learning and Empirical Risk Minimization",
    "descriptor": "",
    "authors": [
      "Mathieu Even",
      "Laurent Massouli\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.04259"
  },
  {
    "id": "arXiv:2102.07268",
    "title": "Using analog computers in today's largest computational challenges",
    "abstract": "Comments: 12 pages, 2 figures, accepted paper towards a Special Issue of the open-access journal \"Advances in Radio Science\"",
    "descriptor": "\nComments: 12 pages, 2 figures, accepted paper towards a Special Issue of the open-access journal \"Advances in Radio Science\"\n",
    "authors": [
      "Sven K\u00f6ppel",
      "Bernd Ulmann",
      "Lars Heimann",
      "Dirk Killat"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Emerging Technologies (cs.ET)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.07268"
  },
  {
    "id": "arXiv:2102.07716",
    "title": "How RL Agents Behave When Their Actions Are Modified",
    "abstract": "Comments: 10 pages (+6 appendix); 7 figures. Published in the AAAI 2021 Conference on AI. Code is available at this https URL",
    "descriptor": "\nComments: 10 pages (+6 appendix); 7 figures. Published in the AAAI 2021 Conference on AI. Code is available at this https URL\n",
    "authors": [
      "Eric D. Langlois",
      "Tom Everitt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.07716"
  },
  {
    "id": "arXiv:2102.07850",
    "title": "Differentiable Particle Filtering via Entropy-Regularized Optimal  Transport",
    "abstract": "Comments: 9 pages of content + 11 pages supplementary, accepted for oral at ICML 2021",
    "descriptor": "\nComments: 9 pages of content + 11 pages supplementary, accepted for oral at ICML 2021\n",
    "authors": [
      "Adrien Corenflos",
      "James Thornton",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.07850"
  },
  {
    "id": "arXiv:2102.08788",
    "title": "ppAURORA: Privacy Preserving Area Under Receiver Operating  Characteristic and Precision-Recall Curves with Secure 3-Party Computation",
    "abstract": "ppAURORA: Privacy Preserving Area Under Receiver Operating  Characteristic and Precision-Recall Curves with Secure 3-Party Computation",
    "descriptor": "",
    "authors": [
      "Ali Burak \u00dcnal",
      "Nico Pfeifer",
      "Mete Akg\u00fcn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08788"
  },
  {
    "id": "arXiv:2102.08871",
    "title": "I Want This Product but Different : Multimodal Retrieval with Synthetic  Query Expansion",
    "abstract": "Comments: Major edits",
    "descriptor": "\nComments: Major edits\n",
    "authors": [
      "Ivona Tautkute",
      "Tomasz Trzcinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08871"
  },
  {
    "id": "arXiv:2102.09962",
    "title": "GEASI: Geodesic-based Earliest Activation Sites Identification in  cardiac models",
    "abstract": "Comments: 38 pages, 17 figures",
    "descriptor": "\nComments: 38 pages, 17 figures\n",
    "authors": [
      "Thomas Grandits",
      "Alexander Effland",
      "Thomas Pock",
      "Rolf Krause",
      "Gernot Plank",
      "Simone Pezzuto"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.09962"
  },
  {
    "id": "arXiv:2102.10159",
    "title": "A convergent finite difference method for computing minimal Lagrangian  graphs",
    "abstract": "A convergent finite difference method for computing minimal Lagrangian  graphs",
    "descriptor": "",
    "authors": [
      "Brittany Froese Hamfeldt",
      "Jacob Lesniewski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.10159"
  },
  {
    "id": "arXiv:2102.12962",
    "title": "Bias-reduced Multi-step Hindsight Experience Replay for Efficient  Multi-goal Reinforcement Learning",
    "abstract": "Comments: 20pages, 8 figures",
    "descriptor": "\nComments: 20pages, 8 figures\n",
    "authors": [
      "Rui Yang",
      "Jiafei Lyu",
      "Yu Yang",
      "Jiangpeng Ya",
      "Feng Luo",
      "Dijun Luo",
      "Lanqing Li",
      "Xiu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.12962"
  },
  {
    "id": "arXiv:2103.00543",
    "title": "On the Utility of Gradient Compression in Distributed Training Systems",
    "abstract": "On the Utility of Gradient Compression in Distributed Training Systems",
    "descriptor": "",
    "authors": [
      "Saurabh Agarwal",
      "Hongyi Wang",
      "Shivaram Venkataraman",
      "Dimitris Papailiopoulos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00543"
  },
  {
    "id": "arXiv:2103.01085",
    "title": "Challenges and Opportunities in High-dimensional Variational Inference",
    "abstract": "Challenges and Opportunities in High-dimensional Variational Inference",
    "descriptor": "",
    "authors": [
      "Akash Kumar Dhaka",
      "Alejandro Catalina",
      "Manushi Welandawe",
      "Michael Riis Andersen",
      "Jonathan Huggins",
      "Aki Vehtari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01085"
  },
  {
    "id": "arXiv:2103.01910",
    "title": "MultiSubs: A Large-scale Multimodal and Multilingual Dataset",
    "abstract": "Comments: Manuscript update: (i) Added links to the dataset and evaluation toolkit; (ii) Section 6.1.4: Added random and n-gram baselines to the fill-in-the-blank task, and added further discussion at the end of the section; (iii) Section 6.2.3: Further elaboration on the ALI metric; (iv) Section 6.2.4: Corrected results for the lexical translation task (Table 8), and updated the discussions accordingly",
    "descriptor": "\nComments: Manuscript update: (i) Added links to the dataset and evaluation toolkit; (ii) Section 6.1.4: Added random and n-gram baselines to the fill-in-the-blank task, and added further discussion at the end of the section; (iii) Section 6.2.3: Further elaboration on the ALI metric; (iv) Section 6.2.4: Corrected results for the lexical translation task (Table 8), and updated the discussions accordingly\n",
    "authors": [
      "Josiah Wang",
      "Pranava Madhyastha",
      "Josiel Figueiredo",
      "Chiraag Lala",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.01910"
  },
  {
    "id": "arXiv:2103.03398",
    "title": "New Directions in Science Emerge from Disconnection and Discord",
    "abstract": "New Directions in Science Emerge from Disconnection and Discord",
    "descriptor": "",
    "authors": [
      "Yiling Lin",
      "James Allen Evans",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.03398"
  },
  {
    "id": "arXiv:2103.03423",
    "title": "Constrained Contrastive Distribution Learning for Unsupervised Anomaly  Detection and Localisation in Medical Images",
    "abstract": "Comments: Accepted at MICCAI 2021",
    "descriptor": "\nComments: Accepted at MICCAI 2021\n",
    "authors": [
      "Yu Tian",
      "Guansong Pang",
      "Fengbei Liu",
      "Yuanhong chen",
      "Seon Ho Shin",
      "Johan W. Verjans",
      "Rajvinder Singh",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03423"
  },
  {
    "id": "arXiv:2103.04000",
    "title": "Off-Belief Learning",
    "abstract": "Off-Belief Learning",
    "descriptor": "",
    "authors": [
      "Hengyuan Hu",
      "Adam Lerer",
      "Brandon Cui",
      "David Wu",
      "Luis Pineda",
      "Noam Brown",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04000"
  },
  {
    "id": "arXiv:2103.04656",
    "title": "Will You Come Back to Contribute? Investigating the Inactivity of OSS  Core Developers in GitHub",
    "abstract": "Comments: Empirical Software Engineering, to appear",
    "descriptor": "\nComments: Empirical Software Engineering, to appear\n",
    "authors": [
      "Fabio Calefato",
      "Marco Aurelio Gerosa",
      "Giuseppe Iaffaldano",
      "Filippo Lanubile",
      "Igor Steinmacher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.04656"
  },
  {
    "id": "arXiv:2103.04969",
    "title": "IoT Roadmap: Support for Internet of Things Software Systems Engineering",
    "abstract": "IoT Roadmap: Support for Internet of Things Software Systems Engineering",
    "descriptor": "",
    "authors": [
      "Rebeca Motta",
      "K\u00e1thia Oliveira",
      "Guilherme Travassos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.04969"
  },
  {
    "id": "arXiv:2103.05247",
    "title": "Pretrained Transformers as Universal Computation Engines",
    "abstract": "Pretrained Transformers as Universal Computation Engines",
    "descriptor": "",
    "authors": [
      "Kevin Lu",
      "Aditya Grover",
      "Pieter Abbeel",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.05247"
  },
  {
    "id": "arXiv:2103.06315",
    "title": "Linear-Mapping based Variational Ensemble Kalman Filter",
    "abstract": "Linear-Mapping based Variational Ensemble Kalman Filter",
    "descriptor": "",
    "authors": [
      "Linjie Wen",
      "Jinglai Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2103.06315"
  },
  {
    "id": "arXiv:2103.06859",
    "title": "Understanding the Origin of Information-Seeking Exploration in  Probabilistic Objectives for Control",
    "abstract": "Comments: 11-03-21 initial upload. 14-03-21 fix Charnov citation. 16-03-21 another fix. 25-06-21 more fixes plus numerical simulations. 30-06-21 minor fixes",
    "descriptor": "\nComments: 11-03-21 initial upload. 14-03-21 fix Charnov citation. 16-03-21 another fix. 25-06-21 more fixes plus numerical simulations. 30-06-21 minor fixes\n",
    "authors": [
      "Beren Millidge",
      "Alexander Tschantz",
      "Anil Seth",
      "Christopher Buckley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.06859"
  },
  {
    "id": "arXiv:2103.07932",
    "title": "Gym-ANM: Reinforcement Learning Environments for Active Network  Management Tasks in Electricity Distribution Systems",
    "abstract": "Comments: 15 main pages, 17 pages of appendix, 10 figures, GitHub repository: this https URL",
    "descriptor": "\nComments: 15 main pages, 17 pages of appendix, 10 figures, GitHub repository: this https URL\n",
    "authors": [
      "Robin Henry",
      "Damien Ernst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.07932"
  },
  {
    "id": "arXiv:2103.09396",
    "title": "Pros and Cons of GAN Evaluation Measures: New Developments",
    "abstract": "Comments: NA",
    "descriptor": "\nComments: NA\n",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.09396"
  },
  {
    "id": "arXiv:2103.11350",
    "title": "Link Prediction via controlling the leading eigenvector",
    "abstract": "Comments: 22 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 22 pages, 4 figures, 4 tables\n",
    "authors": [
      "Yan-Li Lee",
      "Qiang Dong",
      "Tao Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.11350"
  },
  {
    "id": "arXiv:2103.12923",
    "title": "Cautiously Optimistic Policy Optimization and Exploration with Linear  Function Approximation",
    "abstract": "Comments: Appears in COLT 2021",
    "descriptor": "\nComments: Appears in COLT 2021\n",
    "authors": [
      "Andrea Zanette",
      "Ching-An Cheng",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12923"
  },
  {
    "id": "arXiv:2104.00273",
    "title": "Perspective, Survey and Trends: Public Driving Datasets and Toolsets for  Autonomous Driving Virtual Test",
    "abstract": "Comments: 6 pages, 4 figures. Accepted to 24th IEEE International Conference on Intelligent Transportation - ITSC2021",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted to 24th IEEE International Conference on Intelligent Transportation - ITSC2021\n",
    "authors": [
      "Pengliang Ji",
      "Li Ruan",
      "Yunzhi Xue",
      "Limin Xiao",
      "Qian Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.00273"
  },
  {
    "id": "arXiv:2104.00327",
    "title": "Famous Companies Use More Letters in Logo:A Large-Scale Analysis of Text  Area in Logo",
    "abstract": "Comments: Accepted at 14th International Workshop on Graphics Recognition (GREC2021)",
    "descriptor": "\nComments: Accepted at 14th International Workshop on Graphics Recognition (GREC2021)\n",
    "authors": [
      "Shintaro Nishi",
      "Takeaki Kadota",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00327"
  },
  {
    "id": "arXiv:2104.00564",
    "title": "Domain-Adversarial Training of Self-Attention Based Networks for Land  Cover Classification using Multi-temporal Sentinel-2 Satellite Imagery",
    "abstract": "Domain-Adversarial Training of Self-Attention Based Networks for Land  Cover Classification using Multi-temporal Sentinel-2 Satellite Imagery",
    "descriptor": "",
    "authors": [
      "Mauro Martini",
      "Vittorio Mazzia",
      "Aleem Khaliq",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.00564"
  },
  {
    "id": "arXiv:2104.02890",
    "title": "PrivGenDB: Efficient and privacy-preserving query executions over  encrypted SNP-Phenotype database",
    "abstract": "PrivGenDB: Efficient and privacy-preserving query executions over  encrypted SNP-Phenotype database",
    "descriptor": "",
    "authors": [
      "Sara Jafarbeiki",
      "Amin Sakzad",
      "Shabnam Kasra Kermanshahi",
      "Raj Gaire",
      "Ron Steinfeld",
      "Shangqi Lai",
      "Gad Abraham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.02890"
  },
  {
    "id": "arXiv:2104.03123",
    "title": "Partially-Connected Differentiable Architecture Search for Deepfake and  Spoofing Detection",
    "abstract": "Comments: Accepted to INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Wanying Ge",
      "Michele Panariello",
      "Jose Patino",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.03123"
  },
  {
    "id": "arXiv:2104.05025",
    "title": "Reducing Representation Drift in Online Continual Learning",
    "abstract": "Reducing Representation Drift in Online Continual Learning",
    "descriptor": "",
    "authors": [
      "Lucas Caccia",
      "Rahaf Aljundi",
      "Nader Asadi",
      "Tinne Tuytelaars",
      "Joelle Pineau",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05025"
  },
  {
    "id": "arXiv:2104.05575",
    "title": "GAttANet: Global attention agreement for convolutional neural networks",
    "abstract": "Comments: Paper accepted to ICANN 2021 - The 30th International Conference on Artificial Neural Networks",
    "descriptor": "\nComments: Paper accepted to ICANN 2021 - The 30th International Conference on Artificial Neural Networks\n",
    "authors": [
      "Rufin VanRullen",
      "Andrea Alamia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2104.05575"
  },
  {
    "id": "arXiv:2104.05704",
    "title": "Escaping the Big Data Paradigm with Compact Transformers",
    "abstract": "Comments: Added experiments on ImageNet and NLP tasks",
    "descriptor": "\nComments: Added experiments on ImageNet and NLP tasks\n",
    "authors": [
      "Ali Hassani",
      "Steven Walton",
      "Nikhil Shah",
      "Abulikemu Abuduweili",
      "Jiachen Li",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05704"
  },
  {
    "id": "arXiv:2104.07636",
    "title": "Image Super-Resolution via Iterative Refinement",
    "abstract": "Image Super-Resolution via Iterative Refinement",
    "descriptor": "",
    "authors": [
      "Chitwan Saharia",
      "Jonathan Ho",
      "William Chan",
      "Tim Salimans",
      "David J. Fleet",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07636"
  },
  {
    "id": "arXiv:2104.08440",
    "title": "Learning on a Budget via Teacher Imitation",
    "abstract": "Learning on a Budget via Teacher Imitation",
    "descriptor": "",
    "authors": [
      "Ercument Ilhan",
      "Jeremy Gow",
      "Diego Perez-Liebana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08440"
  },
  {
    "id": "arXiv:2104.09719",
    "title": "Effects of Interregional Travels and Vaccination in Infection Spreads  Simulated by Lattice of SEIRS Circuits",
    "abstract": "Comments: 15 pages, one Table, 6 figures, to be submitted to a journal soon, on the way to choose the suitable journal",
    "descriptor": "\nComments: 15 pages, one Table, 6 figures, to be submitted to a journal soon, on the way to choose the suitable journal\n",
    "authors": [
      "Yukio Ohsawa",
      "Teruaki Hayashi",
      "Sae Kondo"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.09719"
  },
  {
    "id": "arXiv:2104.09866",
    "title": "Distill on the Go: Online knowledge distillation in self-supervised  learning",
    "abstract": "Comments: Spotlight @ Learning from Limited or Imperfect Data (L2ID) Workshop - CVPR 2021",
    "descriptor": "\nComments: Spotlight @ Learning from Limited or Imperfect Data (L2ID) Workshop - CVPR 2021\n",
    "authors": [
      "Prashant Bhat",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09866"
  },
  {
    "id": "arXiv:2104.11955",
    "title": "On Logics and Homomorphism Closure",
    "abstract": "On Logics and Homomorphism Closure",
    "descriptor": "",
    "authors": [
      "Manuel Bodirsky",
      "Thomas Feller",
      "Simon Kn\u00e4uer",
      "Sebastian Rudolph"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.11955"
  },
  {
    "id": "arXiv:2104.12292",
    "title": "Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis",
    "abstract": "Comments: To appear at ISCA Speech Synthesis Workshop 2021",
    "descriptor": "\nComments: To appear at ISCA Speech Synthesis Workshop 2021\n",
    "authors": [
      "Erica Cooper",
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.12292"
  },
  {
    "id": "arXiv:2104.12345",
    "title": "Machine Learning-based Lie Detector applied to a Novel Annotated Game  Dataset",
    "abstract": "Machine Learning-based Lie Detector applied to a Novel Annotated Game  Dataset",
    "descriptor": "",
    "authors": [
      "Nuria Rodriguez-Diaz",
      "Decky Aspandi",
      "Federico Sukno",
      "Xavier Binefa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.12345"
  },
  {
    "id": "arXiv:2105.02106",
    "title": "Fixed-point iterative linear inverse solver with extended precision",
    "abstract": "Comments: Draft submission",
    "descriptor": "\nComments: Draft submission\n",
    "authors": [
      "Zheyuan Zhu",
      "Andrew B. Klein",
      "Guifang Li",
      "Shuo Pang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.02106"
  },
  {
    "id": "arXiv:2105.02373",
    "title": "How do Voices from Past Speech Synthesis Challenges Compare Today?",
    "abstract": "Comments: To appear at ISCA Speech Synthesis Workshop 2021",
    "descriptor": "\nComments: To appear at ISCA Speech Synthesis Workshop 2021\n",
    "authors": [
      "Erica Cooper",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.02373"
  },
  {
    "id": "arXiv:2105.03064",
    "title": "When an Energy-Efficient Scheduling is Optimal for Half-Duplex Relay  Networks?",
    "abstract": "When an Energy-Efficient Scheduling is Optimal for Half-Duplex Relay  Networks?",
    "descriptor": "",
    "authors": [
      "Sarthak Jain",
      "Martina Cardone",
      "Soheil Mohajer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03064"
  },
  {
    "id": "arXiv:2105.03248",
    "title": "Parameter Priors for Directed Acyclic Graphical Models and the  Characterization of Several Probability Distributions",
    "abstract": "Comments: This version has improved pointers to the literature. arXiv admin note: substantial text overlap with arXiv:1301.6697",
    "descriptor": "\nComments: This version has improved pointers to the literature. arXiv admin note: substantial text overlap with arXiv:1301.6697\n",
    "authors": [
      "Dan Geiger",
      "David Heckerman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.03248"
  },
  {
    "id": "arXiv:2105.03643",
    "title": "Latency-Controlled Neural Architecture Search for Streaming Speech  Recognition",
    "abstract": "Latency-Controlled Neural Architecture Search for Streaming Speech  Recognition",
    "descriptor": "",
    "authors": [
      "Liqiang He",
      "Shulin Feng",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03643"
  },
  {
    "id": "arXiv:2105.04036",
    "title": "A Novel Map of Knowledge for Science",
    "abstract": "A Novel Map of Knowledge for Science",
    "descriptor": "",
    "authors": [
      "Fan Shen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "History and Philosophy of Physics (physics.hist-ph)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04036"
  },
  {
    "id": "arXiv:2105.04045",
    "title": "Swarm Differential Privacy for Purpose Driven  Data-Information-Knowledge-Wisdom Architecture",
    "abstract": "Swarm Differential Privacy for Purpose Driven  Data-Information-Knowledge-Wisdom Architecture",
    "descriptor": "",
    "authors": [
      "Yingbo Li",
      "Yucong Duan",
      "Zakaria Maama",
      "Haoyang Che",
      "Anamaria-Beatrice Spulber",
      "Stelios Fuentes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04045"
  },
  {
    "id": "arXiv:2105.06241",
    "title": "Likelihoods and Parameter Priors for Bayesian Networks",
    "abstract": "Comments: This version has improved pointers to the literature",
    "descriptor": "\nComments: This version has improved pointers to the literature\n",
    "authors": [
      "David Heckerman",
      "Dan Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.06241"
  },
  {
    "id": "arXiv:2105.06282",
    "title": "Multiaccess Coded Caching with Private Demands",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Dequan Liang",
      "Kai Wan",
      "Minquan Cheng",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06282"
  },
  {
    "id": "arXiv:2105.06456",
    "title": "SaRoCo: Detecting Satire in a Novel Romanian Corpus of News Articles",
    "abstract": "Comments: Accepted at ACL 2021",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Ana-Cristina Rogoz",
      "Mihaela Gaman",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06456"
  },
  {
    "id": "arXiv:2105.07319",
    "title": "The Volctrans Neural Speech Translation System for IWSLT 2021",
    "abstract": "Comments: IWSLT 2021",
    "descriptor": "\nComments: IWSLT 2021\n",
    "authors": [
      "Chengqi Zhao",
      "Zhicheng Liu",
      "Jian Tong",
      "Tao Wang",
      "Mingxuan Wang",
      "Rong Ye",
      "Qianqian Dong",
      "Jun Cao",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.07319"
  },
  {
    "id": "arXiv:2105.07743",
    "title": "Universal Regular Conditional Distributions",
    "abstract": "Comments: Keywords: Universal Regular Conditional Distributions, Geometric Deep Learning, Measure-Valued Neural Networks, Conditional Expectation, Uncertainty Quantification. Additional Information: 27 Pages + 22 Page Appendix, 7 Tables",
    "descriptor": "\nComments: Keywords: Universal Regular Conditional Distributions, Geometric Deep Learning, Measure-Valued Neural Networks, Conditional Expectation, Uncertainty Quantification. Additional Information: 27 Pages + 22 Page Appendix, 7 Tables\n",
    "authors": [
      "Anastasis Kratsios"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.07743"
  },
  {
    "id": "arXiv:2105.08484",
    "title": "Fast Game Content Adaptation Through Bayesian-based Player Modelling",
    "abstract": "Comments: Accepted at CoG2021",
    "descriptor": "\nComments: Accepted at CoG2021\n",
    "authors": [
      "Miguel Gonz\u00e1lez-Duque",
      "Rasmus Berg Palm",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.08484"
  },
  {
    "id": "arXiv:2105.10013",
    "title": "Opening Deep Neural Networks with Generative Models",
    "abstract": "Opening Deep Neural Networks with Generative Models",
    "descriptor": "",
    "authors": [
      "Marcos Vendramini",
      "Hugo Oliveira",
      "Alexei Machado",
      "Jefersson A. dos Santos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10013"
  },
  {
    "id": "arXiv:2105.11147",
    "title": "Harmless but Useful: Beyond Separable Equality Constraints in Datalog+/-",
    "abstract": "Harmless but Useful: Beyond Separable Equality Constraints in Datalog+/-",
    "descriptor": "",
    "authors": [
      "Luigi Bellomarini",
      "Emanuel Sallinger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11147"
  },
  {
    "id": "arXiv:2105.11866",
    "title": "GraphFM: Graph Factorization Machines for Feature Interaction Modeling",
    "abstract": "Comments: submitted to tkde",
    "descriptor": "\nComments: submitted to tkde\n",
    "authors": [
      "Zekun Li",
      "Shu Wu",
      "Zeyu Cui",
      "Xiaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.11866"
  },
  {
    "id": "arXiv:2105.12326",
    "title": "Model Checking Finite-Horizon Markov Chains with Probabilistic Inference",
    "abstract": "Comments: Technical Report. Accepted at CAV 2021",
    "descriptor": "\nComments: Technical Report. Accepted at CAV 2021\n",
    "authors": [
      "Steven Holtzen",
      "Sebastian Junges",
      "Marcell Vazquez-Chanlatte",
      "Todd Millstein",
      "Sanjit A. Seshia",
      "Guy Van Den Broeck"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.12326"
  },
  {
    "id": "arXiv:2105.12839",
    "title": "SIMDRAM: An End-to-End Framework for Bit-Serial SIMD Computing in DRAM",
    "abstract": "Comments: This is an extended version of the paper that appeared at ASPLOS 2021",
    "descriptor": "\nComments: This is an extended version of the paper that appeared at ASPLOS 2021\n",
    "authors": [
      "Nastaran Hajinazar",
      "Geraldo F. Oliveira",
      "Sven Gregorio",
      "Jo\u00e3o Ferreira",
      "Nika Mansouri Ghiasi",
      "Minesh Patel",
      "Mohammed Alser",
      "Saugata Ghose",
      "Juan G\u00f3mez Luna",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.12839"
  },
  {
    "id": "arXiv:2105.13813",
    "title": "Grey-box models for wave loading prediction",
    "abstract": "Grey-box models for wave loading prediction",
    "descriptor": "",
    "authors": [
      "Daniel J Pitchforth",
      "Timothy J Rogers",
      "Ulf T Tygesen",
      "Elizabeth J Cross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2105.13813"
  },
  {
    "id": "arXiv:2105.14069",
    "title": "The Evaluation of Rating Systems in Team-based Battle Royale Games",
    "abstract": "Comments: Updated references -- 10 pages, 1 figure, Accepted in the 23rd International Conference on Artificial Intelligence (ICAI'21)",
    "descriptor": "\nComments: Updated references -- 10 pages, 1 figure, Accepted in the 23rd International Conference on Artificial Intelligence (ICAI'21)\n",
    "authors": [
      "Arman Dehpanah",
      "Muheeb Faizan Ghori",
      "Jonathan Gemmell",
      "Bamshad Mobasher"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.14069"
  },
  {
    "id": "arXiv:2105.14583",
    "title": "A Note On The Randomized Kaczmarz Method With A Partially Weighted  Selection Step",
    "abstract": "Comments: Added references",
    "descriptor": "\nComments: Added references\n",
    "authors": [
      "J\u00fcrgen Gro\u00df"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14583"
  },
  {
    "id": "arXiv:2105.14734",
    "title": "Dual-stream Network for Visual Recognition",
    "abstract": "Dual-stream Network for Visual Recognition",
    "descriptor": "",
    "authors": [
      "Mingyuan Mao",
      "Renrui Zhang",
      "Honghui Zheng",
      "Peng Gao",
      "Teli Ma",
      "Yan Peng",
      "Errui Ding",
      "Baochang Zhang",
      "Shumin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14734"
  },
  {
    "id": "arXiv:2106.00510",
    "title": "CIDER: Commonsense Inference for Dialogue Explanation and Reasoning",
    "abstract": "Comments: SIGDIAL 2021",
    "descriptor": "\nComments: SIGDIAL 2021\n",
    "authors": [
      "Deepanway Ghosal",
      "Pengfei Hong",
      "Siqi Shen",
      "Navonil Majumder",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00510"
  },
  {
    "id": "arXiv:2106.02848",
    "title": "Numerical Composition of Differential Privacy",
    "abstract": "Numerical Composition of Differential Privacy",
    "descriptor": "",
    "authors": [
      "Sivakanth Gopi",
      "Yin Tat Lee",
      "Lukas Wutschitz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02848"
  },
  {
    "id": "arXiv:2106.03373",
    "title": "Pre-trained Language Model for Web-scale Retrieval in Baidu Search",
    "abstract": "Comments: Accepted by KDD 2021",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Yiding Liu",
      "Guan Huang",
      "Jiaxiang Liu",
      "Weixue Lu",
      "Suqi Cheng",
      "Yukun Li",
      "Daiting Shi",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03373"
  },
  {
    "id": "arXiv:2106.03412",
    "title": "Resolution learning in deep convolutional networks using scale-space  theory",
    "abstract": "Resolution learning in deep convolutional networks using scale-space  theory",
    "descriptor": "",
    "authors": [
      "Silvia L.Pintea",
      "Nergis Tomen",
      "Stanley F. Goes",
      "Marco Loog",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03412"
  },
  {
    "id": "arXiv:2106.03706",
    "title": "A Comprehensive Assessment of Dialog Evaluation Metrics",
    "abstract": "A Comprehensive Assessment of Dialog Evaluation Metrics",
    "descriptor": "",
    "authors": [
      "Yi-Ting Yeh",
      "Maxine Eskenazi",
      "Shikib Mehri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03706"
  },
  {
    "id": "arXiv:2106.04140",
    "title": "Broadcasted Residual Learning for Efficient Keyword Spotting",
    "abstract": "Comments: Proceedings of INTERSPEECH 2021",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2021\n",
    "authors": [
      "Byeonggeun Kim",
      "Simyung Chang",
      "Jinkyu Lee",
      "Dooyong Sung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.04140"
  },
  {
    "id": "arXiv:2106.04534",
    "title": "High moment and pathwise error estimates for fully discrete mixed finite  element approximations of the Stochastic Stokes Equations with Multiplicative  Noises",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Liet Vo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.04534"
  },
  {
    "id": "arXiv:2106.05401",
    "title": "Mechanisms and Attributes of Echo Chambers in Social Media",
    "abstract": "Comments: 10 pages, 2 figures, SBP-BRiMS 2021 (2021 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation), working/late-breaking paper",
    "descriptor": "\nComments: 10 pages, 2 figures, SBP-BRiMS 2021 (2021 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation), working/late-breaking paper\n",
    "authors": [
      "Bohan Jiang",
      "Mansooreh Karami",
      "Lu Cheng",
      "Tyler Black",
      "Huan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.05401"
  },
  {
    "id": "arXiv:2106.05739",
    "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability  Metrics",
    "abstract": "Comments: 32 pages, 3 figures",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Carles Domingo-Enrich",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.05739"
  },
  {
    "id": "arXiv:2106.05953",
    "title": "Self-Supervised 3D Hand Pose Estimation from monocular RGB via  Contrastive Learning",
    "abstract": "Self-Supervised 3D Hand Pose Estimation from monocular RGB via  Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Adrian Spurr",
      "Aneesh Dahiya",
      "Xucong Zhang",
      "Xi Wang",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05953"
  },
  {
    "id": "arXiv:2106.07036",
    "title": "Protein-Ligand Docking Surrogate Models: A SARS-CoV-2 Benchmark for Deep  Learning Accelerated Virtual Screening",
    "abstract": "Protein-Ligand Docking Surrogate Models: A SARS-CoV-2 Benchmark for Deep  Learning Accelerated Virtual Screening",
    "descriptor": "",
    "authors": [
      "Austin Clyde",
      "Thomas Brettin",
      "Alexander Partin",
      "Hyunseung Yoo",
      "Yadu Babuji",
      "Ben Blaiszik",
      "Andre Merzky",
      "Matteo Turilli",
      "Shantenu Jha",
      "Arvind Ramanathan",
      "Rick Stevens"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07036"
  },
  {
    "id": "arXiv:2106.07387",
    "title": "An SMT Based Compositional Algorithm to Solve a Conflict-Free Electric  Vehicle Routing Problem",
    "abstract": "An SMT Based Compositional Algorithm to Solve a Conflict-Free Electric  Vehicle Routing Problem",
    "descriptor": "",
    "authors": [
      "Sabino Francesco Roselli",
      "Martin Fabian",
      "Knut \u00c5kesson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07387"
  },
  {
    "id": "arXiv:2106.07954",
    "title": "CatBoost model with synthetic features in application to loan risk  assessment of small businesses",
    "abstract": "CatBoost model with synthetic features in application to loan risk  assessment of small businesses",
    "descriptor": "",
    "authors": [
      "Haoxue Wang",
      "Liexin Cheng"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07954"
  },
  {
    "id": "arXiv:2106.08049",
    "title": "Demographic Fairness in Face Identification: The Watchlist Imbalance  Effect",
    "abstract": "Comments: dispute over contents of section 2",
    "descriptor": "\nComments: dispute over contents of section 2\n",
    "authors": [
      "Pawel Drozdowski",
      "Christian Rathgeb",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.08049"
  },
  {
    "id": "arXiv:2106.08208",
    "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients",
    "abstract": "Comments: 18 pages, 5 figures. We add the detailed proofs and correct some typos",
    "descriptor": "\nComments: 18 pages, 5 figures. We add the detailed proofs and correct some typos\n",
    "authors": [
      "Feihu Huang",
      "Junyi Li",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08208"
  },
  {
    "id": "arXiv:2106.09370",
    "title": "Deep generative modeling for probabilistic forecasting in power systems",
    "abstract": "Deep generative modeling for probabilistic forecasting in power systems",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Antoine Wehenkel Damien Lanaspeze",
      "Bertrand Corn\u00e9lusse",
      "Antonio Sutera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09370"
  },
  {
    "id": "arXiv:2106.10479",
    "title": "Practical Transferability Estimation for Image Classification Tasks",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yang Tan",
      "Yang Li",
      "Shao-Lun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10479"
  },
  {
    "id": "arXiv:2106.10587",
    "title": "Exploring Vision Transformers for Fine-grained Classification",
    "abstract": "Comments: 4 pages, 5 figures, 4 tables. Published in IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) 2021 - FGVC8. For code see this https URL and for other workshop papers see this https URL",
    "descriptor": "\nComments: 4 pages, 5 figures, 4 tables. Published in IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) 2021 - FGVC8. For code see this https URL and for other workshop papers see this https URL\n",
    "authors": [
      "Marcos V. Conde",
      "Kerem Turgutlu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10587"
  },
  {
    "id": "arXiv:2106.10759",
    "title": "Robust Regression via Model Based Methods",
    "abstract": "Robust Regression via Model Based Methods",
    "descriptor": "",
    "authors": [
      "Armin Moharrer",
      "Khashayar Kamran",
      "Edmund Yeh",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10759"
  },
  {
    "id": "arXiv:2106.10782",
    "title": "Strong Singleton type upper bounds for linear insertion-deletion codes",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10782"
  },
  {
    "id": "arXiv:2106.11042",
    "title": "A Taxonomy to Unify Fault Tolerance Regimes for Automotive Systems:  Defining Fail-Operational, Fail-Degraded, and Fail-Safe",
    "abstract": "Comments: 12 pages, 3 figures, 1 table, submitted to IEEE Transactions on Intelligent Vehicles",
    "descriptor": "\nComments: 12 pages, 3 figures, 1 table, submitted to IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Torben Stolte",
      "Stefan Ackermann",
      "Robert Graubohm",
      "Inga Jatzkowski",
      "Bj\u00f6rn Klamann",
      "Hermann Winner",
      "Markus Maurer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11042"
  },
  {
    "id": "arXiv:2106.11396",
    "title": "BiAdam: Fast Adaptive Bilevel Optimization Methods",
    "abstract": "Comments: 66 pages, 2 tables. We add the detailed proofs",
    "descriptor": "\nComments: 66 pages, 2 tables. We add the detailed proofs\n",
    "authors": [
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11396"
  },
  {
    "id": "arXiv:2106.11716",
    "title": "Robust EMRAN based Neural Aided Learning Controller for Autonomous  Vehicles",
    "abstract": "Robust EMRAN based Neural Aided Learning Controller for Autonomous  Vehicles",
    "descriptor": "",
    "authors": [
      "Sauranil Debarshi",
      "Suresh Sundaram",
      "Narasimhan Sundararajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11716"
  },
  {
    "id": "arXiv:2106.11776",
    "title": "A Review of the Vision-based Approaches for Dietary Assessment",
    "abstract": "A Review of the Vision-based Approaches for Dietary Assessment",
    "descriptor": "",
    "authors": [
      "Ghalib Tahir",
      "Chu Kiong Loo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11776"
  },
  {
    "id": "arXiv:2106.12407",
    "title": "STRESS: Super-Resolution for Dynamic Fetal MRI using Self-Supervised  Learning",
    "abstract": "STRESS: Super-Resolution for Dynamic Fetal MRI using Self-Supervised  Learning",
    "descriptor": "",
    "authors": [
      "Junshen Xu",
      "Esra Abaci Turk",
      "P. Ellen Grant",
      "Polina Golland",
      "Elfar Adalsteinsson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12407"
  },
  {
    "id": "arXiv:2106.12714",
    "title": "Circuit Masking: From Theory to Standardization, A Comprehensive Survey  for Hardware Security Researchers and Practitioners",
    "abstract": "Circuit Masking: From Theory to Standardization, A Comprehensive Survey  for Hardware Security Researchers and Practitioners",
    "descriptor": "",
    "authors": [
      "Ana Covic",
      "Fatemeh Ganji",
      "Domenic Forte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.12714"
  },
  {
    "id": "arXiv:2106.13308",
    "title": "Overcoming barriers to scalability in variational quantum Monte Carlo",
    "abstract": "Comments: ACM/IEEE Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC21)",
    "descriptor": "\nComments: ACM/IEEE Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC21)\n",
    "authors": [
      "Tianchen Zhao",
      "Saibal De",
      "Brian Chen",
      "James Stokes",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13308"
  },
  {
    "id": "arXiv:2106.13867",
    "title": "POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network  Controlled Systems",
    "abstract": "POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network  Controlled Systems",
    "descriptor": "",
    "authors": [
      "Chao Huang",
      "Jiameng Fan",
      "Xin Chen",
      "Wenchao Li",
      "Qi Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13867"
  },
  {
    "id": "arXiv:2106.13883",
    "title": "Semi-Supervised Raw-to-Raw Mapping",
    "abstract": "Semi-Supervised Raw-to-Raw Mapping",
    "descriptor": "",
    "authors": [
      "Mahmoud Afifi",
      "Abdullah Abuolaim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.13883"
  },
  {
    "id": "arXiv:2106.14008",
    "title": "Semi-Supervised Deep Ensembles for Blind Image Quality Assessment",
    "abstract": "Comments: 6 pages, 1 figure, 5 tables",
    "descriptor": "\nComments: 6 pages, 1 figure, 5 tables\n",
    "authors": [
      "Zhihua Wang",
      "Dingquan Li",
      "Kede Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.14008"
  },
  {
    "id": "arXiv:2106.14033",
    "title": "BiX-NAS: Searching Efficient Bi-directional Architecture for Medical  Image Segmentation",
    "abstract": "Comments: MICCAI2021",
    "descriptor": "\nComments: MICCAI2021\n",
    "authors": [
      "Xinyi Wang",
      "Tiange Xiang",
      "Chaoyi Zhang",
      "Yang Song",
      "Dongnan Liu",
      "Heng Huang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14033"
  },
  {
    "id": "arXiv:2106.14503",
    "title": "Weight Divergence Driven Divide-and-Conquer Approach for Optimal  Federated Learning from non-IID Data",
    "abstract": "Weight Divergence Driven Divide-and-Conquer Approach for Optimal  Federated Learning from non-IID Data",
    "descriptor": "",
    "authors": [
      "Pravin Chandran",
      "Raghavendra Bhat",
      "Avinash Chakravarthi",
      "Srikanth Chandar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.14503"
  },
  {
    "id": "arXiv:2106.14801",
    "title": "Reasoning on $\\textit{DL-Lite}_{\\cal R}$ with Defeasibility in ASP",
    "abstract": "Comments: Under consideration in Theory and Practice of Logic Programming (TPLP). This paper is an extended and revised version of a conference paper appearing in the proceedings of the 3rd International Joint Conference on Rules and Reasoning (RuleML+RR 2019). (v2 updates: added discussion on equivalence in Appendix, typos corrected). arXiv admin note: text overlap with arXiv:1905.09221",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP). This paper is an extended and revised version of a conference paper appearing in the proceedings of the 3rd International Joint Conference on Rules and Reasoning (RuleML+RR 2019). (v2 updates: added discussion on equivalence in Appendix, typos corrected). arXiv admin note: text overlap with arXiv:1905.09221\n",
    "authors": [
      "Loris Bozzato",
      "Thomas Eiter",
      "Luciano Serafini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.14801"
  },
  {
    "id": "arXiv:2106.14977",
    "title": "The Food Recognition Benchmark: Using DeepLearning to Recognize Food on  Images",
    "abstract": "The Food Recognition Benchmark: Using DeepLearning to Recognize Food on  Images",
    "descriptor": "",
    "authors": [
      "Sharada Prasanna Mohanty",
      "Gaurav Singhal",
      "Eric Antoine Scuccimarra",
      "Djilani Kebaili",
      "Harris H\u00e9ritier",
      "Victor Boulanger",
      "Marcel Salath\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14977"
  },
  {
    "id": "arXiv:2106.15009",
    "title": "Understanding Cognitive Fatigue from fMRI Scans with Self-supervised  Learning",
    "abstract": "Comments: 8 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 5 figures, 2 tables\n",
    "authors": [
      "Ashish Jaiswal",
      "Ashwin Ramesh Babu",
      "Mohammad Zaki Zadeh",
      "Fillia Makedon",
      "Glenn Wylie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15009"
  },
  {
    "id": "arXiv:2106.15064",
    "title": "GuidedMix-Net: Learning to Improve Pseudo Masks Using Labeled Images as  Reference",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Peng Tu",
      "Yawen Huang",
      "Rongrong Ji",
      "Feng Zheng",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15064"
  },
  {
    "id": "arXiv:2106.15083",
    "title": "ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant  Re-Identification",
    "abstract": "ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant  Re-Identification",
    "descriptor": "",
    "authors": [
      "Peter Kulits",
      "Jake Wall",
      "Anka Bedetti",
      "Michelle Henley",
      "Sara Beery"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15083"
  },
  {
    "id": "arXiv:2106.15183",
    "title": "Multi-Exit Vision Transformer for Dynamic Inference",
    "abstract": "Multi-Exit Vision Transformer for Dynamic Inference",
    "descriptor": "",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15183"
  },
  {
    "id": "arXiv:2106.15221",
    "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources",
    "abstract": "Comments: Demo",
    "descriptor": "\nComments: Demo\n",
    "authors": [
      "Linyi Yang",
      "Tin Lok James Ng",
      "Barry Smyth",
      "Ruihai Dong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15221"
  },
  {
    "id": "arXiv:2106.15231",
    "title": "Exploring the Efficacy of Automatically Generated Counterfactuals for  Sentiment Analysis",
    "abstract": "Comments: ACL-21, Main Conference, Long Paper",
    "descriptor": "\nComments: ACL-21, Main Conference, Long Paper\n",
    "authors": [
      "Linyi Yang",
      "Jiazheng Li",
      "P\u00e1draig Cunningham",
      "Yue Zhang",
      "Barry Smyth",
      "Ruihai Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.15231"
  },
  {
    "id": "arXiv:2106.15232",
    "title": "Using Robust Regression to Find Font Usage Trends",
    "abstract": "Comments: 16 pages with 10 figures. Accepted at ICDAR 2021 Workshop on Machine Learning(ICDAR-WML2021)",
    "descriptor": "\nComments: 16 pages with 10 figures. Accepted at ICDAR 2021 Workshop on Machine Learning(ICDAR-WML2021)\n",
    "authors": [
      "Kaigen Tsuji",
      "Seiichi Uchida",
      "Brian Kenji Iwana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15232"
  },
  {
    "id": "arXiv:2106.15236",
    "title": "New Arabic Medical Dataset for Diseases Classification",
    "abstract": "New Arabic Medical Dataset for Diseases Classification",
    "descriptor": "",
    "authors": [
      "Jaafar Hammoud",
      "Aleksandra Vatian",
      "Natalia Dobrenko",
      "Nikolai Vedernikov",
      "Anatoly Shalyto",
      "Natalia Gusarova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15236"
  },
  {
    "id": "arXiv:2106.15324",
    "title": "Effective Evaluation of Deep Active Learning on Image Classification  Tasks",
    "abstract": "Comments: 9 pages in main paper, 6 figures in main paper, 3 tables in main paper. 23 pages in total, 15 figures in total, 14 tables in total",
    "descriptor": "\nComments: 9 pages in main paper, 6 figures in main paper, 3 tables in main paper. 23 pages in total, 15 figures in total, 14 tables in total\n",
    "authors": [
      "Nathan Beck",
      "Durga Sivasubramanian",
      "Apurva Dani",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15324"
  },
  {
    "id": "arXiv:2106.15356",
    "title": "Scalable Gaussian Processes for Data-Driven Design using Big Data with  Categorical Factors",
    "abstract": "Comments: Preprint submitted to Journal of Mechanical Design",
    "descriptor": "\nComments: Preprint submitted to Journal of Mechanical Design\n",
    "authors": [
      "Liwei Wang",
      "Suraj Yerramilli",
      "Akshay Iyer",
      "Daniel Apley",
      "Ping Zhu",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15356"
  },
  {
    "id": "arXiv:2106.15368",
    "title": "Text Prior Guided Scene Text Image Super-resolution",
    "abstract": "Comments: Code has been released on this https URL",
    "descriptor": "\nComments: Code has been released on this https URL\n",
    "authors": [
      "Jianqi Ma",
      "Shi Guo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15368"
  },
  {
    "id": "arXiv:2106.15476",
    "title": "Reducing Boolean Networks with Backward Boolean Equivalence",
    "abstract": "Reducing Boolean Networks with Backward Boolean Equivalence",
    "descriptor": "",
    "authors": [
      "Georgios Argyris",
      "Alberto Lluch Lafuente",
      "Mirco Tribastone",
      "Max Tschaikowski",
      "Andrea Vandin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.15476"
  },
  {
    "id": "arXiv:2106.15561",
    "title": "A Survey on Neural Speech Synthesis",
    "abstract": "Comments: A comprehensive survey on TTS, 63 pages, 18 tables, 7 figures, 450 references",
    "descriptor": "\nComments: A comprehensive survey on TTS, 63 pages, 18 tables, 7 figures, 450 references\n",
    "authors": [
      "Xu Tan",
      "Tao Qin",
      "Frank Soong",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.15561"
  },
  {
    "id": "arXiv:2106.15612",
    "title": "Learning Task Informed Abstractions",
    "abstract": "Comments: 8 pages, 12 figures",
    "descriptor": "\nComments: 8 pages, 12 figures\n",
    "authors": [
      "Xiang Fu",
      "Ge Yang",
      "Pulkit Agrawal",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15612"
  }
]
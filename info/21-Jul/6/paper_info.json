[
  {
    "id": "arXiv:2107.01235",
    "title": "Linear Discrepancy is $\u03a0_2$-Hard to Approximate",
    "abstract": "In this note, we prove that the problem of computing the linear discrepancy\nof a given matrix is $\\Pi_2$-hard, even to approximate within $9/8 - \\epsilon$\nfactor for any $\\epsilon > 0$. This strengthens the NP-hardness result of Li\nand Nikolov [ESA 2020] for the exact version of the problem, and answers a\nquestion posed by them. Furthermore, since Li and Nikolov showed that the\nproblem is contained in $\\Pi_2$, our result makes linear discrepancy another\nnatural problem that is $\\Pi_2$-complete (to approximate).",
    "descriptor": "\nComments: 9 pages; to appear in Information Processing Letters\n",
    "authors": [
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01235"
  },
  {
    "id": "arXiv:2107.01238",
    "title": "Solving Machine Learning Problems",
    "abstract": "Can a machine learn Machine Learning? This work trains a machine learning\nmodel to solve machine learning problems from a University undergraduate level\ncourse. We generate a new training set of questions and answers consisting of\ncourse exercises, homework, and quiz questions from MIT's 6.036 Introduction to\nMachine Learning course and train a machine learning model to answer these\nquestions. Our system demonstrates an overall accuracy of 96% for open-response\nquestions and 97% for multiple-choice questions, compared with MIT students'\naverage of 93%, achieving grade A performance in the course, all in real-time.\nQuestions cover all 12 topics taught in the course, excluding coding questions\nor questions with images. Topics include: (i) basic machine learning\nprinciples; (ii) perceptrons; (iii) feature extraction and selection; (iv)\nlogistic regression; (v) regression; (vi) neural networks; (vii) advanced\nneural networks; (viii) convolutional neural networks; (ix) recurrent neural\nnetworks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)\ndecision trees. Our system uses Transformer models within an encoder-decoder\narchitecture with graph and tree representations. An important aspect of our\napproach is a data-augmentation scheme for generating new example problems. We\nalso train a machine learning model to generate problem hints. Thus, our system\nautomatically generates new questions across topics, answers both open-response\nquestions and multiple-choice questions, classifies problems, and generates\nproblem hints, pushing the envelope of AI for STEM education.",
    "descriptor": "\nComments: 38 pages, 29 figures\n",
    "authors": [
      "Sunny Tran",
      "Pranav Krishna",
      "Ishan Pakuwal",
      "Prabhakar Kafle",
      "Nikhil Singh",
      "Jayson Lynch",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01238"
  },
  {
    "id": "arXiv:2107.01241",
    "title": "Temporal Regular Path Queries: Syntax, Semantics, and Complexity",
    "abstract": "In the last decade, substantial progress has been made towards standardizing\nthe syntax of graph query languages, and towards understanding their semantics\nand complexity of evaluation. In this paper, we consider temporal property\ngraphs (TPGs) and propose temporal regular path queries (TRPQ) that incorporate\ntime into TPGs navigation. Starting with design principles, we propose a\nnatural syntactic extension of the MATCH clause of popular graph query\nlanguages. We then formally present the semantics of TRPQs, and study the\ncomplexity of their evaluation. We show that TRPQs can be evaluated in\npolynomial time if TPGs are time-stamped with time points. We also identify\nfragments of the TRPQ language that admit efficient evaluation over a more\nsuccinct interval-annotated representation. Our work on the syntax, and the\npositive complexity results, pave the way to implementations of TRPQs that are\nboth usable and practical.",
    "descriptor": "",
    "authors": [
      "Marcelo Arenas",
      "Pedro Bahamondes",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01241"
  },
  {
    "id": "arXiv:2107.01243",
    "title": "Neko: A Modern, Portable, and Scalable Framework for High-Fidelity  Computational Fluid Dynamics",
    "abstract": "Recent trends and advancement in including more diverse and heterogeneous\nhardware in High-Performance Computing is challenging software developers in\ntheir pursuit for good performance and numerical stability. The well-known\nmaxim \"software outlives hardware\" may no longer necessarily hold true, and\ndevelopers are today forced to re-factor their codebases to leverage these\npowerful new systems. CFD is one of the many application domains affected. In\nthis paper, we present Neko, a portable framework for high-order spectral\nelement flow simulations. Unlike prior works, Neko adopts a modern\nobject-oriented approach, allowing multi-tier abstractions of the solver stack\nand facilitating hardware backends ranging from general-purpose processors down\nto exotic vector processors and FPGAs. We show that Neko's performance and\naccuracy are comparable to NekRS, and thus on-par with Nek5000's successor on\nmodern CPU machines. Furthermore, we develop a performance model, which we use\nto discuss challenges and opportunities for high-order solvers on emerging\nhardware.",
    "descriptor": "",
    "authors": [
      "Niclas Jansson",
      "Martin Karp",
      "Artur Podobas",
      "Stefano Markidis",
      "Philipp Schlatter"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2107.01243"
  },
  {
    "id": "arXiv:2107.01244",
    "title": "Ensemble Kalman Filter (EnKF) for Reinforcement Learning (RL)",
    "abstract": "This paper is concerned with the problem of representing and learning the\noptimal control law for the linear quadratic Gaussian (LQG) optimal control\nproblem. In recent years, there is a growing interest in re-visiting this\nclassical problem, in part due to the successes of reinforcement learning (RL).\nThe main question of this body of research (and also of our paper) is to\napproximate the optimal control law {\\em without} explicitly solving the\nRiccati equation. For this purpose, a novel simulation-based algorithm, namely\nan ensemble Kalman filter (EnKF), is introduced in this paper. The algorithm is\nused to obtain formulae for optimal control, expressed entirely in terms of the\nEnKF particles. For the general partially observed LQG problem, the proposed\nEnKF is combined with a standard EnKF (for the estimation problem) to obtain\nthe optimal control input based on the use of the separation principle. A\nnonlinear extension of the algorithm is also discussed which clarifies the\nduality roots of the proposed EnKF. The theoretical results and algorithms are\nillustrated with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Anant Joshi",
      "Amirhossein Taghvaei",
      "Prashant G. Mehta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.01244"
  },
  {
    "id": "arXiv:2107.01248",
    "title": "Data Uncertainty Guided Noise-aware Preprocessing Of Fingerprints",
    "abstract": "The effectiveness of fingerprint-based authentication systems on good quality\nfingerprints is established long back. However, the performance of standard\nfingerprint matching systems on noisy and poor quality fingerprints is far from\nsatisfactory. Towards this, we propose a data uncertainty-based framework which\nenables the state-of-the-art fingerprint preprocessing models to quantify noise\npresent in the input image and identify fingerprint regions with background\nnoise and poor ridge clarity. Quantification of noise helps the model two\nfolds: firstly, it makes the objective function adaptive to the noise in a\nparticular input fingerprint and consequently, helps to achieve robust\nperformance on noisy and distorted fingerprint regions. Secondly, it provides a\nnoise variance map which indicates noisy pixels in the input fingerprint image.\nThe predicted noise variance map enables the end-users to understand erroneous\npredictions due to noise present in the input image. Extensive experimental\nevaluation on 13 publicly available fingerprint databases, across different\narchitectural choices and two fingerprint processing tasks demonstrate\neffectiveness of the proposed framework.",
    "descriptor": "\nComments: IJCNN 2021 (Accepted)\n",
    "authors": [
      "Indu Joshi",
      "Ayush Utkarsh",
      "Riya Kothari",
      "Vinod K Kurmi",
      "Antitza Dantcheva",
      "Sumantra Dutta Roy",
      "Prem Kumar Kalra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01248"
  },
  {
    "id": "arXiv:2107.01250",
    "title": "Linear Probing Revisited: Tombstones Mark the Death of Primary  Clustering",
    "abstract": "First introduced in 1954, linear probing is one of the oldest data structures\nin computer science, and due to its unrivaled data locality, it continues to be\none of the fastest hash tables in practice. It is widely believed and taught,\nhowever, that linear probing should never be used at high load factors; this is\nbecause primary-clustering effects cause insertions at load factor $1 - 1 /x$\nto take expected time $\\Theta(x^2)$ (rather than the ideal $\\Theta(x)$). The\ndangers of primary clustering, first discovered by Knuth in 1963, have been\ntaught to generations of computer scientists, and have influenced the design of\nsome of many widely used hash tables.\nWe show that primary clustering is not a foregone conclusion. We demonstrate\nthat small design decisions in how deletions are implemented have dramatic\neffects on the asymptotic performance of insertions, so that, even if a hash\ntable operates continuously at a load factor $1 - \\Theta(1/x)$, the expected\namortized cost per operation is $\\tilde{O}(x)$. This is because tombstones\ncreated by deletions actually cause an anti-clustering effect that combats\nprimary clustering.\nWe also present a new variant of linear probing (which we call graveyard\nhashing) that completely eliminates primary clustering on \\emph{any} sequence\nof operations: if, when an operation is performed, the current load factor is\n$1 - 1/x$ for some $x$, then the expected cost of the operation is $O(x)$. One\ncorollary is that, in the external-memory model with a data blocks of size $B$,\ngraveyard hashing offers the following remarkable guarantee: at any load factor\n$1 - 1/x$ satisfying $x = o(B)$, graveyard hashing achieves $1 + o(1)$ expected\nblock transfers per operation. Past external-memory hash tables have only been\nable to offer a $1 + o(1)$ guarantee when the block size $B$ is at least\n$\\Omega(x^2)$.",
    "descriptor": "",
    "authors": [
      "Michael A. Bender",
      "Bradley C. Kuszmaul",
      "William Kuszmaul"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.01250"
  },
  {
    "id": "arXiv:2107.01253",
    "title": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate  Modeling Optimization",
    "abstract": "The pipeline optimization problem in machine learning requires simultaneous\noptimization of pipeline structures and parameter adaptation of their elements.\nHaving an elegant way to express these structures can help lessen the\ncomplexity in the management and analysis of their performances together with\nthe different choices of optimization strategies. With these issues in mind, we\ncreated the AMLP toolkit which facilitates the creation and evaluation of\ncomplex machine learning pipeline structures using simple expressions. We use\nAMLP to find optimal pipeline signatures, datamine them, and use these\ndatamined features to speed-up learning and prediction. We formulated a\ntwo-stage pipeline optimization with surrogate modeling in AMLP which\noutperforms other AutoML approaches with a 4-hour time budget in less than 5\nminutes of AMLP computation time.",
    "descriptor": "",
    "authors": [
      "Paulito P. Palmes",
      "Akihiro Kishimoto",
      "Radu Marinescu",
      "Parikshit Ram",
      "Elizabeth Daly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01253"
  },
  {
    "id": "arXiv:2107.01259",
    "title": "Accelerating Kinodynamic RRT* Through Dimensionality Reduction",
    "abstract": "Sampling-based motion planning algorithms such as RRT* are well-known for\ntheir ability to quickly find an initial solution and then converge to the\noptimal solution asymptotically. However, the convergence rate can be slow for\nhighdimensional planning problems, particularly for dynamical systems where the\nsampling space is not just the configuration space but the full state space. In\nthis paper, we introduce the idea of using a partial-final-state-free (PFF)\noptimal controller in kinodynamic RRT* [1] to reduce the dimensionality of the\nsampling space. Instead of sampling the full state space, the proposed\naccelerated kinodynamic RRT*, called Kino-RRT*, only samples part of the state\nspace, while the rest of the states are selected by the PFF optimal controller.\nWe also propose a delayed and intermittent update of the optimal arrival time\nof all the edges in the RRT* tree to decrease the computation complexity of the\nalgorithm. We tested the proposed algorithm using 4-D and 10-D state-space\nlinear systems and showed that Kino-RRT* converges much faster than the\nkinodynamic RRT* algorithm.",
    "descriptor": "",
    "authors": [
      "Dongliang Zheng",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01259"
  },
  {
    "id": "arXiv:2107.01264",
    "title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds  for Episodic Reinforcement Learning",
    "abstract": "We provide improved gap-dependent regret bounds for reinforcement learning in\nfinite episodic Markov decision processes. Compared to prior work, our bounds\ndepend on alternative definitions of gaps. These definitions are based on the\ninsight that, in order to achieve a favorable regret, an algorithm does not\nneed to learn how to behave optimally in states that are not reached by an\noptimal policy. We prove tighter upper regret bounds for optimistic algorithms\nand accompany them with new information-theoretic lower bounds for a large\nclass of MDPs. Our results show that optimistic algorithms can not achieve the\ninformation-theoretic lower bounds even in deterministic MDPs unless there is a\nunique optimal policy.",
    "descriptor": "",
    "authors": [
      "Christoph Dann",
      "Teodor V. Marinov",
      "Mehryar Mohri",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01264"
  },
  {
    "id": "arXiv:2107.01272",
    "title": "Physics-Guided Deep Learning for Dynamical Systems: A survey",
    "abstract": "Modeling complex physical dynamics is a fundamental task in science and\nengineering. Traditional physics-based models are interpretable but rely on\nrigid assumptions. And the direct numerical approximation is usually\ncomputationally intensive, requiring significant computational resources and\nexpertise. While deep learning (DL) provides novel alternatives for efficiently\nrecognizing complex patterns and emulating nonlinear dynamics, it does not\nnecessarily obey the governing laws of physical systems, nor do they generalize\nwell across different systems. Thus, the study of physics-guided DL emerged and\nhas gained great progress. It aims to take the best from both physics-based\nmodeling and state-of-the-art DL models to better solve scientific problems. In\nthis paper, we provide a structured overview of existing methodologies of\nintegrating prior physical knowledge or physics-based modeling into DL and\ndiscuss the emerging opportunities.",
    "descriptor": "",
    "authors": [
      "Rui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01272"
  },
  {
    "id": "arXiv:2107.01273",
    "title": "Visual Time Series Forecasting: An Image-driven Approach",
    "abstract": "In this work, we address time-series forecasting as a computer vision task.\nWe capture input data as an image and train a model to produce the subsequent\nimage. This approach results in predicting distributions as opposed to\npointwise values. To assess the robustness and quality of our approach, we\nexamine various datasets and multiple evaluation metrics. Our experiments show\nthat our forecasting tool is effective for cyclic data but somewhat less for\nirregular data such as stock prices. Importantly, when using image-based\nevaluation metrics, we find our method to outperform various baselines,\nincluding ARIMA, and a numerical variation of our deep learning approach.",
    "descriptor": "",
    "authors": [
      "Naftali Cohen",
      "Srijan Sood",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2107.01273"
  },
  {
    "id": "arXiv:2107.01277",
    "title": "Non-Comparative Fairness for Human-Auditing and Its Relation to  Traditional Fairness Notions",
    "abstract": "Bias evaluation in machine-learning based services (MLS) based on traditional\nalgorithmic fairness notions that rely on comparative principles is practically\ndifficult, making it necessary to rely on human auditor feedback. However, in\nspite of taking rigorous training on various comparative fairness notions,\nhuman auditors are known to disagree on various aspects of fairness notions in\npractice, making it difficult to collect reliable feedback. This paper offers a\nparadigm shift to the domain of algorithmic fairness via proposing a new\nfairness notion based on the principle of non-comparative justice. In contrary\nto traditional fairness notions where the outcomes of two individuals/groups\nare compared, our proposed notion compares the MLS' outcome with a desired\noutcome for each input. This desired outcome naturally describes a human\nauditor's expectation, and can be easily used to evaluate MLS on crowd-auditing\nplatforms. We show that any MLS can be deemed fair from the perspective of\ncomparative fairness (be it in terms of individual fairness, statistical\nparity, equal opportunity or calibration) if it is non-comparatively fair with\nrespect to a fair auditor. We also show that the converse holds true in the\ncontext of individual fairness. Given that such an evaluation relies on the\ntrustworthiness of the auditor, we also present an approach to identify fair\nand reliable auditors by estimating their biases with respect to a given set of\nsensitive attributes, as well as quantify the uncertainty in the estimation of\nbiases within a given MLS. Furthermore, all of the above results are also\nvalidated on COMPAS, German credit and Adult Census Income datasets.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2009.04383\n",
    "authors": [
      "Mukund Telukunta",
      "Venkata Sriram Siddhardh Nadendla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.01277"
  },
  {
    "id": "arXiv:2107.01280",
    "title": "Targeted Muscle Effort Distribution with Exercise Robots: Trajectory and  Resistance Effects",
    "abstract": "The objective of this work is to relate muscle effort distributions to the\ntrajectory and resistance settings of a robotic exercise and rehabilitation\nmachine. Muscular effort distribution, representing the participation of each\nmuscle in the training activity, was measured with electromyography sensors\n(EMG) and defined as the individual activation divided by the total muscle\ngroup activation. A four degrees-of-freedom robot and its impedance control\nsystem are used to create advanced exercise protocols whereby the user is asked\nto follow a path against the machine's neutral path and resistance. In this\nwork, the robot establishes a zero-effort circular path, and the subject is\nasked to follow an elliptical trajectory. The control system produces a\nuser-defined stiffness between the deviations from the neutral path and the\ntorque applied by the subject. The trajectory and resistance settings used in\nthe experiments were the orientation of the ellipse and a stiffness parameter.\nMultiple combinations of these parameters were used to measure their effects on\nthe muscle effort distribution. An artificial neural network (ANN) used part of\nthe data for training the model. Then, the accuracy of the model was evaluated\nusing the rest of the data. The results show how the precision of the model is\nlost over time. These outcomes show the complexity of the muscle dynamics for\nlong-term estimations suggesting the existence of time-varying dynamics\npossibly associated with fatigue.",
    "descriptor": "",
    "authors": [
      "Humberto De las Casas",
      "Santino Bianco",
      "Hanz Richter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01280"
  },
  {
    "id": "arXiv:2107.01281",
    "title": "Prescient teleoperation of humanoid robots",
    "abstract": "Humanoid robots could be versatile and intuitive human avatars that operate\nremotely in inaccessible places: the robot could reproduce in the remote\nlocation the movements of an operator equipped with a wearable motion capture\ndevice while sending visual feedback to the operator. While substantial\nprogress has been made on transferring (\"retargeting\") human motions to\nhumanoid robots, a major problem preventing the deployment of such systems in\nreal applications is the presence of communication delays between the human\ninput and the feedback from the robot: even a few hundred milliseconds of delay\ncan irreversibly disturb the operator, let alone a few seconds. To overcome\nthese delays, we introduce a system in which a humanoid robot executes commands\nbefore it actually receives them, so that the visual feedback appears to be\nsynchronized to the operator, whereas the robot executed the commands in the\npast. To do so, the robot continuously predicts future commands by querying a\nmachine learning model that is trained on past trajectories and conditioned on\nthe last received commands. In our experiments, an operator was able to\nsuccessfully control a humanoid robot (32 degrees of freedom) with stochastic\ndelays up to 2 seconds in several whole-body manipulation tasks, including\nreaching different targets, picking up, and placing a box at distinct\nlocations.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Luigi Penco",
      "Jean-Baptiste Mouret",
      "Serena Ivaldi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01281"
  },
  {
    "id": "arXiv:2107.01284",
    "title": "A Novel Disaster Image Dataset and Characteristics Analysis using  Attention Model",
    "abstract": "The advancement of deep learning technology has enabled us to develop systems\nthat outperform any other classification technique. However, success of any\nempirical system depends on the quality and diversity of the data available to\ntrain the proposed system. In this research, we have carefully accumulated a\nrelatively challenging dataset that contains images collected from various\nsources for three different disasters: fire, water and land. Besides this, we\nhave also collected images for various damaged infrastructure due to natural or\nman made calamities and damaged human due to war or accidents. We have also\naccumulated image data for a class named non-damage that contains images with\nno such disaster or sign of damage in them. There are 13,720 manually annotated\nimages in this dataset, each image is annotated by three individuals. We are\nalso providing discriminating image class information annotated manually with\nbounding box for a set of 200 test images. Images are collected from different\nnews portals, social media, and standard datasets made available by other\nresearchers. A three layer attention model (TLAM) is trained and average five\nfold validation accuracy of 95.88% is achieved. Moreover, on the 200 unseen\ntest images this accuracy is 96.48%. We also generate and compare attention\nmaps for these test images to determine the characteristics of the trained\nattention model. Our dataset is available at\nhttps://niloy193.github.io/Disaster-Dataset",
    "descriptor": "\nComments: ICPR 2020\n",
    "authors": [
      "Fahim Faisal Niloy",
      "Arif",
      "Abu Bakar Siddik Nayem",
      "Anis Sarker",
      "Ovi Paul",
      "M. Ashraful Amin",
      "Amin Ahsan Ali",
      "Moinul Islam Zaber",
      "AKM Mahbubur Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01284"
  },
  {
    "id": "arXiv:2107.01288",
    "title": "Breaking Barriers in Robotic Soft Tissue Surgery: Conditional Autonomous  Intestinal Anastomosis",
    "abstract": "Autonomous robotic surgery has the potential to provide efficacy, safety, and\nconsistency independent of individual surgeons skill and experience. Autonomous\nsoft-tissue surgery in unstructured and deformable environments is especially\nchallenging as it necessitates intricate imaging, tissue tracking and surgical\nplanning techniques, as well as a precise execution via highly adaptable\ncontrol strategies. In the laparoscopic setting, soft-tissue surgery is even\nmore challenging due to the need for high maneuverability and repeatability\nunder motion and vision constraints. We demonstrate the first robotic\nlaparoscopic soft tissue surgery with a level of autonomy of 3 out of 5, which\nallows the operator to select among autonomously generated surgical plans while\nthe robot executes a wide range of tasks independently. We also demonstrate the\nfirst in vivo autonomous robotic laparoscopic surgery via intestinal\nanastomosis on porcine models. We compared the criteria including needle\nplacement corrections, suture spacing, suture bite size, completion time, lumen\npatency, and leak pressure between the developed system, manual laparoscopic\nsurgery, and robot-assisted surgery (RAS). The ex vivo results indicate that\nour system outperforms expert surgeons and RAS techniques in terms of\nconsistency and accuracy, and it leads to a remarkable anastomosis quality in\nliving pigs. These results demonstrate that surgical robots exhibiting high\nlevels of autonomy have the potential to improve consistency, patient outcomes,\nand access to a standard surgical technique.",
    "descriptor": "",
    "authors": [
      "H. Saeidi",
      "J. D. Opfermann",
      "M. Kam",
      "S. Wei",
      "S. Leonard",
      "M. H. Hsieh",
      "J. U. Kang",
      "A. Krieger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01288"
  },
  {
    "id": "arXiv:2107.01290",
    "title": "Error estimates for semi-discrete finite element approximations for a  moving boundary problem capturing the penetration of diffusants into rubber",
    "abstract": "We study a semi-discrete finite element approximation of weak solutions to a\nmoving boundary problem that models the diffusion of solvent into rubber. We\nreport on both a priori and a posteriori error estimates for the mass\nconcentration of the diffusants and respectively for the position of the moving\nboundary. Our working techniques include integral and energy-based estimates\nfor a nonlinear parabolic problem posed in a transformed fixed domain combined\nwith a suitable use of the interpolation-trace inequality to handle the\ninterface terms. Numerical illustrations of our FEM approximations are within\nthe experimental range and show good agreement with our theoretical\ninvestigation.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Surendra Nepal",
      "Yosief Wondmagegne",
      "Adrian Muntean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01290"
  },
  {
    "id": "arXiv:2107.01292",
    "title": "Hierarchical Planning for Dynamic Resource Allocation in Smart and  Connected Communities",
    "abstract": "Resource allocation under uncertainty is a classical problem in city-scale\ncyber-physical systems. Consider emergency response as an example; urban\nplanners and first responders optimize the location of ambulances to minimize\nexpected response times to incidents such as road accidents. Typically, such\nproblems deal with sequential decision-making under uncertainty and can be\nmodeled as Markov (or semi-Markov) decision processes. The goal of the\ndecision-maker is to learn a mapping from states to actions that can maximize\nexpected rewards. While online, offline, and decentralized approaches have been\nproposed to tackle such problems, scalability remains a challenge for\nreal-world use-cases. We present a general approach to hierarchical planning\nthat leverages structure in city-level CPS problems for resource allocation. We\nuse emergency response as a case study and show how a large resource allocation\nproblem can be split into smaller problems. We then use Monte-Carlo planning\nfor solving the smaller problems and managing the interaction between them.\nFinally, we use data from Nashville, Tennessee, a major metropolitan area in\nthe United States, to validate our approach. Our experiments show that the\nproposed approach outperforms state-of-the-art approaches used in the field of\nemergency response.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.13300\n",
    "authors": [
      "Geoffrey Pettet",
      "Ayan Mukhopadhyay",
      "Mykel J. Kochenderfer",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.01292"
  },
  {
    "id": "arXiv:2107.01294",
    "title": "Scarecrow: A Framework for Scrutinizing Machine Text",
    "abstract": "Modern neural text generation systems can produce remarkably fluent and\ngrammatical texts. While earlier language models suffered from repetition and\nsyntactic errors, the errors made by contemporary models are often semantic,\nnarrative, or discourse failures.\nTo facilitate research of these complex error types, we introduce a new\nstructured, crowdsourced error annotation schema called Scarecrow. The error\ncategories used in Scarecrow -- such as redundancy, commonsense errors, and\nincoherence -- were identified by combining expert analysis with several pilot\nrounds of ontology-free crowd annotation to arrive at a schema which covers the\nerror phenomena found in real machine generated text.\nWe use Scarecrow to collect 13k annotations of 1.3k human and machine\ngenerate paragraphs of English language news text, amounting to over 41k spans\neach labeled with its error category, severity, a natural language explanation,\nand antecedent span (where relevant). We collect annotations for text generated\nby state-of-the-art systems with varying known performance levels, from GPT-2\nSmall through the largest GPT-3. We isolate several factors for detailed\nanalysis, including parameter count, training data, and decoding technique. Our\nresults show both expected and surprising differences across these settings.\nThese findings demonstrate the value of Scarecrow annotations in the assessment\nof current and future text generation systems. We release our complete\nannotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.",
    "descriptor": "\nComments: The project webpage is at this https URL\n",
    "authors": [
      "Yao Dou",
      "Maxwell Forbes",
      "Rik Koncel-Kedziorski",
      "Noah A.Smith",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01294"
  },
  {
    "id": "arXiv:2107.01295",
    "title": "Dependent Type Systems as Macros",
    "abstract": "We present Turnstile+, a high-level, macros-based metaDSL for building\ndependently typed languages. With it, programmers may rapidly prototype and\niterate on the design of new dependently typed features and extensions. Or they\nmay create entirely new DSLs whose dependent type \"power\" is tailored to a\nspecific domain. Our framework's support of language-oriented programming also\nmakes it suitable for experimenting with systems of interacting components,\ne.g., a proof assistant and its companion DSLs. This paper explains the\nimplementation details of Turnstile+, as well as how it may be used to create a\nwide-variety of dependently typed languages, from a lightweight one with\nindexed types, to a full spectrum proof assistant, complete with a tactic\nsystem and extensions for features like sized types and SMT interaction.",
    "descriptor": "",
    "authors": [
      "Stephen Chang",
      "Michael Ballantyne",
      "Milo Turner",
      "William J. Bowman"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.01295"
  },
  {
    "id": "arXiv:2107.01296",
    "title": "Subspace Clustering Based Analysis of Neural Networks",
    "abstract": "Tools to analyze the latent space of deep neural networks provide a step\ntowards better understanding them. In this work, we motivate sparse subspace\nclustering (SSC) with an aim to learn affinity graphs from the latent structure\nof a given neural network layer trained over a set of inputs. We then use tools\nfrom Community Detection to quantify structures present in the input. These\nexperiments reveal that as we go deeper in a network, inputs tend to have an\nincreasing affinity to other inputs of the same class. Subsequently, we utilise\nmatrix similarity measures to perform layer-wise comparisons between affinity\ngraphs. In doing so we first demonstrate that when comparing a given layer\ncurrently under training to its final state, the shallower the layer of the\nnetwork, the quicker it is to converge than the deeper layers. When performing\na pairwise analysis of the entire network architecture, we observe that, as the\nnetwork increases in size, it reorganises from a state where each layer is\nmoderately similar to its neighbours, to a state where layers within a block\nhave high similarity than to layers in other blocks. Finally, we analyze the\nlearned affinity graphs of the final convolutional layer of the network and\ndemonstrate how an input's local neighbourhood affects its classification by\nthe network.",
    "descriptor": "",
    "authors": [
      "Uday Singh Saini",
      "Pravallika Devineni",
      "Evangelos E. Papalexakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01296"
  },
  {
    "id": "arXiv:2107.01301",
    "title": "Implicit Greedy Rank Learning in Autoencoders via Overparameterized  Linear Networks",
    "abstract": "Deep linear networks trained with gradient descent yield low rank solutions,\nas is typically studied in matrix factorization. In this paper, we take a step\nfurther and analyze implicit rank regularization in autoencoders. We show\ngreedy learning of low-rank latent codes induced by a linear sub-network at the\nautoencoder bottleneck. We further propose orthogonal initialization and\nprincipled learning rate adjustment to mitigate sensitivity of training\ndynamics to spectral prior and linear depth. With linear autoencoders on\nsynthetic data, our method converges stably to ground-truth latent code rank.\nWith nonlinear autoencoders, our method converges to latent ranks optimal for\ndownstream classification and image sampling.",
    "descriptor": "",
    "authors": [
      "Shih-Yu Sun",
      "Vimal Thilak",
      "Etai Littwin",
      "Omid Saremi",
      "Joshua M. Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01301"
  },
  {
    "id": "arXiv:2107.01302",
    "title": "DiSH-trend: Intervention Modeling Simulator That Accounts for Trend  Influences",
    "abstract": "Simulation on directed graphs is an important method for understanding the\ndynamics in the systems where connectivity graphs contain cycles. Discrete\nStochastic Heterogeneous Simulator (DiSH) is one of the simulation tools with\nwide application, which uses regulator values to calculate state updates of\nregulated elements. Here we present a new simulation approach DiSH-trend which\nalso takes into account the trends in regulating elements. We demonstrate the\nfeatures of trend-based regulation, as well as hybrid regulation, which is a\ncombination of the trend- and level-based approaches. The modeling capabilities\nare demonstrated on a small toy model, showcasing different functionalities.\nReal-world capabilities are demonstrated on a larger network model of food\ninsecurity in the Ethiopian region Oromia. Adding trend-based regulation to\nmodels results in increased modeling flexibility, and hybrid regulation\nimproves qualitative dynamic behavior prediction. With appropriate data,\nDiSH-trend becomes a powerful tool for exploring intervention strategies.",
    "descriptor": "\nComments: 12 pages, 5 figures, to be published in Proceedings of the 2021 Winter Simulation Conference\n",
    "authors": [
      "Stefan Andjelkovic",
      "Natasa Miskov-Zivanov"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01302"
  },
  {
    "id": "arXiv:2107.01309",
    "title": "Towards safe human-to-robot handovers of unknown containers",
    "abstract": "Safe human-to-robot handovers of unknown objects require accurate estimation\nof hand poses and object properties, such as shape, trajectory, and weight.\nAccurately estimating these properties requires the use of scanned 3D object\nmodels or expensive equipment, such as motion capture systems and markers, or\nboth. However, testing handover algorithms with robots may be dangerous for the\nhuman and, when the object is an open container with liquids, for the robot. In\nthis paper, we propose a real-to-simulation framework to develop safe\nhuman-to-robot handovers with estimations of the physical properties of unknown\ncups or drinking glasses and estimations of the human hands from videos of a\nhuman manipulating the container. We complete the handover in simulation, and\nwe estimate a region that is not occluded by the hand of the human holding the\ncontainer. We also quantify the safeness of the human and object in simulation.\nWe validate the framework using public recordings of containers manipulated\nbefore a handover and show the safeness of the handover when using noisy\nestimates from a range of perceptual algorithms.",
    "descriptor": "\nComments: Camera-ready version. Paper accepted to RO-MAN 2021. 8 pages, 8 figures, 1 table\n",
    "authors": [
      "Yik Lung Pang",
      "Alessio Xompero",
      "Changjae Oh",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01309"
  },
  {
    "id": "arXiv:2107.01310",
    "title": "Clustering of Time Series Data with Prior Geographical Information",
    "abstract": "Time Series data are broadly studied in various domains of transportation\nsystems. Traffic data area challenging example of spatio-temporal data, as it\nis multi-variate time series with high correlations in spatial and temporal\nneighborhoods. Spatio-temporal clustering of traffic flow data find similar\npatterns in both spatial and temporal domain, where it provides better\ncapability for analyzing a transportation network, and improving related\nmachine learning models, such as traffic flow prediction and anomaly detection.\nIn this paper, we propose a spatio-temporal clustering model, where it clusters\ntime series data based on spatial and temporal contexts. We propose a variation\nof a Deep Embedded Clustering(DEC) model for finding spatio-temporal clusters.\nThe proposed model Spatial-DEC (S-DEC) use prior geographical information in\nbuilding latent feature representations. We also define evaluation metrics for\nspatio-temporal clusters. Not only do the obtained clusters have better\ntemporal similarity when evaluated using DTW distance, but also the clusters\nbetter represents spatial connectivity and dis-connectivity. We use traffic\nflow data obtained by PeMS in our analysis. The results show that the proposed\nSpatial-DEC can find more desired spatio-temporal clusters.",
    "descriptor": "",
    "authors": [
      "Reza Asadi",
      "Amelia Regan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01310"
  },
  {
    "id": "arXiv:2107.01319",
    "title": "Learning Hierarchical Graph Neural Networks for Image Clustering",
    "abstract": "We propose a hierarchical graph neural network (GNN) model that learns how to\ncluster a set of images into an unknown number of identities using a training\nset of images annotated with labels belonging to a disjoint set of identities.\nOur hierarchical GNN uses a novel approach to merge connected components\npredicted at each level of the hierarchy to form a new graph at the next level.\nUnlike fully unsupervised hierarchical clustering, the choice of grouping and\ncomplexity criteria stems naturally from supervision in the training set. The\nresulting method, Hi-LANDER, achieves an average of 54% improvement in F-score\nand 8% increase in Normalized Mutual Information (NMI) relative to current\nGNN-based clustering algorithms. Additionally, state-of-the-art GNN-based\nmethods rely on separate models to predict linkage probabilities and node\ndensities as intermediate steps of the clustering process. In contrast, our\nunified framework achieves a seven-fold decrease in computational cost. We\nrelease our training and inference code at\nhttps://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.",
    "descriptor": "",
    "authors": [
      "Yifan Xing",
      "Tong He",
      "Tianjun Xiao",
      "Yongxin Wang",
      "Yuanjun Xiong",
      "Wei Xia",
      "David Wipf Paul",
      "Zheng Zhang",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01319"
  },
  {
    "id": "arXiv:2107.01321",
    "title": "Row-sensing Templates: A Generic 3D Sensor-based Approach to Robot  Localization with Respect to Orchard Row Centerlines",
    "abstract": "Accurate robot localization relative to orchard row centerlines is essential\nfor autonomous guidance where satellite signals are often obstructed by\nfoliage. Existing sensor-based approaches rely on various features extracted\nfrom images and point clouds. However, any selected features are not available\nconsistently, because the visual and geometrical characteristics of orchard\nrows change drastically when tree types, growth stages, canopy management\npractices, seasons, and weather conditions change. In this work, we introduce a\nnovel localization method that doesn't rely on features; instead, it relies on\nthe concept of a row-sensing template, which is the expected observation of a\n3D sensor traveling in an orchard row, when the sensor is anywhere on the\ncenterline and perfectly aligned with it. First, the template is built using a\nfew measurements, provided that the sensor's true pose with respect to the\ncenterline is available. Then, during navigation, the best pose estimate (and\nits confidence) is estimated by maximizing the match between the template and\nthe sensed point cloud using particle-filtering. The method can adapt to\nvarious orchards and conditions by re-building the template. Experiments were\nperformed in a vineyard, and in an orchard in different seasons. Results showed\nthat the lateral mean absolute error (MAE) was less than 3.6% of the row width,\nand the heading MAE was less than 1.72 degrees. Localization was robust, as\nerrors didn't increase when less than 75% of measurement points were missing.\nThe results indicate that template-based localization can provide a generic\napproach for accurate and robust localization in real-world orchards.",
    "descriptor": "",
    "authors": [
      "Zhenghao Fei",
      "Stavros Vougioukas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01321"
  },
  {
    "id": "arXiv:2107.01322",
    "title": "Physical Layer Security for NOMA-Enabled Multi-Access Edge Computing  Wireless Networks",
    "abstract": "Multi-access edge computing (MEC) has been regarded as a promising technique\nfor enhancing computation capabilities for wireless networks. In this paper, we\nstudy physical layer security in an MEC system where multiple users offload\npartial of their computation tasks to a base station simultaneously based on\nnon-orthogonal multiple access (NOMA), in the presence of a malicious\neavesdropper. Secrecy outage probability is adopted to measure the security\nperformance of the computation offloading against eavesdropping attacks. We aim\nto minimize the sum energy consumption of all the users, subject to constraints\nin terms of the secrecy offloading rate, the secrecy outage probability, and\nthe decoding order of NOMA. Although the original optimization problem is\nnon-convex and challenging to solve, we put forward an efficient algorithm\nbased on sequential convex approximation and penalty dual decomposition.\nNumerical results are eventually provided to validate the convergence of the\nproposed algorithm and its superior energy efficiency with secrecy\nrequirements.",
    "descriptor": "\nComments: 6 pages, 3 figures, and Accepted to present at IEEE/CIC ICCC 2021\n",
    "authors": [
      "Yating Wen",
      "Tong-Xing Zheng",
      "Yongxia Tong",
      "Hao-Wen Liu",
      "Xin Chen",
      "Pengcheng Mu",
      "Hui-Ming Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01322"
  },
  {
    "id": "arXiv:2107.01325",
    "title": "Fair Decision Rules for Binary Classification",
    "abstract": "In recent years, machine learning has begun automating decision making in\nfields as varied as college admissions, credit lending, and criminal\nsentencing. The socially sensitive nature of some of these applications\ntogether with increasing regulatory constraints has necessitated the need for\nalgorithms that are both fair and interpretable. In this paper we consider the\nproblem of building Boolean rule sets in disjunctive normal form (DNF), an\ninterpretable model for binary classification, subject to fairness constraints.\nWe formulate the problem as an integer program that maximizes classification\naccuracy with explicit constraints on two different measures of classification\nparity: equality of opportunity and equalized odds. Column generation\nframework, with a novel formulation, is used to efficiently search over\nexponentially many possible rules. When combined with faster heuristics, our\nmethod can deal with large data-sets. Compared to other fair and interpretable\nclassifiers, our method is able to find rule sets that meet stricter notions of\nfairness with a modest trade-off in accuracy.",
    "descriptor": "",
    "authors": [
      "Connor Lawless",
      "Oktay Gunluk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.01325"
  },
  {
    "id": "arXiv:2107.01326",
    "title": "SHORING: Design Provable Conditional High-Order Interaction Network via  Symbolic Testing",
    "abstract": "Deep learning provides a promising way to extract effective representations\nfrom raw data in an end-to-end fashion and has proven its effectiveness in\nvarious domains such as computer vision, natural language processing, etc.\nHowever, in domains such as content/product recommendation and risk management,\nwhere sequence of event data is the most used raw data form and experts derived\nfeatures are more commonly used, deep learning models struggle to dominate the\ngame. In this paper, we propose a symbolic testing framework that helps to\nanswer the question of what kinds of expert-derived features could be learned\nby a neural network. Inspired by this testing framework, we introduce an\nefficient architecture named SHORING, which contains two components:\n\\textit{event network} and \\textit{sequence network}. The \\textit{event}\nnetwork learns arbitrarily yet efficiently high-order \\textit{event-level}\nembeddings via a provable reparameterization trick, the \\textit{sequence}\nnetwork aggregates from sequence of \\textit{event-level} embeddings. We argue\nthat SHORING is capable of learning certain standard symbolic expressions which\nthe standard multi-head self-attention network fails to learn, and conduct\ncomprehensive experiments and ablation studies on four synthetic datasets and\nthree real-world datasets. The results show that SHORING empirically\noutperforms the state-of-the-art methods.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Hui Li",
      "Xing Fu",
      "Ruofan Wu",
      "Jinyu Xu",
      "Kai Xiao",
      "Xiaofu Chang",
      "Weiqiang Wang",
      "Shuai Chen",
      "Leilei Shi",
      "Tao Xiong",
      "Yuan Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01326"
  },
  {
    "id": "arXiv:2107.01329",
    "title": "The HCCL Speaker Verification System for Far-Field Speaker Verification  Challenge",
    "abstract": "This paper describes the systems submitted by team HCCL to the Far-Field\nSpeaker Verification Challenge. Our previous work in the AIshell Speaker\nVerification Challenge 2019 shows that the powerful modeling abilities of\nNeural Network architectures can provide exceptional performance for this kind\nof task. Therefore, in this challenge, we focus on constructing deep Neural\nNetwork architectures based on TDNN, Resnet and Res2net blocks. Most of the\ndeveloped systems consist of Neural Network embeddings are applied with PLDA\nbackend. Firstly, the speed perturbation method is applied to augment data and\nsignificant performance improvements are achieved. Then, we explore the use of\nAMsoftmax loss function and propose to join a CE-loss branch when we train\nmodel using AMsoftmax loss. In addition, the impact of score normalization on\nperformance is also investigated. The final system, a fusion of four systems,\nachieves minDCF 0.5342, EER 5.05\\% on task1 eval set, and achieves minDCF\n0.5193, EER 5.47\\% on task3 eval set.",
    "descriptor": "",
    "authors": [
      "Zhuo Li",
      "Ce Fang",
      "Runqiu Xiao",
      "Zhigao Chen",
      "Wenchao Wang",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01329"
  },
  {
    "id": "arXiv:2107.01330",
    "title": "SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial  Network",
    "abstract": "Single-pixel imaging is a novel imaging scheme that has gained popularity due\nto its huge computational gain and potential for a low-cost alternative to\nimaging beyond the visible spectrum. The traditional reconstruction methods\nstruggle to produce a clear recovery when one limits the number of illumination\npatterns from a spatial light modulator. As a remedy, several\ndeep-learning-based solutions have been proposed which lack good generalization\nability due to the architectural setup and loss functions. In this paper, we\npropose a generative adversarial network-based reconstruction framework for\nsingle-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images\nwith 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This\nfacilitates much faster reconstruction making our method suitable for\nsingle-pixel video. Furthermore, our ResNet-like architecture for the generator\nleads to useful representation learning that allows us to reconstruct\ncompletely unseen objects. The experimental results demonstrate that SPI-GAN\nachieves significant performance gain, e.g. near 3dB PSNR gain, over the\ncurrent state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01330"
  },
  {
    "id": "arXiv:2107.01335",
    "title": "Average-Case Communication Complexity of Statistical Problems",
    "abstract": "We study statistical problems, such as planted clique, its variants, and\nsparse principal component analysis in the context of average-case\ncommunication complexity. Our motivation is to understand the\nstatistical-computational trade-offs in streaming, sketching, and query-based\nmodels. Communication complexity is the main tool for proving lower bounds in\nthese models, yet many prior results do not hold in an average-case setting. We\nprovide a general reduction method that preserves the input distribution for\nproblems involving a random graph or matrix with planted structure. Then, we\nderive two-party and multi-party communication lower bounds for detecting or\nfinding planted cliques, bipartite cliques, and related problems. As a\nconsequence, we obtain new bounds on the query complexity in the edge-probe,\nvector-matrix-vector, matrix-vector, linear sketching, and\n$\\mathbb{F}_2$-sketching models. Many of these results are nearly tight, and we\nuse our techniques to provide simple proofs of some known lower bounds for the\nedge-probe model.",
    "descriptor": "\nComments: 28 pages. Conference on Learning Theory (COLT), 2021\n",
    "authors": [
      "Cyrus Rashtchian",
      "David P. Woodruff",
      "Peng Ye",
      "Hanlin Zhu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01335"
  },
  {
    "id": "arXiv:2107.01343",
    "title": "Short-term probabilistic photovoltaic power forecast based on deep  convolutional long short-term memory network and kernel density estimation",
    "abstract": "Solar energy is a clean and renewable energy. Photovoltaic (PV) power is an\nimportant way to utilize solar energy. Accurate PV power forecast is crucial to\nthe large-scale application of PV power and the stability of electricity grid.\nThis paper proposes a novel method for short-term photovoltaic power forecast\nusing deep convolutional long short-term memory (ConvLSTM) network and kernel\ndensity estimation (KDE). In the proposed method, ConvLSTM is used to forecast\nthe future photovoltaic power and KDE is used for estimating the joint\nprobabilistic density function and giving the probabilistic confidence\ninterval. Experiments in an actual photovoltaic power station verify the\neffectiveness of the proposed method. Comparison experiments with convolutional\nneural network (CNN) and long short-term memory network (LSTM)shows that\nConvLSTM can combine the advantages of both CNN and LSTM and significantly\noutperform CNN and LSTM in terms of forecast accuracy. Through further\ncomparison with other five conventional methods including multilayer perceptron\n(MLP), support vector regression (SVR), extreme learning machine (ELM),\nclassification and regression tree (CART) and gradient boosting decision tree\n(GBDT), ConvLSTM can significantly improve the forecast accuracy by more than\n20% for most of the five methods and the superiorities of ConvLSTM are further\nverified.",
    "descriptor": "",
    "authors": [
      "Mingliang Bai",
      "Xinyu Zhao",
      "Zhenhua Long",
      "Jinfu Liu",
      "Daren Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01343"
  },
  {
    "id": "arXiv:2107.01345",
    "title": "Cluster Representatives Selection in Non-Metric Spaces for Nearest  Prototype Classification",
    "abstract": "The nearest prototype classification is a less computationally intensive\nreplacement for the $k$-NN method, especially when large datasets are\nconsidered. In metric spaces, centroids are often used as prototypes to\nrepresent whole clusters. The selection of cluster prototypes in non-metric\nspaces is more challenging as the idea of computing centroids is not directly\napplicable.\nIn this paper, we present CRS, a novel method for selecting a small yet\nrepresentative subset of objects as a cluster prototype. Memory and\ncomputationally efficient selection of representatives is enabled by leveraging\nthe similarity graph representation of each cluster created by the NN-Descent\nalgorithm. CRS can be used in an arbitrary metric or non-metric space because\nof the graph-based approach, which requires only a pairwise similarity measure.\nAs we demonstrate in the experimental evaluation, our method outperforms the\nstate of the art techniques on multiple datasets from different domains.",
    "descriptor": "",
    "authors": [
      "Jaroslav Hlav\u00e1\u010d",
      "Martin Kopp",
      "Jan Kohout"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01345"
  },
  {
    "id": "arXiv:2107.01347",
    "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning  Agents: a Case Study",
    "abstract": "In this work we theoretically and experimentally analyze Multi-Agent\nAdvantage Actor-Critic (MA2C) and Independent Advantage Actor-Critic (IA2C),\ntwo recently proposed multi-agent reinforcement learning methods that can be\napplied to control traffic signals in urban areas. The two methods differ in\ntheir use of a reward calculated locally or globally and in the management of\nagents' communication. We analyze the methods theoretically with the framework\nprovided by non-Markov decision processes, which provides useful insights in\nthe analysis of the algorithms. Moreover, we analyze the efficacy and the\nrobustness of the methods experimentally by testing them in two traffic areas\nin the Bologna (Italy) area, simulated by SUMO, a software tool. The\nexperimental results indicate that MA2C achieves the best performance in the\nmajority of cases, outperforms the alternative method considered, and displays\nsufficient stability during the learning process.",
    "descriptor": "\nComments: 41 pages, 16 figures\n",
    "authors": [
      "Paolo Fazzini",
      "Isaac Wheeler",
      "Francesco Petracchini"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01347"
  },
  {
    "id": "arXiv:2107.01348",
    "title": "Examining average and discounted reward optimality criteria in  reinforcement learning",
    "abstract": "In reinforcement learning (RL), the goal is to obtain an optimal policy, for\nwhich the optimality criterion is fundamentally important. Two major optimality\ncriteria are average and discounted rewards, where the later is typically\nconsidered as an approximation to the former. While the discounted reward is\nmore popular, it is problematic to apply in environments that have no natural\nnotion of discounting. This motivates us to revisit a) the progression of\noptimality criteria in dynamic programming, b) justification for and\ncomplication of an artificial discount factor, and c) benefits of directly\nmaximizing the average reward. Our contributions include a thorough examination\nof the relationship between average and discounted rewards, as well as a\ndiscussion of their pros and cons in RL. We emphasize that average-reward RL\nmethods possess the ingredient and mechanism for developing the general\ndiscounting-free optimality criterion (Veinott, 1969) in RL.",
    "descriptor": "\nComments: 14 pages, 3 figures, 10-page main content\n",
    "authors": [
      "Vektor Dewanto",
      "Marcus Gallagher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01348"
  },
  {
    "id": "arXiv:2107.01349",
    "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single  Neural Network",
    "abstract": "Continual learning has been a major problem in the deep learning community,\nwhere the main challenge is how to effectively learn a series of newly arriving\ntasks without forgetting the knowledge of previous tasks. Initiated by Learning\nwithout Forgetting (LwF), many of the existing works report that knowledge\ndistillation is effective to preserve the previous knowledge, and hence they\ncommonly use a soft label for the old task, namely a knowledge distillation\n(KD) loss, together with a class label for the new task, namely a cross entropy\n(CE) loss, to form a composite loss for a single neural network. However, this\napproach suffers from learning the knowledge by a CE loss as a KD loss often\nmore strongly influences the objective function when they are in a competitive\nsituation within a single network. This could be a critical problem\nparticularly in a class incremental scenario, where the knowledge across tasks\nas well as within the new task, both of which can only be acquired by a CE\nloss, is essentially learned due to the existence of a unified classifier. In\nthis paper, we propose a novel continual learning method, called\nSplit-and-Bridge, which can successfully address the above problem by partially\nsplitting a neural network into two partitions for training the new task\nseparated from the old task and re-connecting them for learning the knowledge\nacross tasks. In our thorough experimental analysis, our Split-and-Bridge\nmethod outperforms the state-of-the-art competitors in KD-based continual\nlearning.",
    "descriptor": "\nComments: In AAAI-2021\n",
    "authors": [
      "Jong-Yeong Kim",
      "Dong-Wan Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01349"
  },
  {
    "id": "arXiv:2107.01350",
    "title": "Engineering MultiQueues: Fast Relaxed Concurrent Priority Queues",
    "abstract": "Priority queues with parallel access are an attractive data structure for\napplications like prioritized online scheduling, discrete event simulation, or\ngreedy algorithms. However, a classical priority queue constitutes a severe\nbottleneck in this context, leading to very small throughput. Hence, there has\nbeen significant interest in concurrent priority queues with relaxed semantics.\nWe investigate the complementary quality criteria rank error (how close are\ndeleted elements to the global minimum) and delay (for each element x, how many\nelements with lower priority are deleted before x). In this paper, we introduce\nMultiQueues as a natural approach to relaxed priority queues based on multiple\nsequential priority queues. Their naturally high theoretical scalability is\nfurther enhanced by using three orthogonal ways of batching operations on the\nsequential queues. Experiments indicate that MultiQueues present a very good\nperformance-quality tradeoff and considerably outperform competing approaches\nin at least one of these aspects. We employ a seemingly paradoxical technique\nof \"wait-free locking\" that might be of more general interest to convert\nsequential data structures to relaxed concurrent data structures.",
    "descriptor": "",
    "authors": [
      "Marvin Williams",
      "Peter Sanders",
      "Roman Dementiev"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01350"
  },
  {
    "id": "arXiv:2107.01353",
    "title": "Spatiotemporal convolutional network for time-series prediction and  causal inference",
    "abstract": "Making predictions in a robust way is not easy for nonlinear systems. In this\nwork, a neural network computing framework, i.e., a spatiotemporal\nconvolutional network (STCN), was developed to efficiently and accurately\nrender a multistep-ahead prediction of a time series by employing a\nspatial-temporal information (STI) transformation. The STCN combines the\nadvantages of both the temporal convolutional network (TCN) and the STI\nequation, which maps the high-dimensional/spatial data to the future temporal\nvalues of a target variable, thus naturally providing the prediction of the\ntarget variable. From the observed variables, the STCN also infers the causal\nfactors of the target variable in the sense of Granger causality, which are in\nturn selected as effective spatial information to improve the prediction\nrobustness. The STCN was successfully applied to both benchmark systems and\nreal-world datasets, all of which show superior and robust performance in\nmultistep-ahead prediction, even when the data were perturbed by noise. From\nboth theoretical and computational viewpoints, the STCN has great potential in\npractical applications in artificial intelligence (AI) or machine learning\nfields as a model-free method based only on the observed data, and also opens a\nnew way to explore the observed high-dimensional data in a dynamical manner for\nmachine learning.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Hao Peng",
      "Pei Chen",
      "Rui Liu",
      "Luonan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01353"
  },
  {
    "id": "arXiv:2107.01354",
    "title": "Pool of Experts: Realtime Querying Specialized Knowledge in Massive  Neural Networks",
    "abstract": "In spite of the great success of deep learning technologies, training and\ndelivery of a practically serviceable model is still a highly time-consuming\nprocess. Furthermore, a resulting model is usually too generic and heavyweight,\nand hence essentially goes through another expensive model compression phase to\nfit in a resource-limited device like embedded systems. Inspired by the fact\nthat a machine learning task specifically requested by mobile users is often\nmuch simpler than it is supported by a massive generic model, this paper\nproposes a framework, called Pool of Experts (PoE), that instantly builds a\nlightweight and task-specific model without any training process. For a\nrealtime model querying service, PoE first extracts a pool of primitive\ncomponents, called experts, from a well-trained and sufficiently generic\nnetwork by exploiting a novel conditional knowledge distillation method, and\nthen performs our train-free knowledge consolidation to quickly combine\nnecessary experts into a lightweight network for a target task. Thanks to this\ntrain-free property, in our thorough empirical study, PoE can build a fairly\naccurate yet compact model in a realtime manner, whereas it takes a few minutes\nper query for the other training methods to achieve a similar level of the\naccuracy.",
    "descriptor": "\nComments: In SIGMOD/PODS 2021\n",
    "authors": [
      "Hakbin Kim",
      "Dong-Wan Choi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01354"
  },
  {
    "id": "arXiv:2107.01355",
    "title": "Adaptive stratified sampling for non-smooth problems",
    "abstract": "Science and engineering problems subject to uncertainty are frequently both\ncomputationally expensive and feature nonsmooth parameter dependence, making\nstandard Monte Carlo too slow, and excluding efficient use of accelerated\nuncertainty quantification methods relying on strict smoothness assumptions. To\nremedy these challenges, we propose an adaptive stratification method suitable\nfor nonsmooth problems and with significantly reduced variance compared to\nMonte Carlo sampling. The stratification is iteratively refined and samples are\nadded sequentially to satisfy an allocation criterion combining the benefits of\nproportional and optimal sampling. Theoretical estimates are provided for the\nexpected performance and probability of failure to correctly estimate essential\nstatistics. We devise a practical adaptive stratification method with strata of\nthe same kind of geometrical shapes, cost-effective refinement satisfying a\ngreedy variance reduction criterion. Numerical experiments corroborate the\ntheoretical findings and exhibit speedups of up to three orders of magnitude\ncompared to standard Monte Carlo sampling.",
    "descriptor": "\nComments: 36 pages, 12 figures\n",
    "authors": [
      "Per Pettersson",
      "Sebastian Krumscheid"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01355"
  },
  {
    "id": "arXiv:2107.01358",
    "title": "CInC Flow: Characterizable Invertible 3x3 Convolution",
    "abstract": "Normalizing flows are an essential alternative to GANs for generative\nmodelling, which can be optimized directly on the maximum likelihood of the\ndataset. They also allow computation of the exact latent vector corresponding\nto an image since they are composed of invertible transformations. However, the\nrequirement of invertibility of the transformation prevents standard and\nexpressive neural network models such as CNNs from being directly used.\nEmergent convolutions were proposed to construct an invertible 3$\\times$3 CNN\nlayer using a pair of masked CNN layers, making them inefficient. We study\nconditions such that 3$\\times$3 CNNs are invertible, allowing them to construct\nexpressive normalizing flows. We derive necessary and sufficient conditions on\na padded CNN for it to be invertible. Our conditions for invertibility are\nsimple, can easily be maintained during the training process. Since we require\nonly a single CNN layer for every effective invertible CNN layer, our approach\nis more efficient than emerging convolutions. We also proposed a coupling\nmethod, Quad-coupling. We benchmark our approach and show similar performance\nresults to emergent convolutions while improving the model's efficiency.",
    "descriptor": "\nComments: Accepted for the 4th Workshop on Tractable Probabilistic Modeling,(UAI 2021)\n",
    "authors": [
      "Sandeep Nagar",
      "Marius Dufraisse",
      "Girish Varma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01358"
  },
  {
    "id": "arXiv:2107.01360",
    "title": "Supervised Off-Policy Ranking",
    "abstract": "Off-policy evaluation (OPE) leverages data generated by other policies to\nevaluate a target policy. Previous OPE methods mainly focus on precisely\nestimating the true performance of a policy. We observe that in many\napplications, (1) the end goal of OPE is to compare two or multiple candidate\npolicies and choose a good one, which is actually a much simpler task than\nevaluating their true performance; and (2) there are usually multiple policies\nthat have been deployed in real-world systems and thus whose true performance\nis known through serving real users. Inspired by the two observations, in this\nwork, we define a new problem, supervised off-policy ranking (SOPR), which aims\nto rank a set of new/target policies based on supervised learning by leveraging\noff-policy data and policies with known performance. We further propose a\nmethod for supervised off-policy ranking that learns a policy scoring model by\ncorrectly ranking training policies with known performance rather than\nestimating their precise performance. Our method leverages logged states and\npolicies to learn a Transformer based model that maps offline interaction data\nincluding logged states and the actions taken by a target policy on these\nstates to a score. Experiments on different games, datasets, training policy\nsets, and test policy sets show that our method outperforms strong baseline OPE\nmethods in terms of both rank correlation and performance gap between the truly\nbest and the best of the ranked top three policies. Furthermore, our method is\nmore stable than baseline methods.",
    "descriptor": "",
    "authors": [
      "Yue Jin",
      "Yue Zhang",
      "Tao Qin",
      "Xudong Zhang",
      "Jian Yuan",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01360"
  },
  {
    "id": "arXiv:2107.01361",
    "title": "Sensor-invariant Fingerprint ROI Segmentation Using Recurrent  Adversarial Learning",
    "abstract": "A fingerprint region of interest (roi) segmentation algorithm is designed to\nseparate the foreground fingerprint from the background noise. All the learning\nbased state-of-the-art fingerprint roi segmentation algorithms proposed in the\nliterature are benchmarked on scenarios when both training and testing\ndatabases consist of fingerprint images acquired from the same sensors.\nHowever, when testing is conducted on a different sensor, the segmentation\nperformance obtained is often unsatisfactory. As a result, every time a new\nfingerprint sensor is used for testing, the fingerprint roi segmentation model\nneeds to be re-trained with the fingerprint image acquired from the new sensor\nand its corresponding manually marked ROI. Manually marking fingerprint ROI is\nexpensive because firstly, it is time consuming and more importantly, requires\ndomain expertise. In order to save the human effort in generating annotations\nrequired by state-of-the-art, we propose a fingerprint roi segmentation model\nwhich aligns the features of fingerprint images derived from the unseen sensor\nsuch that they are similar to the ones obtained from the fingerprints whose\nground truth roi masks are available for training. Specifically, we propose a\nrecurrent adversarial learning based feature alignment network that helps the\nfingerprint roi segmentation model to learn sensor-invariant features.\nConsequently, sensor-invariant features learnt by the proposed roi segmentation\nmodel help it to achieve improved segmentation performance on fingerprints\nacquired from the new sensor. Experiments on publicly available FVC databases\ndemonstrate the efficacy of the proposed work.",
    "descriptor": "\nComments: IJCNN 2021 (Accepted)\n",
    "authors": [
      "Indu Joshi",
      "Ayush Utkarsh",
      "Riya Kothari",
      "Vinod K Kurmi",
      "Antitza Dantcheva",
      "Sumantra Dutta Roy",
      "Prem Kumar Kalra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01361"
  },
  {
    "id": "arXiv:2107.01366",
    "title": "Can Transformers Jump Around Right in Natural Language? Assessing  Performance Transfer from SCAN",
    "abstract": "Despite their practical success, modern seq2seq architectures are unable to\ngeneralize systematically on several SCAN tasks. Hence, it is not clear if\nSCAN-style compositional generalization is useful in realistic NLP tasks. In\nthis work, we study the benefit that such compositionality brings about to\nseveral machine translation tasks. We present several focused modifications of\nTransformer that greatly improve generalization capabilities on SCAN and select\none that remains on par with a vanilla Transformer on a standard machine\ntranslation (MT) task. Next, we study its performance in low-resource settings\nand on a newly introduced distribution-shifted English-French translation task.\nOverall, we find that improvements of a SCAN-capable model do not directly\ntransfer to the resource-rich MT setup. In contrast, in the low-resource setup,\ngeneral modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a\nvanilla Transformer. Similarly, an improvement of 14% in an accuracy-based\nmetric is achieved in the introduced compositional English-French translation\ntask. This provides experimental evidence that the compositional generalization\nassessed in SCAN is particularly useful in resource-starved and domain-shifted\nscenarios.",
    "descriptor": "",
    "authors": [
      "Rahma Chaabouni",
      "Roberto Dess\u00ec",
      "Eugene Kharitonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01366"
  },
  {
    "id": "arXiv:2107.01369",
    "title": "On convergence of numerical solutions for the compressible MHD system  with exactly divergence-free magnetic field",
    "abstract": "We study a general convergence theory for the numerical solutions of\ncompressible viscous and electrically conducting fluids with a focus on\nnumerical schemes that preserve the divergence free property of magnetic field\nexactly. Our strategy utilizes the recent concepts of dissipative weak\nsolutions and consistent approximations. First, we show the dissipative\nweak--strong uniqueness principle, meaning a dissipative weak solution\ncoincides with a classical solution as long as they emanate from the same\ninitial data. Next, we show the convergence of consistent approximation towards\nthe dissipative weak solution and thus the classical solution. Upon\ninterpreting the consistent approximation as the stability and consistency of\nsuitable numerical solutions we have established a generalized Lax equivalence\ntheory: convergence $\\Longleftrightarrow$ stability and consistency. Further,\nto illustrate the application of this theory, we propose two novel mixed finite\nvolume-finite element methods with exact divergence-free magnetic field.\nFinally, by showing solutions of these two schemes are consistent\napproximations, we conclude their convergence towards the dissipative weak\nsolution and the classical solution.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.07253\n",
    "authors": [
      "Yang Li",
      "Bangwei She"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01369"
  },
  {
    "id": "arXiv:2107.01372",
    "title": "Learning Debiased Representation via Disentangled Feature Augmentation",
    "abstract": "Image classification models tend to make decisions based on peripheral\nattributes of data items that have strong correlation with a target variable\n(i.e., dataset bias). These biased models suffer from the poor generalization\ncapability when evaluated on unbiased datasets. Existing approaches for\ndebiasing often identify and emphasize those samples with no such correlation\n(i.e., bias-conflicting) without defining the bias type in advance. However,\nsuch bias-conflicting samples are significantly scarce in biased datasets,\nlimiting the debiasing capability of these approaches. This paper first\npresents an empirical analysis revealing that training with \"diverse\"\nbias-conflicting samples beyond a given training set is crucial for debiasing\nas well as the generalization capability. Based on this observation, we propose\na novel feature-level data augmentation technique in order to synthesize\ndiverse bias-conflicting samples. To this end, our method learns the\ndisentangled representation of (1) the intrinsic attributes (i.e., those\ninherently defining a certain class) and (2) bias attributes (i.e., peripheral\nattributes causing the bias), from a large number of bias-aligned samples, the\nbias attributes of which have strong correlation with the target variable.\nUsing the disentangled representation, we synthesize bias-conflicting samples\nthat contain the diverse intrinsic attributes of bias-aligned samples by\nswapping their latent features. By utilizing these diversified bias-conflicting\nfeatures during the training, our approach achieves superior classification\naccuracy and debiasing results against the existing baselines on both synthetic\nas well as real-world datasets.",
    "descriptor": "",
    "authors": [
      "Eungyeup Kim",
      "Jungsoo Lee",
      "Juyoung Lee",
      "Jihyeon Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01372"
  },
  {
    "id": "arXiv:2107.01378",
    "title": "Efficient Vision Transformers via Fine-Grained Manifold Distillation",
    "abstract": "This paper studies the model compression problem of vision transformers.\nBenefit from the self-attention module, transformer architectures have shown\nextraordinary performance on many computer vision tasks. Although the network\nperformance is boosted, transformers are often required more computational\nresources including memory usage and the inference complexity. Compared with\nthe existing knowledge distillation approaches, we propose to excavate useful\ninformation from the teacher transformer through the relationship between\nimages and the divided patches. We then explore an efficient fine-grained\nmanifold distillation approach that simultaneously calculates cross-images,\ncross-patch, and random-selected manifolds in teacher and student models.\nExperimental results conducted on several benchmarks demonstrate the\nsuperiority of the proposed algorithm for distilling portable transformer\nmodels with higher performance. For example, our approach achieves 75.06% Top-1\naccuracy on the ImageNet-1k dataset for training a DeiT-Tiny model, which\noutperforms other ViT distillation methods.",
    "descriptor": "",
    "authors": [
      "Ding Jia",
      "Kai Han",
      "Yunhe Wang",
      "Yehui Tang",
      "Jianyuan Guo",
      "Chao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01378"
  },
  {
    "id": "arXiv:2107.01381",
    "title": "Recent Advancements In Distributed System Communications",
    "abstract": "Overheads in Operating System kernel network stacks and sockets have been\nhindering OSes from managing networking operations efficiently for years.\nMoreover, when building Remote Procedure Calls over TCP, certain TCP features\ndo not match the needs of RPCs, imposing additional overheads. These issues\ndegrade the performance of distributed systems, which rely on fast\ncommunications between machines to be able to serve a large number of client\nrequests with low latency and high throughput. The purpose of this literature\nsurvey is to look into recent proposals in research literature that aim to\novercome these issues. The survey investigates research literature published\nbetween 2010-2020, in order to include important advancements during the most\nrecent decade at the time of writing. The proposals found in papers have been\ncategorized into hardware-based and software-based approaches. The former\nrequire specialized hardware to offer high communications performance. The\nlatter are implemented in software and don't rely on specialized hardware or\nrequire only certain hardware features. Furthermore, the proposals where also\nclassified according to whether they implement kernel bypass, to avoid using\nthe Operating System kernel network stack, or not. The hardware-based\napproaches examined here are RDMA, programmable Network Interface Controllers\n(NIC) and System-on-a-Chip (SoC), while the software-based approaches include\noptimized socket implementations and RPC frameworks, as well as user space\nnetworking.",
    "descriptor": "\nComments: Literature Survey - MSc Computer Science Project : 21 pages, 2 figures\n",
    "authors": [
      "Ioannis Argyroulis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.01381"
  },
  {
    "id": "arXiv:2107.01382",
    "title": "Too Expensive to Attack: Enlarge the Attack Expense through Joint  Defense at the Edge",
    "abstract": "The distributed denial of service (DDoS) attack is detrimental to businesses\nand individuals as people are heavily relying on the Internet. Due to\nremarkable profits, crackers favor DDoS as cybersecurity weapons to attack a\nvictim. Even worse, edge servers are more vulnerable. Current solutions lack\nadequate consideration to the expense of attackers and inter-defender\ncollaborations. Hence, we revisit the DDoS attack and defense, clarifying the\nadvantages and disadvantages of both parties. We further propose a joint\ndefense framework to defeat attackers by incurring a significant increment of\nrequired bots and enlarging attack expenses. The quantitative evaluation and\nexperimental assessment showcase that such expense can surge up to thousands of\ntimes. The skyrocket of expenses leads to heavy loss to the cracker, which\nprevents further attacks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.00236\n",
    "authors": [
      "Jianhua Li",
      "Ximeng Liu",
      "Jiong JIn",
      "Shui Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01382"
  },
  {
    "id": "arXiv:2107.01384",
    "title": "ATC: an Advanced Tucker Compression library for multidimensional data",
    "abstract": "We present ATC, a C++ library for advanced Tucker-based compression of\nmultidimensional numerical data, based on the sequentially truncated\nhigher-order singular value decomposition (ST-HOSVD) and bit plane truncation.\nSeveral techniques are proposed to improve compression rate, speed, memory\nusage and error control. First, a hybrid truncation scheme is described which\ncombines Tucker rank truncation and TTHRESH quantization [Ballester-Ripoll et\nal., IEEE Trans. Visual. Comput. Graph., 2020]. We derive a novel expression to\napproximate the error of truncated Tucker decompositions in the case of core\nand factor perturbations. Furthermore, a Householder-reflector-based approach\nis proposed to compress the orthogonal Tucker factors. Certain key improvements\nto the quantization procedure are also discussed. Moreover, particular\nimplementation aspects are described, such as ST-HOSVD procedure using only a\nsingle transposition. We also discuss several usability features of ATC,\nincluding the presence of multiple interfaces, extensive data type support and\nintegrated downsampling of the decompressed data. Numerical results show that\nATC maintains state-of-the-art Tucker compression rates, while providing\naverage speed-ups of 2.6-3.6 and halving memory usage. Furthermore, our\ncompressor provides precise error control, only deviating 1.4% from the\nrequested error on average. Finally, ATC often achieves significantly higher\ncompression than non-Tucker-based compressors in the high-error domain.",
    "descriptor": "\nComments: The ATC software is publicly available at the following repository: this https URL\n",
    "authors": [
      "Wouter Baert",
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2107.01384"
  },
  {
    "id": "arXiv:2107.01385",
    "title": "Harnessing Context for Budget-Limited Crowdsensing with Massive  Uncertain Workers",
    "abstract": "Crowdsensing is an emerging paradigm of ubiquitous sensing, through which a\ncrowd of workers are recruited to perform sensing tasks collaboratively.\nAlthough it has stimulated many applications, an open fundamental problem is\nhow to select among a massive number of workers to perform a given sensing task\nunder a limited budget. Nevertheless, due to the proliferation of smart devices\nequipped with various sensors, it is very difficult to profile the workers in\nterms of sensing ability. Although the uncertainties of the workers can be\naddressed by standard Combinatorial Multi-Armed Bandit (CMAB) framework through\na trade-off between exploration and exploitation, we do not have sufficient\nallowance to directly explore and exploit the workers under the limited budget.\nFurthermore, since the sensor devices usually have quite limited resources, the\nworkers may have bounded capabilities to perform the sensing task for only few\ntimes, which further restricts our opportunities to learn the uncertainty. To\naddress the above issues, we propose a Context-Aware Worker Selection (CAWS)\nalgorithm in this paper. By leveraging the correlation between the context\ninformation of the workers and their sensing abilities, CAWS aims at maximizing\nthe expected total sensing revenue efficiently with both budget constraint and\ncapacity constraints respected, even when the number of the uncertain workers\nare massive. The efficacy of CAWS can be verified by rigorous theoretical\nanalysis and extensive experiments.",
    "descriptor": "",
    "authors": [
      "Feng Li",
      "Jichao Zhao",
      "Dongxiao Yu",
      "Xiuzhen Cheng",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.01385"
  },
  {
    "id": "arXiv:2107.01386",
    "title": "An asymptotically compatible probabilistic collocation method for  randomly heterogeneous nonlocal problems",
    "abstract": "In this paper we present an asymptotically compatible meshfree method for\nsolving nonlocal equations with random coefficients, describing diffusion in\nheterogeneous media. In particular, the random diffusivity coefficient is\ndescribed by a finite-dimensional random variable or a truncated combination of\nrandom variables with the Karhunen-Lo\\`{e}ve decomposition, then a\nprobabilistic collocation method (PCM) with sparse grids is employed to sample\nthe stochastic process. On each sample, the deterministic nonlocal diffusion\nproblem is discretized with an optimization-based meshfree quadrature rule. We\npresent rigorous analysis for the proposed scheme and demonstrate convergence\nfor a number of benchmark problems, showing that it sustains the asymptotic\ncompatibility spatially and achieves an algebraic or sub-exponential\nconvergence rate in the random coefficients space as the number of collocation\npoints grows. Finally, to validate the applicability of this approach we\nconsider a randomly heterogeneous nonlocal problem with a given spatial\ncorrelation structure, demonstrating that the proposed PCM approach achieves\nsubstantial speed-up compared to conventional Monte Carlo simulations.",
    "descriptor": "",
    "authors": [
      "Yiming Fan",
      "Xiaochuan Tian",
      "Xiu Yang",
      "Xingjie Li",
      "Clayton Webster",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01386"
  },
  {
    "id": "arXiv:2107.01390",
    "title": "Memory and attention in deep learning",
    "abstract": "Intelligence necessitates memory. Without memory, humans fail to perform\nvarious nontrivial tasks such as reading novels, playing games or solving\nmaths. As the ultimate goal of machine learning is to derive intelligent\nsystems that learn and act automatically just like human, memory construction\nfor machine is inevitable. Artificial neural networks model neurons and\nsynapses in the brain by interconnecting computational units via weights, which\nis a typical class of machine learning algorithms that resembles memory\nstructure. Their descendants with more complicated modeling techniques (a.k.a\ndeep learning) have been successfully applied to many practical problems and\ndemonstrated the importance of memory in the learning process of machinery\nsystems. Recent progresses on modeling memory in deep learning have revolved\naround external memory constructions, which are highly inspired by\ncomputational Turing models and biological neuronal systems. Attention\nmechanisms are derived to support acquisition and retention operations on the\nexternal memory. Despite the lack of theoretical foundations, these approaches\nhave shown promises to help machinery systems reach a higher level of\nintelligence. The aim of this thesis is to advance the understanding on memory\nand attention in deep learning. Its contributions include: (i) presenting a\ncollection of taxonomies for memory, (ii) constructing new memory-augmented\nneural networks (MANNs) that support multiple control and memory units, (iii)\nintroducing variability via memory in sequential generative models, (iv)\nsearching for optimal writing operations to maximise the memorisation capacity\nin slot-based memory networks, and (v) simulating the Universal Turing Machine\nvia Neural Stored-program Memory-a new kind of external memory for neural\nnetworks.",
    "descriptor": "\nComments: PHD Thesis\n",
    "authors": [
      "Hung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01390"
  },
  {
    "id": "arXiv:2107.01391",
    "title": "Recombinant Sort: N-Dimensional Cartesian Spaced Algorithm Designed from  Synergetic Combination of Hashing, Bucket, Counting and Radix Sort",
    "abstract": "Sorting is an essential operation which is widely used and is fundamental to\nsome very basic day to day utilities like searches, databases, social networks\nand much more. Optimizing this basic operation in terms of complexity as well\nas efficiency is cardinal. Optimization is achieved with respect to space and\ntime complexities of the algorithm. In this paper, a novel left-field\nN-dimensional cartesian spaced sorting method is proposed by combining the best\ncharacteristics of bucket sort, counting sort and radix sort, in addition to\nemploying hashing and dynamic programming for making the method more efficient.\nComparison between the proposed sorting method and various existing sorting\nmethods like bubble sort, insertion sort, selection sort, merge sort, heap\nsort, counting sort, bucket sort, etc., has also been performed. The time\ncomplexity of the proposed model is estimated to be linear i.e. O(n) for the\nbest, average and worst cases, which is better than every sorting algorithm\nintroduced till date.",
    "descriptor": "",
    "authors": [
      "Peeyush Kumar",
      "Ayushe Gangal",
      "Sunita Kumari",
      "Sunita Tiwari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01391"
  },
  {
    "id": "arXiv:2107.01396",
    "title": "Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations  with Perceptual Similarity",
    "abstract": "Deep neural networks (DNNs) have been found to be vulnerable to adversarial\nexamples. Adversarial examples are malicious images with visually imperceptible\nperturbations. While these carefully crafted perturbations restricted with\ntight $\\Lp$ norm bounds are small, they are still easily perceivable by humans.\nThese perturbations also have limited success rates when attacking black-box\nmodels or models with defenses like noise reduction filters. To solve these\nproblems, we propose Demiguise Attack, crafting ``unrestricted'' perturbations\nwith Perceptual Similarity. Specifically, we can create powerful and\nphotorealistic adversarial examples by manipulating semantic information based\non Perceptual Similarity. Adversarial examples we generate are friendly to the\nhuman visual system (HVS), although the perturbations are of large magnitudes.\nWe extend widely-used attacks with our approach, enhancing adversarial\neffectiveness impressively while contributing to imperceptibility. Extensive\nexperiments show that the proposed method not only outperforms various\nstate-of-the-art attacks in terms of fooling rate, transferability, and\nrobustness against defenses but can also improve attacks effectively. In\naddition, we also notice that our implementation can simulate illumination and\ncontrast changes that occur in real-world scenarios, which will contribute to\nexposing the blind spots of DNNs.",
    "descriptor": "",
    "authors": [
      "Yajie Wang",
      "Shangbo Wu",
      "Wenyi Jiang",
      "Shengang Hao",
      "Yu-an Tan",
      "Quanxin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01396"
  },
  {
    "id": "arXiv:2107.01398",
    "title": "TrafPy: Benchmarking Data Centre Network Systems",
    "abstract": "Benchmarking is commonly used in research fields such as computer\narchitecture design and machine learning as a powerful paradigm for rigorously\nassessing, comparing, and developing novel technologies. However, the data\ncentre networking community lacks a standard open-access benchmark. This is\ncurtailing the community's understanding of existing systems and hindering the\nability with which novel technologies can be developed, compared, and tested.\nWe present TrafPy; an open-access framework for generating both realistic and\ncustom data centre network traffic traces. TrafPy is compatible with any\nsimulation, emulation, or experimentation environment, and can be used for\nstandardised benchmarking and for investigating the properties and limitations\nof network systems such as schedulers, switches, routers, and resource\nmanagers. To demonstrate the efficacy of TrafPy, we use it to conduct a\nthorough investigation into the sensitivity of 4 canonical scheduling\nalgorithms (shortest remaining processing time, fair share, first fit, and\nrandom) to varying traffic trace characteristics. We show how the fundamental\nscheduler performance insights revealed by these tests translate to 4 realistic\ndata centre network types; University, Private Enterprise, Commercial Cloud,\nand Social Media Cloud. We then draw conclusions as to which types of\nscheduling policies are most suited to which types of network load conditions\nand traffic characteristics, leading to the possibility of application-informed\ndecision making at the design stage and new dynamically adaptable scheduling\npolicies. TrafPy is open-sourced via GitHub and all data associated with this\nmanuscript via RDR.",
    "descriptor": "\nComments: 20 content pages, 34 appendix pages, 28 tables, 21 figures\n",
    "authors": [
      "Christopher W. F. Parsonson",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.01398"
  },
  {
    "id": "arXiv:2107.01400",
    "title": "Exact Backpropagation in Binary Weighted Networks with Group Weight  Transformations",
    "abstract": "Quantization based model compression serves as high performing and fast\napproach for inference that yields highly compressed models compared to their\nfull-precision floating point counterparts. The most extreme quantization is a\n1-bit representation of parameters such that they have only two possible\nvalues, typically -1(0) or +1. Models that constrain the weights to binary\nvalues enable efficient implementation of the ubiquitous dot product by\nadditions only without requiring floating point multiplications which is\nbeneficial for resources constrained inference. The main contribution of this\nwork is the introduction of a method to smooth the combinatorial problem of\ndetermining a binary vector of weights to minimize the expected loss for a\ngiven objective by means of empirical risk minimization with backpropagation.\nThis is achieved by approximating a multivariate binary state over the weights\nutilizing a deterministic and differentiable transformation of real-valued\ncontinuous parameters. The proposed method adds little overhead in training,\ncan be readily applied without any substantial modifications to the original\narchitecture, does not introduce additional saturating non-linearities or\nauxiliary losses, and does not prohibit applying other methods for binarizing\nthe activations. It is demonstrated that contrary to common assertions made in\nthe literature, binary weighted networks can train well with the same standard\noptimization techniques and similar hyperparameters settings as their\nfull-precision counterparts, namely momentum SGD with large learning rates and\n$L_2$ regularization. The source code is publicly available at\nhttps://bitbucket.org/YanivShu/binary_weighted_networks_public",
    "descriptor": "",
    "authors": [
      "Yaniv Shulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01400"
  },
  {
    "id": "arXiv:2107.01401",
    "title": "Learning from scarce information: using synthetic data to classify Roman  fine ware pottery",
    "abstract": "In this article we consider a version of the challenging problem of learning\nfrom datasets whose size is too limited to allow generalisation beyond the\ntraining set. To address the challenge we propose to use a transfer learning\napproach whereby the model is first trained on a synthetic dataset replicating\nfeatures of the original objects. In this study the objects were smartphone\nphotographs of near-complete Roman terra sigillata pottery vessels from the\ncollection of the Museum of London. Taking the replicated features from\npublished profile drawings of pottery forms allowed the integration of expert\nknowledge into the process through our synthetic data generator. After this\nfirst initial training the model was fine-tuned with data from photographs of\nreal vessels. We show, through exhaustive experiments across several popular\ndeep learning architectures, different test priors, and considering the impact\nof the photograph viewpoint and excessive damage to the vessels, that the\nproposed hybrid approach enables the creation of classifiers with appropriate\ngeneralisation performance. This performance is significantly better than that\nof classifiers trained exclusively on the original data which shows the promise\nof the approach to alleviate the fundamental issue of learning from small\ndatasets.",
    "descriptor": "",
    "authors": [
      "Santos J. N\u00fa\u00f1ez Jare\u00f1o",
      "Dani\u00ebl P. van Helden",
      "Evgeny M. Mirkes",
      "Ivan Y. Tyukin",
      "Penelope M. Allison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01401"
  },
  {
    "id": "arXiv:2107.01402",
    "title": "Cell-Free Massive MIMO-OFDM Transmission over Frequency-Selective Fading  Channels",
    "abstract": "This letter presents and analyzes orthogonal frequency-division multiplexing\n(OFDM)-based multi-carrier transmission for cell-free massive multi-input\nmulti-output (CFmMIMO) over frequency-selective fading channels.\nFrequency-domain conjugate beamforming, pilot assignment, and user-specific\nresource allocation are proposed. CFmMIMO-OFDM is scalable to serve a massive\nnumber of users and is flexible to offer diverse data rates for heterogeneous\napplications.",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Hans Dieter Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01402"
  },
  {
    "id": "arXiv:2107.01404",
    "title": "Impact of Channel Aging on Zero-Forcing Precoding in Cell-Free Massive  MIMO Systems",
    "abstract": "In the context of cell-free massive multi-input multi-output (mMIMO),\nzero-forcing precoding (ZFP) requires the exchange of instantaneous channel\nstate information and precoded data symbols via a fronthaul network. It causes\nconsiderable propagation and processing delays, which degrade performance. This\nletter analyzes the impact of channel aging on the performance of ZFP in\ncell-free mMIMO. The aging effects of not only user mobility but also phase\nnoise are considered. Numerical results in terms of per-user spectral\nefficiency are illustrated.",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Hans Dieter Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01404"
  },
  {
    "id": "arXiv:2107.01405",
    "title": "A Fuzzy Scheduling Strategy for Deadline-Based Workflow Applications in  Uncertain Edge-Cloud Environments",
    "abstract": "Workflow scheduling is critical to performing many practical workflow\napplications. Scheduling based on edge-cloud computing can help addressing the\nhigh complexity of workflow applications, while decreasing the data\ntransmission delay. However, due to the nature of heterogeneous resources in\nedge-cloud environments and the complicated data dependencies between the tasks\nin such a workflow, significant challenges for workflow scheduling remain,\nincluding the selection of an optimal tasks-servers solution from the possible\nnumerous combinations. Existing studies are mainly done subject to rigorous\nconditions without fluctuations, ignoring the fact that workflow scheduling is\ntypically present in uncertain environments. In this study, we focus on\nreducing the execution cost of workflow applications mainly caused by task\ncomputation and data transmission, while satisfying the workflow deadline in\nuncertain edge-cloud environments. The Triangular Fuzzy Numbers (TFNs) are\nadopted to represent task processing time and data transferring time. A\ncost-driven fuzzy scheduling strategy based on an Adaptive Discrete Particle\nSwarm Optimization (ADPSO) algorithm is proposed, which is employed the\noperators of Genetic Algorithm (GA). This strategy introduces the randomly\ntwo-point crossover operator, neighborhood mutation operator, and adaptive\nmultipoint mutation operator of GA to effectively avoid converging on local\noptima. The experimental results show that our strategy can effectively reduce\nthe workflow execution cost in uncertain edge-cloud environments, compared with\nother benchmark solutions.",
    "descriptor": "",
    "authors": [
      "Bing Lin",
      "Chaowei Lin",
      "Xing Chen",
      "Neal N. Xiong",
      "Peisong Hua",
      "Qiang Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01405"
  },
  {
    "id": "arXiv:2107.01407",
    "title": "Where is the Grass Greener? Revisiting Generalized Policy Iteration for  Offline Reinforcement Learning",
    "abstract": "The performance of state-of-the-art baselines in the offline RL regime varies\nwidely over the spectrum of dataset qualities, ranging from \"far-from-optimal\"\nrandom data to \"close-to-optimal\" expert demonstrations. We re-implement these\nunder a fair, unified, and highly factorized framework, and show that when a\ngiven baseline outperforms its competing counterparts on one end of the\nspectrum, it never does on the other end. This consistent trend prevents us\nfrom naming a victor that outperforms the rest across the board. We attribute\nthe asymmetry in performance between the two ends of the quality spectrum to\nthe amount of inductive bias injected into the agent to entice it to posit that\nthe behavior underlying the offline dataset is optimal for the task. The more\nbias is injected, the higher the agent performs, provided the dataset is\nclose-to-optimal. Otherwise, its effect is brutally detrimental. Adopting an\nadvantage-weighted regression template as base, we conduct an investigation\nwhich corroborates that injections of such optimality inductive bias, when not\ndone parsimoniously, makes the agent subpar in the datasets it was dominant as\nsoon as the offline policy is sub-optimal. In an effort to design methods that\nperform well across the whole spectrum, we revisit the generalized policy\niteration scheme for the offline regime, and study the impact of nine distinct\nnewly-introduced proposal distributions over actions, involved in proposed\ngeneralization of the policy evaluation and policy improvement update rules. We\nshow that certain orchestrations strike the right balance and can improve the\nperformance on one end of the spectrum without harming it on the other end.",
    "descriptor": "",
    "authors": [
      "Lionel Blond\u00e9",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01407"
  },
  {
    "id": "arXiv:2107.01410",
    "title": "Maximum Entropy Weighted Independent Set Pooling for Graph Neural  Networks",
    "abstract": "In this paper, we propose a novel pooling layer for graph neural networks\nbased on maximizing the mutual information between the pooled graph and the\ninput graph. Since the maximum mutual information is difficult to compute, we\nemploy the Shannon capacity of a graph as an inductive bias to our pooling\nmethod. More precisely, we show that the input graph to the pooling layer can\nbe viewed as a representation of a noisy communication channel. For such a\nchannel, sending the symbols belonging to an independent set of the graph\nyields a reliable and error-free transmission of information. We show that\nreaching the maximum mutual information is equivalent to finding a maximum\nweight independent set of the graph where the weights convey entropy contents.\nThrough this communication theoretic standpoint, we provide a distinct\nperspective for posing the problem of graph pooling as maximizing the\ninformation transmission rate across a noisy communication channel, implemented\nby a graph neural network. We evaluate our method, referred to as Maximum\nEntropy Weighted Independent Set Pooling (MEWISPool), on graph classification\ntasks and the combinatorial optimization problem of the maximum independent\nset. Empirical results demonstrate that our method achieves the\nstate-of-the-art and competitive results on graph classification tasks and the\nmaximum independent set problem in several benchmark datasets.",
    "descriptor": "\nComments: 21 pages, 12 figures, under review in 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Amirhossein Nouranizadeh",
      "Mohammadjavad Matinkia",
      "Mohammad Rahmati",
      "Reza Safabakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01410"
  },
  {
    "id": "arXiv:2107.01412",
    "title": "Isotonic Data Augmentation for Knowledge Distillation",
    "abstract": "Knowledge distillation uses both real hard labels and soft labels predicted\nby teacher models as supervision. Intuitively, we expect the soft labels and\nhard labels to be concordant w.r.t. their orders of probabilities. However, we\nfound {\\it critical order violations} between hard labels and soft labels in\naugmented samples. For example, for an augmented sample $x=0.7*panda+0.3*cat$,\nwe expect the order of meaningful soft labels to be\n$P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)>P_\\text{soft}(other|x)$. But real\nsoft labels usually violate the order, e.g.\n$P_\\text{soft}(tiger|x)>P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)$. We\nattribute this to the unsatisfactory generalization ability of the teacher,\nwhich leads to the prediction error of augmented samples. Empirically, we found\nthe violations are common and injure the knowledge transfer.In this paper, we\nintroduce order restrictions to data augmentation for knowledge distillation,\nwhich is denoted as isotonic data augmentation (IDA). We use isotonic\nregression (IR) -- a classic technique from statistics -- to eliminate the\norder violations. We show that IDA can be modeled as a tree-structured IR\nproblem. We thereby adapt the classical IRT-BIN algorithm for optimal solutions\nwith $O(c \\log c)$ time complexity, where $c$ is the number of labels. In order\nto further reduce the time complexity, we also \\cwy{propose} a GPU-friendly\napproximation with linear time complexity. We have verified on variant datasets\nand data augmentation techniques that our proposed IDA algorithms effectively\nincreases the accuracy of knowledge distillation by eliminating the rank\nviolations.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Wanyun Cui",
      "Sen Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01412"
  },
  {
    "id": "arXiv:2107.01418",
    "title": "The operator-splitting method for Cahn-Hilliard is stable",
    "abstract": "We prove energy stability of a standard operator-splitting method for the\nCahn-Hilliard equation. We establish uniform bound of Sobolev norms of the\nnumerical solution and convergence of the splitting approximation. This is the\nfirst unconditional energy stability result for the operator-splitting method\nfor the Cahn-Hilliard equation. Our analysis can be extended to many other\nmodels.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Dong Li",
      "Chaoyu Quan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01418"
  },
  {
    "id": "arXiv:2107.01427",
    "title": "Multi-Objective Congestion Control",
    "abstract": "Decades of research on Internet congestion control (CC) has produced a\nplethora of algorithms that optimize for different performance objectives.\nApplications face the challenge of choosing the most suitable algorithm based\non their needs, and it takes tremendous efforts and expertise to customize CC\nalgorithms when new demands emerge. In this paper, we explore a basic question:\ncan we design a single CC algorithm to satisfy different objectives? We propose\nMOCC, the first multi-objective congestion control algorithm that attempts to\naddress this challenge. The core of MOCC is a novel multi-objective\nreinforcement learning framework for CC that can automatically learn the\ncorrelations between different application requirements and the corresponding\noptimal control policies. Under this framework, MOCC further applies transfer\nlearning to transfer the knowledge from past experience to new applications,\nquickly adapting itself to a new objective even if it is unforeseen. We provide\nboth user-space and kernel-space implementation of MOCC. Real-world experiments\nand extensive simulations show that MOCC well supports multi-objective,\ncompeting or outperforming the best existing CC algorithms on individual\nobjectives, and quickly adapting to new applications (e.g., 14.2x faster than\nprior work) without compromising old ones.",
    "descriptor": "",
    "authors": [
      "Yiqing Ma",
      "Han Tian",
      "Xudong Liao",
      "Junxue Zhang",
      "Weiyan Wang",
      "Kai Chen",
      "Xin Jin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.01427"
  },
  {
    "id": "arXiv:2107.01428",
    "title": "Solving Infinite-Domain CSPs Using the Patchwork Property",
    "abstract": "The constraint satisfaction problem (CSP) has important applications in\ncomputer science and AI. In particular, infinite-domain CSPs have been\nintensively used in subareas of AI such as spatio-temporal reasoning. Since\nconstraint satisfaction is a computationally hard problem, much work has been\ndevoted to identifying restricted problems that are efficiently solvable. One\nway of doing this is to restrict the interactions of variables and constraints,\nand a highly successful approach is to bound the treewidth of the underlying\nprimal graph. Bodirsky & Dalmau [J. Comput. System. Sci. 79(1), 2013] and Huang\net al. [Artif. Intell. 195, 2013] proved that CSP$(\\Gamma)$ can be solved in\n$n^{f(w)}$ time (where $n$ is the size of the instance, $w$ is the treewidth of\nthe primal graph and $f$ is a computable function) for certain classes of\nconstraint languages $\\Gamma$. We improve this bound to $f(w) \\cdot n^{O(1)}$,\nwhere the function $f$ only depends on the language $\\Gamma$, for CSPs whose\nbasic relations have the patchwork property. Hence, such problems are\nfixed-parameter tractable and our algorithm is asymptotically faster than the\nprevious ones. Additionally, our approach is not restricted to binary\nconstraints, so it is applicable to a strictly larger class of problems than\nthat of Huang et al. However, there exist natural problems that are covered by\nBodirsky & Dalmau's algorithm but not by ours, and we begin investigating ways\nof generalising our results to larger families of languages. We also analyse\nour algorithm with respect to its running time and show that it is optimal\n(under the Exponential Time Hypothesis) for certain languages such as Allen's\nInterval Algebra.",
    "descriptor": "\nComments: 34 pages, 2 figures. Parts of this article appeared in the proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI 2021)\n",
    "authors": [
      "Konrad K. Dabrowski",
      "Peter Jonsson",
      "Sebastian Ordyniak",
      "George Osipov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01428"
  },
  {
    "id": "arXiv:2107.01431",
    "title": "Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks",
    "abstract": "Previous math word problem solvers following the encoder-decoder paradigm\nfail to explicitly incorporate essential math symbolic constraints, leading to\nunexplainable and unreasonable predictions. Herein, we propose Neural-Symbolic\nSolver (NS-Solver) to explicitly and seamlessly incorporate different levels of\nsymbolic constraints by auxiliary tasks. Our NS-Solver consists of a problem\nreader to encode problems, a programmer to generate symbolic equations, and a\nsymbolic executor to obtain answers. Along with target expression supervision,\nour solver is also optimized via 4 new auxiliary objectives to enforce\ndifferent symbolic reasoning: a) self-supervised number prediction task\npredicting both number quantity and number locations; b) commonsense constant\nprediction task predicting what prior knowledge (e.g. how many legs a chicken\nhas) is required; c) program consistency checker computing the semantic loss\nbetween predicted equation and target equation to ensure reasonable equation\nmapping; d) duality exploiting task exploiting the quasi duality between\nsymbolic equation generation and problem's part-of-speech generation to enhance\nthe understanding ability of a solver. Besides, to provide a more realistic and\nchallenging benchmark for developing a universal and scalable solver, we also\nconstruct a new large-scale MWP benchmark CM17K consisting of 4 kinds of MWPs\n(arithmetic, one-unknown linear, one-unknown non-linear, equation set) with\nmore than 17K samples. Extensive experiments on Math23K and our CM17k\ndemonstrate the superiority of our NS-Solver compared to state-of-the-art\nmethods.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Jinghui Qin",
      "Xiaodan Liang",
      "Yining Hong",
      "Jianheng Tang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01431"
  },
  {
    "id": "arXiv:2107.01435",
    "title": "Drone Detection Using Convolutional Neural Networks",
    "abstract": "In image processing, it is essential to detect and track air targets,\nespecially UAVs. In this paper, we detect the flying drone using a fisheye\ncamera. In the field of diagnosis and classification of objects, there are\nalways many problems that prevent the development of rapid and significant\nprogress in this area. During the previous decades, a couple of advanced\nclassification methods such as convolutional neural networks and support vector\nmachines have been developed. In this study, the drone was detected using three\nmethods of classification of convolutional neural network (CNN), support vector\nmachine (SVM), and nearest neighbor. The outcomes show that CNN, SVM, and\nnearest neighbor have total accuracy of 95%, 88%, and 80%, respectively.\nCompared with other classifiers with the same experimental conditions, the\naccuracy of the convolutional neural network classifier is satisfactory.",
    "descriptor": "\nComments: 5 pages, conference\n",
    "authors": [
      "Fatemeh Mahdavi",
      "Roozbeh Rajabi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01435"
  },
  {
    "id": "arXiv:2107.01438",
    "title": "Corrected trapezoidal rules for singular implicit boundary integrals",
    "abstract": "We present new higher-order quadratures for a family of boundary integral\noperators re-derived using the approach introduced in [Kublik, Tanushev, and\nTsai - J. Comp. Phys. 247: 279-311, 2013]. In this formulation, a boundary\nintegral over a smooth, closed hypersurface is transformed into an equivalent\nvolume integral defined in a sufficiently thin tubular neighborhood of the\nsurface. The volumetric formulation makes it possible to use the simple\ntrapezoidal rule on uniform Cartesian grids and relieves the need to use\nparameterization for developing quadrature. Consequently, typical point\nsingularities in a layer potential extend along the surface's normal lines. We\npropose new higher-order corrections to the trapezoidal rule on the grid nodes\naround the singularities. This correction is based on local decompositions of\nthe singularity and is dependent on the angle of approach to the singularity\nrelative to the surface's principal curvature directions. The proposed\ndecomposition, combined with the volumetric formulation, leads to a special\nquadrature error cancellation.",
    "descriptor": "\nComments: 41 pages with 18 figures\n",
    "authors": [
      "Federico Izzo",
      "Olof Runborg",
      "Richard Tsai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01438"
  },
  {
    "id": "arXiv:2107.01442",
    "title": "Approximate Core Allocations for Multiple Partners Matching Games",
    "abstract": "The multiple partners matching game is a cooperative profit-sharing game,\nwhich generalizes the classic matching game by allowing each player to have\nmore than one partner. The core is one of the most important concepts in\ncooperative game theory, which consists all possible ways of allocating the\ntotal profit of the game among individual players such that the grand coalition\nremains intact. For the multiple partners matching game, the core may be empty\nin general [Deng et al., Algorithmic aspects of the core of combinatorial\noptimization games, Math. Oper. Res., 1999.]; even when the core is non-empty,\nthe core membership problem is intractable in general [Biro et al., The stable\nfixtures problem with payments, Games Econ. Behav., 2018]. Thus we study\napproximate core allocations for the multiple partners matching game, and\nprovide an LP-based mechanism guaranteeing that no coalition is paid less than\n$2/3$ times the profit it makes on its own. Moreover, we show that the factor\n$2/3$ is best possible in general, but can be improved depending on how\nseverely constrained the players are. Our result generalizes the recent work of\nVazirani [Vazirani, The general graph matching game: approximate core, arXiv,\n2021] from matching games to multiple partners matching games.",
    "descriptor": "",
    "authors": [
      "Han Xiao",
      "Tianhang Lu",
      "Qizhi Fang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.01442"
  },
  {
    "id": "arXiv:2107.01446",
    "title": "Architecture Information Communication in Two OSS Projects: the Why,  Who, When, and What",
    "abstract": "Architecture information is vital for Open Source Software (OSS) development,\nand mailing list is one of the widely used channels for developers to share and\ncommunicate architecture information. This work investigates the nature of\narchitecture information communication (i.e., why, who, when, and what) by OSS\ndevelopers via developer mailing lists. We employed a multiple case study\napproach to extract and analyze the architecture information communication from\nthe developer mailing lists of two OSS projects, ArgoUML and Hibernate, during\ntheir development life-cycle of over 18 years. Our main findings are: (a)\narchitecture negotiation and interpretation are the two main reasons (i.e.,\nwhy) of architecture communication; (b) the amount of architecture information\ncommunicated in developer mailing lists decreases after the first stable\nrelease (i.e., when); (c) architecture communications centered around a few\ncore developers (i.e., who); (d) and the most frequently communicated\narchitecture elements (i.e., what) are Architecture Rationale and Architecture\nModel. There are a few similarities of architecture communication between the\ntwo OSS projects. Such similarities point to how OSS developers naturally\ngravitate towards the four aspects of architecture communication in OSS\ndevelopment.",
    "descriptor": "\nComments: Preprint accepted for publication in Journal of Systems and Software, 2021\n",
    "authors": [
      "Tingting Bi",
      "Wei Ding",
      "Peng Liang",
      "Antony Tang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01446"
  },
  {
    "id": "arXiv:2107.01454",
    "title": "Stochastic Algorithms for Self-consistent Calculations of Electronic  Structures",
    "abstract": "The convergence property of a stochastic algorithm for the self-consistent\ncalculations (SCC) of electron structures is studied. The algorithm is\nformulated by rewriting the electron charges as a trace/diagonal of a matrix\nfunction, which is subsequently expressed as a statistical average. The\nfunction is further approximated by using a Krylov subspace approximation. As a\nresult, each SCC iteration only samples one random vector without having to\ncompute all the orbitals. We consider SCC iterations with damping and mixing,\nand we show with appropriate assumptions that the iterations converge in the\nmean-square sense, when the stochastic error has an almost sure bound.\nOtherwise, the convergence in probability is established.",
    "descriptor": "",
    "authors": [
      "Taehee Ko",
      "Xiantao Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01454"
  },
  {
    "id": "arXiv:2107.01460",
    "title": "Mava: a research framework for distributed multi-agent reinforcement  learning",
    "abstract": "Breakthrough advances in reinforcement learning (RL) research have led to a\nsurge in the development and application of RL. To support the field and its\nrapid growth, several frameworks have emerged that aim to help the community\nmore easily build effective and scalable agents. However, very few of these\nframeworks exclusively support multi-agent RL (MARL), an increasingly active\nfield in itself, concerned with decentralised decision-making problems. In this\nwork, we attempt to fill this gap by presenting Mava: a research framework\nspecifically designed for building scalable MARL systems. Mava provides useful\ncomponents, abstractions, utilities and tools for MARL and allows for simple\nscaling for multi-process system training and execution, while providing a high\nlevel of flexibility and composability. Mava is built on top of DeepMind's Acme\n\\citep{hoffman2020acme}, and therefore integrates with, and greatly benefits\nfrom, a wide range of already existing single-agent RL components made\navailable in Acme. Several MARL baseline systems have already been implemented\nin Mava. These implementations serve as examples showcasing Mava's reusable\nfeatures, such as interchangeable system architectures, communication and\nmixing modules. Furthermore, these implementations allow existing MARL\nalgorithms to be easily reproduced and extended. We provide experimental\nresults for these implementations on a wide range of multi-agent environments\nand highlight the benefits of distributed system training.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Arnu Pretorius",
      "Kale-ab Tessera",
      "Andries P. Smit",
      "Claude Formanek",
      "St John Grimbly",
      "Kevin Eloff",
      "Siphelele Danisa",
      "Lawrence Francis",
      "Jonathan Shock",
      "Herman Kamper",
      "Willie Brink",
      "Herman Engelbrecht",
      "Alexandre Laterre",
      "Karim Beguir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.01460"
  },
  {
    "id": "arXiv:2107.01461",
    "title": "A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust  Neural Acoustic Scene Classification",
    "abstract": "We propose a novel neural model compression strategy combining data\naugmentation, knowledge transfer, pruning, and quantization for device-robust\nacoustic scene classification (ASC). Specifically, we tackle the ASC task in a\nlow-resource environment leveraging a recently proposed advanced neural network\npruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a\nsub-network neural model associated with a small amount non-zero model\nparameters. The effectiveness of LTH for low-complexity acoustic modeling is\nassessed by investigating various data augmentation and compression schemes,\nand we report an efficient joint framework for low-complexity multi-device ASC,\ncalled Acoustic Lottery. Acoustic Lottery could compress an ASC model over\n$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and\nLog loss of 0.76) compared to its not compressed seed model. All results\nreported in this work are based on a joint effort of four groups, namely\nGT-USTC-UKE-Tencent, aiming to address the \"Low-Complexity Acoustic Scene\nClassification (ASC) with Multiple Devices\" in the DCASE 2021 Challenge Task\n1a.",
    "descriptor": "\nComments: 5 figures. DCASE 2021. The project started in November 2020\n",
    "authors": [
      "Chao-Han Huck Yang",
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Qing Wang",
      "Yuyang Wang",
      "Xianjun Xia",
      "Yuanjun Zhao",
      "Yuzhong Wu",
      "Yannan Wang",
      "Jun Du",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01461"
  },
  {
    "id": "arXiv:2107.01462",
    "title": "Development of a Conversation State Recognition System",
    "abstract": "With the evolution of the concept of Speaker diarization using LSTM, it is\nrelatively easier to understand the speaker identities for specific segments of\ninput audio stream data than manually tagging the data. With such a concept, it\nis highly desirable to consider the possibility of using the identified speaker\nidentities to aid in recognizing the Speaker States in a conversation. In this\nstudy, the Markov Chains are used to identify and update the Speaker States for\nthe next conversations between the same set of speakers, to enable\nidentification of their states in the most natural and long conversations. The\nmodel is based on several audio samples from natural conversations of three or\ngreater than three speakers in two datasets with overall total error\npercentages for recognized states being lesser than or equal to 12%. The\nfindings imply that the proposed extension to the Speaker diarization is\neffective to predict the states for a conversation.",
    "descriptor": "",
    "authors": [
      "Sujay Uday Rittikar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01462"
  },
  {
    "id": "arXiv:2107.01464",
    "title": "When Are Learned Models Better Than Hash Functions?",
    "abstract": "In this work, we aim to study when learned models are better hash functions,\nparticular for hash-maps. We use lightweight piece-wise linear models to\nreplace the hash functions as they have small inference times and are\nsufficiently general to capture complex distributions. We analyze the learned\nmodels in terms of: the model inference time and the number of collisions.\nSurprisingly, we found that learned models are not much slower to compute than\nhash functions if optimized correctly. However, it turns out that learned\nmodels can only reduce the number of collisions (i.e., the number of times\ndifferent keys have the same hash value) if the model is able to over-fit to\nthe data; otherwise, it can not be better than an ordinary hash function.\nHence, how much better a learned model is in avoiding collisions highly depends\non the data and the ability of the model to over-fit. To evaluate the\neffectiveness of learned models, we used them as hash functions in the bucket\nchaining and Cuckoo hash tables. For bucket chaining hash table, we found that\nlearned models can achieve 30% smaller sizes and 10% lower probe latency. For\nCuckoo hash tables, in some datasets, learned models can increase the ratio of\nkeys stored in their primary locations by around 10%. In summary, we found that\nlearned models can indeed outperform hash functions but only for certain data\ndistributions and with a limited margin.",
    "descriptor": "",
    "authors": [
      "Ibrahim Sabek",
      "Kapil Vaidya",
      "Dominik Horn",
      "Andreas Kipf",
      "Tim Kraska"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01464"
  },
  {
    "id": "arXiv:2107.01468",
    "title": "First-Order logic and its Infinitary Quantifier Extensions over  Countable Words",
    "abstract": "We contribute to the refined understanding of the language-logic-algebra\ninterplay in the context of first-order properties of countable words. We\nestablish decidable algebraic characterizations of one variable fragment of FO\nas well as boolean closure of existential fragment of FO via a strengthening of\nSimon's theorem about piecewise testable languages. We propose a new extension\nof FO which admits infinitary quantifiers to reason about the inherent\ninfinitary properties of countable words. We provide a very natural and\nhierarchical block-product based characterization of the new extension. We also\nexplicate its role in view of other natural and classical logical systems such\nas WMSO and FO[cut] - an extension of FO where quantification over\nDedekind-cuts is allowed. We also rule out the possibility of a finite basis\nfor a block-product based characterization of these logical systems. Finally,\nwe report simple but novel algebraic characterizations of one variable\nfragments of the hierarchies of the new proposed extension of FO.",
    "descriptor": "",
    "authors": [
      "Bharat Adsul",
      "Saptarshi Sarkar",
      "A.V. Sreejith"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.01468"
  },
  {
    "id": "arXiv:2107.01469",
    "title": "Scene-aware Learning Network for Radar Object Detection",
    "abstract": "Object detection is essential to safe autonomous or assisted driving.\nPrevious works usually utilize RGB images or LiDAR point clouds to identify and\nlocalize multiple objects in self-driving. However, cameras tend to fail in bad\ndriving conditions, e.g. bad weather or weak lighting, while LiDAR scanners are\ntoo expensive to get widely deployed in commercial applications. Radar has been\ndrawing more and more attention due to its robustness and low cost. In this\npaper, we propose a scene-aware radar learning framework for accurate and\nrobust object detection. First, the learning framework contains branches\nconditioning on the scene category of the radar sequence; with each branch\noptimized for a specific type of scene. Second, three different 3D\nautoencoder-based architectures are proposed for radar object detection and\nensemble learning is performed over the different architectures to further\nboost the final performance. Third, we propose novel scene-aware sequence mix\naugmentation (SceneMix) and scene-specific post-processing to generate more\nrobust detection results. In the ROD2021 Challenge, we achieved a final result\nof average precision of 75.0% and an average recall of 81.0%. Moreover, in the\nparking lot scene, our framework ranks first with an average precision of 97.8%\nand an average recall of 98.6%, which demonstrates the effectiveness of our\nframework.",
    "descriptor": "",
    "authors": [
      "Zangwei Zheng",
      "Xiangyu Yue",
      "Kurt Keutzer",
      "Alberto Sangiovanni Vincentelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01469"
  },
  {
    "id": "arXiv:2107.01471",
    "title": "On Tightness of the Tsaknakis-Spirakis Algorithm for Approximate Nash  Equilibrium",
    "abstract": "Finding the minimum approximate ratio for Nash equilibrium of bi-matrix games\nhas derived a series of studies, started with 3/4, followed by 1/2, 0.38 and\n0.36, finally the best approximate ratio of 0.3393 by Tsaknakis and Spirakis\n(TS algorithm for short). Efforts to improve the results remain not successful\nin the past 14 years. This work makes the first progress to show that the bound\nof 0.3393 is indeed tight for the TS algorithm. Next, we characterize all\npossible tight game instances for the TS algorithm. It allows us to conduct\nextensive experiments to study the nature of the TS algorithm and to compare it\nwith other algorithms. We find that this lower bound is not smoothed for the TS\nalgorithm in that any perturbation on the initial point may deviate away from\nthis tight bound approximate solution. Other approximate algorithms such as\nFictitious Play and Regret Matching also find better approximate solutions.\nHowever, the new distributed algorithm for approximate Nash equilibrium by\nCzumaj et al. performs consistently at the same bound of 0.3393. This proves\nour lower bound instances generated against the TS algorithm can serve as a\nbenchmark in design and analysis of approximate Nash equilibrium algorithms.",
    "descriptor": "",
    "authors": [
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Wenhan Huang",
      "Hanyu Li",
      "Yuhao Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01471"
  },
  {
    "id": "arXiv:2107.01475",
    "title": "Privacy-Preserving Representation Learning on Graphs: A Mutual  Information Perspective",
    "abstract": "Learning with graphs has attracted significant attention recently. Existing\nrepresentation learning methods on graphs have achieved state-of-the-art\nperformance on various graph-related tasks such as node classification, link\nprediction, etc. However, we observe that these methods could leak serious\nprivate information. For instance, one can accurately infer the links (or node\nidentity) in a graph from a node classifier (or link predictor) trained on the\nlearnt node representations by existing methods. To address the issue, we\npropose a privacy-preserving representation learning framework on graphs from\nthe \\emph{mutual information} perspective. Specifically, our framework includes\na primary learning task and a privacy protection task, and we consider node\nclassification and link prediction as the two tasks of interest. Our goal is to\nlearn node representations such that they can be used to achieve high\nperformance for the primary learning task, while obtaining performance for the\nprivacy protection task close to random guessing. We formally formulate our\ngoal via mutual information objectives. However, it is intractable to compute\nmutual information in practice. Then, we derive tractable variational bounds\nfor the mutual information terms, where each bound can be parameterized via a\nneural network. Next, we train these parameterized neural networks to\napproximate the true mutual information and learn privacy-preserving node\nrepresentations. We finally evaluate our framework on various graph datasets.",
    "descriptor": "\nComments: Accepted by SIGKDD'21\n",
    "authors": [
      "Binghui Wang",
      "Jiayi Guo",
      "Ang Li",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01475"
  },
  {
    "id": "arXiv:2107.01477",
    "title": "Byzantine-robust Federated Learning through Spatial-temporal Analysis of  Local Model Updates",
    "abstract": "Federated Learning (FL) enables multiple distributed clients (e.g., mobile\ndevices) to collaboratively train a centralized model while keeping the\ntraining data locally on the client. Compared to traditional centralized\nmachine learning, FL offers many favorable features such as offloading\noperations which would usually be performed by a central server and reducing\nrisks of serious privacy leakage. However, Byzantine clients that send\nincorrect or disruptive updates due to system failures or adversarial attacks\nmay disturb the joint learning process, consequently degrading the performance\nof the resulting model. In this paper, we propose to mitigate these failures\nand attacks from a spatial-temporal perspective. Specifically, we use a\nclustering-based method to detect and exclude incorrect updates by leveraging\ntheir geometric properties in the parameter space. Moreover, to further handle\nmalicious clients with time-varying behaviors, we propose to adaptively adjust\nthe learning rate according to momentum-based update speculation. Extensive\nexperiments on 4 public datasets demonstrate that our algorithm achieves\nenhanced robustness comparing to existing methods under both cross-silo and\ncross-device FL settings with faulty/malicious clients.",
    "descriptor": "",
    "authors": [
      "Zhuohang Li",
      "Luyang Liu",
      "Jiaxin Zhang",
      "Jian Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01477"
  },
  {
    "id": "arXiv:2107.01488",
    "title": "A fast algorithm for computing the Boys function",
    "abstract": "We present a new fast algorithm for computing the Boys function using\nnonlinear approximation of the integrand via exponentials. The resulting\nalgorithms evaluate the Boys function with real and complex valued arguments\nand are competitive with previously developed algorithms for the same purpose.",
    "descriptor": "\nComments: 7 pages, two figures and two tables\n",
    "authors": [
      "Gregory Beylkin",
      "Sandeep Sharma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01488"
  },
  {
    "id": "arXiv:2107.01495",
    "title": "On Positional and Structural Node Features for Graph Neural Networks on  Non-attributed Graphs",
    "abstract": "Graph neural networks (GNNs) have been widely used in various graph-related\nproblems such as node classification and graph classification, where the\nsuperior performance is mainly established when natural node features are\navailable. However, it is not well understood how GNNs work without natural\nnode features, especially regarding the various ways to construct artificial\nones. In this paper, we point out the two types of artificial node\nfeatures,i.e., positional and structural node features, and provide insights on\nwhy each of them is more appropriate for certain tasks,i.e., positional node\nclassification, structural node classification, and graph classification.\nExtensive experimental results on 10 benchmark datasets validate our insights,\nthus leading to a practical guideline on the choices between different\nartificial node features for GNNs on non-attributed graphs. The code is\navailable at https://github.com/zjzijielu/gnn-exp/.",
    "descriptor": "\nComments: This paper has been accepted to the Sixth International Workshop on Deep Learning on Graphs (DLG-KDD'21) (co-located with KDD'21)\n",
    "authors": [
      "Hejie Cui",
      "Zijie Lu",
      "Pan Li",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01495"
  },
  {
    "id": "arXiv:2107.01496",
    "title": "A Data-Driven Method for Recognizing Automated Negotiation Strategies",
    "abstract": "Understanding an opponent agent helps in negotiating with it. Existing works\non understanding opponents focus on preference modeling (or estimating the\nopponent's utility function). An important but largely unexplored direction is\nrecognizing an opponent's negotiation strategy, which captures the opponent's\ntactics, e.g., to be tough at the beginning but to concede toward the deadline.\nRecognizing complex, state-of-the-art, negotiation strategies is extremely\nchallenging, and simple heuristics may not be adequate for this purpose. We\npropose a novel data-driven approach for recognizing an opponent's s\nnegotiation strategy. Our approach includes a data generation method for an\nagent to generate domain-independent sequences by negotiating with a variety of\nopponents across domains, a feature engineering method for representing\nnegotiation data as time series with time-step features and overall features,\nand a hybrid (recurrent neural network-based) deep learning method for\nrecognizing an opponent's strategy from the time series of bids. We perform\nextensive experiments, spanning four problem scenarios, to demonstrate the\neffectiveness of our approach.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Ming Li",
      "Pradeep K.Murukannaiah",
      "Catholijn M.Jonker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.01496"
  },
  {
    "id": "arXiv:2107.01499",
    "title": "BAGUA: Scaling up Distributed Learning with System Relaxations",
    "abstract": "Recently years have witnessed a growing list of systems for distributed\ndata-parallel training. Existing systems largely fit into two paradigms, i.e.,\nparameter server and MPI-style collective operations. On the algorithmic side,\nresearchers have proposed a wide range of techniques to lower the communication\nvia system relaxations: quantization, decentralization, and communication\ndelay. However, most, if not all, existing systems only rely on standard\nsynchronous and asynchronous stochastic gradient (SG) based optimization,\ntherefore, cannot take advantage of all possible optimizations that the machine\nlearning community has been developing recently. Given this emerging gap\nbetween the current landscapes of systems and theory, we build BAGUA, a\ncommunication framework whose design goal is to provide a system abstraction\nthat is both flexible and modular to support state-of-the-art system relaxation\ntechniques of distributed training. Powered by the new system design, BAGUA has\na great ability to implement and extend various state-of-the-art distributed\nlearning algorithms. In a production cluster with up to 16 machines (128 GPUs),\nBAGUA can outperform PyTorch-DDP, Horovod and BytePS in the end-to-end training\ntime by a significant margin (up to 1.95 times) across a diverse range of\ntasks. Moreover, we conduct a rigorous tradeoff exploration showing that\ndifferent algorithms and system relaxations achieve the best performance over\ndifferent network conditions.",
    "descriptor": "",
    "authors": [
      "Shaoduo Gan",
      "Xiangru Lian",
      "Rui Wang",
      "Jianbin Chang",
      "Chengjun Liu",
      "Hongmei Shi",
      "Shengzhuo Zhang",
      "Xianghong Li",
      "Tengxu Sun",
      "Jiawei Jiang",
      "Binhang Yuan",
      "Sen Yang",
      "Ji Liu",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01499"
  },
  {
    "id": "arXiv:2107.01504",
    "title": "Overcoming the Force Limitations of Magnetic Robotic Surgery:  Impact-based Tetherless Suturing",
    "abstract": "Magnetic robotics obviate the physical connections between the actuators and\nend effectors resulting in ultra-minimally invasive surgeries. Even though such\na wireless actuation method is highly advantageous in medical applications, the\ntrade-off between the applied force and miniature magnetic end effector\ndimensions has been one of the main challenges in practical applications in\nclinically relevant conditions. This trade-off is crucial for applications\nwhere in-tissue penetration is required (e.g., needle access, biopsy, and\nsuturing). To increase the forces of such magnetic miniature end effectors to\npractically useful levels, we propose an impact-force-based suturing needle\nthat is capable of penetrating into in-vitro and ex-vivo samples with 3-DoF\nplanar freedom (planar positioning and in-plane orienting). The proposed\noptimized design is a custom-built 12 G needle that can generate 1.16 N\npenetration force which is 56 times stronger than its magnetic counterparts\nwith the same size without such an impact force. By containing the fast-moving\npermanent magnet within the needle in a confined tubular structure, the\nmovement of the overall needle remains slow and easily controllable. The\nachieved force is in the range of tissue penetration limits allowing the needle\nto be able to penetrate through tissues to follow a suturing method in a\nteleoperated fashion. We demonstrated in-vitro needle penetration into a bacon\nstrip and successful suturing of a gauze mesh onto an agar gel mimicking a\nhernia repair procedure.",
    "descriptor": "\nComments: Journal, 5 figures\n",
    "authors": [
      "Onder Erin",
      "Xiaolong Liu",
      "Jiawei Ge",
      "Lamar Mair",
      "Yotam Barnoy",
      "Yancy Diaz-Mercado",
      "Axel Krieger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01504"
  },
  {
    "id": "arXiv:2107.01507",
    "title": "Carnegie Mellon Team Tartan: Mission-level Robustness with Rapidly  Deployed Autonomous Aerial Vehicles in the MBZIRC 2020",
    "abstract": "For robotics systems to be used in high risk, real-world situations, they\nhave to be quickly deployable and robust to environmental changes,\nunder-performing hardware, and mission subtask failures. Robots are often\ndesigned to consider a single sequence of mission events, with complex\nalgorithms lowering individual subtask failure rates under some critical\nconstraints. Our approach is to leverage common techniques in vision and\ncontrol and encode robustness into mission structure through outcome monitoring\nand recovery strategies, aided by a system infrastructure that allows for quick\nmission deployments under tight time constraints and no central communication.\nWe also detail lessons in rapid field robotics development and testing. Systems\nwere developed and evaluated through real-robot experiments at an outdoor test\nsite in Pittsburgh, Pennsylvania, USA, as well as in the 2020 Mohamed Bin Zayed\nInternational Robotics Challenge. All competition trials were completed in\nfully autonomous mode without RTK-GPS. Our system led to 4th place in Challenge\n2 and 7th place in the Grand Challenge, and achievements like popping five\nballoons (Challenge 1), successfully picking and placing a block (Challenge 2),\nand dispensing the most water autonomously with a UAV of all teams onto an\noutdoor, real fire (Challenge 3).",
    "descriptor": "\nComments: 28 pages, 26 figures. To appear in Field Robotics, Special Issues on MBZIRC 2020\n",
    "authors": [
      "Anish Bhattacharya",
      "Akshit Gandhi",
      "Lukas Merkle",
      "Rohan Tiwari",
      "Karun Warrior",
      "Stanley Winata",
      "Andrew Saba",
      "Kevin Zhang",
      "Oliver Kroemer",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01507"
  },
  {
    "id": "arXiv:2107.01509",
    "title": "Bayesian decision-making under misspecified priors with applications to  meta-learning",
    "abstract": "Thompson sampling and other Bayesian sequential decision-making algorithms\nare among the most popular approaches to tackle explore/exploit trade-offs in\n(contextual) bandits. The choice of prior in these algorithms offers\nflexibility to encode domain knowledge but can also lead to poor performance\nwhen misspecified. In this paper, we demonstrate that performance degrades\ngracefully with misspecification. We prove that the expected reward accrued by\nThompson sampling (TS) with a misspecified prior differs by at most\n$\\tilde{\\mathcal{O}}(H^2 \\epsilon)$ from TS with a well specified prior, where\n$\\epsilon$ is the total-variation distance between priors and $H$ is the\nlearning horizon. Our bound does not require the prior to have any parametric\nform. For priors with bounded support, our bound is independent of the\ncardinality or structure of the action space, and we show that it is tight up\nto universal constants in the worst case.\nBuilding on our sensitivity analysis, we establish generic PAC guarantees for\nalgorithms in the recently studied Bayesian meta-learning setting and derive\ncorollaries for various families of priors. Our results generalize along two\naxes: (1) they apply to a broader family of Bayesian decision-making\nalgorithms, including a Monte-Carlo implementation of the knowledge gradient\nalgorithm (KG), and (2) they apply to Bayesian POMDPs, the most general\nBayesian decision-making setting, encompassing contextual bandits as a special\ncase. Through numerical simulations, we illustrate how prior misspecification\nand the deployment of one-step look-ahead (as in KG) can impact the convergence\nof meta-learning in multi-armed and contextual bandits with structured and\ncorrelated priors.",
    "descriptor": "",
    "authors": [
      "Max Simchowitz",
      "Christopher Tosh",
      "Akshay Krishnamurthy",
      "Daniel Hsu",
      "Thodoris Lykouris",
      "Miroslav Dud\u00edk",
      "Robert E. Schapire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01509"
  },
  {
    "id": "arXiv:2107.01516",
    "title": "Improved Representation Learning for Session-based Recommendation",
    "abstract": "Session-based recommendation systems suggest relevant items to users by\nmodeling user behavior and preferences using short-term anonymous sessions.\nExisting methods leverage Graph Neural Networks (GNNs) that propagate and\naggregate information from neighboring nodes i.e., local message passing. Such\ngraph-based architectures have representational limits, as a single sub-graph\nis susceptible to overfit the sequential dependencies instead of accounting for\ncomplex transitions between items in different sessions. We propose using a\nTransformer in combination with a target attentive GNN, which allows richer\nRepresentation Learning. Our experimental results and ablation show that our\nproposed method outperforms the existing methods on real-world benchmark\ndatasets.",
    "descriptor": "\nComments: Submitted to AJCAI 2021\n",
    "authors": [
      "Sai Mitheran",
      "Abhinav Java",
      "Surya Kant Sahu",
      "Arshad Shaikh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01516"
  },
  {
    "id": "arXiv:2107.01518",
    "title": "Hierarchical Policies for Cluttered-Scene Grasping with Latent Plans",
    "abstract": "6D grasping in cluttered scenes is a longstanding robotic manipulation\nproblem. Open-loop manipulation pipelines can fail due to modularity and error\nsensitivity while most end-to-end grasping policies with raw perception inputs\nhave not yet scaled to complex scenes with obstacles. In this work, we propose\na new method to close the gap through sampling and selecting plans in the\nlatent space. Our hierarchical framework learns collision-free target-driven\ngrasping based on partial point cloud observations. Our method learns an\nembedding space to represent expert grasping plans and a variational\nautoencoder to sample diverse latent plans at inference time. Furthermore, we\ntrain a latent plan critic for plan selection and an option classifier for\nswitching to an instance grasping policy through hierarchical reinforcement\nlearning. We evaluate and analyze our method and compare against several\nbaselines in simulation, and demonstrate that the latent planning can\ngeneralize to the real-world cluttered-scene grasping task. Our videos and code\ncan be found at https://sites.google.com/view/latent-grasping .",
    "descriptor": "",
    "authors": [
      "Lirui Wang",
      "Yu Xiang",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01518"
  },
  {
    "id": "arXiv:2107.01520",
    "title": "The PCP-like Theorem for Sub-linear Time Inapproximability",
    "abstract": "In this paper we propose the PCP-like theorem for sub-linear time\ninapproximability. Abboud et al. have devised the distributed PCP framework for\nproving sub-quadratic time inapproximability. Here we try to go further in this\ndirection. Staring from SETH, we first find a problem denoted as Ext-$k$-SAT,\nwhich can not be computed in linear time, then devise an efficient MA-like\nprotocol for this problem. To use this protocol to prove the sub-linear time\ninapproximability of other problems, we devise a new kind of reduction denoted\nas Ext-reduction, and it is different from existing reduction techniques. We\nalso define two new hardness class, the problems in which can be computed in\nlinear-time, but can not be efficiently approximated in sub-linear time. Some\nproblems are shown to be in the newly defined hardness class.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.02320\n",
    "authors": [
      "Hengzhao Ma",
      "Jianzhong Li"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01520"
  },
  {
    "id": "arXiv:2107.01525",
    "title": "AdaL: Adaptive Gradient Transformation Contributes to Convergences and  Generalizations",
    "abstract": "Adaptive optimization methods have been widely used in deep learning. They\nscale the learning rates adaptively according to the past gradient, which has\nbeen shown to be effective to accelerate the convergence. However, they suffer\nfrom poor generalization performance compared with SGD. Recent studies point\nthat smoothing exponential gradient noise leads to generalization degeneration\nphenomenon. Inspired by this, we propose AdaL, with a transformation on the\noriginal gradient. AdaL accelerates the convergence by amplifying the gradient\nin the early stage, as well as dampens the oscillation and stabilizes the\noptimization by shrinking the gradient later. Such modification alleviates the\nsmoothness of gradient noise, which produces better generalization performance.\nWe have theoretically proved the convergence of AdaL and demonstrated its\neffectiveness on several benchmarks.",
    "descriptor": "",
    "authors": [
      "Hongwei Zhang",
      "Weidong Zou",
      "Hongbo Zhao",
      "Qi Ming",
      "Tijin Yan",
      "Yuanqing Xia",
      "Weipeng Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01525"
  },
  {
    "id": "arXiv:2107.01528",
    "title": "Incorporating Reachability Knowledge into a Multi-Spatial Graph  Convolution Based Seq2Seq Model for Traffic Forecasting",
    "abstract": "Accurate traffic state prediction is the foundation of transportation control\nand guidance. It is very challenging due to the complex spatiotemporal\ndependencies in traffic data. Existing works cannot perform well for multi-step\ntraffic prediction that involves long future time period. The spatiotemporal\ninformation dilution becomes serve when the time gap between input step and\npredicted step is large, especially when traffic data is not sufficient or\nnoisy. To address this issue, we propose a multi-spatial graph convolution\nbased Seq2Seq model. Our main novelties are three aspects: (1) We enrich the\nspatiotemporal information of model inputs by fusing multi-view features (time,\nlocation and traffic states) (2) We build multiple kinds of spatial\ncorrelations based on both prior knowledge and data-driven knowledge to improve\nmodel performance especially in insufficient or noisy data cases. (3) A\nspatiotemporal attention mechanism based on reachability knowledge is novelly\ndesigned to produce high-level features fed into decoder of Seq2Seq directly to\nease information dilution. Our model is evaluated on two real world traffic\ndatasets and achieves better performance than other competitors.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Jiexia Ye",
      "Furong Zheng",
      "Juanjuan Zhao",
      "Kejiang Ye",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01528"
  },
  {
    "id": "arXiv:2107.01529",
    "title": "Learning Complex Users' Preferences for Recommender Systems",
    "abstract": "Recommender systems (RSs) have emerged as very useful tools to help customers\nwith their decision-making process, find items of their interest, and alleviate\nthe information overload problem. There are two different lines of approaches\nin RSs: (1) general recommenders with the main goal of discovering long-term\nusers' preferences, and (2) sequential recommenders with the main focus of\ncapturing short-term users' preferences in a session of user-item interaction\n(here, a session refers to a record of purchasing multiple items in one\nshopping event). While considering short-term users' preferences may satisfy\ntheir current needs and interests, long-term users' preferences provide users\nwith the items that they may interact with, eventually. In this thesis, we\nfirst focus on improving the performance of general RSs. Most of the existing\ngeneral RSs tend to exploit the users' rating patterns on common items to\ndetect similar users. The data sparsity problem (i.e. the lack of available\ninformation) is one of the major challenges for the current general RSs, and\nthey may fail to have any recommendations when there are no common items of\ninterest among users. We call this problem data sparsity with no feedback on\ncommon items (DSW-n-FCI). To overcome this problem, we propose a\npersonality-based RS in which similar users are identified based on the\nsimilarity of their personality traits.",
    "descriptor": "\nComments: 269 pages, 43 figures, 26 tables\n",
    "authors": [
      "Shahpar Yakhchi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01529"
  },
  {
    "id": "arXiv:2107.01534",
    "title": "Erasures repair for decreasing monomial-Cartesian and augmented  Reed-Muller codes of high rate",
    "abstract": "In this work, we present linear exact repair schemes for one or two erasures\nin decreasing monomial-Cartesian codes DM-CC, a family of codes which provides\na framework for polar codes. In the case of two erasures, the positions of the\nerasures should satisfy a certain restriction. We present families of augmented\nReed-Muller (ARM) and augmented Cartesian codes (ACar) which are families of\nevaluation codes obtained by strategically adding vectors to Reed-Muller and\nCartesian codes, respectively. We develop repair schemes for one or two\nerasures for these families of augmented codes. Unlike the repair scheme for\ntwo erasures of DM-CC, the repair scheme for two erasures for the augmented\ncodes has no restrictions on the positions of the erasures. When the dimension\nand base field are fixed, we give examples where ARM and ACar codes provide a\nlower bandwidth (resp., bitwidth) in comparison with Reed-Solomon (resp.,\nHermitian) codes. When the length and base field are fixed, we give examples\nwhere ACar codes provide a lower bandwidth in comparison with ARM. Finally, we\nanalyze the asymptotic behavior when the augmented codes achieve the maximum\nrate.",
    "descriptor": "",
    "authors": [
      "Hiram H. L\u00f3pez",
      "Gretchen L. Matthews",
      "Daniel Valvo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01534"
  },
  {
    "id": "arXiv:2107.01540",
    "title": "Persian-WSD-Corpus: A Sense Annotated Corpus for Persian All-words Word  Sense Disambiguation",
    "abstract": "Word Sense Disambiguation (WSD) is a long-standing task in Natural Language\nProcessing(NLP) that aims to automatically identify the most relevant meaning\nof the words in a given context. Developing standard WSD test collections can\nbe mentioned as an important prerequisite for developing and evaluating\ndifferent WSD systems in the language of interest. Although many WSD test\ncollections have been developed for a variety of languages, no standard\nAll-words WSD benchmark is available for Persian. In this paper, we address\nthis shortage for the Persian language by introducing SBU-WSD-Corpus, as the\nfirst standard test set for the Persian All-words WSD task. SBU-WSD-Corpus is\nmanually annotated with senses from the Persian WordNet (FarsNet) sense\ninventory. To this end, three annotators used SAMP (a tool for sense annotation\nbased on FarsNet lexical graph) to perform the annotation task. SBU-WSD-Corpus\nconsists of 19 Persian documents in different domains such as Sports, Science,\nArts, etc. It includes 5892 content words of Persian running text and 3371\nmanually sense annotated words (2073 nouns, 566 verbs, 610 adjectives, and 122\nadverbs). Providing baselines for future studies on the Persian All-words WSD\ntask, we evaluate several WSD models on SBU-WSD-Corpus. The corpus is publicly\navailable at https://github.com/hrouhizadeh/SBU-WSD-Corpus.",
    "descriptor": "",
    "authors": [
      "Hossein Rouhizadeh",
      "Mehrnoush Shamsfard",
      "Vahideh Tajalli",
      "Masoud Rouhziadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01540"
  },
  {
    "id": "arXiv:2107.01542",
    "title": "The Semantics of Package Management via Event Structures",
    "abstract": "We propose an approach to the semantics of package management which relates\nit to general event structures, well-known mathematical objects used in the\nsemantics of concurrent, nondeterministic systems. In this approach, the data\nof a package repository is treated as a declarative specification of a\nnondeterministic, concurrent program. We introduce a process calculus\ncorresponding to this data, and investigate its operational and categorical\nsemantics. Our hope is this lays the basis for further formal study of package\nmanagement in which the weight of existing tools can be brought to bear.",
    "descriptor": "",
    "authors": [
      "Gershom Bazerman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.01542"
  },
  {
    "id": "arXiv:2107.01543",
    "title": "STAR-IOS Aided NOMA Networks: Channel Model Approximation and  Performance Analysis",
    "abstract": "Simultaneous transmitting and reflecting intelligent omini-surfaces\n(STAR-IOSs) are able to achieve full coverage \"smart radio environments\". By\nsplitting the energy or altering the active number of STAR-IOS elements,\nSTAR-IOSs provide high flexibility of successive interference cancellation\n(SIC) orders for non-orthogonal multiple access (NOMA) systems. Based on the\naforementioned advantages, this paper investigates a STAR-IOS-aided downlink\nNOMA network with randomly deployed users. We first propose three tractable\nchannel models for different application scenarios, namely the central limit\nmodel, the curve fitting model, and the M-fold convolution model. More\nspecifically, the central limit model fits the scenarios with large-size\nSTAR-IOSs while the curve fitting model is extended to evaluate multi-cell\nnetworks. However, these two models cannot obtain accurate diversity orders.\nHence, we figure out the M-fold convolution model to derive accurate diversity\norders. We consider three protocols for STAR-IOSs, namely, the energy splitting\n(ES) protocol, the time switching (TS) protocol, and the mode switching (MS)\nprotocol. Based on the ES protocol, we derive analytical outage probability\nexpressions for the paired NOMA users by the central limit model and the curve\nfitting model. Based on three STAR-IOS protocols, we derive the diversity gains\nof NOMA users by the M-fold convolution model. The analytical results reveal\nthat the diversity gain of NOMA users is equal to the active number of STAR-IOS\nelements. Numerical results indicate that 1) in high signal-to-noise ratio\nregions, the central limit model performs as an upper bound, while a lower\nbound is obtained by the curve fitting model; 2) the TS protocol has the best\nperformance but requesting more time blocks than other protocols; 3) the ES\nprotocol outperforms the MS protocol as the ES protocol has higher diversity\ngains.",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Wenqiang Yi",
      "Yuanwei Liu",
      "Zhiguo Ding",
      "Lingyang Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01543"
  },
  {
    "id": "arXiv:2107.01544",
    "title": "Proceedings Seventh Workshop on Proof eXchange for Theorem Proving",
    "abstract": "This volume of EPTCS contains the proceedings of the Seventh Workshop on\nProof Exchange for Theorem Proving (PxTP 2021), held on 11 July 2021 as part of\nthe CADE-28 online conference in Pittsburgh, USA. The PxTP workshop series\nbrings together researchers working on various aspects of communication,\nintegration, and cooperation between reasoning systems and formalisms, with a\nspecial focus on proofs. The progress in computer-aided reasoning, both\nautomated and interactive, during the past decades, made it possible to build\ndeduction tools that are increasingly more applicable to a wider range of\nproblems and are able to tackle larger problems progressively faster. In recent\nyears, cooperation between such tools in larger systems has demonstrated the\npotential to reduce the amount of manual intervention. Cooperation between\nreasoning systems relies on availability of theoretical formalisms and\npractical tools to exchange problems, proofs, and models. The PxTP workshop\nseries strives to encourage such cooperation by inviting contributions on all\naspects of cooperation between reasoning tools, whether automatic or\ninteractive.",
    "descriptor": "",
    "authors": [
      "Chantal Keller",
      "Mathias Fleury"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01544"
  },
  {
    "id": "arXiv:2107.01547",
    "title": "Robust End-to-End Offline Chinese Handwriting Text Page Spotter with  Text Kernel",
    "abstract": "Offline Chinese handwriting text recognition is a long-standing research\ntopic in the field of pattern recognition. In previous studies, text detection\nand recognition are separated, which leads to the fact that text recognition is\nhighly dependent on the detection results. In this paper, we propose a robust\nend-to-end Chinese text page spotter framework. It unifies text detection and\ntext recognition with text kernel that integrates global text feature\ninformation to optimize the recognition from multiple scales, which reduces the\ndependence of detection and improves the robustness of the system. Our method\nachieves state-of-the-art results on the CASIA-HWDB2.0-2.2 dataset and\nICDAR-2013 competition dataset. Without any language model, the correct rates\nare 99.12% and 94.27% for line-level recognition, and 99.03% and 94.20% for\npage-level recognition, respectively.",
    "descriptor": "",
    "authors": [
      "Zhihao Wang",
      "Yanwei Yu",
      "Yibo Wang",
      "Haixu Long",
      "Fazheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01547"
  },
  {
    "id": "arXiv:2107.01548",
    "title": "SSPNet: Scale Selection Pyramid Network for Tiny Person Detection from  UAV Images",
    "abstract": "With the increasing demand for search and rescue, it is highly demanded to\ndetect objects of interest in large-scale images captured by Unmanned Aerial\nVehicles (UAVs), which is quite challenging due to extremely small scales of\nobjects. Most existing methods employed Feature Pyramid Network (FPN) to enrich\nshallow layers' features by combing deep layers' contextual features. However,\nunder the limitation of the inconsistency in gradient computation across\ndifferent layers, the shallow layers in FPN are not fully exploited to detect\ntiny objects. In this paper, we propose a Scale Selection Pyramid network\n(SSPNet) for tiny person detection, which consists of three components: Context\nAttention Module (CAM), Scale Enhancement Module (SEM), and Scale Selection\nModule (SSM). CAM takes account of context information to produce hierarchical\nattention heatmaps. SEM highlights features of specific scales at different\nlayers, leading the detector to focus on objects of specific scales instead of\nvast backgrounds. SSM exploits adjacent layers' relationships to fulfill\nsuitable feature sharing between deep layers and shallow layers, thereby\navoiding the inconsistency in gradient computation across different layers.\nBesides, we propose a Weighted Negative Sampling (WNS) strategy to guide the\ndetector to select more representative samples. Experiments on the TinyPerson\nbenchmark show that our method outperforms other state-of-the-art (SOTA)\ndetectors.",
    "descriptor": "",
    "authors": [
      "Mingbo Hong",
      "Shuiwang Li",
      "Yuchao Yang",
      "Feiyu Zhu",
      "Qijun Zhao",
      "Li Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01548"
  },
  {
    "id": "arXiv:2107.01549",
    "title": "Unified Autoregressive Modeling for Joint End-to-End Multi-Talker  Overlapped Speech Recognition and Speaker Attribute Estimation",
    "abstract": "In this paper, we present a novel modeling method for single-channel\nmulti-talker overlapped automatic speech recognition (ASR) systems. Fully\nneural network based end-to-end models have dramatically improved the\nperformance of multi-taker overlapped ASR tasks. One promising approach for\nend-to-end modeling is autoregressive modeling with serialized output training\nin which transcriptions of multiple speakers are recursively generated one\nafter another. This enables us to naturally capture relationships between\nspeakers. However, the conventional modeling method cannot explicitly take into\naccount the speaker attributes of individual utterances such as gender and age\ninformation. In fact, the performance deteriorates when each speaker is the\nsame gender or is close in age. To address this problem, we propose unified\nautoregressive modeling for joint end-to-end multi-talker overlapped ASR and\nspeaker attribute estimation. Our key idea is to handle gender and age\nestimation tasks within the unified autoregressive modeling. In the proposed\nmethod, transformer-based autoregressive model recursively generates not only\ntextual tokens but also attribute tokens of each speaker. This enables us to\neffectively utilize speaker attributes for improving multi-talker overlapped\nASR. Experiments on Japanese multi-talker overlapped ASR tasks demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "\nComments: Accepted at Interspeech 2021\n",
    "authors": [
      "Ryo Masumura",
      "Daiki Okamura",
      "Naoki Makishima",
      "Mana Ihori",
      "Akihiko Takashima",
      "Tomohiro Tanaka",
      "Shota Orihashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01549"
  },
  {
    "id": "arXiv:2107.01557",
    "title": "Leveraging Evidential Deep Learning Uncertainties with Graph-based  Clustering to Detect Anomalies",
    "abstract": "Understanding and representing traffic patterns are key to detecting\nanomalies in the maritime domain. To this end, we propose a novel graph-based\ntraffic representation and association scheme to cluster trajectories of\nvessels using automatic identification system (AIS) data. We utilize the\n(un)clustered data to train a recurrent neural network (RNN)-based evidential\nregression model, which can predict a vessel's trajectory at future timesteps\nwith its corresponding prediction uncertainty. This paper proposes the usage of\na deep learning (DL)-based uncertainty estimation in detecting maritime\nanomalies, such as unusual vessel maneuvering. Furthermore, we utilize the\nevidential deep learning classifiers to detect unusual turns of vessels and the\nloss of AIS signal using predicted class probabilities with associated\nuncertainties. Our experimental results suggest that using graph-based\nclustered data improves the ability of the DL models to learn the\ntemporal-spatial correlation of data and associated uncertainties. Using\ndifferent AIS datasets and experiments, we demonstrate that the estimated\nprediction uncertainty yields fundamental information for the detection of\ntraffic anomalies in the maritime and, possibly in other domains.",
    "descriptor": "\nComments: Under submission in a Journal\n",
    "authors": [
      "Sandeep Kumar Singh",
      "Jaya Shradha Fowdur",
      "Jakob Gawlikowski",
      "Daniel Medina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01557"
  },
  {
    "id": "arXiv:2107.01558",
    "title": "Direct Measure Matching for Crowd Counting",
    "abstract": "Traditional crowd counting approaches usually use Gaussian assumption to\ngenerate pseudo density ground truth, which suffers from problems like\ninaccurate estimation of the Gaussian kernel sizes. In this paper, we propose a\nnew measure-based counting approach to regress the predicted density maps to\nthe scattered point-annotated ground truth directly. First, crowd counting is\nformulated as a measure matching problem. Second, we derive a semi-balanced\nform of Sinkhorn divergence, based on which a Sinkhorn counting loss is\ndesigned for measure matching. Third, we propose a self-supervised mechanism by\ndevising a Sinkhorn scale consistency loss to resist scale changes. Finally, an\nefficient optimization method is provided to minimize the overall loss\nfunction. Extensive experiments on four challenging crowd counting datasets\nnamely ShanghaiTech, UCF-QNRF, JHU++, and NWPU have validated the proposed\nmethod.",
    "descriptor": "\nComments: Accepted by International Joint Conference on Artificial Intelligence (IJCAI2021)\n",
    "authors": [
      "Hui Lin",
      "Xiaopeng Hong",
      "Zhiheng Ma",
      "Xing Wei",
      "Yunfeng Qiu",
      "Yaowei Wang",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01558"
  },
  {
    "id": "arXiv:2107.01559",
    "title": "Smoothed Differential Privacy",
    "abstract": "Differential privacy (DP) is a widely-accepted and widely-applied notion of\nprivacy based on worst-case analysis. Often, DP classifies most mechanisms\nwithout external noise as non-private [Dwork et al., 2014], and external\nnoises, such as Gaussian noise or Laplacian noise [Dwork et al., 2006], are\nintroduced to improve privacy. In many real-world applications, however, adding\nexternal noise is undesirable and sometimes prohibited. For example,\npresidential elections often require a deterministic rule to be used [Liu et\nal., 2020], and small noises can lead to dramatic decreases in the prediction\naccuracy of deep neural networks, especially the underrepresented classes\n[Bagdasaryan et al., 2019].\nIn this paper, we propose a natural extension and relaxation of DP following\nthe worst average-case idea behind the celebrated smoothed analysis [Spielman\nand Teng, 2004]. Our notion, the smoothed DP, can effectively measure the\nprivacy leakage of mechanisms without external noises under realistic settings.\nWe prove several strong properties of the smoothed DP, including\ncomposability, robustness to post-processing and etc. We proved that any\ndiscrete mechanism with sampling procedures is more private than what DP\npredicts. In comparison, many continuous mechanisms with sampling procedures\nare still non-private under smoothed DP. Experimentally, we first verified that\nthe discrete sampling mechanisms are private in real-world elections. Then, we\napply the smoothed DP notion on quantized gradient descent, which indicates\nsome neural networks can be private without adding any extra noises. We believe\nthat these results contribute to the theoretical foundation of realistic\nprivacy measures beyond worst-case analysis.",
    "descriptor": "\nComments: 9 Page main text + Appendix\n",
    "authors": [
      "Ao Liu",
      "Lirong Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01559"
  },
  {
    "id": "arXiv:2107.01560",
    "title": "Virtual synchronous generator of PV generation without energy storage  for frequency support in autonomous microgrid",
    "abstract": "In autonomous microgrids frequency regulation (FR) is a critical issue,\nespecially with a high level of penetration of the photovoltaic (PV)\ngeneration. In this study, a novel virtual synchronous generator (VSG) control\nfor PV generation was introduced to provide frequency support without energy\nstorage. PV generation reserve a part of the active power in accordance with\nthe pre-defined power versus voltage curve. Based on the similarities of the\nsynchronous generator power-angle characteristic curve and the PV array\ncharacteristic curve, PV voltage Vpv can be analogized to the power angle\n{\\delta}. An emulated governor (droop control) and the swing equation control\nis designed and applied to the DC-DC converter. PV voltage deviation is\nsubsequently generated and the pre-defined power versus voltage curve is\nmodified to provide the primary frequency and inertia support. A simulation\nmodel of an autonomous microgrid with PV, storage, and diesel generator was\nbuilt. The feasibility and effectiveness of the proposed VSG strategy are\nexamined under different operating conditions.",
    "descriptor": "\nComments: Accepted by International Journal of Electrical Power and Energy Systems\n",
    "authors": [
      "Cheng Zhong",
      "Huayi Li",
      "Yang Zhou",
      "Yueming Lv",
      "Jikai Chen",
      "Yang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01560"
  },
  {
    "id": "arXiv:2107.01561",
    "title": "Certifiably Robust Interpretation via Renyi Differential Privacy",
    "abstract": "Motivated by the recent discovery that the interpretation maps of CNNs could\neasily be manipulated by adversarial attacks against network interpretability,\nwe study the problem of interpretation robustness from a new perspective of\n\\Renyi differential privacy (RDP). The advantages of our Renyi-Robust-Smooth\n(RDP-based interpretation method) are three-folds. First, it can offer provable\nand certifiable top-$k$ robustness. That is, the top-$k$ important attributions\nof the interpretation map are provably robust under any input perturbation with\nbounded $\\ell_d$-norm (for any $d\\geq 1$, including $d = \\infty$). Second, our\nproposed method offers $\\sim10\\%$ better experimental robustness than existing\napproaches in terms of the top-$k$ attributions. Remarkably, the accuracy of\nRenyi-Robust-Smooth also outperforms existing approaches. Third, our method can\nprovide a smooth tradeoff between robustness and computational efficiency.\nExperimentally, its top-$k$ attributions are {\\em twice} more robust than\nexisting approaches when the computational resources are highly constrained.",
    "descriptor": "\nComments: 19 page main text + appendix\n",
    "authors": [
      "Ao Liu",
      "Xiaoyu Chen",
      "Sijia Liu",
      "Lirong Xia",
      "Chuang Gan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01561"
  },
  {
    "id": "arXiv:2107.01566",
    "title": "Certifying DFA Bounds for Recognition and Separation",
    "abstract": "The automation of decision procedures makes certification essential. We\nsuggest to use determinacy of turn-based two-player games with regular winning\nconditions in order to generate certificates for the number of states that a\ndeterministic finite automaton (DFA) needs in order to recognize a given\nlanguage. Given a language $L$ and a bound $k$, recognizability of $L$ by a DFA\nwith $k$ states is reduced to a game between Prover and Refuter. The\ninteraction along the game then serves as a certificate. Certificates generated\nby Prover are minimal DFAs. Certificates generated by Refuter are faulty\nattempts to define the required DFA. We compare the length of offline\ncertificates, which are generated with no interaction between Prover and\nRefuter, and online certificates, which are based on such an interaction, and\nare thus shorter. We show that our approach is useful also for certification of\nseparability of regular languages by a DFA of a given size. Unlike DFA\nminimization, which can be solved in polynomial time, separation is\nNP-complete, and thus the certification approach is essential. In addition, we\nprove NP-completeness of a strict version of separation.",
    "descriptor": "\nComments: This is the full version of an article with the same title that appears in the ATVA 2021 conference proceedings. The final authenticated publication is available online at this https URL[not-yet-existing-DOI]\n",
    "authors": [
      "Orna Kupferman",
      "Nir Lavee",
      "Salomon Sickert"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.01566"
  },
  {
    "id": "arXiv:2107.01569",
    "title": "Cross-Modal Transformer-Based Neural Correction Models for Automatic  Speech Recognition",
    "abstract": "We propose a cross-modal transformer-based neural correction models that\nrefines the output of an automatic speech recognition (ASR) system so as to\nexclude ASR errors. Generally, neural correction models are composed of\nencoder-decoder networks, which can directly model sequence-to-sequence mapping\nproblems. The most successful method is to use both input speech and its ASR\noutput text as the input contexts for the encoder-decoder networks. However,\nthe conventional method cannot take into account the relationships between\nthese two different modal inputs because the input contexts are separately\nencoded for each modal. To effectively leverage the correlated information\nbetween the two different modal inputs, our proposed models encode two\ndifferent contexts jointly on the basis of cross-modal self-attention using a\ntransformer. We expect that cross-modal self-attention can effectively capture\nthe relationships between two different modals for refining ASR hypotheses. We\nalso introduce a shallow fusion technique to efficiently integrate the\nfirst-pass ASR model and our proposed neural correction model. Experiments on\nJapanese natural language ASR tasks demonstrated that our proposed models\nachieve better ASR performance than conventional neural correction models.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Tomohiro Tanaka",
      "Ryo Masumura",
      "Mana Ihori",
      "Akihiko Takashima",
      "Takafumi Moriya",
      "Takanori Ashihara",
      "Shota Orihashi",
      "Naoki Makishima"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01569"
  },
  {
    "id": "arXiv:2107.01570",
    "title": "Using Computer Simulations to Investigate the Potential Performance of  'A to B' Routing Systems for People with Mobility Impairments",
    "abstract": "Navigating from 'A to B' remains a serious problem for many people with\nmobility impairments, due to the need to avoid accessibility barriers. Yet\nthere is currently no effective routing tool that is regularly used by people\nwith disabilities in order to effectively avoid accessibility barriers in the\nbuilt environment. To explore what is required to produce an effective routing\ntool, we have conducted Monte-Carlo simulations, simulating over 460 million\njourneys. This work illustrates the need to focus on barrier minimization,\ninstead of barrier avoidance, due to the limitations of what can be achieved by\nany accessibility documentation tool. We also make a substantial contribution\nto the concern of meaningful performance metrics for activity recognition,\nillustrating how simulations can operate as useful real-world performance\nmetrics for information sources utilized by navigation systems.",
    "descriptor": "\nComments: Accepted to Mobile HCI 2021, 21 pages\n",
    "authors": [
      "Reuben Kirkham",
      "Benjamin Tannert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.01570"
  },
  {
    "id": "arXiv:2107.01571",
    "title": "Audio-Oriented Multimodal Machine Comprehension: Task, Dataset and Model",
    "abstract": "While Machine Comprehension (MC) has attracted extensive research interests\nin recent years, existing approaches mainly belong to the category of Machine\nReading Comprehension task which mines textual inputs (paragraphs and\nquestions) to predict the answers (choices or text spans). However, there are a\nlot of MC tasks that accept audio input in addition to the textual input, e.g.\nEnglish listening comprehension test. In this paper, we target the problem of\nAudio-Oriented Multimodal Machine Comprehension, and its goal is to answer\nquestions based on the given audio and textual information. To solve this\nproblem, we propose a Dynamic Inter- and Intra-modality Attention (DIIA) model\nto effectively fuse the two modalities (audio and textual). DIIA can work as an\nindependent component and thus be easily integrated into existing MC models.\nMoreover, we further develop a Multimodal Knowledge Distillation (MKD) module\nto enable our multimodal MC model to accurately predict the answers based only\non either the text or the audio. As a result, the proposed approach can handle\nvarious tasks including: Audio-Oriented Multimodal Machine Comprehension,\nMachine Reading Comprehension and Machine Listening Comprehension, in a single\nmodel, making fair comparisons possible between our model and the existing\nunimodal MC models. Experimental results and analysis prove the effectiveness\nof the proposed approaches. First, the proposed DIIA boosts the baseline models\nby up to 21.08% in terms of accuracy; Second, under the unimodal scenarios, the\nMKD module allows our multimodal MC model to significantly outperform the\nunimodal models by up to 18.87%, which are trained and tested with only audio\nor textual data.",
    "descriptor": "\nComments: AAAI 2021\n",
    "authors": [
      "Zhiqi Huang",
      "Fenglin Liu",
      "Xian Wu",
      "Shen Ge",
      "Helin Wang",
      "Wei Fan",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01571"
  },
  {
    "id": "arXiv:2107.01572",
    "title": "Lightning Stokes solver",
    "abstract": "Gopal and Trefethen recently introduced \"lightning solvers\" for the 2D\nLaplace and Helmholtz equations, based on rational functions with poles\nexponentially clustered near singular corners. Making use of the Goursat\nrepresentation in terms of analytic functions, we extend these methods to the\nbiharmonic equation, specifically to 2D Stokes flow. Solutions to model\nproblems are computed to 10-digit accuracy in less than a second of laptop\ntime. As an illustration of the high accuracy, we resolve two or more\ncounter-rotating Moffatt eddies near a singular corner.",
    "descriptor": "",
    "authors": [
      "Pablo D. Brubeck",
      "Lloyd N. Trefethen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01572"
  },
  {
    "id": "arXiv:2107.01573",
    "title": "Arabic Code-Switching Speech Recognition using Monolingual Data",
    "abstract": "Code-switching in automatic speech recognition (ASR) is an important\nchallenge due to globalization. Recent research in multilingual ASR shows\npotential improvement over monolingual systems. We study key issues related to\nmultilingual modeling for ASR through a series of large-scale ASR experiments.\nOur innovative framework deploys a multi-graph approach in the weighted finite\nstate transducers (WFST) framework. We compare our WFST decoding strategies\nwith a transformer sequence to sequence system trained on the same data. Given\na code-switching scenario between Arabic and English languages, our results\nshow that the WFST decoding approaches were more suitable for the\nintersentential code-switching datasets. In addition, the transformer system\nperformed better for intrasentential code-switching task. With this study, we\nrelease an artificially generated development and test sets, along with\necological code-switching test set, to benchmark the ASR performance.",
    "descriptor": "\nComments: Accepted in Interspeech 2021, speech recognition, code-switching, ASR, transformer, WFST, graph approach\n",
    "authors": [
      "Ahmed Ali",
      "Shammur Chowdhury",
      "Amir Hussein",
      "Yasser Hifny"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01573"
  },
  {
    "id": "arXiv:2107.01574",
    "title": "AAA-least squares rational approximation and solution of Laplace  problems",
    "abstract": "A two-step method for solving planar Laplace problems via rational\napproximation is introduced. First complex rational approximations to the\nboundary data are determined by AAA approximation, either globally or locally\nnear each corner or other singularity. The poles of these approximations\noutside the problem domain are then collected and used for a global\nleast-squares fit to the solution. Typical problems are solved in a second of\nlaptop time to 8-digit accuracy, all the way up to the corners, and the\nconjugate harmonic function is also provided. The AAA-least squares combination\nalso offers a new method for avoiding spurious poles in other rational\napproximation problems, and for greatly speeding them up in cases with many\nsingularities. As a special case, AAA-LS approximation leads to a powerful\nmethod for computing the Hilbert transform or Dirichlet-to-Neumann map.",
    "descriptor": "",
    "authors": [
      "Stefano Costa",
      "Lloyd N. Trefethen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01574"
  },
  {
    "id": "arXiv:2107.01579",
    "title": "Similarity-Aware Fusion Network for 3D Semantic Segmentation",
    "abstract": "In this paper, we propose a similarity-aware fusion network (SAFNet) to\nadaptively fuse 2D images and 3D point clouds for 3D semantic segmentation.\nExisting fusion-based methods achieve remarkable performances by integrating\ninformation from multiple modalities. However, they heavily rely on the\ncorrespondence between 2D pixels and 3D points by projection and can only\nperform the information fusion in a fixed manner, and thus their performances\ncannot be easily migrated to a more realistic scenario where the collected data\noften lack strict pair-wise features for prediction. To address this, we employ\na late fusion strategy where we first learn the geometric and contextual\nsimilarities between the input and back-projected (from 2D pixels) point clouds\nand utilize them to guide the fusion of two modalities to further exploit\ncomplementary information. Specifically, we employ a geometric similarity\nmodule (GSM) to directly compare the spatial coordinate distributions of\npair-wise 3D neighborhoods, and a contextual similarity module (CSM) to\naggregate and compare spatial contextual information of corresponding central\npoints. The two proposed modules can effectively measure how much image\nfeatures can help predictions, enabling the network to adaptively adjust the\ncontributions of two modalities to the final prediction of each point.\nExperimental results on the ScanNetV2 benchmark demonstrate that SAFNet\nsignificantly outperforms existing state-of-the-art fusion-based approaches\nacross various data integrity.",
    "descriptor": "\nComments: Accepted by 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Linqing Zhao",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01579"
  },
  {
    "id": "arXiv:2107.01581",
    "title": "Unified Identification and Tuning Approach Using Deep Neural Networks  For Visual Servoing Applications",
    "abstract": "Vision based control of Unmanned Aerial Vehicles (UAVs) has been adopted by a\nwide range of applications due to the availability of low-cost on-board sensors\nand computers. Tuning such systems to work properly requires extensive domain\nspecific experience which limits the growth of emerging applications. Moreover,\nobtaining performance limits of UAV based visual servoing with the current\nstate-of-the-art is not possible due to the complexity of the models used. In\nthis paper, we present a systematic approach for real-time identification and\ntuning of visual servoing systems based on a novel robustified version of the\nrecent deep neural networks with the modified relay feedback test (DNN-MRFT)\napproach. The proposed robust DNN-MRFT algorithm can be used with a multitude\nof vision sensors and estimation algorithms despite the high levels of sensor's\nnoise. Sensitivity of MRFT to perturbations is investigated and its effect on\nidentification and tuning performance is analyzed. DNN-MRFT was able to detect\nperformance changes due to the use of slower vision sensors, or due to the\nintegration of accelerometer measurements. Experimental identification results\nwere closely matching simulation results, which can be used to explain system\nbehaviour and anticipate the closed loop performance limits given a certain\nhardware and software setup. Finally, we demonstrate the capability of the\nDNN-MRFT tuned visual servoing systems to reject external disturbances. Some\nadvantages of the suggested robust identification approach compared to existing\nvisual servoing design approaches are presented.",
    "descriptor": "",
    "authors": [
      "Oussama Abdul Hay",
      "Mohamad Chehadeh",
      "Abdulla Ayyad",
      "Mohamad Wahbah",
      "Muhammad Humais",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01581"
  },
  {
    "id": "arXiv:2107.01583",
    "title": "CasEE: A Joint Learning Framework with Cascade Decoding for Overlapping  Event Extraction",
    "abstract": "Event extraction (EE) is a crucial information extraction task that aims to\nextract event information in texts. Most existing methods assume that events\nappear in sentences without overlaps, which are not applicable to the\ncomplicated overlapping event extraction. This work systematically studies the\nrealistic event overlapping problem, where a word may serve as triggers with\nseveral types or arguments with different roles. To tackle the above problem,\nwe propose a novel joint learning framework with cascade decoding for\noverlapping event extraction, termed as CasEE. Particularly, CasEE sequentially\nperforms type detection, trigger extraction and argument extraction, where the\noverlapped targets are extracted separately conditioned on the specific former\nprediction. All the subtasks are jointly learned in a framework to capture\ndependencies among the subtasks. The evaluation on a public event extraction\nbenchmark FewFC demonstrates that CasEE achieves significant improvements on\noverlapping event extraction over previous competitive methods.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Jiawei Sheng",
      "Shu Guo",
      "Bowen Yu",
      "Qian Li",
      "Yiming Hei",
      "Lihong Wang",
      "Tingwen Liu",
      "Hongbo Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01583"
  },
  {
    "id": "arXiv:2107.01592",
    "title": "Coarse-to-Careful: Seeking Semantic-related Knowledge for Open-domain  Commonsense Question Answering",
    "abstract": "It is prevalent to utilize external knowledge to help machine answer\nquestions that need background commonsense, which faces a problem that\nunlimited knowledge will transmit noisy and misleading information. Towards the\nissue of introducing related knowledge, we propose a semantic-driven\nknowledge-aware QA framework, which controls the knowledge injection in a\ncoarse-to-careful fashion. We devise a tailoring strategy to filter extracted\nknowledge under monitoring of the coarse semantic of question on the knowledge\nextraction stage. And we develop a semantic-aware knowledge fetching module\nthat engages structural knowledge information and fuses proper knowledge\naccording to the careful semantic of questions in a hierarchical way.\nExperiments demonstrate that the proposed approach promotes the performance on\nthe CommonsenseQA dataset comparing with strong baselines.",
    "descriptor": "\nComments: In ICASSP2021\n",
    "authors": [
      "Luxi Xing",
      "Yue Hu",
      "Jing Yu",
      "Yuqiang Xie",
      "Wei Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01592"
  },
  {
    "id": "arXiv:2107.01594",
    "title": "A Rewriting Coherence Theorem with Applications in Homotopy Type Theory",
    "abstract": "Higher-dimensional rewriting systems are tools to analyse the structure of\nformally reducing terms to normal forms, as well as comparing the different\nreduction paths that lead to those normal forms. This higher structure can be\ncaptured by finding a homotopy basis for the rewriting system. We show that the\nbasic notions of confluence and wellfoundedness are sufficient to recursively\nbuild such a homotopy basis, with a construction reminiscent of an argument by\nCraig C. Squier. We then go on to translate this construction to the setting of\nhomotopy type theory, where managing equalities between paths is important in\norder to construct functions which are coherent with respect to higher\ndimensions. Eventually, we apply the result to approximate a series of open\nquestions in homotopy type theory, such as the characterisation of the homotopy\ngroups of the free group on a set and the pushout of 1-types.\nThis paper expands on our previous conference contribution \"Coherence via\nWellfoundedness\" (arXiv:2001.07655) by laying out the construction in the\nlanguage of higher-dimensional rewriting.",
    "descriptor": "\nComments: 30 pages. arXiv admin note: text overlap with arXiv:2001.07655\n",
    "authors": [
      "Nicolai Kraus",
      "Jakob von Raumer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01594"
  },
  {
    "id": "arXiv:2107.01595",
    "title": "Learning in nonatomic games, Part I: Finite action spaces and population  games",
    "abstract": "We examine the long-run behavior of a wide range of dynamics for learning in\nnonatomic games, in both discrete and continuous time. The class of dynamics\nunder consideration includes fictitious play and its regularized variants, the\nbest-reply dynamics (again, possibly regularized), as well as the dynamics of\ndual averaging / \"follow the regularized leader\" (which themselves include as\nspecial cases the replicator dynamics and Friedman's projection dynamics). Our\nanalysis concerns both the actual trajectory of play and its time-average, and\nwe cover potential and monotone games, as well as games with an evolutionarily\nstable state (global or otherwise). We focus exclusively on games with finite\naction spaces; nonatomic games with continuous action spaces are treated in\ndetail in Part II of this paper.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Saeed Hadikhanloo",
      "Rida Laraki",
      "Panayotis Mertikopoulos",
      "Sylvain Sorin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.01595"
  },
  {
    "id": "arXiv:2107.01596",
    "title": "A Systematic Review of Mobile Apps for Child Sexual Abuse Education:  Limitations and Design Guidelines",
    "abstract": "The objectives of this study are understanding the requirements of a CSA\neducation app, identifying the limitations of existing apps, and providing a\nguideline for better app design. An electronic search across three major app\nstores(Google Play, Apple, and Microsoft) is conducted and the selected apps\nare rated by three independent raters. Total 191 apps are found and finally, 14\napps are selected for review based on defined inclusion and exclusion criteria.\nAn app rating scale for CSA education apps is devised by modifying existing\nscales and used to evaluate the selected 14 apps. Our rating scale evaluates\nessential features, criteria, and software quality characteristics that are\nnecessary for CSA education apps, and determined their effectiveness for\npotential use as CSA education programs for children. The internal consistency\nof the rating scale and the inter and intra-rater reliability among the raters\nare also calculated. User comments from the app stores are collected and\nanalyzed to understand their expectations and views. After analyzing the\nfeasibility of reviewed apps, CSA app design considerations are proposed that\nhighlight game-based teaching approaches. Evaluation results showed that most\nof the reviewed apps are not suitable for being used as CSA education programs.\nWhile a few may be able to teach children and parents individually, only the\napps \"Child Abuse Prevention\" (rate 3.89 out of 5) and \"Orbit Rescue\" (rate\n3.92 out of 5) could be deemed suitable for a school-based CSA education\nprogram. However, all those apps need to be improved both their software\nqualities and CSA-specific features for being considered as potential CSA\neducation programs. This study provides the necessary knowledge to developers\nand individuals regarding essential features and software quality\ncharacteristics for designing and developing CSA education apps.",
    "descriptor": "",
    "authors": [
      "Sadia Tasnuva Pritha",
      "Rahnuma Tasnim",
      "Muhammad Ashad Kabir",
      "Sumaiya Amin",
      "Anik Das"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01596"
  },
  {
    "id": "arXiv:2107.01598",
    "title": "Domain Adaptation for Sentiment Analysis Using Increased Intraclass  Separation",
    "abstract": "Sentiment analysis is a costly yet necessary task for enterprises to study\nthe opinions of their customers to improve their products and to determine\noptimal marketing strategies. Due to the existence of a wide range of domains\nacross different products and services, cross-domain sentiment analysis methods\nhave received significant attention. These methods mitigate the domain gap\nbetween different applications by training cross-domain generalizable\nclassifiers which help to relax the need for data annotation for each domain.\nMost existing methods focus on learning domain-agnostic representations that\nare invariant with respect to both the source and the target domains. As a\nresult, a classifier that is trained using the source domain annotated data\nwould generalize well in a related target domain. We introduce a new domain\nadaptation method which induces large margins between different classes in an\nembedding space. This embedding space is trained to be domain-agnostic by\nmatching the data distributions across the domains. Large intraclass margins in\nthe source domain help to reduce the effect of \"domain shift\" on the classifier\nperformance in the target domain. Theoretical and empirical analysis are\nprovided to demonstrate that the proposed method is effective.",
    "descriptor": "",
    "authors": [
      "Mohammad Rostami",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01598"
  },
  {
    "id": "arXiv:2107.01600",
    "title": "ETHTID: Deployable Threshold Information Disclosure on Ethereum",
    "abstract": "We address the Threshold Information Disclosure (TID) problem on Ethereum: An\narbitrary number of users commit to the scheduled disclosure of their\nindividual messages recorded on the Ethereum blockchain if and only if all such\nmessages are disclosed. Before a disclosure, only the original sender of each\nmessage should know its contents. To accomplish this, we task a small council\nwith executing a distributed generation and threshold sharing of an asymmetric\nkey pair. The public key can be used to encrypt messages which only become\nreadable once the threshold-shared decryption key is reconstructed at a\npredefined point in time and recorded on-chain. With blockchains like Ethereum,\nit is possible to coordinate such procedures and attach economic stakes to the\nactions of participating individuals. In this paper, we present ETHTID, an\nEthereum smart contract application to coordinate Threshold Information\nDisclosure. We base our implementation on ETHDKG [1], a smart contract\napplication for distributed key generation and threshold sharing, and adapt it\nto fit our differing use case as well as add functionality to oversee a\nscheduled reconstruction of the decryption key. For our main cost saving\noptimisation, we show that the security of the underlying cryptographic scheme\nis maintained. We evaluate how the execution costs depend on the size of the\ncouncil and the threshold and show that the presented protocol is deployable on\nEthereum with a council of more than 200 members with gas savings of 20-40%\ncompared to ETHDKG.",
    "descriptor": "",
    "authors": [
      "Oliver Stengele",
      "Markus Raiber",
      "J\u00f6rn M\u00fcller-Quade",
      "Hannes Hartenstein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01600"
  },
  {
    "id": "arXiv:2107.01602",
    "title": "Graphical State Space Model",
    "abstract": "In this paper, a new framework, named as graphical state space model, is\nproposed for the real time optimal estimation of one kind of nonlinear state\nspace model. By discretizing this kind of system model as an equation which can\nnot be solved by Extended Kalman filter, factor graph optimization can\noutperform Extended Kalman filter in some cases. A simple nonlinear example are\ngiven to demonstrate the efficiency of this framework.",
    "descriptor": "",
    "authors": [
      "Shaolin L\u00fc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01602"
  },
  {
    "id": "arXiv:2107.01604",
    "title": "Deterministic and Probabilistic Error Bounds for Floating Point  Summation Algorithms",
    "abstract": "We analyse the forward error in the floating point summation of real numbers,\nfrom algorithms that do not require recourse to higher precision or better\nhardware. We derive informative explicit expressions, and new deterministic and\nprobabilistic bounds for errors in three classes of algorithms: general\nsummation,shifted general summation, and compensated (sequential) summation.\nOur probabilistic bounds for general and shifted general summation hold to all\norders. For compensated summation, we also present deterministic and\nprobabilistic first and second order bounds, with a first order bound that\ndiffers from existing ones. Numerical experiments illustrate that the bounds\nare informative and that among the three algorithm classes, compensated\nsummation is generally the most accurate method.",
    "descriptor": "",
    "authors": [
      "Eric Hallman",
      "Ilse C.F. Ipsen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01604"
  },
  {
    "id": "arXiv:2107.01605",
    "title": "Synchronization Strategies for Multi-agent Networked Control Systems",
    "abstract": "With the advent of 21st century and increasing advancements in the field of\ntechnology and connectivity, inter-networking in real-time has achieved great\nimportance. Distributed control and multi-agent paradigm has groped rapidly\nwith history of big time failures of centralized systems in the past. The\nconcepts of synchronization and network control systems have been used\nextensively in the near past to map, analyze and solve defined set of\nobjectives. In this thesis, a diverse set of applications from power flow point\nof view are taken into consideration and modelled/analyzed using\nsynchronization as the central theme. These systems are proposed (or assumed)\nto be network connected and its control has been devised accordingly. It has\nbeen shown how some examples from nature can help recreate similar dynamics\nsynthetically and help achieve system objectives. Few of the applications of\nthe smart world have been ascribed in the thesis and distributed control of\nthese seen from a multi-agent perspective have been devised in order to better\ndesign and operate such systems in real-time. Synchronization happens to be the\nheart of all the networks, as all the agents work in tandem in order to provide\nto a common objective as well abide by the defined constraints. As an\ninflection to the work, I set up a platform for development of new distributed\nand fast acting control strategies for conventional as well as futuristic\ncontrol systems existing/non-existing in the literature. As a major\ncontribution of this dissertation, by combining the ideas from physics and\npower systems, I open up various interesting phenomena already existing in\neither fields to be explored for one another.",
    "descriptor": "\nComments: 101pages\n",
    "authors": [
      "Pratik K. Bajaria"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.01605"
  },
  {
    "id": "arXiv:2107.01606",
    "title": "A Comparison of the Delta Method and the Bootstrap in Deep Learning  Classification",
    "abstract": "We validate the recently introduced deep learning classification adapted\nDelta method by a comparison with the classical Bootstrap. We show that there\nis a strong linear relationship between the quantified predictive epistemic\nuncertainty levels obtained from the two methods when applied on two\nLeNet-based neural network classifiers using the MNIST and CIFAR-10 datasets.\nFurthermore, we demonstrate that the Delta method offers a five times\ncomputation time reduction compared to the Bootstrap.",
    "descriptor": "",
    "authors": [
      "Geir K. Nilsen",
      "Antonella Z. Munthe-Kaas",
      "Hans J. Skaug",
      "Morten Brun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01606"
  },
  {
    "id": "arXiv:2107.01607",
    "title": "Algorithms for normalized multiple sequence alignments",
    "abstract": "Sequence alignment supports numerous tasks in bioinformatics, natural\nlanguage processing, pattern recognition, social sciences, and others fields.\nWhile the alignment of two sequences may be performed swiftly in many\napplications, the simultaneous alignment of multiple sequences proved to be\nnaturally more intricate. Although most multiple sequence alignment (MSA)\nformulations are NP-hard, several approaches have been developed, as they can\noutperform pairwise alignment methods or are necessary for some applications.\nTaking into account not only similarities but also the lengths of the\ncompared sequences (i.e. normalization) can provide better alignment results\nthan both unnormalized or post-normalized approaches. While some normalized\nmethods have been developed for pairwise sequence alignment, none have been\nproposed for MSA. This work is a first effort towards the development of\nnormalized methods for MSA.\nWe discuss multiple aspects of normalized multiple sequence alignment (NMSA).\nWe define three new criteria for computing normalized scores when aligning\nmultiple sequences, showing the NP-hardness and exact algorithms for solving\nthe NMSA using those criteria. In addition, we provide approximation algorithms\nfor MSA and NMSA for some classes of scoring matrices.",
    "descriptor": "\nComments: 26 pages, 2 figures, 5 algorithms\n",
    "authors": [
      "Eloi Araujo",
      "Luiz Rozante",
      "Diego P. Rubert",
      "Fabio V. Martinez"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01607"
  },
  {
    "id": "arXiv:2107.01609",
    "title": "The Complexity of Finding Temporal Separators under Waiting Time  Constraints",
    "abstract": "In this work, we investigate the computational complexity of Restless\nTemporal $(s,z)$-Separation, where we are asked whether it is possible to\ndestroy all restless temporal paths between two distinct vertices $s$ and $z$\nby deleting at most $k$ vertices from a temporal graph. A temporal graph has a\nfixed vertex but the edges have (discrete) time stamps. A restless temporal\npath uses edges with non-decreasing time stamps and the time spent at each\nvertex must not exceed a given duration $\\Delta$.\nRestless Temporal $(s,z)$-Separation naturally generalizes the NP-hard\nTemporal $(s,z)$-Separation problem. We show that Restless Temporal\n$(s,z)$-Separation is complete for $\\Sigma_2^\\text{P}$, a complexity class\nlocated in the second level of the polynomial time hierarchy. We further\nprovide some insights in the parameterized complexity of Restless Temporal\n$(s,z)$-Separation parameterized by the separator size $k$.",
    "descriptor": "\nComments: This work is based on a previously unpublished chapter of the author's PhD-thesis\n",
    "authors": [
      "Hendrik Molter"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01609"
  },
  {
    "id": "arXiv:2107.01610",
    "title": "Expanded Gabidulin Codes and Their Application to Cryptography",
    "abstract": "This paper presents a new family of linear codes, namely the expanded\nGabidulin codes. Exploiting the existing fast decoder of Gabidulin codes, we\npropose an efficient algorithm to decode these new codes when the noise vector\nsatisfies a certain condition. Furthermore, these new codes enjoy an excellent\nerror-correcting capability because of the optimality of their parent Gabidulin\ncodes. Based on different masking techniques, we give two encryption schemes by\nusing expanded Gabidulin codes in the McEliece setting. According to our\nanalysis, both of these two cryptosystems can resist the existing structural\nattacks. Our proposals have an obvious advantage in public-key representation\nwithout using the cyclic or quasi-cyclic structure compared to some other\ncode-based cryptosystems.",
    "descriptor": "",
    "authors": [
      "Wenshuo Guo",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01610"
  },
  {
    "id": "arXiv:2107.01613",
    "title": "Closing the gap for single resource constraint scheduling",
    "abstract": "In the problem called single resource constraint scheduling, we are given $m$\nidentical machines and a set of jobs, each needing one machine to be processed\nas well as a share of a limited renewable resource $R$. A schedule of these\njobs is feasible if, at each point in the schedule, the number of machines and\nresources required by jobs processed at this time is not exceeded. It is\nNP-hard to approximate this problem with a ratio better than $3/2$. On the\nother hand, the best algorithm so far has an absolute approximation ratio of\n$2+\\varepsilon$. This paper presents an algorithm with absolute approximation\nratio~$(3/2+\\varepsilon)$, which closes the gap between inapproximability and\nbest algorithm except for a negligible small~$\\varepsilon$.",
    "descriptor": "",
    "authors": [
      "Klaus Jansen",
      "Malin Rau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01613"
  },
  {
    "id": "arXiv:2107.01614",
    "title": "Survey: Leakage and Privacy at Inference Time",
    "abstract": "Leakage of data from publicly available Machine Learning (ML) models is an\narea of growing significance as commercial and government applications of ML\ncan draw on multiple sources of data, potentially including users' and clients'\nsensitive data. We provide a comprehensive survey of contemporary advances on\nseveral fronts, covering involuntary data leakage which is natural to ML\nmodels, potential malevolent leakage which is caused by privacy attacks, and\ncurrently available defence mechanisms. We focus on inference-time leakage, as\nthe most likely scenario for publicly available models. We first discuss what\nleakage is in the context of different data, tasks, and model architectures. We\nthen propose a taxonomy across involuntary and malevolent leakage, available\ndefences, followed by the currently available assessment metrics and\napplications. We conclude with outstanding challenges and open questions,\noutlining some promising directions for future research.",
    "descriptor": "",
    "authors": [
      "Marija Jegorova",
      "Chaitanya Kaul",
      "Charlie Mayor",
      "Alison Q. O'Neil",
      "Alexander Weir",
      "Roderick Murray-Smith",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01614"
  },
  {
    "id": "arXiv:2107.01615",
    "title": "A Typology of Data Anomalies",
    "abstract": "Anomalies are cases that are in some way unusual and do not appear to fit the\ngeneral patterns present in the dataset. Several conceptualizations exist to\ndistinguish between different types of anomalies. However, these are either too\nspecific to be generally applicable or so abstract that they neither provide\nconcrete insight into the nature of anomaly types nor facilitate the functional\nevaluation of anomaly detection algorithms. With the recent criticism on 'black\nbox' algorithms and analytics it has become clear that this is an undesirable\nsituation. This paper therefore introduces a general typology of anomalies that\noffers a clear and tangible definition of the different types of anomalies in\ndatasets. The typology also facilitates the evaluation of the functional\ncapabilities of anomaly detection algorithms and as a framework assists in\nanalyzing the conceptual levels of data, patterns and anomalies. Finally, it\nserves as an analytical tool for studying anomaly types from other typologies.",
    "descriptor": "\nComments: 13 pages, 5 figures. Presented at the 17th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU 2018). Note: for a fully developed and more detailed typology of anomalies, see the follow-up publication 'On the Nature and Types of Anomalies: A Review of Deviations in Data'. arXiv admin note: text overlap with arXiv:2007.15634\n",
    "authors": [
      "Ralph Foorthuis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01615"
  },
  {
    "id": "arXiv:2107.01616",
    "title": "Analyzing the Stationarity Process in Software Effort Estimation  Datasets",
    "abstract": "Software effort estimation models are typically developed based on an\nunderlying assumption that all data points are equally relevant to the\nprediction of effort for future projects. The dynamic nature of several aspects\nof the software engineering process could mean that this assumption does not\nhold in at least some cases. This study employs three kernel estimator\nfunctions to test the stationarity assumption in five software engineering\ndatasets that have been used in the construction of software effort estimation\nmodels. The kernel estimators are used in the generation of nonuniform weights\nwhich are subsequently employed in weighted linear regression modeling. In each\nmodel, older projects are assigned smaller weights while the more recently\ncompleted projects are assigned larger weights, to reflect their potentially\ngreater relevance to present or future projects that need to be estimated.\nPrediction errors are compared to those obtained from uniform models. Our\nresults indicate that, for the datasets that exhibit underlying nonstationary\nprocesses, uniform models are more accurate than the nonuniform models; that\nis, models based on kernel estimator functions are worse than the models where\nno weighting was applied. In contrast, the accuracies of uniform and nonuniform\nmodels for datasets that exhibited stationary processes were essentially\nequivalent. Our analysis indicates that as the heterogeneity of a dataset\nincreases, the effect of stationarity is overridden. The results of our study\nalso confirm prior findings that the accuracy of effort estimation models is\nindependent of the type of kernel estimator function used in model development.",
    "descriptor": "\nComments: Journal paper, 16 pages, 3 tables, 12 figures. arXiv admin note: substantial text overlap with arXiv:2012.08692\n",
    "authors": [
      "Michael Franklin Bosu",
      "Stephen G. MacDonell",
      "Peter A. Whigham"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01616"
  },
  {
    "id": "arXiv:2107.01619",
    "title": "Deep Edge-Aware Interactive Colorization against Color-Bleeding Effects",
    "abstract": "Deep image colorization networks often suffer from the color-bleeding\nartifact, a problematic color spreading near the boundaries between adjacent\nobjects. The color-bleeding artifacts debase the reality of generated outputs,\nlimiting the applicability of colorization models on a practical application.\nAlthough previous approaches have tackled this problem in an automatic manner,\nthey often generate imperfect outputs because their enhancements are available\nonly in limited cases, such as having a high contrast of gray-scale value in an\ninput image. Instead, leveraging user interactions would be a promising\napproach, since it can help the edge correction in the desired regions. In this\npaper, we propose a novel edge-enhancing framework for the regions of interest,\nby utilizing user scribbles that indicate where to enhance. Our method requires\nminimal user effort to obtain satisfactory enhancements. Experimental results\non various datasets demonstrate that our interactive approach has outstanding\nperformance in improving color-bleeding artifacts against the existing\nbaselines.",
    "descriptor": "",
    "authors": [
      "Eungyeup Kim",
      "Sanghyeon Lee",
      "Jeonghoon Park",
      "Somi Choi",
      "Choonghyun Seo",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01619"
  },
  {
    "id": "arXiv:2107.01620",
    "title": "Auxiliary-Classifier GAN for Malware Analysis",
    "abstract": "Generative adversarial networks (GAN) are a class of powerful machine\nlearning techniques, where both a generative and discriminative model are\ntrained simultaneously. GANs have been used, for example, to successfully\ngenerate \"deep fake\" images. A recent trend in malware research consists of\ntreating executables as images and employing image-based analysis techniques.\nIn this research, we generate fake malware images using auxiliary classifier\nGANs (AC-GAN), and we consider the effectiveness of various techniques for\nclassifying the resulting images. Our results indicate that the resulting\nmulticlass classification problem is challenging, yet we can obtain strong\nresults when restricting the problem to distinguishing between real and fake\nsamples. While the AC-GAN generated images often appear to be very similar to\nreal malware images, we conclude that from a deep learning perspective, the\nAC-GAN generated samples do not rise to the level of deep fake malware images.",
    "descriptor": "",
    "authors": [
      "Rakesh Nagaraju",
      "Mark Stamp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01620"
  },
  {
    "id": "arXiv:2107.01621",
    "title": "The Composability of Intermediate Values in Composable Inductive  Programming",
    "abstract": "It is believed that mechanisms including intermediate values enable\ncomposable inductive programming (CIP) to be used to produce software of any\nsize. We present the results of a study that investigated the relationships\nbetween program size, the number of intermediate values and the number of test\ncases used to specify programs using CIP. In the study 96,000 programs of\nvarious sizes were randomly generated, decomposed into fragments and\ntransformed into test cases. The test cases were then used to regenerate new\nversions of the original programs using Zoea. The results show linear\nrelationships between the number of intermediate values and regenerated program\nsize, and between the number of test cases and regenerated program size within\nthe size range studied. In addition, as program size increases there is\nincreasing scope for trading off the number of test cases against the number of\nintermediate values and vice versa.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Edward McDaid",
      "Sarah McDaid"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01621"
  },
  {
    "id": "arXiv:2107.01622",
    "title": "Multiple-criteria Based Active Learning with Fixed-size Determinantal  Point Processes",
    "abstract": "Active learning aims to achieve greater accuracy with less training data by\nselecting the most useful data samples from which it learns. Single-criterion\nbased methods (i.e., informativeness and representativeness based methods) are\nsimple and efficient; however, they lack adaptability to different real-world\nscenarios. In this paper, we introduce a multiple-criteria based active\nlearning algorithm, which incorporates three complementary criteria, i.e.,\ninformativeness, representativeness and diversity, to make appropriate\nselections in the active learning rounds under different data types. We\nconsider the selection process as a Determinantal Point Process, which good\nbalance among these criteria. We refine the query selection strategy by both\nselecting the hardest unlabeled data sample and biasing towards the classifiers\nthat are more suitable for the current data distribution. In addition, we also\nconsider the dependencies and relationships between these data points in data\nselection by means of centroidbased clustering approaches. Through evaluations\non synthetic and real-world datasets, we show that our method performs\nsignificantly better and is more stable than other multiple-criteria based AL\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Xueying Zhan",
      "Qing Li",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01622"
  },
  {
    "id": "arXiv:2107.01624",
    "title": "Implicit Gender Bias in Computer Science -- A Qualitative Study",
    "abstract": "Gender diversity in the tech sector is - not yet? - sufficient to create a\nbalanced ratio of men and women. For many women, access to computer science is\nhampered by socialization-related, social, cultural and structural obstacles.\nThe so-called implicit gender bias has a great influence in this respect. The\nlack of contact in areas of computer science makes it difficult to develop or\nexpand potential interests. Female role models as well as more transparency of\nthe job description should help women to promote their - possible - interest in\nthe job description. However, gender diversity can also be promoted and\nfostered through adapted measures by leaders.",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lie Breidenbach",
      "Caroline Mahlow",
      "Andreas Schreiber"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01624"
  },
  {
    "id": "arXiv:2107.01627",
    "title": "Machine Learning for Malware Evolution Detection",
    "abstract": "Malware evolves over time and antivirus must adapt to such evolution. Hence,\nit is critical to detect those points in time where malware has evolved so that\nappropriate countermeasures can be undertaken. In this research, we perform a\nvariety of experiments on a significant number of malware families to determine\nwhen malware evolution is likely to have occurred. All of the evolution\ndetection techniques that we consider are based on machine learning and can be\nfully automated -- in particular, no reverse engineering or other\nlabor-intensive manual analysis is required. Specifically, we consider analysis\nbased on hidden Markov models (HMM) and the word embedding techniques HMM2Vec\nand Word2Vec.",
    "descriptor": "",
    "authors": [
      "Lolitha Sresta Tupadha",
      "Mark Stamp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01627"
  },
  {
    "id": "arXiv:2107.01640",
    "title": "SEC-NoSQL: Towards Implementing High Performance Security-as-a-Service  for NoSQL Databases",
    "abstract": "During the last few years, the explosion of Big Data has prompted cloud\ninfrastructures to provide cloud-based database services as cost effective,\nefficient and scalable solutions to store and process large volume of data.\nHence, NoSQL databases became more and more popular because of their inherent\nfeatures of better performance and high scalability compared to other\nrelational databases. However, with this deployment architecture where the\ninformation is stored in a public cloud, protection against the sensitive data\nis still being a major concern. Since the data owner does not have the full\ncontrol over his sensitive data in a cloud-based database solution, many\norganizations are reluctant to move forward with Database-as-a-Service (DBaaS)\nsolutions. Some of the recent work addressed this issue by introducing\nadditional layers to provide encryption mechanisms to encrypt data, however,\nthese approaches are more application specific and they need to be properly\nevaluated to ensure whether they can achieve high performance with the\nscalability when it comes to large volume of data in a cloud-based production\nenvironment. This paper proposes a practical system design and implementation\nto provide Security-as-a-Service for NoSQL databases (SEC-NoSQL) while\nsupporting the execution of query over encrypted data with guaranteed level of\nsystem performance. Several different models of implementations are proposed,\nand their performance is evaluated using YCSB benchmark considering large\nnumber of clients processing simultaneously. Experimental results show that our\ndesign fits well on encrypted data while maintaining the high performance and\nscalability. Moreover, to deploy our solution as a cloud-based service, a\npractical guide establishing Service Level Agreement (SLA) is also included.",
    "descriptor": "",
    "authors": [
      "G. Dumindu Samaraweera",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01640"
  },
  {
    "id": "arXiv:2107.01641",
    "title": "A Theoretical Analysis of Fine-tuning with Linear Teachers",
    "abstract": "Fine-tuning is a common practice in deep learning, achieving excellent\ngeneralization results on downstream tasks using relatively little training\ndata. Although widely used in practice, it is lacking strong theoretical\nunderstanding. We analyze the sample complexity of this scheme for regression\nwith linear teachers in several architectures. Intuitively, the success of\nfine-tuning depends on the similarity between the source tasks and the target\ntask, however measuring it is non trivial. We show that a relevant measure\nconsiders the relation between the source task, the target task and the\ncovariance structure of the target data. In the setting of linear regression,\nwe show that under realistic settings a substantial sample complexity reduction\nis plausible when the above measure is low. For deep linear regression, we\npresent a novel result regarding the inductive bias of gradient-based training\nwhen the network is initialized with pretrained weights. Using this result we\nshow that the similarity measure for this setting is also affected by the depth\nof the network. We further present results on shallow ReLU models, and analyze\nthe dependence of sample complexity there on source and target tasks. We\nempirically demonstrate our results for both synthetic and realistic data.",
    "descriptor": "",
    "authors": [
      "Gal Shachaf",
      "Alon Brutzkus",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01641"
  },
  {
    "id": "arXiv:2107.01642",
    "title": "A Topic Guided Pointer-Generator Model for Generating Natural Language  Code Summaries",
    "abstract": "Code summarization is the task of generating natural language description of\nsource code, which is important for program understanding and maintenance.\nExisting approaches treat the task as a machine translation problem (e.g., from\nJava to English) and applied Neural Machine Translation models to solve the\nproblem. These approaches only consider a given code unit (e.g., a method)\nwithout its broader context. The lacking of context may hinder the NMT model\nfrom gathering sufficient information for code summarization. Furthermore,\nexisting approaches use a fixed vocabulary and do not fully consider the words\nin code, while many words in the code summary may come from the code. In this\nwork, we present a neural network model named ToPNN for code summarization,\nwhich uses the topics in a broader context (e.g., class) to guide the neural\nnetworks that combine the generation of new words and the copy of existing\nwords in code. Based on the model we present an approach for generating natural\nlanguage code summaries at the method level (i.e., method comments). We\nevaluate our approach using a dataset with 4,203,565 commented Java methods.\nThe results show significant improvement over state-of-the-art approaches and\nconfirm the positive effect of class topics and the copy mechanism.",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Xin Peng",
      "Jun Sun",
      "Yifan Zhao",
      "Chi Chen",
      "Jinkai Fan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01642"
  },
  {
    "id": "arXiv:2107.01649",
    "title": "Facility Location Games with Ordinal Preferences",
    "abstract": "We consider a new setting of facility location games with ordinal\npreferences. In such a setting, we have a set of agents and a set of\nfacilities. Each agent is located on a line and has an ordinal preference over\nthe facilities. Our goal is to design strategyproof mechanisms that elicit\ntruthful information (preferences and/or locations) from the agents and locate\nthe facilities to minimize both maximum and total cost objectives as well as to\nmaximize both minimum and total utility objectives. For the four possible\nobjectives, we consider the 2-facility settings in which only preferences are\nprivate, or locations are private. For each possible combination of the\nobjectives and settings, we provide lower and upper bounds on the approximation\nratios of strategyproof mechanisms, which are asymptotically tight up to a\nconstant. Finally, we discuss the generalization of our results beyond two\nfacilities and when the agents can misreport both locations and preferences.",
    "descriptor": "",
    "authors": [
      "Hau Chan",
      "Minming Li",
      "Chenhao Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.01649"
  },
  {
    "id": "arXiv:2107.01650",
    "title": "Learning ODEs via Diffeomorphisms for Fast and Robust Integration",
    "abstract": "Advances in differentiable numerical integrators have enabled the use of\ngradient descent techniques to learn ordinary differential equations (ODEs). In\nthe context of machine learning, differentiable solvers are central for Neural\nODEs (NODEs), a class of deep learning models with continuous depth, rather\nthan discrete layers. However, these integrators can be unsatisfactorily slow\nand inaccurate when learning systems of ODEs from long sequences, or when\nsolutions of the system vary at widely different timescales in each dimension.\nIn this paper we propose an alternative approach to learning ODEs from data: we\nrepresent the underlying ODE as a vector field that is related to another base\nvector field by a differentiable bijection, modelled by an invertible neural\nnetwork. By restricting the base ODE to be amenable to integration, we can\ndrastically speed up and improve the robustness of integration. We demonstrate\nthe efficacy of our method in training and evaluating continuous neural\nnetworks models, as well as in learning benchmark ODE systems. We observe\nimprovements of up to two orders of magnitude when integrating learned ODEs\nwith GPUs computation.",
    "descriptor": "",
    "authors": [
      "Weiming Zhi",
      "Tin Lai",
      "Lionel Ott",
      "Edwin V. Bonilla",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01650"
  },
  {
    "id": "arXiv:2107.01654",
    "title": "Efficient Explanations for Knowledge Compilation Languages",
    "abstract": "Knowledge compilation (KC) languages find a growing number of practical uses,\nincluding in Constraint Programming (CP) and in Machine Learning (ML). In most\napplications, one natural question is how to explain the decisions made by\nmodels represented by a KC language. This paper shows that for many of the best\nknown KC languages, well-known classes of explanations can be computed in\npolynomial time. These classes include deterministic decomposable negation\nnormal form (d-DNNF), and so any KC language that is strictly less succinct\nthan d-DNNF. Furthermore, the paper also investigates the conditions under\nwhich polynomial time computation of explanations can be extended to KC\nlanguages more succinct than d-DNNF.",
    "descriptor": "",
    "authors": [
      "Xuanxiang Huang",
      "Yacine Izza",
      "Alexey Ignatiev",
      "Martin C. Cooper",
      "Nicholas Asher",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01654"
  },
  {
    "id": "arXiv:2107.01655",
    "title": "Attribute-aware Explainable Complementary Clothing Recommendation",
    "abstract": "Modelling mix-and-match relationships among fashion items has become\nincreasingly demanding yet challenging for modern E-commerce recommender\nsystems. When performing clothes matching, most existing approaches leverage\nthe latent visual features extracted from fashion item images for compatibility\nmodelling, which lacks explainability of generated matching results and can\nhardly convince users of the recommendations. Though recent methods start to\nincorporate pre-defined attribute information (e.g., colour, style, length,\netc.) for learning item representations and improving the model\ninterpretability, their utilisation of attribute information is still mainly\nreserved for enhancing the learned item representations and generating\nexplanations via post-processing. As a result, this creates a severe bottleneck\nwhen we are trying to advance the recommendation accuracy and generating\nfine-grained explanations since the explicit attributes have only loose\nconnections to the actual recommendation process. This work aims to tackle the\nexplainability challenge in fashion recommendation tasks by proposing a novel\nAttribute-aware Fashion Recommender (AFRec). Specifically, AFRec recommender\nassesses the outfit compatibility by explicitly leveraging the extracted\nattribute-level representations from each item's visual feature. The attributes\nserve as the bridge between two fashion items, where we quantify the affinity\nof a pair of items through the learned compatibility between their attributes.\nExtensive experiments have demonstrated that, by making full use of the\nexplicit attributes in the recommendation process, AFRec is able to achieve\nstate-of-the-art recommendation accuracy and generate intuitive explanations at\nthe same time.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Tong Chen",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01655"
  },
  {
    "id": "arXiv:2107.01656",
    "title": "IITP at WAT 2021: System description for English-Hindi Multimodal  Translation Task",
    "abstract": "Neural Machine Translation (NMT) is a predominant machine translation\ntechnology nowadays because of its end-to-end trainable flexibility. However,\nNMT still struggles to translate properly in low-resource settings specifically\non distant language pairs. One way to overcome this is to use the information\nfrom other modalities if available. The idea is that despite differences in\nlanguages, both the source and target language speakers see the same thing and\nthe visual representation of both the source and target is the same, which can\npositively assist the system. Multimodal information can help the NMT system to\nimprove the translation by removing ambiguity on some phrases or words. We\nparticipate in the 8th Workshop on Asian Translation (WAT - 2021) for\nEnglish-Hindi multimodal translation task and achieve 42.47 and 37.50 BLEU\npoints for Evaluation and Challenge subset, respectively.",
    "descriptor": "",
    "authors": [
      "Baban Gain",
      "Dibyanayan Bandyopadhyay",
      "Asif Ekbal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01656"
  },
  {
    "id": "arXiv:2107.01657",
    "title": "Class Introspection: A Novel Technique for Detecting Unlabeled  Subclasses by Leveraging Classifier Explainability Methods",
    "abstract": "Detecting latent structure within a dataset is a crucial step in performing\nanalysis of a dataset. However, existing state-of-the-art techniques for\nsubclass discovery are limited: either they are limited to detecting very small\nnumbers of outliers or they lack the statistical power to deal with complex\ndata such as image or audio. This paper proposes a solution to this subclass\ndiscovery problem: by leveraging instance explanation methods, an existing\nclassifier can be extended to detect latent classes via differences in the\nclassifier's internal decisions about each instance. This works not only with\nsimple classification techniques but also with deep neural networks, allowing\nfor a powerful and flexible approach to detecting latent structure within\ndatasets. Effectively, this represents a projection of the dataset into the\nclassifier's \"explanation space,\" and preliminary results show that this\ntechnique outperforms the baseline for the detection of latent classes even\nwith limited processing. This paper also contains a pipeline for analyzing\nclassifiers automatically, and a web application for interactively exploring\nthe results from this technique.",
    "descriptor": "",
    "authors": [
      "Patrick Kage",
      "Pavlos Andreadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01657"
  },
  {
    "id": "arXiv:2107.01662",
    "title": "Security implications of digitalization: The dangers of data colonialism  and the way towards sustainable and sovereign management of environmental  data",
    "abstract": "Digitalization opens up new opportunities in the collection, analysis, and\npresentation of data which can contribute to the achievement of the 2030 Agenda\nand its Sustainable Development Goals (SDGs). In particular, the access to and\ncontrol of environmental and geospatial data is fundamental to identify and\nunderstand global issues and trends. Also immediate crises such as the COVID-19\npandemic demonstrate the importance of accurate health data such as infection\nstatistics and the relevance of digital tools like video conferencing\nplatforms. However, today much of the data is collected and processed by\nprivate actors. Thus, governments and researchers depend on data platforms and\nproprietary systems of big tech companies such as Google or Microsoft. The\nmarket capitalization of the seven largest US and Chinese big tech companies\nhas grown to 8.7tn USD in recent years, about twice the size of Germany's gross\ndomestic product (GDP). Therefore, their market power is enormous, allowing\nthem to dictate many rules of the digital space and even interfere with\nlegislations. Based on a literature review and nine expert interviews this\nstudy presents a framework that identifies the risks and consequences along the\nworkflow of collecting, processing, storing, using of data. It also includes\nsolutions that governmental and multilateral actors can strive for to alleviate\nthe risks. Fundamental to this framework is the novel concept of \"data\ncolonialism\" which describes today's trend of private companies appropriating\nthe digital sphere. Historically, colonial nations used to grab indigenous land\nand exploit the cheap labor of slave workers. In a similar way, today's big\ntech corporations use cheap data of their users to produce valuable services\nand thus create enormous market power.",
    "descriptor": "\nComments: This study was prepared under contract to the Federal Department of Foreign Affairs (FDFA). The authors bear responsibility for the content\n",
    "authors": [
      "Matthias St\u00fcrmer",
      "Jasmin Nussbaumer",
      "Pascal St\u00f6ckli"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.01662"
  },
  {
    "id": "arXiv:2107.01664",
    "title": "Repulsive Surfaces",
    "abstract": "Functionals that penalize bending or stretching of a surface play a key role\nin geometric and scientific computing, but to date have ignored a very basic\nrequirement: in many situations, surfaces must not pass through themselves or\neach other. This paper develops a numerical framework for optimization of\nsurface geometry while avoiding (self-)collision. The starting point is the\ntangent-point energy, which effectively pushes apart pairs of points that are\nclose in space but distant along the surface. We develop a discretization of\nthis energy for triangle meshes, and introduce a novel acceleration scheme\nbased on a fractional Sobolev inner product. In contrast to similar schemes\ndeveloped for curves, we avoid the complexity of building a multiresolution\nmesh hierarchy by decomposing our preconditioner into two ordinary Poisson\nequations, plus forward application of a fractional differential operator. We\nfurther accelerate this scheme via hierarchical approximation, and describe how\nto incorporate a variety of constraints (on area, volume, etc.). Finally, we\nexplore how this machinery might be applied to problems in mathematical\nvisualization, geometric modeling, and geometry processing.",
    "descriptor": "\nComments: 19 pages, 23 figures\n",
    "authors": [
      "Chris Yu",
      "Caleb Brakensiek",
      "Henrik Schumacher",
      "Keenan Crane"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01664"
  },
  {
    "id": "arXiv:2107.01667",
    "title": "Low Dimensional State Representation Learning with Robotics Priors in  Continuous Action Spaces",
    "abstract": "Autonomous robots require high degrees of cognitive and motoric intelligence\nto come into our everyday life. In non-structured environments and in the\npresence of uncertainties, such degrees of intelligence are not easy to obtain.\nReinforcement learning algorithms have proven to be capable of solving\ncomplicated robotics tasks in an end-to-end fashion without any need for\nhand-crafted features or policies. Especially in the context of robotics, in\nwhich the cost of real-world data is usually extremely high, reinforcement\nlearning solutions achieving high sample efficiency are needed. In this paper,\nwe propose a framework combining the learning of a low-dimensional state\nrepresentation, from high-dimensional observations coming from the robot's raw\nsensory readings, with the learning of the optimal policy, given the learned\nstate representation. We evaluate our framework in the context of mobile robot\nnavigation in the case of continuous state and action spaces. Moreover, we\nstudy the problem of transferring what learned in the simulated virtual\nenvironment to the real robot without further retraining using real-world data\nin the presence of visual and depth distractors, such as lighting changes and\nmoving obstacles.",
    "descriptor": "\nComments: Paper Accepted at IROS2021. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Khaled Alaa",
      "Mannes Poel",
      "Beril Sirmacek",
      "Christoph Brune",
      "Abeje Mersha",
      "Stefano Stramigioli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01667"
  },
  {
    "id": "arXiv:2107.01669",
    "title": "Real vs Simulated Foveated Rendering to Reduce Visual Discomfort in  Virtual Reality",
    "abstract": "In this paper, a study aimed at investigating the effects of real (using eye\ntracking to determine the fixation) and simulated foveated blurring in\nimmersive Virtual Reality is presented. Techniques to reduce the optical flow\nperceived at the visual field margins are often employed in immersive Virtual\nReality environments to alleviate discomfort experienced when the visual motion\nperception does not correspond to the body's acceleration. Although still\npreliminary, our results suggest that for participants with higher\nself-declared sensitivity to sickness, there might be an improvement for nausea\nwhen using blurring. The (perceived) difficulty of the task seems to improve\nwhen the real foveated method is used.",
    "descriptor": "\nComments: 9 pages, 2 figures, 1 table, to be published in proceedings of the 18th International Conference promoted by the IFIP Technical Committee 13 on Human Computer Interaction, INTERACT 2021. August 30th September 3rd, 2021, Bari, Italy\n",
    "authors": [
      "Ariel Caputo",
      "Andrea Giachetti",
      "Salwa Abkal",
      "Chiara Marchesini",
      "Massimo Zancanaro"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.01669"
  },
  {
    "id": "arXiv:2107.01671",
    "title": "Cognitive Visual Commonsense Reasoning Using Dynamic Working Memory",
    "abstract": "Visual Commonsense Reasoning (VCR) predicts an answer with corresponding\nrationale, given a question-image input. VCR is a recently introduced visual\nscene understanding task with a wide range of applications, including visual\nquestion answering, automated vehicle systems, and clinical decision support.\nPrevious approaches to solving the VCR task generally rely on pre-training or\nexploiting memory with long dependency relationship encoded models. However,\nthese approaches suffer from a lack of generalizability and prior knowledge. In\nthis paper we propose a dynamic working memory based cognitive VCR network,\nwhich stores accumulated commonsense between sentences to provide prior\nknowledge for inference. Extensive experiments show that the proposed model\nyields significant improvements over existing methods on the benchmark VCR\ndataset. Moreover, the proposed model provides intuitive interpretation into\nvisual commonsense reasoning. A Python implementation of our mechanism is\npublicly available at https://github.com/tanjatang/DMVCR",
    "descriptor": "",
    "authors": [
      "Xuejiao Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01671"
  },
  {
    "id": "arXiv:2107.01673",
    "title": "Sublinear-Space Approximation Algorithms for Max r-SAT",
    "abstract": "In the Max $r$-SAT problem, the input is a CNF formula with $n$ variables\nwhere each clause is a disjunction of at most $r$ literals. The objective is to\ncompute an assignment which satisfies as many of the clauses as possible. While\nthere are a large number of polynomial-time approximation algorithms for this\nproblem, we take the viewpoint of space complexity following [Biswas et al.,\nAlgorithmica 2021] and design sublinear-space approximation algorithms for the\nproblem.\nWe show that the classical algorithm of [Lieberherr and Specker, JACM 1981]\ncan be implemented to run in $n^{O(1)}$ time while using $(\\log{n})$ bits of\nspace. The more advanced algorithms use linear or semi-definite programming,\nand seem harder to carry out in sublinear space. We show that a more recent\nalgorithm with approximation ratio $\\sqrt{2}/2$ [Chou et al., FOCS 2020],\ndesigned for the streaming model, can be implemented to run in time $n^{O(r)}$\nusing $O(r \\log{n})$ bits of space. While known streaming algorithms for the\nproblem approximate optimum values and use randomization, our algorithms are\ndeterministic and can output the approximately optimal assignments in sublinear\nspace.\nFor instances of Max $r$-SAT with planar incidence graphs, we devise a\nfactor-$(1 - \\epsilon)$ approximation scheme which computes assignments in time\n$n^{O(r / \\epsilon)}$ and uses $\\max\\{\\sqrt{n} \\log{n}, (r / \\epsilon)\n\\log^2{n}\\}$ bits of space.",
    "descriptor": "",
    "authors": [
      "Arindam Biswas",
      "Venkatesh Raman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01673"
  },
  {
    "id": "arXiv:2107.01674",
    "title": "PyLUSAT: An open-source Python toolkit for GIS-based land use  suitability analysis",
    "abstract": "Desktop GIS applications, such as ArcGIS and QGIS, provide tools essential\nfor conducting suitability analysis, an activity that is central in formulating\na land-use plan. But, when it comes to building complicated land-use\nsuitability models, these applications have several limitations, including\noperating system-dependence, lack of dedicated modules, insufficient\nreproducibility, and difficult, if not impossible, deployment on a computing\ncluster. To address the challenges, this paper introduces PyLUSAT: Python for\nLand Use Suitability Analysis Tools. PyLUSAT is an open-source software package\nthat provides a series of tools (functions) to conduct various tasks in a\nsuitability modeling workflow. These tools were evaluated against comparable\ntools in ArcMap 10.4 with respect to both accuracy and computational\nefficiency. Results showed that PyLUSAT functions were two to ten times more\nefficient depending on the job's complexity, while generating outputs with\nsimilar accuracy compared to the ArcMap tools. PyLUSAT also features\nextensibility and cross-platform compatibility. It has been used to develop\nfourteen QGIS Processing Algorithms and implemented on a high-performance\ncomputational cluster (HiPerGator at the University of Florida) to expedite the\nprocess of suitability analysis. All these properties make PyLUSAT a\ncompetitive alternative solution for urban planners/researchers to customize\nand automate suitability analysis as well as integrate the technique into a\nlarger analytical framework.",
    "descriptor": "",
    "authors": [
      "Changjie Chen",
      "Jasmeet Judge",
      "David Hulse"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.01674"
  },
  {
    "id": "arXiv:2107.01677",
    "title": "Low-Dimensional State and Action Representation Learning with MDP  Homomorphism Metrics",
    "abstract": "Deep Reinforcement Learning has shown its ability in solving complicated\nproblems directly from high-dimensional observations. However, in end-to-end\nsettings, Reinforcement Learning algorithms are not sample-efficient and\nrequires long training times and quantities of data. In this work, we proposed\na framework for sample-efficient Reinforcement Learning that take advantage of\nstate and action representations to transform a high-dimensional problem into a\nlow-dimensional one. Moreover, we seek to find the optimal policy mapping\nlatent states to latent actions. Because now the policy is learned on abstract\nrepresentations, we enforce, using auxiliary loss functions, the lifting of\nsuch policy to the original problem domain. Results show that the novel\nframework can efficiently learn low-dimensional and interpretable state and\naction representations and the optimal latent policy.",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Mannes Poel",
      "Beril Sirmacek",
      "Christoph Brune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01677"
  },
  {
    "id": "arXiv:2107.01678",
    "title": "A Comprehensive Survey on the State-of-the-art Data Provenance  Approaches for Security Enforcement",
    "abstract": "Data provenance collects comprehensive information about the events and\noperations in a computer system at both application and system levels. It\nprovides a detailed and accurate history of transactions that help delineate\nthe data flow scenario across the whole system. Data provenance helps achieve\nsystem resilience by uncovering several malicious attack traces after a system\ncompromise that are leveraged by the analyzer to understand the attack behavior\nand discover the level of damage. Existing literature demonstrates a number of\nresearch efforts on information capture, management, and analysis of data\nprovenance. In recent years, provenance in IoT devices attracts several\nresearch efforts because of the proliferation of commodity IoT devices. In this\nsurvey paper, we present a comparative study of the state-of-the-art approaches\nto provenance by classifying them based on frameworks, deployed techniques, and\nsubjects of interest. We also discuss the emergence and scope of data\nprovenance in IoT networks. Finally, we present the urgency in several\ndirections that data provenance needs to pursue, including data management and\nanalysis.",
    "descriptor": "",
    "authors": [
      "Md Morshed Alam",
      "Weichao Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01678"
  },
  {
    "id": "arXiv:2107.01687",
    "title": "Linear-Time Model Checking Branching Processes",
    "abstract": "(Multi-type) branching processes are a natural and well-studied model for\ngenerating random infinite trees. Branching processes feature both\nnondeterministic and probabilistic branching, generalizing both transition\nsystems and Markov chains (but not generally Markov decision processes). We\nstudy the complexity of model checking branching processes against linear-time\nomega-regular specifications: is it the case almost surely that every branch of\na tree randomly generated by the branching process satisfies the omega-regular\nspecification? The main result is that for LTL specifications this problem is\nin PSPACE, subsuming classical results for transition systems and Markov\nchains, respectively. The underlying general model-checking algorithm is based\non the automata-theoretic approach, using unambiguous B\\\"uchi automata.",
    "descriptor": "\nComments: full version of a CONCUR'21 paper\n",
    "authors": [
      "Stefan Kiefer",
      "Pavel Semukhin",
      "Cas Widdershoven"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.01687"
  },
  {
    "id": "arXiv:2107.01689",
    "title": "Robust Restless Bandits: Tackling Interval Uncertainty with Deep  Reinforcement Learning",
    "abstract": "We introduce Robust Restless Bandits, a challenging generalization of\nrestless multi-arm bandits (RMAB). RMABs have been widely studied for\nintervention planning with limited resources. However, most works make the\nunrealistic assumption that the transition dynamics are known perfectly,\nrestricting the applicability of existing methods to real-world scenarios. To\nmake RMABs more useful in settings with uncertain dynamics: (i) We introduce\nthe Robust RMAB problem and develop solutions for a minimax regret objective\nwhen transitions are given by interval uncertainties; (ii) We develop a double\noracle algorithm for solving Robust RMABs and demonstrate its effectiveness on\nthree experimental domains; (iii) To enable our double oracle approach, we\nintroduce RMABPPO, a novel deep reinforcement learning algorithm for solving\nRMABs. RMABPPO hinges on learning an auxiliary \"$\\lambda$-network\" that allows\neach arm's learning to decouple, greatly reducing sample complexity required\nfor training; (iv) Under minimax regret, the adversary in the double oracle\napproach is notoriously difficult to implement due to non-stationarity. To\naddress this, we formulate the adversary oracle as a multi-agent reinforcement\nlearning problem and solve it with a multi-agent extension of RMABPPO, which\nmay be of independent interest as the first known algorithm for this setting.\nCode is available at https://github.com/killian-34/RobustRMAB.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Jackson A. Killian",
      "Lily Xu",
      "Arpita Biswas",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01689"
  },
  {
    "id": "arXiv:2107.01691",
    "title": "Bag of Instances Aggregation Boosts Self-supervised Learning",
    "abstract": "Recent advances in self-supervised learning have experienced remarkable\nprogress, especially for contrastive learning based methods, which regard each\nimage as well as its augmentations as an individual class and try to\ndistinguish them from all other images. However, due to the large quantity of\nexemplars, this kind of pretext task intrinsically suffers from slow\nconvergence and is hard for optimization. This is especially true for small\nscale models, which we find the performance drops dramatically comparing with\nits supervised counterpart. In this paper, we propose a simple but effective\ndistillation strategy for unsupervised learning. The highlight is that the\nrelationship among similar samples counts and can be seamlessly transferred to\nthe student to boost the performance. Our method, termed as BINGO, which is\nshort for \\textbf{B}ag of \\textbf{I}nsta\\textbf{N}ces\na\\textbf{G}gregati\\textbf{O}n, targets at transferring the relationship learned\nby the teacher to the student. Here bag of instances indicates a set of similar\nsamples constructed by the teacher and are grouped within a bag, and the goal\nof distillation is to aggregate compact representations over the student with\nrespect to instances in a bag. Notably, BINGO achieves new state-of-the-art\nperformance on small scale models, \\emph{i.e.}, 65.5% and 68.9% top-1\naccuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet-34 as\nbackbone, respectively, surpassing baselines (52.5% and 57.4% top-1 accuracies)\nby a significant margin. The code will be available at\n\\url{https://github.com/haohang96/bingo}.",
    "descriptor": "",
    "authors": [
      "Haohang Xu",
      "Jiemin Fang",
      "Xiaopeng Zhang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Wenrui Dai",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01691"
  },
  {
    "id": "arXiv:2107.01693",
    "title": "A precise bare simulation approach to the minimization of some  distances. Foundations",
    "abstract": "In information theory -- as well as in the adjacent fields of statistics,\nmachine learning, artificial intelligence, signal processing and pattern\nrecognition -- many flexibilizations of the omnipresent Kullback-Leibler\ninformation distance (relative entropy) and of the closely related Shannon\nentropy have become frequently used tools. To tackle corresponding constrained\nminimization (respectively maximization) problems by a newly developed\ndimension-free bare (pure) simulation method, is the main goal of this paper.\nAlmost no assumptions (like convexity) on the set of constraints are needed,\nwithin our discrete setup of arbitrary dimension, and our method is precise\n(i.e., converges in the limit). As a side effect, we also derive an innovative\nway of constructing new useful distances/divergences. To illustrate the core of\nour approach, we present numerous examples. The potential for widespread\napplicability is indicated, too; in particular, we deliver many recent\nreferences for uses of the involved distances/divergences and entropies in\nvarious different research fields (which may also serve as an interdisciplinary\ninterface).",
    "descriptor": "",
    "authors": [
      "Michel Broniatowski",
      "Wolfgang Stummer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01693"
  },
  {
    "id": "arXiv:2107.01694",
    "title": "Model Predictive Control for Electron Beam Stabilization in a  Synchrotron",
    "abstract": "Electron beam stabilization in a synchrotron is a disturbance rejection\nproblem, with hundreds of inputs and outputs, that is sampled at frequencies\nhigher than $10$ kHz. In this feasibility study, we focus on the practical\nissues of an efficient implementation of model predictive control (MPC) for the\nheavily ill-conditioned plant of the electron beam stabilization problem. To\nobtain a tractable control problem that can be solved using only a few\niterations of the fast gradient method, we investigate different methods for\npreconditioning the resulting optimization problem and relate our findings to\nstandard regularization techniques from cross-directional control. We summarize\nthe single- and multi-core implementations of our control algorithm on a\ndigital signal processor (DSP), and show that MPC can be executed at the rate\nrequired for synchrotron control. MPC overcomes various problems of standard\nelectron beam stabilization techniques, and the successful implementation can\nincrease the stability of photon beams in synchrotron light sources.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Idris Kempf",
      "Paul J. Goulart",
      "Stephen R. Duncan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01694"
  },
  {
    "id": "arXiv:2107.01700",
    "title": "End-to-end Neural Coreference Resolution Revisited: A Simple yet  Effective Baseline",
    "abstract": "Since the first end-to-end neural coreference resolution model was\nintroduced, many extensions to the model have been proposed, ranging from using\nhigher-order inference to directly optimizing evaluation metrics using\nreinforcement learning. Despite improving the coreference resolution\nperformance by a large margin, these extensions add a lot of extra complexity\nto the original model. Motivated by this observation and the recent advances in\npre-trained Transformer language models, we propose a simple yet effective\nbaseline for coreference resolution. Our model is a simplified version of the\noriginal neural coreference resolution model, however, it achieves impressive\nperformance, outperforming all recent extended works on the public English\nOntoNotes benchmark. Our work provides evidence for the necessity of carefully\njustifying the complexity of existing or newly proposed models, as introducing\na conceptual or practical simplification to an existing model can still yield\ncompetitive results.",
    "descriptor": "",
    "authors": [
      "Tuan Manh Lai",
      "Trung Bui",
      "Doo Soon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01700"
  },
  {
    "id": "arXiv:2107.01702",
    "title": "Data-Driven Learning of Feedforward Neural Networks with Different  Activation Functions",
    "abstract": "This work contributes to the development of a new data-driven method (D-DM)\nof feedforward neural networks (FNNs) learning. This method was proposed\nrecently as a way of improving randomized learning of FNNs by adjusting the\nnetwork parameters to the target function fluctuations. The method employs\nlogistic sigmoid activation functions for hidden nodes. In this study, we\nintroduce other activation functions, such as bipolar sigmoid, sine function,\nsaturating linear functions, reLU, and softplus. We derive formulas for their\nparameters, i.e. weights and biases. In the simulation study, we evaluate the\nperformance of FNN data-driven learning with different activation functions.\nThe results indicate that the sigmoid activation functions perform much better\nthan others in the approximation of complex, fluctuated target functions.",
    "descriptor": "\nComments: 20th International Conference on Artificial Intelligence and Soft Computing ICAISC 2021\n",
    "authors": [
      "Grzegorz Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01702"
  },
  {
    "id": "arXiv:2107.01705",
    "title": "Randomized Neural Networks for Forecasting Time Series with Multiple  Seasonality",
    "abstract": "This work contributes to the development of neural forecasting models with\nnovel randomization-based learning methods. These methods improve the fitting\nabilities of the neural model, in comparison to the standard method, by\ngenerating network parameters in accordance with the data and target function\nfeatures. A pattern-based representation of time series makes the proposed\napproach useful for forecasting time series with multiple seasonality. In the\nsimulation study, we evaluate the performance of the proposed models and find\nthat they can compete in terms of forecasting accuracy with fully-trained\nnetworks. Extremely fast and easy training, simple architecture, ease of\nimplementation, high accuracy as well as dealing with nonstationarity and\nmultiple seasonality in time series make the proposed model very attractive for\na wide range of complex time series forecasting problems.",
    "descriptor": "\nComments: International Work Conference on Artificial Neural Networks IWANN 2021\n",
    "authors": [
      "Grzegorz Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01705"
  },
  {
    "id": "arXiv:2107.01707",
    "title": "Towards Scheduling Federated Deep Learning using Meta-Gradients for  Inter-Hospital Learning",
    "abstract": "Given the abundance and ease of access of personal data today, individual\nprivacy has become of paramount importance, particularly in the healthcare\ndomain. In this work, we aim to utilise patient data extracted from multiple\nhospital data centres to train a machine learning model without sacrificing\npatient privacy. We develop a scheduling algorithm in conjunction with a\nstudent-teacher algorithm that is deployed in a federated manner. This allows a\ncentral model to learn from batches of data at each federal node. The teacher\nacts between data centres to update the main task (student) algorithm using the\ndata that is stored in the various data centres. We show that the scheduler,\ntrained using meta-gradients, can effectively organise training and as a result\ntrain a machine learning model on a diverse dataset without needing explicit\naccess to the patient data. We achieve state-of-the-art performance and show\nhow our method overcomes some of the problems faced in the federated learning\nsuch as node poisoning. We further show how the scheduler can be used as a\nmechanism for transfer learning, allowing different teachers to work together\nin training a student for state-of-the-art performance.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Rasheed el-Bouri",
      "Tingting Zhu",
      "David A. Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01707"
  },
  {
    "id": "arXiv:2107.01709",
    "title": "Mirror Mirror on the Wall: Next-Generation Wireless Jamming Attacks  Based on Software-Controlled Surfaces",
    "abstract": "The intelligent reflecting surface (IRS) is a promising new paradigm in\nwireless communications to meet the growing demand for high-speed connectivity\nin next-generation mobile networks. IRS, also known as software-controlled\nmetasurfaces, consist of an array of adjustable radio wave reflectors, enabling\nsmart radio environments, e.g., for enhancing the signal-to-noise ratio (SNR)\nand spatial diversity of wireless channels.\nResearch on IRS to date has been largely focused on constructive\napplications. In this work, we show for the first time that the IRS provides a\npractical low-cost toolkit for attackers to easily perform complex signal\nmanipulation attacks on the physical layer in real time. We introduce the\nenvironment reconfiguration attack (ERA) as a novel class of jamming attacks in\nwireless radio networks. Here, an adversary leverages an IRS to rapidly vary\nthe electromagnetic propagation environment to disturb legitimate receivers.\nThe IRS gives the adversary a key advantage over traditional jamming: It no\nlonger has to actively emit a jamming signal itself while the jamming signal is\ncorrelated to the legitimate communication signal.\nWe thoroughly investigate the ERA using the popular orthogonal frequency\ndivision multiplexing~(OFDM) modulation as an example. We show that the ERA\nallows to severely degrade the available data rates even in entire networks. We\npresent insights to the attack through analytical analysis, simulations, as\nwell as experiments. Our results highlight that the attack also works with\nreasonably small IRS sizes. Finally, we implement an attacker setup and\ndemonstrate a practical ERA to slow down a Wi-Fi network.",
    "descriptor": "",
    "authors": [
      "Paul Staat",
      "Harald Elders-Boll",
      "Christian Zenger",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01709"
  },
  {
    "id": "arXiv:2107.01711",
    "title": "Autoencoder based Randomized Learning of Feedforward Neural Networks for  Regression",
    "abstract": "Feedforward neural networks are widely used as universal predictive models to\nfit data distribution. Common gradient-based learning, however, suffers from\nmany drawbacks making the training process ineffective and time-consuming.\nAlternative randomized learning does not use gradients but selects hidden node\nparameters randomly. This makes the training process extremely fast. However,\nthe problem in randomized learning is how to determine the random parameters. A\nrecently proposed method uses autoencoders for unsupervised parameter learning.\nThis method showed superior performance on classification tasks. In this work,\nwe apply this method to regression problems, and, finding that it has some\ndrawbacks, we show how to improve it. We propose a learning method of\nautoencoders that controls the produced random weights. We also propose how to\ndetermine the biases of hidden nodes. We empirically compare autoencoder based\nlearning with other randomized learning methods proposed recently for\nregression and find that despite the proposed improvement of the autoencoder\nbased learning, it does not outperform its competitors in fitting accuracy.\nMoreover, the method is much more complex than its competitors.",
    "descriptor": "\nComments: International Joint Conference on Neural Networks IJCNN 2021\n",
    "authors": [
      "Grzegorz Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01711"
  },
  {
    "id": "arXiv:2107.01713",
    "title": "A Multilayer Network Model of the Coevolution of the Spread of a Disease  and Competing Opinions",
    "abstract": "During the COVID-19 pandemic, conflicting opinions on physical distancing\nswept across social media, affecting both human behavior and the spread of\nCOVID-19. Inspired by such phenomena, we construct a two-layer multiplex\nnetwork for the coupled spread of a disease and conflicting opinions. We model\neach process as a contagion. On one layer, we consider the concurrent evolution\nof two opinions -- pro-physical-distancing and anti-physical-distancing -- that\ncompete with each other and have mutual immunity to each other. The disease\nevolves on the other layer, and individuals are less likely (respectively, more\nlikely) to become infected when they adopt the pro-physical-distancing\n(respectively, anti-physical-distancing) opinion. We develop approximations of\nmean-field type by generalizing monolayer pair approximations to multilayer\nnetworks; these approximations agree well with Monte Carlo simulations for a\nbroad range of parameters and several network structures. Through numerical\nsimulations, we illustrate the influence of opinion dynamics on the spread of\nthe disease from complex interactions both between the two conflicting opinions\nand between the opinions and the disease. We find that lengthening the duration\nthat individuals hold an opinion may help suppress disease transmission, and we\ndemonstrate that increasing the cross-layer correlations or intra-layer\ncorrelations of node degrees may lead to fewer individuals becoming infected\nwith the disease.",
    "descriptor": "",
    "authors": [
      "Kaiyan Peng",
      "Zheng Lu",
      "Vanessa Lin",
      "Michael R. Lindstrom",
      "Christian Parkinson",
      "Chuntian Wang",
      "Andrea L. Bertozzi",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2107.01713"
  },
  {
    "id": "arXiv:2107.01715",
    "title": "Improve Agents without Retraining: Parallel Tree Search with Off-Policy  Correction",
    "abstract": "Tree Search (TS) is crucial to some of the most influential successes in\nreinforcement learning. Here, we tackle two major challenges with TS that limit\nits usability: \\textit{distribution shift} and \\textit{scalability}. We first\ndiscover and analyze a counter-intuitive phenomenon: action selection through\nTS and a pre-trained value function often leads to lower performance compared\nto the original pre-trained agent, even when having access to the exact state\nand reward in future steps. We show this is due to a distribution shift to\nareas where value estimates are highly inaccurate and analyze this effect using\nExtreme Value theory. To overcome this problem, we introduce a novel off-policy\ncorrection term that accounts for the mismatch between the pre-trained value\nand its corresponding TS policy by penalizing under-sampled trajectories. We\nprove that our correction eliminates the above mismatch and bound the\nprobability of sub-optimal action selection. Our correction significantly\nimproves pre-trained Rainbow agents without any further training, often more\nthan doubling their scores on Atari games. Next, we address the scalability\nissue given by the computational complexity of exhaustive TS that scales\nexponentially with the tree depth. We introduce Batch-BFS: a GPU breadth-first\nsearch that advances all nodes in each depth of the tree simultaneously.\nBatch-BFS reduces runtime by two orders of magnitude and, beyond inference,\nenables also training with TS of depths that were not feasible before. We train\nDQN agents from scratch using TS and show improvement in several Atari games\ncompared to both the original DQN and the more advanced Rainbow.",
    "descriptor": "",
    "authors": [
      "Assaf Hallak",
      "Gal Dalal",
      "Steven Dalton",
      "Iuri Frosio",
      "Shie Mannor",
      "Gal Chechik"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01715"
  },
  {
    "id": "arXiv:2107.01717",
    "title": "The $b$-weight distribution for MDS codes",
    "abstract": "For a positive integer $b\\ge2$, the $b$-symbol code is a new coding framework\nproposed to combat $b$-errors in $b$-symbol read channels. Especially, a\n$2$-symbol code is called a symbol-pair code. Remarkably, a classical maximum\ndistance separable (MDS) code is also an MDS $b$-symbol code. Recently, for any\nMDS code $\\mathcal{C}$, Ma and Luo determined the symbol-pair weight\ndistribution for $\\mathcal{C}$. In this paper, by calculating the number of\ncodewords in $\\mathcal{C}$ with special shape, we obtain the $b$-weight\ndistribution for $\\mathcal{C}$, and then generalize Theorem $1$ in \\cite{ML}.",
    "descriptor": "",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.01717"
  },
  {
    "id": "arXiv:2107.01721",
    "title": "Fine-Grained Completeness for Optimization in P",
    "abstract": "We initiate the study of fine-grained completeness theorems for exact and\napproximate optimization in the polynomial-time regime. Inspired by the first\ncompleteness results for decision problems in P (Gao, Impagliazzo, Kolokolova,\nWilliams, TALG 2019) as well as the classic class MaxSNP and\nMaxSNP-completeness for NP optimization problems (Papadimitriou, Yannakakis,\nJCSS 1991), we define polynomial-time analogues MaxSP and MinSP, which contain\na number of natural optimization problems in P, including Maximum Inner\nProduct, general forms of nearest neighbor search and optimization variants of\nthe $k$-XOR problem. Specifically, we define MaxSP as the class of problems\ndefinable as $\\max_{x_1,\\dots,x_k} \\#\\{ (y_1,\\dots,y_\\ell) :\n\\phi(x_1,\\dots,x_k, y_1,\\dots,y_\\ell) \\}$, where $\\phi$ is a quantifier-free\nfirst-order property over a given relational structure (with MinSP defined\nanalogously). On $m$-sized structures, we can solve each such problem in time\n$O(m^{k+\\ell-1})$. Our results are:\n- We determine (a sparse variant of) the Maximum/Minimum Inner Product\nproblem as complete under *deterministic* fine-grained reductions: A strongly\nsubquadratic algorithm for Maximum/Minimum Inner Product would beat the\nbaseline running time of $O(m^{k+\\ell-1})$ for *all* problems in MaxSP/MinSP by\na polynomial factor.\n- This completeness transfers to approximation: Maximum/Minimum Inner Product\nis also complete in the sense that a strongly subquadratic $c$-approximation\nwould give a $(c+\\varepsilon)$-approximation for all MaxSP/MinSP problems in\ntime $O(m^{k+\\ell-1-\\delta})$, where $\\varepsilon > 0$ can be chosen\narbitrarily small. Combining our completeness with~(Chen, Williams, SODA 2019),\nwe obtain the perhaps surprising consequence that refuting the OV Hypothesis is\n*equivalent* to giving a $O(1)$-approximation for all MinSP problems in\nfaster-than-$O(m^{k+\\ell-1})$ time.",
    "descriptor": "\nComments: Full version of APPROX'21 paper, abstract shortened to fit ArXiv requirements\n",
    "authors": [
      "Karl Bringmann",
      "Alejandro Cassis",
      "Nick Fischer",
      "Marvin K\u00fcnnemann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01721"
  },
  {
    "id": "arXiv:2107.01724",
    "title": "Scalable Zonotopic Under-approximation of Backward Reachable Sets for  Uncertain Linear Systems",
    "abstract": "Zonotopes are widely used for over-approximating forward reachable sets of\nuncertain linear systems. In this paper, we use zonotopes to achieve more\nscalable algorithms that under-approximate backward reachable sets for\nuncertain linear systems. The main difference is that the backward reachability\nanalysis is a two-player game and involves Minkowski difference operations, but\nzonotopes are not closed under such operations. We under-approximate this\nMinkowski difference with a zonotope, which can be obtained by solving a linear\noptimization problem. We further develop an efficient zonotope order reduction\ntechnique to bound the complexity of the obtained zonotopic\nunder-approximations. The proposed approach is evaluated against existing\napproaches using randomly generated instances, and illustrated with an aircraft\nposition control system.",
    "descriptor": "",
    "authors": [
      "Liren Yang",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01724"
  },
  {
    "id": "arXiv:2107.01725",
    "title": "Real-time Detection and Adaptive Mitigation of Power-based Side-Channel  Leakage in SoC",
    "abstract": "Power-based side-channel is a serious security threat to the System on Chip\n(SoC). The secret information is leaked from the power profile of the system\nwhile a cryptographic algorithm is running. The mitigation requires efforts\nfrom both the software level and hardware level. Currently, there is no\ncomprehensive solution that can guarantee the whole complex system is free of\nleakage and can generically protect all cryptographic algorithms. In this\npaper, we propose a real-time leakage detection and mitigation system which\nenables the system to monitor the side-channel leakage effects of the hardware.\nOur proposed system has extensions that provide a real-time monitor of power\nconsumption, detection of side-channel leakage, and real-time adaptive\nmitigation of detected side-channel leakage. Our proposed system is generic and\ncan protect any algorithm running on it.",
    "descriptor": "",
    "authors": [
      "Pantea Kiaei",
      "Yuan Yao",
      "Patrick Schaumont"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.01725"
  },
  {
    "id": "arXiv:2107.01726",
    "title": "Adaptive calibration for binary classification",
    "abstract": "This note proposes a way of making probability forecasting rules less\nsensitive to changes in data distribution, concentrating on the simple case of\nbinary classification. This is important in applications of machine learning,\nwhere the quality of a trained predictor may drop significantly in the process\nof its exploitation. Our techniques are based on recent work on conformal test\nmartingales and older work on prediction with expert advice, namely tracking\nthe best expert.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Vladimir Vovk",
      "Ivan Petej",
      "Alex Gammerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01726"
  },
  {
    "id": "arXiv:2107.01729",
    "title": "Multi-layer Hebbian networks with modern deep learning frameworks",
    "abstract": "Deep learning networks generally use non-biological learning methods. By\ncontrast, networks based on more biologically plausible learning, such as\nHebbian learning, show comparatively poor performance and difficulties of\nimplementation. Here we show that hierarchical, convolutional Hebbian learning\ncan be implemented almost trivially with modern deep learning frameworks, by\nusing specific losses whose gradients produce exactly the desired Hebbian\nupdates. We provide expressions whose gradients exactly implement a plain\nHebbian rule (dw ~= xy), Grossberg's instar rule (dw ~= y(x-w)), and Oja's rule\n(dw ~= y(x-yw)). As an application, we build Hebbian convolutional multi-layer\nnetworks for object recognition. We observe that higher layers of such networks\ntend to learn large, simple features (Gabor-like filters and blobs), explaining\nthe previously reported decrease in decoding performance over successive\nlayers. To combat this tendency, we introduce interventions (denser activations\nwith sparse plasticity, pruning of connections between layers) which result in\nsparser learned features, massively increase performance, and allow information\nto increase over successive layers. We hypothesize that more advanced\ntechniques (dynamic stimuli, trace learning, feedback connections, etc.),\ntogether with the massive computational boost offered by modern deep learning\nframeworks, could greatly improve the performance and biological relevance of\nmulti-layer Hebbian networks.",
    "descriptor": "\nComments: All code available at this https URL\n",
    "authors": [
      "Thomas Miconi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01729"
  },
  {
    "id": "arXiv:2107.01733",
    "title": "Toward Increased Airspace Safety: Quadrotor Guidance for Targeting  Aerial Objects",
    "abstract": "As the market for commercially available unmanned aerial vehicles (UAVs)\nbooms, there is an increasing number of small, teleoperated or autonomous\naircraft found in protected or sensitive airspace. Existing solutions for\nremoval of these aircraft are either military-grade and too disruptive for\ndomestic use, or compose of cumbersomely teleoperated counter-UAV vehicles that\nhave proven ineffective in high-profile domestic cases. In this work, we\nexamine the use of a quadrotor for autonomously targeting semi-stationary and\nmoving aerial objects with little or no prior knowledge of the target's flight\ncharacteristics. Guidance and control commands are generated with information\njust from an onboard monocular camera. We draw inspiration from literature in\nmissile guidance, and demonstrate an optimal guidance method implemented on a\nquadrotor but not usable by missiles. Results are presented for first-pass hit\nsuccess and pursuit duration with various methods. Finally, we cover the CMU\nTeam Tartan entry in the MBZIRC 2020 Challenge 1 competition, demonstrating the\neffectiveness of simple line-of-sight guidance methods in a structured\ncompetition setting.",
    "descriptor": "\nComments: 58 pages, 33 figures, 2 tables. Thesis towards a Master of Science in Robotics, CMU\n",
    "authors": [
      "Anish Bhattacharya"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01733"
  },
  {
    "id": "arXiv:2107.01735",
    "title": "Cloud Versus Local Processing in Distributed Networks",
    "abstract": "A method for evaluating the relative performance of local, cloud and combined\nprocessing of divisible (i.e. partitionable) data loads is presented. It is\nshown how to do this in the context of Amdahl's law. A single level (star)\nnetwork operating under each of three fundamental scheduling policies is used\nas an example. Applications include mobile computing, cloud computing and\nsignature searching.",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Abdulaziz M. Alqarni",
      "Thomas G. Robertazzi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01735"
  },
  {
    "id": "arXiv:2107.01739",
    "title": "KAISA: An Adaptive Second-order Optimizer Framework for Deep Neural  Networks",
    "abstract": "Kronecker-factored Approximate Curvature (K-FAC) has recently been shown to\nconverge faster in deep neural network (DNN) training than stochastic gradient\ndescent (SGD); however, K-FAC's larger memory footprint hinders its\napplicability to large models. We present KAISA, a K-FAC-enabled, Adaptable,\nImproved, and ScAlable second-order optimizer framework that adapts the memory\nfootprint, communication, and computation given specific models and hardware to\nachieve maximized performance and enhanced scalability. We quantify the\ntradeoffs between memory and communication cost and evaluate KAISA on large\nmodels, including ResNet-50, Mask R-CNN, U-Net, and BERT, on up to 128 NVIDIA\nA100 GPUs. Compared to the original optimizers, KAISA converges 18.1-36.3%\nfaster across applications with the same global batch size. Under a fixed\nmemory budget, KAISA converges 32.5% and 41.6% faster in ResNet-50 and\nBERT-Large, respectively. KAISA can balance memory and communication to achieve\nscaling efficiency equal to or better than the baseline optimizers.",
    "descriptor": "\nComments: To be published in the proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC21)\n",
    "authors": [
      "J. Gregory Pauloski",
      "Qi Huang",
      "Lei Huang",
      "Shivaram Venkataraman",
      "Kyle Chard",
      "Ian Foster",
      "Zhao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01739"
  },
  {
    "id": "arXiv:2107.01752",
    "title": "Polymorphic dynamic programming by algebraic shortcut fusion",
    "abstract": "Dynamic programming (DP) is a broadly applicable algorithmic design paradigm\nfor the efficient, exact solution of otherwise intractable, combinatorial\nproblems. However, the design of such algorithms is often presented informally\nin an ad-hoc manner, and as a result is often difficult to apply correctly. In\nthis paper, we present a rigorous algebraic formalism for systematically\nderiving novel DP algorithms, either from existing DP algorithms or from simple\nfunctional recurrences. These derivations lead to algorithms which are provably\ncorrect and polymorphic over any semiring, which means that they can be applied\nto the full scope of combinatorial problems expressible in terms of semirings.\nThis includes, for example: optimization, optimal probability and Viterbi\ndecoding, probabilistic marginalization, logical inference, fuzzy sets,\ndifferentiable softmax, and relational and provenance queries. The approach,\nbuilding on many ideas from the existing literature on constructive\nalgorithmics, exploits generic properties of (semiring) polymorphic functions,\ntupling and formal sums (lifting), and algebraic simplifications arising from\nconstraint algebras. We demonstrate the effectiveness of this formalism for\nsome example applications arising in signal processing, bioinformatics and\nreliability engineering.",
    "descriptor": "",
    "authors": [
      "Max A. Little",
      "Ugur Kayas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2107.01752"
  },
  {
    "id": "arXiv:2107.01757",
    "title": "The Least Restriction for Offline Reinforcement Learning",
    "abstract": "Many practical applications of reinforcement learning (RL) constrain the\nagent to learn from a fixed offline dataset of logged interactions, which has\nalready been gathered, without offering further possibility for data\ncollection. However, commonly used off-policy RL algorithms, such as the Deep Q\nNetwork and the Deep Deterministic Policy Gradient, are incapable of learning\nwithout data correlated to the distribution under the current policy, making\nthem ineffective for this offline setting. As the first step towards useful\noffline RL algorithms, we analysis the reason of instability in standard\noff-policy RL algorithms. It is due to the bootstrapping error. The key to\navoiding this error, is ensuring that the agent's action space does not go out\nof the fixed offline dataset. Based on our consideration, a creative offline RL\nframework, the Least Restriction (LR), is proposed in this paper. The LR\nregards selecting an action as taking a sample from the probability\ndistribution. It merely set a little limit for action selection, which not only\navoid the action being out of the offline dataset but also remove all the\nunreasonable restrictions in earlier approaches (e.g. Batch-Constrained Deep\nQ-Learning). In the further, we will demonstrate that the LR, is able to learn\nrobustly from different offline datasets, including random and suboptimal\ndemonstrations, on a range of practical control tasks.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Zizhou Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01757"
  },
  {
    "id": "arXiv:2107.01759",
    "title": "Learning Delaunay Triangulation using Self-attention and Domain  Knowledge",
    "abstract": "Delaunay triangulation is a well-known geometric combinatorial optimization\nproblem with various applications. Many algorithms can generate Delaunay\ntriangulation given an input point set, but most are nontrivial algorithms\nrequiring an understanding of geometry or the performance of additional\ngeometric operations, such as the edge flip. Deep learning has been used to\nsolve various combinatorial optimization problems; however, generating Delaunay\ntriangulation based on deep learning remains a difficult problem, and very few\nresearch has been conducted due to its complexity. In this paper, we propose a\nnovel deep-learning-based approach for learning Delaunay triangulation using a\nnew attention mechanism based on self-attention and domain knowledge. The\nproposed model is designed such that the model efficiently learns\npoint-to-point relationships using self-attention in the encoder. In the\ndecoder, a new attention score function using domain knowledge is proposed to\nprovide a high penalty when the geometric requirement is not satisfied. The\nstrength of the proposed attention score function lies in its ability to extend\nits application to solving other combinatorial optimization problems involving\ngeometry. When the proposed neural net model is well trained, it is simple and\nefficient because it automatically predicts the Delaunay triangulation for an\ninput point set without requiring any additional geometric operations. We\nconduct experiments to demonstrate the effectiveness of the proposed model and\nconclude that it exhibits better performance compared with other\ndeep-learning-based approaches.",
    "descriptor": "",
    "authors": [
      "Jaeseung Lee",
      "Woojin Choi",
      "Jibum Kim"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01759"
  },
  {
    "id": "arXiv:2107.01760",
    "title": "Single Model for Influenza Forecasting of Multiple Countries by  Multi-task Learning",
    "abstract": "The accurate forecasting of infectious epidemic diseases such as influenza is\na crucial task undertaken by medical institutions. Although numerous flu\nforecasting methods and models based mainly on historical flu activity data and\nonline user-generated contents have been proposed in previous studies, no flu\nforecasting model targeting multiple countries using two types of data exists\nat present. Our paper leverages multi-task learning to tackle the challenge of\nbuilding one flu forecasting model targeting multiple countries; each country\nas each task. Also, to develop the flu prediction model with higher\nperformance, we solved two issues; finding suitable search queries, which are\npart of the user-generated contents, and how to leverage search queries\nefficiently in the model creation. For the first issue, we propose the transfer\napproaches from English to other languages. For the second issue, we propose a\nnovel flu forecasting model that takes advantage of search queries using an\nattention mechanism and extend the model to a multi-task model for multiple\ncountries' flu forecasts. Experiments on forecasting flu epidemics in five\ncountries demonstrate that our model significantly improved the performance by\nleveraging the search queries and multi-task learning compared to the\nbaselines.",
    "descriptor": "\nComments: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), 2021\n",
    "authors": [
      "Taichi Murayama",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01760"
  },
  {
    "id": "arXiv:2107.01762",
    "title": "Energy Management Strategy for Unmanned Tracked Vehicles Based on Local  Speed Planning",
    "abstract": "The hybrid electric system has good potential for unmanned tracked vehicles\ndue to its excellent power and economy. Due to unmanned tracked vehicles have\nno traditional driving devices, and the driving cycle is uncertain, it brings\nnew challenges to conventional energy management strategies. This paper\nproposes a novel energy management strategy for unmanned tracked vehicles based\non local speed planning. The contributions are threefold. Firstly, a local\nspeed planning algorithm is adopted for the input of driving cycle prediction\nto avoid the dependence of traditional vehicles on driver's operation.\nSecondly, a prediction model based on Convolutional Neural Networks and Long\nShort-Term Memory (CNN-LSTM) is proposed, which is used to process both the\nplanned and the historical velocity series to improve the prediction accuracy.\nFinally, based on the prediction results, the model predictive control\nalgorithm is used to realize the real-time optimization of energy management.\nThe validity of the method is verified by simulation using collected data from\nactual field experiments of our unmanned tracked vehicle. Compared with\nmulti-step neural networks, the prediction model based on CNN-LSTM improves the\nprediction accuracy by 20%. Compared with the traditional regular energy\nmanagement strategy, the energy management strategy based on model predictive\ncontrol reduces fuel consumption by 7%.",
    "descriptor": "",
    "authors": [
      "Tianxing Sun",
      "Shaohang Xu",
      "Zirui Li",
      "Yingqi Tan",
      "Huiyan Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01762"
  },
  {
    "id": "arXiv:2107.01763",
    "title": "Exploration of increasing drivers trust in a semi-autonomous vehicle  through real time visualizations of collaborative driving dynamic",
    "abstract": "The Thinking Wave is an ongoing development of visualization concepts showing\nthe real-time effort and confidence of semi-autonomous vehicle (AV) systems.\nOffering drivers access to this information can inform their decision making,\nand enable them to handle the situation accordingly and takeover when\nnecessary. Two different visualizations have been designed, Concept one, Tidal,\ndemonstrates the AV systems effort through intensified activity of a simple\ngraphic which fluctuates in speed and frequency. Concept two, Tandem, displays\nthe effort of the AV system as well as the handling dynamic and shared\nresponsibility between the driver and the vehicle system. Working\ncollaboratively with mobility research teams at the University of Tokyo, we are\nprototyping and refining the Thinking Wave and its embodiments as we work\ntowards building a testable version integrated into a driving simulator. The\ndevelopment of the thinking wave aims to calibrate trust by increasing the\ndrivers knowledge and understanding of vehicle handling capacity. By enabling\ntransparent communication of the AV systems capacity, we hope to empower\nAV-skeptic drivers and keep over-trusting drivers on alert in the case of an\nemergency takeover situation, in order to create a safer autonomous driving\nexperience.",
    "descriptor": "\nComments: 8 pages, 11 figures, 2021 IEEE Intelligent Vehicles Symposium (IV21)\n",
    "authors": [
      "A. Koegel",
      "C. Furet",
      "T. Suzuki",
      "Y. Klebanov",
      "J. Hu",
      "T. Kappeler",
      "D. Okazaki",
      "K. Matsui",
      "T. Hiraoka",
      "K. Shimono",
      "K. Nakano",
      "K. Honma",
      "M. Pennington"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.01763"
  },
  {
    "id": "arXiv:2107.01766",
    "title": "E-SC4R: Explaining Software Clustering for Remodularisation",
    "abstract": "Maintenance of existing software requires a large amount of time for\ncomprehending the source code. The architecture of a software, however, may not\nbe clear to maintainers if up to date documentations are not available.\nSoftware clustering is often used as a remodularisation and architecture\nrecovery technique to help recover a semantic representation of the software\ndesign. Due to the diverse domains, structure, and behaviour of software\nsystems, the suitability of different clustering algorithms for different\nsoftware systems are not investigated thoroughly. Research that introduce new\nclustering techniques usually validate their approaches on a specific domain,\nwhich might limit its generalisability. If the chosen test subjects could only\nrepresent a narrow perspective of the whole picture, researchers might risk not\nbeing able to address the external validity of their findings. This work aims\nto fill this gap by introducing a new approach, Explaining Software Clustering\nfor Remodularisation, to evaluate the effectiveness of different software\nclustering approaches. This work focuses on hierarchical clustering and Bunch\nclustering algorithms and provides information about their suitability\naccording to the features of the software, which as a consequence, enables the\nselection of the most optimum algorithm and configuration from our existing\npool of choices for a particular software system. The proposed framework is\ntested on 30 open source software systems with varying sizes and domains, and\ndemonstrates that it can characterise both the strengths and weaknesses of the\nanalysed software clustering algorithms using software features extracted from\nthe code. The proposed approach also provides a better understanding of the\nalgorithms behaviour through the application of dimensionality reduction\ntechniques.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Alvin Jian Jia Tan",
      "Chun Yong Chong",
      "Aldeida Aleti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01766"
  },
  {
    "id": "arXiv:2107.01776",
    "title": "Continual Contrastive Self-supervised Learning for Image Classification",
    "abstract": "For artificial learning systems, continual learning over time from a stream\nof data is essential. The burgeoning studies on supervised continual learning\nhave achieved great progress, while the study of catastrophic forgetting in\nunsupervised learning is still blank. Among unsupervised learning methods,\nself-supervise learning method shows tremendous potential on visual\nrepresentation without any labeled data at scale. To improve the visual\nrepresentation of self-supervised learning, larger and more varied data is\nneeded. In the real world, unlabeled data is generated at all times. This\ncircumstance provides a huge advantage for the learning of the self-supervised\nmethod. However, in the current paradigm, packing previous data and current\ndata together and training it again is a waste of time and resources. Thus, a\ncontinual self-supervised learning method is badly needed. In this paper, we\nmake the first attempt to implement the continual contrastive self-supervised\nlearning by proposing a rehearsal method, which keeps a few exemplars from the\nprevious data. Instead of directly combining saved exemplars with the current\ndata set for training, we leverage self-supervised knowledge distillation to\ntransfer contrastive information among previous data to the current network by\nmimicking similarity score distribution inferred by the old network over a set\nof saved exemplars. Moreover, we build an extra sample queue to assist the\nnetwork to distinguish between previous and current data and prevent mutual\ninterference while learning their own feature representation. Experimental\nresults show that our method performs well on CIFAR100 and ImageNet-Sub.\nCompared with self-supervised baselines, which learning tasks one by one\nwithout taking any technique, we improve the image classification top-1\naccuracy by 1.60% on CIFAR100 and 2.86% on ImageNet-Sub under 10 incremental\nsteps setting.",
    "descriptor": "",
    "authors": [
      "Zhiwei Lin",
      "Yongtao Wang",
      "Hongxiang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01776"
  },
  {
    "id": "arXiv:2107.01779",
    "title": "Depth Quality-Inspired Feature Manipulation for Efficient RGB-D Salient  Object Detection",
    "abstract": "RGB-D salient object detection (SOD) recently has attracted increasing\nresearch interest by benefiting conventional RGB SOD with extra depth\ninformation. However, existing RGB-D SOD models often fail to perform well in\nterms of both efficiency and accuracy, which hinders their potential\napplications on mobile devices and real-world problems. An underlying challenge\nis that the model accuracy usually degrades when the model is simplified to\nhave few parameters. To tackle this dilemma and also inspired by the fact that\ndepth quality is a key factor influencing the accuracy, we propose a novel\ndepth quality-inspired feature manipulation (DQFM) process, which is efficient\nitself and can serve as a gating mechanism for filtering depth features to\ngreatly boost the accuracy. DQFM resorts to the alignment of low-level RGB and\ndepth features, as well as holistic attention of the depth stream to explicitly\ncontrol and enhance cross-modal fusion. We embed DQFM to obtain an efficient\nlight-weight model called DFM-Net, where we also design a tailored depth\nbackbone and a two-stage decoder for further efficiency consideration.\nExtensive experimental results demonstrate that our DFM-Net achieves\nstate-of-the-art accuracy when comparing to existing non-efficient models, and\nmeanwhile runs at 140ms on CPU (2.2$\\times$ faster than the prior fastest\nefficient model) with only $\\sim$8.5Mb model size (14.9% of the prior\nlightest). Our code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Wenbo Zhang",
      "Ge-Peng Ji",
      "Zhuo Wang",
      "Keren Fu",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01779"
  },
  {
    "id": "arXiv:2107.01782",
    "title": "A contextual analysis of multi-layer perceptron models in classifying  hand-written digits and letters: limited resources",
    "abstract": "Classifying hand-written digits and letters has taken a big leap with the\nintroduction of ConvNets. However, on very constrained hardware the time\nnecessary to train such models would be high. Our main contribution is twofold.\nFirst, we extensively test an end-to-end vanilla neural network (MLP) approach\nin pure numpy without any pre-processing or feature extraction done beforehand.\nSecond, we show that basic data mining operations can significantly improve the\nperformance of the models in terms of computational time, without sacrificing\nmuch accuracy. We illustrate our claims on a simpler variant of the Extended\nMNIST dataset, called Balanced EMNIST dataset. Our experiments show that,\nwithout any data mining, we get increased generalization performance when using\nmore hidden layers and regularization techniques, the best model achieving\n84.83% accuracy on a test dataset. Using dimensionality reduction done by PCA\nwe were able to increase that figure to 85.08% with only 10% of the original\nfeature space, reducing the memory size needed by 64%. Finally, adding methods\nto remove possibly harmful training samples like deviation from the mean helped\nus to still achieve over 84% test accuracy but with only 32.8% of the original\nmemory size for the training set. This compares favorably to the majority of\nliterature results obtained through similar architectures. Although this\napproach gets outshined by state-of-the-art models, it does scale to some\n(AlexNet, VGGNet) trained on 50% of the same dataset.",
    "descriptor": "",
    "authors": [
      "Tidor-Vlad Pricope"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01782"
  },
  {
    "id": "arXiv:2107.01784",
    "title": "Learning a Model for Inferring a Spatial Road Lane Network Graph using  Self-Supervision",
    "abstract": "Interconnected road lanes are a central concept for navigating urban roads.\nCurrently, most autonomous vehicles rely on preconstructed lane maps as\ndesigning an algorithmic model is difficult. However, the generation and\nmaintenance of such maps is costly and hinders large-scale adoption of\nautonomous vehicle technology. This paper presents the first self-supervised\nlearning method to train a model to infer a spatially grounded lane-level road\nnetwork graph based on a dense segmented representation of the road scene\ngenerated from onboard sensors. A formal road lane network model is presented\nand proves that any structured road scene can be represented by a directed\nacyclic graph of at most depth three while retaining the notion of intersection\nregions, and that this is the most compressed representation. The formal model\nis implemented by a hybrid neural and search-based model, utilizing a novel\nbarrier function loss formulation for robust learning from partial labels.\nExperiments are conducted for all common road intersection layouts. Results\nshow that the model can generalize to new road layouts, unlike previous\napproaches, demonstrating its potential for real-world application as a\npractical learning-based lane-level map generator.",
    "descriptor": "\nComments: Accepted for IEEE ITSC 2021\n",
    "authors": [
      "Robin Karlsson",
      "David Robert Wong",
      "Simon Thompson",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01784"
  },
  {
    "id": "arXiv:2107.01785",
    "title": "Improved Asymptotic Bounds for Codes Correcting Insertions and Deletions",
    "abstract": "This paper studies the cardinality of codes correcting insertions and\ndeletions. We give an asymptotically improved upper bound on code size. The\nbound is obtained by utilizing the asymmetric property of list decoding for\ninsertions and deletions.",
    "descriptor": "\nComments: 9 pages, 2 fugures\n",
    "authors": [
      "Kenji Yasunaga"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01785"
  },
  {
    "id": "arXiv:2107.01786",
    "title": "Popcorn: Paillier Meets Compression For Efficient Oblivious Neural  Network Inference",
    "abstract": "Oblivious inference enables the cloud to provide neural network\ninference-as-a-service (NN-IaaS), whilst neither disclosing the client data nor\nrevealing the server's model. However, the privacy guarantee under oblivious\ninference usually comes with a heavy cost of efficiency and accuracy.\nWe propose Popcorn, a concise oblivious inference framework entirely built on\nthe Paillier homomorphic encryption scheme. We design a suite of novel\nprotocols to compute non-linear activation and max-pooling layers. We leverage\nneural network compression techniques (i.e., neural weights pruning and\nquantization) to accelerate the inference computation. To implement the Popcorn\nframework, we only need to replace algebraic operations of existing networks\nwith their corresponding Paillier homomorphic operations, which is extremely\nfriendly for engineering development.\nWe first conduct the performance evaluation and comparison based on the MNIST\nand CIFAR-10 classification tasks. Compared with existing solutions, Popcorn\nbrings a significant communication overhead deduction, with a moderate runtime\nincrease. Then, we benchmark the performance of oblivious inference on\nImageNet. To our best knowledge, this is the first report based on a\ncommercial-level dataset, taking a step towards the deployment to production.",
    "descriptor": "",
    "authors": [
      "Jun Wang",
      "Chao Jin",
      "Souhail Meftah",
      "Khin Mi Mi Aung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01786"
  },
  {
    "id": "arXiv:2107.01787",
    "title": "Multi-View Correlation Distillation for Incremental Object Detection",
    "abstract": "In real applications, new object classes often emerge after the detection\nmodel has been trained on a prepared dataset with fixed classes. Due to the\nstorage burden and the privacy of old data, sometimes it is impractical to\ntrain the model from scratch with both old and new data. Fine-tuning the old\nmodel with only new data will lead to a well-known phenomenon of catastrophic\nforgetting, which severely degrades the performance of modern object detectors.\nIn this paper, we propose a novel \\textbf{M}ulti-\\textbf{V}iew\n\\textbf{C}orrelation \\textbf{D}istillation (MVCD) based incremental object\ndetection method, which explores the correlations in the feature space of the\ntwo-stage object detector (Faster R-CNN). To better transfer the knowledge\nlearned from the old classes and maintain the ability to learn new classes, we\ndesign correlation distillation losses from channel-wise, point-wise and\ninstance-wise views to regularize the learning of the incremental model. A new\nmetric named Stability-Plasticity-mAP is proposed to better evaluate both the\nstability for old classes and the plasticity for new classes in incremental\nobject detection. The extensive experiments conducted on VOC2007 and COCO\ndemonstrate that MVCD can effectively learn to detect objects of new classes\nand mitigate the problem of catastrophic forgetting.",
    "descriptor": "",
    "authors": [
      "Dongbao Yang",
      "Yu Zhou",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01787"
  },
  {
    "id": "arXiv:2107.01791",
    "title": "Doing Good or Doing Right? Exploring the Weakness of Commonsense Causal  Reasoning Models",
    "abstract": "Pretrained language models (PLM) achieve surprising performance on the Choice\nof Plausible Alternatives (COPA) task. However, whether PLMs have truly\nacquired the ability of causal reasoning remains a question. In this paper, we\ninvestigate the problem of semantic similarity bias and reveal the\nvulnerability of current COPA models by certain attacks. Previous solutions\nthat tackle the superficial cues of unbalanced token distribution still\nencounter the same problem of semantic bias, even more seriously due to the\nutilization of more training data. We mitigate this problem by simply adding a\nregularization loss and experimental results show that this solution not only\nimproves the model's generalization ability, but also assists the models to\nperform more robustly on a challenging dataset, BCOPA-CE, which has unbiased\ntoken distribution and is more difficult for models to distinguish cause and\neffect.",
    "descriptor": "\nComments: ACL2021, Main Conference, Short Paper\n",
    "authors": [
      "Mingyue Han",
      "Yinglin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01791"
  },
  {
    "id": "arXiv:2107.01793",
    "title": "MIMO Operations in Molecular Communications: Theory, Prototypes, and  Open Challenges",
    "abstract": "The Internet of Bio-nano Things is a significant development for next\ngeneration communication technologies. Because conventional wireless\ncommunication technologies face challenges in realizing new applications (e.g.,\nin-body area networks for health monitoring) and necessitate the substitution\nof information carriers, researchers have shifted their interest to molecular\ncommunications (MC). Although remarkable progress has been made in this field\nover the last decade, advances have been far from acceptable for the\nachievement of its application objectives. A crucial problem of MC is the low\ndata rate and high error rate inherent in particle dynamics specifications, in\ncontrast to wave-based conventional communications. Therefore, it is important\nto investigate the resources by which MC can obtain additional information\npaths and provide strategies to exploit these resources. This study aims to\nexamine techniques involving resource aggregation and exploitation to provide\nprospective directions for future progress in MC. In particular, we focus on\nstate-of-the-art studies on multiple-input multiple-output (MIMO) systems. We\ndiscuss the possible advantages of applying MIMO to various MC system models.\nFurthermore, we survey various studies that aimed to achieve MIMO gains for the\nrespective models, from theoretical background to prototypes. Finally, we\nconclude this study by summarizing the challenges that need to be addressed.",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted in Communications Magazine\n",
    "authors": [
      "Bon-Hong Koo",
      "Changmin Lee",
      "Ali E. Pusane",
      "Tuna Tugcu",
      "Chan-Byoung Chae"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.01793"
  },
  {
    "id": "arXiv:2107.01799",
    "title": "An Information-Theoretic Approach for Automatically Determining the  Number of States when Aggregating Markov Chains",
    "abstract": "A fundamental problem when aggregating Markov chains is the specification of\nthe number of state groups. Too few state groups may fail to sufficiently\ncapture the pertinent dynamics of the original, high-order Markov chain. Too\nmany state groups may lead to a non-parsimonious, reduced-order Markov chain\nwhose complexity rivals that of the original. In this paper, we show that an\naugmented value-of-information-based approach to aggregating Markov chains\nfacilitates the determination of the number of state groups. The optimal\nstate-group count coincides with the case where the complexity of the\nreduced-order chain is balanced against the mutual dependence between the\noriginal- and reduced-order chain dynamics.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP. arXiv admin note: substantial text overlap with arXiv:1903.09266\n",
    "authors": [
      "Isaac J. Sledge",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01799"
  },
  {
    "id": "arXiv:2107.01804",
    "title": "Randomized Dimensionality Reduction for Facility Location and  Single-Linkage Clustering",
    "abstract": "Random dimensionality reduction is a versatile tool for speeding up\nalgorithms for high-dimensional problems. We study its application to two\nclustering problems: the facility location problem, and the single-linkage\nhierarchical clustering problem, which is equivalent to computing the minimum\nspanning tree. We show that if we project the input pointset $X$ onto a random\n$d = O(d_X)$-dimensional subspace (where $d_X$ is the doubling dimension of\n$X$), then the optimum facility location cost in the projected space\napproximates the original cost up to a constant factor. We show an analogous\nstatement for minimum spanning tree, but with the dimension $d$ having an extra\n$\\log \\log n$ term and the approximation factor being arbitrarily close to $1$.\nFurthermore, we extend these results to approximating solutions instead of just\ntheir costs. Lastly, we provide experimental results to validate the quality of\nsolutions and the speedup due to the dimensionality reduction. Unlike several\nprevious papers studying this approach in the context of $k$-means and\n$k$-medians, our dimension bound does not depend on the number of clusters but\nonly on the intrinsic dimensionality of $X$.",
    "descriptor": "\nComments: 25 pages. Published as a conference paper in ICML 2021\n",
    "authors": [
      "Shyam Narayanan",
      "Sandeep Silwal",
      "Piotr Indyk",
      "Or Zamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01804"
  },
  {
    "id": "arXiv:2107.01805",
    "title": "Dual Synchronous Generator: A New Solution for Grid-Forming",
    "abstract": "In order to improve synchronous stability of the power system with\nhigh-penetration power electronics, it is necessary for voltage source\nconverter (VSC) to provide inertial and frequency regulation. In practical\napplication, VSC is better to be controlled as a current source due to its weak\novercurrent capacity. According to the characteristic, a dual synchronous\ntheory is proposed to analyze the synchronization between current sources in\nthis paper. Based on dual synchronous theory, a dual synchronous generator\n(DSG) control is applied in VSC to form inertial current source. In addition, a\nbraking control is embedded in DSG control to improve the transient stability\nof VSC. Finally, hardware-in-the-loop experiments verify the effectiveness of\nthe theory and the control method.",
    "descriptor": "",
    "authors": [
      "Huanhai Xin",
      "Kehao Zhuang",
      "Pengfei Hu",
      "Yunjie Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01805"
  },
  {
    "id": "arXiv:2107.01806",
    "title": "A Framework for Evaluating the Cybersecurity Risk of Real World, Machine  Learning Production Systems",
    "abstract": "Although cyberattacks on machine learning (ML) production systems can be\ndestructive, many industry practitioners are ill equipped, lacking tactical and\nstrategic tools that would allow them to analyze, detect, protect against, and\nrespond to cyberattacks targeting their ML-based systems. In this paper, we\ntake a significant step toward securing ML production systems by integrating\nthese systems and their vulnerabilities into cybersecurity risk assessment\nframeworks. Specifically, we performed a comprehensive threat analysis of ML\nproduction systems and developed an extension to the MulVAL attack graph\ngeneration and analysis framework to incorporate cyberattacks on ML production\nsystems. Using the proposed extension, security practitioners can apply attack\ngraph analysis methods in environments that include ML components, thus\nproviding security experts with a practical tool for evaluating the impact and\nquantifying the risk of a cyberattack targeting an ML production system.",
    "descriptor": "",
    "authors": [
      "Ron Bitton",
      "Nadav Maman",
      "Inderjeet Singh",
      "Satoru Momiyama",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01806"
  },
  {
    "id": "arXiv:2107.01807",
    "title": "Q-SpiNN: A Framework for Quantizing Spiking Neural Networks",
    "abstract": "A prominent technique for reducing the memory footprint of Spiking Neural\nNetworks (SNNs) without decreasing the accuracy significantly is quantization.\nHowever, the state-of-the-art only focus on employing the weight quantization\ndirectly from a specific quantization scheme, i.e., either the post-training\nquantization (PTQ) or the in-training quantization (ITQ), and do not consider\n(1) quantizing other SNN parameters (e.g., neuron membrane potential), (2)\nexploring different combinations of quantization approaches (i.e., quantization\nschemes, precision levels, and rounding schemes), and (3) selecting the SNN\nmodel with a good memory-accuracy trade-off at the end. Therefore, the memory\nsaving offered by these state-of-the-art to meet the targeted accuracy is\nlimited, thereby hindering processing SNNs on the resource-constrained systems\n(e.g., the IoT-Edge devices). Towards this, we propose Q-SpiNN, a novel\nquantization framework for memory-efficient SNNs. The key mechanisms of the\nQ-SpiNN are: (1) employing quantization for different SNN parameters based on\ntheir significance to the accuracy, (2) exploring different combinations of\nquantization schemes, precision levels, and rounding schemes to find efficient\nSNN model candidates, and (3) developing an algorithm that quantifies the\nbenefit of the memory-accuracy trade-off obtained by the candidates, and\nselects the Pareto-optimal one. The experimental results show that, for the\nunsupervised network, the Q-SpiNN reduces the memory footprint by ca. 4x, while\nmaintaining the accuracy within 1% from the baseline on the MNIST dataset. For\nthe supervised network, the Q-SpiNN reduces the memory by ca. 2x, while keeping\nthe accuracy within 2% from the baseline on the DVS-Gesture dataset.",
    "descriptor": "\nComments: Accepted for publication at the 2021 International Joint Conference on Neural Networks (IJCNN), July 2021, Virtual Event\n",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01807"
  },
  {
    "id": "arXiv:2107.01808",
    "title": "Why is Pruning at Initialization Immune to Reinitializing and Shuffling?",
    "abstract": "Recent studies assessing the efficacy of pruning neural networks methods\nuncovered a surprising finding: when conducting ablation studies on existing\npruning-at-initialization methods, namely SNIP, GraSP, SynFlow, and magnitude\npruning, performances of these methods remain unchanged and sometimes even\nimprove when randomly shuffling the mask positions within each layer (Layerwise\nShuffling) or sampling new initial weight values (Reinit), while keeping\npruning masks the same. We attempt to understand the reason behind such network\nimmunity towards weight/mask modifications, by studying layer-wise statistics\nbefore and after randomization operations. We found that under each of the\npruning-at-initialization methods, the distribution of unpruned weights changed\nminimally with randomization operations.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Sahib Singh",
      "Rosanne Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01808"
  },
  {
    "id": "arXiv:2107.01809",
    "title": "Boosting Transferability of Targeted Adversarial Examples via  Hierarchical Generative Networks",
    "abstract": "Transfer-based adversarial attacks can effectively evaluate model robustness\nin the black-box setting. Though several methods have demonstrated impressive\ntransferability of untargeted adversarial examples, targeted adversarial\ntransferability is still challenging. The existing methods either have low\ntargeted transferability or sacrifice computational efficiency. In this paper,\nwe develop a simple yet practical framework to efficiently craft targeted\ntransfer-based adversarial examples. Specifically, we propose a conditional\ngenerative attacking model, which can generate the adversarial examples\ntargeted at different classes by simply altering the class embedding and share\na single backbone. Extensive experiments demonstrate that our method improves\nthe success rates of targeted black-box attacks by a significant margin over\nthe existing methods -- it reaches an average success rate of 29.6\\% against\nsix diverse models based only on one substitute white-box model in the standard\ntesting of NeurIPS 2017 competition, which outperforms the state-of-the-art\ngradient-based attack methods (with an average success rate of $<$2\\%) by a\nlarge margin. Moreover, the proposed method is also more efficient beyond an\norder of magnitude than gradient-based methods.",
    "descriptor": "",
    "authors": [
      "Xiao Yang",
      "Yinpeng Dong",
      "Tianyu Pang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01809"
  },
  {
    "id": "arXiv:2107.01810",
    "title": "Comparative Analysis of Impact of Cryptography Algorithms on Wireless  Sensor Networks",
    "abstract": "Cryptography techniques are essential for a robust and stable security design\nof a system to mitigate the risk of external attacks and thus improve its\nefficiency. Wireless Sensor Networks (WSNs) play a pivotal role in sensing,\nmonitoring, processing, and accumulating raw data to enhance the performance of\nthe actuators, micro-controllers, embedded architectures, IoT devices, and\ncomputing machines to which they are connected. With so much threat of\npotential adversaries, it is essential to scale up the security level of WSN\nwithout affecting its primary goal of seamless data collection and\ncommunication with relay devices. This paper intends to explore the past and\nongoing research activities in this domain. An extensive study of these\nalgorithms referred here, are studied and analyzed. Based on these findings\nthis paper will illustrate the best possible cryptography algorithms which will\nbe most suited to implement the security aspects of the WSN and protect it from\nany threat and reduce its vulnerabilities. This study will pave the way for\nfuture research on this topic since it will provide a comprehensive and\nholistic view of the subject.",
    "descriptor": "",
    "authors": [
      "Bilwasiva Basu Mallick",
      "Ashutosh Bhatia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01810"
  },
  {
    "id": "arXiv:2107.01814",
    "title": "Web-Scale Generic Object Detection at Microsoft Bing",
    "abstract": "In this paper, we present Generic Object Detection (GenOD), one of the\nlargest object detection systems deployed to a web-scale general visual search\nengine that can detect over 900 categories for all Microsoft Bing Visual Search\nqueries in near real-time. It acts as a fundamental visual query understanding\nservice that provides object-centric information and shows gains in multiple\nproduction scenarios, improving upon domain-specific models. We discuss the\nchallenges of collecting data, training, deploying and updating such a\nlarge-scale object detection model with multiple dependencies. We discuss a\ndata collection pipeline that reduces per-bounding box labeling cost by 81.5%\nand latency by 61.2% while improving on annotation quality. We show that GenOD\ncan improve weighted average precision by over 20% compared to multiple\ndomain-specific models. We also improve the model update agility by nearly 2\ntimes with the proposed disjoint detector training compared to joint\nfine-tuning. Finally we demonstrate how GenOD benefits visual search\napplications by significantly improving object-level search relevance by 54.9%\nand user engagement by 59.9%.",
    "descriptor": "\nComments: In Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD) 2021, Virtual Event, Singapore\n",
    "authors": [
      "Stephen Xi Chen",
      "Saurajit Mukherjee",
      "Unmesh Phadke",
      "Tingting Wang",
      "Junwon Park",
      "Ravi Theja Yada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01814"
  },
  {
    "id": "arXiv:2107.01815",
    "title": "A Formal Semantics of the GraalVM Intermediate Representation",
    "abstract": "The optimization phase of a compiler is responsible for transforming an\nintermediate representation (IR) of a program into a more efficient form.\nModern optimizers, such as that used in the GraalVM compiler, use an IR\nconsisting of a sophisticated graph data structure that combines data flow and\ncontrol flow into the one structure. As part of a wider project on the\nverification of optimization passes of GraalVM, this paper describes a\nsemantics for its IR within Isabelle/HOL. The semantics consists of a big-step\noperational semantics for data nodes (which are represented in a graph-based\nstatic single assignment (SSA) form) and a small-step operational semantics for\nhandling control flow including heap-based reads and writes, exceptions, and\nmethod calls. We have proved a suite of canonicalization optimizations and\nconditional elimination optimizations with respect to the semantics.",
    "descriptor": "\nComments: 16 pages, 8 figures, to be published to ATVA 2021\n",
    "authors": [
      "Brae J. Webb",
      "Mark Utting",
      "Ian J. Hayes"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.01815"
  },
  {
    "id": "arXiv:2107.01819",
    "title": "A Note on Error Bounds for Pseudo Skeleton Approximations of Matrices",
    "abstract": "Due to their importance in both data analysis and numerical algorithms, low\nrank approximations have recently been widely studied. They enable the handling\nof very large matrices. Tight error bounds for the computationally efficient\nGaussian elimination based methods (skeleton approximations) are available. In\npractice, these bounds are useful for matrices with singular values which\ndecrease quickly. Using the Chebyshev norm, this paper provides improved bounds\nfor the errors of the matrix elements. These bounds are substantially better in\nthe practically relevant cases where the eigenvalues decrease polynomially.\nResults are proven for general real rectangular matrices. Even stronger bounds\nare obtained for symmetric positive definite matrices. A simple example is\ngiven, comparing these new bounds to earlier ones.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Frank de Hoog",
      "Markus Hegland"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01819"
  },
  {
    "id": "arXiv:2107.01820",
    "title": "An Explainable AI System for the Diagnosis of High Dimensional  Biomedical Data",
    "abstract": "Typical state of the art flow cytometry data samples consists of measures of\nmore than 100.000 cells in 10 or more features. AI systems are able to diagnose\nsuch data with almost the same accuracy as human experts. However, there is one\ncentral challenge in such systems: their decisions have far-reaching\nconsequences for the health and life of people, and therefore, the decisions of\nAI systems need to be understandable and justifiable by humans. In this work,\nwe present a novel explainable AI method, called ALPODS, which is able to\nclassify (diagnose) cases based on clusters, i.e., subpopulations, in the\nhigh-dimensional data. ALPODS is able to explain its decisions in a form that\nis understandable for human experts. For the identified subpopulations, fuzzy\nreasoning rules expressed in the typical language of domain experts are\ngenerated. A visualization method based on these rules allows human experts to\nunderstand the reasoning used by the AI system. A comparison to a selection of\nstate of the art explainable AI systems shows that ALPODS operates efficiently\non known benchmark data and also on everyday routine case data.",
    "descriptor": "\nComments: 22 pages, 1 figure, 5 tables\n",
    "authors": [
      "Alfred Ultsch",
      "J\u00f6rg Hoffmann",
      "Maximilian R\u00f6hnert",
      "Malte Von Bonin",
      "Uta Oelschl\u00e4gel",
      "Cornelia Brendel",
      "Michael C. Thrun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01820"
  },
  {
    "id": "arXiv:2107.01824",
    "title": "Exploring Data Pipelines through the Process Lens: a Reference Model  forComputer Vision",
    "abstract": "Researchers have identified datasets used for training computer vision (CV)\nmodels as an important source of hazardous outcomes, and continue to examine\npopular CV datasets to expose their harms. These works tend to treat datasets\nas objects, or focus on particular steps in data production pipelines. We argue\nhere that we could further systematize our analysis of harms by examining CV\ndata pipelines through a process-oriented lens that captures the creation, the\nevolution and use of these datasets. As a step towards cultivating a\nprocess-oriented lens, we embarked on an empirical study of CV data pipelines\ninformed by the field of method engineering. We present here a preliminary\nresult: a reference model of CV data pipelines. Besides exploring the questions\nthat this endeavor raises, we discuss how the process lens could support\nresearchers in discovering understudied issues, and could help practitioners in\nmaking their processes more transparent.",
    "descriptor": "\nComments: Presented at the CVPR workshop 2021 Beyond Fair Computer Vision\n",
    "authors": [
      "Agathe Balayn",
      "Bogdan Kulynych",
      "Seda Guerses"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01824"
  },
  {
    "id": "arXiv:2107.01825",
    "title": "Sample Efficient Reinforcement Learning via Model-Ensemble Exploration  and Exploitation",
    "abstract": "Model-based deep reinforcement learning has achieved success in various\ndomains that require high sample efficiencies, such as Go and robotics.\nHowever, there are some remaining issues, such as planning efficient\nexplorations to learn more accurate dynamic models, evaluating the uncertainty\nof the learned models, and more rational utilization of models. To mitigate\nthese issues, we present MEEE, a model-ensemble method that consists of\noptimistic exploration and weighted exploitation. During exploration, unlike\nprior methods directly selecting the optimal action that maximizes the expected\naccumulative return, our agent first generates a set of action candidates and\nthen seeks out the optimal action that takes both expected return and future\nobservation novelty into account. During exploitation, different discounted\nweights are assigned to imagined transition tuples according to their model\nuncertainty respectively, which will prevent model predictive error propagation\nin agent training. Experiments on several challenging continuous control\nbenchmark tasks demonstrated that our approach outperforms other model-free and\nmodel-based state-of-the-art methods, especially in sample complexity.",
    "descriptor": "\nComments: 7 pages, 5 figures, accepted by IEEE International Conference on Robotics and Automation 2021 (IEEE ICRA 2021)\n",
    "authors": [
      "Yao Yao",
      "Li Xiao",
      "Zhicheng An",
      "Wanpeng Zhang",
      "Dijun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01825"
  },
  {
    "id": "arXiv:2107.01829",
    "title": "A System for Traded Control Teleoperation of Manipulation Tasks using  Intent Prediction from Hand Gestures",
    "abstract": "This paper presents a teleoperation system that includes robot perception and\nintent prediction from hand gestures. The perception module identifies the\nobjects present in the robot workspace and the intent prediction module which\nobject the user likely wants to grasp. This architecture allows the approach to\nrely on traded control instead of direct control: we use hand gestures to\nspecify the goal objects for a sequential manipulation task, the robot then\nautonomously generates a grasping or a retrieving motion using trajectory\noptimization. The perception module relies on the model-based tracker to\nprecisely track the 6D pose of the objects and makes use of a state of the art\nlearning-based object detection and segmentation method, to initialize the\ntracker by automatically detecting objects in the scene. Goal objects are\nidentified from user hand gestures using a trained a multi-layer perceptron\nclassifier. After presenting all the components of the system and their\nempirical evaluation, we present experimental results comparing our pipeline to\na direct traded control approach (i.e., one that does not use prediction) which\nshows that using intent prediction allows to bring down the overall task\nexecution time.",
    "descriptor": "\nComments: Accepted to IEEE-RoMAN 2021\n",
    "authors": [
      "Yoojin Oh",
      "Marc Toussaint",
      "Jim Mainprice"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.01829"
  },
  {
    "id": "arXiv:2107.01830",
    "title": "ARM-Net: Adaptive Relation Modeling Network for Structured Data",
    "abstract": "Relational databases are the de facto standard for storing and querying\nstructured data, and extracting insights from structured data requires advanced\nanalytics. Deep neural networks (DNNs) have achieved super-human prediction\nperformance in particular data types, e.g., images. However, existing DNNs may\nnot produce meaningful results when applied to structured data. The reason is\nthat there are correlations and dependencies across combinations of attribute\nvalues in a table, and these do not follow simple additive patterns that can be\neasily mimicked by a DNN. The number of possible such cross features is\ncombinatorial, making them computationally prohibitive to model. Furthermore,\nthe deployment of learning models in real-world applications has also\nhighlighted the need for interpretability, especially for high-stakes\napplications, which remains another issue of concern to DNNs.\nIn this paper, we present ARM-Net, an adaptive relation modeling network\ntailored for structured data, and a lightweight framework ARMOR based on\nARM-Net for relational data analytics. The key idea is to model feature\ninteractions with cross features selectively and dynamically, by first\ntransforming the input features into exponential space, and then determining\nthe interaction order and interaction weights adaptively for each cross\nfeature. We propose a novel sparse attention mechanism to dynamically generate\nthe interaction weights given the input tuple, so that we can explicitly model\ncross features of arbitrary orders with noisy features filtered selectively.\nThen during model inference, ARM-Net can specify the cross features being used\nfor each prediction for higher accuracy and better interpretability. Our\nextensive experiments on real-world datasets demonstrate that ARM-Net\nconsistently outperforms existing models and provides more interpretable\npredictions for data-driven decision making.",
    "descriptor": "\nComments: 14 pages, 11 figures, 5 tables, published as a conference paper in ACM SIGMOD 2020\n",
    "authors": [
      "Shaofeng Cai",
      "Kaiping Zheng",
      "Gang Chen",
      "H. V. Jagadish",
      "Beng Chin Ooi",
      "Meihui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01830"
  },
  {
    "id": "arXiv:2107.01832",
    "title": "Provable Convergence of Nesterov Accelerated Method for  Over-Parameterized Neural Networks",
    "abstract": "Despite the empirical success of deep learning, it still lacks theoretical\nunderstandings to explain why randomly initialized neural network trained by\nfirst-order optimization methods is able to achieve zero training loss, even\nthough its landscape is non-convex and non-smooth. Recently, there are some\nworks to demystifies this phenomenon under over-parameterized regime. In this\nwork, we make further progress on this area by considering a commonly used\nmomentum optimization algorithm: Nesterov accelerated method (NAG). We analyze\nthe convergence of NAG for two-layer fully connected neural network with ReLU\nactivation. Specifically, we prove that the error of NAG converges to zero at a\nlinear convergence rate $1-\\Theta(1/\\sqrt{\\kappa})$, where $\\kappa > 1$ is\ndetermined by the initialization and the architecture of neural network.\nComparing to the rate $1-\\Theta(1/\\kappa)$ of gradient descent, NAG achieves an\nacceleration. Besides, it also validates NAG and Heavy-ball method can achieve\na similar convergence rate.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Xin Liu",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01832"
  },
  {
    "id": "arXiv:2107.01833",
    "title": "Age of Information in Relay-Assisted Status Updating Systems",
    "abstract": "In this paper we consider the age of information (AoI) of a status updating\nsystem with a relay, where the updates are delivered to destination either from\nthe direct line or the two-hop link via the relay. An updating packet generated\nat source is sent to receiver and the relay simultaneously. When the direct\npacket transmission fails, the relay replaces the source and retransmits the\npacket until it is eventually obtained at the receiver side. Assume that the\npropagation delay on each link is one time slot, we determine the stationary\ndistribution of the AoI for three cases: (a) relay has no buffer and the packet\ndelivery from relay cannot be preempted by fresher updates from source; (b)\nrelay has no buffer but the packet substitution is allowable; (c) relay has\nsize 1 buffer and the packet in buffer is refreshed when a newer packet is\nobtained. The idea is invoking a multiple-dimensional state vector which\ncontains the AoI as a part and constituting the multiple-dimensional AoI\nstochastic process. We find the steady state of each multiple-dimensional AoI\nprocess by solving the system of stationary equations. Once the steady-state\ndistribution of larger-dimensional AoI process is known, the stationary AoI\ndistribution is also obtained as it is one of the marginal distributions of\nthat process's steady-state distribution. For all the situations, we derive the\nexplicit expression of AoI distribution, and calculate the mean and the\nvariance of the stationary AoI. All the results are compared numerically,\nincluding the AoI performance of the non-relay state updating system. Numerical\nresults show that adding the relay improves the system's timeliness\ndramatically, and no-buffer-and-preemption setting in relay achieves both\nminimal average AoI and AoI's variance. Thus, for the system model discussed in\nthis paper, to reduce the AoI at receiver there is no need to add the buffer in\nrelay.",
    "descriptor": "\nComments: 51 pages, 4 figures\n",
    "authors": [
      "Jixiang Zhang",
      "Yinfei Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01833"
  },
  {
    "id": "arXiv:2107.01835",
    "title": "Fast Rate Learning in Stochastic First Price Bidding",
    "abstract": "First-price auctions have largely replaced traditional bidding approaches\nbased on Vickrey auctions in programmatic advertising. As far as learning is\nconcerned, first-price auctions are more challenging because the optimal\nbidding strategy does not only depend on the value of the item but also\nrequires some knowledge of the other bids. They have already given rise to\nseveral works in sequential learning, many of which consider models for which\nthe value of the buyer or the opponents' maximal bid is chosen in an\nadversarial manner. Even in the simplest settings, this gives rise to\nalgorithms whose regret grows as $\\sqrt{T}$ with respect to the time horizon\n$T$. Focusing on the case where the buyer plays against a stationary stochastic\nenvironment, we show how to achieve significantly lower regret: when the\nopponents' maximal bid distribution is known we provide an algorithm whose\nregret can be as low as $\\log^2(T)$; in the case where the distribution must be\nlearnt sequentially, a generalization of this algorithm can achieve $T^{1/3+\n\\epsilon}$ regret, for any $\\epsilon>0$. To obtain these results, we introduce\ntwo novel ideas that can be of interest in their own right. First, by\ntransposing results obtained in the posted price setting, we provide conditions\nunder which the first-price biding utility is locally quadratic around its\noptimum. Second, we leverage the observation that, on small sub-intervals, the\nconcentration of the variations of the empirical distribution function may be\ncontrolled more accurately than by using the classical\nDvoretzky-Kiefer-Wolfowitz inequality. Numerical simulations confirm that our\nalgorithms converge much faster than alternatives proposed in the literature\nfor various bid distributions, including for bids collected on an actual\nprogrammatic advertising platform.",
    "descriptor": "",
    "authors": [
      "Juliette Achddou",
      "Olivier Capp\u00e9",
      "Aur\u00e9lien Garivier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01835"
  },
  {
    "id": "arXiv:2107.01836",
    "title": "GraspME -- Grasp Manifold Estimator",
    "abstract": "In this paper, we introduce a Grasp Manifold Estimator (GraspME) to detect\ngrasp affordances for objects directly in 2D camera images. To perform\nmanipulation tasks autonomously it is crucial for robots to have such\ngraspability models of the surrounding objects. Grasp manifolds have the\nadvantage of providing continuously infinitely many grasps, which is not the\ncase when using other grasp representations such as predefined grasp points.\nFor instance, this property can be leveraged in motion optimization to define\ngoal sets as implicit surface constraints in the robot configuration space. In\nthis work, we restrict ourselves to the case of estimating possible\nend-effector positions directly from 2D camera images. To this extend, we\ndefine grasp manifolds via a set of key points and locate them in images using\na Mask R-CNN backbone. Using learned features allows generalizing to different\nview angles, with potentially noisy images, and objects that were not part of\nthe training set. We rely on simulation data only and perform experiments on\nsimple and complex objects, including unseen ones. Our framework achieves an\ninference speed of 11.5 fps on a GPU, an average precision for keypoint\nestimation of 94.5% and a mean pixel distance of only 1.29. This shows that we\ncan estimate the objects very well via bounding boxes and segmentation masks as\nwell as approximate the correct grasp manifold's keypoint coordinates.",
    "descriptor": "\nComments: Accepted to RoMan 2021\n",
    "authors": [
      "Janik Hager",
      "Ruben Bauer",
      "Marc Toussaint",
      "Jim Mainprice"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01836"
  },
  {
    "id": "arXiv:2107.01837",
    "title": "Advanced turning maneuver of a multi-legged robot using pitchfork  bifurcation",
    "abstract": "Legged robots have excellent terrestrial mobility for traversing diverse\nenvironments and thus have the potential to be deployed in a wide variety of\nscenarios. However, they are susceptible to falling and leg malfunction during\nlocomotion. Although the use of a large number of legs can overcome these\nproblems, it makes the body long and leads to many contact legs being\nconstrained on the ground to support the long body, which impedes\nmaneuverability. To improve the locomotion maneuverability of the robots, the\npresent study focuses on dynamic instability, which induces rapid and large\nmovement changes, and uses a 12-legged robot with flexible body axis. Our\nprevious work found that the straight walk of the robot becomes unstable\nthrough Hopf bifurcation when the body axis flexibility is changed, which\ninduces body undulations. Furthermore, we developed a simple controller based\non the Hopf bifurcation and showed that the straight walk instability\nfacilitates the turning of the robot. In this study, we newly found that the\nstraight walk becomes unstable through pitchfork bifurcation when the body-axis\nflexibility is changed in a different way from that in our previous work. The\npitchfork bifurcation not only induces the straight walk instability but also\nthe transition into the curved walk, whose curvature can be controlled by the\nbody-axis flexibility. We developed a simple controller based on the\npitchfork-bifurcation characteristics and demonstrated that the robot can\nperform a turning maneuver superior to the previous controller based on the\nHopf bifurcation. This study provides a novel design principle for maneuverable\nlocomotion of many-legged robots using intrinsic dynamic properties.",
    "descriptor": "",
    "authors": [
      "Shinya Aoi",
      "Ryoe Tomatsu",
      "Yuki Yabuuchi",
      "Soichiro Fujiki",
      "Kei Senda",
      "Kazuo Tsuchiya"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01837"
  },
  {
    "id": "arXiv:2107.01848",
    "title": "Differentially Private Sliced Wasserstein Distance",
    "abstract": "Developing machine learning methods that are privacy preserving is today a\ncentral topic of research, with huge practical impacts. Among the numerous ways\nto address privacy-preserving learning, we here take the perspective of\ncomputing the divergences between distributions under the Differential Privacy\n(DP) framework -- being able to compute divergences between distributions is\npivotal for many machine learning problems, such as learning generative models\nor domain adaptation problems. Instead of resorting to the popular\ngradient-based sanitization method for DP, we tackle the problem at its roots\nby focusing on the Sliced Wasserstein Distance and seamlessly making it\ndifferentially private. Our main contribution is as follows: we analyze the\nproperty of adding a Gaussian perturbation to the intrinsic randomized\nmechanism of the Sliced Wasserstein Distance, and we establish the\nsensitivityof the resulting differentially private mechanism. One of our\nimportant findings is that this DP mechanism transforms the Sliced Wasserstein\ndistance into another distance, that we call the Smoothed Sliced Wasserstein\nDistance. This new differentially private distribution distance can be plugged\ninto generative models and domain adaptation algorithms in a transparent way,\nand we empirically show that it yields highly competitive performance compared\nwith gradient-based DP approaches from the literature, with almost no loss in\naccuracy for the domain adaptation problems that we consider.",
    "descriptor": "",
    "authors": [
      "Alain Rakotomamonjy",
      "Liva Ralaivola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01848"
  },
  {
    "id": "arXiv:2107.01853",
    "title": "Ferroelectric Tunneling Junctions for Edge Computing",
    "abstract": "Ferroelectric tunneling junctions (FTJ) are considered to be the\nintrinsically most energy efficient memristors. In this work, specific\nelectrical features of ferroelectric hafnium-zirconium oxide based FTJ devices\nare investigated. Moreover, the impact on the design of FTJ-based circuits for\nedge computing applications is discussed by means of two example circuits.",
    "descriptor": "",
    "authors": [
      "Erika Covi",
      "Quang T. Duong",
      "Suzanne Lancaster",
      "Viktor Havel",
      "Jean Coignus",
      "Justine Barbot",
      "Ole Richter",
      "Philip Klein",
      "Elisabetta Chicca",
      "Laurent Grenouillet",
      "Athanasios Dimoulas",
      "Thomas Mikolajick",
      "Stefan Slesazeck"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01853"
  },
  {
    "id": "arXiv:2107.01854",
    "title": "Poisoning Attack against Estimating from Pairwise Comparisons",
    "abstract": "As pairwise ranking becomes broadly employed for elections, sports\ncompetitions, recommendations, and so on, attackers have strong motivation and\nincentives to manipulate the ranking list. They could inject malicious\ncomparisons into the training data to fool the victim. Such a technique is\ncalled poisoning attack in regression and classification tasks. In this paper,\nto the best of our knowledge, we initiate the first systematic investigation of\ndata poisoning attacks on pairwise ranking algorithms, which can be formalized\nas the dynamic and static games between the ranker and the attacker and can be\nmodeled as certain kinds of integer programming problems. To break the\ncomputational hurdle of the underlying integer programming problems, we\nreformulate them into the distributionally robust optimization (DRO) problems,\nwhich are computationally tractable. Based on such DRO formulations, we propose\ntwo efficient poisoning attack algorithms and establish the associated\ntheoretical guarantees. The effectiveness of the suggested poisoning attack\nstrategies is demonstrated by a series of toy simulations and several real data\nexperiments. These experimental results show that the proposed methods can\nsignificantly reduce the performance of the ranker in the sense that the\ncorrelation between the true ranking list and the aggregated results can be\ndecreased dramatically.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Ke Ma",
      "Qianqian Xu",
      "Jinshan Zeng",
      "Xiaochun Cao",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.01854"
  },
  {
    "id": "arXiv:2107.01856",
    "title": "Winning at Any Cost -- Infringing the Cartel Prohibition With  Reinforcement Learning",
    "abstract": "Pricing decisions are increasingly made by AI. Thanks to their ability to\ntrain with live market data while making decisions on the fly, deep\nreinforcement learning algorithms are especially effective in taking such\npricing decisions. In e-commerce scenarios, multiple reinforcement learning\nagents can set prices based on their competitor's prices. Therefore, research\nstates that agents might end up in a state of collusion in the long run. To\nfurther analyze this issue, we build a scenario that is based on a modified\nversion of a prisoner's dilemma where three agents play the game of rock paper\nscissors. Our results indicate that the action selection can be dissected into\nspecific stages, establishing the possibility to develop collusion prevention\nsystems that are able to recognize situations which might lead to a collusion\nbetween competitors. We furthermore provide evidence for a situation where\nagents are capable of performing a tacit cooperation strategy without being\nexplicitly trained to do so.",
    "descriptor": "\nComments: accepted at the 19th International Conference on Practical Applications of Agents and Multi-Agent Systems (PAAMS 2021)\n",
    "authors": [
      "Michael Schlechtinger",
      "Damaris Kosack",
      "Heiko Paulheim",
      "Thomas Fetzer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.01856"
  },
  {
    "id": "arXiv:2107.01858",
    "title": "Automating Generative Deep Learning for Artistic Purposes: Challenges  and Opportunities",
    "abstract": "We present a framework for automating generative deep learning with a\nspecific focus on artistic applications. The framework provides opportunities\nto hand over creative responsibilities to a generative system as targets for\nautomation. For the definition of targets, we adopt core concepts from\nautomated machine learning and an analysis of generative deep learning\npipelines, both in standard and artistic settings. To motivate the framework,\nwe argue that automation aligns well with the goal of increasing the creative\nresponsibility of a generative system, a central theme in computational\ncreativity research. We understand automation as the challenge of granting a\ngenerative system more creative autonomy, by framing the interaction between\nthe user and the system as a co-creative process. The development of the\nframework is informed by our analysis of the relationship between automation\nand creative autonomy. An illustrative example shows how the framework can give\ninspiration and guidance in the process of handing over creative\nresponsibility.",
    "descriptor": "",
    "authors": [
      "Sebastian Berns",
      "Terence Broad",
      "Christian Guckelsberger",
      "Simon Colton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01858"
  },
  {
    "id": "arXiv:2107.01861",
    "title": "Cost-Oriented Load Forecasting",
    "abstract": "Accurate load prediction is an effective way to reduce power system operation\ncosts. Traditionally, the mean square error (MSE) is a common-used loss\nfunction to guide the training of an accurate load forecasting model. However,\nthe MSE loss function is unable to precisely reflect the real costs associated\nwith forecasting errors because the cost caused by forecasting errors in the\nreal power system is probably neither symmetric nor quadratic. To tackle this\nissue, this paper proposes a generalized cost-oriented load forecasting\nframework. Specifically, how to obtain a differentiable loss function that\nreflects real cost and how to integrate the loss function with regression\nmodels are studied. The economy and effectiveness of the proposed load\nforecasting method are verified by the case studies of an optimal dispatch\nproblem that is built on the IEEE 30-bus system and the open load dataset from\nthe Global Energy Forecasting Competition 2012 (GEFCom2012).",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Jialun Zhang",
      "Yi Wang",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01861"
  },
  {
    "id": "arXiv:2107.01867",
    "title": "Control of rough terrain vehicles using deep reinforcement learning",
    "abstract": "We explore the potential to control terrain vehicles using deep reinforcement\nin scenarios where human operators and traditional control methods are\ninadequate. This letter presents a controller that perceives, plans, and\nsuccessfully controls a 16-tonne forestry vehicle with two frame articulation\njoints, six wheels, and their actively articulated suspensions to traverse\nrough terrain. The carefully shaped reward signal promotes safe, environmental,\nand efficient driving, which leads to the emergence of unprecedented driving\nskills. We test learned skills in a virtual environment, including terrains\nreconstructed from high-density laser scans of forest sites. The controller\ndisplays the ability to handle obstructing obstacles, slopes up to 27$^\\circ$,\nand a variety of natural terrains, all with limited wheel slip, smooth, and\nupright traversal with intelligent use of the active suspensions. The results\nconfirm that deep reinforcement learning has the potential to enhance control\nof vehicles with complex dynamics and high-dimensional observation data\ncompared to human operators or traditional control methods, especially in rough\nterrain.",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "Viktor Wiberg",
      "Erik Wallin",
      "Martin Servin",
      "Tomas Nordfjell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01867"
  },
  {
    "id": "arXiv:2107.01869",
    "title": "Towards Better Adversarial Synthesis of Human Images from Text",
    "abstract": "This paper proposes an approach that generates multiple 3D human meshes from\ntext. The human shapes are represented by 3D meshes based on the SMPL model.\nThe model's performance is evaluated on the COCO dataset, which contains\nchallenging human shapes and intricate interactions between individuals. The\nmodel is able to capture the dynamics of the scene and the interactions between\nindividuals based on text. We further show how using such a shape as input to\nimage synthesis frameworks helps to constrain the network to synthesize humans\nwith realistic human shapes.",
    "descriptor": "",
    "authors": [
      "Rania Briq",
      "Pratika Kochar",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01869"
  },
  {
    "id": "arXiv:2107.01870",
    "title": "Optimum GSSK Transmission in Massive MIMO Systems Using the Box-LASSO  Decoder",
    "abstract": "We propose in this work to employ the Box-LASSO, a variation of the popular\nLASSO method, as a low-complexity decoder in a massive multiple-input\nmultiple-output (MIMO) wireless communication system. The Box-LASSO is mainly\nuseful for detecting simultaneously structured signals such as signals that are\nknown to be sparse and bounded. One modulation technique that generates\nessentially sparse and bounded constellation points is the so-called\ngeneralized space-shift keying (GSSK) modulation. In this direction, we derive\nhigh dimensional sharp characterizations of various performance measures of the\nBox-LASSO such as the mean square error, probability of support recovery, and\nthe element error rate, under independent and identically distributed (i.i.d.)\nGaussian channels that are not perfectly known. In particular, the analytical\ncharacterizations can be used to demonstrate performance improvements of the\nBox-LASSO as compared to the widely used standard LASSO. Then, we can use these\nmeasures to optimally tune the involved hyper-parameters of Box-LASSO such as\nthe regularization parameter. In addition, we derive optimum power allocation\nand training duration schemes in a training-based massive MIMO system. Monte\nCarlo simulations are used to validate these premises and to show the sharpness\nof the derived analytical results.",
    "descriptor": "",
    "authors": [
      "Ayed M. Alrashdi",
      "Abdullah E. Alrashdi",
      "Mohamed A. H. Eleiwa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01870"
  },
  {
    "id": "arXiv:2107.01871",
    "title": "Linking Use Cases and Associated Requirements: A Replicated Eye Tracking  Study on the Impact of Linking Variants on Reading Behavior",
    "abstract": "A wide variety of use case templates supports different variants to link a\nuse case with its associated requirements. Regardless of the linking, a reader\nmust process the related information simultaneously to understand them. Linking\nvariants are intended to cause a specific reading behavior in which a reader\ninterrelates a use case and its associated requirements. Due to the effort to\ncreate and maintain links, we investigated the impact of different linking\nvariants on the reading behavior in terms of visual effort and the intended way\nof interrelating both artifacts. We designed an eye tracking study about\nreading a use case and requirements. We conducted the study twice each with 15\nsubjects as a baseline experiment and as a repetition. The results of the\nbaseline experiment, its repetition, and their joint analysis are consistent.\nAll investigated linking variants cause comparable visual effort. In all cases,\nreading the single artifacts one after the other is the most frequently\noccurring behavior. Only links embedded in the fields of a use case description\nsignificantly increase the readers' efforts to interrelate both artifacts. None\nof the investigated linking variants impedes reading a use case and\nrequirements. However, only the most detailed linking variant causes readers to\nprocess related information simultaneously.",
    "descriptor": "",
    "authors": [
      "Oliver Karras",
      "Alexandra Risch",
      "Jil Kl\u00fcnder"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01871"
  },
  {
    "id": "arXiv:2107.01872",
    "title": "Part2Word: Learning Joint Embedding of Point Clouds and Text by Matching  Parts to Words",
    "abstract": "It is important to learn joint embedding for 3D shapes and text in different\nshape understanding tasks, such as shape-text matching, retrieval, and shape\ncaptioning. Current multi-view based methods learn a mapping from multiple\nrendered views to text. However, these methods can not analyze 3D shapes well\ndue to the self-occlusion and limitation of learning manifolds. To resolve this\nissue, we propose a method to learn joint embedding of point clouds and text by\nmatching parts from shapes to words from sentences in a common space.\nSpecifically, we first learn segmentation prior to segment point clouds into\nparts. Then, we map parts and words into an optimized space, where the parts\nand words can be matched with each other. In the optimized space, we represent\na part by aggregating features of all points within the part, while\nrepresenting each word with its context information, where we train our network\nto minimize the triplet ranking loss. Moreover, we also introduce cross-modal\nattention to capture the relationship of part-word in this matching procedure,\nwhich enhances joint embedding learning. Our experimental results outperform\nthe state-of-the-art in multi-modal retrieval under the widely used benchmark.",
    "descriptor": "",
    "authors": [
      "Chuan Tang",
      "Xi Yang",
      "Bojian Wu",
      "Zhizhong Han",
      "Yi Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01872"
  },
  {
    "id": "arXiv:2107.01873",
    "title": "Detecting Concept Drift With Neural Network Model Uncertainty",
    "abstract": "Deployed machine learning models are confronted with the problem of changing\ndata over time, a phenomenon also called concept drift. While existing\napproaches of concept drift detection already show convincing results, they\nrequire true labels as a prerequisite for successful drift detection.\nEspecially in many real-world application scenarios-like the ones covered in\nthis work-true labels are scarce, and their acquisition is expensive.\nTherefore, we introduce a new algorithm for drift detection, Uncertainty Drift\nDetection (UDD), which is able to detect drifts without access to true labels.\nOur approach is based on the uncertainty estimates provided by a deep neural\nnetwork in combination with Monte Carlo Dropout. Structural changes over time\nare detected by applying the ADWIN technique on the uncertainty estimates, and\ndetected drifts trigger a retraining of the prediction model. In contrast to\ninput data-based drift detection, our approach considers the effects of the\ncurrent input data on the properties of the prediction model rather than\ndetecting change on the input data only (which can lead to unnecessary\nretrainings). We show that UDD outperforms other state-of-the-art strategies on\ntwo synthetic as well as ten real-world data sets for both regression and\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Lucas Baier",
      "Tim Schl\u00f6r",
      "Jakob Sch\u00f6ffer",
      "Niklas K\u00fchl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01873"
  },
  {
    "id": "arXiv:2107.01875",
    "title": "DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling",
    "abstract": "Rap generation, which aims to produce lyrics and corresponding singing beats,\nneeds to model both rhymes and rhythms. Previous works for rap generation\nfocused on rhyming lyrics but ignored rhythmic beats, which are important for\nrap performance. In this paper, we develop DeepRapper, a Transformer-based rap\ngeneration system that can model both rhymes and rhythms. Since there is no\navailable rap dataset with rhythmic beats, we develop a data mining pipeline to\ncollect a large-scale rap dataset, which includes a large number of rap songs\nwith aligned lyrics and rhythmic beats. Second, we design a Transformer-based\nautoregressive language model which carefully models rhymes and rhythms.\nSpecifically, we generate lyrics in the reverse order with rhyme representation\nand constraint for rhyme enhancement and insert a beat symbol into lyrics for\nrhythm/beat modeling. To our knowledge, DeepRapper is the first system to\ngenerate rap with both rhymes and rhythms. Both objective and subjective\nevaluations demonstrate that DeepRapper generates creative and high-quality\nraps with rhymes and rhythms. Code will be released on GitHub.",
    "descriptor": "\nComments: Accepted by ACL 2021 main conference\n",
    "authors": [
      "Lanqing Xue",
      "Kaitao Song",
      "Duocai Wu",
      "Xu Tan",
      "Nevin L. Zhang",
      "Tao Qin",
      "Wei-Qiang Zhang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01875"
  },
  {
    "id": "arXiv:2107.01877",
    "title": "Faster-LTN: a neuro-symbolic, end-to-end object detection architecture",
    "abstract": "The detection of semantic relationships between objects represented in an\nimage is one of the fundamental challenges in image interpretation.\nNeural-Symbolic techniques, such as Logic Tensor Networks (LTNs), allow the\ncombination of semantic knowledge representation and reasoning with the ability\nto efficiently learn from examples typical of neural networks. We here propose\nFaster-LTN, an object detector composed of a convolutional backbone and an LTN.\nTo the best of our knowledge, this is the first attempt to combine both\nframeworks in an end-to-end training setting. This architecture is trained by\noptimizing a grounded theory which combines labelled examples with prior\nknowledge, in the form of logical axioms. Experimental comparisons show\ncompetitive performance with respect to the traditional Faster R-CNN\narchitecture.",
    "descriptor": "\nComments: accepted for presentation at ICANN 2021\n",
    "authors": [
      "Francesco Manigrasso",
      "Filomeno Davide Miro",
      "Lia Morra",
      "Fabrizio Lamberti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01877"
  },
  {
    "id": "arXiv:2107.01881",
    "title": "Robust Online Convex Optimization in the Presence of Outliers",
    "abstract": "We consider online convex optimization when a number k of data points are\noutliers that may be corrupted. We model this by introducing the notion of\nrobust regret, which measures the regret only on rounds that are not outliers.\nThe aim for the learner is to achieve small robust regret, without knowing\nwhere the outliers are. If the outliers are chosen adversarially, we show that\na simple filtering strategy on extreme gradients incurs O(k) additive overhead\ncompared to the usual regret bounds, and that this is unimprovable, which means\nthat k needs to be sublinear in the number of rounds. We further ask which\nadditional assumptions would allow for a linear number of outliers. It turns\nout that the usual benign cases of independently, identically distributed\n(i.i.d.) observations or strongly convex losses are not sufficient. However,\ncombining i.i.d. observations with the assumption that outliers are those\nobservations that are in an extreme quantile of the distribution, does lead to\nsublinear robust regret, even though the expected number of outliers is linear.",
    "descriptor": "",
    "authors": [
      "Tim van Erven",
      "Sarah Sachs",
      "Wouter M. Koolen",
      "Wojciech Kot\u0142owski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01881"
  },
  {
    "id": "arXiv:2107.01883",
    "title": "A Theory of Higher-Order Subtyping with Type Intervals (Extended  Version)",
    "abstract": "The calculus of Dependent Object Types (DOT) has enabled a more principled\nand robust implementation of Scala, but its support for type-level computation\nhas proven insufficient. As a remedy, we propose $F^\\omega_{..}$, a rigorous\ntheoretical foundation for Scala's higher-kinded types. $F^\\omega_{..}$ extends\n$F^\\omega_{<:}$ with interval kinds, which afford a unified treatment of\nimportant type- and kind-level abstraction mechanisms found in Scala, such as\nbounded quantification, bounded operator abstractions, translucent type\ndefinitions and first-class subtyping constraints. The result is a flexible and\ngeneral theory of higher-order subtyping. We prove type and kind safety of\n$F^\\omega_{..}$, as well as weak normalization of types and undecidability of\nsubtyping. All our proofs are mechanized in Agda using a fully syntactic\napproach based on hereditary substitution.",
    "descriptor": "\nComments: 73 pages; to be presented at the 26th ACM SIGPLAN International Conference on Functional Programming (ICFP 2021), 22-27 August 2021\n",
    "authors": [
      "Sandro Stucki",
      "Paolo G. Giarrusso"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01883"
  },
  {
    "id": "arXiv:2107.01884",
    "title": "Online and Offline Robot Programming via Augmented Reality Workspaces",
    "abstract": "Robot programming methods for industrial robots are time consuming and often\nrequire operators to have knowledge in robotics and programming. To reduce\ncosts associated with reprogramming, various interfaces using augmented reality\nhave recently been proposed to provide users with more intuitive means of\ncontrolling robots in real-time and programming them without having to code.\nHowever, most solutions require the operator to be close to the real robot's\nworkspace which implies either removing it from the production line or shutting\ndown the whole production line due to safety hazards. We propose a novel\naugmented reality interface providing the users with the ability to model a\nvirtual representation of a workspace which can be saved and reused to program\nnew tasks or adapt old ones without having to be co-located with the real\nrobot. Similar to previous interfaces, the operators then have the ability to\nprogram robot tasks or control the robot in real-time by manipulating a virtual\nrobot. We evaluate the intuitiveness and usability of the proposed interface\nwith a user study where 18 participants programmed a robot manipulator for a\ndisassembly task.",
    "descriptor": "\nComments: 8 pages, 9 figures, submitted to 'IEEE Robotics & Automation Magazine' (RAM), Special Issue on Extended Reality in Robotics\n",
    "authors": [
      "Yong Joon Thoo",
      "J\u00e9r\u00e9my Maceiras",
      "Philip Abbet",
      "Mattia Racca",
      "Hakan Girgin",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01884"
  },
  {
    "id": "arXiv:2107.01886",
    "title": "Self-Contrastive Learning with Hard Negative Sampling for  Self-supervised Point Cloud Learning",
    "abstract": "Point clouds have attracted increasing attention as a natural representation\nof 3D shapes. Significant progress has been made in developing methods for\npoint cloud analysis, which often requires costly human annotation as\nsupervision in practice. To address this issue, we propose a novel\nself-contrastive learning for self-supervised point cloud representation\nlearning, aiming to capture both local geometric patterns and nonlocal semantic\nprimitives based on the nonlocal self-similarity of point clouds. The\ncontributions are two-fold: on the one hand, instead of contrasting among\ndifferent point clouds as commonly employed in contrastive learning, we exploit\nself-similar point cloud patches within a single point cloud as positive\nsamples and otherwise negative ones to facilitate the task of contrastive\nlearning. Such self-contrastive learning is well aligned with the emerging\nparadigm of self-supervised learning for point cloud analysis. On the other\nhand, we actively learn hard negative samples that are close to positive\nsamples in the representation space for discriminative feature learning, which\nare sampled conditional on each anchor patch leveraging on the degree of\nself-similarity. Experimental results show that the proposed method achieves\nstate-of-the-art performance on widely used benchmark datasets for\nself-supervised point cloud segmentation and transfer learning for\nclassification.",
    "descriptor": "\nComments: Accepted to ACM MM 2021\n",
    "authors": [
      "Bi'an Du",
      "Xiang Gao",
      "Wei Hu",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01886"
  },
  {
    "id": "arXiv:2107.01887",
    "title": "An Analytical Survey on Recent Trends in High Dimensional Data  Visualization",
    "abstract": "Data visualization is the process by which data of any size or dimensionality\nis processed to produce an understandable set of data in a lower\ndimensionality, allowing it to be manipulated and understood more easily by\npeople. The goal of our paper is to survey the performance of current\nhigh-dimensional data visualization techniques and quantify their strengths and\nweaknesses through relevant quantitative measures, including runtime, memory\nusage, clustering quality, separation quality, global structure preservation,\nand local structure preservation. To perform the analysis, we select a subset\nof state-of-the-art methods. Our work shows how the selected algorithms produce\nembeddings with unique qualities that lend themselves towards certain tasks,\nand how each of these algorithms are constrained by compute resources.",
    "descriptor": "\nComments: 17 pages, a survey on recent trends in high dimensional data visualization\n",
    "authors": [
      "Alexander Kiefer",
      "Md. Khaledur Rahman"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01887"
  },
  {
    "id": "arXiv:2107.01889",
    "title": "OPA: Object Placement Assessment Dataset",
    "abstract": "Image composition aims to generate realistic composite image by inserting an\nobject from one image into another background image, where the placement (e.g.,\nlocation, size, occlusion) of inserted object may be unreasonable, which would\nsignificantly degrade the quality of the composite image. Although some works\nattempted to learn object placement to create realistic composite images, they\ndid not focus on assessing the plausibility of object placement. In this paper,\nwe focus on object placement assessment task, which verifies whether a\ncomposite image is plausible in terms of the object placement. To accomplish\nthis task, we construct the first Object Placement Assessment (OPA) dataset\nconsisting of composite images and their rationality labels. Dataset is\navailable at https://github.com/bcmi/Object-Placement-Assessment-Dataset-OPA.",
    "descriptor": "",
    "authors": [
      "Liu Liu",
      "Bo Zhang",
      "Jiangtong Li",
      "Li Niu",
      "Qingyang Liu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01889"
  },
  {
    "id": "arXiv:2107.01892",
    "title": "NOTE: Solution for KDD-CUP 2021 WikiKG90M-LSC",
    "abstract": "WikiKG90M in KDD Cup 2021 is a large encyclopedic knowledge graph, which\ncould benefit various downstream applications such as question answering and\nrecommender systems. Participants are invited to complete the knowledge graph\nby predicting missing triplets. Recent representation learning methods have\nachieved great success on standard datasets like FB15k-237. Thus, we train the\nadvanced algorithms in different domains to learn the triplets, including OTE,\nQuatE, RotatE and TransE. Significantly, we modified OTE into NOTE (short for\nNorm-OTE) for better performance. Besides, we use both the DeepWalk and the\npost-smoothing technique to capture the graph structure for supplementation. In\naddition to the representations, we also use various statistical probabilities\namong the head entities, the relations and the tail entities for the final\nprediction. Experimental results show that the ensemble of state-of-the-art\nrepresentation learning methods could draw on each others strengths. And we\ndevelop feature engineering from validation candidates for further\nimprovements. Please note that we apply the same strategy on the test set for\nfinal inference. And these features may not be practical in the real world when\nconsidering ranking against all the entities.",
    "descriptor": "\nComments: The 1st solution for KDD-CUP 2021 WIKIKG90M-LSC. 7 pages, 2 figures, 1 table\n",
    "authors": [
      "Weiyue Su",
      "Zeyang Fang",
      "Hui Zhong",
      "Huijuan Wang",
      "Siming Dai",
      "Zhengjie Huang",
      "Yunsheng Shi",
      "Shikun Feng",
      "Zeyu Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01892"
  },
  {
    "id": "arXiv:2107.01894",
    "title": "Automated Recovery of Issue-Commit Links Leveraging Both Textual and  Non-textual Data",
    "abstract": "An issue documents discussions around required changes in issue-tracking\nsystems, while a commit contains the change itself in the version control\nsystems. Recovering links between issues and commits can facilitate many\nsoftware evolution tasks such as bug localization, and software documentation.\nA previous study on over half a million issues from GitHub reports only about\n42.2% of issues are manually linked by developers to their pertinent commits.\nAutomating the linking of commit-issue pairs can contribute to the improvement\nof the said tasks. By far, current state-of-the-art approaches for automated\ncommit-issue linking suffer from low precision, leading to unreliable results,\nsometimes to the point that imposes human supervision on the predicted links.\nThe low performance gets even more severe when there is a lack of textual\ninformation in either commits or issues. Current approaches are also proven\ncomputationally expensive.\nWe propose Hybrid-Linker to overcome such limitations by exploiting two\ninformation channels; (1) a non-textual-based component that operates on\nnon-textual, automatically recorded information of the commit-issue pairs to\npredict a link, and (2) a textual-based one which does the same using textual\ninformation of the commit-issue pairs. Then, combining the results from the two\nclassifiers, Hybrid-Linker makes the final prediction. Thus, every time one\ncomponent falls short in predicting a link, the other component fills the gap\nand improves the results. We evaluate Hybrid-Linker against competing\napproaches, namely FRLink and DeepLink on a dataset of 12 projects.\nHybrid-Linker achieves 90.1%, 87.8%, and 88.9% based on recall, precision, and\nF-measure, respectively. It also outperforms FRLink and DeepLink by 31.3%, and\n41.3%, regarding the F-measure. Moreover, Hybrid-Linker exhibits extensive\nimprovements in terms of performance as well.",
    "descriptor": "\nComments: To appear in the Proceedings of the 37th IEEE Conference on Software Maintenance and Evolution (ICSME)\n",
    "authors": [
      "Pooya Rostami Mazrae",
      "Maliheh Izadi",
      "Abbas Heydarnoori"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01894"
  },
  {
    "id": "arXiv:2107.01895",
    "title": "Optimizing the Numbers of Queries and Replies in Federated Learning with  Differential Privacy",
    "abstract": "Federated learning (FL) empowers distributed clients to collaboratively train\na shared machine learning model through exchanging parameter information.\nDespite the fact that FL can protect clients' raw data, malicious users can\nstill crack original data with disclosed parameters. To amend this flaw,\ndifferential privacy (DP) is incorporated into FL clients to disturb original\nparameters, which however can significantly impair the accuracy of the trained\nmodel. In this work, we study a crucial question which has been vastly\noverlooked by existing works: what are the optimal numbers of queries and\nreplies in FL with DP so that the final model accuracy is maximized. In FL, the\nparameter server (PS) needs to query participating clients for multiple global\niterations to complete training. Each client responds a query from the PS by\nconducting a local iteration. Our work investigates how many times the PS\nshould query clients and how many times each client should reply the PS. We\ninvestigate two most extensively used DP mechanisms (i.e., the Laplace\nmechanism and Gaussian mechanisms). Through conducting convergence rate\nanalysis, we can determine the optimal numbers of queries and replies in FL\nwith DP so that the final model accuracy can be maximized. Finally, extensive\nexperiments are conducted with publicly available datasets: MNIST and FEMNIST,\nto verify our analysis and the results demonstrate that properly setting the\nnumbers of queries and replies can significantly improve the final model\naccuracy in FL with DP.",
    "descriptor": "",
    "authors": [
      "Yipeng Zhou",
      "Xuezheng Liu",
      "Yao Fu",
      "Di Wu",
      "Chao Li",
      "Shui Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01895"
  },
  {
    "id": "arXiv:2107.01899",
    "title": "Ray-ONet: Efficient 3D Reconstruction From A Single RGB Image",
    "abstract": "We propose Ray-ONet to reconstruct detailed 3D models from monocular images\nefficiently. By predicting a series of occupancy probabilities along a ray that\nis back-projected from a pixel in the camera coordinate, our method Ray-ONet\nimproves the reconstruction accuracy in comparison with Occupancy Networks\n(ONet), while reducing the network inference complexity to O($N^2$). As a\nresult, Ray-ONet achieves state-of-the-art performance on the ShapeNet\nbenchmark with more than 20$\\times$ speed-up at $128^3$ resolution and\nmaintains a similar memory footprint during inference.",
    "descriptor": "",
    "authors": [
      "Wenjing Bian",
      "Zirui Wang",
      "Kejie Li",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01899"
  },
  {
    "id": "arXiv:2107.01900",
    "title": "On The Distribution of Penultimate Activations of Classification  Networks",
    "abstract": "This paper studies probability distributions ofpenultimate activations of\nclassification networks.We show that, when a classification network istrained\nwith the cross-entropy loss, its final classi-fication layer forms\naGenerative-Discriminativepairwith a generative classifier based on a\nspecificdistribution of penultimate activations. More im-portantly, the\ndistribution is parameterized by theweights of the final fully-connected layer,\nand canbe considered as a generative model that synthe-sizes the penultimate\nactivations without feedinginput data. We empirically demonstrate that\nthisgenerative model enables stable knowledge dis-tillation in the presence of\ndomain shift, and cantransfer knowledge from a classifier to\nvariationalautoencoders and generative adversarial networksfor\nclass-conditional image generation.",
    "descriptor": "\nComments: 8 pages, UAI 2021\n",
    "authors": [
      "Minkyo Seo",
      "Yoonho Lee",
      "Suha Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01900"
  },
  {
    "id": "arXiv:2107.01903",
    "title": "SM-SGE: A Self-Supervised Multi-Scale Skeleton Graph Encoding Framework  for Person Re-Identification",
    "abstract": "Person re-identification via 3D skeletons is an emerging topic with great\npotential in security-critical applications. Existing methods typically learn\nbody and motion features from the body-joint trajectory, whereas they lack a\nsystematic way to model body structure and underlying relations of body\ncomponents beyond the scale of body joints. In this paper, we for the first\ntime propose a Self-supervised Multi-scale Skeleton Graph Encoding (SM-SGE)\nframework that comprehensively models human body, component relations, and\nskeleton dynamics from unlabeled skeleton graphs of various scales to learn an\neffective skeleton representation for person Re-ID. Specifically, we first\ndevise multi-scale skeleton graphs with coarse-to-fine human body partitions,\nwhich enables us to model body structure and skeleton dynamics at multiple\nlevels. Second, to mine inherent correlations between body components in\nskeletal motion, we propose a multi-scale graph relation network to learn\nstructural relations between adjacent body-component nodes and collaborative\nrelations among nodes of different scales, so as to capture more discriminative\nskeleton graph features. Last, we propose a novel multi-scale skeleton\nreconstruction mechanism to enable our framework to encode skeleton dynamics\nand high-level semantics from unlabeled skeleton graphs, which encourages\nlearning a discriminative skeleton representation for person Re-ID. Extensive\nexperiments show that SM-SGE outperforms most state-of-the-art skeleton-based\nmethods. We further demonstrate its effectiveness on 3D skeleton data estimated\nfrom large-scale RGB videos. Our codes are open at\nhttps://github.com/Kali-Hac/SM-SGE.",
    "descriptor": "\nComments: Accepted at ACMMM 2021 Main Track. Sole copyright holder is ACMMM. Codes are available at this https URL\n",
    "authors": [
      "Haocong Rao",
      "Xiping Hu",
      "Jun Cheng",
      "Bin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01903"
  },
  {
    "id": "arXiv:2107.01904",
    "title": "Ensemble and Auxiliary Tasks for Data-Efficient Deep Reinforcement  Learning",
    "abstract": "Ensemble and auxiliary tasks are both well known to improve the performance\nof machine learning models when data is limited. However, the interaction\nbetween these two methods is not well studied, particularly in the context of\ndeep reinforcement learning. In this paper, we study the effects of ensemble\nand auxiliary tasks when combined with the deep Q-learning algorithm. We\nperform a case study on ATARI games under limited data constraint. Moreover, we\nderive a refined bias-variance-covariance decomposition to analyze the\ndifferent ways of learning ensembles and using auxiliary tasks, and use the\nanalysis to help provide some understanding of the case study. Our code is open\nsource and available at https://github.com/NUS-LID/RENAULT.",
    "descriptor": "\nComments: ECML-PKDD 2021. Code: this https URL\n",
    "authors": [
      "Muhammad Rizki Maulana",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01904"
  },
  {
    "id": "arXiv:2107.01905",
    "title": "Creating Unbiased Public Benchmark Datasets with Data Leakage Prevention  for Predictive Process Monitoring",
    "abstract": "Advances in AI, and especially machine learning, are increasingly drawing\nresearch interest and efforts towards predictive process monitoring, the\nsubfield of process mining (PM) that concerns predicting next events, process\noutcomes and remaining execution times. Unfortunately, researchers use a\nvariety of datasets and ways to split them into training and test sets. The\ndocumentation of these preprocessing steps is not always complete.\nConsequently, research results are hard or even impossible to reproduce and to\ncompare between papers. At times, the use of non-public domain knowledge\nfurther hampers the fair competition of ideas. Often the training and test sets\nare not completely separated, a data leakage problem particular to predictive\nprocess monitoring. Moreover, test sets usually suffer from bias in terms of\nboth the mix of case durations and the number of running cases. These obstacles\npose a challenge to the field's progress. The contribution of this paper is to\nidentify and demonstrate the importance of these obstacles and to propose\npreprocessing steps to arrive at unbiased benchmark datasets in a principled\nway, thus creating representative test sets without data leakage with the aim\nof levelling the playing field, promoting open science and contributing to more\nrapid progress in predictive process monitoring.",
    "descriptor": "\nComments: Accepted for AI4BPM workshop at BMP2021 conferences\n",
    "authors": [
      "Hans Weytjens",
      "Jochen De Weerdt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01905"
  },
  {
    "id": "arXiv:2107.01908",
    "title": "Hybrid and dynamic policy gradient optimization for bipedal robot  locomotion",
    "abstract": "Controlling a non-statically bipedal robot is challenging due to the complex\ndynamics and multi-criterion optimization involved. Recent works have\ndemonstrated the effectiveness of deep reinforcement learning (DRL) for\nsimulation and physically implemented bipeds. In these methods, the rewards\nfrom different criteria are normally summed to learn a single value function.\nHowever, this may cause the loss of dependency information between hybrid\nrewards and lead to a sub-optimal policy. In this work, we propose a novel\npolicy gradient reinforcement learning for biped locomotion, allowing the\ncontrol policy to be simultaneously optimized by multiple criteria using a\ndynamic mechanism. Our proposed method applies a multi-head critic to learn a\nseparate value function for each component reward function. This also leads to\nhybrid policy gradients. We further propose dynamic weight for hybrid policy\ngradients to optimize the policy with different priorities. This hybrid and\ndynamic policy gradient (HDPG) design makes the agent learn more efficiently.\nWe showed that the proposed method outperforms summed-up-reward approaches and\nis able to transfer to physical robots. The MuJoCo results further demonstrate\nthe effectiveness and generalization of our HDPG.",
    "descriptor": "",
    "authors": [
      "Changxin Huang",
      "Jiang Su",
      "Zhihong Zhang",
      "Dong Zhao",
      "Liang Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01908"
  },
  {
    "id": "arXiv:2107.01910",
    "title": "Analyzing a Knowledge Graph of Industry4.0 Standards",
    "abstract": "In this article, we tackle the problem of standard interoperability across\ndifferent standardization frameworks, and devise a knowledge-driven approach\nthat allows for the description of standards and standardization frameworks\ninto an Industry 4.0 knowledge graph (I40KG). The STO ontology represents\nproperties of standards and standardization frameworks, as well as\nrelationships among them. The I40KG integrates more than 200 standards and four\nstandardization frameworks. To populate the I40KG, the landscape of standards\nhas been analyzed from a semantic perspective and the resulting I40KG\nrepresents knowledge expressed in more than 200 industrial related documents\nincluding technical reports, research articles, and white papers. Additionally,\nthe I40KG has been linked to existing knowledge graphs and an automated\nreasoning has been implemented to reveal implicit relations between standards\nas well as mappings across standardization frameworks. We analyze both the\nnumber of discovered relations between standards and the accuracy of these\nrelations. Observed results indicate that both reasoning and linking processes\nenable for increasing the connectivity in the knowledge graph by up to 80%,\nwhilst up to 96% of the relations can be validated. These outcomes suggest that\nintegrating standards and standardization frameworks into the I40KG enables the\nresolution of semantic interoperability conflicts, empowering the communication\nin smart factories.",
    "descriptor": "\nComments: Based on the paper Irlan Grangel-Gonzalez, Maria-Esther Vidal: Analyzing a Knowledge Graph of Industry 4.0 Standards. WWW (Companion Volume) 2021: 16-25\n",
    "authors": [
      "Irlan Grangel-Gonzalez",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01910"
  },
  {
    "id": "arXiv:2107.01912",
    "title": "Berserker: ASN.1-based Fuzzing of Radio Resource Control Protocol for 4G  and 5G",
    "abstract": "Telecom networks together with mobile phones must be rigorously tested for\nrobustness against vulnerabilities in order to guarantee availability. RRC\nprotocol is responsible for the management of radio resources and is among the\nmost important telecom protocols whose extensive testing is warranted. To that\nend, we present a novel RRC fuzzer, called Berserker, for 4G and 5G.\nBerserker's novelty comes from being backward and forward compatible to any\nversion of 4G and 5G RRC technical specifications. It is based on RRC message\nformat definitions in ASN.1 and additionally covers fuzz testing of another\nprotocol, called NAS, tunneled in RRC. Berserker uses concrete implementations\nof telecom protocol stack and is unaffected by lower layer protocol handlings\nlike encryption and segmentation. It is also capable of evading size and type\nconstraints in RRC message format definitions. Berserker discovered two\npreviously unknown serious vulnerabilities in srsLTE -- one of which also\naffects openLTE -- confirming its applicability to telecom robustness.",
    "descriptor": "\nComments: 19 pages, 9 figures, 17 tables\n",
    "authors": [
      "Srinath Potnuru",
      "Prajwol Kumar Nakarmi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01912"
  },
  {
    "id": "arXiv:2107.01914",
    "title": "Ranking Online Social Users by their Influence",
    "abstract": "We introduce an original mathematical model to analyse the diffusion of posts\nwithin a generic online social platform. The main novelty is that each user is\nnot simply considered as a node on the social graph, but is further equipped\nwith his/her own Wall and Newsfeed, and has his/her own individual self-posting\nand re-posting activity. As a main result using our developed model, we derive\nin closed form the probabilities that posts originating from a given user are\nfound on the Wall and Newsfeed of any other. These are the solution of a linear\nsystem of equations, which can be resolved iteratively. In fact, our model is\nvery flexible with respect to the modelling assumptions. Using the\nprobabilities derived from the solution, we define a new measure of per-user\ninfluence over the entire network, the $\\Psi$-score, which combines the user\nposition on the graph with user (re-)posting activity. In the homogeneous case\nwhere all users have the same activity rates, it is shown that a variant of the\n$\\Psi$-score is equal to PageRank. Furthermore, we compare the new model and\nits $\\Psi$-score against the empirical influence measured from very large data\ntraces (Twitter, Weibo). The results illustrate that these new tools can\naccurately rank influencers with asymmetric (re-)posting activity for such real\nworld applications.",
    "descriptor": "\nComments: 18 pages, 7 figures, journal publications. arXiv admin note: text overlap with arXiv:1902.07187\n",
    "authors": [
      "Anastasios Giovanidis",
      "Bruno Baynat",
      "Cl\u00e9mence Magnien",
      "Antoine Vendeville"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01914"
  },
  {
    "id": "arXiv:2107.01915",
    "title": "Logic Locking at the Frontiers of Machine Learning: A Survey on  Developments and Opportunities",
    "abstract": "In the past decade, a lot of progress has been made in the design and\nevaluation of logic locking; a premier technique to safeguard the integrity of\nintegrated circuits throughout the electronics supply chain. However, the\nwidespread proliferation of machine learning has recently introduced a new\npathway to evaluating logic locking schemes. This paper summarizes the recent\ndevelopments in logic locking attacks and countermeasures at the frontiers of\ncontemporary machine learning models. Based on the presented work, the key\ntakeaways, opportunities, and challenges are highlighted to offer\nrecommendations for the design of next-generation logic locking.",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted at VLSI-SOC 2021\n",
    "authors": [
      "Dominik Sisejkovic",
      "Lennart M. Reimann",
      "Elmira Moussavi",
      "Farhad Merchant",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01915"
  },
  {
    "id": "arXiv:2107.01917",
    "title": "Proving SIFA Protection of Masked Redundant Circuits",
    "abstract": "Implementation attacks like side-channel and fault attacks pose a\nconsiderable threat to cryptographic devices that are physically accessible by\nan attacker. As a consequence, devices like smart cards implement corresponding\ncountermeasures like redundant computation and masking. Recently, statistically\nineffective fault attacks (SIFA) were shown to be able to circumvent these\nclassical countermeasure techniques. We present a new approach for verifying\nthe SIFA protection of arbitrary masked implementations in both hardware and\nsoftware. The proposed method uses Boolean dependency analysis, factorization,\nand known properties of masked computations to show whether the fault detection\nmechanism of redundant masked circuits can leak information about the processed\nsecret values. We implemented this new method in a tool called Danira, which\ncan show the SIFA resistance of cryptographic implementations like AES S-Boxes\nwithin minutes.",
    "descriptor": "\nComments: This is the extended version of the paper published at ATVA 2021\n",
    "authors": [
      "Vedad Hadzic",
      "Robert Primas",
      "Roderick Bloem"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01917"
  },
  {
    "id": "arXiv:2107.01921",
    "title": "An Empirical Study of Rule-Based and Learning-Based Approaches for  Static Application Security Testing",
    "abstract": "Background: Static Application Security Testing (SAST) tools purport to\nassist developers in detecting security issues in source code. These tools\ntypically use rule-based approaches to scan source code for security\nvulnerabilities. However, due to the significant shortcomings of these tools\n(i.e., high false positive rates), learning-based approaches for Software\nVulnerability Prediction (SVP) are becoming a popular approach. Aims: Despite\nthe similar objectives of these two approaches, their comparative value is\nunexplored. We provide an empirical analysis of SAST tools and SVP models, to\nidentify their relative capabilities for source code security analysis. Method:\nWe evaluate the detection and assessment performance of several common SAST\ntools and SVP models on a variety of vulnerability datasets. We further assess\nthe viability and potential benefits of combining the two approaches. Results:\nSAST tools and SVP models provide similar detection capabilities, but SVP\nmodels exhibit better overall performance for both detection and assessment.\nUnification of the two approaches is difficult due to lacking synergies.\nConclusions: Our study generates 12 main findings which provide insights into\nthe capabilities and synergy of these two approaches. Through these\nobservations we provide recommendations for use and improvement.",
    "descriptor": "\nComments: To be published in ESEM 21\n",
    "authors": [
      "Roland Croft",
      "Dominic Newlands",
      "Ziyu Chen",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01921"
  },
  {
    "id": "arXiv:2107.01927",
    "title": "Android Malware Category and Family Detection and Identification using  Machine Learning",
    "abstract": "Android malware is one of the most dangerous threats on the internet, and\nit's been on the rise for several years. Despite significant efforts in\ndetecting and classifying android malware from innocuous android applications,\nthere is still a long way to go. As a result, there is a need to provide a\nbasic understanding of the behavior displayed by the most common Android\nmalware categories and families. Each Android malware family and category has a\ndistinct objective. As a result, it has impacted every corporate area,\nincluding healthcare, banking, transportation, government, and e-commerce. In\nthis paper, we presented two machine-learning approaches for Dynamic Analysis\nof Android Malware: one for detecting and identifying Android Malware\nCategories and the other for detecting and identifying Android Malware\nFamilies, which was accomplished by analyzing a massive malware dataset with 14\nprominent malware categories and 180 prominent malware families of\nCCCS-CIC-AndMal2020 dataset on Dynamic Layers. Our approach achieves in Android\nMalware Category detection more than 96 % accurate and achieves in Android\nMalware Family detection more than 99% accurate. Our approach provides a method\nfor high-accuracy Dynamic Analysis of Android Malware while also shortening the\ntime required to analyze smartphone malware.",
    "descriptor": "",
    "authors": [
      "Ahmed Hashem El Fiky",
      "Ayman El Shenawy",
      "Mohamed Ashraf Madkour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01927"
  },
  {
    "id": "arXiv:2107.01933",
    "title": "CoCoSum: Contextual Code Summarization with Multi-Relational Graph  Neural Network",
    "abstract": "Source code summaries are short natural language descriptions of code\nsnippets that help developers better understand and maintain source code. There\nhas been a surge of work on automatic code summarization to reduce the burden\nof writing summaries manually. However, most contemporary approaches mainly\nleverage the information within the boundary of the method being summarized\n(i.e., local context), and ignore the broader context that could assist with\ncode summarization. This paper explores two global contexts, namely intra-class\nand inter-class contexts, and proposes the model CoCoSUM: Contextual Code\nSummarization with Multi-Relational Graph Neural Networks. CoCoSUM first\nincorporates class names as the intra-class context to generate the class\nsemantic embeddings. Then, relevant Unified Modeling Language (UML) class\ndiagrams are extracted as inter-class context and are encoded into the class\nrelational embeddings using a novel Multi-Relational Graph Neural Network\n(MRGNN). Class semantic embeddings and class relational embeddings, together\nwith the outputs from code token encoder and AST encoder, are passed to a\ndecoder armed with a two-level attention mechanism to generate high-quality,\ncontext-aware code summaries. We conduct extensive experiments to evaluate our\napproach and compare it with other automatic code summarization models. The\nexperimental results show that CoCoSUM is effective and outperforms\nstate-of-the-art methods. Our source code and experimental data are available\nin the supplementary materials and will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Yanlin Wang",
      "Ensheng Shi",
      "Lun Du",
      "Xiaodi Yang",
      "Yuxuan Hu",
      "Shi Han",
      "Hongyu Zhang",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01933"
  },
  {
    "id": "arXiv:2107.01936",
    "title": "Adversarial Robustness of Probabilistic Network Embedding for Link  Prediction",
    "abstract": "In today's networked society, many real-world problems can be formalized as\npredicting links in networks, such as Facebook friendship suggestions,\ne-commerce recommendations, and the prediction of scientific collaborations in\ncitation networks. Increasingly often, link prediction problem is tackled by\nmeans of network embedding methods, owing to their state-of-the-art\nperformance. However, these methods lack transparency when compared to simpler\nbaselines, and as a result their robustness against adversarial attacks is a\npossible point of concern: could one or a few small adversarial modifications\nto the network have a large impact on the link prediction performance when\nusing a network embedding model? Prior research has already investigated\nadversarial robustness for network embedding models, focused on classification\nat the node and graph level. Robustness with respect to the link prediction\ndownstream task, on the other hand, has been explored much less.\nThis paper contributes to filling this gap, by studying adversarial\nrobustness of Conditional Network Embedding (CNE), a state-of-the-art\nprobabilistic network embedding model, for link prediction. More specifically,\ngiven CNE and a network, we measure the sensitivity of the link predictions of\nthe model to small adversarial perturbations of the network, namely changes of\nthe link status of a node pair. Thus, our approach allows one to identify the\nlinks and non-links in the network that are most vulnerable to such\nperturbations, for further investigation by an analyst. We analyze the\ncharacteristics of the most and least sensitive perturbations, and empirically\nconfirm that our approach not only succeeds in identifying the most vulnerable\nlinks and non-links, but also that it does so in a time-efficient manner thanks\nto an effective approximation.",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Bo Kang",
      "Jefrey Lijffijt",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01936"
  },
  {
    "id": "arXiv:2107.01943",
    "title": "When and How to Fool Explainable Models (and Humans) with Adversarial  Examples",
    "abstract": "Reliable deployment of machine learning models such as neural networks\ncontinues to be challenging due to several limitations. Some of the main\nshortcomings are the lack of interpretability and the lack of robustness\nagainst adversarial examples or out-of-distribution inputs. In this paper, we\nexplore the possibilities and limits of adversarial attacks for explainable\nmachine learning models. First, we extend the notion of adversarial examples to\nfit in explainable machine learning scenarios, in which the inputs, the output\nclassifications and the explanations of the model's decisions are assessed by\nhumans. Next, we propose a comprehensive framework to study whether (and how)\nadversarial examples can be generated for explainable models under human\nassessment, introducing novel attack paradigms. In particular, our framework\nconsiders a wide range of relevant (yet often ignored) factors such as the type\nof problem, the user expertise or the objective of the explanations in order to\nidentify the attack strategies that should be adopted in each scenario to\nsuccessfully deceive the model (and the human). These contributions intend to\nserve as a basis for a more rigorous and realistic study of adversarial\nexamples in the field of explainable machine learning.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Jon Vadillo",
      "Roberto Santana",
      "Jose A. Lozano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01943"
  },
  {
    "id": "arXiv:2107.01952",
    "title": "Partition and Code: learning how to compress graphs",
    "abstract": "Can we use machine learning to compress graph data? The absence of ordering\nin graphs poses a significant challenge to conventional compression algorithms,\nlimiting their attainable gains as well as their ability to discover relevant\npatterns. On the other hand, most graph compression approaches rely on\ndomain-dependent handcrafted representations and cannot adapt to different\nunderlying graph distributions. This work aims to establish the necessary\nprinciples a lossless graph compression method should follow to approach the\nentropy storage lower bound. Instead of making rigid assumptions about the\ngraph distribution, we formulate the compressor as a probabilistic model that\ncan be learned from data and generalise to unseen instances. Our \"Partition and\nCode\" framework entails three steps: first, a partitioning algorithm decomposes\nthe graph into elementary structures, then these are mapped to the elements of\na small dictionary on which we learn a probability distribution, and finally,\nan entropy encoder translates the representation into bits. All three steps are\nparametric and can be trained with gradient descent. We theoretically compare\nthe compression quality of several graph encodings and prove, under mild\nconditions, a total ordering of their expected description lengths. Moreover,\nwe show that, under the same conditions, PnC achieves compression gains w.r.t.\nthe baselines that grow either linearly or quadratically with the number of\nvertices. Our algorithms are quantitatively evaluated on diverse real-world\nnetworks obtaining significant performance improvements with respect to\ndifferent families of non-parametric and parametric graph compressors.",
    "descriptor": "",
    "authors": [
      "Giorgos Bouritsas",
      "Andreas Loukas",
      "Nikolaos Karalias",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01952"
  },
  {
    "id": "arXiv:2107.01955",
    "title": "Detecting Faults during Automatic Screwdriving: A Dataset and Use Case  of Anomaly Detection for Automatic Screwdriving",
    "abstract": "Detecting faults in manufacturing applications can be difficult, especially\nif each fault model is to be engineered by hand. Data-driven approaches, using\nMachine Learning (ML) for detecting faults have recently gained increasing\ninterest, where a ML model can be trained on a set of data from a manufacturing\nprocess. In this paper, we present a use case of using ML models for detecting\nfaults during automated screwdriving operations, and introduce a new dataset\ncontaining fully monitored and registered data from a Universal Robot and\nOnRobot screwdriver during both normal and anomalous operations. We illustrate,\nwith the use of two time-series ML models, how to detect faults in an automated\nscrewdriving application.",
    "descriptor": "",
    "authors": [
      "B\u0142a\u017cej Leporowski",
      "Daniella Tola",
      "Casper Hansen",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01955"
  },
  {
    "id": "arXiv:2107.01959",
    "title": "Universal Approximation of Functions on Sets",
    "abstract": "Modelling functions of sets, or equivalently, permutation-invariant\nfunctions, is a long-standing challenge in machine learning. Deep Sets is a\npopular method which is known to be a universal approximator for continuous set\nfunctions. We provide a theoretical analysis of Deep Sets which shows that this\nuniversal approximation property is only guaranteed if the model's latent space\nis sufficiently high-dimensional. If the latent space is even one dimension\nlower than necessary, there exist piecewise-affine functions for which Deep\nSets performs no better than a na\\\"ive constant baseline, as judged by\nworst-case error. Deep Sets may be viewed as the most efficient incarnation of\nthe Janossy pooling paradigm. We identify this paradigm as encompassing most\ncurrently popular set-learning methods. Based on this connection, we discuss\nthe implications of our results for set learning more broadly, and identify\nsome open questions on the universality of Janossy pooling in general.",
    "descriptor": "\nComments: 54 pages, 13 figures\n",
    "authors": [
      "Edward Wagstaff",
      "Fabian B. Fuchs",
      "Martin Engelcke",
      "Michael A. Osborne",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01959"
  },
  {
    "id": "arXiv:2107.01963",
    "title": "PandaDB: Understanding Unstructured Data in Graph Database",
    "abstract": "At present, graph model is widely used in many applications, such as\nknowledge graph, financial anti-fraud. Unstructured data(such as images,\nvideos, and audios) is under explosive growing. So, queries of unstructured\ndata content on graph are widespread in a rich vein of real-world applications.\nMany graph database systems have started to support unstructured data to meet\nsuch demands. However, queries over structured and unstructured data on graph\nare often treated as separate tasks in most systems. These tasks are executed\non different module of the tools chain. Collaborative queries (i.e., involving\nboth data types) are not yet fully supported.This paper proposes a graph\ndatabase supporting collaborative queries on property graph, named PandaDB. Its\nto fulfill the emerging demands about querying unstructured data on property\ngraph model. PandaDB introduces CypherPlus, a query language which enables the\nusers to express collaborative queries using cypher semantics by introducing\nsub-property and a series of logical operators. PandaDB is built based on\nNeo4j, manage the unstructured data in the format of BLOB. The computable\npattern is proposed to introduce the content of unstructured data into\ncomputation. Moreover, to support the large-scale query, this paper proposes\nthe semantic index, cache and index the extracted computable pattern. The\ncollaborative query on graph is optimized by the min-cost optimization method.\nExperimental results on both public and in-house datasets show the performance\nachieved by PandaDB and its effectiveness.",
    "descriptor": "\nComments: 12pages\n",
    "authors": [
      "Zihao Zhao",
      "Zhihong Shen",
      "Mingjie Tang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01963"
  },
  {
    "id": "arXiv:2107.01965",
    "title": "Managing Knowledge in Energy Data Spaces",
    "abstract": "Data in the energy domain grows at unprecedented rates and is usually\ngenerated by heterogeneous energy systems. Despite the great potential that big\ndata-driven technologies can bring to the energy sector, general adoption is\nstill lagging. Several challenges related to controlled data exchange and data\nintegration are still not wholly achieved. As a result, fragmented applications\nare developed against energy data silos, and data exchange is limited to few\napplications. In this paper, we analyze the challenges and requirements related\nto energy-related data applications. We also evaluate the use of Energy Data\nEcosystems (EDEs) as data-driven infrastructures to overcome the current\nlimitations of fragmented energy applications. EDEs are inspired by the\nInternational Data Space (IDS) initiative launched in Germany at the end of\n2014 with an overall objective to take both the development and use of the IDS\nreference architecture model to a European/global level. The reference\narchitecture model consists of four architectures related to business,\nsecurity, data and service, and software aspects. This paper illustrates the\napplicability of EDEs and IDS reference architecture in real-world scenarios\nfrom the energy sector. The analyzed scenario is positioned in the context of\nthe EU-funded H2020 project PLATOON.",
    "descriptor": "\nComments: Based on the article Valentina Janev, Maria-Esther Vidal, Kemele M. Endris, Dea Pujic: Managing Knowledge in Energy Data Spaces. WWW (Companion Volume) 2021: 7-15\n",
    "authors": [
      "Valentina Janev",
      "Maria-Esther Vidal",
      "Kemele Endris",
      "Dea Pujic"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.01965"
  },
  {
    "id": "arXiv:2107.01969",
    "title": "The MineRL BASALT Competition on Learning from Human Feedback",
    "abstract": "The last decade has seen a significant increase of interest in deep learning\nresearch, with many public successes that have demonstrated its potential. As\nsuch, these systems are now being incorporated into commercial products. With\nthis comes an additional challenge: how can we build AI systems that solve\ntasks where there is not a crisp, well-defined specification? While multiple\nsolutions have been proposed, in this competition we focus on one in\nparticular: learning from human feedback. Rather than training AI systems using\na predefined reward function or using a labeled dataset with a predefined set\nof categories, we instead train the AI system using a learning signal derived\nfrom some form of human feedback, which can evolve over time as the\nunderstanding of the task changes, or as the capabilities of the AI system\nimprove.\nThe MineRL BASALT competition aims to spur forward research on this important\nclass of techniques. We design a suite of four tasks in Minecraft for which we\nexpect it will be hard to write down hardcoded reward functions. These tasks\nare defined by a paragraph of natural language: for example, \"create a\nwaterfall and take a scenic picture of it\", with additional clarifying details.\nParticipants must train a separate agent for each task, using any method they\nwant. Agents are then evaluated by humans who have read the task description.\nTo help participants get started, we provide a dataset of human demonstrations\non each of the four tasks, as well as an imitation learning baseline that\nleverages these demonstrations.\nOur hope is that this competition will improve our ability to build AI\nsystems that do what their designers intend them to do, even when the intent\ncannot be easily formalized. Besides allowing AI to solve more tasks, this can\nalso enable more effective regulation of AI systems, as well as making progress\non the value alignment problem.",
    "descriptor": "\nComments: NeurIPS 2021 Competition Track\n",
    "authors": [
      "Rohin Shah",
      "Cody Wild",
      "Steven H. Wang",
      "Neel Alex",
      "Brandon Houghton",
      "William Guss",
      "Sharada Mohanty",
      "Anssi Kanervisto",
      "Stephanie Milani",
      "Nicholay Topin",
      "Pieter Abbeel",
      "Stuart Russell",
      "Anca Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01969"
  },
  {
    "id": "arXiv:2107.01975",
    "title": "The information loss of a stochastic map",
    "abstract": "We provide a stochastic extension of the Baez-Fritz-Leinster characterization\nof the Shannon information loss associated with a measure-preserving function.\nThis recovers the conditional entropy and a closely related\ninformation-theoretic measure that we call `conditional information loss.'\nAlthough not functorial, these information measures are semi-functorial, a\nconcept we introduce that is definable in any Markov category. We also\nintroduce the notion of an `entropic Bayes' rule' for information measures, and\nwe provide a characterization of conditional entropy in terms of this rule.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "James Fullwood",
      "Arthur J. Parzygnat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01975"
  },
  {
    "id": "arXiv:2107.01979",
    "title": "Machine Learning for Fraud Detection in E-Commerce: A Research Agenda",
    "abstract": "Fraud detection and prevention play an important part in ensuring the\nsustained operation of any e-commerce business. Machine learning (ML) often\nplays an important role in these anti-fraud operations, but the organizational\ncontext in which these ML models operate cannot be ignored. In this paper, we\ntake an organization-centric view on the topic of fraud detection by\nformulating an operational model of the anti-fraud departments in e-commerce\norganizations. We derive 6 research topics and 12 practical challenges for\nfraud detection from this operational model. We summarize the state of the\nliterature for each research topic, discuss potential solutions to the\npractical challenges, and identify 22 open research challenges.",
    "descriptor": "\nComments: Accepted and to appear in the proceedings of the KDD 2021 co-located workshop: the 2nd International Workshop on Deployable Machine Learning for Security Defense (MLHat)\n",
    "authors": [
      "Niek Tax",
      "Kees Jan de Vries",
      "Mathijs de Jong",
      "Nikoleta Dosoula",
      "Bram van den Akker",
      "Jon Smith",
      "Olivier Thuong",
      "Lucas Bernardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01979"
  },
  {
    "id": "arXiv:2107.01980",
    "title": "Gaze Estimation with an Ensemble of Four Architectures",
    "abstract": "This paper presents a method for gaze estimation according to face images. We\ntrain several gaze estimators adopting four different network architectures,\nincluding an architecture designed for gaze estimation (i.e.,iTracker-MHSA) and\nthree originally designed for general computer vision tasks(i.e., BoTNet,\nHRNet, ResNeSt). Then, we select the best six estimators and ensemble their\npredictions through a linear combination. The method ranks the first on the\nleader-board of ETH-XGaze Competition, achieving an average angular error of\n$3.11^{\\circ}$ on the ETH-XGaze test set.",
    "descriptor": "",
    "authors": [
      "Xin Cai",
      "Boyu Chen",
      "Jiabei Zeng",
      "Jiajun Zhang",
      "Yunjia Sun",
      "Xiao Wang",
      "Zhilong Ji",
      "Xiao Liu",
      "Xilin Chen",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01980"
  },
  {
    "id": "arXiv:2107.01982",
    "title": "The DCU-EPFL Enhanced Dependency Parser at the IWPT 2021 Shared Task",
    "abstract": "We describe the DCU-EPFL submission to the IWPT 2021 Shared Task on Parsing\ninto Enhanced Universal Dependencies. The task involves parsing Enhanced UD\ngraphs, which are an extension of the basic dependency trees designed to be\nmore facilitative towards representing semantic structure. Evaluation is\ncarried out on 29 treebanks in 17 languages and participants are required to\nparse the data from each language starting from raw strings. Our approach uses\nthe Stanza pipeline to preprocess the text files, XLMRoBERTa to obtain\ncontextualized token representations, and an edge-scoring and labeling model to\npredict the enhanced graph. Finally, we run a post-processing script to ensure\nall of our outputs are valid Enhanced UD graphs. Our system places 6th out of 9\nparticipants with a coarse Enhanced Labeled Attachment Score (ELAS) of 83.57.\nWe carry out additional post-deadline experiments which include using Trankit\nfor pre-processing, XLM-RoBERTa-LARGE, treebank concatenation, and multitask\nlearning between a basic and an enhanced dependency parser. All of these\nmodifications improve our initial score and our final system has a coarse ELAS\nof 88.04.",
    "descriptor": "\nComments: Submitted to the IWPT 2021 Shared Task: From Raw Text to Enhanced Universal Dependencies: the Parsing Shared Task at IWPT 2021\n",
    "authors": [
      "James Barry",
      "Alireza Mohammadshahi",
      "Joachim Wagner",
      "Jennifer Foster",
      "James Henderson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01982"
  },
  {
    "id": "arXiv:2107.01983",
    "title": "Imputation-Free Learning from Incomplete Observations",
    "abstract": "Although recent works have developed methods that can generate estimations\n(or imputations) of the missing entries in a dataset to facilitate downstream\nanalysis, most depend on assumptions that may not align with real-world\napplications and could suffer from poor performance in subsequent tasks. This\nis particularly true if the data have large missingness rates or a small\npopulation. More importantly, the imputation error could be propagated into the\nprediction step that follows, causing the gradients used to train the\nprediction models to be biased. Consequently, in this work, we introduce the\nimportance guided stochastic gradient descent (IGSGD) method to train\nmultilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly\nperform inference from inputs containing missing values without imputation.\nSpecifically, we employ reinforcement learning (RL) to adjust the gradients\nused to train the models via back-propagation. This not only reduces bias but\nallows the model to exploit the underlying information behind missingness\npatterns. We test the proposed approach on real-world time-series (i.e.,\nMIMIC-III), tabular data obtained from an eye clinic, and a standard dataset\n(i.e., MNIST), where our imputation-free predictions outperform the traditional\ntwo-step imputation-based predictions using state-of-the-art imputation\nmethods.",
    "descriptor": "",
    "authors": [
      "Qitong Gao",
      "Dong Wang",
      "Joshua D. Amason",
      "Siyang Yuan",
      "Chenyang Tao",
      "Ricardo Henao",
      "Majda Hadziahmetovic",
      "Lawrence Carin",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01983"
  },
  {
    "id": "arXiv:2107.01984",
    "title": "A Systematic Literature Review of Empiricism and Norms of Reporting in  Computing Education Research Literature",
    "abstract": "Computing Education Research (CER) is critical for supporting the increasing\nnumber of students who need to learn computing skills. To systematically\nadvance knowledge, publications must be clear enough to support replications,\nmeta-analyses, and theory-building. The goal of this study is to characterize\nthe reporting of empiricism in CER literature by identifying whether\npublications include information to support replications, meta-analyses, and\ntheory building. The research questions are: RQ1) What percentage of papers in\nCER venues have empirical evaluation? RQ2) What are the characteristics of the\nempirical evaluation? RQ3) Do the papers with empirical evaluation follow\nreporting norms (both for inclusion and for labeling of key information)? We\nconducted an SLR of 427 papers published during 2014 and 2015 in five CER\nvenues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the\nCER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical\nevaluation. Quantitative evaluation methods were the most frequent. Papers most\nfrequently reported results on interventions around pedagogical techniques,\ncurriculum, community, or tools. There was a split in papers that had some type\nof comparison between an intervention and some other data set or baseline. Many\npapers lacked properly reported research objectives, goals, research questions,\nor hypotheses, description of participants, study design, data collection, and\nthreats to validity. CER authors are contributing empirical results to the\nliterature; however, not all norms for reporting are met. We encourage authors\nto provide clear, labeled details about their work so readers can use the\nmethodologies and results for replications and meta-analyses. As our community\ngrows, our reporting of CER should mature to help establish computing education\ntheory to support the next generation of computing learners.",
    "descriptor": "\nComments: Paper to appear in ACM Transactions on Computing Education\n",
    "authors": [
      "Sarah Heckman",
      "Jeffrey C. Carver",
      "Mark Sherriff",
      "Ahmed Al-Zubidy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.01984"
  },
  {
    "id": "arXiv:2107.01987",
    "title": "Contradiction Detection in Persian Text",
    "abstract": "Detection of semantic contradictory sentences is one of the most challenging\nand fundamental issues for NLP applications such as recognition of textual\nentailments. Contradiction in this study includes different types of semantic\nconfrontation, such as conflict and antonymy. Due to lack of sufficient data to\napply precise machine learning and specifically deep learning methods to\nPersian and other low resource languages, rule-based approaches that can\nfunction similarly to these systems will be of a great interest. Also recently,\nemergence of new methods such as transfer learning, has opened up the\npossibility of deep learning for low-resource languages. Considering two above\npoints, in this study, along with a simple rule-base baseline, a novel\nrule-base system for identifying semantic contradiction along with a Bert base\ndeep contradiction detection system for Persian texts have been introduced. The\nrule base system has used frequent rule mining method to extract appropriate\ncontradiction rules using a development set. Extracted rules are tested for\ndifferent categories of contradictory sentences. In this system the maximum\nf-measure among contradiction categories is obtained for negation about 90% and\nthe average F-measure of system for all classes is about 76% which outperforms\nother algorithms on Persian texts. On the other hand, because of medium\nperformance of rule base system for some categories of contradiction, we use a\nBert base deep learning system using our translated dataset; with average\nF-measure of 73. Our hybrid system has f-measure of about 80.",
    "descriptor": "\nComments: 24 pages, 9 tables and 5 figures\n",
    "authors": [
      "Zeinab Rahimi",
      "Mehrnoush ShamsFard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01987"
  },
  {
    "id": "arXiv:2107.01990",
    "title": "Dominant subspace and low-rank approximations from block Krylov  subspaces without a gap",
    "abstract": "In this work we obtain results related to the approximation of\n$h$-dimensional dominant subspaces and low rank approximations of matrices\n$\\mathbf A\\in\\mathbb K^{m\\times n}$ (where $\\mathbb K=\\mathbb R$ or $\\mathbb\nC)$ in case there is no singular gap, i.e. if $\\sigma_h=\\sigma_{h+1}$ (where\n$\\sigma_1\\geq \\ldots\\geq \\sigma_p\\geq 0$ denote the singular values of $\\mathbf\nA$, and $p=\\min\\{m,n\\}$). In order to do this, we describe in a convenient way\nthe class of $h$-dimensional right (respectively left) dominant subspaces.\nThen, we show that starting with a matrix $\\mathbf X\\in\\mathbb K^{n\\times r}$\nwith $r\\geq h$ satisfying a compatibility assumption with some $h$-dimensional\nright dominant subspace, block Krylov methods produce arbitrarily good\napproximations for both problems mentioned above. Our approach is based on\nrecent work by Drineas, Ipsen, Kontopoulou and Magdon-Ismail on approximation\nof structural left dominant subspaces; but instead of exploiting a singular gap\nat $h$ (which is zero in this case) we exploit the nearest existing singular\ngaps.",
    "descriptor": "",
    "authors": [
      "Pedro Massey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2107.01990"
  },
  {
    "id": "arXiv:2107.01993",
    "title": "Design and Production of an Autonomous Rotary Composter Powered by  Photovoltaic Energy",
    "abstract": "The problem of household waste management is becoming more and more acute\nwith the growth of economic development that the country of Morocco has\nexperienced. Moreover, the management of this waste is a burden for the\nmunicipalities, in view of its cost, which is increasing with time. Therefore,\nin this work we present the design, the mechanical and photovoltaic study of a\nnew autonomous solar composter intended mainly for households. It allows to\ntransform organic waste in situ, into a good quality compost that serves as a\nsoil conditioner, in a short time compared to other composting systems, these\ntimes do not exceed 4 weeks. This innovative technology will reduce the amount\nof waste going to final landfill, or incineration, and exploit the compost\nproduced in gardening and horticulture, which will be a very effective solution\nfor waste management in Morocco.",
    "descriptor": "\nComments: 10 pages, 12 figures, Research paper Published with International Journal of Engineering Trends and Technology (IJETT)\n",
    "authors": [
      "Fatima Zahra Siti",
      "Mustafa Elalami",
      "Fatima Zahra Beraich",
      "Moha Arouch",
      "Salah Dine Qanadli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01993"
  },
  {
    "id": "arXiv:2107.01995",
    "title": "Here's What I've Learned: Asking Questions that Reveal Reward Learning",
    "abstract": "Robots can learn from humans by asking questions. In these questions the\nrobot demonstrates a few different behaviors and asks the human for their\nfavorite. But how should robots choose which questions to ask? Today's robots\noptimize for informative questions that actively probe the human's preferences\nas efficiently as possible. But while informative questions make sense from the\nrobot's perspective, human onlookers often find them arbitrary and misleading.\nIn this paper we formalize active preference-based learning from the human's\nperspective. We hypothesize that -- from the human's point-of-view -- the\nrobot's questions reveal what the robot has and has not learned. Our insight\nenables robots to use questions to make their learning process transparent to\nthe human operator. We develop and test a model that robots can leverage to\nrelate the questions they ask to the information these questions reveal. We\nthen introduce a trade-off between informative and revealing questions that\nconsiders both human and robot perspectives: a robot that optimizes for this\ntrade-off actively gathers information from the human while simultaneously\nkeeping the human up to date with what it has learned. We evaluate our approach\nacross simulations, online surveys, and in-person user studies. Videos of our\nuser studies and results are available here: https://youtu.be/tC6y_jHN7Vw.",
    "descriptor": "",
    "authors": [
      "Soheil Habibian",
      "Ananth Jonnavittula",
      "Dylan P. Losey"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01995"
  },
  {
    "id": "arXiv:2107.01996",
    "title": "Explainability via Interactivity? Supporting Nonexperts' Sensemaking of  Pretrained CNN by Interacting with Their Daily Surroundings",
    "abstract": "Current research on Explainable AI (XAI) heavily targets on expert users\n(data scientists or AI developers). However, increasing importance has been\nargued for making AI more understandable to nonexperts, who are expected to\nleverage AI techniques, but have limited knowledge about AI. We present a\nmobile application to support nonexperts to interactively make sense of\nConvolutional Neural Networks (CNN); it allows users to play with a pretrained\nCNN by taking pictures of their surrounding objects. We use an up-to-date XAI\ntechnique (Class Activation Map) to intuitively visualize the model's decision\n(the most important image regions that lead to a certain result). Deployed in a\nuniversity course, this playful learning tool was found to support design\nstudents to gain vivid understandings about the capabilities and limitations of\npretrained CNNs in real-world environments. Concrete examples of students'\nplayful explorations are reported to characterize their sensemaking processes\nreflecting different depths of thought.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Chao Wang",
      "Pengcheng An"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01996"
  },
  {
    "id": "arXiv:2107.01998",
    "title": "Nested Sequents for Intuitionistic Modal Logics via Structural  Refinement",
    "abstract": "We employ a recently developed methodology -- called \"structural refinement\"\n-- to extract nested sequent systems for a sizable class of intuitionistic\nmodal logics from their respective labelled sequent systems. This method can be\nseen as a means by which labelled sequent systems can be transformed into\nnested sequent systems through the introduction of propagation rules and the\nelimination of structural rules, followed by a notational translation. The\nnested systems we obtain incorporate propagation rules that are parameterized\nwith formal grammars, and which encode certain frame conditions expressible as\nfirst-order Horn formulae that correspond to a subclass of the Scott-Lemmon\naxioms. We show that our nested systems are sound, cut-free complete, and admit\nhp-admissibility of typical structural rules.",
    "descriptor": "",
    "authors": [
      "Tim S. Lyon"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01998"
  },
  {
    "id": "arXiv:2107.01999",
    "title": "FINT: Field-aware INTeraction Neural Network For CTR Prediction",
    "abstract": "As a critical component for online advertising and marking, click-through\nrate (CTR) prediction has draw lots of attentions from both industry and\nacademia field. Recently, the deep learning has become the mainstream\nmethodological choice for CTR. Despite of sustainable efforts have been made,\nexisting approaches still pose several challenges. On the one hand, high-order\ninteraction between the features is under-explored. On the other hand,\nhigh-order interactions may neglect the semantic information from the low-order\nfields. In this paper, we proposed a novel prediction method, named FINT, that\nemploys the Field-aware INTeraction layer which captures high-order feature\ninteractions while retaining the low-order field information. To empirically\ninvestigate the effectiveness and robustness of the FINT, we perform extensive\nexperiments on the three realistic databases: KDD2012, Criteo and Avazu. The\nobtained results demonstrate that the FINT can significantly improve the\nperformance compared to the existing methods, without increasing the amount of\ncomputation required. Moreover, the proposed method brought about 2.72\\%\nincrease to the advertising revenue of a big online video app through A/B\ntesting. To better promote the research in CTR field, we will release our code\nas well as reference implementation of those baseline models in the final\nversion.",
    "descriptor": "\nComments: 5 pages, Submitted to CIKM 2021\n",
    "authors": [
      "Zhishan Zhao",
      "Sen Yang",
      "Guohui Liu",
      "Dawei Feng",
      "Kele Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01999"
  },
  {
    "id": "arXiv:2107.02000",
    "title": "A System Model-Based Approach for the Control of Power Park Modules for  Grid Voltage and Frequency Services",
    "abstract": "A new control approach is proposed for the grid insertion of Power Park\nModules (PPMs). It allows full participation of these modules to ancillary\nservices. This means that, not only their control have some positive impact on\nthe grid frequency and voltage dynamics, but they can effectively participate\nto existing primary and secondary control loops together with the classic\nthermal/inertia synchronous generators and fulfill the same specifications both\nfrom the control and contractual points of view. To achieve such level of\nperformances, a system approach based on an innovatory control model is\nproposed. The latter control model drops classic hypothesis for separation of\nvoltage and frequency dynamics used till now in order to gather these dynamics\ninto a small size model. From the system point of view, dynamics are grouped by\ntime-scales of phenomena in the proposed control model. This results in more\nperformant controls in comparison to classic approaches which orient controls\nto physical actuators (control of grid side converter and of generator side\nconverter). Also, this allows coordination between control of converters and\ngenerator or, in case of multimachines specifications, among several PPMs. From\nthe control synthesis point of view, classic robust approaches are used (like,\ne.g., H-infinity synthesis). Implementation and validation tests are presented\nfor wind PPMs but the approach holds for any other type of PPM. These results\nwill be further used to control the units of the new concept of Dynamic Virtual\nPower Plant introduced in the H2020 POSYTYF project.",
    "descriptor": "",
    "authors": [
      "Bogdan Marinescu",
      "Elkhatib Kamal",
      "Hoang-Trung Ngo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.02000"
  },
  {
    "id": "arXiv:2107.02004",
    "title": "Enhanced prediction for discrete-time input-delayed systems with unknown  disturbances",
    "abstract": "This paper deals with the problem of predicting the future state of\ndiscrete-time input-delayed systems in the presence of unknown disturbances\nthat can affect both the input and the output equations of the plant. Since the\ndisturbance is unknown, an exact prediction of the plant states is not\nfeasible. We propose the use of a high-order extended Luenberger-type observer\nfor the plant states, disturbances, and their finite difference variables.\nThen, a new method for computation of the prediction is proposed which, under\ncertain assumptions, allows for enhanced prediction and consequently improved\nattenuation of the unknown disturbances. Detailed analysis of the performance\nof the proposed scheme is carried out, while linear matrix inequalities (LMIs)\nare used for the observer design in order to mitigate the prediction errors.",
    "descriptor": "\nComments: Preprint submitted to Automatica\n",
    "authors": [
      "Thiago Alves Lima",
      "Valessa V. Viana",
      "Bismark C. Torrico",
      "Fabr\u00edcio G. Nogueira",
      "Diego de S. Madeira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.02004"
  },
  {
    "id": "arXiv:2107.02005",
    "title": "Blockchain-enabled Network Sharing for O-RAN",
    "abstract": "The innovation provided by network virtualization in 5G, together with\nstandardization and openness boosted by the Open Radio Access Network (O-RAN)\nAlliance, has paved the way to a collaborative future in cellular systems,\ndriven by flexible network sharing. Such advents are expected to attract new\nplayers like content providers and verticals, increasing competitiveness in the\ntelecom market. However, scalability and trust issues are expected to arise,\ngiven the criticality of ownership traceability and resource exchanging in an\nopen RAN sharing ecosystem. To address that, we propose the integration of\nBlockchain (BC) technology for enabling mobile operators (OPs) and other\nplayers to exchange RAN resources (e.g., infrastructure, spectrum usage) in the\nform of virtual network functions (VNF) autonomously and dynamically. BC will\nprovide automation, robustness, trustworthiness, and reliability to mobile\nnetworks, so that confidence is generated in an open RAN environment. In\nparticular, we define a novel O-RAN-based BC-enabled architecture that allows\nautomating RAN sharing procedures through either auction or marketplace-based\nmechanisms. The potential advantages of the proposed solution are demonstrated\nthrough simulation results. The used simulation platform is openly released.",
    "descriptor": "",
    "authors": [
      "Lorenza Giupponi",
      "Francesc Wilhelmi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.02005"
  },
  {
    "id": "arXiv:2107.02006",
    "title": "Towards Node Liability in Federated Learning: Computational Cost and  Network Overhead",
    "abstract": "Many machine learning (ML) techniques suffer from the drawback that their\noutput (e.g., a classification decision) is not clearly and intuitively\nconnected to their input (e.g., an image). To cope with this issue, several\nexplainable ML techniques have been proposed to, e.g., identify which pixels of\nan input image had the strongest influence on its classification. However, in\ndistributed scenarios, it is often more important to connect decisions with the\ninformation used for the model training and the nodes supplying such\ninformation. To this end, in this paper we focus on federated learning and\npresent a new methodology, named node liability in federated learning (NL-FL),\nwhich permits to identify the source of the training information that most\ncontributed to a given decision. After discussing NL-FL's cost in terms of\nextra computation, storage, and network latency, we demonstrate its usefulness\nin an edge-based scenario. We find that NL-FL is able to swiftly identify\nmisbehaving nodes and to exclude them from the training process, thereby\nimproving learning accuracy.",
    "descriptor": "",
    "authors": [
      "Francesco Malandrino",
      "Carla Fabiana Chiasserini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.02006"
  },
  {
    "id": "arXiv:2107.02007",
    "title": "A Serverless Cloud Integration For Quantum Computing",
    "abstract": "Starting from the idea of Quantum Computing which is a concept that dates\nback to 80s, we come to the present day where we can perform calculations on\nreal quantum computers. This sudden development of technology opens up new\nscenarios that quickly lead to the desire and the real possibility of\nintegrating this technology into current software architectures. The usage of\nframeworks that allow computation to be performed directly on quantum hardware\nposes a series of challenges. This document describes a an architectural\nframework that addresses the problems of integrating an API exposed Quantum\nprovider in an existing Enterprise architecture and it provides a minimum\nviable product (MVP) solution that really merges classical quantum computers on\na basic scenario with reusable code on GitHub repository. The solution\nleverages a web-based frontend where user can build and select applications/use\ncases and simply execute it without any further complication. Every triggered\nrun leverages on multiple backend options, that include a scheduler managing\nthe queuing mechanism to correctly schedule jobs and final results retrieval.\nThe proposed solution uses the up-to-date cloud native technologies (e.g. Cloud\nFunctions, Containers, Microservices) and serves as a general framework to\ndevelop multiple applications on the same infrastructure.",
    "descriptor": "\nComments: 8 pages, 4 figures. Conceptualization, Methodology, Software, Writing - Original Draft, Review & Editing: MG, LC, AA. Methodology, Software Design, Writing, Review & Editing: GB, VS. Software and Formal analysis, Writing, Review & Editing: EP, NS, FT. Supervision and validation: FM\n",
    "authors": [
      "M. Grossi",
      "L. Crippa",
      "A. Aita",
      "G. Bartoli",
      "V. Sammarco",
      "E. Picca",
      "N. Said",
      "F. Tramonto",
      "F. Mattei"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.02007"
  },
  {
    "id": "arXiv:2107.02008",
    "title": "Improving a neural network model by explanation-guided training for  glioma classification based on MRI data",
    "abstract": "In recent years, artificial intelligence (AI) systems have come to the\nforefront. These systems, mostly based on Deep learning (DL), achieve excellent\nresults in areas such as image processing, natural language processing, or\nspeech recognition. Despite the statistically high accuracy of deep learning\nmodels, their output is often a decision of \"black box\". Thus, Interpretability\nmethods have become a popular way to gain insight into the decision-making\nprocess of deep learning models. Explanation of a deep learning model is\ndesirable in the medical domain since the experts have to justify their\njudgments to the patient. In this work, we proposed a method for\nexplanation-guided training that uses a Layer-wise relevance propagation (LRP)\ntechnique to force the model to focus only on the relevant part of the image.\nWe experimentally verified our method on a convolutional neural network (CNN)\nmodel for low-grade and high-grade glioma classification problems. Our\nexperiments show promising results in a way to use interpretation techniques in\nthe model training process.",
    "descriptor": "\nComments: 8 pages, 7 figures, submitted for review to the journal \"Machine vision and applications\" (in reviewing process)\n",
    "authors": [
      "Frantisek Sefcik",
      "Wanda Benesova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02008"
  },
  {
    "id": "arXiv:2107.02010",
    "title": "Fast and Scalable Optimal Transport for Brain Tractograms",
    "abstract": "We present a new multiscale algorithm for solving regularized Optimal\nTransport problems on the GPU, with a linear memory footprint. Relying on\nSinkhorn divergences which are convex, smooth and positive definite loss\nfunctions, this method enables the computation of transport plans between\nmillions of points in a matter of minutes. We show the effectiveness of this\napproach on brain tractograms modeled either as bundles of fibers or as track\ndensity maps. We use the resulting smooth assignments to perform label transfer\nfor atlas-based segmentation of fiber tractograms. The parameters -- blur and\nreach -- of our method are meaningful, defining the minimum and maximum\ndistance at which two fibers are compared with each other. They can be set\naccording to anatomical knowledge. Furthermore, we also propose to estimate a\nprobabilistic atlas of a population of track density maps as a Wasserstein\nbarycenter. Our CUDA implementation is endowed with a user-friendly PyTorch\ninterface, freely available on the PyPi repository (pip install geomloss) and\nat www.kernel-operations.io/geomloss.",
    "descriptor": "\nComments: MICCAI 2019\n",
    "authors": [
      "Jean Feydy",
      "Pierre Roussillon",
      "Alain Trouv\u00e9",
      "Pietro Gori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02010"
  },
  {
    "id": "arXiv:2107.02012",
    "title": "Tackling COVID-19 Infodemic using Deep Learning",
    "abstract": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.",
    "descriptor": "\nComments: 15 pages, 4 figures, Accepted in 4th International Conference on Computational Intelligence and Data Engineering\n",
    "authors": [
      "Prathmesh Pathwar",
      "Simran Gill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02012"
  },
  {
    "id": "arXiv:2107.02013",
    "title": "Subset Privacy: Draw from an Obfuscated Urn",
    "abstract": "With the rapidly increasing ability to collect and analyze personal data,\ndata privacy becomes an emerging concern. In this work, we develop a new\nstatistical notion of local privacy to protect each categorical data that will\nbe collected by untrusted entities. The proposed solution, named subset\nprivacy, privatizes the original data value by replacing it with a random\nsubset containing that value. We develop methods for the estimation of\ndistribution functions and independence testing from subset-private data with\ntheoretical guarantees. We also study different mechanisms to realize the\nsubset privacy and evaluation metrics to quantify the amount of privacy in\npractice. Experimental results on both simulated and real-world datasets\ndemonstrate the encouraging performance of the developed concepts and methods.",
    "descriptor": "",
    "authors": [
      "Ganghua Wang",
      "Jie Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.02013"
  },
  {
    "id": "arXiv:2107.02016",
    "title": "FFR_FD: Effective and Fast Detection of DeepFakes Based on Feature Point  Defects",
    "abstract": "The internet is filled with fake face images and videos synthesized by deep\ngenerative models. These realistic DeepFakes pose a challenge to determine the\nauthenticity of multimedia content. As countermeasures, artifact-based\ndetection methods suffer from insufficiently fine-grained features that lead to\nlimited detection performance. DNN-based detection methods are not efficient\nenough, given that a DeepFake can be created easily by mobile apps and\nDNN-based models require high computational resources. We show that DeepFake\nfaces have fewer feature points than real ones, especially in certain facial\nregions. Inspired by feature point detector-descriptors to extract\ndiscriminative features at the pixel level, we propose the Fused Facial\nRegion_Feature Descriptor (FFR_FD) for effective and fast DeepFake detection.\nFFR_FD is only a vector extracted from the face, and it can be constructed from\nany feature point detector-descriptors. We train a random forest classifier\nwith FFR_FD and conduct extensive experiments on six large-scale DeepFake\ndatasets, whose results demonstrate that our method is superior to most state\nof the art DNN-based models.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Gaojian Wang",
      "Qian Jiang",
      "Xin Jin",
      "Xiaohui Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02016"
  },
  {
    "id": "arXiv:2107.02018",
    "title": "Spanner Approximations in Practice",
    "abstract": "A multiplicative $\\alpha$-spanner $H$ is a subgraph of $G=(V,E)$ with the\nsame vertices and fewer edges that preserves distances up to the factor\n$\\alpha$, i.e., $d_H(u,v)\\leq\\alpha\\cdot d_G(u,v)$ for all vertices $u$, $v$.\nWhile many algorithms have been developed to find good spanners in terms of\napproximation guarantees, no experimental studies comparing different\napproaches exist. We implemented a rich selection of those algorithms and\nevaluate them on a variety of instances regarding, e.g., their running time,\nsparseness, lightness, and effective stretch.",
    "descriptor": "",
    "authors": [
      "Markus Chimani",
      "Finn Stutzenstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.02018"
  },
  {
    "id": "arXiv:2107.02023",
    "title": "Mathematical foundations of adaptive isogeometric analysis",
    "abstract": "This paper reviews the state of the art and discusses recent developments in\nthe field of adaptive isogeometric analysis, with special focus on the\nmathematical theory. This includes an overview of available spline technologies\nfor the local resolution of possible singularities as well as the\nstate-of-the-art formulation of convergence and quasi-optimality of adaptive\nalgorithms for both the finite element method (FEM) and the boundary element\nmethod (BEM) in the frame of isogeometric analysis (IGA).",
    "descriptor": "",
    "authors": [
      "Annalisa Buffa",
      "Gregor Gantner",
      "Carlotta Giannelli",
      "Dirk Praetorius",
      "Rafael V\u00e1zquez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02023"
  },
  {
    "id": "arXiv:2107.02024",
    "title": "Statistical Analysis of Perspective Scores on Hate Speech Detection",
    "abstract": "Hate speech detection has become a hot topic in recent years due to the\nexponential growth of offensive language in social media. It has proven that,\nstate-of-the-art hate speech classifiers are efficient only when tested on the\ndata with the same feature distribution as training data. As a consequence,\nmodel architecture plays the second role to improve the current results. In\nsuch a diverse data distribution relying on low level features is the main\ncause of deficiency due to natural bias in data. That's why we need to use high\nlevel features to avoid a biased judgement. In this paper, we statistically\nanalyze the Perspective Scores and their impact on hate speech detection. We\nshow that, different hate speech datasets are very similar when it comes to\nextract their Perspective Scores. Eventually, we prove that, over-sampling the\nPerspective Scores of a hate speech dataset can significantly improve the\ngeneralization performance when it comes to be tested on other hate speech\ndatasets.",
    "descriptor": "\nComments: Accepted paper in International IJCAI Workshop on Artificial Intelligence for Social Good 2021\n",
    "authors": [
      "Hadi Mansourifar",
      "Dana Alsagheer",
      "Weidong Shi",
      "Lan Ni",
      "Yan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02024"
  },
  {
    "id": "arXiv:2107.02025",
    "title": "Textual Data Distributions: Kullback Leibler Textual Distributions  Contrasts on GPT-2 Generated Texts, with Supervised, Unsupervised Learning on  Vaccine & Market Topics & Sentiment",
    "abstract": "Efficient textual data distributions (TDD) alignment and generation are open\nresearch problems in textual analytics and NLP. It is presently difficult to\nparsimoniously and methodologically confirm that two or more natural language\ndatasets belong to similar distributions, and to identify the extent to which\ntextual data possess alignment. This study focuses on addressing a segment of\nthe broader problem described above by applying multiple supervised and\nunsupervised machine learning (ML) methods to explore the behavior of TDD by\n(i) topical alignment, and (ii) by sentiment alignment. Furthermore we use\nmultiple text generation methods including fine-tuned GPT-2, to generate text\nby topic and by sentiment. Finally we develop a unique process driven variation\nof Kullback-Leibler divergence (KLD) application to TDD, named KL Textual\nDistributions Contrasts(KL-TDC) to identify the alignment of machine generated\ntextual corpora with naturally occurring textual corpora. This study thus\nidentifies a unique approach for generating and validating TDD by topic and\nsentiment, which can be used to help address sparse data problems and other\nresearch, practice and classroom situations in need of artificially generated\ntopic or sentiment aligned textual data.",
    "descriptor": "",
    "authors": [
      "Jim Samuel",
      "Ratnakar Palle",
      "Eduardo Correa Soares"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.02025"
  },
  {
    "id": "arXiv:2107.02027",
    "title": "Packing: Towards 2x NLP BERT Acceleration",
    "abstract": "We find that at sequence length 512 padding tokens represent in excess of 50%\nof the Wikipedia dataset used for pretraining BERT (Bidirectional Encoder\nRepresentations from Transformers). Therefore by removing all padding we\nachieve a 2x speed-up in terms of sequences/sec. To exploit this characteristic\nof the dataset, we develop and contrast two deterministic packing algorithms.\nBoth algorithms rely on the assumption that sequences are interchangeable and\ntherefore packing can be performed on the histogram of sequence lengths, rather\nthan per sample. This transformation of the problem leads to algorithms which\nare fast and have linear complexity in dataset size. The shortest-pack-first\nhistogram-packing (SPFHP) algorithm determines the packing order for the\nWikipedia dataset of over 16M sequences in 0.02 seconds. The non-negative\nleast-squares histogram-packing (NNLSHP) algorithm converges in 28.4 seconds\nbut produces solutions which are more depth efficient, managing to get near\noptimal packing by combining a maximum of 3 sequences in one sample. Using the\ndataset with multiple sequences per sample requires additional masking in the\nattention layer and a modification of the MLM loss function. We demonstrate\nthat both of these changes are straightforward to implement and have relatively\nlittle impact on the achievable performance gain on modern hardware. Finally,\nwe pretrain BERT-Large using the packed dataset, demonstrating no loss of\nconvergence and the desired 2x speed-up.",
    "descriptor": "",
    "authors": [
      "Matej Kosec",
      "Sheng Fu",
      "Mario Michael Krell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02027"
  },
  {
    "id": "arXiv:2107.02030",
    "title": "Are Non-Experts Able to Comprehend Business Process Models -- Study  Insights Involving Novices and Experts",
    "abstract": "The comprehension of business process models is crucial for enterprises.\nPrior research has shown that children as well as adolescents perceive and\ninterpret graphical representations in a different manner compared to\ngrown-ups. To evaluate this, observations in the context of business process\nmodels are presented in this paper obtained from a study on visual literacy in\ncultural education. We demonstrate that adolescents without expertise in\nprocess model comprehension are able to correctly interpret business process\nmodels expressed in terms of BPMN 2.0. In a comprehensive study, n = 205\nlearners (i.e., pupils at the age of 15) needed to answer questions related to\nprocess models they were confronted with, reflecting different levels of\ncomplexity. In addition, process models were created with varying styles of\nelement labels. Study results indicate that an abstract description (i.e.,\nusing only alphabetic letters) of process models is understood more easily\ncompared to concrete or pseudo} descriptions. As benchmark, results are\ncompared with the ones of modeling experts (n = 40). Amongst others, study\nfindings suggest using abstract descriptions in order to introduce novices to\nprocess modeling notations. With the obtained insights, we highlight that\nprocess models can be properly comprehended by novices.",
    "descriptor": "",
    "authors": [
      "Michael Winter",
      "R\u00fcdiger Pryss",
      "Thomas Probst",
      "Winfried Schlee",
      "Miles Tallon",
      "Ulrich Frick",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.02030"
  },
  {
    "id": "arXiv:2107.02032",
    "title": "Exponential convergence of perfectly matched layers for scattering  problems with periodic surfaces",
    "abstract": "The main task in this paper is to prove that the perfectly matched layers\n(PML) method converges exponentially with respect to the PML parameter, for\nscattering problems with periodic surfaces. In [5], a linear convergence is\nproved for the PML method for scattering problems with rough surfaces. At the\nend of that paper, three important questions are asked, and the third question\nis if exponential convergence holds locally. In our paper, we answer this\nquestion for a special case, which is scattering problems with periodic\nsurfaces. The result can also be easily extended to locally perturbed periodic\nsurfaces or periodic layers. Due to technical reasons, we have to exclude all\nthe half integer valued wavenumbers. The main idea of the proof is to apply the\nFloquet-Bloch transform to write the problem into an equivalent family of\nquasi-periodic problems, and then study the analytic extension of the\nquasi-periodic problems with respect to the Floquet-Bloch parameters. Then the\nCauchy integral formula is applied for piecewise analytic functions to avoid\nlinear convergent points. Finally the exponential convergence is proved from\nthe inverse Floquet-Bloch transform. Numerical results are also presented at\nthe end of this paper.",
    "descriptor": "",
    "authors": [
      "Ruming Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02032"
  },
  {
    "id": "arXiv:2107.02033",
    "title": "Quality Metrics for Transparent Machine Learning With and Without Humans  In the Loop Are Not Correlated",
    "abstract": "The field explainable artificial intelligence (XAI) has brought about an\narsenal of methods to render Machine Learning (ML) predictions more\ninterpretable. But how useful explanations provided by transparent ML methods\nare for humans remains difficult to assess. Here we investigate the quality of\ninterpretable computer vision algorithms using techniques from psychophysics.\nIn crowdsourced annotation tasks we study the impact of different\ninterpretability approaches on annotation accuracy and task time. We compare\nthese quality metrics with classical XAI, automated quality metrics. Our\nresults demonstrate that psychophysical experiments allow for robust quality\nassessment of transparency in machine learning. Interestingly the quality\nmetrics computed without humans in the loop did not provide a consistent\nranking of interpretability methods nor were they representative for how useful\nan explanation was for humans. These findings highlight the potential of\nmethods from classical psychophysics for modern machine learning applications.\nWe hope that our results provide convincing arguments for evaluating\ninterpretability in its natural habitat, human-ML interaction, if the goal is\nto obtain an authentic assessment of interpretability.",
    "descriptor": "\nComments: Proceedings of the ICML Workshop on Theoretical Foundations, Criticism, and Application Trends of Explainable AI held in conjunction with the 38th International Conference on Machine Learning (ICML), a non-peer-reviewed longer version was previously published as preprint here arXiv:1912.05011\n",
    "authors": [
      "Felix Biessmann",
      "Dionysius Refiano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02033"
  },
  {
    "id": "arXiv:2107.02036",
    "title": "A topological solution to object segmentation and tracking",
    "abstract": "The world is composed of objects, the ground, and the sky. Visual perception\nof objects requires solving two fundamental challenges: segmenting visual input\ninto discrete units, and tracking identities of these units despite appearance\nchanges due to object deformation, changing perspective, and dynamic occlusion.\nCurrent computer vision approaches to segmentation and tracking that approach\nhuman performance all require learning, raising the question: can objects be\nsegmented and tracked without learning? Here, we show that the mathematical\nstructure of light rays reflected from environment surfaces yields a natural\nrepresentation of persistent surfaces, and this surface representation provides\na solution to both the segmentation and tracking problems. We describe how to\ngenerate this surface representation from continuous visual input, and\ndemonstrate that our approach can segment and invariantly track objects in\ncluttered synthetic video despite severe appearance changes, without requiring\nlearning.",
    "descriptor": "\nComments: 21 pages, 6 main figures, 3 supplemental figures, and supplementary material containing mathematical proofs\n",
    "authors": [
      "Thomas Tsao",
      "Doris Y. Tsao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02036"
  },
  {
    "id": "arXiv:2107.02039",
    "title": "Power Law Graph Transformer for Machine Translation and Representation  Learning",
    "abstract": "We present the Power Law Graph Transformer, a transformer model with well\ndefined deductive and inductive tasks for prediction and representation\nlearning. The deductive task learns the dataset level (global) and instance\nlevel (local) graph structures in terms of learnable power law distribution\nparameters. The inductive task outputs the prediction probabilities using the\ndeductive task output, similar to a transductive model. We trained our model\nwith Turkish-English and Portuguese-English datasets from TED talk transcripts\nfor machine translation and compared the model performance and characteristics\nto a transformer model with scaled dot product attention trained on the same\nexperimental setup. We report BLEU scores of $17.79$ and $28.33$ on the\nTurkish-English and Portuguese-English translation tasks with our model,\nrespectively. We also show how a duality between a quantization set and\nN-dimensional manifold representation can be leveraged to transform between\nlocal and global deductive-inductive outputs using successive application of\nlinear and non-linear transformations end-to-end.",
    "descriptor": "\nComments: 55 pages, 39 figures\n",
    "authors": [
      "Burc Gokden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02039"
  },
  {
    "id": "arXiv:2107.02040",
    "title": "A Knowledge-based Approach for Answering Complex Questions in Persian",
    "abstract": "Research on open-domain question answering (QA) has a long tradition. A\nchallenge in this domain is answering complex questions (CQA) that require\ncomplex inference methods and large amounts of knowledge. In low resource\nlanguages, such as Persian, there are not many datasets for open-domain complex\nquestions and also the language processing toolkits are not very accurate. In\nthis paper, we propose a knowledge-based approach for answering Persian complex\nquestions using Farsbase; the Persian knowledge graph, exploiting PeCoQ; the\nnewly created complex Persian question dataset. In this work, we handle\nmulti-constraint and multi-hop questions by building their set of possible\ncorresponding logical forms. Then Multilingual-BERT is used to select the\nlogical form that best describes the input complex question syntactically and\nsemantically. The answer to the question is built from the answer to the\nlogical form, extracted from the knowledge graph. Experiments show that our\napproach outperforms other approaches in Persian CQA.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Romina Etezadi",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02040"
  },
  {
    "id": "arXiv:2107.02041",
    "title": "No-Reference Quality Assessment for Colored Point Cloud and Mesh Based  on Natural Scene Statistics",
    "abstract": "To improve the viewer's quality of experience and optimize processing systems\nin computer graphics applications, the 3D quality assessment (3D-QA) has become\nan important task in the multimedia area. Point cloud and mesh are the two most\nwidely used electronic representation formats of 3D models, the quality of\nwhich is quite sensitive to operations like simplification and compression.\nTherefore, many studies concerning point cloud quality assessment (PCQA) and\nmesh quality assessment (MQA) have been carried out to measure the visual\nquality degradations caused by lossy operations. However, a large part of\nprevious studies utilizes full-reference (FR) metrics, which means they may\nfail to predict the accurate quality level of 3D models when the reference 3D\nmodel is not available. Furthermore, limited numbers of 3D-QA metrics are\ncarried out to take color features into consideration, which significantly\nrestricts the effectiveness and scope of application. In many quality\nassessment studies, natural scene statistics (NSS) have shown a good ability to\nquantify the distortion of natural scenes to statistical parameters. Therefore,\nwe propose an NSS-based no-reference quality assessment metric for colored 3D\nmodels. In this paper, quality-aware features are extracted from the aspects of\ncolor and geometry directly from the 3D models. Then the statistic parameters\nare estimated using different distribution models to describe the\ncharacteristic of the 3D models. Our method is mainly validated on the colored\npoint cloud quality assessment database (SJTU-PCQA) and the colored mesh\nquality assessment database (CMDM). The experimental results show that the\nproposed method outperforms all the state-of-art NR 3D-QA metrics and obtains\nan acceptable gap with the state-of-art FR 3D-QA metrics.",
    "descriptor": "",
    "authors": [
      "Zicheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02041"
  },
  {
    "id": "arXiv:2107.02045",
    "title": "Understanding the Security of Deepfake Detection",
    "abstract": "Deepfakes pose growing challenges to the trust of information on the\nInternet. Therefore,detecting deepfakes has attracted increasing attentions\nfrom both academia and industry. State-of-the-art deepfake detection methods\nconsist of two key components, i.e., face extractor and face classifier, which\nextract the face region in an image and classify it to be real/fake,\nrespectively. Existing studies mainly focused on improving the detection\nperformance in non-adversarial settings, leaving security of deepfake detection\nin adversarial settings largely unexplored. In this work, we aim to bridge the\ngap. In particular, we perform a systematic measurement study to understand the\nsecurity of the state-of-the-art deepfake detection methods in adversarial\nsettings. We use two large-scale public deepfakes data sources including\nFaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes\nare fake face images; and we train state-of-the-art deepfake detection methods.\nThese detection methods can achieve 0.94--0.99 accuracies in non-adversarial\nsettings on these datasets. However, our measurement results uncover multiple\nsecurity limitations of the deepfake detection methods in adversarial settings.\nFirst, we find that an attacker can evade a face extractor, i.e., the face\nextractor fails to extract the correct face regions, via adding small Gaussian\nnoise to its deepfake images. Second, we find that a face classifier trained\nusing deepfakes generated by one method cannot detect deepfakes generated by\nanother method, i.e., an attacker can evade detection via generating deepfakes\nusing a new method. Third, we find that an attacker can leverage backdoor\nattacks developed by the adversarial machine learning community to evade a face\nclassifier. Our results highlight that deepfake detection should consider the\nadversarial nature of the problem.",
    "descriptor": "\nComments: To appear in SecureComm 2021\n",
    "authors": [
      "Xiaoyu Cao",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02045"
  },
  {
    "id": "arXiv:2107.02052",
    "title": "Dealing with Adversarial Player Strategies in the Neural Network Game  iNNk through Ensemble Learning",
    "abstract": "Applying neural network (NN) methods in games can lead to various new and\nexciting game dynamics not previously possible. However, they also lead to new\nchallenges such as the lack of large, clean datasets, varying player skill\nlevels, and changing gameplay strategies. In this paper, we focus on the\nadversarial player strategy aspect in the game iNNk, in which players try to\ncommunicate secret code words through drawings with the goal of not being\ndeciphered by a NN. Some strategies exploit weaknesses in the NN that\nconsistently trick it into making incorrect classifications, leading to\nunbalanced gameplay. We present a method that combines transfer learning and\nensemble methods to obtain a data-efficient adaptation to these strategies.\nThis combination significantly outperforms the baseline NN across all\nadversarial player strategies despite only being trained on a limited set of\nadversarial examples. We expect the methods developed in this paper to be\nuseful for the rapidly growing field of NN-based games, which will require new\napproaches to deal with unforeseen player creativity.",
    "descriptor": "\nComments: 10 pages, 4 Figures. Accepted for publishing at the 16th International Conference on the Foundations of Digital Games (FDG) 2021\n",
    "authors": [
      "Mathias L\u00f6we",
      "Jennifer Villareale",
      "Evan Freed",
      "Aleksanteri Sladek",
      "Jichen Zhu",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02052"
  },
  {
    "id": "arXiv:2107.02053",
    "title": "MixStyle Neural Networks for Domain Generalization and Adaptation",
    "abstract": "Convolutional neural networks (CNNs) often have poor generalization\nperformance under domain shift. One way to improve domain generalization is to\ncollect diverse source data from multiple relevant domains so that a CNN model\nis allowed to learn more domain-invariant, and hence generalizable\nrepresentations. In this work, we address domain generalization with MixStyle,\na plug-and-play, parameter-free module that is simply inserted to shallow CNN\nlayers and requires no modification to training objectives. Specifically,\nMixStyle probabilistically mixes feature statistics between instances. This\nidea is inspired by the observation that visual domains can often be\ncharacterized by image styles which are in turn encapsulated within\ninstance-level feature statistics in shallow CNN layers. Therefore, inserting\nMixStyle modules in effect synthesizes novel domains albeit in an implicit way.\nMixStyle is not only simple and flexible, but also versatile -- it can be used\nfor problems whereby unlabeled images are available, such as semi-supervised\ndomain generalization and unsupervised domain adaptation, with a simple\nextension to mix feature statistics between labeled and pseudo-labeled\ninstances. We demonstrate through extensive experiments that MixStyle can\nsignificantly boost the out-of-distribution generalization performance across a\nwide range of tasks including object recognition, instance retrieval, and\nreinforcement learning.",
    "descriptor": "\nComments: Extension of this https URL Code available at this https URL\n",
    "authors": [
      "Kaiyang Zhou",
      "Yongxin Yang",
      "Yu Qiao",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02053"
  },
  {
    "id": "arXiv:2107.02057",
    "title": "6D Object Pose Estimation using Keypoints and Part Affinity Fields",
    "abstract": "The task of 6D object pose estimation from RGB images is an important\nrequirement for autonomous service robots to be able to interact with the real\nworld. In this work, we present a two-step pipeline for estimating the 6 DoF\ntranslation and orientation of known objects. Keypoints and Part Affinity\nFields (PAFs) are predicted from the input image adopting the OpenPose CNN\narchitecture from human pose estimation. Object poses are then calculated from\n2D-3D correspondences between detected and model keypoints via the PnP-RANSAC\nalgorithm. The proposed approach is evaluated on the YCB-Video dataset and\nachieves accuracy on par with recent methods from the literature. Using PAFs to\nassemble detected keypoints into object instances proves advantageous over only\nusing heatmaps. Models trained to predict keypoints of a single object class\nperform significantly better than models trained for several classes.",
    "descriptor": "\nComments: In: Proceedings of 24th RoboCup International Symposium, June 2021, 12 pages, 6 figures\n",
    "authors": [
      "Moritz Zappel",
      "Simon Bultmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.02057"
  },
  {
    "id": "arXiv:2107.02058",
    "title": "Tight Guarantees for Multi-unit Prophet Inequalities and Online  Stochastic Knapsack",
    "abstract": "Prophet inequalities are a useful tool for designing online allocation\nprocedures and comparing their performance to the optimal offline allocation.\nIn the basic setting of $k$-unit prophet inequalities, the magical procedure of\nAlaei (2011) with its celebrated performance guarantee of\n$1-\\frac{1}{\\sqrt{k+3}}$ has found widespread adoption in mechanism design and\nother online allocation problems in online advertising, healthcare scheduling,\nand revenue management. Despite being commonly used for implementing online\nallocation, the tightness of Alaei's procedure for a given $k$ has remained\nunknown. In this paper we resolve this question, characterizing the tight bound\nby identifying the structure of the optimal online implementation, and\nconsequently improving the best-known guarantee for $k$-unit prophet\ninequalities for all $k>1$. We also consider a more general online stochastic\nknapsack problem where each individual allocation can consume an arbitrary\nfraction of the initial capacity. We introduce a new \"best-fit\" procedure for\nimplementing a fractionally-feasible knapsack solution online, with a\nperformance guarantee of $\\frac{1}{3+e^{-2}}\\approx0.319$, which we also show\nis tight. This improves the previously best-known guarantee of 0.2 for online\nknapsack. Our analysis differs from existing ones by eschewing the need to\nsplit items into \"large\" or \"small\" based on capacity consumption, using\ninstead an invariant for the overall utilization on different sample paths.\nFinally, we refine our technique for the unit-density special case of knapsack,\nand improve the guarantee from 0.321 to 0.3557 in the multi-resource\nappointment scheduling application of Stein et al. (2020). All in all, our\nresults imply \\textit{tight} Online Contention Resolution Schemes for\n$k$-uniform matroids and the knapsack polytope, respectively, which has further\nimplications in mechanism design.",
    "descriptor": "",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.02058"
  },
  {
    "id": "arXiv:2107.02060",
    "title": "On the Complexity of the Escape Problem for Linear Dynamical Systems  over Compact Semialgebraic Sets",
    "abstract": "We study the computational complexity of the Escape Problem for discrete-time\nlinear dynamical systems over compact semialgebraic sets, or equivalently the\nTermination Problem for affine loops with compact semialgebraic guard sets.\nConsider the fragment of the theory of the reals consisting of negation-free\n$\\exists \\forall$-sentences without strict inequalities. We derive several\nequivalent characterisations of the associated complexity class which\ndemonstrate its robustness and illustrate its expressive power. We show that\nthe Compact Escape Problem is complete for this class.",
    "descriptor": "",
    "authors": [
      "Julian D'Costa",
      "Engel Lefaucheux",
      "Eike Neumann",
      "Jo\u00ebl Ouaknine",
      "James Worrell"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.02060"
  },
  {
    "id": "arXiv:2107.02063",
    "title": "Using Probabilistic Movement Primitives in Analyzing Human Motion  Difference under Transcranial Current Stimulation",
    "abstract": "In medical tasks such as human motion analysis, computer-aided auxiliary\nsystems have become preferred choice for human experts for its high efficiency.\nHowever, conventional approaches are typically based on user-defined features\nsuch as movement onset times, peak velocities, motion vectors or frequency\ndomain analyses. Such approaches entail careful data post-processing or\nspecific domain knowledge to achieve a meaningful feature extraction. Besides,\nthey are prone to noise and the manual-defined features could hardly be re-used\nfor other analyses. In this paper, we proposed probabilistic movement\nprimitives (ProMPs), a widely-used approach in robot skill learning, to model\nhuman motions. The benefit of ProMPs is that the features are directly learned\nfrom the data and ProMPs can capture important features describing the\ntrajectory shape, which can easily be extended to other tasks. Distinct from\nprevious research, where classification tasks are mostly investigated, we\napplied ProMPs together with a variant of Kullback-Leibler (KL) divergence to\nquantify the effect of different transcranial current stimulation methods on\nhuman motions. We presented an initial result with 10 participants. The results\nvalidate ProMPs as a robust and effective feature extractor for human motions.",
    "descriptor": "",
    "authors": [
      "Honghu Xue",
      "Rebecca Herzog",
      "Till M Berger",
      "Tobias B\u00e4umer",
      "Anne Weissbach",
      "Elmar Rueckert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02063"
  },
  {
    "id": "arXiv:2107.02067",
    "title": "Distance-based Hyperspherical Classification for Multi-source Open-Set  Domain Adaptation",
    "abstract": "Vision systems trained in closed-world scenarios will inevitably fail when\npresented with new environmental conditions, new data distributions and novel\nclasses at deployment time. How to move towards open-world learning is a long\nstanding research question, but the existing solutions mainly focus on specific\naspects of the problem (single domain Open-Set, multi-domain Closed-Set), or\npropose complex strategies which combine multiple losses and manually tuned\nhyperparameters. In this work we tackle multi-source Open-Set domain adaptation\nby introducing HyMOS: a straightforward supervised model that exploits the\npower of contrastive learning and the properties of its hyperspherical feature\nspace to correctly predict known labels on the target, while rejecting samples\nbelonging to any unknown class. HyMOS includes a tailored data balancing to\nenforce cross-source alignment and introduces style transfer among the instance\ntransformations of contrastive learning for source-target adaptation, avoiding\nthe risk of negative transfer. Finally a self-training strategy refines the\nmodel without the need for handcrafted thresholds. We validate our method over\nthree challenging datasets and provide an extensive quantitative and\nqualitative experimental analysis. The obtained results show that HyMOS\noutperforms several Open-Set and universal domain adaptation approaches,\ndefining the new state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Silvia Bucci",
      "Francesco Cappio Borlino",
      "Barbara Caputo",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02067"
  },
  {
    "id": "arXiv:2107.02069",
    "title": "SCOD: Active Object Detection for Embodied Agents using Sensory  Commutativity of Action Sequences",
    "abstract": "We introduce SCOD (Sensory Commutativity Object Detection), an active method\nfor movable and immovable object detection. SCOD exploits the commutative\nproperties of action sequences, in the scenario of an embodied agent equipped\nwith first-person sensors and a continuous motor space with multiple degrees of\nfreedom. SCOD is based on playing an action sequence in two different orders\nfrom the same starting point and comparing the two final observations obtained\nafter each sequence. Our experiments on 3D realistic robotic setups (iGibson)\ndemonstrate the accuracy of SCOD and its generalization to unseen environments\nand objects. We also successfully apply SCOD on a real robot to further\nillustrate its generalization properties. With SCOD, we aim at providing a\nnovel way of approaching the problem of object discovery in the context of a\nnaive embodied agent. We provide code and a supplementary video.",
    "descriptor": "\nComments: Accepted to AAMAS 2021 (Extended Abstract)\n",
    "authors": [
      "Hugo Caselles-Dupr\u00e9",
      "Michael Garcia-Ortiz",
      "David Filliat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.02069"
  },
  {
    "id": "arXiv:2107.02071",
    "title": "Unsupervised Ensemble Selection for Multilayer Bootstrap Networks",
    "abstract": "Multilayer bootstrap network (MBN), which is a recent simple unsupervised\ndeep model, is sensitive to its network structure. How to select a proper\nnetwork structure that may be dramatically different in different applications\nis a hard issue, given little prior knowledge of data. In this paper, we\nexplore ensemble learning and selection techniques for determining the optimal\nnetwork structure of MBN automatically. Specifically, we first propose an MBN\nensemble (MBN-E) algorithm which concatenates the sparse outputs of a set of\nMBN base models with different network structures into a new representation.\nThen, we take the new representation as a reference for selecting the optimal\nMBN base models. The ensemble selection criteria can be categorized into two\nclasses. The first kind employs optimization-like selection criteria, under the\nassumption that the number of classes of data is known as a prior. The second\nkind proposes distribution divergence criteria, when such a prior is\nunavailable. Experimental results on several benchmark datasets show that MBN-E\nyields good performance that is close to the optimal performance of MBN, while\nthe ensemble selection techniques for MBN-E can further improve the\nperformance. More importantly, MBN-E and its ensemble selection techniques\nmaintain the simple formulation of MBN, and act like off-the-shelf methods that\nreach the state-of-the-art performance without manual hyperparameter tuning.\nThe source code is available at this http URL",
    "descriptor": "",
    "authors": [
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02071"
  },
  {
    "id": "arXiv:2107.02072",
    "title": "Selective decay for the rotating shallow-water equations with a  structure-preserving discretization",
    "abstract": "Numerical models of weather and climate critically depend on long-term\nstability of integrators for systems of hyperbolic conservation laws. While\nsuch stability is often obtained from (physical or numerical) dissipation\nterms, physical fidelity of such simulations also depends on properly\npreserving conserved quantities, such as energy, of the system. To address this\napparent paradox, we develop a variational integrator for the shallow water\nequations that conserves energy, but dissipates potential enstrophy. Our\napproach follows the continuous selective decay framework , which enables\ndissipating an otherwise conserved quantity while conserving the total energy.\nWe use this in combination with the variational discretization method to obtain\na discrete selective decay framework. This is applied to the shallow water\nequations, both in the plane and on the sphere, to dissipate the potential\nenstrophy. The resulting scheme significantly improves the quality of the\napproximate solutions, enabling long-term integrations to be carried out.",
    "descriptor": "",
    "authors": [
      "R\u00fcdiger Brecht",
      "Werner Bauer",
      "Alexander Bihlo",
      "Fran\u00e7ois Gay-Balmaz",
      "Scott MacLachlan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02072"
  },
  {
    "id": "arXiv:2107.02076",
    "title": "Stabilization Bounds for Influence Propagation from a Random Initial  State",
    "abstract": "We study the stabilization time of two common types of influence propagation.\nIn majority processes, nodes in a graph want to switch to the most frequent\nstate in their neighborhood, while in minority processes, nodes want to switch\nto the least frequent state in their neighborhood. We consider the sequential\nmodel of these processes, and assume that every node starts out from a uniform\nrandom state.\nWe first show that if nodes change their state for any small improvement in\nthe process, then stabilization can last for up to $\\Theta(n^2)$ steps in both\ncases. Furthermore, we also study the proportional switching case, when nodes\nonly decide to change their state if they are in conflict with a\n$\\frac{1+\\lambda}{2}$ fraction of their neighbors, for some parameter $\\lambda\n\\in (0,1)$. In this case, we show that if $\\lambda < \\frac{1}{3}$, then there\nis a construction where stabilization can indeed last for $\\Omega(n^{1+c})$\nsteps for some constant $c>0$. On the other hand, if $\\lambda > \\frac{1}{2}$,\nwe prove that the stabilization time of the processes is upper-bounded by $O(n\n\\cdot \\log{n})$.",
    "descriptor": "",
    "authors": [
      "P\u00e1l Andr\u00e1s Papp",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.02076"
  },
  {
    "id": "arXiv:2107.02080",
    "title": "Uso de GSO cooperativos com decaimentos de pesos para otimizacao de  redes neurais",
    "abstract": "Training of Artificial Neural Networks is a complex task of great importance\nin supervised learning problems. Evolutionary Algorithms are widely used as\nglobal optimization techniques and these approaches have been used for\nArtificial Neural Networks to perform various tasks. An optimization algorithm,\ncalled Group Search Optimizer (GSO), was proposed and inspired by the search\nbehaviour of animals. In this article we present two new hybrid approaches:\nCGSO-Hk-WD and CGSO-Sk-WD. Cooperative GSOs are based on the divide-and-conquer\nparadigm, employing cooperative behaviour between GSO groups to improve the\nperformance of the standard GSO. We also apply the weight decay strategy (WD,\nacronym for Weight Decay) to increase the generalizability of the networks. The\nresults show that cooperative GSOs are able to achieve better performance than\ntraditional GSO for classification problems in benchmark datasets such as\nCancer, Diabetes, Ecoli and Glass datasets.",
    "descriptor": "\nComments: 9 pages, in Portuguese, 2 Figures, 6 Tables\n",
    "authors": [
      "Danielle Silva",
      "Teresa Ludermir"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.02080"
  },
  {
    "id": "arXiv:2107.02083",
    "title": "Modeling Interactions of Multimodal Road Users in Shared Spaces",
    "abstract": "In shared spaces, motorized and non-motorized road users share the same space\nwith equal priority. Their movements are not regulated by traffic rules, hence\nthey interact more frequently to negotiate priority over the shared space. To\nestimate the safeness and efficiency of shared spaces, reproducing the traffic\nbehavior in such traffic places is important. In this paper, we consider and\ncombine different levels of interaction between pedestrians and cars in shared\nspace environments. Our proposed model consists of three layers: a layer to\nplan trajectories of road users; a force-based modeling layer to reproduce free\nflow movement and simple interactions; and a game-theoretic decision layer to\nhandle complex situations where road users need to make a decision over\ndifferent alternatives. We validate our model by simulating scenarios involving\nvarious interactions between pedestrians and cars and also car-to-car\ninteraction. The results indicate that simulated behaviors match observed\nbehaviors well.",
    "descriptor": "",
    "authors": [
      "Fatema T. Johora",
      "J\u00f6rg P. M\u00fcller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02083"
  },
  {
    "id": "arXiv:2107.02084",
    "title": "Biomimetic Tactile Receptors for 3d-printed Skin",
    "abstract": "For robot touch to converge with the human sense of touch, artificial\ntransduction should involve biologically-plausible population codes analogous\nto those of natural afferents. Using a biomimetic tactile sensor with\n3d-printed skin based on the dermal-epidermal boundary, we propose two novel\nfeature sets to mimic slowly-adapting and rapidly-adapting type-I tactile\nmechanoreceptor function. Their plausibility is tested with three classic\nexperiments from the study of natural touch: impingement on a flat plate to\nprobe adaptation and spatial modulation; stimulation by spatially-complex\nridged stimuli to probe single afferent responses; and perception of grating\norientation to probe the population response. Our results show a match between\nartificial and natural afferent responses in their sensitivity to edges and\ngaps; likewise, the human and robot psychometric functions match for grating\norientation. These findings could benefit robot manipulation, prosthetics and\nthe neurophysiology of touch.",
    "descriptor": "",
    "authors": [
      "Nicholas Pestell",
      "Thom Griffith",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.02084"
  },
  {
    "id": "arXiv:2107.02086",
    "title": "One-Cycle Pruning: Pruning ConvNets Under a Tight Training Budget",
    "abstract": "Introducing sparsity in a neural network has been an efficient way to reduce\nits complexity while keeping its performance almost intact. Most of the time,\nsparsity is introduced using a three-stage pipeline: 1) train the model to\nconvergence, 2) prune the model according to some criterion, 3) fine-tune the\npruned model to recover performance. The last two steps are often performed\niteratively, leading to reasonable results but also to a time-consuming and\ncomplex process. In our work, we propose to get rid of the first step of the\npipeline and to combine the two other steps in a single pruning-training cycle,\nallowing the model to jointly learn for the optimal weights while being pruned.\nWe do this by introducing a novel pruning schedule, named One-Cycle Pruning,\nwhich starts pruning from the beginning of the training, and until its very\nend. Adopting such a schedule not only leads to better performing pruned models\nbut also drastically reduces the training budget required to prune a model.\nExperiments are conducted on a variety of architectures (VGG-16 and ResNet-18)\nand datasets (CIFAR-10, CIFAR-100 and Caltech-101), and for relatively high\nsparsity values (80%, 90%, 95% of weights removed). Our results show that\nOne-Cycle Pruning consistently outperforms commonly used pruning schedules such\nas One-Shot Pruning, Iterative Pruning and Automated Gradual Pruning, on a\nfixed training budget.",
    "descriptor": "\nComments: Accepted at Sparsity in Neural Networks (SNN 2021)\n",
    "authors": [
      "Nathan Hubens",
      "Matei Mancas",
      "Bernard Gosselin",
      "Marius Preda",
      "Titus Zaharia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02086"
  },
  {
    "id": "arXiv:2107.02093",
    "title": "A Differentiable Solver Approach to Operator Inference",
    "abstract": "Model Order Reduction is a key technology for industrial applications in the\ncontext of digital twins. Key requirements are non-intrusiveness,\nphysics-awareness, as well as robustness and usability. Operator inference\nbased on least-squares minimization combined with the Discrete Empirical\nInterpolation Method captures most of these requirements, though the required\nregularization limits usability. Within this contribution we reformulate the\nproblem of operator inference as a constrained optimization problem allowing to\nrelax on the required regularization. The result is a robust model order\nreduction approach for real-world industrial applications, which is validated\nalong a dynamics complex 3D cooling process of a multi-tubular reactor using a\ncommercial software package.",
    "descriptor": "",
    "authors": [
      "Dirk Hartmann",
      "Lukas Failer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02093"
  },
  {
    "id": "arXiv:2107.02095",
    "title": "Are standard Object Segmentation models sufficient for Learning  Affordance Segmentation?",
    "abstract": "Affordances are the possibilities of actions the environment offers to the\nindividual. Ordinary objects (hammer, knife) usually have many affordances\n(grasping, pounding, cutting), and detecting these allow artificial agents to\nunderstand what are their possibilities in the environment, with obvious\napplication in Robotics. Proposed benchmarks and state-of-the-art prediction\nmodels for supervised affordance segmentation are usually modifications of\npopular object segmentation models such as Mask R-CNN. We observe that\ntheoretically, these popular object segmentation methods should be sufficient\nfor detecting affordances masks. So we ask the question: is it necessary to\ntailor new architectures to the problem of learning affordances? We show that\napplying the out-of-the-box Mask R-CNN to the problem of affordances\nsegmentation outperforms the current state-of-the-art. We conclude that the\nproblem of supervised affordance segmentation is included in the problem of\nobject segmentation and argue that better benchmarks for affordance learning\nshould include action capacities.",
    "descriptor": "",
    "authors": [
      "Hugo Caselles-Dupr\u00e9",
      "Michael Garcia-Ortiz",
      "David Filliat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02095"
  },
  {
    "id": "arXiv:2107.02096",
    "title": "An Empirical Analysis of Practitioners' Perspectives on Security Tool  Integration into DevOps",
    "abstract": "Background: Security tools play a vital role in enabling developers to build\nsecure software. However, it can be quite a challenging undertaking to\nintroduce and fully leverage security tools without affecting the speed or\nfrequency of deployments in the DevOps paradigm. Aims: We aim to empirically\ninvestigate the key challenges practitioners face when integrating security\ntools into a DevOps workflow in order to provide recommendations for overcoming\nthe challenges. Method: We conducted a study involving 31 systematically\nselected webinars on integrating security in DevOps. We used a qualitative data\nanalysis method, i.e., thematic analysis, to identify and understand the\nchallenges of integrating security tools in DevOps. Results: We find that\nwhilst traditional security tools are unable to cater for the needs of DevOps,\nthe industry is developing and adopting new generations of security tools that\nhave started focusing on the needs of DevOps. We have developed a DevOps\nworkflow that integrates security tools and a set of guidelines by synthesizing\npractitioners' recommendations in the analyzed webinars. Conclusion: Whilst the\nlatest security tools are addressing some of the requirements of DevOps, there\nare many tool-related drawbacks yet to be adequately addressed.",
    "descriptor": "\nComments: Accepted at ESEM2021: Currently addressing reviewer comments\n",
    "authors": [
      "Roshan Namal Rajapakse",
      "Mansooreh Zahedi",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.02096"
  },
  {
    "id": "arXiv:2107.02102",
    "title": "Training Adaptive Computation for Open-Domain Question Answering with  Computational Constraints",
    "abstract": "Adaptive Computation (AC) has been shown to be effective in improving the\nefficiency of Open-Domain Question Answering (ODQA) systems. However, current\nAC approaches require tuning of all model parameters, and training\nstate-of-the-art ODQA models requires significant computational resources that\nmay not be available for most researchers. We propose Adaptive Passage Encoder,\nan AC method that can be applied to an existing ODQA model and can be trained\nefficiently on a single GPU. It keeps the parameters of the base ODQA model\nfixed, but it overrides the default layer-by-layer computation of the encoder\nwith an AC policy that is trained to optimise the computational efficiency of\nthe model. Our experimental results show that our method improves upon a\nstate-of-the-art model on two datasets, and is also more accurate than previous\nAC methods due to the stronger base ODQA model. All source code and datasets\nare available at https://github.com/uclnlp/APE.",
    "descriptor": "\nComments: 7 pages, 1 figure, to be published in ACL-IJCNLP 2021\n",
    "authors": [
      "Yuxiang Wu",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02102"
  },
  {
    "id": "arXiv:2107.02104",
    "title": "RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting",
    "abstract": "Chest radiographs are one of the most common diagnostic modalities in\nclinical routine. It can be done cheaply, requires minimal equipment, and the\nimage can be diagnosed by every radiologists. However, the number of chest\nradiographs obtained on a daily basis can easily overwhelm the available\nclinical capacities. We propose RATCHET: RAdiological Text Captioning for Human\nExamined Thoraces. RATCHET is a CNN-RNN-based medical transformer that is\ntrained end-to-end. It is capable of extracting image features from chest\nradiographs, and generates medically accurate text reports that fit seamlessly\ninto clinical work flows. The model is evaluated for its natural language\ngeneration ability using common metrics from NLP literature, as well as its\nmedically accuracy through a surrogate report classification task. The model is\navailable for download at: this http URL",
    "descriptor": "",
    "authors": [
      "Benjamin Hou",
      "Georgios Kaissis",
      "Ronald Summers",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02104"
  },
  {
    "id": "arXiv:2107.02108",
    "title": "Super Resolution in Human Pose Estimation: Pixelated Poses to a  Resolution Result?",
    "abstract": "The results obtained from state of the art human pose estimation (HPE) models\ndegrade rapidly when evaluating people of a low resolution, but can super\nresolution (SR) be used to help mitigate this effect? By using various SR\napproaches we enhanced two low resolution datasets and evaluated the change in\nperformance of both an object and keypoint detector as well as end-to-end HPE\nresults. We remark the following observations. First we find that for low\nresolution people their keypoint detection performance improved once SR was\napplied. Second, the keypoint detection performance gained is dependent on the\npersons initial resolution (segmentation area in pixels) in the original image;\nkeypoint detection performance was improved when SR was applied to people with\na small initial segmentation area, but degrades as this becomes larger. To\naddress this we introduced a novel Mask-RCNN approach, utilising a segmentation\narea threshold to decide when to use SR during the keypoint detection step.\nThis approach achieved the best results for each of our HPE performance\nmetrics.",
    "descriptor": "",
    "authors": [
      "Peter Hardy",
      "Srinandan Dasmahapatra",
      "Hansung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02108"
  },
  {
    "id": "arXiv:2107.02112",
    "title": "Recovering the Unbiased Scene Graphs from the Biased Ones",
    "abstract": "Given input images, scene graph generation (SGG) aims to produce\ncomprehensive, graphical representations describing visual relationships among\nsalient objects. Recently, more efforts have been paid to the long tail problem\nin SGG; however, the imbalance in the fraction of missing labels of different\nclasses, or reporting bias, exacerbating the long tail is rarely considered and\ncannot be solved by the existing debiasing methods. In this paper we show that,\ndue to the missing labels, SGG can be viewed as a \"Learning from Positive and\nUnlabeled data\" (PU learning) problem, where the reporting bias can be removed\nby recovering the unbiased probabilities from the biased ones by utilizing\nlabel frequencies, i.e., the per-class fraction of labeled, positive examples\nin all the positive examples. To obtain accurate label frequency estimates, we\npropose Dynamic Label Frequency Estimation (DLFE) to take advantage of\ntraining-time data augmentation and average over multiple training iterations\nto introduce more valid examples. Extensive experiments show that DLFE is more\neffective in estimating label frequencies than a naive variant of the\ntraditional estimate, and DLFE significantly alleviates the long tail and\nachieves state-of-the-art debiasing performance on the VG dataset. We also show\nqualitatively that SGG models with DLFE produce prominently more balanced and\nunbiased scene graphs.",
    "descriptor": "\nComments: Accepted by ACMMM 2021. Source code will be available at this https URL\n",
    "authors": [
      "Meng-Jiun Chiou",
      "Henghui Ding",
      "Hanshu Yan",
      "Changhu Wang",
      "Roger Zimmermann",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.02112"
  },
  {
    "id": "arXiv:2107.02113",
    "title": "Economic Dispatch of an Integrated Microgrid Based on the Dynamic  Process of CCGT Plant",
    "abstract": "Intra-day economic dispatch of an integrated microgrid is a fundamental\nrequirement to integrate distributed generators. The dynamic energy flows in\ncogeneration units present challenges to the energy management of the\nmicrogrid. In this paper, a novel approximate dynamic programming (ADP)\napproach is proposed to solve this problem based on value function\napproximation, which is distinct with the consideration of the dynamic process\nconstraints of the combined-cycle gas turbine (CCGT) plant. First, we\nmathematically formulate the multi-time periods decision problem as a\nfinite-horizon Markov decision process. To deal with the thermodynamic process,\nan augmented state vector of CCGT is introduced. Second, the proposed VFA-ADP\nalgorithm is employed to derive the near-optimal real-time operation\nstrategies. In addition, to guarantee the monotonicity of piecewise linear\nfunction, we apply the SPAR algorithm in the update process. To validate the\neffectiveness of the proposed method, we conduct experiments with comparisons\nto some traditional optimization methods. The results indicate that our\nproposed ADP method achieves better performance on the economic dispatch of the\nmicrogrid.",
    "descriptor": "\nComments: This paper has won the Zhang Si-Ying (CCDC) Outstanding Youth Paper Award in the 33 rd Chinese Control and Decision Conference (CCDC 2021)\n",
    "authors": [
      "Zhiyi Lin",
      "Chunyue Song",
      "Jun Zhao",
      "Chao Yang",
      "Huan Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.02113"
  },
  {
    "id": "arXiv:2107.02114",
    "title": "Semi-supervised Learning for Dense Object Detection in Retail Scenes",
    "abstract": "Retail scenes usually contain densely packed high number of objects in each\nimage. Standard object detection techniques use fully supervised training\nmethodology. This is highly costly as annotating a large dense retail object\ndetection dataset involves an order of magnitude more effort compared to\nstandard datasets. Hence, we propose semi-supervised learning to effectively\nuse the large amount of unlabeled data available in the retail domain. We adapt\na popular self supervised method called noisy student initially proposed for\nobject classification to the task of dense object detection. We show that using\nunlabeled data with the noisy student training methodology, we can improve the\nstate of the art on precise detection of objects in densely packed retail\nscenes. We also show that performance of the model increases as you increase\nthe amount of unlabeled data.",
    "descriptor": "",
    "authors": [
      "Jaydeep Chauhan",
      "Srikrishna Varadarajan",
      "Muktabh Mayank Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02114"
  },
  {
    "id": "arXiv:2107.02121",
    "title": "ParDen: Surrogate Assisted Hyper-Parameter Optimisation for Portfolio  Selection",
    "abstract": "Portfolio optimisation is a multi-objective optimisation problem (MOP), where\nan investor aims to optimise the conflicting criteria of maximising a\nportfolio's expected return whilst minimising its risk and other costs.\nHowever, selecting a portfolio is a computationally expensive problem because\nof the cost associated with performing multiple evaluations on test data\n(\"backtesting\") rather than solving the convex optimisation problem itself. In\nthis research, we present ParDen, an algorithm for the inclusion of any\ndiscriminative or generative machine learning model as a surrogate to mitigate\nthe computationally expensive backtest procedure. In addition, we compare the\nperformance of alternative metaheuristic algorithms: NSGA-II, R-NSGA-II,\nNSGA-III, R-NSGA-III, U-NSGA-III, MO-CMA-ES, and COMO-CMA-ES. We measure\nperformance using multi-objective performance indicators, including\nGenerational Distance Plus, Inverted Generational Distance Plus and\nHypervolume. We also consider meta-indicators, Success Rate and Average\nExecutions to Success Rate, of the Hypervolume to provide more insight into the\nquality of solutions. Our results show that ParDen can reduce the number of\nevaluations required by almost a third while obtaining an improved Pareto front\nover the state-of-the-art for the problem of portfolio selection.",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables, submitted to ISCMI 2021\n",
    "authors": [
      "Terence van Zyl",
      "Matthew Woolway",
      "Andrew Paskaramoorthy"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.02121"
  },
  {
    "id": "arXiv:2107.02126",
    "title": "Deep Learning Schema-based Event Extraction: Literature Review and  Current Trends",
    "abstract": "Schema-based event extraction is a critical technique to apprehend the\nessential content of events promptly. With the rapid development of deep\nlearning technology, event extraction technology based on deep learning has\nbecome a research hotspot. Numerous methods, datasets, and evaluation metrics\nhave been proposed in the literature, raising the need for a comprehensive and\nupdated survey. This paper fills the gap by reviewing the state-of-the-art\napproaches, focusing on deep learning-based models. We summarize the task\ndefinition, paradigm, and models of schema-based event extraction and then\ndiscuss each of these in detail. We introduce benchmark datasets that support\ntests of predictions and evaluation metrics. A comprehensive comparison between\ndifferent techniques is also provided in this survey. Finally, we conclude by\nsummarizing future research directions facing the research area.",
    "descriptor": "",
    "authors": [
      "Qian Li",
      "Hao Peng",
      "Jianxin Li",
      "Yiming Hei",
      "Rui Sun",
      "Jiawei Sheng",
      "Shu Guo",
      "Lihong Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.02126"
  },
  {
    "id": "arXiv:2107.02128",
    "title": "On Bi-gram Graph Attributes",
    "abstract": "We propose a new approach to text semantic analysis and general corpus\nanalysis using, as termed in this article, a \"bi-gram graph\" representation of\na corpus. The different attributes derived from graph theory are measured and\nanalyzed as unique insights or against other corpus graphs. We observe a vast\ndomain of tools and algorithms that can be developed on top of the graph\nrepresentation; creating such a graph proves to be computationally cheap, and\nmuch of the heavy lifting is achieved via basic graph calculations.\nFurthermore, we showcase the different use-cases for the bi-gram graphs and how\nscalable it proves to be when dealing with large datasets.",
    "descriptor": "\nComments: 7 pages,8 figures\n",
    "authors": [
      "Thomas Konstantinovsky",
      "Matan Mizrachi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02128"
  },
  {
    "id": "arXiv:2107.02133",
    "title": "Test-Time Personalization with a Transformer for Human Pose Estimation",
    "abstract": "We propose to personalize a human pose estimator given a set of test images\nof a person without using any manual annotations. While there is a significant\nadvancement in human pose estimation, it is still very challenging for a model\nto generalize to different unknown environments and unseen persons. Instead of\nusing a fixed model for every test case, we adapt our pose estimator during\ntest time to exploit person-specific information. We first train our model on\ndiverse data with both a supervised and a self-supervised pose estimation\nobjectives jointly. We use a Transformer model to build a transformation\nbetween the self-supervised keypoints and the supervised keypoints. During test\ntime, we personalize and adapt our model by fine-tuning with the\nself-supervised objective. The pose is then improved by transforming the\nupdated self-supervised keypoints. We experiment with multiple datasets and\nshow significant improvements on pose estimations with our self-supervised\npersonalization.",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Miao Hao",
      "Yizhuo Li",
      "Zonglin Di",
      "Nitesh B. Gundavarapu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02133"
  },
  {
    "id": "arXiv:2107.02137",
    "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language  Understanding and Generation",
    "abstract": "Pre-trained models have achieved state-of-the-art results in various Natural\nLanguage Processing (NLP) tasks. Recent works such as T5 and GPT-3 have shown\nthat scaling up pre-trained language models can improve their generalization\nabilities. Particularly, the GPT-3 model with 175 billion parameters shows its\nstrong task-agnostic zero-shot/few-shot learning capabilities. Despite their\nsuccess, these large-scale models are trained on plain texts without\nintroducing knowledge such as linguistic knowledge and world knowledge. In\naddition, most large-scale models are trained in an auto-regressive way. As a\nresult, this kind of traditional fine-tuning approach demonstrates relatively\nweak performance when solving downstream language understanding tasks. In order\nto solve the above problems, we propose a unified framework named ERNIE 3.0 for\npre-training large-scale knowledge enhanced models. It fuses auto-regressive\nnetwork and auto-encoding network, so that the trained model can be easily\ntailored for both natural language understanding and generation tasks with\nzero-shot learning, few-shot learning or fine-tuning. We trained the model with\n10 billion parameters on a 4TB corpus consisting of plain texts and a\nlarge-scale knowledge graph. Empirical results show that the model outperforms\nthe state-of-the-art models on 54 Chinese NLP tasks, and its English version\nachieves the first place on the SuperGLUE benchmark (July 3, 2021), surpassing\nthe human performance by +0.8% (90.6% vs. 89.8%).",
    "descriptor": "",
    "authors": [
      "Yu Sun",
      "Shuohuan Wang",
      "Shikun Feng",
      "Siyu Ding",
      "Chao Pang",
      "Junyuan Shang",
      "Jiaxiang Liu",
      "Xuyi Chen",
      "Yanbin Zhao",
      "Yuxiang Lu",
      "Weixin Liu",
      "Zhihua Wu",
      "Weibao Gong",
      "Jianzhong Liang",
      "Zhizhou Shang",
      "Peng Sun",
      "Wei Liu",
      "Xuan Ouyang",
      "Dianhai Yu",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.02137"
  },
  {
    "id": "arXiv:2107.02139",
    "title": "Feature Cross Search via Submodular Optimization",
    "abstract": "In this paper, we study feature cross search as a fundamental primitive in\nfeature engineering. The importance of feature cross search especially for the\nlinear model has been known for a while, with well-known textbook examples. In\nthis problem, the goal is to select a small subset of features, combine them to\nform a new feature (called the crossed feature) by considering their Cartesian\nproduct, and find feature crosses to learn an \\emph{accurate} model. In\nparticular, we study the problem of maximizing a normalized Area Under the\nCurve (AUC) of the linear model trained on the crossed feature column.\nFirst, we show that it is not possible to provide an $n^{1/\\log\\log\nn}$-approximation algorithm for this problem unless the exponential time\nhypothesis fails. This result also rules out the possibility of solving this\nproblem in polynomial time unless $\\mathsf{P}=\\mathsf{NP}$. On the positive\nside, by assuming the \\naive\\ assumption, we show that there exists a simple\ngreedy $(1-1/e)$-approximation algorithm for this problem. This result is\nestablished by relating the AUC to the total variation of the commutator of two\nprobability measures and showing that the total variation of the commutator is\nmonotone and submodular. To show this, we relate the submodularity of this\nfunction to the positive semi-definiteness of a corresponding kernel matrix.\nThen, we use Bochner's theorem to prove the positive semi-definiteness by\nshowing that its inverse Fourier transform is non-negative everywhere. Our\ntechniques and structural results might be of independent interest.",
    "descriptor": "\nComments: Accepted to ESA 2021. Authors are ordered alphabetically\n",
    "authors": [
      "Lin Chen",
      "Hossein Esfandiari",
      "Gang Fu",
      "Vahab S. Mirrokni",
      "Qian Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02139"
  },
  {
    "id": "arXiv:2107.02144",
    "title": "The Curious Case of the Diamond Network",
    "abstract": "This work considers the one-shot capacity of communication networks subject\nto adversarial noise affecting a subset of network edges. In particular, we\nexamine previously-established upper bounds on one-shot capacity. We introduce\nthe Diamond Network as a minimal example to show that known cut-set bounds are\nnot sharp in general. We then give a capacity-achieving scheme for the Diamond\nNetwork that implements an adversary detection strategy. Finally, we give a\nsufficient condition for tightness of the Singleton Cut-Set Bound in a family\nof two-level networks.",
    "descriptor": "",
    "authors": [
      "Allison Beemer",
      "Alberto Ravagnani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.02144"
  },
  {
    "id": "arXiv:2107.02153",
    "title": "FaVIQ: FAct Verification from Information-seeking Questions",
    "abstract": "Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.",
    "descriptor": "\nComments: 12 pages, 3 figures; Data & Code available at this https URL\n",
    "authors": [
      "Jungsoo Park",
      "Sewon Min",
      "Jaewoo Kang",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02153"
  },
  {
    "id": "arXiv:2107.02156",
    "title": "Do Different Tracking Tasks Require Different Appearance Models?",
    "abstract": "Tracking objects of interest in a video is one of the most popular and widely\napplicable problems in computer vision. However, with the years, a Cambrian\nexplosion of use cases and benchmarks has fragmented the problem in a multitude\nof different experimental setups. As a consequence, the literature has\nfragmented too, and now the novel approaches proposed by the community are\nusually specialised to fit only one specific setup. To understand to what\nextent this specialisation is actually necessary, in this work we present\nUniTrack, a unified tracking solution to address five different tasks within\nthe same framework. UniTrack consists of a single and task-agnostic appearance\nmodel, which can be learned in a supervised or self-supervised fashion, and\nmultiple \"heads\" to address individual tasks and that do not require training.\nWe show how most tracking tasks can be solved within this framework, and that\nthe same appearance model can be used to obtain performance that is competitive\nagainst specialised methods for all the five tasks considered. The framework\nalso allows us to analyse appearance models obtained with the most recent\nself-supervised methods, thus significantly extending their evaluation and\ncomparison to a larger variety of important problems. Code available at\nhttps://github.com/Zhongdao/UniTrack.",
    "descriptor": "",
    "authors": [
      "Zhongdao Wang",
      "Hengshuang Zhao",
      "Ya-Li Li",
      "Shengjin Wang",
      "Philip H.S. Torr",
      "Luca Bertinetto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02156"
  },
  {
    "id": "arXiv:2107.02162",
    "title": "Conditional Identity Disentanglement for Differential Face Morph  Detection",
    "abstract": "We present the task of differential face morph attack detection using a\nconditional generative network (cGAN). To determine whether a face image in an\nidentification document, such as a passport, is morphed or not, we propose an\nalgorithm that learns to implicitly disentangle identities from the morphed\nimage conditioned on the trusted reference image using the cGAN. Furthermore,\nthe proposed method can also recover some underlying information about the\nsecond subject used in generating the morph. We performed experiments on AMSL\nface morph, MorGAN, and EMorGAN datasets to demonstrate the effectiveness of\nthe proposed method. We also conducted cross-dataset and cross-attack detection\nexperiments. We obtained promising results of 3% BPCER @ 10% APCER on\nintra-dataset evaluation, which is comparable to existing methods; and 4.6%\nBPCER @ 10% APCER on cross-dataset evaluation, which outperforms\nstate-of-the-art methods by at least 13.9%.",
    "descriptor": "",
    "authors": [
      "Sudipta Banerjee",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02162"
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Dataset of Dynamic Protein-Protein Interaction  Networks",
    "abstract": "Nowadays, many network representation learning algorithms and downstream\nnetwork mining tasks have already paid attention to dynamic networks or\ntemporal networks, which are more suitable for real-world complex scenarios by\nmodeling evolving patterns and temporal dependencies between node interactions.\nMoreover, representing and mining temporal networks have a wide range of\napplications, such as fraud detection, social network analysis, and drug\ndiscovery. To contribute to the network representation learning and network\nmining research community, in this paper, we generate a new biological dataset\nof dynamic protein-protein interaction networks (i.e., DPPIN), which consists\nof twelve dynamic protein-level interaction networks of yeast cells at\ndifferent scales. We first introduce the generation process of DPPIN. To\ndemonstrate the value of our published dataset DPPIN, we then list the\npotential applications that would be benefited. Furthermore, we design dynamic\nlocal clustering, dynamic spectral clustering, dynamic subgraph matching,\ndynamic node classification, and dynamic graph classification experiments,\nwhere DPPIN indicates future research opportunities for some tasks by\npresenting challenges on state-of-the-art baseline algorithms. Finally, we\nidentify future directions for improving this dataset utility and welcome\ninputs from the community. All resources of this work are deployed and publicly\navailable at https://github.com/DongqiFu/DPPIN.",
    "descriptor": "",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02168"
  },
  {
    "id": "arXiv:2107.02170",
    "title": "On Model Calibration for Long-Tailed Object Detection and Instance  Segmentation",
    "abstract": "Vanilla models for object detection and instance segmentation suffer from the\nheavy bias toward detecting frequent objects in the long-tailed setting.\nExisting methods address this issue mostly during training, e.g., by\nre-sampling or re-weighting. In this paper, we investigate a largely overlooked\napproach -- post-processing calibration of confidence scores. We propose\nNorCal, Normalized Calibration for long-tailed object detection and instance\nsegmentation, a simple and straightforward recipe that reweighs the predicted\nscores of each class by its training sample size. We show that separately\nhandling the background class and normalizing the scores over classes for each\nproposal are keys to achieving superior performance. On the LVIS dataset,\nNorCal can effectively improve nearly all the baseline models not only on rare\nclasses but also on common and frequent classes. Finally, we conduct extensive\nanalysis and ablation studies to offer insights into various modeling choices\nand mechanisms of our approach.",
    "descriptor": "",
    "authors": [
      "Tai-Yu Pan",
      "Cheng Zhang",
      "Yandong Li",
      "Hexiang Hu",
      "Dong Xuan",
      "Soravit Changpinyo",
      "Boqing Gong",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02170"
  },
  {
    "id": "arXiv:2107.02173",
    "title": "Is Automated Topic Model Evaluation Broken?: The Incoherence of  Coherence",
    "abstract": "Topic model evaluation, like evaluation of other unsupervised methods, can be\ncontentious. However, the field has coalesced around automated estimates of\ntopic coherence, which rely on the frequency of word co-occurrences in a\nreference corpus. Recent models relying on neural components surpass classical\ntopic models according to these metrics. At the same time, unlike classical\nmodels, the practice of neural topic model evaluation suffers from a validation\ngap: automatic coherence for neural models has not been validated using human\nexperimentation. In addition, as we show via a meta-analysis of topic modeling\nliterature, there is a substantial standardization gap in the use of automated\ntopic modeling benchmarks. We address both the standardization gap and the\nvalidation gap. Using two of the most widely used topic model evaluation\ndatasets, we assess a dominant classical model and two state-of-the-art neural\nmodels in a systematic, clearly documented, reproducible way. We use automatic\ncoherence along with the two most widely accepted human judgment tasks, namely,\ntopic rating and word intrusion. Automated evaluation will declare one model\nsignificantly different from another when corresponding human evaluations do\nnot, calling into question the validity of fully automatic evaluations\nindependent of human judgments.",
    "descriptor": "",
    "authors": [
      "Alexander Hoyle",
      "Pranav Goel",
      "Denis Peskov",
      "Andrew Hian-Cheong",
      "Jordan Boyd-Graber",
      "Philip Resnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02173"
  },
  {
    "id": "arXiv:2107.02174",
    "title": "What Makes for Hierarchical Vision Transformer?",
    "abstract": "Recent studies show that hierarchical Vision Transformer with interleaved\nnon-overlapped intra window self-attention \\& shifted window self-attention is\nable to achieve state-of-the-art performance in various visual recognition\ntasks and challenges CNN's dense sliding window paradigm. Most follow-up works\ntry to replace shifted window operation with other kinds of cross window\ncommunication while treating self-attention as the de-facto standard for intra\nwindow information aggregation. In this short preprint, we question whether\nself-attention is the only choice for hierarchical Vision Transformer to attain\nstrong performance, and what makes for hierarchical Vision Transformer? We\nreplace self-attention layers in Swin Transformer and Shuffle Transformer with\nsimple linear mapping and keep other components unchanged. The resulting\narchitecture with 25.4M parameters and 4.2G FLOPs achieves 80.5\\% Top-1\naccuracy, compared to 81.3\\% for Swin Transformer with 28.3M parameters and\n4.5G FLOPs. We also experiment with other alternatives to self-attention for\ncontext aggregation inside each non-overlapped window, which all give similar\ncompetitive results under the same architecture. Our study reveals that the\n\\textbf{macro architecture} of Swin model families (i.e., interleaved intra\nwindow \\& cross window communications), other than specific aggregation layers\nor specific means of cross window communication, may be more responsible for\nits strong performance and is the real challenger to CNN's dense sliding window\nparadigm.",
    "descriptor": "\nComments: Preprint. Work in progress\n",
    "authors": [
      "Yuxin Fang",
      "Xinggang Wang",
      "Rui Wu",
      "Jianwei Niu",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02174"
  },
  {
    "id": "arXiv:2107.01214",
    "title": "Truncated Marginal Neural Ratio Estimation",
    "abstract": "Parametric stochastic simulators are ubiquitous in science, often featuring\nhigh-dimensional input parameters and/or an intractable likelihood. Performing\nBayesian parameter inference in this context can be challenging. We present a\nneural simulator-based inference algorithm which simultaneously offers\nsimulation efficiency and fast empirical posterior testability, which is unique\namong modern algorithms. Our approach is simulation efficient by simultaneously\nestimating low-dimensional marginal posteriors instead of the joint posterior\nand by proposing simulations targeted to an observation of interest via a prior\nsuitably truncated by an indicator function. Furthermore, by estimating a\nlocally amortized posterior our algorithm enables efficient empirical tests of\nthe robustness of the inference results. Such tests are important for\nsanity-checking inference in real-world applications, which do not feature a\nknown ground truth. We perform experiments on a marginalized version of the\nsimulation-based inference benchmark and two complex and narrow posteriors,\nhighlighting the simulator efficiency of our algorithm as well as the quality\nof the estimated marginal posteriors. Implementation on GitHub.",
    "descriptor": "\nComments: 9 pages. 23 pages with references and supplemental material. Code available at this http URL Underlying library this http URL\n",
    "authors": [
      "Benjamin Kurt Miller",
      "Alex Cole",
      "Patrick Forr\u00e9",
      "Gilles Louppe",
      "Christoph Weniger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01214"
  },
  {
    "id": "arXiv:2107.01232",
    "title": "Become a better you: correlation between the change of research  direction and the change of scientific performance",
    "abstract": "It is important to explore how scientists decide their research agenda and\nthe corresponding consequences, as their decisions collectively shape\ncontemporary science. There are studies focusing on the overall performance of\nindividuals with different problem choosing strategies. Here we ask a slightly\ndifferent but relatively unexplored question: how is a scientist's change of\nresearch agenda associated with her change of scientific performance. Using\npublication records of over 14,000 authors in physics, we quantitatively\nmeasure the extent of research direction change and the performance change of\nindividuals. We identify a strong positive correlation between the direction\nchange and impact change. Scientists with a larger direction change not only\nare more likely to produce works with increased scientific impact compared to\ntheir past ones, but also have a higher growth rate of scientific impact. On\nthe other hand, the direction change is not associated with productivity\nchange. Those who stay in familiar topics do not publish faster than those who\nventure out and establish themselves in a new field. The gauge of research\ndirection in this work is uncorrelated with the diversity of research agenda\nand the switching probability among topics, capturing the evolution of\nindividual careers from a new point of view. Though the finding is inevitably\naffected by the survival bias, it sheds light on a range of problems in the\ncareer development of individual scientists.",
    "descriptor": "\nComments: 22 pages, 4 figures, and SI, to be published in Journal of Informetrics\n",
    "authors": [
      "Xiaoyao Yu",
      "Boleslaw K. Szymanski",
      "Tao Jia"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01232"
  },
  {
    "id": "arXiv:2107.01269",
    "title": "Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech  Recognition",
    "abstract": "Attention-based end-to-end automatic speech recognition (ASR) systems have\nrecently demonstrated state-of-the-art results for numerous tasks. However, the\napplication of self-attention and attention-based encoder-decoder models\nremains challenging for streaming ASR, where each word must be recognized\nshortly after it was spoken. In this work, we present the dual\ncausal/non-causal self-attention (DCN) architecture, which in contrast to\nrestricted self-attention prevents the overall context to grow beyond the\nlook-ahead of a single layer when used in a deep architecture. DCN is compared\nto chunk-based and restricted self-attention using streaming transformer and\nconformer architectures, showing improved ASR performance over restricted\nself-attention and competitive ASR results compared to chunk-based\nself-attention, while providing the advantage of frame-synchronous processing.\nCombined with triggered attention, the proposed streaming end-to-end ASR\nsystems obtained state-of-the-art results on the LibriSpeech, HKUST, and\nSwitchboard ASR tasks.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Niko Moritz",
      "Takaaki Hori",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01269"
  },
  {
    "id": "arXiv:2107.01274",
    "title": "Unbiasing Procedures for Scale-invariant Multi-reference Alignment",
    "abstract": "This article discusses a generalization of the 1-dimensional multi-reference\nalignment problem. The goal is to recover a hidden signal from many noisy\nobservations, where each noisy observation includes a random translation and\nrandom dilation of the hidden signal, as well as high additive noise. We\npropose a method that recovers the power spectrum of the hidden signal by\napplying a data-driven, nonlinear unbiasing procedure, and thus the hidden\nsignal is obtained up to an unknown phase. An unbiased estimator of the power\nspectrum is defined, whose error depends on the sample size and noise levels,\nand we precisely quantify the convergence rate of the proposed estimator. The\nunbiasing procedure relies on knowledge of the dilation distribution, and we\nimplement an optimization procedure to learn the dilation variance when this\nparameter is unknown. Our theoretical work is supported by extensive numerical\nexperiments on a wide range of signals.",
    "descriptor": "\nComments: 12 pages, 5 figures. Code reproducing numerical results at this https URL\n",
    "authors": [
      "Matthew Hirn",
      "Anna Little"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01274"
  },
  {
    "id": "arXiv:2107.01275",
    "title": "Relaxed Attention: A Simple Method to Boost Performance of End-to-End  Automatic Speech Recognition",
    "abstract": "Recently, attention-based encoder-decoder (AED) models have shown high\nperformance for end-to-end automatic speech recognition (ASR) across several\ntasks. Addressing overconfidence in such models, in this paper we introduce the\nconcept of relaxed attention, which is a simple gradual injection of a uniform\ndistribution to the encoder-decoder attention weights during training that is\neasily implemented with two lines of code. We investigate the effect of relaxed\nattention across different AED model architectures and two prominent ASR tasks,\nWall Street Journal (WSJ) and Librispeech. We found that transformers trained\nwith relaxed attention outperform the standard baseline models consistently\nduring decoding with external language models. On WSJ, we set a new benchmark\nfor transformer-based end-to-end speech recognition with a word error rate of\n3.65%, outperforming state of the art (4.20%) by 13.1% relative, while\nintroducing only a single hyperparameter. Upon acceptance, models will be\npublished on github.",
    "descriptor": "\nComments: submitted to ASRU 2021\n",
    "authors": [
      "Timo Lohrenz",
      "Patrick Schwarz",
      "Zhengyang Li",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01275"
  },
  {
    "id": "arXiv:2107.01276",
    "title": "Efficient and Accurate Adaptive Resolution for Weakly-Compressible SPH",
    "abstract": "In this paper we propose an accurate, and computationally efficient method\nfor incorporating adaptive spatial resolution into weakly-compressible Smoothed\nParticle Hydrodynamics (SPH) schemes. Particles are adaptively split and merged\nin an accurate manner while ensuring that the number of particles is not large\nfor a given resolution. Critically, the method ensures that the number of\nneighbors of each particle is optimal, leading to an efficient algorithm. A set\nof background particles is used to specify either geometry-based spatial\nresolution or solution-based adaptive resolution. This allows us to simulate\nproblems using particles having length variations of the order of 1:250 with\nmuch fewer particles than currently reported with other techniques. The method\nis designed to automatically adapt when any solid bodies move. The algorithms\nemployed are fully parallel. We consider a suite of benchmark problems to\ndemonstrate the accuracy of the approach. We then consider the classic problem\nof the flow past a circular cylinder at a range of Reynolds numbers and show\nthat the proposed method produces accurate results with a significantly reduced\nnumber of particles. We provide an open source implementation and a fully\nreproducible manuscript.",
    "descriptor": "\nComments: 44 pages, 32 figures, 3 tables\n",
    "authors": [
      "Abhinav Muta",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.01276"
  },
  {
    "id": "arXiv:2107.01285",
    "title": "Optimizing ROC Curves with a Sort-Based Surrogate Loss Function for  Binary Classification and Changepoint Detection",
    "abstract": "Receiver Operating Characteristic (ROC) curves are plots of true positive\nrate versus false positive rate which are useful for evaluating binary\nclassification models, but difficult to use for learning since the Area Under\nthe Curve (AUC) is non-convex. ROC curves can also be used in other problems\nthat have false positive and true positive rates such as changepoint detection.\nWe show that in this more general context, the ROC curve can have loops, points\nwith highly sub-optimal error rates, and AUC greater than one. This observation\nmotivates a new optimization objective: rather than maximizing the AUC, we\nwould like a monotonic ROC curve with AUC=1 that avoids points with large\nvalues for Min(FP,FN). We propose a convex relaxation of this objective that\nresults in a new surrogate loss function called the AUM, short for Area Under\nMin(FP, FN). Whereas previous loss functions are based on summing over all\nlabeled examples or pairs, the AUM requires a sort and a sum over the sequence\nof points on the ROC curve. We show that AUM directional derivatives can be\nefficiently computed and used in a gradient descent learning algorithm. In our\nempirical study of supervised binary classification and changepoint detection\nproblems, we show that our new AUM minimization learning algorithm results in\nimproved AUC and comparable speed relative to previous baselines.",
    "descriptor": "",
    "authors": [
      "Jonathan Hillman",
      "Toby Dylan Hocking"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01285"
  },
  {
    "id": "arXiv:2107.01303",
    "title": "Data-driven mapping between functional connectomes using optimal  transport",
    "abstract": "Functional connectomes derived from functional magnetic resonance imaging\nhave long been used to understand the functional organization of the brain.\nNevertheless, a connectome is intrinsically linked to the atlas used to create\nit. In other words, a connectome generated from one atlas is different in scale\nand resolution compared to a connectome generated from another atlas. Being\nable to map connectomes and derived results between different atlases without\nadditional pre-processing is a crucial step in improving interpretation and\ngeneralization between studies that use different atlases. Here, we use optimal\ntransport, a powerful mathematical technique, to find an optimum mapping\nbetween two atlases. This mapping is then used to transform time series from\none atlas to another in order to reconstruct a connectome. We validate our\napproach by comparing transformed connectomes against their \"gold-standard\"\ncounterparts (i.e., connectomes generated directly from an atlas) and\ndemonstrate the utility of transformed connectomes by applying these\nconnectomes to predictive models based on a different atlas. We show that these\ntransformed connectomes are significantly similar to their \"gold-standard\"\ncounterparts and maintain individual differences in brain-behavior\nassociations, demonstrating both the validity of our approach and its utility\nin downstream analyses. Overall, our approach is a promising avenue to increase\nthe generalization of connectome-based results across different atlases.",
    "descriptor": "",
    "authors": [
      "Javid Dadashkarimi",
      "Amin Karbasi",
      "Dustin Scheinost"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01303"
  },
  {
    "id": "arXiv:2107.01305",
    "title": "Maximum likelihood for high-noise group orbit estimation and  single-particle cryo-EM",
    "abstract": "Motivated by applications to single-particle cryo-electron microscopy\n(cryo-EM), we study several problems of function estimation in a low SNR\nregime, where samples are observed under random rotations of the function\ndomain. In a general framework of group orbit estimation with linear\nprojection, we describe a stratification of the Fisher information eigenvalues\naccording to a sequence of transcendence degrees in the invariant algebra, and\nrelate critical points of the log-likelihood landscape to a sequence of\nmethod-of-moments optimization problems. This extends previous results for a\ndiscrete rotation group without projection.\nWe then compute these transcendence degrees and the forms of these moment\noptimization problems for several examples of function estimation under $SO(2)$\nand $SO(3)$ rotations, including a simplified model of cryo-EM as introduced by\nBandeira, Blum-Smith, Kileel, Perry, Weed, and Wein. For several of these\nexamples, we affirmatively resolve numerical conjectures that\n$3^\\text{rd}$-order moments are sufficient to locally identify a generic signal\nup to its rotational orbit.\nFor low-dimensional approximations of the electric potential maps of two\nsmall protein molecules, we empirically verify that the noise-scalings of the\nFisher information eigenvalues conform with these theoretical predictions over\na range of SNR, in a model of $SO(3)$ rotations without projection.",
    "descriptor": "",
    "authors": [
      "Zhou Fan",
      "Roy R. Lederman",
      "Yi Sun",
      "Tianhao Wang",
      "Sheng Xu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.01305"
  },
  {
    "id": "arXiv:2107.01312",
    "title": "Lonely individuals process the world in idiosyncratic ways",
    "abstract": "Loneliness (i.e., the distressing feeling that often accompanies the\nsubjective sense of social disconnection) is detrimental to mental and physical\nhealth, and deficits in self-reported feelings of being understood by others is\na risk factor for loneliness. What contributes to these deficits in lonely\npeople? We used functional magnetic resonance imaging (fMRI) to unobtrusively\nmeasure the relative alignment of various aspects of people's mental processing\nof naturalistic stimuli (specifically, videos) as they unfold over time. We\nthereby tested whether lonely people actually process the world in\nidiosyncratic ways, rather than only exaggerating or misperceiving how\ndissimilar others' views are to their own (which could lead them to feel\nmisunderstood, even if they actually see the world similarly to those around\nthem). We found evidence for such idiosyncrasy: lonely individuals' neural\nresponses during free viewing of the videos were dissimilar to peers in their\ncommunities, particularly in brain regions (e.g., regions of the default-mode\nnetwork) in which similar responses have been associated with shared\npsychological perspectives and subjective understanding. Our findings were\nrobust even after controlling for demographic similarities, participants'\noverall levels of objective social isolation, and their friendships with each\nother. These results suggest that being surrounded predominantly by people who\nsee the world differently from oneself may be a risk factor for loneliness,\neven if one is friends with them.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.02726\n",
    "authors": [
      "Elisa C. Baek",
      "Ryan Hyon",
      "Karina L\u00f3pez",
      "Mason A. Porter",
      "Carolyn Parkinson"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01312"
  },
  {
    "id": "arXiv:2107.01318",
    "title": "A study of CNN capacity applied to Left Venticle Segmentation in Cardiac  MRI",
    "abstract": "CNN (Convolutional Neural Network) models have been successfully used for\nsegmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance\nImaging), providing clinical measurements.In practice, two questions arise with\ndeployment of CNNs: 1) when is it better to use a shallow model instead of a\ndeeper one? 2) how the size of a dataset might change the network performance?\nWe propose a framework to answer them, by experimenting with deep and shallow\nversions of three U-Net families, trained from scratch in six subsets varying\nfrom 100 to 10,000 images, different network sizes, learning rates and\nregularization values. 1620 models were evaluated using 5-foldcross-validation\nby loss and DICE. The results indicate that: sample size affects performance\nmore than architecture or hyper-parameters; in small samples the performance is\nmore sensitive to hyper-parameters than architecture; the performance\ndifference between shallow and deeper networks is not the same across families.",
    "descriptor": "\nComments: Submitted to IJBRA\n",
    "authors": [
      "Marcelo Toledo",
      "Daniel Lima",
      "Jos\u00e9 Krieger",
      "Marco Gutierrez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01318"
  },
  {
    "id": "arXiv:2107.01323",
    "title": "Minimum Wasserstein Distance Estimator under Finite Location-scale  Mixtures",
    "abstract": "When a population exhibits heterogeneity, we often model it via a finite\nmixture: decompose it into several different but homogeneous subpopulations.\nContemporary practice favors learning the mixtures by maximizing the likelihood\nfor statistical efficiency and the convenient EM-algorithm for numerical\ncomputation. Yet the maximum likelihood estimate (MLE) is not well defined for\nthe most widely used finite normal mixture in particular and for finite\nlocation-scale mixture in general. We hence investigate feasible alternatives\nto MLE such as minimum distance estimators. Recently, the Wasserstein distance\nhas drawn increased attention in the machine learning community. It has\nintuitive geometric interpretation and is successfully employed in many new\napplications. Do we gain anything by learning finite location-scale mixtures\nvia a minimum Wasserstein distance estimator (MWDE)? This paper investigates\nthis possibility in several respects. We find that the MWDE is consistent and\nderive a numerical solution under finite location-scale mixtures. We study its\nrobustness against outliers and mild model mis-specifications. Our moderate\nscaled simulation study shows the MWDE suffers some efficiency loss against a\npenalized version of MLE in general without noticeable gain in robustness. We\nreaffirm the general superiority of the likelihood based learning strategies\neven for the non-regular finite location-scale mixtures.",
    "descriptor": "",
    "authors": [
      "Qiong Zhang",
      "Jiahua Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01323"
  },
  {
    "id": "arXiv:2107.01327",
    "title": "VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and  Labeling of Individual Ribs on Chest X-rays",
    "abstract": "We introduce a new benchmark dataset, namely VinDr-RibCXR, for automatic\nsegmentation and labeling of individual ribs from chest X-ray (CXR) scans. The\nVinDr-RibCXR contains 245 CXRs with corresponding ground truth annotations\nprovided by human experts. A set of state-of-the-art segmentation models are\ntrained on 196 images from the VinDr-RibCXR to segment and label 20 individual\nribs. Our best performing model obtains a Dice score of 0.834 (95% CI,\n0.810--0.853) on an independent test set of 49 images. Our study, therefore,\nserves as a proof of concept and baseline performance for future research.",
    "descriptor": "\nComments: This is a preprint of our paper, which was accepted for publication by Medical Imaging with Deep Learning (MIDL 2021)\n",
    "authors": [
      "Hoang C. Nguyen",
      "Tung T. Le",
      "Hieu H. Pham",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01327"
  },
  {
    "id": "arXiv:2107.01333",
    "title": "A Uniformly Consistent Estimator of non-Gaussian Causal Effects Under  the k-Triangle-Faithfulness Assumption",
    "abstract": "Kalisch and B\\\"{u}hlmann (2007) showed that for linear Gaussian models, under\nthe Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and\nthe assumption of causal sufficiency, the PC algorithm is a uniformly\nconsistent estimator of the Markov Equivalence Class of the true causal DAG for\nlinear Gaussian models; it follows from this that for the identifiable causal\neffects in the Markov Equivalence Class, there are uniformly consistent\nestimators of causal effects as well. The $k$-Triangle-Faithfulness Assumption\nis a strictly weaker assumption that avoids some implausible implications of\nthe Strong Causal Faithfulness Assumption and also allows for uniformly\nconsistent estimates of Markov Equivalence Classes (in a weakened sense), and\nof identifiable causal effects. However, both of these assumptions are\nrestricted to linear Gaussian models. We propose the Generalized $k$-Triangle\nFaithfulness, which can be applied to any smooth distribution. In addition,\nunder the Generalized $k$-Triangle Faithfulness Assumption, we describe the\nEdge Estimation Algorithm that provides uniformly consistent estimates of\ncausal effects in some cases (and otherwise outputs \"can't tell\"), and the\n\\textit{Very Conservative }$SGS$ Algorithm that (in a slightly weaker sense) is\na uniformly consistent estimator of the Markov equivalence class of the true\nDAG.",
    "descriptor": "",
    "authors": [
      "Shuyan Wang",
      "Peter Spirtes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.01333"
  },
  {
    "id": "arXiv:2107.01337",
    "title": "CT Image Harmonization for Enhancing Radiomics Studies",
    "abstract": "While remarkable advances have been made in Computed Tomography (CT),\ncapturing CT images with non-standardized protocols causes low reproducibility\nregarding radiomic features, forming a barrier on CT image analysis in a large\nscale. RadiomicGAN is developed to effectively mitigate the discrepancy caused\nby using non-standard reconstruction kernels. RadiomicGAN consists of hybrid\nneural blocks including both pre-trained and trainable layers adopted to learn\nradiomic feature distributions efficiently. A novel training approach, called\nDynamic Window-based Training, has been developed to smoothly transform the\npre-trained model to the medical imaging domain. Model performance evaluated\nusing 1401 radiomic features show that RadiomicGAN clearly outperforms the\nstate-of-art image standardization models.",
    "descriptor": "",
    "authors": [
      "Md Selim",
      "Jie Zhang",
      "Baowei Fei",
      "Guo-Qiang Zhang",
      "Jin Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01337"
  },
  {
    "id": "arXiv:2107.01338",
    "title": "Sibling Regression for Generalized Linear Models",
    "abstract": "Field observations form the basis of many scientific studies, especially in\necological and social sciences. Despite efforts to conduct such surveys in a\nstandardized way, observations can be prone to systematic measurement errors.\nThe removal of systematic variability introduced by the observation process, if\npossible, can greatly increase the value of this data. Existing non-parametric\ntechniques for correcting such errors assume linear additive noise models. This\nleads to biased estimates when applied to generalized linear models (GLM). We\npresent an approach based on residual functions to address this limitation. We\nthen demonstrate its effectiveness on synthetic data and show it reduces\nsystematic detection variability in moth surveys.",
    "descriptor": "",
    "authors": [
      "Shiv Shankar",
      "Daniel Sheldon"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01338"
  },
  {
    "id": "arXiv:2107.01351",
    "title": "EAR-NET: Error Attention Refining Network For Retinal Vessel  Segmentation",
    "abstract": "The precise detection of blood vessels in retinal images is crucial to the\nearly diagnosis of the retinal vascular diseases, e.g., diabetic, hypertensive\nand solar retinopathies. Existing works often fail in predicting the abnormal\nareas, e.g, sudden brighter and darker areas and are inclined to predict a\npixel to background due to the significant class imbalance, leading to high\naccuracy and specificity while low sensitivity. To that end, we propose a novel\nerror attention refining network (ERA-Net) that is capable of learning and\npredicting the potential false predictions in a two-stage manner for effective\nretinal vessel segmentation. The proposed ERA-Net in the refine stage drives\nthe model to focus on and refine the segmentation errors produced in the\ninitial training stage. To achieve this, unlike most previous attention\napproaches that run in an unsupervised manner, we introduce a novel error\nattention mechanism which considers the differences between the ground truth\nand the initial segmentation masks as the ground truth to supervise the\nattention map learning. Experimental results demonstrate that our method\nachieves state-of-the-art performance on two common retinal blood vessel\ndatasets.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Jun Wang",
      "Xiaohan Yu",
      "Yongsheng Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01351"
  },
  {
    "id": "arXiv:2107.01368",
    "title": "The coarsest lattice that determines a discrete multidimensional system",
    "abstract": "A discrete multidimensional system is the set of solutions to a system of\npartial difference equations defined on the lattice $\\Z^n$. This paper shows\nthat it is determined by a unique coarsest sublattice, in the sense that the\nsolutions of the system on this sublattice determine the solutions on $\\Z^n$;\nit is therefore the correct domain of definition of the discrete system. This\nsublattice is the linear, higher order analogue of an invariant manifold for a\nvector field. In turn, the defining sublattice is determined by a Galois group\nof symmetries that leave invariant the equations defining the system. These\nresults find application in understanding properties of the system such as\ncontrollability and autonomy.",
    "descriptor": "\nComments: Comments welcome!\n",
    "authors": [
      "Debasattam Pal",
      "Shiva Shankar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01368"
  },
  {
    "id": "arXiv:2107.01392",
    "title": "WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative  Cases and Vaticinating the Probability of Maturation to ARDS using  Posteroanterior Chest X-Rays",
    "abstract": "Coronavirus is a large virus family consisting of diverse viruses, some of\nwhich disseminate among mammals and others cause sickness among humans.\nCOVID-19 is highly contagious and is rapidly spreading, rendering its early\ndiagnosis of preeminent status. Researchers, medical specialists and\norganizations all over the globe have been working tirelessly to combat this\nvirus and help in its containment. In this paper, a novel neural network called\nWisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.\nThe WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is\na two-layered convolutional Neural Network (CNN), which takes chest x-ray\nimages as input. Both layers of the proposed neural network consist of a number\nof neural networks each. The dataset used for this study consists of chest\nx-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on\nGitHub, and the chest x-ray images of healthy lungs and lungs affected by viral\nand bacterial pneumonia were obtained from Kaggle. The network not only\npinpoints the presence of COVID-19, but also gives the probability of the\ndisease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,\npredicting the progression of the disease in the COVID-19 positive patients.\nThe network also slender the occurrences of false negative cases by employing a\nhigh threshold value, thus aids in curbing the spread of the disease and gives\nan accuracy of 100% for successfully predicting COVID-19 among the chest x-rays\nof patients affected with COVID-19, bacterial and viral pneumonia.",
    "descriptor": "\nComments: 10 pages, 4 figures, 1 table\n",
    "authors": [
      "Peeyush Kumar",
      "Ayushe Gangal",
      "Sunita Kumari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01392"
  },
  {
    "id": "arXiv:2107.01408",
    "title": "Scale Mixtures of Neural Network Gaussian Processes",
    "abstract": "Recent works have revealed that infinitely-wide feed-forward or recurrent\nneural networks of any architecture correspond to Gaussian processes referred\nto as $\\mathrm{NNGP}$. While these works have extended the class of neural\nnetworks converging to Gaussian processes significantly, however, there has\nbeen little focus on broadening the class of stochastic processes that such\nneural networks converge to. In this work, inspired by the scale mixture of\nGaussian random variables, we propose the scale mixture of $\\mathrm{NNGP}$ for\nwhich we introduce a prior distribution on the scale of the last-layer\nparameters. We show that simply introducing a scale prior on the last-layer\nparameters can turn infinitely-wide neural networks of any architecture into a\nricher class of stochastic processes. Especially, with certain scale priors, we\nobtain heavy-tailed stochastic processes, and we recover Student's $t$\nprocesses in the case of inverse gamma priors. We further analyze the\ndistributions of the neural networks initialized with our prior setting and\ntrained with gradient descents and obtain similar results as for\n$\\mathrm{NNGP}$. We present a practical posterior-inference algorithm for the\nscale mixture of $\\mathrm{NNGP}$ and empirically demonstrate its usefulness on\nregression and classification tasks.",
    "descriptor": "",
    "authors": [
      "Hyungi Lee",
      "Eunggu Yun",
      "Hongseok Yang",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01408"
  },
  {
    "id": "arXiv:2107.01422",
    "title": "Imaging dynamics beneath turbid media via parallelized single-photon  detection",
    "abstract": "Noninvasive optical imaging through dynamic scattering media has numerous\nimportant biomedical applications but still remains a challenging task. While\nstandard methods aim to form images based upon optical absorption or\nfluorescent emission, it is also well-established that the temporal correlation\nof scattered coherent light diffuses through tissue much like optical\nintensity. Few works to date, however, have aimed to experimentally measure and\nprocess such data to demonstrate deep-tissue imaging of decorrelation dynamics.\nIn this work, we take advantage of a single-photon avalanche diode (SPAD) array\ncamera, with over one thousand detectors, to simultaneously detect speckle\nfluctuations at the single-photon level from 12 different phantom tissue\nsurface locations delivered via a customized fiber bundle array. We then apply\na deep neural network to convert the acquired single-photon measurements into\nvideo of scattering dynamics beneath rapidly decorrelating liquid tissue\nphantoms. We demonstrate the ability to record video of dynamic events\noccurring 5-8 mm beneath a decorrelating tissue phantom with mm-scale\nresolution and at a 2.5-10 Hz frame rate.",
    "descriptor": "",
    "authors": [
      "Shiqi Xu",
      "Xi Yang",
      "Wenhui Liu",
      "Joakim Jonsson",
      "Ruobing Qian",
      "Pavan Chandra Konda",
      "Kevin C. Zhou",
      "Qionghai Dai",
      "Haoqian Wang",
      "Edouard Berrocal",
      "Roarke Horstmeyer"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2107.01422"
  },
  {
    "id": "arXiv:2107.01429",
    "title": "QKSA: Quantum Knowledge Seeking Agent",
    "abstract": "In this article we present the motivation and the core thesis towards the\nimplementation of a Quantum Knowledge Seeking Agent (QKSA). QKSA is a general\nreinforcement learning agent that can be used to model classical and quantum\ndynamics. It merges ideas from universal artificial general intelligence,\nconstructor theory and genetic programming to build a robust and general\nframework for testing the capabilities of the agent in a variety of\nenvironments. It takes the artificial life (or, animat) path to artificial\ngeneral intelligence where a population of intelligent agents are instantiated\nto explore valid ways of modelling the perceptions. The multiplicity and\nsurvivability of the agents are defined by the fitness, with respect to the\nexplainability and predictability, of a resource-bounded computational model of\nthe environment. This general learning approach is then employed to model the\nphysics of an environment based on subjective observer states of the agents. A\nspecific case of quantum process tomography as a general modelling principle is\npresented. The various background ideas and a baseline formalism are discussed\nin this article which sets the groundwork for the implementations of the QKSA\nthat are currently in active development.",
    "descriptor": "\nComments: pre-print: motivation, core thesis and baseline framework\n",
    "authors": [
      "Aritra Sarkar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01429"
  },
  {
    "id": "arXiv:2107.01443",
    "title": "Quantifying agent impacts on contact sequences in social interactions",
    "abstract": "Human social behavior plays a crucial role in how pathogens like SARS-CoV-2\nor fake news spread in a population. Social interactions determine the contact\nnetwork among individuals, while spreading, requiring individual-to-individual\ntransmission, takes place on top of the network. Studying the topological\naspects of a contact network, therefore, not only has the potential of leading\nto valuable insights into how the behavior of individuals impacts spreading\nphenomena, but it may also open up possibilities for devising effective\nbehavioral interventions. Because of the temporal nature of interactions -\nsince the topology of the network, containing who is in contact with whom,\nwhen, for how long, and in which precise sequence, varies (rapidly) in time -\nanalyzing them requires developing network methods and metrics that respect\ntemporal variability, in contrast to those developed for static (i.e.,\ntime-invariant) networks. Here, by means of event mapping, we propose a method\nto quantify how quickly agents mingle by transforming temporal network data of\nagent contacts. We define a novel measure called 'contact sequence centrality',\nwhich quantifies the impact of an individual on the contact sequences,\nreflecting the individual's behavioral potential for spreading. Comparing\ncontact sequence centrality across agents allows for ranking the impact of\nagents and identifying potential 'behavioral super-spreaders'. The method is\napplied to social interaction data collected at an art fair in Amsterdam. We\nrelate the measure to the existing network metrics, both temporal and static,\nand find that (mostly at longer time scales) traditional metrics lose their\nresemblance to contact sequence centrality. Our work highlights the importance\nof accounting for the sequential nature of contacts when analyzing social\ninteractions.",
    "descriptor": "",
    "authors": [
      "Mark M. Dekker",
      "Tessa F. Blanken",
      "Fabian Dablander",
      "Jiamin Ou",
      "Denny Borsboom",
      "Debabrata Panja"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01443"
  },
  {
    "id": "arXiv:2107.01456",
    "title": "Custom Deep Neural Network for 3D Covid Chest CT-scan Classification",
    "abstract": "3D CT-scan base on chest is one of the controversial topisc of the researcher\nnowadays. There are many tasks to diagnose the disease through CT-scan images,\ninclude Covid19. In this paper, we propose a method that custom and combine\nDeep Neural Network to classify the series of 3D CT-scans chest images. In our\nmethods, we experiment with 2 backbones is DenseNet 121 and ResNet 101. In this\nproposal, we separate the experiment into 2 tasks, one is for 2 backbones\ncombination of ResNet and DenseNet, one is for DenseNet backbones combination.",
    "descriptor": "",
    "authors": [
      "Quoc Huy Trinh",
      "Minh Van Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01456"
  },
  {
    "id": "arXiv:2107.01458",
    "title": "Quantum Error Mitigation Relying on Permutation Filtering",
    "abstract": "Quantum error mitigation (QEM) is a class of promising techniques capable of\nreducing the computational error of variational quantum algorithms tailored for\ncurrent noisy intermediate-scale quantum computers. The recently proposed\npermutation-based methods are practically attractive, since they do not rely on\nany a priori information concerning the quantum channels. In this treatise, we\npropose a general framework termed as permutation filters, which includes the\nexisting permutation-based methods as special cases. In particular, we show\nthat the proposed filter design algorithm always converge to the global\noptimum, and that the optimal filters can provide substantial improvements over\nthe existing permutation-based methods in the presence of narrowband quantum\nnoise, corresponding to large-depth, high-error-rate quantum circuits.",
    "descriptor": "",
    "authors": [
      "Yifeng Xiong",
      "Soon Xin Ng",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01458"
  },
  {
    "id": "arXiv:2107.01466",
    "title": "A convolutional neural network for prestack fracture detection",
    "abstract": "Fractures are widely developed in hydrocarbon reservoirs and constitute the\naccumulation spaces and transport channels of oil and gas. Fracture detection\nis a fundamental task for reservoir characterization. From prestack seismic\ngathers, anisotropic analysis and inversion were commonly applied to\ncharacterize the dominant orientations and relative intensities of fractures.\nHowever, the existing methods were mostly based on the vertical aligned facture\nhypothesis, it is impossible for them to recognize fracture dip. Furthermore,\nit is difficult or impractical for existing methods to attain the real fracture\ndensities. Based on data-driven deep learning, this paper designed a\nconvolutional neural network to perform prestack fracture detection.\nCapitalizing on the connections between seismic responses and fracture\nparameters, a suitable azimuth dataset was firstly generated through fracture\neffective medium modeling and anisotropic plane wave analyzing. Then a\nmulti-input and multi-output convolutional neural network was constructed to\nsimultaneously detect fracture density, dip and strike azimuth. The application\non a practical survey validated the effectiveness of the proposed CNN model.",
    "descriptor": "",
    "authors": [
      "Zhenyu Yuan",
      "Yuxin Jiang",
      "Jingjing Li",
      "Handong Huang"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01466"
  },
  {
    "id": "arXiv:2107.01473",
    "title": "Slope and generalization properties of neural networks",
    "abstract": "Neural networks are very successful tools in for example advanced\nclassification. From a statistical point of view, fitting a neural network may\nbe seen as a kind of regression, where we seek a function from the input space\nto a space of classification probabilities that follows the \"general\" shape of\nthe data, but avoids overfitting by avoiding memorization of individual data\npoints. In statistics, this can be done by controlling the geometric complexity\nof the regression function. We propose to do something similar when fitting\nneural networks by controlling the slope of the network.\nAfter defining the slope and discussing some of its theoretical properties,\nwe go on to show empirically in examples, using ReLU networks, that the\ndistribution of the slope of a well-trained neural network classifier is\ngenerally independent of the width of the layers in a fully connected network,\nand that the mean of the distribution only has a weak dependence on the model\narchitecture in general. The slope is of similar size throughout the relevant\nvolume, and varies smoothly. It also behaves as predicted in rescaling\nexamples. We discuss possible applications of the slope concept, such as using\nit as a part of the loss function or stopping criterion during network\ntraining, or ranking data sets in terms of their complexity.",
    "descriptor": "",
    "authors": [
      "Anton Johansson",
      "Niklas Engsner",
      "Claes Stranneg\u00e5rd",
      "Petter Mostad"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01473"
  },
  {
    "id": "arXiv:2107.01500",
    "title": "Geometric vs Algebraic Nullity for Hyperpaths",
    "abstract": "We consider the question of how the eigenvarieties of a hypergraph relate to\nthe algebraic multiplicities of their corresponding eigenvalues. Specifically,\nwe (1) fully describe the irreducible components of the zero-eigenvariety of a\nloose $3$-hyperpath (its \"nullvariety\"), (2) use recent results of\nBao-Fan-Wang-Zhu to compute the corresponding algebraic multiplicity of zero\n(its \"nullity\"), and then (3) for this special class of hypergraphs, verify a\nconjecture of Hu-Ye about the relationship between the geometric\n(multi-)dimension of the nullvariety and the nullity.",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Joshua Cooper",
      "Grant Fickes"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.01500"
  },
  {
    "id": "arXiv:2107.01502",
    "title": "Pulmonary Vessel Segmentation based on Orthogonal Fused U-Net++ of Chest  CT Images",
    "abstract": "Pulmonary vessel segmentation is important for clinical diagnosis of\npulmonary diseases, while is also challenging due to the complicated structure.\nIn this work, we present an effective framework and refinement process of\npulmonary vessel segmentation from chest computed tomographic (CT) images. The\nkey to our approach is a 2.5D segmentation network applied from three\northogonal axes, which presents a robust and fully automated pulmonary vessel\nsegmentation result with lower network complexity and memory usage compared to\n3D networks. The slice radius is introduced to convolve the adjacent\ninformation of the center slice and the multi-planar fusion optimizes the\npresentation of intra- and inter- slice features. Besides, the tree-like\nstructure of the pulmonary vessel is extracted in the post-processing process,\nwhich is used for segmentation refining and pruning. In the evaluation\nexperiments, three fusion methods are tested and the most promising one is\ncompared with the state-of-the-art 2D and 3D structures on 300 cases of lung\nimages randomly selected from LIDC dataset. Our method outperforms other\nnetwork structures by a large margin and achieves by far the highest average\nDICE score of 0.9272 and precision of 0.9310, as per our knowledge from the\npulmonary vessel segmentation models available in the literature.",
    "descriptor": "\nComments: Published in Medical Image Computing and Computer Assisted Intervention (MICCAI 2019)\n",
    "authors": [
      "Hejie Cui",
      "Xinglong Liu",
      "Ning Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01502"
  },
  {
    "id": "arXiv:2107.01510",
    "title": "Directed Percolation in Temporal Networks",
    "abstract": "Connectivity transitions in static networks are well described by percolation\ntheory, yet the corresponding description is not developed for temporal\nnetworks. We map the connectivity problem of temporal networks to directed\npercolation and show that the reachability phase transition in random temporal\nnetwork models, as induced by any limited-waiting-time process, appears with\nthe mean-field exponents of directed percolation. Furthermore, we measure the\ncentral thermodynamic quantities adapted to large-scale real temporal networks\nto uncover reachability transitions in their global connectedness.",
    "descriptor": "",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Kive\u00e4",
      "Mikko"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01510"
  },
  {
    "id": "arXiv:2107.01527",
    "title": "COVID-Rate: An Automated Framework for Segmentation of COVID-19 Lesions  from Chest CT Scans",
    "abstract": "Novel Coronavirus disease (COVID-19) is a highly contagious respiratory\ninfection that has had devastating effects on the world. Recently, new COVID-19\nvariants are emerging making the situation more challenging and threatening.\nEvaluation and quantification of COVID-19 lung abnormalities based on chest\nComputed Tomography (CT) scans can help determining the disease stage,\nefficiently allocating limited healthcare resources, and making informed\ntreatment decisions. During pandemic era, however, visual assessment and\nquantification of COVID-19 lung lesions by expert radiologists become expensive\nand prone to error, which raises an urgent quest to develop practical\nautonomous solutions. In this context, first, the paper introduces an open\naccess COVID-19 CT segmentation dataset containing 433 CT images from 82\npatients that have been annotated by an expert radiologist. Second, a Deep\nNeural Network (DNN)-based framework is proposed, referred to as the\nCOVID-Rate, that autonomously segments lung abnormalities associated with\nCOVID-19 from chest CT scans. Performance of the proposed COVID-Rate framework\nis evaluated through several experiments based on the introduced and external\ndatasets. The results show a dice score of 0:802 and specificity and\nsensitivity of 0:997 and 0:832, respectively. Furthermore, the results indicate\nthat the COVID-Rate model can efficiently segment COVID-19 lesions in both 2D\nCT images and whole lung volumes. Results on the external dataset illustrate\ngeneralization capabilities of the COVID-Rate model to CT images obtained from\na different scanner.",
    "descriptor": "",
    "authors": [
      "Nastaran Enshaei",
      "Anastasia Oikonomou",
      "Moezedin Javad Rafiee",
      "Parnian Afshar",
      "Shahin Heidarian",
      "Arash Mohammadi",
      "Konstantinos N. Plataniotis",
      "Farnoosh Naderkhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01527"
  },
  {
    "id": "arXiv:2107.01531",
    "title": "TENET: A Time-reversal Enhancement Network for Noise-robust ASR",
    "abstract": "Due to the unprecedented breakthroughs brought about by deep learning, speech\nenhancement (SE) techniques have been developed rapidly and play an important\nrole prior to acoustic modeling to mitigate noise effects on speech. To\nincrease the perceptual quality of speech, current state-of-the-art in the SE\nfield adopts adversarial training by connecting an objective metric to the\ndiscriminator. However, there is no guarantee that optimizing the perceptual\nquality of speech will necessarily lead to improved automatic speech\nrecognition (ASR) performance. In this study, we present TENET, a novel\nTime-reversal Enhancement NETwork, which leverages the transformation of an\ninput noisy signal itself, i.e., the time-reversed version, in conjunction with\nthe siamese network and complex dual-path transformer to promote SE performance\nfor noise-robust ASR. Extensive experiments conducted on the Voicebank-DEMAND\ndataset show that TENET can achieve state-of-the-art results compared to a few\ntop-of-the-line methods in terms of both SE and ASR evaluation metrics. To\ndemonstrate the model generalization ability, we further evaluate TENET on the\ntest set of scenarios contaminated with unseen noise, and the results also\nconfirm the superiority of this promising method.",
    "descriptor": "\nComments: Submitted to ASRU 2021\n",
    "authors": [
      "Fu-An Chao",
      "Shao-Wei Fan Jiang",
      "Bi-Cheng Yan",
      "Jeih-weih Hung",
      "Berlin Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01531"
  },
  {
    "id": "arXiv:2107.01545",
    "title": "Towards Neural Diarization for Unlimited Numbers of Speakers Using  Global and Local Attractors",
    "abstract": "Attractor-based end-to-end diarization is achieving comparable accuracy to\nthe carefully tuned conventional clustering-based methods on challenging\ndatasets. However, the main drawback is that it cannot deal with the case where\nthe number of speakers is larger than the one observed during training. This is\nbecause its speaker counting relies on supervised learning. In this work, we\nintroduce an unsupervised clustering process embedded in the attractor-based\nend-to-end diarization. We first split a sequence of frame-wise embeddings into\nshort subsequences and then perform attractor-based diarization for each\nsubsequence. Given subsequence-wise diarization results, inter-subsequence\nspeaker correspondence is obtained by unsupervised clustering of the vectors\ncomputed from the attractors from all the subsequences. This makes it possible\nto produce diarization results of a large number of speakers for the whole\nrecording even if the number of output speakers for each subsequence is\nlimited. Experimental results showed that our method could produce accurate\ndiarization results of an unseen number of speakers. Our method achieved 11.84\n%, 28.33 %, and 19.49 % on the CALLHOME, DIHARD II, and DIHARD III datasets,\nrespectively, each of which is better than the conventional end-to-end\ndiarization methods.",
    "descriptor": "",
    "authors": [
      "Shota Horiguchi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Yawen Xue",
      "Yuki Takashima",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01545"
  },
  {
    "id": "arXiv:2107.01553",
    "title": "The persistent cup-length invariant",
    "abstract": "We define a persistent cohomology invariant called persistent cup-length\nwhich is able to extract non trivial information about the evolution of the\ncohomology ring structure across a filtration. We also devise algorithms for\nthe computation of this invariant and we furthermore show that the persistent\ncup-length is 2-Lipschitz continuous with respect to the homotopy interleaving\nand Gromov-Hausdorff distances.",
    "descriptor": "\nComments: 39 pages, 13 figures\n",
    "authors": [
      "Marco Contessoto",
      "Facundo M\u00e9moli",
      "Anastasios Stefanou",
      "Ling Zhou"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.01553"
  },
  {
    "id": "arXiv:2107.01554",
    "title": "EditSpeech: A Text Based Speech Editing System Using Partial Inference  and Bidirectional Fusion",
    "abstract": "This paper presents the design, implementation and evaluation of a speech\nediting system, named EditSpeech, which allows a user to perform deletion,\ninsertion and replacement of words in a given speech utterance, without causing\naudible degradation in speech quality and naturalness. The EditSpeech system is\ndeveloped upon a neural text-to-speech (NTTS) synthesis framework. Partial\ninference and bidirectional fusion are proposed to effectively incorporate the\ncontextual information related to the edited region and achieve smooth\ntransition at both left and right boundaries. Distortion introduced to the\nunmodified parts of the utterance is alleviated. The EditSpeech system is\ndeveloped and evaluated on English and Chinese in multi-speaker scenarios.\nObjective and subjective evaluation demonstrate that EditSpeech outperforms a\nfew baseline systems in terms of low spectral distortion and preferred speech\nquality. Audio samples are available online for demonstration\nhttps://daxintan-cuhk.github.io/EditSpeech/ .",
    "descriptor": "",
    "authors": [
      "Daxin Tan",
      "Liqun Deng",
      "Yu Ting Yeung",
      "Xin Jiang",
      "Xiao Chen",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01554"
  },
  {
    "id": "arXiv:2107.01562",
    "title": "Random Neural Networks in the Infinite Width Limit as Gaussian Processes",
    "abstract": "This article gives a new proof that fully connected neural networks with\nrandom weights and biases converge to Gaussian processes in the regime where\nthe input dimension, output dimension, and depth are kept fixed, while the\nhidden layer widths tend to infinity. Unlike prior work, convergence is shown\nassuming only moment conditions for the distribution of weights and for quite\ngeneral non-linearities.",
    "descriptor": "\nComments: 26p\n",
    "authors": [
      "Boris Hanin"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.01562"
  },
  {
    "id": "arXiv:2107.01590",
    "title": "Deep Gaussian Process Emulation using Stochastic Imputation",
    "abstract": "We propose a novel deep Gaussian process (DGP) inference method for computer\nmodel emulation using stochastic imputation. By stochastically imputing the\nlatent layers, the approach transforms the DGP into the linked GP, a\nstate-of-the-art surrogate model formed by linking a system of feed-forward\ncoupled GPs. This transformation renders a simple while efficient DGP training\nprocedure that only involves optimizations of conventional stationary GPs. In\naddition, the analytically tractable mean and variance of the linked GP allows\none to implement predictions from DGP emulators in a fast and accurate manner.\nWe demonstrate the method in a series of synthetic examples and real-world\napplications, and show that it is a competitive candidate for efficient DGP\nsurrogate modeling in comparison to the variational inference and the\nfully-Bayesian approach. A $\\texttt{Python}$ package $\\texttt{dgpsi}$\nimplementing the method is also produced and available at\nhttps://github.com/mingdeyu/DGP.",
    "descriptor": "",
    "authors": [
      "Deyu Ming",
      "Daniel Williamson",
      "Serge Guillas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.01590"
  },
  {
    "id": "arXiv:2107.01601",
    "title": "Applications And Potentials Of Intelligent Swarms For Magnetospheric  Studies",
    "abstract": "Earth's magnetosphere is vital for today's technologically dependent society.\nTo date, numerous design studies have been conducted and over a dozen science\nmissions have own to study the magnetosphere. However, a majority of these\nsolutions relied on large monolithic satellites, which limited the spatial\nresolution of these investigations, as did the technological limitations of the\npast. To counter these limitations, we propose the use of a satellite swarm\ncarrying numerous and distributed payloads for magnetospheric measurements. Our\nmission is named APIS (Applications and Potentials of Intelligent Swarms),\nwhich aims to characterize fundamental plasma processes in the Earth's\nmagnetosphere and measure the effect of the solar wind on our magnetosphere. We\npropose a swarm of 40 CubeSats in two highly-elliptical orbits around the\nEarth, which perform radio tomography in the magnetotail at 8-12 Earth Radii\n(RE) downstream, and the subsolar magnetosphere at 8-12RE upstream. In\naddition, in-situ measurements of the magnetic and electric fields, plasma\ndensity will be performed by on-board instruments.\nIn this article, we present an outline of previous missions and designs for\nmagnetospheric studies, along with the science drivers and motivation for the\nAPIS mission. Furthermore, preliminary design results are included to show the\nfeasibility of such a mission. The science requirements drive the APIS mission\ndesign, the mission operation and the system requirements. In addition to the\nvarious science payloads, critical subsystems of the satellites are\ninvestigated e.g., navigation, communication, processing and power systems. We\nsummarize our findings, along with the potential next steps to strengthen our\ndesign study.",
    "descriptor": "\nComments: Accepted in Acta Astronautica\n",
    "authors": [
      "Raj Thilak Rajan",
      "Shoshana Ben-Maor",
      "Shaziana Kaderali",
      "Calum Turner",
      "Mohammed Milhim",
      "Catrina Melograna",
      "Dawn Haken",
      "Gary Paul",
      "Vedant",
      "Sreekumar V",
      "Johannes Weppler",
      "Yosephine Gumulya",
      "Riccardo Bunt",
      "Asia Bulgarini",
      "Maurice Marnat",
      "Kadri Bussov",
      "Frederick Pringle",
      "Jusha Ma",
      "Rushanka Amrutkar",
      "Miguel Coto",
      "Jiang He",
      "Zijian Shi",
      "Shahd Hayder",
      "Dina Saad Fayez Jaber",
      "Junchao Zuo",
      "Mohammad Alsukour",
      "Cecile Renaud",
      "Matthew Christie",
      "Neta Engad",
      "Yu Lian",
      "Jie Wen",
      "Ruth McAvinia",
      "Andrew Simon-Butler",
      "Anh Nguyen",
      "Jacob Cohen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01601"
  },
  {
    "id": "arXiv:2107.01629",
    "title": "The Role of \"Live\" in Livestreaming Markets: Evidence Using Orthogonal  Random Forest",
    "abstract": "The common belief about the growing medium of livestreaming is that its value\nlies in its \"live\" component. In this paper, we leverage data from a large\nlivestreaming platform to examine this belief. We are able to do this as this\nplatform also allows viewers to purchase the recorded version of the\nlivestream. We summarize the value of livestreaming content by estimating how\ndemand responds to price before, on the day of, and after the livestream. We do\nthis by proposing a generalized Orthogonal Random Forest framework. This\nframework allows us to estimate heterogeneous treatment effects in the presence\nof high-dimensional confounders whose relationships with the treatment policy\n(i.e., price) are complex but partially known. We find significant dynamics in\nthe price elasticity of demand over the temporal distance to the scheduled\nlivestreaming day and after. Specifically, demand gradually becomes less price\nsensitive over time to the livestreaming day and is inelastic on the\nlivestreaming day. Over the post-livestream period, demand is still sensitive\nto price, but much less than the pre-livestream period. This indicates that the\nvlaue of livestreaming persists beyond the live component. Finally, we provide\nsuggestive evidence for the likely mechanisms driving our results. These are\nquality uncertainty reduction for the patterns pre- and post-livestream and the\npotential of real-time interaction with the creator on the day of the\nlivestream.",
    "descriptor": "",
    "authors": [
      "Ziwei Cong",
      "Jia Liu",
      "Puneet Manchanda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01629"
  },
  {
    "id": "arXiv:2107.01651",
    "title": "The hidden dependence of spreading vulnerability on topological  complexity",
    "abstract": "Many dynamical phenomena, e.g., pathogen transmission, disruptions in\ntransport over networks, and (fake) news purveyance, concern spreading that\nplays out on top of networks with changing architectures over time - commonly\nknown as temporal networks. Assessing a system's proneness to facilitate\nspreading phenomena, which we refer to as its spreading vulnerability, from its\ntopological information alone remains a challenging task. We report a\nmethodological advance in terms of a novel metric for topological complexity:\n'entanglement entropy'. Using publicly available datasets, we demonstrate that\nthe metric naturally allows for topological comparisons across vastly different\nsystems, and importantly, reveals that the spreading vulnerability of a system\ncan be quantitatively related to its topological complexity. In doing so, the\nmetric opens itself for applications in a wide variety of natural, social,\nbiological and engineered systems.",
    "descriptor": "",
    "authors": [
      "Mark M. Dekker",
      "Debabrata Panja"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01651"
  },
  {
    "id": "arXiv:2107.01658",
    "title": "Learning Bayesian Networks through Birkhoff Polytope: A Relaxation  Method",
    "abstract": "We establish a novel framework for learning a directed acyclic graph (DAG)\nwhen data are generated from a Gaussian, linear structural equation model. It\nconsists of two parts: (1) introduce a permutation matrix as a new parameter\nwithin a regularized Gaussian log-likelihood to represent variable ordering;\nand (2) given the ordering, estimate the DAG structure through sparse Cholesky\nfactor of the inverse covariance matrix. For permutation matrix estimation, we\npropose a relaxation technique that avoids the NP-hard combinatorial problem of\norder estimation. Given an ordering, a sparse Cholesky factor is estimated\nusing a cyclic coordinatewise descent algorithm which decouples row-wise. Our\nframework recovers DAGs without the need for an expensive verification of the\nacyclicity constraint or enumeration of possible parent sets. We establish\nnumerical convergence of the algorithm, and consistency of the Cholesky factor\nestimator when the order of variables is known. Through several simulated and\nmacro-economic datasets, we study the scope and performance of the proposed\nmethodology.",
    "descriptor": "",
    "authors": [
      "Aramayis Dallakyan",
      "Mohsen Pourahmadi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01658"
  },
  {
    "id": "arXiv:2107.01682",
    "title": "COVID-VIT: Classification of COVID-19 from CT chest images based on  vision transformer models",
    "abstract": "This paper is responding to the MIA-COV19 challenge to classify COVID from\nnon-COVID based on CT lung images. The COVID-19 virus has devastated the world\nin the last eighteen months by infecting more than 182 million people and\ncausing over 3.9 million deaths. The overarching aim is to predict the\ndiagnosis of the COVID-19 virus from chest radiographs, through the development\nof explainable vision transformer deep learning techniques, leading to\npopulation screening in a more rapid, accurate and transparent way. In this\ncompetition, there are 5381 three-dimensional (3D) datasets in total, including\n1552 for training, 374 for evaluation and 3455 for testing. While most of the\ndata volumes are in axial view, there are a number of subjects' data are in\ncoronal or sagittal views with 1 or 2 slices are in axial view. Hence, while 3D\ndata based classification is investigated, in this competition, 2D images\nremains the main focus. Two deep learning methods are studied, which are vision\ntransformer (ViT) based on attention models and DenseNet that is built upon\nconventional convolutional neural network (CNN). Initial evaluation results\nbased on validation datasets whereby the ground truth is known indicate that\nViT performs better than DenseNet with F1 scores being 0.76 and 0.72\nrespectively. Codes are available at GitHub at\n<https://github/xiaohong1/COVID-ViT>.",
    "descriptor": "",
    "authors": [
      "Xiaohong Gao",
      "Yu Qian",
      "Alice Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01682"
  },
  {
    "id": "arXiv:2107.01690",
    "title": "Interval probability density functions constructed from a generalization  of the Moore and Yang integral",
    "abstract": "Moore and Yang defined an integral notion, based on an extension of Riemann\nsums, for inclusion monotonic continuous interval functions, where the\nintegrations limits are real numbers. This integral notion extend the usual\nintegration of real functions based on Riemann sums. In this paper, we extend\nthis approach by considering intervals as integration limits instead of real\nnumbers and we abolish the inclusion monotonicity restriction of the interval\nfunctions and this notion is used to determine interval probability density\nfunctions.",
    "descriptor": "",
    "authors": [
      "Benjam\u00edn Bedregal",
      "Claudilene Gomes da Costa",
      "Eduardo Palmeira",
      "Edmundo Mansilla"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01690"
  },
  {
    "id": "arXiv:2107.01706",
    "title": "Testing Binomiality of Chemical Reaction Networks Using Comprehensive  Gr\u00f6bner System",
    "abstract": "We consider the problem of binomiality of the steady state ideals of\nbiochemical reaction networks. We are interested in finding polynomial\nconditions on the parameters such that the steady state ideal of a chemical\nreaction network is binomial under every specialisation of the parameters if\nthe conditions on the parameters hold. We approach the binomiality problem\nusing Comprehensive Gr\\\"obner systems. Considering rate constants as\nparameters, we compute comprehensive Gr\\\"obner systems for various reactions.\nIn particular, we make automatic computations on $n-$site phosphorylations and\nbiomodels from the Biomodels repository using the grobcov library of the\ncomputer algebra system Singular.",
    "descriptor": "",
    "authors": [
      "Hamid Rahkooy",
      "Thomas Sturm"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2107.01706"
  },
  {
    "id": "arXiv:2107.01714",
    "title": "A convex optimization approach to online set-membership EIV  identification of LTV systems",
    "abstract": "This paper addresses the problem of recursive set-membership identification\nfor linear time varying (LTV) systems when both input and output measurements\nare affected by bounded additive noise. First we formulate the problem of\nonline computation of the parameter uncertainty intervals (PUIs) in terms of\nnonconvex polynomial optimization. Then, we propose a convex relaxation\napproach based on McCormick envelopes to solve the formulated problem to the\nglobal optimum by means of linear programming. The effectiveness of the\nproposed identification scheme is demonstrated by means of two simulation\nexamples.",
    "descriptor": "\nComments: Accepted for publication in the 2021 60th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\n",
    "authors": [
      "Sophie M. Fosson",
      "Diego Regruto",
      "Talal Abdalla",
      "Abdul Salam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01714"
  },
  {
    "id": "arXiv:2107.01731",
    "title": "Supporting decisions by unleashing multiple mindsets using pairwise  comparisons method",
    "abstract": "Inconsistency in pairwise comparison judgements is often perceived as an\nunwanted phenomenon and researchers have proposed a number of techniques to\neither reduce it or to correct it. We take a viewpoint that this inconsistency\nunleashes different mindsets of the decision maker(s) that should be taken into\naccount when generating recommendations as decision support. With this aim we\nconsider the spanning trees analysis which is a recently emerging idea for use\nwith the pairwise comparison approach that represents the plurality of mindsets\n(in terms of a plurality of vectors corresponding to different spanning trees).\nUntil now, the multiplicity of the vectors supplied by the spanning trees\napproach have been amalgamated into a single preference vector, losing the\ninformation about the plurality of mindsets. To preserve this information, we\npropose a novel methodology taking an approach similar to Stochastic\nMulti-criteria Acceptability Analysis. Considering all the rankings of\nalternatives corresponding to the different mindsets, our methodology gives the\nprobability that an alternative attains a given ranking position as well as the\nprobability that an alternative is preferred to another one. Since the\nexponential number of spanning trees makes their enumeration prohibitive, we\npropose computing approximate probabilities using statistical sampling of the\nspanning trees. Our approach is also appealing because it can be applied also\nto incomplete sets of pairwise comparisons. We demonstrate its usefulness with\na didactic example as well as with an application to a real-life case of\nselecting a Telecom backbone infrastructure for rural areas.",
    "descriptor": "",
    "authors": [
      "Salvatore Greco",
      "Sajid Siraj",
      "Michele Lundy"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01731"
  },
  {
    "id": "arXiv:2107.01734",
    "title": "Latent structure blockmodels for Bayesian spectral graph clustering",
    "abstract": "Spectral embedding of network adjacency matrices often produces node\nrepresentations living approximately around low-dimensional submanifold\nstructures. In particular, hidden substructure is expected to arise when the\ngraph is generated from a latent position model. Furthermore, the presence of\ncommunities within the network might generate community-specific submanifold\nstructures in the embedding, but this is not explicitly accounted for in most\nstatistical models for networks. In this article, a class of models called\nlatent structure block models (LSBM) is proposed to address such scenarios,\nallowing for graph clustering when community-specific one dimensional manifold\nstructure is present. LSBMs focus on a specific class of latent space model,\nthe random dot product graph (RDPG), and assign a latent submanifold to the\nlatent positions of each community. A Bayesian model for the embeddings arising\nfrom LSBMs is discussed, and shown to have a good performance on simulated and\nreal world network data. The model is able to correctly recover the underlying\ncommunities living in a one-dimensional manifold, even when the parametric form\nof the underlying curves is unknown, achieving remarkable results on a variety\nof real data.",
    "descriptor": "",
    "authors": [
      "Francesco Sanna Passino",
      "Nicholas A. Heard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01734"
  },
  {
    "id": "arXiv:2107.01748",
    "title": "Controllable cardiac synthesis via disentangled anatomy arithmetic",
    "abstract": "Acquiring annotated data at scale with rare diseases or conditions remains a\nchallenge. It would be extremely useful to have a method that controllably\nsynthesizes images that can correct such underrepresentation. Assuming a proper\nlatent representation, the idea of a \"latent vector arithmetic\" could offer the\nmeans of achieving such synthesis. A proper representation must encode the\nfidelity of the input data, preserve invariance and equivariance, and permit\narithmetic operations. Motivated by the ability to disentangle images into\nspatial anatomy (tensor) factors and accompanying imaging (vector)\nrepresentations, we propose a framework termed \"disentangled anatomy\narithmetic\", in which a generative model learns to combine anatomical factors\nof different input images such that when they are re-entangled with the desired\nimaging modality (e.g. MRI), plausible new cardiac images are created with the\ntarget characteristics. To encourage a realistic combination of anatomy factors\nafter the arithmetic step, we propose a localized noise injection network that\nprecedes the generator. Our model is used to generate realistic images,\npathology labels, and segmentation masks that are used to augment the existing\ndatasets and subsequently improve post-hoc classification and segmentation\ntasks. Code is publicly available at https://github.com/vios-s/DAA-GAN.",
    "descriptor": "\nComments: Accepted for publication in MICCAI 2021\n",
    "authors": [
      "Spyridon Thermos",
      "Xiao Liu",
      "Alison O'Neil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01748"
  },
  {
    "id": "arXiv:2107.01753",
    "title": "A comparative study of eight human auditory models of monaural  processing",
    "abstract": "A number of auditory models have been developed using diverging approaches,\neither physiological or perceptual, but they share comparable stages of signal\nprocessing, as they are inspired by the same constitutive parts of the auditory\nsystem. We compare eight monaural models that are openly accessible in the\nAuditory Modelling Toolbox. We discuss the considerations required to make the\nmodel outputs comparable to each other, as well as the results for the\nfollowing model processing stages or their equivalents: outer and middle ear,\ncochlear filter bank, inner hair cell, auditory nerve synapse, cochlear\nnucleus, and inferior colliculus. The discussion includes some practical\nconsiderations related to the use of monaural stages in binaural frameworks.",
    "descriptor": "",
    "authors": [
      "Alejandro Osses Vecchi",
      "L\u00e9o Varnet",
      "Laurel H. Carney",
      "Torsten Dau",
      "Ian C. Bruce",
      "Sarah Verhulst",
      "Piotr Majdak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01753"
  },
  {
    "id": "arXiv:2107.01777",
    "title": "Statistical Theory for Imbalanced Binary Classification",
    "abstract": "Within the vast body of statistical theory developed for binary\nclassification, few meaningful results exist for imbalanced classification, in\nwhich data are dominated by samples from one of the two classes. Existing\ntheory faces at least two main challenges. First, meaningful results must\nconsider more complex performance measures than classification accuracy. To\naddress this, we characterize a novel generalization of the Bayes-optimal\nclassifier to any performance metric computed from the confusion matrix, and we\nuse this to show how relative performance guarantees can be obtained in terms\nof the error of estimating the class probability function under uniform\n($\\mathcal{L}_\\infty$) loss. Second, as we show, optimal classification\nperformance depends on certain properties of class imbalance that have not\npreviously been formalized. Specifically, we propose a novel sub-type of class\nimbalance, which we call Uniform Class Imbalance. We analyze how Uniform Class\nImbalance influences optimal classifier performance and show that it\nnecessitates different classifier behavior than other types of class imbalance.\nWe further illustrate these two contributions in the case of $k$-nearest\nneighbor classification, for which we develop novel guarantees. Together, these\nresults provide some of the first meaningful finite-sample statistical theory\nfor imbalanced binary classification.",
    "descriptor": "\nComments: Parts of this paper have been revised from arXiv:2004.04715v2 [math.ST]\n",
    "authors": [
      "Shashank Singh",
      "Justin Khim"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01777"
  },
  {
    "id": "arXiv:2107.01778",
    "title": "Quantaloidal approach to constraint satisfaction",
    "abstract": "The constraint satisfaction problem (CSP) is a computational problem that\nincludes a range of important problems in computer science. We point out that\nfundamental concepts of the CSP, such as the solution set of an instance and\npolymorphisms, can be formulated abstractly inside the 2-category\n$\\mathcal{P}\\mathbf{FinSet}$ of finite sets and sets of functions between them.\nThe 2-category $\\mathcal{P}\\mathbf{FinSet}$ is a quantaloid, and the\nformulation relies mainly on structure available in any quantaloid. This\nobservation suggests a formal development of generalisations of the CSP and\nconcomitant notions of polymorphism in a large class of quantaloids. We extract\na class of optimisation problems as a special case, and show that their\ncomputational complexity can be classified by the associated notion of\npolymorphism.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Soichiro Fujii",
      "Yuni Iwamasa",
      "Kei Kimura"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01778"
  },
  {
    "id": "arXiv:2107.01816",
    "title": "Sets of Marginals and Pearson-Correlation-based CHSH Inequalities for a  Two-Qubit System",
    "abstract": "Quantum mass functions (QMFs), which are tightly related to decoherence\nfunctionals, were introduced by Loeliger and Vontobel [IEEE Trans. Inf. Theory,\n2017, 2020] as a generalization of probability mass functions toward modeling\nquantum information processing setups in terms of factor graphs.\nSimple quantum mass functions (SQMFs) are a special class of QMFs that do not\nexplicitly model classical random variables. Nevertheless, classical random\nvariables appear implicitly in an SQMF if some marginals of the SQMF satisfy\nsome conditions; variables of the SQMF corresponding to these \"emerging\" random\nvariables are called classicable variables. Of particular interest are jointly\nclassicable variables.\nIn this paper we initiate the characterization of the set of marginals given\nby the collection of jointly classicable variables of a graphical model and\ncompare them with other concepts associated with graphical models like the sets\nof realizable marginals and the local marginal polytope.\nIn order to further characterize this set of marginals given by the\ncollection of jointly classicable variables, we generalize the CHSH inequality\nbased on the Pearson correlation coefficients, and thereby prove a conjecture\nproposed by Pozsgay et al. A crucial feature of this inequality is its\nnonlinearity, which poses difficulties in the proof.",
    "descriptor": "",
    "authors": [
      "Yuwen Huang",
      "Pascal O. Vontobel"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01816"
  },
  {
    "id": "arXiv:2107.01834",
    "title": "Third Party Risk Modelling and Assessment for Safe UAV Path Planning in  Metropolitan Environments",
    "abstract": "Various applications of advanced air mobility (AAM) in urban environments\nfacilitate our daily life and public services. As one of the key issues of\nrealizing these applications autonomously, path planning problem has been\nstudied with main objectives on minimizing travel distance, flight time and\nenergy cost. However, AAM operations in metropolitan areas bring safety and\nsociety issues. Because most of AAM aircraft are unmanned aerial vehicles\n(UAVs) and they may fail to operate resulting in fatality risk, property damage\nrisk and societal impacts (noise and privacy) to the public. To quantitatively\nassess these risks and mitigate them in planning phase, this paper proposes an\nintegrated risk assessment model and develops a hybrid algorithm to solve the\nrisk-based 3D path planning problem. The integrated risk assessment method\nconsiders probability and severity models of UAV impact ground people and\nvehicle. By introducing gravity model, the population density and traffic\ndensity are estimated in a finer scale, which enables more accurate risk\nassessment. The 3D risk-based path planning problem is first formulated as a\nspecial minimum cost flow problem. Then, a hybrid estimation of distribution\nalgorithm (EDA) and risk-based A* (named as EDA-RA*) algorithm is proposed to\nsolve the problem. To improve computational efficiency, k-means clustering\nmethod is incorporated into EDA-RA* to provide both global and local search\nheuristic information, which formed the EDA and fast risk-based A* algorithm we\ncall EDA-FRA*. Case study results show that the risk assessment model can\ncapture high risk areas and the generated risk map enables safe UAV path\nplanning in urban complex environments.",
    "descriptor": "",
    "authors": [
      "Bizhao Pang",
      "Xinting Hu",
      "Wei Dai",
      "Kin Huat Low"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01834"
  },
  {
    "id": "arXiv:2107.01850",
    "title": "Matching a Desired Causal State via Shift Interventions",
    "abstract": "Transforming a causal system from a given initial state to a desired target\nstate is an important task permeating multiple fields including control theory,\nbiology, and materials science. In causal models, such transformations can be\nachieved by performing a set of interventions. In this paper, we consider the\nproblem of identifying a shift intervention that matches the desired mean of a\nsystem through active learning. We define the Markov equivalence class that is\nidentifiable from shift interventions and propose two active learning\nstrategies that are guaranteed to exactly match a desired mean. We then derive\na worst-case lower bound for the number of interventions required and show that\nthese strategies are optimal for certain classes of graphs. In particular, we\nshow that our strategies may require exponentially fewer interventions than the\npreviously considered approaches, which optimize for structure learning in the\nunderlying causal graph. In line with our theoretical results, we also\ndemonstrate experimentally that our proposed active learning strategies require\nfewer interventions compared to several baselines.",
    "descriptor": "",
    "authors": [
      "Jiaqi Zhang",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01850"
  },
  {
    "id": "arXiv:2107.01857",
    "title": "Versatile and concurrent FPGA-based architecture for practical quantum  communication systems",
    "abstract": "This work presents a hardware and software architecture which can be used in\nthose systems that implement practical Quantum Key Distribution (QKD) and\nQuantum Random Number Generation (QRNG) schemes. This architecture fully\nexploits the capability of a System-on-a-Chip (SoC) which comprehends both a\nField Programmable Gate Array (FPGA) and a dual core CPU unit. By assigning the\ntime-related tasks to the FPGA and the management to the CPU, we built a\nflexible system with optimized resource sharing on a commercial off-the-shelf\n(COTS) evaluation board which includes a SoC. Furthermore, by changing the\ndataflow direction, the versatile system architecture can be exploited as a QKD\ntransmitter, QKD receiver and QRNG control-acquiring unit. Finally, we\nexploited the dual core functionality and realized a concurrent stream device\nto implement a practical QKD transmitter where one core continuously receives\nfresh data at a sustained rate from an external QRNG source while the other\noperates with the FPGA to drive the qubits transmission to the QKD receiver.\nThe system was successfully tested on a long-term run proving its stability and\nsecurity. This demonstration paves the way towards a more secure QKD\nimplementation, with fully unconditional security as the QKD states are\nentirely generated by a true random process and not by deterministic expansion\nalgorithms. Eventually, this enables the realization of a standalone quantum\ntransmitter, including both the random numbers and the qubits generation.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Andrea Stanco",
      "Francesco B. L. Santagiustina",
      "Luca Calderaro",
      "Marco Avesani",
      "Tommaso Bertapelle",
      "Daniele Dequal",
      "Giuseppe Vallone",
      "Paolo Villoresi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.01857"
  },
  {
    "id": "arXiv:2107.01863",
    "title": "On the Efficiency of Various Deep Transfer Learning Models in Glitch  Waveform Detection in Gravitational-Wave Data",
    "abstract": "LIGO is considered the most sensitive and complicated gravitational\nexperiment ever built. Its main objective is to detect the gravitational wave\nfrom the strongest events in the universe by observing if the length of its\n4-kilometer arms change by a distance 10,000 times smaller than the diameter of\na proton. Due to its sensitivity, LIGO is prone to the disturbance of external\nnoises which affects the data being collected to detect the gravitational wave.\nThese noises are commonly called by the LIGO community as glitches. The\nobjective of this study is to evaluate the effeciency of various deep trasnfer\nlearning models namely VGG19, ResNet50V2, VGG16 and ResNet101 to detect glitch\nwaveform in gravitational wave data. The accuracy achieved by the said models\nare 98.98%, 98.35%, 97.56% and 94.73% respectively. Even though the models\nachieved fairly high accuracy, it is observed that all of the model suffered\nfrom the lack of data for certain classes which is the main concern found in\nthe experiment",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Reymond Mesuga",
      "Brian James Bayanay"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01863"
  },
  {
    "id": "arXiv:2107.01876",
    "title": "Causally Invariant Predictor with Shift-Robustness",
    "abstract": "This paper proposes an invariant causal predictor that is robust to\ndistribution shift across domains and maximally reserves the transferable\ninvariant information. Based on a disentangled causal factorization, we\nformulate the distribution shift as soft interventions in the system, which\ncovers a wide range of cases for distribution shift as we do not make prior\nspecifications on the causal structure or the intervened variables. Instead of\nimposing regularizations to constrain the invariance of the predictor, we\npropose to predict by the intervened conditional expectation based on the\ndo-operator and then prove that it is invariant across domains. More\nimportantly, we prove that the proposed predictor is the robust predictor that\nminimizes the worst-case quadratic loss among the distributions of all domains.\nFor empirical learning, we propose an intuitive and flexible estimating method\nbased on data regeneration and present a local causal discovery procedure to\nguide the regeneration step. The key idea is to regenerate data such that the\nregenerated distribution is compatible with the intervened graph, which allows\nus to incorporate standard supervised learning methods with the regenerated\ndata. Experimental results on both synthetic and real data demonstrate the\nefficacy of our predictor in improving the predictive accuracy and robustness\nacross domains.",
    "descriptor": "",
    "authors": [
      "Xiangyu Zheng",
      "Xinwei Sun",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01876"
  },
  {
    "id": "arXiv:2107.01885",
    "title": "PRNU Based Source Camera Identification for Webcam Videos",
    "abstract": "This communication is about an application of image forensics where we use\ncamera sensor fingerprints to identify source camera (SCI: Source Camera\nIdentification) in webcam videos. Sensor or camera fingerprints are based on\ncomputing the intrinsic noise that is always present in this kind of sensors\ndue to manufacturing imperfections. This is an unavoidable characteristic that\nlinks each sensor with its noise pattern. PRNU (Photo Response Non-Uniformity)\nhas become the default technique to compute a camera fingerprint. There are\nmany applications nowadays dealing with PRNU patterns for camera identification\nusing still images. In this work we focus on video, more specifically on webcam\nvideo, because of the great importance of webcam video nowadays. Three possible\nmethods for SCI are implemented and assessed in this work.",
    "descriptor": "\nComments: 4 pages, 3 figures, 3 tables\n",
    "authors": [
      "Fernando Martin-Rodriguez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.01885"
  },
  {
    "id": "arXiv:2107.01893",
    "title": "Combining Orthology and Xenology Data in a Common Phylogenetic Tree",
    "abstract": "A rooted tree $T$ with vertex labels $t(v)$ and set-valued edge labels\n$\\lambda(e)$ defines maps $\\delta$ and $\\varepsilon$ on the pairs of leaves of\n$T$ by setting $\\delta(x,y)=q$ if the last common ancestor $\\text{lca}(x,y)$ of\n$x$ and $y$ is labeled $q$, and $m\\in \\varepsilon(x,y)$ if $m\\in\\lambda(e)$ for\nat least one edge $e$ along the path from $\\text{lca}(x,y)$ to $y$. We show\nthat a pair of maps $(\\delta,\\varepsilon)$ derives from a tree $(T,t,\\lambda)$\nif and only if there exists a common refinement of the (unique) least-resolved\nvertex labeled tree $(T_{\\delta},t_{\\delta})$ that explains $\\delta$ and the\n(unique) least resolved edge labeled tree\n$(T_{\\varepsilon},\\lambda_{\\varepsilon})$ that explains $\\varepsilon$ (provided\nboth trees exist). This result remains true if certain combinations of labels\nat incident vertices and edges are forbidden.",
    "descriptor": "",
    "authors": [
      "Marc Hellmuth",
      "Mira Michel",
      "Nikolai N. N\u00f8jgaard",
      "David Schaller",
      "Peter F. Stadler"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2107.01893"
  },
  {
    "id": "arXiv:2107.01906",
    "title": "The Last-Iterate Convergence Rate of Optimistic Mirror Descent in  Stochastic Variational Inequalities",
    "abstract": "In this paper, we analyze the local convergence rate of optimistic mirror\ndescent methods in stochastic variational inequalities, a class of optimization\nproblems with important applications to learning theory and machine learning.\nOur analysis reveals an intricate relation between the algorithm's rate of\nconvergence and the local geometry induced by the method's underlying Bregman\nfunction. We quantify this relation by means of the Legendre exponent, a notion\nthat we introduce to measure the growth rate of the Bregman divergence relative\nto the ambient norm near a solution. We show that this exponent determines both\nthe optimal step-size policy of the algorithm and the optimal rates attained,\nexplaining in this way the differences observed for some popular Bregman\nfunctions (Euclidean projection, negative entropy, fractional power, etc.).",
    "descriptor": "\nComments: 31 pages, 3 figures, 1 table; to be presented at the 34th Annual Conference on Learning Theory (COLT 2021)\n",
    "authors": [
      "Wa\u00efss Azizian",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01906"
  },
  {
    "id": "arXiv:2107.01913",
    "title": "Randomized multilevel Monte Carlo for embarrassingly parallel inference",
    "abstract": "This position paper summarizes a recently developed research program focused\non inference in the context of data centric science and engineering\napplications, and forecasts its trajectory forward over the next decade. Often\none endeavours in this context to learn complex systems in order to make more\ninformed predictions and high stakes decisions under uncertainty. Some key\nchallenges which must be met in this context are robustness, generalizability,\nand interpretability. The Bayesian framework addresses these three challenges,\nwhile bringing with it a fourth, undesirable feature: it is typically far more\nexpensive than its deterministic counterparts. In the 21st century, and\nincreasingly over the past decade, a growing number of methods have emerged\nwhich allow one to leverage cheap low-fidelity models in order to precondition\nalgorithms for performing inference with more expensive models and make\nBayesian inference tractable in the context of high-dimensional and expensive\nmodels. Notable examples are multilevel Monte Carlo (MLMC), multi-index Monte\nCarlo (MIMC), and their randomized counterparts (rMLMC), which are able to\nprovably achieve a dimension-independent (including $\\infty-$dimension)\ncanonical complexity rate with respect to mean squared error (MSE) of $1/$MSE.\nSome parallelizability is typically lost in an inference context, but recently\nthis has been largely recovered via novel double randomization approaches. Such\nan approach delivers i.i.d. samples of quantities of interest which are\nunbiased with respect to the infinite resolution target distribution. Over the\ncoming decade, this family of algorithms has the potential to transform data\ncentric science and engineering, as well as classical machine learning\napplications such as deep learning, by scaling up and scaling out fully\nBayesian inference.",
    "descriptor": "",
    "authors": [
      "Ajay Jasra",
      "Kody J. H. Law",
      "Fangyuan Yu"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01913"
  },
  {
    "id": "arXiv:2107.01922",
    "title": "Investigation of Practical Aspects of Single Channel Speech Separation  for ASR",
    "abstract": "Speech separation has been successfully applied as a frontend processing\nmodule of conversation transcription systems thanks to its ability to handle\noverlapped speech and its flexibility to combine with downstream tasks such as\nautomatic speech recognition (ASR). However, a speech separation model often\nintroduces target speech distortion, resulting in a sub-optimum word error rate\n(WER). In this paper, we describe our efforts to improve the performance of a\nsingle channel speech separation system. Specifically, we investigate a\ntwo-stage training scheme that firstly applies a feature level optimization\ncriterion for pretraining, followed by an ASR-oriented optimization criterion\nusing an end-to-end (E2E) speech recognition model. Meanwhile, to keep the\nmodel light-weight, we introduce a modified teacher-student learning technique\nfor model compression. By combining those approaches, we achieve a absolute\naverage WER improvement of 2.70% and 0.77% using models with less than 10M\nparameters compared with the previous state-of-the-art results on the LibriCSS\ndataset for utterance-wise evaluation and continuous evaluation, respectively",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Jian Wu",
      "Zhuo Chen",
      "Sanyuan Chen",
      "Yu Wu",
      "Takuya Yoshioka",
      "Naoyuki Kanda",
      "Shujie Liu",
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01922"
  },
  {
    "id": "arXiv:2107.01966",
    "title": "An analytical solution of the isentropic vortex problem in the special  relativistic magnetohydrodynamics",
    "abstract": "The isentropic vortex problem is frequently solved to test the accuracy of\nnumerical methods and verify corresponding code. Unfortunately, its existing\nsolution was derived in the relativistic magnetohydrodynamics by numerically\nsolving an ordinary differential equation. This note provides an analytical\nsolution of the 2D isentropic vortex problem with explicit algebraic\nexpressions in the special relativistic hydrodynamics and magnetohydrodynamics\nand extends it to the 3D case.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Junming Duan",
      "Huazhong Tang"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01966"
  },
  {
    "id": "arXiv:2107.01988",
    "title": "UCSL : A Machine Learning Expectation-Maximization framework for  Unsupervised Clustering driven by Supervised Learning",
    "abstract": "Subtype Discovery consists in finding interpretable and consistent sub-parts\nof a dataset, which are also relevant to a certain supervised task. From a\nmathematical point of view, this can be defined as a clustering task driven by\nsupervised learning in order to uncover subgroups in line with the supervised\nprediction. In this paper, we propose a general Expectation-Maximization\nensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised\nLearning). Our method is generic, it can integrate any clustering method and\ncan be driven by both binary classification and regression. We propose to\nconstruct a non-linear model by merging multiple linear estimators, one per\ncluster. Each hyperplane is estimated so that it correctly discriminates - or\npredict - only one cluster. We use SVC or Logistic Regression for\nclassification and SVR for regression. Furthermore, to perform cluster analysis\nwithin a more suitable space, we also propose a dimension-reduction algorithm\nthat projects the data onto an orthonormal space relevant to the supervised\ntask. We analyze the robustness and generalization capability of our algorithm\nusing synthetic and experimental datasets. In particular, we validate its\nability to identify suitable consistent sub-types by conducting a\npsychiatric-diseases cluster analysis with known ground-truth labels. The gain\nof the proposed method over previous state-of-the-art techniques is about +1.9\npoints in terms of balanced accuracy. Finally, we make codes and examples\navailable in a scikit-learn-compatible Python package at\nhttps://github.com/neurospin-projects/2021_rlouiset_ucsl",
    "descriptor": "\nComments: ECML/PKDD 2021\n",
    "authors": [
      "Robin Louiset",
      "Pietro Gori",
      "Benoit Dufumier",
      "Josselin Houenou",
      "Antoine Grigis",
      "Edouard Duchesnay"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01988"
  },
  {
    "id": "arXiv:2107.01994",
    "title": "Template-Based Graph Clustering",
    "abstract": "We propose a novel graph clustering method guided by additional information\non the underlying structure of the clusters (or communities). The problem is\nformulated as the matching of a graph to a template with smaller dimension,\nhence matching $n$ vertices of the observed graph (to be clustered) to the $k$\nvertices of a template graph, using its edges as support information, and\nrelaxed on the set of orthonormal matrices in order to find a $k$ dimensional\nembedding. With relevant priors that encode the density of the clusters and\ntheir relationships, our method outperforms classical methods, especially for\nchallenging cases.",
    "descriptor": "\nComments: ECML-PKDD, Workshop on Graph Embedding and Minin (GEM) 2020\n",
    "authors": [
      "Mateus Riva",
      "Florian Yger",
      "Pietro Gori",
      "Roberto M. Cesar Jr.",
      "Isabelle Bloch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01994"
  },
  {
    "id": "arXiv:2107.01997",
    "title": "The self-organizing impact of averaged payoffs on the evolution of  cooperation",
    "abstract": "According to the fundamental principle of evolutionary game theory, the more\nsuccessful strategy in a population should spread. Hence, during a strategy\nimitation process a player compares its payoff value to the payoff value held\nby a competing strategy. But this information is not always accurate. To avoid\nambiguity a learner may therefore decide to collect a more reliable statistics\nby averaging the payoff values of its opponents in the neighborhood, and makes\na decision afterwards. This simple alteration of the standard microscopic\nprotocol significantly improves the cooperation level in a population.\nFurthermore, the positive impact can be strengthened by increasing the role of\nthe environment and the size of the evaluation circle. The mechanism that\nexplains this improvement is based on a self-organizing process which reveals\nthe detrimental consequence of defector aggregation that remains partly hidden\nduring face-to-face comparisons. Notably, the reported phenomenon is not\nlimited to lattice populations but remains valid also for systems described by\nirregular interaction networks.",
    "descriptor": "\nComments: 16 pages, 7 figures; accepted for publication in New Journal of Physics\n",
    "authors": [
      "A. Szolnoki",
      "M. Perc"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2107.01997"
  },
  {
    "id": "arXiv:2107.02003",
    "title": "Speech Synthesis from Text and Ultrasound Tongue Image-based  Articulatory Input",
    "abstract": "Articulatory information has been shown to be effective in improving the\nperformance of HMM-based and DNN-based text-to-speech synthesis. Speech\nsynthesis research focuses traditionally on text-to-speech conversion, when the\ninput is text or an estimated linguistic representation, and the target is\nsynthesized speech. However, a research field that has risen in the last decade\nis articulation-to-speech synthesis (with a target application of a Silent\nSpeech Interface, SSI), when the goal is to synthesize speech from some\nrepresentation of the movement of the articulatory organs. In this paper, we\nextend traditional (vocoder-based) DNN-TTS with articulatory input, estimated\nfrom ultrasound tongue images. We compare text-only, ultrasound-only, and\ncombined inputs. Using data from eight speakers, we show that that the combined\ntext and articulatory input can have advantages in limited-data scenarios,\nnamely, it may increase the naturalness of synthesized speech compared to\nsingle text input. Besides, we analyze the ultrasound tongue recordings of\nseveral speakers, and show that misalignments in the ultrasound transducer\npositioning can have a negative effect on the final synthesis performance.",
    "descriptor": "\nComments: accepted at SSW11 (11th Speech Synthesis Workshop)\n",
    "authors": [
      "Tam\u00e1s G\u00e1bor Csap\u00f3",
      "L\u00e1szl\u00f3 T\u00f3th",
      "G\u00e1bor Gosztolya",
      "Alexandra Mark\u00f3"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.02003"
  },
  {
    "id": "arXiv:2107.02043",
    "title": "An extended watershed-based zonal statistical AHP model for flood risk  estimation: Constraining runoff converging related indicators by  sub-watersheds",
    "abstract": "Floods are highly uncertain events, occurring in different regions, with\nvarying prerequisites and intensities. A highly reliable flood disaster risk\nmap can help reduce the impact of floods for flood management, disaster\ndecreasing, and urbanization resilience. In flood risk estimation, the widely\nused analytic hierarchy process (AHP) usually adopts pixel as a basic unit, it\ncannot capture the similar threaten caused by neighborhood source flooding\ncells at sub-watershed scale. Thus, an extended watershed-based zonal\nstatistical AHP model constraining runoff converging related indicators by\nsub-watersheds (WZSAHP-Slope & Stream) is proposed to fill this gap. Taking the\nChaohu basin as test case, we validated the proposed method with a real-flood\narea extracted in July 2020. The results indicate that the WZSAHP-Slope &\nStream model using multiple flow direction division watersheds to calculate\nstatistics of distance from stream and slope by maximum statistic method\noutperformed other tested methods. Compering with pixel-based AHP method, the\nproposed method can improve the correct ratio by 16% (from 67% to 83%) and fit\nratio by 1% (from 13% to 14%) as in validation 1, and improve the correct ratio\nby 37% (from 23% to 60%) and fit ratio by 6% (from 12% to 18%) as in validation\n2.",
    "descriptor": "\nComments: This paper is a research paper, it contains 40 pages and 8 figures. This paper is a modest contribution to the ongoing discussions the accuracy of flood risk estimation via AHP model improved by adopting pixels replaced with sub-watersheds as basic unit\n",
    "authors": [
      "Hongping Zhang",
      "Zhenfeng Shao",
      "Jinqi Zhao",
      "Xiao Huang",
      "Jie Yang",
      "Bin Hu",
      "Wenfu Wu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.02043"
  },
  {
    "id": "arXiv:2107.02070",
    "title": "Antithetic Riemannian Manifold And Quantum-Inspired Hamiltonian Monte  Carlo",
    "abstract": "Markov Chain Monte Carlo inference of target posterior distributions in\nmachine learning is predominately conducted via Hamiltonian Monte Carlo and its\nvariants. This is due to Hamiltonian Monte Carlo based samplers ability to\nsuppress random-walk behaviour. As with other Markov Chain Monte Carlo methods,\nHamiltonian Monte Carlo produces auto-correlated samples which results in high\nvariance in the estimators, and low effective sample size rates in the\ngenerated samples. Adding antithetic sampling to Hamiltonian Monte Carlo has\nbeen previously shown to produce higher effective sample rates compared to\nvanilla Hamiltonian Monte Carlo. In this paper, we present new algorithms which\nare antithetic versions of Riemannian Manifold Hamiltonian Monte Carlo and\nQuantum-Inspired Hamiltonian Monte Carlo. The Riemannian Manifold Hamiltonian\nMonte Carlo algorithm improves on Hamiltonian Monte Carlo by taking into\naccount the local geometry of the target, which is beneficial for target\ndensities that may exhibit strong correlations in the parameters.\nQuantum-Inspired Hamiltonian Monte Carlo is based on quantum particles that can\nhave random mass. Quantum-Inspired Hamiltonian Monte Carlo uses a random mass\nmatrix which results in better sampling than Hamiltonian Monte Carlo on spiky\nand multi-modal distributions such as jump diffusion processes. The analysis is\nperformed on jump diffusion process using real world financial market data, as\nwell as on real world benchmark classification tasks using Bayesian logistic\nregression.",
    "descriptor": "",
    "authors": [
      "Wilson Tsakane Mongwe",
      "Rendani Mbuvha",
      "Tshilidzi Marwala"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.02070"
  },
  {
    "id": "arXiv:2107.02085",
    "title": "Analyzing Relevance Vector Machines using a single penalty approach",
    "abstract": "Relevance vector machine (RVM) is a popular sparse Bayesian learning model\ntypically used for prediction. Recently it has been shown that improper priors\nassumed on multiple penalty parameters in RVM may lead to an improper\nposterior. Currently in the literature, the sufficient conditions for posterior\npropriety of RVM do not allow improper priors over the multiple penalty\nparameters. In this article, we propose a single penalty relevance vector\nmachine (SPRVM) model in which multiple penalty parameters are replaced by a\nsingle penalty and we consider a semi Bayesian approach for fitting the SPRVM.\nThe necessary and sufficient conditions for posterior propriety of SPRVM are\nmore liberal than those of RVM and allow for several improper priors over the\npenalty parameter. Additionally, we also prove the geometric ergodicity of the\nGibbs sampler used to analyze the SPRVM model and hence can estimate the\nasymptotic standard errors associated with the Monte Carlo estimate of the\nmeans of the posterior predictive distribution. Such a Monte Carlo standard\nerror cannot be computed in the case of RVM, since the rate of convergence of\nthe Gibbs sampler used to analyze RVM is not known. The predictive performance\nof RVM and SPRVM is compared by analyzing three real life datasets.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Anand Dixit",
      "Vivekananda Roy"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02085"
  },
  {
    "id": "arXiv:2107.02115",
    "title": "Persistence of Conley-Morse Graphs in Combinatorial Dynamical Systems",
    "abstract": "Multivector fields provide an avenue for studying continuous dynamical\nsystems in a combinatorial framework. There are currently two approaches in the\nliterature which use persistent homology to capture changes in combinatorial\ndynamical systems. The first captures changes in the Conley index, while the\nsecond captures changes in the Morse decomposition. However, such approaches\nhave limitations. The former approach only describes how the Conley index\nchanges across a selected isolated invariant set though the dynamics can be\nmuch more complicated than the behavior of a single isolated invariant set.\nLikewise, considering a Morse decomposition omits much information about the\nindividual Morse sets. In this paper, we propose a method to summarize changes\nin combinatorial dynamical systems by capturing changes in the so-called\nConley-Morse graphs. A Conley-Morse graph contains information about both the\nstructure of a selected Morse decomposition and about the Conley index at each\nMorse set in the decomposition. Hence, our method summarizes the changing\nstructure of a sequence of dynamical systems at a finer granularity than\nprevious approaches.",
    "descriptor": "",
    "authors": [
      "Tamal Dey",
      "Marian Mrozek",
      "Ryan Slechta"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2107.02115"
  },
  {
    "id": "arXiv:2107.02145",
    "title": "Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context",
    "abstract": "In this paper we investigate the amount of spatial context required for\nchannel attention. To this end we study the popular squeeze-and-excite (SE)\nblock which is a simple and lightweight channel attention mechanism. SE blocks\nand its numerous variants commonly use global average pooling (GAP) to create a\nsingle descriptor for each channel. Here, we empirically analyze the amount of\nspatial context needed for effective channel attention and find that limited\nlocalcontext on the order of seven rows or columns of the original image is\nsufficient to match the performance of global context. We propose tiled\nsqueeze-and-excite (TSE), which is a framework for building SE-like blocks that\nemploy several descriptors per channel, with each descriptor based on local\ncontext only. We further show that TSE is a drop-in replacement for the SE\nblock and can be used in existing SE networks without re-training. This implies\nthat local context descriptors are similar both to each other and to the global\ncontext descriptor. Finally, we show that TSE has important practical\nimplications for deployment of SE-networks to dataflow AI accelerators due to\ntheir reduced pipeline buffering requirements. For example, using TSE reduces\nthe amount of activation pipeline buffering in EfficientDetD2 by 90% compared\nto SE (from 50M to 4.77M) without loss of accuracy. Our code and pre-trained\nmodels will be publicly available.",
    "descriptor": "",
    "authors": [
      "Niv Vosco",
      "Alon Shenkler",
      "Mark Grobman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02145"
  },
  {
    "id": "arXiv:2107.02155",
    "title": "Reconfigurable Intelligent Surface Assisted Device-to-Device  Communications",
    "abstract": "Reconfigurable intelligent surface (RIS) technology is a promising method to\nenhance wireless communications services and to realize the smart radio\nenvironment. In this paper, we investigate the application of RIS in D2D\ncommunications, and maximize the sum of the transmission rate of the D2D\nunderlaying networks in a new perspective. Instead of solving similarly\nformulated resource allocation problems for D2D communications, this paper\ntreats the wireless environment as a variable by adjusting the position and\nphase shift of the RIS. To solve this non-convex problem, we propose a novel\ndouble deep Q-network (DDQN) based structure which is able to achieve the\nnear-optimal performance with lower complexity and enhanced robustness.\nSimulation results illustrate that the proposed DDQN based structure can\nachieve a higher uplink rate compared to the benchmarks, meanwhile meeting the\nquality of service (QoS) requirements at the base station (BS) and D2D\nreceivers.",
    "descriptor": "\nComments: This work have been submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Zelin Ji",
      "Zhijin Qin",
      "Clive G. Parini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.02155"
  },
  {
    "id": "arXiv:1603.05620",
    "title": "A Moment Majorization principle for random matrix ensembles",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Steven Heilman"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1603.05620"
  },
  {
    "id": "arXiv:1703.10049",
    "title": "Autonomous Recharging and Flight Mission Planning for Battery-operated  Autonomous Drones",
    "abstract": "Comments: Under review in IEEE Systems journal",
    "descriptor": "\nComments: Under review in IEEE Systems journal\n",
    "authors": [
      "Rashid Alyassi",
      "Majid Khonji",
      "Sid Chi-Kin Chau",
      "Khaled Elbassioni",
      "Chien-Ming Tseng",
      "Areg Karapetyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1703.10049"
  },
  {
    "id": "arXiv:1709.05876",
    "title": "Approximations for Generalized Unsplittable Flow on Paths with  Application to Power Systems Optimization",
    "abstract": "Approximations for Generalized Unsplittable Flow on Paths with  Application to Power Systems Optimization",
    "descriptor": "",
    "authors": [
      "Areg Karapetyan",
      "Khaled Elbassioni",
      "Majid Khonji",
      "Chi-Kin Chau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1709.05876"
  },
  {
    "id": "arXiv:1711.01381",
    "title": "Finding branch-decompositions of matroids, hypergraphs, and more",
    "abstract": "Comments: 79 pages, 15 figures; revised. Accepted to SIAM J. Discrete Math",
    "descriptor": "\nComments: 79 pages, 15 figures; revised. Accepted to SIAM J. Discrete Math\n",
    "authors": [
      "Jisu Jeong",
      "Eun Jung Kim",
      "Sang-il Oum"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1711.01381"
  },
  {
    "id": "arXiv:1711.04916",
    "title": "Generative Steganography with Kerckhoffs' Principle",
    "abstract": "Generative Steganography with Kerckhoffs' Principle",
    "descriptor": "",
    "authors": [
      "Yan Ke",
      "Minqing Zhang",
      "Jia Liu",
      "Tingting Su",
      "Xiaoyuan Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1711.04916"
  },
  {
    "id": "arXiv:1805.03696",
    "title": "Bayeslands: A Bayesian inference approach for parameter uncertainty  quantification in Badlands",
    "abstract": "Bayeslands: A Bayesian inference approach for parameter uncertainty  quantification in Badlands",
    "descriptor": "",
    "authors": [
      "Rohitash Chandra",
      "Danial Azam",
      "R. Dietmar M\u00fcller",
      "Tristan Salles",
      "Sally Cripps"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/1805.03696"
  },
  {
    "id": "arXiv:1806.02127",
    "title": "Addendum to \"HTN Acting: A Formalism and an Algorithm\"",
    "abstract": "Comments: This paper is a more detailed version of the following publication: Lavindra de Silva, \"HTN Acting: A Formalism and an Algorithm\", in Proceedings of AAMAS 2018",
    "descriptor": "\nComments: This paper is a more detailed version of the following publication: Lavindra de Silva, \"HTN Acting: A Formalism and an Algorithm\", in Proceedings of AAMAS 2018\n",
    "authors": [
      "Lavindra de Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1806.02127"
  },
  {
    "id": "arXiv:1807.04209",
    "title": "Differentially Private False Discovery Rate Control",
    "abstract": "Comments: To appear in The Journal of Privacy and Confidentiality",
    "descriptor": "\nComments: To appear in The Journal of Privacy and Confidentiality\n",
    "authors": [
      "Cynthia Dwork",
      "Weijie J. Su",
      "Li Zhang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1807.04209"
  },
  {
    "id": "arXiv:1810.04320",
    "title": "Least Squares Normalized Cross Correlation",
    "abstract": "Comments: 18 pages. Submitted for re-review to TPAMI on July 6th 2021",
    "descriptor": "\nComments: 18 pages. Submitted for re-review to TPAMI on July 6th 2021\n",
    "authors": [
      "Oliver J. Woodford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1810.04320"
  },
  {
    "id": "arXiv:1902.09434",
    "title": "S-TRIGGER: Continual State Representation Learning via Self-Triggered  Generative Replay",
    "abstract": "Comments: Accepted to IJCNN 2021. arXiv admin note: text overlap with arXiv:1810.03880",
    "descriptor": "\nComments: Accepted to IJCNN 2021. arXiv admin note: text overlap with arXiv:1810.03880\n",
    "authors": [
      "Hugo Caselles-Dupr\u00e9",
      "Michael Garcia-Ortiz",
      "David Filliat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.09434"
  },
  {
    "id": "arXiv:1905.01489",
    "title": "WoodScape: A multi-task, multi-camera fisheye dataset for autonomous  driving",
    "abstract": "Comments: Accepted for Oral Presentation at IEEE International Conference on Computer Vision (ICCV) 2019. Please refer to our website this https URL and this https URL for release status and updates",
    "descriptor": "\nComments: Accepted for Oral Presentation at IEEE International Conference on Computer Vision (ICCV) 2019. Please refer to our website this https URL and this https URL for release status and updates\n",
    "authors": [
      "Senthil Yogamani",
      "Ciaran Hughes",
      "Jonathan Horgan",
      "Ganesh Sistu",
      "Padraig Varley",
      "Derek O'Dea",
      "Michal Uricar",
      "Stefan Milz",
      "Martin Simon",
      "Karl Amende",
      "Christian Witt",
      "Hazem Rashed",
      "Sumanth Chennupati",
      "Sanjaya Nayak",
      "Saquib Mansoor",
      "Xavier Perroton",
      "Patrick Perez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.01489"
  },
  {
    "id": "arXiv:1905.04117",
    "title": "Computing Probabilistic Controlled Invariant Sets",
    "abstract": "Comments: Journal article in the IEEE Transactions on Automatic Control (Volume: 66, Issue: 7, July 2021)",
    "descriptor": "\nComments: Journal article in the IEEE Transactions on Automatic Control (Volume: 66, Issue: 7, July 2021)\n",
    "authors": [
      "Yulong Gao",
      "Karl H. Johansson",
      "Lihua Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1905.04117"
  },
  {
    "id": "arXiv:1905.10488",
    "title": "GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy  Images",
    "abstract": "Comments: ICLR 2021 camera ready version",
    "descriptor": "\nComments: ICLR 2021 camera ready version\n",
    "authors": [
      "Sungmin Cha",
      "Taeeon Park",
      "Byeongjoon Kim",
      "Jongduk Baek",
      "Taesup Moon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.10488"
  },
  {
    "id": "arXiv:1906.04675",
    "title": "Taxonomy of Saliency Metrics for Channel Pruning",
    "abstract": "Taxonomy of Saliency Metrics for Channel Pruning",
    "descriptor": "",
    "authors": [
      "Kaveena Persand",
      "Andrew Anderson",
      "David Gregg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.04675"
  },
  {
    "id": "arXiv:1906.09727",
    "title": "Bag Query Containment and Information Theory",
    "abstract": "Bag Query Containment and Information Theory",
    "descriptor": "",
    "authors": [
      "Mahmoud Abo Khamis",
      "Phokion G. Kolaitis",
      "Hung Q. Ngo",
      "Dan Suciu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1906.09727"
  },
  {
    "id": "arXiv:1910.02325",
    "title": "Bayesian Learning-Based Adaptive Control for Safety Critical Systems",
    "abstract": "Comments: Corrected an error in section II, where previously the problem was introduced in a non-stochastic setting and wrongly assumed the solution to an ODE with Gaussian distributed parametric uncertainty was equivalent to an SDE with a learned diffusion term. See Lew, T et al. \"On the Problem of Reformulating Systems with Uncertain Dynamics as a Stochastic Differential Equation\"",
    "descriptor": "\nComments: Corrected an error in section II, where previously the problem was introduced in a non-stochastic setting and wrongly assumed the solution to an ODE with Gaussian distributed parametric uncertainty was equivalent to an SDE with a learned diffusion term. See Lew, T et al. \"On the Problem of Reformulating Systems with Uncertain Dynamics as a Stochastic Differential Equation\"\n",
    "authors": [
      "David D. Fan",
      "Jennifer Nguyen",
      "Rohan Thakker",
      "Nikhilesh Alatur",
      "Ali-akbar Agha-mohammadi",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1910.02325"
  },
  {
    "id": "arXiv:1910.06895",
    "title": "CRISLoc: Reconstructable CSI Fingerprintingfor Indoor Smartphone  Localization",
    "abstract": "CRISLoc: Reconstructable CSI Fingerprintingfor Indoor Smartphone  Localization",
    "descriptor": "",
    "authors": [
      "Zhihui Gao",
      "Yunfan Gao",
      "Sulei Wang",
      "Dan Li",
      "Yuedong Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1910.06895"
  },
  {
    "id": "arXiv:1911.02903",
    "title": "How Implicit Regularization of ReLU Neural Networks Characterizes the  Learned Function -- Part I: the 1-D Case of Two Layers with Random First  Layer",
    "abstract": "Comments: further generalizing training loss L, fixing typos, improving formulations",
    "descriptor": "\nComments: further generalizing training loss L, fixing typos, improving formulations\n",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.02903"
  },
  {
    "id": "arXiv:1911.04872",
    "title": "Two Ridge Solutions for the Incremental Broad Learning System on Added  Nodes",
    "abstract": "Two Ridge Solutions for the Incremental Broad Learning System on Added  Nodes",
    "descriptor": "",
    "authors": [
      "Hufei Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.04872"
  },
  {
    "id": "arXiv:1911.09234",
    "title": "Robust Learning Model Predictive Control for Linear Systems Performing  Iterative Tasks",
    "abstract": "Robust Learning Model Predictive Control for Linear Systems Performing  Iterative Tasks",
    "descriptor": "",
    "authors": [
      "Ugo Rosolia",
      "Xiaojing Zhang",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1911.09234"
  },
  {
    "id": "arXiv:1911.11494",
    "title": "The Sitting Closer to Friends than Enemies Problem in Trees",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Rosa Becerra",
      "Christopher Thraves Caro"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1911.11494"
  },
  {
    "id": "arXiv:1912.08516",
    "title": "PCPATCH: software for the topological construction of multigrid  relaxation methods",
    "abstract": "Comments: 22 pages, minor fixes in bibliography",
    "descriptor": "\nComments: 22 pages, minor fixes in bibliography\n",
    "authors": [
      "Patrick E. Farrell",
      "Matthew G. Knepley",
      "Lawrence Mitchell",
      "Florian Wechsung"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.08516"
  },
  {
    "id": "arXiv:2001.04463",
    "title": "Unsupervised Audiovisual Synthesis via Exemplar Autoencoders",
    "abstract": "Comments: ICLR 2021; Project page -- this https URL",
    "descriptor": "\nComments: ICLR 2021; Project page -- this https URL\n",
    "authors": [
      "Kangle Deng",
      "Aayush Bansal",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2001.04463"
  },
  {
    "id": "arXiv:2001.05446",
    "title": "What Contributes to a Crowdfunding Campaign's Success? Evidence and  Analyses from GoFundMe Data",
    "abstract": "Comments: Accepted for publication in IEEE Journal of Social Computing, 2021",
    "descriptor": "\nComments: Accepted for publication in IEEE Journal of Social Computing, 2021\n",
    "authors": [
      "Xupin Zhang",
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2001.05446"
  },
  {
    "id": "arXiv:2001.07248",
    "title": "SGLB: Stochastic Gradient Langevin Boosting",
    "abstract": "SGLB: Stochastic Gradient Langevin Boosting",
    "descriptor": "",
    "authors": [
      "Aleksei Ustimenko",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.07248"
  },
  {
    "id": "arXiv:2001.08603",
    "title": "Learning Distributional Programs for Relational Autocompletion",
    "abstract": "Learning Distributional Programs for Relational Autocompletion",
    "descriptor": "",
    "authors": [
      "Kumar Nitesh",
      "Kuzelka Ondrej",
      "De Raedt Luc"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2001.08603"
  },
  {
    "id": "arXiv:2002.00113",
    "title": "Better Compression with Deep Pre-Editing",
    "abstract": "Better Compression with Deep Pre-Editing",
    "descriptor": "",
    "authors": [
      "Hossein Talebi",
      "Damien Kelly",
      "Xiyang Luo",
      "Ignacio Garcia Dorado",
      "Feng Yang",
      "Peyman Milanfar",
      "Michael Elad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2002.00113"
  },
  {
    "id": "arXiv:2002.00291",
    "title": "Oracle Lower Bounds for Stochastic Gradient Sampling Algorithms",
    "abstract": "Comments: 21 pages; accepted for publication at Bernoulli",
    "descriptor": "\nComments: 21 pages; accepted for publication at Bernoulli\n",
    "authors": [
      "Niladri S. Chatterji",
      "Peter L. Bartlett",
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2002.00291"
  },
  {
    "id": "arXiv:2002.09650",
    "title": "Learning Cost Functions for Optimal Transport",
    "abstract": "Learning Cost Functions for Optimal Transport",
    "descriptor": "",
    "authors": [
      "Shaojun Ma",
      "Haodong Sun",
      "Xiaojing Ye",
      "Hongyuan Zha",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.09650"
  },
  {
    "id": "arXiv:2003.07238",
    "title": "A Rotation-Invariant Framework for Deep Point Cloud Analysis",
    "abstract": "A Rotation-Invariant Framework for Deep Point Cloud Analysis",
    "descriptor": "",
    "authors": [
      "Xianzhi Li",
      "Ruihui Li",
      "Guangyong Chen",
      "Chi-Wing Fu",
      "Daniel Cohen-Or",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.07238"
  },
  {
    "id": "arXiv:2004.00124",
    "title": "Axiomatizing Hybrid XPath with Data",
    "abstract": "Axiomatizing Hybrid XPath with Data",
    "descriptor": "",
    "authors": [
      "Carlos Areces",
      "Raul Fervari"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.00124"
  },
  {
    "id": "arXiv:2004.01274",
    "title": "Does Comma Selection Help To Cope With Local Optima",
    "abstract": "Comments: 36 pages. Full version of a paper that appeared at GECCO 2020",
    "descriptor": "\nComments: 36 pages. Full version of a paper that appeared at GECCO 2020\n",
    "authors": [
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.01274"
  },
  {
    "id": "arXiv:2004.02837",
    "title": "Near-linear convergence of the Random Osborne algorithm for Matrix  Balancing",
    "abstract": "Comments: v2: Fixed minor typos. Modified title for clarity. Corrected statement of Thm 6.1; this does not affect our main results",
    "descriptor": "\nComments: v2: Fixed minor typos. Modified title for clarity. Corrected statement of Thm 6.1; this does not affect our main results\n",
    "authors": [
      "Jason M. Altschuler",
      "Pablo A. Parrilo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.02837"
  },
  {
    "id": "arXiv:2005.03572",
    "title": "Enhancing Geometric Factors in Model Learning and Inference for Object  Detection and Instance Segmentation",
    "abstract": "Comments: This work has been accepted to IEEE Transactions on Cybernetics. The source codes are available at this https URL",
    "descriptor": "\nComments: This work has been accepted to IEEE Transactions on Cybernetics. The source codes are available at this https URL\n",
    "authors": [
      "Zhaohui Zheng",
      "Ping Wang",
      "Dongwei Ren",
      "Wei Liu",
      "Rongguang Ye",
      "Qinghua Hu",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.03572"
  },
  {
    "id": "arXiv:2005.07448",
    "title": "Sobolev Gradients for the M\u00f6bius Energy",
    "abstract": "Comments: 44 pages, 7 figures",
    "descriptor": "\nComments: 44 pages, 7 figures\n",
    "authors": [
      "Philipp Reiter",
      "Henrik Schumacher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2005.07448"
  },
  {
    "id": "arXiv:2005.08081",
    "title": "Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Fenglin Liu",
      "Xuancheng Ren",
      "Guangxiang Zhao",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.08081"
  },
  {
    "id": "arXiv:2005.09310",
    "title": "Distilling Knowledge from Ensembles of Acoustic Models for Joint  CTC-Attention End-to-End Speech Recognition",
    "abstract": "Distilling Knowledge from Ensembles of Acoustic Models for Joint  CTC-Attention End-to-End Speech Recognition",
    "descriptor": "",
    "authors": [
      "Yan Gao",
      "Titouan Parcollet",
      "Nicholas Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.09310"
  },
  {
    "id": "arXiv:2005.10190",
    "title": "Feature Purification: How Adversarial Training Performs Robust Deep  Learning",
    "abstract": "Comments: v2 and V3 polish writing and experiments",
    "descriptor": "\nComments: v2 and V3 polish writing and experiments\n",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.10190"
  },
  {
    "id": "arXiv:2005.10435",
    "title": "Optimal Distributed Subsampling for Maximum Quasi-Likelihood Estimators  with Massive Data",
    "abstract": "Optimal Distributed Subsampling for Maximum Quasi-Likelihood Estimators  with Massive Data",
    "descriptor": "",
    "authors": [
      "Jun Yu",
      "HaiYing Wang",
      "Mingyao Ai",
      "Huiming Zhang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.10435"
  },
  {
    "id": "arXiv:2005.10696",
    "title": "Novel Policy Seeking with Constrained Optimization",
    "abstract": "Novel Policy Seeking with Constrained Optimization",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Zhenghao Peng",
      "Bo Dai",
      "Jian Guo",
      "Dahua Lin",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.10696"
  },
  {
    "id": "arXiv:2006.00492",
    "title": "BiERU: Bidirectional Emotional Recurrent Unit for Conversational  Sentiment Analysis",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Wei Li",
      "Wei Shao",
      "Shaoxiong Ji",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.00492"
  },
  {
    "id": "arXiv:2006.05900",
    "title": "All Local Minima are Global for Two-Layer ReLU Neural Networks: The  Hidden Convex Optimization Landscape",
    "abstract": "All Local Minima are Global for Two-Layer ReLU Neural Networks: The  Hidden Convex Optimization Landscape",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Jonathan Lacotte",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05900"
  },
  {
    "id": "arXiv:2006.06067",
    "title": "Treewidth versus clique number. I. Graph classes with a forbidden  structure",
    "abstract": "Treewidth versus clique number. I. Graph classes with a forbidden  structure",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Martin Milani\u010d",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.06067"
  },
  {
    "id": "arXiv:2006.06600",
    "title": "Zeroth-Order Supervised Policy Improvement",
    "abstract": "Zeroth-Order Supervised Policy Improvement",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Ziping Xu",
      "Yuhang Song",
      "Meng Fang",
      "Jiechao Xiong",
      "Bo Dai",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06600"
  },
  {
    "id": "arXiv:2006.07796",
    "title": "Structure by Architecture: Disentangled Representations without  Regularization",
    "abstract": "Comments: Under review at NeurIPS 2021",
    "descriptor": "\nComments: Under review at NeurIPS 2021\n",
    "authors": [
      "Felix Leeb",
      "Guilia Lanzillotta",
      "Yashas Annadani",
      "Michel Besserve",
      "Stefan Bauer",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07796"
  },
  {
    "id": "arXiv:2006.09252",
    "title": "Improving Graph Neural Network Expressivity via Subgraph Isomorphism  Counting",
    "abstract": "Improving Graph Neural Network Expressivity via Subgraph Isomorphism  Counting",
    "descriptor": "",
    "authors": [
      "Giorgos Bouritsas",
      "Fabrizio Frasca",
      "Stefanos Zafeiriou",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09252"
  },
  {
    "id": "arXiv:2006.10621",
    "title": "On the Predictability of Pruning Across Scales",
    "abstract": "On the Predictability of Pruning Across Scales",
    "descriptor": "",
    "authors": [
      "Jonathan S. Rosenfeld",
      "Jonathan Frankle",
      "Michael Carbin",
      "Nir Shavit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10621"
  },
  {
    "id": "arXiv:2006.11918",
    "title": "MaxVA: Fast Adaptation of Step Sizes by Maximizing Observed Variance of  Gradients",
    "abstract": "Comments: ECML PKDD 2021",
    "descriptor": "\nComments: ECML PKDD 2021\n",
    "authors": [
      "Chen Zhu",
      "Yu Cheng",
      "Zhe Gan",
      "Furong Huang",
      "Jingjing Liu",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.11918"
  },
  {
    "id": "arXiv:2006.12655",
    "title": "Perceptual Adversarial Robustness: Defense Against Unseen Threat Models",
    "abstract": "Comments: Published in ICLR 2021. Code and data are available at this https URL",
    "descriptor": "\nComments: Published in ICLR 2021. Code and data are available at this https URL\n",
    "authors": [
      "Cassidy Laidlaw",
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12655"
  },
  {
    "id": "arXiv:2006.15714",
    "title": "Active Finite Reward Automaton Inference and Reinforcement Learning  Using Queries and Counterexamples",
    "abstract": "Active Finite Reward Automaton Inference and Reinforcement Learning  Using Queries and Counterexamples",
    "descriptor": "",
    "authors": [
      "Zhe Xu",
      "Bo Wu",
      "Aditya Ojha",
      "Daniel Neider",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2006.15714"
  },
  {
    "id": "arXiv:2006.16161",
    "title": "A Two-step Surface-based 3D Deep Learning Pipeline for Segmentation of  Intracranial Aneurysms",
    "abstract": "Comments: It is a pre-released version",
    "descriptor": "\nComments: It is a pre-released version\n",
    "authors": [
      "Xi Yang",
      "Ding Xia",
      "Taichi Kin",
      "Takeo Igarashi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.16161"
  },
  {
    "id": "arXiv:2006.16785",
    "title": "Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial  Imitation Learning",
    "abstract": "Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial  Imitation Learning",
    "descriptor": "",
    "authors": [
      "Lionel Blond\u00e9",
      "Pablo Strasser",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2006.16785"
  },
  {
    "id": "arXiv:2006.16818",
    "title": "Coded Caching for Broadcast Networks with User Cooperation",
    "abstract": "Comments: 43 pages, 5 figures",
    "descriptor": "\nComments: 43 pages, 5 figures\n",
    "authors": [
      "Jiahui Chen",
      "Xiaowen You",
      "Youlong Wu",
      "Shuai Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2006.16818"
  },
  {
    "id": "arXiv:2007.00451",
    "title": "Improvement on Extrapolation of Species Abundance Distribution Across  Scales from Moments Across Scales",
    "abstract": "Comments: This work is done within 2017-2019. On the date of publishing on ArXiv, Saeid Alirezazadeh is with C4 - Cloud Computing Competence Centre (C4-UBI), Universidade da Beira Interior, Covilh\\~{a}, Portugal, and Khadijeh Alibabaei is with C-MAST Center for Mechanical and Aerospace Science and Technologies, University of Beira Interior, Covilh\\~{a}, Portugal",
    "descriptor": "\nComments: This work is done within 2017-2019. On the date of publishing on ArXiv, Saeid Alirezazadeh is with C4 - Cloud Computing Competence Centre (C4-UBI), Universidade da Beira Interior, Covilh\\~{a}, Portugal, and Khadijeh Alibabaei is with C-MAST Center for Mechanical and Aerospace Science and Technologies, University of Beira Interior, Covilh\\~{a}, Portugal\n",
    "authors": [
      "Saeid Alirezazadeh",
      "Khadijeh Alibabaei"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2007.00451"
  },
  {
    "id": "arXiv:2007.01099",
    "title": "Reinforcement Learning and its Connections with Neuroscience and  Psychology",
    "abstract": "Comments: Preprint submitted to Elsevier Neural Networks; 60 pages, 6 figures, 1 table",
    "descriptor": "\nComments: Preprint submitted to Elsevier Neural Networks; 60 pages, 6 figures, 1 table\n",
    "authors": [
      "Ajay Subramanian",
      "Sharad Chitlangia",
      "Veeky Baths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.01099"
  },
  {
    "id": "arXiv:2007.03727",
    "title": "TripMD: Driving patterns investigation via Motif Analysis",
    "abstract": "Comments: 14 pages, 11 figures, to be published in Expert Systems with Applications",
    "descriptor": "\nComments: 14 pages, 11 figures, to be published in Expert Systems with Applications\n",
    "authors": [
      "Maria In\u00eas Silva",
      "Roberto Henriques"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2007.03727"
  },
  {
    "id": "arXiv:2007.04698",
    "title": "Cycle Extendability of Hamiltonian Strongly Chordal Graphs",
    "abstract": "Comments: 14 pages, 6 figures. [v3]: To appear in SIDMA",
    "descriptor": "\nComments: 14 pages, 6 figures. [v3]: To appear in SIDMA\n",
    "authors": [
      "Guozhen Rong",
      "Wenjun Li",
      "Jianxin Wang",
      "Yongjie Yang"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.04698"
  },
  {
    "id": "arXiv:2007.08243",
    "title": "Lottery Tickets in Linear Models: An Analysis of Iterative Magnitude  Pruning",
    "abstract": "Comments: Updated for Sparsity in Neural Networks Workshop",
    "descriptor": "\nComments: Updated for Sparsity in Neural Networks Workshop\n",
    "authors": [
      "Bryn Elesedy",
      "Varun Kanade",
      "Yee Whye Teh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.08243"
  },
  {
    "id": "arXiv:2007.08864",
    "title": "Sparse Linear Networks with a Fixed Butterfly Structure: Theory and  Practice",
    "abstract": "Comments: Accepted to UAI 2021",
    "descriptor": "\nComments: Accepted to UAI 2021\n",
    "authors": [
      "Nir Ailon",
      "Omer Leibovich",
      "Vineet Nair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.08864"
  },
  {
    "id": "arXiv:2007.14209",
    "title": "Langevin Monte Carlo: random coordinate descent and variance reduction",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.06068",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.06068\n",
    "authors": [
      "Zhiyan Ding",
      "Qin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.14209"
  },
  {
    "id": "arXiv:2008.00268",
    "title": "Big Ramsey degrees of 3-uniform hypergraphs are finite",
    "abstract": "Comments: 10 pages, 2 figures. Minor corrections and presentation improvements suggested by the referees",
    "descriptor": "\nComments: 10 pages, 2 figures. Minor corrections and presentation improvements suggested by the referees\n",
    "authors": [
      "Martin Balko",
      "David Chodounsk\u00fd",
      "Jan Hubi\u010dka",
      "Mat\u011bj Kone\u010dn\u00fd",
      "Lluis Vena"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.00268"
  },
  {
    "id": "arXiv:2008.00460",
    "title": "Joint Object Contour Points and Semantics for Instance Segmentation",
    "abstract": "Joint Object Contour Points and Semantics for Instance Segmentation",
    "descriptor": "",
    "authors": [
      "Wenchao Zhang",
      "Chong Fu",
      "Mai Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.00460"
  },
  {
    "id": "arXiv:2008.01393",
    "title": "Neural Granular Sound Synthesis",
    "abstract": "Comments: presented for ICMC 2021 (2020 postponed)",
    "descriptor": "\nComments: presented for ICMC 2021 (2020 postponed)\n",
    "authors": [
      "Adrien Bitton",
      "Philippe Esling",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2008.01393"
  },
  {
    "id": "arXiv:2008.10208",
    "title": "Multi-view Graph Learning by Joint Modeling of Consistency and  Inconsistency",
    "abstract": "Comments: Preprint, under review",
    "descriptor": "\nComments: Preprint, under review\n",
    "authors": [
      "Youwei Liang",
      "Dong Huang",
      "Chang-Dong Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.10208"
  },
  {
    "id": "arXiv:2008.13491",
    "title": "Semipaired Domination in Some Subclasses of Chordal Graphs",
    "abstract": "Semipaired Domination in Some Subclasses of Chordal Graphs",
    "descriptor": "",
    "authors": [
      "Michael A. Henning",
      "Arti Pandey",
      "Vikash Tripathi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2008.13491"
  },
  {
    "id": "arXiv:2008.13578",
    "title": "Against Membership Inference Attack: Pruning is All You Need",
    "abstract": "Comments: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)",
    "descriptor": "\nComments: Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)\n",
    "authors": [
      "Yijue Wang",
      "Chenghong Wang",
      "Zigeng Wang",
      "Shanglin Zhou",
      "Hang Liu",
      "Jinbo Bi",
      "Caiwen Ding",
      "Sanguthevar Rajasekaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.13578"
  },
  {
    "id": "arXiv:2009.03228",
    "title": "Information Theoretic Meta Learning with Gaussian Processes",
    "abstract": "Comments: 15 pages, 2 figures",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Michalis K. Titsias",
      "Francisco J. R. Ruiz",
      "Sotirios Nikoloutsopoulos",
      "Alexandre Galashov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03228"
  },
  {
    "id": "arXiv:2009.03671",
    "title": "A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D  Skeleton Based Person Re-Identification",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). Journal version of this https URL (IJCAI 2020). Codes are available at this https URL arXiv admin note: text overlap with arXiv:2008.09435",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). Journal version of this https URL (IJCAI 2020). Codes are available at this https URL arXiv admin note: text overlap with arXiv:2008.09435\n",
    "authors": [
      "Haocong Rao",
      "Siqi Wang",
      "Xiping Hu",
      "Mingkui Tan",
      "Yi Guo",
      "Jun Cheng",
      "Xinwang Liu",
      "Bin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.03671"
  },
  {
    "id": "arXiv:2009.06725",
    "title": "A scalable spectral Stokes solver for simulation of time-periodic flows  in complex geometries",
    "abstract": "A scalable spectral Stokes solver for simulation of time-periodic flows  in complex geometries",
    "descriptor": "",
    "authors": [
      "Chenwei Meng",
      "Anirban Bhattacharjee",
      "Mahdi Esmaily"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2009.06725"
  },
  {
    "id": "arXiv:2009.08416",
    "title": "Near-Optimal Decremental Hopsets with Applications",
    "abstract": "Near-Optimal Decremental Hopsets with Applications",
    "descriptor": "",
    "authors": [
      "Jakub \u0141\u0105cki",
      "Yasamin Nazari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.08416"
  },
  {
    "id": "arXiv:2009.14715",
    "title": "Learning Rewards from Linguistic Feedback",
    "abstract": "Comments: 9 pages, 4 figures. AAAI '21",
    "descriptor": "\nComments: 9 pages, 4 figures. AAAI '21\n",
    "authors": [
      "Theodore R. Sumers",
      "Mark K. Ho",
      "Robert D. Hawkins",
      "Karthik Narasimhan",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.14715"
  },
  {
    "id": "arXiv:2010.00143",
    "title": "Opinion dynamics on tie-decay networks",
    "abstract": "Comments: 15 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 15 pages, 8 figures, 2 tables\n",
    "authors": [
      "Kashin Sugishita",
      "Mason A. Porter",
      "Mariano Beguerisse-D\u00edaz",
      "Naoki Masuda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.00143"
  },
  {
    "id": "arXiv:2010.00378",
    "title": "GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for  Identifying COVID-19 on Chest X-rays",
    "abstract": "GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for  Identifying COVID-19 on Chest X-rays",
    "descriptor": "",
    "authors": [
      "Angelica I Aviles-Rivero",
      "Philip Sellars",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Nicolas Papadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00378"
  },
  {
    "id": "arXiv:2010.01592",
    "title": "Unknown Presentation Attack Detection against Rational Attackers",
    "abstract": "Unknown Presentation Attack Detection against Rational Attackers",
    "descriptor": "",
    "authors": [
      "Ali Khodabakhsh",
      "Zahid Akhtar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.01592"
  },
  {
    "id": "arXiv:2010.02358",
    "title": "VisualWordGrid: Information Extraction From Scanned Documents Using A  Multimodal Approach",
    "abstract": "VisualWordGrid: Information Extraction From Scanned Documents Using A  Multimodal Approach",
    "descriptor": "",
    "authors": [
      "Mohamed Kerroumi",
      "Othmane Sayem",
      "Aymen Shabou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.02358"
  },
  {
    "id": "arXiv:2010.04389",
    "title": "A Survey of Knowledge-Enhanced Text Generation",
    "abstract": "Comments: 42 pages, 12 tables, 8 figures; Under review at ACM CSUR (revised manuscript)",
    "descriptor": "\nComments: 42 pages, 12 tables, 8 figures; Under review at ACM CSUR (revised manuscript)\n",
    "authors": [
      "Wenhao Yu",
      "Chenguang Zhu",
      "Zaitang Li",
      "Zhiting Hu",
      "Qingyun Wang",
      "Heng Ji",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.04389"
  },
  {
    "id": "arXiv:2010.07541",
    "title": "Byzantine-Resilient Federated Learning with Heterogeneous Data  Distribution",
    "abstract": "Byzantine-Resilient Federated Learning with Heterogeneous Data  Distribution",
    "descriptor": "",
    "authors": [
      "Saurav Prakash",
      "Hanieh Hashemi",
      "Yongqin Wang",
      "Murali Annavaram",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.07541"
  },
  {
    "id": "arXiv:2010.08707",
    "title": "Constrained Motion Planning Networks X",
    "abstract": "Comments: This is preprint version of a paper published in IEEE Transactions on Robotics. The videos, code, dataset and trained models can be found here: this https URL",
    "descriptor": "\nComments: This is preprint version of a paper published in IEEE Transactions on Robotics. The videos, code, dataset and trained models can be found here: this https URL\n",
    "authors": [
      "Ahmed H. Qureshi",
      "Jiangeng Dong",
      "Asfiya Baig",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2010.08707"
  },
  {
    "id": "arXiv:2010.11880",
    "title": "Fast Approximate CoSimRanks via Random Projections",
    "abstract": "Comments: Some mistakes in the papers",
    "descriptor": "\nComments: Some mistakes in the papers\n",
    "authors": [
      "Renchi Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.11880"
  },
  {
    "id": "arXiv:2010.13991",
    "title": "Speech SIMCLR: Combining Contrastive and Reconstruction Objective for  Self-supervised Speech Representation Learning",
    "abstract": "Speech SIMCLR: Combining Contrastive and Reconstruction Objective for  Self-supervised Speech Representation Learning",
    "descriptor": "",
    "authors": [
      "Dongwei Jiang",
      "Wubo Li",
      "Miao Cao",
      "Wei Zou",
      "Xiangang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.13991"
  },
  {
    "id": "arXiv:2010.14531",
    "title": "Assessing Viewpoint Diversity in Search Results Using Ranking Fairness  Metrics",
    "abstract": "Assessing Viewpoint Diversity in Search Results Using Ranking Fairness  Metrics",
    "descriptor": "",
    "authors": [
      "Tim Draws",
      "Nava Tintarev",
      "Ujwal Gadiraju",
      "Alessandro Bozzon",
      "Benjamin Timmermans"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.14531"
  },
  {
    "id": "arXiv:2010.14672",
    "title": "How Does the Task Landscape Affect MAML Performance?",
    "abstract": "How Does the Task Landscape Affect MAML Performance?",
    "descriptor": "",
    "authors": [
      "Liam Collins",
      "Aryan Mokhtari",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.14672"
  },
  {
    "id": "arXiv:2010.14995",
    "title": "Accelerated Probabilistic Power Flow in Electrical Distribution Networks  via Model Order Reduction and Neumann Series Expansion",
    "abstract": "Accelerated Probabilistic Power Flow in Electrical Distribution Networks  via Model Order Reduction and Neumann Series Expansion",
    "descriptor": "",
    "authors": [
      "Samuel Chevalier",
      "Luca Schenato",
      "Luca Daniel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.14995"
  },
  {
    "id": "arXiv:2011.01777",
    "title": "Near-Optimal Entrywise Sampling of Numerically Sparse Matrices",
    "abstract": "Comments: 20 pages. To appear in COLT 2021",
    "descriptor": "\nComments: 20 pages. To appear in COLT 2021\n",
    "authors": [
      "Vladimir Braverman",
      "Robert Krauthgamer",
      "Aditya Krishnan",
      "Shay Sapir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.01777"
  },
  {
    "id": "arXiv:2011.03148",
    "title": "RetinaGAN: An Object-aware Approach to Sim-to-Real Transfer",
    "abstract": "Comments: International Conference on Robotics and Automation (ICRA) 2021",
    "descriptor": "\nComments: International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Daniel Ho",
      "Kanishka Rao",
      "Zhuo Xu",
      "Eric Jang",
      "Mohi Khansari",
      "Yunfei Bai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.03148"
  },
  {
    "id": "arXiv:2011.03495",
    "title": "Semi-Streaming Bipartite Matching in Fewer Passes and Optimal Space",
    "abstract": "Semi-Streaming Bipartite Matching in Fewer Passes and Optimal Space",
    "descriptor": "",
    "authors": [
      "Sepehr Assadi",
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.03495"
  },
  {
    "id": "arXiv:2011.04246",
    "title": "EVA-Planner: Environmental Adaptive Quadrotor Planning",
    "abstract": "Comments: IEEE International Conference on Robotics and Automation (ICRA 2021)",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA 2021)\n",
    "authors": [
      "Lun Quan",
      "Zhiwei Zhang",
      "Xingguang Zhong",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.04246"
  },
  {
    "id": "arXiv:2011.07006",
    "title": "Federated Multi-Mini-Batch: An Efficient Training Approach to Federated  Learning in Non-IID Environments",
    "abstract": "Federated Multi-Mini-Batch: An Efficient Training Approach to Federated  Learning in Non-IID Environments",
    "descriptor": "",
    "authors": [
      "Reza Nasirigerdeh",
      "Mohammad Bakhtiari",
      "Reihaneh Torkzadehmahani",
      "Amirhossein Bayat",
      "Markus List",
      "David B. Blumenthal",
      "Jan Baumbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.07006"
  },
  {
    "id": "arXiv:2011.07410",
    "title": "Robust and Efficient Multilevel-ILU Preconditioning of Hybrid  Newton-GMRES for Incompressible Navier-Stokes Equations",
    "abstract": "Comments: Submitted to International Journal for Numerical Methods in Fluids",
    "descriptor": "\nComments: Submitted to International Journal for Numerical Methods in Fluids\n",
    "authors": [
      "Qiao Chen",
      "Xiangmin Jiao",
      "Oliver Yang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2011.07410"
  },
  {
    "id": "arXiv:2011.08933",
    "title": "The Alternating Direction Method of Multipliers for Finding the Distance  between Ellipsoids",
    "abstract": "Comments: Multiple mistakes and typos were corrected in the second and third versions. In particular, erroneous Proposition 1 was replaced by Lemma 1",
    "descriptor": "\nComments: Multiple mistakes and typos were corrected in the second and third versions. In particular, erroneous Proposition 1 was replaced by Lemma 1\n",
    "authors": [
      "M.V. Dolgopolik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.08933"
  },
  {
    "id": "arXiv:2011.12783",
    "title": "General Purpose Atomic Crosschain Transactions",
    "abstract": "Comments: 9 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2005.09790",
    "descriptor": "\nComments: 9 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2005.09790\n",
    "authors": [
      "Peter Robinson",
      "Raghavendra Ramesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.12783"
  },
  {
    "id": "arXiv:2011.13248",
    "title": "Disjoint Stable Matchings in Linear Time",
    "abstract": "Comments: Conference: International Workshop on Graph-Theoretic Concepts in Computer Science 2021 (this https URL)",
    "descriptor": "\nComments: Conference: International Workshop on Graph-Theoretic Concepts in Computer Science 2021 (this https URL)\n",
    "authors": [
      "Aadityan Ganesh",
      "Vishwa Prakash HV",
      "Prajakta Nimbhorkar",
      "Geevarghese Philip"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.13248"
  },
  {
    "id": "arXiv:2011.13485",
    "title": "Near-linear-time, Optimal Vertex Cut Sparsifiers in Directed Acyclic  Graphs",
    "abstract": "Near-linear-time, Optimal Vertex Cut Sparsifiers in Directed Acyclic  Graphs",
    "descriptor": "",
    "authors": [
      "Zhiyang He",
      "Jason Li",
      "Magnus Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.13485"
  },
  {
    "id": "arXiv:2011.13662",
    "title": "FFCI: A Framework for Interpretable Automatic Evaluation of  Summarization",
    "abstract": "Comments: Under review for the Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: Under review for the Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Fajri Koto",
      "Timothy Baldwin",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.13662"
  },
  {
    "id": "arXiv:2012.00779",
    "title": "Dynamic Feature Pyramid Networks for Object Detection",
    "abstract": "Dynamic Feature Pyramid Networks for Object Detection",
    "descriptor": "",
    "authors": [
      "Mingjian Zhu",
      "Kai Han",
      "Changbin Yu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.00779"
  },
  {
    "id": "arXiv:2012.01880",
    "title": "On Parameterized Complexity of Binary Networked Public Goods Game",
    "abstract": "Comments: 25 pages, 1 figure",
    "descriptor": "\nComments: 25 pages, 1 figure\n",
    "authors": [
      "Arnab Maiti",
      "Palash Dey"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.01880"
  },
  {
    "id": "arXiv:2012.02130",
    "title": "A similarity-based Bayesian mixture-of-experts model",
    "abstract": "A similarity-based Bayesian mixture-of-experts model",
    "descriptor": "",
    "authors": [
      "Tianfang Zhang",
      "Rasmus Bokrantz",
      "Jimmy Olsson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2012.02130"
  },
  {
    "id": "arXiv:2012.03292",
    "title": "FedSiam: Towards Adaptive Federated Semi-Supervised Learning",
    "abstract": "FedSiam: Towards Adaptive Federated Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Zewei Long",
      "Liwei Che",
      "Yaqing Wang",
      "Muchao Ye",
      "Junyu Luo",
      "Jinze Wu",
      "Houping Xiao",
      "Fenglong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03292"
  },
  {
    "id": "arXiv:2012.03910",
    "title": "Conformance Relations and Hyperproperties for Doping Detection in Time  and Space",
    "abstract": "Conformance Relations and Hyperproperties for Doping Detection in Time  and Space",
    "descriptor": "",
    "authors": [
      "Sebastian Biewer",
      "Rayna Dimitrova",
      "Michael Fries",
      "Maciej Gazda",
      "Thomas Heinze",
      "Holger Hermanns",
      "Mohammad Reza Mousavi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.03910"
  },
  {
    "id": "arXiv:2012.06062",
    "title": "Faster Deterministic Modular Subset Sum",
    "abstract": "Comments: 16 pages, accepted at ESA 2021",
    "descriptor": "\nComments: 16 pages, accepted at ESA 2021\n",
    "authors": [
      "Krzysztof Pot\u0119pa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.06062"
  },
  {
    "id": "arXiv:2012.06188",
    "title": "Recent Theoretical Advances in Non-Convex Optimization",
    "abstract": "Comments: 79 pages",
    "descriptor": "\nComments: 79 pages\n",
    "authors": [
      "Marina Danilova",
      "Pavel Dvurechensky",
      "Alexander Gasnikov",
      "Eduard Gorbunov",
      "Sergey Guminov",
      "Dmitry Kamzolov",
      "Innokentiy Shibaev"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.06188"
  },
  {
    "id": "arXiv:2012.06244",
    "title": "The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous  Neural Networks",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Bohan Wang",
      "Qi Meng",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.06244"
  },
  {
    "id": "arXiv:2012.06279",
    "title": "Autoencoding Slow Representations for Semi-supervised Data Efficient  Regression",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Oliver Struckmeier",
      "Kshitij Tiwari",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.06279"
  },
  {
    "id": "arXiv:2012.06702",
    "title": "Lions and contamination, triangular grids, and Cheeger constants",
    "abstract": "Lions and contamination, triangular grids, and Cheeger constants",
    "descriptor": "",
    "authors": [
      "Henry Adams",
      "Leah Gibson",
      "Jack Pfaffinger"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.06702"
  },
  {
    "id": "arXiv:2012.07176",
    "title": "Extended Few-Shot Learning: Exploiting Existing Resources for Novel  Tasks",
    "abstract": "Comments: Added the new version",
    "descriptor": "\nComments: Added the new version\n",
    "authors": [
      "Reza Esfandiarpoor",
      "Amy Pu",
      "Mohsen Hajabdollahi",
      "Stephen H. Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.07176"
  },
  {
    "id": "arXiv:2012.08849",
    "title": "Affective visualization in Virtual Reality: An integrative review",
    "abstract": "Affective visualization in Virtual Reality: An integrative review",
    "descriptor": "",
    "authors": [
      "Andres Pinilla",
      "Jaime Garcia",
      "William Raffe",
      "Jan-Niklas Voigt-Antons",
      "Robert Spang",
      "Sebastian M\u00f6ller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2012.08849"
  },
  {
    "id": "arXiv:2012.09816",
    "title": "Towards Understanding Ensemble, Knowledge Distillation and  Self-Distillation in Deep Learning",
    "abstract": "Comments: v2 polishes writing",
    "descriptor": "\nComments: v2 polishes writing\n",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.09816"
  },
  {
    "id": "arXiv:2012.10033",
    "title": "Exploring Fluent Query Reformulations with Text-to-Text Transformers and  Reinforcement Learning",
    "abstract": "Comments: Workshop on the 9th Dialog System Technology Challenge (DSTC-9), AAAI 2021",
    "descriptor": "\nComments: Workshop on the 9th Dialog System Technology Challenge (DSTC-9), AAAI 2021\n",
    "authors": [
      "Jerry Zikun Chen",
      "Shi Yu",
      "Haoran Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.10033"
  },
  {
    "id": "arXiv:2012.11245",
    "title": "Bounded Model Checking of Software Using Interval Methods via  Contractors",
    "abstract": "Bounded Model Checking of Software Using Interval Methods via  Contractors",
    "descriptor": "",
    "authors": [
      "Mohannad Aldughaim",
      "Kaled Alshmrany",
      "Mohamed Mustafa",
      "Lucas Cordeiro",
      "Alexandru Stancu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.11245"
  },
  {
    "id": "arXiv:2012.12561",
    "title": "GANDA: A deep generative adversarial network predicts the spatial  distribution of nanoparticles in tumor pixelly",
    "abstract": "Comments: 28 pages, 17 figures, 3 tables",
    "descriptor": "\nComments: 28 pages, 17 figures, 3 tables\n",
    "authors": [
      "Jiulou Zhang",
      "Yuxia Tang",
      "Shouju Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.12561"
  },
  {
    "id": "arXiv:2012.13739",
    "title": "Transience in Countable MDPs",
    "abstract": "Transience in Countable MDPs",
    "descriptor": "",
    "authors": [
      "Stefan Kiefer",
      "Richard Mayr",
      "Mahsa Shirmohammadi",
      "Patrick Totzke"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.13739"
  },
  {
    "id": "arXiv:2101.00376",
    "title": "RiddleSense: Reasoning about Riddle Questions Featuring Linguistic  Creativity and Commonsense Knowledge",
    "abstract": "Comments: Accepted to ACL 2021 (Findings). Project page: this https URL",
    "descriptor": "\nComments: Accepted to ACL 2021 (Findings). Project page: this https URL\n",
    "authors": [
      "Bill Yuchen Lin",
      "Ziyi Wu",
      "Yichi Yang",
      "Dong-Ho Lee",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.00376"
  },
  {
    "id": "arXiv:2101.01543",
    "title": "Noise Sensitivity-Based Energy Efficient and Robust Adversary Detection  in Neural Networks",
    "abstract": "Comments: Accepted in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2021",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2021\n",
    "authors": [
      "Rachel Sterneck",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.01543"
  },
  {
    "id": "arXiv:2101.02931",
    "title": "Block-Term Tensor Decomposition Model Selection and Computation: The  Bayesian Way",
    "abstract": "Block-Term Tensor Decomposition Model Selection and Computation: The  Bayesian Way",
    "descriptor": "",
    "authors": [
      "Paris V. Giampouras",
      "Athanasios A. Rontogiannis",
      "Eleftherios Kofidis"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.02931"
  },
  {
    "id": "arXiv:2101.05235",
    "title": "Space-Efficient Algorithms for Reachability in Geometric Graphs",
    "abstract": "Space-Efficient Algorithms for Reachability in Geometric Graphs",
    "descriptor": "",
    "authors": [
      "Sujoy Bhore",
      "Rahul Jain"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2101.05235"
  },
  {
    "id": "arXiv:2101.07608",
    "title": "Game values of arithmetic functions",
    "abstract": "Comments: 20 pages, 4 figures",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Douglas E. Iannucci",
      "Urban Larsson"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.07608"
  },
  {
    "id": "arXiv:2101.08629",
    "title": "Image-to-Image Translation: Methods and Applications",
    "abstract": "Comments: 24 pages, 21 figures",
    "descriptor": "\nComments: 24 pages, 21 figures\n",
    "authors": [
      "Yingxue Pang",
      "Jianxin Lin",
      "Tao Qin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08629"
  },
  {
    "id": "arXiv:2101.11897",
    "title": "Deep ReLU Network Expression Rates for Option Prices in  high-dimensional, exponential L\u00e9vy models",
    "abstract": "Deep ReLU Network Expression Rates for Option Prices in  high-dimensional, exponential L\u00e9vy models",
    "descriptor": "",
    "authors": [
      "Lukas Gonon",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2101.11897"
  },
  {
    "id": "arXiv:2101.12715",
    "title": "Disparate Impact Diminishes Consumer Trust Even for Advantaged Users",
    "abstract": "Disparate Impact Diminishes Consumer Trust Even for Advantaged Users",
    "descriptor": "",
    "authors": [
      "Tim Draws",
      "Zolt\u00e1n Szl\u00e1vik",
      "Benjamin Timmermans",
      "Nava Tintarev",
      "Kush R. Varshney",
      "Michael Hind"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.12715"
  },
  {
    "id": "arXiv:2102.00378",
    "title": "Model-Based Testing of Networked Applications",
    "abstract": "Comments: 11 pages, 15 figures",
    "descriptor": "\nComments: 11 pages, 15 figures\n",
    "authors": [
      "Yishuai Li",
      "Benjamin C. Pierce",
      "Steve Zdancewic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.00378"
  },
  {
    "id": "arXiv:2102.00621",
    "title": "Polyphone Disambiguition in Mandarin Chinese with Semi-Supervised  Learning",
    "abstract": "Polyphone Disambiguition in Mandarin Chinese with Semi-Supervised  Learning",
    "descriptor": "",
    "authors": [
      "Yi Shi",
      "Congyi Wang",
      "Yu Chen",
      "Bin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.00621"
  },
  {
    "id": "arXiv:2102.02410",
    "title": "A Local Convergence Theory for Mildly Over-Parameterized Two-Layer  Neural Network",
    "abstract": "Comments: Added references and fixed typos. Accepted to COLT 2021",
    "descriptor": "\nComments: Added references and fixed typos. Accepted to COLT 2021\n",
    "authors": [
      "Mo Zhou",
      "Rong Ge",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02410"
  },
  {
    "id": "arXiv:2102.06462",
    "title": "Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph  Convolutional Neural Networks",
    "abstract": "Comments: Including 8 page supplement",
    "descriptor": "\nComments: Including 8 page supplement\n",
    "authors": [
      "Yujun Yan",
      "Milad Hashemi",
      "Kevin Swersky",
      "Yaoqing Yang",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06462"
  },
  {
    "id": "arXiv:2102.06755",
    "title": "Unpacking Human Teachers' Intentions For Natural Interactive Task  Learning",
    "abstract": "Comments: 8 pages, 5 figures, paper revised for submission to conference, authors updated, to be presented at RO-MAN 2021",
    "descriptor": "\nComments: 8 pages, 5 figures, paper revised for submission to conference, authors updated, to be presented at RO-MAN 2021\n",
    "authors": [
      "Preeti Ramaraj",
      "Charles L. Ortiz, Jr.",
      "Shiwali Mohan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.06755"
  },
  {
    "id": "arXiv:2102.07845",
    "title": "MARINA: Faster Non-Convex Distributed Learning with Compression",
    "abstract": "Comments: ICML 2021; v2 contains additional experiments; 41 pages, 6 figures, 3 algorithms",
    "descriptor": "\nComments: ICML 2021; v2 contains additional experiments; 41 pages, 6 figures, 3 algorithms\n",
    "authors": [
      "Eduard Gorbunov",
      "Konstantin Burlachenko",
      "Zhize Li",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.07845"
  },
  {
    "id": "arXiv:2102.08185",
    "title": "Efficient Data Gathering and Aggregation for Multiple Applications in  Wireless Sensor Networks",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Fathima Begum M",
      "M. Abdul Naseer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08185"
  },
  {
    "id": "arXiv:2102.08201",
    "title": "Improper Reinforcement Learning with Gradient-based Policy Optimization",
    "abstract": "Improper Reinforcement Learning with Gradient-based Policy Optimization",
    "descriptor": "",
    "authors": [
      "Mohammadi Zaki",
      "Avinash Mohan",
      "Aditya Gopalan",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.08201"
  },
  {
    "id": "arXiv:2102.08474",
    "title": "Adversarially Robust Kernel Smoothing",
    "abstract": "Adversarially Robust Kernel Smoothing",
    "descriptor": "",
    "authors": [
      "Jia-Jie Zhu",
      "Christina Kouridi",
      "Yassine Nemmour",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08474"
  },
  {
    "id": "arXiv:2102.09822",
    "title": "A Higher-Order Generalized Singular Value Decomposition for Rank  Deficient Matrices",
    "abstract": "Comments: 13 pages, 2 figures",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Idris Kempf",
      "Paul J. Goulart",
      "Stephen R. Duncan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.09822"
  },
  {
    "id": "arXiv:2102.10754",
    "title": "Wallpaper group kirigami",
    "abstract": "Wallpaper group kirigami",
    "descriptor": "",
    "authors": [
      "Lucy Liu",
      "Gary P. T. Choi",
      "L. Mahadevan"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Geometry (cs.CG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.10754"
  },
  {
    "id": "arXiv:2102.11828",
    "title": "Uniform Elgot Iteration in Foundations",
    "abstract": "Comments: Full version of ICALP 2021 accepted paper",
    "descriptor": "\nComments: Full version of ICALP 2021 accepted paper\n",
    "authors": [
      "Sergey Goncharov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.11828"
  },
  {
    "id": "arXiv:2102.12010",
    "title": "PixSet : An Opportunity for 3D Computer Vision to Go Beyond Point Clouds  With a Full-Waveform LiDAR Dataset",
    "abstract": "Comments: 7 pages, 9 figures",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Jean-Luc D\u00e9ziel",
      "Pierre Merriaux",
      "Francis Tremblay",
      "Dave Lessard",
      "Dominique Plourde",
      "Julien Stanguennec",
      "Pierre Goulet",
      "Pierre Olivier"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.12010"
  },
  {
    "id": "arXiv:2102.12017",
    "title": "Annotating Motion Primitives for Simplifying Action Search in  Reinforcement Learning",
    "abstract": "Comments: Submitted to IEEE Transactions on Emerging Topics in Computational Intelligence",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Emerging Topics in Computational Intelligence\n",
    "authors": [
      "Isaac J. Sledge",
      "Darshan W. Bryner",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.12017"
  },
  {
    "id": "arXiv:2102.12304",
    "title": "Two Problems about Monomial Bent Functions",
    "abstract": "Two Problems about Monomial Bent Functions",
    "descriptor": "",
    "authors": [
      "Honggang Hu",
      "Bei Wang",
      "Xianhong Xie",
      "Yiyuan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.12304"
  },
  {
    "id": "arXiv:2102.12330",
    "title": "Re-Evaluating GermEval17 Using German Pre-Trained Language Models",
    "abstract": "Comments: Accepted as a conference paper at the 6th Swiss Text Analytics Conference (SwissText), Brugg, Switzerland (Online), June 14-16, 2021",
    "descriptor": "\nComments: Accepted as a conference paper at the 6th Swiss Text Analytics Conference (SwissText), Brugg, Switzerland (Online), June 14-16, 2021\n",
    "authors": [
      "M. A\u00dfenmacher",
      "A. Corvonato",
      "C. Heumann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12330"
  },
  {
    "id": "arXiv:2103.00112",
    "title": "Transformer in Transformer",
    "abstract": "Comments: PyTorch code is available at this https URL",
    "descriptor": "\nComments: PyTorch code is available at this https URL\n",
    "authors": [
      "Kai Han",
      "An Xiao",
      "Enhua Wu",
      "Jianyuan Guo",
      "Chunjing Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00112"
  },
  {
    "id": "arXiv:2103.01012",
    "title": "Unambiguously coded systems",
    "abstract": "Unambiguously coded systems",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Dominique Perrin",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2103.01012"
  },
  {
    "id": "arXiv:2103.01143",
    "title": "Towards 6G with Connected Sky: UAVs and Beyond",
    "abstract": "Comments: \\c{opyright}2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright}2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Mohammad Mozaffari",
      "Xingqin Lin",
      "Stephen Hayes"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.01143"
  },
  {
    "id": "arXiv:2103.03198",
    "title": "Catala: A Programming Language for the Law",
    "abstract": "Catala: A Programming Language for the Law",
    "descriptor": "",
    "authors": [
      "Denis Merigoux",
      "Nicolas Chataing",
      "Jonathan Protzenko"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.03198"
  },
  {
    "id": "arXiv:2103.03621",
    "title": "Low-latency auditory spatial attention detection based on  spectro-spatial features from EEG",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Siqi Cai",
      "Pengcheng Sun",
      "Tanja Schultz",
      "Haizhou Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.03621"
  },
  {
    "id": "arXiv:2103.04379",
    "title": "Repurposing GANs for One-shot Semantic Part Segmentation",
    "abstract": "Comments: CVPR 2021 (Oral)",
    "descriptor": "\nComments: CVPR 2021 (Oral)\n",
    "authors": [
      "Nontawat Tritrong",
      "Pitchaporn Rewatbowornwong",
      "Supasorn Suwajanakorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04379"
  },
  {
    "id": "arXiv:2103.04699",
    "title": "CUHK-EE Voice Cloning System for ICASSP 2021 M2VoC Challenge",
    "abstract": "CUHK-EE Voice Cloning System for ICASSP 2021 M2VoC Challenge",
    "descriptor": "",
    "authors": [
      "Daxin Tan",
      "Hingpang Huang",
      "Guangyan Zhang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.04699"
  },
  {
    "id": "arXiv:2103.06326",
    "title": "S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement  Learning",
    "abstract": "S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Ajay Mandlekar",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06326"
  },
  {
    "id": "arXiv:2103.11615",
    "title": "A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra  Computation",
    "abstract": "A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra  Computation",
    "descriptor": "",
    "authors": [
      "Hiromi Ishii"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Mathematical Software (cs.MS)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.11615"
  },
  {
    "id": "arXiv:2103.11811",
    "title": "MasakhaNER: Named Entity Recognition for African Languages",
    "abstract": "Comments: Accepted to TACL 2021, pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to TACL 2021, pre-MIT Press publication version\n",
    "authors": [
      "David Ifeoluwa Adelani",
      "Jade Abbott",
      "Graham Neubig",
      "Daniel D'souza",
      "Julia Kreutzer",
      "Constantine Lignos",
      "Chester Palen-Michel",
      "Happy Buzaaba",
      "Shruti Rijhwani",
      "Sebastian Ruder",
      "Stephen Mayhew",
      "Israel Abebe Azime",
      "Shamsuddeen Muhammad",
      "Chris Chinenye Emezue",
      "Joyce Nakatumba-Nabende",
      "Perez Ogayo",
      "Anuoluwapo Aremu",
      "Catherine Gitau",
      "Derguene Mbaye",
      "Jesujoba Alabi",
      "Seid Muhie Yimam",
      "Tajuddeen Gwadabe",
      "Ignatius Ezeani",
      "Rubungo Andre Niyongabo",
      "Jonathan Mukiibi",
      "Verrah Otiende",
      "Iroro Orife",
      "Davis David",
      "Samba Ngom",
      "Tosin Adewumi",
      "Paul Rayson",
      "Mofetoluwa Adeyemi",
      "Gerald Muriuki",
      "Emmanuel Anebi",
      "Chiamaka Chukwuneke",
      "Nkiruka Odu",
      "Eric Peter Wairagala",
      "Samuel Oyerinde",
      "Clemencia Siro",
      "Tobius Saul Bateesa",
      "Temilola Oloyede",
      "Yvonne Wambui",
      "Victor Akinode",
      "Deborah Nabagereka",
      "Maurice Katusiime",
      "Ayodele Awokoya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11811"
  },
  {
    "id": "arXiv:2103.12634",
    "title": "Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures",
    "abstract": "Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures",
    "descriptor": "",
    "authors": [
      "Abbas K. Rizi",
      "Ali Faqeeh",
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2103.12634"
  },
  {
    "id": "arXiv:2103.13355",
    "title": "Bag of Tricks for Node Classification with Graph Neural Networks",
    "abstract": "Bag of Tricks for Node Classification with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Yangkun Wang",
      "Jiarui Jin",
      "Weinan Zhang",
      "Yong Yu",
      "Zheng Zhang",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13355"
  },
  {
    "id": "arXiv:2103.15890",
    "title": "Learning Domain Invariant Representations for Generalizable Person  Re-Identification",
    "abstract": "Learning Domain Invariant Representations for Generalizable Person  Re-Identification",
    "descriptor": "",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zhang Zhang",
      "Da Li",
      "Zhen Jia",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15890"
  },
  {
    "id": "arXiv:2103.15990",
    "title": "An Overview of Human Activity Recognition Using Wearable Sensors:  Healthcare and Artificial Intelligence",
    "abstract": "An Overview of Human Activity Recognition Using Wearable Sensors:  Healthcare and Artificial Intelligence",
    "descriptor": "",
    "authors": [
      "Rex Liu",
      "Albara Ah Ramli",
      "Huanle Zhang",
      "Esha Datta",
      "Erik Henricson",
      "Xin Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15990"
  },
  {
    "id": "arXiv:2103.16525",
    "title": "Endo-Depth-and-Motion: Reconstruction and Tracking in Endoscopic Videos  using Depth Networks and Photometric Constraints",
    "abstract": "Endo-Depth-and-Motion: Reconstruction and Tracking in Endoscopic Videos  using Depth Networks and Photometric Constraints",
    "descriptor": "",
    "authors": [
      "David Recasens",
      "Jos\u00e9 Lamarca",
      "Jos\u00e9 M. F\u00e1cil",
      "J. M. M. Montiel",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.16525"
  },
  {
    "id": "arXiv:2104.01631",
    "title": "Marked for Disruption: Tracing the Evolution of Malware Delivery  Operations Targeted for Takedown",
    "abstract": "Comments: 14 pages, to appear in RAID 2021 conference",
    "descriptor": "\nComments: 14 pages, to appear in RAID 2021 conference\n",
    "authors": [
      "Colin C. Ife",
      "Yun Shen",
      "Steven J. Murdoch",
      "Gianluca Stringhini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.01631"
  },
  {
    "id": "arXiv:2104.03255",
    "title": "A Unified Model for Fingerprint Authentication and Presentation Attack  Detection",
    "abstract": "Comments: Accepted at IJCB2021; 12 pages",
    "descriptor": "\nComments: Accepted at IJCB2021; 12 pages\n",
    "authors": [
      "Additya Popli",
      "Saraansh Tandon",
      "Joshua J. Engelsma",
      "Naoyuki Onoe",
      "Atsushi Okubo",
      "Anoop Namboodiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03255"
  },
  {
    "id": "arXiv:2104.04572",
    "title": "Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next  Frontier for Intelligent Safe-Driving Assessment",
    "abstract": "Comments: 8 pages, 6 figures, this paper has been submitted to IEEE Network Magazine and is still awaiting the review results",
    "descriptor": "\nComments: 8 pages, 6 figures, this paper has been submitted to IEEE Network Magazine and is still awaiting the review results\n",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Rafiq Swash",
      "Lina Mohjazi",
      "Lei Zhang",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.04572"
  },
  {
    "id": "arXiv:2104.07279",
    "title": "COVID-19 detection using deep convolutional neural networks and  binary-differential-algorithm-based feature selection on X-ray images",
    "abstract": "COVID-19 detection using deep convolutional neural networks and  binary-differential-algorithm-based feature selection on X-ray images",
    "descriptor": "",
    "authors": [
      "Mohammad Saber Iraji",
      "Mohammad-Reza Feizi-Derakhshi",
      "Jafar Tanha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07279"
  },
  {
    "id": "arXiv:2104.08137",
    "title": "Hierarchical Human-Motion Prediction and Logic-Geometric Programming for  Minimal Interference Human-Robot Tasks",
    "abstract": "Comments: 8 pages, accepted to IEEE-ROMAN 2021",
    "descriptor": "\nComments: 8 pages, accepted to IEEE-ROMAN 2021\n",
    "authors": [
      "An T. Le",
      "Philipp Kratzer",
      "Simon Hagenmayer",
      "Marc Toussaint",
      "Jim Mainprice"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.08137"
  },
  {
    "id": "arXiv:2104.10314",
    "title": "Efficient Sparse Coding using Hierarchical Riemannian Pursuit",
    "abstract": "Comments: This paper has been accepted by IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: This paper has been accepted by IEEE Transactions on Signal Processing\n",
    "authors": [
      "Ye Xue",
      "Vincent Lau",
      "Songfu Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.10314"
  },
  {
    "id": "arXiv:2104.10394",
    "title": "Game Theory to Study Interactions between Mobility Stakeholders",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Gioele Zardini",
      "Nicolas Lanzetti",
      "Laura Guerrini",
      "Emilio Frazzoli",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.10394"
  },
  {
    "id": "arXiv:2104.10533",
    "title": "On the Path to 6G: Low Orbit is the New High",
    "abstract": "On the Path to 6G: Low Orbit is the New High",
    "descriptor": "",
    "authors": [
      "Xingqin Lin",
      "Stefan Cioni",
      "Gilles Charbit",
      "Nicolas Chuberre",
      "Sven Hellsten",
      "Jean-Francois Boutillon"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.10533"
  },
  {
    "id": "arXiv:2104.10868",
    "title": "Towards Adversarial Patch Analysis and Certified Defense against Crowd  Counting",
    "abstract": "Comments: After discussions with the authors, we find that we did not clarify clearly the proposed APAM algorithm and want to add more comparison results with baseline data to make other researchers more understandable. Moreover, we will add more visualization results of crowd counting models, these experimental results are significant. We hope the new version will make the conclusion safe and sound",
    "descriptor": "\nComments: After discussions with the authors, we find that we did not clarify clearly the proposed APAM algorithm and want to add more comparison results with baseline data to make other researchers more understandable. Moreover, we will add more visualization results of crowd counting models, these experimental results are significant. We hope the new version will make the conclusion safe and sound\n",
    "authors": [
      "Qiming Wu",
      "Zhikang Zou",
      "Pan Zhou",
      "Xiaoqing Ye",
      "Binghui Wang",
      "Ang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10868"
  },
  {
    "id": "arXiv:2104.10895",
    "title": "On convergence rates of adaptive ensemble Kalman inversion for linear  ill-posed problems",
    "abstract": "On convergence rates of adaptive ensemble Kalman inversion for linear  ill-posed problems",
    "descriptor": "",
    "authors": [
      "Fabian Parzer",
      "Otmar Scherzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.10895"
  },
  {
    "id": "arXiv:2104.11463",
    "title": "Decision Tree Learning in CEGIS-Based Termination Analysis",
    "abstract": "Comments: camera ready for CAV 2021",
    "descriptor": "\nComments: camera ready for CAV 2021\n",
    "authors": [
      "Satoshi Kura",
      "Hiroshi Unno",
      "Ichiro Hasuo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.11463"
  },
  {
    "id": "arXiv:2104.11557",
    "title": "Knodle: Modular Weakly Supervised Learning with PyTorch",
    "abstract": "Knodle: Modular Weakly Supervised Learning with PyTorch",
    "descriptor": "",
    "authors": [
      "Anastasiia Sedova",
      "Andreas Stephan",
      "Marina Speranskaya",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.11557"
  },
  {
    "id": "arXiv:2104.11824",
    "title": "Optimal Dynamic Regret in Exp-Concave Online Learning",
    "abstract": "Comments: Added a post processing step to Lemma 5; Added Remark 6",
    "descriptor": "\nComments: Added a post processing step to Lemma 5; Added Remark 6\n",
    "authors": [
      "Dheeraj Baby",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.11824"
  },
  {
    "id": "arXiv:2104.11969",
    "title": "Vietnamese Complaint Detection on E-Commerce Websites",
    "abstract": "Vietnamese Complaint Detection on E-Commerce Websites",
    "descriptor": "",
    "authors": [
      "Nhung Thi-Hong Nguyen",
      "Phuong Phan-Dieu Ha",
      "Luan Thanh Nguyen",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.11969"
  },
  {
    "id": "arXiv:2104.12437",
    "title": "Towards Rigorous Interpretations: a Formalisation of Feature Attribution",
    "abstract": "Comments: 38th International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Darius Afchar",
      "Romain Hennequin",
      "Vincent Guigue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.12437"
  },
  {
    "id": "arXiv:2104.12958",
    "title": "On the Evaluation of the Eigendecomposition of the Airy Integral  Operator",
    "abstract": "Comments: 48 pages, 3 tables, 8 figures",
    "descriptor": "\nComments: 48 pages, 3 tables, 8 figures\n",
    "authors": [
      "Zewen Shen",
      "Kirill Serkh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.12958"
  },
  {
    "id": "arXiv:2104.13634",
    "title": "A Deep Learning Object Detection Method for an Efficient Clusters  Initialization",
    "abstract": "A Deep Learning Object Detection Method for an Efficient Clusters  Initialization",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Couturier",
      "Hassan N. Noura",
      "Ola Salman",
      "Abderrahmane Sider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13634"
  },
  {
    "id": "arXiv:2105.00173",
    "title": "Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis  Tool for Singers",
    "abstract": "Comments: 26 pages, 10 figures, 6 tables",
    "descriptor": "\nComments: 26 pages, 10 figures, 6 tables\n",
    "authors": [
      "Daniel Szelogowski"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.00173"
  },
  {
    "id": "arXiv:2105.02467",
    "title": "Body Meshes as Points",
    "abstract": "Comments: To appear at CVPR 2021",
    "descriptor": "\nComments: To appear at CVPR 2021\n",
    "authors": [
      "Jianfeng Zhang",
      "Dongdong Yu",
      "Jun Hao Liew",
      "Xuecheng Nie",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02467"
  },
  {
    "id": "arXiv:2105.03075",
    "title": "A Survey of Data Augmentation Approaches for NLP",
    "abstract": "Comments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL",
    "descriptor": "\nComments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL\n",
    "authors": [
      "Steven Y. Feng",
      "Varun Gangal",
      "Jason Wei",
      "Sarath Chandar",
      "Soroush Vosoughi",
      "Teruko Mitamura",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03075"
  },
  {
    "id": "arXiv:2105.04030",
    "title": "A Bit More Bayesian: Domain-Invariant Learning with Uncertainty",
    "abstract": "Comments: accepted to ICML 2021",
    "descriptor": "\nComments: accepted to ICML 2021\n",
    "authors": [
      "Zehao Xiao",
      "Jiayi Shen",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04030"
  },
  {
    "id": "arXiv:2105.04963",
    "title": "Exploring a Handwriting Programming Language for Educational Robots",
    "abstract": "Comments: To appear in the proceedings of the 12th International Conference on Robotics in Education (RiE, 2021)",
    "descriptor": "\nComments: To appear in the proceedings of the 12th International Conference on Robotics in Education (RiE, 2021)\n",
    "authors": [
      "Laila El-Hamamsy",
      "Vaios Papaspyros",
      "Taavet Kangur",
      "Laura Mathex",
      "Christian Giang",
      "Melissa Skweres",
      "Barbara Bruno",
      "Francesco Mondada"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04963"
  },
  {
    "id": "arXiv:2105.04980",
    "title": "Teachers' perspective on fostering computational thinking through  educational robotics",
    "abstract": "Comments: To appear in the proceedings of the 12th international conference on robotics in education (RiE 2021)",
    "descriptor": "\nComments: To appear in the proceedings of the 12th international conference on robotics in education (RiE 2021)\n",
    "authors": [
      "Morgane Chevalier",
      "Laila El-Hamamsy",
      "Christian Giang",
      "Barbara Bruno",
      "Francesco Mondada"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04980"
  },
  {
    "id": "arXiv:2105.05848",
    "title": "Pointwise-in-time a posteriori error control for time-fractional  parabolic equations",
    "abstract": "Pointwise-in-time a posteriori error control for time-fractional  parabolic equations",
    "descriptor": "",
    "authors": [
      "Natalia Kopteva"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.05848"
  },
  {
    "id": "arXiv:2105.06571",
    "title": "Toward Real-time Analysis of Experimental Science Workloads on  Geographically Distributed Supercomputers",
    "abstract": "Toward Real-time Analysis of Experimental Science Workloads on  Geographically Distributed Supercomputers",
    "descriptor": "",
    "authors": [
      "Michael Salim",
      "Thomas Uram",
      "J. Taylor Childers",
      "Venkat Vishwanath",
      "Michael E. Papka"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.06571"
  },
  {
    "id": "arXiv:2105.06947",
    "title": "Thank you BART! Rewarding Pre-Trained Models Improves Formality Style  Transfer",
    "abstract": "Thank you BART! Rewarding Pre-Trained Models Improves Formality Style  Transfer",
    "descriptor": "",
    "authors": [
      "Huiyuan Lai",
      "Antonio Toral",
      "Malvina Nissim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06947"
  },
  {
    "id": "arXiv:2105.07603",
    "title": "EasyFL: A Low-code Federated Learning Platform For Dummies",
    "abstract": "EasyFL: A Low-code Federated Learning Platform For Dummies",
    "descriptor": "",
    "authors": [
      "Weiming Zhuang",
      "Xin Gan",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07603"
  },
  {
    "id": "arXiv:2105.07830",
    "title": "Learning to Relate Depth and Semantics for Unsupervised Domain  Adaptation",
    "abstract": "Comments: Accepted at CVPR 2021; updated results according to the released source code",
    "descriptor": "\nComments: Accepted at CVPR 2021; updated results according to the released source code\n",
    "authors": [
      "Suman Saha",
      "Anton Obukhov",
      "Danda Pani Paudel",
      "Menelaos Kanakis",
      "Yuhua Chen",
      "Stamatios Georgoulis",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07830"
  },
  {
    "id": "arXiv:2105.08551",
    "title": "Improved Ackermannian lower bound for the Petri nets reachability  problem",
    "abstract": "Improved Ackermannian lower bound for the Petri nets reachability  problem",
    "descriptor": "",
    "authors": [
      "S\u0142awomir Lasota"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.08551"
  },
  {
    "id": "arXiv:2105.09358",
    "title": "Improved Product-Based High-Dimensional Expanders",
    "abstract": "Comments: 17 pages; added references",
    "descriptor": "\nComments: 17 pages; added references\n",
    "authors": [
      "Louis Golowich"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.09358"
  },
  {
    "id": "arXiv:2105.09551",
    "title": "CLARQ: A Dynamic ARQ Solution for Ultra-high Closed-loop Reliability",
    "abstract": "Comments: Accepted on 03.07.2021 by IEEE Transactions on Wireless Communications for publication",
    "descriptor": "\nComments: Accepted on 03.07.2021 by IEEE Transactions on Wireless Communications for publication\n",
    "authors": [
      "Bin Han",
      "Yao Zhu",
      "Muxia Sun",
      "Vincenzo Sciancalepore",
      "Yulin Hu",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.09551"
  },
  {
    "id": "arXiv:2105.09856",
    "title": "High-Fidelity and Low-Latency Universal Neural Vocoder based on  Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform  Modeling",
    "abstract": "Comments: Accepted for INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted for INTERSPEECH 2021\n",
    "authors": [
      "Patrick Lumban Tobing",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.09856"
  },
  {
    "id": "arXiv:2105.09858",
    "title": "Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic  Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear  Prediction",
    "abstract": "Comments: Accepted for SSW11",
    "descriptor": "\nComments: Accepted for SSW11\n",
    "authors": [
      "Patrick Lumban Tobing",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.09858"
  },
  {
    "id": "arXiv:2105.10661",
    "title": "An Efficient Network Solver for Dynamic Simulation of Power Systems  Based on Hierarchical Inverse Computation and Modification",
    "abstract": "Comments: 6 pages, 10 figures",
    "descriptor": "\nComments: 6 pages, 10 figures\n",
    "authors": [
      "Lu Zhang",
      "Bin Wang",
      "Vivek Sarin",
      "Weiping Shi",
      "P. R. Kumar",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.10661"
  },
  {
    "id": "arXiv:2105.10798",
    "title": "On the Complexity and Parallel Implementation of Hensel's Lemma and  Weierstrass Preparation",
    "abstract": "Comments: 21 pages, 3 figures, submitted to Computer Algebra in Scientific Computing CASC 2021",
    "descriptor": "\nComments: 21 pages, 3 figures, submitted to Computer Algebra in Scientific Computing CASC 2021\n",
    "authors": [
      "Alexander Brandt",
      "Marc Moreno Maza"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2105.10798"
  },
  {
    "id": "arXiv:2105.10853",
    "title": "Parametric Toricity of Steady State Varieties of Reaction Networks",
    "abstract": "Comments: Computations available as ancillary files",
    "descriptor": "\nComments: Computations available as ancillary files\n",
    "authors": [
      "Hamid Rahkooy",
      "Thomas Sturm"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.10853"
  },
  {
    "id": "arXiv:2105.11763",
    "title": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "abstract": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "descriptor": "",
    "authors": [
      "Emilio Gamba",
      "Bart Bogaerts",
      "Tias Guns"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.11763"
  },
  {
    "id": "arXiv:2105.12071",
    "title": "Security Analysis in Multicasting over Shadowed Rician and  \u03b1-\u03bc Fading Channels: A Dual-hop Hybrid Satellite Terrestrial  Relaying Network",
    "abstract": "Security Analysis in Multicasting over Shadowed Rician and  \u03b1-\u03bc Fading Channels: A Dual-hop Hybrid Satellite Terrestrial  Relaying Network",
    "descriptor": "",
    "authors": [
      "Abida Sultana Sumona",
      "Milton Kumar Kundu",
      "A. S. M. Badrudduza"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.12071"
  },
  {
    "id": "arXiv:2105.12807",
    "title": "XOmiVAE: an interpretable deep learning model for cancer classification  using high-dimensional omics data",
    "abstract": "Comments: 12 pages, 7 figures, 10 tables",
    "descriptor": "\nComments: 12 pages, 7 figures, 10 tables\n",
    "authors": [
      "Eloise Withnell",
      "Xiaoyu Zhang",
      "Kai Sun",
      "Yike Guo"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2105.12807"
  },
  {
    "id": "arXiv:2105.12846",
    "title": "General Game Heuristic Prediction Based on Ludeme Descriptions",
    "abstract": "Comments: 4 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 4 pages, 1 figure, 2 tables\n",
    "authors": [
      "Matthew Stephenson",
      "Dennis J. N. J. Soemers",
      "Eric Piette",
      "Cameron Browne"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12846"
  },
  {
    "id": "arXiv:2105.13353",
    "title": "Unsupervised Activity Segmentation by Joint Representation Learning and  Online Clustering",
    "abstract": "Comments: Preprint. Under review",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Sateesh Kumar",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13353"
  },
  {
    "id": "arXiv:2105.13487",
    "title": "Multidimensional Byzantine Agreement in a Synchronous Setting",
    "abstract": "Comments: 15 pages, 0 figures",
    "descriptor": "\nComments: 15 pages, 0 figures\n",
    "authors": [
      "Andrea Flamini",
      "Riccardo Longo",
      "Alessio Meneghetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13487"
  },
  {
    "id": "arXiv:2105.13502",
    "title": "Unsupervised Domain Adaptation of Object Detectors: A Survey",
    "abstract": "Unsupervised Domain Adaptation of Object Detectors: A Survey",
    "descriptor": "",
    "authors": [
      "Poojan Oza",
      "Vishwanath A. Sindagi",
      "Vibashan VS",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13502"
  },
  {
    "id": "arXiv:2105.13783",
    "title": "Quantile Encoder: Tackling High Cardinality Categorical Features in  Regression Problems",
    "abstract": "Comments: Accepted at The 18th International Conference on Modeling Decisions for Artificial Intelligence (MDAI)",
    "descriptor": "\nComments: Accepted at The 18th International Conference on Modeling Decisions for Artificial Intelligence (MDAI)\n",
    "authors": [
      "Carlos Mougan",
      "David Masip",
      "Jordi Nin",
      "Oriol Pujol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13783"
  },
  {
    "id": "arXiv:2105.14197",
    "title": "The Impact of the U.S. Census Disclosure Avoidance System on  Redistricting and Voting Rights Analysis",
    "abstract": "Comments: 30 pages, 13 figures. General revisions, improved figures, and updates reflecting new developments since initial publication",
    "descriptor": "\nComments: 30 pages, 13 figures. General revisions, improved figures, and updates reflecting new developments since initial publication\n",
    "authors": [
      "Christopher T. Kenny",
      "Shiro Kuriwaki",
      "Cory McCartan",
      "Evan Rosenman",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14197"
  },
  {
    "id": "arXiv:2105.14711",
    "title": "CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in  Computed Tomography",
    "abstract": "CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in  Computed Tomography",
    "descriptor": "",
    "authors": [
      "Yang Deng",
      "Ce Wang",
      "Yuan Hui",
      "Qian Li",
      "Jun Li",
      "Shiwei Luo",
      "Mengke Sun",
      "Quan Quan",
      "Shuxin Yang",
      "You Hao",
      "Pengbo Liu",
      "Honghu Xiao",
      "Chunpeng Zhao",
      "Xinbao Wu",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14711"
  },
  {
    "id": "arXiv:2105.14779",
    "title": "Towards One Model to Rule All: Multilingual Strategy for Dialectal  Code-Switching Arabic ASR",
    "abstract": "Comments: Accepted in INTERSPEECH 2021, Multilingual ASR, Multi-dialectal ASR, Code-Switching ASR, Arabic ASR, Conformer, Transformer, E2E ASR, Speech Recognition, ASR, Arabic, English, French",
    "descriptor": "\nComments: Accepted in INTERSPEECH 2021, Multilingual ASR, Multi-dialectal ASR, Code-Switching ASR, Arabic ASR, Conformer, Transformer, E2E ASR, Speech Recognition, ASR, Arabic, English, French\n",
    "authors": [
      "Shammur Absar Chowdhury",
      "Amir Hussein",
      "Ahmed Abdelali",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.14779"
  },
  {
    "id": "arXiv:2105.14964",
    "title": "A Capacity Region Outer Bound for the Two-User Perturbative Nonlinear  Fiber Optical Channel",
    "abstract": "Comments: Incorrect Proposition 1 was removed",
    "descriptor": "\nComments: Incorrect Proposition 1 was removed\n",
    "authors": [
      "Viswanathan Ramachandran",
      "Astrid Barreiro",
      "Gabriele Liga",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14964"
  },
  {
    "id": "arXiv:2105.15134",
    "title": "Toward Understanding the Feature Learning Process of Self-supervised  Contrastive Learning",
    "abstract": "Comments: V3 corrected related works. Accepted to ICML2021",
    "descriptor": "\nComments: V3 corrected related works. Accepted to ICML2021\n",
    "authors": [
      "Zixin Wen",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15134"
  },
  {
    "id": "arXiv:2106.00623",
    "title": "A 3-Approximation Algorithm for Maximum Independent Set of Rectangles",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Waldo Galvez",
      "Arindam Khan",
      "Mathieu Mari",
      "Tobias Momke",
      "Madhusudhan Reddy",
      "Andreas Wiese"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00623"
  },
  {
    "id": "arXiv:2106.02813",
    "title": "Machine learning equipped web based disease prediction and recommender  system",
    "abstract": "Machine learning equipped web based disease prediction and recommender  system",
    "descriptor": "",
    "authors": [
      "Harish Rajora",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02813"
  },
  {
    "id": "arXiv:2106.02994",
    "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion",
    "abstract": "Learning Topology from Synthetic Data for Unsupervised Depth Completion",
    "descriptor": "",
    "authors": [
      "Alex Wong",
      "Safa Cicek",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02994"
  },
  {
    "id": "arXiv:2106.03706",
    "title": "A Comprehensive Assessment of Dialog Evaluation Metrics",
    "abstract": "A Comprehensive Assessment of Dialog Evaluation Metrics",
    "descriptor": "",
    "authors": [
      "Yi-Ting Yeh",
      "Maxine Eskenazi",
      "Shikib Mehri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03706"
  },
  {
    "id": "arXiv:2106.04205",
    "title": "Micro BTB: A High Performance and Lightweight Last-Level Branch Target  Buffer for Servers",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Vishal Gupta",
      "Biswabandan Panda"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.04205"
  },
  {
    "id": "arXiv:2106.04679",
    "title": "Self-Adaptive Swarm System (SASS)",
    "abstract": "Comments: The preprint for IJCAI 2021 Doctoral Consortium (The Final Version)",
    "descriptor": "\nComments: The preprint for IJCAI 2021 Doctoral Consortium (The Final Version)\n",
    "authors": [
      "Qin Yang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.04679"
  },
  {
    "id": "arXiv:2106.04979",
    "title": "Benchmarking the Nvidia GPU Lineage: From Early K80 to Modern A100 with  Asynchronous Memory Transfers",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Martin Svedin",
      "Steven W. D. Chien",
      "Gibson Chikafa",
      "Niclas Jansson",
      "Artur Podobas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.04979"
  },
  {
    "id": "arXiv:2106.05485",
    "title": "VaLiPro: Linear Programming Validator for Cluster Computing Systems",
    "abstract": "Comments: Submitted to \"Supercomputing Frontiers and Innovations\" journal",
    "descriptor": "\nComments: Submitted to \"Supercomputing Frontiers and Innovations\" journal\n",
    "authors": [
      "Leonid B. Sokolinsky",
      "Irina M. Sokolinskaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.05485"
  },
  {
    "id": "arXiv:2106.06433",
    "title": "FPGA-Based Near-Memory Acceleration of Modern Data-Intensive  Applications",
    "abstract": "Comments: This is an extended and updated version of a paper published in IEEE Micro, vol. 41, no. 4, pp. 39-48, 1 July-Aug. 2021",
    "descriptor": "\nComments: This is an extended and updated version of a paper published in IEEE Micro, vol. 41, no. 4, pp. 39-48, 1 July-Aug. 2021\n",
    "authors": [
      "Gagandeep Singh",
      "Mohammed Alser",
      "Damla Senol Cali",
      "Dionysios Diamantopoulos",
      "Juan G\u00f3mez-Luna",
      "Henk Corporaal",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06433"
  },
  {
    "id": "arXiv:2106.06944",
    "title": "SASICM A Multi-Task Benchmark For Subtext Recognition",
    "abstract": "Comments: 34 pages, 6 figures, 6 tables. Submitted to the journal of artificial intelligence",
    "descriptor": "\nComments: 34 pages, 6 figures, 6 tables. Submitted to the journal of artificial intelligence\n",
    "authors": [
      "Hua Yan",
      "Feng Han",
      "Junyi An",
      "Weikang Xiao",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06944"
  },
  {
    "id": "arXiv:2106.06999",
    "title": "A Dataset of Dynamic Reverberant Sound Scenes with Directional  Interferers for Sound Event Localization and Detection",
    "abstract": "A Dataset of Dynamic Reverberant Sound Scenes with Directional  Interferers for Sound Event Localization and Detection",
    "descriptor": "",
    "authors": [
      "Archontis Politis",
      "Sharath Adavanne",
      "Daniel Krause",
      "Antoine Deleforge",
      "Prerak Srivastava",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.06999"
  },
  {
    "id": "arXiv:2106.07023",
    "title": "Styleformer: Transformer based Generative Adversarial Networks with  Style Vector",
    "abstract": "Styleformer: Transformer based Generative Adversarial Networks with  Style Vector",
    "descriptor": "",
    "authors": [
      "Jeeseung Park",
      "Younggeun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.07023"
  },
  {
    "id": "arXiv:2106.07250",
    "title": "Unified Interpretation of Softmax Cross-Entropy and Negative Sampling:  With Case Study for Knowledge Graph Embedding",
    "abstract": "Comments: Accepted at ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07250"
  },
  {
    "id": "arXiv:2106.07474",
    "title": "Discovering Interpretable Machine Learning Models in Parallel  Coordinates",
    "abstract": "Comments: 8 pages, 18 figures",
    "descriptor": "\nComments: 8 pages, 18 figures\n",
    "authors": [
      "Boris Kovalerchuk",
      "Dustin Hayes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07474"
  },
  {
    "id": "arXiv:2106.07568",
    "title": "Full interpretable machine learning in 2D with inline coordinates",
    "abstract": "Comments: 8 pages, 20 figures",
    "descriptor": "\nComments: 8 pages, 20 figures\n",
    "authors": [
      "Boris Kovalerchuk",
      "Hoang Phan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07568"
  },
  {
    "id": "arXiv:2106.07932",
    "title": "Medical Code Prediction from Discharge Summary: Document to Sequence  BERT using Sequence Attention",
    "abstract": "Medical Code Prediction from Discharge Summary: Document to Sequence  BERT using Sequence Attention",
    "descriptor": "",
    "authors": [
      "Tak-Sung Heo",
      "Yongmin Yoo",
      "Yeongjoon Park",
      "Byeong-Cheol Jo",
      "Kyungsun Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07932"
  },
  {
    "id": "arXiv:2106.08087",
    "title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark",
    "abstract": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark",
    "descriptor": "",
    "authors": [
      "Mosha Chen",
      "Chuanqi Tan",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Lei Li",
      "Ningyu Zhang",
      "Xin Shang",
      "Kangping Yin",
      "Chuanqi Tan",
      "Jian Xu",
      "Mosha Chen",
      "Fei Huang",
      "Luo Si",
      "Yuan Ni",
      "Guotong Xie",
      "Zhifang Sui",
      "Baobao Chang",
      "Hui Zong",
      "Zheng Yuan",
      "Linfeng Li",
      "Jun Yan",
      "Hongying Zan",
      "Kunli Zhang",
      "Buzhou Tang",
      "Qingcai Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08087"
  },
  {
    "id": "arXiv:2106.08253",
    "title": "Code Generation Based on Deep Learning: a Brief Review",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qihao Zhu",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08253"
  },
  {
    "id": "arXiv:2106.08727",
    "title": "AtrialGeneral: Domain Generalization for Left Atrial Segmentation of  Multi-Center LGE MRIs",
    "abstract": "Comments: 10 pages, 4 figures, MICCAI2021",
    "descriptor": "\nComments: 10 pages, 4 figures, MICCAI2021\n",
    "authors": [
      "Lei Li",
      "Veronika A. Zimmer",
      "Julia A. Schnabel",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08727"
  },
  {
    "id": "arXiv:2106.08775",
    "title": "Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained  SDPs",
    "abstract": "Comments: 10 pages, 8 figures, preprint under review",
    "descriptor": "\nComments: 10 pages, 8 figures, preprint under review\n",
    "authors": [
      "Junhyung Lyle Kim",
      "Jose Antonio Lara Benitez",
      "Mohammad Taha Toghani",
      "Cameron Wolfe",
      "Zhiwei Zhang",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08775"
  },
  {
    "id": "arXiv:2106.09455",
    "title": "Conference proceedings KI4Industry AI for SMEs -- the online congress  for practical entry into AI for SMEs",
    "abstract": "Comments: Editors: Matthias Feiner and Manuel Schoellhorn, 72 pages, 48 figures, in German, Conference proceedings Ki4 Industry 79 pages in total",
    "descriptor": "\nComments: Editors: Matthias Feiner and Manuel Schoellhorn, 72 pages, 48 figures, in German, Conference proceedings Ki4 Industry 79 pages in total\n",
    "authors": [
      "Michael Arnemann",
      "Per Olof Beckemeier",
      "Thomas Bertram",
      "Michael Eder",
      "Maximilian Erschig",
      "Matthias Feiner",
      "Francisco Javier Fernandez Garcia",
      "Frederic Foerster",
      "Ruediger Haas",
      "Martin Kipfmueller",
      "Jan Kotschenreuther",
      "Bernd Langer",
      "Ivan Lozada Rodriguez",
      "Thomas Meibert",
      "Simon Ottenhaus",
      "Stefan Paschek",
      "Lars Pfotzer",
      "Michael Roth",
      "Tim Schanz",
      "Philip Scherer",
      "Janine Schwienke",
      "Robin Tenscher-Philipp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09455"
  },
  {
    "id": "arXiv:2106.09989",
    "title": "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly  Detection",
    "abstract": "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Yulin Zhu",
      "Yuni Lai",
      "Kaifa Zhao",
      "Xiapu Luo",
      "Mingquan Yuan",
      "Jian Ren",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09989"
  },
  {
    "id": "arXiv:2106.10333",
    "title": "Non-parametric Differentially Private Confidence Intervals for the  Median",
    "abstract": "Comments: 44 pages, 15 figures",
    "descriptor": "\nComments: 44 pages, 15 figures\n",
    "authors": [
      "Joerg Drechsler",
      "Ira Globus-Harris",
      "Audra McMillan",
      "Jayshree Sarathy",
      "Adam Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10333"
  },
  {
    "id": "arXiv:2106.10417",
    "title": "Variance-Dependent Best Arm Identification",
    "abstract": "Variance-Dependent Best Arm Identification",
    "descriptor": "",
    "authors": [
      "Pinyan Lu",
      "Chao Tao",
      "Xiaojin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10417"
  },
  {
    "id": "arXiv:2106.10420",
    "title": "Finding important edges in networks through local information",
    "abstract": "Finding important edges in networks through local information",
    "descriptor": "",
    "authors": [
      "En-Yu Yu",
      "Yan Fu",
      "Jun-Lin Zhou",
      "Duan-Bing Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10420"
  },
  {
    "id": "arXiv:2106.10486",
    "title": "CompConv: A Compact Convolution Module for Efficient Feature Learning",
    "abstract": "CompConv: A Compact Convolution Module for Efficient Feature Learning",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Yinghao Xu",
      "Yujun Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10486"
  },
  {
    "id": "arXiv:2106.10514",
    "title": "Cooperative Evasion by Translating Targets with Variable Speeds",
    "abstract": "Cooperative Evasion by Translating Targets with Variable Speeds",
    "descriptor": "",
    "authors": [
      "Shivam Bajaj",
      "Eloy Garcia",
      "Shaunak D. Bopardikar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10514"
  },
  {
    "id": "arXiv:2106.10558",
    "title": "Rayleigh-Gauss-Newton optimization with enhanced sampling for  variational Monte Carlo",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Robert J. Webber",
      "Michael Lindsey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10558"
  },
  {
    "id": "arXiv:2106.10686",
    "title": "Quality-Aware Memory Network for Interactive Volumetric Image  Segmentation",
    "abstract": "Comments: MICCAI 2021. Code: this https URL",
    "descriptor": "\nComments: MICCAI 2021. Code: this https URL\n",
    "authors": [
      "Tianfei Zhou",
      "Liulei Li",
      "Gustav Bredell",
      "Jianwu Li",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10686"
  },
  {
    "id": "arXiv:2106.11087",
    "title": "Recolouring weakly chordal graphs and the complement of triangle-free  graphs",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Owen Merkel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.11087"
  },
  {
    "id": "arXiv:2106.11160",
    "title": "Effects of boundary conditions in fully convolutional networks for  learning spatio-temporal dynamics",
    "abstract": "Comments: 16 pages, 8 figures, submitted to ECML PKDD 2021 Conference",
    "descriptor": "\nComments: 16 pages, 8 figures, submitted to ECML PKDD 2021 Conference\n",
    "authors": [
      "Antonio Alguacil",
      "Wagner Gon\u00e7alves Pinto",
      "Michael Bauerheim",
      "Marc C. Jacob",
      "St\u00e9phane Moreau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.11160"
  },
  {
    "id": "arXiv:2106.11169",
    "title": "Signals to Spikes for Neuromorphic Regulated Reservoir Computing and EMG  Hand Gesture Recognition",
    "abstract": "Comments: Accepted to International Conference on Neuromorphic Systems (ICONS 2021)",
    "descriptor": "\nComments: Accepted to International Conference on Neuromorphic Systems (ICONS 2021)\n",
    "authors": [
      "Nikhil Garg",
      "Ismael Balafrej",
      "Yann Beilliard",
      "Dominique Drouin",
      "Fabien Alibart",
      "Jean Rouat"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.11169"
  },
  {
    "id": "arXiv:2106.11655",
    "title": "On Constrained Optimization in Differentiable Neural Architecture Search",
    "abstract": "On Constrained Optimization in Differentiable Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Kaitlin Maile",
      "Erwan Lecarpentier",
      "Herv\u00e9 Luga",
      "Dennis G. Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11655"
  },
  {
    "id": "arXiv:2106.11886",
    "title": "A Negative Answer to $P\\overset{?}{=}PSPACE$",
    "abstract": "Comments: Thanks go to a net user in stackexchange (stackoverflow) for pointing out a flaw in Lemma 2 in v1; (v2-v3) minor change in section of introduction and Lemma 3 is newly added. Any comments are welcome",
    "descriptor": "\nComments: Thanks go to a net user in stackexchange (stackoverflow) for pointing out a flaw in Lemma 2 in v1; (v2-v3) minor change in section of introduction and Lemma 3 is newly added. Any comments are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11886"
  },
  {
    "id": "arXiv:2106.11929",
    "title": "Physics-Informed Deep Reversible Regression Model for Temperature Field  Reconstruction of Heat-Source Systems",
    "abstract": "Comments: Submitted to IEEE TIE",
    "descriptor": "\nComments: Submitted to IEEE TIE\n",
    "authors": [
      "Zhiqiang Gong",
      "Weien Zhou",
      "Jun Zhang",
      "Wei Peng",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11929"
  },
  {
    "id": "arXiv:2106.12194",
    "title": "Uncertainty-Aware Model-Based Reinforcement Learning with Application to  Autonomous Driving",
    "abstract": "Uncertainty-Aware Model-Based Reinforcement Learning with Application to  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Jingda Wu",
      "Zhiyu Huang",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12194"
  },
  {
    "id": "arXiv:2106.12210",
    "title": "An alternative to proportional-integral and  proportional-integral-derivative regulators: Intelligent  proportional-derivative regulators",
    "abstract": "Comments: Accepted in \"International Journal of Robust and Nonlinear Control\"",
    "descriptor": "\nComments: Accepted in \"International Journal of Robust and Nonlinear Control\"\n",
    "authors": [
      "Michel Fliess",
      "C\u00e9dric Join"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.12210"
  },
  {
    "id": "arXiv:2106.12673",
    "title": "Conditional Deformable Image Registration with Convolutional Neural  Network",
    "abstract": "Comments: Early accepted by MICCAI2021",
    "descriptor": "\nComments: Early accepted by MICCAI2021\n",
    "authors": [
      "Tony C. W. Mok",
      "Albert C. S. Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.12673"
  },
  {
    "id": "arXiv:2106.12914",
    "title": "Speech is Silver, Silence is Golden: What do ASVspoof-trained Models  Really Learn?",
    "abstract": "Speech is Silver, Silence is Golden: What do ASVspoof-trained Models  Really Learn?",
    "descriptor": "",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Franziska Dieckmann",
      "Pavel Czempin",
      "Roman Canals",
      "Jennifer Williams",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.12914"
  },
  {
    "id": "arXiv:2106.13122",
    "title": "Exploring Corruption Robustness: Inductive Biases in Vision Transformers  and MLP-Mixers",
    "abstract": "Comments: Under review at the Uncertainty and Robustness in Deep Learning workshop at ICML 2021. Our appendix is attached to the last page of the paper",
    "descriptor": "\nComments: Under review at the Uncertainty and Robustness in Deep Learning workshop at ICML 2021. Our appendix is attached to the last page of the paper\n",
    "authors": [
      "Katelyn Morrison",
      "Benjamin Gilby",
      "Colton Lipchak",
      "Adam Mattioli",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13122"
  },
  {
    "id": "arXiv:2106.13367",
    "title": "SeaNet -- Towards A Knowledge Graph Based Autonomic Management of  Software Defined Networks",
    "abstract": "SeaNet -- Towards A Knowledge Graph Based Autonomic Management of  Software Defined Networks",
    "descriptor": "",
    "authors": [
      "Qianru Zhou",
      "Alasdair J.G. Gray",
      "Stephen McLaughlin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.13367"
  },
  {
    "id": "arXiv:2106.13435",
    "title": "NP-DRAW: A Non-Parametric Structured Latent Variable Model for Image  Generation",
    "abstract": "Comments: UAI2021, code at this https URL",
    "descriptor": "\nComments: UAI2021, code at this https URL\n",
    "authors": [
      "Xiaohui Zeng",
      "Raquel Urtasun",
      "Richard Zemel",
      "Sanja Fidler",
      "Renjie Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13435"
  },
  {
    "id": "arXiv:2106.13797",
    "title": "PVTv2: Improved Baselines with Pyramid Vision Transformer",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Wenhai Wang",
      "Enze Xie",
      "Xiang Li",
      "Deng-Ping Fan",
      "Kaitao Song",
      "Ding Liang",
      "Tong Lu",
      "Ping Luo",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13797"
  },
  {
    "id": "arXiv:2106.13884",
    "title": "Multimodal Few-Shot Learning with Frozen Language Models",
    "abstract": "Multimodal Few-Shot Learning with Frozen Language Models",
    "descriptor": "",
    "authors": [
      "Maria Tsimpoukelli",
      "Jacob Menick",
      "Serkan Cabi",
      "S. M. Ali Eslami",
      "Oriol Vinyals",
      "Felix Hill"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13884"
  },
  {
    "id": "arXiv:2106.13939",
    "title": "Domain Adaptive YOLO for One-Stage Cross-Domain Detection",
    "abstract": "Domain Adaptive YOLO for One-Stage Cross-Domain Detection",
    "descriptor": "",
    "authors": [
      "Shizhao Zhang",
      "Hongya Tuo",
      "Jian Hu",
      "Zhongliang Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13939"
  },
  {
    "id": "arXiv:2106.14076",
    "title": "Learning from Synthetic Data for Opinion-free Blind Image Quality  Assessment in the Wild",
    "abstract": "Comments: 15 pages, 9 figures, 6 tables",
    "descriptor": "\nComments: 15 pages, 9 figures, 6 tables\n",
    "authors": [
      "Zhihua Wang",
      "Zhiri Tang",
      "Jiangguo Zhang",
      "Yuming Fang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.14076"
  },
  {
    "id": "arXiv:2106.14153",
    "title": "Automatic Differentiation With Higher Infinitesimals, or Computational  Smooth Infinitesimal Analysis in Weil Algebra",
    "abstract": "Comments: to appear in Computer Algebra in Scientific Computing 2021",
    "descriptor": "\nComments: to appear in Computer Algebra in Scientific Computing 2021\n",
    "authors": [
      "Hiromi Ishii"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Mathematical Software (cs.MS)",
      "Category Theory (math.CT)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.14153"
  },
  {
    "id": "arXiv:2106.14344",
    "title": "Non-Exhaustive Learning Using Gaussian Mixture Generative Adversarial  Networks",
    "abstract": "Comments: Accepted by ECML-PKDD 2021",
    "descriptor": "\nComments: Accepted by ECML-PKDD 2021\n",
    "authors": [
      "Jun Zhuang",
      "Mohammad Al Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14344"
  },
  {
    "id": "arXiv:2106.14475",
    "title": "A More Compact Object Detector Head Network with Feature Enhancement and  Relational Reasoning",
    "abstract": "A More Compact Object Detector Head Network with Feature Enhancement and  Relational Reasoning",
    "descriptor": "",
    "authors": [
      "Wenchao Zhang",
      "Chong Fu",
      "Xiangshi Chang",
      "Tengfei Zhao",
      "Xiang Li",
      "Chiu-Wing Sham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14475"
  },
  {
    "id": "arXiv:2106.14938",
    "title": "Seeking Stability by being Lazy and Shallow",
    "abstract": "Comments: Haskell Symposium 21",
    "descriptor": "\nComments: Haskell Symposium 21\n",
    "authors": [
      "Gert-Jan Bottu",
      "Richard A. Eisenberg"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.14938"
  },
  {
    "id": "arXiv:2106.14993",
    "title": "Modularity in Reinforcement Learning via Algorithmic Independence in  Credit Assignment",
    "abstract": "Comments: Long Presentation at the Thirty-eighth International Conference on Machine Learning (ICML) 2021. 21 pages, 11 figures. v2: updated acknowledgments",
    "descriptor": "\nComments: Long Presentation at the Thirty-eighth International Conference on Machine Learning (ICML) 2021. 21 pages, 11 figures. v2: updated acknowledgments\n",
    "authors": [
      "Michael Chang",
      "Sidhant Kaushik",
      "Sergey Levine",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14993"
  },
  {
    "id": "arXiv:2106.15113",
    "title": "An Efficient Cervical Whole Slide Image Analysis Framework Based on  Multi-scale Semantic and Spatial Deep Features",
    "abstract": "Comments: 16 pages, 8 figures, already submitted to Medical Image Analysis",
    "descriptor": "\nComments: 16 pages, 8 figures, already submitted to Medical Image Analysis\n",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Xiuli Liu",
      "Shaoqun Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15113"
  },
  {
    "id": "arXiv:2106.15232",
    "title": "Using Robust Regression to Find Font Usage Trends",
    "abstract": "Comments: 16 pages with 10 figures. Accepted at ICDAR 2021 Workshop on Machine Learning(ICDAR-WML2021)",
    "descriptor": "\nComments: 16 pages with 10 figures. Accepted at ICDAR 2021 Workshop on Machine Learning(ICDAR-WML2021)\n",
    "authors": [
      "Kaigen Tsuji",
      "Seiichi Uchida",
      "Brian Kenji Iwana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15232"
  },
  {
    "id": "arXiv:2106.15236",
    "title": "New Arabic Medical Dataset for Diseases Classification",
    "abstract": "New Arabic Medical Dataset for Diseases Classification",
    "descriptor": "",
    "authors": [
      "Jaafar Hammoud",
      "Aleksandra Vatian",
      "Natalia Dobrenko",
      "Nikolai Vedernikov",
      "Anatoly Shalyto",
      "Natalia Gusarova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.15236"
  },
  {
    "id": "arXiv:2106.15318",
    "title": "Analysing Affective Behavior in the second ABAW2 Competition",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2001.11409",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2001.11409\n",
    "authors": [
      "Dimitrios Kollias",
      "Irene Kotsia",
      "Elnar Hajiyev",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15318"
  },
  {
    "id": "arXiv:2106.15338",
    "title": "Probabilistic Attention for Interactive Segmentation",
    "abstract": "Comments: Updated with link to GitHub, 17 pages, 8 figures",
    "descriptor": "\nComments: Updated with link to GitHub, 17 pages, 8 figures\n",
    "authors": [
      "Prasad Gabbur",
      "Manjot Bilkhu",
      "Javier Movellan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15338"
  },
  {
    "id": "arXiv:2106.15596",
    "title": "Towards a Unified Theory of Light Spanners I: Fast (Yet Optimal)  Constructions",
    "abstract": "Comments: 55 pages, 8 figures",
    "descriptor": "\nComments: 55 pages, 8 figures\n",
    "authors": [
      "Hung Le",
      "Shay Solomon"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15596"
  },
  {
    "id": "arXiv:2106.15877",
    "title": "Experience-Driven PCG via Reinforcement Learning: A Super Mario Bros  Study",
    "abstract": "Comments: This paper is accepted by the 2021 IEEE Conference on Games",
    "descriptor": "\nComments: This paper is accepted by the 2021 IEEE Conference on Games\n",
    "authors": [
      "Tianye Shu",
      "Jialin Liu",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15877"
  },
  {
    "id": "arXiv:2106.16036",
    "title": "A Generative Model for Raw Audio Using Transformer Architectures",
    "abstract": "Comments: DAFX 2021",
    "descriptor": "\nComments: DAFX 2021\n",
    "authors": [
      "Prateek Verma",
      "Chris Chafe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.16036"
  },
  {
    "id": "arXiv:2106.16126",
    "title": "Recognizing Facial Expressions in the Wild using Multi-Architectural  Representations based Ensemble Learning with Distillation",
    "abstract": "Comments: 5 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 4 tables\n",
    "authors": [
      "Rauf Momin",
      "Ali Shan Momin",
      "Khalid Rasheed",
      "Muhammad Saqib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16126"
  },
  {
    "id": "arXiv:2107.00114",
    "title": "QuickFlex: a Fast Algorithm for Flexible Region Construction for the  TSO-DSO Coordination",
    "abstract": "QuickFlex: a Fast Algorithm for Flexible Region Construction for the  TSO-DSO Coordination",
    "descriptor": "",
    "authors": [
      "Luis Lopez",
      "Alvaro Gonzalez-Castellanos",
      "David Pozo",
      "Mardavij Roozbehani",
      "Munther Dahleh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00114"
  },
  {
    "id": "arXiv:2107.00430",
    "title": "Segmenting 3D Hybrid Scenes via Zero-Shot Learning",
    "abstract": "Comments: 7 pages, 3 figures",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Bo Liu",
      "Shuang Deng",
      "Qiulei Dong",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00430"
  },
  {
    "id": "arXiv:2107.00729",
    "title": "Essence of Factual Knowledge",
    "abstract": "Comments: 4 pages, 1 figure",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Ruoyu Wang",
      "Daniel Sun",
      "Guoqiang Li",
      "Raymond Wong",
      "Shiping Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.00729"
  },
  {
    "id": "arXiv:2107.00842",
    "title": "Cross-view Geo-localization with Evolving Transformer",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Hongji Yang",
      "Xiufan Lu",
      "Yingying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00842"
  },
  {
    "id": "arXiv:2107.00868",
    "title": "Construction and Adaptability Analysis of User's Preference Models Based  on Check-in Data in LBSN",
    "abstract": "Construction and Adaptability Analysis of User's Preference Models Based  on Check-in Data in LBSN",
    "descriptor": "",
    "authors": [
      "Yuanbang Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.00868"
  },
  {
    "id": "arXiv:2107.00934",
    "title": "Mixed Supervision Learning for Whole Slide Image Classification",
    "abstract": "Mixed Supervision Learning for Whole Slide Image Classification",
    "descriptor": "",
    "authors": [
      "Jiahui Li",
      "Wen Chen",
      "Xiaodi Huang",
      "Zhiqiang Hu",
      "Qi Duan",
      "Hongsheng Li",
      "Dimitris N. Metaxas",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00934"
  },
  {
    "id": "arXiv:2107.00946",
    "title": "Online Metro Origin-Destination Prediction via Heterogeneous Information  Aggregation",
    "abstract": "Comments: UnderReview",
    "descriptor": "\nComments: UnderReview\n",
    "authors": [
      "Lingbo Liu",
      "Yuying Zhu",
      "Guanbin Li",
      "Ziyi Wu",
      "Lei Bai",
      "Mingzhi Mao",
      "Liang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00946"
  },
  {
    "id": "arXiv:2107.01003",
    "title": "PI$^2$ Parameters",
    "abstract": "PI$^2$ Parameters",
    "descriptor": "",
    "authors": [
      "Bob Briscoe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.01003"
  },
  {
    "id": "arXiv:2107.01183",
    "title": "Ethics Sheets for AI Tasks",
    "abstract": "Ethics Sheets for AI Tasks",
    "descriptor": "",
    "authors": [
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01183"
  },
  {
    "id": "arXiv:2107.01194",
    "title": "How Incomplete is Contrastive Learning? An Inter-intra Variant Dual  Representation Method for Self-supervised Video Recognition",
    "abstract": "Comments: 10 pages with appendix",
    "descriptor": "\nComments: 10 pages with appendix\n",
    "authors": [
      "Lin Zhang",
      "Qi She",
      "Zhengyang Shen",
      "Changhu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01194"
  }
]
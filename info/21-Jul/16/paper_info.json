[
  {
    "id": "arXiv:2107.06889",
    "title": "Counting list homomorphisms from graphs of bounded treewidth: tight  complexity bounds",
    "abstract": "The goal of this work is to give precise bounds on the counting complexity of\na family of generalized coloring problems (list homomorphisms) on\nbounded-treewidth graphs. Given graphs $G$, $H$, and lists $L(v)\\subseteq V(H)$\nfor every $v\\in V(G)$, a {\\em list homomorphism} is a function $f:V(G)\\to V(H)$\nthat preserves the edges (i.e., $uv\\in E(G)$ implies $f(u)f(v)\\in E(H)$) and\nrespects the lists (i.e., $f(v)\\in L(v))$. Standard techniques show that if $G$\nis given with a tree decomposition of width $t$, then the number of list\nhomomorphisms can be counted in time $|V(H)|^t\\cdot n^{\\mathcal{O}(1)}$. Our\nmain result is determining, for every fixed graph $H$, how much the base\n$|V(H)|$ in the running time can be improved. For a connected graph $H$ we\ndefine $\\operatorname{irr}(H)$ the following way: if $H$ has a loop or is\nnonbipartite, then $\\operatorname{irr}(H)$ is the maximum size of a set\n$S\\subseteq V(H)$ where any two vertices have different neighborhoods; if $H$\nis bipartite, then $\\operatorname{irr}(H)$ is the maximum size of such a set\nthat is fully in one of the bipartition classes. For disconnected $H$, we\ndefine $\\operatorname{irr}(H)$ as the maximum of $\\operatorname{irr}(C)$ over\nevery connected component $C$ of $H$. We show that, for every fixed graph $H$,\nthe number of list homomorphisms from $(G,L)$ to $H$\n* can be counted in time $\\operatorname{irr}(H)^t\\cdot n^{\\mathcal{O}(1)}$ if\na tree decomposition of $G$ having width at most $t$ is given in the input, and\n* cannot be counted in time $(\\operatorname{irr}(H)-\\epsilon)^t\\cdot\nn^{\\mathcal{O}(1)}$ for any $\\epsilon>0$, even if a tree decomposition of $G$\nhaving width at most $t$ is given in the input, unless the #SETH fails.\nThereby we give a precise and complete complexity classification featuring\nmatching upper and lower bounds for all target graphs with or without loops.",
    "descriptor": "",
    "authors": [
      "Jacob Focke",
      "D\u00e1niel Marx",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06889"
  },
  {
    "id": "arXiv:2107.06905",
    "title": "Transition-based Bubble Parsing: Improvements on Coordination Structure  Prediction",
    "abstract": "We propose a transition-based bubble parser to perform coordination structure\nidentification and dependency-based syntactic analysis simultaneously. Bubble\nrepresentations were proposed in the formal linguistics literature decades ago;\nthey enhance dependency trees by encoding coordination boundaries and internal\nrelationships within coordination structures explicitly. In this paper, we\nintroduce a transition system and neural models for parsing these\nbubble-enhanced structures. Experimental results on the English Penn Treebank\nand the English GENIA corpus show that our parsers beat previous\nstate-of-the-art approaches on the task of coordination structure prediction,\nespecially for the subset of sentences with complex coordination structures.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Tianze Shi",
      "Lillian Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06905"
  },
  {
    "id": "arXiv:2107.06907",
    "title": "TGIF: Tree-Graph Integrated-Format Parser for Enhanced UD with Two-Stage  Generic- to Individual-Language Finetuning",
    "abstract": "We present our contribution to the IWPT 2021 shared task on parsing into\nenhanced Universal Dependencies. Our main system component is a hybrid\ntree-graph parser that integrates (a) predictions of spanning trees for the\nenhanced graphs with (b) additional graph edges not present in the spanning\ntrees. We also adopt a finetuning strategy where we first train a\nlanguage-generic parser on the concatenation of data from all available\nlanguages, and then, in a second step, finetune on each individual language\nseparately. Additionally, we develop our own complete set of pre-processing\nmodules relevant to the shared task, including tokenization, sentence\nsegmentation, and multiword token expansion, based on pre-trained XLM-R models\nand our own pre-training of character-level language models. Our submission\nreaches a macro-average ELAS of 89.24 on the test set. It ranks top among all\nteams, with a margin of more than 2 absolute ELAS over the next best-performing\nsubmission, and best score on 16 out of 17 languages.",
    "descriptor": "\nComments: IWPT 2021 Shared Task\n",
    "authors": [
      "Tianze Shi",
      "Lillian Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06907"
  },
  {
    "id": "arXiv:2107.06908",
    "title": "Understanding Failures in Out-of-Distribution Detection with Deep  Generative Models",
    "abstract": "Deep generative models (DGMs) seem a natural fit for detecting\nout-of-distribution (OOD) inputs, but such models have been shown to assign\nhigher probabilities or densities to OOD images than images from the training\ndistribution. In this work, we explain why this behavior should be attributed\nto model misestimation. We first prove that no method can guarantee performance\nbeyond random chance without assumptions on which out-distributions are\nrelevant. We then interrogate the typical set hypothesis, the claim that\nrelevant out-distributions can lie in high likelihood regions of the data\ndistribution, and that OOD detection should be defined based on the data\ndistribution's typical set. We highlight the consequences implied by assuming\nsupport overlap between in- and out-distributions, as well as the arbitrariness\nof the typical set for OOD detection. Our results suggest that estimation error\nis a more plausible explanation than the misalignment between likelihood-based\nOOD detection and out-distributions of interest, and we illustrate how even\nminimal estimation error can lead to OOD detection failures, yielding\nimplications for future work in deep generative modeling and OOD detection.",
    "descriptor": "\nComments: Accepted at ICML 2021\n",
    "authors": [
      "Lily H. Zhang",
      "Mark Goldstein",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06908"
  },
  {
    "id": "arXiv:2107.06912",
    "title": "From Show to Tell: A Survey on Image Captioning",
    "abstract": "Connecting Vision and Language plays an essential role in Generative\nIntelligence. For this reason, in the last few years, a large research effort\nhas been devoted to image captioning, i.e. the task of describing images with\nsyntactically and semantically meaningful sentences. Starting from 2015 the\ntask has generally been addressed with pipelines composed of a visual encoding\nstep and a language model for text generation. During these years, both\ncomponents have evolved considerably through the exploitation of object\nregions, attributes, and relationships and the introduction of multi-modal\nconnections, fully-attentive approaches, and BERT-like early-fusion strategies.\nHowever, regardless of the impressive results obtained, research in image\ncaptioning has not reached a conclusive answer yet. This work aims at providing\na comprehensive overview and categorization of image captioning approaches,\nfrom visual encoding and text generation to training strategies, used datasets,\nand evaluation metrics. In this respect, we quantitatively compare many\nrelevant state-of-the-art approaches to identify the most impactful technical\ninnovations in image captioning architectures and training strategies.\nMoreover, many variants of the problem and its open challenges are analyzed and\ndiscussed. The final goal of this work is to serve as a tool for understanding\nthe existing state-of-the-art and highlighting the future directions for an\narea of research where Computer Vision and Natural Language Processing can find\nan optimal synergy.",
    "descriptor": "",
    "authors": [
      "Matteo Stefanini",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Silvia Cascianelli",
      "Giuseppe Fiameni",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06912"
  },
  {
    "id": "arXiv:2107.06916",
    "title": "Training Compact CNNs for Image Classification using Dynamic-coded  Filter Fusion",
    "abstract": "The mainstream approach for filter pruning is usually either to force a\nhard-coded importance estimation upon a computation-heavy pretrained model to\nselect \"important\" filters, or to impose a hyperparameter-sensitive sparse\nconstraint on the loss objective to regularize the network training. In this\npaper, we present a novel filter pruning method, dubbed dynamic-coded filter\nfusion (DCFF), to derive compact CNNs in a computation-economical and\nregularization-free manner for efficient image classification. Each filter in\nour DCFF is firstly given an inter-similarity distribution with a temperature\nparameter as a filter proxy, on top of which, a fresh Kullback-Leibler\ndivergence based dynamic-coded criterion is proposed to evaluate the filter\nimportance. In contrast to simply keeping high-score filters in other methods,\nwe propose the concept of filter fusion, i.e., the weighted averages using the\nassigned proxies, as our preserved filters. We obtain a one-hot\ninter-similarity distribution as the temperature parameter approaches infinity.\nThus, the relative importance of each filter can vary along with the training\nof the compact CNN, leading to dynamically changeable fused filters without\nboth the dependency on the pretrained model and the introduction of sparse\nconstraints. Extensive experiments on classification benchmarks demonstrate the\nsuperiority of our DCFF over the compared counterparts. For example, our DCFF\nderives a compact VGGNet-16 with only 72.77M FLOPs and 1.06M parameters while\nreaching top-1 accuracy of 93.47% on CIFAR-10. A compact ResNet-50 is obtained\nwith 63.8% FLOPs and 58.6% parameter reductions, retaining 75.60% top-1\naccuracy on ILSVRC-2012. Our code, narrower models and training logs are\navailable at https://github.com/lmbxmu/DCFF.",
    "descriptor": "",
    "authors": [
      "Mingbao Lin",
      "Rongrong Ji",
      "Bohong Chen",
      "Fei Chao",
      "Jianzhuang Liu",
      "Wei Zeng",
      "Yonghong Tian",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06916"
  },
  {
    "id": "arXiv:2107.06917",
    "title": "A Field Guide to Federated Optimization",
    "abstract": "Federated learning and analytics are a distributed approach for\ncollaboratively learning models (or statistics) from decentralized data,\nmotivated by and designed for privacy protection. The distributed learning\nprocess can be formulated as solving federated optimization problems, which\nemphasize communication efficiency, data heterogeneity, compatibility with\nprivacy and system requirements, and other constraints that are not primary\nconsiderations in other problem settings. This paper provides recommendations\nand guidelines on formulating, designing, evaluating and analyzing federated\noptimization algorithms through concrete examples and practical implementation,\nwith a focus on conducting effective simulations to infer real-world\nperformance. The goal of this work is not to survey the current literature, but\nto inspire researchers and practitioners to design federated learning\nalgorithms that can be used in various practical applications.",
    "descriptor": "",
    "authors": [
      "Jianyu Wang",
      "Zachary Charles",
      "Zheng Xu",
      "Gauri Joshi",
      "H. Brendan McMahan",
      "Blaise Aguera y Arcas",
      "Maruan Al-Shedivat",
      "Galen Andrew",
      "Salman Avestimehr",
      "Katharine Daly",
      "Deepesh Data",
      "Suhas Diggavi",
      "Hubert Eichner",
      "Advait Gadhikar",
      "Zachary Garrett",
      "Antonious M. Girgis",
      "Filip Hanzely",
      "Andrew Hard",
      "Chaoyang He",
      "Samuel Horvath",
      "Zhouyuan Huo",
      "Alex Ingerman",
      "Martin Jaggi",
      "Tara Javidi",
      "Peter Kairouz",
      "Satyen Kale",
      "Sai Praneeth Karimireddy",
      "Jakub Konecny",
      "Sanmi Koyejo",
      "Tian Li",
      "Luyang Liu",
      "Mehryar Mohri",
      "Hang Qi",
      "Sashank J. Reddi",
      "Peter Richtarik",
      "Karan Singhal",
      "Virginia Smith",
      "Mahdi Soltanolkotabi",
      "Weikang Song",
      "Ananda Theertha Suresh",
      "Sebastian U. Stich",
      "Ameet Talwalkar",
      "Hongyi Wang",
      "Blake Woodworth",
      "Shanshan Wu",
      "Felix X. Yu",
      "Honglin Yuan",
      "Manzil Zaheer",
      "Mi Zhang",
      "Tong Zhang",
      "Chunxiang Zheng",
      "Chen Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06917"
  },
  {
    "id": "arXiv:2107.06921",
    "title": "Potential UAV Landing Sites Detection through Digital Elevation Models  Analysis",
    "abstract": "In this paper, a simple technique for Unmanned Aerial Vehicles (UAVs)\npotential landing site detection using terrain information through\nidentification of flat areas, is presented. The algorithm utilizes digital\nelevation models (DEM) that represent the height distribution of an area. Flat\nareas which constitute appropriate landing zones for UAVs in normal or\nemergency situations result by thresholding the image gradient magnitude of the\ndigital surface model (DSM). The proposed technique also uses connected\ncomponents evaluation on the thresholded gradient image in order to discover\nconnected regions of sufficient size for landing. Moreover, man-made structures\nand vegetation areas are detected and excluded from the potential landing\nsites. Quantitative performance evaluation of the proposed landing site\ndetection algorithm in a number of areas on real world and synthetic datasets,\naccompanied by a comparison with a state-of-the-art algorithm, proves its\nefficiency and superiority.",
    "descriptor": "\nComments: Proceedings of the 2019 27th European Signal Processing Conference (EUSIPCO) satellite workshop \"Signal Processing Computer vision and Deep Learning for Autonomous Systems\"\n",
    "authors": [
      "Efstratios Kakaletsis",
      "Nikos Nikolaidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.06921"
  },
  {
    "id": "arXiv:2107.06922",
    "title": "A Byzantine Fault-Tolerant Consensus Library for Hyperledger Fabric",
    "abstract": "Hyperledger Fabric is an enterprise grade permissioned distributed ledger\nplatform that offers modularity for a broad set of industry use cases. One\nmodular component is a pluggable ordering service that establishes consensus on\nthe order of transactions and batches them into blocks. However, as of the time\nof this writing, there is no production grade Byzantine Fault-Tolerant (BFT)\nordering service for Fabric, with the latest version (v2.1) supporting only\nCrash Fault-Tolerance (CFT). In our work, we address crucial aspects of BFT\nintegration into Fabric that were left unsolved in all prior works, making them\nunfit for production use. In this work we describe the design and\nimplementation of a BFT ordering service for Fabric, employing a new BFT\nconsensus library. The new library, based on the BFT-Smart protocol and written\nin Go, is tailored to the blockchain use-case, yet is general enough to cater\nto a wide variety of other uses. We evaluate the new BFT ordering service by\ncomparing it with the currently supported Raft-based CFT ordering service in\nHyperledger Fabric.",
    "descriptor": "\nComments: IEEE International Conference on Blockchain and Cryptocurrency, this https URL\n",
    "authors": [
      "Artem Barger",
      "Yacov Manevich",
      "Hagar Meir",
      "Yoav Tock"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06922"
  },
  {
    "id": "arXiv:2107.06924",
    "title": "Deformable Elasto-Plastic Object Shaping using an Elastic Hand and  Model-Based Reinforcement Learning",
    "abstract": "Deformable solid objects such as clay or dough are prevalent in industrial\nand home environments. However, robotic manipulation of such objects has\nlargely remained unexplored in literature due to the high complexity involved\nin representing and modeling their deformation. This work addresses the problem\nof shaping elasto-plastic dough by proposing to use a novel elastic\nend-effector to roll dough in a reinforcement learning framework. The\ntransition model for the end-effector-to-dough interactions is learned from one\nhour of robot exploration, and doughs of different hydration levels are rolled\nout into varying lengths. Experimental results are encouraging, with the\nproposed framework accomplishing the task of rolling out dough into a specified\nlength with 60% fewer actions than a heuristic method. Furthermore, we show\nthat estimating stiffness using the soft end-effector can be used to\neffectively initialize models, improving robot performance by approximately 40%\nover incorrect model initialization.",
    "descriptor": "\nComments: 9 pages, 6 figures, To be published in Proc. 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Carolyn Matl",
      "Ruzena Bajcsy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06924"
  },
  {
    "id": "arXiv:2107.06925",
    "title": "Chimera: Efficiently Training Large-Scale Neural Networks with  Bidirectional Pipelines",
    "abstract": "Training large deep learning models at scale is very challenging. This paper\nproposes Chimera, a novel pipeline parallelism scheme which combines\nbidirectional pipelines for efficiently training large-scale models. Chimera is\na synchronous approach and therefore no loss of accuracy, which is more\nconvergence-friendly than asynchronous approaches. Compared with the latest\nsynchronous pipeline approach, Chimera reduces the number of bubbles by up to\n50%; benefiting from the sophisticated scheduling of bidirectional pipelines,\nChimera has a more balanced activation memory consumption. Evaluations are\nconducted on Transformer based language models. For a GPT-2 model with 1.3\nbillion parameters running on 2,048 GPU nodes of the Piz Daint supercomputer,\nChimera improves the training throughput by 1.16x-2.34x over the\nstate-of-the-art synchronous and asynchronous pipeline approaches.",
    "descriptor": "\nComments: The paper was accepted by the 2021 International Conference for High Performance Computing, Networking, Storage and Analysis (SC'21), in Best Paper Finalist\n",
    "authors": [
      "Shigang Li",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06925"
  },
  {
    "id": "arXiv:2107.06929",
    "title": "Feature Shift Detection: Localizing Which Features Have Shifted via  Conditional Distribution Tests",
    "abstract": "While previous distribution shift detection approaches can identify if a\nshift has occurred, these approaches cannot localize which specific features\nhave caused a distribution shift -- a critical step in diagnosing or fixing any\nunderlying issue. For example, in military sensor networks, users will want to\ndetect when one or more of the sensors has been compromised, and critically,\nthey will want to know which specific sensors might be compromised. Thus, we\nfirst define a formalization of this problem as multiple conditional\ndistribution hypothesis tests and propose both non-parametric and parametric\nstatistical tests. For both efficiency and flexibility, we then propose to use\na test statistic based on the density model score function (i.e. gradient with\nrespect to the input) -- which can easily compute test statistics for all\ndimensions in a single forward and backward pass. Any density model could be\nused for computing the necessary statistics including deep density models such\nas normalizing flows or autoregressive models. We additionally develop methods\nfor identifying when and where a shift occurs in multivariate time-series data\nand show results for multiple scenarios using realistic attack models on both\nsimulated and real world data.",
    "descriptor": "\nComments: NeurIPS 2020 Camera Ready\n",
    "authors": [
      "Sean Kulinski",
      "Saurabh Bagchi",
      "David I. Inouye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06929"
  },
  {
    "id": "arXiv:2107.06935",
    "title": "Object Retrieval and Localization in Large Art Collections using Deep  Multi-Style Feature Fusion and Iterative Voting",
    "abstract": "The search for specific objects or motifs is essential to art history as both\nassist in decoding the meaning of artworks. Digitization has produced large art\ncollections, but manual methods prove to be insufficient to analyze them. In\nthe following, we introduce an algorithm that allows users to search for image\nregions containing specific motifs or objects and find similar regions in an\nextensive dataset, helping art historians to analyze large digitized art\ncollections. Computer vision has presented efficient methods for visual\ninstance retrieval across photographs. However, applied to art collections,\nthey reveal severe deficiencies because of diverse motifs and massive domain\nshifts induced by differences in techniques, materials, and styles. In this\npaper, we present a multi-style feature fusion approach that successfully\nreduces the domain gap and improves retrieval results without labelled data or\ncurated image collections. Our region-based voting with GPU-accelerated\napproximate nearest-neighbour search allows us to find and localize even small\nmotifs within an extensive dataset in a few seconds. We obtain state-of-the-art\nresults on the Brueghel dataset and demonstrate its generalization to\ninhomogeneous collections with a large number of distractors.",
    "descriptor": "\nComments: Accepted at ECCV 2020 Workshop Computer Vision for Art Analysis\n",
    "authors": [
      "Nikolai Ufer",
      "Sabine Lang",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06935"
  },
  {
    "id": "arXiv:2107.06941",
    "title": "Mutually improved endoscopic image synthesis and landmark detection in  unpaired image-to-image translation",
    "abstract": "The CycleGAN framework allows for unsupervised image-to-image translation of\nunpaired data. In a scenario of surgical training on a physical surgical\nsimulator, this method can be used to transform endoscopic images of phantoms\ninto images which more closely resemble the intra-operative appearance of the\nsame surgical target structure. This can be viewed as a novel augmented reality\napproach, which we coined Hyperrealism in previous work. In this use case, it\nis of paramount importance to display objects like needles, sutures or\ninstruments consistent in both domains while altering the style to a more\ntissue-like appearance. Segmentation of these objects would allow for a direct\ntransfer, however, contouring of these, partly tiny and thin foreground objects\nis cumbersome and perhaps inaccurate. Instead, we propose to use landmark\ndetection on the points when sutures pass into the tissue. This objective is\ndirectly incorporated into a CycleGAN framework by treating the performance of\npre-trained detector models as an additional optimization goal. We show that a\ntask defined on these sparse landmark labels improves consistency of synthesis\nby the generator network in both domains. Comparing a baseline CycleGAN\narchitecture to our proposed extension (DetCycleGAN), mean precision (PPV)\nimproved by +61.32, mean sensitivity (TPR) by +37.91, and mean F1 score by\n+0.4743. Furthermore, it could be shown that by dataset fusion, generated\nintra-operative images can be leveraged as additional training data for the\ndetection network itself. The data is released within the scope of the AdaptOR\nMICCAI Challenge 2021 at https://adaptor2021.github.io/, and code at\nhttps://github.com/Cardio-AI/detcyclegan_pytorch.",
    "descriptor": "\nComments: Submitted to IEEE JBHI 2021, 13 pages, 8 figures, 4 tables\n",
    "authors": [
      "Lalith Sharan",
      "Gabriele Romano",
      "Sven Koehler",
      "Halvar Kelm",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06941"
  },
  {
    "id": "arXiv:2107.06943",
    "title": "FetalNet: Multi-task deep learning framework for fetal ultrasound  biometric measurements",
    "abstract": "In this paper, we propose an end-to-end multi-task neural network called\nFetalNet with an attention mechanism and stacked module for spatio-temporal\nfetal ultrasound scan video analysis. Fetal biometric measurement is a standard\nexamination during pregnancy used for the fetus growth monitoring and\nestimation of gestational age and fetal weight. The main goal in fetal\nultrasound scan video analysis is to find proper standard planes to measure the\nfetal head, abdomen and femur. Due to natural high speckle noise and shadows in\nultrasound data, medical expertise and sonographic experience are required to\nfind the appropriate acquisition plane and perform accurate measurements of the\nfetus. In addition, existing computer-aided methods for fetal US biometric\nmeasurement address only one single image frame without considering temporal\nfeatures. To address these shortcomings, we propose an end-to-end multi-task\nneural network for spatio-temporal ultrasound scan video analysis to\nsimultaneously localize, classify and measure the fetal body parts. We propose\na new encoder-decoder segmentation architecture that incorporates a\nclassification branch. Additionally, we employ an attention mechanism with a\nstacked module to learn salient maps to suppress irrelevant US regions and\nefficient scan plane localization. We trained on the fetal ultrasound video\ncomes from routine examinations of 700 different patients. Our method called\nFetalNet outperforms existing state-of-the-art methods in both classification\nand segmentation in fetal ultrasound video recordings.",
    "descriptor": "\nComments: Submitted to ICONIP 2021\n",
    "authors": [
      "Szymon P\u0142otka",
      "Tomasz W\u0142odarczyk",
      "Adam Klasa",
      "Micha\u0142 Lipa",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06943"
  },
  {
    "id": "arXiv:2107.06944",
    "title": "On the impossibility of non-trivial accuracy under fairness constraints",
    "abstract": "One of the main concerns about fairness in machine learning (ML) is that, in\norder to achieve it, one may have to renounce to some accuracy. Having this\ntrade-off in mind, Hardt et al. have proposed the notion of equal opportunities\n(EO), designed so as to be compatible with accuracy. In fact, it can be shown\nthat if the source of input data is deterministic, the two notions go well\nalong with each other. In the probabilistic case, however, things change.\nAs we show, there are probabilistic data sources for which EO can only be\nachieved at the total detriment of accuracy, i.e. among the models that achieve\nEO, those whose prediction does not depend on the input have the highest\naccuracy.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Carlos Pinz\u00f3n",
      "Catuscia Palamidessi",
      "Pablo Piantanida",
      "Frank Valencia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.06944"
  },
  {
    "id": "arXiv:2107.06945",
    "title": "Twisted Reed-Solomon Codes",
    "abstract": "In this article, we present a new construction of evaluation codes in the\nHamming metric, which we call twisted Reed-Solomon codes. Whereas Reed-Solomon\n(RS) codes are MDS codes, this need not be the case for twisted RS codes.\nNonetheless, we show that our construction yields several families of MDS\ncodes. Further, for a large subclass of (MDS) twisted RS codes, we show that\nthe new codes are not generalized RS codes. To achieve this, we use properties\nof Schur squares of codes as well as an explicit description of the dual of a\nlarge subclass of our codes. We conclude the paper with a description of a\ndecoder, that performs very well in practice as shown by extensive simulation\nresults.",
    "descriptor": "",
    "authors": [
      "Peter Beelen",
      "Sven Puchinger",
      "Johan Rosenkilde"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06945"
  },
  {
    "id": "arXiv:2107.06946",
    "title": "Towards Quantifying the Carbon Emissions of Differentially Private  Machine Learning",
    "abstract": "In recent years, machine learning techniques utilizing large-scale datasets\nhave achieved remarkable performance. Differential privacy, by means of adding\nnoise, provides strong privacy guarantees for such learning algorithms. The\ncost of differential privacy is often a reduced model accuracy and a lowered\nconvergence speed. This paper investigates the impact of differential privacy\non learning algorithms in terms of their carbon footprint due to either longer\nrun-times or failed experiments. Through extensive experiments, further\nguidance is provided on choosing the noise levels which can strike a balance\nbetween desired privacy levels and reduced carbon emissions.",
    "descriptor": "\nComments: 4+3 pages; 6 figures; 8 tables. Accepted at SRML workshop at ICML'21\n",
    "authors": [
      "Rakshit Naidu",
      "Harshita Diddee",
      "Ajinkya Mulay",
      "Aleti Vardhan",
      "Krithika Ramesh",
      "Ahmed Zamzam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06946"
  },
  {
    "id": "arXiv:2107.06951",
    "title": "Levenshtein Graphs: Resolvability, Automorphisms & Determining Sets",
    "abstract": "We introduce the notion of Levenshtein graphs, an analog to Hamming graphs\nbut using the edit distance instead of the Hamming distance; in particular,\nLevenshtein graphs allow for underlying strings (nodes) of different lengths.\nWe characterize various properties of these graphs, including a necessary and\nsufficient condition for their geodesic distance to be identical to the edit\ndistance, their automorphism group and determining number, and an upper bound\non their metric dimension. Regarding the latter, we construct a resolving set\ncomposed of two-run strings and an algorithm that computes the edit distance\nbetween a string of length $k$ and any single-run or two-run string in $O(k)$\noperations.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Perrin E. Ruth",
      "Manuel E. Lladser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.06951"
  },
  {
    "id": "arXiv:2107.06955",
    "title": "HTLM: Hyper-Text Pre-Training and Prompting of Language Models",
    "abstract": "We introduce HTLM, a hyper-text language model trained on a large-scale web\ncrawl. Modeling hyper-text has a number of advantages: (1) it is easily\ngathered at scale, (2) it provides rich document-level and end-task-adjacent\nsupervision (e.g. class and id attributes often encode document category\ninformation), and (3) it allows for new structured prompting that follows the\nestablished semantics of HTML (e.g. to do zero-shot summarization by infilling\ntitle tags for a webpage that contains the input text). We show that\npretraining with a BART-style denoising loss directly on simplified HTML\nprovides highly effective transfer for a wide range of end tasks and\nsupervision levels. HTLM matches or exceeds the performance of comparably sized\ntext-only LMs for zero-shot prompting and fine-tuning for classification\nbenchmarks, while also setting new state-of-the-art performance levels for\nzero-shot summarization. We also find that hyper-text prompts provide more\nvalue to HTLM, in terms of data efficiency, than plain text prompts do for\nexisting LMs, and that HTLM is highly effective at auto-prompting itself, by\nsimply generating the most likely hyper-text formatting for any available\ntraining data. We will release all code and models to support future HTLM\nresearch.",
    "descriptor": "",
    "authors": [
      "Armen Aghajanyan",
      "Dmytro Okhonko",
      "Mike Lewis",
      "Mandar Joshi",
      "Hu Xu",
      "Gargi Ghosh",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06955"
  },
  {
    "id": "arXiv:2107.06956",
    "title": "On the construction of conservative semi-Lagrangian IMEX advection  schemes for multiscale time dependent PDEs",
    "abstract": "This article is devoted to the construction of a new class of semi-Lagrangian\n(SL) schemes with implicit-explicit (IMEX) Runge-Kutta (RK) time stepping for\nPDEs involving multiple space-time scales. The semi-Lagrangian (SL) approach\nfully couples the space and time discretization, thus making the use of RK\nstrategies particularly difficult to be combined with. First, a simple scalar\nadvection-diffusion equation is considered as a prototype PDE for the\ndevelopment of a high order formulation of the semi-Lagrangian IMEX algorithms.\nThe advection part of the PDE is discretized explicitly at the aid of a SL\ntechnique, while an implicit discretization is employed for the diffusion\nterms. Second, the SL-IMEX approach is extended to deal with hyperbolic systems\nwith multiple scales, including balance laws, that involve shock waves and\nother discontinuities. A novel SL technique is proposed, which is based on the\nintegration of the governing equations over the space-time control volume which\narises from the motion of each grid point. High order of accuracy is ensured by\nthe usage of IMEX RK schemes combined with a Cauchy-Kowalevskaya procedure that\nprovides a predictor solution within each space-time element. The\none-dimensional shallow water equations (SWE) are chosen to validate the new\nconservative SL-IMEX schemes, where convection and pressure fluxes are treated\nexplicitly and implicitly, respectively. The asymptotic-preserving (AP)\nproperty of the novel schemes is also studied considering a relaxation PDE\nsystem for the SWE. A large suite of convergence studies for both the\nnon-conservative and the conservative version of the novel class of methods\ndemonstrates that the formal order of accuracy is achieved and numerical\nevidences about the conservation property are shown. The AP property for the\ncorresponding relaxation system is also investigated.",
    "descriptor": "",
    "authors": [
      "Walter Boscheri",
      "Maurizio Tavelli",
      "Lorenzo Pareschi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06956"
  },
  {
    "id": "arXiv:2107.06959",
    "title": "FST: the FAIR Speech Translation System for the IWSLT21 Multilingual  Shared Task",
    "abstract": "In this paper, we describe our end-to-end multilingual speech translation\nsystem submitted to the IWSLT 2021 evaluation campaign on the Multilingual\nSpeech Translation shared task. Our system is built by leveraging transfer\nlearning across modalities, tasks and languages. First, we leverage\ngeneral-purpose multilingual modules pretrained with large amounts of\nunlabelled and labelled data. We further enable knowledge transfer from the\ntext task to the speech task by training two tasks jointly. Finally, our\nmultilingual model is finetuned on speech translation task-specific data to\nachieve the best translation results. Experimental results show our system\noutperforms the reported systems, including both end-to-end and cascaded based\napproaches, by a large margin.\nIn some translation directions, our speech translation results evaluated on\nthe public Multilingual TEDx test set are even comparable with the ones from a\nstrong text-to-text translation system, which uses the oracle speech\ntranscripts as input.",
    "descriptor": "\nComments: Accepted by IWSLT 2021 as a system paper\n",
    "authors": [
      "Yun Tang",
      "Hongyu Gong",
      "Xian Li",
      "Changhan Wang",
      "Juan Pino",
      "Holger Schwenk",
      "Naman Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06959"
  },
  {
    "id": "arXiv:2107.06960",
    "title": "Memory-Aware Fusing and Tiling of Neural Networks for Accelerated Edge  Inference",
    "abstract": "A rising research challenge is running costly machine learning (ML) networks\nlocally on resource-constrained edge devices. ML networks with large\nconvolutional layers can easily exceed available memory, increasing latency due\nto excessive swapping. Previous memory reduction techniques such as pruning and\nquantization reduce model accuracy and often require retraining. Alternatively,\ndistributed methods partition the convolutions into equivalent smaller\nsub-computations, but the implementations introduce communication costs and\nrequire a network of devices. However, a distributed partitioning approach can\nalso be used to run in a reduced memory footprint on a single device by\nsubdividing the network into smaller operations.\nThis report extends prior work on distributed partitioning using tiling and\nfusing of convolutional layers into a memory-aware execution on a single\ndevice. Our approach extends prior fusing strategies to allow for two groups of\nconvolutional layers that are fused and tiled independently. This approach\nreduces overhead via data reuse, and reduces the memory footprint further. We\nalso propose a memory usage predictor coupled with a search algorithm to\nprovide fusing and tiling configurations for an arbitrary set of convolutional\nlayers. When applied to the YOLOv2 object detection network, results show that\nour approach can run in less than half the memory, and with a speedup of up to\n2.78 under severe memory constraints. Additionally, our algorithm will return a\nconfiguration with a latency that is within 6% of the best latency measured in\na manual search.",
    "descriptor": "",
    "authors": [
      "Jackson Farley",
      "Andreas Gerstlauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.06960"
  },
  {
    "id": "arXiv:2107.06963",
    "title": "Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable  Features",
    "abstract": "Knowledge-grounded dialogue systems are intended to convey information that\nis based on evidence provided in a given source text. We discuss the challenges\nof training a generative neural dialogue model for such systems that is\ncontrolled to stay faithful to the evidence. Existing datasets contain a mix of\nconversational responses that are faithful to selected evidence as well as more\nsubjective or chit-chat style responses. We propose different evaluation\nmeasures to disentangle these different styles of responses by quantifying the\ninformativeness and objectivity. At training time, additional inputs based on\nthese evaluation measures are given to the dialogue model. At generation time,\nthese additional inputs act as stylistic controls that encourage the model to\ngenerate responses that are faithful to the provided evidence. We also\ninvestigate the usage of additional controls at decoding time using resampling\ntechniques. In addition to automatic metrics, we perform a human evaluation\nstudy where raters judge the output of these controlled generation models to be\ngenerally more objective and faithful to the evidence compared to baseline\ndialogue systems.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Hannah Rashkin",
      "David Reitter",
      "Gaurav Singh Tomar",
      "Dipanjan Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06963"
  },
  {
    "id": "arXiv:2107.06964",
    "title": "Surgical Instruction Generation with Transformers",
    "abstract": "Automatic surgical instruction generation is a prerequisite towards\nintra-operative context-aware surgical assistance. However, generating\ninstructions from surgical scenes is challenging, as it requires jointly\nunderstanding the surgical activity of current view and modelling relationships\nbetween visual information and textual description. Inspired by the neural\nmachine translation and imaging captioning tasks in open domain, we introduce a\ntransformer-backboned encoder-decoder network with self-critical reinforcement\nlearning to generate instructions from surgical images. We evaluate the\neffectiveness of our method on DAISI dataset, which includes 290 procedures\nfrom various medical disciplines. Our approach outperforms the existing\nbaseline over all caption evaluation metrics. The results demonstrate the\nbenefits of the encoder-decoder structure backboned by transformer in handling\nmultimodal context.",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Jinglu Zhang",
      "Yinyu Nie",
      "Jian Chang",
      "Jian Jun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06964"
  },
  {
    "id": "arXiv:2107.06965",
    "title": "Connections Between Finite Difference and Finite Element Approximations",
    "abstract": "We present useful connections between the finite difference and the finite\nelement methods for a model boundary value problem. We start from the\nobservation that, in the finite element context, the interpolant of the\nsolution in one dimension coincides with the finite element approximation of\nthe solution. This result can be viewed as an extension of the Green function\nformula for the solution at the continuous level. We write the finite\ndifference and the finite element systems such that the two corresponding\nlinear systems have the same stiffness matrices and compare the right hand side\nload vectors for the two methods. Using evaluation of the Green function, a\nformula for the inverse of the stiffness matrix is extended to the case of\nnon-uniformly distributed mesh points. We provide an error analysis based on\nthe connection between the two methods, and estimate the energy norm of the\ndifference of the two solutions. Interesting extensions to the 2D case are\nprovided.",
    "descriptor": "\nComments: Submitted to Applicable Analysis Journal on July 2, 2021\n",
    "authors": [
      "Cristina Bacuta",
      "Constantin Bacuta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.06965"
  },
  {
    "id": "arXiv:2107.06970",
    "title": "Identifying Competition and Mutualism Between Online Groups",
    "abstract": "Platforms often host multiple online groups with highly overlapping topics\nand members. How can researchers and designers understand how interactions\nbetween related groups affect measures of group health? Inspired by population\necology, prior social computing research has studied competition and mutualism\namong related groups by correlating group size with degrees of overlap in\ncontent and membership. The resulting body of evidence is puzzling as overlaps\nseem sometimes to help and other times to hurt. We suggest that this confusion\nresults from aggregating inter-group relationships into an overall\nenvironmental effect instead of focusing on networks of competition and\nmutualism among groups. We propose a theoretical framework based on community\necology and a method for inferring competitive and mutualistic interactions\nfrom time series participation data. We compare population and community\necology analyses of online community growth by analyzing clusters of subreddits\nwith high user overlap but varying degrees of competition and mutualism.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Nathan TeBlunthuis",
      "Benjamin Mako Hill"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06970"
  },
  {
    "id": "arXiv:2107.06973",
    "title": "Solving sparse linear systems with approximate inverse preconditioners  on analog devices",
    "abstract": "Sparse linear system solvers are computationally expensive kernels that lie\nat the heart of numerous applications. This paper proposes a flexible\npreconditioning framework to substantially reduce the time and energy\nrequirements of this task by utilizing a hybrid architecture that combines\nconventional digital microprocessors with analog crossbar array accelerators.\nOur analysis and experiments with a simulator for analog hardware demonstrate\nthat an order of magnitude speedup is readily attainable without much impact on\nconvergence, despite the noise in analog computations.",
    "descriptor": "",
    "authors": [
      "Vasileios Kalantzis",
      "Anshul Gupta",
      "Lior Horesh",
      "Tomasz Nowicki",
      "Mark S. Squillante",
      "Chai Wah Wu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.06973"
  },
  {
    "id": "arXiv:2107.06978",
    "title": "Look who's watching: platform labels and user engagement on state-backed  media outlets",
    "abstract": "Recently, social media platforms have introduced several measures to counter\nmisleading information. Among these measures are state media labels which help\nusers identify and evaluate the credibility of state-backed news. YouTube was\nthe first platform to introduce labels that provide information about\nstate-backed news channels. While previous work has examined the efficiency of\ninformation labels in controlled lab settings, few studies have examined how\nstate media labels affect user perceptions of content from state-backed\noutlets. This paper proposes new methodological and theoretical approaches to\ninvestigate the effect of state media labels on user engagement with content.\nDrawing on a content analysis of 8,071 YouTube comments posted before and after\nthe labelling of five state-funded channels (Al Jazeera English, CGTN, RT, TRT\nWorld, and Voice of America), this paper analyses the effect state media labels\nhad on user engagement with state-backed media content. We found the labels had\nno impact on the amount of likes videos received before and after the policy\nintroduction, except for RT which received less likes after it was labelled.\nHowever, for RT, comments left by users were associated with 30 percent\ndecrease in the likelihood of observing a critical comment following the policy\nimplementation, and a 70 percent decrease in likelihood of observing a critical\ncomment about RT as a media source. While other state-funded broadcasters, like\nAl Jazeera English and VOA News, received fewer critical comments after YouTube\nintroduced its policy; this relationship was associated with how political the\nvideo was, rather than the policy change. Our study contributes to the ongoing\ndiscussion on the efficacy of platform governance in relation to state-backed\nmedia, showing that audience preferences impact the effectiveness of labels.",
    "descriptor": "\nComments: 25 pages, 7 tables\n",
    "authors": [
      "Samantha Bradshaw",
      "Mona Elswah",
      "Antonella Perini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06978"
  },
  {
    "id": "arXiv:2107.06980",
    "title": "Online Allocation and Display Ads Optimization with Surplus Supply",
    "abstract": "In this work, we study a scenario where a publisher seeks to maximize its\ntotal revenue across two sales channels: guaranteed contracts that promise to\ndeliver a certain number of impressions to the advertisers, and spot demands\nthrough an Ad Exchange. On the one hand, if a guaranteed contract is not fully\ndelivered, it incurs a penalty for the publisher. On the other hand, the\npublisher might be able to sell an impression at a high price in the Ad\nExchange. How does a publisher maximize its total revenue as a sum of the\nrevenue from the Ad Exchange and the loss from the under-delivery penalty? We\nstudy this problem parameterized by \\emph{supply factor $f$}: a notion we\nintroduce that, intuitively, captures the number of times a publisher can\nsatisfy all its guaranteed contracts given its inventory supply. In this work\nwe present a fast simple deterministic algorithm with the optimal competitive\nratio. The algorithm and the optimal competitive ratio are a function of the\nsupply factor, penalty, and the distribution of the bids in the Ad Exchange.\nBeyond the yield optimization problem, classic online allocation problems\nsuch as online bipartite matching of [Karp-Vazirani-Vazirani '90] and its\nvertex-weighted variant of [Aggarwal et al. '11] can be studied in the presence\nof the additional supply guaranteed by the supply factor. We show that a supply\nfactor of $f$ improves the approximation factors from $1-1/e$ to $f-fe^{-1/f}$.\nOur approximation factor is tight and approaches $1$ as $f \\to \\infty$.",
    "descriptor": "",
    "authors": [
      "Melika Abolhassani",
      "Hossein Esfandiari",
      "Yasamin Nazari",
      "Balasubramanian Sivan",
      "Yifeng Teng",
      "Creighton Thomas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06980"
  },
  {
    "id": "arXiv:2107.06981",
    "title": "Mapping Learning Algorithms on Data, a useful step for optimizing  performances and their comparison",
    "abstract": "In the paper, we propose a novel methodology to map learning algorithms on\ndata (performance map) in order to gain more insights in the distribution of\ntheir performances across their parameter space. This methodology provides\nuseful information when selecting a learner's best configuration for the data\nat hand, and it also enhances the comparison of learners across learning\ncontexts. In order to explain the proposed methodology, the study introduces\nthe notions of learning context, performance map, and high performance\nfunction. It then applies these concepts to a variety of learning contexts to\nshow how their use can provide more insights in a learner's behavior, and can\nenhance the comparison of learners across learning contexts. The study is\ncompleted by an extensive experimental study describing how the proposed\nmethodology can be applied.",
    "descriptor": "\nComments: The main classification class for the paper is Machine Learning\n",
    "authors": [
      "Filippo Neri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06981"
  },
  {
    "id": "arXiv:2107.06986",
    "title": "$\\ell^p\\!-\\!\\ell^q$-Norm Minimization for Joint Precoding and  Peak-to-Average-Power Ratio Reduction",
    "abstract": "Wireless communication systems that rely on orthogonal frequency-division\nmultiplexing (OFDM) suffer from a high peak-to-average (power) ratio (PAR),\nwhich necessitates power-inefficient radio-frequency (RF) chains to avoid an\nincrease in error-vector magnitude (EVM) and out-of-band (OOB) emissions. The\nsituation is further aggravated in massive multiuser (MU) multiple-input\nmultiple-output (MIMO) systems that would require hundreds of linear RF chains.\nIn this paper, we present a novel approach to joint precoding and PAR reduction\nthat builds upon a novel $\\ell^p\\!-\\!\\ell^q$-norm formulation, which is able to\nfind minimum PAR solutions while suppressing MU interference. We provide a\ntheoretical underpinning of our approach and provide simulation results for a\nmassive MU-MIMO-OFDM system that demonstrate significant reductions in PAR at\nlow complexity, without causing an increase in EVM or OOB emissions.",
    "descriptor": "\nComments: to appear at ASILOMAR 2021\n",
    "authors": [
      "Sueda Taner",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.06986"
  },
  {
    "id": "arXiv:2107.06990",
    "title": "Annotation and Classification of Evidence and Reasoning Revisions in  Argumentative Writing",
    "abstract": "Automated writing evaluation systems can improve students' writing insofar as\nstudents attend to the feedback provided and revise their essay drafts in ways\naligned with such feedback. Existing research on revision of argumentative\nwriting in such systems, however, has focused on the types of revisions\nstudents make (e.g., surface vs. content) rather than the extent to which\nrevisions actually respond to the feedback provided and improve the essay. We\nintroduce an annotation scheme to capture the nature of sentence-level\nrevisions of evidence use and reasoning (the `RER' scheme) and apply it to 5th-\nand 6th-grade students' argumentative essays. We show that reliable manual\nannotation can be achieved and that revision annotations correlate with a\nholistic assessment of essay improvement in line with the feedback provided.\nFurthermore, we explore the feasibility of automatically classifying revisions\naccording to our scheme.",
    "descriptor": "\nComments: 10 pages, 11 tables, 15th Workshop on Innovative Use of NLP for Building Educational Applications\n",
    "authors": [
      "Tazin Afrin",
      "Elaine Wang",
      "Diane Litman",
      "Lindsay C. Matsumura",
      "Richard Correnti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06990"
  },
  {
    "id": "arXiv:2107.06991",
    "title": "Physics-informed generative neural network: an application to  troposphere temperature prediction",
    "abstract": "The troposphere is one of the atmospheric layers where most weather phenomena\noccur. Temperature variations in the troposphere, especially at 500 hPa, a\ntypical level of the middle troposphere, are significant indicators of future\nweather changes. Numerical weather prediction is effective for temperature\nprediction, but its computational complexity hinders a timely response. This\npaper proposes a novel temperature prediction approach in framework\nofphysics-informed deep learning. The new model, called PGnet, builds upon a\ngenerative neural network with a mask matrix. The mask is designed to\ndistinguish the low-quality predicted regions generated by the first physical\nstage. The generative neural network takes the mask as prior for the\nsecond-stage refined predictions. A mask-loss and a jump pattern strategy are\ndeveloped to train the generative neural network without accumulating errors\nduring making time-series predictions. Experiments on ERA5 demonstrate that\nPGnet can generate more refined temperature predictions than the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Zhihao Chen",
      "Jie Gao",
      "Weikai Wang",
      "Zheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06991"
  },
  {
    "id": "arXiv:2107.06992",
    "title": "Finding Significant Features for Few-Shot Learning using Dimensionality  Reduction",
    "abstract": "Few-shot learning is a relatively new technique that specializes in problems\nwhere we have little amounts of data. The goal of these methods is to classify\ncategories that have not been seen before with just a handful of samples.\nRecent approaches, such as metric learning, adopt the meta-learning strategy in\nwhich we have episodic tasks conformed by support (training) data and query\n(test) data. Metric learning methods have demonstrated that simple models can\nachieve good performance by learning a similarity function to compare the\nsupport and the query data. However, the feature space learned by a given\nmetric learning approach may not exploit the information given by a specific\nfew-shot task. In this work, we explore the use of dimension reduction\ntechniques as a way to find task-significant features helping to make better\npredictions. We measure the performance of the reduced features by assigning a\nscore based on the intra-class and inter-class distance, and selecting a\nfeature reduction method in which instances of different classes are far away\nand instances of the same class are close. This module helps to improve the\naccuracy performance by allowing the similarity function, given by the metric\nlearning method, to have more discriminative features for the classification.\nOur method outperforms the metric learning baselines in the miniImageNet\ndataset by around 2% in accuracy performance.",
    "descriptor": "\nComments: This paper is currently under review for the Mexican International Conference on Artificial Intelligence (MICAI) 2021\n",
    "authors": [
      "Mauricio Mendez-Ruiz",
      "Ivan Garcia Jorge Gonzalez-Zapata",
      "Gilberto Ochoa-Ruiz",
      "Andres Mendez-Vazquez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06992"
  },
  {
    "id": "arXiv:2107.06993",
    "title": "Confidence Conditioned Knowledge Distillation",
    "abstract": "In this paper, a novel confidence conditioned knowledge distillation (CCKD)\nscheme for transferring the knowledge from a teacher model to a student model\nis proposed. Existing state-of-the-art methods employ fixed loss functions for\nthis purpose and ignore the different levels of information that need to be\ntransferred for different samples. In addition to that, these methods are also\ninefficient in terms of data usage. CCKD addresses these issues by leveraging\nthe confidence assigned by the teacher model to the correct class to devise\nsample-specific loss functions (CCKD-L formulation) and targets (CCKD-T\nformulation). Further, CCKD improves the data efficiency by employing\nself-regulation to stop those samples from participating in the distillation\nprocess on which the student model learns faster. Empirical evaluations on\nseveral benchmark datasets show that CCKD methods achieve at least as much\ngeneralization performance levels as other state-of-the-art methods while being\ndata efficient in the process. Student models trained through CCKD methods do\nnot retain most of the misclassifications commited by the teacher model on the\ntraining set. Distillation through CCKD methods improves the resilience of the\nstudent models against adversarial attacks compared to the conventional KD\nmethod. Experiments show at least 3% increase in performance against\nadversarial attacks for the MNIST and the Fashion MNIST datasets, and at least\n6% increase for the CIFAR10 dataset.",
    "descriptor": "\nComments: 31 pages, 41 references, 5 figures, 9 tables\n",
    "authors": [
      "Sourav Mishra",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06993"
  },
  {
    "id": "arXiv:2107.06994",
    "title": "What underlies rapid learning and systematic generalization in humans",
    "abstract": "Despite the groundbreaking successes of neural networks, contemporary models\nrequire extensive training with massive datasets and exhibit poor out-of-sample\ngeneralization. One proposed solution is to build systematicity and\ndomain-specific constraints into the model, echoing the tenets of classical,\nsymbolic cognitive architectures. In this paper, we consider the limitations of\nthis approach by examining human adults' ability to learn an abstract reasoning\ntask from a brief instructional tutorial and explanatory feedback for incorrect\nresponses, demonstrating that human learning dynamics and ability to generalize\noutside the range of the training examples differ drastically from those of a\nrepresentative neural network model, and that the model is brittle to changes\nin features not anticipated by its authors. We present further evidence from\nhuman data that the ability to consistently solve the puzzles was associated\nwith education, particularly basic mathematics education, and with the ability\nto provide a reliably identifiable, valid description of the strategy used. We\npropose that rapid learning and systematic generalization in humans may depend\non a gradual, experience-dependent process of learning-to-learn using\ninstructions and explanations to guide the construction of explicit abstract\nrules that support generalizable inferences.",
    "descriptor": "\nComments: 22 pages, 48 references, 6 Figures, and one Table, plus SI\n",
    "authors": [
      "Andrew Joohun Nam",
      "James L. McClelland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2107.06994"
  },
  {
    "id": "arXiv:2107.06995",
    "title": "Low-Rank Temporal Attention-Augmented Bilinear Network for financial  time-series forecasting",
    "abstract": "Financial market analysis, especially the prediction of movements of stock\nprices, is a challenging problem. The nature of financial time-series data,\nbeing non-stationary and nonlinear, is the main cause of these challenges. Deep\nlearning models have led to significant performance improvements in many\nproblems coming from different domains, including prediction problems of\nfinancial time-series data. Although the prediction performance is the main\ngoal of such models, dealing with ultra high-frequency data sets restrictions\nin terms of the number of model parameters and its inference speed. The\nTemporal Attention-Augmented Bilinear network was recently proposed as an\nefficient and high-performing model for Limit Order Book time-series\nforecasting. In this paper, we propose a low-rank tensor approximation of the\nmodel to further reduce the number of trainable parameters and increase its\nspeed.",
    "descriptor": "",
    "authors": [
      "Mostafa Shabani",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06995"
  },
  {
    "id": "arXiv:2107.06996",
    "title": "Elastic Graph Neural Networks",
    "abstract": "While many existing graph neural networks (GNNs) have been proven to perform\n$\\ell_2$-based graph smoothing that enforces smoothness globally, in this work\nwe aim to further enhance the local smoothness adaptivity of GNNs via\n$\\ell_1$-based graph smoothing. As a result, we introduce a family of GNNs\n(Elastic GNNs) based on $\\ell_1$ and $\\ell_2$-based graph smoothing. In\nparticular, we propose a novel and general message passing scheme into GNNs.\nThis message passing algorithm is not only friendly to back-propagation\ntraining but also achieves the desired smoothing properties with a theoretical\nconvergence guarantee. Experiments on semi-supervised learning tasks\ndemonstrate that the proposed Elastic GNNs obtain better adaptivity on\nbenchmark datasets and are significantly robust to graph adversarial attacks.\nThe implementation of Elastic GNNs is available at\n\\url{https://github.com/lxiaorui/ElasticGNN}.",
    "descriptor": "\nComments: ICML 2021 (International Conference on Machine Learning)\n",
    "authors": [
      "Xiaorui Liu",
      "Wei Jin",
      "Yao Ma",
      "Yaxin Li",
      "Hua Liu",
      "Yiqi Wang",
      "Ming Yan",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.06996"
  },
  {
    "id": "arXiv:2107.06997",
    "title": "DeepHyperion: Exploring the Feature Space of Deep Learning-Based Systems  through Illumination Search",
    "abstract": "Deep Learning (DL) has been successfully applied to a wide range of\napplication domains, including safety-critical ones. Several DL testing\napproaches have been recently proposed in the literature but none of them aims\nto assess how different interpretable features of the generated inputs affect\nthe system's behaviour. In this paper, we resort to Illumination Search to find\nthe highest-performing test cases (i.e., misbehaving and closest to\nmisbehaving), spread across the cells of a map representing the feature space\nof the system. We introduce a methodology that guides the users of our approach\nin the tasks of identifying and quantifying the dimensions of the feature space\nfor a given domain. We developed DeepHyperion, a search-based tool for DL\nsystems that illuminates, i.e., explores at large, the feature space, by\nproviding developers with an interpretable feature map where automatically\ngenerated inputs are placed along with information about the exposed\nbehaviours.",
    "descriptor": "\nComments: To be published in Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA '21), July 11-17, 2021, Virtual, Denmark. ACM, New York, NY, USA, 12 pages\n",
    "authors": [
      "Tahereh Zohdinasab",
      "Vincenzo Riccio",
      "Alessio Gambi",
      "Paolo Tonella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06997"
  },
  {
    "id": "arXiv:2107.06999",
    "title": "Reuse of Semantic Models for Emerging Smart Grids Applications",
    "abstract": "Data in the energy domain grows at unprecedented rates. Despite the great\npotential that IoT platforms and other big data-driven technologies have\nbrought in the energy sector, data exchange and data integration are still not\nwholly achieved. As a result, fragmented applications are developed against\nenergy data silos, and data exchange is limited to few applications. Therefore,\nthis paper identifies semantic models that can be reused for building\ninteroperable energy management services and applications. The ambition is to\ninnovate the Institute Mihajlo Pupin proprietary SCADA system and to enable\nintegration of the Institute Mihajlo Pupin services and applications in the\nEuropean Union (EU) Energy Data Space. The selection of reusable models has\nbeen done based on a set of scenarios related to electricity balancing\nservices, predictive maintenance services, and services for the residential,\ncommercial and industrial sectors.",
    "descriptor": "\nComments: Paper presented at the ICIST Conference 2021\n",
    "authors": [
      "Valentina Janev",
      "Du\u0161an Popadi\u0107",
      "Dea Puji\u0107",
      "Maria Esther Vidal",
      "Kemele Endris"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.06999"
  },
  {
    "id": "arXiv:2107.07000",
    "title": "Sensorimotor-inspired Tactile Feedback and Control Improve Consistency  of Prosthesis Manipulation in the Absence of Direct Vision",
    "abstract": "The lack of haptically aware upper-limb prostheses forces amputees to rely\nlargely on visual cues to complete activities of daily living. In contrast,\nable-bodied individuals inherently rely on conscious haptic perception and\nautomatic tactile reflexes to govern volitional actions in situations that do\nnot allow for constant visual attention. We therefore propose a myoelectric\nprosthesis system that reflects these concepts to aid manipulation performance\nwithout direct vision. To implement this design, we built two fabric-based\ntactile sensors that measure contact location along the palmar and dorsal sides\nof the prosthetic fingers and grasp pressure at the tip of the prosthetic\nthumb. Inspired by the natural sensorimotor system, we use the measurements\nfrom these sensors to provide vibrotactile feedback of contact location and\nimplement a tactile grasp controller that uses automatic reflexes to prevent\nover-grasping and object slip. We compare this system to a standard myoelectric\nprosthesis in a challenging reach-to-pick-and-place task conducted without\ndirect vision; 17 able-bodied adults took part in this single-session\nbetween-subjects study. Participants in the tactile group achieved more\nconsistent high performance compared to participants in the standard group.\nThese results indicate that the addition of contact-location feedback and\nreflex control increases the consistency with which objects can be grasped and\nmoved without direct vision in upper-limb prosthetics.",
    "descriptor": "\nComments: Accepted to IROS 2021\n",
    "authors": [
      "Neha Thomas",
      "Farimah Fazlollahi",
      "Jeremy D. Brown",
      "Katherine J. Kuchenbecker"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07000"
  },
  {
    "id": "arXiv:2107.07002",
    "title": "The Benchmark Lottery",
    "abstract": "The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.",
    "descriptor": "",
    "authors": [
      "Mostafa Dehghani",
      "Yi Tay",
      "Alexey A. Gritsenko",
      "Zhe Zhao",
      "Neil Houlsby",
      "Fernando Diaz",
      "Donald Metzler",
      "Oriol Vinyals"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07002"
  },
  {
    "id": "arXiv:2107.07004",
    "title": "Lidar Light Scattering Augmentation (LISA): Physics-based Simulation of  Adverse Weather Conditions for 3D Object Detection",
    "abstract": "Lidar-based object detectors are critical parts of the 3D perception pipeline\nin autonomous navigation systems such as self-driving cars. However, they are\nknown to be sensitive to adverse weather conditions such as rain, snow and fog\ndue to reduced signal-to-noise ratio (SNR) and signal-to-background ratio\n(SBR). As a result, lidar-based object detectors trained on data captured in\nnormal weather tend to perform poorly in such scenarios. However, collecting\nand labelling sufficient training data in a diverse range of adverse weather\nconditions is laborious and prohibitively expensive. To address this issue, we\npropose a physics-based approach to simulate lidar point clouds of scenes in\nadverse weather conditions. These augmented datasets can then be used to train\nlidar-based detectors to improve their all-weather reliability. Specifically,\nwe introduce a hybrid Monte-Carlo based approach that treats (i) the effects of\nlarge particles by placing them randomly and comparing their back reflected\npower against the target, and (ii) attenuation effects on average through\ncalculation of scattering efficiencies from the Mie theory and particle size\ndistributions. Retraining networks with this augmented data improves mean\naverage precision evaluated on real world rainy scenes and we observe greater\nimprovement in performance with our model relative to existing models from the\nliterature. Furthermore, we evaluate recent state-of-the-art detectors on the\nsimulated weather conditions and present an in-depth analysis of their\nperformance.",
    "descriptor": "",
    "authors": [
      "Velat Kilic",
      "Deepti Hegde",
      "Vishwanath Sindagi",
      "A. Brinton Cooper",
      "Mark A. Foster",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.07004"
  },
  {
    "id": "arXiv:2107.07005",
    "title": "WeightScale: Interpreting Weight Change in Neural Networks",
    "abstract": "Interpreting the learning dynamics of neural networks can provide useful\ninsights into how networks learn and the development of better training and\ndesign approaches. We present an approach to interpret learning in neural\nnetworks by measuring relative weight change on a per layer basis and\ndynamically aggregating emerging trends through combination of dimensionality\nreduction and clustering which allows us to scale to very deep networks. We use\nthis approach to investigate learning in the context of vision tasks across a\nvariety of state-of-the-art networks and provide insights into the learning\nbehavior of these networks, including how task complexity affects layer-wise\nlearning in deeper layers of networks.",
    "descriptor": "\nComments: 9 pages, 8 figures. arXiv admin note: text overlap with arXiv:2011.06735\n",
    "authors": [
      "Ayush Manish Agrawal",
      "Atharva Tendle",
      "Harshvardhan Sikka",
      "Sahib Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07005"
  },
  {
    "id": "arXiv:2107.07009",
    "title": "Free-Text Keystroke Dynamics for User Authentication",
    "abstract": "In this research, we consider the problem of verifying user identity based on\nkeystroke dynamics obtained from free-text. We employ a novel feature\nengineering method that generates image-like transition matrices. For this\nimage-like feature, a convolution neural network (CNN) with cutout achieves the\nbest results. A hybrid model consisting of a CNN and a recurrent neural network\n(RNN) is also shown to outperform previous research in this field.",
    "descriptor": "",
    "authors": [
      "Jianwei Li",
      "Han-Chih Chang",
      "Mark Stamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07009"
  },
  {
    "id": "arXiv:2107.07011",
    "title": "A Bayesian Compressive Sensing Approach to Robust Near-Field Antenna  Characterization",
    "abstract": "A novel probabilistic sparsity-promoting method for robust near-field (NF)\nantenna characterization is proposed. It leverages on the\nmeasurements-by-design (MebD) paradigm and it exploits some a-priori\ninformation on the antenna under test (AUT) to generate an over-complete\nrepresentation basis. Accordingly, the problem at hand is reformulated in a\ncompressive sensing (CS) framework as the retrieval of a maximally-sparse\ndistribution (with respect to the overcomplete basis) from a reduced set of\nmeasured data and then it is solved by means of a Bayesian strategy.\nRepresentative numerical results are presented to, also comparatively, assess\nthe effectiveness of the proposed approach in reducing the \"burden/cost\" of the\nacquisition process as well as to mitigate (possible) truncation errors when\ndealing with space-constrained probing systems.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Marco Salucci",
      "Nicola Anselmi",
      "Marco Donald Migliore",
      "Andrea Massa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07011"
  },
  {
    "id": "arXiv:2107.07013",
    "title": "Passive attention in artificial neural networks predicts human visual  selectivity",
    "abstract": "Developments in machine learning interpretability techniques over the past\ndecade have provided new tools to observe the image regions that are most\ninformative for classification and localization in artificial neural networks\n(ANNs). Are the same regions similarly informative to human observers? Using\ndata from 78 new experiments and 6,610 participants, we show that passive\nattention techniques reveal a significant overlap with human visual selectivity\nestimates derived from 6 distinct behavioral tasks including visual\ndiscrimination, spatial localization, recognizability, free-viewing,\ncued-object search, and saliency search fixations. We find that input\nvisualizations derived from relatively simple ANN architectures probed using\nguided backpropagation methods are the best predictors of a shared component in\nthe joint variability of the human measures. We validate these correlational\nresults with causal manipulations using recognition experiments. We show that\nimages masked with ANN attention maps were easier for humans to classify than\ncontrol masks in a speeded recognition experiment. Similarly, we find that\nrecognition performance in the same ANN models was likewise influenced by\nmasking input images using human visual selectivity maps. This work contributes\na new approach to evaluating the biological and psychological validity of\nleading ANNs as models of human vision: by examining their similarities and\ndifferences in terms of their visual selectivity to the information contained\nin images.",
    "descriptor": "",
    "authors": [
      "Thomas A. Langlois",
      "H. Charles Zhao",
      "Erin Grant",
      "Ishita Dasgupta",
      "Thomas L. Griffiths",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07013"
  },
  {
    "id": "arXiv:2107.07014",
    "title": "Hybrid Bayesian Neural Networks with Functional Probabilistic Layers",
    "abstract": "Bayesian neural networks provide a direct and natural way to extend standard\ndeep neural networks to support probabilistic deep learning through the use of\nprobabilistic layers that, traditionally, encode weight (and bias) uncertainty.\nIn particular, hybrid Bayesian neural networks utilize standard deterministic\nlayers together with few probabilistic layers judicially positioned in the\nnetworks for uncertainty estimation. A major aspect and benefit of Bayesian\ninference is that priors, in principle, provide the means to encode prior\nknowledge for use in inference and prediction. However, it is difficult to\nspecify priors on weights since the weights have no intuitive interpretation.\nFurther, the relationships of priors on weights to the functions computed by\nnetworks are difficult to characterize. In contrast, functions are intuitive to\ninterpret and are direct since they map inputs to outputs. Therefore, it is\nnatural to specify priors on functions to encode prior knowledge, and to use\nthem in inference and prediction based on functions. To support this, we\npropose hybrid Bayesian neural networks with functional probabilistic layers\nthat encode function (and activation) uncertainty. We discuss their foundations\nin functional Bayesian inference, functional variational inference, sparse\nGaussian processes, and sparse variational Gaussian processes. We further\nperform few proof-of-concept experiments using GPflus, a new library that\nprovides Gaussian process layers and supports their use with deterministic\nKeras layers to form hybrid neural network and Gaussian process models.",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07014"
  },
  {
    "id": "arXiv:2107.07015",
    "title": "Do Humans Trust Advice More if it Comes from AI? An Analysis of Human-AI  Interactions",
    "abstract": "In many applications of AI, the algorithm's output is framed as a suggestion\nto a human user. The user may ignore the advice or take it into consideration\nto modify his/her decisions. With the increasing prevalence of such human-AI\ninteractions, it is important to understand how users act (or do not act) upon\nAI advice, and how users regard advice differently if they believe the advice\ncome from an \"AI\" versus another human. In this paper, we characterize how\nhumans use AI suggestions relative to equivalent suggestions from a group of\npeer humans across several experimental settings. We find that participants'\nbeliefs about the human versus AI performance on a given task affects whether\nor not they heed the advice. When participants decide to use the advice, they\ndo so similarly for human and AI suggestions. These results provide insights\ninto factors that affect human-AI interactions.",
    "descriptor": "\nComments: 34 pages, 6 figures + 18 full page figures\n",
    "authors": [
      "Kailas Vodrahalli",
      "Tobias Gerstenberg",
      "James Zou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07015"
  },
  {
    "id": "arXiv:2107.07016",
    "title": "Forgetting in Answer Set Programming -- A Survey",
    "abstract": "Forgetting - or variable elimination - is an operation that allows the\nremoval, from a knowledge base, of middle variables no longer deemed relevant.\nIn recent years, many different approaches for forgetting in Answer Set\nProgramming have been proposed, in the form of specific operators, or classes\nof such operators, commonly following different principles and obeying\ndifferent properties. Each such approach was developed to somehow address some\nparticular view on forgetting, aimed at obeying a specific set of properties\ndeemed desirable in such view, but a comprehensive and uniform overview of all\nthe existing operators and properties is missing. In this paper, we thoroughly\nexamine existing properties and (classes of) operators for forgetting in Answer\nSet Programming, drawing a complete picture of the landscape of these classes\nof forgetting operators, which includes many novel results on relations between\nproperties and operators, including considerations on concrete operators to\ncompute results of forgetting and computational complexity. Our goal is to\nprovide guidance to help users in choosing the operator most adequate for their\napplication requirements.",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Ricardo Gon\u00e7alves",
      "Matthias Knorr",
      "Jo\u00e3o Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.07016"
  },
  {
    "id": "arXiv:2107.07018",
    "title": "Effective Interfaces for Student-Driven Revision Sessions for  Argumentative Writing",
    "abstract": "We present the design and evaluation of a web-based intelligent writing\nassistant that helps students recognize their revisions of argumentative\nessays. To understand how our revision assistant can best support students, we\nhave implemented four versions of our system with differences in the unit span\n(sentence versus sub-sentence) of revision analysis and the level of feedback\nprovided (none, binary, or detailed revision purpose categorization). We first\ndiscuss the design decisions behind relevant components of the system, then\nanalyze the efficacy of the different versions through a Wizard of Oz study\nwith university students. Our results show that while a simple interface with\nno revision feedback is easier to use, an interface that provides a detailed\ncategorization of sentence-level revisions is the most helpful based on user\nsurvey data, as well as the most effective based on improvement in writing\noutcomes.",
    "descriptor": "\nComments: 13 pages, The 2021 ACM CHI Virtual Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Tazin Afrin",
      "Omid Kashefi",
      "Christopher Olshefski",
      "Diane Litman",
      "Rebecca Hwa",
      "Amanda Godley"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07018"
  },
  {
    "id": "arXiv:2107.07023",
    "title": "Reel Life vs. Real Life: How Software Developers Share Their Daily Life  through Vlogs",
    "abstract": "Software developers are turning to vlogs (video blogs) to share what a day is\nlike to walk in their shoes. Through these vlogs developers share a rich\nperspective of their technical work as well their personal lives. However, does\nthe type of activities portrayed in vlogs differ from activities developers in\nthe industry perform? Would developers at a software company prefer to show\nactivities to different extents if they were asked to share about their day\nthrough vlogs? To answer these questions, we analyzed 130 vlogs by software\ndevelopers on YouTube and conducted a survey with 335 software developers at a\nlarge software company. We found that although vlogs present traditional\ndevelopment activities such as coding and code peripheral activities (11%),\nthey also prominently feature wellness and lifestyle related activities (47.3%)\nthat have not been reflected in previous software engineering literature. We\nalso found that developers at the software company were inclined to share more\nnon-coding tasks (e.g., personal projects, time spent with family and friends,\nand health) when asked to create a mock-up vlog to promote diversity. These\nfindings demonstrate a shift in our understanding of how software developers\nare spending their time and find valuable to share publicly. We discuss how\nvlogs provide a more complete perspective of software development work and\nserve as a valuable source of data for empirical research.",
    "descriptor": "\nComments: 12 pages, 2 figures, 3 tables\n",
    "authors": [
      "Souti Chattopadhyay",
      "Thomas Zimmermann",
      "Denae Ford"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07023"
  },
  {
    "id": "arXiv:2107.07029",
    "title": "Leveraging Hierarchical Structures for Few-Shot Musical Instrument  Recognition",
    "abstract": "Deep learning work on musical instrument recognition has generally focused on\ninstrument classes for which we have abundant data. In this work, we exploit\nhierarchical relationships between instruments in a few-shot learning setup to\nenable classification of a wider set of musical instruments, given a few\nexamples at inference. We apply a hierarchical loss function to the training of\nprototypical networks, combined with a method to aggregate prototypes\nhierarchically, mirroring the structure of a predefined musical instrument\nhierarchy. These extensions require no changes to the network architecture and\nnew levels can be easily added or removed. Compared to a non-hierarchical\nfew-shot baseline, our method leads to a significant increase in classification\naccuracy and significant decrease mistake severity on instrument classes unseen\nin training.",
    "descriptor": "",
    "authors": [
      "Hugo Flores Garcia",
      "Aldo Aguilar",
      "Ethan Manilow",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.07029"
  },
  {
    "id": "arXiv:2107.07030",
    "title": "Diff-Net: Image Feature Difference based High-Definition Map Change  Detection",
    "abstract": "Up-to-date High-Definition (HD) maps are essential for self-driving cars. To\nachieve constantly updated HD maps, we present a deep neural network (DNN),\nDiff-Net, to detect changes in them. Compared to traditional methods based on\nobject detectors, the essential design in our work is a parallel feature\ndifference calculation structure that infers map changes by comparing features\nextracted from the camera and rasterized images. To generate these rasterized\nimages, we project map elements onto images in the camera view, yielding\nmeaningful map representations that can be consumed by a DNN accordingly. As we\nformulate the change detection task as an object detection problem, we leverage\nthe anchor-based structure that predicts bounding boxes with different change\nstatus categories. Furthermore, rather than relying on single frame input, we\nintroduce a spatio-temporal fusion module that fuses features from history\nframes into the current, thus improving the overall performance. Finally, we\ncomprehensively validate our method's effectiveness using freshly collected\ndatasets. Results demonstrate that our Diff-Net achieves better performance\nthan the baseline methods and is ready to be integrated into a map production\npipeline maintaining an up-to-date HD map.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Lei He",
      "Shengjie Jiang",
      "Xiaoqing Liang",
      "Ning Wang",
      "Shiyu Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07030"
  },
  {
    "id": "arXiv:2107.07031",
    "title": "Experimental Evidence that Empowerment May Drive Exploration in  Sparse-Reward Environments",
    "abstract": "Reinforcement Learning (RL) is known to be often unsuccessful in environments\nwith sparse extrinsic rewards. A possible countermeasure is to endow RL agents\nwith an intrinsic reward function, or 'intrinsic motivation', which rewards the\nagent based on certain features of the current sensor state. An intrinsic\nreward function based on the principle of empowerment assigns rewards\nproportional to the amount of control the agent has over its own sensors. We\nimplemented a variation on a recently proposed intrinsically motivated agent,\nwhich we refer to as the 'curious' agent, and an empowerment-inspired agent.\nThe former leverages sensor state encoding with a variational autoencoder,\nwhile the latter predicts the next sensor state via a variational information\nbottleneck. We compared the performance of both agents to that of an advantage\nactor-critic baseline in four sparse reward grid worlds. Both the empowerment\nagent and its curious competitor seem to benefit to similar extents from their\nintrinsic rewards. This provides some experimental support to the conjecture\nthat empowerment can be used to drive exploration.",
    "descriptor": "\nComments: 6 pages, 3 figures, to be published in proceedings of the International Conference on Development and Learning 2021\n",
    "authors": [
      "Francesco Massari",
      "Martin Biehl",
      "Lisa Meeden",
      "Ryota Kanai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07031"
  },
  {
    "id": "arXiv:2107.07038",
    "title": "Conditional Teaching Size",
    "abstract": "Recent research in machine teaching has explored the instruction of any\nconcept expressed in a universal language. In this compositional context, new\nexperimental results have shown that there exist data teaching sets\nsurprisingly shorter than the concept description itself. However, there exists\na bound for those remarkable experimental findings through teaching size and\nconcept complexity that we further explore here. As concepts are rarely taught\nin isolation we investigate the best configuration of concepts to teach a given\nset of concepts, where those that have been acquired first can be reused for\nthe description of new ones. This new notion of conditional teaching size\nuncovers new insights, such as the interposition phenomenon: certain prior\nknowledge generates simpler compatible concepts that increase the teaching size\nof the concept that we want to teach. This does not happen for conditional\nKolmogorov complexity. Furthermore, we provide an algorithm that constructs\noptimal curricula based on interposition avoidance. This paper presents a\nseries of theoretical results, including their proofs, and some directions for\nfuture work. New research possibilities in curriculum teaching in compositional\nscenarios are now wide open to exploration.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Manuel Garcia-Piqueras",
      "Jos\u00e9 Hern\u00e1ndez-Orallo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07038"
  },
  {
    "id": "arXiv:2107.07039",
    "title": "Short-term Hourly Streamflow Prediction with Graph Convolutional GRU  Networks",
    "abstract": "The frequency and impact of floods are expected to increase due to climate\nchange. It is crucial to predict streamflow, consequently flooding, in order to\nprepare and mitigate its consequences in terms of property damage and\nfatalities. This paper presents a Graph Convolutional GRUs based model to\npredict the next 36 hours of streamflow for a sensor location using the\nupstream river network. As shown in experiment results, the model presented in\nthis study provides better performance than the persistence baseline and a\nConvolutional Bidirectional GRU network for the selected study area in\nshort-term streamflow prediction.",
    "descriptor": "\nComments: 4 pages, Accepted to Tackling Climate Change with Machine Learning workshop at ICML 2021\n",
    "authors": [
      "Muhammed Sit",
      "Bekir Demiray",
      "Ibrahim Demir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07039"
  },
  {
    "id": "arXiv:2107.07040",
    "title": "Parsimony-Enhanced Sparse Bayesian Learning for Robust Discovery of  Partial Differential Equations",
    "abstract": "Robust physics discovery is of great interest for many scientific and\nengineering fields. Inspired by the principle that a representative model is\nthe one simplest possible, a new model selection criteria considering both\nmodel's Parsimony and Sparsity is proposed. A Parsimony Enhanced Sparse\nBayesian Learning (PeSBL) method is developed for discovering the governing\nPartial Differential Equations (PDEs) of nonlinear dynamical systems. Compared\nwith the conventional Sparse Bayesian Learning (SBL) method, the PeSBL method\npromotes parsimony of the learned model in addition to its sparsity. In this\nmethod, the parsimony of model terms is evaluated using their locations in the\nprescribed candidate library, for the first time, considering the increased\ncomplexity with the power of polynomials and the order of spatial derivatives.\nSubsequently, the model parameters are updated through Bayesian inference with\nthe raw data. This procedure aims to reduce the error associated with the\npossible loss of information in data preprocessing and numerical\ndifferentiation prior to sparse regression. Results of numerical case studies\nindicate that the governing PDEs of many canonical dynamical systems can be\ncorrectly identified using the proposed PeSBL method from highly noisy data (up\nto 50% in the current study). Next, the proposed methodology is extended for\nstochastic PDE learning where all parameters and modeling error are considered\nas random variables. Hierarchical Bayesian Inference (HBI) is integrated with\nthe proposed framework for stochastic PDE learning from a population of\nobservations. Finally, the proposed PeSBL is demonstrated for system response\nprediction with uncertainties and anomaly diagnosis. Codes of all demonstrated\nexamples in this study are available on the website: https://github.com/ymlasu.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.06504\n",
    "authors": [
      "Zhiming Zhang",
      "Yongming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07040"
  },
  {
    "id": "arXiv:2107.07041",
    "title": "Mitigating Memorization in Sample Selection for Learning with Noisy  Labels",
    "abstract": "Because deep learning is vulnerable to noisy labels, sample selection\ntechniques, which train networks with only clean labeled data, have attracted a\ngreat attention. However, if the labels are dominantly corrupted by few\nclasses, these noisy samples are called dominant-noisy-labeled samples, the\nnetwork also learns dominant-noisy-labeled samples rapidly via content-aware\noptimization. In this study, we propose a compelling criteria to penalize\ndominant-noisy-labeled samples intensively through class-wise penalty labels.\nBy averaging prediction confidences for the each observed label, we obtain\nsuitable penalty labels that have high values if the labels are largely\ncorrupted by some classes. Experiments were performed using benchmarks\n(CIFAR-10, CIFAR-100, Tiny-ImageNet) and real-world datasets (ANIMAL-10N,\nClothing1M) to evaluate the proposed criteria in various scenarios with\ndifferent noise rates. Using the proposed sample selection, the learning\nprocess of the network becomes significantly robust to noisy labels compared to\nexisting methods in several noise types.",
    "descriptor": "\nComments: 14 pages, 9 figures, spotlight presented at the ICML 2021 Workshop on Subset Selection in ML\n",
    "authors": [
      "Kyeongbo Kong",
      "Junggi Lee",
      "Youngchul Kwak",
      "Young-Rae Cho",
      "Seong-Eun Kim",
      "Woo-Jin Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07041"
  },
  {
    "id": "arXiv:2107.07042",
    "title": "Classifying Component Function in Product Assemblies with Graph Neural  Networks",
    "abstract": "Function is defined as the ensemble of tasks that enable the product to\ncomplete the designed purpose. Functional tools, such as functional modeling,\noffer decision guidance in the early phase of product design, where explicit\ndesign decisions are yet to be made. Function-based design data is often sparse\nand grounded in individual interpretation. As such, function-based design tools\ncan benefit from automatic function classification to increase data fidelity\nand provide function representation models that enable function-based\nintelligent design agents. Function-based design data is commonly stored in\nmanually generated design repositories. These design repositories are a\ncollection of expert knowledge and interpretations of function in product\ndesign bounded by function-flow and component taxonomies. In this work, we\nrepresent a structured taxonomy-based design repository as assembly-flow\ngraphs, then leverage a graph neural network (GNN) model to perform automatic\nfunction classification. We support automated function classification by\nlearning from repository data to establish the ground truth of component\nfunction assignment. Experimental results show that our GNN model achieves a\nmicro-average F${_1}$-score of 0.832 for tier 1 (broad), 0.756 for tier 2, and\n0.783 for tier 3 (specific) functions. Given the imbalance of data features,\nthe results are encouraging. Our efforts in this paper can be a starting point\nfor more sophisticated applications in knowledge-based CAD systems and\nDesign-for-X consideration in function-based design.",
    "descriptor": "",
    "authors": [
      "Vincenzo Ferrero",
      "Kaveh Hassani",
      "Daniele Grandi",
      "Bryony DuPont"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07042"
  },
  {
    "id": "arXiv:2107.07043",
    "title": "GGT: Graph-Guided Testing for Adversarial Sample Detection of Deep  Neural Network",
    "abstract": "Deep Neural Networks (DNN) are known to be vulnerable to adversarial samples,\nthe detection of which is crucial for the wide application of these DNN models.\nRecently, a number of deep testing methods in software engineering were\nproposed to find the vulnerability of DNN systems, and one of them, i.e., Model\nMutation Testing (MMT), was used to successfully detect various adversarial\nsamples generated by different kinds of adversarial attacks. However, the\nmutated models in MMT are always huge in number (e.g., over 100 models) and\nlack diversity (e.g., can be easily circumvented by high-confidence adversarial\nsamples), which makes it less efficient in real applications and less effective\nin detecting high-confidence adversarial samples. In this study, we propose\nGraph-Guided Testing (GGT) for adversarial sample detection to overcome these\naforementioned challenges. GGT generates pruned models with the guide of graph\ncharacteristics, each of them has only about 5% parameters of the mutated model\nin MMT, and graph guided models have higher diversity. The experiments on\nCIFAR10 and SVHN validate that GGT performs much better than MMT with respect\nto both effectiveness and efficiency.",
    "descriptor": "",
    "authors": [
      "Zuohui Chen",
      "Renxuan Wang",
      "Jingyang Xiang",
      "Yue Yu",
      "Xin Xia",
      "Shouling Ji",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07043"
  },
  {
    "id": "arXiv:2107.07044",
    "title": "NVCell: Standard Cell Layout in Advanced Technology Nodes with  Reinforcement Learning",
    "abstract": "High quality standard cell layout automation in advanced technology nodes is\nstill challenging in the industry today because of complex design rules. In\nthis paper we introduce an automatic standard cell layout generator called\nNVCell that can generate layouts with equal or smaller area for over 90% of\nsingle row cells in an industry standard cell library on an advanced technology\nnode. NVCell leverages reinforcement learning (RL) to fix design rule\nviolations during routing and to generate efficient placements.",
    "descriptor": "",
    "authors": [
      "Haoxing Ren",
      "Matthew Fojtik",
      "Brucek Khailany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07044"
  },
  {
    "id": "arXiv:2107.07045",
    "title": "Explainable AI: current status and future directions",
    "abstract": "Explainable Artificial Intelligence (XAI) is an emerging area of research in\nthe field of Artificial Intelligence (AI). XAI can explain how AI obtained a\nparticular solution (e.g., classification or object detection) and can also\nanswer other \"wh\" questions. This explainability is not possible in traditional\nAI. Explainability is essential for critical applications, such as defense,\nhealth care, law and order, and autonomous driving vehicles, etc, where the\nknow-how is required for trust and transparency. A number of XAI techniques so\nfar have been purposed for such applications. This paper provides an overview\nof these techniques from a multimedia (i.e., text, image, audio, and video)\npoint of view. The advantages and shortcomings of these techniques have been\ndiscussed, and pointers to some future directions have also been provided.",
    "descriptor": "",
    "authors": [
      "Prashant Gohel",
      "Priyanka Singh",
      "Manoranjan Mohanty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07045"
  },
  {
    "id": "arXiv:2107.07046",
    "title": "Backprop-Free Reinforcement Learning with Active Neural Generative  Coding",
    "abstract": "In humans, perceptual awareness facilitates the fast recognition and\nextraction of information from sensory input. This awareness largely depends on\nhow the human agent interacts with the environment. In this work, we propose\nactive neural generative coding, a computational framework for learning\naction-driven generative models without backpropagation of errors (backprop) in\ndynamic environments. Specifically, we develop an intelligent agent that\noperates even with sparse rewards, drawing inspiration from the cognitive\ntheory of planning as inference. We demonstrate on several control problems, in\nthe online learning setting, that our proposed modeling framework performs\ncompetitively with deep Q-learning models. The robust performance of our agent\noffers promising evidence that a backprop-free approach for neural inference\nand learning can drive goal-directed behavior.",
    "descriptor": "",
    "authors": [
      "Alexander Ororbia",
      "Ankur Mali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07046"
  },
  {
    "id": "arXiv:2107.07054",
    "title": "Expert Graphs: Synthesizing New Expertise via Collaboration",
    "abstract": "Consider multiple experts with overlapping expertise working on a\nclassification problem under uncertain input. What constitutes a consistent set\nof opinions? How can we predict the opinions of experts on missing sub-domains?\nIn this paper, we define a framework of to analyze this problem, termed \"expert\ngraphs.\" In an expert graph, vertices represent classes and edges represent\nbinary opinions on the topics of their vertices. We derive necessary conditions\nfor expert graph validity and use them to create \"synthetic experts\" which\ndescribe opinions consistent with the observed opinions of other experts. We\nshow this framework to be equivalent to the well-studied linear ordering\npolytope. We show our conditions are not sufficient for describing all expert\ngraphs on cliques, but are sufficient for cycles.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Bijan Mazaheri",
      "Siddharth Jain",
      "Jehoshua Bruck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2107.07054"
  },
  {
    "id": "arXiv:2107.07056",
    "title": "Learning Sparse Interaction Graphs of Partially Observed Pedestrians for  Trajectory Prediction",
    "abstract": "Multi-pedestrian trajectory prediction is an indispensable safety element of\nautonomous systems that interact with crowds in unstructured environments. Many\nrecent efforts have developed trajectory prediction algorithms with focus on\nunderstanding social norms behind pedestrian motions. Yet we observe these\nworks usually hold two assumptions that prevent them from being smoothly\napplied to robot applications: positions of all pedestrians are consistently\ntracked; the target agent pays attention to all pedestrians in the scene. The\nfirst assumption leads to biased interaction modeling with incomplete\npedestrian data, and the second assumption introduces unnecessary disturbances\nand leads to the freezing robot problem. Thus, we propose Gumbel Social\nTransformer, in which an Edge Gumbel Selector samples a sparse interaction\ngraph of partially observed pedestrians at each time step. A Node Transformer\nEncoder and a Masked LSTM encode the pedestrian features with the sampled\nsparse graphs to predict trajectories. We demonstrate that our model overcomes\nthe potential problems caused by the assumptions, and our approach outperforms\nthe related works in benchmark evaluation.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Zhe Huang",
      "Ruohua Li",
      "Kazuki Shin",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07056"
  },
  {
    "id": "arXiv:2107.07058",
    "title": "A Generalized Framework for Edge-preserving and Structure-preserving  Image Smoothing",
    "abstract": "Image smoothing is a fundamental procedure in applications of both computer\nvision and graphics. The required smoothing properties can be different or even\ncontradictive among different tasks. Nevertheless, the inherent smoothing\nnature of one smoothing operator is usually fixed and thus cannot meet the\nvarious requirements of different applications. In this paper, we first\nintroduce the truncated Huber penalty function which shows strong flexibility\nunder different parameter settings. A generalized framework is then proposed\nwith the introduced truncated Huber penalty function. When combined with its\nstrong flexibility, our framework is able to achieve diverse smoothing natures\nwhere contradictive smoothing behaviors can even be achieved. It can also yield\nthe smoothing behavior that can seldom be achieved by previous methods, and\nsuperior performance is thus achieved in challenging cases. These together\nenable our framework capable of a range of applications and able to outperform\nthe state-of-the-art approaches in several tasks, such as image detail\nenhancement, clip-art compression artifacts removal, guided depth map\nrestoration, image texture removal, etc. In addition, an efficient numerical\nsolution is provided and its convergence is theoretically guaranteed even the\noptimization framework is non-convex and non-smooth. A simple yet effective\napproach is further proposed to reduce the computational cost of our method\nwhile maintaining its performance. The effectiveness and superior performance\nof our approach are validated through comprehensive experiments in a range of\napplications. Our code is available at\nhttps://github.com/wliusjtu/Generalized-Smoothing-Framework.",
    "descriptor": "\nComments: This work is accepted by TPAMI. The code is available at this https URL arXiv admin note: substantial text overlap with arXiv:1907.09642\n",
    "authors": [
      "Wei Liu",
      "Pingping Zhang",
      "Yinjie Lei",
      "Xiaolin Huang",
      "Jie Yang",
      "Michael Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07058"
  },
  {
    "id": "arXiv:2107.07060",
    "title": "Blockchain-based Trust Information Storage in Crowdsourced IoT Services",
    "abstract": "We propose a novel distributed integrity-preserving framework for storing\ntrust information in crowdsourced IoT environments. The integrity and\navailability of the trust information is paramount to ensure accurate trust\nassessment. Our proposed framework leverages the blockchain to build a\ndistributed storage medium for trust-related information that ensures its\nintegrity. We propose a geo-scoping approach, which ensures that trust-related\ninformation is only available where needed, thus, enabling fast access and\nstorage space preservation. We conduct several experiments using real datasets\nto highlight the effectiveness of our framework.",
    "descriptor": "\nComments: 10 pages, Accepted and to appear in 2021 IEEE International Conference on Web Services (ICWS). Content may change prior to final publication\n",
    "authors": [
      "Mohammed Bahutair",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07060"
  },
  {
    "id": "arXiv:2107.07062",
    "title": "Motor Imagery Classification based on CNN-GRU Network with  Spatio-Temporal Feature Representation",
    "abstract": "Recently, various deep neural networks have been applied to classify\nelectroencephalogram (EEG) signal. EEG is a brain signal that can be acquired\nin a non-invasive way and has a high temporal resolution. It can be used to\ndecode the intention of users. As the EEG signal has a high dimension of\nfeature space, appropriate feature extraction methods are needed to improve\nclassification performance. In this study, we obtained spatio-temporal feature\nrepresentation and classified them with the combined convolutional neural\nnetworks (CNN)-gated recurrent unit (GRU) model. To this end, we obtained\ncovariance matrices in each different temporal band and then concatenated them\non the temporal axis to obtain a final spatio-temporal feature representation.\nIn the classification model, CNN is responsible for spatial feature extraction\nand GRU is responsible for temporal feature extraction. Classification\nperformance was improved by distinguishing spatial data processing and temporal\ndata processing. The average accuracy of the proposed model was 77.70% for the\nBCI competition IV_2a data set. The proposed method outperformed all other\nmethods compared as a baseline method.",
    "descriptor": "\nComments: Submitted to IAPR 6th Asian Conference on Pattern Recognition (ACPR 2021)\n",
    "authors": [
      "Ji-Seon Bang",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.07062"
  },
  {
    "id": "arXiv:2107.07063",
    "title": "BlockJack: Towards Improved Prevention of IP Prefix Hijacking Attacks in  Inter-Domain Routing Via Blockchain",
    "abstract": "We propose BlockJack, a system based on a distributed and tamper-proof\nconsortium Blockchain that aims at blocking IP prefix hijacking in the Border\nGateway Protocol (BGP). In essence, BlockJack provides synchronization among\nBlockChain and BGP network through interfaces ensuring operational independence\nand this approach preserving the legacy system and accommodates the impact of a\nrace condition if the Blockchain process exceeds the BGP update interval.\nBlockJack is also resilient to dynamic routing path changes during the\noccurrence of the IP prefix hijacking in the routing tables. We implement\nBlockJack using Hyperledger Fabric Blockchain and Quagga software package and\nwe perform initial sets of experiments to evaluate its efficacy. We evaluate\nthe performance and resilience of BlockJack in various attack scenarios\nincluding single path attacks, multiple path attacks, and attacks from random\nsources in the random network topology. The Evaluation results show that\nBlockJack is able to handle multiple attacks caused by AS paths changes during\na BGP prefix hijacking. In experiment settings with 50 random routers,\nBlockJack takes on average 0.08 seconds (with a standard deviation of 0.04\nseconds) to block BGP prefix hijacking attacks. The test result showing that\nBlockJack conservative approach feasible to handle the IP Prefix hijacking in\nthe Border Gateway Protocol.",
    "descriptor": "",
    "authors": [
      "I Wayan Budi Sentana",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07063"
  },
  {
    "id": "arXiv:2107.07065",
    "title": "Why Crypto-detectors Fail: A Systematic Evaluation of Cryptographic  Misuse Detection Techniques",
    "abstract": "The correct use of cryptography is central to ensuring data security in\nmodern software systems. Hence, several academic and commercial static analysis\ntools have been developed for detecting and mitigating crypto-API misuse. While\ndevelopers are optimistically adopting these crypto-API misuse detectors (or\ncrypto-detectors) in their software development cycles, this momentum must be\naccompanied by a rigorous understanding of their effectiveness at finding\ncrypto-API misuse in practice. This paper presents the MASC framework, which\nenables a systematic and data-driven evaluation of crypto-detectors using\nmutation testing. We ground MASC in a comprehensive view of the problem space\nby developing a data-driven taxonomy of existing crypto-API misuse, containing\n$105$ misuse cases organized among nine semantic clusters. We develop $12$\ngeneralizable usage-based mutation operators and three mutation scopes that can\nexpressively instantiate thousands of compilable variants of the misuse cases\nfor thoroughly evaluating crypto-detectors. Using MASC, we evaluate nine major\ncrypto-detectors and discover $19$ unique, undocumented flaws that severely\nimpact the ability of crypto-detectors to discover misuses in practice. We\nconclude with a discussion on the diverse perspectives that influence the\ndesign of crypto-detectors and future directions towards building\nsecurity-focused crypto-detectors by design.",
    "descriptor": "\nComments: 18 pages, 2 figures, 2 tables\n",
    "authors": [
      "Amit Seal Ami",
      "Nathan Cooper",
      "Kaushal Kafle",
      "Kevin Moran",
      "Denys Poshyvanyk",
      "Adwait Nadkarni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07065"
  },
  {
    "id": "arXiv:2107.07066",
    "title": "Deep Reinforcement Learning based Dynamic Optimization of Bus Timetable",
    "abstract": "Bus timetable optimization is a key issue to reduce operational cost of bus\ncompanies and improve the service quality. Existing methods use exact or\nheuristic algorithms to optimize the timetable in an offline manner. In\npractice, the passenger flow may change significantly over time. Timetables\ndetermined in offline cannot adjust the departure interval to satisfy the\nchanged passenger flow. Aiming at improving the online performance of bus\ntimetable, we propose a Deep Reinforcement Learning based bus Timetable dynamic\nOptimization method (DRL-TO). In this method, the timetable optimization is\nconsidered as a sequential decision problem. A Deep Q-Network (DQN) is employed\nas the decision model to determine whether to dispatch a bus service during\neach minute of the service period. Therefore, the departure intervals of bus\nservices are determined in real time in accordance with passenger demand. We\nidentify several new and useful state features for the DQN, including the load\nfactor, carrying capacity utilization rate, and the number of stranding\npassengers. Taking into account both the interests of the bus company and\npassengers, a reward function is designed, which includes the indicators of\nfull load rate, empty load rate, passengers' waiting time, and the number of\nstranding passengers. Building on an existing method for calculating the\ncarrying capacity, we develop a new technique to enhance the matching degree at\neach bus station. Experiments demonstrate that compared with the timetable\ngenerated by the state-of-the-art bus timetable optimization approach based on\na memetic algorithm (BTOA-MA), Genetic Algorithm (GA) and the manual method,\nDRL-TO can dynamically determine the departure intervals based on the real-time\npassenger flow, saving 8$\\%$ of vehicles and reducing 17$\\%$ of passengers'\nwaiting time on average.",
    "descriptor": "",
    "authors": [
      "Guanqun Ai",
      "Xingquan Zuo",
      "Gang chen",
      "Binglin Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07066"
  },
  {
    "id": "arXiv:2107.07067",
    "title": "MeNToS: Tracklets Association with a Space-Time Memory Network",
    "abstract": "We propose a method for multi-object tracking and segmentation (MOTS) that\ndoes not require fine-tuning or per benchmark hyperparameter selection. The\nproposed method addresses particularly the data association problem. Indeed,\nthe recently introduced HOTA metric, that has a better alignment with the human\nvisual assessment by evenly balancing detections and associations quality, has\nshown that improvements are still needed for data association. After creating\ntracklets using instance segmentation and optical flow, the proposed method\nrelies on a space-time memory network (STM) developed for one-shot video object\nsegmentation to improve the association of tracklets with temporal gaps. To the\nbest of our knowledge, our method, named MeNToS, is the first to use the STM\nnetwork to track object masks for MOTS. We took the 4th place in the RobMOTS\nchallenge. The project page is https://mehdimiah.com/mentos.html.",
    "descriptor": "\nComments: Presented at the \"Robust Video Scene Understanding: Tracking and Video Segmentation\" workshop (CVPR-W 2021)\n",
    "authors": [
      "Mehdi Miah",
      "Guillaume-Alexandre Bilodeau",
      "Nicolas Saunier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07067"
  },
  {
    "id": "arXiv:2107.07072",
    "title": "EICO: Energy-Harvesting Long-Range Environmental Sensor Nodes with  Energy-Information Dynamic Co-Optimization",
    "abstract": "Intensive research on energy harvested sensor nodes with traditional battery\npowered devices has been driven by the challenges in achieving the stringent\ndesign goals of battery lifetime, information accuracy, transmission distance,\nand cost. This challenge is further amplified by the inherent power intensive\nnature of long-range communication when sensor networks are required to span\nvast areas such as agricultural fields and remote terrain. Solar power is a\ncommon energy source is wireless sensor nodes, however, it is not reliable due\nto fluctuations in power stemming from the changing seasons and weather\nconditions. This paper tackles these issues by presenting a\nperpetually-powered, energy-harvesting sensor node which utilizes a minimally\nsized solar cell and is capable of long range communication by dynamically\nco-optimizing energy consumption and information transfer, termed as\nEnergy-Information Dynamic Co-Optimization (EICO). This energy-information\nintelligence is achieved by adaptive duty cycling of information transfer based\non the total amount of energy available from the harvester and charge storage\nelement to optimize the energy consumption of the sensor node, while employing\nin-sensor analytics (ISA) to minimize loss of information. This is the first\nreported sensor node < 35cm2 in dimension, which is capable of long-range\ncommunication over > 1Km at continuous information transfer rates of upto 1\npacket/second which is enabled by EICO and ISA.",
    "descriptor": "",
    "authors": [
      "Shitij Avlani",
      "Donghyun Seo",
      "Baibhab Chatterjee",
      "Shreyas Sen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07072"
  },
  {
    "id": "arXiv:2107.07075",
    "title": "Deep Learning on a Data Diet: Finding Important Examples Early in  Training",
    "abstract": "The recent success of deep learning has partially been driven by training\nincreasingly overparametrized networks on ever larger datasets. It is therefore\nnatural to ask: how much of the data is superfluous, which examples are\nimportant for generalization, and how do we find them? In this work, we make\nthe striking observation that, on standard vision benchmarks, the initial loss\ngradient norm of individual training examples, averaged over several weight\ninitializations, can be used to identify a smaller set of training data that is\nimportant for generalization. Furthermore, after only a few epochs of training,\nthe information in gradient norms is reflected in the normed error--L2 distance\nbetween the predicted probabilities and one hot labels--which can be used to\nprune a significant fraction of the dataset without sacrificing test accuracy.\nBased on this, we propose data pruning methods which use only local information\nearly in training, and connect them to recent work that prunes data by\ndiscarding examples that are rarely forgotten over the course of training. Our\nmethods also shed light on how the underlying data distribution shapes the\ntraining dynamics: they rank examples based on their importance for\ngeneralization, detect noisy examples and identify subspaces of the model's\ndata representation that are relatively stable over training.",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Mansheej Paul",
      "Surya Ganguli",
      "Gintare Karolina Dziugaite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07075"
  },
  {
    "id": "arXiv:2107.07076",
    "title": "An Overview and Experimental Study of Learning-based Optimization  Algorithms for Vehicle Routing Problem",
    "abstract": "Vehicle routing problem (VRP) is a typical discrete combinatorial\noptimization problem, and many models and algorithms have been proposed to\nsolve VRP and variants. Although existing approaches has contributed a lot to\nthe development of this field, these approaches either are limited in problem\nsize or need manual intervening in choosing parameters. To tackle these\ndifficulties, many studies consider learning-based optimization algorithms to\nsolve VRP. This paper reviews recent advances in this field and divides\nrelevant approaches into end-to-end approaches and step-by-step approaches. We\ndesign three part experiments to justly evaluate performance of four\nrepresentative learning-based optimization algorithms and conclude that\ncombining heuristic search can effectively improve learning ability and sampled\nefficiency of LBO models. Finally we point out that research trend of LBO\nalgorithms is to solve large-scale and multiple constraints problems from real\nworld.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Bingjie Li",
      "Guohua Wu",
      "Yongming He",
      "Mingfeng Fan",
      "Witold Pedrycz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07076"
  },
  {
    "id": "arXiv:2107.07080",
    "title": "A Petrov-Galerkin method for nonlocal convection-dominated diffusion  problems",
    "abstract": "We present a Petrov-Gelerkin (PG) method for a class of nonlocal\nconvection-dominated diffusion problems. There are two main ingredients in our\napproach. First, we define the norm on the test space as induced by the trial\nspace norm, i.e., the optimal test norm, so that the inf-sup condition can be\nsatisfied uniformly independent of the problem. We show the well-posedness of a\nclass of nonlocal convection-dominated diffusion problems under the optimal\ntest norm with general assumptions on the nonlocal diffusion and convection\nkernels. Second, following the framework of Cohen et al.~(2012), we embed the\noriginal nonlocal convection-dominated diffusion problem into a larger mixed\nproblem so as to choose an enriched test space as a stabilization of the\nnumerical algorithm. In the numerical experiments, we use an approximate\noptimal test norm which can be efficiently implemented in 1d, and study its\nperformance against the energy norm on the test space. We conduct convergence\nstudies for the nonlocal problem using uniform $h$- and $p$-refinements, and\nadaptive $h$-refinements on both smooth manufactured solutions and solutions\nwith sharp gradient in a transition layer. In addition, we confirm that the PG\nmethod is asymptotically compatible.",
    "descriptor": "",
    "authors": [
      "Yu Leng",
      "Xiaochuan Tian",
      "Leszek Demkowicz",
      "Hector Gomez",
      "John T. Foster"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.07080"
  },
  {
    "id": "arXiv:2107.07083",
    "title": "Combatting Gerrymandering with Social Choice: the Design of Multi-member  Districts",
    "abstract": "Every representative democracy must specify a mechanism under which voters\nchoose their representatives. The most common mechanism in the United States --\nwinner-take-all single-member districts -- both enables substantial partisan\ngerrymandering and constrains `fair' redistricting, preventing proportional\nrepresentation in legislatures. We study the design of \\textit{multi-member\ndistricts (MMDs)}, in which each district elects multiple representatives,\npotentially through a non-winner-takes-all voting rule. We carry out\nlarge-scale analyses for the U.S. House of Representatives under MMDs with\ndifferent social choice functions, under algorithmically generated maps\noptimized for either partisan benefit or proportionality. Doing so requires\nefficiently incorporating predicted partisan outcomes -- under various\nmulti-winner social choice functions -- into an algorithm that optimizes over\nan ensemble of maps. We find that with three-member districts using Single\nTransferable Vote, fairness-minded independent commissions would be able to\nachieve proportional outcomes in every state up to rounding, \\textit{and}\nadvantage-seeking partisans would have their power to gerrymander significantly\ncurtailed. Simultaneously, such districts would preserve geographic cohesion,\nan arguably important aspect of representative democracies. In the process, we\nopen up a rich research agenda at the intersection of social choice and\ncomputational redistricting.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Nikhil Garg",
      "Wes Gurnee",
      "David Rothschild",
      "David Shmoys"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.07083"
  },
  {
    "id": "arXiv:2107.07084",
    "title": "Vision-Based Target Localization for a Flapping-Wing Aerial Vehicle",
    "abstract": "The flapping-wing aerial vehicle (FWAV) is a new type of flying robot that\nmimics the flight mode of birds and insects. However, FWAVs have their special\ncharacteristics of less load capacity and short endurance time, so that most\nexisting systems of ground target localization are not suitable for them. In\nthis paper, a vision-based target localization algorithm is proposed for FWAVs\nbased on a generic camera model. Since sensors exist measurement error and the\ncamera exists jitter and motion blur during flight, Gaussian noises are\nintroduced in the simulation experiment, and then a first-order low-pass filter\nis used to stabilize the localization values. Moreover, in order to verify the\nfeasibility and accuracy of the target localization algorithm, we design a set\nof simulation experiments where various noises are added. From the simulation\nresults, it is found that the target localization algorithm has a good\nperformance.",
    "descriptor": "\nComments: Submitted to the 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC2021)\n",
    "authors": [
      "Xinghao Dong",
      "Qiang Fu",
      "Chunhua Zhang",
      "Wei He"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07084"
  },
  {
    "id": "arXiv:2107.07089",
    "title": "STAR: Sparse Transformer-based Action Recognition",
    "abstract": "The cognitive system for human action and behavior has evolved into a deep\nlearning regime, and especially the advent of Graph Convolution Networks has\ntransformed the field in recent years. However, previous works have mainly\nfocused on over-parameterized and complex models based on dense graph\nconvolution networks, resulting in low efficiency in training and inference.\nMeanwhile, the Transformer architecture-based model has not yet been well\nexplored for cognitive application in human action and behavior estimation.\nThis work proposes a novel skeleton-based human action recognition model with\nsparse attention on the spatial dimension and segmented linear attention on the\ntemporal dimension of data. Our model can also process the variable length of\nvideo clips grouped as a single batch. Experiments show that our model can\nachieve comparable performance while utilizing much less trainable parameters\nand achieve high speed in training and inference. Experiments show that our\nmodel achieves 4~18x speedup and 1/7~1/15 model size compared with the baseline\nmodels at competitive accuracy.",
    "descriptor": "",
    "authors": [
      "Feng Shi",
      "Chonghan Lee",
      "Liang Qiu",
      "Yizhou Zhao",
      "Tianyi Shen",
      "Shivran Muralidhar",
      "Tian Han",
      "Song-Chun Zhu",
      "Vijaykrishnan Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07089"
  },
  {
    "id": "arXiv:2107.07093",
    "title": "Support Constrained Generator Matrices and the Generalized Hamming  Weights",
    "abstract": "Support constrained generator matrices for linear codes have been found\napplications in multiple access networks and weakly secure document exchange.\nThe necessary and sufficient conditions for the existence of Reed-Solomon codes\nwith support constrained generator matrices were conjectured by Dau, Song, Yuen\nand Hassibi. This conjecture is called the GM-MDS conjecture and finally proved\nrecently in independent works of Lovett and Yildiz-Hassibi. From their\nconjecture support constrained generator matrices for MDS codes are existent\nover linear size small fields. In this paper we propose a natural generalized\nconjecture for the support constrained matrices based on the generalized\nHamming weights (SCGM-GHW conjecture). The GM-MDS conjecture can be thought as\na very special case of our SCGM-GHW conjecture for linear $1$-MDS codes. We\ninvestigate the support constrained generator matrices for some linear codes\nsuch as $2$-MDS codes, first order Reed-Muller codes, algebraic-geometric codes\nfrom elliptic curves from the view of our SCGM-GHW conjecture. In particular\nthe direct generalization of the GM-MDS conjecture about $1$-MDS codes to\n$2$-MDS codes is not true. For linear $2$-MDS codes only cardinality-based\nconstraints on subset systems are not sufficient for the purpose that these\nsubsets are in the zero coordinate position sets of rows in generator matrices.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07093"
  },
  {
    "id": "arXiv:2107.07095",
    "title": "Applying the Case Difference Heuristic to Learn Adaptations from Deep  Network Features",
    "abstract": "The case difference heuristic (CDH) approach is a knowledge-light method for\nlearning case adaptation knowledge from the case base of a case-based reasoning\nsystem. Given a pair of cases, the CDH approach attributes the difference in\ntheir solutions to the difference in the problems they solve, and generates\nadaptation rules to adjust solutions accordingly when a retrieved case and new\nquery have similar problem differences. As an alternative to learning\nadaptation rules, several researchers have applied neural networks to learn to\npredict solution differences from problem differences. Previous work on such\napproaches has assumed that the feature set describing problems is predefined.\nThis paper investigates a two-phase process combining deep learning for feature\nextraction and neural network based adaptation learning from extracted\nfeatures. Its performance is demonstrated in a regression task on an image\ndata: predicting age given the image of a face. Results show that the combined\nprocess can successfully learn adaptation knowledge applicable to nonsymbolic\ndifferences in cases. The CBR system achieves slightly lower performance\noverall than a baseline deep network regressor, but better performance than the\nbaseline on novel queries.",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 table. To be published in the IJCAI-21 Workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future Synergies\n",
    "authors": [
      "Xiaomeng Ye",
      "Ziwei Zhao",
      "David Leake",
      "Xizi Wang",
      "David Crandall"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07095"
  },
  {
    "id": "arXiv:2107.07101",
    "title": "Joint CFO, Gridless Channel Estimation and Data Detection for Underwater  Acoustic OFDM Systems",
    "abstract": "In this paper, we propose an iterative receiver based on gridless variational\nBayesian line spectra estimation (VALSE) named JCCD-VALSE that \\emph{j}ointly\nestimates the \\emph{c}arrier frequency offset (CFO), the \\emph{c}hannel with\nhigh resolution and carries out \\emph{d}ata decoding. Based on a modularized\npoint of view and motivated by the high resolution and low complexity gridless\nVALSE algorithm, three modules named the VALSE module, the minimum mean squared\nerror (MMSE) module and the decoder module are built. Soft information is\nexchanged between the modules to progressively improve the channel estimation\nand data decoding accuracy. Since the delays of multipaths of the channel are\ntreated as continuous parameters, instead of on a grid, the leakage effect is\navoided. Besides, the proposed approach is a more complete Bayesian approach as\nall the nuisance parameters such as the noise variance, the parameters of the\nprior distribution of the channel, the number of paths are automatically\nestimated. Numerical simulations and sea test data are utilized to demonstrate\nthat the proposed approach performs significantly better than the existing\ngrid-based generalized approximate message passing (GAMP) based \\emph{j}oint\n\\emph{c}hannel and \\emph{d}ata decoding approach (JCD-GAMP). Furthermore, it is\nalso verified that joint processing including CFO estimation provides\nperformance gain.",
    "descriptor": "",
    "authors": [
      "Lei Wan",
      "Jiang Zhu",
      "En Cheng",
      "Zhiwei Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07101"
  },
  {
    "id": "arXiv:2107.07103",
    "title": "Multilinear extension of $k$-submodular functions",
    "abstract": "A $k$-submodular function is a function that given $k$ disjoint subsets\noutputs a value that is submodular in every orthant. In this paper, we provide\na new framework for $k$-submodular maximization problems, by relaxing the\noptimization to the continuous space with the multilinear extension of\n$k$-submodular functions and a variant of pipage rounding that recovers the\ndiscrete solution. The multilinear extension introduces new techniques to\nanalyze and optimize $k$-submodular functions.\nWhen the function is monotone, we propose almost $\\frac{1}{2}$-approximation\nalgorithms for unconstrained maximization and maximization under total size and\nknapsack constraints. For unconstrained monotone and non-monotone maximization,\nwe propose an algorithm that is almost as good as any combinatorial algorithm\nbased on Iwata, Tanigawa, and Yoshida's meta-framework\n($\\frac{k}{2k-1}$-approximation for the monotone case and\n$\\frac{k^2+1}{2k^2+1}$-approximation for the non-monotone case).",
    "descriptor": "",
    "authors": [
      "Baoxiang Wang",
      "Huanjian Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.07103"
  },
  {
    "id": "arXiv:2107.07104",
    "title": "Scalable Biophysical Simulations of the Neuromuscular System",
    "abstract": "The human neuromuscular system consisting of skeletal muscles and neural\ncircuits is a complex system that is not yet fully understood. Surface\nelectromyography (EMG) can be used to study muscle behavior from the outside.\nComputer simulations with detailed biophysical models provide a non-invasive\ntool to interpret EMG signals and gain new insights into the system. The\nnumerical solution of such multi-scale models imposes high computational work\nloads, which restricts their application to short simulation time spans or\ncoarse resolutions. We tackled this challenge by providing scalable software\nemploying instruction-level and task-level parallelism, suitable numerical\nmethods and efficient data handling. We implemented a comprehensive,\nstate-of-the-art, multi-scale multi-physics model framework that can simulate\nsurface EMG signals and muscle contraction as a result of neuromuscular\nstimulation.\nThis work describes the model framework and its numerical discretization,\ndevelops new algorithms for mesh generation and parallelization, covers the use\nand implementation of our software OpenDiHu, and evaluates its computational\nperformance in numerous use cases. We obtain a speedup of several hundred\ncompared to a baseline solver from the literature and demonstrate, that our\ndistributed-memory parallelization and the use of High Performance Computing\nresources enables us to simulate muscular surface EMG of the biceps brachii\nmuscle with realistic muscle fiber counts of several hundred thousands. We find\nthat certain model effects are only visible with such high resolution. In\nconclusion, our software contributes to more realistic simulations of the\nneuromuscular system and provides a tool for applied researchers to complement\nin vivo experiments with in-silico studies. It can serve as a building block to\nset up comprehensive models for more organs in the musculoskeletal system.",
    "descriptor": "\nComments: PhD thesis, 530 pages, 208 figures\n",
    "authors": [
      "Benjamin Maier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.07104"
  },
  {
    "id": "arXiv:2107.07106",
    "title": "Online Learning for Recommendations at Grubhub",
    "abstract": "We propose a method to easily modify existing offline Recommender Systems to\nrun online using Transfer Learning. Online Learning for Recommender Systems has\ntwo main advantages: quality and scale. Like many Machine Learning algorithms\nin production if not regularly retrained will suffer from Concept Drift. A\npolicy that is updated frequently online can adapt to drift faster than a batch\nsystem. This is especially true for user-interaction systems like recommenders\nwhere the underlying distribution can shift drastically to follow user\nbehaviour. As a platform grows rapidly like Grubhub, the cost of running batch\ntraining jobs becomes material. A shift from stateless batch learning offline\nto stateful incremental learning online can recover, for example, at Grubhub,\nup to a 45x cost savings and a +20% metrics increase. There are a few\nchallenges to overcome with the transition to online stateful learning, namely\nconvergence, non-stationary embeddings and off-policy evaluation, which we\nexplore from our experiences running this system in production.",
    "descriptor": "",
    "authors": [
      "Alex Egg"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07106"
  },
  {
    "id": "arXiv:2107.07108",
    "title": "Improving I/O Performance for Exascale Applications through Online Data  Layout Reorganization",
    "abstract": "The applications being developed within the U.S. Exascale Computing Project\n(ECP) to run on imminent Exascale computers will generate scientific results\nwith unprecedented fidelity and record turn-around time. Many of these codes\nare based on particle-mesh methods and use advanced algorithms, especially\ndynamic load-balancing and mesh-refinement, to achieve high performance on\nExascale machines. Yet, as such algorithms improve parallel application\nefficiency, they raise new challenges for I/O logic due to their irregular and\ndynamic data distributions. Thus, while the enormous data rates of Exascale\nsimulations already challenge existing file system write strategies, the need\nfor efficient read and processing of generated data introduces additional\nconstraints on the data layout strategies that can be used when writing data to\nsecondary storage. We review these I/O challenges and introduce two online data\nlayout reorganization approaches for achieving good tradeoffs between read and\nwrite performance. We demonstrate the benefits of using these two approaches\nfor the ECP particle-in-cell simulation WarpX, which serves as a motif for a\nlarge class of important Exascale applications. We show that by understanding\napplication I/O patterns and carefully designing data layouts we can increase\nread performance by more than 80%.",
    "descriptor": "\nComments: 12 pages, 15 figures, accepted by IEEE Transactions on Parallel and Distributed Systems\n",
    "authors": [
      "Lipeng Wan",
      "Axel Huebl",
      "Junmin Gu",
      "Franz Poeschel",
      "Ana Gainaru",
      "Ruonan Wang",
      "Jieyang Chen",
      "Xin Liang",
      "Dmitry Ganyushin",
      "Todd Munson",
      "Ian Foster",
      "Jean-Luc Vay",
      "Norbert Podhorszki",
      "Kesheng Wu",
      "Scott Klasky"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07108"
  },
  {
    "id": "arXiv:2107.07110",
    "title": "Recurrent Parameter Generators",
    "abstract": "We present a generic method for recurrently using the same parameters for\nmany different convolution layers to build a deep network. Specifically, for a\nnetwork, we create a recurrent parameter generator (RPG), from which the\nparameters of each convolution layer are generated. Though using recurrent\nmodels to build a deep convolutional neural network (CNN) is not entirely new,\nour method achieves significant performance gain compared to the existing\nworks. We demonstrate how to build a one-layer neural network to achieve\nsimilar performance compared to other traditional CNN models on various\napplications and datasets. Such a method allows us to build an arbitrarily\ncomplex neural network with any amount of parameters. For example, we build a\nResNet34 with model parameters reduced by more than $400$ times, which still\nachieves $41.6\\%$ ImageNet top-1 accuracy. Furthermore, we demonstrate the RPG\ncan be applied at different scales, such as layers, blocks, or even\nsub-networks. Specifically, we use the RPG to build a ResNet18 network with the\nnumber of weights equivalent to one convolutional layer of a conventional\nResNet and show this model can achieve $67.2\\%$ ImageNet top-1 accuracy. The\nproposed method can be viewed as an inverse approach to model compression.\nRather than removing the unused parameters from a large model, it aims to\nsqueeze more information into a small number of parameters. Extensive\nexperiment results are provided to demonstrate the power of the proposed\nrecurrent parameter generator.",
    "descriptor": "",
    "authors": [
      "Jiayun Wang",
      "Yubei Chen",
      "Stella X. Yu",
      "Brian Cheung",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07110"
  },
  {
    "id": "arXiv:2107.07111",
    "title": "On nondeterminism in combinatorial filters",
    "abstract": "The problem of combinatorial filter reduction arises from questions of\nresource optimization in robots; it is one specific way in which automation can\nhelp to achieve minimalism, to build better, simpler robots. This paper\ncontributes a new definition of filter minimization that is broader than its\nantecedents, allowing filters (input, output, or both) to be nondeterministic.\nThis changes the problem considerably. Nondeterministic filters are able to\nre-use states to obtain, essentially, more 'behavior' per vertex. We show that\nthe gap in size can be significant (larger than polynomial), suggesting such\ncases will generally be more challenging than deterministic problems. Indeed,\nthis is supported by the core computational complexity result established in\nthis paper: producing nondeterministic minimizers is PSPACE-hard. The hardness\nseparation for minimization which exists between deterministic filter and\ndeterministic automata, thus, does not hold for the nondeterministic case.",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Yulin Zhang",
      "Dylan A. Shell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07111"
  },
  {
    "id": "arXiv:2107.07112",
    "title": "Neural Code Summarization: How Far Are We?",
    "abstract": "Source code summaries are important for the comprehension and maintenance of\nprograms. However, there are plenty of programs with missing, outdated, or\nmismatched summaries. Recently, deep learning techniques have been exploited to\nautomatically generate summaries for given code snippets. To achieve a profound\nunderstanding of how far we are from solving this problem, in this paper, we\nconduct a systematic and in-depth analysis of five state-of-the-art neural\nsource code summarization models on three widely used datasets. Our evaluation\nresults suggest that: (1) The BLEU metric, which is widely used by existing\nwork for evaluating the performance of the summarization models, has many\nvariants. Ignoring the differences among the BLEU variants could affect the\nvalidity of the claimed results. Furthermore, we discover an important,\npreviously unknown bug about BLEU calculation in a commonly-used software\npackage. (2) Code pre-processing choices can have a large impact on the\nsummarization performance, therefore they should not be ignored. (3) Some\nimportant characteristics of datasets (corpus size, data splitting method, and\nduplication ratio) have a significant impact on model evaluation. Based on the\nexperimental results, we give some actionable guidelines on more systematic\nways for evaluating code summarization and choosing the best method in\ndifferent scenarios. We also suggest possible future research directions. We\nbelieve that our results can be of great help for practitioners and researchers\nin this interesting area.",
    "descriptor": "",
    "authors": [
      "Ensheng Shi",
      "Yanlin Wang",
      "Lun Du",
      "Junjie Chen",
      "Shi Han",
      "Hongyu Zhang",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07112"
  },
  {
    "id": "arXiv:2107.07113",
    "title": "Robust Learning for Text Classification with Multi-source Noise  Simulation and Hard Example Mining",
    "abstract": "Many real-world applications involve the use of Optical Character Recognition\n(OCR) engines to transform handwritten images into transcripts on which\ndownstream Natural Language Processing (NLP) models are applied. In this\nprocess, OCR engines may introduce errors and inputs to downstream NLP models\nbecome noisy. Despite that pre-trained models achieve state-of-the-art\nperformance in many NLP benchmarks, we prove that they are not robust to noisy\ntexts generated by real OCR engines. This greatly limits the application of NLP\nmodels in real-world scenarios. In order to improve model performance on noisy\nOCR transcripts, it is natural to train the NLP model on labelled noisy texts.\nHowever, in most cases there are only labelled clean texts. Since there is no\nhandwritten pictures corresponding to the text, it is impossible to directly\nuse the recognition model to obtain noisy labelled data. Human resources can be\nemployed to copy texts and take pictures, but it is extremely expensive\nconsidering the size of data for model training. Consequently, we are\ninterested in making NLP models intrinsically robust to OCR errors in a low\nresource manner. We propose a novel robust training framework which 1) employs\nsimple but effective methods to directly simulate natural OCR noises from clean\ntexts and 2) iteratively mines the hard examples from a large number of\nsimulated samples for optimal performance. 3) To make our model learn\nnoise-invariant representations, a stability loss is employed. Experiments on\nthree real-world datasets show that the proposed framework boosts the\nrobustness of pre-trained models by a large margin. We believe that this work\ncan greatly promote the application of NLP models in actual scenarios, although\nthe algorithm we use is simple and straightforward. We make our codes and three\ndatasets publicly\navailable\\footnote{https://github.com/tal-ai/Robust-learning-MSSHEM}.",
    "descriptor": "\nComments: ECML-PKDD'21: The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2021\n",
    "authors": [
      "Guowei Xu",
      "Wenbiao Ding",
      "Weiping Fu",
      "Zhongqin Wu",
      "Zitao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07113"
  },
  {
    "id": "arXiv:2107.07114",
    "title": "Uncertainty-Aware Reliable Text Classification",
    "abstract": "Deep neural networks have significantly contributed to the success in\npredictive accuracy for classification tasks. However, they tend to make\nover-confident predictions in real-world settings, where domain shifting and\nout-of-distribution (OOD) examples exist. Most research on uncertainty\nestimation focuses on computer vision because it provides visual validation on\nuncertainty quality. However, few have been presented in the natural language\nprocess domain. Unlike Bayesian methods that indirectly infer uncertainty\nthrough weight uncertainties, current evidential uncertainty-based methods\nexplicitly model the uncertainty of class probabilities through subjective\nopinions. They further consider inherent uncertainty in data with different\nroot causes, vacuity (i.e., uncertainty due to a lack of evidence) and\ndissonance (i.e., uncertainty due to conflicting evidence). In our paper, we\nfirstly apply evidential uncertainty in OOD detection for text classification\ntasks. We propose an inexpensive framework that adopts both auxiliary outliers\nand pseudo off-manifold samples to train the model with prior knowledge of a\ncertain class, which has high vacuity for OOD samples. Extensive empirical\nexperiments demonstrate that our model based on evidential uncertainty\noutperforms other counterparts for detecting OOD examples. Our approach can be\neasily deployed to traditional recurrent neural networks and fine-tuned\npre-trained transformers.",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Yibo Hu",
      "Latifur Khan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07114"
  },
  {
    "id": "arXiv:2107.07116",
    "title": "Transformer-based Machine Learning for Fast SAT Solvers and Logic  Synthesis",
    "abstract": "CNF-based SAT and MaxSAT solvers are central to logic synthesis and\nverification systems. The increasing popularity of these constraint problems in\nelectronic design automation encourages studies on different SAT problems and\ntheir properties for further computational efficiency. There has been both\ntheoretical and practical success of modern Conflict-driven clause learning SAT\nsolvers, which allows solving very large industrial instances in a relatively\nshort amount of time. Recently, machine learning approaches provide a new\ndimension to solving this challenging problem. Neural symbolic models could\nserve as generic solvers that can be specialized for specific domains based on\ndata without any changes to the structure of the model. In this work, we\npropose a one-shot model derived from the Transformer architecture to solve the\nMaxSAT problem, which is the optimization version of SAT where the goal is to\nsatisfy the maximum number of clauses. Our model has a scale-free structure\nwhich could process varying size of instances. We use meta-path and\nself-attention mechanism to capture interactions among homogeneous nodes. We\nadopt cross-attention mechanisms on the bipartite graph to capture interactions\namong heterogeneous nodes. We further apply an iterative algorithm to our model\nto satisfy additional clauses, enabling a solution approaching that of an\nexact-SAT problem. The attention mechanisms leverage the parallelism for\nspeedup. Our evaluation indicates improved speedup compared to heuristic\napproaches and improved completion rate compared to machine learning\napproaches.",
    "descriptor": "",
    "authors": [
      "Feng Shi",
      "Chonghan Lee",
      "Mohammad Khairul Bashar",
      "Nikhil Shukla",
      "Song-Chun Zhu",
      "Vijaykrishnan Narayanan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07116"
  },
  {
    "id": "arXiv:2107.07117",
    "title": "Collision Avoidance Using Spherical Harmonics",
    "abstract": "In this paper, we propose a novel optimization-based trajectory planner that\nutilizes spherical harmonics to estimate the collision-free solution space\naround an agent. The space is estimated using a constrained over-determined\nleast-squares estimator to determine the parameters that define a spherical\nharmonic approximation at a given time step. Since spherical harmonics produce\nstar-convex shapes, the planner can consider all paths that are in\nline-of-sight for the agent within a given radius. This contrasts with other\nstate-of-the-art planners that generate trajectories by estimating obstacle\nboundaries with rough approximations and using heuristic rules to prune a\nsolution space into one that can be easily explored. Those methods cause the\ntrajectory planner to be overly conservative in environments where an agent\nmust get close to obstacles to accomplish a goal. Our method is shown to\nperform on-par with other path planners and surpass these planners in certain\nenvironments. It generates feasible trajectories while still running in\nreal-time and guaranteeing safety when a valid solution exists.",
    "descriptor": "\nComments: 6 pages, MECC 2021\n",
    "authors": [
      "Steven Patrick",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07117"
  },
  {
    "id": "arXiv:2107.07119",
    "title": "Multi-Task Learning based Online Dialogic Instruction Detection with  Pre-trained Language Models",
    "abstract": "In this work, we study computational approaches to detect online dialogic\ninstructions, which are widely used to help students understand learning\nmaterials, and build effective study habits. This task is rather challenging\ndue to the widely-varying quality and pedagogical styles of dialogic\ninstructions. To address these challenges, we utilize pre-trained language\nmodels, and propose a multi-task paradigm which enhances the ability to\ndistinguish instances of different classes by enlarging the margin between\ncategories via contrastive loss. Furthermore, we design a strategy to fully\nexploit the misclassified examples during the training stage. Extensive\nexperiments on a real-world online educational data set demonstrate that our\napproach achieves superior performance compared to representative baselines. To\nencourage reproducible results, we make our implementation online available at\n\\url{https://github.com/AIED2021/multitask-dialogic-instruction}.",
    "descriptor": "\nComments: AIED'21: The 22nd International Conference on Artificial Intelligence in Education, 2021\n",
    "authors": [
      "Yang Hao",
      "Hang Li",
      "Wenbiao Ding",
      "Zhongqin Wu",
      "Jiliang Tang",
      "Rose Luckin",
      "Zitao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07119"
  },
  {
    "id": "arXiv:2107.07121",
    "title": "Preference Incorporation into Many-Objective Optimization: An  Outranking-based Ant Colony Algorithm",
    "abstract": "In this paper, we enriched Ant Colony Optimization (ACO) with interval\noutranking to develop a novel multiobjective ACO optimizer to approach problems\nwith many objective functions. This proposal is suitable if the preferences of\nthe Decision Maker (DM) can be modeled through outranking relations. The\nintroduced algorithm (named Interval Outranking-based ACO, IO-ACO) is the first\nant-colony optimizer that embeds an outranking model to bear vagueness and\nill-definition of DM preferences. This capacity is the most differentiating\nfeature of IO-ACO because this issue is highly relevant in practice. IO-ACO\nbiases the search towards the Region of Interest (RoI), the privileged zone of\nthe Pareto frontier containing the solutions that better match the DM\npreferences. Two widely studied benchmarks were utilized to measure the\nefficiency of IO-ACO, i.e., the DTLZ and WFG test suites. Accordingly, IO-ACO\nwas compared with two competitive many-objective optimizers: The\nIndicator-based Many-Objective ACO and the Multiobjective Evolutionary\nAlgorithm Based on Decomposition. The numerical results show that IO-ACO\napproximates the Region of Interest (RoI) better than the leading\nmetaheuristics based on approximating the Pareto frontier alone.",
    "descriptor": "\nComments: 23 pages, 2 figures, 4 tables. submitted to Swarm and Evolutionary Computation Journal\n",
    "authors": [
      "Gilberto Rivera",
      "Carlos A. Coello Coello",
      "Laura Cruz-Reyes",
      "Eduardo R. Fernandez",
      "Claudia Gomez-Santillan",
      "Nelson Rangel-Valdez"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.07121"
  },
  {
    "id": "arXiv:2107.07122",
    "title": "Solving ESL Sentence Completion Questions via Pre-trained Neural  Language Models",
    "abstract": "Sentence completion (SC) questions present a sentence with one or more blanks\nthat need to be filled in, three to five possible words or phrases as options.\nSC questions are widely used for students learning English as a Second Language\n(ESL) and building computational approaches to automatically solve such\nquestions is beneficial to language learners. In this work, we propose a neural\nframework to solve SC questions in English examinations by utilizing\npre-trained language models. We conduct extensive experiments on a real-world\nK-12 ESL SC question dataset and the results demonstrate the superiority of our\nmodel in terms of prediction accuracy. Furthermore, we run precision-recall\ntrade-off analysis to discuss the practical issues when deploying it in\nreal-life scenarios. To encourage reproducible results, we make our code\npublicly available at \\url{https://github.com/AIED2021/ESL-SentenceCompletion}.",
    "descriptor": "\nComments: AIED'21: The 22nd International Conference on Artificial Intelligence in Education, 2021\n",
    "authors": [
      "Qiongqiong Liu",
      "Tianqiao Liu",
      "Jiafu Zhao",
      "Qiang Fang",
      "Wenbiao Ding",
      "Zhongqin Wu",
      "Feng Xia",
      "Jiliang Tang",
      "Zitao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07122"
  },
  {
    "id": "arXiv:2107.07124",
    "title": "An Educational System for Personalized Teacher Recommendation in K-12  Online Classrooms",
    "abstract": "In this paper, we propose a simple yet effective solution to build practical\nteacher recommender systems for online one-on-one classes. Our system consists\nof (1) a pseudo matching score module that provides reliable training labels;\n(2) a ranking model that scores every candidate teacher; (3) a novelty boosting\nmodule that gives additional opportunities to new teachers; and (4) a diversity\nmetric that guardrails the recommended results to reduce the chance of\ncollision. Offline experimental results show that our approach outperforms a\nwide range of baselines. Furthermore, we show that our approach is able to\nreduce the number of student-teacher matching attempts from 7.22 to 3.09 in a\nfive-month observation on a third-party online education platform.",
    "descriptor": "\nComments: AIED'21: The 22nd International Conference on Artificial Intelligence in Education, 2021\n",
    "authors": [
      "Jiahao Chen",
      "Hang Li",
      "Wenbiao Ding",
      "Zitao Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07124"
  },
  {
    "id": "arXiv:2107.07127",
    "title": "NeuSaver: Neural Adaptive Power Consumption Optimization for Mobile  Video Streaming",
    "abstract": "Video streaming services strive to support high-quality videos at higher\nresolutions and frame rates to improve the quality of experience (QoE).\nHowever, high-quality videos consume considerable amounts of energy on mobile\ndevices. This paper proposes NeuSaver, which reduces the power consumption of\nmobile devices when streaming videos by applying an adaptive frame rate to each\nvideo chunk without compromising user experience. NeuSaver generates an optimal\npolicy that determines the appropriate frame rate for each video chunk using\nreinforcement learning (RL). The RL model automatically learns the policy that\nmaximizes the QoE goals based on previous observations. NeuSaver also uses an\nasynchronous advantage actor-critic algorithm to reinforce the RL model quickly\nand robustly. Streaming servers that support NeuSaver preprocesses videos into\nsegments with various frame rates, which is similar to the process of creating\nvideos with multiple bit rates in dynamic adaptive streaming over HTTP.\nNeuSaver utilizes the commonly used H.264 video codec. We evaluated NeuSaver in\nvarious experiments and a user study through four video categories along with\nthe state-of-the-art model. Our experiments showed that NeuSaver effectively\nreduces the power consumption of mobile devices when streaming video by an\naverage of 16.14% and up to 23.12% while achieving high QoE.",
    "descriptor": "\nComments: 13 pages, 8 figures, 3 tables, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kyoungjun Park",
      "Myungchul Kim",
      "Laihyuk Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07127"
  },
  {
    "id": "arXiv:2107.07133",
    "title": "A life-long SLAM approach using adaptable local maps based on rasterized  LIDAR images",
    "abstract": "Most real-time autonomous robot applications require a robot to traverse\nthrough a dynamic space for a long time. In some cases, a robot needs to work\nin the same environment. Such applications give rise to the problem of a\nlife-long SLAM system. Life-long SLAM presents two main challenges i.e. the\ntracking should not fail in a dynamic environment and the need for a robust and\nefficient mapping strategy. The system should update maps with new information;\nwhile also keeping track of older observations. But, mapping for a long time\ncan require higher computational requirements. In this paper, we propose a\nsolution to the problem of life-long SLAM. We represent the global map as a set\nof rasterized images of local maps along with a map management system\nresponsible for updating local maps and keeping track of older values. We also\npresent an efficient approach of using the bag of visual words method for loop\nclosure detection and relocalization. We evaluate the performance of our system\non the KITTI dataset and an indoor dataset. Our loop closure system reported\nrecall and precision of above 90 percent. The computational cost of our system\nis much lower as compared to state-of-the-art methods. Our method reports lower\ncomputational requirements even for long-term operation.",
    "descriptor": "",
    "authors": [
      "Waqas Ali",
      "Peilin Liu",
      "Rendong Ying",
      "Zheng Gong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07133"
  },
  {
    "id": "arXiv:2107.07136",
    "title": "Learning Mixed-Integer Linear Programs from Contextual Examples",
    "abstract": "Mixed-integer linear programs (MILPs) are widely used in artificial\nintelligence and operations research to model complex decision problems like\nscheduling and routing. Designing such programs however requires both domain\nand modelling expertise. In this paper, we study the problem of acquiring MILPs\nfrom contextual examples, a novel and realistic setting in which examples\ncapture solutions and non-solutions within a specific context. The resulting\nlearning problem involves acquiring continuous parameters -- namely, a cost\nvector and a feasibility polytope -- but has a distinctly combinatorial flavor.\nTo solve this complex problem, we also contribute MISSLE, an algorithm for\nlearning MILPs from contextual examples. MISSLE uses a variant of stochastic\nlocal search that is guided by the gradient of a continuous surrogate loss\nfunction. Our empirical evaluation on synthetic data shows that MISSLE acquires\nbetter MILPs faster than alternatives based on stochastic local search and\ngradient descent.",
    "descriptor": "",
    "authors": [
      "Mohit Kumar",
      "Samuel Kolb",
      "Luc De Raedt",
      "Stefano Teso"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07136"
  },
  {
    "id": "arXiv:2107.07137",
    "title": "Direct-drive ocean wave-powered batch reverse osmosis",
    "abstract": "Ocean waves provide a consistent, reliable source of clean energy making them\na viable energy source for desalination. Ocean wave energy is useful to coastal\ncommunities, especially island nations. However, large capital costs render\ncurrent wave-powered desalination technologies economically infeasible. This\nwork presents a high efficiency configuration for ocean wave energy powering\nbatch reverse osmosis. The proposed system uses seawater as the working fluid\nin a hydro-mechanical wave energy converter and replaces the reverse osmosis\nhigh-pressure pump with a hydraulic converter for direct-drive coupling. This\nallows for minimal intermediary power conversions, fewer components, and higher\nefficiencies. The concept was analyzed with MATLAB to model the transient\nenergy dynamics of the wave energy converter, power take-off system, and\ndesalination load. The fully hydro-mechanical coupling, incorporating energy\nrecovery, could achieve an SEC and LCOW as low as 2.30 kWh/m3 and $1.96,\nrespectively, for different sea states. The results were validated at the\nsub-system level against existing literature on wave energy models and previous\nwork completed on batch reverse osmosis models, as this system was the first to\ncombine these two technologies. SEC and LCOW values were validated by comparing\nto known and predicted values for various types of RO systems.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Katie M. Brodersen",
      "Emily A. Bywater",
      "Alec M. Lanter",
      "Hayden H. Schennum",
      "Kumansh N. Furia",
      "Maulee K. Sheth",
      "Nathaniel S. Kiefer",
      "Brittany K. Cafferty",
      "Akshay K. Rao",
      "Jose M. Garcia",
      "David M. Warsinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07137"
  },
  {
    "id": "arXiv:2107.07141",
    "title": "An Efficient Semi-Streaming PTAS for Tournament Feedback ArcSet with Few  Passes",
    "abstract": "We present the first semi-streaming PTAS for the minimum feedback arc set\nproblem on directed tournaments in a small number of passes. Namely, we obtain\na $(1 + \\varepsilon)$-approximation in polynomial time $O \\left( \\text{poly}(n)\n2^{\\text{poly}(1/\\varepsilon)} \\right)$, with $p$ passes in $n^{1+1/p} \\cdot\n\\text{poly}\\left(\\frac{\\log n}{\\varepsilon}\\right)$ space. The only previous\nalgorithm with this pass/space trade-off gave a $3$-approximation (SODA, 2020),\nand other polynomial-time algorithms which achieved a\n$(1+\\varepsilon)$-approximation did so with quadratic memory or with a linear\nnumber of passes. We also present a new time/space trade-off for $1$-pass\nalgorithms that solve the tournament feedback arc set problem. This problem has\nseveral applications in machine learning such as creating linear classifiers\nand doing Bayesian inference. We also provide several additional algorithms and\nlower bounds for related streaming problems on directed graphs, which is a\nmostly unexplored territory.",
    "descriptor": "\nComments: 29 pages, 4 figures, 1 table, 8 algorithms\n",
    "authors": [
      "Anubhav Baweja",
      "Justin Jia",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07141"
  },
  {
    "id": "arXiv:2107.07148",
    "title": "What Image Features Boost Housing Market Predictions?",
    "abstract": "The attractiveness of a property is one of the most interesting, yet\nchallenging, categories to model. Image characteristics are used to describe\ncertain attributes, and to examine the influence of visual factors on the price\nor timeframe of the listing. In this paper, we propose a set of techniques for\nthe extraction of visual features for efficient numerical inclusion in\nmodern-day predictive algorithms. We discuss techniques such as Shannon's\nentropy, calculating the center of gravity, employing image segmentation, and\nusing Convolutional Neural Networks. After comparing these techniques as\napplied to a set of property-related images (indoor, outdoor, and satellite),\nwe conclude the following: (i) the entropy is the most efficient single-digit\nvisual measure for housing price prediction; (ii) image segmentation is the\nmost important visual feature for the prediction of housing lifespan; and (iii)\ndeep image features can be used to quantify interior characteristics and\ncontribute to captivation modeling. The set of 40 image features selected here\ncarries a significant amount of predictive power and outperforms some of the\nstrongest metadata predictors. Without any need to replace a human expert in a\nreal-estate appraisal process, we conclude that the techniques presented in\nthis paper can efficiently describe visible characteristics, thus introducing\nperceived attractiveness as a quantitative measure into the predictive modeling\nof housing.",
    "descriptor": "",
    "authors": [
      "Zona Kostic",
      "Aleksandar Jevremovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07148"
  },
  {
    "id": "arXiv:2107.07150",
    "title": "Tailor: Generating and Perturbing Text with Semantic Controls",
    "abstract": "Making controlled perturbations is essential for various tasks (e.g., data\naugmentation), but building task-specific generators can be expensive. We\nintroduce Tailor, a task-agnostic generation system that perturbs text in a\nsemantically-controlled way. With unlikelihood training, we design Tailor's\ngenerator to follow a series of control codes derived from semantic roles.\nThrough modifications of these control codes, Tailor can produce fine-grained\nperturbations. We implement a set of operations on control codes that can be\ncomposed into complex perturbation strategies, and demonstrate their\neffectiveness in three distinct applications: First, Tailor facilitates the\nconstruction of high-quality contrast sets that are lexically diverse, and less\nbiased than original task test data. Second, paired with automated labeling\nheuristics, Tailor helps improve model generalization through data\naugmentation: We obtain an average gain of 1.73 on an NLI challenge set by\nperturbing just 5% of training data. Third, without any finetuning overhead,\nTailor's perturbations effectively improve compositionality in fine-grained\nstyle transfer, outperforming fine-tuned baselines on 6 transfers.",
    "descriptor": "",
    "authors": [
      "Alexis Ross",
      "Tongshuang Wu",
      "Hao Peng",
      "Matthew E. Peters",
      "Matt Gardner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.07150"
  },
  {
    "id": "arXiv:2107.07153",
    "title": "Semantic Image Cropping",
    "abstract": "Automatic image cropping techniques are commonly used to enhance the\naesthetic quality of an image; they do it by detecting the most beautiful or\nthe most salient parts of the image and removing the unwanted content to have a\nsmaller image that is more visually pleasing. In this thesis, I introduce an\nadditional dimension to the problem of cropping, semantics. I argue that image\ncropping can also enhance the image's relevancy for a given entity by using the\nsemantic information contained in the image. I call this problem, Semantic\nImage Cropping. To support my argument, I provide a new dataset containing 100\nimages with at least two different entities per image and four ground truth\ncroppings collected using Amazon Mechanical Turk. I use this dataset to show\nthat state-of-the-art cropping algorithms that only take into account\naesthetics do not perform well in the problem of semantic image cropping.\nAdditionally, I provide a new deep learning system that takes not just\naesthetics but also semantics into account to generate image croppings, and I\nevaluate its performance using my new semantic cropping dataset, showing that\nusing the semantic information of an image can help to produce better\ncroppings.",
    "descriptor": "",
    "authors": [
      "Oriol Corcoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07153"
  },
  {
    "id": "arXiv:2107.07154",
    "title": "What and When to Look?: Temporal Span Proposal Network for Video Visual  Relation Detection",
    "abstract": "Identifying relations between objects is central to understanding the scene.\nWhile several works have been proposed for relation modeling in the image\ndomain, there have been many constraints in the video domain due to challenging\ndynamics of spatio-temporal interactions (e.g., Between which objects are there\nan interaction? When do relations occur and end?). To date, two representative\nmethods have been proposed to tackle Video Visual Relation Detection (VidVRD):\nsegment-based and window-based. We first point out the limitations these two\nmethods have and propose Temporal Span Proposal Network (TSPN), a novel method\nwith two advantages in terms of efficiency and effectiveness. 1) TSPN tells\nwhat to look: it sparsifies relation search space by scoring relationness\n(i.e., confidence score for the existence of a relation between pair of\nobjects) of object pair. 2) TSPN tells when to look: it leverages the full\nvideo context to simultaneously predict the temporal span and categories of the\nentire relations. TSPN demonstrates its effectiveness by achieving new\nstate-of-the-art by a significant margin on two VidVRD benchmarks\n(ImageNet-VidVDR and VidOR) while also showing lower time complexity than\nexisting methods - in particular, twice as efficient as a popular segment-based\napproach.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sangmin Woo",
      "Junhyug Noh",
      "Kangil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07154"
  },
  {
    "id": "arXiv:2107.07155",
    "title": "Predicting market inflation expectations with news topics and sentiment",
    "abstract": "This study presents a novel approach to incorporating news topics and their\nassociated sentiment into predictions of breakeven inflation rate (BEIR)\nmovements for eight countries with mature bond markets. We calibrate five\nclasses of machine learning models including narrative-based features for each\ncountry, and find that they generally outperform corresponding benchmarks that\ndo not include such features. We find Logistic Regression and XGBoost\nclassifiers to deliver the best performance across countries. We complement\nthese results with a feature importance analysis, showing that economic and\nfinancial topics are the key performance drivers in our predictions, with\nadditional contributions from topics related to health and government. We\nexamine cross-country spillover effects of news narrative on BEIR via Graphical\nGranger Causality and confirm their existence for the US and Germany, while\nfive other countries considered in our study are only influenced by local\nnarrative.",
    "descriptor": "",
    "authors": [
      "Sonja Tilly",
      "Giacomo Livan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07155"
  },
  {
    "id": "arXiv:2107.07157",
    "title": "A64FX -- Your Compiler You Must Decide!",
    "abstract": "The current number one of the TOP500 list, Supercomputer Fugaku, has\ndemonstrated that CPU-only HPC systems aren't dead and CPUs can be used for\nmore than just being the host controller for a discrete accelerators. While the\nspecifications of the chip and overall system architecture, and benchmarks\nsubmitted to various lists, like TOP500 and Green500, etc., are clearly\nhighlighting the potential, the proliferation of Arm into the HPC business is\nrather recent and hence the software stack might not be fully matured and\ntuned, yet. We test three state-of-the-art compiler suite against a broad set\nof benchmarks. Our measurements show that orders of magnitudes in performance\ncan be gained by deviating from the recommended usage model of the A64FX\ncompute nodes.",
    "descriptor": "",
    "authors": [
      "Jens Domke"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.07157"
  },
  {
    "id": "arXiv:2107.07160",
    "title": "Lockout: Sparse Regularization of Neural Networks",
    "abstract": "Many regression and classification procedures fit a parameterized function\n$f(x;w)$ of predictor variables $x$ to data $\\{x_{i},y_{i}\\}_1^N$ based on some\nloss criterion $L(y,f)$. Often, regularization is applied to improve accuracy\nby placing a constraint $P(w)\\leq t$ on the values of the parameters $w$.\nAlthough efficient methods exist for finding solutions to these constrained\noptimization problems for all values of $t\\geq0$ in the special case when $f$\nis a linear function, none are available when $f$ is non-linear (e.g. Neural\nNetworks). Here we present a fast algorithm that provides all such solutions\nfor any differentiable function $f$ and loss $L$, and any constraint $P$ that\nis an increasing monotone function of the absolute value of each parameter.\nApplications involving sparsity inducing regularization of arbitrary Neural\nNetworks are discussed. Empirical results indicate that these sparse solutions\nare usually superior to their dense counterparts in both accuracy and\ninterpretability. This improvement in accuracy can often make Neural Networks\ncompetitive with, and sometimes superior to, state-of-the-art methods in the\nanalysis of tabular data.",
    "descriptor": "",
    "authors": [
      "Gilmer Valdes",
      "Wilmer Arbelo",
      "Yannet Interian",
      "Jerome H. Friedman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07160"
  },
  {
    "id": "arXiv:2107.07161",
    "title": "Frequency-Time Division based Deep Learning for OFDM Channel Estimation",
    "abstract": "In this paper, we propose a frequency-time division network (FreqTimeNet) to\nimprove the performance of deep learning (DL) based OFDM channel estimation.\nThis FreqTimeNet is designed based on the orthogonality between the frequency\ndomain and the time domain. In FreqTimeNet, the input signals are processed by\nparallel frequency blocks first and then go through parallel time blocks. Using\n3rd Generation Partnership Project (3GPP) channel models, the mean square error\n(MSE) performance of FreqTimeNet under different scenarios is evaluated. A\nmethod for constructing mixed training data is proposed, which could address\nthe generalization problem in DL. It is observed that FreqTimeNet outperforms\nother DL networks, with acceptable complexity.",
    "descriptor": "",
    "authors": [
      "Ang Yang",
      "Peng Sun",
      "Tamrakar Rakesh",
      "Bule Sun",
      "Fei Qin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07161"
  },
  {
    "id": "arXiv:2107.07164",
    "title": "The Feedback Capacity of Noisy Output is the STate (NOST) Channels",
    "abstract": "We consider finite-state channels (FSCs) where the channel state is\nstochastically dependent on the previous channel output. We refer to these as\nNoisy Output is the STate (NOST) channels. We derive the feedback capacity of\nNOST channels in two scenarios: with and without causal state information (CSI)\navailable at the encoder. If CSI is unavailable, the feedback capacity is\n$C_{\\text{FB}}= \\max_{P(x|y')} I(X;Y|Y')$, while if it is available at the\nencoder, the feedback capacity is $C_{\\text{FB-CSI}}= \\max_{P(u|y'),x(u,s')}\nI(U;Y|Y')$, where $U$ is an auxiliary random variable with finite cardinality.\nIn both formulas, the output process is a Markov process with stationary\ndistribution. The derived formulas generalize special known instances from the\nliterature, such as where the state is distributed i.i.d. and where it is a\ndeterministic function of the output. $C_{\\text{FB}}$ and $C_{\\text{FB-CSI}}$\nare also shown to be computable via concave optimization problem formulations.\nFinally, we give a sufficient condition under which CSI available at the\nencoder does not increase the feedback capacity, and we present an interesting\nexample that demonstrates this.",
    "descriptor": "\nComments: 28 pages, 5 figures\n",
    "authors": [
      "Eli Shemuel",
      "Oron Sabag",
      "Haim Permuter"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07164"
  },
  {
    "id": "arXiv:2107.07167",
    "title": "An Efficient and Small Convolutional Neural Network for Pest Recognition  -- ExquisiteNet",
    "abstract": "Nowadays, due to the rapid population expansion, food shortage has become a\ncritical issue. In order to stabilizing the food source production, preventing\ncrops from being attacked by pests is very important. In generally, farmers use\npesticides to kill pests, however, improperly using pesticides will also kill\nsome insects which is beneficial to crops, such as bees. If the number of bees\nis too few, the supplement of food in the world will be in short. Besides,\nexcessive pesticides will seriously pollute the environment. Accordingly,\nfarmers need a machine which can automatically recognize the pests. Recently,\ndeep learning is popular because its effectiveness in the field of image\nclassification. In this paper, we propose a small and efficient model called\nExquisiteNet to complete the task of recognizing the pests and we expect to\napply our model on mobile devices. ExquisiteNet mainly consists of two blocks.\nOne is double fusion with squeeze-and-excitation-bottleneck block (DFSEB\nblock), and the other is max feature expansion block (ME block). ExquisiteNet\nonly has 0.98M parameters and its computing speed is very fast almost the same\nas SqueezeNet. In order to evaluate our model's performance, we test our model\non a benchmark pest dataset called IP102. Compared to many state-of-the-art\nmodels, such as ResNet101, ShuffleNetV2, MobileNetV3-large and EfficientNet\netc., our model achieves higher accuracy, that is, 52.32% on the test set of\nIP102 without any data augmentation.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Shi-Yao Zhou",
      "Chung-Yen Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07167"
  },
  {
    "id": "arXiv:2107.07169",
    "title": "Arrow: A RISC-V Vector Accelerator for Machine Learning Inference",
    "abstract": "In this paper we present Arrow, a configurable hardware accelerator\narchitecture that implements a subset of the RISC-V v0.9 vector ISA extension\naimed at edge machine learning inference. Our experimental results show that an\nArrow co-processor can execute a suite of vector and matrix benchmarks\nfundamental to machine learning inference 2 - 78x faster than a scalar RISC\nprocessor while consuming 20% - 99% less energy when implemented in a Xilinx\nXC7A200T-1SBG484C FPGA.",
    "descriptor": "\nComments: Presented at the Fifth Workshop on Computer Architecture Research with RISC-V (CARRV 2021), co-located with ISCA 2021\n",
    "authors": [
      "Imad Al Assir",
      "Mohamad El Iskandarani",
      "Hadi Rayan Al Sandid",
      "Mazen A. R. Saghir"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.07169"
  },
  {
    "id": "arXiv:2107.07170",
    "title": "FLEX: Unifying Evaluation for Few-Shot NLP",
    "abstract": "Few-shot NLP research is highly active, yet conducted in disjoint research\nthreads with evaluation suites that lack challenging-yet-realistic testing\nsetups and fail to employ careful experimental design. Consequently, the\ncommunity does not know which techniques perform best or even if they\noutperform simple baselines. We formulate desiderata for an ideal few-shot NLP\nbenchmark and present FLEX, the first benchmark, public leaderboard, and\nframework that provides unified, comprehensive measurement for few-shot NLP\ntechniques. FLEX incorporates and introduces new best practices for few-shot\nevaluation, including measurement of four transfer settings, textual labels for\nzero-shot evaluation, and a principled approach to benchmark design that\noptimizes statistical accuracy while keeping evaluation costs accessible to\nresearchers without large compute resources. In addition, we present UniFew, a\nsimple yet strong prompt-based model for few-shot learning which unifies the\npretraining and finetuning prompt formats, eschewing complex machinery of\nrecent prompt-based approaches in adapting downstream task formats to language\nmodel pretraining objectives. We demonstrate that despite simplicity UniFew\nachieves results competitive with both popular meta-learning and prompt-based\napproaches.",
    "descriptor": "\nComments: First two authors contributed equally. Code and leaderboard available at: this https URL\n",
    "authors": [
      "Jonathan Bragg",
      "Arman Cohan",
      "Kyle Lo",
      "Iz Beltagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07170"
  },
  {
    "id": "arXiv:2107.07171",
    "title": "DeFed: A Principled Decentralized and Privacy-Preserving Federated  Learning Algorithm",
    "abstract": "Federated learning enables a large number of clients to participate in\nlearning a shared model while maintaining the training data stored in each\nclient, which protects data privacy and security. Till now, federated learning\nframeworks are built in a centralized way, in which a central client is needed\nfor collecting and distributing information from every other client. This not\nonly leads to high communication pressure at the central client, but also\nrenders the central client highly vulnerable to failure and attack. Here we\npropose a principled decentralized federated learning algorithm (DeFed), which\nremoves the central client in the classical Federated Averaging (FedAvg)\nsetting and only relies information transmission between clients and their\nlocal neighbors. The proposed DeFed algorithm is proven to reach the global\nminimum with a convergence rate of $O(1/T)$ when the loss function is smooth\nand strongly convex, where $T$ is the number of iterations in gradient descent.\nFinally, the proposed algorithm has been applied to a number of toy examples to\ndemonstrate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Ye Yuan",
      "Ruijuan Chen",
      "Chuan Sun",
      "Maolin Wang",
      "Feng Hua",
      "Xinlei Yi",
      "Tao Yang",
      "Jun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07171"
  },
  {
    "id": "arXiv:2107.07173",
    "title": "Scene-adaptive Knowledge Distillation for Sequential Recommendation via  Differentiable Architecture Search",
    "abstract": "Sequential recommender systems (SRS) have become a research hotspot due to\nits power in modeling user dynamic interests and sequential behavioral\npatterns. To maximize model expressive ability, a default choice is to apply a\nlarger and deeper network architecture, which, however, often brings high\nnetwork latency when generating online recommendations. Naturally, we argue\nthat compressing the heavy recommendation models into middle- or light- weight\nneural networks is of great importance for practical production systems. To\nrealize such a goal, we propose AdaRec, a knowledge distillation (KD) framework\nwhich compresses knowledge of a teacher model into a student model adaptively\naccording to its recommendation scene by using differentiable Neural\nArchitecture Search (NAS). Specifically, we introduce a target-oriented\ndistillation loss to guide the structure search process for finding the student\nnetwork architecture, and a cost-sensitive loss as constraints for model size,\nwhich achieves a superior trade-off between recommendation effectiveness and\nefficiency. In addition, we leverage Earth Mover's Distance (EMD) to realize\nmany-to-many layer mapping during knowledge distillation, which enables each\nintermediate student layer to learn from other intermediate teacher layers\nadaptively. Extensive experiments on real-world recommendation datasets\ndemonstrate that our model achieves competitive or better accuracy with notable\ninference speedup comparing to strong counterparts, while discovering diverse\nneural architectures for sequential recommender models under different\nrecommendation scenes.",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Fajie Yuan",
      "Jiaxi Yang",
      "Min Yang",
      "Chengming Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07173"
  },
  {
    "id": "arXiv:2107.07179",
    "title": "Conflict-free Cooperation Method for Connected and Automated Vehicles at  Unsignalized Intersections: Graph-based Modeling and Optimality Analysis",
    "abstract": "Connected and automated vehicles have shown great potential in improving\ntraffic mobility and reducing emissions, especially at unsignalized\nintersections. Previous research has shown that vehicle passing order is the\nkey influencing factor in improving intersection traffic mobility. In this\npaper, we propose a graph-based cooperation method to formalize the\nconflict-free scheduling problem at an unsignalized intersection. Based on\ngraphical analysis, a vehicle's trajectory conflict relationship is modeled as\na conflict directed graph and a coexisting undirected graph. Then, two\ngraph-based methods are proposed to find the vehicle passing order. The first\nis an improved depth-first spanning tree algorithm, which aims to find the\nlocal optimal passing order vehicle by vehicle. The other novel method is a\nminimum clique cover algorithm, which identifies the global optimal solution.\nFinally, a distributed control framework and communication topology are\npresented to realize the conflict-free cooperation of vehicles. Extensive\nnumerical simulations are conducted for various numbers of vehicles and traffic\nvolumes, and the simulation results prove the effectiveness of the proposed\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Chaoyi Chen",
      "Qing Xu",
      "Mengchi Cai",
      "Jiawei Wang",
      "Jianqiang Wang",
      "Biao Xu",
      "Keqiang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07179"
  },
  {
    "id": "arXiv:2107.07183",
    "title": "Streaming Submodular Maximization with Matroid and Matching Constraints",
    "abstract": "Recent progress in (semi-)streaming algorithms for monotone submodular\nfunction maximization has led to tight results for a simple cardinality\nconstraint. However, current techniques fail to give a similar understanding\nfor natural generalizations such as matroid and matching constraints. This\npaper aims at closing this gap. For a single matroid of rank $k$ (i.e., any\nsolution has cardinality at most $k$), our main results are:\n$\\bullet$ A single-pass streaming algorithm that uses $\\widetilde{O}(k)$\nmemory and achieves an approximation guarantee of 0.3178.\n$\\bullet$ A multi-pass streaming algorithm that uses $\\widetilde{O}(k)$\nmemory and achieves an approximation guarantee of $(1-1/e - \\varepsilon)$ by\ntaking constant number of passes over the stream.\nThis improves on the previously best approximation guarantees of 1/4 and 1/2\nfor single-pass and multi-pass streaming algorithms, respectively. In fact, our\nmulti-pass streaming algorithm is tight in that any algorithm with a better\nguarantee than 1/2 must make several passes through the stream and any\nalgorithm that beats our guarantee $1-1/e$ must make linearly many passes.\nFor the problem of maximizing a monotone submodular function subject to a\nbipartite matching constraint (which is a special case of matroid\nintersection), we show that it is not possible to obtain better than\n0.3715-approximation in a single pass, which improves over a recent\ninapproximability of 0.522 for this problem. Furthermore, given a plausible\nassumption, our inapproximability result improves to $1/3 \\approx 0.333$.",
    "descriptor": "\nComments: 58 pages\n",
    "authors": [
      "Moran Feldman",
      "Ashkan Norouzi-Fard",
      "Ola Svensson",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.07183"
  },
  {
    "id": "arXiv:2107.07184",
    "title": "MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven  Reinforcement Learning",
    "abstract": "Exploration in reinforcement learning is a challenging problem: in the worst\ncase, the agent must search for reward states that could be hidden anywhere in\nthe state space. Can we define a more tractable class of RL problems, where the\nagent is provided with examples of successful outcomes? In this problem\nsetting, the reward function can be obtained automatically by training a\nclassifier to categorize states as successful or not. If trained properly, such\na classifier can not only afford a reward function, but actually provide a\nwell-shaped objective landscape that both promotes progress toward good states\nand provides a calibrated exploration bonus. In this work, we we show that an\nuncertainty aware classifier can solve challenging reinforcement learning\nproblems by both encouraging exploration and provided directed guidance towards\npositive outcomes. We propose a novel mechanism for obtaining these calibrated,\nuncertainty-aware classifiers based on an amortized technique for computing the\nnormalized maximum likelihood (NML) distribution, also showing how these\ntechniques can be made computationally tractable by leveraging tools from\nmeta-learning. We show that the resulting algorithm has a number of intriguing\nconnections to both count-based exploration methods and prior algorithms for\nlearning reward functions, while also providing more effective guidance towards\nthe goal. We demonstrate that our algorithm solves a number of challenging\nnavigation and robotic manipulation tasks which prove difficult or impossible\nfor prior methods.",
    "descriptor": "\nComments: Accepted to ICML 2021. First two authors contributed equally\n",
    "authors": [
      "Kevin Li",
      "Abhishek Gupta",
      "Ashwin Reddy",
      "Vitchyr Pong",
      "Aurick Zhou",
      "Justin Yu",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07184"
  },
  {
    "id": "arXiv:2107.07191",
    "title": "Deep Learning based Food Instance Segmentation using Synthetic Data",
    "abstract": "In the process of intelligently segmenting foods in images using deep neural\nnetworks for diet management, data collection and labeling for network training\nare very important but labor-intensive tasks. In order to solve the\ndifficulties of data collection and annotations, this paper proposes a food\nsegmentation method applicable to real-world through synthetic data. To perform\nfood segmentation on healthcare robot systems, such as meal assistance robot\narm, we generate synthetic data using the open-source 3D graphics software\nBlender placing multiple objects on meal plate and train Mask R-CNN for\ninstance segmentation. Also, we build a data collection system and verify our\nsegmentation model on real-world food data. As a result, on our real-world\ndataset, the model trained only synthetic data is available to segment food\ninstances that are not trained with 52.2% mask AP@all, and improve performance\nby +6.4%p after fine-tuning comparing to the model trained from scratch. In\naddition, we also confirm the possibility and performance improvement on the\npublic dataset for fair analysis. Our code and pre-trained weights are\navaliable online at: https://github.com/gist-ailab/Food-Instance-Segmentation",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "D. Park",
      "J. Lee",
      "J. Lee",
      "K. Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07191"
  },
  {
    "id": "arXiv:2107.07192",
    "title": "Incorporating Lambertian Priors into Surface Normals Measurement",
    "abstract": "The goal of photometric stereo is to measure the precise surface normal of a\n3D object from observations with various shading cues. However, non-Lambertian\nsurfaces influence the measurement accuracy due to irregular shading cues.\nDespite deep neural networks have been employed to simulate the performance of\nnon-Lambertian surfaces, the error in specularities, shadows, and crinkle\nregions is hard to be reduced. In order to address this challenge, we here\npropose a photometric stereo network that incorporates Lambertian priors to\nbetter measure the surface normal. In this paper, we use the initial normal\nunder the Lambertian assumption as the prior information to refine the normal\nmeasurement, instead of solely applying the observed shading cues to deriving\nthe surface normal. Our method utilizes the Lambertian information to\nreparameterize the network weights and the powerful fitting ability of deep\nneural networks to correct these errors caused by general reflectance\nproperties. Our explorations include: the Lambertian priors (1) reduce the\nlearning hypothesis space, making our method learn the mapping in the same\nsurface normal space and improving the accuracy of learning, and (2) provides\nthe differential features learning, improving the surfaces reconstruction of\ndetails. Extensive experiments verify the effectiveness of the proposed\nLambertian prior photometric stereo network in accurate surface normal\nmeasurement, on the challenging benchmark dataset.",
    "descriptor": "",
    "authors": [
      "Yakun Ju",
      "Muwei Jian",
      "Shaoxiang Guo",
      "Yingyu Wang",
      "Huiyu Zhou",
      "Junyu Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07192"
  },
  {
    "id": "arXiv:2107.07195",
    "title": "Efficient Resources Distribution for an Ephemeral Cloud/Edge continuum",
    "abstract": "This paper presents the idea and the concepts behind the vision of an\nEphemeral Cloud/Edge Continuum, a cloud/edge computing landscape that enables\nthe exploitation of a widely distributed, dynamic, and context-aware set of\nresources. The Ephemeral Continuum answer to the need of combining a plethora\nof heterogeneous devices, which nowadays are pervasively embedding anthropic\nenvironments, with both federations of cloud providers and the resources\nlocated at the Edge. The aim of the Ephemeral Continuum is to realise a\ncontext-aware and personalised federation of computational, data and network\nresources, able to manage their heterogeneity in a highly distributed\ndeployment.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1610.07371\n",
    "authors": [
      "Emanuele Carlini",
      "Patrizio Dazzi",
      "Luca Ferrucci",
      "Matteo Mordacchini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07195"
  },
  {
    "id": "arXiv:2107.07197",
    "title": "Randomized ReLU Activation for Uncertainty Estimation of Deep Neural  Networks",
    "abstract": "Deep neural networks (DNNs) have successfully learned useful data\nrepresentations in various tasks, however, assessing the reliability of these\nrepresentations remains a challenge. Deep Ensemble is widely considered the\nstate-of-the-art method for uncertainty estimation, but it is very expensive to\ntrain and test. MC-Dropout is another alternative method, which is less\nexpensive but lacks the diversity of predictions. To get more diverse\npredictions in less time, we introduce Randomized ReLU Activation (RRA)\nframework. Under the framework, we propose two strategies, MC-DropReLU and\nMC-RReLU, to estimate uncertainty. Instead of randomly dropping some neurons of\nthe network as in MC-Dropout, the RRA framework adds randomness to the\nactivation function module, making the outputs diverse. As far as we know, this\nis the first attempt to add randomness to the activation function module to\ngenerate predictive uncertainty. We analyze and compare the output diversity of\nMC-Dropout and our method from the variance perspective and obtain the\nrelationship between the hyperparameters and output diversity in the two\nmethods. Moreover, our method is simple to implement and does not need to\nmodify the existing model. We experimentally validate the RRA framework on\nthree widely used datasets, CIFAR10, CIFAR100, and TinyImageNet. The\nexperiments demonstrate that our method has competitive performance but is more\nfavorable in training time and memory requirements.",
    "descriptor": "",
    "authors": [
      "Yufeng Xia",
      "Jun Zhang",
      "Zhiqiang Gong",
      "Tingsong Jiang",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07197"
  },
  {
    "id": "arXiv:2107.07200",
    "title": "Real-Time Grasping Strategies Using Event Camera",
    "abstract": "Robotic vision plays a key role for perceiving the environment in grasping\napplications. However, the conventional framed-based robotic vision, suffering\nfrom motion blur and low sampling rate, may not meet the automation needs of\nevolving industrial requirements. This paper, for the first time, proposes an\nevent-based robotic grasping framework for multiple known and unknown objects\nin a cluttered scene. Compared with standard frame-based vision, neuromorphic\nvision has advantages of microsecond-level sampling rate and no motion blur.\nBuilding on that, the model-based and model-free approaches are developed for\nknown and unknown objects' grasping respectively. For the model-based approach,\nevent-based multi-view approach is used to localize the objects in the scene,\nand then point cloud processing allows for the clustering and registering of\nobjects. Differently, the proposed model-free approach utilizes the developed\nevent-based object segmentation, visual servoing and grasp planning to\nlocalize, align to, and grasp the targeting object. The proposed approaches are\nexperimentally validated with objects of different sizes, using a UR10 robot\nwith an eye-in-hand neuromorphic camera and a Barrett hand gripper. Moreover,\nthe robustness of the two proposed event-based grasping approaches are\nvalidated in a low-light environment. This low-light operating ability shows a\ngreat advantage over the grasping using the standard frame-based vision.\nFurthermore, the developed model-free approach demonstrates the advantage of\ndealing with unknown object without prior knowledge compared to the proposed\nmodel-based approach.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Xiaoqian Huang",
      "Mohamad Halwani",
      "Rajkumar Muthusamy",
      "Abdulla Ayyad",
      "Dewald Swart",
      "Lakmal Seneviratne",
      "Dongming Gan",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07200"
  },
  {
    "id": "arXiv:2107.07201",
    "title": "Neighbor-view Enhanced Model for Vision and Language Navigation",
    "abstract": "Vision and Language Navigation (VLN) requires an agent to navigate to a\ntarget location by following natural language instructions. Most of existing\nworks represent a navigation candidate by the feature of the corresponding\nsingle view where the candidate lies in. However, an instruction may mention\nlandmarks out of the single view as references, which might lead to failures of\ntextual-visual matching of existing methods. In this work, we propose a\nmulti-module Neighbor-View Enhanced Model (NvEM) to adaptively incorporate\nvisual contexts from neighbor views for better textual-visual matching.\nSpecifically, our NvEM utilizes a subject module and a reference module to\ncollect contexts from neighbor views. The subject module fuses neighbor views\nat a global level, and the reference module fuses neighbor objects at a local\nlevel. Subjects and references are adaptively determined via attention\nmechanisms. Our model also includes an action module to utilize the strong\norientation guidance (e.g., ``turn left'') in instructions. Each module\npredicts navigation action separately and their weighted sum is used for\npredicting the final action. Extensive experimental results demonstrate the\neffectiveness of the proposed method on the R2R and R4R benchmarks against\nseveral state-of-the-art navigators, and NvEM even beats some pre-training\nones. Our code is available at https://github.com/MarSaKi/NvEM.",
    "descriptor": "",
    "authors": [
      "Dong An",
      "Yuankai Qi",
      "Yan Huang",
      "Qi Wu",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07201"
  },
  {
    "id": "arXiv:2107.07203",
    "title": "Clustering-based convergence diagnostic for multi-modal identification  in parameter estimation of chromatography model with parallel MCMC",
    "abstract": "Uncertainties from experiments and models render multi-modal difficulties in\nmodel calibrations. Bayesian inference and \\textsc{mcmc} algorithm have been\napplied to obtain posterior distributions of model parameters upon uncertainty.\nHowever, multi-modality leads to difficulty in convergence criterion of\nparallel \\textsc{mcmc} sampling chains. The commonly applied $\\widehat{R}$\ndiagnostic does not behave well when multiple sampling chains are evolving to\ndifferent modes. Both partitional and hierarchical clustering methods has been\ncombined to the traditional $\\widehat{R}$ diagnostic to deal with sampling of\ntarget distributions that are rough and multi-modal. It is observed that the\ndistributions of binding parameters and pore diffusion of particle parameters\nare multi-modal. Therefore, the steric mass-action model used to describe\nion-exchange effects of the model protein, lysozyme, on the \\textsc{sp}\nSepharose \\textsc{ff} stationary phase might not be fully capable in certain\nexperimental conditions, as model uncertainty from steric mass-action would\nresult in multi-modality.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Yue-Chao Zhu",
      "Zhaoxi Sun",
      "Qiao-Le He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.07203"
  },
  {
    "id": "arXiv:2107.07208",
    "title": "Design of Distributed Reconfigurable Robotics Systems with ReconROS",
    "abstract": "Robotics applications process large amounts of data in real-time and require\ncompute platforms that provide high performance and energy-efficiency. FPGAs\nare well-suited for many of these applications, but there is a reluctance in\nthe robotics community to use hardware acceleration due to increased design\ncomplexity and a lack of consistent programming models across the\nsoftware/hardware boundary. In this paper we present ReconROS, a framework that\nintegrates the widely-used robot operating system (ROS) with ReconOS, which\nfeatures multithreaded programming of hardware and software threads for\nreconfigurable computers. This unique combination gives ROS2 developers the\nflexibility to transparently accelerate parts of their robotics applications in\nhardware. We elaborate on the architecture and the design flow for ReconROS and\nreport on a set of experiments that underline the feasibility and flexibility\nof our approach.",
    "descriptor": "\nComments: Paper is under review\n",
    "authors": [
      "Christian Lienen",
      "Marco Platzner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07208"
  },
  {
    "id": "arXiv:2107.07211",
    "title": "Decentralized Bayesian Learning with Metropolis-Adjusted Hamiltonian  Monte Carlo",
    "abstract": "Federated learning performed by a decentralized networks of agents is\nbecoming increasingly important with the prevalence of embedded software on\nautonomous devices. Bayesian approaches to learning benefit from offering more\ninformation as to the uncertainty of a random quantity, and Langevin and\nHamiltonian methods are effective at realizing sampling from an uncertain\ndistribution with large parameter dimensions. Such methods have only recently\nappeared in the decentralized setting, and either exclusively use stochastic\ngradient Langevin and Hamiltonian Monte Carlo approaches that require a\ndiminishing stepsize to asymptotically sample from the posterior and are known\nin practice to characterize uncertainty less faithfully than constant step-size\nmethods with a Metropolis adjustment, or assume strong convexity properties of\nthe potential function. We present the first approach to incorporating constant\nstepsize Metropolis-adjusted HMC in the decentralized sampling framework, show\ntheoretical guarantees for consensus and probability distance to the posterior\nstationary distribution, and demonstrate their effectiveness numerically on\nstandard real world problems, including decentralized learning of neural\nnetworks which is known to be highly non-convex.",
    "descriptor": "",
    "authors": [
      "Vyacheslav Kungurtsev",
      "Adam Cobb",
      "Tara Javidi",
      "Brian Jalaian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07211"
  },
  {
    "id": "arXiv:2107.07212",
    "title": "Duplicated Code Pattern Mining in Visual Programming Languages",
    "abstract": "Visual Programming Languages (VPLs), coupled with the high-level abstractions\nthat are commonplace in visual programming environments, enable users with less\ntechnical knowledge to become proficient programmers. However, the lower skill\nfloor required by VPLs also entails that programmers are more likely to not\nadhere to best practices of software development, producing systems with high\ntechnical debt, and thus poor maintainability. Duplicated code is one important\nexample of such technical debt. In fact, we observed that the amount of\nduplication in the OutSystems VPL code bases can reach as high as $39\\%$.\nDuplicated code detection in text-based programming languages is still an\nactive area of research with important implications regarding software\nmaintainability and evolution. However, to the best of our knowledge, the\nliterature on duplicated code detection for VPLs is very limited. We propose a\nnovel and scalable duplicated code pattern mining algorithm that leverages the\nvisual structure of VPLs in order to not only detect duplicated code, but also\nhighlight duplicated code patterns that explain the reported duplication. The\nperformance of the proposed approach is evaluated on a wide range of real-world\nmobile and web applications developed using OutSystems.",
    "descriptor": "\nComments: Shorter version accepted for publication at FSE 2021\n",
    "authors": [
      "Miguel Terra-Neves",
      "Jo\u00e3o Nadkarni",
      "Miguel Ventura",
      "Pedro Resende",
      "Hugo Veiga",
      "Ant\u00f3nio Alegria"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07212"
  },
  {
    "id": "arXiv:2107.07217",
    "title": "Satellite Communication Digital Twin for Evaluating Novel Solutions:  Dynamic Link Emulation Architecture",
    "abstract": "This paper presents the design and architecture of a network emulator whose\nlinks' parameters (such as delay and bandwidth) vary at different time\ninstances. The emulator is used as a digital twin for satellite communication\nsystems, in order to test and evaluate novel solutions before their final\ndeployment. To achieve such a goal, different existing technologies are\ncarefully combined to emulate link dynamicity, automatic traffic generation,\nand overall topology emulation. Since emulating asymmetric dynamic links (as\nrequired in satellite communications) is far from trivial, we provide a\ndetailed design architecture for solving such task. Experimental results show\nthe precision of our dynamic assignments and the overall flexibility of the\nproposed solution.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted for evaluation\n",
    "authors": [
      "Erick Petersen",
      "Jorge L\u00f3pez",
      "Natalia Kushik",
      "Claude Poletti",
      "Djamal Zeghlache$"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07217"
  },
  {
    "id": "arXiv:2107.07223",
    "title": "Improving Security in McAdams Coefficient-Based Speaker Anonymization by  Watermarking Method",
    "abstract": "Speaker anonymization aims to suppress speaker individuality to protect\nprivacy in speech while preserving the other aspects, such as speech content.\nOne effective solution for anonymization is to modify the McAdams coefficient.\nIn this work, we propose a method to improve the security for speaker\nanonymization based on the McAdams coefficient by using a speech watermarking\napproach. The proposed method consists of two main processes: one for embedding\nand one for detection. In embedding process, two different McAdams coefficients\nrepresent binary bits ``0\" and ``1\". The watermarked speech is then obtained by\nframe-by-frame bit inverse switching. Subsequently, the detection process is\ncarried out by a power spectrum comparison. We conducted objective evaluations\nwith reference to the VoicePrivacy 2020 Challenge (VP2020) and of the speech\nwatermarking with reference to the Information Hiding Challenge (IHC) and found\nthat our method could satisfy the blind detection, inaudibility, and robustness\nrequirements in watermarking. It also significantly improved the anonymization\nperformance in comparison to the secondary baseline system in VP2020.",
    "descriptor": "",
    "authors": [
      "Candy Olivia Mawalim",
      "Masashi Unoki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.07223"
  },
  {
    "id": "arXiv:2107.07224",
    "title": "StyleVideoGAN: A Temporal Generative Model using a Pretrained StyleGAN",
    "abstract": "Generative adversarial models (GANs) continue to produce advances in terms of\nthe visual quality of still images, as well as the learning of temporal\ncorrelations. However, few works manage to combine these two interesting\ncapabilities for the synthesis of video content: Most methods require an\nextensive training dataset in order to learn temporal correlations, while being\nrather limited in the resolution and visual quality of their output frames. In\nthis paper, we present a novel approach to the video synthesis problem that\nhelps to greatly improve visual quality and drastically reduce the amount of\ntraining data and resources necessary for generating video content. Our\nformulation separates the spatial domain, in which individual frames are\nsynthesized, from the temporal domain, in which motion is generated. For the\nspatial domain we make use of a pre-trained StyleGAN network, the latent space\nof which allows control over the appearance of the objects it was trained for.\nThe expressive power of this model allows us to embed our training videos in\nthe StyleGAN latent space. Our temporal architecture is then trained not on\nsequences of RGB frames, but on sequences of StyleGAN latent codes. The\nadvantageous properties of the StyleGAN space simplify the discovery of\ntemporal correlations. We demonstrate that it suffices to train our temporal\narchitecture on only 10 minutes of footage of 1 subject for about 6 hours.\nAfter training, our model can not only generate new portrait videos for the\ntraining subject, but also for any random subject which can be embedded in the\nStyleGAN space.",
    "descriptor": "",
    "authors": [
      "Gereon Fox",
      "Ayush Tewari",
      "Mohamed Elgharib",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07224"
  },
  {
    "id": "arXiv:2107.07225",
    "title": "COAST: COntrollable Arbitrary-Sampling NeTwork for Compressive Sensing",
    "abstract": "Recent deep network-based compressive sensing (CS) methods have achieved\ngreat success. However, most of them regard different sampling matrices as\ndifferent independent tasks and need to train a specific model for each target\nsampling matrix. Such practices give rise to inefficiency in computing and\nsuffer from poor generalization ability. In this paper, we propose a novel\nCOntrollable Arbitrary-Sampling neTwork, dubbed COAST, to solve CS problems of\narbitrary-sampling matrices (including unseen sampling matrices) with one\nsingle model. Under the optimization-inspired deep unfolding framework, our\nCOAST exhibits good interpretability. In COAST, a random projection\naugmentation (RPA) strategy is proposed to promote the training diversity in\nthe sampling space to enable arbitrary sampling, and a controllable proximal\nmapping module (CPMM) and a plug-and-play deblocking (PnP-D) strategy are\nfurther developed to dynamically modulate the network features and effectively\neliminate the blocking artifacts, respectively. Extensive experiments on widely\nused benchmark datasets demonstrate that our proposed COAST is not only able to\nhandle arbitrary sampling matrices with one single model but also to achieve\nstate-of-the-art performance with fast speed. The source code is available on\nhttps://github.com/jianzhangcs/COAST.",
    "descriptor": "\nComments: Published in IEEE Transactions on Image Processing, 2021\n",
    "authors": [
      "Di You",
      "Jian Zhang",
      "Jingfen Xie",
      "Bin Chen",
      "Siwei Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.07225"
  },
  {
    "id": "arXiv:2107.07228",
    "title": "Tableaux for Free Logics with Descriptions",
    "abstract": "The paper provides a tableau approach to definite descriptions. We focus on\nseveral formalizations of the so-called minimal free description theory (MFD)\nusually formulated axiomatically in the setting of free logic. We consider five\nanalytic tableau systems corresponding to different kinds of free logic,\nincluding the logic of definedness applied in computer science and constructive\nmathematics for dealing with partial functions (here called negative quasi-free\nlogic). The tableau systems formalise MFD based on PFL (positive free logic),\nNFL (negative free logic), PQFL and NQFL (the quasi-free counterparts of the\nformer ones). Also the logic NQFLm is taken into account, which is equivalent\nto NQFL, but whose language does not comprise the existence predicate. It is\nshown that all tableaux are sound and complete with respect to the semantics of\nthese logics.",
    "descriptor": "\nComments: This is a full version of a conference paper that will appear in the proceedings of the 30th International Conference on Automated Reasoning with Analytic Tableaux and Related Methods (TABLEAUX)\n",
    "authors": [
      "Andrzej Indrzejczak",
      "Micha\u0142 Zawidzki"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.07228"
  },
  {
    "id": "arXiv:2107.07229",
    "title": "Trusting RoBERTa over BERT: Insights from CheckListing the Natural  Language Inference Task",
    "abstract": "The recent state-of-the-art natural language understanding (NLU) systems\noften behave unpredictably, failing on simpler reasoning examples. Despite\nthis, there has been limited focus on quantifying progress towards systems with\nmore predictable behavior. We think that reasoning capability-wise behavioral\nsummary is a step towards bridging this gap. We create a CheckList test-suite\n(184K examples) for the Natural Language Inference (NLI) task, a representative\nNLU task. We benchmark state-of-the-art NLI systems on this test-suite, which\nreveals fine-grained insights into the reasoning abilities of BERT and RoBERTa.\nOur analysis further reveals inconsistencies of the models on examples derived\nfrom the same template or distinct templates but pertaining to same reasoning\ncapability, indicating that generalizing the models' behavior through\nobservations made on a CheckList is non-trivial. Through an user-study, we find\nthat users were able to utilize behavioral information to generalize much\nbetter for examples predicted from RoBERTa, compared to that of BERT.",
    "descriptor": "\nComments: 15 pages, 5 figures and 9 tables\n",
    "authors": [
      "Ishan Tarunesh",
      "Somak Aditya",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07229"
  },
  {
    "id": "arXiv:2107.07232",
    "title": "On the expressivity of bi-Lipschitz normalizing flows",
    "abstract": "An invertible function is bi-Lipschitz if both the function and its inverse\nhave bounded Lipschitz constants. Nowadays, most Normalizing Flows are\nbi-Lipschitz by design or by training to limit numerical errors (among other\nthings). In this paper, we discuss the expressivity of bi-Lipschitz Normalizing\nFlows and identify several target distributions that are difficult to\napproximate using such models. Then, we characterize the expressivity of\nbi-Lipschitz Normalizing Flows by giving several lower bounds on the Total\nVariation distance between these particularly unfavorable distributions and\ntheir best possible approximation. Finally, we discuss potential remedies which\ninclude using more complex latent distributions.",
    "descriptor": "",
    "authors": [
      "Alexandre Verine",
      "Benjamin Negrevergne",
      "Fabrice Rossi",
      "Yann Chevaleyre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07232"
  },
  {
    "id": "arXiv:2107.07233",
    "title": "Genetic CFL: Optimization of Hyper-Parameters in Clustered Federated  Learning",
    "abstract": "Federated learning (FL) is a distributed model for deep learning that\nintegrates client-server architecture, edge computing, and real-time\nintelligence. FL has the capability of revolutionizing machine learning (ML)\nbut lacks in the practicality of implementation due to technological\nlimitations, communication overhead, non-IID (independent and identically\ndistributed) data, and privacy concerns. Training a ML model over heterogeneous\nnon-IID data highly degrades the convergence rate and performance. The existing\ntraditional and clustered FL algorithms exhibit two main limitations, including\ninefficient client training and static hyper-parameter utilization. To overcome\nthese limitations, we propose a novel hybrid algorithm, namely genetic\nclustered FL (Genetic CFL), that clusters edge devices based on the training\nhyper-parameters and genetically modifies the parameters cluster-wise. Then, we\nintroduce an algorithm that drastically increases the individual cluster\naccuracy by integrating the density-based clustering and genetic\nhyper-parameter optimization. The results are bench-marked using MNIST\nhandwritten digit dataset and the CIFAR-10 dataset. The proposed genetic CFL\nshows significant improvements and works well with realistic cases of non-IID\nand ambiguous data.",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables\n",
    "authors": [
      "Shaashwat Agrawal",
      "Sagnik Sarkar",
      "Mamoun Alazab",
      "Praveen Kumar Reddy Maddikunta",
      "Thippa Reddy Gadekallu",
      "Quoc-Viet Pham"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07233"
  },
  {
    "id": "arXiv:2107.07235",
    "title": "Deep Automatic Natural Image Matting",
    "abstract": "Automatic image matting (AIM) refers to estimating the soft foreground from\nan arbitrary natural image without any auxiliary input like trimap, which is\nuseful for image editing. Prior methods try to learn semantic features to aid\nthe matting process while being limited to images with salient opaque\nforegrounds such as humans and animals. In this paper, we investigate the\ndifficulties when extending them to natural images with salient\ntransparent/meticulous foregrounds or non-salient foregrounds. To address the\nproblem, a novel end-to-end matting network is proposed, which can predict a\ngeneralized trimap for any image of the above types as a unified semantic\nrepresentation. Simultaneously, the learned semantic features guide the matting\nnetwork to focus on the transition areas via an attention mechanism. We also\nconstruct a test set AIM-500 that contains 500 diverse natural images covering\nall types along with manually labeled alpha mattes, making it feasible to\nbenchmark the generalization ability of AIM models. Results of the experiments\ndemonstrate that our network trained on available composite matting datasets\noutperforms existing methods both objectively and subjectively. The source code\nand dataset are available at https://github.com/JizhiziLi/AIM.",
    "descriptor": "\nComments: Accepted to IJCAI-21, code and dataset available at this https URL\n",
    "authors": [
      "Jizhizi Li",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07235"
  },
  {
    "id": "arXiv:2107.07240",
    "title": "Subnet Replacement: Deployment-stage backdoor attack against deep neural  networks in gray-box setting",
    "abstract": "We study the realistic potential of conducting backdoor attack against deep\nneural networks (DNNs) during deployment stage. Specifically, our goal is to\ndesign a deployment-stage backdoor attack algorithm that is both threatening\nand realistically implementable. To this end, we propose Subnet Replacement\nAttack (SRA), which is capable of embedding backdoor into DNNs by directly\nmodifying a limited number of model parameters. Considering the realistic\npracticability, we abandon the strong white-box assumption widely adopted in\nexisting studies, instead, our algorithm works in a gray-box setting, where\narchitecture information of the victim model is available but the adversaries\ndo not have any knowledge of parameter values. The key philosophy underlying\nour approach is -- given any neural network instance (regardless of its\nspecific parameter values) of a certain architecture, we can always embed a\nbackdoor into that model instance, by replacing a very narrow subnet of a\nbenign model (without backdoor) with a malicious backdoor subnet, which is\ndesigned to be sensitive (fire large activation value) to a particular backdoor\ntrigger pattern.",
    "descriptor": "\nComments: 6 pages, 3 figures, ICLR 2021 Workshop on Security and Safety in Machine Learning System\n",
    "authors": [
      "Xiangyu Qi",
      "Jifeng Zhu",
      "Chulin Xie",
      "Yong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07240"
  },
  {
    "id": "arXiv:2107.07243",
    "title": "VILENS: Visual, Inertial, Lidar, and Leg Odometry for All-Terrain Legged  Robots",
    "abstract": "We present VILENS (Visual Inertial Lidar Legged Navigation System), an\nodometry system for legged robots based on factor graphs. The key novelty is\nthe tight fusion of four different sensor modalities to achieve reliable\noperation when the individual sensors would otherwise produce degenerate\nestimation. To minimize leg odometry drift, we extend the robot's state with a\nlinear velocity bias term which is estimated online. This bias is only\nobservable because of the tight fusion of this preintegrated velocity factor\nwith vision, lidar, and IMU factors. Extensive experimental validation on the\nANYmal quadruped robots is presented, for a total duration of 2 h and 1.8 km\ntraveled. The experiments involved dynamic locomotion over loose rocks, slopes,\nand mud; these included perceptual challenges, such as dark and dusty\nunderground caverns or open, feature-deprived areas, as well as mobility\nchallenges such as slipping and terrain deformation. We show an average\nimprovement of 62% translational and 51% rotational errors compared to a\nstate-of-the-art loosely coupled approach. To demonstrate its robustness,\nVILENS was also integrated with a perceptive controller and a local path\nplanner.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "David Wisth",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07243"
  },
  {
    "id": "arXiv:2107.07249",
    "title": "Empowered and Embedded: Ethics and Agile Processes",
    "abstract": "In this article we focus on the structural aspects of the development of\nethical software, and argue that ethical considerations need to be embedded\ninto the (agile) software development process. In fact, we claim that agile\nprocesses of software development lend themselves specifically well for this\nendeavour. First, we contend that ethical evaluations need to go beyond the use\nof software products and include an evaluation of the software itself. This\nimplies that software engineers influence peoples' lives through the features\nof their designed products. Embedded values are thus approached best by\nsoftware engineers themselves. Therefore, we put emphasis on the possibility to\nimplement ethical deliberations in already existing and well established agile\nsoftware development processes. Our approach relies on software engineers\nmaking their own judgments throughout the entire development process to ensure\nthat technical features and ethical evaluation can be addressed adequately to\ntransport and foster desirable values and norms. We argue that agile software\ndevelopment processes may help the implementation of ethical deliberation for\nfive reasons: 1) agile methods are widely spread, 2) their emphasis on flat\nhierarchies promotes independent thinking, 3) their reliance on existing team\nstructures serve as an incubator for deliberation, 4) agile development\nenhances object-focused techno-ethical realism, and, finally, 5) agile\nstructures provide a salient endpoint to deliberation.",
    "descriptor": "",
    "authors": [
      "Niina Zuber",
      "Severin Kacianka",
      "Jan Gogoll",
      "Alexander Pretschner",
      "Julian Nida-R\u00fcmelin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07249"
  },
  {
    "id": "arXiv:2107.07250",
    "title": "A Low-Complexity Radar Detector Outperforming OS-CFAR for Indoor Drone  Obstacle Avoidance",
    "abstract": "As radar sensors are being miniaturized, there is a growing interest for\nusing them in indoor sensing applications such as indoor drone obstacle\navoidance. In those novel scenarios, radars must perform well in dense scenes\nwith a large number of neighboring scatterers. Central to radar performance is\nthe detection algorithm used to separate targets from the background noise and\nclutter. Traditionally, most radar systems use conventional CFAR detectors but\ntheir performance degrades in indoor scenarios with many reflectors. Inspired\nby the advances in non-linear target detection, we propose a novel\nhigh-performance, yet low-complexity target detector and we experimentally\nvalidate our algorithm on a dataset acquired using a radar mounted on a drone.\nWe experimentally show that our proposed algorithm drastically outperforms\nOS-CFAR (standard detector used in automotive systems) for our specific task of\nindoor drone navigation with more than 19% higher probability of detection for\na given probability of false alarm. We also benchmark our proposed detector\nagainst a number of recently proposed multi-target CFAR detectors and show an\nimprovement of 16% in probability of detection compared to CHA-CFAR, with even\nlarger improvements compared to both OR-CFAR and TS-LNCFAR in our particular\nindoor scenario. To the best of our knowledge, this work improves the state of\nthe art for high-performance yet low-complexity radar detection in critical\nindoor sensing applications.",
    "descriptor": "",
    "authors": [
      "Ali Safa",
      "Tim Verbelen",
      "Lars Keuninckx",
      "Ilja Ocket",
      "Matthias Hartmann",
      "Andr\u00e9 Bourdoux",
      "Franky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07250"
  },
  {
    "id": "arXiv:2107.07253",
    "title": "Spanish Language Models",
    "abstract": "This paper presents the Spanish RoBERTa-base and RoBERTa-large models, as\nwell as the corresponding performance evaluations. Both models were pre-trained\nusing the largest Spanish corpus known to date, with a total of 570GB of clean\nand deduplicated text processed for this work, compiled from the web crawlings\nperformed by the National Library of Spain from 2009 to 2019.",
    "descriptor": "",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "Jordi Armengol-Estap\u00e9",
      "Marc P\u00e0mies",
      "Joan Llop-Palao",
      "Joaqu\u00edn Silveira-Ocampo",
      "Casimiro Pio Carrino",
      "Aitor Gonzalez-Agirre",
      "Carme Armentano-Oller",
      "Carlos Rodriguez-Penagos",
      "Marta Villegas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07253"
  },
  {
    "id": "arXiv:2107.07254",
    "title": "Variable-Horizon Guidance for Autonomous Rendezvous and Docking to a  Tumbling Target",
    "abstract": "In this paper, the trajectory planning problem for autonomous rendezvous and\ndocking between a controlled spacecraft and a tumbling target is addressed. The\nuse of a variable planning horizon is proposed in order to construct an\nappropriate maneuver plan, within an optimization-based framework. The involved\noptimization problem is nonconvex and features nonlinear constraints. The main\ncontribution is to show that such problem can be tackled effectively by solving\na finite number of linear programs. To this aim, a specifically conceived\nhorizon search algorithm is employed in combination with a polytopic constraint\napproximation technique. The resulting guidance scheme provides the ability to\nidentify favourable docking configurations, by exploiting the time-varying\nnature of the optimization problem endpoint. Simulation results involving the\ncapture of the nonoperational EnviSat spacecraft indicate that the method is\nable to generate optimal trajectories at a fraction of the computational cost\nincurred by a state-of-the-art nonlinear solver.",
    "descriptor": "",
    "authors": [
      "Mirko Leomanni",
      "Renato Quartullo",
      "Gianni Bianchini",
      "Andrea Garulli",
      "Antonio Giannitrapani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07254"
  },
  {
    "id": "arXiv:2107.07255",
    "title": "PHiLIP on the HiL: Automated Multi-platform OS Testing with External  Reference Devices",
    "abstract": "Developing an operating system (OS) for low-end embedded devices requires\ncontinuous adaptation to new hardware architectures and components, while\nserviceability of features needs to be assured for each individual platform\nunder tight resource constraints. It is challenging to design a versatile and\naccurate heterogeneous test environment that is agile enough to cover a\ncontinuous evolution of the code base and platforms. This mission is even\nmorehallenging when organized in an agile open-source community process with\nmany contributors such as for the RIOT OS. Hardware in the Loop (HiL) testing\nand Continuous Integration (CI) are automatable approaches to verify\nfunctionality, prevent regressions, and improve the overall quality at\ndevelopment speed in large community projects. In this paper, we present PHiLIP\n(Primitive Hardware in the Loop Integration Product), an open-source external\nreference device together with tools that validate the system software while it\ncontrols hardware and interprets physical signals. Instead of focusing on a\nspecific test setting, PHiLIP takes the approach of a tool-assisted agile HiL\ntest process, designed for continuous evolution and deployment cycles. We\nexplain its design, describe how it supports HiL tests, evaluate performance\nmetrics, and report on practical experiences of employing PHiLIP in an\nautomated CI test infrastructure. Our initial deployment comprises 22 unique\nplatforms, each of which executes 98 peripheral tests every night. PHiLIP\nallows for easy extension of low-cost, adaptive testing infrastructures but\nserves testing techniques and tools to a much wider range of applications.",
    "descriptor": "",
    "authors": [
      "Kevin Weiss",
      "Michel Rottleuthner",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Operating Systems (cs.OS)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07255"
  },
  {
    "id": "arXiv:2107.07259",
    "title": "Single-image Full-body Human Relighting",
    "abstract": "We present a single-image data-driven method to automatically relight images\nwith full-body humans in them. Our framework is based on a realistic scene\ndecomposition leveraging precomputed radiance transfer (PRT) and spherical\nharmonics (SH) lighting. In contrast to previous work, we lift the assumptions\non Lambertian materials and explicitly model diffuse and specular reflectance\nin our data. Moreover, we introduce an additional light-dependent residual term\nthat accounts for errors in the PRT-based image reconstruction. We propose a\nnew deep learning architecture, tailored to the decomposition performed in PRT,\nthat is trained using a combination of L1, logarithmic, and rendering losses.\nOur model outperforms the state of the art for full-body human relighting both\nwith synthetic images and photographs.",
    "descriptor": "\nComments: 11 pages, 12 figures\n",
    "authors": [
      "Manuel Lagunas",
      "Xin Sun",
      "Jimei Yang",
      "Ruben Villegas",
      "Jianming Zhang",
      "Zhixin Shu",
      "Belen Masia",
      "Diego Gutierrez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.07259"
  },
  {
    "id": "arXiv:2107.07260",
    "title": "MCL-GAN: Generative Adversarial Networks with Multiple Specialized  Discriminators",
    "abstract": "We propose a generative adversarial network with multiple discriminators,\nwhere each discriminator is specialized to distinguish the subset of a real\ndataset. This approach facilitates learning a generator coinciding with the\nunderlying data distribution and thus mitigates the chronic mode collapse\nproblem. From the inspiration of multiple choice learning, we guide each\ndiscriminator to have expertise in the subset of the entire data and allow the\ngenerator to find reasonable correspondences between the latent and real data\nspaces automatically without supervision for training examples and the number\nof discriminators. Despite the use of multiple discriminators, the backbone\nnetworks are shared across the discriminators and the increase of training cost\nis minimized. We demonstrate the effectiveness of our algorithm in the standard\ndatasets using multiple evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Jinyoung Choi",
      "Bohyung Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07260"
  },
  {
    "id": "arXiv:2107.07261",
    "title": "Turning Tables: Generating Examples from Semi-structured Tables for  Endowing Language Models with Reasoning Skills",
    "abstract": "Models pre-trained with a language modeling objective possess ample world\nknowledge and language skills, but are known to struggle in tasks that require\nreasoning. In this work, we propose to leverage semi-structured tables, and\nautomatically generate at scale question-paragraph pairs, where answering the\nquestion requires reasoning over multiple facts in the paragraph. We add a\npre-training step over this synthetic data, which includes examples that\nrequire 16 different reasoning skills such as number comparison, conjunction,\nand fact composition. To improve data efficiency, we propose sampling\nstrategies that focus training on reasoning skills the model is currently\nlacking. We evaluate our approach on three reading comprehension datasets that\nare focused on reasoning, and show that our model, PReasM, substantially\noutperforms T5, a popular pre-trained encoder-decoder model. Moreover, sampling\nexamples based on current model errors leads to faster training and higher\noverall performance.",
    "descriptor": "",
    "authors": [
      "Ori Yoran",
      "Alon Talmor",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07261"
  },
  {
    "id": "arXiv:2107.07263",
    "title": "Increasing Transmission Distance in THz systems with MDPC Code and  Auxiliary Channel",
    "abstract": "We analyze whether multidimensional parity check (MDPC) code and an auxiliary\nchannel can improve the throughput and extend the THz transmission distance.\nWhile channel quality is addressed by various coding approaches, and an\neffective THz transmission system configuration is enabled by other approaches\nwith additional channels, their combination is new with the potential for\nsignificant improvements in quality of the data transmission. Our specific\nsolution is designed to correct data bits at the physical layer by a low\ncomplexity erasure code (MDPC), whereby original data and parity data are\nsimultaneously transferred over two parallel THz channels, including one main\nchannel and one additional channel. The results are theoretically analyzed to\nsee that our new solution can improve throughput, support higher modulation\nlevels and transfer data over the longer distances with THz communications.",
    "descriptor": "\nComments: This paper is uploaded here for research community, thus it is for non-commercial purposes\n",
    "authors": [
      "Cao Vien Phung",
      "Christoph Herold",
      "David Humphreys",
      "Thomas Kurner",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.07263"
  },
  {
    "id": "arXiv:2107.07264",
    "title": "Automatic Resource Allocation in Business Processes: A Systematic  Literature Survey",
    "abstract": "For delivering products or services to their clients, organizations execute\nmanifold business processes. During such execution, upcoming process tasks need\nto be allocated to internal resources. Resource allocation is a complex\ndecision-making problem with high impact on the effectiveness and efficiency of\nprocesses. A wide range of approaches was developed to support research\nallocation automatically. This systematic literature survey provides an\noverview of approaches and categorizes them regarding their resource allocation\ngoals and capabilities, their use of models and data, their algorithmic\nsolutions, and their maturity. Rule-based approaches were identified as\ndominant, but heuristics and learning approaches also play a relevant role.",
    "descriptor": "",
    "authors": [
      "Luise Pufahl",
      "Sven Ihde",
      "Fabian Stiehle",
      "Mathias Weske",
      "Ingo Weber"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07264"
  },
  {
    "id": "arXiv:2107.07266",
    "title": "Neural Architecture Search using Covariance Matrix Adaptation Evolution  Strategy",
    "abstract": "Evolution-based neural architecture search requires high computational\nresources, resulting in long search time. In this work, we propose a framework\nof applying the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to the\nneural architecture search problem called CMANAS, which achieves better results\nthan previous evolution-based methods while reducing the search time\nsignificantly. The architectures are modelled using a normal distribution,\nwhich is updated using CMA-ES based on the fitness of the sampled population.\nWe used the accuracy of a trained one shot model (OSM) on the validation data\nas a prediction of the fitness of an individual architecture to reduce the\nsearch time. We also used an architecture-fitness table (AF table) for keeping\nrecord of the already evaluated architecture, thus further reducing the search\ntime. CMANAS finished the architecture search on CIFAR-10 with the top-1 test\naccuracy of 97.44% in 0.45 GPU day and on CIFAR-100 with the top-1 test\naccuracy of 83.24% for 0.6 GPU day on a single GPU. The top architectures from\nthe searches on CIFAR-10 and CIFAR-100 were then transferred to ImageNet,\nachieving the top-5 accuracy of 92.6% and 92.1%, respectively.",
    "descriptor": "\nComments: Under review (Submitted to IEEE Transactions on Evolutionary Computation)\n",
    "authors": [
      "Nilotpal Sinha",
      "Kuan-Wen Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.07266"
  },
  {
    "id": "arXiv:2107.07268",
    "title": "Cross-modal Variational Auto-encoder for Content-based Micro-video  Background Music Recommendation",
    "abstract": "In this paper, we propose a cross-modal variational auto-encoder (CMVAE) for\ncontent-based micro-video background music recommendation. CMVAE is a\nhierarchical Bayesian generative model that matches relevant background music\nto a micro-video by projecting these two multimodal inputs into a shared\nlow-dimensional latent space, where the alignment of two corresponding\nembeddings of a matched video-music pair is achieved by cross-generation.\nMoreover, the multimodal information is fused by the product-of-experts (PoE)\nprinciple, where the semantic information in visual and textual modalities of\nthe micro-video are weighted according to their variance estimations such that\nthe modality with a lower noise level is given more weights. Therefore, the\nmicro-video latent variables contain less irrelevant information that results\nin a more robust model generalization. Furthermore, we establish a large-scale\ncontent-based micro-video background music recommendation dataset, TT-150k,\ncomposed of approximately 3,000 different background music clips associated to\n150,000 micro-videos from different users. Extensive experiments on the\nestablished TT-150k dataset demonstrate the effectiveness of the proposed\nmethod. A qualitative assessment of CMVAE by visualizing some recommendation\nresults is also included.",
    "descriptor": "",
    "authors": [
      "Jing Yi",
      "Yaochen Zhu",
      "Jiayi Xie",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.07268"
  },
  {
    "id": "arXiv:2107.07274",
    "title": "A Robust Deep Learning Workflow to Predict Multiphase Flow Behavior  during Geological CO2 Sequestration Injection and Post-Injection Periods",
    "abstract": "This paper contributes to the development and evaluation of a deep learning\nworkflow that accurately and efficiently predicts the temporal-spatial\nevolution of pressure and CO2 plumes during injection and post-injection\nperiods of geologic CO2 sequestration (GCS) operations. Based on a Fourier\nNeuron Operator, the deep learning workflow takes input variables or features\nincluding rock properties, well operational controls and time steps, and\npredicts the state variables of pressure and CO2 saturation. To further improve\nthe predictive fidelity, separate deep learning models are trained for CO2\ninjection and post-injection periods due the difference in primary driving\nforce of fluid flow and transport during these two phases. We also explore\ndifferent combinations of features to predict the state variables. We use a\nrealistic example of CO2 injection and storage in a 3D heterogeneous saline\naquifer, and apply the deep learning workflow that is trained from\nphysics-based simulation data and emulate the physics process. Through this\nnumerical experiment, we demonstrate that using two separate deep learning\nmodels to distinguish post-injection from injection period generates the most\naccurate prediction of pressure, and a single deep learning model of the whole\nGCS process including the cumulative injection volume of CO2 as a deep learning\nfeature, leads to the most accurate prediction of CO2 saturation. For the\npost-injection period, it is key to use cumulative CO2 injection volume to\ninform the deep learning models about the total carbon storage when predicting\neither pressure or saturation. The deep learning workflow not only provides\nhigh predictive fidelity across temporal and spatial scales, but also offers a\nspeedup of 250 times compared to full physics reservoir simulation, and thus\nwill be a significant predictive tool for engineers to manage the long term\nprocess of GCS.",
    "descriptor": "\nComments: 16 pages, 13 figures, 4 tables\n",
    "authors": [
      "Bicheng Yan",
      "Bailian Chen",
      "Dylan Robert Harp",
      "Rajesh J. Pawar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.07274"
  },
  {
    "id": "arXiv:2107.07277",
    "title": "Passivity-based Decentralized Control for Discrete-time Large-scale  Systems",
    "abstract": "Passivity theory has recently contributed to developing decentralized control\nschemes for large-scale systems. Many decentralized passivity-based control\nschemes are designed in continuous-time. It is well-known, however, that the\npassivity properties of continuous-time systems may be lost under\ndiscretization. In this work, we present a novel stabilizing decentralized\ncontrol scheme by ensuring passivity for discrete-time systems directly and\nthus avoiding the issue of passivity preservation. The controller is\nsynthesized by locally solving a semidefinite program offline for each\nsubsystem in a decentralized fashion. This program comprises local conditions\nensuring that the corresponding subsystem is locally passive. Passivity is\nensured with respect to a local virtual output which is different from the\nlocal actual output. The program also comprises local conditions ensuring that\nthe local passivity of all subsystems implies the asymptotic stability of the\nwhole system. The performance of the proposed controller is evaluated on a case\nstudy in DC microgrids.",
    "descriptor": "",
    "authors": [
      "Ahmed Aboudonia",
      "Andrea Martinelli",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07277"
  },
  {
    "id": "arXiv:2107.07281",
    "title": "Input Dependent Sparse Gaussian Processes",
    "abstract": "Gaussian Processes (GPs) are Bayesian models that provide uncertainty\nestimates associated to the predictions made. They are also very flexible due\nto their non-parametric nature. Nevertheless, GPs suffer from poor scalability\nas the number of training instances N increases. More precisely, they have a\ncubic cost with respect to $N$. To overcome this problem, sparse GP\napproximations are often used, where a set of $M \\ll N$ inducing points is\nintroduced during training. The location of the inducing points is learned by\nconsidering them as parameters of an approximate posterior distribution $q$.\nSparse GPs, combined with variational inference for inferring $q$, reduce the\ntraining cost of GPs to $\\mathcal{O}(M^3)$. Critically, the inducing points\ndetermine the flexibility of the model and they are often located in regions of\nthe input space where the latent function changes. A limitation is, however,\nthat for some learning tasks a large number of inducing points may be required\nto obtain a good prediction performance. To address this limitation, we propose\nhere to amortize the computation of the inducing points locations, as well as\nthe parameters of the variational posterior approximation q. For this, we use a\nneural network that receives the observed data as an input and outputs the\ninducing points locations and the parameters of $q$. We evaluate our method in\nseveral experiments, showing that it performs similar or better than other\nstate-of-the-art sparse variational GP approaches. However, with our method the\nnumber of inducing points is reduced drastically due to their dependency on the\ninput data. This makes our method scale to larger datasets and have faster\ntraining and prediction times.",
    "descriptor": "",
    "authors": [
      "Bahram Jafrasteh",
      "Carlos Villacampa-Calvo",
      "Daniel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07281"
  },
  {
    "id": "arXiv:2107.07282",
    "title": "On the stability of robust dynamical low-rank approximations for  hyperbolic problems",
    "abstract": "The dynamical low-rank approximation (DLRA) is used to treat high-dimensional\nproblems that arise in such diverse fields as kinetic transport and uncertainty\nquantification. Even though it is well known that certain spatial and temporal\ndiscretizations when combined with the DLRA approach can result in numerical\ninstability, this phenomenon is poorly understood. In this paper we perform a\n$L^2$ stability analysis for the corresponding nonlinear equations of motion.\nThis reveals the source of the instability for the projector splitting\nintegrator when first discretizing the equations and then applying the DLRA.\nBased on this we propose a projector splitting integrator, based on applying\nDLRA to the continuous system before performing the discretization, that\nrecovers the classic CFL condition. We also show that the unconventional\nintegrator has more favorable stability properties and explain why the\nprojector splitting integrator performs better when approximating higher\nmoments, while the unconventional integrator is generally superior for first\norder moments. Furthermore, an efficient and stable dynamical low-rank update\nfor the scattering term in kinetic transport is proposed. Numerical experiments\nfor kinetic transport and uncertainty quantification, which confirm the results\nof the stability analysis, are presented.",
    "descriptor": "",
    "authors": [
      "Jonas Kusch",
      "Lukas Einkemmer",
      "Gianluca Ceruti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.07282"
  },
  {
    "id": "arXiv:2107.07284",
    "title": "Auto-detecting groups based on textual similarity for group  recommendations",
    "abstract": "In general, recommender systems are designed to provide personalized items to\na user. But in few cases, items are recommended for a group, and the challenge\nis to aggregate the individual user preferences to infer the recommendation to\na group. It is also important to consider the similarity of characteristics\namong the members of a group to generate a better recommendation. Members of an\nautomatically identified group will have similar characteristics, and reaching\na consensus with a decision-making process is preferable in this case. It\nrequires users-items and their rating interactions over a utility matrix to\nauto-detect the groups in group recommendations. We may not overlook other\nintrinsic information to form a group. The textual information also plays a\npivotal role in user clustering. In this paper, we auto-detect the groups based\non the textual similarity of the metadata (review texts). We consider the order\nin user preferences in our models. We have conducted extensive experiments over\ntwo real-world datasets to check the efficacy of the proposed models. We have\nalso conducted a competitive comparison with a baseline model to show the\nimprovements in the quality of recommendations.",
    "descriptor": "",
    "authors": [
      "Chintoo Kumar",
      "C. Ravindranath Chowdary"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.07284"
  },
  {
    "id": "arXiv:2107.07296",
    "title": "The Art of the Meta Stream Protocol: Torrents of Streams",
    "abstract": "The rise of streaming libraries such as Akka Stream, Reactive Extensions, and\nLINQ popularized the declarative functional style of data processing. The\nstream paradigm offers concise syntax to write down processing pipelines to\nconsume the vast amounts of real-time data available today. These libraries\noffer the programmer a domain specific language (DSL) embedded in the host\nlanguage to describe data streams. These libraries however, all suffer from\nextensibility issues. The semantics of a stream is hard-coded into the DSL\nlanguage and cannot be changed by the user of the library. We introduce an\napproach to modify the semantics of a streaming library by means of\nmeta-programming at both run-time and compile-time, and showcase its\ngenerality. We show that the expressiveness of the meta-facilities is strong\nenough to enable push and pull semantics, error handling, parallelism, and\noperator fusion. We evaluate our work by implementing the identified\nshortcomings in terms of a novel stream meta-architecture and show that its\ndesign and architecture adhere to the design principles of a meta-level\narchitecture. The state of the art offers plenty of choice to programmers\nregarding reactive stream processing libraries. Expressing reactive systems is\notherwise difficult to do in general purpose languages. Extensibility and\nfine-tuning should be possible in these libraries to ensure a broad variety of\napplications can be expressed within this single DSL.",
    "descriptor": "",
    "authors": [
      "Christophe De Troyer",
      "Jens Nicolay",
      "Wolfgang De Meuter"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.07296"
  },
  {
    "id": "arXiv:2107.07297",
    "title": "Shard Scheduler: object placement and migration in sharded account-based  blockchains",
    "abstract": "We propose Shard Scheduler, a system for object placement and migration in\naccount-based sharded blockchains. Our system calculates optimal placement and\ndecides of object migrations across shards and supports complex multi-account\ntransactions caused by smart contracts. Placement and migration decisions made\nby Shard Scheduler are fully deterministic, verifiable, and can be made part of\nthe consensus protocol. Shard Scheduler reduces the number of costly\ncross-shard transactions, ensures balanced load distribution and maximizes the\nnumber of processed transactions for the blockchain as a whole. It leverages a\nnovel incentive model motivating miners to maximize the global throughput of\nthe entire blockchain rather than the throughput of a specific shard. Shard\nScheduler reduces the number of costly cross-shard transactions by half in our\nsimulations, ensuring equal load and increasing the throughput 3 fold when\nusing 60 shards. We also implement and evaluate Shard Scheduler on Chainspace,\nmore than doubling its throughput and reducing user-perceived latency by 70%\nwhen using 10 shards.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Kr\u00f3l",
      "Onur Ascigil",
      "Sergi Rene",
      "Alberto Sonnino",
      "Mustafa Al-Bassam",
      "Etienne Rivi\u00e8re"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07297"
  },
  {
    "id": "arXiv:2107.07298",
    "title": "An Optimised Flow for Futures: From Theory to Practice",
    "abstract": "A future is an entity representing the result of an ongoing computation. A\nsynchronisation with a \"get\" operation blocks the caller until the computation\nis over, to return the corresponding value. When a computation in charge of\nfulfilling a future delegates part of its processing to another task,\nmainstream languages return nested futures, and several \"get\" operations are\nneeded to retrieve the computed value (we call such futures \"control-flow\nfutures\"). Several approaches were proposed to tackle this issues: the\n\"forward\" construct, that allows the programmer to make delegation explicit and\navoid nested futures, and \"data-flow explicit futures\" which natively collapse\nnested futures into plain futures. This paper supports the claim that data-flow\nexplicit futures form a powerful set of language primitives, on top of which\nother approaches can be built. We prove the equivalence, in the context of\ndata-flow explicit futures, between the \"forward\" construct and classical\n\"return\" from functions. The proof relies on a branching bisimulation between a\nprogram using \"forward\" and its \"return\" counterpart. This result allows\nlanguage designers to consider \"forward\" as an optimisation directive rather\nthan as a language primitive. Following the principles of the Godot system, we\nprovide a library implementation of control-flow futures, based on data-flow\nexplicit futures implemented in the compiler. This small library supports the\nclaim that the implementation of classical futures based on data-flow ones is\neasier than the opposite. Our benchmarks show the viability of the approach\nfrom a performance point of view.",
    "descriptor": "",
    "authors": [
      "Nicolas Chappe",
      "Ludovic Henrio",
      "Amaury Maill\u00e9",
      "Matthieu Moy",
      "Hadrien Renaud"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.07298"
  },
  {
    "id": "arXiv:2107.07300",
    "title": "Deriving Static Security Testing from Runtime Security Protection for  Web Applications",
    "abstract": "Context: Static Application Security Testing (SAST) and Runtime Application\nSecurity Protection (RASP) are important and complementary techniques used for\ndetecting and enforcing application-level security policies in web\napplications.\nInquiry: The current state of the art, however, does not allow a safe and\nefficient combination of SAST and RASP based on a shared set of security\npolicies, forcing developers to reimplement and maintain the same policies and\ntheir enforcement code in both tools.\nApproach: In this work, we present a novel technique for deriving SAST from\nan existing RASP mechanism by using a two-phase abstract interpretation\napproach in the SAST component that avoids duplicating the effort of specifying\nsecurity policies and implementing their semantics. The RASP mechanism enforces\nsecurity policies by instrumenting a base program to trap security-relevant\noperations and execute the required policy enforcement code. The static\nanalysis of security policies is then obtained from the RASP mechanism by first\nstatically analyzing the base program without any traps. The results of this\nfirst phase are used in a second phase to detect trapped operations and\nabstractly execute the associated and unaltered RASP policy enforcement code.\nKnowledge: Splitting the analysis into two phases enables running each phase\nwith a specific analysis configuration, rendering the static analysis approach\ntractable while maintaining sufficient precision.\nGrounding: We validate the applicability of our two-phase analysis approach\nby using it to both dynamically enforce and statically detect a range of\nsecurity policies found in related work. Our experiments suggest that our\ntwo-phase analysis can enable faster and more precise policy violation\ndetection compared to analyzing the full instrumented application under a\nsingle analysis configuration.\nImportance: Deriving a SAST component from a RASP mechanism enables\nequivalent semantics for the security policies across the static and dynamic\ncontexts in which policies are verified during the software development\nlifecycle. Moreover, our two-phase abstract interpretation approach does not\nrequire RASP developers to reimplement the enforcement code for static\nanalysis.",
    "descriptor": "",
    "authors": [
      "Angel Luis Scull Pupo",
      "Jens Nicolay",
      "Elisa Gonzalez Boix"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.07300"
  },
  {
    "id": "arXiv:2107.07301",
    "title": "A Functional Programming Language with Versions",
    "abstract": "While modern software development heavily uses versioned packages,\nprogramming languages rarely support the concept of versions in their\nsemantics, which makes software updates more bulky and unsafe. This paper\nproposes a programming language that intrinsically supports versions. The main\ngoals are to design core language features to support multiple versions in one\nprogram and establish a proper notion of type safety with those features. The\nproposed core calculus, called Lambda VL, has versioned values, each containing\ndifferent values under different versions. We show the construction of the type\nsystem as an extension of coeffect calculus by mapping versions to\ncomputational resources. The type system guarantees the existence of a valid\ncombination of versions for a program. The calculus enables programming\nlanguages to use multiple versions of a package within a program. It will serve\nas a basis for designing advanced language features like module systems and\nsemantic versioning.",
    "descriptor": "",
    "authors": [
      "Yudai Tanabe",
      "Luthfan Anshar Lubis",
      "Tomoyuki Aotani",
      "Hidehiko Masuhara"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.07301"
  },
  {
    "id": "arXiv:2107.07304",
    "title": "Exploring Object Stores for High-Energy Physics Data Storage",
    "abstract": "Over the last two decades, ROOT TTree has been used for storing over one\nexabyte of High-Energy Physics (HEP) events. The TTree columnar on-disk layout\nhas been proved to be ideal for analyses of HEP data that typically require\naccess to many events, but only a subset of the information stored for each of\nthem. Future colliders, and particularly HL-LHC, will bring an increase of at\nleast one order of magnitude in the volume of generated data. Therefore, the\nuse of modern storage hardware, such as low-latency high-bandwidth NVMe devices\nand distributed object stores, becomes more important. However, TTree was not\ndesigned to optimally exploit modern hardware and may become a bottleneck for\ndata retrieval. The ROOT RNTuple I/O system aims at overcoming TTree's\nlimitations and at providing improved efficiency for modern storage systems. In\nthis paper, we extend RNTuple with a backend that uses Intel DAOS as the\nunderlying storage, demonstrating that the RNTuple architecture can accommodate\nhigh-performance object stores. From the user perspective, data can be accessed\nwith minimal changes to the code, that is by replacing a filesystem path by a\nDAOS URI. Our performance evaluation shows that the new backend can be used for\nrealistic analyses, while outperforming the compatibility solution provided by\nthe DAOS project.",
    "descriptor": "\nComments: Accepted for Proceedings of 25th International Conference on Computing in High-Energy and Nuclear Physics\n",
    "authors": [
      "Javier L\u00f3pez-G\u00f3mez",
      "Jakob Blomer"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2107.07304"
  },
  {
    "id": "arXiv:2107.07305",
    "title": "Training for temporal sparsity in deep neural networks, application in  video processing",
    "abstract": "Activation sparsity improves compute efficiency and resource utilization in\nsparsity-aware neural network accelerators. As the predominant operation in\nDNNs is multiply-accumulate (MAC) of activations with weights to compute inner\nproducts, skipping operations where (at least) one of the two operands is zero\ncan make inference more efficient in terms of latency and power. Spatial\nsparsification of activations is a popular topic in DNN literature and several\nmethods have already been established to bias a DNN for it. On the other hand,\ntemporal sparsity is an inherent feature of bio-inspired spiking neural\nnetworks (SNNs), which neuromorphic processing exploits for hardware\nefficiency. Introducing and exploiting spatio-temporal sparsity, is a topic\nmuch less explored in DNN literature, but in perfect resonance with the trend\nin DNN, to shift from static signal processing to more streaming signal\nprocessing. Towards this goal, in this paper we introduce a new DNN layer\n(called Delta Activation Layer), whose sole purpose is to promote temporal\nsparsity of activations during training. A Delta Activation Layer casts\ntemporal sparsity into spatial activation sparsity to be exploited when\nperforming sparse tensor multiplications in hardware. By employing delta\ninference and ``the usual'' spatial sparsification heuristics during training,\nthe resulting model learns to exploit not only spatial but also temporal\nactivation sparsity (for a given input data distribution). One may use the\nDelta Activation Layer either during vanilla training or during a refinement\nphase. We have implemented Delta Activation Layer as an extension of the\nstandard Tensoflow-Keras library, and applied it to train deep neural networks\non the Human Action Recognition (UCF101) dataset. We report an almost 3x\nimprovement of activation sparsity, with recoverable loss of model accuracy\nafter longer training.",
    "descriptor": "",
    "authors": [
      "Amirreza Yousefzadeh",
      "Manolis Sifalakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.07305"
  },
  {
    "id": "arXiv:2107.07314",
    "title": "Variational Topic Inference for Chest X-Ray Report Generation",
    "abstract": "Automating report generation for medical imaging promises to reduce workload\nand assist diagnosis in clinical practice. Recent work has shown that deep\nlearning models can successfully caption natural images. However, learning from\nmedical data is challenging due to the diversity and uncertainty inherent in\nthe reports written by different radiologists with discrepant expertise and\nexperience. To tackle these challenges, we propose variational topic inference\nfor automatic report generation. Specifically, we introduce a set of topics as\nlatent variables to guide sentence generation by aligning image and language\nmodalities in a latent space. The topics are inferred in a conditional\nvariational inference framework, with each topic governing the generation of a\nsentence in the report. Further, we adopt a visual attention module that\nenables the model to attend to different locations in the image and generate\nmore informative descriptions. We conduct extensive experiments on two\nbenchmarks, namely Indiana U. Chest X-rays and MIMIC-CXR. The results\ndemonstrate that our proposed variational topic inference method can generate\nnovel reports rather than mere copies of reports used in training, while still\nachieving comparable performance to state-of-the-art methods in terms of\nstandard language generation criteria.",
    "descriptor": "\nComments: To be published in the International Conference on Medical Image Computing and Computer Assisted Intervention 2021\n",
    "authors": [
      "Ivona Najdenkoska",
      "Xiantong Zhen",
      "Marcel Worring",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.07314"
  },
  {
    "id": "arXiv:2107.07316",
    "title": "Minimizing Safety Interference for Safe and Comfortable Automated  Driving with Distributional Reinforcement Learning",
    "abstract": "Despite recent advances in reinforcement learning (RL), its application in\nsafety critical domains like autonomous vehicles is still challenging. Although\npunishing RL agents for risky situations can help to learn safe policies, it\nmay also lead to highly conservative behavior. In this paper, we propose a\ndistributional RL framework in order to learn adaptive policies that can tune\ntheir level of conservativity at run-time based on the desired comfort and\nutility. Using a proactive safety verification approach, the proposed framework\ncan guarantee that actions generated from RL are fail-safe according to the\nworst-case assumptions. Concurrently, the policy is encouraged to minimize\nsafety interference and generate more comfortable behavior. We trained and\nevaluated the proposed approach and baseline policies using a high level\nsimulator with a variety of randomized scenarios including several corner cases\nwhich rarely happen in reality but are very crucial. In light of our\nexperiments, the behavior of policies learned using distributional RL can be\nadaptive at run-time and robust to the environment uncertainty. Quantitatively,\nthe learned distributional RL agent drives in average 8 seconds faster than the\nnormal DQN policy and requires 83\\% less safety interference compared to the\nrule-based policy with slightly increasing the average crossing time. We also\nstudy sensitivity of the learned policy in environments with higher perception\nnoise and show that our algorithm learns policies that can still drive reliable\nwhen the perception noise is two times higher than the training configuration\nfor automated merging and crossing at occluded intersections.",
    "descriptor": "",
    "authors": [
      "Danial Kamran",
      "Tizian Engelgeh",
      "Marvin Busch",
      "Johannes Fischer",
      "Christoph Stiller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07316"
  },
  {
    "id": "arXiv:2107.07330",
    "title": "DynaDog+T: A Parametric Animal Model for Synthetic Canine Image  Generation",
    "abstract": "Synthetic data is becoming increasingly common for training computer vision\nmodels for a variety of tasks. Notably, such data has been applied in tasks\nrelated to humans such as 3D pose estimation where data is either difficult to\ncreate or obtain in realistic settings. Comparatively, there has been less work\ninto synthetic animal data and it's uses for training models. Consequently, we\nintroduce a parametric canine model, DynaDog+T, for generating synthetic canine\nimages and data which we use for a common computer vision task, binary\nsegmentation, which would otherwise be difficult due to the lack of available\ndata.",
    "descriptor": "\nComments: CV4Animals Workshop in CVPR 2021\n",
    "authors": [
      "Jake Deane",
      "Sinead Kearney",
      "Kwang In Kim",
      "Darren Cosker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07330"
  },
  {
    "id": "arXiv:2107.07331",
    "title": "Modeling Accurate Human Activity Recognition for Embedded Devices Using  Multi-level Distillation",
    "abstract": "Human activity recognition (HAR) based on IMU sensors is an essential domain\nin ubiquitous computing. Because of the improving trend to deploy artificial\nintelligence into IoT devices or smartphones, more researchers design the HAR\nmodels for embedded devices. We propose a plug-and-play HAR modeling pipeline\nwith multi-level distillation to build deep convolutional HAR models with\nnative support of embedded devices. SMLDist consists of stage distillation,\nmemory distillation, and logits distillation, which covers all the information\nflow of the deep models. Stage distillation constrains the learning direction\nof the intermediate features. Memory distillation teaches the student models\nhow to explain and store the inner relationship between high-dimensional\nfeatures based on Hopfield networks. Logits distillation constructs distilled\nlogits by a smoothed conditional rule to keep the probable distribution and\nimprove the correctness of the soft target. We compare the performance of\naccuracy, F1 macro score, and energy cost on the embedded platform of various\nstate-of-the-art HAR frameworks with a MobileNet V3 model built by SMLDist. The\nproduced model has well balance with robustness, efficiency, and accuracy.\nSMLDist can also compress the models with minor performance loss in an equal\ncompression rate than other state-of-the-art knowledge distillation methods on\nseven public datasets.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Runze Chen",
      "Haiyong Luo",
      "Fang Zhao",
      "Xuechun Meng",
      "Zhiqing Xie",
      "Yida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07331"
  },
  {
    "id": "arXiv:2107.07332",
    "title": "Negative time splitting is stable",
    "abstract": "For high order (than two) in time operator-splitting methods applied to\ndissipative systems, a folklore issue is the appearance of\nnegative-time/backward-in-time linear evolution operators such as backward\nheat operators interwoven with nonlinear evolutions. The stability of such\nmethods has remained an ensuing difficult open problem. In this work we\nconsider a fourth order operator splitting discretization for the Allen-Cahn\nequation which is a prototypical high order splitting method with negative\ntime-stepping, i.e. backward in time integration for the linear parabolic part.\nWe introduce a new theoretical framework and prove uniform energy stability and\nhigher Sobolev stability. This is the first strong stability result for\nnegative time stepping operator-splitting methods.",
    "descriptor": "\nComments: 15 pages. arXiv admin note: text overlap with arXiv:2107.05349\n",
    "authors": [
      "Dong Li",
      "Chaoyu Quan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.07332"
  },
  {
    "id": "arXiv:2107.07333",
    "title": "Unsupervised Anomaly Instance Segmentation for Baggage Threat  Recognition",
    "abstract": "Identifying potential threats concealed within the baggage is of prime\nconcern for the security staff. Many researchers have developed frameworks that\ncan detect baggage threats from X-ray scans. However, to the best of our\nknowledge, all of these frameworks require extensive training on large-scale\nand well-annotated datasets, which are hard to procure in the real world. This\npaper presents a novel unsupervised anomaly instance segmentation framework\nthat recognizes baggage threats, in X-ray scans, as anomalies without requiring\nany ground truth labels. Furthermore, thanks to its stylization capacity, the\nframework is trained only once, and at the inference stage, it detects and\nextracts contraband items regardless of their scanner specifications. Our\none-staged approach initially learns to reconstruct normal baggage content via\nan encoder-decoder network utilizing a proposed stylization loss function. The\nmodel subsequently identifies the abnormal regions by analyzing the disparities\nwithin the original and the reconstructed scans. The anomalous regions are then\nclustered and post-processed to fit a bounding box for their localization. In\naddition, an optional classifier can also be appended with the proposed\nframework to recognize the categories of these extracted anomalies. A thorough\nevaluation of the proposed system on four public baggage X-ray datasets,\nwithout any re-training, demonstrates that it achieves competitive performance\nas compared to the conventional fully supervised methods (i.e., the mean\naverage precision score of 0.7941 on SIXray, 0.8591 on GDXray, 0.7483 on\nOPIXray, and 0.5439 on COMPASS-XP dataset) while outperforming state-of-the-art\nsemi-supervised and unsupervised baggage threat detection frameworks by 67.37%,\n32.32%, 47.19%, and 45.81% in terms of F1 score across SIXray, GDXray, OPIXray,\nand COMPASS-XP datasets, respectively.",
    "descriptor": "",
    "authors": [
      "Taimur Hassan",
      "Samet Akcay",
      "Mohammed Bennamoun",
      "Salman Khan",
      "Naoufel Werghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.07333"
  },
  {
    "id": "arXiv:2107.07334",
    "title": "Tournesol: A quest for a large, secure and trustworthy database of  reliable human judgments",
    "abstract": "Today's large-scale algorithms have become immensely influential, as they\nrecommend and moderate the content that billions of humans are exposed to on a\ndaily basis. They are the de-facto regulators of our societies' information\ndiet, from shaping opinions on public health to organizing groups for social\nmovements. This creates serious concerns, but also great opportunities to\npromote quality information. Addressing the concerns and seizing the\nopportunities is a challenging, enormous and fabulous endeavor, as intuitively\nappealing ideas often come with unwanted {\\it side effects}, and as it requires\nus to think about what we deeply prefer.\nUnderstanding how today's large-scale algorithms are built is critical to\ndetermine what interventions will be most effective. Given that these\nalgorithms rely heavily on {\\it machine learning}, we make the following key\nobservation: \\emph{any algorithm trained on uncontrolled data must not be\ntrusted}. Indeed, a malicious entity could take control over the data, poison\nit with dangerously manipulative fabricated inputs, and thereby make the\ntrained algorithm extremely unsafe. We thus argue that the first step towards\nsafe and ethical large-scale algorithms must be the collection of a large,\nsecure and trustworthy dataset of reliable human judgments.\nTo achieve this, we introduce \\emph{Tournesol}, an open source platform\navailable at \\url{https://tournesol.app}. Tournesol aims to collect a large\ndatabase of human judgments on what algorithms ought to widely recommend (and\nwhat they ought to stop widely recommending). We outline the structure of the\nTournesol database, the key features of the Tournesol platform and the main\nhurdles that must be overcome to make it a successful project. Most\nimportantly, we argue that, if successful, Tournesol may then serve as the\nessential foundation for any safe and ethical large-scale algorithm.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "L\u00ea-Nguy\u00ean Hoang",
      "Louis Faucon",
      "Aidan Jungo",
      "Sergei Volodin",
      "Dalia Papuc",
      "Orfeas Liossatos",
      "Ben Crulis",
      "Mariame Tighanimine",
      "Isabela Constantin",
      "Anastasiia Kucherenko",
      "Alexandre Maurer",
      "Felix Grimberg",
      "Vlad Nitu",
      "Chris Vossen",
      "S\u00e9bastien Rouault",
      "El-Mahdi El-Mhamdi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07334"
  },
  {
    "id": "arXiv:2107.07335",
    "title": "Towards Natural Brain-Machine Interaction using Endogenous Potentials  based on Deep Neural Networks",
    "abstract": "Human-robot collaboration has the potential to maximize the efficiency of the\noperation of autonomous robots. Brain-machine interface (BMI) would be a\ndesirable technology to collaborate with robots since the intention or state of\nusers can be translated from the neural activities. However, the\nelectroencephalogram (EEG), which is one of the most popularly used\nnon-invasive BMI modalities, has low accuracy and a limited degree of freedom\n(DoF) due to a low signal-to-noise ratio. Thus, improving the performance of\nmulti-class EEG classification is crucial to develop more flexible BMI-based\nhuman-robot collaboration. In this study, we investigated the possibility for\ninter-paradigm classification of multiple endogenous BMI paradigms, such as\nmotor imagery (MI), visual imagery (VI), and speech imagery (SI), to enhance\nthe limited DoF while maintaining robust accuracy. We conducted the statistical\nand neurophysiological analyses on MI, VI, and SI and classified three\nparadigms using the proposed temporal information-based neural network (TINN).\nWe confirmed that statistically significant features could be extracted on\ndifferent brain regions when classifying three endogenous paradigms. Moreover,\nour proposed TINN showed the highest accuracy of 0.93 compared to the previous\nmethods for classifying three different types of mental imagery tasks (MI, VI,\nand SI).",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Hyung-Ju Ahn",
      "Dae-Hyeok Lee",
      "Ji-Hoon Jeong",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07335"
  },
  {
    "id": "arXiv:2107.07336",
    "title": "Mixed reality technologies for people with dementia: Participatory  evaluation methods",
    "abstract": "Technologies can support people with early onset dementia (PwD) to aid them\nin Instrumental Activities of Daily Living (IADL). The integration of physical\nand virtual realities in Mixed reality technologies (MRTs) could provide\nscalable and deployable options in developing prompting systems for PwD.\nHowever, these emerging technologies should be evaluated and investigated for\nfeasibility with PwD. Survey instruments such as SUS, SUPR-Q and ethnographic\nmethods that are used for usability evaluation of websites and apps are used to\nevaluate and study MRTs. However, PwD who cannot provide written and verbal\nfeedback are unable to participate in these studies. MRTs also present\nchallenges due to different ways in which physical and virtual realities could\nbe coupled. Experiences with physical, virtual and the couplings between the\ntwo are to be considered in evaluating MRTs.",
    "descriptor": "",
    "authors": [
      "Shital Desai",
      "Arlene Astell"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07336"
  },
  {
    "id": "arXiv:2107.07338",
    "title": "An Overview of Machine Learning-aided Optical Performance Monitoring  Techniques",
    "abstract": "Future communication systems are faced with increased demand for high\ncapacity, dynamic bandwidth, reliability and heterogeneous traffic. To meet\nthese requirements, networks have become more complex and thus require new\ndesign methods and monitoring techniques, as they evolve towards becoming\nautonomous. Machine learning has come to the forefront in recent years as a\npromising technology to aid in this evolution. Optical fiber communications can\nalready provide the high capacity required for most applications, however,\nthere is a need for increased scalability and adaptability to changing user\ndemands and link conditions. Accurate performance monitoring is an integral\npart of this transformation. In this paper we review optical performance\nmonitoring techniques where machine learning algorithms have been applied.\nMoreover, since alot of OPM depends on knowledge of the signal type, we also\nreview work for modulation format recognition and bitrate identification. We\nadditionally briefly introduce a neuromorphic approach to OPM as an emerging\ntechnique that has only recently been applied to this domain.",
    "descriptor": "",
    "authors": [
      "Dativa K. Tizikara",
      "Jonathan Serugunda",
      "Andrew Katumba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.07338"
  },
  {
    "id": "arXiv:2107.07341",
    "title": "Leveraging wisdom of the crowds to improve consensus among radiologists  by real time, blinded collaborations on a digital swarm platform",
    "abstract": "Radiologists today play a key role in making diagnostic decisions and\nlabeling images for training A.I. algorithms. Low inter-reader reliability\n(IRR) can be seen between experts when interpreting challenging cases. While\nteams-based decisions are known to outperform individual decisions,\ninter-personal biases often creep up in group interactions which limit\nnon-dominant participants from expressing true opinions. To overcome the dual\nproblems of low consensus and inter-personal bias, we explored a solution\nmodeled on biological swarms of bees. Two separate cohorts; three radiologists\nand five radiology residents collaborated on a digital swarm platform in real\ntime and in a blinded fashion, grading meniscal lesions on knee MR exams. These\nconsensus votes were benchmarked against clinical (arthroscopy) and\nradiological (senior-most radiologist) observations. The IRR of the consensus\nvotes was compared to the IRR of the majority and most confident votes of the\ntwo cohorts.The radiologist cohort saw an improvement of 23% in IRR of swarm\nvotes over majority vote. Similar improvement of 23% in IRR in 3-resident swarm\nvotes over majority vote, was observed. The 5-resident swarm had an even higher\nimprovement of 32% in IRR over majority vote. Swarm consensus votes also\nimproved specificity by up to 50%. The swarm consensus votes outperformed\nindividual and majority vote decisions in both the radiologists and resident\ncohorts. The 5-resident swarm had higher IRR than 3-resident swarm indicating\npositive effect of increased swarm size. The attending and resident swarms also\noutperformed predictions from a state-of-the-art A.I. algorithm. Utilizing a\ndigital swarm platform improved agreement and allows participants to express\njudgement free intent, resulting in superior clinical performance and robust\nA.I. training labels.",
    "descriptor": "\nComments: 24 pages, 2 tables, 7 figures\n",
    "authors": [
      "Rutwik Shah",
      "Bruno Astuto",
      "Tyler Gleason",
      "Will Fletcher",
      "Justin Banaga",
      "Kevin Sweetwood",
      "Allen Ye",
      "Rina Patel",
      "Kevin McGill",
      "Thomas Link",
      "Jason Crane",
      "Valentina Pedoia",
      "Sharmila Majumdar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.07341"
  },
  {
    "id": "arXiv:2107.07342",
    "title": "Probabilistic analysis of solar cell optical performance using Gaussian  processes",
    "abstract": "This work investigates application of different machine learning based\nprediction methodologies to estimate the performance of silicon based textured\ncells. Concept of confidence bound regions is introduced and advantages of this\nconcept are discussed in detail. Results show that reflection profiles and\ndepth dependent optical generation profiles can be accurately estimated using\nGaussian processes with exact knowledge of uncertainty in the prediction\nvalues.It is also shown that cell design parameters can be estimated for a\ndesired performance metric.",
    "descriptor": "",
    "authors": [
      "Rahul Jaiswal",
      "Manel Mart\u00ednez-Ram\u00f3n",
      "Tito Busani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.07342"
  },
  {
    "id": "arXiv:2107.07343",
    "title": "Mutation is all you need",
    "abstract": "Neural architecture search (NAS) promises to make deep learning accessible to\nnon-experts by automating architecture engineering of deep neural networks.\nBANANAS is one state-of-the-art NAS method that is embedded within the Bayesian\noptimization framework. Recent experimental findings have demonstrated the\nstrong performance of BANANAS on the NAS-Bench-101 benchmark being determined\nby its path encoding and not its choice of surrogate model. We present\nexperimental results suggesting that the performance of BANANAS on the\nNAS-Bench-301 benchmark is determined by its acquisition function optimizer,\nwhich minimally mutates the incumbent.",
    "descriptor": "\nComments: Accepted for the 8th ICML Workshop on Automated Machine Learning (2021). 10 pages, 1 table, 3 figures\n",
    "authors": [
      "Lennart Schneider",
      "Florian Pfisterer",
      "Martin Binder",
      "Bernd Bischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.07343"
  },
  {
    "id": "arXiv:2107.07344",
    "title": "Framework for A Personalized Intelligent Assistant to Elderly People for  Activities of Daily Living",
    "abstract": "The increasing population of elderly people is associated with the need to\nmeet their increasing requirements and to provide solutions that can improve\ntheir quality of life in a smart home. In addition to fear and anxiety towards\ninterfacing with systems; cognitive disabilities, weakened memory, disorganized\nbehavior and even physical limitations are some of the problems that elderly\npeople tend to face with increasing age. The essence of providing\ntechnology-based solutions to address these needs of elderly people and to\ncreate smart and assisted living spaces for the elderly; lies in developing\nsystems that can adapt by addressing their diversity and can augment their\nperformances in the context of their day to day goals. Therefore, this work\nproposes a framework for development of a Personalized Intelligent Assistant to\nhelp elderly people perform Activities of Daily Living (ADLs) in a smart and\nconnected Internet of Things (IoT) based environment. This Personalized\nIntelligent Assistant can analyze different tasks performed by the user and\nrecommend activities by considering their daily routine, current affective\nstate and the underlining user experience. To uphold the efficacy of this\nproposed framework, it has been tested on a couple of datasets for modelling an\naverage user and a specific user respectively. The results presented show that\nthe model achieves a performance accuracy of 73.12% when modelling a specific\nuser, which is considerably higher than its performance while modelling an\naverage user, this upholds the relevance for development and implementation of\nthis proposed framework.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.15599\n",
    "authors": [
      "Nirmalya Thakur",
      "Chia Y. Han"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07344"
  },
  {
    "id": "arXiv:2107.07345",
    "title": "Inferring the Structure of Ordinary Differential Equations",
    "abstract": "Understanding physical phenomena oftentimes means understanding the\nunderlying dynamical system that governs observational measurements. While\naccurate prediction can be achieved with black box systems, they often lack\ninterpretability and are less amenable for further expert investigation.\nAlternatively, the dynamics can be analysed via symbolic regression. In this\npaper, we extend the approach by (Udrescu et al., 2020) called AIFeynman to the\ndynamic setting to perform symbolic regression on ODE systems based on\nobservations from the resulting trajectories. We compare this extension to\nstate-of-the-art approaches for symbolic regression empirically on several\ndynamical systems for which the ground truth equations of increasing complexity\nare available. Although the proposed approach performs best on this benchmark,\nwe observed difficulties of all the compared symbolic regression approaches on\nmore complex systems, such as Cart-Pole.",
    "descriptor": "",
    "authors": [
      "Juliane Weilbach",
      "Sebastian Gerwinn",
      "Christian Weilbach",
      "Melih Kandemir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07345"
  },
  {
    "id": "arXiv:2107.07346",
    "title": "You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a  (Mostly) Serverless and Open Stack",
    "abstract": "We argue that immature data pipelines are preventing a large portion of\nindustry practitioners from leveraging the latest research on recommender\nsystems. We propose our template data stack for machine learning at \"reasonable\nscale\", and show how many challenges are solved by embracing a serverless\nparadigm. Leveraging our experience, we detail how modern open source can\nprovide a pipeline processing terabytes of data with limited infrastructure\nwork.",
    "descriptor": "\nComments: Manuscript version of a work accepted at RecSys 2021 (camera-ready forthcoming)\n",
    "authors": [
      "Jacopo Tagliabue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07346"
  },
  {
    "id": "arXiv:2107.07347",
    "title": "Sparse Fourier Transform by traversing Cooley-Tukey FFT computation  graphs",
    "abstract": "Computing the dominant Fourier coefficients of a vector is a common task in\nmany fields, such as signal processing, learning theory, and computational\ncomplexity. In the Sparse Fast Fourier Transform (Sparse FFT) problem, one is\ngiven oracle access to a $d$-dimensional vector $x$ of size $N$, and is asked\nto compute the best $k$-term approximation of its Discrete Fourier Transform,\nquickly and using few samples of the input vector $x$. While the sample\ncomplexity of this problem is quite well understood, all previous approaches\neither suffer from an exponential dependence of runtime on the dimension $d$ or\ncan only tolerate a trivial amount of noise. This is in sharp contrast with the\nclassical FFT algorithm of Cooley and Tukey, which is stable and completely\ninsensitive to the dimension of the input vector: its runtime is $O(N\\log N)$\nin any dimension $d$.\nIn this work, we introduce a new high-dimensional Sparse FFT toolkit and use\nit to obtain new algorithms, both on the exact, as well as in the case of\nbounded $\\ell_2$ noise. This toolkit includes i) a new strategy for exploring a\npruned FFT computation tree that reduces the cost of filtering, ii) new\nstructural properties of adaptive aliasing filters recently introduced by\nKapralov, Velingker and Zandieh'SODA'19, and iii) a novel lazy estimation\nargument, suited to reducing the cost of estimation in FFT tree-traversal\napproaches. Our robust algorithm can be viewed as a highly optimized sparse,\nstable extension of the Cooley-Tukey FFT algorithm.\nFinally, we explain the barriers we have faced by proving a conditional\nquadratic lower bound on the running time of the well-studied non-equispaced\nFourier transform problem. This resolves a natural and frequently asked\nquestion in computational Fourier transforms. Lastly, we provide a preliminary\nexperimental evaluation comparing the runtime of our algorithm to FFTW and SFFT\n2.0.",
    "descriptor": "",
    "authors": [
      "Karl Bringmann",
      "Michael Kapralov",
      "Mikhail Makarov",
      "Vasileios Nakos",
      "Amir Yagudin",
      "Amir Zandieh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07347"
  },
  {
    "id": "arXiv:2107.07349",
    "title": "A multi-schematic classifier-independent oversampling approach for  imbalanced datasets",
    "abstract": "Over 85 oversampling algorithms, mostly extensions of the SMOTE algorithm,\nhave been built over the past two decades, to solve the problem of imbalanced\ndatasets. However, it has been evident from previous studies that different\noversampling algorithms have different degrees of efficiency with different\nclassifiers. With numerous algorithms available, it is difficult to decide on\nan oversampling algorithm for a chosen classifier. Here, we overcome this\nproblem with a multi-schematic and classifier-independent oversampling\napproach: ProWRAS(Proximity Weighted Random Affine Shadowsampling). ProWRAS\nintegrates the Localized Random Affine Shadowsampling (LoRAS)algorithm and the\nProximity Weighted Synthetic oversampling (ProWSyn) algorithm. By controlling\nthe variance of the synthetic samples, as well as a proximity-weighted\nclustering system of the minority classdata, the ProWRAS algorithm improves\nperformance, compared to algorithms that generate synthetic samples through\nmodelling high dimensional convex spaces of the minority class. ProWRAS has\nfour oversampling schemes, each of which has its unique way to model the\nvariance of the generated data. Most importantly, the performance of ProWRAS\nwith proper choice of oversampling schemes, is independent of the classifier\nused. We have benchmarked our newly developed ProWRAS algorithm against five\nsate-of-the-art oversampling models and four different classifiers on 20\npublicly available datasets. ProWRAS outperforms other oversampling algorithms\nin a statistically significant way, in terms of both F1-score and Kappa-score.\nMoreover, we have introduced a novel measure for classifier independence\nI-score, and showed quantitatively that ProWRAS performs better, independent of\nthe classifier used. In practice, ProWRAS customizes synthetic sample\ngeneration according to a classifier of choice and thereby reduces benchmarking\nefforts.",
    "descriptor": "\nComments: 12 tables, 6 figures\n",
    "authors": [
      "Saptarshi Bej",
      "Kristian Schultz",
      "Prashant Srivastava",
      "Markus Wolfien",
      "Olaf Wolkenhauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07349"
  },
  {
    "id": "arXiv:2107.07352",
    "title": "Copula-Based Normalizing Flows",
    "abstract": "Normalizing flows, which learn a distribution by transforming the data to\nsamples from a Gaussian base distribution, have proven powerful density\napproximations. But their expressive power is limited by this choice of the\nbase distribution. We, therefore, propose to generalize the base distribution\nto a more elaborate copula distribution to capture the properties of the target\ndistribution more accurately. In a first empirical analysis, we demonstrate\nthat this replacement can dramatically improve the vanilla normalizing flows in\nterms of flexibility, stability, and effectivity for heavy-tailed data. Our\nresults suggest that the improvements are related to an increased local\nLipschitz-stability of the learned flow.",
    "descriptor": "\nComments: Accepted for presentation at the ICML 2021 Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+ 2021)\n",
    "authors": [
      "Mike Laszkiewicz",
      "Johannes Lederer",
      "Asja Fischer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07352"
  },
  {
    "id": "arXiv:2107.07355",
    "title": "Using Cyber Digital Twins for Automated Automotive Cybersecurity Testing",
    "abstract": "Cybersecurity testing of automotive systems has become a practical necessity,\nwith the wide adoption of advanced driving assistance functions and vehicular\ncommunications. These functionalities require the integration of information\nand communication technologies that not only allow for a plethora of on-the-fly\nconfiguration abilities, but also provide a huge surface for attacks. Theses\ncircumstances have also been recognized by standardization and regulation\nbodies, making the need for not only proper cybersecurity engineering but also\nproving the effectiveness of security measures by verification and validation\nthrough testing also a formal necessity. In order to keep pace with the rapidly\ngrowing demand of neutral-party security testing of vehicular systems, novel\napproaches are needed. This paper therefore presents a methodology to create\nand execute cybersecurity test cases on the fly in a black box setting by using\npattern matching-based binary analysis and translation mechanisms to formal\nattack descriptions as well as model-checking techniques. The approach is\nintended to generate meaningful attack vectors on a system with next-to-zero a\npriori knowledge.",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted for the joint SRCNAS/STRIVE workshop at the 6th IEEE European Symposium on Security and Privacy\n",
    "authors": [
      "Stefan Marksteiner",
      "Slava Bronfman",
      "Markus Wolf",
      "Eddie Lazebnik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07355"
  },
  {
    "id": "arXiv:2107.07356",
    "title": "DiRe Committee : Diversity and Representation Constraints in Multiwinner  Elections",
    "abstract": "The study of fairness in multiwinner elections focuses on settings where\ncandidates have attributes. However, voters may also be divided into predefined\npopulations under one or more attributes (e.g., \"California\" and \"Illinois\"\npopulations under the \"state\" attribute), which may be same or different from\ncandidate attributes. The models that focus on candidate attributes alone may\nsystematically under-represent smaller voter populations. Hence, we develop a\nmodel, DiRe Committee Winner Determination (DRCWD), which delineates candidate\nand voter attributes to select a committee by specifying diversity and\nrepresentation constraints and a voting rule. We show the generalizability of\nour model, and analyze its computational complexity, inapproximability, and\nparameterized complexity. We develop a heuristic-based algorithm, which finds\nthe winning DiRe committee in under two minutes on 63% of the instances of\nsynthetic datasets and on 100% of instances of real-world datasets. We present\nan empirical analysis of the running time, feasibility, and utility traded-off.\nOverall, DRCWD motivates that a study of multiwinner elections should\nconsider both its actors, namely candidates and voters, as candidate-specific\n\"fair\" models can unknowingly harm voter populations, and vice versa.\nAdditionally, even when the attributes of candidates and voters coincide, it is\nimportant to treat them separately as having a female candidate on the\ncommittee, for example, is different from having a candidate on the committee\nwho is preferred by the female voters, and who themselves may or may not be\nfemale.",
    "descriptor": "\nComments: 30 pages, 8 figures, 2 tables, 4 algorithms\n",
    "authors": [
      "Kunal Relia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07356"
  },
  {
    "id": "arXiv:2107.07357",
    "title": "One Thousand and One Stories: A Large-Scale Survey of Software  Refactoring",
    "abstract": "Despite the availability of refactoring as a feature in popular IDEs, recent\nstudies revealed that developers are reluctant to use them, and still prefer\nthe manual refactoring of their code. At JetBrains, our goal is to fully\nsupport refactoring features in IntelliJ-based IDEs and improve their adoption\nin practice. Therefore, we start by raising the following main questions. How\nexactly do people refactor code? What refactorings are the most popular? Why do\nsome developers tend not to use convenient IDE refactoring tools?\nIn this paper, we investigate the raised questions through the design and\nimplementation of a survey targeting 1,183 users of IntelliJ-based IDEs. Our\nquantitative and qualitative analysis of the survey results shows that almost\ntwo-thirds of developers spend more than one hour in a single session\nrefactoring their code; that refactoring types vary greatly in popularity; and\nthat a lot of developers would like to know more about IDE refactoring features\nbut lack the means to do so. These results serve us internally to support the\nnext generation of refactoring features, as well as can help our research\ncommunity to establish new directions in the refactoring usability research.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Yaroslav Golubev",
      "Zarina Kurbatova",
      "Eman Abdullah AlOmar",
      "Timofey Bryksin",
      "Mohamed Wiem Mkaouer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07357"
  },
  {
    "id": "arXiv:2107.07358",
    "title": "A Refined Approximation for Euclidean k-Means",
    "abstract": "In the Euclidean $k$-Means problem we are given a collection of $n$ points\n$D$ in an Euclidean space and a positive integer $k$. Our goal is to identify a\ncollection of $k$ points in the same space (centers) so as to minimize the sum\nof the squared Euclidean distances between each point in $D$ and the closest\ncenter. This problem is known to be APX-hard and the current best approximation\nratio is a primal-dual $6.357$ approximation based on a standard LP for the\nproblem [Ahmadian et al. FOCS'17, SICOMP'20].\nIn this note we show how a minor modification of Ahmadian et al.'s analysis\nleads to a slightly improved $6.12903$ approximation. As a related result, we\nalso show that the mentioned LP has integrality gap at least\n$\\frac{16+\\sqrt{5}}{15}>1.2157$.",
    "descriptor": "",
    "authors": [
      "Fabrizio Grandoni",
      "Rafail Ostrovsky",
      "Yuval Rabani",
      "Leonard J. Schulman",
      "Rakesh Venkat"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.07358"
  },
  {
    "id": "arXiv:2107.07359",
    "title": "Efficient M\u00f6bius Transformations and their applications to  Dempster-Shafer Theory: Clarification and implementation",
    "abstract": "Dempster-Shafer Theory (DST) generalizes Bayesian probability theory,\noffering useful additional information, but suffers from a high computational\nburden. A lot of work has been done to reduce the complexity of computations\nused in information fusion with Dempster's rule. The main approaches exploit\neither the structure of Boolean lattices or the information contained in belief\nsources. Each has its merits depending on the situation. In this paper, we\npropose sequences of graphs for the computation of the zeta and M\\\"obius\ntransformations that optimally exploit both the structure of distributive\nsemilattices and the information contained in belief sources. We call them the\nEfficient M\\\"obius Transformations (EMT). We show that the complexity of the\nEMT is always inferior to the complexity of algorithms that consider the whole\nlattice, such as the Fast M\\\"obius Transform (FMT) for all DST transformations.\nWe then explain how to use them to fuse two belief sources. More generally, our\nEMTs apply to any function in any finite distributive lattice, focusing on a\nmeet-closed or join-closed subset. This article extends our work published at\nthe international conference on Scalable Uncertainty Management (SUM). It\nclarifies it, brings some minor corrections and provides implementation details\nsuch as data structures and algorithms applied to DST.",
    "descriptor": "\nComments: Extension of an article published in the proceedings of the international conference on Scalable Uncertainty Management (SUM) in 2019\n",
    "authors": [
      "Maxime Chaveroche",
      "Franck Davoine",
      "V\u00e9ronique Cherfaoui"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.07359"
  },
  {
    "id": "arXiv:2107.07360",
    "title": "Sketching sounds: an exploratory study on sound-shape associations",
    "abstract": "Sound synthesiser controls typically correspond to technical parameters of\nsignal processing algorithms rather than intuitive sound descriptors that\nrelate to human perception of sound. This makes it difficult to realise sound\nideas in a straightforward way. Cross-modal mappings, for example between\ngestures and sound, have been suggested as a more intuitive control mechanism.\nA large body of research shows consistency in human associations between sounds\nand shapes. However, the use of drawings to drive sound synthesis has not been\nexplored to its full extent. This paper presents an exploratory study that\nasked participants to sketch visual imagery of sounds with a monochromatic\ndigital drawing interface, with the aim to identify different representational\napproaches and determine whether timbral sound characteristics can be\ncommunicated reliably through visual sketches. Results imply that the\ndevelopment of a synthesiser exploiting sound-shape associations is feasible,\nbut a larger and more focused dataset is needed in followup studies.",
    "descriptor": "\nComments: accepted for International Computer Music Conference (ICMC) 2021\n",
    "authors": [
      "Sebastian L\u00f6bbers",
      "Mathieu Barthet",
      "Gy\u00f6rgy Fazekas"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.07360"
  },
  {
    "id": "arXiv:2107.07362",
    "title": "Should I Stay or Should I Go: Predicting Changes in Cluster Membership",
    "abstract": "Most research on predicting community evolution focuses on changes in the\nstates of communities. Instead, we focus on individual nodes and define the\nnovel problem of predicting whether a specific node stays in the same cluster,\nmoves to another cluster or drops out of the network. We explore variations of\nthe problem and propose appropriate classification features based on local and\nglobal node measures. Motivated by the prevalence of machine learning\napproaches based on embeddings, we also introduce efficiently computed\ndistance-based features using appropriate node embeddings. In addition, we\nconsider chains of features to capture the history of the nodes. Our\nexperimental results depict the complexity of the different formulations of the\nproblem and the suitability of the selected features and chain lengths.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Evangelia Tsoukanara",
      "Georgia Koloniari",
      "Evaggelia Pitoura"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.07362"
  },
  {
    "id": "arXiv:2107.07364",
    "title": "SilGAN: Generating driving maneuvers for scenario-based  software-in-the-loop testing",
    "abstract": "Automotive software testing continues to rely largely upon expensive field\ntests to ensure quality because alternatives like simulation-based testing are\nrelatively immature. As a step towards lowering reliance on field tests, we\npresent SilGAN, a deep generative model that eases specification, stimulus\ngeneration, and automation of automotive software-in-the-loop testing. The\nmodel is trained using data recorded from vehicles in the field. Upon training,\nthe model uses a concise specification for a driving scenario to generate\nrealistic vehicle state transitions that can occur during such a scenario. Such\nauthentic emulation of internal vehicle behavior can be used for rapid,\nsystematic and inexpensive testing of vehicle control software. In addition, by\npresenting a targeted method for searching through the information learned by\nthe model, we show how a test objective like code coverage can be automated.\nThe data driven end-to-end testing pipeline that we present vastly expands the\nscope and credibility of automotive simulation-based testing. This reduces time\nto market while helping maintain required standards of quality.",
    "descriptor": "\nComments: Preprint of article accepted at The third IEEE International Conference On Artificial Intelligence Testing 2021, Oxford, UK\n",
    "authors": [
      "Dhasarathy Parthasarathy",
      "Anton Johansson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07364"
  },
  {
    "id": "arXiv:2107.07373",
    "title": "A Reinforcement Learning Environment for Mathematical Reasoning via  Program Synthesis",
    "abstract": "We convert the DeepMind Mathematics Dataset into a reinforcement learning\nenvironment by interpreting it as a program synthesis problem. Each action\ntaken in the environment adds an operator or an input into a discrete compute\ngraph. Graphs which compute correct answers yield positive reward, enabling the\noptimization of a policy to construct compute graphs conditioned on problem\nstatements. Baseline models are trained using Double DQN on various subsets of\nproblem types, demonstrating the capability to learn to correctly construct\ngraphs despite the challenges of combinatorial explosion and noisy rewards.",
    "descriptor": "",
    "authors": [
      "Joseph Palermo",
      "Johnny Ye",
      "Alok Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07373"
  },
  {
    "id": "arXiv:2107.07374",
    "title": "Toward quantifying trust dynamics: How people adjust their trust after  moment-to-moment interaction with automation",
    "abstract": "Objective: We examine how human operators adjust their trust in automation as\na result of their moment-to-moment interaction with automation. Background:\nMost existing studies measured trust by administering questionnaires at the end\nof an experiment. Only a limited number of studies viewed trust as a dynamic\nvariable that can strengthen or decay over time. Method: Seventy-five\nparticipants took part in an aided memory recognition task. In the task,\nparticipants viewed a series of images and later on performed 40 trials of the\nrecognition task to identify a target image when it was presented with a\ndistractor. In each trial, participants performed the initial recognition by\nthemselves, received a recommendation from an automated decision aid, and\nperformed the final recognition. After each trial, participants reported their\ntrust on a visual analog scale. Results: Outcome bias and contrast effect\nsignificantly influence human operators' trust adjustments. An automation\nfailure leads to a larger trust decrement if the final outcome is undesirable,\nand a marginally larger trust decrement if the human operator succeeds the task\nby him-/her-self. An automation success engenders a greater trust increment if\nthe human operator fails the task. Additionally, automation failures have a\nlarger effect on trust adjustment than automation successes. Conclusion: Human\noperators adjust their trust in automation as a result of their\nmoment-to-moment interaction with automation. Their trust adjustments are\nsignificantly influenced by decision-making heuristics/biases. Application:\nUnderstanding the trust adjustment process enables accurate prediction of the\noperators' moment-to-moment trust in automation and informs the design of\ntrust-aware adaptive automation.",
    "descriptor": "",
    "authors": [
      "X. Jessie Yang",
      "Christopher Schemanske",
      "Christine Searle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07374"
  },
  {
    "id": "arXiv:2107.07376",
    "title": "Proceedings of the Sixteenth Workshop on Logical Frameworks and  Meta-Languages: Theory and Practice",
    "abstract": "Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop brings together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.",
    "descriptor": "",
    "authors": [
      "Elaine Pimentel",
      "Enrico Tassi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.07376"
  },
  {
    "id": "arXiv:2107.07377",
    "title": "Computing Permanents on a Trellis",
    "abstract": "The problem of computing the permanent of a matrix has attracted interest\nsince the work of Ryser(1963) and Valiant(1979). On the other hand, trellises\nwere extensively studied in coding theory since the 1960s. In this work, we\nestablish a connection between the two domains. We introduce the canonical\ntrellis $T_n$ that represents all permutations, and show that the permanent of\na $n$ by $n$ matrix $A$ can be computed as a flow on this trellis. Under\ncertain normalization, the trellis-based method invokes slightly less\noperations than best known exact methods. Moreover, if $A$ has structure, then\n$T_n$ becomes amenable to vertex merging, thereby significantly reducing its\ncomplexity.\n- Repeated rows: Suppose $A$ has only $t<n$ distinct rows. The best known\nmethod to compute $per(A)$, due to Clifford and Clifford (2020), has complexity\n$O(n^{t+1})$. Merging vertices in $T_n$, we obtain a reduced trellis that has\ncomplexity $O(n^t)$.\n- Order statistics: Using trellises, we compute the joint distribution of $t$\norder statistics of $n$ independent, but not identically distributed, random\nvariables in time $O(n^{t+1})$. Previously, polynomial-time methods were known\nonly when the variables are drawn from two non-identical distributions.\n- Sparse matrices: Suppose each entry in $A$ is nonzero with probability\n$d/n$ with $d$ is constant. We show that $T_n$ can be pruned to exponentially\nfewer vertices, resulting in complexity $O(\\phi^n)$ with $\\phi<2$.\n- TSP: Intersecting $T_n$ with another trellis that represents walks, we\nobtain a trellis that represents circular permutations. Using the latter\ntrellis to solve the traveling salesperson problem recovers the well-known\nHeld-Karp algorithm.\nNotably, in all cases, the reduced trellis are obtained using known\ntechniques in trellis theory. We expect other trellis-theoretic results to\napply to other structured matrices.",
    "descriptor": "",
    "authors": [
      "Han Mao Kiah",
      "Alexander Vardy",
      "Hanwen Yao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.07377"
  },
  {
    "id": "arXiv:2107.07382",
    "title": "Hybrid Ant Swarm-Based Data Clustering",
    "abstract": "Biologically inspired computing techniques are very effective and useful in\nmany areas of research including data clustering. Ant clustering algorithm is a\nnature-inspired clustering technique which is extensively studied for over two\ndecades. In this study, we extend the ant clustering algorithm (ACA) to a\nhybrid ant clustering algorithm (hACA). Specifically, we include a genetic\nalgorithm in standard ACA to extend the hybrid algorithm for better\nperformance. We also introduced novel pick up and drop off rules to speed up\nthe clustering performance. We study the performance of the hACA algorithm and\ncompare with standard ACA as a benchmark.",
    "descriptor": "\nComments: Conference\n",
    "authors": [
      "Md Ali Azam",
      "Abir Hossen",
      "Md Hafizur Rahman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07382"
  },
  {
    "id": "arXiv:2107.07383",
    "title": "Lossy Kernelization of Same-Size Clustering",
    "abstract": "In this work, we study the $k$-median clustering problem with an additional\nequal-size constraint on the clusters, from the perspective of parameterized\npreprocessing. Our main result is the first lossy ($2$-approximate) polynomial\nkernel for this problem, parameterized by the cost of clustering. We complement\nthis result by establishing lower bounds for the problem that eliminate the\nexistences of an (exact) kernel of polynomial size and a PTAS.",
    "descriptor": "",
    "authors": [
      "Sayan Bandyapadhyay",
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Nidhi Purohit",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07383"
  },
  {
    "id": "arXiv:2107.07384",
    "title": "A Fixed Version of Quadratic Program in Gradient Episodic Memory",
    "abstract": "Gradient Episodic Memory is indeed a novel method for continual learning,\nwhich solves new problems quickly without forgetting previously acquired\nknowledge. However, in the process of studying the paper, we found there were\nsome problems in the proof of the dual problem of Quadratic Program, so here we\ngive our fixed version for this problem.",
    "descriptor": "",
    "authors": [
      "Wei Zhou",
      "Yiying Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07384"
  },
  {
    "id": "arXiv:2107.07385",
    "title": "Together we learn better: leveraging communities of practice for MOOC  learners",
    "abstract": "MOOC participants often feel isolated and disconnected from their peers.\nNavigating meaningful peer interactions, generating a sense of belonging, and\nachieving social presence are all major challenges for MOOC platforms. MOOC\nusers often rely on external social platforms for such connection and peer\ninteraction, however, off-platform networking often distracts participants from\ntheir learning. With the intention of resolving this issue, we introduce\nPeerCollab, a web-based platform that provides affordances to create\ncommunities and supports meaningful peer interactions, building close-knit\ngroups of learners. We present an initial evaluation through a field study\n(n=56) over 6 weeks and a controlled experiment (n=22). The result indicates\ninsights on how learners build a sense of belonging and develop peer\ninteractions leading to close-knit learning circles. We find that PeerCollab\ncan provide more meaningful interactions and create a community to bring a\nculture of social learning to decentralized, and isolated MOOC learners.",
    "descriptor": "\nComments: Asian CHI Symposium 2021\n",
    "authors": [
      "Dilrukshi Gamage",
      "Mark E Whiting"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.07385"
  },
  {
    "id": "arXiv:2107.07386",
    "title": "Scheme-theoretic Approach to Computational Complexity I. The Separation  of P and NP",
    "abstract": "We lay the foundations of a new theory for algorithms and computational\ncomplexity by parameterizing the instances of a computational problem as a\nmoduli scheme. Considering the geometry of the scheme associated to 3-SAT, we\nseparate P and NP.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Ali \u00c7ivril"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.07386"
  },
  {
    "id": "arXiv:2107.07387",
    "title": "Scheme-theoretic Approach to Computational Complexity II. The Separation  of P and NP over $\\mathbb{C}$, $\\mathbb{R}$, and $\\mathbb{Z}$",
    "abstract": "We show that the problem of determining the feasibility of quadratic systems\nover $\\mathbb{C}$, $\\mathbb{R}$, and $\\mathbb{Z}$ requires exponential time.\nThis separates P and NP over these fields/rings in the BCSS model of\ncomputation.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Ali \u00c7ivril"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.07387"
  },
  {
    "id": "arXiv:2107.07393",
    "title": "Auditing for Diversity using Representative Examples",
    "abstract": "Assessing the diversity of a dataset of information associated with people is\ncrucial before using such data for downstream applications. For a given\ndataset, this often involves computing the imbalance or disparity in the\nempirical marginal distribution of a protected attribute (e.g. gender, dialect,\netc.). However, real-world datasets, such as images from Google Search or\ncollections of Twitter posts, often do not have protected attributes labeled.\nConsequently, to derive disparity measures for such datasets, the elements need\nto hand-labeled or crowd-annotated, which are expensive processes.\nWe propose a cost-effective approach to approximate the disparity of a given\nunlabeled dataset, with respect to a protected attribute, using a control set\nof labeled representative examples. Our proposed algorithm uses the pairwise\nsimilarity between elements in the dataset and elements in the control set to\neffectively bootstrap an approximation to the disparity of the dataset.\nImportantly, we show that using a control set whose size is much smaller than\nthe size of the dataset is sufficient to achieve a small approximation error.\nFurther, based on our theoretical framework, we also provide an algorithm to\nconstruct adaptive control sets that achieve smaller approximation errors than\nrandomly chosen control sets. Simulations on two image datasets and one Twitter\ndataset demonstrate the efficacy of our approach (using random and adaptive\ncontrol sets) in auditing the diversity of a wide variety of datasets.",
    "descriptor": "",
    "authors": [
      "Vijay Keswani",
      "L. Elisa Celis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07393"
  },
  {
    "id": "arXiv:2107.07394",
    "title": "Explore and Control with Adversarial Surprise",
    "abstract": "Reinforcement learning (RL) provides a framework for learning goal-directed\npolicies given user-specified rewards. However, since designing rewards often\nrequires substantial engineering effort, we are interested in the problem of\nlearning without rewards, where agents must discover useful behaviors in the\nabsence of task-specific incentives. Intrinsic motivation is a family of\nunsupervised RL techniques which develop general objectives for an RL agent to\noptimize that lead to better exploration or the discovery of skills. In this\npaper, we propose a new unsupervised RL technique based on an adversarial game\nwhich pits two policies against each other to compete over the amount of\nsurprise an RL agent experiences. The policies each take turns controlling the\nagent. The Explore policy maximizes entropy, putting the agent into surprising\nor unfamiliar situations. Then, the Control policy takes over and seeks to\nrecover from those situations by minimizing entropy. The game harnesses the\npower of multi-agent competition to drive the agent to seek out increasingly\nsurprising parts of the environment while learning to gain mastery over them.\nWe show empirically that our method leads to the emergence of complex skills by\nexhibiting clear phase transitions. Furthermore, we show both theoretically\n(via a latent state space coverage argument) and empirically that our method\nhas the potential to be applied to the exploration of stochastic,\npartially-observed environments. We show that Adversarial Surprise learns more\ncomplex behaviors, and explores more effectively than competitive baselines,\noutperforming intrinsic motivation methods based on active inference,\nnovelty-seeking (Random Network Distillation (RND)), and multi-agent\nunsupervised RL (Asymmetric Self-Play (ASP)) in MiniGrid, Atari and VizDoom\nenvironments.",
    "descriptor": "",
    "authors": [
      "Arnaud Fickinger",
      "Natasha Jaques",
      "Samyak Parajuli",
      "Michael Chang",
      "Nicholas Rhinehart",
      "Glen Berseth",
      "Stuart Russell",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07394"
  },
  {
    "id": "arXiv:2107.07397",
    "title": "Level generation and style enhancement -- deep learning for game  development overview",
    "abstract": "We present practical approaches of using deep learning to create and enhance\nlevel maps and textures for video games -- desktop, mobile, and web. We aim to\npresent new possibilities for game developers and level artists. The task of\ndesigning levels and filling them with details is challenging. It is both\ntime-consuming and takes effort to make levels rich, complex, and with a\nfeeling of being natural. Fortunately, recent progress in deep learning\nprovides new tools to accompany level designers and visual artists. Moreover,\nthey offer a way to generate infinite worlds for game replayability and adjust\neducational games to players' needs. We present seven approaches to create\nlevel maps, each using statistical methods, machine learning, or deep learning.\nIn particular, we include:\n- Generative Adversarial Networks for creating new images from existing\nexamples (e.g. ProGAN).\n- Super-resolution techniques for upscaling images while preserving crisp\ndetail (e.g. ESRGAN).\n- Neural style transfer for changing visual themes.\n- Image translation - turning semantic maps into images (e.g. GauGAN).\n- Semantic segmentation for turning images into semantic masks (e.g. U-Net).\n- Unsupervised semantic segmentation for extracting semantic features (e.g.\nTile2Vec).\n- Texture synthesis - creating large patterns based on a smaller sample (e.g.\nInGAN).",
    "descriptor": "\nComments: 16 pages, 10 figures, submitted to the 52nd International Simulation and Gaming Association (ISAGA) Conference 2021\n",
    "authors": [
      "Piotr Migda\u0142",
      "Bart\u0142omiej Olechno",
      "B\u0142a\u017cej Podg\u00f3rski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07397"
  },
  {
    "id": "arXiv:2107.07401",
    "title": "On Hard and Soft Decision Decoding of BCH Codes",
    "abstract": "Cyclic codes have the advantage that it is only necessary to store one\npolynomial. The binary primitive BCH codes are cyclic and are created by\nchoosing a subset of the cyclotomic cosets which can be done in various ways.\nWe compare different BCH codes of the same coderate with different weight\ndistributions, thus, are not equivalent by using different choices of\ncyclotomic cosets. We recall an old result from the sixties that any\nReed-Muller code is equivalent to a particular BCH code extended by a parity\nbit. The motivation for decoding BCH codes is that they have possibly better\nparameters than Reed-Muller codes which are related in recent publications to\npolar codes. We present several hard and soft decision decoding schemes based\non minimal weight codewords of the dual code, including information set\ndecoding in case of a channel without reliability information. Different BCH\ncodes of the same rate are compared and show different decoding performance and\ncomplexity. Some examples of hard decision decoding of BCH codes have the same\ndecoding performance as maximum likelihood decoding. All presented decoding\nmethods can be extended to include reliability information of a Gaussian\nchannel for soft decision decoding. We show various simulation results for soft\ndecision list information set decoding and analyze the influence of different\naspects on the performance.",
    "descriptor": "",
    "authors": [
      "Martin Bossert",
      "Rebekka Schulz",
      "Sebastian Bitzer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07401"
  },
  {
    "id": "arXiv:2107.07402",
    "title": "CLSRIL-23: Cross Lingual Speech Representations for Indic Languages",
    "abstract": "We present a CLSRIL-23, a self supervised learning based audio pre-trained\nmodel which learns cross lingual speech representations from raw audio across\n23 Indic languages. It is built on top of wav2vec 2.0 which is solved by\ntraining a contrastive task over masked latent speech representations and\njointly learns the quantization of latents shared across all languages. We\ncompare the language wise loss during pretraining to compare effects of\nmonolingual and multilingual pretraining. Performance on some downstream\nfine-tuning tasks for speech recognition is also compared and our experiments\nshow that multilingual pretraining outperforms monolingual training, in terms\nof learning speech representations which encodes phonetic similarity of\nlanguages and also in terms of performance on down stream tasks. A decrease of\n5% is observed in WER and 9.5% in CER when a multilingual pretrained model is\nused for finetuning in Hindi. All the code models are also open sourced.\nCLSRIL-23 is a model trained on $23$ languages and almost 10,000 hours of audio\ndata to facilitate research in speech recognition for Indic languages. We hope\nthat new state of the art systems will be created using the self supervised\napproach, especially for low resources Indic languages.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Anirudh Gupta",
      "Harveen Singh Chadha",
      "Priyanshi Shah",
      "Neeraj Chimmwal",
      "Ankur Dhuriya",
      "Rishabh Gaur",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.07402"
  },
  {
    "id": "arXiv:2107.07403",
    "title": "Local Search for Weighted Tree Augmentation and Steiner Tree",
    "abstract": "We present a technique that allows for improving on some relative greedy\nprocedures by well-chosen (non-oblivious) local search algorithms. Relative\ngreedy procedures are a particular type of greedy algorithm that start with a\nsimple, though weak, solution, and iteratively replace parts of this starting\nsolution by stronger components. Some well-known applications of relative\ngreedy algorithms include approximation algorithms for Steiner Tree and, more\nrecently, for connectivity augmentation problems.\nThe main application of our technique leads to a\n$(1.5+\\epsilon)$-approximation for Weighted Tree Augmentation, improving on a\nrecent relative greedy based method with approximation factor $1+\\ln 2 +\n\\epsilon\\approx 1.69$. Furthermore, we show how our local search technique can\nbe applied to Steiner Tree, leading to an alternative way to obtain the\ncurrently best known approximation factor of $\\ln 4 + \\epsilon$. Contrary to\nprior methods, our approach is purely combinatorial without the need to solve\nan LP. Nevertheless, the solution value can still be bounded in terms of the\nwell-known hypergraphic LP, leading to an alternative, and arguably simpler,\ntechnique to bound its integrality gap by $\\ln 4$.",
    "descriptor": "",
    "authors": [
      "Vera Traub",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.07403"
  },
  {
    "id": "arXiv:2107.07404",
    "title": "Two-Sided Matching Meets Fair Division",
    "abstract": "We introduce a new model for two-sided matching which allows us to borrow\npopular fairness notions from the fair division literature such as\nenvy-freeness up to one good and maximin share guarantee. In our model, each\nagent is matched to multiple agents on the other side over whom she has\nadditive preferences. We demand fairness for each side separately, giving rise\nto notions such as double envy-freeness up to one match (DEF1) and double\nmaximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1\ncannot always be achieved, but in the special case where both sides have\nidentical preferences, the round-robin algorithm with a carefully designed\nagent ordering achieves it. In contrast, DMMS cannot be achieved even when both\nsides have identical preferences.",
    "descriptor": "",
    "authors": [
      "Rupert Freeman",
      "Evi Micha",
      "Nisarg Shah"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07404"
  },
  {
    "id": "arXiv:2107.07406",
    "title": "Design and Implementation of an IoT Based LPG and CO Gases Monitoring  System",
    "abstract": "Nowadays use of liquefied petroleum gas (LPG) has increased. LPG is an\nasphyxiating, volatile and highly flammable gas. In a LPG leak situation,\npotential health accidents are increased either by inhalation or by combustion\nof the gas. On the other hand, carbon monoxide (CO) is a toxic gas that comes\nmainly from combustion in car engines. Breathing CO-polluted air can cause\ndizziness, fainting, breathing problems, and sometimes death. To prevent health\naccidents, including explosions, in open or closed environments, remote and\nreal-time monitoring of the concentration levels of CO and LPG gases has become\na necessity. The aim of this work is to demonstrate the use of Internet of\nThings (IoT) techniques to design and build a telemetry system to monitor in\nreal-time the concentration of GLP and CO gases in the surrounding air. To\nimplement this work, as central hardware there is a microcontroller, CO and PLG\nsensors on the electronic station. Besides, Amazon Web Services (AWS) was used\nas an IoT platform and data storage in the cloud. The main result was a\ntelematics system to monitor in real time the concentrations of both GLP and CO\ngases, whose data is accessible from any device with internet access through a\nwebsite. Field tests have been successful and have shown that the proposed\nsystem is an efficient and low-cost option.",
    "descriptor": "\nComments: David C. Wyld et al. (Eds): BIoT, DKMP, CCSEA, EMSA - 2021 pp. 31-39, 2021. CS & IT - CSCP 2021\n",
    "authors": [
      "Otoniel Flores-Cortez",
      "Ronny Cortez",
      "Bruno Gonz\u00e1lez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.07406"
  },
  {
    "id": "arXiv:2107.07409",
    "title": "Machine Learning-Based Analysis of Free-Text Keystroke Dynamics",
    "abstract": "The development of active and passive biometric authentication and\nidentification technology plays an increasingly important role in\ncybersecurity. Keystroke dynamics can be used to analyze the way that a user\ntypes based on various keyboard input. Previous work has shown that user\nauthentication and classification can be achieved based on keystroke dynamics.\nIn this research, we consider the problem of user classification based on\nkeystroke dynamics features collected from free-text. We implement and analyze\na novel a deep learning model that combines a convolutional neural network\n(CNN) and a gated recurrent unit (GRU). We optimize the resulting model and\nconsider several relevant related problems. Our model is competitive with the\nbest results obtained in previous comparable research.",
    "descriptor": "",
    "authors": [
      "Han-Chih Chang",
      "Jianwei Li",
      "Mark Stamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07409"
  },
  {
    "id": "arXiv:2107.07410",
    "title": "PC-MLP: Model-based Reinforcement Learning with Policy Cover Guided  Exploration",
    "abstract": "Model-based Reinforcement Learning (RL) is a popular learning paradigm due to\nits potential sample efficiency compared to model-free RL. However, existing\nempirical model-based RL approaches lack the ability to explore. This work\nstudies a computationally and statistically efficient model-based algorithm for\nboth Kernelized Nonlinear Regulators (KNR) and linear Markov Decision Processes\n(MDPs). For both models, our algorithm guarantees polynomial sample complexity\nand only uses access to a planning oracle. Experimentally, we first demonstrate\nthe flexibility and efficacy of our algorithm on a set of exploration\nchallenging control tasks where existing empirical model-based RL approaches\ncompletely fail. We then show that our approach retains excellent performance\neven in common dense reward control benchmarks that do not require heavy\nexploration. Finally, we demonstrate that our method can also perform\nreward-free exploration efficiently. Our code can be found at\nhttps://github.com/yudasong/PCMLP.",
    "descriptor": "",
    "authors": [
      "Yuda Song",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07410"
  },
  {
    "id": "arXiv:2107.07413",
    "title": "High-level Decisions from a Safe Maneuver Catalog with Reinforcement  Learning for Safe and Cooperative Automated Merging",
    "abstract": "Reinforcement learning (RL) has recently been used for solving challenging\ndecision-making problems in the context of automated driving. However, one of\nthe main drawbacks of the presented RL-based policies is the lack of safety\nguarantees, since they strive to reduce the expected number of collisions but\nstill tolerate them. In this paper, we propose an efficient RL-based\ndecision-making pipeline for safe and cooperative automated driving in merging\nscenarios. The RL agent is able to predict the current situation and provide\nhigh-level decisions, specifying the operation mode of the low level planner\nwhich is responsible for safety. In order to learn a more generic policy, we\npropose a scalable RL architecture for the merging scenario that is not\nsensitive to changes in the environment configurations. According to our\nexperiments, the proposed RL agent can efficiently identify cooperative drivers\nfrom their vehicle state history and generate interactive maneuvers, resulting\nin faster and more comfortable automated driving. At the same time, thanks to\nthe safety constraints inside the planner, all of the maneuvers are collision\nfree and safe.",
    "descriptor": "",
    "authors": [
      "Danial Kamran",
      "Yu Ren",
      "Martin Lauer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07413"
  },
  {
    "id": "arXiv:2107.07416",
    "title": "Cheatsheets for Authentication and Key Agreements in 2G, 3G, 4G, and 5G",
    "abstract": "Authentication and Key Agreement (AKA) is a type of security protocol, used\nin 3GPP mobile networks, that provides two security capabilities. The first\ncapability, called authentication, is to cryptographically assert that a mobile\nphone or a network is indeed who it claims to be, and the second capability,\ncalled key agreement, is to put necessary cryptographic keys in place for\nprotection of traffic between the mobile phone and the network. Jointly, these\ntwo capabilities lay the foundation of secure 3GPP mobile networks. From 2G-5G,\nthere are eight main versions of AKA, details of which are spread over and\nembedded deep in multiple technical specifications. It is getting increasingly\ndifficult to quickly check a certain property of a certain AKA, let alone grasp\nthe full picture of all AKAs. Therefore, I have prepared cheatsheets for all\nAKA versions and listed their main properties. I hope these will benefit\nuniversity students, security researchers, and 3GPP standardization community.\nI welcome any corrections and feedback.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Prajwol Kumar Nakarmi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.07416"
  },
  {
    "id": "arXiv:2107.07420",
    "title": "Optimal Scoring Rule Design",
    "abstract": "This paper introduces an optimization problem for proper scoring rule design.\nConsider a principal who wants to collect an agent's prediction about an\nunknown state. The agent can either report his prior prediction or access a\ncostly signal and report the posterior prediction. Given a collection of\npossible distributions containing the agent's posterior prediction\ndistribution, the principal's objective is to design a bounded scoring rule to\nmaximize the agent's worst-case payoff increment between reporting his\nposterior prediction and reporting his prior prediction.\nWe study two settings of such optimization for proper scoring rules: static\nand asymptotic settings. In the static setting, where the agent can access one\nsignal, we propose an efficient algorithm to compute an optimal scoring rule\nwhen the collection of distributions is finite. The agent can adaptively and\nindefinitely refine his prediction in the asymptotic setting. We first consider\na sequence of collections of posterior distributions with vanishing covariance,\nwhich emulates general estimators with large samples, and show the optimality\nof the quadratic scoring rule. Then, when the agent's posterior distribution is\na Beta-Bernoulli process, we find that the log scoring rule is optimal. We also\nprove the optimality of the log scoring rule over a smaller set of functions\nfor categorical distributions with Dirichlet priors.",
    "descriptor": "",
    "authors": [
      "Yiling Chen",
      "Fang-Yi Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.07420"
  },
  {
    "id": "arXiv:2107.07430",
    "title": "Wordcraft: a Human-AI Collaborative Editor for Story Writing",
    "abstract": "As neural language models grow in effectiveness, they are increasingly being\napplied in real-world settings. However these applications tend to be limited\nin the modes of interaction they support. In this extended abstract, we propose\nWordcraft, an AI-assisted editor for story writing in which a writer and a\ndialog system collaborate to write a story. Our novel interface uses few-shot\nlearning and the natural affordances of conversation to support a variety of\ninteractions. Our editor provides a sandbox for writers to probe the boundaries\nof transformer-based language models and paves the way for future\nhuman-in-the-loop training pipelines and novel evaluation methods.",
    "descriptor": "",
    "authors": [
      "Andy Coenen",
      "Luke Davis",
      "Daphne Ippolito",
      "Emily Reif",
      "Ann Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.07430"
  },
  {
    "id": "arXiv:2107.07431",
    "title": "High carbon stock mapping at large scale with optical satellite imagery  and spaceborne LIDAR",
    "abstract": "The increasing demand for commodities is leading to changes in land use\nworldwide. In the tropics, deforestation, which causes high carbon emissions\nand threatens biodiversity, is often linked to agricultural expansion. While\nthe need for deforestation-free global supply chains is widely recognized,\nmaking progress in practice remains a challenge. Here, we propose an automated\napproach that aims to support conservation and sustainable land use planning\ndecisions by mapping tropical landscapes at large scale and high spatial\nresolution following the High Carbon Stock (HCS) approach. A deep learning\napproach is developed that estimates canopy height for each 10 m Sentinel-2\npixel by learning from sparse GEDI LIDAR reference data, achieving an overall\nRMSE of 6.3 m. We show that these wall-to-wall maps of canopy top height are\npredictive for classifying HCS forests and degraded areas with an overall\naccuracy of 86 % and produce a first high carbon stock map for Indonesia,\nMalaysia, and the Philippines.",
    "descriptor": "",
    "authors": [
      "Nico Lang",
      "Konrad Schindler",
      "Jan Dirk Wegner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07431"
  },
  {
    "id": "arXiv:2107.07432",
    "title": "Hierarchical graph neural nets can capture long-range interactions",
    "abstract": "Graph neural networks (GNNs) based on message passing between neighboring\nnodes are known to be insufficient for capturing long-range interactions in\ngraphs. In this project we study hierarchical message passing models that\nleverage a multi-resolution representation of a given graph. This facilitates\nlearning of features that span large receptive fields without loss of local\ninformation, an aspect not studied in preceding work on hierarchical GNNs. We\nintroduce Hierarchical Graph Net (HGNet), which for any two connected nodes\nguarantees existence of message-passing paths of at most logarithmic length\nw.r.t. the input graph size. Yet, under mild assumptions, its internal\nhierarchy maintains asymptotic size equivalent to that of the input graph. We\nobserve that our HGNet outperforms conventional stacking of GCN layers\nparticularly in molecular property prediction benchmarks. Finally, we propose\ntwo benchmarking tasks designed to elucidate capability of GNNs to leverage\nlong-range interactions in graphs.",
    "descriptor": "",
    "authors": [
      "Ladislav Ramp\u00e1\u0161ek",
      "Guy Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07432"
  },
  {
    "id": "arXiv:2107.07437",
    "title": "StyleFusion: A Generative Model for Disentangling Spatial Segments",
    "abstract": "We present StyleFusion, a new mapping architecture for StyleGAN, which takes\nas input a number of latent codes and fuses them into a single style code.\nInserting the resulting style code into a pre-trained StyleGAN generator\nresults in a single harmonized image in which each semantic region is\ncontrolled by one of the input latent codes. Effectively, StyleFusion yields a\ndisentangled representation of the image, providing fine-grained control over\neach region of the generated image. Moreover, to help facilitate global control\nover the generated image, a special input latent code is incorporated into the\nfused representation. StyleFusion operates in a hierarchical manner, where each\nlevel is tasked with learning to disentangle a pair of image regions (e.g., the\ncar body and wheels). The resulting learned disentanglement allows one to\nmodify both local, fine-grained semantics (e.g., facial features) as well as\nmore global features (e.g., pose and background), providing improved\nflexibility in the synthesis process. As a natural extension, StyleFusion\nenables one to perform semantically-aware cross-image mixing of regions that\nare not necessarily aligned. Finally, we demonstrate how StyleFusion can be\npaired with existing editing techniques to more faithfully constrain the edit\nto the user's region of interest.",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Omer Kafri",
      "Or Patashnik",
      "Yuval Alaluf",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07437"
  },
  {
    "id": "arXiv:2107.07438",
    "title": "Convolutional Neural Bandit: Provable Algorithm for Visual-aware  Advertising",
    "abstract": "Online advertising is ubiquitous in web business. Image displaying is\nconsidered as one of the most commonly used formats to interact with customers.\nContextual multi-armed bandit has shown success in the application of\nadvertising to solve the exploration-exploitation dilemma existed in the\nrecommendation procedure. Inspired by the visual-aware advertising, in this\npaper, we propose a contextual bandit algorithm, where the convolutional neural\nnetwork (CNN) is utilized to learn the reward function along with an upper\nconfidence bound (UCB) for exploration. We also prove a near-optimal regret\nbound $\\tilde{\\mathcal{O}}(\\sqrt{T})$ when the network is over-parameterized\nand establish strong connections with convolutional neural tangent kernel\n(CNTK). Finally, we evaluate the empirical performance of the proposed\nalgorithm and show that it outperforms other state-of-the-art UCB-based bandit\nalgorithms on real-world image data sets.",
    "descriptor": "\nComments: 23 pages, in submission\n",
    "authors": [
      "Yikun Ban",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07438"
  },
  {
    "id": "arXiv:2107.07440",
    "title": "EPTAS for stable allocations in matching games",
    "abstract": "Gale-Shapley introduced a matching problem between two sets of agents where\neach agent on one side has a preference over the agents of the other side and\nproved algorithmically the existence of a pairwise stable matching (i.e. no\nuncoupled pair can be better off by matching). Shapley-Shubik, Demange-Gale,\nand many others extended the model by allowing monetary transfers. In this\npaper, we study an extension where matched couples obtain their payoffs as the\noutcome of a strategic game and more particularly a solution concept that\ncombines Gale-Shapley pairwise stability with a constrained Nash equilibrium\nnotion (no player can increase its payoff by playing a different strategy\nwithout violating the participation constraint of the partner). Whenever all\ncouples play zero-sum matrix games, strictly competitive bi-matrix games, or\ninfinitely repeated bi-matrix games, we can prove that a modification of some\nalgorithms in the literature converge to an $\\varepsilon$-stable allocation in\nat most $O(\\frac{1}{\\varepsilon})$ steps where each step is polynomial (linear\nwith respect to the number of players and polynomial of degree at most 5 with\nrespect to the number of pure actions per player).",
    "descriptor": "",
    "authors": [
      "Felipe Garrido-Lucero",
      "Rida Laraki"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.07440"
  },
  {
    "id": "arXiv:2107.07441",
    "title": "Reliability Analysis of Slotted Aloha with Capture for an OWC-based IoT  system",
    "abstract": "In this article, we consider a random access scheme for an indoor Internet of\nThings (IoT) framework that uses optical wireless communication (OWC). We focus\non a Slotted ALOHA (SA)-based solution where a number of OWC IoT users contend\nto send data to a central OWC receiver. In any given slot, and for a randomly\nselected active user, we consider the reliability of decoding the user's data\npacket at the receiver. This is done by deriving the\nsignal-to-noise-and-interference-ratio (SINR) statistics from a randomly chosen\nuser and evaluating the probability that the user's SINR is below a given\nthreshold. By placing our analysis in the context of an indoor OWC IoT uplink\nsetup, and employing the standard OWC channel model, we investigate the\ntrade-offs between the reliability and the OWC system parameters such as the\ncell area or the transmitter's semi-angle. We obtain valuable insights into the\ndesign of an SA-based random access solution for a typical indoor OWC cell.",
    "descriptor": "",
    "authors": [
      "Milica Petkovic",
      "Tijana Devaja",
      "Dejan Vukobratovic",
      "Francisco J. Escribano",
      "Cedomir Stefanovic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.07441"
  },
  {
    "id": "arXiv:2107.07442",
    "title": "MXDAG: A Hybrid Abstraction for Cluster Applications",
    "abstract": "Distributed applications, such as database queries and distributed training,\nconsist of both compute and network tasks. DAG-based abstraction primarily\ntargets compute tasks and has no explicit network-level scheduling. In\ncontrast, Coflow abstraction collectively schedules network flows among compute\ntasks but lacks the end-to-end view of the application DAG. Because of the\ndependencies and interactions between these two types of tasks, it is\nsub-optimal to only consider one of them. We argue that co-scheduling of both\ncompute and network tasks can help applications towards the globally optimal\nend-to-end performance. However, none of the existing abstractions can provide\nfine-grained information for co-scheduling. We propose MXDAG, an abstraction to\ntreat both compute and network tasks explicitly. It can capture the\ndependencies and interactions of both compute and network tasks leading to\nimproved application performance.",
    "descriptor": "",
    "authors": [
      "Weitao Wang",
      "Sushovan Das",
      "Xinyu Crystal Wu",
      "Zhuang Wang",
      "Ang Chen",
      "T. S. Eugene Ng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.07442"
  },
  {
    "id": "arXiv:2107.07445",
    "title": "AutoBERT-Zero: Evolving BERT Backbone from Scratch",
    "abstract": "Transformer-based pre-trained language models like BERT and its variants have\nrecently achieved promising performance in various natural language processing\n(NLP) tasks. However, the conventional paradigm constructs the backbone by\npurely stacking the manually designed global self-attention layers, introducing\ninductive bias and thus leading to sub-optimal. In this work, we propose an\nOperation-Priority Neural Architecture Search (OP-NAS) algorithm to\nautomatically search for promising hybrid backbone architectures. Our\nwell-designed search space (i) contains primitive math operations in the\nintra-layer level to explore novel attention structures, and (ii) leverages\nconvolution blocks to be the supplementary for attention structure in the\ninter-layer level to better learn local dependency. We optimize both the search\nalgorithm and evaluation of candidate models to boost the efficiency of our\nproposed OP-NAS. Specifically, we propose Operation-Priority (OP) evolution\nstrategy to facilitate model search via balancing exploration and exploitation.\nFurthermore, we design a Bi-branch Weight-Sharing (BIWS) training strategy for\nfast model evaluation. Extensive experiments show that the searched\narchitecture (named AutoBERT-Zero) significantly outperforms BERT and its\nvariants of different model capacities in various downstream tasks, proving the\narchitecture's transfer and generalization abilities. Remarkably,\nAutoBERT-Zero-base outperforms RoBERTa-base (using much more data) and\nBERT-large (with much larger model size) by 2.4 and 1.4 higher score on GLUE\ntest set. Code and pre-trained models will be made publicly available.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Jiahui Gao",
      "Hang Xu",
      "Han shi",
      "Xiaozhe Ren",
      "Philip L.H. Yu",
      "Xiaodan Liang",
      "Xin Jiang",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07445"
  },
  {
    "id": "arXiv:2107.07446",
    "title": "Personalizing User Engagement Dynamics in a Non-Verbal Communication  Game for Cerebral Palsy",
    "abstract": "Children and adults with cerebral palsy (CP) can have involuntary upper limb\nmovements as a consequence of the symptoms that characterize their motor\ndisability, leading to difficulties in communicating with caretakers and peers.\nWe describe how a socially assistive robot may help individuals with CP to\npractice non-verbal communicative gestures using an active orthosis in a\none-on-one number-guessing game. We performed a user study and data collection\nwith participants with CP; we found that participants preferred an embodied\nrobot over a screen-based agent, and we used the participant data to train\npersonalized models of participant engagement dynamics that can be used to\nselect personalized robot actions. Our work highlights the benefit of\npersonalized models in the engagement of users with CP with a socially\nassistive robot and offers design insights for future work in this area.",
    "descriptor": "\nComments: 7 pages, 6 figures. Accepted to IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) 2021\n",
    "authors": [
      "Nathaniel Dennler",
      "Catherine Yunis",
      "Jonathan Realmuto",
      "Terence Sanger",
      "Stefanos Nikolaidis",
      "Maja Matari\u0107"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07446"
  },
  {
    "id": "arXiv:2107.07449",
    "title": "Adversarial Attacks on Multi-task Visual Perception for Autonomous  Driving",
    "abstract": "Deep neural networks (DNNs) have accomplished impressive success in various\napplications, including autonomous driving perception tasks, in recent years.\nOn the other hand, current deep neural networks are easily fooled by\nadversarial attacks. This vulnerability raises significant concerns,\nparticularly in safety-critical applications. As a result, research into\nattacking and defending DNNs has gained much coverage. In this work, detailed\nadversarial attacks are applied on a diverse multi-task visual perception deep\nnetwork across distance estimation, semantic segmentation, motion detection,\nand object detection. The experiments consider both white and black box attacks\nfor targeted and un-targeted cases, while attacking a task and inspecting the\neffect on all the others, in addition to inspecting the effect of applying a\nsimple defense method. We conclude this paper by comparing and discussing the\nexperimental results, proposing insights and future work. The visualizations of\nthe attacks are available at https://youtu.be/R3JUV41aiPY.",
    "descriptor": "",
    "authors": [
      "Ibrahim Sobh",
      "Ahmed Hamed",
      "Varun Ravi Kumar",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07449"
  },
  {
    "id": "arXiv:2107.07451",
    "title": "Data vs classifiers, who wins?",
    "abstract": "The classification experiments covered by machine learning (ML) are composed\nby two important parts: the data and the algorithm. As they are a fundamental\npart of the problem, both must be considered when evaluating a model's\nperformance against a benchmark. The best classifiers need robust benchmarks to\nbe properly evaluated. For this, gold standard benchmarks such as OpenML-CC18\nare used. However, data complexity is commonly not considered along with the\nmodel during a performance evaluation. Recent studies employ Item Response\nTheory (IRT) as a new approach to evaluating datasets and algorithms, capable\nof evaluating both simultaneously. This work presents a new evaluation\nmethodology based on IRT and Glicko-2, jointly with the decodIRT tool developed\nto guide the estimation of IRT in ML. It explores the IRT as a tool to evaluate\nthe OpenML-CC18 benchmark for its algorithmic evaluation capability and checks\nif there is a subset of datasets more efficient than the original benchmark.\nSeveral classifiers, from classics to ensemble, are also evaluated using the\nIRT models. The Glicko-2 rating system was applied together with IRT to\nsummarize the innate ability and classifiers performance. It was noted that not\nall OpenML-CC18 datasets are really useful for evaluating algorithms, where\nonly 10% were rated as being really difficult. Furthermore, it was verified the\nexistence of a more efficient subset containing only 50% of the original size.\nWhile Randon Forest was singled out as the algorithm with the best innate\nability.",
    "descriptor": "\nComments: 15 pages, 6 figures and 9 tables\n",
    "authors": [
      "Lucas F. F. Cardoso",
      "Vitor C. A. Santos",
      "Regiane S. Kawasaki Franc\u00eas",
      "Ricardo B. C. Prud\u00eancio",
      "Ronnie C. O. Alves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07451"
  },
  {
    "id": "arXiv:2107.07452",
    "title": "GI-NNet \\& RGI-NNet: Development of Robotic Grasp Pose Models, Trainable  with Large as well as Limited Labelled Training Datasets, under supervised  and semi supervised paradigms",
    "abstract": "Our way of grasping objects is challenging for efficient, intelligent and\noptimal grasp by COBOTs. To streamline the process, here we use deep learning\ntechniques to help robots learn to generate and execute appropriate grasps\nquickly. We developed a Generative Inception Neural Network (GI-NNet) model,\ncapable of generating antipodal robotic grasps on seen as well as unseen\nobjects. It is trained on Cornell Grasping Dataset (CGD) and attained 98.87%\ngrasp pose accuracy for detecting both regular and irregular shaped objects\nfrom RGB-Depth (RGB-D) images while requiring only one third of the network\ntrainable parameters as compared to the existing approaches. However, to attain\nthis level of performance the model requires the entire 90% of the available\nlabelled data of CGD keeping only 10% labelled data for testing which makes it\nvulnerable to poor generalization. Furthermore, getting sufficient and quality\nlabelled dataset is becoming increasingly difficult keeping in pace with the\nrequirement of gigantic networks. To address these issues, we attach our model\nas a decoder with a semi-supervised learning based architecture known as Vector\nQuantized Variational Auto Encoder (VQVAE), which works efficiently when\ntrained both with the available labelled and unlabelled data. The proposed\nmodel, which we name as Representation based GI-NNet (RGI-NNet), has been\ntrained with various splits of label data on CGD with as minimum as 10%\nlabelled dataset together with latent embedding generated from VQVAE up to 50%\nlabelled data with latent embedding obtained from VQVAE. The performance level,\nin terms of grasp pose accuracy of RGI-NNet, varies between 92.13% to 95.6%\nwhich is far better than several existing models trained with only labelled\ndataset. For the performance verification of both GI-NNet and RGI-NNet models,\nwe use Anukul (Baxter) hardware cobot.",
    "descriptor": "",
    "authors": [
      "Priya Shukla",
      "Nilotpal Pramanik",
      "Deepesh Mehta",
      "G.C. Nandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07452"
  },
  {
    "id": "arXiv:2107.07453",
    "title": "Next-item Recommendations in Short Sessions",
    "abstract": "The changing preferences of users towards items trigger the emergence of\nsession-based recommender systems (SBRSs), which aim to model the dynamic\npreferences of users for next-item recommendations. However, most of the\nexisting studies on SBRSs are based on long sessions only for recommendations,\nignoring short sessions, though short sessions, in fact, account for a large\nproportion in most of the real-world datasets. As a result, the applicability\nof existing SBRSs solutions is greatly reduced. In a short session, quite\nlimited contextual information is available, making the next-item\nrecommendation very challenging. To this end, in this paper, inspired by the\nsuccess of few-shot learning (FSL) in effectively learning a model with limited\ninstances, we formulate the next-item recommendation as an FSL problem.\nAccordingly, following the basic idea of a representative approach for FSL,\ni.e., meta-learning, we devise an effective SBRS called INter-SEssion\ncollaborative Recommender netTwork (INSERT) for next-item recommendations in\nshort sessions. With the carefully devised local module and global module,\nINSERT is able to learn an optimal preference representation of the current\nuser in a given short session. In particular, in the global module, a similar\nsession retrieval network (SSRN) is designed to find out the sessions similar\nto the current short session from the historical sessions of both the current\nuser and other users, respectively. The obtained similar sessions are then\nutilized to complement and optimize the preference representation learned from\nthe current short session by the local module for more accurate next-item\nrecommendations in this short session. Extensive experiments conducted on two\nreal-world datasets demonstrate the superiority of our proposed INSERT over the\nstate-of-the-art SBRSs when making next-item recommendations in short sessions.",
    "descriptor": "\nComments: This paper has been accepted by ACM RecSys'21\n",
    "authors": [
      "Wenzhuo Song",
      "Shoujin Wang",
      "Yan Wang",
      "Shengsheng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.07453"
  },
  {
    "id": "arXiv:2107.07455",
    "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple  Large-Scale Tasks",
    "abstract": "There has been significant research done on developing methods for improving\nrobustness to distributional shift and uncertainty estimation. In contrast,\nonly limited work has examined developing standard datasets and benchmarks for\nassessing these approaches. Additionally, most work on uncertainty estimation\nand robustness has developed new techniques based on small-scale regression or\nimage classification tasks. However, many tasks of practical interest have\ndifferent modalities, such as tabular data, audio, text, or sensor data, which\noffer significant challenges involving regression and discrete or continuous\nstructured prediction. Thus, given the current state of the field, a\nstandardized large-scale dataset of tasks across a range of modalities affected\nby distributional shifts is necessary. This will enable researchers to\nmeaningfully evaluate the plethora of recently developed uncertainty\nquantification methods, as well as assessment criteria and state-of-the-art\nbaselines. In this work, we propose the \\emph{Shifts Dataset} for evaluation of\nuncertainty estimates and robustness to distributional shift. The dataset,\nwhich has been collected from industrial sources and services, is composed of\nthree tasks, with each corresponding to a particular data modality: tabular\nweather prediction, machine translation, and self-driving car (SDC) vehicle\nmotion prediction. All of these data modalities and tasks are affected by real,\n`in-the-wild' distributional shifts and pose interesting challenges with\nrespect to uncertainty estimation. In this work we provide a description of the\ndataset and baseline results for all tasks.",
    "descriptor": "",
    "authors": [
      "Andrey Malinin",
      "Neil Band",
      "German Chesnokov",
      "Yarin Gal",
      "Mark J. F. Gales",
      "Alexey Noskov",
      "Andrey Ploskonosov",
      "Liudmila Prokhorenkova",
      "Ivan Provilkov",
      "Vatsal Raina",
      "Vyas Raina",
      "Mariya Shmatova",
      "Panos Tigas",
      "Boris Yangel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07455"
  },
  {
    "id": "arXiv:2107.07458",
    "title": "On the Complexity of SPEs in Parity Games",
    "abstract": "We study the complexity of problems related to subgame-perfect equilibria\n(SPEs) in infinite duration non zero-sum multiplayer games played on finite\ngraphs with parity objectives. We present new complexity results that close\ngaps in the literature. Our techniques are based on a recent characterization\nof SPEs in prefix-independent games that is grounded on the notions of\nrequirements and negotiation, and according to which the plays supported by\nSPEs are exactly the plays consistent with the requirement that is the least\nfixed point of the negotiation function. The new results are as follows. First,\nchecking that a given requirement is a fixed point of the negotiation function\nis an NP-complete problem. Second, we show that the SPE constrained existence\nproblem is NP-complete, this problem was previously known to be ExpTime-easy\nand NP-hard. Third, the SPE constrained existence problem is fixed-parameter\ntractable when the number of players and of colors are parameters. Fourth,\ndeciding whether some requirement is the least fixed point of the negotiation\nfunction is complete for the second level of the Boolean hierarchy. Finally,\nthe SPE-verification problem -- that is, the problem of deciding whether there\nexists a play supported by a SPE that satisfies some LTL formula -- is\nPSpace-complete, this problem was known to be ExpTime-easy and PSpace-hard.",
    "descriptor": "",
    "authors": [
      "L\u00e9onard Brice",
      "Marie van den Bogaard",
      "Jean-Fran\u00e7ois Raskin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.07458"
  },
  {
    "id": "arXiv:2107.07460",
    "title": "Rule-based Evaluation and Optimal Control for Autonomous Driving",
    "abstract": "We develop optimal control strategies for autonomous vehicles (AVs) that are\nrequired to meet complex specifications imposed as rules of the road (ROTR) and\nlocally specific cultural expectations of reasonable driving behavior. We\nformulate these specifications as rules, and specify their priorities by\nconstructing a priority structure, called \\underline{T}otal \\underline{OR}der\nover e\\underline{Q}uivalence classes (TORQ). We propose a recursive framework,\nin which the satisfaction of the rules in the priority structure are\niteratively relaxed in reverse order of priority.\nCentral to this framework is an optimal control problem, where convergence to\ndesired states is achieved using Control Lyapunov Functions (CLFs) and\nclearance with other road users is enforced through Control Barrier Functions\n(CBFs). We present offline and online approaches to this problem. In the\nlatter, the AV has limited sensing range that affects the activation of the\nrules, and the control is generated using a receding horizon (Model Predictive\nControl, MPC) approach. We also show how the offline method can be used for\nafter-the-fact (offline) pass/fail evaluation of trajectories - a given\ntrajectory is rejected if we can find a controller producing a trajectory that\nleads to less violation of the rule priority structure. We present case studies\nwith multiple driving scenarios to demonstrate the effectiveness of the\nalgorithms, and to compare the offline and online versions of our proposed\nframework.",
    "descriptor": "\nComments: under review in TAC, 16 pages. arXiv admin note: substantial text overlap with arXiv:2101.05709\n",
    "authors": [
      "Wei Xiao",
      "Noushin Mehdipour",
      "Anne Collin",
      "Amitai Y. Bin-Nun",
      "Emilio Frazzoli",
      "Radboud Duintjer Tebbens",
      "Calin Belta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07460"
  },
  {
    "id": "arXiv:2107.07461",
    "title": "Using a template engine as a computer algebra tool",
    "abstract": "In research problems that involve the use of numerical methods for solving\nsystems of ordinary differential equations (ODEs), it is often required to\nselect the most efficient method for a particular problem. To solve a Cauchy\nproblem for a system of ODEs, Runge-Kutta methods (explicit or implicit ones,\nwith or without step-size control, etc.) are employed. In that case, it is\nrequired to search through many implementations of the numerical method and\nselect coefficients or other parameters of its numerical scheme. This paper\nproposes a library and scripts for automated generation of routine functions in\nthe Julia programming language for a set of numerical schemes of Runge-Kutta\nmethods. For symbolic manipulations, we use a template substitution tool. The\nproposed approach to automated generation of program code allows us to use a\nsingle template for editing, instead of modifying each individual function to\nbe compared. On the one hand, this provides universality in the implementation\nof a numerical scheme and, on the other hand, makes it possible to minimize the\nnumber of errors in the process of modifying the compared implementations of\nthe numerical method. We consider Runge-Kutta methods without step-size\ncontrol, embedded methods with step-size control, and Rosenbrock methods with\nstep-size control. The program codes for the numerical schemes, which are\ngenerated automatically using the proposed library, are tested by numerical\nsolution of several well-known problems.",
    "descriptor": "\nComments: in English; in Russian\n",
    "authors": [
      "Migran N. Gevorkyan",
      "Anna V. Korolkova",
      "Dmitry S. Kulyabov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2107.07461"
  },
  {
    "id": "arXiv:2107.07464",
    "title": "Amodal segmentation just like doing a jigsaw",
    "abstract": "Amodal segmentation is a new direction of instance segmentation while\nconsidering the segmentation of the visible and occluded parts of the instance.\nThe existing state-of-the-art method uses multi-task branches to predict the\namodal part and the visible part separately and subtract the visible part from\nthe amodal part to obtain the occluded part. However, the amodal part contains\nvisible information. Therefore, the separated prediction method will generate\nduplicate information. Different from this method, we propose a method of\namodal segmentation based on the idea of the jigsaw. The method uses multi-task\nbranches to predict the two naturally decoupled parts of visible and occluded,\nwhich is like getting two matching jigsaw pieces. Then put the two jigsaw\npieces together to get the amodal part. This makes each branch focus on the\nmodeling of the object. And we believe that there are certain rules in the\nocclusion relationship in the real world. This is a kind of occlusion context\ninformation. This jigsaw method can better model the occlusion relationship and\nuse the occlusion context information, which is important for amodal\nsegmentation. Experiments on two widely used amodally annotated datasets prove\nthat our method exceeds existing state-of-the-art methods. The source code of\nthis work will be made public soon.",
    "descriptor": "",
    "authors": [
      "Xunli Zeng",
      "Jianqin Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07464"
  },
  {
    "id": "arXiv:2107.07466",
    "title": "Trade-Based LDPC Codes",
    "abstract": "LDPC codes based on multiple-edge protographs potentially have larger minimum\ndistances compared to their counterparts, single-edge protographs. However,\nconsidering different features of their Tanner graph, such as short cycles,\ngirth and other graphical structures, is harder than for Tanner graphs from\nsingle-edge protographs. In this paper, we provide a novel approach to\nconstruct the parity-check matrix of an LDPC code which is based on trades\nobtained from block designs. We employ our method to construct two important\ncategories of LDPC codes; quasi-cyclic (QC) LDPC and spatially-coupled LDPC\n(SC-LDPC) codes.\nWe use those trade-based matrices to define base matrices of multiple-edge\nprotographs. The construction of exponent matrices corresponding to these base\nmatrices has less complexity compared to the ones proposed in the literature.\nWe prove that these base matrices result in QC-LDPC codes with smaller lower\nbounds on the lifting degree than existing ones.\nThere are three categories of SC-LDPC codes: periodic, time-invariant and\ntime-varying. Constructing the parity-check matrix of the third one is more\ndifficult because of the time dependency in the parity-check matrix. We use a\ntrade-based matrix to obtain the parity-check matrix of a time-varying SC-LDPC\ncode in which each downwards row displacement of the trade-based matrix yields\nsyndrome matrices of a particular time. Combining the different row shifts the\nwhole parity-check matrix is obtained.\nOur proposed method to construct parity-check and base matrices from trade\ndesigns is applicable to any type of super-simple directed block designs. We\napply our technique to directed designs with smallest defining sets containing\nat least half of the blocks. To demonstrate the significance of our\ncontribution, we provide a number of numerical and simulation results.",
    "descriptor": "",
    "authors": [
      "Farzane Amirzade",
      "Daniel Panario",
      "Mohammad-Reza Sadeghi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07466"
  },
  {
    "id": "arXiv:2107.07467",
    "title": "Only Train Once: A One-Shot Neural Network Training And Pruning  Framework",
    "abstract": "Structured pruning is a commonly used technique in deploying deep neural\nnetworks (DNNs) onto resource-constrained devices. However, the existing\npruning methods are usually heuristic, task-specified, and require an extra\nfine-tuning procedure. To overcome these limitations, we propose a framework\nthat compresses DNNs into slimmer architectures with competitive performances\nand significant FLOPs reductions by Only-Train-Once (OTO). OTO contains two\nkeys: (i) we partition the parameters of DNNs into zero-invariant groups,\nenabling us to prune zero groups without affecting the output; and (ii) to\npromote zero groups, we then formulate a structured-sparsity optimization\nproblem and propose a novel optimization algorithm, Half-Space Stochastic\nProjected Gradient (HSPG), to solve it, which outperforms the standard proximal\nmethods on group sparsity exploration and maintains comparable convergence. To\ndemonstrate the effectiveness of OTO, we train and compress full models\nsimultaneously from scratch without fine-tuning for inference speedup and\nparameter reduction, and achieve state-of-the-art results on VGG16 for CIFAR10,\nResNet50 for CIFAR10/ImageNet and Bert for SQuAD.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Tianyi Chen",
      "Bo Ji",
      "Tianyu Ding",
      "Biyi Fang",
      "Guanyi Wang",
      "Zhihui Zhu",
      "Luming Liang",
      "Yixin Shi",
      "Sheng Yi",
      "Xiao Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07467"
  },
  {
    "id": "arXiv:2107.07471",
    "title": "Objective Metrics to Evaluate Residual-Echo Suppression During  Double-Talk",
    "abstract": "Human subjective evaluation is optimal to assess speech quality for human\nperception. The recently introduced deep noise suppression mean opinion score\n(DNSMOS) metric was shown to estimate human ratings with great accuracy. The\nsignal-to-distortion ratio (SDR) metric is widely used to evaluate\nresidual-echo suppression (RES) systems by estimating speech quality during\ndouble-talk. However, since the SDR is affected by both speech distortion and\nresidual-echo presence, it does not correlate well with human ratings according\nto the DNSMOS. To address that, we introduce two objective metrics to\nseparately quantify the desired-speech maintained level (DSML) and\nresidual-echo suppression level (RESL) during double-talk. These metrics are\nevaluated using a deep learning-based RES-system with a tunable design\nparameter. Using 280 hours of real and simulated recordings, we show that the\nDSML and RESL correlate well with the DNSMOS with high generalization to\nvarious setups. Also, we empirically investigate the relation between tuning\nthe RES-system design parameter and the DSML-RESL tradeoff it creates and offer\na practical design scheme for dynamic system requirements.",
    "descriptor": "\nComments: Accepted to WASPAA\n",
    "authors": [
      "Amir Ivry",
      "Israel Cohen",
      "Baruch Berdugo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.07471"
  },
  {
    "id": "arXiv:2107.07477",
    "title": "A Survey of Perception-Based Visualization Studies by Task",
    "abstract": "Knowledge of human perception has long been incorporated into visualizations\nto enhance their quality and effectiveness. The last decade, in particular, has\nshown an increase in perception-based visualization research studies. With all\nof this recent progress, the visualization community lacks a comprehensive\nguide to contextualize their results. In this report, we provide a systematic\nand comprehensive review of research studies on perception related to\nvisualization. This survey reviews perception-focused visualization studies\nsince 1980 and summarizes their research developments focusing on low-level\ntasks, further breaking techniques down by visual encoding and visualization\ntype. In particular, we focus on how perception is used to evaluate the\neffectiveness of visualizations, to help readers understand and apply the\nprinciples of perception of their visualization designs through a\ntask-optimized approach. We concluded our report with a summary of the\nweaknesses and open research questions in the area.",
    "descriptor": "",
    "authors": [
      "Ghulam Jilani Quadri",
      "Paul Rosen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.07477"
  },
  {
    "id": "arXiv:2107.07482",
    "title": "Characteristics and Challenges of Low-Code Development: The  Practitioners' Perspective",
    "abstract": "Background: In recent years, Low-code development (LCD) is growing rapidly,\nand Gartner and Forrester have predicted that the use of LCD is very promising.\nGiant companies, such as Microsoft, Mendix, and Outsystems have also launched\ntheir LCD platforms. Aim: In this work, we explored two popular online\ndeveloper communities, Stack Overflow (SO) and Reddit, to provide insights on\nthe characteristics and challenges of LCD from a practitioners' perspective.\nMethod: We used two LCD related terms to search the relevant posts in SO and\nextracted 73 posts. Meanwhile, we explored three LCD related subreddits from\nReddit and collected 228 posts. We extracted data from these posts and applied\nthe Constant Comparison method to analyze the descriptions, benefits, and\nlimitations and challenges of LCD. For platforms and programming languages used\nin LCD, implementation units in LCD, supporting technologies of LCD, types of\napplications developed by LCD, and domains that use LCD, we used descriptive\nstatistics to analyze and present the results. Results: Our findings show that:\n(1) LCD may provide a graphical user interface for users to drag and drop with\nlittle or even no code; (2) the equipment of out-of-the-box units (e.g., APIs\nand components) in LCD platforms makes them easy to learn and use as well as\nspeeds up the development; (3) LCD is particularly favored in the domains that\nhave the need for automated processes and workflows; and (4) practitioners have\nconflicting views on the advantages and disadvantages of LCD. Conclusions: Our\nfindings suggest that researchers should clearly define the terms when they\nrefer to LCD, and developers should consider whether the characteristics of LCD\nare appropriate for their projects.",
    "descriptor": "\nComments: 15th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)\n",
    "authors": [
      "Yajing Luo",
      "Peng Liang",
      "Chong Wang",
      "Mojtaba Shahin",
      "Jing Zhan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07482"
  },
  {
    "id": "arXiv:2107.07484",
    "title": "Data Disclosure with Non-zero Leakage and Non-invertible Leakage Matrix",
    "abstract": "We study a statistical signal processing privacy problem, where an agent\nobserves useful data $Y$ and wants to reveal the information to a user. Since\nthe useful data is correlated with the private data $X$, the agent employs a\nprivacy mechanism to generate data $U$ that can be released. We study the\nprivacy mechanism design that maximizes the revealed information about $Y$\nwhile satisfying a strong $\\ell_1$-privacy criterion. When a sufficiently small\nleakage is allowed, we show that the optimizer vectors of the privacy mechanism\ndesign problem have a specific geometry, i.e., they are perturbations of fixed\nvector distributions. This geometrical structure allows us to use a local\napproximation of the conditional entropy. By using this approximation the\noriginal optimization problem can be reduced to a linear program so that an\napproximate solution for privacy mechanism can be easily obtained. The main\ncontribution of this work is to consider non-zero leakage with a non-invertible\nleakage matrix. In an example inspired by water mark application, we first\ninvestigate the accuracy of the approximation. Then, we employ different\nmeasures for utility and privacy leakage to compare the privacy-utility\ntrade-off using our approach with other methods. In particular, it has been\nshown that by allowing small leakage, significant utility can be achieved using\nour method compared to the case where no leakage is allowed.",
    "descriptor": "",
    "authors": [
      "Amirreza Zamani",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07484"
  },
  {
    "id": "arXiv:2107.07485",
    "title": "A Hybrid Simulation Model for Open Software Development Processes",
    "abstract": "Open software development provides software organizations access to infinite\nonline resource supply. The resource supply is a pool of unknown workers who\nwork from different location and time zone and are interested in performing\nvarious type of tasks. Improper task execution in such dynamic and competitive\nenvironment leads to zero task registration, zero task submissions or low\nqualified submissions due to unforeseen reasons such as uncertainty in workers'\nbehavior and performance. Therefore, to ensure effectiveness of open software\ndevelopment, there is a need for improved understanding and visibility into\ncharacteristics associated with attracting reliable workers in making qualified\nsubmissions and reducing task failure.",
    "descriptor": "\nComments: 172 pages. Copyright of the Dissertation is held by the Author\n",
    "authors": [
      "Razieh Saremi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.07485"
  },
  {
    "id": "arXiv:2107.07486",
    "title": "Moufang Patterns and Geometry of Information",
    "abstract": "Technology of data collection and information transmission is based on\nvarious mathematical models of encoding. The words \"Geometry of information\"\nrefer to such models, whereas the words \"Moufang patterns\" refer to various\nsophisticated symmetries appearing naturally in such models. In this paper we\nshow that the symmetries of spaces of probability distributions, endowed with\ntheir canonical Riemannian metric of information geometry, have the structure\nof a commutative Moufang loop. We also show that the F-manifold structure on\nthe space of probability distribution can be described in terms of differential\n3-webs and Malcev algebras. We then present a new construction of\n(noncommutative) Moufang loops associated to almost-symplectic structures over\nfinite fields, and use then to construct a new class of code loops with\nassociated quantum error-correcting codes and networks of perfect tensors.",
    "descriptor": "\nComments: amstex, 42 pages\n",
    "authors": [
      "Noemie Combe",
      "Yuri I. Manin",
      "Matilde Marcolli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07486"
  },
  {
    "id": "arXiv:2107.07489",
    "title": "Clustering of heterogeneous populations of networks",
    "abstract": "Statistical methods for reconstructing networks from repeated measurements\ntypically assume that all measurements are generated from the same underlying\nnetwork structure. This need not be the case, however. People's social networks\nmight be different on weekdays and weekends, for instance. Brain networks may\ndiffer between healthy patients and those with dementia or other conditions.\nHere we describe a Bayesian analysis framework for such data that allows for\nthe fact that network measurements may be reflective of multiple possible\nstructures. We define a finite mixture model of the measurement process and\nderive a fast Gibbs sampling procedure that samples exactly from the full\nposterior distribution of model parameters. The end result is a clustering of\nthe measured networks into groups with similar structure. We demonstrate the\nmethod on both real and synthetic network populations.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Jean-Gabriel Young",
      "Alec Kirkley",
      "M. E. J. Newman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.07489"
  },
  {
    "id": "arXiv:2107.07493",
    "title": "Algorithmic Concept-based Explainable Reasoning",
    "abstract": "Recent research on graph neural network (GNN) models successfully applied\nGNNs to classical graph algorithms and combinatorial optimisation problems.\nThis has numerous benefits, such as allowing applications of algorithms when\npreconditions are not satisfied, or reusing learned models when sufficient\ntraining data is not available or can't be generated. Unfortunately, a key\nhindrance of these approaches is their lack of explainability, since GNNs are\nblack-box models that cannot be interpreted directly. In this work, we address\nthis limitation by applying existing work on concept-based explanations to GNN\nmodels. We introduce concept-bottleneck GNNs, which rely on a modification to\nthe GNN readout mechanism. Using three case studies we demonstrate that: (i)\nour proposed model is capable of accurately learning concepts and extracting\npropositional formulas based on the learned concepts for each target class;\n(ii) our concept-based GNN models achieve comparative performance with\nstate-of-the-art models; (iii) we can derive global graph concepts, without\nexplicitly providing any supervision on graph-level concepts.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Dobrik Georgiev",
      "Pietro Barbiero",
      "Dmitry Kazhdan",
      "Petar Veli\u010dkovi\u0107",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07493"
  },
  {
    "id": "arXiv:2107.07497",
    "title": "Context-Conditional Adaptation for Recognizing Unseen Classes in Unseen  Domains",
    "abstract": "Recent progress towards designing models that can generalize to unseen\ndomains (i.e domain generalization) or unseen classes (i.e zero-shot learning)\nhas embarked interest towards building models that can tackle both domain-shift\nand semantic shift simultaneously (i.e zero-shot domain generalization). For\nmodels to generalize to unseen classes in unseen domains, it is crucial to\nlearn feature representation that preserves class-level (domain-invariant) as\nwell as domain-specific information. Motivated from the success of generative\nzero-shot approaches, we propose a feature generative framework integrated with\na COntext COnditional Adaptive (COCOA) Batch-Normalization to seamlessly\nintegrate class-level semantic and domain-specific information. The generated\nvisual features better capture the underlying data distribution enabling us to\ngeneralize to unseen classes and domains at test-time. We thoroughly evaluate\nand analyse our approach on established large-scale benchmark - DomainNet and\ndemonstrate promising performance over baselines and state-of-art methods.",
    "descriptor": "",
    "authors": [
      "Puneet Mangla",
      "Shivam Chandhok",
      "Vineeth N Balasubramanian",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07497"
  },
  {
    "id": "arXiv:2107.07498",
    "title": "FewCLUE: A Chinese Few-shot Learning Evaluation Benchmark",
    "abstract": "Pretrained Language Models (PLMs) have achieved tremendous success in natural\nlanguage understanding tasks. While different learning schemes -- fine-tuning,\nzero-shot and few-shot learning -- have been widely explored and compared for\nlanguages such as English, there is comparatively little work in Chinese to\nfairly and comprehensively evaluate and compare these methods. This work first\nintroduces Chinese Few-shot Learning Evaluation Benchmark (FewCLUE), the first\ncomprehensive small sample evaluation benchmark in Chinese. It includes nine\ntasks, ranging from single-sentence and sentence-pair classification tasks to\nmachine reading comprehension tasks. Given the high variance of the few-shot\nlearning performance, we provide multiple training/validation sets to\nfacilitate a more accurate and stable evaluation of few-shot modeling. An\nunlabeled training set with up to 20,000 additional samples per task is\nprovided, allowing researchers to explore better ways of using unlabeled\nsamples. Next, we implement a set of state-of-the-art (SOTA) few-shot learning\nmethods (including PET, ADAPET, LM-BFF, P-tuning and EFL), and compare their\nperformance with fine-tuning and zero-shot learning schemes on the newly\nconstructed FewCLUE benchmark.Our results show that: 1) all five few-shot\nlearning methods exhibit better performance than fine-tuning or zero-shot\nlearning; 2) among the five methods, PET is the best performing few-shot\nmethod; 3) few-shot learning performance is highly dependent on the specific\ntask. Our benchmark and code are available at\nhttps://github.com/CLUEbenchmark/FewCLUE",
    "descriptor": "\nComments: Work in Progress; 8 pages, 3 tables\n",
    "authors": [
      "Liang Xu",
      "Xiaojing Lu",
      "Chenyang Yuan",
      "Xuanwei Zhang",
      "Hu Yuan",
      "Huilin Xu",
      "Guoao Wei",
      "Xiang Pan",
      "Hai Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07498"
  },
  {
    "id": "arXiv:2107.07500",
    "title": "Recommending best course of treatment based on similarities of  prognostic markers\\thanks{All authors contributed equally",
    "abstract": "With the advancement in the technology sector spanning over every field, a\nhuge influx of information is inevitable. Among all the opportunities that the\nadvancements in the technology have brought, one of them is to propose\nefficient solutions for data retrieval. This means that from an enormous pile\nof data, the retrieval methods should allow the users to fetch the relevant and\nrecent data over time. In the field of entertainment and e-commerce,\nrecommender systems have been functioning to provide the aforementioned.\nEmploying the same systems in the medical domain could definitely prove to be\nuseful in variety of ways. Following this context, the goal of this paper is to\npropose collaborative filtering based recommender system in the healthcare\nsector to recommend remedies based on the symptoms experienced by the patients.\nFurthermore, a new dataset is developed consisting of remedies concerning\nvarious diseases to address the limited availability of the data. The proposed\nrecommender system accepts the prognostic markers of a patient as the input and\ngenerates the best remedy course. With several experimental trials, the\nproposed model achieved promising results in recommending the possible remedy\nfor given prognostic markers.",
    "descriptor": "",
    "authors": [
      "Sudhanshu",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07500"
  },
  {
    "id": "arXiv:2107.07501",
    "title": "An End-to-End Differentiable Framework for Contact-Aware Robot Design",
    "abstract": "The current dominant paradigm for robotic manipulation involves two separate\nstages: manipulator design and control. Because the robot's morphology and how\nit can be controlled are intimately linked, joint optimization of design and\ncontrol can significantly improve performance. Existing methods for\nco-optimization are limited and fail to explore a rich space of designs. The\nprimary reason is the trade-off between the complexity of designs that is\nnecessary for contact-rich tasks against the practical constraints of\nmanufacturing, optimization, contact handling, etc. We overcome several of\nthese challenges by building an end-to-end differentiable framework for\ncontact-aware robot design. The two key components of this framework are: a\nnovel deformation-based parameterization that allows for the design of\narticulated rigid robots with arbitrary, complex geometry, and a differentiable\nrigid body simulator that can handle contact-rich scenarios and computes\nanalytical gradients for a full spectrum of kinematic and dynamic parameters.\nOn multiple manipulation tasks, our framework outperforms existing methods that\neither only optimize for control or for design using alternate representations\nor co-optimize using gradient-free methods.",
    "descriptor": "\nComments: Robotics: Science and Systems\n",
    "authors": [
      "Jie Xu",
      "Tao Chen",
      "Lara Zlokapa",
      "Michael Foshey",
      "Wojciech Matusik",
      "Shinjiro Sueda",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.07501"
  },
  {
    "id": "arXiv:2107.07502",
    "title": "MultiBench: Multiscale Benchmarks for Multimodal Representation Learning",
    "abstract": "Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. It is a challenging yet crucial area\nwith numerous real-world applications in multimedia, affective computing,\nrobotics, finance, human-computer interaction, and healthcare. Unfortunately,\nmultimodal research has seen limited resources to study (1) generalization\nacross domains and modalities, (2) complexity during training and inference,\nand (3) robustness to noisy and missing modalities. In order to accelerate\nprogress towards understudied modalities and tasks while ensuring real-world\nrobustness, we release MultiBench, a systematic and unified large-scale\nbenchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6\nresearch areas. MultiBench provides an automated end-to-end machine learning\npipeline that simplifies and standardizes data loading, experimental setup, and\nmodel evaluation. To enable holistic evaluation, MultiBench offers a\ncomprehensive methodology to assess (1) generalization, (2) time and space\ncomplexity, and (3) modality robustness. MultiBench introduces impactful\nchallenges for future research, including scalability to large-scale multimodal\ndatasets and robustness to realistic imperfections. To accompany this\nbenchmark, we also provide a standardized implementation of 20 core approaches\nin multimodal learning. Simply applying methods proposed in different research\nareas can improve the state-of-the-art performance on 9/15 datasets. Therefore,\nMultiBench presents a milestone in unifying disjoint efforts in multimodal\nresearch and paves the way towards a better understanding of the capabilities\nand limitations of multimodal models, all the while ensuring ease of use,\naccessibility, and reproducibility. MultiBench, our standardized code, and\nleaderboards are publicly available, will be regularly updated, and welcomes\ninputs from the community.",
    "descriptor": "\nComments: Code: this https URL and Website: this https URL\n",
    "authors": [
      "Paul Pu Liang",
      "Yiwei Lyu",
      "Xiang Fan",
      "Zetian Wu",
      "Yun Cheng",
      "Jason Wu",
      "Leslie Chen",
      "Peter Wu",
      "Michelle A. Lee",
      "Yuke Zhu",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.07502"
  },
  {
    "id": "arXiv:2107.07506",
    "title": "Adaptable Agent Populations via a Generative Model of Policies",
    "abstract": "In the natural world, life has found innumerable ways to survive and often\nthrive. Between and even within species, each individual is in some manner\nunique, and this diversity lends adaptability and robustness to life. In this\nwork, we aim to learn a space of diverse and high-reward policies on any given\nenvironment. To this end, we introduce a generative model of policies, which\nmaps a low-dimensional latent space to an agent policy space. Our method\nenables learning an entire population of agent policies, without requiring the\nuse of separate policy parameters. Just as real world populations can adapt and\nevolve via natural selection, our method is able to adapt to changes in our\nenvironment solely by selecting for policies in latent space. We test our\ngenerative model's capabilities in a variety of environments, including an\nopen-ended grid-world and a two-player soccer environment. Code,\nvisualizations, and additional experiments can be found at\nhttps://kennyderek.github.io/adap/.",
    "descriptor": "\nComments: Website at this https URL\n",
    "authors": [
      "Kenneth Derek",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.07506"
  },
  {
    "id": "arXiv:2107.07507",
    "title": "Optimization-Based Quadrupedal Hybrid Wheeled-Legged Locomotion",
    "abstract": "Hybrid wheeled-legged locomotion is a navigation paradigm only recently\nopened up by novel robotic designs,e.g. the centaur-type humanoid CENTAURO [1]\nor the quadruped ANYmal [2] in its configuration featuring non-steerable\nwheels. The term Hybrid Locomotion is hereafter used to indicate a particular\ntype of locomotion, achieved with simultaneous and coordinate use of legs and\nwheels,see Fig. 1. Such choice stems at the intersection between legged\nlocomotion and the simpler wheeled navigation, in order to get the best from\nboth techniques: agility and ability to traverse uneven terrains from the\nfirst, speed and stability from the second. As a consequence, the problem of\nplanning feasible trajectories for a hybrid robot shares many similarities with\nthe legged locomotion problem: also in the hybrid case the motion of the base\nis reached through contact of the feet with the environment, taking into\naccount that the wheeled feet can just push on the ground and not pull it.\nForces compatible with friction cones have to be considered, while the contacts\ncan slide just along the direction prescribed by the orientation of the wheels.",
    "descriptor": "\nComments: Presented at Humanoids 2020\n",
    "authors": [
      "Italo Belli",
      "Matteo Parigi Polverini",
      "Arturo Laurenzi",
      "Enrico Mingo Hoffman",
      "Paolo Rocco",
      "Nikolaos Tsagarakis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07507"
  },
  {
    "id": "arXiv:2107.07508",
    "title": "USCO-Solver: Solving Undetermined Stochastic Combinatorial Optimization  Problems",
    "abstract": "Real-world decision-making systems are often subject to uncertainties that\nhave to be resolved through observational data. Therefore, we are frequently\nconfronted with combinatorial optimization problems of which the objective\nfunction is unknown and thus has to be debunked using empirical evidence. In\ncontrast to the common practice that relies on a learning-and-optimization\nstrategy, we consider the regression between combinatorial spaces, aiming to\ninfer high-quality optimization solutions from samples of input-solution pairs\n-- without the need to learn the objective function. Our main deliverable is a\nuniversal solver that is able to handle abstract undetermined stochastic\ncombinatorial optimization problems. For learning foundations, we present\nlearning-error analysis under the PAC-Bayesian framework using a new\nmargin-based analysis. In empirical studies, we demonstrate our design using\nproof-of-concept experiments, and compare it with other methods that are\npotentially applicable. Overall, we obtain highly encouraging experimental\nresults for several classic combinatorial problems on both synthetic and\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Guangmo Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07508"
  },
  {
    "id": "arXiv:2107.07511",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free  Uncertainty Quantification",
    "abstract": "Black-box machine learning learning methods are now routinely used in\nhigh-risk settings, like medical diagnostics, which demand uncertainty\nquantification to avoid consequential model failures. Distribution-free\nuncertainty quantification (distribution-free UQ) is a user-friendly paradigm\nfor creating statistically rigorous confidence intervals/sets for such\npredictions. Critically, the intervals/sets are valid without distributional\nassumptions or model assumptions, with explicit guarantees with finitely many\ndatapoints. Moreover, they adapt to the difficulty of the input; when the input\nexample is difficult, the uncertainty intervals/sets are large, signaling that\nthe model might be wrong. Without much work, one can use distribution-free\nmethods on any underlying algorithm, such as a neural network, to produce\nconfidence sets guaranteed to contain the ground truth with a user-specified\nprobability, such as 90%. Indeed, the methods are easy-to-understand and\ngeneral, applying to many modern prediction problems arising in the fields of\ncomputer vision, natural language processing, deep reinforcement learning, and\nso on. This hands-on introduction is aimed at a reader interested in the\npractical implementation of distribution-free UQ, including conformal\nprediction and related methods, who is not necessarily a statistician. We will\ninclude many explanatory illustrations, examples, and code samples in Python,\nwith PyTorch syntax. The goal is to provide the reader a working understanding\nof distribution-free UQ, allowing them to put confidence intervals on their\nalgorithms, with one self-contained document.",
    "descriptor": "\nComments: Blog and tutorial video this http URL\n",
    "authors": [
      "Anastasios N. Angelopoulos",
      "Stephen Bates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07511"
  },
  {
    "id": "arXiv:2107.06898",
    "title": "Towards quantifying information flows: relative entropy in deep neural  networks and the renormalization group",
    "abstract": "We investigate the analogy between the renormalization group (RG) and deep\nneural networks, wherein subsequent layers of neurons are analogous to\nsuccessive steps along the RG. In particular, we quantify the flow of\ninformation by explicitly computing the relative entropy or Kullback-Leibler\ndivergence in both the one- and two-dimensional Ising models under decimation\nRG, as well as in a feedforward neural network as a function of depth. We\nobserve qualitatively identical behavior characterized by the monotonic\nincrease to a parameter-dependent asymptotic value. On the quantum field theory\nside, the monotonic increase confirms the connection between the relative\nentropy and the c-theorem. For the neural networks, the asymptotic behavior may\nhave implications for various information maximization methods in machine\nlearning, as well as for disentangling compactness and generalizability.\nFurthermore, while both the two-dimensional Ising model and the random neural\nnetworks we consider exhibit non-trivial critical points, the relative entropy\nappears insensitive to the phase structure of either system. In this sense,\nmore refined probes are required in order to fully elucidate the flow of\ninformation in these models.",
    "descriptor": "\nComments: 41 pages, 8 figures; code available at this https URL\n",
    "authors": [
      "Johanna Erdmenger",
      "Kevin T. Grosvenor",
      "Ro Jefferson"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06898"
  },
  {
    "id": "arXiv:2107.06936",
    "title": "Performance of Bayesian linear regression in a model with mismatch",
    "abstract": "For a model of high-dimensional linear regression with random design, we\nanalyze the performance of an estimator given by the mean of a log-concave\nBayesian posterior distribution with gaussian prior. The model is mismatched in\nthe following sense: like the model assumed by the statistician, the\nlabels-generating process is linear in the input data, but both the classifier\nground-truth prior and gaussian noise variance are unknown to her. This\ninference model can be rephrased as a version of the Gardner model in spin\nglasses and, using the cavity method, we provide fixed point equations for\nvarious overlap order parameters, yielding in particular an expression for the\nmean-square reconstruction error on the classifier (under an assumption of\nuniqueness of solutions). As a direct corollary we obtain an expression for the\nfree energy. Similar models have already been studied by Shcherbina and Tirozzi\nand by Talagrand, but our arguments are more straightforward and some\nassumptions are relaxed. An interesting consequence of our analysis is that in\nthe random design setting of ridge regression, the performance of the posterior\nmean is independent of the noise variance (or \"temperature\") assumed by the\nstatistician, and matches the one of the usual (zero temperature) ridge\nestimator.",
    "descriptor": "",
    "authors": [
      "Jean Barbier",
      "Wei-Kuo Chen",
      "Dmitry Panchenko",
      "Manuel S\u00e1enz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.06936"
  },
  {
    "id": "arXiv:2107.06937",
    "title": "Planning Strategies for Lane Reversals in Transportation Networks",
    "abstract": "This paper studies strategies to optimize the lane configuration of a\ntransportation network for a given set of Origin-Destination demands using a\nplanning macroscopic network flow model. The lane reversal problem is, in\ngeneral, NP-hard since the optimization is made over integer variables. To\novercome this burden, we reformulate the problem using a piecewise affine\napproximation of the travel latency function which allows us to exploit the\ntotal unimodularity property of Integer Linear Programming (ILP). Consequently,\nwe transform the ILP problem to a linear program by relaxing the integer\nvariables. In addition, our method is capable of solving the problem for a\ndesired number of lane reversals which serves to perform cost-benefit analysis.\nWe perform a case study using the transportation network of Eastern\nMassachusetts (EMA) and we test our method against the original lane\nconfiguration and a projected lower bound solution. Our empirical results\nquantify the travel time savings for different levels of demand intensity. We\nobserve reduction in travel times up to 40% for certain links in the network.",
    "descriptor": "\nComments: Proc. IEEE Int. Conf. on Intelligent Transportation Systems, Indianapolis, USA, 2021. (In Press)\n",
    "authors": [
      "Salomon Wollenstein-Betech",
      "Ioannis Ch. Paschalidis",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06937"
  },
  {
    "id": "arXiv:2107.06953",
    "title": "Optimality of the Discrete Fourier Transform for Beamspace Massive  MU-MIMO Communication",
    "abstract": "Beamspace processing is an emerging technique to reduce baseband complexity\nin massive multiuser (MU) multiple-input multiple-output (MIMO) communication\nsystems operating at millimeter-wave (mmWave) and terahertz frequencies. The\nhigh directionality of wave propagation at such high frequencies ensures that\nonly a small number of transmission paths exist between user equipments and\nbasestation (BS). In order to resolve the sparse nature of wave propagation,\nbeamspace processing traditionally computes a spatial discrete Fourier\ntransform (DFT) across a uniform linear antenna array at the BS where each DFT\noutput is associated with a specific beam. In this paper, we study optimality\nconditions of the DFT for sparsity-based beamspace processing with idealistic\nmmWave channel models and realistic channels. To this end, we propose two\nalgorithms that learn unitary beamspace transforms using an $\\ell^4$-norm-based\nsparsity measure, and we investigate their optimality theoretically and via\nsimulations.",
    "descriptor": "\nComments: to appear at ISIT 2021, minor bug fix in Algorithm 2\n",
    "authors": [
      "Sueda Taner",
      "Christoph Studer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06953"
  },
  {
    "id": "arXiv:2107.06961",
    "title": "On complete classes of valuated matroids",
    "abstract": "We characterize a rich class of valuated matroids, called R-minor valuated\nmatroids that includes the indicator functions of matroids, and is closed under\noperations such as taking minors, duality, and induction by network. We refute\nthe refinement of a 2003 conjecture by Frank, exhibiting valuated matroids that\nare not R-minor. The family of counterexamples is based on sparse paving\nmatroids. Valuated matroids are inherently related to gross substitute\nvaluations in mathematical economics. By the same token we refute the Matroid\nBased Valuation Conjecture by Ostrovsky and Paes Leme (Theoretical Economics\n2015) asserting that every gross substitute valuation arises from weighted\nmatroid rank functions by repeated applications of merge and endowment\noperations. Our result also has implications in the context of Lorentzian\npolynomials: it reveals the limitations of known construction operations.",
    "descriptor": "\nComments: 53 pages, 13 figures\n",
    "authors": [
      "Edin Husi\u0107",
      "Georg Loho",
      "Ben Smith",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.06961"
  },
  {
    "id": "arXiv:2107.06962",
    "title": "Frequency-packed Faster-than-Nyquist Signaling via Symbol-level  Precoding for Multi-user MISO Redundant Transmissions",
    "abstract": "This work addresses the issue of interference generated by co-channel users\nin downlink multi-antenna multicarrier systems with frequency-packed\nfaster-than-Nyquist (FTN) signaling. The resulting interference stems from an\naggressive strategy for enhancing the throughput via frequency reuse across\ndifferent users and the squeezing of signals in the time-frequency plane beyond\nthe Nyquist limit. The error-free spectral efficiency is proved to be\nincreasing with the frequency packing and FTN acceleration factors. The lower\nbound for the FTN sampling period that guarantees information losslesness is\nderived as a function of the transmitting-filter roll-off factor, the\nfrequency-packing factor, and the number of subcarriers. Space-time-frequency\nsymbol-level precoders (SLPs) that trade off constructive and destructive\ninterblock interference (IBI) at the single-antenna user terminals are\nproposed. Redundant elements are added as guard interval to cope with vestigial\ndestructive IBI effects. The proposals can handle channels with delay spread\nlonger than the multicarrier-symbol duration. The receiver architecture is\nsimple, for it does not require digital multicarrier demodulation. Simulations\nindicate that the proposed SLP outperforms zero-forcing precoding and achieves\na target balance between spectral and energy efficiencies by controlling the\namount of added redundancy from zero (full IBI) to half (destructive IBI-free)\nthe group delay of the equivalent channel.",
    "descriptor": "",
    "authors": [
      "Wallace A. Martins",
      "Symeon Chatzinotas",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.06962"
  },
  {
    "id": "arXiv:2107.07001",
    "title": "Fast Homotopy for Spacecraft Rendezvous Trajectory Optimization with  Discrete Logic",
    "abstract": "This paper presents a computationally efficient optimization algorithm for\nsolving nonconvex optimal control problems that involve discrete logic\nconstraints. Traditional solution methods for these constraints require binary\nvariables and mixed-integer programming, which is prohibitively slow and\ncomputationally expensive. This paper targets a fast solution that is capable\nof real-time implementation onboard spacecraft. To do so, a novel algorithm is\ndeveloped that blends sequential convex programming and numerical continuation\ninto a single iterative solution process. Inside the algorithm, discrete logic\nconstraints are approximated by smooth functions, and a homotopy parameter\ngoverns the accuracy of this approximation. As the algorithm converges, the\nhomotopy parameter is updated such that the smooth approximations enforce the\nexact discrete logic. The effectiveness of this approach is numerically\ndemonstrated for a realistic rendezvous scenario inspired by the Apollo\nTransposition and Docking maneuver. In under 15 seconds of cumulative solver\ntime, the algorithm is able to reliably find difficult fuel-optimal\ntrajectories that obey the following discrete logic constraints: thruster\nminimum impulse-bit, range-triggered approach cone, and range-triggered plume\nimpingement. The optimized trajectory uses significantly less fuel than\nreported NASA design targets.",
    "descriptor": "\nComments: 40 pages, 19 figures; submitted to the AIAA Journal of Guidance, Control, and Dynamics\n",
    "authors": [
      "Danylo Malyuta",
      "Behcet Acikmese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07001"
  },
  {
    "id": "arXiv:2107.07026",
    "title": "A new class of conditional Markov jump processes with regime switching  and path dependence: properties and maximum likelihood estimation",
    "abstract": "This paper develops a new class of conditional Markov jump processes with\nregime switching and paths dependence. The key novel feature of the developed\nprocess lies on its ability to switch the transition rate as it moves from one\nstate to another with switching probability depending on the current state and\ntime of the process as well as its past trajectories. As such, the transition\nfrom current state to another depends on the holding time of the process in the\nstate. Distributional properties of the process are given explicitly in terms\nof the speed regimes represented by a finite number of different transition\nmatrices, the probabilities of selecting regime membership within each state,\nand past realization of the process. In particular, it has distributional\nequivalent stochastic representation with a general mixture of Markov jump\nprocesses introduced in Frydman and Surya (2020). Maximum likelihood estimates\n(MLE) of the distribution parameters of the process are derived in closed form.\nThe estimation is done iteratively using the EM algorithm. Akaike information\ncriterion is used to assess the goodness-of-fit of the selected model. An\nexplicit observed Fisher information matrix of the MLE is derived for the\ncalculation of standard errors of the MLE. The information matrix takes on a\nsimplified form of the general matrix formula of Louis (1982). Large sample\nproperties of the MLE are presented. In particular, the covariance matrix for\nthe MLE of transition rates is equal to the Cram\\'er-Rao lower bound, and is\nless for the MLE of regime membership. The simulation study confirms these\nfindings and shows that the parameter estimates are accurate, consistent, and\nhave asymptotic normality as the sample size increases.",
    "descriptor": "\nComments: 28 pages, 3 figures\n",
    "authors": [
      "Budhi Surya"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.07026"
  },
  {
    "id": "arXiv:2107.07049",
    "title": "Learning-based Spectrum Sensing and Access in Cognitive Radios via  Approximate POMDPs",
    "abstract": "A novel LEarning-based Spectrum Sensing and Access (LESSA) framework is\nproposed, wherein a cognitive radio (CR) learns a time-frequency correlation\nmodel underlying spectrum occupancy of licensed users (LUs) in a radio\necosystem; concurrently, it devises an approximately optimal spectrum sensing\nand access policy under sensing constraints. A Baum-Welch algorithm is proposed\nto learn a parametric Markov transition model of LU spectrum occupancy based on\nnoisy spectrum measurements. Spectrum sensing and access are cast as a\nPartially-Observable Markov Decision Process, approximately optimized via\nrandomized point-based value iteration. Fragmentation, Hamming-distance state\nfilters and Monte-Carlo methods are proposed to alleviate the inherent\ncomputational complexity, and a weighted reward metric to regulate the\ntrade-off between CR throughput and LU interference. Numerical evaluations\ndemonstrate that LESSA performs within 5 percent of a genie-aided upper bound\nwith foreknowledge of LU spectrum occupancy, and outperforms state-of-the-art\nalgorithms across the entire trade-off region: 71 percent over\ncorrelation-based clustering, 26 percent over Neyman-Pearson detection, 6\npercent over the Viterbi algorithm, and 9 percent over an adaptive Deep\nQ-Network. LESSA is then extended to a distributed Multi-Agent setting\n(MA-LESSA), by proposing novel neighbor discovery and channel access rank\nallocation. MA-LESSA improves CR throughput by 43 percent over cooperative\nTD-SARSA, 84 percent over cooperative greedy distributed learning, and 3x over\nnon-cooperative learning via g-statistics and ACKs. Finally, MA-LESSA is\nimplemented on the DARPA SC2 platform, manifesting superior performance over\ncompetitors in a real-world TDWR-UNII WLAN emulation; its implementation\nfeasibility is further validated on a testbed of ESP32 radios, exhibiting 96\npercent success probability.",
    "descriptor": "\nComments: 33 pages, 9 figures, 1 table, Major Revisions under review at IEEE Transactions on Cognitive Communications and Networking (IEEE TCCN)\n",
    "authors": [
      "Bharath Keshavamurthy",
      "Nicolo Michelusi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07049"
  },
  {
    "id": "arXiv:2107.07061",
    "title": "Distributed Grid Optimization via Distributed Dual Subgradient Methods  with Averaging",
    "abstract": "A collection of optimization problems central to power system operation\nrequires distributed solution architectures to avoid the need for aggregation\nof all information at a central location. In this paper, we study distributed\ndual subgradient methods to solve three such optimization problems. Namely,\nthese are tie-line scheduling in multi-area power systems, coordination of\ndistributed energy resources in radial distribution networks, and joint\ndispatch of transmission and distribution assets. With suitable relaxations or\napproximations of the nonconvex power flow equations, all three problems can be\nreduced to a multi-agent constrained convex optimization problem. We utilize a\nconstant step-size dual subgradient method with averaging on these problems.\nFor this algorithm, we provide a convergence guarantee that is shown to be\norder-optimal. We illustrate its application on the grid optimization problems.",
    "descriptor": "",
    "authors": [
      "Subhonmesh Bose",
      "Hoa Dinh Nguyen",
      "Ye Guo",
      "Thinh T. Doan",
      "Carolyn L. Beck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07061"
  },
  {
    "id": "arXiv:2107.07064",
    "title": "DAL: Feature Learning from Overt Speech to Decode Imagined Speech-based  EEG Signals with Convolutional Autoencoder",
    "abstract": "Brain-computer interface (BCI) is one of the tools which enables the\ncommunication between humans and devices by reflecting intention and status of\nhumans. With the development of artificial intelligence, the interest in\ncommunication between humans and drones using electroencephalogram (EEG) is\nincreased. Especially, in the case of controlling drone swarms such as\ndirection or formation, there are many advantages compared with controlling a\ndrone unit. Imagined speech is one of the endogenous BCI paradigms, which can\nidentify intentions of users. When conducting imagined speech, the users\nimagine the pronunciation as if actually speaking. In contrast, overt speech is\na task in which the users directly pronounce the words. When controlling drone\nswarms using imagined speech, complex commands can be delivered more\nintuitively, but decoding performance is lower than that of other endogenous\nBCI paradigms. We proposed the Deep-autoleaner (DAL) to learn EEG features of\novert speech for imagined speech-based EEG signals classification. To the best\nof our knowledge, this study is the first attempt to use EEG features of overt\nspeech to decode imagined speech-based EEG signals with an autoencoder. A total\nof eight subjects participated in the experiment. When classifying four words,\nthe average accuracy of the DAL was 48.41%. In addition, when comparing the\nperformance between w/o and w/ EEG features of overt speech, there was a\nperformance improvement of 7.42% when including EEG features of overt speech.\nHence, we demonstrated that EEG features of overt speech could improve the\ndecoding performance of imagined speech.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Dae-Hyeok Lee",
      "Sung-Jin Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.07064"
  },
  {
    "id": "arXiv:2107.07071",
    "title": "A Combinatorial Interpretation for the Shor-Laflamme Weight Enumerators  of CWS Codes",
    "abstract": "We show that one of the Shor-Laflamme weight enumerators of a codeword\nstabilized quantum code may be interpreted as the distance enumerator of an\nassociated classical code.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Andrew Nemec",
      "Andreas Klappenecker"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07071"
  },
  {
    "id": "arXiv:2107.07087",
    "title": "Entropic Inequality Constraints from $e$-separation Relations in  Directed Acyclic Graphs with Hidden Variables",
    "abstract": "Directed acyclic graphs (DAGs) with hidden variables are often used to\ncharacterize causal relations between variables in a system. When some\nvariables are unobserved, DAGs imply a notoriously complicated set of\nconstraints on the distribution of observed variables. In this work, we present\nentropic inequality constraints that are implied by $e$-separation relations in\nhidden variable DAGs with discrete observed variables. The constraints can\nintuitively be understood to follow from the fact that the capacity of\nvariables along a causal pathway to convey information is restricted by their\nentropy; e.g. at the extreme case, a variable with entropy $0$ can convey no\ninformation. We show how these constraints can be used to learn about the true\ncausal model from an observed data distribution. In addition, we propose a\nmeasure of causal influence called the minimal mediary entropy, and demonstrate\nthat it can augment traditional measures such as the average causal effect.",
    "descriptor": "\nComments: 15 pages. This arXiv version is slightly updated relative to the version in UAI proceedings. (Theorem 5 and Proposition 8 have been strengthened, with Appendix C revised correspondingly. Appendix D has been added.)\n",
    "authors": [
      "Noam Finkelstein",
      "Beata Zjawin",
      "Elie Wolfe",
      "Ilya Shpitser",
      "Robert W. Spekkens"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07087"
  },
  {
    "id": "arXiv:2107.07098",
    "title": "Hida-Mat\u00e9rn Kernel",
    "abstract": "We present the class of Hida-Mat\\'ern kernels, which is the canonical family\nof covariance functions over the entire space of stationary Gauss-Markov\nProcesses. It extends upon Mat\\'ern kernels, by allowing for flexible\nconstruction of priors over processes with oscillatory components. Any\nstationary kernel, including the widely used squared-exponential and spectral\nmixture kernels, are either directly within this class or are appropriate\nasymptotic limits, demonstrating the generality of this class. Taking advantage\nof its Markovian nature we show how to represent such processes as state space\nmodels using only the kernel and its derivatives. In turn this allows us to\nperform Gaussian Process inference more efficiently and side step the usual\ncomputational burdens. We also show how exploiting special properties of the\nstate space representation enables improved numerical stability in addition to\nfurther reductions of computational complexity.",
    "descriptor": "",
    "authors": [
      "Matthew Dowling",
      "Piotr Sok\u00f3\u0142",
      "Il Memming Park"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07098"
  },
  {
    "id": "arXiv:2107.07105",
    "title": "Continuous-variable neural-network quantum states and the quantum rotor  model",
    "abstract": "We initiate the study of neural-network quantum state algorithms for\nanalyzing continuous-variable lattice quantum systems in first quantization. A\nsimple family of continuous-variable trial wavefunctons is introduced which\nnaturally generalizes the restricted Boltzmann machine (RBM) wavefunction\nintroduced for analyzing quantum spin systems. By virtue of its simplicity, the\nsame variational Monte Carlo training algorithms that have been developed for\nground state determination and time evolution of spin systems have natural\nanalogues in the continuum. We offer a proof of principle demonstration in the\ncontext of ground state determination of a stoquastic quantum rotor\nHamiltonian. Results are compared against those obtained from partial\ndifferential equation (PDE) based scalable eigensolvers. This study serves as a\nbenchmark against which future investigation of continuous-variable neural\nquantum states can be compared, and points to the need to consider deep network\narchitectures and more sophisticated training algorithms.",
    "descriptor": "",
    "authors": [
      "James Stokes",
      "Saibal De",
      "Shravan Veerapaneni",
      "Giuseppe Carleo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2107.07105"
  },
  {
    "id": "arXiv:2107.07115",
    "title": "Principal component analysis for Gaussian process posteriors",
    "abstract": "This paper proposes an extension of principal component analysis for Gaussian\nprocess posteriors denoted by GP-PCA. Since GP-PCA estimates a low-dimensional\nspace of GP posteriors, it can be used for meta-learning, which is a framework\nfor improving the precision of a new task by estimating a structure of a set of\ntasks. The issue is how to define a structure of a set of GPs with an\ninfinite-dimensional parameter, such as coordinate system and a divergence. In\nthis study, we reduce the infiniteness of GP to the finite-dimensional case\nunder the information geometrical framework by considering a space of GP\nposteriors that has the same prior. In addition, we propose an approximation\nmethod of GP-PCA based on variational inference and demonstrate the\neffectiveness of GP-PCA as meta-learning through experiments.",
    "descriptor": "",
    "authors": [
      "Hideaki Ishibashi",
      "Shotaro Akaho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07115"
  },
  {
    "id": "arXiv:2107.07246",
    "title": "Estimation of spatially varying parameters with application to  hyperbolic SPDEs",
    "abstract": "More often than not, we encounter problems with varying parameters as opposed\nto those that are static. In this paper, we treat the estimation of parameters\nwhich vary with space. We use Metropolis-Hastings algorithm as a selection\ncriteria for the maximum filter likelihood. Comparisons are made with the use\nof joint estimation of both the spatially varying parameters and the state. We\nillustrate the procedures employed in this paper by means of two hyperbolic\nSPDEs: the advection and the wave equation. The Metropolis-Hastings procedure\nregisters better estimates.",
    "descriptor": "",
    "authors": [
      "David Angwenyi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.07246"
  },
  {
    "id": "arXiv:2107.07271",
    "title": "Multi-Channel Auto-Encoders and a Novel Dataset for Learning Domain  Invariant Representations of Histopathology Images",
    "abstract": "Domain shift is a problem commonly encountered when developing automated\nhistopathology pipelines. The performance of machine learning models such as\nconvolutional neural networks within automated histopathology pipelines is\noften diminished when applying them to novel data domains due to factors\narising from differing staining and scanning protocols. The Dual-Channel\nAuto-Encoder (DCAE) model was previously shown to produce feature\nrepresentations that are less sensitive to appearance variation introduced by\ndifferent digital slide scanners. In this work, the Multi-Channel Auto-Encoder\n(MCAE) model is presented as an extension to DCAE which learns from more than\ntwo domains of data. Additionally, a synthetic dataset is generated using\nCycleGANs that contains aligned tissue images that have had their appearance\nsynthetically modified. Experimental results show that the MCAE model produces\nfeature representations that are less sensitive to inter-domain variations than\nthe comparative StaNoSA method when tested on the novel synthetic data.\nAdditionally, the MCAE and StaNoSA models are tested on a novel tissue\nclassification task. The results of this experiment show the MCAE model out\nperforms the StaNoSA model by 5 percentage-points in the f1-score. These\nresults show that the MCAE model is able to generalise better to novel data and\ntasks than existing approaches by actively learning normalised feature\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Andrew Moyes",
      "Richard Gault",
      "Kun Zhang",
      "Ji Ming",
      "Danny Crookes",
      "Jing Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07271"
  },
  {
    "id": "arXiv:2107.07312",
    "title": "FMNet: Latent Feature-wise Mapping Network for Cleaning up Noisy  Micro-Doppler Spectrogram",
    "abstract": "Micro-Doppler signatures contain considerable information about target\ndynamics. However, the radar sensing systems are easily affected by noisy\nsurroundings, resulting in uninterpretable motion patterns on the micro-Doppler\nspectrogram. Meanwhile, radar returns often suffer from multipath, clutter and\ninterference. These issues lead to difficulty in, for example motion feature\nextraction, activity classification using micro Doppler signatures ($\\mu$-DS),\netc. In this paper, we propose a latent feature-wise mapping strategy, called\nFeature Mapping Network (FMNet), to transform measured spectrograms so that\nthey more closely resemble the output from a simulation under the same\nconditions. Based on measured spectrogram and the matched simulated data, our\nframework contains three parts: an Encoder which is used to extract latent\nrepresentations/features, a Decoder outputs reconstructed spectrogram according\nto the latent features, and a Discriminator minimizes the distance of latent\nfeatures of measured and simulated data. We demonstrate the FMNet with six\nactivities data and two experimental scenarios, and final results show strong\nenhanced patterns and can keep actual motion information to the greatest\nextent. On the other hand, we also propose a novel idea which trains a\nclassifier with only simulated data and predicts new measured samples after\ncleaning them up with the FMNet. From final classification results, we can see\nsignificant improvements.",
    "descriptor": "",
    "authors": [
      "Chong Tang",
      "Wenda Li",
      "Shelly Vishwakarma",
      "Fangzhan Shi",
      "Simon Julier",
      "Kevin Chetty"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07312"
  },
  {
    "id": "arXiv:2107.07322",
    "title": "A unified framework for bandit multiple testing",
    "abstract": "In bandit multiple hypothesis testing, each arm corresponds to a different\nnull hypothesis that we wish to test, and the goal is to design adaptive\nalgorithms that correctly identify large set of interesting arms (true\ndiscoveries), while only mistakenly identifying a few uninteresting ones (false\ndiscoveries). One common metric in non-bandit multiple testing is the false\ndiscovery rate (FDR). We propose a unified, modular framework for bandit FDR\ncontrol that emphasizes the decoupling of exploration and summarization of\nevidence. We utilize the powerful martingale-based concept of ``e-processes''\nto ensure FDR control for arbitrary composite nulls, exploration rules and\nstopping times in generic problem settings. In particular, valid FDR control\nholds even if the reward distributions of the arms could be dependent, multiple\narms may be queried simultaneously, and multiple (cooperating or competing)\nagents may be querying arms, covering combinatorial semi-bandit type settings\nas well. Prior work has considered in great detail the setting where each arm's\nreward distribution is independent and sub-Gaussian, and a single arm is\nqueried at each step. Our framework recovers matching sample complexity\nguarantees in this special case, and performs comparably or better in practice.\nFor other settings, sample complexities will depend on the finer details of the\nproblem (composite nulls being tested, exploration algorithm, data dependence\nstructure, stopping rule) and we do not explore these; our contribution is to\nshow that the FDR guarantee is clean and entirely agnostic to these details.",
    "descriptor": "\nComments: 37 pages. 6 figures\n",
    "authors": [
      "Ziyu Xu",
      "Ruodu Wang",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.07322"
  },
  {
    "id": "arXiv:2107.07348",
    "title": "Article Processing Charges based publications: to which extent the price  explains scientific impact?",
    "abstract": "The present study aims to analyze relationship between Citations Normalized\nScore (NCS) of scientific publications and Article Processing Charges (APCs)\namounts of Gold Open access publications. To do so, we use APCs information\nprovided by OpenAPC database and citations scores of publications in the Web of\nScience database (WoS). Database covers the period from 2006 to 2019 with\n83,752 articles published in 4751 journals belonging to 267 distinct\npublishers. Results show that contrary to this belief, paying dearly does not\nnecessarily increase the impact of publications. First, large publishers with\nhigh impact are not the most expensive. Second, publishers with the highest\nAPCs are not necessarily the best in terms of impact. Correlation between APCs\nand impact is moderate. Otherwise, in the econometric analysis we have shown\nthat publication quality is strongly determined by journal quality in which it\nis published. International collaboration also plays an important role in\ncitations score.",
    "descriptor": "\nComments: ISSI 2021 - 18th International Conference on Scientometrics & Informetrics, Jul 2021, Leuven, Belgium\n",
    "authors": [
      "Abdelghani Maddi",
      "David Sapinho"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.07348"
  },
  {
    "id": "arXiv:2107.07361",
    "title": "From Reddit to Wall Street: The role of committed minorities in  financial collective action",
    "abstract": "In January 2021, retail investors coordinated on Reddit to target short\nselling activity by hedge funds on GameStop shares, causing a surge in the\nshare price and triggering significant losses for the funds involved. Such an\neffective collective action was unprecedented in finance, and its dynamics\nremain unclear. Here, we analyse Reddit and financial data and rationalise the\nevents based on recent findings describing how a small fraction of committed\nindividuals may trigger behavioural cascades. First, we operationalise the\nconcept of individual commitment in financial discussions. Second, we show that\nthe increase of commitment within Reddit predated the initial surge in price.\nThird, we reveal that initial committed users occupied a central position in\nthe network of Reddit conversations. Finally, we show that the social identity\nof the broader Reddit community grew as the collective action unfolded. These\nfindings shed light on financial collective action, as several observers\nanticipate it will grow in importance.",
    "descriptor": "\nComments: Main: 9 pages, 3 figures, 3 tables. Supplementary: 7 pages, 7 figures\n",
    "authors": [
      "Lorenzo Lucchini",
      "Luca Maria Aiello",
      "Laura Alessandretti",
      "Gianmarco De Francisci Morales",
      "Michele Starnini",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07361"
  },
  {
    "id": "arXiv:2107.07365",
    "title": "Szegedy Walk Unitaries for Quantum Maps",
    "abstract": "Szegedy developed a generic method for quantizing classical algorithms based\non random walks [Proceedings of FOCS, 2004, pp. 32-41]. A major contribution of\nhis work was the construction of a walk unitary for any reversible random walk.\nSuch unitary posses two crucial properties: its eigenvector with eigenphase $0$\nis a quantum sample of the limiting distribution of the random walk and its\neigenphase gap is quadratically larger than the spectral gap of the random\nwalk. It was an open question if it is possible to generalize Szegedy's\nquantization method for stochastic maps to quantum maps. We answer this in the\naffirmative by presenting an explicit construction of a Szegedy walk unitary\nfor detailed balanced Lindbladians -- generators of quantum Markov semigroups\n-- and detailed balanced quantum channels. We prove that our Szegedy walk\nunitary has a purification of the fixed point of the Lindbladian as eigenvector\nwith eigenphase $0$ and that its eigenphase gap is quadratically larger than\nthe spectral gap of the Lindbladian. To construct the walk unitary we leverage\na canonical form for detailed balanced Lindbladians showing that they are\nstructurally related to Davies generators. We also explain how the quantization\nmethod for Lindbladians can be applied to quantum channels. We give an\nefficient quantum algorithm for quantizing Davies generators that describe many\nimportant open-system dynamics, for instance, the relaxation of a quantum\nsystem coupled to a bath. Our algorithm extends known techniques for simulating\nquantum systems on a quantum computer.",
    "descriptor": "",
    "authors": [
      "Pawel Wocjan",
      "Kristan Temme"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07365"
  },
  {
    "id": "arXiv:2107.07368",
    "title": "A note on hyperopic cops and robber",
    "abstract": "We explore a variant of the game of Cops and Robber introduced by Bonato et\nal.~where the robber is invisible unless outside the common neighbourhood of\nthe cops. The hyperopic cop number is analogous to the cop number and we\ninvestigate bounds on this quantity. We define a small common neighbourhood set\nand relate the minimum cardinality of this graph parameter to the hyperopic cop\nnumber. We consider diameter 2 graphs, particularly the join of two graphs, as\nwell as Cartesian products.",
    "descriptor": "",
    "authors": [
      "Nancy E. Clarke",
      "Stephen Finbow",
      "Margaret-Ellen Messinger",
      "Amanda Porter"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.07368"
  },
  {
    "id": "arXiv:2107.07379",
    "title": "Spectral Processing and Optimization of Static and Dynamic 3D Geometries",
    "abstract": "Geometry processing of 3D objects is of primary interest in many areas of\ncomputer vision and graphics, including robot navigation, 3D object\nrecognition, classification, feature extraction, etc. The recent introduction\nof cheap range sensors has created a great interest in many new areas, driving\nthe need for developing efficient algorithms for 3D object processing.\nPreviously, in order to capture a 3D object, expensive specialized sensors were\nused, such as lasers or dedicated range images, but now this limitation has\nchanged. The current approaches of 3D object processing require a significant\namount of manual intervention and they are still time-consuming making them\nunavailable for use in real-time applications. The aim of this thesis is to\npresent algorithms, mainly inspired by the spectral analysis, subspace\ntracking, etc, that can be used and facilitate many areas of low-level 3D\ngeometry processing (i.e., reconstruction, outliers removal, denoising,\ncompression), pattern recognition tasks (i.e., significant features extraction)\nand high-level applications (i.e., registration and identification of 3D\nobjects in partially scanned and cluttered scenes), taking into consideration\ndifferent types of 3D models (i.e., static and dynamic point clouds, static and\ndynamic 3D meshes).",
    "descriptor": "",
    "authors": [
      "Gerasimos Arvanitis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.07379"
  },
  {
    "id": "arXiv:2107.07380",
    "title": "A Linear Dynamical Perspective on Epidemiology: Interplay Between Early  COVID-19 Outbreak and Human Mobility",
    "abstract": "This paper investigates the impact of human activity and mobility (HAM) in\nthe spreading dynamics of an epidemic. Specifically, it explores the\ninterconnections between HAM and its effect on the early spread of the COVID-19\nvirus. During the early stages of the pandemic, effective reproduction numbers\nexhibited a high correlation with human mobility patterns, leading to a\nhypothesis that the HAM system can be studied as a coupled system with disease\nspread dynamics. This study applies the generalized Koopman framework with\ncontrol inputs to determine the nonlinear disease spread dynamics and the\ninput-output characteristics as a locally linear controlled dynamical system.\nThe approach solely relies on the snapshots of spatiotemporal data and does not\nrequire any knowledge of the system's physical laws. We exploit the Koopman\noperator framework by utilizing the Hankel Dynamic Mode Decomposition with\nControl (HDMDc) algorithm to obtain a linear disease spread model incorporating\nhuman mobility as a control input. The study demonstrated that the proposed\nmethodology could capture the impact of local mobility on the early dynamics of\nthe ongoing global pandemic. The obtained locally linear model can accurately\nforecast the number of new infections for various prediction windows ranging\nfrom two to four weeks. The study corroborates a leader-follower relationship\nbetween mobility and disease spread dynamics. In addition, the effect of delay\nembedding in the HDMDc algorithm is also investigated and reported. A case\nstudy was performed using COVID infection data from Florida, US, and HAM data\nextracted from Google community mobility data report.",
    "descriptor": "",
    "authors": [
      "Shakib Mustavee",
      "Shaurya Agarwal",
      "Chinwendu Enyioha",
      "Suddhasattwa Das"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07380"
  },
  {
    "id": "arXiv:2107.07412",
    "title": "Assign Hysteresis Parameter For Ericsson BTS Power Saving Algorithm  Using Unsupervised Learning",
    "abstract": "Gaza Strip suffers from a chronic electricity deficit that affects all\nindustries including the telecommunication field, so there is a need to\noptimize and reduce power consumption of the telecommunication equipment. In\nthis paper we propose a new model that helps GSM radio frequency engineers to\nchoose the optimal value of hysteresis parameter for Ericsson BTS power saving\nalgorithm which aims to switch OFF unused frequency channels, our model is\nbased on unsupervised machine learning clustering K-means algorithm. By using\nour model with BTS power saving algorithm we reduce number of active TRX by\n20.9%.",
    "descriptor": "\nComments: 7 pages, 4 tables, 9 figures\n",
    "authors": [
      "Thaer Sahmoud",
      "Wesam Ashor"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07412"
  },
  {
    "id": "arXiv:2107.07423",
    "title": "Untrained DNN for Channel Estimation of RIS-Assisted Multi-User OFDM  System with Hardware Impairments",
    "abstract": "Reconfigurable intelligent surface (RIS) is an emerging technology for\nimproving performance in fifth-generation (5G) and beyond networks. Practically\nchannel estimation of RIS-assisted systems is challenging due to the passive\nnature of the RIS. The purpose of this paper is to introduce a deep\nlearning-based, low complexity channel estimator for the RIS-assisted\nmulti-user single-input-multiple-output (SIMO) orthogonal frequency division\nmultiplexing (OFDM) system with hardware impairments. We propose an untrained\ndeep neural network (DNN) based on the deep image prior (DIP) network to\ndenoise the effective channel of the system obtained from the conventional\npilot-based least-square (LS) estimation and acquire a more accurate\nestimation. We have shown that our proposed method has high performance in\nterms of accuracy and low complexity compared to conventional methods. Further,\nwe have shown that the proposed estimator is robust to interference caused by\nthe hardware impairments at the transceiver and RIS.",
    "descriptor": "",
    "authors": [
      "Nipuni Ginige",
      "K. B. Shashika Manosha",
      "Nandana Rajatheva",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07423"
  },
  {
    "id": "arXiv:2107.07425",
    "title": "Multiclass Permanent Magnets Superstructure for Indoor Localization  using Artificial Intelligence",
    "abstract": "Smartphones have become a popular tool for indoor localization and position\nestimation of users. Existing solutions mainly employ Wi-Fi, RFID, and magnetic\nsensing techniques to track movements in crowded venues. These are highly\nsensitive to magnetic clutters and depend on local ambient magnetic fields,\nwhich frequently degrades their performance. Also, these techniques often\nrequire pre-known mapping surveys of the area, or the presence of active\nbeacons, which are not always available. We embed small-volume and large-moment\nmagnets in pre-known locations and arrange them in specific geometric\nconstellations that create magnetic superstructure patterns of supervised\nmagnetic signatures. These signatures constitute an unambiguous magnetic\nenvironment with respect to the moving sensor carrier. The localization\nalgorithm learns the unique patterns of the scattered magnets during training\nand detects them from the ongoing streaming of data during localization. Our\ncontribution is twofold. First, we deploy passive permanent magnets that do not\nrequire a power supply, in contrast to active magnetic transmitters. Second, we\nperform localization based on smartphone motion rather than on static\npositioning of the magnetometer. In our previous study, we considered a single\nsuperstructure pattern. Here, we present an extended version of that algorithm\nfor multi-superstructure localization, which covers a broader localization area\nof the user. Experimental results demonstrate localization accuracy of 95% with\na mean localization error of less than 1m using artificial intelligence.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Magnetics\n",
    "authors": [
      "Amir Ivry",
      "Elad Fisher",
      "Roger Alimi",
      "Idan Mosseri",
      "Kanna Nahir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07425"
  },
  {
    "id": "arXiv:2107.07436",
    "title": "FastSHAP: Real-Time Shapley Value Estimation",
    "abstract": "Shapley values are widely used to explain black-box models, but they are\ncostly to calculate because they require many model evaluations. We introduce\nFastSHAP, a method for estimating Shapley values in a single forward pass using\na learned explainer model. FastSHAP amortizes the cost of explaining many\ninputs via a learning approach inspired by the Shapley value's weighted least\nsquares characterization, and it can be trained using standard stochastic\ngradient optimization. We compare FastSHAP to existing estimation approaches,\nrevealing that it generates high-quality explanations with orders of magnitude\nspeedup.",
    "descriptor": "\nComments: 20 pages, 10 figures, 3 tables\n",
    "authors": [
      "Neil Jethani",
      "Mukund Sudarshan",
      "Ian Covert",
      "Su-In Lee",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07436"
  },
  {
    "id": "arXiv:2107.07443",
    "title": "Multi-label Chaining with Imprecise Probabilities",
    "abstract": "We present two different strategies to extend the classical multi-label\nchaining approach to handle imprecise probability estimates. These estimates\nuse convex sets of distributions (or credal sets) in order to describe our\nuncertainty rather than a precise one. The main reasons one could have for\nusing such estimations are (1) to make cautious predictions (or no decision at\nall) when a high uncertainty is detected in the chaining and (2) to make better\nprecise predictions by avoiding biases caused in early decisions in the\nchaining. Through the use of the naive credal classifier, we propose efficient\nprocedures with theoretical justifications to solve both strategies. Our\nexperimental results on missing labels, which investigate how reliable these\npredictions are in both approaches, indicate that our approaches produce\nrelevant cautiousness on those hard-to-predict instances where the precise\nmodels fail.",
    "descriptor": "",
    "authors": [
      "Yonatan Carlos Carranza Alarc\u00f3n",
      "S\u00e9bastien Destercke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07443"
  },
  {
    "id": "arXiv:2107.07468",
    "title": "A modular U-Net for automated segmentation of X-ray tomography images in  composite materials",
    "abstract": "X-ray Computed Tomography (XCT) techniques have evolved to a point that\nhigh-resolution data can be acquired so fast that classic segmentation methods\nare prohibitively cumbersome, demanding automated data pipelines capable of\ndealing with non-trivial 3D images. Deep learning has demonstrated success in\nmany image processing tasks, including material science applications, showing a\npromising alternative for a humanfree segmentation pipeline. In this paper a\nmodular interpretation of UNet (Modular U-Net) is proposed and trained to\nsegment 3D tomography images of a three-phased glass fiber-reinforced Polyamide\n66. We compare 2D and 3D versions of our model, finding that the former is\nslightly better than the latter. We observe that human-comparable results can\nbe achievied even with only 10 annotated layers and using a shallow U-Net\nyields better results than a deeper one. As a consequence, Neural Network (NN)\nshow indeed a promising venue to automate XCT data processing pipelines needing\nno human, adhoc intervention.",
    "descriptor": "\nComments: Submitted to Nature Machine Intelligence\n",
    "authors": [
      "Jo\u00e3o P C Bertoldo",
      "Etienne Decenci\u00e8re",
      "David Ryckelynck",
      "Henry Proudhon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07468"
  },
  {
    "id": "arXiv:2107.07480",
    "title": "Newton-LESS: Sparsification without Trade-offs for the Sketched Newton  Update",
    "abstract": "In second-order optimization, a potential bottleneck can be computing the\nHessian matrix of the optimized function at every iteration. Randomized\nsketching has emerged as a powerful technique for constructing estimates of the\nHessian which can be used to perform approximate Newton steps. This involves\nmultiplication by a random sketching matrix, which introduces a trade-off\nbetween the computational cost of sketching and the convergence rate of the\noptimization algorithm. A theoretically desirable but practically much too\nexpensive choice is to use a dense Gaussian sketching matrix, which produces\nunbiased estimates of the exact Newton step and which offers strong\nproblem-independent convergence guarantees. We show that the Gaussian sketching\nmatrix can be drastically sparsified, significantly reducing the computational\ncost of sketching, without substantially affecting its convergence properties.\nThis approach, called Newton-LESS, is based on a recently introduced sketching\ntechnique: LEverage Score Sparsified (LESS) embeddings. We prove that\nNewton-LESS enjoys nearly the same problem-independent local convergence rate\nas Gaussian embeddings, not just up to constant factors but even down to lower\norder terms, for a large class of optimization tasks. In particular, this leads\nto a new state-of-the-art convergence result for an iterative least squares\nsolver. Finally, we extend LESS embeddings to include uniformly sparsified\nrandom sign matrices which can be implemented efficiently and which perform\nwell in numerical experiments.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Derezi\u0144ski",
      "Jonathan Lacotte",
      "Mert Pilanci",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07480"
  },
  {
    "id": "arXiv:2107.07483",
    "title": "Personalized and Reliable Decision Sets: Enhancing Interpretability in  Clinical Decision Support Systems",
    "abstract": "In this study, we present a novel clinical decision support system and\ndiscuss its interpretability-related properties. It combines a decision set of\nrules with a machine learning scheme to offer global and local\ninterpretability. More specifically, machine learning is used to predict the\nlikelihood of each of those rules to be correct for a particular patient, which\nmay also contribute to better predictive performances. Moreover, the\nreliability analysis of individual predictions is also addressed, contributing\nto further personalized interpretability. The combination of these several\nelements may be crucial to obtain the clinical stakeholders' trust, leading to\na better assessment of patients' conditions and improvement of the physicians'\ndecision-making.",
    "descriptor": "\nComments: Accepted to the ICML 2021 Workshop on Interpretable Machine Learning in Healthcare\n",
    "authors": [
      "Francisco Valente",
      "Sim\u00e3o Paredes",
      "Jorge Henriques"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07483"
  },
  {
    "id": "arXiv:2107.07494",
    "title": "Mid-flight Forecasting for CPA Lines in Online Advertising",
    "abstract": "For Verizon MediaDemand Side Platform(DSP), forecasting of ad campaign\nperformance not only feeds key information to the optimization server to allow\nthe system to operate on a high-performance mode, but also produces actionable\ninsights to the advertisers. In this paper, the forecasting problem for CPA\nlines in the middle of the flight is investigated by taking the bidding\nmechanism into account. The proposed methodology generates relationships\nbetween various key performance metrics and optimization signals. It can also\nbe used to estimate the sensitivity of ad campaign performance metrics to the\nadjustments of optimization signal, which is important to the design of a\ncampaign management system. The relationship between advertiser spends and\neffective Cost Per Action(eCPA) is also characterized, which serves as a\nguidance for mid-flight line adjustment to the advertisers. Several practical\nissues in implementation, such as downsampling of the dataset, are also\ndiscussed in the paper. At last, the forecasting results are validated against\nactual deliveries and demonstrates promising accuracy.",
    "descriptor": "\nComments: 41st International Symposium on Forecasting, June 27-30, 2021\n",
    "authors": [
      "Hao He",
      "Tian Zhou",
      "Lihua Ren",
      "Niklas Karlsson",
      "Aaron Flores"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07494"
  },
  {
    "id": "arXiv:2107.07503",
    "title": "Filtered Noise Shaping for Time Domain Room Impulse Response Estimation  From Reverberant Speech",
    "abstract": "Deep learning approaches have emerged that aim to transform an audio signal\nso that it sounds as if it was recorded in the same room as a reference\nrecording, with applications both in audio post-production and augmented\nreality. In this work, we propose FiNS, a Filtered Noise Shaping network that\ndirectly estimates the time domain room impulse response (RIR) from reverberant\nspeech. Our domain-inspired architecture features a time domain encoder and a\nfiltered noise shaping decoder that models the RIR as a summation of decaying\nfiltered noise signals, along with direct sound and early reflection\ncomponents. Previous methods for acoustic matching utilize either large models\nto transform audio to match the target room or predict parameters for\nalgorithmic reverberators. Instead, blind estimation of the RIR enables\nefficient and realistic transformation with a single convolution. An evaluation\ndemonstrates our model not only synthesizes RIRs that match parameters of the\ntarget room, such as the $T_{60}$ and DRR, but also more accurately reproduces\nperceptual characteristics of the target room, as shown in a listening test\nwhen compared to deep learning baselines.",
    "descriptor": "\nComments: Accepted to WASPAA 2021. See details at this https URL\n",
    "authors": [
      "Christian J. Steinmetz",
      "Vamsi Krishna Ithapu",
      "Paul Calamia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.07503"
  },
  {
    "id": "arXiv:2107.07509",
    "title": "VAD-free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording",
    "abstract": "In this work, we propose novel decoding algorithms to enable streaming\nautomatic speech recognition (ASR) on unsegmented long-form recordings without\nvoice activity detection (VAD), based on monotonic chunkwise attention (MoChA)\nwith an auxiliary connectionist temporal classification (CTC) objective. We\npropose a block-synchronous beam search decoding to take advantage of efficient\nbatched output-synchronous and low-latency input-synchronous searches. We also\npropose a VAD-free inference algorithm that leverages CTC probabilities to\ndetermine a suitable timing to reset the model states to tackle the\nvulnerability to long-form data. Experimental evaluations demonstrate that the\nblock-synchronous decoding achieves comparable accuracy to the\nlabel-synchronous one. Moreover, the VAD-free inference can recognize long-form\nspeech robustly for up to a few hours.",
    "descriptor": "\nComments: Accepted at Interspeech 2021\n",
    "authors": [
      "Hirofumi Inaguma",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.07509"
  },
  {
    "id": "arXiv:1403.6184",
    "title": "The Density of Fan-Planar Graphs",
    "abstract": "Comments: after being informed about a flaw in our original arguments, we add one more forbidden configuration in order to properly arrive at fan-planar graphs",
    "descriptor": "\nComments: after being informed about a flaw in our original arguments, we add one more forbidden configuration in order to properly arrive at fan-planar graphs\n",
    "authors": [
      "Michael Kaufmann",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1403.6184"
  },
  {
    "id": "arXiv:1808.03292",
    "title": "NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo  Workspaces",
    "abstract": "NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo  Workspaces",
    "descriptor": "",
    "authors": [
      "Chathika Gunaratne",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1808.03292"
  },
  {
    "id": "arXiv:1905.05323",
    "title": "Two-stage Estimation for Quantum Detector Tomography: Error Analysis,  Numerical and Experimental Results",
    "abstract": "Comments: 34 pages, 10 figures",
    "descriptor": "\nComments: 34 pages, 10 figures\n",
    "authors": [
      "Yuanlong Wang",
      "Shota Yokoyama",
      "Daoyi Dong",
      "Ian R. Petersen",
      "Elanor H. Huntington",
      "Hidehiro Yonezawa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1905.05323"
  },
  {
    "id": "arXiv:1909.02068",
    "title": "ApproxNet: Content and Contention-Aware Video Analytics System for  Embedded Clients",
    "abstract": "Comments: This paper has been accepted to appear in ACM Transactions on Sensor Networks in 2021",
    "descriptor": "\nComments: This paper has been accepted to appear in ACM Transactions on Sensor Networks in 2021\n",
    "authors": [
      "Ran Xu",
      "Rakesh Kumar",
      "Pengcheng Wang",
      "Peter Bai",
      "Ganga Meghanath",
      "Somali Chaterji",
      "Subrata Mitra",
      "Saurabh Bagchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1909.02068"
  },
  {
    "id": "arXiv:1910.06026",
    "title": "Symplectic model reduction methods for the Vlasov equation",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Tomasz M. Tyranowski",
      "Michael Kraus"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/1910.06026"
  },
  {
    "id": "arXiv:1911.02161",
    "title": "Exact Partitioning of High-order Models with a Novel Convex Tensor Cone  Relaxation",
    "abstract": "Exact Partitioning of High-order Models with a Novel Convex Tensor Cone  Relaxation",
    "descriptor": "",
    "authors": [
      "Chuyang Ke",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.02161"
  },
  {
    "id": "arXiv:1911.07306",
    "title": "Quantum Speedup for Graph Sparsification, Cut Approximation and  Laplacian Solving",
    "abstract": "Comments: v2: several small improvements to the text. An extended abstract will appear in FOCS'20; v3: corrected a minor mistake in Appendix A",
    "descriptor": "\nComments: v2: several small improvements to the text. An extended abstract will appear in FOCS'20; v3: corrected a minor mistake in Appendix A\n",
    "authors": [
      "Simon Apers",
      "Ronald de Wolf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1911.07306"
  },
  {
    "id": "arXiv:2001.09461",
    "title": "The SPECIAL-K Personal Data Processing Transparency and Compliance  Platform",
    "abstract": "The SPECIAL-K Personal Data Processing Transparency and Compliance  Platform",
    "descriptor": "",
    "authors": [
      "Sabrina Kirrane",
      "Javier D. Fern\u00e1ndez",
      "Piero Bonatti",
      "Uros Milosevic",
      "Axel Polleres",
      "Rigo Wenning"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2001.09461"
  },
  {
    "id": "arXiv:2002.00865",
    "title": "Designing GANs: A Likelihood Ratio Approach",
    "abstract": "Comments: Accepted to \"The Joint International Conference on Neural Networks (IJCNN 2021)\"",
    "descriptor": "\nComments: Accepted to \"The Joint International Conference on Neural Networks (IJCNN 2021)\"\n",
    "authors": [
      "Kalliopi Basioti",
      "George V. Moustakides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00865"
  },
  {
    "id": "arXiv:2003.05383",
    "title": "xCos: An Explainable Cosine Metric for Face Verification Task",
    "abstract": "Comments: ACM Transactions on Multimedia Computing Communications and Applications (TOMM). 2021",
    "descriptor": "\nComments: ACM Transactions on Multimedia Computing Communications and Applications (TOMM). 2021\n",
    "authors": [
      "Yu-Sheng Lin",
      "Zhe-Yu Liu",
      "Yu-An Chen",
      "Yu-Siang Wang",
      "Ya-Liang Chang",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2003.05383"
  },
  {
    "id": "arXiv:2003.07982",
    "title": "Adversarial Transferability in Wearable Sensor Systems",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Ramesh Kumar Sah",
      "Hassan Ghasemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.07982"
  },
  {
    "id": "arXiv:2004.00279",
    "title": "Statistical Verification of Autonomous Systems using Surrogate Models  and Conformal Inference",
    "abstract": "Statistical Verification of Autonomous Systems using Surrogate Models  and Conformal Inference",
    "descriptor": "",
    "authors": [
      "Chuchu Fan",
      "Xin Qin",
      "Yuan Xia",
      "Aditya Zutshi",
      "Jyotirmoy Deshmukh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.00279"
  },
  {
    "id": "arXiv:2004.11094",
    "title": "Consistent Online Gaussian Process Regression Without the Sample  Complexity Bottleneck",
    "abstract": "Consistent Online Gaussian Process Regression Without the Sample  Complexity Bottleneck",
    "descriptor": "",
    "authors": [
      "Alec Koppel",
      "Hrusikesha Pradhan",
      "Ketan Rajawat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2004.11094"
  },
  {
    "id": "arXiv:2005.00054",
    "title": "APo-VAE: Text Generation in Hyperbolic Space",
    "abstract": "APo-VAE: Text Generation in Hyperbolic Space",
    "descriptor": "",
    "authors": [
      "Shuyang Dai",
      "Zhe Gan",
      "Yu Cheng",
      "Chenyang Tao",
      "Lawrence Carin",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00054"
  },
  {
    "id": "arXiv:2005.09028",
    "title": "Sham: A DSL for Fast DSLs",
    "abstract": "Sham: A DSL for Fast DSLs",
    "descriptor": "",
    "authors": [
      "Rajan Walia",
      "Chung-chieh Shan",
      "Sam Tobin-Hochstadt"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2005.09028"
  },
  {
    "id": "arXiv:2005.12604",
    "title": "An adaptive block Bregman proximal gradient method for computing  stationary states of multicomponent phase-field crystal model",
    "abstract": "Comments: 38 pages, 9 figures",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "Chenglong Bao",
      "Chang Chen",
      "Kai Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.12604"
  },
  {
    "id": "arXiv:2006.00165",
    "title": "Cyber LOPA: An Integrated Approach for the Design of Dependable and  Secure Cyber Physical Systems",
    "abstract": "Comments: Main Content: Title adjusted, Related work moved to end, added references, Sec IV (prev. sec V): expanded discussion, design and Alg. 1 updated | Sec V (prev. sec VI): Expanded discussion, Table V Expanded. Editorial: Fig 1 redrawn horiz., Eq (4)(5) math notation changed, same content. Eq (25) expanded, Page-wide eq. not ref as fig (shift by 1 of fig num), Fig 4 iterative design values shown",
    "descriptor": "\nComments: Main Content: Title adjusted, Related work moved to end, added references, Sec IV (prev. sec V): expanded discussion, design and Alg. 1 updated | Sec V (prev. sec VI): Expanded discussion, Table V Expanded. Editorial: Fig 1 redrawn horiz., Eq (4)(5) math notation changed, same content. Eq (25) expanded, Page-wide eq. not ref as fig (shift by 1 of fig num), Fig 4 iterative design values shown\n",
    "authors": [
      "Ashraf Tantawy",
      "Sherif Abdelwahed",
      "Abdelkarim Erradi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.00165"
  },
  {
    "id": "arXiv:2006.08177",
    "title": "Dissimilarity Mixture Autoencoder for Deep Clustering",
    "abstract": "Comments: 20 pages (2.5 pages of references)",
    "descriptor": "\nComments: 20 pages (2.5 pages of references)\n",
    "authors": [
      "Juan S. Lara",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08177"
  },
  {
    "id": "arXiv:2006.16098",
    "title": "An Investigation of Traffic Density Changes inside Wuhan during the  COVID-19 Epidemic with GF-2 Time-Series Images",
    "abstract": "Comments: 35 pages, 9 figures, submitted to International Journal of Applied Earth Observation and Geoinformation",
    "descriptor": "\nComments: 35 pages, 9 figures, submitted to International Journal of Applied Earth Observation and Geoinformation\n",
    "authors": [
      "Chen Wu",
      "Yinong Guo",
      "Haonan Guo",
      "Jingwen Yuan",
      "Lixiang Ru",
      "Hongruixuan Chen",
      "Bo Du",
      "Liangpei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.16098"
  },
  {
    "id": "arXiv:2007.10915",
    "title": "Wireless Image Retrieval at the Edge",
    "abstract": "Wireless Image Retrieval at the Edge",
    "descriptor": "",
    "authors": [
      "Mikolaj Jankowski",
      "Deniz Gunduz",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.10915"
  },
  {
    "id": "arXiv:2007.11427",
    "title": "Formal Analysis of EDHOC Key Establishment for Constrained IoT Devices",
    "abstract": "Comments: 12 pages; version 3 is the version accepted to SECRYPT 2021",
    "descriptor": "\nComments: 12 pages; version 3 is the version accepted to SECRYPT 2021\n",
    "authors": [
      "Karl Norrman",
      "Vaishnavi Sundararajan",
      "Alessandro Bruni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.11427"
  },
  {
    "id": "arXiv:2007.11839",
    "title": "A Guideline on Pseudorandom Number Generation (PRNG) in the IoT",
    "abstract": "Comments: 43 pages, 11 figures, 11 tables",
    "descriptor": "\nComments: 43 pages, 11 figures, 11 tables\n",
    "authors": [
      "Peter Kietzmann",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2007.11839"
  },
  {
    "id": "arXiv:2007.15847",
    "title": "A Functional Model for Structure Learning and Parameter Estimation in  Continuous Time Bayesian Network: An Application in Identifying Patterns of  Multiple Chronic Conditions",
    "abstract": "Comments: Submitted to IEEE Access for review",
    "descriptor": "\nComments: Submitted to IEEE Access for review\n",
    "authors": [
      "Syed Hasib Akhter Faruqui",
      "Adel Alaeddini",
      "Jing Wang",
      "Carlos A. Jaramillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.15847"
  },
  {
    "id": "arXiv:2008.00394",
    "title": "Point Cloud Completion by Learning Shape Priors",
    "abstract": "Comments: IROS 2020",
    "descriptor": "\nComments: IROS 2020\n",
    "authors": [
      "Xiaogang Wang",
      "Marcelo H Ang Jr",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.00394"
  },
  {
    "id": "arXiv:2008.01627",
    "title": "SL1-Simplex: Safe Velocity Regulation of Self-Driving Vehicles in  Dynamic and Unforeseen Environments",
    "abstract": "Comments: Submitted to ACM Transactions on Cyber-Physical Systems",
    "descriptor": "\nComments: Submitted to ACM Transactions on Cyber-Physical Systems\n",
    "authors": [
      "Yanbing Mao",
      "Yuliang Gu",
      "Naira Hovakimyan",
      "Lui Sha",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.01627"
  },
  {
    "id": "arXiv:2008.02766",
    "title": "Assessing the (Un)Trustworthiness of Saliency Maps for Localizing  Abnormalities in Medical Imaging",
    "abstract": "Comments: Submitted to Radiology AI journal",
    "descriptor": "\nComments: Submitted to Radiology AI journal\n",
    "authors": [
      "Nishanth Arun",
      "Nathan Gaw",
      "Praveer Singh",
      "Ken Chang",
      "Mehak Aggarwal",
      "Bryan Chen",
      "Katharina Hoebel",
      "Sharut Gupta",
      "Jay Patel",
      "Mishka Gidwani",
      "Julius Adebayo",
      "Matthew D. Li",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.02766"
  },
  {
    "id": "arXiv:2009.03887",
    "title": "Low-Rank Training of Deep Neural Networks for Emerging Memory Technology",
    "abstract": "Low-Rank Training of Deep Neural Networks for Emerging Memory Technology",
    "descriptor": "",
    "authors": [
      "Albert Gural",
      "Phillip Nadeau",
      "Mehul Tikekar",
      "Boris Murmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03887"
  },
  {
    "id": "arXiv:2009.05722",
    "title": "Generator Versus Segmentor: Pseudo-healthy Synthesis",
    "abstract": "Comments: Accepted by MICCAI2021",
    "descriptor": "\nComments: Accepted by MICCAI2021\n",
    "authors": [
      "Zhang Yunlong",
      "Li Chenxin",
      "Lin Xin",
      "Sun Liyan",
      "Zhuang Yihong",
      "Huang Yue",
      "Ding Xinghao",
      "Liu Xiaoqing",
      "Yu Yizhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.05722"
  },
  {
    "id": "arXiv:2009.05823",
    "title": "On Achieving Fairness and Stability in Many-to-One Matchings",
    "abstract": "On Achieving Fairness and Stability in Many-to-One Matchings",
    "descriptor": "",
    "authors": [
      "Shivika Narang",
      "Arpita Biswas",
      "Y Narahari"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.05823"
  },
  {
    "id": "arXiv:2009.09066",
    "title": "Vehicle Class, Speed, and Roadway Geometry Based Driver Behavior  Identification and Classification",
    "abstract": "Vehicle Class, Speed, and Roadway Geometry Based Driver Behavior  Identification and Classification",
    "descriptor": "",
    "authors": [
      "Awad Abdelhalim",
      "Montasir Abbas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2009.09066"
  },
  {
    "id": "arXiv:2010.07249",
    "title": "Environment Inference for Invariant Learning",
    "abstract": "Environment Inference for Invariant Learning",
    "descriptor": "",
    "authors": [
      "Elliot Creager",
      "J\u00f6rn-Henrik Jacobsen",
      "Richard Zemel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.07249"
  },
  {
    "id": "arXiv:2010.09112",
    "title": "BBB-Voting: 1-out-of-k Blockchain-Based Boardroom Voting",
    "abstract": "BBB-Voting: 1-out-of-k Blockchain-Based Boardroom Voting",
    "descriptor": "",
    "authors": [
      "Sarad Venugopalan",
      "Ivan Homoliak",
      "Zengpeng Li",
      "Pawel Szalachowski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.09112"
  },
  {
    "id": "arXiv:2010.10341",
    "title": "Learning to Learn Variational Semantic Memory",
    "abstract": "Comments: accepted to NeurIPS 2020; code is available in this https URL",
    "descriptor": "\nComments: accepted to NeurIPS 2020; code is available in this https URL\n",
    "authors": [
      "Xiantong Zhen",
      "Yingjun Du",
      "Huan Xiong",
      "Qiang Qiu",
      "Cees G. M. Snoek",
      "Ling Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10341"
  },
  {
    "id": "arXiv:2010.10580",
    "title": "Causal Understanding of Fake News Dissemination on Social Media",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Lu Cheng",
      "Ruocheng Guo",
      "Kai Shu",
      "Huan Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2010.10580"
  },
  {
    "id": "arXiv:2010.11448",
    "title": "Parallel Algorithms and Heuristics for Efficient Computation of  High-Order Line Graphs of Hypergraphs",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Xu T. Liu",
      "Jesun Firoz",
      "Andrew Lumsdaine",
      "Cliff Joslyn",
      "Sinan Aksoy",
      "Brenda Praggastis",
      "Assefaw Gebremedhin"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2010.11448"
  },
  {
    "id": "arXiv:2010.12733",
    "title": "Learning Fine-Grained Cross Modality Excitement for Speech Emotion  Recognition",
    "abstract": "Comments: The Interspeech Conference, 2021 (INTERSPEECH 2021)",
    "descriptor": "\nComments: The Interspeech Conference, 2021 (INTERSPEECH 2021)\n",
    "authors": [
      "Hang Li",
      "Wenbiao Ding",
      "Zhongqin Wu",
      "Zitao Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.12733"
  },
  {
    "id": "arXiv:2011.06572",
    "title": "Relative Lipschitzness in Extragradient Methods and a Direct Recipe for  Acceleration",
    "abstract": "Comments: 32 pages. This is the full version of a paper appearing in ITCS 2021. v2 addresses reviewer comments and adds citations",
    "descriptor": "\nComments: 32 pages. This is the full version of a paper appearing in ITCS 2021. v2 addresses reviewer comments and adds citations\n",
    "authors": [
      "Michael B. Cohen",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06572"
  },
  {
    "id": "arXiv:2011.07669",
    "title": "An exact sin$\u0398$ formula for matrix perturbation analysis and its  applications",
    "abstract": "An exact sin$\u0398$ formula for matrix perturbation analysis and its  applications",
    "descriptor": "",
    "authors": [
      "He Lyu",
      "Rongrong Wang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.07669"
  },
  {
    "id": "arXiv:2011.13564",
    "title": "Intellectual Property Protection for Deep Learning Models: Taxonomy,  Methods, Attacks, and Evaluations",
    "abstract": "Intellectual Property Protection for Deep Learning Models: Taxonomy,  Methods, Attacks, and Evaluations",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Yushu Zhang",
      "Jian Wang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.13564"
  },
  {
    "id": "arXiv:2012.00585",
    "title": "A flexible sparse matrix data format and parallel algorithms for the  assembly of sparse matrices in general finite element applications using  atomic synchronisation primitives",
    "abstract": "A flexible sparse matrix data format and parallel algorithms for the  assembly of sparse matrices in general finite element applications using  atomic synchronisation primitives",
    "descriptor": "",
    "authors": [
      "Adam Sky",
      "C\u00e9sar Polindara",
      "Ingo Muench",
      "Carolin Birk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2012.00585"
  },
  {
    "id": "arXiv:2012.12368",
    "title": "Understanding Frank-Wolfe Adversarial Training",
    "abstract": "Comments: Accepted to ICML 2021 Adversarial Machine Learning Workshop. Under review",
    "descriptor": "\nComments: Accepted to ICML 2021 Adversarial Machine Learning Workshop. Under review\n",
    "authors": [
      "Theodoros Tsiligkaridis",
      "Jay Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.12368"
  },
  {
    "id": "arXiv:2012.14261",
    "title": "A Survey on Neural Network Interpretability",
    "abstract": "Comments: This work has been accepted by IEEE-TETCI",
    "descriptor": "\nComments: This work has been accepted by IEEE-TETCI\n",
    "authors": [
      "Yu Zhang",
      "Peter Ti\u0148o",
      "Ale\u0161 Leonardis",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.14261"
  },
  {
    "id": "arXiv:2012.14861",
    "title": "Linearized trinomials with maximum kernel",
    "abstract": "Comments: Accepted for publication in Journal of Pure and Applied Algebra",
    "descriptor": "\nComments: Accepted for publication in Journal of Pure and Applied Algebra\n",
    "authors": [
      "Paolo Santonastaso",
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.14861"
  },
  {
    "id": "arXiv:2101.06562",
    "title": "Asynchronous Multi-View SLAM",
    "abstract": "Comments: 25 pages, 23 figures, 13 tables",
    "descriptor": "\nComments: 25 pages, 23 figures, 13 tables\n",
    "authors": [
      "Anqi Joyce Yang",
      "Can Cui",
      "Ioan Andrei B\u00e2rsan",
      "Raquel Urtasun",
      "Shenlong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06562"
  },
  {
    "id": "arXiv:2101.08757",
    "title": "Expectation-Maximization Regularized Deep Learning for Weakly Supervised  Tumor Segmentation for Glioblastoma",
    "abstract": "Expectation-Maximization Regularized Deep Learning for Weakly Supervised  Tumor Segmentation for Glioblastoma",
    "descriptor": "",
    "authors": [
      "Chao Li",
      "Wenjian Huang",
      "Xi Chen",
      "Yiran Wei",
      "Stephen J. Price",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2101.08757"
  },
  {
    "id": "arXiv:2101.10072",
    "title": "Agents.jl: A performant and feature-full agent based modelling software  of minimal code complexity",
    "abstract": "Agents.jl: A performant and feature-full agent based modelling software  of minimal code complexity",
    "descriptor": "",
    "authors": [
      "George Datseris",
      "Ali R. Vahdati",
      "Timothy C. DuBois"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2101.10072"
  },
  {
    "id": "arXiv:2101.10549",
    "title": "Robust and Secure Sum-Rate Maximization for Multiuser MISO Downlink  Systems with Self-sustainable IRS",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2005.11663",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2005.11663\n",
    "authors": [
      "Shaokang Hu",
      "Zhiqiang Wei",
      "Yuanxin Cai",
      "Chang Liu",
      "Derrick Wing Kwan Ng",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.10549"
  },
  {
    "id": "arXiv:2101.11787",
    "title": "Joint Transmission Scheme and Coded Content Placement in Cluster-centric  UAV-aided Cellular Networks",
    "abstract": "Joint Transmission Scheme and Coded Content Placement in Cluster-centric  UAV-aided Cellular Networks",
    "descriptor": "",
    "authors": [
      "Zohreh HajiAkhondi-Meybodi",
      "Arash Mohammadi",
      "Jamshid Abouei",
      "Ming Hou",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Multimedia (cs.MM)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.11787"
  },
  {
    "id": "arXiv:2101.12684",
    "title": "Modelling Sovereign Credit Ratings: Evaluating the Accuracy and Driving  Factors using Machine Learning Techniques",
    "abstract": "Modelling Sovereign Credit Ratings: Evaluating the Accuracy and Driving  Factors using Machine Learning Techniques",
    "descriptor": "",
    "authors": [
      "Bart H.L. Overes",
      "Michel van der Wel"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12684"
  },
  {
    "id": "arXiv:2102.00760",
    "title": "Fast rates in structured prediction",
    "abstract": "Comments: 14 main pages, 3 main figures, 43 pages, 4 figures (with appendix)",
    "descriptor": "\nComments: 14 main pages, 3 main figures, 43 pages, 4 figures (with appendix)\n",
    "authors": [
      "Vivien Cabannes",
      "Alessandro Rudi",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.00760"
  },
  {
    "id": "arXiv:2102.01200",
    "title": "Group Testing in the High Dilution Regime",
    "abstract": "Group Testing in the High Dilution Regime",
    "descriptor": "",
    "authors": [
      "Gabriel Arpino",
      "Nicol\u00f2 Grometto",
      "Afonso S. Bandeira"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.01200"
  },
  {
    "id": "arXiv:2102.02789",
    "title": "Disambiguation of weak supervision with exponential convergence rates",
    "abstract": "Comments: 22 pages; 6 figures",
    "descriptor": "\nComments: 22 pages; 6 figures\n",
    "authors": [
      "Vivien Cabannes",
      "Francis Bach",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02789"
  },
  {
    "id": "arXiv:2102.03893",
    "title": "Enhancement of Distribution System State Estimation Using Pruned  Physics-Aware Neural Networks",
    "abstract": "Enhancement of Distribution System State Estimation Using Pruned  Physics-Aware Neural Networks",
    "descriptor": "",
    "authors": [
      "Minh-Quan Tran",
      "Ahmed S. Zamzam",
      "Phuong H. Nguyen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.03893"
  },
  {
    "id": "arXiv:2102.06607",
    "title": "Intelligent Software Web Agents: A Gap Analysis",
    "abstract": "Intelligent Software Web Agents: A Gap Analysis",
    "descriptor": "",
    "authors": [
      "Sabrina Kirrane"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.06607"
  },
  {
    "id": "arXiv:2102.07342",
    "title": "The Phase Transition of Discrepancy in Random Hypergraphs",
    "abstract": "The Phase Transition of Discrepancy in Random Hypergraphs",
    "descriptor": "",
    "authors": [
      "Calum MacRury",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Leilani Pai",
      "Xavier P\u00e9rez-Gim\u00e9nez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.07342"
  },
  {
    "id": "arXiv:2102.08864",
    "title": "Automated Test-Case Generation for Solidity Smart Contracts: the AGSolT  Approach and its Evaluation",
    "abstract": "Comments: Currently under review at IEEE Transactions on Services Computing",
    "descriptor": "\nComments: Currently under review at IEEE Transactions on Services Computing\n",
    "authors": [
      "Stefan Driessen",
      "Dario Di Nucci",
      "Geert Monsieur",
      "Willem-Jan van den Heuvel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.08864"
  },
  {
    "id": "arXiv:2102.11658",
    "title": "A Goodness-of-fit Test on the Number of Biclusters in a Relational Data  Matrix",
    "abstract": "A Goodness-of-fit Test on the Number of Biclusters in a Relational Data  Matrix",
    "descriptor": "",
    "authors": [
      "Chihiro Watanabe",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11658"
  },
  {
    "id": "arXiv:2102.12351",
    "title": "Approximability of all Boolean CSPs in the dynamic streaming setting",
    "abstract": "Approximability of all Boolean CSPs in the dynamic streaming setting",
    "descriptor": "",
    "authors": [
      "Chi-Ning Chou",
      "Alexander Golovnev",
      "Madhu Sudan",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.12351"
  },
  {
    "id": "arXiv:2103.00022",
    "title": "Synthesizing Safe and Efficient Kernel Extensions for Packet Processing",
    "abstract": "Synthesizing Safe and Efficient Kernel Extensions for Packet Processing",
    "descriptor": "",
    "authors": [
      "Qiongwen Xu",
      "Michael D. Wong",
      "Tanvi Wagle",
      "Srinivas Narayana",
      "Anirudh Sivaraman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.00022"
  },
  {
    "id": "arXiv:2103.01114",
    "title": "Deep Perceptual Image Quality Assessment for Compression",
    "abstract": "Deep Perceptual Image Quality Assessment for Compression",
    "descriptor": "",
    "authors": [
      "Juan Carlos Mier",
      "Eddie Huang",
      "Hossein Talebi",
      "Feng Yang",
      "Peyman Milanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.01114"
  },
  {
    "id": "arXiv:2103.02512",
    "title": "Approximation Algorithms for Socially Fair Clustering",
    "abstract": "Comments: COLT 2021",
    "descriptor": "\nComments: COLT 2021\n",
    "authors": [
      "Yury Makarychev",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.02512"
  },
  {
    "id": "arXiv:2103.02644",
    "title": "Compute and memory efficient universal sound source separation",
    "abstract": "Comments: Accepted to Journal of Signal Processing Systems this https URL arXiv admin note: substantial text overlap with arXiv:2007.06833",
    "descriptor": "\nComments: Accepted to Journal of Signal Processing Systems this https URL arXiv admin note: substantial text overlap with arXiv:2007.06833\n",
    "authors": [
      "Efthymios Tzinis",
      "Zhepei Wang",
      "Xilin Jiang",
      "Paris Smaragdis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.02644"
  },
  {
    "id": "arXiv:2103.04150",
    "title": "Signal Processing on the Permutahedron: Tight Spectral Frames for Ranked  Data Analysis",
    "abstract": "Signal Processing on the Permutahedron: Tight Spectral Frames for Ranked  Data Analysis",
    "descriptor": "",
    "authors": [
      "Yilin Chen",
      "Jennifer DeJong",
      "Tom Halverson",
      "David I Shuman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2103.04150"
  },
  {
    "id": "arXiv:2103.07534",
    "title": "S2AND: A Benchmark and Evaluation System for Author Name Disambiguation",
    "abstract": "S2AND: A Benchmark and Evaluation System for Author Name Disambiguation",
    "descriptor": "",
    "authors": [
      "Shivashankar Subramanian",
      "Daniel King",
      "Doug Downey",
      "Sergey Feldman"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.07534"
  },
  {
    "id": "arXiv:2103.08573",
    "title": "RoRD: Rotation-Robust Descriptors and Orthographic Views for Local  Feature Matching",
    "abstract": "Comments: Accepted to IROS 2021. Project Page: this https URL",
    "descriptor": "\nComments: Accepted to IROS 2021. Project Page: this https URL\n",
    "authors": [
      "Udit Singh Parihar",
      "Aniket Gujarathi",
      "Kinal Mehta",
      "Satyajit Tourani",
      "Sourav Garg",
      "Michael Milford",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.08573"
  },
  {
    "id": "arXiv:2103.08850",
    "title": "Few Shot System Identification for Reinforcement Learning",
    "abstract": "Few Shot System Identification for Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Karim Farid",
      "Nourhan Sakr"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.08850"
  },
  {
    "id": "arXiv:2103.10620",
    "title": "Towards a Dimension-Free Understanding of Adaptive Linear Control",
    "abstract": "Comments: presented at COLT 2021",
    "descriptor": "\nComments: presented at COLT 2021\n",
    "authors": [
      "Juan C. Perdomo",
      "Max Simchowitz",
      "Alekh Agarwal",
      "Peter Bartlett"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.10620"
  },
  {
    "id": "arXiv:2103.11341",
    "title": "Parameterised-Response Zero-Intelligence Traders",
    "abstract": "Comments: 39 pages, 18 figures, 67 references",
    "descriptor": "\nComments: 39 pages, 18 figures, 67 references\n",
    "authors": [
      "Dave Cliff"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2103.11341"
  },
  {
    "id": "arXiv:2103.11641",
    "title": "iRotate: Active Visual SLAM for Omnidirectional Robots",
    "abstract": "Comments: 10 pages, 11 figures, 3 tables. Submitted to RAS",
    "descriptor": "\nComments: 10 pages, 11 figures, 3 tables. Submitted to RAS\n",
    "authors": [
      "Elia Bonetto",
      "Pascal Goldschmid",
      "Michael Pabst",
      "Michael J. Black",
      "Aamir Ahmad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.11641"
  },
  {
    "id": "arXiv:2103.11850",
    "title": "Triage and diagnosis of COVID-19 from medical social media",
    "abstract": "Comments: 13 pages, 6 figrues",
    "descriptor": "\nComments: 13 pages, 6 figrues\n",
    "authors": [
      "Abul Hasan",
      "Mark Levene",
      "David Weston",
      "Renate Fromson",
      "Nicolas Koslover",
      "Tamara Levene"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.11850"
  },
  {
    "id": "arXiv:2103.14917",
    "title": "Reinforcement Learning Random Access for Delay-Constrained Heterogeneous  Wireless Networks: A Two-User Case",
    "abstract": "Reinforcement Learning Random Access for Delay-Constrained Heterogeneous  Wireless Networks: A Two-User Case",
    "descriptor": "",
    "authors": [
      "Danzhou Wu",
      "Lei Deng",
      "Zilong Liu",
      "Yijin Zhang",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.14917"
  },
  {
    "id": "arXiv:2104.01708",
    "title": "A unified framework for non-negative matrix and tensor factorisations  with a smoothed Wasserstein loss",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Stephen Y. Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.01708"
  },
  {
    "id": "arXiv:2104.05771",
    "title": "Online Weighted Matching with a Sample",
    "abstract": "Comments: 31 pages, 2 figures",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Haim Kaplan",
      "David Naori",
      "Danny Raz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.05771"
  },
  {
    "id": "arXiv:2104.07395",
    "title": "Robust Backdoor Attacks against Deep Neural Networks in Real Physical  World",
    "abstract": "Robust Backdoor Attacks against Deep Neural Networks in Real Physical  World",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Can He",
      "Shichang Sun",
      "Jian Wang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07395"
  },
  {
    "id": "arXiv:2104.11452",
    "title": "SportsCap: Monocular 3D Human Motion Capture and Fine-grained  Understanding in Challenging Sports Videos",
    "abstract": "Comments: 18 pages, 13 figures",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Xin Chen",
      "Anqi Pang",
      "Wei Yang",
      "Yuexin Ma",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11452"
  },
  {
    "id": "arXiv:2104.12984",
    "title": "Accelerating Coordinate Descent via Active Set Selection for Device  Activity Detection for Multi-Cell Massive Random Access",
    "abstract": "Comments: 5 pages, 3 figures, accepted for publication in IEEE SPAWC 2021",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted for publication in IEEE SPAWC 2021\n",
    "authors": [
      "Ziyue Wang",
      "Ya-Feng Liu",
      "Zhilin Chen",
      "Wei Yu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.12984"
  },
  {
    "id": "arXiv:2104.13069",
    "title": "Visualization of Linear Operations in the Spherical Harmonics Domain",
    "abstract": "Comments: Pre-print of accepted paper at International Conference on Immersive and 3D Audio 2021 (I3DA)",
    "descriptor": "\nComments: Pre-print of accepted paper at International Conference on Immersive and 3D Audio 2021 (I3DA)\n",
    "authors": [
      "Maximilian Kentgens",
      "Peter Jax"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.13069"
  },
  {
    "id": "arXiv:2105.00287",
    "title": "The complexity of approximating the complex-valued Ising model on  bounded degree graphs",
    "abstract": "Comments: 49 pages, 9 figures",
    "descriptor": "\nComments: 49 pages, 9 figures\n",
    "authors": [
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Andr\u00e9s Herrera-Poyatos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.00287"
  },
  {
    "id": "arXiv:2105.01785",
    "title": "An Optimal Algorithm for Triangle Counting in the Stream",
    "abstract": "Comments: Title changed and some minor edits",
    "descriptor": "\nComments: Title changed and some minor edits\n",
    "authors": [
      "Rajesh Jayaram",
      "John Kallaugher"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.01785"
  },
  {
    "id": "arXiv:2105.01830",
    "title": "Contemporary COBOL: Developers' Perspectives on Defects and Defect  Location",
    "abstract": "Contemporary COBOL: Developers' Perspectives on Defects and Defect  Location",
    "descriptor": "",
    "authors": [
      "Agnieszka Ciborowska",
      "Aleksandar Chakarov",
      "Rahul Pandita"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.01830"
  },
  {
    "id": "arXiv:2105.02363",
    "title": "Universal Algorithms for Clustering Problems",
    "abstract": "Comments: Appeared in ICALP 2021, Track A. Fixed mismatch between paper title and arXiv title",
    "descriptor": "\nComments: Appeared in ICALP 2021, Track A. Fixed mismatch between paper title and arXiv title\n",
    "authors": [
      "Arun Ganesh",
      "Bruce M. Maggs",
      "Debmalya Panigrahi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.02363"
  },
  {
    "id": "arXiv:2105.02579",
    "title": "MCMC-driven importance samplers",
    "abstract": "MCMC-driven importance samplers",
    "descriptor": "",
    "authors": [
      "F. Llorente",
      "E. Curbelo",
      "L. Martino",
      "V. Elvira",
      "D. Delgado"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02579"
  },
  {
    "id": "arXiv:2105.02722",
    "title": "Mutual Visibility in Graphs",
    "abstract": "Comments: Added comparisons with general position set and general position number concepts. Results achieved in the first version are still valid, but sometime refined. Added new references. 23 pages, 6 figures",
    "descriptor": "\nComments: Added comparisons with general position set and general position number concepts. Results achieved in the first version are still valid, but sometime refined. Added new references. 23 pages, 6 figures\n",
    "authors": [
      "Gabriele Di Stefano"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.02722"
  },
  {
    "id": "arXiv:2105.02914",
    "title": "Self-Replication via Tile Self-Assembly (extended abstract)",
    "abstract": "Comments: Updated to include changes reflecting reviewer comments",
    "descriptor": "\nComments: Updated to include changes reflecting reviewer comments\n",
    "authors": [
      "Andrew Alseth",
      "Daniel Hader",
      "Matthew J. Patitz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2105.02914"
  },
  {
    "id": "arXiv:2105.04030",
    "title": "A Bit More Bayesian: Domain-Invariant Learning with Uncertainty",
    "abstract": "Comments: accepted to ICML 2021",
    "descriptor": "\nComments: accepted to ICML 2021\n",
    "authors": [
      "Zehao Xiao",
      "Jiayi Shen",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04030"
  },
  {
    "id": "arXiv:2105.04170",
    "title": "AutoDebias: Learning to Debias for Recommendation",
    "abstract": "Comments: Accepted by SIGIR 2021",
    "descriptor": "\nComments: Accepted by SIGIR 2021\n",
    "authors": [
      "Jiawei Chen",
      "Hande Dong",
      "Yang Qiu",
      "Xiangnan He",
      "Xin Xin",
      "Liang Chen",
      "Guli Lin",
      "Keping Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04170"
  },
  {
    "id": "arXiv:2105.04727",
    "title": "Separate but Together: Unsupervised Federated Learning for Speech  Enhancement from Non-IID Data",
    "abstract": "Comments: Accepted to WASPAA 21",
    "descriptor": "\nComments: Accepted to WASPAA 21\n",
    "authors": [
      "Efthymios Tzinis",
      "Jonah Casebeer",
      "Zhepei Wang",
      "Paris Smaragdis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04727"
  },
  {
    "id": "arXiv:2105.06081",
    "title": "Gradual Program Analysis for Null Pointers",
    "abstract": "Comments: 31 pages, 12 figures, published in ECOOP 2021",
    "descriptor": "\nComments: 31 pages, 12 figures, published in ECOOP 2021\n",
    "authors": [
      "Sam Estep",
      "Jenna Wise",
      "Jonathan Aldrich",
      "\u00c9ric Tanter",
      "Johannes Bader",
      "Joshua Sunshine"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.06081"
  },
  {
    "id": "arXiv:2105.09232",
    "title": "Diffusion Approximations for Thompson Sampling",
    "abstract": "Diffusion Approximations for Thompson Sampling",
    "descriptor": "",
    "authors": [
      "Lin Fan",
      "Peter W. Glynn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.09232"
  },
  {
    "id": "arXiv:2105.11229",
    "title": "FaaSNet: Scalable and Fast Provisioning of Custom Serverless Container  Runtimes at Alibaba Cloud Function Compute",
    "abstract": "Comments: This is the preprint version of a paper published in USENIX ATC 2021",
    "descriptor": "\nComments: This is the preprint version of a paper published in USENIX ATC 2021\n",
    "authors": [
      "Ao Wang",
      "Shuai Chang",
      "Huangshi Tian",
      "Hongqi Wang",
      "Haoran Yang",
      "Huiba Li",
      "Rui Du",
      "Yue Cheng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11229"
  },
  {
    "id": "arXiv:2105.11366",
    "title": "GMAC: A Distributional Perspective on Actor-Critic Framework",
    "abstract": "GMAC: A Distributional Perspective on Actor-Critic Framework",
    "descriptor": "",
    "authors": [
      "Daniel Wontae Nam",
      "Younghoon Kim",
      "Chan Y. Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11366"
  },
  {
    "id": "arXiv:2105.12485",
    "title": "TreeBERT: A Tree-Based Pre-Trained Model for Programming Language",
    "abstract": "Comments: Accepted by UAI2021",
    "descriptor": "\nComments: Accepted by UAI2021\n",
    "authors": [
      "Xue Jiang",
      "Zhuoran Zheng",
      "Chen Lyu",
      "Liang Li",
      "Lei Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.12485"
  },
  {
    "id": "arXiv:2105.12802",
    "title": "Direct Detection Under Tukey Signalling",
    "abstract": "Comments: Submitted to J. Lightwave Techn. on May 26th, 2021",
    "descriptor": "\nComments: Submitted to J. Lightwave Techn. on May 26th, 2021\n",
    "authors": [
      "Amir Tasbihi",
      "Frank R. Kschischang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.12802"
  },
  {
    "id": "arXiv:2105.13309",
    "title": "Concept drift detection and adaptation for federated and continual  learning",
    "abstract": "Concept drift detection and adaptation for federated and continual  learning",
    "descriptor": "",
    "authors": [
      "Fernando E. Casado",
      "Dylan Lema",
      "Marcos F. Criado",
      "Roberto Iglesias",
      "Carlos V. Regueiro",
      "Sen\u00e9n Barro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13309"
  },
  {
    "id": "arXiv:2105.13327",
    "title": "Encoders and Ensembles for Task-Free Continual Learning",
    "abstract": "Encoders and Ensembles for Task-Free Continual Learning",
    "descriptor": "",
    "authors": [
      "Murray Shanahan",
      "Christos Kaplanis",
      "Jovana Mitrovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13327"
  },
  {
    "id": "arXiv:2106.04289",
    "title": "Morphing tree drawings in a small 3D grid",
    "abstract": "Comments: 30 pages, corrected version",
    "descriptor": "\nComments: 30 pages, corrected version\n",
    "authors": [
      "Elena Arseneva",
      "Rahul Gangopadhyay",
      "Aleksandra Istomina"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.04289"
  },
  {
    "id": "arXiv:2106.04575",
    "title": "DNS attack mitigation Using OpenStack Isolation",
    "abstract": "Comments: 6 pages, 3 figures, and 2 tables",
    "descriptor": "\nComments: 6 pages, 3 figures, and 2 tables\n",
    "authors": [
      "Hassnain ul hassan",
      "Rizal Mohd Nor",
      "Md Amiruzzaman",
      "Sharyar Wani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.04575"
  },
  {
    "id": "arXiv:2106.05606",
    "title": "VT-SSum: A Benchmark Dataset for Video Transcript Segmentation and  Summarization",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Tengchao Lv",
      "Lei Cui",
      "Momcilo Vasilijevic",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.05606"
  },
  {
    "id": "arXiv:2106.05825",
    "title": "HASI: Hardware-Accelerated Stochastic Inference, A Defense Against  Adversarial Machine Learning Attacks",
    "abstract": "HASI: Hardware-Accelerated Stochastic Inference, A Defense Against  Adversarial Machine Learning Attacks",
    "descriptor": "",
    "authors": [
      "Mohammad Hossein Samavatian",
      "Saikat Majumdar",
      "Kristin Barber",
      "Radu Teodorescu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05825"
  },
  {
    "id": "arXiv:2106.06345",
    "title": "JKOnet: Proximal Optimal Transport Modeling of Population Dynamics",
    "abstract": "JKOnet: Proximal Optimal Transport Modeling of Population Dynamics",
    "descriptor": "",
    "authors": [
      "Charlotte Bunne",
      "Laetitia Meng-Papaxanthos",
      "Andreas Krause",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06345"
  },
  {
    "id": "arXiv:2106.07609",
    "title": "The Exact Spectral Derivative Discretization Finite Difference (ESDDFD)  Method for Wave Models: A Universal Wave View Through Natural Fractional /  Fractal Derivative Representations (or View Lens Shops for The Exponential  Wave Universe)",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "D.P. Clemence-Mkhope"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07609"
  },
  {
    "id": "arXiv:2106.10544",
    "title": "Learning Space Partitions for Path Planning",
    "abstract": "Learning Space Partitions for Path Planning",
    "descriptor": "",
    "authors": [
      "Kevin Yang",
      "Tianjun Zhang",
      "Chris Cummins",
      "Brandon Cui",
      "Benoit Steiner",
      "Linnan Wang",
      "Joseph E. Gonzalez",
      "Dan Klein",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10544"
  },
  {
    "id": "arXiv:2106.12382",
    "title": "Innovations Autoencoder and its Application in One-class Anomalous  Sequence Detection",
    "abstract": "Innovations Autoencoder and its Application in One-class Anomalous  Sequence Detection",
    "descriptor": "",
    "authors": [
      "Xinyi Wang",
      "Lang Tong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12382"
  },
  {
    "id": "arXiv:2106.12423",
    "title": "Alias-Free Generative Adversarial Networks",
    "abstract": "Alias-Free Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Samuli Laine",
      "Erik H\u00e4rk\u00f6nen",
      "Janne Hellsten",
      "Jaakko Lehtinen",
      "Timo Aila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12423"
  },
  {
    "id": "arXiv:2106.12433",
    "title": "A Note On Symmetric Positive Definite Preconditioners for Multiple  Saddle-Point Systems",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "John W. Pearson",
      "Andreas Potschka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12433"
  },
  {
    "id": "arXiv:2106.14251",
    "title": "Pairing Conceptual Modeling with Machine Learning",
    "abstract": "Pairing Conceptual Modeling with Machine Learning",
    "descriptor": "",
    "authors": [
      "Wolfgang Maass",
      "Veda C. Storey"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14251"
  },
  {
    "id": "arXiv:2106.15188",
    "title": "Tensor-train approximation of the chemical master equation and its  application for parameter inference",
    "abstract": "Tensor-train approximation of the chemical master equation and its  application for parameter inference",
    "descriptor": "",
    "authors": [
      "Ion Gabriel Ion",
      "Christian Wildner",
      "Dimitrios Loukrezis",
      "Heinz Koeppl",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15188"
  },
  {
    "id": "arXiv:2106.15543",
    "title": "BOTTER: A framework to analyze social bots in Twitter",
    "abstract": "BOTTER: A framework to analyze social bots in Twitter",
    "descriptor": "",
    "authors": [
      "Javier Pastor-Galindo",
      "F\u00e9lix G\u00f3mez M\u00e1rmol",
      "Gregorio Mart\u00ednez P\u00e9rez"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15543"
  },
  {
    "id": "arXiv:2106.15869",
    "title": "GPU Based Improved Fast Iterative Algorithm for Eikonal Equation",
    "abstract": "Comments: 18 pages, 14 figures",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Yuhao Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15869"
  },
  {
    "id": "arXiv:2107.00368",
    "title": "Ensemble Learning-Based Approach for Improving Generalization Capability  of Machine Reading Comprehension Systems",
    "abstract": "Ensemble Learning-Based Approach for Improving Generalization Capability  of Machine Reading Comprehension Systems",
    "descriptor": "",
    "authors": [
      "Razieh Baradaran",
      "Hossein Amirkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00368"
  },
  {
    "id": "arXiv:2107.00635",
    "title": "StableEmit: Selection Probability Discount for Reducing Emission Latency  of Streaming Monotonic Attention ASR",
    "abstract": "Comments: Accepted at Interspeech 2021",
    "descriptor": "\nComments: Accepted at Interspeech 2021\n",
    "authors": [
      "Hirofumi Inaguma",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.00635"
  },
  {
    "id": "arXiv:2107.00652",
    "title": "CSWin Transformer: A General Vision Transformer Backbone with  Cross-Shaped Windows",
    "abstract": "Comments: The code repo is available at this https URL, SOTA performance on ADE20k Segmentation benchmark is updated",
    "descriptor": "\nComments: The code repo is available at this https URL, SOTA performance on ADE20k Segmentation benchmark is updated\n",
    "authors": [
      "Xiaoyi Dong",
      "Jianmin Bao",
      "Dongdong Chen",
      "Weiming Zhang",
      "Nenghai Yu",
      "Lu Yuan",
      "Dong Chen",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00652"
  },
  {
    "id": "arXiv:2107.00774",
    "title": "Almost Tight Approximation Algorithms for Explainable Clustering",
    "abstract": "Comments: 27 pages. Added references to independent work, as well as a table of results, pseudocode, and improved introduction. Note: first version was uploaded on July 1, 2021",
    "descriptor": "\nComments: 27 pages. Added references to independent work, as well as a table of results, pseudocode, and improved introduction. Note: first version was uploaded on July 1, 2021\n",
    "authors": [
      "Hossein Esfandiari",
      "Vahab Mirrokni",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00774"
  },
  {
    "id": "arXiv:2107.00793",
    "title": "The Causal-Neural Connection: Expressiveness, Learnability, and  Inference",
    "abstract": "Comments: 10 pages main body (53 total pages with references and appendix), 5 figures in main body (20 total figures including appendix)",
    "descriptor": "\nComments: 10 pages main body (53 total pages with references and appendix), 5 figures in main body (20 total figures including appendix)\n",
    "authors": [
      "Kevin Xia",
      "Kai-Zhan Lee",
      "Yoshua Bengio",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00793"
  },
  {
    "id": "arXiv:2107.01386",
    "title": "An asymptotically compatible probabilistic collocation method for  randomly heterogeneous nonlocal problems",
    "abstract": "An asymptotically compatible probabilistic collocation method for  randomly heterogeneous nonlocal problems",
    "descriptor": "",
    "authors": [
      "Yiming Fan",
      "Xiaochuan Tian",
      "Xiu Yang",
      "Xingjie Li",
      "Clayton Webster",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.01386"
  },
  {
    "id": "arXiv:2107.02433",
    "title": "Double-Uncertainty Assisted Spatial and Temporal Regularization  Weighting for Learning-based Registration",
    "abstract": "Comments: 11 pages, version 1",
    "descriptor": "\nComments: 11 pages, version 1\n",
    "authors": [
      "Zhe Xu",
      "Jie Luo",
      "Donghuan Lu",
      "Jiangpeng Yan",
      "Jayender Jagadeesan",
      "William Wells III",
      "Sarah Frisken",
      "Kai Ma",
      "Yefeng Zheng",
      "Raymond Kai-yu Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02433"
  },
  {
    "id": "arXiv:2107.03107",
    "title": "Learning Vision Transformer with Squeeze and Excitation for Facial  Expression Recognition",
    "abstract": "Learning Vision Transformer with Squeeze and Excitation for Facial  Expression Recognition",
    "descriptor": "",
    "authors": [
      "Mouath Aouayeb",
      "Wassim Hamidouche",
      "Catherine Soladie",
      "Kidiyo Kpalma",
      "Renaud Seguier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03107"
  },
  {
    "id": "arXiv:2107.03492",
    "title": "Persistent Software Combining",
    "abstract": "Persistent Software Combining",
    "descriptor": "",
    "authors": [
      "Panagiota Fatourou",
      "Nikolaos D. Kallimanis",
      "Eleftherios Kosmas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.03492"
  },
  {
    "id": "arXiv:2107.04187",
    "title": "A Multi-modal and Multi-task Learning Method for Action Unit and  Expression Recognition",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yue Jin",
      "Tianqing Zheng",
      "Chao Gao",
      "Guoqiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04187"
  },
  {
    "id": "arXiv:2107.04367",
    "title": "Lithography Hotspot Detection via Heterogeneous Federated Learning with  Local Adaptation",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Xuezhong Lin",
      "Jingyu Pan",
      "Jinming Xu",
      "Yiran Chen",
      "Cheng Zhuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04367"
  },
  {
    "id": "arXiv:2107.05051",
    "title": "On the Expressiveness of Assignment Messages",
    "abstract": "On the Expressiveness of Assignment Messages",
    "descriptor": "",
    "authors": [
      "Maximilian Fichtl"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.05051"
  },
  {
    "id": "arXiv:2107.05131",
    "title": "A dual approach for dynamic pricing in multi-demand markets",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Erika R. B\u00e9rczi-Kov\u00e1cs",
      "Evelin Sz\u00f6gi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05131"
  },
  {
    "id": "arXiv:2107.05315",
    "title": "Contrastive Learning for Cold-Start Recommendation",
    "abstract": "Comments: Accepted by ACM Multimedia 2021",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2021\n",
    "authors": [
      "Yinwei Wei",
      "Xiang Wang",
      "Qi Li",
      "Liqiang Nie",
      "Yan Li",
      "Xuanping Li",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.05315"
  },
  {
    "id": "arXiv:2107.05757",
    "title": "Kernel Continual Learning",
    "abstract": "Comments: accepted to ICML 2021",
    "descriptor": "\nComments: accepted to ICML 2021\n",
    "authors": [
      "Mohammad Mahdi Derakhshani",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05757"
  },
  {
    "id": "arXiv:2107.05829",
    "title": "Promises and Perils of Inferring Personality on GitHub",
    "abstract": "Promises and Perils of Inferring Personality on GitHub",
    "descriptor": "",
    "authors": [
      "Frenk van Mil",
      "Ayushi Rastogi",
      "Andy Zaidman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.05829"
  },
  {
    "id": "arXiv:2107.05847",
    "title": "Hyperparameter Optimization: Foundations, Algorithms, Best Practices and  Open Challenges",
    "abstract": "Hyperparameter Optimization: Foundations, Algorithms, Best Practices and  Open Challenges",
    "descriptor": "",
    "authors": [
      "Bernd Bischl",
      "Martin Binder",
      "Michel Lang",
      "Tobias Pielok",
      "Jakob Richter",
      "Stefan Coors",
      "Janek Thomas",
      "Theresa Ullmann",
      "Marc Becker",
      "Anne-Laure Boulesteix",
      "Difan Deng",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05847"
  },
  {
    "id": "arXiv:2107.06031",
    "title": "Understanding Factors Affecting Fuel Consumption of Vehicles Through  Explainable Boosting Machines",
    "abstract": "Comments: 30 pages, 15 Figures",
    "descriptor": "\nComments: 30 pages, 15 Figures\n",
    "authors": [
      "Alberto Barbado",
      "\u00d3scar Corcho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06031"
  },
  {
    "id": "arXiv:2107.06130",
    "title": "Scalable Surface Reconstruction with Delaunay-Graph Neural Networks",
    "abstract": "Comments: The presentation of this work at SGP 2021 is available at this https URL",
    "descriptor": "\nComments: The presentation of this work at SGP 2021 is available at this https URL\n",
    "authors": [
      "Raphael Sulzer",
      "Loic Landrieu",
      "Renaud Marlet",
      "Bruno Vallet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.06130"
  },
  {
    "id": "arXiv:2107.06260",
    "title": "OpenCDA:An Open Cooperative Driving Automation Framework Integrated with  Co-Simulation",
    "abstract": "Comments: Accepted by ITSC2021",
    "descriptor": "\nComments: Accepted by ITSC2021\n",
    "authors": [
      "Runsheng Xu",
      "Yi Guo",
      "Xu Han",
      "Xin Xia",
      "Hao Xiang",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.06260"
  },
  {
    "id": "arXiv:2107.06263",
    "title": "CMT: Convolutional Neural Networks Meet Vision Transformers",
    "abstract": "CMT: Convolutional Neural Networks Meet Vision Transformers",
    "descriptor": "",
    "authors": [
      "Jianyuan Guo",
      "Kai Han",
      "Han Wu",
      "Chang Xu",
      "Yehui Tang",
      "Chunjing Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06263"
  },
  {
    "id": "arXiv:2107.06307",
    "title": "HDMapNet: An Online HD Map Construction and Evaluation Framework",
    "abstract": "HDMapNet: An Online HD Map Construction and Evaluation Framework",
    "descriptor": "",
    "authors": [
      "Qi Li",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06307"
  },
  {
    "id": "arXiv:2107.06341",
    "title": "Hybrid A Posteriori Error Estimators for Conforming Finite Element  Approximations to Stationary Convection-Diffusion-Reaction equations",
    "abstract": "Hybrid A Posteriori Error Estimators for Conforming Finite Element  Approximations to Stationary Convection-Diffusion-Reaction equations",
    "descriptor": "",
    "authors": [
      "Difeng Cai",
      "Zhiqiang Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06341"
  },
  {
    "id": "arXiv:2107.06344",
    "title": "Inverse Reinforcement Learning Based Stochastic Driver Behavior Learning",
    "abstract": "Comments: Accepted to 2021 Modeling, Estimation and Control Conference (MECC)",
    "descriptor": "\nComments: Accepted to 2021 Modeling, Estimation and Control Conference (MECC)\n",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Abishek Joseph Rocque",
      "Yao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.06344"
  },
  {
    "id": "arXiv:2107.06495",
    "title": "GgViz: Accelerating Large-Scale Esports Game Analysis",
    "abstract": "GgViz: Accelerating Large-Scale Esports Game Analysis",
    "descriptor": "",
    "authors": [
      "Peter Xenopoulos",
      "Joao Rulff",
      "Claudio Silva"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.06495"
  },
  {
    "id": "arXiv:2107.06630",
    "title": "Online Evaluation Methods for the Causal Effect of Recommendations",
    "abstract": "Comments: accepted at RecSys 2021",
    "descriptor": "\nComments: accepted at RecSys 2021\n",
    "authors": [
      "Masahiro Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06630"
  },
  {
    "id": "arXiv:2107.06632",
    "title": "ParCourE: A Parallel Corpus Explorer for a Massively Multilingual Corpus",
    "abstract": "Comments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    "descriptor": "\nComments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\n",
    "authors": [
      "Ayyoob Imani",
      "Masoud Jalili Sabet",
      "Philipp Dufter",
      "Michael Cysouw",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.06632"
  },
  {
    "id": "arXiv:2107.06650",
    "title": "An Efficient Deep Distribution Network for Bid Shading in First-Price  Auctions",
    "abstract": "Comments: In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'21), August 14-18, 2021, Singapore",
    "descriptor": "\nComments: In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'21), August 14-18, 2021, Singapore\n",
    "authors": [
      "Tian Zhou",
      "Hao He",
      "Shengjun Pan",
      "Niklas Karlsson",
      "Bharatbhushan Shetty",
      "Brendan Kitts",
      "Djordje Gligorijevic",
      "San Gultekin",
      "Tingyu Mao",
      "Junwei Pan",
      "Jianlong Zhang",
      "Aaron Flores"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06650"
  },
  {
    "id": "arXiv:2107.06695",
    "title": "Solving discrete constrained problems on de Rham complex",
    "abstract": "Solving discrete constrained problems on de Rham complex",
    "descriptor": "",
    "authors": [
      "Zhongjie Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06695"
  },
  {
    "id": "arXiv:2107.06703",
    "title": "Zero-Round Active Learning",
    "abstract": "Zero-Round Active Learning",
    "descriptor": "",
    "authors": [
      "Si Chen",
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06703"
  },
  {
    "id": "arXiv:2107.06785",
    "title": "Large-Scale News Classification using BERT Language Model: Spark NLP  Approach",
    "abstract": "Large-Scale News Classification using BERT Language Model: Spark NLP  Approach",
    "descriptor": "",
    "authors": [
      "Kuncahyo Setyo Nugroho",
      "Anantha Yullian Sukmadewa",
      "Novanto Yudistira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06785"
  }
]
[
  {
    "id": "arXiv:2112.14769",
    "title": "Frame invariance and scalability of neural operators for partial  differential equations",
    "abstract": "Partial differential equations (PDEs) play a dominant role in the\nmathematical modeling of many complex dynamical processes. Solving these PDEs\noften requires prohibitively high computational costs, especially when multiple\nevaluations must be made for different parameters or conditions. After\ntraining, neural operators can provide PDEs solutions significantly faster than\ntraditional PDE solvers. In this work, invariance properties and computational\ncomplexity of two neural operators are examined for transport PDE of a scalar\nquantity. Neural operator based on graph kernel network (GKN) operates on\ngraph-structured data to incorporate nonlocal dependencies. Here we propose a\nmodified formulation of GKN to achieve frame invariance. Vector cloud neural\nnetwork (VCNN) is an alternate neural operator with embedded frame invariance\nwhich operates on point cloud data. GKN-based neural operator demonstrates\nslightly better predictive performance compared to VCNN. However, GKN requires\nan excessively high computational cost that increases quadratically with the\nincreasing number of discretized objects as compared to a linear increase for\nVCNN.",
    "descriptor": "",
    "authors": [
      "Muhammad I. Zafar",
      "Jiequn Han",
      "Xu-Hui Zhou",
      "Heng Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14769"
  },
  {
    "id": "arXiv:2112.14770",
    "title": "Proceedings of the 13th International Conference on Automated Deduction  in Geometry",
    "abstract": "Automated Deduction in Geometry (ADG) is a forum to exchange ideas and views,\nto present research results and progress, and to demonstrate software tools at\nthe intersection between geometry and automated deduction. Relevant topics\ninclude (but are not limited to): polynomial algebra, invariant and\ncoordinate-free methods; probabilistic, synthetic, and logic approaches,\ntechniques for automated geometric reasoning from discrete mathematics,\ncombinatorics, and numerics; interactive theorem proving in geometry; symbolic\nand numeric methods for geometric computation, geometric constraint solving,\nautomated generation/reasoning and manipulation with diagrams; design and\nimplementation of geometry software, automated theorem provers, special-purpose\ntools, experimental studies; applications of ADG in mechanics, geometric\nmodelling, CAGD/CAD, computer vision, robotics and education.\nTraditionally, the ADG conference is held every two years. The previous\neditions of ADG were held in Nanning in 2018, Strasbourg in 2016, Coimbra in\n2014, Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,\nGainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and\nToulouse in 1996. The 13th edition of ADG was supposed to be held in 2020 in\nHagenberg, Austria, but due to the COVID-19 pandemic, it was postponed for\n2021, and held online (still hosted by RISC Institute, Hagenberg, Austria),\nSeptember 15-17, 2021 (https://www.risc.jku.at/conferences/adg2021).",
    "descriptor": "",
    "authors": [
      "Predrag Jani\u010di\u0107",
      "Zolt\u00e1n Kov\u00e1cs"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.14770"
  },
  {
    "id": "arXiv:2112.14771",
    "title": "Gas Gauge: A Security Analysis Tool for Smart Contract Out-of-Gas  Vulnerabilities",
    "abstract": "In recent years we have witnessed a dramatic increase in the adoption and\napplication of smart contracts in a variety of contexts such as decentralized\nfinance, supply chain management, and identity management. However, a critical\nstumbling block to the further adoption of smart contracts is their security. A\nparticularly widespread class of security vulnerabilities that afflicts\nEthereum smart contracts is the gas limit denial of service(DoS) on a contract\nvia unbounded operations. These vulnerabilities result in a failed transaction\nwith an out-of-gas error and are often present in contracts containing loops\nwhose bounds are affected by end-user input. Note that such vulnerabilities\ndiffer from gas limit DoS on the network via block stuffing. Therefore, we\npresent Gas Gauge, a tool aimed at detecting Out-of-Gas DoS vulnerabilities in\nEthereum smart contracts. Gas Gauge consists of three major components: the\nDetection, Identification, and Correction Phases. The Detection Phase consists\nof an accurate static analysis approach that finds and summarizes all the loops\nin a smart contract. The Identification Phase uses a white-box fuzzing approach\nto generate a set of inputs that causes the contract to run out of gas. The\nCorrection Phase uses static analysis and run-time verification to predict the\nmaximum loop bounds consistent with allowable gas usage and suggest appropriate\nrepairs to the user of the tool. Each part of the tool can be used separately\nfor different purposes or all together to detect, identify and help repair the\ncontracts vulnerable to Out-of-Gas DoS vulnerabilities. Gas Gauge was tested on\n1,000 real-world solidity smart contracts deployed on the Ethereum Mainnet. The\nresults were compared to seven state-of-the-art static and symbolic tools, and\nit was empirically demonstrated that Gas Gauge is far more effective than\ncompeting state-of-the-art tools.",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "Behkish Nassirzadeh",
      "Huaiying Sun",
      "Sebastian Banescu",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14771"
  },
  {
    "id": "arXiv:2112.14772",
    "title": "Deep Graph Clustering via Dual Correlation Reduction",
    "abstract": "Deep graph clustering, which aims to reveal the underlying graph structure\nand divide the nodes into different groups, has attracted intensive attention\nin recent years. However, we observe that, in the process of node encoding,\nexisting methods suffer from representation collapse which tends to map all\ndata into the same representation. Consequently, the discriminative capability\nof the node representation is limited, leading to unsatisfied clustering\nperformance. To address this issue, we propose a novel self-supervised deep\ngraph clustering method termed Dual Correlation Reduction Network (DCRN) by\nreducing information correlation in a dual manner. Specifically, in our method,\nwe first design a siamese network to encode samples. Then by forcing the\ncross-view sample correlation matrix and cross-view feature correlation matrix\nto approximate two identity matrices, respectively, we reduce the information\ncorrelation in the dual-level, thus improving the discriminative capability of\nthe resulting features. Moreover, in order to alleviate representation collapse\ncaused by over-smoothing in GCN, we introduce a propagation regularization term\nto enable the network to gain long-distance information with the shallow\nnetwork structure. Extensive experimental results on six benchmark datasets\ndemonstrate the effectiveness of the proposed DCRN against the existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yue Liu",
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Linxuan Song",
      "Xihong Yang",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14772"
  },
  {
    "id": "arXiv:2112.14773",
    "title": "Working mechanism of Eternalblue and its application in ransomworm",
    "abstract": "After the leaking of exploit Eternalblue, some ransomworms utilizing this\nexploit have been developed to sweep over the world in recent years. Ransomworm\nis a global growing threat as it blocks users' access to their files unless a\nransom is paid by victims. Wannacry and Notpetya are two of those ransomworms\nwhich are responsible for the loss of millions of dollar, from crippling U.K.\nnational systems to shutting down a Honda Motor Company in Japan. Many dynamic\nanalytic papers on Wannacry were published, however, static analytic papers\nabout Wannacry were limited. Our aim is to present readers an systematic\nknowledge about exploit Eternalblue, from a high\\textendash leveled semantic\nview to the code details. Specifically, the working mechanism of Eternalblue,\nthe reverse engineering analysis of Eternalblue in Wannacry, and the comparison\nwith the Metasploit's Eternalblue exploit are presented. The key finding of our\nanalysis is that the code remains almost the same when Eternalblue is\ntransplanted into Wannacry, which indicates its potential for signatures and\nthus detection.",
    "descriptor": "",
    "authors": [
      "Zian Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.14773"
  },
  {
    "id": "arXiv:2112.14789",
    "title": "Attention-based Bidirectional LSTM for Deceptive Opinion Spam  Classification",
    "abstract": "Online Reviews play a vital role in e commerce for decision making. Much of\nthe population makes the decision of which places, restaurant to visit, what to\nbuy and from where to buy based on the reviews posted on the respective\nplatforms. A fraudulent review or opinion spam is categorized as an untruthful\nor deceptive review. Positive reviews of a product or a restaurant helps\nattract customers and thereby lead to an increase in sales whereas negative\nreviews may hamper the progress of a restaurant or sales of a product and\nthereby lead to defamed reputation and loss. Fraudulent reviews are\ndeliberately posted on various online review platforms to trick customers to\nbuy, visit or distract against a product or a restaurant. They are also written\nto commend or discredit the product's repute. The work aims at detecting and\nclassifying the reviews as deceptive or truthful. It involves use of various\ndeep learning techniques for classifying the reviews and an overview of\nproposed approach involving Attention based Bidirectional LSTM to tackle issues\nrelated to semantic information in reviews and a comparative study over\nbaseline machine learning techniques for review classification.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1909.04826 by other authors\n",
    "authors": [
      "Ashish Salunkhe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.14789"
  },
  {
    "id": "arXiv:2112.14792",
    "title": "Graph Neural Networks for Communication Networks: Context, Use Cases and  Opportunities",
    "abstract": "Graph neural networks (GNN) have shown outstanding applications in many\nfields where data is fundamentally represented as graphs (e.g., chemistry,\nbiology, recommendation systems). In this vein, communication networks comprise\nmany fundamental components that are naturally represented in a\ngraph-structured manner (e.g., topology, configurations, traffic flows). This\nposition article presents GNNs as a fundamental tool for modeling, control and\nmanagement of communication networks. GNNs represent a new generation of\ndata-driven models that can accurately learn and reproduce the complex\nbehaviors behind real networks. As a result, such models can be applied to a\nwide variety of networking use cases, such as planning, online optimization, or\ntroubleshooting. The main advantage of GNNs over traditional neural networks\nlies in its unprecedented generalization capabilities when applied to other\nnetworks and configurations unseen during training, which is a critical feature\nfor achieving practical data-driven solutions for networking. This article\ncomprises a brief tutorial on GNNs and their possible applications to\ncommunication networks. To showcase the potential of this technology, we\npresent two use cases with state-of-the-art GNN models respectively applied to\nwired and wireless networks. Lastly, we delve into the key open challenges and\nopportunities yet to be explored in this novel research area.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Paul Almasan",
      "Miquel Ferriol-Galm\u00e9s",
      "Krzysztof Rusek",
      "Fabien Geyer",
      "Xiangle Cheng",
      "Xiang Shi",
      "Shihan Xiao",
      "Franco Scarselli",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.14792"
  },
  {
    "id": "arXiv:2112.14793",
    "title": "A sampling-based approach for efficient clustering in large datasets",
    "abstract": "We propose a simple and efficient clustering method for high-dimensional data\nwith a large number of clusters. Our algorithm achieves high-performance by\nevaluating distances of datapoints with a subset of the cluster centres. Our\ncontribution is substantially more efficient than k-means as it does not\nrequire an all to all comparison of data points and clusters. We show that the\noptimal solutions of our approximation are the same as in the exact solution.\nHowever, our approach is considerably more efficient at extracting these\nclusters compared to the state-of-the-art. We compare our approximation with\nthe exact k-means and alternative approximation approaches on a series of\nstandardised clustering tasks. For the evaluation, we consider the algorithmic\ncomplexity, including number of operations to convergence, and the stability of\nthe results.",
    "descriptor": "\nComments: 10 pages, 5 figures, 1 table, an open source implementation of the algorithm is provided in the this https URL\n",
    "authors": [
      "Georgios Exarchakis",
      "Omar Oubari",
      "Gregor Lenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.14793"
  },
  {
    "id": "arXiv:2112.14796",
    "title": "Deep Learning meets Liveness Detection: Recent Advancements and  Challenges",
    "abstract": "Facial biometrics has been recently received tremendous attention as a\nconvenient replacement for traditional authentication systems. Consequently,\ndetecting malicious attempts has found great significance, leading to extensive\nstudies in face anti-spoofing~(FAS),i.e., face presentation attack detection.\nDeep feature learning and techniques, as opposed to hand-crafted features, have\npromised a dramatic increase in the FAS systems' accuracy, tackling the key\nchallenges of materializing the real-world application of such systems. Hence,\na new research area dealing with the development of more generalized as well as\naccurate models is increasingly attracting the attention of the research\ncommunity and industry. In this paper, we present a comprehensive survey on the\nliterature related to deep-feature-based FAS methods since 2017. To shed light\non this topic, a semantic taxonomy based on various features and learning\nmethodologies is represented. Further, we cover predominant public datasets for\nFAS in chronological order, their evolutional progress, and the evaluation\ncriteria (both intra-dataset and inter-dataset). Finally, we discuss the open\nresearch challenges and future directions.",
    "descriptor": "",
    "authors": [
      "Arian Sabaghi",
      "Marzieh Oghbaie",
      "Kooshan Hashemifard",
      "Mohammad Akbari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14796"
  },
  {
    "id": "arXiv:2112.14801",
    "title": "Modeling Prejudice and Its Effect on Societal Prosperity",
    "abstract": "Existing studies on prejudice, which is important in multi-group dynamics in\nsocieties, focus on the social-psychological knowledge behind the processes\ninvolving prejudice and its propagation. We instead create a multi-agent\nframework that simulates the propagation of prejudice and measures its tangible\nimpact on the prosperity of individuals as well as of larger social structures,\nincluding groups and factions within. Groups in society help us define\nprejudice, and factions represent smaller tight-knit circles of individuals\nwith similar opinions. We model social interactions using the Continuous\nPrisoner's Dilemma (CPD) and a type of agent called a prejudiced agent, whose\ncooperation is affected by a prejudice attribute, updated over time based both\non the agent's own experiences and those of others in its faction. Our\nsimulations show that modeling prejudice as an exclusively out-group phenomenon\ngenerates implicit in-group promotion, which eventually leads to higher\nrelative prosperity of the prejudiced population. This skew in prosperity is\nshown to be correlated to factors such as size difference between groups and\nthe number of prejudiced agents in a group. Although prejudiced agents achieve\nhigher prosperity within prejudiced societies, their presence degrades the\noverall prosperity levels of their societies. Our proposed system model can\nserve as a basis for promoting a deeper understanding of origins, propagation,\nand ramifications of prejudice through rigorous simulative studies grounded in\napt theoretical backgrounds. This can help conduct impactful research on\nprominent social issues such as racism, religious discrimination, and unfair\nimmigrant treatment. This model can also serve as a foundation to study other\nsocio-psychological phenomena in tandem with prejudice such as the distribution\nof wealth, social status, and ethnocentrism in a society.",
    "descriptor": "\nComments: 12 pages, 7 figures, 4 tables\n",
    "authors": [
      "Deep Inder Mohan",
      "Arjun Verma",
      "Shrisha Rao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.14801"
  },
  {
    "id": "arXiv:2112.14804",
    "title": "Learning Inception Attention for Image Synthesis and Image Recognition",
    "abstract": "Image synthesis and image recognition have witnessed remarkable progress, but\noften at the expense of computationally expensive training and inference.\nLearning lightweight yet expressive deep model has emerged as an important and\ninteresting direction. Inspired by the well-known split-transform-aggregate\ndesign heuristic in the Inception building block, this paper proposes a\nSkip-Layer Inception Module (SLIM) that facilitates efficient learning of image\nsynthesis models, and a same-layer variant (dubbed as SLIM too) as a stronger\nalternative to the well-known ResNeXts for image recognition. In SLIM, the\ninput feature map is first split into a number of groups (e.g., 4).Each group\nis then transformed to a latent style vector(via channel-wise attention) and a\nlatent spatial mask (via spatial attention). The learned latent masks and\nlatent style vectors are aggregated to modulate the target feature map. For\ngenerative learning, SLIM is built on a recently proposed lightweight\nGenerative Adversarial Networks (i.e., FastGANs) which present a skip-layer\nexcitation(SLE) module. For few-shot image synthesis tasks, the proposed SLIM\nachieves better performance than the SLE work and other related methods. For\none-shot image synthesis tasks, it shows stronger capability of preserving\nimages structures than prior arts such as the SinGANs. For image classification\ntasks, the proposed SLIM is used as a drop-in replacement for convolution\nlayers in ResNets (resulting in ResNeXt-like models) and achieves better\naccuracy in theImageNet-1000 dataset, with significantly smaller model\ncomplexity",
    "descriptor": "",
    "authors": [
      "Jianghao Shen",
      "Tianfu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14804"
  },
  {
    "id": "arXiv:2112.14806",
    "title": "AutoFITS: Automatic Feature Engineering for Irregular Time Series",
    "abstract": "A time series represents a set of observations collected over time.\nTypically, these observations are captured with a uniform sampling frequency\n(e.g. daily). When data points are observed in uneven time intervals the time\nseries is referred to as irregular or intermittent. In such scenarios, the most\ncommon solution is to reconstruct the time series to make it regular, thus\nremoving its intermittency. We hypothesise that, in irregular time series, the\ntime at which each observation is collected may be helpful to summarise the\ndynamics of the data and improve forecasting performance. We study this idea by\ndeveloping a novel automatic feature engineering framework, which focuses on\nextracting information from this point of view, i.e., when each instance is\ncollected. We study how valuable this information is by integrating it in a\ntime series forecasting workflow and investigate how it compares to or\ncomplements state-of-the-art methods for regular time series forecasting. In\nthe end, we contribute by providing a novel framework that tackles feature\nengineering for time series from an angle previously vastly ignored. We show\nthat our approach has the potential to further extract more information about\ntime series that significantly improves forecasting performance.",
    "descriptor": "",
    "authors": [
      "Pedro Costa",
      "Vitor Cerqueira",
      "Jo\u00e3o Vinagre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14806"
  },
  {
    "id": "arXiv:2112.14809",
    "title": "Explanation by Automated Reasoning Using the Isabelle Infrastructure  Framework",
    "abstract": "In this paper, we propose the use of interactive theorem proving for\nexplainable machine learning. After presenting our proposition, we illustrate\nit on the dedicated application of explaining security attacks using the\nIsabelle Infrastructure framework and its process of dependability engineering.\nThis formal framework and process provides the logics for specification and\nmodeling. Attacks on security of the system are explained by specification and\nproofs in the Isabelle Infrastructure framework. Existing case studies of\ndependability engineering in Isabelle are used as feasibility studies to\nillustrate how different aspects of explanations are covered by the Isabelle\nInfrastructure framework.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.04374\n",
    "authors": [
      "Florian Kamm\u00fcller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.14809"
  },
  {
    "id": "arXiv:2112.14811",
    "title": "Active Learning-Based Optimization of Scientific Experimental Design",
    "abstract": "Active learning (AL) is a machine learning algorithm that can achieve greater\naccuracy with fewer labeled training instances, for having the ability to ask\noracles to label the most valuable unlabeled data chosen iteratively and\nheuristically by query strategies. Scientific experiments nowadays, though\nbecoming increasingly automated, are still suffering from human involvement in\nthe designing process and the exhaustive search in the experimental space. This\narticle performs a retrospective study on a drug response dataset using the\nproposed AL scheme comprised of the matrix factorization method of alternating\nleast square (ALS) and deep neural networks (DNN). This article also proposes\nan AL query strategy based on expected loss minimization. As a result, the\nretrospective study demonstrates that scientific experimental design, instead\nof being manually set, can be optimized by AL, and the proposed query strategy\nELM sampling shows better experimental performance than other ones such as\nrandom sampling and uncertainty sampling.",
    "descriptor": "\nComments: 2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE 2021)\n",
    "authors": [
      "Ruoyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14811"
  },
  {
    "id": "arXiv:2112.14815",
    "title": "Materialized Knowledge Bases from Commonsense Transformers",
    "abstract": "Starting from the COMET methodology by Bosselut et al. (2019), generating\ncommonsense knowledge directly from pre-trained language models has recently\nreceived significant attention. Surprisingly, up to now no materialized\nresource of commonsense knowledge generated this way is publicly available.\nThis paper fills this gap, and uses the materialized resources to perform a\ndetailed analysis of the potential of this approach in terms of precision and\nrecall. Furthermore, we identify common problem cases, and outline use cases\nenabled by materialized resources. We posit that the availability of these\nresources is important for the advancement of the field, as it enables an\noff-the-shelf-use of the resulting knowledge, as well as further analyses on\nits strengths and weaknesses.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tuan-Phong Nguyen",
      "Simon Razniewski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.14815"
  },
  {
    "id": "arXiv:2112.14820",
    "title": "Application of Hierarchical Temporal Memory Theory for Document  Categorization",
    "abstract": "The current work intends to study the performance of the Hierarchical\nTemporal Memory(HTM) theory for automated classification of text as well as\ndocuments. HTM is a biologically inspired theory based on the working\nprinciples of the human neocortex. The current study intends to provide an\nalternative framework for document categorization using the Spatial Pooler\nlearning algorithm in the HTM Theory. As HTM accepts only a stream of binary\ndata as input, Latent Semantic Indexing(LSI) technique is used for extracting\nthe top features from the input and converting them into binary format. The\nSpatial Pooler algorithm converts the binary input into sparse patterns with\nsimilar input text having overlapping spatial patterns making it easy for\nclassifying the patterns into categories. The results obtained prove that HTM\ntheory, although is in its nascent stages, performs at par with most of the\npopular machine learning based classifiers.",
    "descriptor": "\nComments: 6 pages, 3 figures, 2 tables\n",
    "authors": [
      "Deven Shah",
      "Pinak Ghate",
      "Manali Paranjape",
      "Amit Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14820"
  },
  {
    "id": "arXiv:2112.14821",
    "title": "Anomaly Detection in Cyber-Physical Systems: Reconstruction of a  Prediction Error Feature Space",
    "abstract": "Cyber-physical systems are infrastructures that use digital information such\nas network communications and sensor readings to control entities in the\nphysical world. Many cyber-physical systems in airports, hospitals and nuclear\npower plants are regarded as critical infrastructures since a disruption of its\nnormal functionality can result in negative consequences for the society. In\nthe last few years, some security solutions for cyber-physical systems based on\nartificial intelligence have been proposed. Nevertheless, knowledge domain is\nrequired to properly setup and train artificial intelligence algorithms. Our\nwork proposes a novel anomaly detection framework based on error space\nreconstruction, where genetic algorithms are used to perform hyperparameter\noptimization of machine learning methods. The proposed method achieved an\nF1-score of 87.89% in the SWaT dataset.",
    "descriptor": "",
    "authors": [
      "Nuno Oliveira",
      "Norberto Sousa",
      "Jorge Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14821"
  },
  {
    "id": "arXiv:2112.14822",
    "title": "UCoDe: Unified Community Detection with Graph Convolutional Networks",
    "abstract": "Community detection is the unsupervised task of finding groups of nodes in a\ngraph based on mutual similarity. Existing approaches for community detection\neither partition the graph in disjoint, non-overlapping, communities, or return\noverlapping communities. Currently, no method satisfactorily detects both\noverlapping and non-overlapping communities. We propose UCoDe, a unified method\nfor unsupervised community detection in attributed graphs. It leverages recent\ndevelopments in Graph Neural Networks (GNNs) for representation learning. So\nfar, GNN methods for community detection provide competitive results in either\noverlapping or non-overlapping community detection tasks, but have had little\nsuccess in both. UCoDe overcomes these issues by introducing a new loss that\ncaptures node similarity on a macro-scale. We provide theoretical justification\nfor our approach's validity in the task of community detection and show that it\ncan be applied in both the overlapping and non-overlapping settings. As our\nexperiments demonstrate on several real benchmark graphs, UCoDe consistently\nprovides high quality results in both overlapping and non-overlapping settings\nin an easy to apply fashion.",
    "descriptor": "",
    "authors": [
      "Atefeh Moradan",
      "Andrew Draganov",
      "Davide Mottin",
      "Ira Assent"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14822"
  },
  {
    "id": "arXiv:2112.14825",
    "title": "ReSplit: Improving the Structure of Jupyter Notebooks by Re-Splitting  Their Cells",
    "abstract": "Jupyter notebooks represent a unique format for programming - a combination\nof code and Markdown with rich formatting, separated into individual cells. We\npropose to perceive a Jupyter Notebook cell as a simplified and raw version of\na programming function. Similar to functions, Jupyter cells should strive to\ncontain singular, self-contained actions. At the same time, research shows that\nreal-world notebooks fail to do so and suffer from the lack of proper\nstructure.\nTo combat this, we propose ReSplit, an algorithm for an automatic\nre-splitting of cells in Jupyter notebooks. The algorithm analyzes\ndefinition-usage chains in the notebook and consists of two parts - merging and\nsplitting the cells. We ran the algorithm on a large corpus of notebooks to\nevaluate its performance and its overall effect on notebooks, and evaluated it\nby human experts: we showed them several notebooks in their original and the\nre-split form. In 29.5% of cases, the re-split notebook was selected as the\npreferred way of perceiving the code. We analyze what influenced this decision\nand describe several individual cases in detail.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Sergey Titov",
      "Yaroslav Golubev",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.14825"
  },
  {
    "id": "arXiv:2112.14829",
    "title": "On the Number of Incidences when Avoiding the Klan",
    "abstract": "We prove a bound of $O( k (n+m)\\log^{d-1})$ on the number of incidences\nbetween $n$ points and $m$ axis parallel boxes in $\\mathbb{R}^d$, if no $k$\nboxes contain $k$ common points. That is, the incidence graph between the\npoints and the boxes does not contain $K_{k,k}$ as a subgraph. This new bound\nimproves over previous work by a factor of $\\log^d n$, for $d >2$.\nWe also study the variant of the problem for points and halfspaces, where we\nuse shallow cuttings to get a near linear bound in two and three dimensions.",
    "descriptor": "",
    "authors": [
      "Sariel Har-Peled"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.14829"
  },
  {
    "id": "arXiv:2112.14831",
    "title": "A Hardware-Software Stack for Serverless Edge Swarms",
    "abstract": "Swarms of autonomous devices are increasing in ubiquity and size, making the\nneed for rethinking their hardware-software system stack critical.\nWe present HiveMind, the first swarm coordination platform that enables\nprogrammable execution of complex task workflows between cloud and edge\nresources in a performant and scalable manner. HiveMind is a software-hardware\nplatform that includes a domain-specific language to simplify programmability\nof cloud-edge applications, a program synthesis tool to automatically explore\ntask placement strategies, a centralized controller that leverages serverless\ncomputing to elastically scale cloud resources, and a reconfigurable hardware\nacceleration fabric for network and remote memory accesses.\nWe design and build the full end-to-end HiveMind system on two real edge\nswarms comprised of drones and robotic cars. We quantify the opportunities and\nchallenges serverless introduces to edge applications, as well as the\ntrade-offs between centralized and distributed coordination. We show that\nHiveMind achieves significantly better performance predictability and battery\nefficiency compared to existing centralized and decentralized platforms, while\nalso incurring lower network traffic. Using both real systems and a validated\nsimulator we show that HiveMind can scale to thousands of edge devices without\nsacrificing performance or efficiency, demonstrating that centralized platforms\ncan be both scalable and performant.",
    "descriptor": "",
    "authors": [
      "Liam Patterson",
      "David Pigorovsky",
      "Brian Dempsey",
      "Nikita Lazarev",
      "Aditya Shah",
      "Clara Steinhoff",
      "Ariana Bruno",
      "Justin Hu",
      "Christina Delimitrou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.14831"
  },
  {
    "id": "arXiv:2112.14834",
    "title": "Training Quantized Deep Neural Networks via Cooperative Coevolution",
    "abstract": "Quantizing deep neural networks (DNNs) has been a promising solution for\ndeploying deep neural networks on embedded devices. However, most of the\nexisting methods do not quantize gradients, and the process of quantizing DNNs\nstill has a lot of floating-point operations, which hinders the further\napplications of quantized DNNs. To solve this problem, we propose a new\nheuristic method based on cooperative coevolution for quantizing DNNs. Under\nthe framework of cooperative coevolution, we use the estimation of distribution\nalgorithm to search for the low-bits weights. Specifically, we first construct\nan initial quantized network from a pre-trained network instead of random\ninitialization and then start searching from it by restricting the search\nspace. So far, the problem is the largest discrete problem known to be solved\nby evolutionary algorithms. Experiments show that our method can train 4 bit\nResNet-20 on the Cifar-10 dataset without sacrificing accuracy.",
    "descriptor": "",
    "authors": [
      "Fu Peng",
      "Shengcai Liu",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14834"
  },
  {
    "id": "arXiv:2112.14837",
    "title": "Recent Trends in Artificial Intelligence-inspired Electronic Thermal  Management",
    "abstract": "The rise of computation-based methods in thermal management has gained\nimmense attention in recent years due to the ability of deep learning to solve\ncomplex 'physics' problems, which are otherwise difficult to be approached\nusing conventional techniques. Thermal management is required in electronic\nsystems to keep them from overheating and burning, enhancing their efficiency\nand lifespan. For a long time, numerical techniques have been employed to aid\nin the thermal management of electronics. However, they come with some\nlimitations. To increase the effectiveness of traditional numerical approaches\nand address the drawbacks faced in conventional approaches, researchers have\nlooked at using artificial intelligence at various stages of the thermal\nmanagement process. The present study discusses in detail, the current uses of\ndeep learning in the domain of 'electronic' thermal management.",
    "descriptor": "\nComments: International Conference on Fluid Flow and Thermal Sciences (ICAFFTS)\n",
    "authors": [
      "Aviral Chharia",
      "Nishi Mehta",
      "Shivam Gupta",
      "Shivam Prajapati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.14837"
  },
  {
    "id": "arXiv:2112.14839",
    "title": "An overview of the quantitative causality analysis and causal graph  reconstruction based on a rigorous formalism of information flow",
    "abstract": "Inference of causal relations from data now has become an important field in\nartificial intelligence. During the past 16 years, causality analysis (in a\nquantitative sense) has been developed independently in physics from first\nprinciples. This short note is a brief summary of this line of work, including\npart of the theory and several representative applications.",
    "descriptor": "\nComments: 7 pages, 1 figure. Presented at the First International AIxIA Workshop on Causality, Causal-ITALY, Italian Conference on Artificial Intelligence, November 30, 2021\n",
    "authors": [
      "X. San Liang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.14839"
  },
  {
    "id": "arXiv:2112.14840",
    "title": "K-Core Decomposition on Super Large Graphs with Limited Resources",
    "abstract": "K-core decomposition is a commonly used metric to analyze graph structure or\nstudy the relative importance of nodes in complex graphs. Recent years have\nseen rapid growth in the scale of the graph, especially in industrial settings.\nFor example, our industrial partner runs popular social applications with\nbillions of users and is able to gather a rich set of user data. As a result,\napplying K-core decomposition on large graphs has attracted more and more\nattention from academics and the industry. A simple but effective method to\ndeal with large graphs is to train them in the distributed settings, and some\ndistributed K-core decomposition algorithms are also proposed. Despite their\neffectiveness, we experimentally and theoretically observe that these\nalgorithms consume too many resources and become unstable on super-large-scale\ngraphs, especially when the given resources are limited. In this paper, we deal\nwith those super-large-scale graphs and propose a divide-and-conquer strategy\non top of the distributed K-core decomposition algorithm. We evaluate our\napproach on three large graphs. The experimental results show that the\nconsumption of resources can be significantly reduced, and the calculation on\nlarge-scale graphs becomes more stable than the existing methods. For example,\nthe distributed K-core decomposition algorithm can scale to a large graph with\n136 billion edges without losing correctness with our divide-and-conquer\ntechnique.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Shicheng Gao",
      "Jie Xu",
      "Xiaosen Li",
      "Fangcheng Fu",
      "Wentao Zhang",
      "Wen Ouyang",
      "Yangyu Tao",
      "Bin Cui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14840"
  },
  {
    "id": "arXiv:2112.14842",
    "title": "Explainable Signature-based Machine Learning Approach for Identification  of Faults in Grid-Connected Photovoltaic Systems",
    "abstract": "The transformation of conventional power networks into smart grids with the\nheavy penetration level of renewable energy resources, particularly\ngrid-connected Photovoltaic (PV) systems, has increased the need for efficient\nfault identification systems. Malfunctioning any single component in\ngrid-connected PV systems may lead to grid instability and other serious\nconsequences, showing that a reliable fault identification system is the utmost\nrequirement for ensuring operational integrity. Therefore, this paper presents\na novel fault identification approach based on statistical signatures of PV\noperational states. These signatures are unique because each fault has a\ndifferent nature and distinctive impact on the electrical system. Thus, the\nRandom Forest Classifier trained on these extracted signatures showed 100%\naccuracy in identifying all types of faults. Furthermore, the performance\ncomparison of the proposed framework with other Machine Learning classifiers\ndepicts its credibility. Moreover, to elevate user trust in the predicted\noutcomes, SHAP (Shapley Additive Explanation) was utilized during the training\nphase to extract a complete model response (global explanation). This extracted\nglobal explanation can help in the assessment of predicted outcomes credibility\nby decoding each prediction in terms of features contribution. Hence, the\nproposed explainable signature-based fault identification technique is highly\ncredible and fulfills all the requirements of smart grids.",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Syed Wali",
      "Irfan Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14842"
  },
  {
    "id": "arXiv:2112.14843",
    "title": "A Graph Attention Learning Approach to Antenna Tilt Optimization",
    "abstract": "6G will move mobile networks towards increasing levels of complexity. To deal\nwith this complexity, optimization of network parameters is key to ensure high\nperformance and timely adaptivity to dynamic network environments. The\noptimization of the antenna tilt provides a practical and cost-efficient method\nto improve coverage and capacity in the network. Previous methods based on\nReinforcement Learning (RL) have shown great promise for tilt optimization by\nlearning adaptive policies outperforming traditional tilt optimization methods.\nHowever, most existing RL methods are based on single-cell features\nrepresentation, which fails to fully characterize the agent state, resulting in\nsuboptimal performance. Also, most of such methods lack scalability, due to\nstate-action explosion, and generalization ability. In this paper, we propose a\nGraph Attention Q-learning (GAQ) algorithm for tilt optimization. GAQ relies on\na graph attention mechanism to select relevant neighbors information, improve\nthe agent state representation, and update the tilt control policy based on a\nhistory of observations using a Deep Q-Network (DQN). We show that GAQ\nefficiently captures important network information and outperforms standard DQN\nwith local information by a large margin. In addition, we demonstrate its\nability to generalize to network deployments of different sizes and densities.",
    "descriptor": "",
    "authors": [
      "Yifei Jin",
      "Filippo Vannella",
      "Maxime Bouton",
      "Jaeseong Jeong",
      "Ezeddin Al Hakim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14843"
  },
  {
    "id": "arXiv:2112.14845",
    "title": "Learned Autoscaling for Cloud Microservices with Multi-Armed Bandits",
    "abstract": "As cloud applications shift from monolithic architectures to loosely coupled\nmicroservices, several challenges in resource management arise. Application\ndevelopers are tasked with determining compute capacity needed for each\nmicroservice in an application. This allocation dictates both the cost and\nperformance of the application and typically relies on using either machine\nutilization (e.g. CPU, RAM) metrics. Our approach, COLA, relies on training a\ncontextual multi armed bandit on representative workloads for an application\nand uses techniques to generalize performance to unseen workloads. We evaluate\nworkloads of varying complexity including those with a fixed rate, diurnal\npattern and dynamic request distribution. Across a set of five open-source\nmicroservice applications, we compare COLA against a variety of utilization and\nmachine learning baselines. We find COLA provides the most cost effective\nautoscaling solution for a desired median or tail latency target on 13 of 18\nworkloads. On average, clusters managed by COLA cost 25.1\\% fewer dollars than\nthe next closest alternative that meets a specified target latency. We discuss\nseveral optimizations, inspired by systems and machine learning literature, we\nmake during training to efficiently explore the space of possible microservice\nconfigurations. These optimizations enable us to train our models over the\ncourse of a few hours. The cost savings from managing a cluster with COLA\nresult in the system paying for its own training cost within a few days.",
    "descriptor": "",
    "authors": [
      "Vighnesh Sachidananda",
      "Anirudh Sivaraman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14845"
  },
  {
    "id": "arXiv:2112.14853",
    "title": "Effects of Plasticity Functions on Neural Assemblies",
    "abstract": "We explore the effects of various plasticity functions on assemblies of\nneurons. To bridge the gap between experimental and computational theories we\nmake use of a conceptual framework, the Assembly Calculus, which is a formal\nsystem for the description of brain function based on assemblies of neurons.\nThe Assembly Calculus includes operations for projecting, associating, and\nmerging assemblies of neurons. Our research is focused on simulating different\nplasticity functions with Assembly Calculus. Our main contribution is the\nmodification and evaluation of the projection operation. We experiment with\nOja's and Spike Time-Dependent Plasticity (STDP) rules and test the effect of\nvarious hyper-parameters.",
    "descriptor": "",
    "authors": [
      "Christodoulos Constantinides",
      "Kareem Nassar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.14853"
  },
  {
    "id": "arXiv:2112.14861",
    "title": "Using word clouds for fast identification of papers' subject domain and  reviewers' competences",
    "abstract": "Generating word (tag) clouds is a powerful data visualization technique that\nallows people to get easily acquainted with the content of a large collection\nof textual documents and identify their subject domains for a matter of\nseconds, without reading them at all. This paper suggests applying word clouds\nvisualization to conference management systems (specialized document management\nand decision support systems) in order to support and facilitate decision\nmaking in at least two important processes - forming the Programme Committee by\ninviting suitable reviewers and manual (re)assignment of reviewers to papers.\nWord clouds proved to be very useful tool for fast identification of papers'\nsubject domain and reviewers' competences.",
    "descriptor": "",
    "authors": [
      "Yordan Kalmukov"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2112.14861"
  },
  {
    "id": "arXiv:2112.14864",
    "title": "A high-order unfitted finite element method for moving interface  problems",
    "abstract": "We propose a $k^{\\rm th}$-order unfitted finite element method ($2\\le k\\le\n4$) to solve the moving interface problem of the Oseen equations. Thorough\nerror estimates for the discrete solutions are presented by considering errors\nfrom interface-tracking, time integration, and spatial discretization. In\nliteratures on time-dependent Stokes interface problems, error estimates for\nthe discrete pressure are usually sub-optimal, namely, $(k-1)^{\\rm th}$-order,\nunder the $L^2$-norm. We have obtained a $(k-1)^{\\rm th}$-order error estimate\nfor the discrete pressure under the $H^1$-norm. Numerical experiments for a\nseverely deforming interface show that optimal convergence orders are obtained\nfor $k = 3$ and $4$.",
    "descriptor": "",
    "authors": [
      "Chuwen Ma",
      "Weiying Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14864"
  },
  {
    "id": "arXiv:2112.14869",
    "title": "A Unified DRO View of Multi-class Loss Functions with top-N Consistency",
    "abstract": "Multi-class classification is one of the most common tasks in machine\nlearning applications, where data is labeled by one of many class labels. Many\nloss functions have been proposed for multi-class classification including two\nwell-known ones, namely the cross-entropy (CE) loss and the crammer-singer (CS)\nloss (aka. the SVM loss). While CS loss has been used widely for traditional\nmachine learning tasks, CE loss is usually a default choice for multi-class\ndeep learning tasks. There are also top-$k$ variants of CS loss and CE loss\nthat are proposed to promote the learning of a classifier for achieving better\ntop-$k$ accuracy. Nevertheless, it still remains unclear the relationship\nbetween these different losses, which hinders our understanding of their\nexpectations in different scenarios. In this paper, we present a unified view\nof the CS/CE losses and their smoothed top-$k$ variants by proposing a new\nfamily of loss functions, which are arguably better than the CS/CE losses when\nthe given label information is incomplete and noisy. The new family of smooth\nloss functions named {label-distributionally robust (LDR) loss} is defined by\nleveraging the distributionally robust optimization (DRO) framework to model\nthe uncertainty in the given label information, where the uncertainty over true\nclass labels is captured by using distributional weights for each label\nregularized by a function.",
    "descriptor": "",
    "authors": [
      "Dixian Zhu",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14869"
  },
  {
    "id": "arXiv:2112.14871",
    "title": "Analytical Models for Motifs in Temporal Networks: Discovering Trends  and Anomalies",
    "abstract": "Dynamic evolving networks capture temporal relations in domains such as\nsocial networks, communication networks, and financial transaction networks. In\nsuch networks, temporal motifs, which are repeated sequences of time-stamped\nedges/transactions, offer valuable information about the networks' evolution\nand function. However, currently no analytical models for temporal graphs exist\nand there are no models that would allow for scalable modeling of temporal\nmotif frequencies over time. Here, we develop the Temporal Activity State Block\nModel (TASBM), to model temporal motifs in temporal graphs. We develop\nefficient model fitting methods and derive closed-form expressions for the\nexpected motif frequencies and their variances in a given temporal network,\nthus enabling the discovery of statistically significant temporal motifs. Our\nTASMB framework can accurately track the changes in the expected motif\nfrequencies over time, and also scales well to networks with tens of millions\nof edges/transactions as it does not require time-consuming generation of many\nrandom temporal networks and then computing motif counts for each one of them.\nWe show that TASBM is able to model changes in temporal activity over time in a\nnetwork of financial transactions, a phone call, and an email network.\nAdditionally, we show that deviations from the expected motif counts calculated\nby our analytical framework correspond to anomalies in the financial\ntransactions and phone call networks.",
    "descriptor": "",
    "authors": [
      "Alexandra Porter",
      "Baharan Mirzasoleiman",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14871"
  },
  {
    "id": "arXiv:2112.14877",
    "title": "A Unified and Constructive Framework for the Universality of Neural  Networks",
    "abstract": "One of the reasons that many neural networks are capable of replicating\ncomplicated tasks or functions is their universality property. The past few\ndecades have seen many attempts in providing constructive proofs for single or\nclass of neural networks. This paper is an effort to provide a unified and\nconstructive framework for the universality of a large class of activations\nincluding most of existing activations and beyond. At the heart of the\nframework is the concept of neural network approximate identity. It turns out\nthat most of existing activations are neural network approximate identity, and\nthus universal in the space of continuous of functions on compacta. The\nframework induces several advantages. First, it is constructive with elementary\nmeans from functional analysis, probability theory, and numerical analysis.\nSecond, it is the first unified attempt that is valid for most of existing\nactivations. Third, as a by product, the framework provides the first\nuniversity proof for some of the existing activation functions including Mish,\nSiLU, ELU, GELU, and etc. Fourth, it discovers new activations with guaranteed\nuniversality property. Indeed, any activation\\textemdash whose $\\k$th\nderivative, with $\\k$ being an integer, is integrable and essentially\nbounded\\textemdash is universal. Fifth, for a given activation and error\ntolerance, the framework provides precisely the architecture of the\ncorresponding one-hidden neural network with predetermined number of neuron,\nand the values of weights/biases.",
    "descriptor": "",
    "authors": [
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.14877"
  },
  {
    "id": "arXiv:2112.14883",
    "title": "XLPN: Efficient and Scalable Cross-Ledger Protocols for the Topological  Consortium of Permissioned Blockchains",
    "abstract": "While increasingly more application-specific blockchains, or ledgers, are\nbeing implemented and deployed, exchanging information between these ledgers\nremains an open problem. Existing cross-ledger protocols (XLPs) exhibit a\nvariety of limitations such as scalability, liveness, efficiency, among others.\nThis paper proposes a new XLP, namely XLPN-22, which introduces a global\ntopology for the consortium of ledgers to achieve better efficiency and\nscalability of cross-ledger data exchanges. In this work, we prove the safety\nand liveness of XLPN-22 and analyze its theoretical complexity. We also\nimplement XLPN-22 on SciChain ledgers and evaluate it on up to 128 nodes, 8\nledgers, and 16,000 transactions. Experimental results show that XLPN-22\noutperforms two baseline protocols, namely VLDB-20 and PODC-18, by 18--50\\% and\n64--84\\%, respectively.",
    "descriptor": "",
    "authors": [
      "Dongfang Zhao"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.14883"
  },
  {
    "id": "arXiv:2112.14885",
    "title": "A Test Bench For Evaluating Exoskeletons For Upper Limb Rehabilitation",
    "abstract": "The potential of wearable robotics technology is undeniable. However,\nquantifying its value is difficult. Various types of exoskeleton robots have\nalready been developed and tested for upper limb rehabilitation but,\nevaluations are not standardized, particularly in pediatric rehabilitation.\nThis paper proposes a methodology for the quantitative evaluation of upper limb\nexoskeletons that, like a test bench, would serve for replicable testing. We\ndetermined the range of motion (ROM) and joint torques using both kinematic\nmodeling and experimental measurements (using sensors integrated into Dynamixel\nactuators). The proposed test bench can provide an accurate range of motion\n(ROM) and joint torques during the pronation-supination (PS) task. The range of\nmotion obtained with the physical prototype was approximately 156.26 +-\n4.71{\\deg} during the PS task, while it was approximately 146.84 +- 14.32{\\deg}\nfor the multibody model. The results show that the average range of\nexperimental torques (0.28 +- 0.06 N.m) was overestimated by 40% and just 3.4%,\nrespectively, when compared to the average range of simulated torques (0.2 +-\n0.05 N.m) and to the highest range of simulated torques (0.29 N.m). For the\nexperimental measurements, test-retest reliability was excellent (0.96-0.98)\nwithin sessions and excellent (0.93) or good (0.81-0.86) between sessions.\nFinally, the suggested approach provides a ROM close to the normal ROM\nnecessary during PS tasks. These results validate the measurements' accuracy\nand underline the proposed methodology's relevance. The proposed test bench\ncould become a reference standard for evaluating exoskeletons. This study also\naddresses a methodological aspect on the accurate assessment of joint torques\nthat can serve in applications such as the sizing of actuators in exoskeletons\nor the non-invasive evaluation of muscle forces in the human body.",
    "descriptor": "\nComments: 35 pages and 7 figures\n",
    "authors": [
      "Clautilde Nguiadem",
      "Maxime Raison",
      "Sofiane Achiche"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.14885"
  },
  {
    "id": "arXiv:2112.14887",
    "title": "Accurate Automotive Radar Based Metric Localization with Explicit  Doppler Compensation",
    "abstract": "Automotive mmWave radar has been widely used in the automotive industry due\nto its small size, low cost, and complementary advantages to optical sensors\n(cameras, LiDAR, etc.) in adverse weathers, e.g., fog, raining, and snowing. On\nthe other side, its large wavelength also poses fundamental challenges to\nperceive the environment. Recent advances have made breakthroughs on its\ninherent drawbacks, i.e., the multipath reflection and the sparsity of mmWave\nradar's point clouds. However, the lower frequency of mmWave signals is more\nsensitive to vehicles' mobility than that of the visual and laser signals. This\nwork focuses on the problem of frequency shift, i.e., the Doppler effect\ndistorts the radar ranging measurements and its knock-on effect on metric\nlocalization. We propose a new radar-based metric localization framework that\nobtains more accurate location estimation by restoring the Doppler distortion.\nSpecifically, we first design a new algorithm that explicitly compensates the\nDoppler distortion of radar scans and then model the measurement uncertainty of\nthe Doppler-compensated point cloud to further optimize the metric\nlocalization. Extensive experiments using the public nuScenes dataset and Carla\nsimulator demonstrate that our method outperforms the state-of-the-art approach\nby 19.2\\% and 13.5\\% improvements in terms of translation and rotation errors,\nrespectively.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Pengen Gao",
      "Shengkai Zhang",
      "Wei Wang",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.14887"
  },
  {
    "id": "arXiv:2112.14889",
    "title": "Few-shot Backdoor Defense Using Shapley Estimation",
    "abstract": "Deep neural networks have achieved impressive performance in a variety of\ntasks over the last decade, such as autonomous driving, face recognition, and\nmedical diagnosis. However, prior works show that deep neural networks are\neasily manipulated into specific, attacker-decided behaviors in the inference\nstage by backdoor attacks which inject malicious small hidden triggers into\nmodel training, raising serious security threats. To determine the triggered\nneurons and protect against backdoor attacks, we exploit Shapley value and\ndevelop a new approach called Shapley Pruning (ShapPruning) that successfully\nmitigates backdoor attacks from models in a data-insufficient situation (1\nimage per class or even free of data). Considering the interaction between\nneurons, ShapPruning identifies the few infected neurons (under 1% of all\nneurons) and manages to protect the model's structure and accuracy after\npruning as many infected neurons as possible. To accelerate ShapPruning, we\nfurther propose discarding threshold and $\\epsilon$-greedy strategy to\naccelerate Shapley estimation, making it possible to repair poisoned models\nwith only several minutes. Experiments demonstrate the effectiveness and\nrobustness of our method against various attacks and tasks compared to existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Jiyang Guan",
      "Zhuozhuo Tu",
      "Ran He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.14889"
  },
  {
    "id": "arXiv:2112.14890",
    "title": "QEMind: Alibaba's Submission to the WMT21 Quality Estimation Shared Task",
    "abstract": "Quality Estimation, as a crucial step of quality control for machine\ntranslation, has been explored for years. The goal is to investigate automatic\nmethods for estimating the quality of machine translation results without\nreference translations. In this year's WMT QE shared task, we utilize the\nlarge-scale XLM-Roberta pre-trained model and additionally propose several\nuseful features to evaluate the uncertainty of the translations to build our QE\nsystem, named \\textit{QEMind}. The system has been applied to the\nsentence-level scoring task of Direct Assessment and the binary score\nprediction task of Critical Error Detection. In this paper, we present our\nsubmissions to the WMT 2021 QE shared task and an extensive set of experimental\nresults have shown us that our multilingual systems outperform the best system\nin the Direct Assessment QE task of WMT 2020.",
    "descriptor": "\nComments: Winner of WMT 2021 QE shared task 1\n",
    "authors": [
      "Jiayi Wang",
      "Ke Wang",
      "Boxing Chen",
      "Yu Zhao",
      "Weihua Luo",
      "Yuqi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.14890"
  },
  {
    "id": "arXiv:2112.14893",
    "title": "Reversible Upper Confidence Bound Algorithm to Generate Diverse  Optimized Candidates",
    "abstract": "Most algorithms for the multi-armed bandit problem in reinforcement learning\naimed to maximize the expected reward, which are thus useful in searching the\noptimized candidate with the highest reward (function value) for diverse\napplications (e.g., AlphaGo). However, in some typical application scenaios\nsuch as drug discovery, the aim is to search a diverse set of candidates with\nhigh reward. Here we propose a reversible upper confidence bound (rUCB)\nalgorithm for such a purpose, and demonstrate its application in virtual\nscreening upon intrinsically disordered proteins (IDPs). It is shown that rUCB\ngreatly reduces the query times while achieving both high accuracy and low\nperformance loss.The rUCB may have potential application in multipoint\noptimization and other reinforcement-learning cases.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Bin Chong",
      "Yingguang Yang",
      "Zi-Le Wang",
      "Hang Xing",
      "Zhirong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14893"
  },
  {
    "id": "arXiv:2112.14894",
    "title": "Feature Generation and Hypothesis Verification for Reliable Face  Anti-Spoofing",
    "abstract": "Although existing face anti-spoofing (FAS) methods achieve high accuracy in\nintra-domain experiments, their effects drop severely in cross-domain scenarios\nbecause of poor generalization. Recently, multifarious techniques have been\nexplored, such as domain generalization and representation disentanglement.\nHowever, the improvement is still limited by two issues: 1) It is difficult to\nperfectly map all faces to a shared feature space. If faces from unknown\ndomains are not mapped to the known region in the shared feature space,\naccidentally inaccurate predictions will be obtained. 2) It is hard to\ncompletely consider various spoof traces for disentanglement. In this paper, we\npropose a Feature Generation and Hypothesis Verification framework to alleviate\nthe two issues. Above all, feature generation networks which generate\nhypotheses of real faces and known attacks are introduced for the first time in\nthe FAS task. Subsequently, two hypothesis verification modules are applied to\njudge whether the input face comes from the real-face space and the real-face\ndistribution respectively. Furthermore, some analyses of the relationship\nbetween our framework and Bayesian uncertainty estimation are given, which\nprovides theoretical support for reliable defense in unknown domains.\nExperimental results show our framework achieves promising results and\noutperforms the state-of-the-art approaches on extensive public datasets.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Shice Liu",
      "Shitao Lu",
      "Hongyi Xu",
      "Jing Yang",
      "Shouhong Ding",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14894"
  },
  {
    "id": "arXiv:2112.14900",
    "title": "Motif Graph Neural Network",
    "abstract": "Graphs can model complicated interactions between entities, which naturally\nemerge in many important applications. These applications can often be cast\ninto standard graph learning tasks, in which a crucial step is to learn\nlow-dimensional graph representations. Graph neural networks (GNNs) are\ncurrently the most popular model in graph embedding approaches. However,\nstandard GNNs in the neighborhood aggregation paradigm suffer from limited\ndiscriminative power in distinguishing \\emph{high-order} graph structures as\nopposed to \\emph{low-order} structures. To capture high-order structures,\nresearchers have resorted to motifs and developed motif-based GNNs. However,\nexisting motif-based GNNs still often suffer from less discriminative power on\nhigh-order structures. To overcome the above limitations, we propose Motif\nGraph Neural Network (MGNN), a novel framework to better capture high-order\nstructures, hinging on our proposed motif redundancy minimization operator and\ninjective motif combination. First, MGNN produces a set of node representations\nw.r.t. each motif. The next phase is our proposed redundancy minimization among\nmotifs which compares the motifs with each other and distills the features\nunique to each motif. Finally, MGNN performs the updating of node\nrepresentations by combining multiple representations from different motifs. In\nparticular, to enhance the discriminative power, MGNN utilizes an injective\nfunction to combine the representations w.r.t. different motifs. We further\nshow that our proposed architecture increases the expressive power of GNNs with\na theoretical analysis. We demonstrate that MGNN outperforms state-of-the-art\nmethods on seven public benchmarks on both node classification and graph\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Xuexin Chen",
      "Ruichu Cai",
      "Yuan Fang",
      "Min Wu",
      "Zijian Li",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14900"
  },
  {
    "id": "arXiv:2112.14901",
    "title": "On-Policy Robust Adaptive Discrete-Time Regulator for Passive  Unidirectional System using Stochastic Hill-climbing Algorithm and Associated  Search Element",
    "abstract": "Non-linear discrete-time state-feedback regulators are widely used in passive\nunidirectional systems. Offline system identification is required for tuning\nparameters of these regulators. However, offline system identification is\nchallenging in some applications. Furthermore, the parameters of a system may\nbe slowly changing over time, which makes the system identification less\neffective. Many adaptive regulators have been proposed to tune the parameters\nonline when the offline information is neither accessible nor time-invariant.\nStability and convergence of these adaptive regulators are challenging,\nespecially in unidirectional systems. In this paper, a novel adaptive regulator\nis proposed for first-order unidirectional passive systems. In this method, an\nassociated search element checks the eligibility of the update law. Then, a\nstochastic hill-climbing algorithm updates the parameters of the discrete-time\nstate-feedback regulator. Simulation results demonstrate the effectiveness of\nthe proposed method. The experiments on regulating of two passive systems show\nthe ability of the method in regulating of passive unidirectional system in the\npresence of noise and disturbance.",
    "descriptor": "\nComments: This paper is original and not published anywhere. It showed effectiveness in controlling unidirectional systems (thermal actuators) such as SMA and TCP actuators. It has 24 pages including references, 9 figures and 6 algorithms. Both theoretical simulations and experiments are included\n",
    "authors": [
      "Mohsen Jafarzadeh",
      "Nicholas Gans",
      "Yonas Tadesse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14901"
  },
  {
    "id": "arXiv:2112.14911",
    "title": "A Survey of Deep Learning Techniques for Dynamic Branch Prediction",
    "abstract": "Branch prediction is an architectural feature that speeds up the execution of\nbranch instruction on pipeline processors and reduces the cost of branching.\nRecent advancements of Deep Learning (DL) in the post Moore's Law era is\naccelerating areas of automated chip design, low-power computer architectures,\nand much more. Traditional computer architecture design and algorithms could\nbenefit from dynamic predictors based on deep learning algorithms which learns\nfrom experience by optimizing its parameters on large number of data. In this\nsurvey paper, we focus on traditional branch prediction algorithms, analyzes\nits limitations, and presents a literature survey of how deep learning\ntechniques can be applied to create dynamic branch predictors capable of\npredicting conditional branch instructions. Prior surveys in this field focus\non dynamic branch prediction techniques based on neural network perceptrons. We\nplan to improve the survey based on latest research in DL and advanced Machine\nLearning (ML) based branch predictors.",
    "descriptor": "\nComments: Survey paper\n",
    "authors": [
      "Rinu Joseph"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14911"
  },
  {
    "id": "arXiv:2112.14912",
    "title": "Risk-Bounded Control with Kalman Filtering and Stochastic Barrier  Functions",
    "abstract": "In this paper, we study Stochastic Control Barrier Functions (SCBFs) to\nenable the design of probabilistic safe real-time controllers in presence of\nuncertainties and based on noisy measurements. Our goal is to design\ncontrollers that bound the probability of a system failure in finite-time to a\ngiven desired value. To that end, we first estimate the system states from the\nnoisy measurements using an Extended Kalman filter, and compute confidence\nintervals on the filtering errors. Then, we account for filtering errors and\nderive sufficient conditions on the control input based on the estimated states\nto bound the probability that the real states of the system enter an unsafe\nregion within a finite time interval. We show that these sufficient conditions\nare linear constraints on the control input, and, hence, they can be used in\ntractable optimization problems to achieve safety, in addition to other\nproperties like reachability, and stability. Our approach is evaluated using a\nsimulation of a lane-changing scenario on a highway with dense traffic.",
    "descriptor": "\nComments: CDC 2021, 60th Conference on Decision and Control, 7 pages\n",
    "authors": [
      "Shakiba Yaghoubi",
      "Georgios Fainekos",
      "Tomoya Yamaguchi",
      "Danil Prokhorov",
      "Bardh Hoxha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.14912"
  },
  {
    "id": "arXiv:2112.14916",
    "title": "INTCP: Information-centric TCP for Satellite Network",
    "abstract": "Satellite networks are booming to provide high-speed and low latency Internet\naccess, but the transport layer becomes one of the main obstacles. Legacy\nend-to-end TCP is designed for terrestrial networks, not suitable for\nerror-prone, propagation delay varying, and intermittent satellite links. It is\nnecessary to make a clean-slate design for the satellite transport layer. This\npaper introduces a novel Information-centric Hop-by-Hop transport layer design,\nINTCP. It carries out hop-by-hop packets retransmission and hop-by-hop\ncongestion control with the help of cache and request-response model.\nHop-by-hop retransmission recovers lost packets on hop, reduces retransmission\ndelay. INTCP controls traffic and congestion also by hop. Each hop tries its\nbest to maximize its bandwidth utilization and improves end-to-end throughput.\nThe capability of caching enables asynchronous multicast in transport layer.\nThis would save precious spectrum resources in the satellite network. The\nperformance of INTCP is evaluated with the simulated Starlink constellation.\nLong-distance communication with more than 1000km is carried out. The results\ndemonstrate that, for the unicast scenario INTCP could reduce 42% one-way\ndelay, 53% delay jitters, and improve 60% throughput compared with the legacy\nTCP. In multicast scenario, INTCP could achieve more than 6X throughput.",
    "descriptor": "",
    "authors": [
      "Jinyu Yin",
      "Li Jiang",
      "Xinggong Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.14916"
  },
  {
    "id": "arXiv:2112.14921",
    "title": "Retrieving Black-box Optimal Images from External Databases",
    "abstract": "Suppose we have a black-box function (e.g., deep neural network) that takes\nan image as input and outputs a value that indicates preference. How can we\nretrieve optimal images with respect to this function from an external database\non the Internet? Standard retrieval problems in the literature (e.g., item\nrecommendations) assume that an algorithm has full access to the set of items.\nIn other words, such algorithms are designed for service providers. In this\npaper, we consider the retrieval problem under different assumptions.\nSpecifically, we consider how users with limited access to an image database\ncan retrieve images using their own black-box functions. This formulation\nenables a flexible and finer-grained image search defined by each user. We\nassume the user can access the database through a search query with tight API\nlimits. Therefore, a user needs to efficiently retrieve optimal images in terms\nof the number of queries. We propose an efficient retrieval algorithm Tiara for\nthis problem. In the experiments, we confirm that our proposed method performs\nbetter than several baselines under various settings.",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14921"
  },
  {
    "id": "arXiv:2112.14927",
    "title": "An Empirical Study of Security Practices for Microservices Systems",
    "abstract": "Despite the numerous benefits of microservices systems, security has been a\ncritical issue in such systems. Several factors explain this difficulty,\nincluding a knowledge gap among microservices practitioners on properly\nsecuring a microservices system. To (partially) bridge this gap, we conducted\nan empirical study to manually analyze 861 security points collected from 10\nGitHub open-source microservices systems and Stack Overflow posts concerning\nsecurity of microservices systems, leading to a catalog of 28 microservices\nsecurity practices. We then ran a survey with 63 microservices practitioners to\nevaluate the usefulness of these 28 practices. Our findings demonstrate that\nthe survey respondents affirmed the usefulness of the 28 practices. These 28\nsecurity practices are further classified into six categories based on their\ntopics: Authorization and Authentication, Token and Credentials, Internal and\nExternal Microservices, Microservices Communications, Private Microservices,\nand Database and Environments. We believe that the catalog of microservices\nsecurity practices can serve as a valuable resource for microservices\npractitioners to more effectively address security issues in microservices\nsystems. It can also inform the research community of the required or less\nexplored areas to develop microservices-specific security practices and tools.",
    "descriptor": "\nComments: 18 pages, 5 images, 8 tables, Manuscript submitted to a Journal (2021)\n",
    "authors": [
      "Ali Rezaei Nasab",
      "Mojtaba Shahin",
      "Seyed Ali Hoseyni Raviz",
      "Peng Liang",
      "Amir Mashmool",
      "Valentina Lenarduzzi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14927"
  },
  {
    "id": "arXiv:2112.14928",
    "title": "An empirical user-study of text-based nonverbal annotation systems for  human-human conversations",
    "abstract": "the substantial increase in the number of online human-human conversations\nand the usefulness of multimodal transcripts, there is a rising need for\nautomated multimodal transcription systems to help us better understand the\nconversations. In this paper, we evaluated three methods to perform multimodal\ntranscription. They were (1) Jefferson -- an existing manual system used widely\nby the linguistics community, (2) MONAH -- a system that aimed to make\nmultimodal transcripts accessible and automated, (3) MONAH+ -- a system that\nbuilds on MONAH that visualizes machine attention. Based on 104 participants\nresponses, we found that (1) all text-based methods significantly reduced the\namount of information for the human users, (2) MONAH was found to be more\nusable than Jefferson, (3) Jefferson's relative strength was in chronemics\n(pace / delay) and paralinguistics (pitch / volume) annotations, whilst MONAH's\nrelative strength was in kinesics (body language) annotations, (4) enlarging\nwords' font-size based on machine attention was confusing human users as\nloudness. These results pose considerations for researchers designing a\nmultimodal annotation system for the masses who would like a fully-automated or\nhuman-augmented conversational analysis system.",
    "descriptor": "\nComments: 45 pages\n",
    "authors": [
      "Joshua Y. Kim",
      "Kalina Yacef"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.14928"
  },
  {
    "id": "arXiv:2112.14930",
    "title": "Feature extraction with mel scale separation method on noise audio  recordings",
    "abstract": "This paper focuses on improving the accuracy of noise audio recordings.\nHigh-quality audio recording, extraction using the mel frequency cepstral\ncoefficients (MFCC) method produces high accuracy. While the low-quality is\nbecause of noise, the accuracy is low. Improved accuracy by investigating the\neffect of bandwidth on the mel scale. The proposed improvement uses the mel\nscale separation methods into two frequency channels (MFCC dual channel). For\nthe comparison method using the mel scale bandwidth without separation (MFCC\nsingle-channel). Feature analysis using k-mean clustering. The data uses a\nnoise variance of up to -16 dB. Testing on the MFCC single channel method for\n-16 dB noise has an accuracy of 47.5%, while the MFCC dual-channel method has\nan accuracy better of 76.25%. The next test used adaptive noise-canceling (ANC)\nto reduce noise before extraction. The result is that the MFCC single-channel\nmethod has an accuracy of 82.5% and the MFCC dual-channel method has an\naccuracy better of 83.75%. High-quality audio recording testing for the MFCC\nsingle-channel method has an accuracy of 92.5% and the MFCC dual-channel method\nhas an accuracy better of 97.5%. The test results show the effect of mel scale\nbandwidth to increase accuracy. The MFCC dual-channel method has higher\naccuracy.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Roy Rudolf Huizen",
      "Florentina Tatrin Kurniati"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.14930"
  },
  {
    "id": "arXiv:2112.14931",
    "title": "Dense Depth Estimation from Multiple 360-degree Images Using Virtual  Depth",
    "abstract": "In this paper, we propose a dense depth estimation pipeline for multiview\n360\\degree\\: images. The proposed pipeline leverages a spherical camera model\nthat compensates for radial distortion in 360\\degree\\: images. The key\ncontribution of this paper is the extension of a spherical camera model to\nmultiview by introducing a translation scaling scheme. Moreover, we propose an\neffective dense depth estimation method by setting virtual depth and minimizing\nphotonic reprojection error. We validate the performance of the proposed\npipeline using the images of natural scenes as well as the synthesized dataset\nfor quantitive evaluation. The experimental results verify that the proposed\npipeline improves estimation accuracy compared to the current state-of-art\ndense depth estimation methods.",
    "descriptor": "",
    "authors": [
      "Seongyeop Yang",
      "Kunhee Kim",
      "Yeejin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.14931"
  },
  {
    "id": "arXiv:2112.14933",
    "title": "RheFrameDetect: A Text Classification System for Automatic Detection of  Rhetorical Frames in AI from Open Sources",
    "abstract": "Rhetorical Frames in AI can be thought of as expressions that describe AI\ndevelopment as a competition between two or more actors, such as governments or\ncompanies. Examples of such Frames include robotic arms race, AI rivalry,\ntechnological supremacy, cyberwarfare dominance and 5G race. Detection of\nRhetorical Frames from open sources can help us track the attitudes of\ngovernments or companies towards AI, specifically whether attitudes are\nbecoming more cooperative or competitive over time. Given the rapidly\nincreasing volumes of open sources (online news media, twitter, blogs), it is\ndifficult for subject matter experts to identify Rhetorical Frames in (near)\nreal-time. Moreover, these sources are in general unstructured (noisy) and\ntherefore, detecting Frames from these sources will require state-of-the-art\ntext classification techniques. In this paper, we develop RheFrameDetect, a\ntext classification system for (near) real-time capture of Rhetorical Frames\nfrom open sources. Given an input document, RheFrameDetect employs text\nclassification techniques at multiple levels (document level and paragraph\nlevel) to identify all occurrences of Frames used in the discussion of AI. We\nperformed extensive evaluation of the text classification techniques used in\nRheFrameDetect against human annotated Frames from multiple news sources. To\nfurther demonstrate the effectiveness of RheFrameDetect, we show multiple case\nstudies depicting the Frames identified by RheFrameDetect compared against\nhuman annotated Frames.",
    "descriptor": "",
    "authors": [
      "Saurav Ghosh",
      "Philippe Loustaunau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14933"
  },
  {
    "id": "arXiv:2112.14934",
    "title": "SFU-HW-Tracks-v1: Object Tracking Dataset on Raw Video Sequences",
    "abstract": "We present a dataset that contains object annotations with unique object\nidentities (IDs) for the High Efficiency Video Coding (HEVC) v1 Common Test\nConditions (CTC) sequences. Ground-truth annotations for 13 sequences were\nprepared and released as the dataset called SFU-HW-Tracks-v1. For each video\nframe, ground truth annotations include object class ID, object ID, and\nbounding box location and its dimensions. The dataset can be used to evaluate\nobject tracking performance on uncompressed video sequences and study the\nrelationship between video compression and object tracking.",
    "descriptor": "\nComments: 4 pages, 3 figures, submitted to Data in Brief\n",
    "authors": [
      "Takehiro Tanaka",
      "Hyomin Choi",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.14934"
  },
  {
    "id": "arXiv:2112.14936",
    "title": "Are we really making much progress? Revisiting, benchmarking, and  refining heterogeneous graph neural networks",
    "abstract": "Heterogeneous graph neural networks (HGNNs) have been blossoming in recent\nyears, but the unique data processing and evaluation setups used by each work\nobstruct a full understanding of their advancements. In this work, we present a\nsystematical reproduction of 12 recent HGNNs by using their official codes,\ndatasets, settings, and hyperparameters, revealing surprising findings about\nthe progress of HGNNs. We find that the simple homogeneous GNNs, e.g., GCN and\nGAT, are largely underestimated due to improper settings. GAT with proper\ninputs can generally match or outperform all existing HGNNs across various\nscenarios. To facilitate robust and reproducible HGNN research, we construct\nthe Heterogeneous Graph Benchmark (HGB), consisting of 11 diverse datasets with\nthree tasks. HGB standardizes the process of heterogeneous graph data splits,\nfeature processing, and performance evaluation. Finally, we introduce a simple\nbut very strong baseline Simple-HGN--which significantly outperforms all\nprevious models on HGB--to accelerate the advancement of HGNNs in the future.",
    "descriptor": "\nComments: KDD 2021 research track\n",
    "authors": [
      "Qingsong Lv",
      "Ming Ding",
      "Qiang Liu",
      "Yuxiang Chen",
      "Wenzheng Feng",
      "Siming He",
      "Chang Zhou",
      "Jianguo Jiang",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14936"
  },
  {
    "id": "arXiv:2112.14938",
    "title": "Automatic Mixed-Precision Quantization Search of BERT",
    "abstract": "Pre-trained language models such as BERT have shown remarkable effectiveness\nin various natural language processing tasks. However, these models usually\ncontain millions of parameters, which prevents them from practical deployment\non resource-constrained devices. Knowledge distillation, Weight pruning, and\nQuantization are known to be the main directions in model compression. However,\ncompact models obtained through knowledge distillation may suffer from\nsignificant accuracy drop even for a relatively small compression ratio. On the\nother hand, there are only a few quantization attempts that are specifically\ndesigned for natural language processing tasks. They suffer from a small\ncompression ratio or a large error rate since manual setting on\nhyper-parameters is required and fine-grained subgroup-wise quantization is not\nsupported. In this paper, we proposed an automatic mixed-precision quantization\nframework designed for BERT that can simultaneously conduct quantization and\npruning in a subgroup-wise level. Specifically, our proposed method leverages\nDifferentiable Neural Architecture Search to assign scale and precision for\nparameters in each sub-group automatically, and at the same time pruning out\nredundant groups of parameters. Extensive evaluations on BERT downstream tasks\nreveal that our proposed method outperforms baselines by providing the same\nperformance with much smaller model size. We also show the feasibility of\nobtaining the extremely light-weight model by combining our solution with\northogonal methods such as DistilBERT.",
    "descriptor": "",
    "authors": [
      "Changsheng Zhao",
      "Ting Hua",
      "Yilin Shen",
      "Qian Lou",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14938"
  },
  {
    "id": "arXiv:2112.14940",
    "title": "Close Friends, Popular Peers, Team formation and Leadership in Group  Projects",
    "abstract": "The paper discusses diverse interconnected relationships formed within a\nseemingly unrelated group of students and a conceptually different problem\nstatement. This study uses a Social Network Analysis (SNA) to analyze and map\nthe connections among the individuals. SNA facilitates understanding the\npsychology of a group of people while performing a certain task. This could\nhelp predict further patterns in which a similar group might perform these\ntasks. As discussed in this paper, the analysis of selection of teammates for a\nproject indirectly implies friendships in a department and can predict new\nfriendships that could result from these. The data collected can be represented\nas a Social Network using various analysis tools such as Gephi and NodeXL. The\nresult of the analysis determines the popular peer among the students and\nelucidates the reason behind it. Also, various other Inferences such as the\nclose friends list, Social Influence of a node, and more were deduced.",
    "descriptor": "",
    "authors": [
      "Deekshajyothi S",
      "Gowrishankar G"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14940"
  },
  {
    "id": "arXiv:2112.14941",
    "title": "A General Traffic Shaping Protocol in E-Commerce",
    "abstract": "To approach different business objectives, online traffic shaping algorithms\naim at improving exposures of a target set of items, such as boosting the\ngrowth of new commodities. Generally, these algorithms assume that the utility\nof each user-item pair can be accessed via a well-trained conversion rate\nprediction model. However, for real E-Commerce platforms, there are unavoidable\nfactors preventing us from learning such an accurate model. In order to break\nthe heavy dependence on accurate inputs of the utility, we propose a general\nonline traffic shaping protocol for online E-Commerce applications. In our\nframework, we approximate the function mapping the bonus scores, which\ngenerally are the only method to influence the ranking result in the traffic\nshaping problem, to the numbers of exposures and purchases. Concretely, we\napproximate the above function by a class of the piece-wise linear function\nconstructed on the convex hull of the explored data points. Moreover, we\nreformulate the online traffic shaping problem as linear programming where\nthese piece-wise linear functions are embedded into both the objective and\nconstraints. Our algorithm can straightforwardly optimize the linear\nprogramming in the prime space, and its solution can be simply applied by a\nstochastic strategy to fulfill the optimized objective and the constraints in\nexpectation. Finally, the online A/B test shows our proposed algorithm steadily\noutperforms the previous industrial level traffic shaping algorithm.",
    "descriptor": "",
    "authors": [
      "Chenlin Shen",
      "Guangda Huzhang",
      "Yuhang Zhou",
      "Chen Liang",
      "Qing Da"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.14941"
  },
  {
    "id": "arXiv:2112.14944",
    "title": "PPRviz: Effective and Efficient Graph Visualization based on  Personalized PageRank",
    "abstract": "Graph visualization is an important problem that finds applications in\nvarious domains, e.g., social network analysis, traffic planning, and\nbioinformatics. Existing solutions for graph visualization, however, fail to\nscale to large graphs with millions of nodes, as they either provide inferior\nvisualization results or incur significant computational cost. To address the\ndeficiencies of prior works, we propose PPRviz, a multi-level visualization\nmethod for large graphs. Lying in the core of PPRviz is a new measure of graph\nnode distance, PDist, that is specifically designed for visualization. In\nparticular, PDist is formulated based on personalized PageRank, and it provides\nnon-trivial theoretical guarantees for two well-adopted aesthetic measures. We\npresent efficient algorithms for estimating PDist with provable accuracy and\ntime complexity, while incurring small preprocessing costs. Extensive\nexperiments show that PPRviz significantly outperforms 13 state-of-the-art\ncompetitors on 12 real-world graphs in terms of both effectiveness and\nefficiency, and that PPRviz provides interactive visualizations within one\nsecond on billion-edge graphs.",
    "descriptor": "\nComments: Technical report for VLDB 2022\n",
    "authors": [
      "Shiqi Zhang",
      "Renchi Yang",
      "Xiaokui Xiao",
      "Xiao Yan",
      "Bo Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14944"
  },
  {
    "id": "arXiv:2112.14947",
    "title": "AutoCast: Scalable Infrastructure-less Cooperative Perception for  Distributed Collaborative Driving",
    "abstract": "Autonomous vehicles use 3D sensors for perception. Cooperative perception\nenables vehicles to share sensor readings with each other to improve safety.\nPrior work in cooperative perception scales poorly even with infrastructure\nsupport. AutoCast enables scalable infrastructure-less cooperative perception\nusing direct vehicle-to-vehicle communication. It carefully determines which\nobjects to share based on positional relationships between traffic\nparticipants, and the time evolution of their trajectories. It coordinates\nvehicles and optimally schedules transmissions in a distributed fashion.\nExtensive evaluation results under different scenarios show that, unlike\ncompeting approaches, AutoCast can avoid crashes and near-misses which occur\nfrequently without cooperative perception, its performance scales gracefully in\ndense traffic scenarios providing 2-4x visibility into safety critical objects\ncompared to existing cooperative perception schemes, its transmission schedules\ncan be completed on the real radio testbed, and its scheduling algorithm is\nnear-optimal with negligible computation overhead.",
    "descriptor": "",
    "authors": [
      "Hang Qiu",
      "Pohan Huang",
      "Namo Asavisanu",
      "Xiaochen Liu",
      "Konstantinos Psounis",
      "Ramesh Govindan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14947"
  },
  {
    "id": "arXiv:2112.14948",
    "title": "Data-Driven State Estimation for Light-Emitting Diode Underwater Optical  Communication",
    "abstract": "Light-Emitting Diodes (LEDs) based underwater optical wireless communications\n(UOWCs), a technology with low latency and high data rates, have attracted\nsignificant importance for underwater robots. However, maintaining a controlled\nline of sight link between transmitter and receiver is challenging due to the\nconstant movement of the underlying optical platform caused by the dynamic\nuncertainties of the LED model and vibration effects. Additionally, the\nalignment angle required for tracking is not directly measured and has to be\nestimated. Besides, the light scattering propagates beam pulse in water\ntemporally, resulting in time-varying underwater optical links with\ninterference. We address the state estimation problem by designing an LED\ncommunication system that provides the angular position and velocity\ninformation to overcome the challenges. In this way, we leverage the power of\ndeep learning-based observer design to explore the LED communication's state\nspace properly. Simulation results are presented to illustrate the performance\nof the data-driven LED state estimation.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Yingquan Li",
      "Zhenwen Liang",
      "Ibrahima N'Doye",
      "Xiangliang Zhang",
      "Mohamed-Slim Alouini",
      "Taous-Meriem Laleg-Kirati"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14948"
  },
  {
    "id": "arXiv:2112.14952",
    "title": "A Survey of fault mitigation techniques for multi-core architectures",
    "abstract": "Fault tolerance in multi-core architecture has attracted attention of\nresearch community for the past 20 years. Rapid improvements in the CMOS\ntechnology resulted in exponential growth of transistor density. It resulted in\nincreased challenges for designing resilient multi-core architecture at the\nsame pace. The article presents a survey of fault tolerant methods like fault\ndetection, recovery, re-configurability and repair techniques for multi-core\narchitectures. Salvaging at micro-architectural and architectural level are\nalso discussed. Gamut of fault tolerant approaches discussed in this article\nhave tangible improvements on the reliability of the multi-core architectures.\nEvery concept in the seminal articles is examined with respect to relevant\nmetrics like performance cost, area overhead, fault coverage, level of\nprotection, detection latency and Mean Time To Failure. The existing literature\nis critically examined. New research directions in the form of new fault\ntolerant design alternatives for both homogeneous and heterogeneous multi-core\narchitectures are presented. Brief on an analytical approach for fault\ntolerating model is suggested for Intel and AMD based modern homogeneous\nmulti-core architecture are presented to enhance the understanding of the\nreaders about the architecture with respect to performance degradation, memory\naccess time and execution time.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Shashikiran Venkatesha",
      "Ranjani Parthasarathi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.14952"
  },
  {
    "id": "arXiv:2112.14953",
    "title": "Adaptive Gaussian Process based Stochastic Trajectory Optimization for  Motion Planning",
    "abstract": "We propose a new formulation of optimal motion planning (OMP) algorithm for\nrobots operating in a hazardous environment, called adaptive Gaussian-process\nbased stochastic trajectory optimization (AGP-STO). It first restarts the\naccelerated gradient descent with the reestimated Lipschitz constant (L-reAGD)\nto improve the computation efficiency, only requiring 1st-order momentum.\nHowever, it still cannot infer a global optimum of the nonconvex problem,\ninformed by the prior information of Gaussian-process (GP) and obstacles. So it\nthen integrates the adaptive stochastic trajectory optimization (ASTO) in the\nL-reestimation process to learn the GP-prior rewarded by the important samples\nvia accelerated moving averaging (AMA). Moreover, we introduce the incremental\noptimal motion planning (iOMP) to upgrade AGP-STO to iAGP-STO. It interpolates\nthe trajectory incrementally among the previously optimized waypoints to ensure\ntime-continuous safety. Finally, we benchmark iAGP-STO against the numerical\n(CHOMP, TrajOpt, GPMP) and sampling (STOMP, RRT-Connect) methods and conduct\nthe tuning experiment of key parameters to show how the integration of L-reAGD,\nASTO, and iOMP elevates computation efficiency and reliability. Moreover, the\nimplementation of iAGP- STO on LBR-iiwa, multi-AGV, and rethink-Baxter\ndemonstrates its application in manipulation, collaboration, and assistance.",
    "descriptor": "",
    "authors": [
      "Feng Yichang",
      "Zhang Haiyun",
      "Wang Jin",
      "Lu Guodong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.14953"
  },
  {
    "id": "arXiv:2112.14954",
    "title": "Set membership with two classical and quantum bit probes",
    "abstract": "We consider the following problem: Given a set S of at most n elements from a\nuniverse of size m, represent it in memory as a bit string so that membership\nqueries of the form \"Is x in S?\" can be answered by making at most t probes\ninto the bit string. Let s(m,n,t) be the minimum number of bits needed by any\nsuch scheme. We obtain new upper bounds for s(m,n,t=2), which match or improve\nall the previously known bounds. We also consider the quantum version of this\nproblem and obtain improved upper bounds.",
    "descriptor": "",
    "authors": [
      "Shyam Dhamapurkar",
      "Shubham Vivek Pawar",
      "Jaikumar Radhakrishnan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.14954"
  },
  {
    "id": "arXiv:2112.14957",
    "title": "Tiansuan Constellation: An Open Research Platform",
    "abstract": "Satellite network is the first step of interstellar voyages. It can provide\nglobal Internet connectivity everywhere on earth, where most areas cannot\naccess the Internet by the terrestrial infrastructure due to the geographic\naccessibility and high cost. The space industry experiences a rise in large\nlow-earth-orbit satellite constellations to achieve universal connectivity. The\nresearch community is also urgent to do some leading research to bridge the\nconnectivity divide. Researchers now conduct their work by simulation, which is\nfar from enough. However, experiments on real satellites are blocked by the\nhigh threshold of space technology, such as deployment cost and unknown risks.\nTo solve the above dilemma, we are eager to contribute to the universal\nconnectivity and build an open research platform, Tiansuan constellation to\nsupport experiments on real satellite networks. We discuss the potential\nresearch topics that would benefit from Tiansuan constellation. We provide two\ncase studies that have already deployed in two experimental satellites of\nTiansuan constellation.",
    "descriptor": "",
    "authors": [
      "Shangguang Wang",
      "Qing Li",
      "Mengwei Xu",
      "Xiao Ma",
      "Ao Zhou",
      "Qibo Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.14957"
  },
  {
    "id": "arXiv:2112.14958",
    "title": "A Benchmark Dataset for Micro-video Thumbnail Selection",
    "abstract": "The thumbnail, as the first sight of a micro-video, plays a pivotal role in\nattracting users to click and watch. Although several pioneer efforts have been\ndedicated to jointly considering the quality and representativeness for\nselecting the thumbnail, they are limited in exploring the influence of users`\ninterests. While in the real scenario, the more the thumbnails satisfy the\nusers, the more likely the micro-videos will be clicked. In this paper, we aim\nto select the thumbnail of a given micro-video that meets most users`\ninterests. Towards this end, we construct a large-scale dataset for the\nmicro-video thumbnails. Ultimately, we conduct several baselines on the dataset\nand demonstrate the effectiveness of our dataset.",
    "descriptor": "",
    "authors": [
      "Liu Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.14958"
  },
  {
    "id": "arXiv:2112.14961",
    "title": "Flag: a Self-Dual Modality for Non-Commutative Contraction and  Duplication in the Category of Coherence Spaces",
    "abstract": "After reminding what coherences spaces are and how they interpret linear\nlogic, we define a modality \"flag\" in the category of coherence spaces (or\nhypercoherences) with two inverse linear (iso)morphisms: \"duplication\" from\n(flag A) to ((flag A) < (flag A)) and \"contraction\" in the opposite direction\n-- where < is the self dual and non-commutative connective known as \"before\" in\npomset logic and known as \"seq(ential)\" in the deep inference system (S)BV. In\naddition, as expected, the coherence space A is a retract of its modal image\n(flag A). This suggests an intuitive interpretation of (flag A) as \"repeatedly\nA\" or as \"A at any instant\" when \"before\" is given a temporal interpretation.\nWe hope the semantic construction of flag(A) will help to design proof rules\nfor \"flag\" and we briefly discuss this at the end of the paper.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Christian Retor\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14961"
  },
  {
    "id": "arXiv:2112.14962",
    "title": "Exponentially Handsome Proof Nets and Their Normalization",
    "abstract": "Handsome proof nets were introduced by Retor\\'e as a syntax for\nmultiplicative linear logic. These proof nets are defined by means of cographs\n(graphs representing formulas) equipped with a vertices partition satisfying\nsimple topological conditions. In this paper we extend this syntax to\nmultiplicative linear logic with units and exponentials. For this purpose we\ndevelop a new sound and complete sequent system for the logic, enforcing a\nstronger notion of proof equivalence with respect to the one usually considered\nin the literature. We then define combinatorial proofs, a graphical proof\nsystem able to capture syntactically the proof equivalence, for the cut-free\nfragment of the calculus. We conclude the paper by defining the exponentially\nhandsome proof nets as combinatorial proofs with cuts and defining an internal\nnormalization procedure for this syntax.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Matteo Acclavio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14962"
  },
  {
    "id": "arXiv:2112.14963",
    "title": "A Deep Inference System for Differential Linear Logic",
    "abstract": "Differential linear logic (DiLL) provides a fine analysis of resource\nconsumption in cut-elimination. We investigate the subsystem of DiLL without\npromotion in a deep inference formalism, where cuts are at an atomic level. In\nour system every provable formula admits a derivation in normal form, via a\nnormalization procedure that commutes with the translation from sequent\ncalculus to deep inference.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Matteo Acclavio",
      "Giulio Guerrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14963"
  },
  {
    "id": "arXiv:2112.14964",
    "title": "Super Exponentials in Linear Logic",
    "abstract": "Following the idea of Subexponential Linear Logic and Stratified Bounded\nLinear Logic, we propose a new parameterized version of Linear Logic which\nsubsumes other systems like ELL, LLL or SLL, by including variants of the\nexponential rules. We call this system Superexponential Linear Logic (superLL).\nAssuming some appropriate constraints on the parameters of superLL, we give a\ngeneric proof of cut elimination. This implies that each variant of Linear\nLogic which appears as a valid instance of superLL also satisfies cut\nelimination.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Esa\u00efe Bauer",
      "Olivier Laurent"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14964"
  },
  {
    "id": "arXiv:2112.14965",
    "title": "A Braided Lambda Calculus",
    "abstract": "We present an untyped linear lambda calculus with braids, the corresponding\ncombinatory logic, and the semantic models given by crossed G-sets.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Masahito Hasegawa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.14965"
  },
  {
    "id": "arXiv:2112.14966",
    "title": "Deriving Distributive Laws for Graded Linear Types",
    "abstract": "The recent notion of graded modal types provides a framework for extending\ntype theories with fine-grained data-flow reasoning. The Granule language\nexplores this idea in the context of linear types. In this practical setting,\nwe observe that the presence of graded modal types can introduce an additional\nimpediment when programming: when composing programs, it is often necessary to\n'distribute' data types over graded modalities, and vice versa. In this paper,\nwe show how to automatically derive these distributive laws as combinators for\nprogramming. We discuss the implementation and use of this automated deriving\nprocedure in Granule, providing easy access to these distributive combinators.\nThis work is also applicable to Linear Haskell (which retrofits Haskell with\nlinear types via grading) and we apply our technique there to provide the same\nautomatically derived combinators. Along the way, we discuss interesting\nconsiderations for pattern matching analysis via graded linear types. Lastly,\nwe show how other useful structural combinators can also be automatically\nderived.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Jack Hughes",
      "Michael Vollmer",
      "Dominic Orchard"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.14966"
  },
  {
    "id": "arXiv:2112.14967",
    "title": "Harmony in the Light of Computational Ludics",
    "abstract": "Prawitz formulated the so-called inversion principle as one of the\ncharacteristic features of Gentzen's intuitionistic natural deduction. In the\nliterature on proof-theoretic semantics, this principle is often coupled with\nanother that is called the recovery principle. By adopting the Computational\nLudics framework, we reformulate these principles into one and the same\ncondition, which we call the harmony condition. We show that this reformulation\nallows us to reveal two intuitive ideas standing behind these principles: the\nidea of \"containment\" present in the inversion principle, and the idea that the\nrecovery principle is the \"converse\" of the inversion principle. We also\nformulate two other conditions in the Computational Ludics framework, and we\nshow that each of them is equivalent to the harmony condition.",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Alberto Naibo",
      "Yuta Takahashi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14967"
  },
  {
    "id": "arXiv:2112.14968",
    "title": "A Novel Generator with Auxiliary Branch for Improving GAN Performance",
    "abstract": "The generator in the generative adversarial network (GAN) learns image\ngeneration in a coarse-to-fine manner in which earlier layers learn an overall\nstructure of the image and the latter ones refine the details. To propagate the\ncoarse information well, recent works usually build their generators by\nstacking up multiple residual blocks. Although the residual block can produce\nthe high-quality image as well as be trained stably, it often impedes the\ninformation flow in the network. To alleviate this problem, this brief\nintroduces a novel generator architecture that produces the image by combining\nfeatures obtained through two different branches: the main and auxiliary\nbranches. The goal of the main branch is to produce the image by passing\nthrough the multiple residual blocks, whereas the auxiliary branch is to convey\nthe coarse information in the earlier layer to the later one. To combine the\nfeatures in the main and auxiliary branches successfully, we also propose a\ngated feature fusion module that controls the information flow in those\nbranches. To prove the superiority of the proposed method, this brief provides\nextensive experiments using various standard datasets including CIFAR-10,\nCIFAR-100, LSUN, CelebA-HQ, AFHQ, and tiny- ImageNet. Furthermore, we conducted\nvarious ablation studies to demonstrate the generalization ability of the\nproposed method. Quantitative evaluations prove that the proposed method\nexhibits impressive GAN performance in terms of Inception score (IS) and\nFrechet inception distance (FID). For instance, the proposed method boosts the\nFID and IS scores on the tiny-ImageNet dataset from 35.13 to 25.00 and 20.23 to\n25.57, respectively.",
    "descriptor": "",
    "authors": [
      "Seung Park",
      "Yong-Goo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14968"
  },
  {
    "id": "arXiv:2112.14971",
    "title": "Contrastive Fine-grained Class Clustering via Generative Adversarial  Networks",
    "abstract": "Unsupervised fine-grained class clustering is practical yet challenging task\ndue to the difficulty of feature representations learning of subtle object\ndetails. We introduce C3-GAN, a method that leverages the categorical inference\npower of InfoGAN by applying contrastive learning. We aim to learn feature\nrepresentations that encourage the data to form distinct cluster boundaries in\nthe embedding space, while also maximizing the mutual information between the\nlatent code and its observation. Our approach is to train the discriminator,\nwhich is used for inferring clusters, to optimize the contrastive loss, where\nthe image-latent pairs that maximize the mutual information are considered as\npositive pairs and the rest as negative pairs. Specifically, we map the input\nof the generator, which has sampled from the categorical distribution, to the\nembedding space of the discriminator and let them act as a cluster centroid. In\nthis way, C3-GAN achieved to learn a clustering-friendly embedding space where\neach cluster is distinctively separable. Experimental results show that C3-GAN\nachieved state-of-the-art clustering performance on four fine-grained benchmark\ndatasets, while also alleviating the mode collapse phenomenon.",
    "descriptor": "",
    "authors": [
      "Yunji Kim",
      "Jung-Woo Ha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14971"
  },
  {
    "id": "arXiv:2112.14976",
    "title": "Contrastive Learning of Semantic and Visual Representations for Text  Tracking",
    "abstract": "Semantic representation is of great benefit to the video text tracking(VTT)\ntask that requires simultaneously classifying, detecting, and tracking texts in\nthe video. Most existing approaches tackle this task by appearance similarity\nin continuous frames, while ignoring the abundant semantic features. In this\npaper, we explore to robustly track video text with contrastive learning of\nsemantic and visual representations. Correspondingly, we present an end-to-end\nvideo text tracker with Semantic and Visual Representations(SVRep), which\ndetects and tracks texts by exploiting the visual and semantic relationships\nbetween different texts in a video sequence. Besides, with a light-weight\narchitecture, SVRep achieves state-of-the-art performance while maintaining\ncompetitive inference speed. Specifically, with a backbone of ResNet-18, SVRep\nachieves an ${\\rm ID_{F1}}$ of $\\textbf{65.9\\%}$, running at $\\textbf{16.7}$\nFPS, on the ICDAR2015(video) dataset with $\\textbf{8.6\\%}$ improvement than the\nprevious state-of-the-art methods.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhuang Li",
      "Weijia Wu",
      "Mike Zheng Shou",
      "Jiahong Li",
      "Size Li",
      "Zhongyuan Wang",
      "Hong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14976"
  },
  {
    "id": "arXiv:2112.14980",
    "title": "Efficiently Enumerating Scaled Copies of Point Set Patterns",
    "abstract": "Problems on repeated geometric patterns in finite point sets in Euclidean\nspace are extensively studied in the literature of combinatorial and\ncomputational geometry. Such problems trace their inspiration to Erd\\H{o}s'\noriginal work on that topic. In this paper, we investigate the particular case\nof finding scaled copies of any pattern within a set of $n$ points, that is,\nthe algorithmic task of efficiently enumerating all such copies. We initially\nfocus on one particularly simple pattern of axis-parallel squares, and present\nan algorithm with an $O(n\\sqrt{n})$ running time and $O(n)$ space for this\ntask, involving various bucket-based and sweep-line techniques. Our algorithm\nis worst-case optimal, as it matches the known lower bound of\n$\\Omega(n\\sqrt{n})$ on the maximum number of axis-parallel squares determined\nby $n$ points in the plane, thereby solving an open question for more than\nthree decades of realizing that bound for this pattern. We extend our result to\nan algorithm that enumerates all copies, up to scaling, of any full-dimensional\nfixed set of points in $d$-dimensional Euclidean space, that works in time\n$O(n^{1+1/d})$ and space $O(n)$, also matching the corresponding lower bound\ndue to Elekes and Erd\\H{o}s.",
    "descriptor": "",
    "authors": [
      "Aya Bernstine",
      "Yehonatan Mizrahi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.14980"
  },
  {
    "id": "arXiv:2112.14983",
    "title": "Exploring the pattern of Emotion in children with ASD as an early  biomarker through Recurring-Convolution Neural Network (R-CNN)",
    "abstract": "Autism Spectrum Disorder (ASD) is found to be a major concern among various\noccupational therapists. The foremost challenge of this neurodevelopmental\ndisorder lies in the fact of analyzing and exploring various symptoms of the\nchildren at their early stage of development. Such early identification could\nprop up the therapists and clinicians to provide proper assistive support to\nmake the children lead an independent life. Facial expressions and emotions\nperceived by the children could contribute to such early intervention of\nautism. In this regard, the paper implements in identifying basic facial\nexpression and exploring their emotions upon a time variant factor. The\nemotions are analyzed by incorporating the facial expression identified through\nCNN using 68 landmark points plotted on the frontal face with a prediction\nnetwork formed by RNN known as RCNN-FER system. The paper adopts R-CNN to take\nthe advantage of increased accuracy and performance with decreased time\ncomplexity in predicting emotion as a textual network analysis. The papers\nproves better accuracy in identifying the emotion in autistic children when\ncompared over simple machine learning models built for such identifications\ncontributing to autistic society.",
    "descriptor": "\nComments: 8 figures and 2 tables. totally 18 pages\n",
    "authors": [
      "Abirami S P",
      "Kousalya G",
      "Karthick R"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.14983"
  },
  {
    "id": "arXiv:2112.14985",
    "title": "THE Benchmark: Transferable Representation Learning for Monocular Height  Estimation",
    "abstract": "Generating 3D city models rapidly is crucial for many applications. Monocular\nheight estimation is one of the most efficient and timely ways to obtain\nlarge-scale geometric information. However, existing works focus primarily on\ntraining and testing models using unbiased datasets, which don't align well\nwith real-world applications. Therefore, we propose a new benchmark dataset to\nstudy the transferability of height estimation models in a cross-dataset\nsetting. To this end, we first design and construct a large-scale benchmark\ndataset for cross-dataset transfer learning on the height estimation task. This\nbenchmark dataset includes a newly proposed large-scale synthetic dataset, a\nnewly collected real-world dataset, and four existing datasets from different\ncities. Next, two new experimental protocols, zero-shot and few-shot\ncross-dataset transfer, are designed. For few-shot cross-dataset transfer, we\nenhance the window-based Transformer with the proposed scale-deformable\nconvolution module to handle the severe scale-variation problem. To improve the\ngeneralizability of deep models in the zero-shot cross-dataset setting, a\nmax-normalization-based Transformer network is designed to decouple the\nrelative height map from the absolute heights. Experimental results have\ndemonstrated the effectiveness of the proposed methods in both the traditional\nand cross-dataset transfer settings. The datasets and codes are publicly\navailable at https://thebenchmarkh.github.io/.",
    "descriptor": "",
    "authors": [
      "Zhitong Xiong",
      "Wei Huang",
      "Jingtao Hu",
      "Yilei Shi",
      "Qi Wang",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14985"
  },
  {
    "id": "arXiv:2112.14994",
    "title": "Soundness in Object-centric Workflow Petri Nets",
    "abstract": "Recently introduced Petri net-based formalisms advocate the importance of\nproper representation and management of case objects as well as their\nco-evolution. In this work we build on top of one of such formalisms and\nintroduce the notion of soundness for it. We demonstrate that for nets with\nnon-deterministic synchronization between case objects, the soundness problem\nis decidable.",
    "descriptor": "\nComments: This is an ongoing work that introduces basic notions and theoretical results needed for establishing the theoretical framework for checking soundness of object-centric Petri nets\n",
    "authors": [
      "Irina A. Lomazova",
      "Alexey A. Mitsyuk",
      "Andrey Rivkin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.14994"
  },
  {
    "id": "arXiv:2112.14996",
    "title": "Expressive power versus decidability",
    "abstract": "In this note we prove that there exists no fragment of first-order logic\nwhich satisfies simultaneously the following requirements: a) it has a\nrecursive syntax b) it is equi-expressive with first-order logic over finite\nmodels c) it has a decidable finite satisfiability problem d) it is effectively\nclosed under conjunction. We also point out that there exists a fragment of\nfirst-order logic which satisfies requirements a), b) and c) simultaneously.",
    "descriptor": "",
    "authors": [
      "Reijo Jaakkola"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14996"
  },
  {
    "id": "arXiv:2112.15001",
    "title": "Circuit-Free General-Purpose Multi-Party Computation via Co-Utile  Unlinkable Outsourcing",
    "abstract": "Multiparty computation (MPC) consists in several parties engaging in joint\ncomputation in such a way that each party's input and output remain private to\nthat party. Whereas MPC protocols for specific computations have existed since\nthe 1980s, only recently general-purpose compilers have been developed to allow\nMPC on arbitrary functions. Yet, using today's MPC compilers requires\nsubstantial programming effort and skill on the user's side, among other things\nbecause nearly all compilers translate the code of the computation into a\nBoolean or arithmetic circuit. In particular, the circuit representation\nrequires unrolling loops and recursive calls, which forces programmers to\n(often manually) define loop bounds and hardly use recursion. We present an\napproach allowing MPC on an arbitrary computation expressed as ordinary code\nwith all functionalities that does not need to be translated into a circuit.\nOur notion of input and output privacy is predicated on unlinkability. Our\nmethod leverages co-utile computation outsourcing using anonymous channels via\ndecentralized reputation, makes a minimalistic use of cryptography and does not\nrequire participants to be honest-but-curious: it works as long as participants\nare rational (self-interested), which may include rationally malicious peers\n(who become attackers if this is advantageous to them). We present example\napplications, including e-voting. Our empirical work shows that reputation\ncaptures well the behavior of peers and ensures that parties with high\nreputation obtain correct results.",
    "descriptor": "\nComments: IEEE Transactions on Dependable and Secure Computing, to appear\n",
    "authors": [
      "Josep Domingo-Ferrer",
      "Jes\u00fas Manj\u00f3n"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.15001"
  },
  {
    "id": "arXiv:2112.15006",
    "title": "Using Mobility Patterns for the Planning of Vehicle-to-Grid  Infrastructures that Support Photovoltaics in Cities",
    "abstract": "The vehicle-to-grid (V2G) concept utilises electric vehicles as distributed\nenergy storage and thus may help to balance out the intermittent availability\nof renewable energy sources such as photovoltaics. V2G is therefore considered\nto play an important role for achieving low-carbon energy and transportation\nsystems in cities. However, the adequate planning of city-wide V2G\ninfrastructures requires detailed knowledge of the aggregate mobility patterns\nof individuals and also needs to keep track with ongoing developments of urban\ntransportation modes. Here, we introduce an initial framework that infers\npopulation-wide mobility patterns from anonymised mobile phone location data\nand subsequently superimposes a vehicle charging and discharging scheme. The\nframework allows for the estimation of the aggregate V2G energy supply and\ndemand at fine-grained spatial and temporal scales under a given electric\nvehicle usage scenario. This information provides an adequate basis for\nassessing the role of V2G in the context of maximising the deployment of\nphotovoltaics, as well as for the sizing and placement of the required vehicle\n(dis)charging infrastructure. The proposed framework is applied to Singapore as\na case study.",
    "descriptor": "",
    "authors": [
      "Markus Schl\u00e4pfer",
      "Hong Jun Chew",
      "Seanglidet Yean",
      "Bu-Sung Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15006"
  },
  {
    "id": "arXiv:2112.15008",
    "title": "Simulation of the Geometrically Exact Nonlinear String via Energy  Quadratisation",
    "abstract": "String vibration represents an active field of research in acoustics.\nSmall-amplitude vibration is often assumed, leading to simplified physical\nmodels that can be simulated efficiently. However, the inclusion of nonlinear\nphenomena due to larger string stretchings is necessary to capture important\nfeatures, and efficient numerical algorithms are currently lacking in this\ncontext. Of the available techniques, many lead to schemes which may only be\nsolved iteratively, resulting in high computational cost, and the additional\nconcerns of existence and uniqueness of solutions. Slow and fast waves are\npresent concurrently in the transverse and longitudinal directions of motion,\nadding further complications concerning numerical dispersion. This work\npresents a linearly-implicit scheme for the simulation of the geometrically\nexact nonlinear string model. The scheme conserves a numerical energy,\nexpressed as the sum of quadratic terms only, and including an auxiliary state\nvariable yielding the nonlinear effects. This scheme allows to treat the\ntransverse and longitudinal waves separately, using a mixed finite\ndifference/modal scheme for the two directions of motion, thus allowing to\naccurately resolve the wave speeds at reference sample rates. Numerical\nexperiments are presented throughout.",
    "descriptor": "\nComments: 44 pages, 13 figures\n",
    "authors": [
      "Michele Ducceschi",
      "Stefan Bilbao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15008"
  },
  {
    "id": "arXiv:2112.15012",
    "title": "Investigating Pose Representations and Motion Contexts Modeling for 3D  Motion Prediction",
    "abstract": "Predicting human motion from historical pose sequence is crucial for a\nmachine to succeed in intelligent interactions with humans. One aspect that has\nbeen obviated so far, is the fact that how we represent the skeletal pose has a\ncritical impact on the prediction results. Yet there is no effort that\ninvestigates across different pose representation schemes. We conduct an\nindepth study on various pose representations with a focus on their effects on\nthe motion prediction task. Moreover, recent approaches build upon\noff-the-shelf RNN units for motion prediction. These approaches process input\npose sequence sequentially and inherently have difficulties in capturing\nlong-term dependencies. In this paper, we propose a novel RNN architecture\ntermed AHMR (Attentive Hierarchical Motion Recurrent network) for motion\nprediction which simultaneously models local motion contexts and a global\ncontext. We further explore a geodesic loss and a forward kinematics loss for\nthe motion prediction task, which have more geometric significance than the\nwidely employed L2 loss. Interestingly, we applied our method to a range of\narticulate objects including human, fish, and mouse. Empirical results show\nthat our approach outperforms the state-of-the-art methods in short-term\nprediction and achieves much enhanced long-term prediction proficiency, such as\nretaining natural human-like motions over 50 seconds predictions. Our codes are\nreleased.",
    "descriptor": "\nComments: Accepted to IEEE TPAMI, 27 Dec. 2021\n",
    "authors": [
      "Zhenguang Liu",
      "Shuang Wu",
      "Shuyuan Jin",
      "Shouling Ji",
      "Qi Liu",
      "Shijian Lu",
      "Li Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15012"
  },
  {
    "id": "arXiv:2112.15015",
    "title": "Measuring and Sampling: A Metric-guided Subgraph Learning Framework for  Graph Neural Network",
    "abstract": "Graph neural network (GNN) has shown convincing performance in learning\npowerful node representations that preserve both node attributes and graph\nstructural information. However, many GNNs encounter problems in effectiveness\nand efficiency when they are designed with a deeper network structure or handle\nlarge-sized graphs. Several sampling algorithms have been proposed for\nimproving and accelerating the training of GNNs, yet they ignore understanding\nthe source of GNN performance gain. The measurement of information within graph\ndata can help the sampling algorithms to keep high-value information while\nremoving redundant information and even noise. In this paper, we propose a\nMetric-Guided (MeGuide) subgraph learning framework for GNNs. MeGuide employs\ntwo novel metrics: Feature Smoothness and Connection Failure Distance to guide\nthe subgraph sampling and mini-batch based training. Feature Smoothness is\ndesigned for analyzing the feature of nodes in order to retain the most\nvaluable information, while Connection Failure Distance can measure the\nstructural information to control the size of subgraphs. We demonstrate the\neffectiveness and efficiency of MeGuide in training various GNNs on multiple\ndatasets.",
    "descriptor": "",
    "authors": [
      "Jiyang Bai",
      "Yuxiang Ren",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15015"
  },
  {
    "id": "arXiv:2112.15019",
    "title": "Deep Transfer-Learning for patient specific model re-calibration:  Application to sEMG-Classification",
    "abstract": "Accurate decoding of surface electromyography (sEMG) is pivotal for\nmuscle-to-machine-interfaces (MMI) and their application for e.g.\nrehabilitation therapy. sEMG signals have high inter-subject variability, due\nto various factors, including skin thickness, body fat percentage, and\nelectrode placement. Therefore, obtaining high generalization quality of a\ntrained sEMG decoder is quite challenging. Usually, machine learning based sEMG\ndecoders are either trained on subject-specific data, or at least recalibrated\nfor each user, individually. Even though, deep learning algorithms produced\nseveral state of the art results for sEMG decoding,however, due to the limited\namount of availability of sEMG data, the deep learning models are prone to\noverfitting. Recently, transfer learning for domain adaptation improved\ngeneralization quality with reduced training time on various machine learning\ntasks. In this study, we investigate the effectiveness of transfer learning\nusing weight initialization for recalibration of two different pretrained deep\nlearning models on a new subjects data, and compare their performance to\nsubject-specific models. To the best of our knowledge, this is the first study\nthat thoroughly investigated weight-initialization based transfer learning for\nsEMG classification and compared transfer learning to subject-specific\nmodeling. We tested our models on three publicly available databases under\nvarious settings. On average over all settings, our transfer learning approach\nimproves 5~\\%-points on the pretrained models without fine-tuning and\n12~\\%-points on the subject-specific models, while being trained on average\n22~\\% fewer epochs. Our results indicate that transfer learning enables faster\ntraining on fewer samples than user-specific models, and improves the\nperformance of pretrained models as long as enough data is available.",
    "descriptor": "",
    "authors": [
      "Stephan Johann Lehmler",
      "Muhammad Saif-ur-Rehman",
      "Tobias Glasmachers",
      "Ioannis Iossifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15019"
  },
  {
    "id": "arXiv:2112.15022",
    "title": "Continually Learning Self-Supervised Representations with Projected  Functional Regularization",
    "abstract": "Recent self-supervised learning methods are able to learn high-quality image\nrepresentations and are closing the gap with supervised methods. However, these\nmethods are unable to acquire new knowledge incrementally -- they are, in fact,\nmostly used only as a pre-training phase with IID data. In this work we\ninvestigate self-supervised methods in continual learning regimes without\nadditional memory or replay. To prevent forgetting of previous knowledge, we\npropose the usage of functional regularization. We will show that naive\nfunctional regularization, also known as feature distillation, leads to low\nplasticity and therefore seriously limits continual learning performance. To\naddress this problem, we propose Projected Functional Regularization where a\nseparate projection network ensures that the newly learned feature space\npreserves information of the previous feature space, while allowing for the\nlearning of new features. This allows us to prevent forgetting while\nmaintaining the plasticity of the learner. Evaluation against other incremental\nlearning approaches applied to self-supervision demonstrates that our method\nobtains competitive performance in different scenarios and on multiple\ndatasets.",
    "descriptor": "",
    "authors": [
      "Alex Gomez-Villa",
      "Bartlomiej Twardowski",
      "Lu Yu",
      "Andrew D. Bagdanov",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15022"
  },
  {
    "id": "arXiv:2112.15025",
    "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy  Updates",
    "abstract": "We study the problem of learning a good set of policies, so that when\ncombined together, they can solve a wide variety of unseen reinforcement\nlearning tasks with no or very little new data. Specifically, we consider the\nframework of generalized policy evaluation and improvement, in which the\nrewards for all tasks of interest are assumed to be expressible as a linear\ncombination of a fixed set of features. We show theoretically that, under\ncertain assumptions, having access to a specific set of diverse policies, which\nwe call a set of independent policies, can allow for instantaneously achieving\nhigh-level performance on all possible downstream tasks which are typically\nmore complex than the ones on which the agent was trained. Based on this\ntheoretical analysis, we propose a simple algorithm that iteratively constructs\nthis set of policies. In addition to empirically validating our theoretical\nresults, we compare our approach with recently proposed diverse policy set\nconstruction methods and show that, while others fail, our approach is able to\nbuild a behavior basis that enables instantaneous transfer to all possible\ndownstream tasks. We also show empirically that having access to a set of\nindependent policies can better bootstrap the learning process on downstream\ntasks where the new reward function cannot be described as a linear combination\nof the features. Finally, we demonstrate that this policy set can be useful in\na realistic lifelong reinforcement learning setting.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR2022\n",
    "authors": [
      "Safa Alver",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15025"
  },
  {
    "id": "arXiv:2112.15026",
    "title": "Two Instances of Interpretable Neural Network for Universal  Approximations",
    "abstract": "This paper proposes two bottom-up interpretable neural network (NN)\nconstructions for universal approximation, namely Triangularly-constructed NN\n(TNN) and Semi-Quantized Activation NN (SQANN). The notable properties are (1)\nresistance to catastrophic forgetting (2) existence of proof for arbitrarily\nhigh accuracies on training dataset (3) for an input \\(x\\), users can identify\nspecific samples of training data whose activation ``fingerprints\" are similar\nto that of \\(x\\)'s activations. Users can also identify samples that are out of\ndistribution.",
    "descriptor": "",
    "authors": [
      "Erico Tjoa",
      "Guan Cuntai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15026"
  },
  {
    "id": "arXiv:2112.15031",
    "title": "Development of a face mask detection pipeline for mask-wearing  monitoring in the era of the COVID-19 pandemic: A modular approach",
    "abstract": "During the SARS-Cov-2 pandemic, mask-wearing became an effective tool to\nprevent spreading and contracting the virus. The ability to monitor the\nmask-wearing rate in the population would be useful for determining public\nhealth strategies against the virus. However, artificial intelligence\ntechnologies for detecting face masks have not been deployed at a large scale\nin real-life to measure the mask-wearing rate in public. In this paper, we\npresent a two-step face mask detection approach consisting of two separate\nmodules: 1) face detection and alignment and 2) face mask classification. This\napproach allowed us to experiment with different combinations of face detection\nand face mask classification modules. More specifically, we experimented with\nPyramidKey and RetinaFace as face detectors while maintaining a lightweight\nbackbone for the face mask classification module. Moreover, we also provide a\nrelabeled annotation of the test set of the AIZOO dataset, where we rectified\nthe incorrect labels for some face images. The evaluation results on the AIZOO\nand Moxa 3K datasets showed that the proposed face mask detection pipeline\nsurpassed the state-of-the-art methods. The proposed pipeline also yielded a\nhigher mAP on the relabeled test set of the AIZOO dataset than the original\ntest set. Since we trained the proposed model using in-the-wild face images, we\ncan successfully deploy our model to monitor the mask-wearing rate using public\nCCTV images.",
    "descriptor": "",
    "authors": [
      "Benjaphan Sommana",
      "Ukrit Watchareeruetai",
      "Ankush Ganguly",
      "Samuel W.F. Earp",
      "Taya Kitiyakara",
      "Suparee Boonmanunt",
      "Ratchainant Thammasudjarit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15031"
  },
  {
    "id": "arXiv:2112.15034",
    "title": "Self Reward Design with Fine-grained Interpretability",
    "abstract": "Transparency and fairness issues in Deep Reinforcement Learning may stem from\nthe black-box nature of deep neural networks used to learn its policy, value\nfunctions etc. This paper proposes a way to circumvent the issues through the\nbottom-up design of neural networks (NN) with detailed interpretability, where\neach neuron or layer has its own meaning and utility that corresponds to\nhumanly understandable concept. With deliberate design, we show that lavaland\nproblems can be solved using NN model with few parameters. Furthermore, we\nintroduce the Self Reward Design (SRD), inspired by the Inverse Reward Design,\nso that our interpretable design can (1) solve the problem by pure design\n(although imperfectly) (2) be optimized via SRD (3) perform avoidance of\nunknown states by recognizing the inactivations of neurons aggregated as the\nactivation in \\(w_{unknown}\\).",
    "descriptor": "",
    "authors": [
      "Erico Tjoa",
      "Guan Cuntai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15034"
  },
  {
    "id": "arXiv:2112.15039",
    "title": "Weakly imposed Dirichlet boundary conditions for 2D and 3D Virtual  Elements",
    "abstract": "In the framework of virtual element discretizazions, we address the problem\nof imposing non homogeneous Dirichlet boundary conditions in a weak form, both\non polygonal/polyhedral domains and on two/three dimensional domains with\ncurved boundaries. We consider a Nitsche's type method [43,41], and the\nstabilized formulation of the Lagrange multiplier method proposed by Barbosa\nand Hughes in [9]. We prove that also for the virtual element method (VEM),\nprovided the stabilization parameter is suitably chosen (large enough for\nNitsche's method and small enough for the Barbosa-Hughes Lagrange multiplier\nmethod), the resulting discrete problem is well posed, and yields convergence\nwith optimal order on polygonal/polyhedral domains. On smooth two/three\ndimensional domains, we combine both methods with a projection approach similar\nto the one of [31]. We prove that, given a polygonal/polyhedral approximation\n$\\Omega_h$ of the domain $\\Omega$, an optimal convergence rate can be achieved\nby using a suitable correction depending on high order derivatives of the\ndiscrete solution along outward directions (not necessarily orthogonal) at the\nboundary facets of $\\Omega_h$. Numerical experiments validate the theory.",
    "descriptor": "",
    "authors": [
      "Silvia Bertoluzza",
      "Micol Pennacchio",
      "Daniele Prada"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15039"
  },
  {
    "id": "arXiv:2112.15043",
    "title": "YACLC: A Chinese Learner Corpus with Multidimensional Annotation",
    "abstract": "Learner corpus collects language data produced by L2 learners, that is second\nor foreign-language learners. This resource is of great relevance for second\nlanguage acquisition research, foreign-language teaching, and automatic\ngrammatical error correction. However, there is little focus on learner corpus\nfor Chinese as Foreign Language (CFL) learners. Therefore, we propose to\nconstruct a large-scale, multidimensional annotated Chinese learner corpus. To\nconstruct the corpus, we first obtain a large number of topic-rich texts\ngenerated by CFL learners. Then we design an annotation scheme including a\nsentence acceptability score as well as grammatical error and fluency-based\ncorrections. We build a crowdsourcing platform to perform the annotation\neffectively (https://yaclc.wenmind.net). We name the corpus YACLC (Yet Another\nChinese Learner Corpus) and release it as part of the CUGE benchmark\n(this http URL). By analyzing the original sentences and annotations\nin the corpus, we found that YACLC has a considerable size and very high\nannotation quality. We hope this corpus can further enhance the studies on\nChinese International Education and Chinese automatic grammatical error\ncorrection.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Yingying Wang",
      "Cunliang Kong",
      "Liner Yang",
      "Yijun Wang",
      "Xiaorong Lu",
      "Renfen Hu",
      "Shan He",
      "Zhenghao Liu",
      "Yun Chen",
      "Erhong Yang",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15043"
  },
  {
    "id": "arXiv:2112.15051",
    "title": "Does QA-based intermediate training help fine-tuning language models for  text classification?",
    "abstract": "Fine-tuning pre-trained language models for downstream tasks has become a\nnorm for NLP. Recently it is found that intermediate training based on\nhigh-level inference tasks such as Question Answering (QA) can improve the\nperformance of some language models for target tasks. However it is not clear\nif intermediate training generally benefits various language models. In this\npaper, using the SQuAD-2.0 QA task for intermediate training for target text\nclassification tasks, we experimented on eight tasks for single-sequence\nclassification and eight tasks for sequence-pair classification using two base\nand two compact language models. Our experiments show that QA-based\nintermediate training generates varying transfer performance across different\nlanguage models, except for similar QA tasks.",
    "descriptor": "\nComments: Accepted by ALTA 2021\n",
    "authors": [
      "Shiwei Zhang",
      "Xiuzhen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15051"
  },
  {
    "id": "arXiv:2112.15057",
    "title": "Weaving patterns inspired by the pentagon snub subdivision scheme",
    "abstract": "Various computer simulations regarding, e.g., the weather or structural\nmechanics, solve complex problems on a two-dimensional domain. They mostly do\nso by splitting the input domain into a finite set of smaller and simpler\nelements on which the simulation can be run fast and efficiently. This process\nof splitting can be automatized by using subdivision schemes.\nGiven the wide range of simulation problems to be tackled, an equally wide\nrange of subdivision schemes is available. They create subdivisions that are\n(mainly) comprised of triangles, quadrilaterals, or hexagons. Furthermore, they\nensure that (almost) all vertices have the same number of neighboring vertices.\nThis paper illustrates a subdivision scheme that splits the input domain into\npentagons. Repeated application of the scheme gives rise to fractal-like\nstructures. Furthermore, the resulting subdivided domain admits to certain\nweaving patterns. These patterns are subsequently generalized to several other\nsubdivision schemes.\nAs a final contribution, we provide paper models illustrating the weaving\npatterns induced by the pentagonal subdivision scheme. Furthermore, we present\na jigsaw puzzle illustrating both the subdivision process and the induced\nweaving pattern. These transform the visual and abstract mathematical\nalgorithms into tactile objects that offer exploration possibilities aside from\nthe visual.",
    "descriptor": "\nComments: Submitted for publication to the Journal of Mathematics and the Arts\n",
    "authors": [
      "Henriette Lipsch\u00fctz",
      "Ulrich Reitebuch",
      "Martin Skrodzki",
      "Konrad Polthiera"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.15057"
  },
  {
    "id": "arXiv:2112.15060",
    "title": "TextRGNN: Residual Graph Neural Networks for Text Classification",
    "abstract": "Recently, text classification model based on graph neural network (GNN) has\nattracted more and more attention. Most of these models adopt a similar network\nparadigm, that is, using pre-training node embedding initialization and\ntwo-layer graph convolution. In this work, we propose TextRGNN, an improved GNN\nstructure that introduces residual connection to deepen the convolution network\ndepth. Our structure can obtain a wider node receptive field and effectively\nsuppress the over-smoothing of node features. In addition, we integrate the\nprobabilistic language model into the initialization of graph node embedding,\nso that the non-graph semantic information of can be better extracted. The\nexperimental results show that our model is general and efficient. It can\nsignificantly improve the classification accuracy whether in corpus level or\ntext level, and achieve SOTA performance on a wide range of text classification\ndatasets.",
    "descriptor": "",
    "authors": [
      "Jiayuan Chen",
      "Boyu Zhang",
      "Yinfei Xu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15060"
  },
  {
    "id": "arXiv:2112.15064",
    "title": "Feferman-Vaught Decompositions for Prefix Classes of First Order Logic",
    "abstract": "The Feferman-Vaught theorem provides a way of evaluating a first order\nsentence $\\varphi$ on a disjoint union of structures by producing a\ndecomposition of $\\varphi$ into sentences which can be evaluated on the\nindividual structures and the results of these evaluations combined using a\npropositional formula. This decomposition can in general be non-elementarily\nlarger than $\\varphi$. We show that for first order sentences in prenex normal\nform with a fixed number of quantifier alternations, such a decomposition,\nfurther with the same number of quantifier alternations, can be obtained in\ntime elementary in the size of $\\varphi$. We obtain this result as a\nconsequence of a more general decomposition theorem that we prove for a family\nof infinitary logics we define. We extend these results by considering binary\noperations other than disjoint union, in particular sum-like operations such as\nordered sum and NLC-sum, that are definable using quantifier-free\ninterpretations.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Abhisekh Sankaran"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.15064"
  },
  {
    "id": "arXiv:2112.15065",
    "title": "V2V-Based Task Offloading and Resource Allocation in Vehicular Edge  Computing Networks",
    "abstract": "In the research and application of vehicle ad hoc networks (VANETs), it is\noften assumed that vehicles obtain cloud computing services by accessing to\nroadside units (RSUs). However, due to the problems of insufficient\nconstruction quantity, limited communication range and overload of calculation\nload of roadside units, the calculation mode relying only on vehicle to\nroadside units is difficult to deal with complex and changeable calculation\ntasks. In this paper, when the roadside unit is missing, the vehicle mobile\nunit is regarded as a natural edge computing node to make full use of the\nexcess computing power of mobile vehicles and perform the offloading task of\nsurrounding mobile vehicles in time. In this paper, the OPFTO framework is\ndesigned, an improved task allocation algorithm HGSA is proposed, and the\npre-filtering process is designed with full consideration of the moving\ncharacteristics of vehicles. In addition, vehicle simulation experiments show\nthat the proposed strategy has the advantages of low delay and high accuracy\ncompared with other task scheduling strategies, which provides a reference\nscheme for the construction of Urban Intelligent Transportation in the future.",
    "descriptor": "\nComments: IEEE Access\n",
    "authors": [
      "Junjin He",
      "Yujie Wang",
      "Xin Du",
      "Zhihui Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15065"
  },
  {
    "id": "arXiv:2112.15066",
    "title": "Frequency Selection for Platoon Communications in Secondary Spectrum  Using Radio Environment Maps",
    "abstract": "Platoon-based driving is an idea that vehicles follow each other at a close\ndistance, in order to increase road throughput and fuel savings. This requires\nreliable wireless communications to adjust the speeds of vehicles. Although\nthere is a dedicated frequency band for vehicle-to-vehicle (V2V)\ncommunications, studies have shown that it is too congested to provide reliable\ntransmission for the platoons. Additional spectrum resources, i.e., secondary\nspectrum channels, can be utilized when these are not occupied by other users.\nCharacteristics of interference in these channels are usually\nlocation-dependent and can be stored in the so-called Radio Environment Maps\n(REMs). This paper aims to design REM, in order to support the selection of\nsecondary spectrum channel for intra-platoon communications. We propose to\nassess the channel's quality in terms of outage probability computed, with the\nuse of estimated interference distributions stored in REM. A frequency\nselection algorithm that minimizes the number of channel switches along the\nplanned platoon route is proposed. Additionally, the REM creation procedure is\nshown that reduces the number of database entries using (Density-Based Spatial\nClustering of Applications with Noise) DBSCAN algorithm. The proposals are\ntested using real IQ samples captured on a real road. Application of the DBSCAN\nclustering to the constructed REM provided 7% reduction in its size.\nUtilization of the proposed channel selection algorithm resulted in a 35 times\nreduction of channel switches concerning channel assignment performed\nindependently in every location.",
    "descriptor": "",
    "authors": [
      "Marcin Hoffmann",
      "Pawel Kryszkiewicz",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15066"
  },
  {
    "id": "arXiv:2112.15067",
    "title": "SIM-SITU: A Framework for the Faithful Simulation of in-situ Workflows",
    "abstract": "The amount of data generated by numerical simulations in various scientific\ndomains such as molecular dynamics, climate modeling, biology, or astrophysics,\nled to a fundamental redesign of application workflows. The throughput and the\ncapacity of storage subsystems have not evolved as fast as the computing power\nin extreme-scale supercomputers. As a result, the classical post-hoc analysis\nof simulation outputs became highly inefficient. In-situ workflows have then\nemerged as a solution in which simulation and data analytics are intertwined\nthrough shared computing resources, thus lower latencies. Determining the best\nallocation, i.e., how many resources to allocate to each component of an\nin-situ workflow; and mapping, i.e., where and at which frequency to run the\ndata analytics component, is a complex task whose performance assessment is\ncrucial to the efficient execution of in-situ workflows. However, such a\nperformance evaluation of different allocation and mapping strategies usually\nrelies either on directly running them on the targeted execution environments,\nwhich can rapidly become extremely time-and resource-consuming, or on resorting\nto the simulation of simplified models of the components of an in-situ\nworkflow, which can lack of realism. In both cases, the validity of the\nperformance evaluation is limited. To address this issue, we introduce\nSIM-SITU, a framework for the faithful simulation of in-situ workflows. This\nframework builds on the SimGrid toolkit and benefits of several important\nfeatures of this versatile simulation tool. We designed SIM-SITU to reflect the\ntypical structure of in-situ workflows and thanks to its modular design,\nSIM-SITU has the necessary flexibility to easily and faithfully evaluate the\nbehavior and performance of various allocation and mapping strategies for\nin-situ workflows. We illustrate the simulation capabilities of SIM-SITU on a\nMolecular Dynamics use case. We study the impact of different allocation and\nmapping strategies on performance and show how users can leverage SIM-SITU to\ndetermine interesting tradeoffs when designing their in-situ workflow.",
    "descriptor": "",
    "authors": [
      "Valentin Honor\u00e9",
      "Tu Mai Anh Do",
      "Lo\u00efc Pottier",
      "Rafael Ferreira da Silva",
      "Ewa Deelman",
      "Fr\u00e9d\u00e9ric Suter"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15067"
  },
  {
    "id": "arXiv:2112.15068",
    "title": "Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised  Semantic Segmentation",
    "abstract": "Each grid block in a 3D geological model requires a rock type that represents\nall physical and chemical properties of that block. The properties that\nclassify rock types are lithology, permeability, and capillary pressure.\nScientists and engineers determined these properties using conventional\nlaboratory measurements, which embedded destructive methods to the sample or\naltered some of its properties (i.e., wettability, permeability, and porosity)\nbecause the measurements process includes sample crushing, fluid flow, or fluid\nsaturation. Lately, Digital Rock Physics (DRT) has emerged to quantify these\nproperties from micro-Computerized Tomography (uCT) and Magnetic Resonance\nImaging (MRI) images. However, the literature did not attempt rock typing in a\nwholly digital context. We propose performing Digital Rock Typing (DRT) by: (1)\nintegrating the latest DRP advances in a novel process that honors digital rock\nproperties determination, while; (2) digitalizing the latest rock typing\napproaches in carbonate, and (3) introducing a novel carbonate rock typing\nprocess that utilizes computer vision capabilities to provide more insight\nabout the heterogeneous carbonate rock texture.",
    "descriptor": "",
    "authors": [
      "Omar Alfarisi",
      "Djamel Ouzzane",
      "Mohamed Sassi",
      "Tiejun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.15068"
  },
  {
    "id": "arXiv:2112.15072",
    "title": "Deep Learning Models for Knowledge Tracing: Review and Empirical  Evaluation",
    "abstract": "In this work, we review and evaluate a body of deep learning knowledge\ntracing (DLKT) models with openly available and widely-used data sets, and with\na novel data set of students learning to program. The evaluated DLKT models\nhave been reimplemented for assessing reproducibility and replicability of\npreviously reported results. We test different input and output layer\nvariations found in the compared models that are independent of the main\narchitectures of the models, and different maximum attempt count options that\nhave been implicitly and explicitly used in some studies. Several metrics are\nused to reflect on the quality of the evaluated knowledge tracing models. The\nevaluated knowledge tracing models include Vanilla-DKT, two Long Short-Term\nMemory Deep Knowledge Tracing (LSTM-DKT) variants, two Dynamic Key-Value Memory\nNetwork (DKVMN) variants, and Self-Attentive Knowledge Tracing (SAKT). We\nevaluate logistic regression, Bayesian Knowledge Tracing (BKT) and simple\nnon-learning models as baselines. Our results suggest that the DLKT models in\ngeneral outperform non-DLKT models, and the relative differences between the\nDLKT models are subtle and often vary between datasets. Our results also show\nthat naive models such as mean prediction can yield better performance than\nmore sophisticated knowledge tracing models, especially in terms of accuracy.\nFurther, our metric and hyperparameter analysis shows that the metric used to\nselect the best model hyperparameters has a noticeable effect on the\nperformance of the models, and that metric choice can affect model ranking. We\nalso study the impact of input and output layer variations, filtering out long\nattempt sequences, and non-model properties such as randomness and hardware.\nFinally, we discuss model performance replicability and related issues. Our\nmodel implementations, evaluation code, and data are published as a part of\nthis work.",
    "descriptor": "\nComments: 72 pages, 9 figures, submitted to JEDM\n",
    "authors": [
      "Sami Sarsa",
      "Juho Leinonen",
      "Arto Hellas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15072"
  },
  {
    "id": "arXiv:2112.15075",
    "title": "Pose Estimation of Specific Rigid Objects",
    "abstract": "In this thesis, we address the problem of estimating the 6D pose of rigid\nobjects from a single RGB or RGB-D input image, assuming that 3D models of the\nobjects are available. This problem is of great importance to many application\nfields such as robotic manipulation, augmented reality, and autonomous driving.\nFirst, we propose EPOS, a method for 6D object pose estimation from an RGB\nimage. The key idea is to represent an object by compact surface fragments and\npredict the probability distribution of corresponding fragments at each pixel\nof the input image by a neural network. Each pixel is linked with a\ndata-dependent number of fragments, which allows systematic handling of\nsymmetries, and the 6D poses are estimated from the links by a RANSAC-based\nfitting method. EPOS outperformed all RGB and most RGB-D and D methods on\nseveral standard datasets. Second, we present HashMatch, an RGB-D method that\nslides a window over the input image and searches for a match against\ntemplates, which are pre-generated by rendering 3D object models in different\norientations. The method applies a cascade of evaluation stages to each window\nlocation, which avoids exhaustive matching against all templates. Third, we\npropose ObjectSynth, an approach to synthesize photorealistic images of 3D\nobject models for training methods based on neural networks. The images yield\nsubstantial improvements compared to commonly used images of objects rendered\non top of random photographs. Fourth, we introduce T-LESS, the first dataset\nfor 6D object pose estimation that includes 3D models and RGB-D images of\nindustry-relevant objects. Fifth, we define BOP, a benchmark that captures the\nstatus quo in the field. BOP comprises eleven datasets in a unified format, an\nevaluation methodology, an online evaluation system, and public challenges held\nat international workshops organized at the ICCV and ECCV conferences.",
    "descriptor": "\nComments: Tomas Hodan's PhD thesis defended on July 7, 2021. Supervisor: Prof. Jiri Matas. Reviewers: Prof. Vincent Lepetit, Prof. Markus Vincze, Dr. Slobodan Ilic. A recording of the defense: this https URL\n",
    "authors": [
      "Tomas Hodan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.15075"
  },
  {
    "id": "arXiv:2112.15085",
    "title": "Feature Extraction and Prediction for Hand Hygiene Gestures with KNN  Algorithm",
    "abstract": "This work focuses upon the analysis of hand gestures involved in the process\nof hand washing. There are six standard hand hygiene gestures for washing hands\nas provided by World Health Organisation hand hygiene guidelines. In this\npaper, hand features such as contours of hands, the centroid of the hands, and\nextreme hand points along the largest contour are extracted with the use of the\ncomputer vision library, OpenCV. These hand features are extracted for each\ndata frame in a hand hygiene video. A robust hand hygiene dataset of video\nrecordings was created in the project. A subset of this dataset is used in this\nwork. Extracted hand features are further grouped into classes based on the KNN\nalgorithm with a cross-fold validation technique for the classification and\nprediction of the unlabelled data. A mean accuracy score of >95% is achieved\nand proves that the KNN algorithm with an appropriate input value of K=5 is\nefficient for classification. A complete dataset with six distinct hand hygiene\nclasses will be used with the KNN classifier for future work.",
    "descriptor": "",
    "authors": [
      "Rashmi Bakshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15085"
  },
  {
    "id": "arXiv:2112.15087",
    "title": "ChunkFormer: Learning Long Time Series with Multi-stage Chunked  Transformer",
    "abstract": "The analysis of long sequence data remains challenging in many real-world\napplications. We propose a novel architecture, ChunkFormer, that improves the\nexisting Transformer framework to handle the challenges while dealing with long\ntime series. Original Transformer-based models adopt an attention mechanism to\ndiscover global information along a sequence to leverage the contextual data.\nLong sequential data traps local information such as seasonality and\nfluctuations in short data sequences. In addition, the original Transformer\nconsumes more resources by carrying the entire attention matrix during the\ntraining course. To overcome these challenges, ChunkFormer splits the long\nsequences into smaller sequence chunks for the attention calculation,\nprogressively applying different chunk sizes in each stage. In this way, the\nproposed model gradually learns both local and global information without\nchanging the total length of the input sequences. We have extensively tested\nthe effectiveness of this new architecture on different business domains and\nhave proved the advantage of such a model over the existing Transformer-based\nmodels.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Yue Ju",
      "Alka Isac",
      "Yimin Nie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15087"
  },
  {
    "id": "arXiv:2112.15089",
    "title": "Deconfounded Training for Graph Neural Networks",
    "abstract": "Learning powerful representations is one central theme of graph neural\nnetworks (GNNs). It requires refining the critical information from the input\ngraph, instead of the trivial patterns, to enrich the representations. Towards\nthis end, graph attention and pooling methods prevail. They mostly follow the\nparadigm of \"learning to attend\". It maximizes the mutual information between\nthe attended subgraph and the ground-truth label. However, this training\nparadigm is prone to capture the spurious correlations between the trivial\nsubgraph and the label. Such spurious correlations are beneficial to\nin-distribution (ID) test evaluations, but cause poor generalization in the\nout-of-distribution (OOD) test data. In this work, we revisit the GNN modeling\nfrom the causal perspective. On the top of our causal assumption, the trivial\ninformation serves as a confounder between the critical information and the\nlabel, which opens a backdoor path between them and makes them spuriously\ncorrelated. Hence, we present a new paradigm of deconfounded training (DTP)\nthat better mitigates the confounding effect and latches on the critical\ninformation, to enhance the representation and generalization ability.\nSpecifically, we adopt the attention modules to disentangle the critical\nsubgraph and trivial subgraph. Then we make each critical subgraph fairly\ninteract with diverse trivial subgraphs to achieve a stable prediction. It\nallows GNNs to capture a more reliable subgraph whose relation with the label\nis robust across different distributions. We conduct extensive experiments on\nsynthetic and real-world datasets to demonstrate the effectiveness.",
    "descriptor": "",
    "authors": [
      "Yongduo Sui",
      "Xiang Wang",
      "Jiancan Wu",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15089"
  },
  {
    "id": "arXiv:2112.15091",
    "title": "Leveraging in-domain supervision for unsupervised image-to-image  translation tasks via multi-stream generators",
    "abstract": "Supervision for image-to-image translation (I2I) tasks is hard to come by,\nbut bears significant effect on the resulting quality. In this paper, we\nobserve that for many Unsupervised I2I (UI2I) scenarios, one domain is more\nfamiliar than the other, and offers in-domain prior knowledge, such as semantic\nsegmentation. We argue that for complex scenes, figuring out the semantic\nstructure of the domain is hard, especially with no supervision, but is an\nimportant part of a successful I2I operation. We hence introduce two techniques\nto incorporate this invaluable in-domain prior knowledge for the benefit of\ntranslation quality: through a novel Multi-Stream generator architecture, and\nthrough a semantic segmentation-based regularization loss term. In essence, we\npropose splitting the input data according to semantic masks, explicitly\nguiding the network to different behavior for the different regions of the\nimage. In addition, we propose training a semantic segmentation network along\nwith the translation task, and to leverage this output as a loss term that\nimproves robustness. We validate our approach on urban data, demonstrating\nsuperior quality in the challenging UI2I tasks of converting day images to\nnight ones. In addition, we also demonstrate how reinforcing the target dataset\nwith our augmented images improves the training of downstream tasks such as the\nclassical detection one.",
    "descriptor": "",
    "authors": [
      "Dvir Yerushalmi",
      "Dov Danon",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15091"
  },
  {
    "id": "arXiv:2112.15093",
    "title": "Benchmarking Chinese Text Recognition: Datasets, Baselines, and an  Empirical Study",
    "abstract": "The flourishing blossom of deep learning has witnessed the rapid development\nof text recognition in recent years. However, the existing text recognition\nmethods are mainly for English texts, whereas ignoring the pivotal role of\nChinese texts. As another widely-spoken language, Chinese text recognition in\nall ways has extensive application markets. Based on our observations, we\nattribute the scarce attention on Chinese text recognition to the lack of\nreasonable dataset construction standards, unified evaluation methods, and\nresults of the existing baselines. To fill this gap, we manually collect\nChinese text datasets from publicly available competitions, projects, and\npapers, then divide them into four categories including scene, web, document,\nand handwriting datasets. Furthermore, we evaluate a series of representative\ntext recognition methods on these datasets with unified evaluation methods to\nprovide experimental results. By analyzing the experimental results, we\nsurprisingly observe that state-of-the-art baselines for recognizing English\ntexts cannot perform well on Chinese scenarios. We consider that there still\nremain numerous challenges under exploration due to the characteristics of\nChinese texts, which are quite different from English texts. The code and\ndatasets are made publicly available at\nhttps://github.com/FudanVI/benchmarking-chinese-text-recognition.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Jingye Chen",
      "Haiyang Yu",
      "Jianqi Ma",
      "Mengnan Guan",
      "Xixi Xu",
      "Xiaocong Wang",
      "Shaobo Qu",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15093"
  },
  {
    "id": "arXiv:2112.15094",
    "title": "Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems",
    "abstract": "Linear dynamical systems are canonical models for learning-based control of\nplants with uncertain dynamics. The setting consists of a stochastic\ndifferential equation that captures the state evolution of the plant\nunderstudy, while the true dynamics matrices are unknown and need to be learned\nfrom the observed data of state trajectory. An important issue is to ensure\nthat the system is stabilized and destabilizing control actions due to model\nuncertainties are precluded as soon as possible. A reliable stabilization\nprocedure for this purpose that can effectively learn from unstable data to\nstabilize the system in a finite time is not currently available. In this work,\nwe propose a novel Bayesian learning algorithm that stabilizes unknown\ncontinuous-time stochastic linear systems. The presented algorithm is flexible\nand exposes effective stabilization performance after a remarkably short time\nperiod of interacting with the system.",
    "descriptor": "",
    "authors": [
      "Mohamad Kazem Shirani Faradonbeh",
      "Mohamad Sadegh Shirani Faradonbeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15094"
  },
  {
    "id": "arXiv:2112.15095",
    "title": "A general technique for the estimation of farm animal body part weights  from CT scans and its applications in a rabbit breeding program",
    "abstract": "Various applications of farm animal imaging are based on the estimation of\nweights of certain body parts and cuts from the CT images of animals. In many\ncases, the complexity of the problem is increased by the enormous variability\nof postures in CT images due to the scanning of non-sedated, living animals. In\nthis paper, we propose a general and robust approach for the estimation of the\nweights of cuts and body parts from the CT images of (possibly) living animals.\nWe adapt multi-atlas based segmentation driven by elastic registration and\njoint feature and model selection for the regression component to cape with the\nlarge number of features and low number of samples. The proposed technique is\nevaluated and illustrated through real applications in rabbit breeding\nprograms, showing r^2 scores 12% higher than previous techniques and methods\nthat used to drive the selection so far. The proposed technique is easily\nadaptable to similar problems, consequently, it is shared in an open source\nsoftware package for the benefit of the community.",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Cs\u00f3ka",
      "Gy\u00f6rgy Kov\u00e1cs",
      "Vir\u00e1g \u00c1cs",
      "Zsolt Matics",
      "Zsolt Gerencs\u00e9r",
      "Zsolt Szendr\u0151",
      "Istv\u00e1n Nagy",
      "\u00d6rs Petneh\u00e1zy",
      "Imre Repa",
      "Mariann Moizs",
      "Tam\u00e1s Donk\u00f3"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15095"
  },
  {
    "id": "arXiv:2112.15099",
    "title": "KIND: an Italian Multi-Domain Dataset for Named Entity Recognition",
    "abstract": "In this paper we present KIND, an Italian dataset for Named-Entity\nRecognition. It contains more than one million tokens with the annotation\ncovering three classes: persons, locations, and organizations. Most of the\ndataset (around 600K tokens) contains manual gold annotations in three\ndifferent domains: news, literature, and political discourses. Texts and\nannotations are downloadable for free from the Github repository.",
    "descriptor": "",
    "authors": [
      "Teresa Paccosi",
      "Alessio Palmero Aprosio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15099"
  },
  {
    "id": "arXiv:2112.15102",
    "title": "Weak approximations of nonlinear SDEs with non-globally Lipschitz  continuous coefficients",
    "abstract": "As opposed to an overwhelming number of works on strong approximations, weak\napproximations of stochastic differential equations (SDEs), sometimes more\nrelevant in applications, are less studied in the literature. Most of the weak\nerror analysis among them relies on a fundamental weak approximation theorem\noriginally proposed by Milstein in 1986, which requires the coefficients of\nSDEs to be globally Lipschitz continuous. However, SDEs from applications\nrarely obey such a restrictive condition and the study of weak approximations\nin a non-globally Lipschitz setting turns out to be a challenging problem. This\npaper aims to carry out the weak error analysis of discrete-time approximations\nfor SDEs with non-globally Lipschitz coefficients. Under certain board\nassumptions on the analytical and numerical solutions of SDEs, a general weak\nconvergence theorem is formulated for one-step numerical approximations of\nSDEs. Explicit conditions on coefficients of SDEs are also offered to guarantee\nthe aforementioned board assumptions, which allows coefficients to grow\nsuper-linearly. As applications of the obtained weak convergence theorems, we\nprove the expected weak convergence rate of two well-known types of schemes\nsuch as the tamed Euler method and the backward Euler method, in the\nnon-globally Lipschitz setting. Numerical examples are finally provided to\nconfirm the previous findings.",
    "descriptor": "\nComments: 34 Pages\n",
    "authors": [
      "Xiaojie Wang",
      "Yuying Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.15102"
  },
  {
    "id": "arXiv:2112.15110",
    "title": "Audio-to-symbolic Arrangement via Cross-modal Music Representation  Learning",
    "abstract": "Could we automatically derive the score of a piano accompaniment based on the\naudio of a pop song? This is the audio-to-symbolic arrangement problem we\ntackle in this paper. A good arrangement model should not only consider the\naudio content but also have prior knowledge of piano composition (so that the\ngeneration \"sounds like\" the audio and meanwhile maintains musicality.) To this\nend, we contribute a cross-modal representation-learning model, which 1)\nextracts chord and melodic information from the audio, and 2) learns texture\nrepresentation from both audio and a corrupted ground truth arrangement. We\nfurther introduce a tailored training strategy that gradually shifts the source\nof texture information from corrupted score to audio. In the end, the\nscore-based texture posterior is reduced to a standard normal distribution, and\nonly audio is needed for inference. Experiments show that our model captures\nmajor audio information and outperforms baselines in generation quality.",
    "descriptor": "",
    "authors": [
      "Ziyu Wang",
      "Dejing Xu",
      "Gus Xia",
      "Ying Shan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.15110"
  },
  {
    "id": "arXiv:2112.15111",
    "title": "Stochastic Layers in Vision Transformers",
    "abstract": "We introduce fully stochastic layers in vision transformers, without causing\nany severe drop in performance. The additional stochasticity boosts the\nrobustness of visual features and strengthens privacy. In this process, linear\nlayers with fully stochastic parameters are used, both during training and\ninference, to transform the feature activations of each multilayer perceptron.\nSuch stochastic linear operations preserve the topological structure, formed by\nthe set of tokens passing through the shared multilayer perceptron. This\noperation encourages the learning of the recognition task to rely on the\ntopological structures of the tokens, instead of their values, which in turn\noffers the desired robustness and privacy of the visual features. In this\npaper, we use our features for three different applications, namely,\nadversarial robustness, network calibration, and feature privacy. Our features\noffer exciting results on those tasks. Furthermore, we showcase an experimental\nsetup for federated and transfer learning, where the vision transformers with\nstochastic layers are again shown to be well behaved. Our source code will be\nmade publicly available.",
    "descriptor": "",
    "authors": [
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Thomas Probst",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15111"
  },
  {
    "id": "arXiv:2112.15115",
    "title": "Aim in Climate Change and City Pollution",
    "abstract": "The sustainability of urban environments is an increasingly relevant problem.\nAir pollution plays a key role in the degradation of the environment as well as\nthe health of the citizens exposed to it. In this chapter we provide a review\nof the methods available to model air pollution, focusing on the application of\nmachine-learning methods. In fact, machine-learning methods have proved to\nimportantly increase the accuracy of traditional air-pollution approaches while\nlimiting the development cost of the models. Machine-learning tools have opened\nnew approaches to study air pollution, such as flow-dynamics modelling or\nremote-sensing methodologies.",
    "descriptor": "",
    "authors": [
      "Pablo Torres",
      "Beril Sirmacek",
      "Sergio Hoyas",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.15115"
  },
  {
    "id": "arXiv:2112.15121",
    "title": "On the Role of Neural Collapse in Transfer Learning",
    "abstract": "We study the ability of foundation models to learn representations for\nclassification that are transferable to new, unseen classes. Recent results in\nthe literature show that representations learned by a single classifier over\nmany classes are competitive on few-shot learning problems with representations\nlearned by special-purpose algorithms designed for such problems. In this paper\nwe provide an explanation for this behavior based on the recently observed\nphenomenon that the features learned by overparameterized classification\nnetworks show an interesting clustering property, called neural collapse. We\ndemonstrate both theoretically and empirically that neural collapse generalizes\nto new samples from the training classes, and -- more importantly -- to new\nclasses as well, allowing foundation models to provide feature maps that work\nwell in transfer learning and, specifically, in the few-shot setting.",
    "descriptor": "",
    "authors": [
      "Tomer Galanti",
      "Andr\u00e1s Gy\u00f6rgy",
      "Marcus Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15121"
  },
  {
    "id": "arXiv:2112.15124",
    "title": "Utilizing Wordnets for Cognate Detection among Indian Languages",
    "abstract": "Automatic Cognate Detection (ACD) is a challenging task which has been\nutilized to help NLP applications like Machine Translation, Information\nRetrieval and Computational Phylogenetics. Unidentified cognate pairs can pose\na challenge to these applications and result in a degradation of performance.\nIn this paper, we detect cognate word pairs among ten Indian languages with\nHindi and use deep learning methodologies to predict whether a word pair is\ncognate or not. We identify IndoWordnet as a potential resource to detect\ncognate word pairs based on orthographic similarity-based methods and train\nneural network models using the data obtained from it. We identify parallel\ncorpora as another potential resource and perform the same experiments for\nthem. We also validate the contribution of Wordnets through further\nexperimentation and report improved performance of up to 26%. We discuss the\nnuances of cognate detection among closely related Indian languages and release\nthe lists of detected cognates as a dataset. We also observe the behaviour of,\nto an extent, unrelated Indian language pairs and release the lists of detected\ncognates among them as well.",
    "descriptor": "\nComments: Published at GWC 2019\n",
    "authors": [
      "Diptesh Kanojia",
      "Kevin Patel",
      "Pushpak Bhattacharyya",
      "Malhar Kulkarni",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15124"
  },
  {
    "id": "arXiv:2112.15127",
    "title": "Towards Automated Sample Collection and Return in Extreme Underwater  Environments",
    "abstract": "In this report, we present the system design, operational strategy, and\nresults of coordinated multi-vehicle field demonstrations of autonomous marine\nrobotic technologies in search-for-life missions within the Pacific shelf\nmargin of Costa Rica and the Santorini-Kolumbo caldera complex, which serve as\nanalogs to environments that may exist in oceans beyond Earth. This report\nfocuses on the automation of ROV manipulator operations for targeted biological\nsample-collection-and-return from the seafloor. In the context of future\nextraterrestrial exploration missions to ocean worlds, an ROV is an analog to a\nplanetary lander, which must be capable of high-level autonomy. Our field\ntrials involve two underwater vehicles, the SuBastian ROV and the Nereid Under\nIce (NUI) hybrid ROV for mixed initiative (i.e., teleoperated or autonomous)\nmissions, both equipped 7-DoF hydraulic manipulators. We describe an adaptable,\nhardware-independent computer vision architecture that enables high-level\nautomated manipulation. The vision system provides a 3D understanding of the\nworkspace to inform manipulator motion planning in complex unstructured\nenvironments. We demonstrate the effectiveness of the vision system and control\nframework through field trials in increasingly challenging environments,\nincluding the automated collection and return of biological samples from within\nthe active undersea volcano, Kolumbo. Based on our experiences in the field, we\ndiscuss the performance of our system and identify promising directions for\nfuture research.",
    "descriptor": "\nComments: 36 pages, 23 figures, accepted to Field Robotics\n",
    "authors": [
      "Gideon Billings",
      "Matthew Walter",
      "Oscar Pizarro",
      "Matthew Johnson-Roberson",
      "Richard Camilli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15127"
  },
  {
    "id": "arXiv:2112.15131",
    "title": "Resource-Efficient Deep Learning: A Survey on Model-, Arithmetic-, and  Implementation-Level Techniques",
    "abstract": "Deep learning is pervasive in our daily life, including self-driving cars,\nvirtual assistants, social network services, healthcare services, face\nrecognition, etc. However, deep neural networks demand substantial compute\nresources during training and inference. The machine learning community has\nmainly focused on model-level optimizations such as architectural compression\nof deep learning models, while the system community has focused on\nimplementation-level optimization. In between, various arithmetic-level\noptimization techniques have been proposed in the arithmetic community. This\narticle provides a survey on resource-efficient deep learning techniques in\nterms of model-, arithmetic-, and implementation-level techniques and\nidentifies the research gaps for resource-efficient deep learning techniques\nacross the three different level techniques. Our survey clarifies the influence\nfrom higher to lower-level techniques based on our resource-efficiency metric\ndefinition and discusses the future trend for resource-efficient deep learning\nresearch.",
    "descriptor": "\nComments: Submitted to ACM Computing Surveys\n",
    "authors": [
      "JunKyu Lee",
      "Lev Mukhanov",
      "Amir Sabbagh Molahosseini",
      "Umar Minhas",
      "Yang Hua",
      "Jesus Martinez del Rincon",
      "Kiril Dichev",
      "Cheol-Ho Hong",
      "Hans Vandierendonck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15131"
  },
  {
    "id": "arXiv:2112.15139",
    "title": "Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural  Networks",
    "abstract": "Quantized neural networks typically require smaller memory footprints and\nlower computation complexity, which is crucial for efficient deployment.\nHowever, quantization inevitably leads to a distribution divergence from the\noriginal network, which generally degrades the performance. To tackle this\nissue, massive efforts have been made, but most existing approaches lack\nstatistical considerations and depend on several manual configurations. In this\npaper, we present an adaptive-mapping quantization method to learn an optimal\nlatent sub-distribution that is inherent within models and smoothly\napproximated with a concrete Gaussian Mixture (GM). In particular, the network\nweights are projected in compliance with the GM-approximated sub-distribution.\nThis sub-distribution evolves along with the weight update in a co-tuning\nschema guided by the direct task-objective optimization. Sufficient experiments\non image classification and object detection over various modern architectures\ndemonstrate the effectiveness, generalization property, and transferability of\nthe proposed method. Besides, an efficient deployment flow for the mobile CPU\nis developed, achieving up to 7.46$\\times$ inference acceleration on an\nocta-core ARM CPU. Codes are publicly released at\nhttps://github.com/RunpeiDong/DGMS.",
    "descriptor": "\nComments: 15 pages, 4 figures, submitted to IJCV (International Journal of Computer Vision)\n",
    "authors": [
      "Runpei Dong",
      "Zhanhong Tan",
      "Mengdi Wu",
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15139"
  },
  {
    "id": "arXiv:2112.15147",
    "title": "An Automatically Verified Prototype of a Landing Gear System",
    "abstract": "In this paper we show how $\\{log\\}$ (read `setlog'), a Constraint Logic\nProgramming (CLP) language based on set theory, can be used as an automated\nverifier for B specifications. In particular we encode in $\\{log\\}$ an Event-B\nspecification, developed by Mammar and Laleau, of the case study known as the\nLanding Gear System (LGS). Next we use $\\{log\\}$ to discharge all the proof\nobligations proposed in the Event-B specification by the Rodin platform. In\nthis way, the $\\{log\\}$ program can be regarded as an automatically verified\nprototype of the LGS. We believe this case study provides empirical evidence on\nhow CLP and set theory can be used in tandem as a vehicle for program\nverification.",
    "descriptor": "",
    "authors": [
      "Maximiliano Cristi\u00e1",
      "Gianfranco Rossi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.15147"
  },
  {
    "id": "arXiv:2112.15151",
    "title": "From Behavioral Theories to Econometrics: Inferring Preferences of Human  Agents from Data on Repeated Interactions",
    "abstract": "We consider the problem of estimating preferences of human agents from data\nof strategic systems where the agents repeatedly interact. Recently, it was\ndemonstrated that a new estimation method called \"quantal regret\" produces more\naccurate estimates for human agents than the classic approach that assumes that\nagents are rational and reach a Nash equilibrium; however, this method has not\nbeen compared to methods that take into account behavioral aspects of human\nplay. In this paper we leverage equilibrium concepts from behavioral economics\nfor this purpose and ask how well they perform compared to the quantal regret\nand Nash equilibrium methods. We develop four estimation methods based on\nestablished behavioral equilibrium models to infer the utilities of human\nagents from observed data of normal-form games. The equilibrium models we study\nare quantal-response equilibrium, action-sampling equilibrium, payoff-sampling\nequilibrium, and impulse-balance equilibrium. We show that in some of these\nconcepts the inference is achieved analytically via closed formulas, while in\nthe others the inference is achieved only algorithmically. We use experimental\ndata of 2x2 games to evaluate the estimation success of these behavioral\nequilibrium methods. The results show that the estimates they produce are more\naccurate than the estimates of the Nash equilibrium. The comparison with the\nquantal-regret method shows that the behavioral methods have better hit rates,\nbut the quantal-regret method performs better in terms of the overall mean\nsquared error, and we discuss the differences between the methods.",
    "descriptor": "\nComments: Published in the Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)\n",
    "authors": [
      "Gali Noti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15151"
  },
  {
    "id": "arXiv:2112.15153",
    "title": "DPG methods for a fourth-order div problem",
    "abstract": "We study a fourth-order div problem and its approximation by the\ndiscontinuous Petrov-Galerkin method with optimal test functions. We present\ntwo variants, based on first and second-order systems. In both cases we prove\nwell-posedness of the formulation and quasi-optimal convergence of the\napproximation. Our analysis includes the fully-discrete schemes with\napproximated test functions, for general dimension and polynomial degree in the\nfirst-order case, and for two dimensions and lowest-order approximation in the\nsecond-order case. Numerical results illustrate the performance for\nquasi-uniform and adaptively refined meshes.",
    "descriptor": "\nComments: Supported by ANID-Chile through FONDECYT projects 1190009, 1210391\n",
    "authors": [
      "Thomas F\u00fchrer",
      "Pablo Herrera",
      "Norbert Heuer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15153"
  },
  {
    "id": "arXiv:2112.15156",
    "title": "Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal  Difference and Successor Representation",
    "abstract": "Distributed Multi-Agent Reinforcement Learning (MARL) algorithms has\nattracted a surge of interest lately mainly due to the recent advancements of\nDeep Neural Networks (DNNs). Conventional Model-Based (MB) or Model-Free (MF)\nRL algorithms are not directly applicable to the MARL problems due to\nutilization of a fixed reward model for learning the underlying value function.\nWhile DNN-based solutions perform utterly well when a single agent is involved,\nsuch methods fail to fully generalize to the complexities of MARL problems. In\nother words, although recently developed approaches based on DNNs for\nmulti-agent environments have achieved superior performance, they are still\nprone to overfiting, high sensitivity to parameter selection, and sample\ninefficiency. The paper proposes the Multi-Agent Adaptive Kalman Temporal\nDifference (MAK-TD) framework and its Successor Representation-based variant,\nreferred to as the MAK-SR. Intuitively speaking, the main objective is to\ncapitalize on unique characteristics of Kalman Filtering (KF) such as\nuncertainty modeling and online second order learning. The proposed MAK-TD/SR\nframeworks consider the continuous nature of the action-space that is\nassociated with high dimensional multi-agent environments and exploit Kalman\nTemporal Difference (KTD) to address the parameter uncertainty. By leveraging\nthe KTD framework, SR learning procedure is modeled into a filtering problem,\nwhere Radial Basis Function (RBF) estimators are used to encode the continuous\nspace into feature vectors. On the other hand, for learning localized reward\nfunctions, we resort to Multiple Model Adaptive Estimation (MMAE), to deal with\nthe lack of prior knowledge on the observation noise covariance and observation\nmapping function. The proposed MAK-TD/SR frameworks are evaluated via several\nexperiments, which are implemented through the OpenAI Gym MARL benchmarks.",
    "descriptor": "",
    "authors": [
      "Mohammad Salimibeni",
      "Arash Mohammadi",
      "Parvin Malekzadeh",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15156"
  },
  {
    "id": "arXiv:2112.15167",
    "title": "Chatbot for fitness management using IBM Watson",
    "abstract": "Chatbots have revolutionized the way humans interact with computer systems\nand they have substituted the use of service agents, call-center\nrepresentatives etc. Fitness industry has always been a growing industry\nalthough it has not adapted to the latest technologies like AI, ML and cloud\ncomputing. In this paper, we propose an idea to develop a chatbot for fitness\nmanagement using IBM Watson and integrate it with a web application. We\nproposed using Natural Language Processing (NLP) and Natural Language\nUnderstanding (NLU) along with frameworks of IBM Cloud Watson provided for the\nChatbot Assistant. This software uses a serverless architecture to combine the\nservices of a professional by offering diet plans, home exercises, interactive\ncounseling sessions, fitness recommendations.",
    "descriptor": "",
    "authors": [
      "Sai Rugved Lola",
      "Rahul Dhadvai",
      "Wei Wang",
      "Ting Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15167"
  },
  {
    "id": "arXiv:2112.15169",
    "title": "Investigations of Smart Health Reliability",
    "abstract": "A balanced investigation into the reliability of wireless smart health\ndevices when it comes to the collection of biometric data under varying\nnetwork/environmental conditions. Followed by a program implementation to begin\nintroductory analysis on measurement accuracy and data collection to gauge the\nreliability of smart health devices.",
    "descriptor": "",
    "authors": [
      "Sharlet Claros",
      "Wei Wang",
      "Ting Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.15169"
  },
  {
    "id": "arXiv:2112.15176",
    "title": "Comparing different solutions for testing resistive defects in low-power  SRAMs",
    "abstract": "Low-power SRAM architectures are especially sensitive to many types of\ndefects that may occur during manufacturing. Among these, resistive defects can\nappear. This paper analyzes some types of such defects that may impair the\ndevice functionalities in subtle ways, depending on the defect characteristics,\nand that may not be directly or easily detectable by traditional test methods,\nsuch as March algorithms. We analyze different methods to test such defects and\ndiscuss them in terms of complexity and test time.",
    "descriptor": "\nComments: Paper accepted and presented in The 22nd IEEE Latin-American Test Symposium (LATS 2021) October 27 - 29, 2021, Brazil. It is going to be published in the IEEExplorer. 6 pages, 7 figures, 3 tables\n",
    "authors": [
      "Nunzio Mirabella",
      "Michelangelo Grosso",
      "Giovanna Franchino",
      "Salvatore Rinaudo",
      "Ioannis Deretzis",
      "Antonino La Magna",
      "Matteo Sonza Reorda"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.15176"
  },
  {
    "id": "arXiv:2112.15182",
    "title": "Product Form of Projection-Based Model Reduction and its Application to  Multi-Agent Systems",
    "abstract": "Orthogonal projection-based reduced order models (PROM) are the output of\nwidely-used model reduction methods. In this work, a novel product form is\nderived for the reduction error system of these reduced models, and it is shown\nthat any such PROM can be obtained from a sequence of 1-dimensional projection\nreductions. Investigating the error system product form, we then define\ninterface-invariant PROMs, model order reductions with projection-invariant\ninput and output matrices, and it is shown that for such PROMs the error\nproduct systems are strictly proper. Furthermore, exploiting this structure, an\nanalytic $\\mathcal{H}_{\\infty}$ reduction error bound is obtained and an\n$\\mathcal{H}_{\\infty}$ bound optimization problem is defined.\nInterface-invariant reduced models are natural to graph-based model reduction\nof multi-agent systems where subsets of agents function as the input and output\nof the system. In the second part of this study, graph contractions are used as\na constructive solution approach to the $\\mathcal{H}_{\\infty}$ bound\noptimization problem for multi-agent systems. Edge-based contractions are then\nutilized in a greedy-edge reduction algorithm and are demonstrated for the\nmodel reduction of a first-order Laplacian controlled consensus protocol.",
    "descriptor": "",
    "authors": [
      "Noam Leiter",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15182"
  },
  {
    "id": "arXiv:2112.15187",
    "title": "Stability-Preserving Automatic Tuning of PID Control with Reinforcement  Learning",
    "abstract": "PID control has been the dominant control strategy in the process industry\ndue to its simplicity in design and effectiveness in controlling a wide range\nof processes. However, traditional methods on PID tuning often require\nextensive domain knowledge and field experience. To address the issue, this\nwork proposes an automatic PID tuning framework based on reinforcement learning\n(RL), particularly the deterministic policy gradient (DPG) method. Different\nfrom existing studies on using RL for PID tuning, in this work, we consider the\nclosed-loop stability throughout the RL-based tuning process. In particular, we\npropose a novel episodic tuning framework that allows for an episodic\nclosed-loop operation under selected PID parameters where the actor and critic\nnetworks are updated once at the end of each episode. To ensure the closed-loop\nstability during the tuning, we initialize the training with a conservative but\nstable baseline PID controller and the resultant reward is used as a benchmark\nscore. A supervisor mechanism is used to monitor the running reward (e.g.,\ntracking error) at each step in the episode. As soon as the running reward\nexceeds the benchmark score, the underlying controller is replaced by the\nbaseline controller as an early correction to prevent instability. Moreover, we\nuse layer normalization to standardize the input to each layer in actor and\ncritic networks to overcome the issue of policy saturation at action bounds, to\nensure the convergence to the optimum. The developed methods are validated\nthrough setpoint tracking experiments on a second-order plus dead-time system.\nSimulation results show that with our scheme, the closed-loop stability can be\nmaintained throughout RL explorations and the explored PID parameters by the RL\nagent converge quickly to the optimum.",
    "descriptor": "\nComments: 6 figures, 1 table, 19 pages\n",
    "authors": [
      "Ayub I. Lakhani",
      "Myisha A. Chowdhury",
      "Qiugang Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15187"
  },
  {
    "id": "arXiv:2112.15188",
    "title": "Towards Robustness of Neural Networks",
    "abstract": "We introduce several new datasets namely ImageNet-A/O and ImageNet-R as well\nas a synthetic environment and testing suite we called CAOS. ImageNet-A/O allow\nresearchers to focus in on the blind spots remaining in ImageNet. ImageNet-R\nwas specifically created with the intention of tracking robust representation\nas the representations are no longer simply natural but include artistic, and\nother renditions. The CAOS suite is built off of CARLA simulator which allows\nfor the inclusion of anomalous objects and can create reproducible synthetic\nenvironment and scenes for testing robustness. All of the datasets were created\nfor testing robustness and measuring progress in robustness. The datasets have\nbeen used in various other works to measure their own progress in robustness\nand allowing for tangential progress that does not focus exclusively on natural\naccuracy.\nGiven these datasets, we created several novel methods that aim to advance\nrobustness research. We build off of simple baselines in the form of Maximum\nLogit, and Typicality Score as well as create a novel data augmentation method\nin the form of DeepAugment that improves on the aforementioned benchmarks.\nMaximum Logit considers the logit values instead of the values after the\nsoftmax operation, while a small change produces noticeable improvements. The\nTypicality Score compares the output distribution to a posterior distribution\nover classes. We show that this improves performance over the baseline in all\nbut the segmentation task. Speculating that perhaps at the pixel level the\nsemantic information of a pixel is less meaningful than that of class level\ninformation. Finally the new augmentation technique of DeepAugment utilizes\nneural networks to create augmentations on images that are radically different\nthan the traditional geometric and camera based transformations used\npreviously.",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Steven Basart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15188"
  },
  {
    "id": "arXiv:2112.15198",
    "title": "Massively Parallelized Interpolated Factored Green Function Method",
    "abstract": "This paper presents a parallel implementation of the \"Interpolated Factored\nGreen Function\" (IFGF) method introduced recently for the accelerated\nevaluation of discrete integral operators arising in wave scattering and other\nareas (Bauinger and Bruno, Jour. Computat. Phys., 2021). On the basis of the\nhierarchical IFGF interpolation strategy, the proposed (hybrid MPI-OpenMP)\nparallel implementation results in highly efficient data communication, and it\nexhibits in practice excellent parallel scaling up to large numbers of cores --\nwithout any hard limitations on the number of cores concurrently employed in an\nefficient manner. Moreover, on any given number of cores, the proposed parallel\napproach preserves the O(N log N) computing cost inherent in the sequential\nversion of the IFGF algorithm. Unlike other approaches, the IFGF method does\nnot utilize the Fast Fourier Transform (FFT), and it is thus better suited than\nother methods for efficient parallelization in distributed-memory computer\nsystems. A variety of numerical results presented in this paper illustrate the\ncharacter of the proposed parallel algorithm, including excellent weak and\nstrong parallel scaling properties in all cases considered -- for problems of\nup to 4,096 wavelengths in electrical size, and scaling tests spanning from 1\ncompute core to all 1,680 cores available in the HPC cluster used.",
    "descriptor": "\nComments: 26 pages, 4 figures, 1 table, 14 algorithms, 6 pages supplementary materials with 4 tables\n",
    "authors": [
      "Christoph Bauinger",
      "Oscar P. Bruno"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15198"
  },
  {
    "id": "arXiv:2112.15202",
    "title": "Visual and Object Geo-localization: A Comprehensive Survey",
    "abstract": "The concept of geo-localization refers to the process of determining where on\nearth some `entity' is located, typically using Global Positioning System (GPS)\ncoordinates. The entity of interest may be an image, sequence of images, a\nvideo, satellite image, or even objects visible within the image. As massive\ndatasets of GPS tagged media have rapidly become available due to smartphones\nand the internet, and deep learning has risen to enhance the performance\ncapabilities of machine learning models, the fields of visual and object\ngeo-localization have emerged due to its significant impact on a wide range of\napplications such as augmented reality, robotics, self-driving vehicles, road\nmaintenance, and 3D reconstruction. This paper provides a comprehensive survey\nof geo-localization involving images, which involves either determining from\nwhere an image has been captured (Image geo-localization) or geo-locating\nobjects within an image (Object geo-localization). We will provide an in-depth\nstudy, including a summary of popular algorithms, a description of proposed\ndatasets, and an analysis of performance results to illustrate the current\nstate of each field.",
    "descriptor": "",
    "authors": [
      "Daniel Wilson",
      "Xiaohan Zhang",
      "Waqas Sultani",
      "Safwan Wshah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15202"
  },
  {
    "id": "arXiv:2112.15210",
    "title": "Persformer: A Transformer Architecture for Topological Machine Learning",
    "abstract": "One of the main challenges of Topological Data Analysis (TDA) is to extract\nfeatures from persistent diagrams directly usable by machine learning\nalgorithms. Indeed, persistence diagrams are intrinsically (multi-)sets of\npoints in R2 and cannot be seen in a straightforward manner as vectors. In this\narticle, we introduce Persformer, the first Transformer neural network\narchitecture that accepts persistence diagrams as input. The Persformer\narchitecture significantly outperforms previous topological neural network\narchitectures on classical synthetic benchmark datasets. Moreover, it satisfies\na universal approximation theorem. This allows us to introduce the first\ninterpretability method for topological machine learning, which we explore in\ntwo examples.",
    "descriptor": "",
    "authors": [
      "Raphael Reinauer",
      "Matteo Caorsi",
      "Nicolas Berkouk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2112.15210"
  },
  {
    "id": "arXiv:2112.15216",
    "title": "Bayesian Inference for Fluid Dynamics: A Case Study for the Stochastic  Rotating Shallow Water Model",
    "abstract": "In this work, we use a tempering-based adaptive particle filter to infer from\na partially observed stochastic rotating shallow water (SRSW) model which has\nbeen derived using the Stochastic Advection by Lie Transport (SALT) approach.\nThe methodology we present here validates the applicability of tempering and\nsample regeneration via a Metropolis-Hastings algorithm to high-dimensional\nmodels used in stochastic fluid dynamics. The methodology is first tested on\nthe Lorenz '63 model with both full and partial observations. Then we discuss\nthe efficiency of the particle filter the SALT-SRSW model.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Peter Jan van Leeuwen",
      "Dan Crisan",
      "Oana Lang",
      "Roland Potthast"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.15216"
  },
  {
    "id": "arXiv:2112.15217",
    "title": "VisQA: Quantifying Information Visualisation Recallability via Question  Answering",
    "abstract": "Despite its importance for assessing the effectiveness of communicating\ninformation visually, fine-grained recallability of information visualisations\nhas not been studied quantitatively so far. In this work we propose a visual\nquestion answering (VQA) paradigm to study visualisation recallability and\npresent VisQA -- a novel VQA dataset consisting of 200 visualisations that are\nannotated with crowd-sourced human (N~=~305) recallability scores obtained from\n1,000 questions from five question types. Furthermore, we present the first\ncomputational method to predict recallability of different visualisation\nelements, such as the title or specific data values. We report detailed\nanalyses of our method on VisQA and demonstrate that it outperforms several\nbaselines in overall recallability and FE-, F-, RV-, and U-question\nrecallability. We further demonstrate one possible application of our method:\nrecommending the visualisation type that maximises user recallability for a\ngiven data source. Taken together, our work makes fundamental contributions\ntowards a new generation of methods to assist designers in optimising\nvisualisations.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Yao Wang",
      "Chuhan Jiao",
      "Mihai B\u00e2ce",
      "Andreas Bulling"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.15217"
  },
  {
    "id": "arXiv:2112.15221",
    "title": "Constraint Sampling Reinforcement Learning: Incorporating Expertise For  Faster Learning",
    "abstract": "Online reinforcement learning (RL) algorithms are often difficult to deploy\nin complex human-facing applications as they may learn slowly and have poor\nearly performance. To address this, we introduce a practical algorithm for\nincorporating human insight to speed learning. Our algorithm, Constraint\nSampling Reinforcement Learning (CSRL), incorporates prior domain knowledge as\nconstraints/restrictions on the RL policy. It takes in multiple potential\npolicy constraints to maintain robustness to misspecification of individual\nconstraints while leveraging helpful ones to learn quickly. Given a base RL\nlearning algorithm (ex. UCRL, DQN, Rainbow) we propose an upper confidence with\nelimination scheme that leverages the relationship between the constraints, and\ntheir observed performance, to adaptively switch among them. We instantiate our\nalgorithm with DQN-type algorithms and UCRL as base algorithms, and evaluate\nour algorithm in four environments, including three simulators based on real\ndata: recommendations, educational activity sequencing, and HIV treatment\nsequencing. In all cases, CSRL learns a good policy faster than baselines.",
    "descriptor": "",
    "authors": [
      "Tong Mu",
      "Georgios Theocharous",
      "David Arbour",
      "Emma Brunskill"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15221"
  },
  {
    "id": "arXiv:2112.15230",
    "title": "AntiCopyPaster: Extracting Code Duplicates As Soon As They Are  Introduced in the IDE",
    "abstract": "We have developed a plugin for IntelliJ IDEA called AntiCopyPaster that\ntracks the pasting of code inside the IDE and suggests appropriate Extract\nMethod refactorings to combat the propagation of duplicates. To implement the\nplugin, we gathered a dataset of code fragments that should and should not be\nextracted, compiled a list of metrics of code that can influence the decision,\nand trained several popular classifying machine learning models, of which a\ngradient boosting classifier showed the best results. When a developer pastes a\ncode fragment, the plugin searches for duplicates in the currently opened file.\nIf there are any, it waits for a short period of time to allow the developer to\nedit the code. If the code duplicates are still present after a delay,\nAntiCopyPaster calculates the metrics for the fragment and inferences the\ndecision: if the fragment should be extracted, the plugin suggests to refactor\nit. This can help the developers to keep their code clean and save them future\nmaintenance time by providing the possibility to refactor code timely and\nwithout losing the context.\nYou can find the plugin and its source code on GitHub at\nhttps://github.com/JetBrains-Research/anti-copy-paster.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Anton Ivanov",
      "Zarina Kurbatova",
      "Yaroslav Golubev",
      "Andrey Kirilenko",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.15230"
  },
  {
    "id": "arXiv:2112.15233",
    "title": "Space-Efficient FPT Algorithms",
    "abstract": "We prove algorithmic results showing that a number of natural parameterized\nproblems are in the restricted-space parameterized classes Para-L and FPT+XL.\nThe first class comprises problems solvable in f(k) n^{O(1)} time using g(k) +\nO(log n)) bits of space (k is the parameter and n is the input size; f and g\nare computable functions). The second class comprises problems solvable under\nthe same time bound, but using g(k) log n bits of space instead.\nEarlier work on these classes has focused largely on their structural aspects\nand their relationships with various other classes. We complement this with\nPara-L and FPT+XL algorithms for a restriction of Hitting Set, some graph\ndeletion problems where the target class has an infinite forbidden set\ncharacterization, a number of problems parameterized by vertex cover number,\nand Feedback Vertex Set.",
    "descriptor": "",
    "authors": [
      "Arindam Biswas",
      "Venkatesh Raman",
      "Srinivasa Rao Satti",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.15233"
  },
  {
    "id": "arXiv:2112.15235",
    "title": "Fast algorithms for interpolation with L-splines for differential  operators L of order 4 with constant coefficients",
    "abstract": "In the classical theory of cubic interpolation splines there exists an\nalgorithm which works with only $O\\left( n\\right)$ arithmetic operations. Also,\nthe smoothing cubic splines may be computed via the algorithm of Reinsch which\nreduces their computation to interpolation cubic splines and also performs with\n$O\\left( n\\right)$ arithmetic operations. In this paper it is shown that many\nfeatures of the polynomial cubic spline setting carry over to the larger class\nof $L$-splines where $L$ is a linear differential operator of order $4$ with\nconstant coefficients. Criteria are given such that the associated matrix $R$\nis strictly diagonally dominant which implies the existence of a fast algorithm\nfor interpolation.",
    "descriptor": "\nComments: 33 pages, 4 figures\n",
    "authors": [
      "Ognyan Kounchev",
      "Hermann Render",
      "Tsvetomir Tsachev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2112.15235"
  },
  {
    "id": "arXiv:2112.15236",
    "title": "Learning Agent State Online with Recurrent Generate-and-Test",
    "abstract": "Learning continually and online from a continuous stream of data is\nchallenging, especially for a reinforcement learning agent with sequential\ndata. When the environment only provides observations giving partial\ninformation about the state of the environment, the agent must learn the agent\nstate based on the data stream of experience. We refer to the state learned\ndirectly from the data stream of experience as the agent state. Recurrent\nneural networks can learn the agent state, but the training methods are\ncomputationally expensive and sensitive to the hyper-parameters, making them\nunideal for online learning. This work introduces methods based on the\ngenerate-and-test approach to learn the agent state. A generate-and-test\nalgorithm searches for state features by generating features and testing their\nusefulness. In this process, features useful for the agent's performance on the\ntask are preserved, and the least useful features get replaced with newly\ngenerated features. We study the effectiveness of our methods on two online\nmulti-step prediction problems. The first problem, trace conditioning, focuses\non the agent's ability to remember a cue for a prediction multiple steps into\nthe future. In the second problem, trace patterning, the agent needs to learn\npatterns in the observation signals and remember them for future predictions.\nWe show that our proposed methods can effectively learn the agent state online\nand produce accurate predictions.",
    "descriptor": "",
    "authors": [
      "Amir Samani",
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15236"
  },
  {
    "id": "arXiv:2112.15238",
    "title": "Studying the Interplay between Information Loss and Operation Loss in  Representations for Classification",
    "abstract": "Information-theoretic measures have been widely adopted in the design of\nfeatures for learning and decision problems. Inspired by this, we look at the\nrelationship between i) a weak form of information loss in the Shannon sense\nand ii) the operation loss in the minimum probability of error (MPE) sense when\nconsidering a family of lossy continuous representations (features) of a\ncontinuous observation. We present several results that shed light on this\ninterplay. Our first result offers a lower bound on a weak form of information\nloss as a function of its respective operation loss when adopting a discrete\nlossy representation (quantization) instead of the original raw observation.\nFrom this, our main result shows that a specific form of vanishing information\nloss (a weak notion of asymptotic informational sufficiency) implies a\nvanishing MPE loss (or asymptotic operational sufficiency) when considering a\ngeneral family of lossy continuous representations. Our theoretical findings\nsupport the observation that the selection of feature representations that\nattempt to capture informational sufficiency is appropriate for learning, but\nthis selection is a rather conservative design principle if the intended goal\nis achieving MPE in classification. Supporting this last point, and under some\nstructural conditions, we show that it is possible to adopt an alternative\nnotion of informational sufficiency (strictly weaker than pure sufficiency in\nthe mutual information sense) to achieve operational sufficiency in learning.",
    "descriptor": "\nComments: 64 pages, 9 figures\n",
    "authors": [
      "Jorge F. Silva",
      "Felipe Tobar",
      "Mario Vicu\u00f1a",
      "Felipe Cordova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15238"
  },
  {
    "id": "arXiv:2112.15246",
    "title": "When are Iterative Gaussian Processes Reliably Accurate?",
    "abstract": "While recent work on conjugate gradient methods and Lanczos decompositions\nhave achieved scalable Gaussian process inference with highly accurate point\npredictions, in several implementations these iterative methods appear to\nstruggle with numerical instabilities in learning kernel hyperparameters, and\npoor test likelihoods. By investigating CG tolerance, preconditioner rank, and\nLanczos decomposition rank, we provide a particularly simple prescription to\ncorrect these issues: we recommend that one should use a small CG tolerance\n($\\epsilon \\leq 0.01$) and a large root decomposition size ($r \\geq 5000$).\nMoreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs,\nachieving convergence with fewer gradient updates.",
    "descriptor": "\nComments: ICML 2021 OPTML Workshop\n",
    "authors": [
      "Wesley J. Maddox",
      "Sanyam Kapoor",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15246"
  },
  {
    "id": "arXiv:2112.15250",
    "title": "Benign Overfitting in Adversarially Robust Linear Classification",
    "abstract": "\"Benign overfitting\", where classifiers memorize noisy training data yet\nstill achieve a good generalization performance, has drawn great attention in\nthe machine learning community. To explain this surprising phenomenon, a series\nof works have provided theoretical justification in over-parameterized linear\nregression, classification, and kernel methods. However, it is not clear if\nbenign overfitting still occurs in the presence of adversarial examples, i.e.,\nexamples with tiny and intentional perturbations to fool the classifiers. In\nthis paper, we show that benign overfitting indeed occurs in adversarial\ntraining, a principled approach to defend against adversarial examples. In\ndetail, we prove the risk bounds of the adversarially trained linear classifier\non the mixture of sub-Gaussian data under $\\ell_p$ adversarial perturbations.\nOur result suggests that under moderate perturbations, adversarially trained\nlinear classifiers can achieve the near-optimal standard and adversarial risks,\ndespite overfitting the noisy training data. Numerical experiments validate our\ntheoretical findings.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Jinghui Chen",
      "Yuan Cao",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15250"
  },
  {
    "id": "arXiv:2112.15253",
    "title": "First order linear logic and tensor type calculus for categorial  grammars",
    "abstract": "We study relationship between first order multiplicative linear logic (MLL1),\nwhich has been known to provide representations to different categorial\ngrammars, and the recently introduced extended tensor type calculus (ETTC). We\nidentify a fragment of MLL1, which seems sufficient for many grammar\nrepresentations, and establish a correspondence between ETTC and this fragment.\nThe system ETTC, thus, can be seen as an alternative syntax and intrinsic\ndeductive system together with a geometric representation for the latter. We\nalso give a natural deduction formulation of ETTC, which might be convenient.",
    "descriptor": "",
    "authors": [
      "Sergey Slavnov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15253"
  },
  {
    "id": "arXiv:2112.15259",
    "title": "Elimination (a,b)-trees with fast, durable updates",
    "abstract": "Many concurrent dictionary implementations are designed and optimized for\nread-mostly workloads with uniformly distributed keys, and often perform poorly\non update-heavy workloads. In this work, we first present a concurrent\n(a,b)-tree, the OCC-ABtree, which outperforms its fastest competitor by up to\n2x on uniform update-heavy workloads, and is competitive on other workloads. We\nthen turn our attention to skewed update-heavy workloads (which feature many\ninserts/deletes on the same key) and introduce the Elim-ABtree, which uses a\nnew optimization called publishing elimination. In publishing elimination,\nconcurrent inserts and deletes to a key are reordered to eliminate them. This\nreduces the number of writes in the data structure. The Elim-ABtree achieves up\nto 2.5x the performance of its fastest competitor (including the OCC-ABtree).\nThe OCC-ABtree and Elim-ABtree are linearizable. We also introduce durable\nlinearizable versions (for systems with Intel Optane DCPMM non-volatile main\nmemory) that are nearly as fast.",
    "descriptor": "\nComments: 22 pages, 17 figures, 1 table. Full version of the paper to published in Principles and Practice of Parallel Programming (PPoPP) 2022\n",
    "authors": [
      "Anubhav Srivastava",
      "Trevor Brown"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15259"
  },
  {
    "id": "arXiv:2112.15261",
    "title": "Discrete LQR and ILQR methods based on high order Runge-Kutta methods",
    "abstract": "In this paper, discrete linear quadratic regulator (DLQR) and iterative\nlinear quadratic regulator (ILQR) methods based on high-order Runge-Kutta (RK)\ndiscretization are proposed for solving linear and nonlinear quadratic optimal\ncontrol problems respectively. As discovered in [W. Hager, Runge-Kutta method\nin optimal control and the discrete adjoint system, Numer. Math.,2000, pp.\n247-282], direct approach with RK discretization is equivalent with indirect\napproach based on symplectic partitioned Runge-Kutta (SPRK) integration. In\nthis paper, we will reconstruct this equivalence by the analogue of continuous\nand discrete dynamic programming. Then, based on the equivalence, we discuss\nthe issue that the internal-stage controls produced by direct approach may have\nlower order accuracy than the RK method used. We propose order conditions for\ninternal-stage controls and then demonstrate that third or fourth order\nexplicit RK discretization cannot avoid the order reduction phenomenon. To\novercome this obstacle, we calculate node control instead of internal-stage\ncontrols in DLQR and ILQR methods. And numerical examples will illustrate the\nvalidity of our methods. Another advantage of our methods is high computational\nefficiency which comes from the usage of feedback technique. In this paper, we\nalso demonstrate that ILQR is essentially a quasi-Newton method with linear\nconvergence rate.",
    "descriptor": "",
    "authors": [
      "Zuodi Xie",
      "Tieqiang Gang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.15261"
  },
  {
    "id": "arXiv:2112.15270",
    "title": "Echo state graph neural networks with analogue random resistor arrays",
    "abstract": "Recent years have witnessed an unprecedented surge of interest, from social\nnetworks to drug discovery, in learning representations of graph-structured\ndata. However, graph neural networks, the machine learning models for handling\ngraph-structured data, face significant challenges when running on conventional\ndigital hardware, including von Neumann bottleneck incurred by physically\nseparated memory and processing units, slowdown of Moore's law due to\ntransistor scaling limit, and expensive training cost. Here we present a novel\nhardware-software co-design, the random resistor array-based echo state graph\nneural network, which addresses these challenges. The random resistor arrays\nnot only harness low-cost, nanoscale and stackable resistors for highly\nefficient in-memory computing using simple physical laws, but also leverage the\nintrinsic stochasticity of dielectric breakdown to implement random projections\nin hardware for an echo state network that effectively minimizes the training\ncost thanks to its fixed and random weights. The system demonstrates\nstate-of-the-art performance on both graph classification using the MUTAG and\nCOLLAB datasets and node classification using the CORA dataset, achieving\n34.2x, 93.2x, and 570.4x improvement of energy efficiency and 98.27%, 99.46%,\nand 95.12% reduction of training cost compared to conventional graph learning\non digital hardware, respectively, which may pave the way for the next\ngeneration AI system for graph learning.",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Shaocong Wang",
      "Yi Li",
      "Dingchen Wang",
      "Woyu Zhang",
      "Xi Chen",
      "Danian Dong",
      "Songqi Wang",
      "Xumeng Zhang",
      "Peng Lin",
      "Claudio Gallicchio",
      "Xiaoxin Xu",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Zhongrui Wang",
      "Dashan Shang",
      "Ming Liu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.15270"
  },
  {
    "id": "arXiv:2112.15271",
    "title": "BP-Net: Cuff-less, Calibration-free, and Non-invasive Blood Pressure  Estimation via a Generic Deep Convolutional Architecture",
    "abstract": "Objective: The paper focuses on development of robust and accurate processing\nsolutions for continuous and cuff-less blood pressure (BP) monitoring. In this\nregard, a robust deep learning-based framework is proposed for computation of\nlow latency, continuous, and calibration-free upper and lower bounds on the\nsystolic and diastolic BP. Method: Referred to as the BP-Net, the proposed\nframework is a novel convolutional architecture that provides longer effective\nmemory while achieving superior performance due to incorporation of casual\ndialated convolutions and residual connections. To utilize the real potential\nof deep learning in extraction of intrinsic features (deep features) and\nenhance the long-term robustness, the BP-Net uses raw Electrocardiograph (ECG)\nand Photoplethysmograph (PPG) signals without extraction of any form of\nhand-crafted features as it is common in existing solutions. Results: By\ncapitalizing on the fact that datasets used in recent literature are not\nunified and properly defined, a benchmark dataset is constructed from the\nMIMIC-I and MIMIC-III databases obtained from PhysioNet. The proposed BP-Net is\nevaluated based on this benchmark dataset demonstrating promising performance\nand shows superior generalizable capacity. Conclusion: The proposed BP-Net\narchitecture is more accurate than canonical recurrent networks and enhances\nthe long-term robustness of the BP estimation task. Significance: The proposed\nBP-Net architecture addresses key drawbacks of existing BP estimation\nsolutions, i.e., relying heavily on extraction of hand-crafted features, such\nas pulse arrival time (PAT), and; Lack of robustness. Finally, the constructed\nBP-Net dataset provides a unified base for evaluation and comparison of deep\nlearning-based BP estimation algorithms.",
    "descriptor": "",
    "authors": [
      "Soheil Zabihi",
      "Elahe Rahimian",
      "Fatemeh Marefat",
      "Amir Asif",
      "Pedram Mohseni",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15271"
  },
  {
    "id": "arXiv:2112.15272",
    "title": "ViNMT: Neural Machine Translation Tookit",
    "abstract": "We present an open-source toolkit for neural machine translation (NMT). The\nnew toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along\nwith many other improvements detailed below, in order to create a\nself-contained, simple to use, consistent and comprehensive framework for\nMachine Translation tasks of various domains. It is tooled to support both\nbilingual and multilingual translation tasks, starting from building the model\nfrom respective corpora, to inferring new predictions or packaging the model to\nserving-capable JIT format.",
    "descriptor": "",
    "authors": [
      "Nguyen Hoang Quan",
      "Nguyen Thanh Dat",
      "Nguyen Hoang Minh Cong",
      "Nguyen Van Vinh",
      "Ngo Thi Vinh",
      "Nguyen Phuong Thai",
      "Tran Hong Viet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15272"
  },
  {
    "id": "arXiv:2112.15277",
    "title": "Machine Learning Application Development: Practitioners' Insights",
    "abstract": "Nowadays, intelligent systems and services are getting increasingly popular\nas they provide data-driven solutions to diverse real-world problems, thanks to\nrecent breakthroughs in Artificial Intelligence (AI) and Machine Learning (ML).\nHowever, machine learning meets software engineering not only with promising\npotentials but also with some inherent challenges. Despite some recent research\nefforts, we still do not have a clear understanding of the challenges of\ndeveloping ML-based applications and the current industry practices. Moreover,\nit is unclear where software engineering researchers should focus their efforts\nto better support ML application developers. In this paper, we report about a\nsurvey that aimed to understand the challenges and best practices of ML\napplication development. We synthesize the results obtained from 80\npractitioners (with diverse skills, experience, and application domains) into\n17 findings; outlining challenges and best practices for ML application\ndevelopment. Practitioners involved in the development of ML-based software\nsystems can leverage the summarized best practices to improve the quality of\ntheir system. We hope that the reported challenges will inform the research\ncommunity about topics that need to be investigated to improve the engineering\nprocess and the quality of ML-based applications.",
    "descriptor": "",
    "authors": [
      "Md Saidur Rahman",
      "Foutse Khomh",
      "Alaleh Hamidi",
      "Jinghui Cheng",
      "Giuliano Antoniol",
      "Hironori Washizaki"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15277"
  },
  {
    "id": "arXiv:2112.15278",
    "title": "Data-Free Knowledge Transfer: A Survey",
    "abstract": "In the last decade, many deep learning models have been well trained and made\na great success in various fields of machine intelligence, especially for\ncomputer vision and natural language processing. To better leverage the\npotential of these well-trained models in intra-domain or cross-domain transfer\nlearning situations, knowledge distillation (KD) and domain adaptation (DA) are\nproposed and become research highlights. They both aim to transfer useful\ninformation from a well-trained model with original training data. However, the\noriginal data is not always available in many cases due to privacy, copyright\nor confidentiality. Recently, the data-free knowledge transfer paradigm has\nattracted appealing attention as it deals with distilling valuable knowledge\nfrom well-trained models without requiring to access to the training data. In\nparticular, it mainly consists of the data-free knowledge distillation (DFKD)\nand source data-free domain adaptation (SFDA). On the one hand, DFKD aims to\ntransfer the intra-domain knowledge of original data from a cumbersome teacher\nnetwork to a compact student network for model compression and efficient\ninference. On the other hand, the goal of SFDA is to reuse the cross-domain\nknowledge stored in a well-trained source model and adapt it to a target\ndomain. In this paper, we provide a comprehensive survey on data-free knowledge\ntransfer from the perspectives of knowledge distillation and unsupervised\ndomain adaptation, to help readers have a better understanding of the current\nresearch status and ideas. Applications and challenges of the two areas are\nbriefly reviewed, respectively. Furthermore, we provide some insights to the\nsubject of future research.",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Yuang Liu",
      "Wei Zhang",
      "Jun Wang",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15278"
  },
  {
    "id": "arXiv:2112.15280",
    "title": "What is Event Knowledge Graph: A Survey",
    "abstract": "Besides entity-centric knowledge, usually organized as Knowledge Graph (KG),\nevents are also an essential kind of knowledge in the world, which trigger the\nspring up of event-centric knowledge representation form like Event KG (EKG).\nIt plays an increasingly important role in many machine learning and artificial\nintelligence applications, such as intelligent search, question-answering,\nrecommendation, and text generation. This paper provides a comprehensive survey\nof EKG from history, ontology, instance, and application views. Specifically,\nto characterize EKG thoroughly, we focus on its history, definitions, schema\ninduction, acquisition, related representative graphs/systems, and\napplications. The development processes and trends are studied therein. We\nfurther summarize perspective directions to facilitate future research on EKG.",
    "descriptor": "",
    "authors": [
      "Saiping Guan",
      "Xueqi Cheng",
      "Long Bai",
      "Fujun Zhang",
      "Zixuan Li",
      "Yutao Zeng",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15280"
  },
  {
    "id": "arXiv:2112.15281",
    "title": "Efficient Channel Estimation for RIS-Aided MIMO Communications with  Unitary Approximate Message Passing",
    "abstract": "Reconfigurable intelligent surface (RIS) is very promising for wireless\nnetworks to achieve high energy efficiency, extended coverage, improved\ncapacity, massive connectivity, etc. To unleash the full potentials of\nRIS-aided communications, acquiring accurate channel state information is\ncrucial, which however is very challenging. For RIS-aided multiple-input and\nmultiple-output (MIMO) communications, the existing channel estimation methods\nhave computational complexity growing rapidly with the number of RIS units $N$\n(e.g., in the order of $N^2$ or $N^3$) and/or have special requirements on the\nmatrices involved (e.g., the matrices need to be sparse for algorithm\nconvergence to achieve satisfactory performance), which hinder their\napplications. In this work, instead of using the conventional signal model in\nthe literature, we derive a new signal model obtained through proper\nvectorization and reduction operations. Then, leveraging the unitary\napproximate message passing (UAMP), we develop a more efficient channel\nestimator that has complexity linear with $N$ and does not have special\nrequirements on the relevant matrices, thanks to the robustness of UAMP. These\nfacilitate the applications of the proposed algorithm to a general RIS-aided\nMIMO system with a larger $N$. Moreover, extensive numerical results show that\nthe proposed estimator delivers much better performance and/or requires\nsignificantly less number of training symbols, thereby leading to notable\nreductions in both training overhead and latency.",
    "descriptor": "",
    "authors": [
      "Yabo Guo",
      "Peng Sun",
      "Zhengdao Yuan",
      "Chongwen Huang",
      "Qinghua Guo",
      "Zhongyong Wang",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15281"
  },
  {
    "id": "arXiv:2112.15282",
    "title": "Energy-Aware Multi-Robot Task Allocation in Persistent Tasks",
    "abstract": "The applicability of the swarm robots to perform foraging tasks is inspired\nby their compact size and cost. A considerable amount of energy is required to\nperform such tasks, especially if the tasks are continuous and/or repetitive.\nReal-world situations in which robots perform tasks continuously while staying\nalive (survivability) and maximizing production (performance) require energy\nawareness. This paper proposes an energy-conscious distributed task allocation\nalgorithm to solve continuous tasks (e.g., unlimited foraging) for cooperative\nrobots to achieve highly effective missions. We consider efficiency as a\nfunction of the energy consumed by the robot during exploration and collection\nwhen food is returned to the collection bin. Finally, the proposed\nenergy-efficient algorithm minimizes the total transit time to the charging\nstation and time consumed while recharging and maximizes the robot's lifetime\nto perform maximum tasks to enhance the overall efficiency of collaborative\nrobots. We evaluated the proposed solution against a typical greedy\nbenchmarking strategy (assigning the closest collection bin to the available\nrobot and recharging the robot at maximum) for efficiency and performance in\nvarious scenarios. The proposed approach significantly improved performance and\nefficiency over the baseline approach.",
    "descriptor": "\nComments: Accepted for Presentation at the SWARM 2022 Conference\n",
    "authors": [
      "Ehsan Latif",
      "Yikang Gui",
      "Aiman Munir",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.15282"
  },
  {
    "id": "arXiv:2112.15283",
    "title": "ERNIE-ViLG: Unified Generative Pre-training for Bidirectional  Vision-Language Generation",
    "abstract": "Conventional methods for the image-text generation tasks mainly tackle the\nnaturally bidirectional generation tasks separately, focusing on designing\ntask-specific frameworks to improve the quality and fidelity of the generated\nsamples. Recently, Vision-Language Pre-training models have greatly improved\nthe performance of the image-to-text generation tasks, but large-scale\npre-training models for text-to-image synthesis task are still under-developed.\nIn this paper, we propose ERNIE-ViLG, a unified generative pre-training\nframework for bidirectional image-text generation with transformer model. Based\non the image quantization models, we formulate both image generation and text\ngeneration as autoregressive generative tasks conditioned on the text/image\ninput. The bidirectional image-text generative modeling eases the semantic\nalignments across vision and language. For the text-to-image generation\nprocess, we further propose an end-to-end training method to jointly learn the\nvisual sequence generator and the image reconstructor. To explore the landscape\nof large-scale pre-training for bidirectional text-image generation, we train a\n10-billion parameter ERNIE-ViLG model on a large-scale dataset of 145 million\n(Chinese) image-text pairs which achieves state-of-the-art performance for both\ntext-to-image and image-to-text tasks, obtaining an FID of 7.9 on MS-COCO for\ntext-to-image synthesis and best results on COCO-CN and AIC-ICC for image\ncaptioning.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Han Zhang",
      "Weichong Yin",
      "Yewei Fang",
      "Lanxin Li",
      "Boqiang Duan",
      "Zhihua Wu",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15283"
  },
  {
    "id": "arXiv:2112.15285",
    "title": "Modelling of Bi-directional Spatio-Temporal Dependence and Users'  Dynamic Preferences for Missing POI Check-in Identification",
    "abstract": "Human mobility data accumulated from Point-of-Interest (POI) check-ins\nprovides great opportunity for user behavior understanding. However, data\nquality issues (e.g., geolocation information missing, unreal check-ins, data\nsparsity) in real-life mobility data limit the effectiveness of existing\nPOI-oriented studies, e.g., POI recommendation and location prediction, when\napplied to real applications. To this end, in this paper, we develop a model,\nnamed Bi-STDDP, which can integrate bi-directional spatio-temporal dependence\nand users' dynamic preferences, to identify the missing POI check-in where a\nuser has visited at a specific time. Specifically, we first utilize\nbi-directional global spatial and local temporal information of POIs to capture\nthe complex dependence relationships. Then, target temporal pattern in\ncombination with user and POI information are fed into a multi-layer network to\ncapture users' dynamic preferences. Moreover, the dynamic preferences are\ntransformed into the same space as the dependence relationships to form the\nfinal model. Finally, the proposed model is evaluated on three large-scale\nreal-world datasets and the results demonstrate significant improvements of our\nmodel compared with state-of-the-art methods. Also, it is worth noting that the\nproposed model can be naturally extended to address POI recommendation and\nlocation prediction tasks with competitive performances.",
    "descriptor": "\nComments: Accepted by AAAI2019\n",
    "authors": [
      "Dongbo Xi",
      "Fuzhen Zhuang",
      "Yanchi Liu",
      "Jingjing Gu",
      "Hui Xiong",
      "Qing He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.15285"
  },
  {
    "id": "arXiv:2112.15290",
    "title": "Domain Adaptation with Category Attention Network for Deep Sentiment  Analysis",
    "abstract": "Domain adaptation tasks such as cross-domain sentiment classification aim to\nutilize existing labeled data in the source domain and unlabeled or few labeled\ndata in the target domain to improve the performance in the target domain via\nreducing the shift between the data distributions. Existing cross-domain\nsentiment classification methods need to distinguish pivots, i.e., the\ndomain-shared sentiment words, and non-pivots, i.e., the domain-specific\nsentiment words, for excellent adaptation performance. In this paper, we first\ndesign a Category Attention Network (CAN), and then propose a model named\nCAN-CNN to integrate CAN and a Convolutional Neural Network (CNN). On the one\nhand, the model regards pivots and non-pivots as unified category attribute\nwords and can automatically capture them to improve the domain adaptation\nperformance; on the other hand, the model makes an attempt at interpretability\nto learn the transferred category attribute words. Specifically, the\noptimization objective of our model has three different components: 1) the\nsupervised classification loss; 2) the distributions loss of category feature\nweights; 3) the domain invariance loss. Finally, the proposed model is\nevaluated on three public sentiment analysis datasets and the results\ndemonstrate that CAN-CNN can outperform other various baseline methods.",
    "descriptor": "\nComments: Accepted by WWW2020\n",
    "authors": [
      "Dongbo Xi",
      "Fuzhen Zhuang",
      "Ganbin Zhou",
      "Xiaohu Cheng",
      "Fen Lin",
      "Qing He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15290"
  },
  {
    "id": "arXiv:2112.15292",
    "title": "Neural Hierarchical Factorization Machines for User's Event Sequence  Analysis",
    "abstract": "Many prediction tasks of real-world applications need to model multi-order\nfeature interactions in user's event sequence for better detection performance.\nHowever, existing popular solutions usually suffer two key issues: 1) only\nfocusing on feature interactions and failing to capture the sequence influence;\n2) only focusing on sequence information, but ignoring internal feature\nrelations of each event, thus failing to extract a better event representation.\nIn this paper, we consider a two-level structure for capturing the hierarchical\ninformation over user's event sequence: 1) learning effective feature\ninteractions based event representation; 2) modeling the sequence\nrepresentation of user's historical events. Experimental results on both\nindustrial and public datasets clearly demonstrate that our model achieves\nsignificantly better performance compared with state-of-the-art baselines.",
    "descriptor": "\nComments: Accepted by SIGIR2020\n",
    "authors": [
      "Dongbo Xi",
      "Fuzhen Zhuang",
      "Bowen Song",
      "Yongchun Zhu",
      "Shuai Chen",
      "Dan Hong",
      "Tao Chen",
      "Xi Gu",
      "Qing He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15292"
  },
  {
    "id": "arXiv:2112.15300",
    "title": "BatchLens: A Visualization Approach for Analyzing Batch Jobs in Cloud  Systems",
    "abstract": "Cloud systems are becoming increasingly powerful and complex. It is highly\nchallenging to identify anomalous execution behaviors and pinpoint problems by\nexamining the overwhelming intermediate results/states in complex application\nworkflows. Domain scientists urgently need a friendly and functional interface\nto understand the quality of the computing services and the performance of\ntheir applications in real time. To meet these needs, we explore data generated\nby job schedulers and investigate general performance metrics (e.g.,\nutilization of CPU, memory and disk I/O). Specifically, we propose an\ninteractive visual analytics approach, BatchLens, to provide both providers and\nusers of cloud service with an intuitive and effective way to explore the\nstatus of system batch jobs and help them conduct root-cause analysis of\nanomalous behaviors in batch jobs. We demonstrate the effectiveness of\nBatchLens through a case study on the public Alibaba bench workload trace\ndatasets.",
    "descriptor": "",
    "authors": [
      "Shaolun Ruan",
      "Yong Wang",
      "Hailong Jiang",
      "Weijia Xu",
      "Qiang Guan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.15300"
  },
  {
    "id": "arXiv:2112.15303",
    "title": "SimSR: Simple Distance-based State Representation for Deep Reinforcement  Learning",
    "abstract": "This work explores how to learn robust and generalizable state representation\nfrom image-based observations with deep reinforcement learning methods.\nAddressing the computational complexity, stringent assumptions, and\nrepresentation collapse challenges in the existing work of bisimulation metric,\nwe devise Simple State Representation (SimSR) operator, which achieves\nequivalent functionality while reducing the complexity by an order in\ncomparison with bisimulation metric. SimSR enables us to design a\nstochastic-approximation-based method that can practically learn the mapping\nfunctions (encoders) from observations to latent representation space. Besides\nthe theoretical analysis, we experimented and compared our work with recent\nstate-of-the-art solutions in visual MuJoCo tasks. The results show that our\nmodel generally achieves better performance and has better robustness and good\ngeneralization.",
    "descriptor": "\nComments: Accepted by AAAI 2022, Preprint version with Appendix\n",
    "authors": [
      "Hongyu Zang",
      "Xin Li",
      "Mingzhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15303"
  },
  {
    "id": "arXiv:2112.15304",
    "title": "An Intelligent Self-driving Truck System For Highway Transportation",
    "abstract": "Recently, there have been many advances in autonomous driving society,\nattracting a lot of attention from academia and industry. However, existing\nworks mainly focus on cars, extra development is still required for\nself-driving truck algorithms and models. In this paper, we introduce an\nintelligent self-driving truck system. Our presented system consists of three\nmain components, 1) a realistic traffic simulation module for generating\nrealistic traffic flow in testing scenarios, 2) a high-fidelity truck model\nwhich is designed and evaluated for mimicking real truck response in real-world\ndeployment, 3) an intelligent planning module with learning-based decision\nmaking algorithm and multi-mode trajectory planner, taking into account the\ntruck's constraints, road slope changes, and the surrounding traffic flow. We\nprovide quantitative evaluations for each component individually to demonstrate\nthe fidelity and performance of each part. We also deploy our proposed system\non a real truck and conduct real world experiments which shows our system's\ncapacity of mitigating sim-to-real gap. Our code is available at\nhttps://github.com/InceptioResearch/IITS",
    "descriptor": "",
    "authors": [
      "Dawei Wang",
      "Lingping Gao",
      "Ziquan Lan",
      "Wei Li",
      "Jiaping Ren",
      "Jiahui Zhang",
      "Peng Zhang",
      "Pei Zhou",
      "Shengao Wang",
      "Jia Pan",
      "Dinesh Manocha",
      "Ruigang Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15304"
  },
  {
    "id": "arXiv:2112.15311",
    "title": "Bayesian Optimization of Function Networks",
    "abstract": "We consider Bayesian optimization of the output of a network of functions,\nwhere each function takes as input the output of its parent nodes, and where\nthe network takes significant time to evaluate. Such problems arise, for\nexample, in reinforcement learning, engineering design, and manufacturing.\nWhile the standard Bayesian optimization approach observes only the final\noutput, our approach delivers greater query efficiency by leveraging\ninformation that the former ignores: intermediate output within the network.\nThis is achieved by modeling the nodes of the network using Gaussian processes\nand choosing the points to evaluate using, as our acquisition function, the\nexpected improvement computed with respect to the implied posterior on the\nobjective. Although the non-Gaussian nature of this posterior prevents\ncomputing our acquisition function in closed form, we show that it can be\nefficiently maximized via sample average approximation. In addition, we prove\nthat our method is asymptotically consistent, meaning that it finds a globally\noptimal solution as the number of evaluations grows to infinity, thus\ngeneralizing previously known convergence results for the expected improvement.\nNotably, this holds even though our method might not evaluate the domain\ndensely, instead leveraging problem structure to leave regions unexplored.\nFinally, we show that our approach dramatically outperforms standard Bayesian\noptimization methods in several synthetic and real-world problems.",
    "descriptor": "\nComments: In Advances in Neural Information Processing Systems, 2021\n",
    "authors": [
      "Raul Astudillo",
      "Peter I. Frazier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15311"
  },
  {
    "id": "arXiv:2112.15317",
    "title": "SplitBrain: Hybrid Data and Model Parallel Deep Learning",
    "abstract": "The recent success of deep learning applications has coincided with those\nwidely available powerful computational resources for training sophisticated\nmachine learning models with huge datasets. Nonetheless, training large models\nsuch as convolutional neural networks using model parallelism (as opposed to\ndata parallelism) is challenging because the complex nature of communication\nbetween model shards makes it difficult to partition the computation\nefficiently across multiple machines with an acceptable trade-off. This paper\npresents SplitBrain, a high performance distributed deep learning framework\nsupporting hybrid data and model parallelism. Specifically, SplitBrain provides\nlayer-specific partitioning that co-locates compute intensive convolutional\nlayers while sharding memory demanding layers. A novel scalable group\ncommunication is proposed to further improve the training throughput with\nreduced communication overhead. The results show that SplitBrain can achieve\nnearly linear speedup while saving up to 67\\% of memory consumption for data\nand model parallel VGG over CIFAR-10.",
    "descriptor": "",
    "authors": [
      "Farley Lai",
      "Asim Kadav",
      "Erik Kruus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15317"
  },
  {
    "id": "arXiv:2112.15319",
    "title": "A Critical Review of Inductive Logic Programming Techniques for  Explainable AI",
    "abstract": "Despite recent advances in modern machine learning algorithms, the opaqueness\nof their underlying mechanisms continues to be an obstacle in adoption. To\ninstill confidence and trust in artificial intelligence systems, Explainable\nArtificial Intelligence has emerged as a response to improving modern machine\nlearning algorithms' explainability. Inductive Logic Programming (ILP), a\nsubfield of symbolic artificial intelligence, plays a promising role in\ngenerating interpretable explanations because of its intuitive logic-driven\nframework. ILP effectively leverages abductive reasoning to generate\nexplainable first-order clausal theories from examples and background\nknowledge. However, several challenges in developing methods inspired by ILP\nneed to be addressed for their successful application in practice. For example,\nexisting ILP systems often have a vast solution space, and the induced\nsolutions are very sensitive to noises and disturbances. This survey paper\nsummarizes the recent advances in ILP and a discussion of statistical\nrelational learning and neural-symbolic algorithms, which offer synergistic\nviews to ILP. Following a critical review of the recent advances, we delineate\nobserved challenges and highlight potential avenues of further ILP-motivated\nresearch toward developing self-explanatory artificial intelligence systems.",
    "descriptor": "",
    "authors": [
      "Zheng Zhang",
      "Levent Yilmaz",
      "Bo Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15319"
  },
  {
    "id": "arXiv:2112.15320",
    "title": "InverseMV: Composing Piano Scores with a Convolutional Video-Music  Transformer",
    "abstract": "Many social media users prefer consuming content in the form of videos rather\nthan text. However, in order for content creators to produce videos with a high\nclick-through rate, much editing is needed to match the footage to the music.\nThis posts additional challenges for more amateur video makers. Therefore, we\npropose a novel attention-based model VMT (Video-Music Transformer) that\nautomatically generates piano scores from video frames. Using music generated\nfrom models also prevent potential copyright infringements that often come with\nusing existing music. To the best of our knowledge, there is no work besides\nthe proposed VMT that aims to compose music for video. Additionally, there\nlacks a dataset with aligned video and symbolic music. We release a new dataset\ncomposed of over 7 hours of piano scores with fine alignment between pop music\nvideos and MIDI files. We conduct experiments with human evaluation on VMT,\nSeqSeq model (our baseline), and the original piano version soundtrack. VMT\nachieves consistent improvements over the baseline on music smoothness and\nvideo relevance. In particular, with the relevance scores and our case study,\nour model has shown the capability of multimodality on frame-level actors'\nmovement for music generation. Our VMT model, along with the new dataset,\npresents a promising research direction toward composing the matching\nsoundtrack for videos. We have released our code at\nhttps://github.com/linchintung/VMT",
    "descriptor": "\nComments: Rejected by ISMIR 2020\n",
    "authors": [
      "Chin-Tung Lin",
      "Mu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.15320"
  },
  {
    "id": "arXiv:2112.15322",
    "title": "An Efficient and Robust Committee Structure for Sharding Blockchain",
    "abstract": "Nowadays, sharding is deemed as a promising way to save traditional\nblockchain protocols from their low scalability. However, such technique also\nbrings several potential risks and huge communication overheads. An improper\ndesign may give rise to the inconsistent state among different committees.\nFurther, the communication overheads arising from cross-shard transactions\nunfortunately reduce the system's performance. In this paper, we first\nsummarize five essential issues that all sharding blockchain designers face.\nFor each issue, we discuss its key challenge and propose our suggested\nsolutions. In order to break the performance bottlenecks, we propose a\nreputation mechanism for selecting leaders. The term of reputation in our\ndesign reflects each node's honest computation resources. In addition, we\nintroduce a referee committee and partial sets in each committee, and design a\nrecovery procedure in case the leader is malicious. Under the design, we prove\nthat malicious leaders will not hurt the system and will be evicted.\nFurthermore, we conduct a series of simulations to evaluate our design. The\nresults show that selecting leaders by the reputation can dramatically improve\nthe system performance.",
    "descriptor": "",
    "authors": [
      "Mengqian Zhang",
      "Jichen Li",
      "Zhaohua Chen",
      "Hongyin Chen",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15322"
  },
  {
    "id": "arXiv:2112.15324",
    "title": "Deconfounded Visual Grounding",
    "abstract": "We focus on the confounding bias between language and location in the visual\ngrounding pipeline, where we find that the bias is the major visual reasoning\nbottleneck. For example, the grounding process is usually a trivial\nlanguage-location association without visual reasoning, e.g., grounding any\nlanguage query containing sheep to the nearly central regions, due to that most\nqueries about sheep have ground-truth locations at the image center. First, we\nframe the visual grounding pipeline into a causal graph, which shows the\ncausalities among image, query, target location and underlying confounder.\nThrough the causal graph, we know how to break the grounding bottleneck:\ndeconfounded visual grounding. Second, to tackle the challenge that the\nconfounder is unobserved in general, we propose a confounder-agnostic approach\ncalled: Referring Expression Deconfounder (RED), to remove the confounding\nbias. Third, we implement RED as a simple language attention, which can be\napplied in any grounding method. On popular benchmarks, RED improves various\nstate-of-the-art grounding methods by a significant margin. Code will soon be\navailable at: https://github.com/JianqiangH/Deconfounded_VG.",
    "descriptor": "\nComments: AAAI 2022 Accepted\n",
    "authors": [
      "Jianqiang Huang",
      "Yu Qin",
      "Jiaxin Qi",
      "Qianru Sun",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15324"
  },
  {
    "id": "arXiv:2112.15327",
    "title": "Sufficient Statistic Memory AMP",
    "abstract": "Approximate message passing (AMP) is a promising technique for unknown signal\nreconstruction of certain high-dimensional linear systems with non-Gaussian\nsignaling. A distinguished feature of the AMP-type algorithms is that their\ndynamics can be rigorously described by state evolution. However, state\nevolution does not necessarily guarantee the convergence of iterative\nalgorithms. To solve the convergence problem of AMP-type algorithms in\nprinciple, this paper proposes a memory AMP (MAMP) under a sufficient statistic\ncondition, named sufficient statistic MAMP (SS-MAMP). We show that the\ncovariance matrices of SS-MAMP are L-banded and convergent. Given an arbitrary\nMAMP, we can construct an SS-MAMP by damping, which not only ensures the\nconvergence of MAMP but also preserves the orthogonality of MAMP, i.e., its\ndynamics can be rigorously described by state evolution. As a byproduct, we\nprove that the Bayes-optimal orthogonal/vector AMP (BO-OAMP/VAMP) is an\nSS-MAMP. As a result, we reveal two interesting properties of BO-OAMP/VAMP for\nlarge systems: 1) the covariance matrices are L-banded and are convergent in\nBO-OAMP/VAMP, and 2) damping and memory are useless (i.e., do not bring\nperformance improvement) in BO-OAMP/VAMP. As an example, we construct a\nsufficient statistic Bayes-optimal MAMP (BO-MAMP), which is Bayes optimal if\nits state evolution has a unique fixed point and its MSE is not worse than the\noriginal BO-MAMP. Finally, simulations are provided to verify the validity and\naccuracy of the theoretical results.",
    "descriptor": "\nComments: Double-column, 16 pages, 4 figures\n",
    "authors": [
      "Lei Liu",
      "Shunqi Huang",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15327"
  },
  {
    "id": "arXiv:2112.15328",
    "title": "Temporal aware Multi-Interest Graph Neural Network For Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) is a challenging task, which aims at\nrecommending next items based on anonymous interaction sequences. Despite the\nsuperior performance of existing methods for SBR, there are still several\nlimitations: (i) Almost all existing works concentrate on single interest\nextraction and fail to disentangle multiple interests of user, which easily\nresults in suboptimal representations for SBR. (ii) Furthermore, previous\nmethods also ignore the multi-form temporal information, which is significant\nsignal to obtain current intention for SBR. To address the limitations\nmentioned above, we propose a novel method, called \\emph{Temporal aware\nMulti-Interest Graph Neural Network} (TMI-GNN) to disentangle multi-interest\nand yield refined intention representations with the injection of two level\ntemporal information. Specifically, by appending multiple interest nodes, we\nconstruct a multi-interest graph for current session, and adopt the GNNs to\nmodel the item-item relation to capture adjacent item transitions,\nitem-interest relation to disentangle the multi-interests, and interest-item\nrelation to refine the item representation. Meanwhile, we incorporate\nitem-level time interval signals to guide the item information propagation, and\ninterest-level time distribution information to assist the scattering of\ninterest information. Experiments on three benchmark datasets demonstrate that\nTMI-GNN outperforms other state-of-the-art methods consistently.",
    "descriptor": "",
    "authors": [
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.15328"
  },
  {
    "id": "arXiv:2112.15329",
    "title": "On Distinctive Properties of Universal Perturbations",
    "abstract": "We identify properties of universal adversarial perturbations (UAPs) that\ndistinguish them from standard adversarial perturbations. Specifically, we show\nthat targeted UAPs generated by projected gradient descent exhibit two\nhuman-aligned properties: semantic locality and spatial invariance, which\nstandard targeted adversarial perturbations lack. We also demonstrate that UAPs\ncontain significantly less signal for generalization than standard adversarial\nperturbations -- that is, UAPs leverage non-robust features to a smaller extent\nthan standard adversarial perturbations.",
    "descriptor": "",
    "authors": [
      "Sung Min Park",
      "Kuo-An Wei",
      "Kai Xiao",
      "Jerry Li",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15329"
  },
  {
    "id": "arXiv:2112.15331",
    "title": "Using Graph-Aware Reinforcement Learning to Identify Winning Strategies  in Diplomacy Games (Student Abstract)",
    "abstract": "This abstract proposes an approach towards goal-oriented modeling of the\ndetection and modeling complex social phenomena in multiparty discourse in an\nonline political strategy game. We developed a two-tier approach that first\nencodes sociolinguistic behavior as linguistic features then use reinforcement\nlearning to estimate the advantage afforded to any player. In the first tier,\nsociolinguistic behavior, such as Friendship and Reasoning, that speakers use\nto influence others are encoded as linguistic features to identify the\npersuasive strategies applied by each player in simultaneous two-party\ndialogues. In the second tier, a reinforcement learning approach is used to\nestimate a graph-aware reward function to quantify the advantage afforded to\neach player based on their standing in this multiparty setup. We apply this\ntechnique to the game Diplomacy, using a dataset comprising of over 15,000\nmessages exchanged between 78 users. Our graph-aware approach shows robust\nperformance compared to a context-agnostic setup.",
    "descriptor": "",
    "authors": [
      "Hansin Ahuja",
      "Lynnette Hui Xian Ng",
      "Kokil Jaidka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.15331"
  },
  {
    "id": "arXiv:2112.15336",
    "title": "Improved Algorithm for the Network Alignment Problem with Application to  Binary Diffing",
    "abstract": "In this paper, we present a novel algorithm to address the Network Alignment\nproblem. It is inspired from a previous message passing framework of Bayati et\nal. [2] and includes several modifications designed to significantly speed up\nthe message updates as well as to enforce their convergence. Experiments show\nthat our proposed model outperforms other state-of-the-art solvers. Finally, we\npropose an application of our method in order to address the Binary Diffing\nproblem. We show that our solution provides better assignment than the\nreference differs in almost all submitted instances and outline the importance\nof leveraging the graphical structure of binary programs.",
    "descriptor": "",
    "authors": [
      "Elie Mengin",
      "Fabrice Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15336"
  },
  {
    "id": "arXiv:2112.15337",
    "title": "Binary Diffing as a Network Alignment Problem via Belief Propagation",
    "abstract": "In this paper, we address the problem of finding a correspondence, or\nmatching, between the functions of two programs in binary form, which is one of\nthe most common task in binary diffing. We introduce a new formulation of this\nproblem as a particular instance of a graph edit problem over the call graphs\nof the programs. In this formulation, the quality of a mapping is evaluated\nsimultaneously with respect to both function content and call graph\nsimilarities. We show that this formulation is equivalent to a network\nalignment problem. We propose a solving strategy for this problem based on\nmax-product belief propagation. Finally, we implement a prototype of our\nmethod, called QBinDiff, and propose an extensive evaluation which shows that\nour approach outperforms state of the art diffing tools.",
    "descriptor": "",
    "authors": [
      "Elie Mengin",
      "Fabrice Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15337"
  },
  {
    "id": "arXiv:2112.15338",
    "title": "Clustering Vietnamese Conversations From Facebook Page To Build Training  Dataset For Chatbot",
    "abstract": "The biggest challenge of building chatbots is training data. The required\ndata must be realistic and large enough to train chatbots. We create a tool to\nget actual training data from Facebook messenger of a Facebook page. After text\npreprocessing steps, the newly obtained dataset generates FVnC and Sample\ndataset. We use the Retraining of BERT for Vietnamese (PhoBERT) to extract\nfeatures of our text data. K-Means and DBSCAN clustering algorithms are used\nfor clustering tasks based on output embeddings from PhoBERT$_{base}$. We apply\nV-measure score and Silhouette score to evaluate the performance of clustering\nalgorithms. We also demonstrate the efficiency of PhoBERT compared to other\nmodels in feature extraction on Sample dataset. A GridSearch algorithm that\ncombines both clustering evaluations is also proposed to find optimal\nparameters. Thanks to clustering such a number of conversations, we save a lot\nof time and effort to build data and storylines for training chatbot.",
    "descriptor": "\nComments: Preprint submitted to JJCIT (September 26, 2021)\n",
    "authors": [
      "Trieu Hai Nguyen",
      "Thi-Kim-Ngoan Pham",
      "Thi-Hong-Minh Bui",
      "Thanh-Quynh-Chau Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15338"
  },
  {
    "id": "arXiv:2112.15341",
    "title": "Towards a Domain Ontology for the Analysis of Ancient Fabrics The  SILKNOW Project and the Case of European Silk Heritage",
    "abstract": "In this article, we present the SILKNOW project (Silk heritage in the\nKnowledge Society: from punched card to Big Data, Deep Learning and\nvisual/tangible simulations) (2018-2021). This project aimed to use Semantic\nWeb technologies to give greater visibility to silk objects produced and\nconsumed in Europe between the 15th and 19th centuries. Silk is a particularly\nimportant material in European history, and it has produced some exceptional\nobjects of great historical interest. However, it is a threatened heritage that\nis little known to the general public. We show the interest of using Semantic\nWeb technologies to give more visibility to such a heritage, by describing the\nresults we have obtained. We present the methodology used to develop a\nknowledge graph, and in particular the different steps that were necessary to\ncreate the underlying data model, based on the CIDOC CRM or CIDOC Conceptual\nReference Model. We also propose a CIDOC CRM-compatible extension to express\nthe complex semantics of the creation and production process of ancient silk\nfabrics.",
    "descriptor": "\nComments: in French\n",
    "authors": [
      "Marie Puren",
      "Pierre Vernus"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.15341"
  },
  {
    "id": "arXiv:2112.15344",
    "title": "P2P-Loc: Point to Point Tiny Person Localization",
    "abstract": "Bounding-box annotation form has been the most frequently used method for\nvisual object localization tasks. However, bounding-box annotation relies on\nthe large amounts of precisely annotating bounding boxes, which is expensive,\nlaborious, thus impossible in practical scenarios, and even redundant for some\napplications caring not about size. Therefore, we propose a novel point-based\nframework for the person localization task by annotating each person as a\ncoarse point (CoarsePoint) which can be any point within the object extent,\ninstead of an accurate bounding box. And then predict the person's location as\na 2D coordinate in the image. That greatly simplifies the data annotation\npipeline. However, the CoarsePoint annotation inevitably causes the label\nreliability decrease (label uncertainty) and network confusion during training.\nAs a result, we propose a point self-refinement approach, which iteratively\nupdates point annotations in a self-paced way. The proposed refinement system\nalleviates the label uncertainty and progressively improves localization\nperformance. Experiments show that our approach achieves comparable object\nlocalization performance while saving annotation cost up to 80$\\%$. Code is\nenclosed in the supplementary materials.",
    "descriptor": "",
    "authors": [
      "Xuehui Yu",
      "Di Wu",
      "Qixiang Ye",
      "Jianbin Jiao",
      "Zhenjun Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15344"
  },
  {
    "id": "arXiv:2112.15345",
    "title": "Distributed Hybrid CPU and GPU training for Graph Neural Networks on  Billion-Scale Graphs",
    "abstract": "Graph neural networks (GNN) have shown great success in learning from\ngraph-structured data. They are widely used in various applications, such as\nrecommendation, fraud detection, and search. In these domains, the graphs are\ntypically large, containing hundreds of millions or billions of nodes. To\ntackle this challenge, we develop DistDGLv2, a system that extends DistDGL for\ntraining GNNs in a mini-batch fashion, using distributed hybrid CPU/GPU\ntraining to scale to large graphs. DistDGLv2 places graph data in distributed\nCPU memory and performs mini-batch computation in GPUs. DistDGLv2 distributes\nthe graph and its associated data (initial features) across the machines and\nuses this distribution to derive a computational decomposition by following an\nowner-compute rule. DistDGLv2 follows a synchronous training approach and\nallows ego-networks forming mini-batches to include non-local nodes. To\nminimize the overheads associated with distributed computations, DistDGLv2 uses\na multi-level graph partitioning algorithm with min-edge cut along with\nmultiple balancing constraints. This localizes computation in both machine\nlevel and GPU level and statically balance the computations. DistDGLv2 deploys\nan asynchronous mini-batch generation pipeline that makes all computation and\ndata access asynchronous to fully utilize all hardware (CPU, GPU, network,\nPCIe). The combination allows DistDGLv2 to train high-quality models while\nachieving high parallel efficiency and memory scalability. We demonstrate\nDistDGLv2 on various GNN workloads. Our results show that DistDGLv2 achieves\n2-3X speedup over DistDGL and 18X speedup over Euler. It takes only 5-10\nseconds to complete an epoch on graphs with 100s millions of nodes on a cluster\nwith 64 GPUs.",
    "descriptor": "",
    "authors": [
      "Da Zheng",
      "Xiang Song",
      "Chengru Yang",
      "Dominique LaSalle",
      "Qidong Su",
      "Minjie Wang",
      "Chao Ma",
      "George Karypis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.15345"
  },
  {
    "id": "arXiv:2112.15346",
    "title": "Efficient Multi-Beam Training For Terahertz Wireless communications",
    "abstract": "Although Terahertz communication systems can provide high data rates, it\nneeds high directional beamforming at transmitters and receivers to achieve\nsuch rates over a long distance. Therefore, an efficient beam training method\nis vital to accelerate the link establishment. In this study, we propose a\nlow-complexity beam training scheme of terahertz communication system which\nuses a low-cost small-scale hybrid architecture to assist a large-scale array\nfor data transmission. The proposed scheme includes two key stages: (1) coarse\nAoAs/AoDs estimation for beam subset optimization in auxiliary array stage, and\n(2) accurate AoAs/AoDs estimation by exploiting channel sparsity in data\ntransmission array stage. The analysis shows that the complexity of the scheme\nis linear with the number of main paths, and thus greatly reduces the\ncomplexity of beam training. Simulation results have verified the better\nperformance in spectral efficiency of the proposed scheme than that of the\nrelated work.",
    "descriptor": "\nComments: 5 pages 3 figure3\n",
    "authors": [
      "Songjie Yang",
      "Zhongpei Zhang",
      "Zhenzhen Hu",
      "Nuan Song",
      "Hao Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15346"
  },
  {
    "id": "arXiv:2112.15347",
    "title": "Complex contraction on trees without proof of correlation decay",
    "abstract": "We prove complex contraction for zero-free regions of counting weighted set\ncover problem in which an element can appear in an unbounded number of sets,\nthus obtaining fully polynomial-time approximation schemes(FPTAS) via\nBarvinok's algorithmic paradigm\\cite{barvinok2016combinatorics}. Relying on the\ncomputation tree expansion, our approach does not need proof of correlation\ndecay in the real axis. We directly look in the complex plane for a region that\ncontracts into its interior as the tree recursion procedure goes from leaves to\nthe root.\nFor the class of problems under the framework of weighted set covers, we are\nable to give a general approach for describing the contraction regions and draw\na unified algorithmic conclusion. Several previous results, including counting\n(weighted-)edge covers, counting bipartite independent sets and counting\nmonotone CNFs can be completely or partially covered by our main theorem. In\ncontrast to the correlation decay method which also depends on tree expansions\nand needs different potential functions for different problems, our approach is\nmore generic in the sense that our contraction region for different problems\nshares a common shape in the complex plane.",
    "descriptor": "",
    "authors": [
      "Liang Li",
      "Guangzeng Xie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.15347"
  },
  {
    "id": "arXiv:2112.15348",
    "title": "Training Recurrent Neural Networks by Sequential Least Squares and the  Alternating Direction Method of Multipliers",
    "abstract": "For training recurrent neural network models of nonlinear dynamical systems\nfrom an input/output training dataset based on rather arbitrary convex and\ntwice-differentiable loss functions and regularization terms, we propose the\nuse of sequential least squares for determining the optimal network parameters\nand hidden states. In addition, to handle non-smooth regularization terms such\nas L1, L0, and group-Lasso regularizers, as well as to impose possibly\nnon-convex constraints such as integer and mixed-integer constraints, we\ncombine sequential least squares with the alternating direction method of\nmultipliers (ADMM). The performance of the resulting algorithm, that we call\nNAILS (Nonconvex ADMM Iterations and Least Squares), is tested in a nonlinear\nsystem identification benchmark.",
    "descriptor": "\nComments: 15 pages, 3 figures. Submitted for publication\n",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.15348"
  },
  {
    "id": "arXiv:2112.15351",
    "title": "Learning to Predict 3D Lane Shape and Camera Pose from a Single Image  via Geometry Constraints",
    "abstract": "Detecting 3D lanes from the camera is a rising problem for autonomous\nvehicles. In this task, the correct camera pose is the key to generating\naccurate lanes, which can transform an image from perspective-view to the\ntop-view. With this transformation, we can get rid of the perspective effects\nso that 3D lanes would look similar and can accurately be fitted by low-order\npolynomials. However, mainstream 3D lane detectors rely on perfect camera poses\nprovided by other sensors, which is expensive and encounters multi-sensor\ncalibration issues. To overcome this problem, we propose to predict 3D lanes by\nestimating camera pose from a single image with a two-stage framework. The\nfirst stage aims at the camera pose task from perspective-view images. To\nimprove pose estimation, we introduce an auxiliary 3D lane task and geometry\nconstraints to benefit from multi-task learning, which enhances consistencies\nbetween 3D and 2D, as well as compatibility in the above two tasks. The second\nstage targets the 3D lane task. It uses previously estimated pose to generate\ntop-view images containing distance-invariant lane appearances for predicting\naccurate 3D lanes. Experiments demonstrate that, without ground truth camera\npose, our method outperforms the state-of-the-art perfect-camera-pose-based\nmethods and has the fewest parameters and computations. Codes are available at\nhttps://github.com/liuruijin17/CLGo.",
    "descriptor": "\nComments: 14 pages, 10 figures, accepted by AAAI 2022\n",
    "authors": [
      "Ruijin Liu",
      "Dapeng Chen",
      "Tie Liu",
      "Zhiliang Xiong",
      "Zejian Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15351"
  },
  {
    "id": "arXiv:2112.15352",
    "title": "Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) is proposed to recommend items within\nshort sessions given that user profiles are invisible in various scenarios\nnowadays, such as e-commerce and short video recommendation. There is a common\nscenario that user specifies a target category of items as a global filter,\nhowever previous SBR settings mainly consider the item sequence and overlook\nthe rich target category information in this scenario. Therefore, we define a\nnew task called Category-aware Session-Based Recommendation (CSBR), focusing on\nthe above scenario, in which the user-specified category can be efficiently\nutilized by the recommendation system. To address the challenges of the\nproposed task, we develop a novel method called Intention Adaptive Graph Neural\nNetwork (IAGNN), which takes advantage of relationship between items and their\ncategories to achieve an accurate recommendation result. Specifically, we\nconstruct a category-aware graph with both item and category nodes to represent\nthe complex transition information in the session. An intention-adaptive graph\nneural network on the category-aware graph is utilized to capture user\nintention by transferring the historical interaction information to the\nuser-specified category domain. Extensive experiments on three real-world\ndatasets are conducted to show our IAGNN outperforms the state-of-the-art\nbaselines in the new task.",
    "descriptor": "",
    "authors": [
      "Chuan Cui",
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Zhenwei Dong",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.15352"
  },
  {
    "id": "arXiv:2112.15354",
    "title": "Statistical Device Activity Detection for OFDM-based Massive Grant-Free  Access",
    "abstract": "Existing works on grant-free access, proposed to support massive machine-type\ncommunication (mMTC) for the Internet of things (IoT), mainly concentrate on\nnarrow band systems under flat fading. However, little is known about massive\ngrant-free access for wideband systems under frequency-selective fading. This\npaper investigates massive grant-free access in a wideband system under\nfrequency-selective fading. First, we present an orthogonal frequency division\nmultiplexing (OFDM)-based massive grant-free access scheme. Then, we propose\ntwo different but equivalent models for the received pilot signal, which are\nessential for designing various device activity detection and channel\nestimation methods for OFDM-based massive grant-free access. One directly\nmodels the received signal for actual devices, whereas the other can be\ninterpreted as a signal model for virtual devices. Next, we investigate\nstatistical device activity detection under frequency-selective Rayleigh fading\nbased on the two signal models. We first model device activities as unknown\ndeterministic quantities and propose three maximum likelihood (ML)\nestimation-based device activity detection methods with different detection\naccuracies and computation times. We also model device activities as random\nvariables with a known joint distribution and propose three maximum a posterior\nprobability (MAP) estimation-based device activity methods, which further\nenhance the accuracies of the corresponding ML estimation-based methods.\nOptimization techniques and matrix analysis are applied in designing and\nanalyzing these methods. Finally, numerical results show that the proposed\nstatistical device activity detection methods outperform existing\nstate-of-the-art device activity detection methods under frequency-selective\nRayleigh fading.",
    "descriptor": "\nComments: 30 pages, 7 figures, be submitted to IEEE Transactions on WIreless Communications\n",
    "authors": [
      "Yuhang Jia",
      "Ying Cui",
      "Wuyang Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15354"
  },
  {
    "id": "arXiv:2112.15355",
    "title": "Sparse LiDAR Assisted Self-supervised Stereo Disparity Estimation",
    "abstract": "Deep stereo matching has made significant progress in recent years. However,\nstate-of-the-art methods are based on expensive 4D cost volume, which limits\ntheir use in real-world applications. To address this issue, 3D correlation\nmaps and iterative disparity updates have been proposed. Regarding that in\nreal-world platforms, such as self-driving cars and robots, the Lidar is\nusually installed. Thus we further introduce the sparse Lidar point into the\niterative updates, which alleviates the burden of network updating the\ndisparity from zero states. Furthermore, we propose training the network in a\nself-supervised way so that it can be trained on any captured data for better\ngeneralization ability. Experiments and comparisons show that the presented\nmethod is effective and achieves comparable results with related methods.",
    "descriptor": "",
    "authors": [
      "Xiaoming Zhao",
      "Weihai Chen",
      "Xingming Wu",
      "Peter C. Y. Chen",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15355"
  },
  {
    "id": "arXiv:2112.15356",
    "title": "OpenQA: Hybrid QA System Relying on Structured Knowledge Base as well as  Non-structured Data",
    "abstract": "Search engines based on keyword retrieval can no longer adapt to the way of\ninformation acquisition in the era of intelligent Internet of Things due to the\nreturn of keyword related Internet pages. How to quickly, accurately and\neffectively obtain the information needed by users from massive Internet data\nhas become one of the key issues urgently needed to be solved. We propose an\nintelligent question-answering system based on structured KB and unstructured\ndata, called OpenQA, in which users can give query questions and the model can\nquickly give accurate answers back to users. We integrate KBQA structured\nquestion answering based on semantic parsing and deep representation learning,\nand two-stage unstructured question answering based on retrieval and neural\nmachine reading comprehension into OpenQA, and return the final answer with the\nhighest probability through the Transformer answer selection module in OpenQA.\nWe carry out preliminary experiments on our constructed dataset, and the\nexperimental results prove the effectiveness of the proposed intelligent\nquestion answering system. At the same time, the core technology of each module\nof OpenQA platform is still in the forefront of academic hot spots, and the\ntheoretical essence and enrichment of OpenQA will be further explored based on\nthese academic hot spots.",
    "descriptor": "",
    "authors": [
      "Gaochen Wu",
      "Bin Xu",
      "Yuxin Qin",
      "Yang Liu",
      "Lingyu Liu",
      "Ziwei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15356"
  },
  {
    "id": "arXiv:2112.15358",
    "title": "Conditional Generative Data-Free Knowledge Distillation based on  Attention Transfer",
    "abstract": "Knowledge distillation has made remarkable achievements in model compression.\nHowever, most existing methods demand original training data, while real data\nin practice are often unavailable due to privacy, security and transmission\nlimitation. To address this problem, we propose a conditional generative\ndata-free knowledge distillation (CGDD) framework to train efficient portable\nnetwork without any real data. In this framework, except using the knowledge\nextracted from teacher model, we introduce preset labels as additional\nauxiliary information to train the generator. Then, the trained generator can\nproduce meaningful training samples of specified category as required. In order\nto promote distillation process, except using conventional distillation loss,\nwe treat preset label as ground truth label so that student network is directly\nsupervised by the category of synthetic training sample. Moreover, we force\nstudent network to mimic the attention maps of teacher model and further\nimprove its performance. To verify the superiority of our method, we design a\nnew evaluation metric is called as relative accuracy to directly compare the\neffectiveness of different distillation methods. Trained portable network\nlearned with proposed data-free distillation method obtains 99.63%, 99.07% and\n99.84% relative accuracy on CIFAR10, CIFAR100 and Caltech101, respectively. The\nexperimental results demonstrate the superiority of proposed method.",
    "descriptor": "",
    "authors": [
      "Xinyi YU",
      "Ling Yan",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15358"
  },
  {
    "id": "arXiv:2112.15360",
    "title": "Making AI 'Smart': Bridging AI and Cognitive Science",
    "abstract": "The last two decades have seen tremendous advances in Artificial\nIntelligence. The exponential growth in terms of computation capabilities has\ngiven us hope of developing humans like robots. The question is: are we there\nyet? Maybe not. With the integration of cognitive science, the 'artificial'\ncharacteristic of Artificial Intelligence (AI) might soon be replaced with\n'smart'. This will help develop more powerful AI systems and simultaneously\ngives us a better understanding of how the human brain works. We discuss the\nvarious possibilities and challenges of bridging these two fields and how they\ncan benefit each other. We argue that the possibility of AI taking over human\ncivilization is low as developing such an advanced system requires a better\nunderstanding of the human brain first.",
    "descriptor": "",
    "authors": [
      "Madhav Agarwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15360"
  },
  {
    "id": "arXiv:2112.15361",
    "title": "Preference Swaps for the Stable Matching Problem",
    "abstract": "An instance $I$ of the Stable Matching Problem (SMP) is given by a bipartite\ngraph with a preference list of neighbors for every vertex. A swap in $I$ is\nthe exchange of two consecutive vertices in a preference list. A swap can be\nviewed as a smallest perturbation of $I$. Boehmer et al. (2021) designed a\npolynomial-time algorithm to find the minimum number of swaps required to turn\na given maximal matching into a stable matching. To generalize this result to\nthe many-to-many version of SMP, we introduce a new representation of SMP as an\nextended bipartite graph and reduce the problem to submodular minimization. It\nis a natural problem to establish computational complexity of deciding whether\nat most $k$ swaps are enough to turn $I$ into an instance where one of the\nmaximum matchings is stable. Using a hardness result of Gupta et al. (2020), we\nprove that it is NP-hard to decide whether at most $k$ swaps are enough to turn\n$I$ into an instance with a stable perfect matching. Moreover, this problem\nparameterized by $k$ is W[1]-hard. We also obtain a lower bound on the running\ntime for solving the problem using the Exponential Time Hypothesis.",
    "descriptor": "",
    "authors": [
      "Eduard Eiben",
      "Gregory Gutin",
      "Philip R. Neary",
      "Cl\u00e9ment Rambaud",
      "Magnus Wahlstr\u00f6m",
      "Anders Yeo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.15361"
  },
  {
    "id": "arXiv:2112.15364",
    "title": "Robust Entropy-regularized Markov Decision Processes",
    "abstract": "Stochastic and soft optimal policies resulting from entropy-regularized\nMarkov decision processes (ER-MDP) are desirable for exploration and imitation\nlearning applications. Motivated by the fact that such policies are sensitive\nwith respect to the state transition probabilities, and the estimation of these\nprobabilities may be inaccurate, we study a robust version of the ER-MDP model,\nwhere the stochastic optimal policies are required to be robust with respect to\nthe ambiguity in the underlying transition probabilities. Our work is at the\ncrossroads of two important schemes in reinforcement learning (RL), namely,\nrobust MDP and entropy regularized MDP. We show that essential properties that\nhold for the non-robust ER-MDP and robust unregularized MDP models also hold in\nour settings, making the robust ER-MDP problem tractable. We show how our\nframework and results can be integrated into different algorithmic schemes\nincluding value or (modified) policy iteration, which would lead to new robust\nRL and inverse RL algorithms to handle uncertainties. Analyses on computational\ncomplexity and error propagation under conventional uncertainty settings are\nalso provided.",
    "descriptor": "",
    "authors": [
      "Tien Mai",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15364"
  },
  {
    "id": "arXiv:2112.15370",
    "title": "Subresultant of several univariate polynomials",
    "abstract": "Subresultant of two univariate polynomials is a fundamental object in\ncomputational algebra and geometry with many applications (for instance,\nparametric GCD and parametric multiplicity of roots). In this paper, we\ngeneralize the theory of subresultants of two polynomials to arbitrary number\nof polynomials, resulting in multi-polynomial subresultants. Specifically,\n1. we propose a definition of multi-polynomial subresultants, which is an\nexpression in terms of roots;\n2. we illustrate the usefulness of the proposed definition via the following\ntwo fundamental applications:\n- parametric GCD of multi-polynomials, and\n- parametric multiplicity of roots of a polynomial;\n3. we provide several expressions for the multi-polynomials subresultants in\nterms of coefficients, for computation.",
    "descriptor": "",
    "authors": [
      "Hoon Hong",
      "Jing Yang"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.15370"
  },
  {
    "id": "arXiv:2112.15399",
    "title": "InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering",
    "abstract": "We present an information-theoretic regularization technique for few-shot\nnovel view synthesis based on neural implicit representation. The proposed\napproach minimizes potential reconstruction inconsistency that happens due to\ninsufficient viewpoints by imposing the entropy constraint of the density in\neach ray. In addition, to alleviate the potential degenerate issue when all\ntraining images are acquired from almost redundant viewpoints, we further\nincorporate the spatially smoothness constraint into the estimated images by\nrestricting information gains from a pair of rays with slightly different\nviewpoints. The main idea of our algorithm is to make reconstructed scenes\ncompact along individual rays and consistent across rays in the neighborhood.\nThe proposed regularizers can be plugged into most of existing neural volume\nrendering techniques based on NeRF in a straightforward way. Despite its\nsimplicity, we achieve consistently improved performance compared to existing\nneural view synthesis methods by large margins on multiple standard benchmarks.\nOur project website is available at\n\\url{this http URL}.",
    "descriptor": "",
    "authors": [
      "Mijeong Kim",
      "Seonguk Seo",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.15399"
  },
  {
    "id": "arXiv:2112.15400",
    "title": "Settling the Bias and Variance of Meta-Gradient Estimation for  Meta-Reinforcement Learning",
    "abstract": "In recent years, gradient based Meta-RL (GMRL) methods have achieved\nremarkable successes in either discovering effective online hyperparameter for\none single task (Xu et al., 2018) or learning good initialisation for\nmulti-task transfer learning (Finn et al., 2017). Despite the empirical\nsuccesses, it is often neglected that computing meta gradients via vanilla\nbackpropagation is ill-defined. In this paper, we argue that the stochastic\nmeta-gradient estimation adopted by many existing MGRL methods are in fact\nbiased; the bias comes from two sources: 1) the compositional bias that is\ninborn in the structure of compositional optimisation problems and 2) the bias\nof multi-step Hessian estimation caused by direct automatic differentiation. To\nbetter understand the meta gradient biases, we perform the first of its kind\nstudy to quantify the amount for each of them. We start by providing a unifying\nderivation for existing GMRL algorithms, and then theoretically analyse both\nthe bias and the variance of existing gradient estimation methods. On\nunderstanding the underlying principles of bias, we propose two mitigation\nsolutions based on off-policy correction and multi-step Hessian estimation\ntechniques. Comprehensive ablation studies have been conducted and results\nreveals: (1) The existence of these two biases and how they influence the\nmeta-gradient estimation when combined with different estimator/sample\nsize/step and learning rate. (2) The effectiveness of these mitigation\napproaches for meta-gradient estimation and thereby the final return on two\npractical Meta-RL algorithms: LOLA-DiCE and Meta-gradient Reinforcement\nLearning.",
    "descriptor": "",
    "authors": [
      "Bo Liu",
      "Xidong Feng",
      "Haifeng Zhang",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15400"
  },
  {
    "id": "arXiv:2112.15402",
    "title": "Revisiting Experience Replay: Continual Learning by Adaptively Tuning  Task-wise Relationship",
    "abstract": "Continual learning requires models to learn new tasks while maintaining\npreviously learned knowledge. Various algorithms have been proposed to address\nthis real challenge. Till now, rehearsal-based methods, such as experience\nreplay, have achieved state-of-the-art performance. These approaches save a\nsmall part of the data of the past tasks as a memory buffer to prevent models\nfrom forgetting previously learned knowledge. However, most of them treat every\nnew task equally, i.e., fixed the hyperparameters of the framework while\nlearning different new tasks. Such a setting lacks the consideration of the\nrelationship/similarity between past and new tasks. For example, the previous\nknowledge/features learned from dogs are more beneficial for the identification\nof cats (new task), compared to those learned from buses. In this regard, we\npropose a meta learning algorithm based on bi-level optimization to adaptively\ntune the relationship between the knowledge extracted from the past and new\ntasks. Therefore, the model can find an appropriate direction of gradient\nduring continual learning and avoid the serious overfitting problem on memory\nbuffer. Extensive experiments are conducted on three publicly available\ndatasets (i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet). The experimental\nresults demonstrate that the proposed method can consistently improve the\nperformance of all baselines.",
    "descriptor": "",
    "authors": [
      "Quanziang Wang",
      "Yuexiang Li",
      "Dong Wei",
      "Renzhen Wang",
      "Kai Ma",
      "Yefeng Zheng",
      "Deyu Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15402"
  },
  {
    "id": "arXiv:2112.15403",
    "title": "Fast Graph Subset Selection Based on G-optimal Design",
    "abstract": "Graph sampling theory extends the traditional sampling theory to graphs with\ntopological structures. As a key part of the graph sampling theory, subset\nselection chooses nodes on graphs as samples to reconstruct the original\nsignal. Due to the eigen-decomposition operation for Laplacian matrices of\ngraphs, however, existing subset selection methods usually require\nhigh-complexity calculations. In this paper, with an aim of enhancing the\ncomputational efficiency of subset selection on graphs, we propose a novel\nobjective function based on the optimal experimental design. Theoretical\nanalysis shows that this function enjoys an $\\alpha$-supermodular property with\na provable lower bound on $\\alpha$. The objective function, together with an\napproximate of the low-pass filter on graphs, suggests a fast subset selection\nmethod that does not require any eigen-decomposition operation. Experimental\nresults show that the proposed method exhibits high computational efficiency,\nwhile having competitive results compared to the state-of-the-art ones,\nespecially when the sampling rate is low.",
    "descriptor": "",
    "authors": [
      "Zhengpin Li",
      "Zheng Wei",
      "Jian Wang",
      "Yun Lin",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15403"
  },
  {
    "id": "arXiv:2112.15404",
    "title": "Virtualization over Multiprocessor System-on-Chip: an Enabling Paradigm  for Industrial IoT",
    "abstract": "The next-generation Industrial Internet of Things (IIoT) inherently requires\nsmart devices featuring rich connectivity, local intelligence, and autonomous\nbehavior. Emerging Multiprocessor System-on-Chip (MPSoC) platforms along with\ncomprehensive support for virtualization will represent two key building blocks\nfor smart devices in future IIoT edge infrastructures. We review representative\nexisting solutions, highlighting the aspects that are most relevant for\nintegration in IIoT solutions. From the analysis, we derive a reference\narchitecture for a general virtualization-ready edge IIoT node. We then analyze\nthe implications and benefits for a concrete use case scenario and identify the\ncrucial research challenges to be faced to bridge the gap towards full support\nfor virtualization-ready IIoT nodes",
    "descriptor": "\nComments: 10 pages, 3 figures, 1 table, accepted for publication in IEEE Computer\n",
    "authors": [
      "Alessandro Cilardo",
      "Marcello Cinque",
      "Luigi De Simone",
      "Nicola Mazzocca"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.15404"
  },
  {
    "id": "arXiv:2112.15405",
    "title": "$C^1$-VEM for some variants of the Cahn-Hilliard equation: a numerical  exploration",
    "abstract": "We consider the $C^1$-Virtual Element Method (VEM) for the conforming\nnumerical approximation of some variants of the Cahn-Hilliard equation on\npolygonal meshes. In particular, we focus on the discretization of the\nadvective Cahn-Hilliard problem and the Cahn-Hilliard inpainting problem. We\npresent the numerical approximation and several numerical results to assess the\nefficacy of the proposed methodology.",
    "descriptor": "",
    "authors": [
      "Paola F. Antonietti",
      "Simone Scacchi",
      "Giuseppe Vacca",
      "Marco Verani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15405"
  },
  {
    "id": "arXiv:2112.15411",
    "title": "Disjoint Contrastive Regression Learning for Multi-Sourced Annotations",
    "abstract": "Large-scale datasets are important for the development of deep learning\nmodels. Such datasets usually require a heavy workload of annotations, which\nare extremely time-consuming and expensive. To accelerate the annotation\nprocedure, multiple annotators may be employed to label different subsets of\nthe data. However, the inconsistency and bias among different annotators are\nharmful to the model training, especially for qualitative and subjective\ntasks.To address this challenge, in this paper, we propose a novel contrastive\nregression framework to address the disjoint annotations problem, where each\nsample is labeled by only one annotator and multiple annotators work on\ndisjoint subsets of the data. To take account of both the intra-annotator\nconsistency and inter-annotator inconsistency, two strategies are\nemployed.Firstly, a contrastive-based loss is applied to learn the relative\nranking among different samples of the same annotator, with the assumption that\nthe ranking of samples from the same annotator is unanimous. Secondly, we apply\nthe gradient reversal layer to learn robust representations that are invariant\nto different annotators. Experiments on the facial expression prediction task,\nas well as the image quality assessment task, verify the effectiveness of our\nproposed framework.",
    "descriptor": "",
    "authors": [
      "Xiaoqian Ruan",
      "Gaoang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15411"
  },
  {
    "id": "arXiv:2112.15414",
    "title": "Notes on the Boussinesq-Full dispersion systems for internal waves:  Numerical solution and solitary waves",
    "abstract": "In this paper we study some theoretical and numerical issues of the\nBoussinesq/Full dispersion system. This is a a three-parameter system of pde's\nthat models the propagation of internal waves along the interface of two-fluid\nlayers with rigid lid condition for the upper layer, and under a Boussinesq\nregime for the upper layer and a full dispersion regime for the lower layer. We\nfirst discretize in space the periodic initial-value problem with a\nFourier-Galerkin spectral method and prove error estimates for several ranges\nof values of the parameters. Solitary waves of the model systems are then\nstudied numerically in several ways. The numerical generation is analyzed by\napproximating the ode system with periodic boundary conditions for the\nsolitary-wave profiles with a Fourier spectral scheme, implemented in a\ncollocation form, and solving iteratively the corresponding algebraic system in\nFourier space with the Petviashvili method accelerated with the minimal\npolynomial extrapolation technique. Motivated by the numerical results, a new\nresult of existence of solitary waves is proved. In the last part of the paper,\nthe dynamics of these solitary waves is studied computationally, To this end,\nthe semidiscrete systems obtained from the Fourier-Galerkin discretization in\nspace are integrated numerically in time by a Runge-Kutta Composition method of\norder four. The fully discrete scheme is used to explore numerically the\nstability of solitary waves, their collisions, and the resolution of other\ninitial conditions into solitary waves.",
    "descriptor": "",
    "authors": [
      "V. A. Dougalis",
      "A. Dur\u00e1n",
      "L. Saridaki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.15414"
  },
  {
    "id": "arXiv:2112.15417",
    "title": "Hypers at ComMA@ICON: Modelling Aggressiveness, Gender Bias and Communal  Bias Identification",
    "abstract": "Due to the exponentially increasing reach of social media, it is essential to\nfocus on its negative aspects as it can potentially divide society and incite\npeople into violence. In this paper, we present our system description of work\non the shared task ComMA@ICON, where we have to classify how aggressive the\nsentence is and if the sentence is gender-biased or communal biased. These\nthree could be the primary reasons to cause significant problems in society. As\nteam Hypers we have proposed an approach that utilizes different pretrained\nmodels with Attention and mean pooling methods. We were able to get Rank 3 with\n0.223 Instance F1 score on Bengali, Rank 2 with 0.322 Instance F1 score on\nMulti-lingual set, Rank 4 with 0.129 Instance F1 score on Meitei and Rank 5\nwith 0.336 Instance F1 score on Hindi. The source code and the pretrained\nmodels of this work can be found here.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Sean Benhur",
      "Roshan Nayak",
      "Kanchana Sivanraju",
      "Adeep Hande",
      "Subalalitha Chinnaudayar Navaneethakrishnan",
      "Ruba Priyadharshini",
      "Bharathi Raja Chakravarthi6"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15417"
  },
  {
    "id": "arXiv:2112.15419",
    "title": "Channel Estimation for Hybrid Massive MIMO Systems with  Adaptive-Resolution ADCs",
    "abstract": "Achieving high channel estimation accuracy and reducing hardware cost as well\nas power dissipation constitute substantial challenges in the design of massive\nmultiple-input multiple-output (MIMO) systems. To resolve these difficulties,\nsophisticated pilot designs have been conceived for the family of\nenergy-efficient hybrid analog-digital (HAD) beamforming architecture relying\non adaptive-resolution analog-to-digital converters (RADCs). In this paper, we\njointly optimize the pilot sequences, the number of RADC quantization bits and\nthe hybrid receiver combiner in the uplink of multiuser massive MIMO systems.\nWe solve the associated mean square error (MSE) minimization problem of channel\nestimation in the context of correlated Rayleigh fading channels subject to\npractical constraints. The associated mixed-integer problem is quite\nchallenging due to the nonconvex nature of the objective function and of the\nconstraints. By relying on advanced fractional programming (FP) techniques, we\nfirst recast the original problem into a more tractable yet equivalent form,\nwhich allows the decoupling of the fractional objective function. We then\nconceive a pair of novel algorithms for solving the resultant problems for\ncodebook-based and codebook-free pilot schemes, respectively. To reduce the\ndesign complexity, we also propose a simplified algorithm for the\ncodebook-based pilot scheme. Our simulation results confirm the superiority of\nthe proposed algorithms over the relevant state-of-the-art benchmark schemes.",
    "descriptor": "",
    "authors": [
      "Yalin Wang",
      "Xihan Chen",
      "Yunlong Cai",
      "Benoit Champagne",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15419"
  },
  {
    "id": "arXiv:2112.15421",
    "title": "Representation Learning via Consistent Assignment of Views to Clusters",
    "abstract": "We introduce Consistent Assignment for Representation Learning (CARL), an\nunsupervised learning method to learn visual representations by combining ideas\nfrom self-supervised contrastive learning and deep clustering. By viewing\ncontrastive learning from a clustering perspective, CARL learns unsupervised\nrepresentations by learning a set of general prototypes that serve as energy\nanchors to enforce different views of a given image to be assigned to the same\nprototype. Unlike contemporary work on contrastive learning with deep\nclustering, CARL proposes to learn the set of general prototypes in an online\nfashion, using gradient descent without the necessity of using\nnon-differentiable algorithms or K-Means to solve the cluster assignment\nproblem. CARL surpasses its competitors in many representations learning\nbenchmarks, including linear evaluation, semi-supervised learning, and transfer\nlearning.",
    "descriptor": "\nComments: The 37th ACM/SIGAPP Symposium on Applied Computing (SAC'22)\n",
    "authors": [
      "Thalles Silva",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15421"
  },
  {
    "id": "arXiv:2112.15422",
    "title": "Scalar reward is not enough: A response to Silver, Singh, Precup and  Sutton (2021)",
    "abstract": "The recent paper `\"Reward is Enough\" by Silver, Singh, Precup and Sutton\nposits that the concept of reward maximisation is sufficient to underpin all\nintelligence, both natural and artificial. We contest the underlying assumption\nof Silver et al. that such reward can be scalar-valued. In this paper we\nexplain why scalar rewards are insufficient to account for some aspects of both\nbiological and computational intelligence, and argue in favour of explicitly\nmulti-objective models of reward maximisation. Furthermore, we contend that\neven if scalar reward functions can trigger intelligent behaviour in specific\ncases, it is still undesirable to use this approach for the development of\nartificial general intelligence due to unacceptable risks of unsafe or\nunethical behaviour.",
    "descriptor": "",
    "authors": [
      "Peter Vamplew",
      "Benjamin J. Smith",
      "Johan Kallstrom",
      "Gabriel Ramos",
      "Roxana Radulescu",
      "Diederik M. Roijers",
      "Conor F. Hayes",
      "Fredrik Heintz",
      "Patrick Mannion",
      "Pieter J.K. Libin",
      "Richard Dazeley",
      "Cameron Foale"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15422"
  },
  {
    "id": "arXiv:2112.15424",
    "title": "A Survey on Hyperdimensional Computing aka Vector Symbolic  Architectures, Part II: Applications, Cognitive Models, and Challenges",
    "abstract": "This is Part II of the two-part comprehensive survey devoted to a computing\nframework most commonly known under the names Hyperdimensional Computing and\nVector Symbolic Architectures (HDC/VSA). Both names refer to a family of\ncomputational models that use high-dimensional distributed representations and\nrely on the algebraic properties of their key operations to incorporate the\nadvantages of structured symbolic representations and vector distributed\nrepresentations. Holographic Reduced Representations is an influential HDC/VSA\nmodel that is well-known in the machine learning domain and often used to refer\nto the whole family. However, for the sake of consistency, we use HDC/VSA to\nrefer to the area. Part I of this survey covered foundational aspects of the\narea, such as historical context leading to the development of HDC/VSA, key\nelements of any HDC/VSA model, known HDC/VSA models, and transforming input\ndata of various types into high-dimensional vectors suitable for HDC/VSA. This\nsecond part surveys existing applications, the role of HDC/VSA in cognitive\ncomputing and architectures, as well as directions for future work. Most of the\napplications lie within the machine learning/artificial intelligence domain,\nhowever we also cover other applications to provide a thorough picture. The\nsurvey is written to be useful for both newcomers and practitioners.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Denis Kleyko",
      "Dmitri A. Rachkovskij",
      "Evgeny Osipov",
      "Abbas Rahim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15424"
  },
  {
    "id": "arXiv:2112.15430",
    "title": "Robustness and risk management via distributional dynamic programming",
    "abstract": "In dynamic programming (DP) and reinforcement learning (RL), an agent learns\nto act optimally in terms of expected long-term return by sequentially\ninteracting with its environment modeled by a Markov decision process (MDP).\nMore generally in distributional reinforcement learning (DRL), the focus is on\nthe whole distribution of the return, not just its expectation. Although\nDRL-based methods produced state-of-the-art performance in RL with function\napproximation, they involve additional quantities (compared to the\nnon-distributional setting) that are still not well understood. As a first\ncontribution, we introduce a new class of distributional operators, together\nwith a practical DP algorithm for policy evaluation, that come with a robust\nMDP interpretation. Indeed, our approach reformulates through an augmented\nstate space where each state is split into a worst-case substate and a\nbest-case substate, whose values are maximized by safe and risky policies\nrespectively. Finally, we derive distributional operators and DP algorithms\nsolving a new control task: How to distinguish safe from risky optimal actions\nin order to break ties in the space of optimal policies?",
    "descriptor": "",
    "authors": [
      "Mastane Achab",
      "Gergely Neu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.15430"
  },
  {
    "id": "arXiv:2112.15434",
    "title": "Adversarial Learning for Incentive Optimization in Mobile Payment  Marketing",
    "abstract": "Many payment platforms hold large-scale marketing campaigns, which allocate\nincentives to encourage users to pay through their applications. To maximize\nthe return on investment, incentive allocations are commonly solved in a\ntwo-stage procedure. After training a response estimation model to estimate the\nusers' mobile payment probabilities (MPP), a linear programming process is\napplied to obtain the optimal incentive allocation. However, the large amount\nof biased data in the training set, generated by the previous biased allocation\npolicy, causes a biased estimation. This bias deteriorates the performance of\nthe response model and misleads the linear programming process, dramatically\ndegrading the performance of the resulting allocation policy. To overcome this\nobstacle, we propose a bias correction adversarial network. Our method\nleverages the small set of unbiased data obtained under a full-randomized\nallocation policy to train an unbiased model and then uses it to reduce the\nbias with adversarial learning. Offline and online experimental results\ndemonstrate that our method outperforms state-of-the-art approaches and\nsignificantly improves the performance of the resulting allocation policy in a\nreal-world marketing campaign.",
    "descriptor": "\nComments: Accept by 30th ACM International Conference on Information & Knowledge Management(CIKM2021)\n",
    "authors": [
      "Xuanying Chen",
      "Zhining Liu",
      "Li Yu",
      "Sen Li",
      "Lihong Gu",
      "Xiaodong Zeng",
      "Yize Tan",
      "Jinjie Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15434"
  },
  {
    "id": "arXiv:2112.15439",
    "title": "Deep Facial Synthesis: A New Challenge",
    "abstract": "The goal of this paper is to conduct a comprehensive study on the facial\nsketch synthesis (FSS) problem. However, due to the high costs in obtaining\nhand-drawn sketch datasets, there lacks a complete benchmark for assessing the\ndevelopment of FSS algorithms over the last decade. As such, we first introduce\na high-quality dataset for FSS, named FS2K, which consists of 2,104\nimage-sketch pairs spanning three types of sketch styles, image backgrounds,\nlighting conditions, skin colors, and facial attributes. FS2K differs from\nprevious FSS datasets in difficulty, diversity, and scalability, and should\nthus facilitate the progress of FSS research. Second, we present the\nlargest-scale FSS study by investigating 139 classical methods, including 24\nhandcrafted feature based facial sketch synthesis approaches, 37 general\nneural-style transfer methods, 43 deep image-to-image translation methods, and\n35 image-to-sketch approaches. Besides, we elaborate comprehensive experiments\nfor existing 19 cutting-edge models. Third, we present a simple baseline for\nFSS, named FSGAN. With only two straightforward components, i.e., facial-aware\nmasking and style-vector expansion, FSGAN surpasses the performance of all\nprevious state-of-the-art models on the proposed FS2K dataset, by a large\nmargin. Finally, we conclude with lessons learned over the past years, and\npoint out several unsolved challenges. Our open-source code is available at\nhttps://github.com/DengPingFan/FSGAN.",
    "descriptor": "\nComments: First submission. FS2K and FSGAN have been released\n",
    "authors": [
      "Deng-Ping Fan",
      "Ziling Huang",
      "Peng Zheng",
      "Hong Liu",
      "Xuebin Qin",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15439"
  },
  {
    "id": "arXiv:2112.15442",
    "title": "Mythological Medical Machine Learning: Boosting the Performance of a  Deep Learning Medical Data Classifier Using Realistic Physiological Models",
    "abstract": "Objective: To determine if a realistic, but computationally efficient model\nof the electrocardiogram can be used to pre-train a deep neural network (DNN)\nwith a wide range of morphologies and abnormalities specific to a given\ncondition - T-wave Alternans (TWA) as a result of Post-Traumatic Stress\nDisorder, or PTSD - and significantly boost performance on a small database of\nrare individuals.\nApproach: Using a previously validated artificial ECG model, we generated\n180,000 artificial ECGs with or without significant TWA, with varying heart\nrate, breathing rate, TWA amplitude, and ECG morphology. A DNN, trained on over\n70,000 patients to classify 25 different rhythms, was modified the output layer\nto a binary class (TWA or no-TWA, or equivalently, PTSD or no-PTSD), and\ntransfer learning was performed on the artificial ECG. In a final transfer\nlearning step, the DNN was trained and cross-validated on ECG from 12 PTSD and\n24 controls for all combinations of using the three databases.\nMain results: The best performing approach (AUROC = 0.77, Accuracy = 0.72,\nF1-score = 0.64) was found by performing both transfer learning steps, using\nthe pre-trained arrhythmia DNN, the artificial data and the real PTSD-related\nECG data. Removing the artificial data from training led to the largest drop in\nperformance. Removing the arrhythmia data from training provided a modest, but\nsignificant, drop in performance. The final model showed no significant drop in\nperformance on the artificial data, indicating no overfitting.\nSignificance: In healthcare, it is common to only have a small collection of\nhigh-quality data and labels, or a larger database with much lower quality (and\nless relevant) labels. The paradigm presented here, involving model-based\nperformance boosting, provides a solution through transfer learning on a large\nrealistic artificial database, and a partially relevant real database.",
    "descriptor": "\nComments: Presented at the University of Chicago Data Science Institute Dec 6th 2021. See: this https URL and this https URL\n",
    "authors": [
      "Ismail Sadiq",
      "Erick A. Perez-Alday",
      "Amit J. Shah",
      "Ali Bahrami Rad",
      "Reza Sameni",
      "Gari D. Clifford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15442"
  },
  {
    "id": "arXiv:2112.15443",
    "title": "FPGA Based Accelerator for Neural Networks Computation with Flexible  Pipelining",
    "abstract": "FPGA is appropriate for fix-point neural networks computing due to high power\nefficiency and configurability. However, its design must be intensively refined\nto achieve high performance using limited hardware resources. We present an\nFPGA-based neural networks accelerator and its optimization framework, which\ncan achieve optimal efficiency for various CNN models and FPGA resources.\nTargeting high throughput, we adopt layer-wise pipeline architecture for higher\nDSP utilization. To get the optimal performance, a flexible algorithm to\nallocate balanced hardware resources to each layer is also proposed, supported\nby activation buffer design. Through our well-balanced implementation of four\nCNN models on ZC706, the DSP utilization and efficiency are over 90%. For VGG16\non ZC706, the proposed accelerator achieves the performance of 2.58x, 1.53x and\n1.35x better than the referenced non-pipeline architecture [1], pipeline\narchitecture [2] and [3], respectively.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Qingyang Yi",
      "Heming Sun",
      "Masahiro Fujita"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.15443"
  },
  {
    "id": "arXiv:2112.15444",
    "title": "GANISP: a GAN-assisted Importance SPlitting Probability Estimator",
    "abstract": "Designing manufacturing processes with high yield and strong reliability\nrelies on effective methods for rare event estimation. Genealogical importance\nsplitting reduces the variance of rare event probability estimators by\niteratively selecting and replicating realizations that are headed towards a\nrare event. The replication step is difficult when applied to deterministic\nsystems where the initial conditions of the offspring realizations need to be\nmodified. Typically, a random perturbation is applied to the offspring to\ndifferentiate their trajectory from the parent realization. However, this\nrandom perturbation strategy may be effective for some systems while failing\nfor others, preventing variance reduction in the probability estimate. This\nwork seeks to address this limitation using a generative model such as a\nGenerative Adversarial Network (GAN) to generate perturbations that are\nconsistent with the attractor of the dynamical system. The proposed\nGAN-assisted Importance SPlitting method (GANISP) improves the variance\nreduction for the system targeted. An implementation of the method is available\nin a companion repository (https://github.com/NREL/GANISP).",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Malik Hassanaly",
      "Andrew Glaws",
      "Ryan N. King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2112.15444"
  },
  {
    "id": "arXiv:2112.15445",
    "title": "Speedup deep learning models on GPU by taking advantage of efficient  unstructured pruning and bit-width reduction",
    "abstract": "This work is focused on the pruning of some convolutional neural networks\n(CNNs) and improving theirs efficiency on graphic processing units (GPU) by\nusing a direct sparse algorithm. The Nvidia deep neural network (cuDnn) library\nis the most effective implementations of deep learning (DL) algorithms for\nGPUs. GPUs are the most commonly used accelerators for deep learning\ncomputations. One of the most common techniques for improving the efficiency of\nCNN models is weight pruning and quantization. There are two main types of\npruning: structural and non-structural. The first enables much easier\nacceleration on many type of accelerators, but with this type it is difficult\nto achieve a sparsity level and accuracy as high as that obtained with the\nsecond type. Non-structural pruning with retraining can generate a weight\ntensors up to 90% or more of sparsity in some deep CNN models. In this article\nthe pruning algorithm is presented which makes it possible to achieve high\nsparsity levels without accuracy drop. In the next stage the linear and\nnon-linear quantization is adapted for further time and footprint reduction.\nThis paper is an extended of previously published paper concerning effective\npruning techniques and present real models pruned with high sparsities and\nreduced precision which can achieve better performance than the CuDnn library.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.06295\n",
    "authors": [
      "Marcin Pietro\u0144",
      "Dominik \u017burek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.15445"
  },
  {
    "id": "arXiv:2112.15446",
    "title": "Uniform-in-Phase-Space Data Selection with Iterative Normalizing Flows",
    "abstract": "Improvements in computational and experimental capabilities are rapidly\nincreasing the amount of scientific data that is routinely generated. In\napplications that are constrained by memory and computational intensity,\nexcessively large datasets may hinder scientific discovery, making data\nreduction a critical component of data-driven methods. Datasets are growing in\ntwo directions: the number of data points and their dimensionality. Whereas\ndata compression techniques are concerned with reducing dimensionality, the\nfocus here is on reducing the number of data points. A strategy is proposed to\nselect data points such that they uniformly span the phase-space of the data.\nThe algorithm proposed relies on estimating the probability map of the data and\nusing it to construct an acceptance probability. An iterative method is used to\naccurately estimate the probability of the rare data points when only a small\nsubset of the dataset is used to construct the probability map. Instead of\nbinning the phase-space to estimate the probability map, its functional form is\napproximated with a normalizing flow. Therefore, the method naturally extends\nto high-dimensional datasets. The proposed framework is demonstrated as a\nviable pathway to enable data-efficient machine learning when abundant data is\navailable. An implementation of the method is available in a companion\nrepository (https://github.com/NREL/Phase-space-sampling).",
    "descriptor": "\nComments: 23 pages, 18 figures, 6 tables\n",
    "authors": [
      "Malik Hassanaly",
      "Bruce A. Perry",
      "Michael E. Mueller",
      "Shashank Yellapantula"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.15446"
  },
  {
    "id": "arXiv:2112.15453",
    "title": "On Mathematics of Bubbles in Dynamical Systems",
    "abstract": "A new concept called biased derivative is proposed. It has a potential to\nbetter understand and model some aspects of dynamical systems associated with\ncreating bubbles.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Petr Klan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.15453"
  },
  {
    "id": "arXiv:2112.15454",
    "title": "Advanced Smart Drone Swarm Security Network by Using Strategic Alliance  for Blockchain Governance Game",
    "abstract": "This paper deals with the design of the secure network of the Advanced Smart\nDrone Swarm security network by using the Strategic Alliance for Blockchain\nGovernance Game (SABGG). The SABGG is the system model of the stochastic game\nto find best strategies towards preparation for preventing a network\nmalfunction by an attacker and the newly proposed adapts this innovative game\nmodel into the artificial drone swarm security. Analytically tractable\nsolutions enable to estimate the moment of safety modes and to deliver the\noptimal accountability of ally drones for preventing attacks. This research\nhelps for whom considers the advanced secure drone swarm architecture with the\nSABGG within a decentralized network.",
    "descriptor": "\nComments: This working paper is targeted to submit to an international journal in the area of security, blockchain and/or drones\n",
    "authors": [
      "Song-Kyoo Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.15454"
  },
  {
    "id": "arXiv:2112.15458",
    "title": "PiFeNet: Pillar-Feature Network for Real-Time 3D Pedestrian Detection  from Point Cloud",
    "abstract": "We present PiFeNet, an efficient and accurate real-time 3D detector for\npedestrian detection from point clouds. We address two challenges that 3D\nobject detection frameworks encounter when detecting pedestrians: low\nexpressiveness of pillar features and small occupation areas of pedestrians in\npoint clouds. Firstly, we introduce a stackable Pillar Aware Attention (PAA)\nmodule for enhanced pillar features extraction while suppressing noises in the\npoint clouds. By integrating multi-point-aware-pooling, point-wise,\nchannel-wise, and task-aware attention into a simple module, the representation\ncapabilities are boosted while requiring little additional computing resources.\nWe also present Mini-BiFPN, a small yet effective feature network that creates\nbidirectional information flow and multi-level cross-scale feature fusion to\nbetter integrate multi-resolution features. Our approach is ranked 1st in KITTI\npedestrian BEV and 3D leaderboards while running at 26 frames per second (FPS),\nand achieves state-of-the-art performance on Nuscenes detection benchmark.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Multimedia and Expo (ICME) 2022\n",
    "authors": [
      "Duy-Tho Le",
      "Hengcan Shi",
      "Hamid Rezatofighi",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15458"
  },
  {
    "id": "arXiv:2112.15459",
    "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
    "abstract": "We are making the case that empirical results from social psychology and\nsocial neuroscience along with the framework of dynamics can be of inspiration\nto the development of more intelligent artificial agents. We specifically argue\nthat the complex human cognitive architecture owes a large portion of its\nexpressive power to its ability to engage in social and cultural learning. In\nthe first section, we aim at demonstrating that social learning plays a key\nrole in the development of intelligence. We do so by discussing social and\ncultural learning theories and investigating the abilities that various animals\nhave at learning from others; we also explore findings from social neuroscience\nthat examine human brains during social interaction and learning. Then, we\ndiscuss three proposed lines of research that fall under the umbrella of Social\nNeuroAI and can contribute to developing socially intelligent embodied agents\nin complex environments. First, neuroscientific theories of cognitive\narchitecture, such as the global workspace theory and the attention schema\ntheory, can enhance biological plausibility and help us understand how we could\nbridge individual and social theories of intelligence. Second, intelligence\noccurs in time as opposed to over time, and this is naturally incorporated by\nthe powerful framework offered by dynamics. Third, social embodiment has been\ndemonstrated to provide social interactions between virtual agents and humans\nwith a more sophisticated array of communicative signals. To conclude, we\nprovide a new perspective on the field of multiagent robot systems, exploring\nhow it can advance by following the aforementioned three axes.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Samuele Bolotta",
      "Guillaume Dumas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15459"
  },
  {
    "id": "arXiv:2112.15462",
    "title": "Quaternary linear codes and related binary subfield codes",
    "abstract": "In this paper, we mainly study quaternary linear codes and their binary\nsubfield codes. First we obtain a general explicit relationship between\nquaternary linear codes and their binary subfield codes in terms of generator\nmatrices and defining sets. Second, we construct quaternary linear codes via\nsimplicial complexes and determine the weight distributions of these codes.\nThird, the weight distributions of the binary subfield codes of these\nquaternary codes are also computed by employing the general characterization.\nFurthermore, we present two infinite families of optimal linear codes with\nrespect to the Griesmer Bound, and a class of binary almost optimal codes with\nrespect to the Sphere Packing Bound. We also need to emphasize that we obtain\nat least 9 new quaternary linear codes.",
    "descriptor": "\nComments: 24 pages, to appear in IEEE TIT\n",
    "authors": [
      "Yansheng Wu",
      "Chengju Li",
      "Fu Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.15462"
  },
  {
    "id": "arXiv:2112.15466",
    "title": "Polynomial-Time Key Recovery Attack on the Lau-Tan Cryptosystem Based on  Gabidulin Codes",
    "abstract": "This paper presents a key recovery attack on the cryptosystem proposed by Lau\nand Tan in a talk at ACISP 2018. The Lau-Tan cryptosystem uses Gabidulin codes\nas the underlying decodable code. To hide the algebraic structure of Gabidulin\ncodes, the authors chose a matrix of column rank $n$ to mix with a generator\nmatrix of the secret Gabidulin code. The other part of the public key, however,\nreveals crucial information about the private key. Our analysis shows that the\nproblem of recovering the private key can be reduced to solving a multivariate\nlinear system, rather than solving a multivariate quadratic system as claimed\nby the authors. Apparently, this attack costs polynomial time, and therefore\ncompletely breaks the cryptosystem.",
    "descriptor": "",
    "authors": [
      "Wenshuo Guo",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.15466"
  },
  {
    "id": "arXiv:2112.15471",
    "title": "A Survey on Using Gaze Behaviour for Natural Language Processing",
    "abstract": "Gaze behaviour has been used as a way to gather cognitive information for a\nnumber of years. In this paper, we discuss the use of gaze behaviour in solving\ndifferent tasks in natural language processing (NLP) without having to record\nit at test time. This is because the collection of gaze behaviour is a costly\ntask, both in terms of time and money. Hence, in this paper, we focus on\nresearch done to alleviate the need for recording gaze behaviour at run time.\nWe also mention different eye tracking corpora in multiple languages, which are\ncurrently available and can be used in natural language processing. We conclude\nour paper by discussing applications in a domain - education - and how learning\ngaze behaviour can help in solving the tasks of complex word identification and\nautomatic essay grading.",
    "descriptor": "\nComments: Published at IJCAI-PRICAI 2020\n",
    "authors": [
      "Sandeep Mathias",
      "Diptesh Kanojia",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15471"
  },
  {
    "id": "arXiv:2112.15475",
    "title": "Shift-Equivariant Similarity-Preserving Hypervector Representations of  Sequences",
    "abstract": "Hyperdimensional Computing (HDC), also known as Vector-Symbolic Architectures\n(VSA), is a promising framework for the development of cognitive architectures\nand artificial intelligence systems, as well as for technical applications and\nemerging neuromorphic and nanoscale hardware. HDC/VSA operate with\nhypervectors, i.e., distributed vector representations of large fixed dimension\n(usually > 1000). One of the key ingredients of HDC/VSA are the methods for\nencoding data of various types (from numeric scalars and vectors to graphs)\ninto hypervectors. In this paper, we propose an approach for the formation of\nhypervectors of sequences that provides both an equivariance with respect to\nthe shift of sequences and preserves the similarity of sequences with identical\nelements at nearby positions. Our methods represent the sequence elements by\ncompositional hypervectors and exploit permutations of hypervectors for\nrepresenting the order of sequence elements. We experimentally explored the\nproposed representations using a diverse set of tasks with data in the form of\nsymbolic strings. Although our approach is feature-free as it forms the\nhypervector of a sequence from the hypervectors of its symbols at their\npositions, it demonstrated the performance on a par with the methods that apply\nvarious features, such as subsequences. The proposed techniques were designed\nfor the HDC/VSA model known as Sparse Binary Distributed Representations.\nHowever, they can be adapted to hypervectors in formats of other HDC/VSA\nmodels, as well as for representing sequences of types other than symbolic\nstrings.",
    "descriptor": "",
    "authors": [
      "Dmitri A. Rachkovskij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.15475"
  },
  {
    "id": "arXiv:2112.15479",
    "title": "BTS: An Accelerator for Bootstrappable Fully Homomorphic Encryption",
    "abstract": "Homomorphic encryption (HE) enables secure offloading of computation to the\ncloud by providing computation on encrypted data (ciphertexts). HE is based on\nnoisy encryption schemes such that noise accumulates as we apply more\ncomputation to the data. The limited number of operations applicable to the\ndata prevents practical applications from exploiting HE. Bootstrapping enables\nan unlimited number of operations or fully HE (FHE) by refreshing the\nciphertext. Unfortunately, bootstrapping requires a significant amount of\nadditional computation and memory bandwidth. Prior works have proposed hardware\naccelerators for computation primitives of FHE. However, to the best of our\nknowledge, this is the first to propose a hardware FHE accelerator tailored to\nsupport bootstrapping efficiently.\nIn particular, we propose BTS -- Bootstrappable, Technology-driven, Secure\naccelerator architecture for FHE. We identify the challenges of supporting\nbootstrapping in the accelerator and analyze the off-chip memory bandwidth and\ncomputation required. In particular, given the limitations of modern memory\ntechnology, we identify the HE parameter sets that are efficient for FHE\nacceleration. Based on the insights from our analysis, we propose BTS that\neffectively exploits parallelism innate in HE operations by arranging a massive\nnumber of processing elements in a grid. We present the design and\nmicroarchitecture of BTS, including the network-on-chip that exploits the\ndeterministic communication pattern. BTS shows 5,556$\\times$ and 1,306$\\times$\nimproved execution time on ResNet-20 and logistic regression over CPU, using\n373.6mm$^2$ chip area and up to 133.8W of power.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Sangpyo Kim",
      "Jongmin Kim",
      "Michael Jaemin Kim",
      "Wonkyung Jung",
      "Minsoo Rhu",
      "John Kim",
      "Jung Ho Ahn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.15479"
  },
  {
    "id": "arXiv:2112.15483",
    "title": "Cloud Removal from Satellite Images",
    "abstract": "In this report, we have analyzed available cloud detection technique using\nsentinel hub. We have also implemented spatial attention generative adversarial\nnetwork and improved quality of generated image compared to previous solution\n[7].",
    "descriptor": "",
    "authors": [
      "Rutvik Chauhan",
      "Antarpuneet Singh",
      "Sujoy Saha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15483"
  },
  {
    "id": "arXiv:2112.15484",
    "title": "A Research Agenda for Artificial Intelligence in the Field of Flexible  Production Systems",
    "abstract": "Production companies face problems when it comes to quickly adapting their\nproduction control to fluctuating demands or changing requirements. Control\napproaches aiming to encapsulate production functions in the sense of services\nhave shown to be promising in order to increase flexibility of Cyber-Physical\nProduction Systems. But an existing challenge of such approaches is finding\nproduction plans based on provided functionalities for a set of requirements,\nespecially when there is no direct (i.e., syntactic) match between demanded and\nprovided functions. In such cases it can become complicated to find those\nprovided functions that can be arranged into a plan satisfying the demand.\nWhile there is a variety of different approaches to production planning,\nflexible production poses specific requirements that are not covered by\nexisting research. In this contribution, we first capture these requirements\nfor flexible production environments. Afterwards, an overview of current\nArtificial Intelligence approaches that can be utilized in order to overcome\nthe aforementioned challenges is given. Approaches from both symbolic AI\nplanning as well as approaches based on Machine Learning are discussed and\neventually compared against the requirements. Based on this comparison, a\nresearch agenda is derived.",
    "descriptor": "",
    "authors": [
      "Aljosha K\u00f6cher",
      "Ren\u00e9 Heesch",
      "Niklas Widulle",
      "Anna Nordhausen",
      "Julian Putzke",
      "Alexander Windmann",
      "Sven Vagt",
      "Oliver Niggemann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15484"
  },
  {
    "id": "arXiv:2112.15485",
    "title": "REST API Fuzzing by Coverage Level Guided Blackbox Testing",
    "abstract": "With the growth of web applications, REST APIs have become the primary\ncommunication method between services. In order to ensure system reliability\nand security, software quality can be assured by effective testing methods.\nBlack box fuzz testing is one of the effective methods to perform tests on a\nlarge scale. However, conventional black box fuzz testing generates random data\nwithout judging the quality of the input.\nWe implement a black box fuzz testing method for REST APIs. It resolves the\nissues of blind mutations without knowing the effectiveness by Test Coverage\nLevel feedback. We also enhance the mutation strategies by reducing the testing\ncomplexity for REST APIs, generating more appropriate test cases to cover\npossible paths.\nWe evaluate our method by testing two large open-source projects and 89 bugs\nare reported and confirmed. In addition, we find 351 bugs from 64 remote API\nservices in APIs.guru.\nThe work is in https://github.com/iasthc/hsuan-fuzz.",
    "descriptor": "",
    "authors": [
      "Chung-Hsuan Tsai",
      "Shi-Chun Tsai",
      "Shih-Kun Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.15485"
  },
  {
    "id": "arXiv:2112.15486",
    "title": "Efficient and Reliable Overlay Networks for Decentralized Federated  Learning",
    "abstract": "We propose near-optimal overlay networks based on $d$-regular expander graphs\nto accelerate decentralized federated learning (DFL) and improve its\ngeneralization. In DFL a massive number of clients are connected by an overlay\nnetwork, and they solve machine learning problems collaboratively without\nsharing raw data. Our overlay network design integrates spectral graph theory\nand the theoretical convergence and generalization bounds for DFL. As such, our\nproposed overlay networks accelerate convergence, improve generalization, and\nenhance robustness to clients failures in DFL with theoretical guarantees.\nAlso, we present an efficient algorithm to convert a given graph to a practical\noverlay network and maintaining the network topology after potential client\nfailures. We numerically verify the advantages of DFL with our proposed\nnetworks on various benchmark tasks, ranging from image classification to\nlanguage modeling using hundreds of clients.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Yifan Hua",
      "Kevin Miller",
      "Andrea L. Bertozzi",
      "Chen Qian",
      "Bao Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15486"
  },
  {
    "id": "arXiv:2112.15488",
    "title": "Multi-relation Graph Summarization",
    "abstract": "Graph summarization is beneficial in a wide range of applications, such as\nvisualization, interactive and exploratory analysis, approximate query\nprocessing, reducing the on-disk storage footprint, and graph processing in\nmodern hardware. However, the bulk of the literature on graph summarization\nsurprisingly overlooks the possibility of having edges of different types. In\nthis paper, we study the novel problem of producing summaries of multi-relation\nnetworks, i.e., graphs where multiple edges of different types may exist\nbetween any pair of nodes. Multi-relation graphs are an expressive model of\nreal-world activities, in which a relation can be a topic in social networks,\nan interaction type in genetic networks, or a snapshot in temporal graphs. The\nfirst approach that we consider for multi-relation graph summarization is a\ntwo-step method based on summarizing each relation in isolation, and then\naggregating the resulting summaries in some clever way to produce a final\nunique summary. In doing this, as a side contribution, we provide the first\npolynomial-time approximation algorithm based on the k-Median clustering for\nthe classic problem of lossless single-relation graph summarization. Then, we\ndemonstrate the shortcomings of these two-step methods, and propose holistic\napproaches, both approximate and heuristic algorithms, to compute a summary\ndirectly for multi-relation graphs. In particular, we prove that the\napproximation bound of k-Median clustering for the single relation solution can\nbe maintained in a multi-relation graph with proper aggregation operation over\nadjacency matrices corresponding to its multiple relations. Experimental\nresults and case studies (on co-authorship networks and brain networks)\nvalidate the effectiveness and efficiency of the proposed algorithms.",
    "descriptor": "\nComments: To appear, ACM TKDD\n",
    "authors": [
      "Xiangyu Ke",
      "Arijit Khan",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.15488"
  },
  {
    "id": "arXiv:2112.15489",
    "title": "MRT-based Joint Unicast and Multigroup Multicast Transmission in Massive  MIMO Systems",
    "abstract": "We study joint unicast and multigroup multicast transmission in single-cell\nmassive multiple-input-multiple-output (MIMO) systems, under maximum ratio\ntransmission. For the unicast transmission, the objective is to maximize the\nweighted sum spectral efficiency (SE) of the unicast user terminals (UTs) and\nfor the multicast transmission the objective is to maximize the minimum SE of\nthe multicast UTs. These two problems are coupled to each other in a\nconflicting manner, due to their shared power resource and interference. To\naddress this, we formulate a multiobjective optimization problem (MOOP). We\nderive the Pareto boundary of the MOOP analytically and determine the values of\nthe system parameters to achieve any desired Pareto optimal point. Moreover, we\nprove that the Pareto region is convex, hence the system should serve the\nunicast and multicast UTs at the same time-frequency resource.",
    "descriptor": "\nComments: Published at 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5 pages, 1 figure. arXiv admin note: substantial text overlap with arXiv:1911.08165\n",
    "authors": [
      "Meysam Sadeghi",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson",
      "Chau Yuen",
      "Thomas L. Marzetta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15489"
  },
  {
    "id": "arXiv:2112.15490",
    "title": "Centralized and Distributed Power Allocation for Max-Min Fairness in  Cell-Free Massive MIMO",
    "abstract": "Cell-free Massive MIMO systems consist of a large number of geographically\ndistributed access points (APs) that serve users by coherent joint\ntransmission. Downlink power allocation is important in these systems, to\ndetermine which APs should transmit to which users and with what power. If the\nsystem is implemented correctly, it can deliver a more uniform user performance\nthan conventional cellular networks. To this end, previous works have shown how\nto perform system-wide max-min fairness power allocation when using maximum\nratio precoding. In this paper, we first generalize this method to arbitrary\nprecoding, and then train a neural network to perform approximately the same\npower allocation but with reduced computational complexity. Finally, we train\none neural network per AP to mimic system-wide max-min fairness power\nallocation, but using only local information. By learning the structure of the\nlocal propagation environment, this method outperforms the state-of-the-art\ndistributed power allocation method from the Cell-free Massive MIMO literature.",
    "descriptor": "\nComments: Published at 2019 Asilomar Conference on Signals, Systems, and Computers, 5 pages, 3 figures\n",
    "authors": [
      "Sucharita Chakraborty",
      "Emil Bj\u00f6rnson",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15490"
  },
  {
    "id": "arXiv:2112.15491",
    "title": "Semantics-Recovering Decompilation through Neural Machine Translation",
    "abstract": "Decompilation transforms low-level program languages (PL) (e.g., binary code)\ninto high-level PLs (e.g., C/C++). It has been widely used when analysts\nperform security analysis on software (systems) whose source code is\nunavailable, such as vulnerability search and malware analysis. However,\ncurrent decompilation tools usually need lots of experts' efforts, even for\nyears, to generate the rules for decompilation, which also requires long-term\nmaintenance as the syntax of high-level PL or low-level PL changes. Also, an\nideal decompiler should concisely generate high-level PL with similar\nfunctionality to the source low-level PL and semantic information (e.g.,\nmeaningful variable names), just like human-written code. Unfortunately,\nexisting manually-defined rule-based decompilation techniques only functionally\nrestore the low-level PL to a similar high-level PL and are still powerless to\nrecover semantic information. In this paper, we propose a novel neural\ndecompilation approach to translate low-level PL into accurate and\nuser-friendly high-level PL, effectively improving its readability and\nunderstandability. Furthermore, we implement the proposed approaches called\nSEAM. Evaluations on four real-world applications show that SEAM has an average\naccuracy of 94.41%, which is much better than prior neural machine translation\n(NMT) models. Finally, we evaluate the effectiveness of semantic information\nrecovery through a questionnaire survey, and the average accuracy is 92.64%,\nwhich is comparable or superior to the state-of-the-art compilers.",
    "descriptor": "",
    "authors": [
      "Ruigang Liang",
      "Ying Cao",
      "Peiwei Hu",
      "Jinwen He",
      "Kai Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.15491"
  },
  {
    "id": "arXiv:2112.15492",
    "title": "Human and Machine Type Communications can Coexist in Uplink Massive MIMO  Systems",
    "abstract": "Future cellular networks are expected to support new communication paradigms\nsuch as machine-type communication (MTC) services along with human-type\ncommunication (HTC) services. This requires base stations to serve a large\nnumber of devices in relatively short channel coherence intervals which renders\nallocation of orthogonal pilot sequence per-device approaches impractical.\nFurthermore, the stringent power constraints, place-and-play type connectivity\nand various data rate requirements of MTC devices make it impossible for the\ntraditional cellular architecture to accommodate MTC and HTC services together.\nMassive multiple-input-multiple-output (MaMIMO) technology has the potential to\nallow the coexistence of HTC and MTC services, thanks to its inherent spatial\nmultiplexing properties and low transmission power requirements. In this work,\nwe investigate the performance of a single cell under a shared physical channel\nassumption for MTC and HTC services and propose a novel scheme for sharing the\ntime-frequency resources. The analysis reveals that MaMIMO can significantly\nenhance the performance of such a setup and allow the inclusion of MTC services\ninto the cellular networks without requiring additional resources.",
    "descriptor": "\nComments: Published at the 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5 pages, 4 figures. arXiv admin note: substantial text overlap with arXiv:1808.09177\n",
    "authors": [
      "Kamil Senel",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15492"
  },
  {
    "id": "arXiv:2112.15493",
    "title": "NOMA Versus Massive MIMO in Rayleigh Fading",
    "abstract": "This paper compares the sum rates and rate regions achieved by power-domain\nNOMA (non-orthogonal multiple access) and standard massive MIMO (multiple-input\nmultiple-output) techniques. We prove analytically that massive MIMO always\noutperforms NOMA in i.i.d.~Rayleigh fading channels, if a sufficient number of\nantennas are used at the base stations. The simulation results show that the\ncrossing point occurs already when having 20-30 antennas, which is far less\nthan what is considered for the next generation cellular networks.",
    "descriptor": "\nComments: Published at the 2019 IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), 5 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:1809.07072\n",
    "authors": [
      "Kamil Senel",
      "Hei Victor Cheng",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15493"
  },
  {
    "id": "arXiv:2112.15498",
    "title": "State Selection Algorithms and Their Impact on The Performance of  Stateful Network Protocol Fuzzing",
    "abstract": "The statefulness property of network protocol implementations poses a unique\nchallenge for testing and verification techniques, including Fuzzing. Stateful\nfuzzers tackle this challenge by leveraging state models to partition the state\nspace and assist the test generation process. Since not all states are equally\nimportant and fuzzing campaigns have time limits, fuzzers need effective state\nselection algorithms to prioritize progressive states over others. Several\nstate selection algorithms have been proposed but they were implemented and\nevaluated separately on different platforms, making it hard to achieve\nconclusive findings. In this work, we evaluate an extensive set of state\nselection algorithms on the same fuzzing platform that is AFLNet, a\nstate-of-the-art fuzzer for network servers. The algorithm set includes\nexisting ones supported by AFLNet and our novel and principled algorithm called\nAFLNetLegion. The experimental results on the ProFuzzBench benchmark show that\n(i) the existing state selection algorithms of AFLNet achieve very similar code\ncoverage, (ii) AFLNetLegion clearly outperforms these algorithms in selected\ncase studies, but (iii) the overall improvement appears insignificant. These\nare unexpected yet interesting findings. We identify problems and share\ninsights that could open opportunities for future research on this topic.",
    "descriptor": "\nComments: 10 pages, 8 figures, coloured, conference\n",
    "authors": [
      "Dongge Liu",
      "Van-Thuan Pham",
      "Gidon Ernst",
      "Toby Murray",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15498"
  },
  {
    "id": "arXiv:2112.15504",
    "title": "A unified framework for the regularization of final value  time-fractional diffusion equation",
    "abstract": "This paper focuses on the regularization of backward time-fractional\ndiffusion problem on unbounded domain. This problem is well-known to be\nill-posed, whence the need of a regularization method in order to recover\nstable approximate solution. For the problem under consideration, we present a\nunified framework of regularization which covers some techniques such as\nFourier regularization [19], mollification [12] and approximate-inverse [7]. We\ninvestigate a regularization technique with two major advantages: the\nsimplicity of computation of the regularized solution and the avoid of\ntruncation of high frequency components (so as to avoid undesirable oscillation\non the resulting approximate-solution). Under classical Sobolev-smoothness\nconditions, we derive order-optimal error estimates between the approximate\nsolution and the exact solution in the case where both the data and the model\nare only approximately known. In addition, an order-optimal a-posteriori\nparameter choice rule based on the Morozov principle is given. Finally, via\nsome numerical experiments in two-dimensional space, we illustrate the\nefficiency of our regularization approach and we numerically confirm the\ntheoretical convergence rates established in the paper.",
    "descriptor": "",
    "authors": [
      "Walter Simo Tao Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.15504"
  },
  {
    "id": "arXiv:2112.15505",
    "title": "Structural Model and Mathematical Foundation of Information Space",
    "abstract": "In today's era, there is no doubt about the importance of information.\nHowever, people still have different opinions on information, and the research\non information measurement is also inconclusive. Based on the researches of\npredecessors, this paper summarizes the important progress and main\nshortcomings in understanding and measurement of information, discusses the\nbasic problems such as the essential connotation of objectivity of information,\nputs forward the mathematical model of information and the basic properties of\ninformation, and deduces and establishes the universality, delicacy,\npersistence, richness, inclusiveness, delay, etc.. The structural model and\nmathematical basic theoretical framework of information space are formed. The\nmotion law of information flow in information space is systematically and\ncomprehensively analyzed, and the information dynamics for complex information\nsystem is preliminarily discussed.",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Jianfeng Xu",
      "Zhenyu Liu",
      "Tao Zheng",
      "Shuliang Wamg",
      "Yingfei Wang",
      "Yashi Wang",
      "Yongjie Qiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.15505"
  },
  {
    "id": "arXiv:2112.15506",
    "title": "Coupled Tank Non-linear System; Modeling and Level Control using PID and  Fuzzy Logic Techniques",
    "abstract": "Liquid level control is very important in industrial field, where the liquid\nlevel is required, and to prevent overflows. The coupled-tank is a common\nsystem in industrial control processes. The system consists of two tanks\nconnected together and the liquid flows between them. Tanks contain an inlet\nand outlet for each tank. The main principle of controlling this system is to\nmaintain a constant level of liquid in both tanks when there are an inflow and\noutflow of liquid in each tank. To control liquid level in the coupled tank\nsystem, the mathematical model of the system had been derived and evaluated as\na form of linear model. The mathematical model of coupled tank was developed to\napply to both conventional and fuzzy control systems where the dynamic behavior\nof the system was considered. When the system had been designed the\ncorresponding model was implemented in simulation by using Matlab and Simulink\ntools.",
    "descriptor": "",
    "authors": [
      "Akram Muntaser",
      "Nagi Buaossa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2112.15506"
  },
  {
    "id": "arXiv:2112.15509",
    "title": "Scene-Adaptive Attention Network for Crowd Counting",
    "abstract": "In recent years, significant progress has been made on the research of crowd\ncounting. However, as the challenging scale variations and complex scenes\nexisted in crowds, neither traditional convolution networks nor recent\nTransformer architectures with fixed-size attention could handle the task well.\nTo address this problem, this paper proposes a scene-adaptive attention\nnetwork, termed SAANet. First of all, we design a deformable attention in-built\nTransformer backbone, which learns adaptive feature representations with\ndeformable sampling locations and dynamic attention weights. Then we propose\nthe multi-level feature fusion and count-attentive feature enhancement modules\nfurther, to strengthen feature representation under the global image context.\nThe learned representations could attend to the foreground and are adaptive to\ndifferent scales of crowds. We conduct extensive experiments on four\nchallenging crowd counting benchmarks, demonstrating that our method achieves\nstate-of-the-art performance. Especially, our method currently ranks No.1 on\nthe public leaderboard of the NWPU-Crowd benchmark. We hope our method could be\na strong baseline to support future research in crowd counting. The source code\nwill be released to the community.",
    "descriptor": "",
    "authors": [
      "Xing Wei",
      "Yuanrui Kang",
      "Jihao Yang",
      "Yunfeng Qiu",
      "Dahu Shi",
      "Wenming Tan",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15509"
  },
  {
    "id": "arXiv:2112.15521",
    "title": "Inferring perceptual decision making parameters from behavior in  production and reproduction tasks",
    "abstract": "Bayesian models of behavior have provided computational level explanations in\na range of psychophysical tasks. One fundamental experimental paradigm is the\nproduction or reproduction task, in which subjects are instructed to generate\nan action that either reproduces a previously sensed stimulus magnitude or\nachieves a target response. This type of task therefore distinguishes itself\nfrom other psychophysical tasks in that the responses are on a continuum and\neffort plays an important role with increasing response magnitude. Based on\nBayesian decision theory we present an inference method to recover perceptual\nuncertainty, response variability, and the cost function underlying human\nresponses. Crucially, the cost function is parameterized such that effort is\nexplicitly included. We present a hybrid inference method employing MCMC\nsampling utilizing appropriate proposal distributions and an inner loop\nutilizing amortized inference with a neural network that approximates the mode\nof the optimal response distribution. We show how this model can be utilized to\navoid unidentifiability of experimental designs and that parameters can be\nrecovered through validation on synthetic and application to experimental data.\nOur approach will enable behavioral scientists to perform Bayesian inference of\ndecision making parameters in production and reproduction tasks.",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Nils Neup\u00e4rtl",
      "Constantin A. Rothkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.15521"
  },
  {
    "id": "arXiv:2112.15522",
    "title": "Machine Learning in Congestion Control: A Survey on Selected Algorithms  and a New Roadmap to their Implementation",
    "abstract": "With the emergence of new technologies, computer networks are becoming more\nstructurally complex, diverse and heterogenous. The increasing discrepancy\n(among the interconnected networks) in data rates, delays, packet loss, and\ntransmission scenarios, influence significantly the dynamics of congestion\ncontrol (CC) parametrization. In contrast to the traditional endto-end CC\nalgorithms that rely on strict rules, new approaches aim to involve machine\nlearning in order to continuously adapt the CC to real-time network\nrequirements. However, due to the high computational complexity and memory\nconsumption, the feasibility of these schemes may still be questioned. This\npaper surveys selected machine-learning based approaches to CC and proposes a\nroadmap to their implementation in computer systems, by using dataflow\ncomputing and Gallium Arsenide (GaAs) chips.",
    "descriptor": "",
    "authors": [
      "Zhilbert Tafa",
      "Veljko Milutinovic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.15522"
  },
  {
    "id": "arXiv:2112.15524",
    "title": "Structural Liveness of Immediate Observation Petri Nets",
    "abstract": "We show that the structural liveness problem for immediate observation nets\n(introduced by Esparza et al., 2019) is PSPACE-complete.",
    "descriptor": "",
    "authors": [
      "Jiri Valusek",
      "Petr Jancar"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.15524"
  },
  {
    "id": "arXiv:2112.15530",
    "title": "Scalable Deep Graph Clustering with Random-walk based Self-supervised  Learning",
    "abstract": "Web-based interactions can be frequently represented by an attributed graph,\nand node clustering in such graphs has received much attention lately. Multiple\nefforts have successfully applied Graph Convolutional Networks (GCN), though\nwith some limits on accuracy as GCNs have been shown to suffer from\nover-smoothing issues. Though other methods (particularly those based on\nLaplacian Smoothing) have reported better accuracy, a fundamental limitation of\nall the work is a lack of scalability. This paper addresses this open problem\nby relating the Laplacian smoothing to the Generalized PageRank and applying a\nrandom-walk based algorithm as a scalable graph filter. This forms the basis\nfor our scalable deep clustering algorithm, RwSL, where through a\nself-supervised mini-batch training mechanism, we simultaneously optimize a\ndeep neural network for sample-cluster assignment distribution and an\nautoencoder for a clustering-oriented embedding. Using 6 real-world datasets\nand 6 clustering metrics, we show that RwSL achieved improved results over\nseveral recent baselines. Most notably, we show that RwSL, unlike all other\ndeep clustering frameworks, can continue to scale beyond graphs with more than\none million nodes, i.e., handle web-scale. We also demonstrate how RwSL could\nperform node clustering on a graph with 1.8 billion edges using only a single\nGPU.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Dong Li",
      "Ruoming Jin",
      "Gagan Agrawal",
      "Rajiv Ramnath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.15530"
  },
  {
    "id": "arXiv:2112.15538",
    "title": "Machine learning based disease diagnosis: A comprehensive review",
    "abstract": "Globally, there is a substantial unmet need to diagnose various diseases\neffectively. The complexity of the different disease mechanisms and underlying\nsymptoms of the patient population presents massive challenges to developing\nthe early diagnosis tool and effective treatment. Machine Learning (ML), an\narea of Artificial Intelligence (AI), enables researchers, physicians, and\npatients to solve some of these issues. Based on relevant research, this review\nexplains how Machine Learning (ML) and Deep Learning (DL) are being used to\nhelp in the early identification of numerous diseases. To begin, a bibliometric\nstudy of the publication is given using data from the Scopus and Web of Science\n(WOS) databases. The bibliometric study of 1216 publications was undertaken to\ndetermine the most prolific authors, nations, organizations, and most cited\narticles. The review then summarizes the most recent trends and approaches in\nMachine Learning-based Disease Diagnosis (MLBDD), considering the following\nfactors: algorithm, disease types, data type, application, and evaluation\nmetrics. Finally, the paper highlights key results and provides insight into\nfuture trends and opportunities in the MLBDD area.",
    "descriptor": "",
    "authors": [
      "Md Manjurul Ahsan",
      "Zahed Siddique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15538"
  },
  {
    "id": "arXiv:2112.15541",
    "title": "on the effectiveness of generative adversarial network on anomaly  detection",
    "abstract": "Identifying anomalies refers to detecting samples that do not resemble the\ntraining data distribution. Many generative models have been used to find\nanomalies, and among them, generative adversarial network (GAN)-based\napproaches are currently very popular. GANs mainly rely on the rich contextual\ninformation of these models to identify the actual training distribution.\nFollowing this analogy, we suggested a new unsupervised model based on GANs --a\ncombination of an autoencoder and a GAN. Further, a new scoring function was\nintroduced to target anomalies where a linear combination of the internal\nrepresentation of the discriminator and the generator's visual representation,\nplus the encoded representation of the autoencoder, come together to define the\nproposed anomaly score. The model was further evaluated on benchmark datasets\nsuch as SVHN, CIFAR10, and MNIST, as well as a public medical dataset of\nleukemia images. In all the experiments, our model outperformed its existing\ncounterparts while slightly improving the inference time.",
    "descriptor": "\nComments: This paper is an improved version of an existing paper published by the same authors in ICANN2020\n",
    "authors": [
      "Laya Rafiee Sevyeri",
      "Thomas Fevens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15541"
  },
  {
    "id": "arXiv:2112.15544",
    "title": "OWLOOP: A Modular API to Describe OWL Axioms in OOP Objects Hierarchies",
    "abstract": "OWLOOP is an Application Programming Interface (API) for using the Ontology\nWeb Language (OWL) by the means of Object-Oriented Programming (OOP). It is\ncommon to design software architectures using the OOP paradigm for increasing\ntheir modularity. If the components of an architecture also exploit OWL\nontologies for knowledge representation and reasoning, they would require to be\ninterfaced with OWL axioms. Since OWL does not adhere to the OOP paradigm, such\nan interface often leads to boilerplate code affecting modularity, and OWLOOP\nis designed to address this issue as well as the associated computational\naspects. We present an extension of the OWL-API to provide a general-purpose\ninterface between OWL axioms subject to reasoning and modular OOP objects\nhierarchies.",
    "descriptor": "\nComments: This version of the manuscript has been published on the SoftwareX Elsevier journal in January 2022. The manuscript is made of 21 pages, which include 3 tables, 6 figures, and 4 listings\n",
    "authors": [
      "Luca Buoncompagni",
      "Syed Yusha Kareem",
      "Fulvio Mastrogiovanni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.15544"
  },
  {
    "id": "arXiv:2112.15545",
    "title": "Training and Generating Neural Networks in Compressed Weight Space",
    "abstract": "The inputs and/or outputs of some neural nets are weight matrices of other\nneural nets. Indirect encodings or end-to-end compression of weight matrices\ncould help to scale such approaches. Our goal is to open a discussion on this\ntopic, starting with recurrent neural networks for character-level language\nmodelling whose weight matrices are encoded by the discrete cosine transform.\nOur fast weight version thereof uses a recurrent neural network to parameterise\nthe compressed weights. We present experimental results on the enwik8 dataset.",
    "descriptor": "\nComments: Presented at ICLR 2021 Workshop on Neural Compression, this https URL\n",
    "authors": [
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15545"
  },
  {
    "id": "arXiv:2112.15547",
    "title": "A Markov Decision Process Framework for Efficient and Implementable  Contact Tracing and Isolation",
    "abstract": "Efficient contact tracing and isolation is an effective strategy to control\nepidemics. It was used effectively during the Ebola epidemic and successfully\nimplemented in several parts of the world during the ongoing COVID-19 pandemic.\nAn important consideration while implementing manual contact tracing is the\nnumber of contact tracers available -- the number of such individuals is\nlimited for socioeconomic reasons. In this paper, we present a Markov Decision\nProcess (MDP) framework to formulate the problem of efficient contact tracing\nthat reduces the size of the outbreak while using a limited number of contact\ntracers. We formulate each step of the MDP as a combinatorial problem,\nMinExposed. We demonstrate that MinExposed is NP-Hard, so we develop an\nLP-based approximation algorithm. Though this algorithm directly solves\nMinExposed, it is often impractical in the real world due to information\nconstraints. To this end, we develop a greedy approach based on insights from\nthe analysis of the previous algorithm, which we show is more interpretable. A\nkey feature of the greedy algorithm is that it does not need complete\ninformation of the underlying social contact network. This makes the heuristic\nimplementable in practice and is an important consideration. Finally, we carry\nout experiments on simulations of the MDP run on real-world networks, and show\nhow the algorithms can help in bending the epidemic curve while limiting the\nnumber of isolated individuals. Our experimental results demonstrate that the\ngreedy algorithm and its variants are especially effective, robust, and\npractical in a variety of realistic scenarios, such as when the contact graph\nand specific transmission probabilities are not known. All code can be found in\nour GitHub repository: https://github.com/gzli929/ContactTracing.",
    "descriptor": "\nComments: 23 pages, 10 figures, to be published in AAMAS-22 as a 2 page extended abstract\n",
    "authors": [
      "George Li",
      "Arash Haddadan",
      "Ann Li",
      "Madhav Marathe",
      "Aravind Srinivasan",
      "Anil Vullikanti",
      "Zeyu Zhao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.15547"
  },
  {
    "id": "arXiv:2112.15550",
    "title": "Improving Baselines in the Wild",
    "abstract": "We share our experience with the recently released WILDS benchmark, a\ncollection of ten datasets dedicated to developing models and training\nstrategies which are robust to domain shifts. Several experiments yield a\ncouple of critical observations which we believe are of general interest for\nany future work on WILDS. Our study focuses on two datasets: iWildCam and FMoW.\nWe show that (1) Conducting separate cross-validation for each evaluation\nmetric is crucial for both datasets, (2) A weak correlation between validation\nand test performance might make model development difficult for iWildCam, (3)\nMinor changes in the training of hyper-parameters improve the baseline by a\nrelatively large margin (mainly on FMoW), (4) There is a strong correlation\nbetween certain domains and certain target labels (mainly on iWildCam). To the\nbest of our knowledge, no prior work on these datasets has reported these\nobservations despite their obvious importance. Our code is public.",
    "descriptor": "\nComments: Presented at NeurIPS 2021 Workshop on Distribution Shifts, this https URL\n",
    "authors": [
      "Kazuki Irie",
      "Imanol Schlag",
      "R\u00f3bert Csord\u00e1s",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15550"
  },
  {
    "id": "arXiv:2112.15553",
    "title": "Non-Linear Age of Information: An Energy Efficient Receiver-Centric  Approach",
    "abstract": "The age of information (AoI) performance metric for point-to-point wireless\ncommunication systems is analytically studied under Rician-faded channels and\nwhen the receiver is equipped with multiple antennas. The general scenario of a\nnon-linear AoI function is considered, which includes the conventional linear\nAoI as a special case. The stop-and-wait transmission policy is adopted, where\nthe source node samples and then transmits new data only upon the successful\nreception of previous data. This approach can serve as a performance benchmark\nfor any queuing system used in practice. New analytical and closed-form\nexpressions are derived with respect to the average AoI and average peak AoI\nfor the considered system configuration. We particularly focus on the energy\nefficiency of the said mode of operation, whereas some useful engineering\ninsights are provided.",
    "descriptor": "",
    "authors": [
      "Nikolaos I. Miridakis",
      "Theodoros A. Tsiftsis",
      "Guanghua Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.15553"
  },
  {
    "id": "arXiv:2112.15555",
    "title": "An Unsupervised Domain Adaptation Model based on Dual-module Adversarial  Training",
    "abstract": "In this paper, we propose a dual-module network architecture that employs a\ndomain discriminative feature module to encourage the domain invariant feature\nmodule to learn more domain invariant features. The proposed architecture can\nbe applied to any model that utilizes domain invariant features for\nunsupervised domain adaptation to improve its ability to extract domain\ninvariant features. We conduct experiments with the Domain-Adversarial Training\nof Neural Networks (DANN) model as a representative algorithm. In the training\nprocess, we supply the same input to the two modules and then extract their\nfeature distribution and prediction results respectively. We propose a\ndiscrepancy loss to find the discrepancy of the prediction results and the\nfeature distribution between the two modules. Through the adversarial training\nby maximizing the loss of their feature distribution and minimizing the\ndiscrepancy of their prediction results, the two modules are encouraged to\nlearn more domain discriminative and domain invariant features respectively.\nExtensive comparative evaluations are conducted and the proposed approach\noutperforms the state-of-the-art in most unsupervised domain adaptation tasks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.00610\n",
    "authors": [
      "Yiju Yang",
      "Tianxiao Zhang",
      "Guanyu Li",
      "Taejoon Kim",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15555"
  },
  {
    "id": "arXiv:2112.15561",
    "title": "SOK: On the Analysis of Web Browser Security",
    "abstract": "Web browsers are integral parts of everyone's daily life. They are commonly\nused for security-critical and privacy sensitive tasks, like banking\ntransactions and checking medical records. Unfortunately, modern web browsers\nare too complex to be bug free (e.g., 25 million lines of code in Chrome), and\ntheir role as an interface to the cyberspace makes them an attractive target\nfor attacks. Accordingly, web browsers naturally become an arena for\ndemonstrating advanced exploitation techniques by attackers and\nstate-of-the-art defenses by browser vendors. Web browsers, arguably, are the\nmost exciting place to learn the latest security issues and techniques, but\nremain as a black art to most security researchers because of their\nfast-changing characteristics and complex code bases.\nTo bridge this gap, this paper attempts to systematize the security landscape\nof modern web browsers by studying the popular classes of security bugs, their\nexploitation techniques, and deployed defenses. More specifically, we first\nintroduce a unified architecture that faithfully represents the security design\nof four major web browsers. Second, we share insights from a 10-year\nlongitudinal study on browser bugs. Third, we present a timeline and context of\nmitigation schemes and their effectiveness. Fourth, we share our lessons from a\nfull-chain exploit used in 2020 Pwn2Own competition. and the implication of bug\nbounty programs to web browser security. We believe that the key takeaways from\nthis systematization can shed light on how to advance the status quo of modern\nweb browsers, and, importantly, how to create secure yet complex software in\nthe future.",
    "descriptor": "",
    "authors": [
      "Jungwon Lim",
      "Yonghwi Jin",
      "Mansour Alharthi",
      "Xiaokuan Zhang",
      "Jinho Jung",
      "Rajat Gupta",
      "Kuilin Li",
      "Daehee Jang",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.15561"
  },
  {
    "id": "arXiv:2112.15566",
    "title": "In Lieu of Privacy: Anonymous Contact Tracing",
    "abstract": "We present Tracer Tokens, a hardware token of privacy-preserving contact\ntracing utilizing Exposure Notification \\cite{GAEN} protocol. Through\nsubnetworks, we show that any disease spread by proximity can be traced such as\nseasonal flu, cold, regional strains of COVID-19, or Tuberculosis. Further, we\nshow this protocol to notify $n^n$ users in parallel, providing a speed of\ninformation unmatched by current contact tracing methods.",
    "descriptor": "\nComments: 9 pages, 2 figures, student project\n",
    "authors": [
      "Rohit Bhat",
      "Shranav Palakurthi",
      "Naman Tiwari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.15566"
  },
  {
    "id": "arXiv:2112.15568",
    "title": "Actor Loss of Soft Actor Critic Explained",
    "abstract": "This technical report is devoted to explaining how the actor loss of soft\nactor critic is obtained, as well as the associated gradient estimate. It gives\nthe necessary mathematical background to derive all the presented equations,\nfrom the theoretical actor loss to the one implemented in practice. This\nnecessitates a comparison of the reparameterization trick used in soft actor\ncritic with the nabla log trick, which leads to open questions regarding the\nmost efficient method to use.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Thibault Lahire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15568"
  },
  {
    "id": "arXiv:2112.15571",
    "title": "PCACE: A Statistical Approach to Ranking Neurons for CNN  Interpretability",
    "abstract": "In this paper we introduce a new problem within the growing literature of\ninterpretability for convolution neural networks (CNNs). While previous work\nhas focused on the question of how to visually interpret CNNs, we ask what it\nis that we care to interpret, that is, which layers and neurons are worth our\nattention? Due to the vast size of modern deep learning network architectures,\nautomated, quantitative methods are needed to rank the relative importance of\nneurons so as to provide an answer to this question. We present a new\nstatistical method for ranking the hidden neurons in any convolutional layer of\na network. We define importance as the maximal correlation between the\nactivation maps and the class score. We provide different ways in which this\nmethod can be used for visualization purposes with MNIST and ImageNet, and show\na real-world application of our method to air pollution prediction with\nstreet-level images.",
    "descriptor": "",
    "authors": [
      "S\u00edlvia Casacuberta",
      "Esra Suel",
      "Seth Flaxman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15571"
  },
  {
    "id": "arXiv:2112.15575",
    "title": "Fast Learning of MNL Model from General Partial Rankings with  Application to Network Formation Modeling",
    "abstract": "Multinomial Logit (MNL) is one of the most popular discrete choice models and\nhas been widely used to model ranking data. However, there is a long-standing\ntechnical challenge of learning MNL from many real-world ranking data: exact\ncalculation of the MNL likelihood of \\emph{partial rankings} is generally\nintractable. In this work, we develop a scalable method for approximating the\nMNL likelihood of general partial rankings in polynomial time complexity. We\nalso extend the proposed method to learn mixture of MNL. We demonstrate that\nthe proposed methods are particularly helpful for applications to choice-based\nnetwork formation modeling, where the formation of new edges in a network is\nviewed as individuals making choices of their friends over a candidate set. The\nproblem of learning mixture of MNL models from partial rankings naturally\narises in such applications. And the proposed methods can be used to learn MNL\nmodels from network data without the strong assumption that temporal orders of\nall the edge formation are available. We conduct experiments on both synthetic\nand real-world network data to demonstrate that the proposed methods achieve\nmore accurate parameter estimation and better fitness of data compared to\nconventional methods.",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Jiaqi Ma",
      "Xingjian Zhang",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.15575"
  },
  {
    "id": "arXiv:2112.15577",
    "title": "Infinite wide (finite depth) Neural Networks benefit from multi-task  learning unlike shallow Gaussian Processes -- an exact quantitative  macroscopic characterization",
    "abstract": "We prove in this paper that wide ReLU neural networks (NNs) with at least one\nhidden layer optimized with l2-regularization on the parameters enforces\nmulti-task learning due to representation-learning - also in the limit width to\ninfinity. This is in contrast to multiple other idealized settings discussed in\nthe literature where wide (ReLU)-NNs loose their ability to benefit from\nmulti-task learning in the limit width to infinity. We deduce the multi-task\nlearning ability from proving an exact quantitative macroscopic\ncharacterization of the learned NN in function space.",
    "descriptor": "\nComments: 8 pages + appendix\n",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15577"
  },
  {
    "id": "arXiv:2112.15578",
    "title": "Importance of Empirical Sample Complexity Analysis for Offline  Reinforcement Learning",
    "abstract": "We hypothesize that empirically studying the sample complexity of offline\nreinforcement learning (RL) is crucial for the practical applications of RL in\nthe real world. Several recent works have demonstrated the ability to learn\npolicies directly from offline data. In this work, we ask the question of the\ndependency on the number of samples for learning from offline data. Our\nobjective is to emphasize that studying sample complexity for offline RL is\nimportant, and is an indicator of the usefulness of existing offline\nalgorithms. We propose an evaluation approach for sample complexity analysis of\noffline RL.",
    "descriptor": "",
    "authors": [
      "Samin Yeasar Arnob",
      "Riashat Islam",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15578"
  },
  {
    "id": "arXiv:2112.15579",
    "title": "Single-Shot Pruning for Offline Reinforcement Learning",
    "abstract": "Deep Reinforcement Learning (RL) is a powerful framework for solving complex\nreal-world problems. Large neural networks employed in the framework are\ntraditionally associated with better generalization capabilities, but their\nincreased size entails the drawbacks of extensive training duration,\nsubstantial hardware resources, and longer inference times. One way to tackle\nthis problem is to prune neural networks leaving only the necessary parameters.\nState-of-the-art concurrent pruning techniques for imposing sparsity perform\ndemonstrably well in applications where data distributions are fixed. However,\nthey have not yet been substantially explored in the context of RL. We close\nthe gap between RL and single-shot pruning techniques and present a general\npruning approach to the Offline RL. We leverage a fixed dataset to prune neural\nnetworks before the start of RL training. We then run experiments varying the\nnetwork sparsity level and evaluating the validity of pruning at initialization\ntechniques in continuous control tasks. Our results show that with 95% of the\nnetwork weights pruned, Offline-RL algorithms can still retain performance in\nthe majority of our experiments. To the best of our knowledge, no prior work\nutilizing pruning in RL retained performance at such high levels of sparsity.\nMoreover, pruning at initialization techniques can be easily integrated into\nany existing Offline-RL algorithms without changing the learning objective.",
    "descriptor": "",
    "authors": [
      "Samin Yeasar Arnob",
      "Riyasat Ohib",
      "Sergey Plis",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15579"
  },
  {
    "id": "arXiv:2112.15588",
    "title": "Computing the dominant eigenpair of an essentially nonnegative tensor  via a homotopy method",
    "abstract": "The theory of eigenvalues and eigenvectors is one of the fundamental and\nessential components in tensor analysis. Computing the dominant eigenpair of an\nessentially nonnegative tensor is an important topic in tensor computation\nbecause of the critical applications in network resource allocations. In this\npaper, we consider the aforementioned topic and there are two main\ncontributions. First, we show that an irreducible essentially nonnegative\ntensor has a unique positive dominant eigenvalue with a unique positive\nnormalized eigenvector. Second, we present a homotopy method to compute the\ndominant eigenpair and prove that it converges to the desired dominant\neigenpair whether the given tensor is irreducible or reducible based on an\napproximation technique. Finally, we implement the method using a\nprediction-correction approach for path following and some numerical results\nare reported to illustrate the efficiency of the proposed algorithm.",
    "descriptor": "\nComments: 22 pages, 0 figure\n",
    "authors": [
      "Xingbang Cui",
      "Liping Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.15588"
  },
  {
    "id": "arXiv:2112.15589",
    "title": "3-D Material Style Transfer for Reconstructing Unknown Appearance in  Complex Natural Materials",
    "abstract": "We propose a 3-D material style transfer framework for reconstructing\ninvisible (or faded) appearance properties in complex natural materials. Our\nalgorithm addresses the technical challenge of transferring appearance\nproperties from one object to another of the same material when both objects\nhave intricate, noncorresponding color patterns. Eggshells, exoskeletons, and\nminerals, for example, have patterns composed of highly randomized layers of\norganic and inorganic compounds. These materials pose a challenge as the\ndistribution of compounds that determine surface color changes from object to\nobject and within local pattern regions. Our solution adapts appearance\nobservations from a material property distribution in an exemplar to the\nmaterial property distribution of a target object to reconstruct its unknown\nappearance. We use measured reflectance in 3-D bispectral textures to record\nchanging material property distributions. Our novel implementation of spherical\nharmonics uses principles from chemistry and biology to learn relationships\nbetween color (hue and saturation) and material composition and concentration\nin an exemplar. The encoded relationships are transformed to the property\ndistribution of a target for color recovery and material assignment.\nQuantitative and qualitative evaluation methods show that we replicate color\npatterns more accurately than methods that only rely on shape correspondences\nand coarse-level perceptual differences. We demonstrate applications of our\nwork for reconstructing color in extinct fossils, restoring faded artifacts and\ngenerating synthetic textures.",
    "descriptor": "\nComments: 15 pages, 22 figures\n",
    "authors": [
      "Shashank Ranjan",
      "Corey Toler-Franklin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15589"
  },
  {
    "id": "arXiv:2112.15594",
    "title": "A Neural Network Solves and Generates Mathematics Problems by Program  Synthesis: Calculus, Differential Equations, Linear Algebra, and More",
    "abstract": "We demonstrate that a neural network pre-trained on text and fine-tuned on\ncode solves Mathematics problems by program synthesis. We turn questions into\nprogramming tasks, automatically generate programs, and then execute them,\nperfectly solving university-level problems from MIT's large Mathematics\ncourses (Single Variable Calculus 18.01, Multivariable Calculus 18.02,\nDifferential Equations 18.03, Introduction to Probability and Statistics 18.05,\nLinear Algebra 18.06, and Mathematics for Computer Science 6.042) as well as\nquestions from a MATH dataset (on Prealgebra, Algebra, Counting and\nProbability, Number Theory, and Precalculus), the latest benchmark of advanced\nmathematics problems specifically designed to assess mathematical reasoning. We\nexplore prompt generation methods that enable Transformers to generate question\nsolving programs for these subjects, including solutions with plots. We\ngenerate correct answers for a random sample of questions in each topic. We\nquantify the gap between the original and transformed questions and perform a\nsurvey to evaluate the quality and difficulty of generated questions. This is\nthe first work to automatically solve, grade, and generate university-level\nMathematics course questions at scale which represents a milestone for higher\neducation.",
    "descriptor": "\nComments: 114 pages\n",
    "authors": [
      "Iddo Drori",
      "Sunny Tran",
      "Roman Wang",
      "Newman Cheng",
      "Kevin Liu",
      "Leonard Tang",
      "Elizabeth Ke",
      "Nikhil Singh",
      "Taylor L. Patti",
      "Jayson Lynch",
      "Avi Shporer",
      "Nakul Verma",
      "Eugene Wu",
      "Gilbert Strang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15594"
  },
  {
    "id": "arXiv:2112.14768",
    "title": "Video Reconstruction from a Single Motion Blurred Image using Learned  Dynamic Phase Coding",
    "abstract": "Video reconstruction from a single motion-blurred image is a challenging\nproblem, which can enhance existing cameras' capabilities. Recently, several\nworks addressed this task using conventional imaging and deep learning. Yet,\nsuch purely-digital methods are inherently limited, due to direction ambiguity\nand noise sensitivity. Some works proposed to address these limitations using\nnon-conventional image sensors, however, such sensors are extremely rare and\nexpensive. To circumvent these limitations with simpler means, we propose a\nhybrid optical-digital method for video reconstruction that requires only\nsimple modifications to existing optical systems. We use a learned dynamic\nphase-coding in the lens aperture during the image acquisition to encode the\nmotion trajectories, which serve as prior information for the video\nreconstruction process. The proposed computational camera generates a sharp\nframe burst of the scene at various frame rates from a single coded\nmotion-blurred image, using an image-to-video convolutional neural network. We\npresent advantages and improved performance compared to existing methods, using\nboth simulations and a real-world camera prototype.",
    "descriptor": "",
    "authors": [
      "Erez Yosef",
      "Shay Elmalem",
      "Raja Giryes"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14768"
  },
  {
    "id": "arXiv:2112.14798",
    "title": "DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model",
    "abstract": "A long standing problem in the modeling of non-Newtonian hydrodynamics is the\navailability of reliable and interpretable hydrodynamic models that faithfully\nencode the underlying micro-scale polymer dynamics. The main complication\narises from the long polymer relaxation time, the complex molecular structure,\nand heterogeneous interaction. DeePN$^2$, a deep learning-based non-Newtonian\nhydrodynamic model, has been proposed and has shown some success in\nsystematically passing the micro-scale structural mechanics information to the\nmacro-scale hydrodynamics for suspensions with simple polymer conformation and\nbond potential. The model retains a multi-scaled nature by mapping the polymer\nconfigurations into a set of symmetry-preserving macro-scale features. The\nextended constitutive laws for these macro-scale features can be directly\nlearned from the kinetics of their micro-scale counterparts. In this paper, we\ncarry out further study of DeePN$^2$ using more complex micro-structural\nmodels. We show that DeePN$^2$ can faithfully capture the broadly overlooked\nviscoelastic differences arising from the specific molecular structural\nmechanics without human intervention.",
    "descriptor": "",
    "authors": [
      "Lidong Fang",
      "Pei Ge",
      "Lei Zhang",
      "Huan Lei",
      "Weinan E"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.14798"
  },
  {
    "id": "arXiv:2112.14808",
    "title": "On the Poisson Stability to Study a Fourth-Order Dynamical System with  Quadratic Nonlinearities",
    "abstract": "This article discusses the search procedure for the Poincar\\'e recurrences to\nclassify solutions on an attractor of a fourth-order nonlinear dynamical system\nusing a previously developed high-precision numerical method. For the resulting\nlimiting solution, the Lyapunov exponents are calculated using the modified\nBenettin's algorithm to study the stability of the found regime and confirm the\ntype of attractor.",
    "descriptor": "\nComments: Mathematics, 9:17 (2021), 2057\n",
    "authors": [
      "Alexander N. Pchelintsev"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.14808"
  },
  {
    "id": "arXiv:2112.14826",
    "title": "PINNs for the Solution of the Hyperbolic Buckley-Leverett Problem with a  Non-convex Flux Function",
    "abstract": "The displacement of two immiscible fluids is a common problem in fluid flow\nin porous media. Such a problem can be posed as a partial differential equation\n(PDE) in what is commonly referred to as a Buckley-Leverett (B-L) problem. The\nB-L problem is a non-linear hyperbolic conservation law that is known to be\nnotoriously difficult to solve using traditional numerical methods. Here, we\naddress the forward hyperbolic B-L problem with a nonconvex flux function using\nphysics-informed neural networks (PINNs). The contributions of this paper are\ntwofold. First, we present a PINN approach to solve the hyperbolic B-L problem\nby embedding the Oleinik entropy condition into the neural network residual. We\ndo not use a diffusion term (artificial viscosity) in the residual-loss, but we\nrely on the strong form of the PDE. Second, we use the Adam optimizer with\nresidual-based adaptive refinement (RAR) algorithm to achieve an ultra-low loss\nwithout weighting. Our solution method can accurately capture the shock-front\nand produce an accurate overall solution. We report a L2 validation error of 2\nx 10-2 and a L2 loss of 1x 10-6. The proposed method does not require any\nadditional regularization or weighting of losses to obtain such accurate\nsolution.",
    "descriptor": "",
    "authors": [
      "Waleed Diab",
      "Mohammed Al Kobaisi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14826"
  },
  {
    "id": "arXiv:2112.14838",
    "title": "Facial Input Decompositions for Robust Peak and Reachable Set Estimation  under Polyhedral Uncertainty",
    "abstract": "This work bounds extreme values of state functions and approximates reachable\nsets for a class of input-affine continuous-time systems that are affected by\npolyhedral-bounded uncertainty. Instances of these systems may arise in\ndata-driven peak estimation, in which the state function must be bounded for\nall systems that are that are consistent with a set of state-derivative data\nrecords corrupted under L-infinity bounded noise. Existing occupation\nmeasure-based methods form a convergent sequence of outer approximations to the\ntrue peak value or reachable set volume, given an initial set, by solving a\nhierarchy of semidefinite programs in increasing size. These techniques scale\ncombinatorially in the number of state variables and uncertain parameters. We\npresent tractable algorithms for peak and reachable set estimation that scale\nlinearly in the number of faces of the uncertainty-bounding polytope rather\nthan combinatorially in the number of uncertain parameters by leveraging convex\nduality and a theorem of alternatives (facial decomposition). The sequence of\ndecomposed semidefinite programs will converge to the true optimal value under\nmild assumptions (convergence and smoothness of dynamics).",
    "descriptor": "\nComments: 18 pages, 10 figures, 1 table\n",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14838"
  },
  {
    "id": "arXiv:2112.14868",
    "title": "The SAMME.C2 algorithm for severely imbalanced multi-class  classification",
    "abstract": "Classification predictive modeling involves the accurate assignment of\nobservations in a dataset to target classes or categories. There is an\nincreasing growth of real-world classification problems with severely\nimbalanced class distributions. In this case, minority classes have much fewer\nobservations to learn from than those from majority classes. Despite this\nsparsity, a minority class is often considered the more interesting class yet\ndeveloping a scientific learning algorithm suitable for the observations\npresents countless challenges. In this article, we suggest a novel multi-class\nclassification algorithm specialized to handle severely imbalanced classes\nbased on the method we refer to as SAMME.C2. It blends the flexible mechanics\nof the boosting techniques from SAMME algorithm, a multi-class classifier, and\nAda.C2 algorithm, a cost-sensitive binary classifier designed to address highly\nclass imbalances. Not only do we provide the resulting algorithm but we also\nestablish scientific and statistical formulation of our proposed SAMME.C2\nalgorithm. Through numerical experiments examining various degrees of\nclassifier difficulty, we demonstrate consistent superior performance of our\nproposed model.",
    "descriptor": "\nComments: 25 pages, 8 figures, algorithms\n",
    "authors": [
      "Banghee So",
      "Emiliano A. Valdez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14868"
  },
  {
    "id": "arXiv:2112.14872",
    "title": "Local Quadratic Convergence of Stochastic Gradient Descent with Adaptive  Step Size",
    "abstract": "Establishing a fast rate of convergence for optimization methods is crucial\nto their applicability in practice. With the increasing popularity of deep\nlearning over the past decade, stochastic gradient descent and its adaptive\nvariants (e.g. Adagrad, Adam, etc.) have become prominent methods of choice for\nmachine learning practitioners. While a large number of works have demonstrated\nthat these first order optimization methods can achieve sub-linear or linear\nconvergence, we establish local quadratic convergence for stochastic gradient\ndescent with adaptive step size for problems such as matrix inversion.",
    "descriptor": "\nComments: ICML 2021 Workshop on Beyond first-order methods in ML systems\n",
    "authors": [
      "Adityanarayanan Radhakrishnan",
      "Mikhail Belkin",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14872"
  },
  {
    "id": "arXiv:2112.14888",
    "title": "Parallel Network Flow Allocation in Repeated Routing Games via LQR  Optimal Control",
    "abstract": "In this article, we study the repeated routing game problem on a parallel\nnetwork with affine latency functions on each edge. We cast the game setup in a\nLQR control theoretic framework, leveraging the Rosenthal potential\nformulation. We use control techniques to analyze the convergence of the game\ndynamics with specific cases that lend themselves to optimal control. We design\nproper dynamics parameters so that the conservation of flow is guaranteed. We\nprovide an algorithmic solution for the general optimal control setup using a\nmultiparametric quadratic programming approach (explicit MPC). Finally we\nillustrate with numerics the impact of varying system parameters on the\nsolutions.",
    "descriptor": "\nComments: 23 pages, 9 figures, TRB submission\n",
    "authors": [
      "Marsalis Gibson",
      "Yiling You",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14888"
  },
  {
    "id": "arXiv:2112.14949",
    "title": "Decentralized Optimization Over the Stiefel Manifold by an Approximate  Augmented Lagrangian Function",
    "abstract": "In this paper, we focus on the decentralized optimization problem over the\nStiefel manifold, which is defined on a connected network of $d$ agents. The\nobjective is an average of $d$ local functions, and each function is privately\nheld by an agent and encodes its data. The agents can only communicate with\ntheir neighbors in a collaborative effort to solve this problem. In existing\nmethods, multiple rounds of communications are required to guarantee the\nconvergence, giving rise to high communication costs. In contrast, this paper\nproposes a decentralized algorithm, called DESTINY, which only invokes a single\nround of communications per iteration. DESTINY combines gradient tracking\ntechniques with a novel approximate augmented Lagrangian function. The global\nconvergence to stationary points is rigorously established. Comprehensive\nnumerical experiments demonstrate that DESTINY has a strong potential to\ndeliver a cutting-edge performance in solving a variety of testing problems.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Lei Wang",
      "Xin Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.14949"
  },
  {
    "id": "arXiv:2112.14988",
    "title": "Deniable Encryption in a Quantum World",
    "abstract": "(Sender-)Deniable encryption provides a very strong privacy guarantee: a\nsender who is coerced by an attacker into \"opening\" their ciphertext\nafter-the-fact is able to generate \"fake\" local random choices that are\nconsistent with any plaintext of their choice. The only known fully-efficient\nconstructions of public-key deniable encryption rely on indistinguishability\nobfuscation (iO) (which currently can only be based on sub-exponential hardness\nassumptions).\nIn this work, we study (sender-)deniable encryption in a setting where the\nencryption procedure is a quantum algorithm, but the ciphertext is classical.\nWe propose two notions of deniable encryption in this setting. The first\nnotion, called quantum deniability, parallels the classical one. We give a\nfully efficient construction satisfying this definition, assuming the quantum\nhardness of the Learning with Errors (LWE) problem. The second notion,\nunexplainability, starts from a new perspective on deniability, and leads to a\nnatural common view of deniability in the classical and quantum settings. We\ngive a construction which is secure in the random oracle model, assuming the\nquantum hardness of LWE. Notably, our construction satisfies a strong form of\nunexplainability which is impossible to achieve classically, thus highlighting\na new quantum phenomenon that may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Andrea Coladangelo",
      "Shafi Goldwasser",
      "Umesh Vazirani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14988"
  },
  {
    "id": "arXiv:2112.15009",
    "title": "Knowledge Matters: Radiology Report Generation with General and Specific  Knowledge",
    "abstract": "Automatic radiology report generation is critical in clinics which can\nrelieve experienced radiologists from the heavy workload and remind\ninexperienced radiologists of misdiagnosis or missed diagnose. Existing\napproaches mainly formulate radiology report generation as an image captioning\ntask and adopt the encoder-decoder framework. However, in the medical domain,\nsuch pure data-driven approaches suffer from the following problems: 1) visual\nand textual bias problem; 2) lack of expert knowledge. In this paper, we\npropose a knowledge-enhanced radiology report generation approach introduces\ntwo types of medical knowledge: 1) General knowledge, which is input\nindependent and provides the broad knowledge for report generation; 2) Specific\nknowledge, which is input dependent and provides the fine-grained knowledge for\nreport generation. To fully utilize both the general and specific knowledge, we\nalso propose a knowledge-enhanced multi-head attention mechanism. By merging\nthe visual features of the radiology image with general knowledge and specific\nknowledge, the proposed model can improve the quality of generated reports.\nExperimental results on two publicly available datasets IU-Xray and MIMIC-CXR\nshow that the proposed knowledge enhanced approach outperforms state-of-the-art\nimage captioning based methods. Ablation studies also demonstrate that both\ngeneral and specific knowledge can help to improve the performance of radiology\nreport generation.",
    "descriptor": "",
    "authors": [
      "Shuxin Yang",
      "Xian Wu",
      "Shen Ge",
      "Shaohua Kevin Zhou",
      "Li Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15009"
  },
  {
    "id": "arXiv:2112.15011",
    "title": "Radiology Report Generation with a Learned Knowledge Base and  Multi-modal Alignment",
    "abstract": "In clinics, a radiology report is crucial for guiding a patient's treatment.\nUnfortunately, report writing imposes a heavy burden on radiologists. To\neffectively reduce such a burden, we hereby present an automatic, multi-modal\napproach for report generation from chest x-ray. Our approach, motivated by the\nobservation that the descriptions in radiology reports are highly correlated\nwith the x-ray images, features two distinct modules: (i) Learned knowledge\nbase. To absorb the knowledge embedded in the above-mentioned correlation, we\nautomatically build a knowledge base based on textual embedding. (ii)\nMulti-modal alignment. To promote the semantic alignment among reports, disease\nlabels and images, we explicitly utilize textual embedding to guide the\nlearning of the visual feature space. We evaluate the performance of the\nproposed model using metrics from both natural language generation and clinic\nefficacy on the public IU and MIMIC-CXR datasets. Our ablation study shows that\neach module contributes to improving the quality of generated reports.\nFurthermore, with the aid of both modules, our approach clearly outperforms\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shuxin Yang",
      "Xian Wu",
      "Shen Ge",
      "Xingwang Wu",
      "S.Kevin Zhou",
      "Li Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15011"
  },
  {
    "id": "arXiv:2112.15036",
    "title": "Dimensionality reduction for prediction: Application to Bitcoin and  Ethereum",
    "abstract": "The objective of this paper is to assess the performances of dimensionality\nreduction techniques to establish a link between cryptocurrencies. We have\nfocused our analysis on the two most traded cryptocurrencies: Bitcoin and\nEthereum. To perform our analysis, we took log returns and added some\ncovariates to build our data set. We first introduced the pearson correlation\ncoefficient in order to have a preliminary assessment of the link between\nBitcoin and Ethereum. We then reduced the dimension of our data set using\ncanonical correlation analysis and principal component analysis. After\nperforming an analysis of the links between Bitcoin and Ethereum with both\nstatistical techniques, we measured their performance on forecasting Ethereum\nreturns with Bitcoin s features.",
    "descriptor": "",
    "authors": [
      "Hugo Inzirillo",
      "Benjamin Mat"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15036"
  },
  {
    "id": "arXiv:2112.15096",
    "title": "Verification and generation of unrefinable partitions",
    "abstract": "Unrefinable partitions are a subset of partitions into distinct parts which\nsatisfy an additional unrefinability property. More precisely, no parts of such\npartitions can be written as the sum of different integers which are not parts.\nWe address in this paper the algorithmic aspects related to unrefinable\npartitions, such as testing whether a given partition is unrefinable or not and\nenumerating all the partitions whose sum is a given number. We design two\nalgorithms to solve the two mentioned problems and we discuss their complexity.",
    "descriptor": "",
    "authors": [
      "Riccardo Aragona",
      "Lorenzo Campioni",
      "Roberto Civino",
      "Massimo Lauria"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2112.15096"
  },
  {
    "id": "arXiv:2112.15106",
    "title": "Colour alignment for relative colour constancy via non-standard  references",
    "abstract": "Relative colour constancy is an essential requirement for many scientific\nimaging applications. However, most digital cameras differ in their image\nformations and native sensor output is usually inaccessible, e.g., in\nsmartphone camera applications. This makes it hard to achieve consistent colour\nassessment across a range of devices, and that undermines the performance of\ncomputer vision algorithms. To resolve this issue, we propose a colour\nalignment model that considers the camera image formation as a black-box and\nformulates colour alignment as a three-step process: camera response\ncalibration, response linearisation, and colour matching. The proposed model\nworks with non-standard colour references, i.e., colour patches without knowing\nthe true colour values, by utilising a novel balance-of-linear-distances\nfeature. It is equivalent to determining the camera parameters through an\nunsupervised process. It also works with a minimum number of corresponding\ncolour patches across the images to be colour aligned to deliver the applicable\nprocessing. Two challenging image datasets collected by multiple cameras under\nvarious illumination and exposure conditions were used to evaluate the model.\nPerformance benchmarks demonstrated that our model achieved superior\nperformance compared to other popular and state-of-the-art methods.",
    "descriptor": "\nComments: 13 pages, 10 figures, 2 tables\n",
    "authors": [
      "Yunfeng Zhao",
      "Stuart Ferguson",
      "Huiyu Zhou",
      "Chris Elliott",
      "Karen Rafferty"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15106"
  },
  {
    "id": "arXiv:2112.15109",
    "title": "GenShare: Sharing Accurate Differentially-Private Statistics for Genomic  Datasets with Dependent Tuples",
    "abstract": "Motivation: Cutting the cost of DNA sequencing technology led to a quantum\nleap in the availability of genomic data. While sharing genomic data across\nresearchers is an essential driver of advances in health and biomedical\nresearch, the sharing process is often infeasible due to data privacy concerns.\nDifferential privacy is one of the rigorous mechanisms utilized to facilitate\nthe sharing of aggregate statistics from genomic datasets without disclosing\nany private individual-level data. However, differential privacy can still\ndivulge sensitive information about the dataset participants due to the\ncorrelation between dataset tuples. Results: Here, we propose GenShare model\nbuilt upon Laplace-perturbation-mechanism-based DP to introduce a\nprivacy-preserving query-answering sharing model for statistical genomic\ndatasets that include dependency due to the inherent correlations between\ngenomes of individuals (i.e., family ties). We demonstrate our privacy\nimprovement over the state-of-the-art approaches for a range of practical\nqueries including cohort discovery, minor allele frequency, and chi^2\nassociation tests. With a fine-grained analysis of sensitivity in the Laplace\nperturbation mechanism and considering joint distributions, GenShare results\nnear-achieve the formal privacy guarantees permitted by the theory of\ndifferential privacy as the queries that computed over independent tuples (only\nup to 6% differences). GenShare ensures that query results are as accurate as\ntheoretically guaranteed by differential privacy. For empowering the advances\nin different scientific and medical research areas, GenShare presents a path\ntoward an interactive genomic data sharing system when the datasets include\nparticipants with familial relationships.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Nour Almadhoun Alserr",
      "Ozgur Ulusoy",
      "Erman Ayday",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.15109"
  },
  {
    "id": "arXiv:2112.15113",
    "title": "Quantum secure direct communication with private dense coding using  general preshared quantum state",
    "abstract": "We study quantum secure direct communication by using a general preshared\nquantum state and a generalization of dense coding. In this scenario, Alice is\nallowed to apply a unitary on the preshared state to encode her message, and\nthe set of allowed unitaries forms a group. To decode the message, Bob is\nallowed to apply a measurement across his own system and the system he\nreceives. In the worst scenario, we guarantee that Eve obtains no information\nfor the message even when Eve access the joint system between the system that\nshe intercepts and her original system of the preshared state. For a practical\napplication, we propose a concrete protocol and derive an upper bound of\ninformation leakage in the finite-length setting. We also discuss how to apply\nour scenario to the case with discrete Weyl-Heisenberg representation when the\npreshared state is unknown.",
    "descriptor": "",
    "authors": [
      "Jiawei Wu",
      "Gui-Lu Long",
      "Masahito Hayashi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.15113"
  },
  {
    "id": "arXiv:2112.15180",
    "title": "A Resolution Enhancement Plug-in for Deformable Registration of Medical  Images",
    "abstract": "Image registration is a fundamental task for medical imaging. Resampling of\nthe intensity values is required during registration and better spatial\nresolution with finer and sharper structures can improve the resampling\nperformance and hence the registration accuracy. Super-resolution (SR) is an\nalgorithmic technique targeting at spatial resolution enhancement which can\nachieve an image resolution beyond the hardware limitation. In this work, we\nconsider SR as a preprocessing technique and present a CNN-based resolution\nenhancement module (REM) which can be easily plugged into the registration\nnetwork in a cascaded manner. Different residual schemes and network\nconfigurations of REM are investigated to obtain an effective architecture\ndesign of REM. In fact, REM is not confined to image registration, it can also\nbe straightforwardly integrated into other vision tasks for enhanced\nresolution. The proposed REM is thoroughly evaluated for deformable\nregistration on medical images quantitatively and qualitatively at different\nupscaling factors. Experiments on LPBA40 brain MRI dataset demonstrate that REM\nnot only improves the registration accuracy, especially when the input images\nsuffer from degraded spatial resolution, but also generates resolution enhanced\nimages which can be exploited for successive diagnosis.",
    "descriptor": "",
    "authors": [
      "Kaicong Sun",
      "Sven Simon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.15180"
  },
  {
    "id": "arXiv:2112.15199",
    "title": "Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave  Saddle-Point Problems with Bilinear Coupling",
    "abstract": "In this paper we study a convex-concave saddle-point problem $\\min_x\\max_y\nf(x) + y^\\top\\mathbf{A} x - g(y)$, where $f(x)$ and $g(y)$ are smooth and\nconvex functions. We propose an Accelerated Primal-Dual Gradient Method for\nsolving this problem which (i) achieves an optimal linear convergence rate in\nthe strongly-convex-strongly-concave regime matching the lower complexity bound\n(Zhang et al., 2021) and (ii) achieves an accelerated linear convergence rate\nin the case when only one of the functions $f(x)$ and $g(y)$ is strongly convex\nor even none of them are. Finally, we obtain a linearly-convergent algorithm\nfor the general smooth and convex-concave saddle point problem $\\min_x\\max_y\nF(x,y)$ without requirement of strong convexity or strong concavity.",
    "descriptor": "",
    "authors": [
      "Dmitry Kovalev",
      "Alexander Gasnikov",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15199"
  },
  {
    "id": "arXiv:2112.15232",
    "title": "Triads of Conics Associated with a Triangle",
    "abstract": "We revisit constructions based on triads of conics with foci at pairs of\nvertices of a reference triangle. We find that their 6 vertices lie on\nwell-known conics, whose type we analyze. We give conditions for these to be\ncircles and/or degenerate. In the latter case, we study the locus of their\ncenter.",
    "descriptor": "\nComments: 25 pages, 25 figures, 16 references\n",
    "authors": [
      "Ronaldo Garcia",
      "Liliana Gheorghe",
      "Peter Moses",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.15232"
  },
  {
    "id": "arXiv:2112.15237",
    "title": "Quantum Operads",
    "abstract": "The most standard description of symmetries of a mathematical structure\nproduces a group. However, when the definition of this structure is motivated\nby physics, or information theory, etc., the respective symmetry objects might\nbecome more sophisticated: quasigroups, loops, quantum groups, ... In this\npaper, we introduce and study quantum symmetries of very general categorical\nstructures: operads. Its initial motivation were spaces of probability\ndistributions on finite sets. We also investigate here how structures of\nquantum information, such as quantum states and some constructions of quantum\ncodes are algebras over operads.",
    "descriptor": "\nComments: amstex, 34 pages\n",
    "authors": [
      "Noemie Combe",
      "Yuri Manin",
      "Matilde Marcolli"
    ],
    "subjectives": [
      "Quantum Algebra (math.QA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.15237"
  },
  {
    "id": "arXiv:2112.15265",
    "title": "Entropy Regularized Optimal Transport Independence Criterion",
    "abstract": "Optimal transport (OT) and its entropy regularized offspring have recently\ngained a lot of attention in both machine learning and AI domains. In\nparticular, optimal transport has been used to develop probability metrics\nbetween probability distributions. We introduce in this paper an independence\ncriterion based on entropy regularized optimal transport. Our criterion can be\nused to test for independence between two samples. We establish non-asymptotic\nbounds for our test statistic, and study its statistical behavior under both\nthe null and alternative hypothesis. Our theoretical results involve tools from\nU-process theory and optimal transport theory. We present experimental results\non existing benchmarks, illustrating the interest of the proposed criterion.",
    "descriptor": "",
    "authors": [
      "Lang Liu",
      "Soumik Pal",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15265"
  },
  {
    "id": "arXiv:2112.15275",
    "title": "Learned Coarse Models for Efficient Turbulence Simulation",
    "abstract": "Turbulence simulation with classical numerical solvers requires very\nhigh-resolution grids to accurately resolve dynamics. Here we train learned\nsimulators at low spatial and temporal resolutions to capture turbulent\ndynamics generated at high resolution. We show that our proposed model can\nsimulate turbulent dynamics more accurately than classical numerical solvers at\nthe same low resolutions across various scientifically relevant metrics. Our\nmodel is trained end-to-end from data and is capable of learning a range of\nchallenging chaotic and turbulent dynamics at low resolution, including\ntrajectories generated by the state-of-the-art Athena++ engine. We show that\nour simpler, general-purpose architecture outperforms various more specialized,\nturbulence-specific architectures from the learned turbulence simulation\nliterature. In general, we see that learned simulators yield unstable\ntrajectories; however, we show that tuning training noise and temporal\ndownsampling solves this problem. We also find that while generalization beyond\nthe training distribution is a challenge for learned models, training noise,\nconvolutional architectures, and added loss constraints can help. Broadly, we\nconclude that our learned simulator outperforms traditional solvers run on\ncoarser grids, and emphasize that simple design choices can offer stability and\nrobust generalization.",
    "descriptor": "",
    "authors": [
      "Kimberly Stachenfeld",
      "Drummond B. Fielding",
      "Dmitrii Kochkov",
      "Miles Cranmer",
      "Tobias Pfaff",
      "Jonathan Godwin",
      "Can Cui",
      "Shirley Ho",
      "Peter Battaglia",
      "Alvaro Sanchez-Gonzalez"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.15275"
  },
  {
    "id": "arXiv:2112.15287",
    "title": "Distributed Random Reshuffling over Networks",
    "abstract": "In this paper, we consider the distributed optimization problem where $n$\nagents, each possessing a local cost function, collaboratively minimize the\naverage of the local cost functions over a connected network. To solve the\nproblem, we propose a distributed random reshuffling (D-RR) algorithm that\ncombines the classical distributed gradient descent (DGD) method and Random\nReshuffling (RR). We show that D-RR inherits the superiority of RR for both\nsmooth strongly convex and smooth nonconvex objective functions. In particular,\nfor smooth strongly convex objective functions, D-RR achieves\n$\\mathcal{O}(1/T^2)$ rate of convergence (here, $T$ counts the total number of\niterations) in terms of the squared distance between the iterate and the unique\nminimizer. When the objective function is assumed to be smooth nonconvex and\nhas Lipschitz continuous component functions, we show that D-RR drives the\nsquared norm of gradient to $0$ at a rate of $\\mathcal{O}(1/T^{2/3})$. These\nconvergence results match those of centralized RR (up to constant factors).",
    "descriptor": "\nComments: 28 pages, 5 figures\n",
    "authors": [
      "Kun Huang",
      "Xiao Li",
      "Andre Milzarek",
      "Shi Pu",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.15287"
  },
  {
    "id": "arXiv:2112.15296",
    "title": "Uncovering migration systems through spatio-temporal tensor  co-clustering",
    "abstract": "A central problem in the study of human mobility is that of migration\nsystems. Typically, migration systems are defined as a set of relatively stable\nmovements of people between two or more locations over time. While these\nemergent systems are expected to vary over time, they ideally contain a stable\nunderlying structure that could be discovered empirically. There have been some\nnotable attempts to formally or informally define migration systems, however\nthey have been limited by being hard to operationalize, and by defining\nmigration systems in ways that ignore origin/destination aspects and/or fail to\naccount for migration dynamics. In this work we propose a novel method,\nspatio-temporal (ST) tensor co-clustering, stemming from signal processing and\nmachine learning theory. To demonstrate its effectiveness for describing stable\nmigration systems we focus on domestic migration between counties in the US\nfrom 1990-2018. Relevant data for this period has been made available through\nthe US Internal Revenue Service. Specifically, we concentrate on three\nillustrative case studies: (i) US Metropolitan Areas, (ii) the state of\nCalifornia, and (iii) Louisiana, focusing on detecting exogenous events such as\nHurricane Katrina in 2005. Finally, we conclude with discussion and limitations\nof this approach.",
    "descriptor": "",
    "authors": [
      "Zack W. Almquist",
      "Tri Duc Nguyen",
      "Mikael Sorensen",
      "Xiao Fu",
      "Nicholas D. Sidiropoulos"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.15296"
  },
  {
    "id": "arXiv:2112.15299",
    "title": "CSformer: Bridging Convolution and Transformer for Compressive Sensing",
    "abstract": "Convolution neural networks (CNNs) have succeeded in compressive image\nsensing. However, due to the inductive bias of locality and weight sharing, the\nconvolution operations demonstrate the intrinsic limitations in modeling the\nlong-range dependency. Transformer, designed initially as a\nsequence-to-sequence model, excels at capturing global contexts due to the\nself-attention-based architectures even though it may be equipped with limited\nlocalization abilities. This paper proposes CSformer, a hybrid framework that\nintegrates the advantages of leveraging both detailed spatial information from\nCNN and the global context provided by transformer for enhanced representation\nlearning. The proposed approach is an end-to-end compressive image sensing\nmethod, composed of adaptive sampling and recovery. In the sampling module,\nimages are measured block-by-block by the learned sampling matrix. In the\nreconstruction stage, the measurement is projected into dual stems. One is the\nCNN stem for modeling the neighborhood relationships by convolution, and the\nother is the transformer stem for adopting global self-attention mechanism. The\ndual branches structure is concurrent, and the local features and global\nrepresentations are fused under different resolutions to maximize the\ncomplementary of features. Furthermore, we explore a progressive strategy and\nwindow-based transformer block to reduce the parameter and computational\ncomplexity. The experimental results demonstrate the effectiveness of the\ndedicated transformer-based architecture for compressive sensing, which\nachieves superior performance compared to state-of-the-art methods on different\ndatasets.",
    "descriptor": "",
    "authors": [
      "Dongjie Ye",
      "Zhangkai Ni",
      "Hanli Wang",
      "Jian Zhang",
      "Shiqi Wang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15299"
  },
  {
    "id": "arXiv:2112.15343",
    "title": "An Off-grid Compressive Sensing Strategy for the Subarray Synthesis of  Non-uniform Linear Arrays",
    "abstract": "With the increasing popularity of large-scale antenna arrays, the subarraying\ntechnology becomes more attractive. In this paper, we propose two effective\nsubarraying methods right after formulating the subarray synthesis as a\ncompressive sensing (CS) problem: i) Orthogonal matching pursuit based subarray\nsynthesis (OMP-SS), a common CS approach which can be used for the subarray\nsynthesis to attain the subarray information (the subarray number, the number\nof elements per subarray and corresponding excitation coeffcients) and ii)\nOff-grid orthogonal matching pursuit based subarray synthesis (OGOMP-SS), an\nadvanced approach for optimizing antenna elements positions and the subarray\ninformation mentioned above simultaneously. In addition, two user-defined modes\nare designed for different application scenarios, wherein, mode-1 is to\noptimize the pattern synthesis performance for the given the number of\nsubarrays, and mode-2 is to obtain the minimum number of subarrays for the\ncases when the pattern synthsis accuracy is satisfied. Finally, our simulation\nresults reveal that it is of paramount significance to optimize antenna\nelements positions for the subarray synthesis performance on the one hand and\ndemonstrate the excellent performances of proposed schemes in comparison with\nother competitive state-of-the-art subarray synthesis methods on the other\nhand.",
    "descriptor": "\nComments: 10 pages, 20 figures\n",
    "authors": [
      "Songjie Yang",
      "Wanting Lyu",
      "Zhongpei Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15343"
  },
  {
    "id": "arXiv:2112.15362",
    "title": "Calibrated Hyperspectral Image Reconstruction via Graph-based  Self-Tuning Network",
    "abstract": "Recently, hyperspectral imaging (HSI) has attracted increasing research\nattention, especially for the ones based on a coded aperture snapshot spectral\nimaging (CASSI) system. Existing deep HSI reconstruction models are generally\ntrained on paired data to retrieve original signals upon 2D compressed\nmeasurements given by a particular optical hardware mask in CASSI, during which\nthe mask largely impacts the reconstruction performance and could work as a\n\"model hyperparameter\" governing on data augmentations. This mask-specific\ntraining style will lead to a hardware miscalibration issue, which sets up\nbarriers to deploying deep HSI models among different hardware and noisy\nenvironments. To address this challenge, we introduce mask uncertainty for HSI\nwith a complete variational Bayesian learning treatment and explicitly model it\nthrough a mask decomposition inspired by real hardware. Specifically, we\npropose a novel Graph-based Self-Tuning (GST) network to reason uncertainties\nadapting to varying spatial structures of masks among different hardware.\nMoreover, we develop a bilevel optimization framework to balance HSI\nreconstruction and uncertainty estimation, accounting for the hyperparameter\nproperty of masks. Extensive experimental results and model discussions\nvalidate the effectiveness (over 33/30 dB) of the proposed GST method under two\nmiscalibration scenarios and demonstrate a highly competitive performance\ncompared with the state-of-the-art well-calibrated methods. Our code and\npre-trained model are available at https://github.com/Jiamian\nWang/mask_uncertainty_spectral_SCI",
    "descriptor": "",
    "authors": [
      "Jiamian Wang",
      "Yulun Zhang",
      "Xin Yuan",
      "Ziyi Meng",
      "Zhiqiang Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15362"
  },
  {
    "id": "arXiv:2112.15367",
    "title": "Weakly Supervised Change Detection Using Guided Anisotropic Difusion",
    "abstract": "Large scale datasets created from crowdsourced labels or openly available\ndata have become crucial to provide training data for large scale learning\nalgorithms. While these datasets are easier to acquire, the data are frequently\nnoisy and unreliable, which is motivating research on weakly supervised\nlearning techniques. In this paper we propose original ideas that help us to\nleverage such datasets in the context of change detection. First, we propose\nthe guided anisotropic diffusion (GAD) algorithm, which improves semantic\nsegmentation results using the input images as guides to perform edge\npreserving filtering. We then show its potential in two weakly-supervised\nlearning strategies tailored for change detection. The first strategy is an\niterative learning method that combines model optimisation and data cleansing\nusing GAD to extract the useful information from a large scale change detection\ndataset generated from open vector data. The second one incorporates GAD within\na novel spatial attention layer that increases the accuracy of weakly\nsupervised networks trained to perform pixel-level predictions from image-level\nlabels. Improvements with respect to state-of-the-art are demonstrated on 4\ndifferent public datasets.",
    "descriptor": "\nComments: Machine Learning Journal 2021. arXiv admin note: substantial text overlap with arXiv:1904.08208\n",
    "authors": [
      "Rodrigo Caye Daudt",
      "Bertrand Le Saux",
      "Alexandre Boulch",
      "Yann Gousseau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15367"
  },
  {
    "id": "arXiv:2112.15382",
    "title": "Processing Images from Multiple IACTs in the TAIGA Experiment with  Convolutional Neural Networks",
    "abstract": "Extensive air showers created by high-energy particles interacting with the\nEarth atmosphere can be detected using imaging atmospheric Cherenkov telescopes\n(IACTs). The IACT images can be analyzed to distinguish between the events\ncaused by gamma rays and by hadrons and to infer the parameters of the event\nsuch as the energy of the primary particle. We use convolutional neural\nnetworks (CNNs) to analyze Monte Carlo-simulated images from the telescopes of\nthe TAIGA experiment. The analysis includes selection of the images\ncorresponding to the showers caused by gamma rays and estimating the energy of\nthe gamma rays. We compare performance of the CNNs using images from a single\ntelescope and the CNNs using images from two telescopes as inputs.",
    "descriptor": "\nComments: In Proceedings of 5th International Workshop on Deep Learning in Computational Physics (DLCP2021), 28-29 June, 2021, Moscow, Russia\n",
    "authors": [
      "Stanislav Polyakov",
      "Andrey Demichev",
      "Alexander Kryukov",
      "Evgeny Postnikov"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15382"
  },
  {
    "id": "arXiv:2112.15383",
    "title": "Separation of scales and a thermodynamic description of feature learning  in some CNNs",
    "abstract": "Deep neural networks (DNNs) are powerful tools for compressing and distilling\ninformation. Due to their scale and complexity, often involving billions of\ninter-dependent internal degrees of freedom, exact analysis approaches often\nfall short. A common strategy in such cases is to identify slow degrees of\nfreedom that average out the erratic behavior of the underlying fast\nmicroscopic variables. Here, we identify such a separation of scales occurring\nin over-parameterized deep convolutional neural networks (CNNs) at the end of\ntraining. It implies that neuron pre-activations fluctuate in a nearly Gaussian\nmanner with a deterministic latent kernel. While for CNNs with infinitely many\nchannels these kernels are inert, for finite CNNs they adapt and learn from\ndata in an analytically tractable manner. The resulting thermodynamic theory of\ndeep learning yields accurate predictions on several deep non-linear CNN toy\nmodels. In addition, it provides new ways of analyzing and understanding CNNs.",
    "descriptor": "",
    "authors": [
      "Inbar Seroussi",
      "Zohar Ringel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.15383"
  },
  {
    "id": "arXiv:2112.15386",
    "title": "Efficient Single Image Super-Resolution Using Dual Path Connections with  Multiple Scale Learning",
    "abstract": "Deep convolutional neural networks have been demonstrated to be effective for\nSISR in recent years. On the one hand, residual connections and dense\nconnections have been used widely to ease forward information and backward\ngradient flows to boost performance. However, current methods use residual\nconnections and dense connections separately in most network layers in a\nsub-optimal way. On the other hand, although various networks and methods have\nbeen designed to improve computation efficiency, save parameters, or utilize\ntraining data of multiple scale factors for each other to boost performance, it\neither do super-resolution in HR space to have a high computation cost or can\nnot share parameters between models of different scale factors to save\nparameters and inference time. To tackle these challenges, we propose an\nefficient single image super-resolution network using dual path connections\nwith multiple scale learning named as EMSRDPN. By introducing dual path\nconnections inspired by Dual Path Networks into EMSRDPN, it uses residual\nconnections and dense connections in an integrated way in most network layers.\nDual path connections have the benefits of both reusing common features of\nresidual connections and exploring new features of dense connections to learn a\ngood representation for SISR. To utilize the feature correlation of multiple\nscale factors, EMSRDPN shares all network units in LR space between different\nscale factors to learn shared features and only uses a separate reconstruction\nunit for each scale factor, which can utilize training data of multiple scale\nfactors to help each other to boost performance, meanwhile which can save\nparameters and support shared inference for multiple scale factors to improve\nefficiency. Experiments show EMSRDPN achieves better performance and comparable\nor even better parameter and inference efficiency over SOTA methods.",
    "descriptor": "\nComments: 20 pages, 9 figures, 2 tables\n",
    "authors": [
      "Bin-Cheng Yang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.15386"
  },
  {
    "id": "arXiv:2112.15389",
    "title": "$H^2$-Optimal Reduction of Positive Networks using Riemannian Augmented  Lagrangian Method",
    "abstract": "In this study, we formulate the model reduction problem of a stable and\npositive network system as a constrained Riemannian optimization problem with\nthe $H^2$-error objective function of the original and reduced network systems.\nWe improve the reduction performance of the clustering-based method, which is\none of the most known methods for model reduction of positive network systems,\nby using the output of the clustering-based method as the initial point for the\nproposed method. The proposed method reduces the dimension of the network\nsystem while preserving the properties of stability, positivity, and\ninterconnection structure by applying the Riemannian augmented Lagrangian\nmethod (RALM) and deriving the Riemannian gradient of the Lagrangian. To check\nthe efficiency of our method, we conduct a numerical experiment and compare it\nwith the clustering-based method in the sense of $H^2$-error and\n$H^\\infty$-error.",
    "descriptor": "\nComments: Submitted for IEEE L-CSS\n",
    "authors": [
      "Sota Misawa",
      "Kazuhiro Sato"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15389"
  },
  {
    "id": "arXiv:2112.15448",
    "title": "Exact Post-selection Inference For Tracking S&P500",
    "abstract": "The problem that is solved in this paper is known as index tracking. The\nmethod of Lasso is used to reduce the dimensions of S&P500 index which has many\napplications in both investment and portfolio management algorithms. The\nnovelty of this paper is that post-selection inference is used to have better\nmodeling and inference for Lasso approach to index tracking. Both confidence\nintervals and curves indicate that the performance of Lasso type method for\ndimension reduction of S&P500 is remarkably high. Keywords: index tracking,\nlasso, post-selection inference, S&P500",
    "descriptor": "\nComments: 4 figures, 1 table\n",
    "authors": [
      "Farshad Noravesh",
      "Hamid Boustanifar"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.15448"
  },
  {
    "id": "arXiv:2112.15510",
    "title": "Data-Driven Optimal Control of Bilinear Systems",
    "abstract": "This paper develops a method to learn optimal controls from data for bilinear\nsystems without a priori knowledge of the system dynamics. Given an unknown\nbilinear system, we first characterize when the available data is suitable to\nsolve the optimal control problem. This characterization leads us to propose an\nonline control experiment design procedure that guarantees that any input/state\ntrajectory can be represented as a linear combination of collected input/state\ndata matrices. Leveraging this data-based representation, we transform the\noriginal optimal control problem into an equivalent data-based optimization\nproblem with bilinear constraints. We solve the latter by iteratively employing\na convex-concave procedure to convexify it and find a locally optimal control\nsequence. Simulations show that the performance of the proposed data-based\napproach is comparable with model-based methods.",
    "descriptor": "",
    "authors": [
      "Zhenyi Yuan",
      "Jorge Cortes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15510"
  },
  {
    "id": "arXiv:2112.15516",
    "title": "Transfer learning of phase transitions in percolation and directed  percolation",
    "abstract": "The latest advances of statistical physics have shown remarkable performance\nof machine learning in identifying phase transitions. In this paper, we apply\ndomain adversarial neural network (DANN) based on transfer learning to studying\nnon-equilibrium and equilibrium phase transition models, which are percolation\nmodel and directed percolation (DP) model, respectively. With the DANN, only a\nsmall fraction of input configurations (2d images) needs to be labeled, which\nis automatically chosen, in order to capture the critical point. To learn the\nDP model, the method is refined by an iterative procedure in determining the\ncritical point, which is a prerequisite for the data collapse in calculating\nthe critical exponent $\\nu_{\\perp}$. We then apply the DANN to a\ntwo-dimensional site percolation with configurations filtered to include only\nthe largest cluster which may contain the information related to the order\nparameter. The DANN learning of both models yields reliable results which are\ncomparable to the ones from Monte Carlo simulations. Our study also shows that\nthe DANN can achieve quite high accuracy at much lower cost, compared to the\nsupervised learning.",
    "descriptor": "\nComments: 11 pages,10 figures\n",
    "authors": [
      "Jianmin Shen",
      "Feiyi Liu",
      "Shiyang Chen",
      "Dian Xu",
      "Xiangna Chen",
      "Shengfeng Deng",
      "Wei Li",
      "Gabor Papp",
      "Chunbin Yang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.15516"
  },
  {
    "id": "arXiv:2112.15523",
    "title": "Transfer learning for cancer diagnosis in histopathological images",
    "abstract": "Transfer learning allows us to exploit knowledge gained from one task to\nassist in solving another but relevant task. In modern computer vision\nresearch, the question is which architecture performs better for a given\ndataset. In this paper, we compare the performance of 14 pre-trained ImageNet\nmodels on the histopathologic cancer detection dataset, where each model has\nbeen configured as a naive model, feature extractor model, or fine-tuned model.\nDensenet161 has been shown to have high precision whilst Resnet101 has a high\nrecall. A high precision model is suitable to be used when follow-up\nexamination cost is high, whilst low precision but a high recall/sensitivity\nmodel can be used when the cost of follow-up examination is low. Results also\nshow that transfer learning helps to converge a model faster.",
    "descriptor": "",
    "authors": [
      "Sandhya Aneja",
      "Nagender Aneja",
      "Pg Emeroylariffion Abas",
      "Abdul Ghani Naim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15523"
  },
  {
    "id": "arXiv:2112.15532",
    "title": "Machine Learning Trivializing Maps: A First Step Towards Understanding  How Flow-Based Samplers Scale Up",
    "abstract": "A trivializing map is a field transformation whose Jacobian determinant\nexactly cancels the interaction terms in the action, providing a representation\nof the theory in terms of a deterministic transformation of a distribution from\nwhich sampling is trivial. Recently, a proof-of-principle study by Albergo,\nKanwar and Shanahan [arXiv:1904.12072] demonstrated that approximations of\ntrivializing maps can be `machine-learned' by a class of invertible,\ndifferentiable neural models called \\textit{normalizing flows}. By ensuring\nthat the Jacobian determinant can be computed efficiently, asymptotically exact\nsampling from the theory of interest can be performed by drawing samples from a\nsimple distribution and passing them through the network. From a theoretical\nperspective, this approach has the potential to become more efficient than\ntraditional Markov Chain Monte Carlo sampling techniques, where\nautocorrelations severely diminish the sampling efficiency as one approaches\nthe continuum limit. A major caveat is that it is not yet understood how the\nsize of models and the cost of training them is expected to scale. As a first\nstep, we have conducted an exploratory scaling study using two-dimensional\n$\\phi^4$ with up to $20^2$ lattice sites. Although the scope of our study is\nlimited to a particular model architecture and training algorithm, initial\nresults paint an interesting picture in which training costs grow very quickly\nindeed. We describe a candidate explanation for the poor scaling, and outline\nour intentions to clarify the situation in future work.",
    "descriptor": "\nComments: Submitted as a conference proceeding for the 38th International Symposium on Lattice Field Theory (2021)\n",
    "authors": [
      "Luigi Del Debbio",
      "Joe Marsh Rossney",
      "Michael Wilson"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15532"
  },
  {
    "id": "arXiv:2112.15562",
    "title": "Large-scale focusing joint inversion of gravity and magnetic data with  Gramian constraint",
    "abstract": "A fast algorithm for the large-scale joint inversion of gravity and magnetic\ndata is developed. It uses a nonlinear Gramian constraint to impose correlation\nbetween density and susceptibility of reconstructed models. The global\nobjective function is formulated in the space of the weighted parameters, but\nthe Gramian constraint is implemented in the original space, and the nonlinear\nconstraint is imposed using two separate Lagrange parameters, one for each\nmodel domain. This combined approach provides more similarity between the\nreconstructed models. It is assumed that the measured data are obtained on a\nuniform grid and that a consistent regular discretization of the volume domain\nis imposed. The sensitivity matrices exhibit a block Toeplitz Toeplitz block\nstructure for each depth layer of the model domain. Forward and transpose\noperations with the matrices can be implemented efficiently using two\ndimensional fast Fourier transforms. This makes it feasible to solve for large\nscale problems with respect to both computational costs and memory demands, and\nto solve the nonlinear problem by applying iterative methods that rely only on\nmatrix vector multiplications. As such, the use of the regularized reweighted\nconjugate gradient algorithm, in conjunction with the structure of the\nsensitivity matrices, leads to a fast methodology for large-scale joint\ninversion of geophysical data sets. Numerical simulations demonstrate that it\nis possible to apply a nonlinear joint inversion algorithm, with $L_p$-norm\nstabilisers, for the reconstruction of large model domains on a standard laptop\ncomputer. It is demonstrated, that the p=1 choice provides sparse reconstructed\nsolutions with sharp boundaries, and $p=2$ provides smooth and blurred models.\nGravity and magnetic data obtained over an area in northwest of Mesoproterozoic\nSt. Francois Terrane, southeast of Missouri, USA are inverted.",
    "descriptor": "",
    "authors": [
      "Saeed Vatankhah",
      "Rosemary A. Renaut",
      "Xingguo Huang",
      "Kevin Mickus",
      "Mostafa Gharloghi"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15562"
  },
  {
    "id": "arXiv:2112.15572",
    "title": "Statistical scalability and approximate inference in distributed  computing environments",
    "abstract": "Harnessing distributed computing environments to build scalable inference\nalgorithms for very large data sets is a core challenge across the broad\nmathematical sciences. Here we provide a theoretical framework to do so along\nwith fully implemented examples of scalable algorithms with performance\nguarantees. We begin by formalizing the class of statistics which admit\nstraightforward calculation in such environments through independent\nparallelization. We then show how to use such statistics to approximate\narbitrary functional operators, thereby providing practitioners with a generic\napproximate inference procedure that does not require data to reside entirely\nin memory. We characterize the $L^2$ approximation properties of our approach,\nand then use it to treat two canonical examples that arise in large-scale\nstatistical analyses: sample quantile calculation and local polynomial\nregression. A variety of avenues and extensions remain open for future work.",
    "descriptor": "\nComments: 74 pages, 3 figures; submitted for publication\n",
    "authors": [
      "Aritra Chakravorty",
      "William S. Cleveland",
      "Patrick J. Wolfe"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.15572"
  },
  {
    "id": "arXiv:2112.15595",
    "title": "Triangular Flows for Generative Modeling: Statistical Consistency,  Smoothness Classes, and Fast Rates",
    "abstract": "Triangular flows, also known as Kn\\\"{o}the-Rosenblatt measure couplings,\ncomprise an important building block of normalizing flow models for generative\nmodeling and density estimation, including popular autoregressive flow models\nsuch as real-valued non-volume preserving transformation models (Real NVP). We\npresent statistical guarantees and sample complexity bounds for triangular flow\nstatistical models. In particular, we establish the statistical consistency and\nthe finite sample convergence rates of the Kullback-Leibler estimator of the\nKn\\\"{o}the-Rosenblatt measure coupling using tools from empirical process\ntheory. Our results highlight the anisotropic geometry of function classes at\nplay in triangular flows, shed light on optimal coordinate ordering, and lead\nto statistical guarantees for Jacobian flows. We conduct numerical experiments\non synthetic data to illustrate the practical implications of our theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Nicholas J. Irons",
      "Meyer Scetbon",
      "Soumik Pal",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.15595"
  },
  {
    "id": "arXiv:2112.15596",
    "title": "A Strongly Monotonic Polygonal Euler Scheme",
    "abstract": "Rate of convergence results are presented for a new class of explicit Euler\nschemes, which approximate stochastic differential equations (SDEs) with\nsuperlinearly growing drift coefficients that satisfy a particular form of\nstrong monotonicity. The new, distinct feature of this class of explicit\nschemes is the preservation of the monotonicity condition for the new, suitably\ncontrolled drift coefficients that guaranty the finiteness of moments of the\nnumerical solutions up to a desired order.",
    "descriptor": "",
    "authors": [
      "Tim Johnston",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15596"
  },
  {
    "id": "arXiv:1710.05465",
    "title": "Flow: A Modular Learning Framework for Mixed Autonomy Traffic",
    "abstract": "Comments: 17 pages, 8 figures, 5 tables. 2021 IEEE Transactions on Robotics (T-RO)",
    "descriptor": "\nComments: 17 pages, 8 figures, 5 tables. 2021 IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Cathy Wu",
      "Aboudy Kreidieh",
      "Kanaad Parvate",
      "Eugene Vinitsky",
      "Alexandre M Bayen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1710.05465"
  },
  {
    "id": "arXiv:1905.08707",
    "title": "Lagrangian uncertainty quantification and information inequalities for  stochastic flows",
    "abstract": "Lagrangian uncertainty quantification and information inequalities for  stochastic flows",
    "descriptor": "",
    "authors": [
      "Michal Branicki",
      "Kenneth Uda"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1905.08707"
  },
  {
    "id": "arXiv:1906.09338",
    "title": "G-PATE: Scalable Differentially Private Data Generator via Private  Aggregation of Teacher Discriminators",
    "abstract": "G-PATE: Scalable Differentially Private Data Generator via Private  Aggregation of Teacher Discriminators",
    "descriptor": "",
    "authors": [
      "Yunhui Long",
      "Boxin Wang",
      "Zhuolin Yang",
      "Bhavya Kailkhura",
      "Aston Zhang",
      "Carl A. Gunter",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.09338"
  },
  {
    "id": "arXiv:1906.12072",
    "title": "Multiple Testing and Variable Selection along the path of the Least  Angle Regression",
    "abstract": "Comments: 58 pages; new: FDR control and power comparison between Knockoff, FCD, Slope and our proposed method; new: the introduction has been revised and now present a synthetic presentation of the main results. We believe that this introduction brings new insists compared to previous versions",
    "descriptor": "\nComments: 58 pages; new: FDR control and power comparison between Knockoff, FCD, Slope and our proposed method; new: the introduction has been revised and now present a synthetic presentation of the main results. We believe that this introduction brings new insists compared to previous versions\n",
    "authors": [
      "J.-M. Aza\u00efs",
      "Y. De Castro"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.12072"
  },
  {
    "id": "arXiv:1907.00457",
    "title": "BERTphone: Phonetically-Aware Encoder Representations for  Utterance-Level Speaker and Language Recognition",
    "abstract": "Comments: Odyssey 2020 camera-ready (presented Nov. 2020)",
    "descriptor": "\nComments: Odyssey 2020 camera-ready (presented Nov. 2020)\n",
    "authors": [
      "Shaoshi Ling",
      "Julian Salazar",
      "Yuzong Liu",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1907.00457"
  },
  {
    "id": "arXiv:1911.11845",
    "title": "Fast computation of soft tissue thermal response under deformation based  on fast explicit dynamics finite element algorithm for surgical simulation",
    "abstract": "Comments: Accepted for publication in Computer Methods and Programs in Biomedicine",
    "descriptor": "\nComments: Accepted for publication in Computer Methods and Programs in Biomedicine\n",
    "authors": [
      "Jinao Zhang",
      "Sunita Chauhan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/1911.11845"
  },
  {
    "id": "arXiv:1911.12360",
    "title": "How Much Over-parameterization Is Sufficient to Learn Deep ReLU  Networks?",
    "abstract": "Comments: 21 pages, 1 figure, 1 table. In ICLR 2021",
    "descriptor": "\nComments: 21 pages, 1 figure, 1 table. In ICLR 2021\n",
    "authors": [
      "Zixiang Chen",
      "Yuan Cao",
      "Difan Zou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.12360"
  },
  {
    "id": "arXiv:2002.01711",
    "title": "Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement  Learning Framework",
    "abstract": "Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement  Learning Framework",
    "descriptor": "",
    "authors": [
      "Chengchun Shi",
      "Xiaoyu Wang",
      "Shikai Luo",
      "Hongtu Zhu",
      "Jieping Ye",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.01711"
  },
  {
    "id": "arXiv:2002.06635",
    "title": "The HPIM-DM Multicast Routing Protocol",
    "abstract": "The HPIM-DM Multicast Routing Protocol",
    "descriptor": "",
    "authors": [
      "Pedro Oliveira",
      "Alexandre Silva",
      "Rui Valadas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2002.06635"
  },
  {
    "id": "arXiv:2003.03929",
    "title": "Geometry-aware Compensation Scheme for Morphing Drones",
    "abstract": "Geometry-aware Compensation Scheme for Morphing Drones",
    "descriptor": "",
    "authors": [
      "Amedeo Fabris",
      "Kevin Kleber",
      "Davide Falanga",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.03929"
  },
  {
    "id": "arXiv:2004.00184",
    "title": "A theory of independent mechanisms for extrapolation in generative  models",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Michel Besserve",
      "R\u00e9my Sun",
      "Dominik Janzing",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.00184"
  },
  {
    "id": "arXiv:2004.01365",
    "title": "Coloring of ($P_5$, $4$-wheel)-free graphs",
    "abstract": "Comments: Revised compact version; Accepted for publication in Discrete Mathematics",
    "descriptor": "\nComments: Revised compact version; Accepted for publication in Discrete Mathematics\n",
    "authors": [
      "Arnab Char",
      "T. Karthick"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2004.01365"
  },
  {
    "id": "arXiv:2004.08487",
    "title": "*-Autonomous Envelopes and Conservativity",
    "abstract": "Comments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Michael Shulman"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.08487"
  },
  {
    "id": "arXiv:2005.02247",
    "title": "A Linear Algebra Approach to Linear Metatheory",
    "abstract": "Comments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "James Wood",
      "Robert Atkey"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2005.02247"
  },
  {
    "id": "arXiv:2005.11203",
    "title": "Towards a Neural Model for Serial Order in Frontal Cortex: a Brain  Theory from Memory Development to Higher-Level Cognition",
    "abstract": "Towards a Neural Model for Serial Order in Frontal Cortex: a Brain  Theory from Memory Development to Higher-Level Cognition",
    "descriptor": "",
    "authors": [
      "Alexandre Pitti",
      "Mathias Quoy",
      "Catherine Lavandier",
      "Sofiane Boucenna",
      "Wassim Swaileh",
      "Claudio Weidmann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2005.11203"
  },
  {
    "id": "arXiv:2007.01033",
    "title": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "abstract": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "descriptor": "",
    "authors": [
      "Paul Wild",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.01033"
  },
  {
    "id": "arXiv:2007.01771",
    "title": "Learning Expectation of Label Distribution for Facial Age and  Attractiveness Estimation",
    "abstract": "Comments: submitted to Pattern Recognition",
    "descriptor": "\nComments: submitted to Pattern Recognition\n",
    "authors": [
      "Bin-Bin Gao",
      "Xin-Xin Liu",
      "Hong-Yu Zhou",
      "Jianxin Wu",
      "Xin Geng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.01771"
  },
  {
    "id": "arXiv:2007.05170",
    "title": "A Two-Timescale Framework for Bilevel Optimization: Complexity Analysis  and Application to Actor-Critic",
    "abstract": "Comments: Major revision; Streamlined the presentation; Added new numerical experiments",
    "descriptor": "\nComments: Major revision; Streamlined the presentation; Added new numerical experiments\n",
    "authors": [
      "Mingyi Hong",
      "Hoi-To Wai",
      "Zhaoran Wang",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.05170"
  },
  {
    "id": "arXiv:2007.07047",
    "title": "Quantum Software Engineering: Landscapes and Horizons",
    "abstract": "Quantum Software Engineering: Landscapes and Horizons",
    "descriptor": "",
    "authors": [
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.07047"
  },
  {
    "id": "arXiv:2007.14325",
    "title": "Optimal Probabilistic Motion Planning with Potential Infeasible LTL  Constraints",
    "abstract": "Comments: IEEE TAC",
    "descriptor": "\nComments: IEEE TAC\n",
    "authors": [
      "Mingyu Cai",
      "Shaoping Xiao",
      "Zhijun Li",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.14325"
  },
  {
    "id": "arXiv:2009.04432",
    "title": "Smooth Converse Lyapunov-Barrier Theorems for Asymptotic Stability with  Safety Constraints and Reach-Avoid-Stay Specifications",
    "abstract": "Comments: Preprint submitted for publication, 13 pages, 2 figures",
    "descriptor": "\nComments: Preprint submitted for publication, 13 pages, 2 figures\n",
    "authors": [
      "Yiming Meng",
      "Yinan Li",
      "Maxwell Fitzsimmons",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.04432"
  },
  {
    "id": "arXiv:2009.10400",
    "title": "Towards real-time finite-strain anisotropic thermo-visco-elastodynamic  analysis of soft tissues for thermal ablative therapy",
    "abstract": "Comments: Submitted to Computer Methods and Programs in Biomedicine",
    "descriptor": "\nComments: Submitted to Computer Methods and Programs in Biomedicine\n",
    "authors": [
      "Jinao Zhang",
      "Remi Jacob Lay",
      "Stuart K. Roberts",
      "Sunita Chauhan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2009.10400"
  },
  {
    "id": "arXiv:2009.13794",
    "title": "From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction  Using Social Media Data",
    "abstract": "From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction  Using Social Media Data",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Sean Qian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13794"
  },
  {
    "id": "arXiv:2010.00827",
    "title": "Neural Thompson Sampling",
    "abstract": "Comments: 26 pages, 2 tables, 5 figures. In ICLR 2021",
    "descriptor": "\nComments: 26 pages, 2 tables, 5 figures. In ICLR 2021\n",
    "authors": [
      "Weitong Zhang",
      "Dongruo Zhou",
      "Lihong Li",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00827"
  },
  {
    "id": "arXiv:2010.00975",
    "title": "Taking Modality-free Human Identification as Zero-shot Learning",
    "abstract": "Comments: This manuscript has been accepted by IEEE Transactions on Circuits and Systems for Video Technology",
    "descriptor": "\nComments: This manuscript has been accepted by IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Zhizhe Liu",
      "Xingxing Zhang",
      "Zhenfeng Zhu",
      "Shuai Zheng",
      "Yao Zhao",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.00975"
  },
  {
    "id": "arXiv:2010.01278",
    "title": "Efficient Robust Training via Backward Smoothing",
    "abstract": "Comments: 12 pages, 15 tables, 6 figures. In AAAI 2022",
    "descriptor": "\nComments: 12 pages, 15 tables, 6 figures. In AAAI 2022\n",
    "authors": [
      "Jinghui Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Quanquan Gu",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01278"
  },
  {
    "id": "arXiv:2010.07370",
    "title": "A Comparison of Reduced-Order Modeling Approaches Using Artificial  Neural Networks for PDEs with Bifurcating Solutions",
    "abstract": "A Comparison of Reduced-Order Modeling Approaches Using Artificial  Neural Networks for PDEs with Bifurcating Solutions",
    "descriptor": "",
    "authors": [
      "Martin W. Hess",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.07370"
  },
  {
    "id": "arXiv:2011.09049",
    "title": "Incentives to Invite Others to Form Larger Coalitions",
    "abstract": "Comments: accepted at AAMAS 2022; a preview version",
    "descriptor": "\nComments: accepted at AAMAS 2022; a preview version\n",
    "authors": [
      "Yao Zhang",
      "Dengji Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.09049"
  },
  {
    "id": "arXiv:2011.11636",
    "title": "Blade Envelopes Part I: Concept and Methodology",
    "abstract": "Blade Envelopes Part I: Concept and Methodology",
    "descriptor": "",
    "authors": [
      "Chun Yui Wong",
      "Pranay Seshadri",
      "Ashley Scillitoe",
      "Andrew B. Duncan",
      "Geoffrey Parks"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.11636"
  },
  {
    "id": "arXiv:2012.03782",
    "title": "PCT-TEE: Trajectory-based Private Contact Tracing System with Trusted  Execution Environment",
    "abstract": "Comments: Accepted by ACM TSAS",
    "descriptor": "\nComments: Accepted by ACM TSAS\n",
    "authors": [
      "Fumiyuki Kato",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2012.03782"
  },
  {
    "id": "arXiv:2012.09856",
    "title": "Reconstructing Hand-Object Interactions in the Wild",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Zhe Cao",
      "Ilija Radosavovic",
      "Angjoo Kanazawa",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09856"
  },
  {
    "id": "arXiv:2012.10861",
    "title": "Memory AMP",
    "abstract": "Comments: 43 pages, 13 figures, submitted to IEEE Trans. on Information Theory for possible publication. [Memory AMP inherits the strengths of AMP and OAMP/VAMP such as low complexity, Bayes optimality and applicability to unitarily-inavariant matrices, while avoiding the weakness of AMP (e.g. limited to IID matrices) and OAMP/VAMP (e.g. needs high-complexity LMMSE).]",
    "descriptor": "\nComments: 43 pages, 13 figures, submitted to IEEE Trans. on Information Theory for possible publication. [Memory AMP inherits the strengths of AMP and OAMP/VAMP such as low complexity, Bayes optimality and applicability to unitarily-inavariant matrices, while avoiding the weakness of AMP (e.g. limited to IID matrices) and OAMP/VAMP (e.g. needs high-complexity LMMSE).]\n",
    "authors": [
      "Lei Liu",
      "Shunqi Huang",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2012.10861"
  },
  {
    "id": "arXiv:2012.15579",
    "title": "Blade Envelopes Part II: Multiple Objectives and Inverse Design",
    "abstract": "Blade Envelopes Part II: Multiple Objectives and Inverse Design",
    "descriptor": "",
    "authors": [
      "Chun Yui Wong",
      "Pranay Seshadri",
      "Ashley Scillitoe",
      "Bryn Noel Ubald",
      "Andrew B. Duncan",
      "Geoffrey Parks"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2012.15579"
  },
  {
    "id": "arXiv:2101.01041",
    "title": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity",
    "abstract": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity",
    "descriptor": "",
    "authors": [
      "Kaiqing Zhang",
      "Xiangyuan Zhang",
      "Bin Hu",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.01041"
  },
  {
    "id": "arXiv:2102.00654",
    "title": "Regionalized location obfuscation mechanism with personalized privacy  levels",
    "abstract": "Comments: 12 pages, 11 figures",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Shun Zhang",
      "Benfei Duan",
      "Zhili Chen",
      "Tianjiao Ni",
      "Hong Zhong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.00654"
  },
  {
    "id": "arXiv:2102.01451",
    "title": "Canonical scale separation in two-dimensional incompressible  hydrodynamics",
    "abstract": "Comments: 27 pages, 9 figures",
    "descriptor": "\nComments: 27 pages, 9 figures\n",
    "authors": [
      "Klas Modin",
      "Milo Viviani"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2102.01451"
  },
  {
    "id": "arXiv:2102.12834",
    "title": "On a Network SIS Epidemic Model with Cooperative and Antagonistic  Opinion Dynamics",
    "abstract": "On a Network SIS Epidemic Model with Cooperative and Antagonistic  Opinion Dynamics",
    "descriptor": "",
    "authors": [
      "Baike She",
      "Ji Liu",
      "Shreyas Sundaram",
      "Philip E. Par\u00e9"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.12834"
  },
  {
    "id": "arXiv:2103.01908",
    "title": "Structural Sparsity in Multiple Measurements",
    "abstract": "Comments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Florian Bo\u00dfmann",
      "Sara Krause-Solberg",
      "Johannes Maly",
      "Nada Sissouno"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.01908"
  },
  {
    "id": "arXiv:2103.08077",
    "title": "Distribution Privacy Under Function Recoverability",
    "abstract": "Distribution Privacy Under Function Recoverability",
    "descriptor": "",
    "authors": [
      "Ajaykrishnan Nageswaran",
      "Prakash Narayan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.08077"
  },
  {
    "id": "arXiv:2103.08250",
    "title": "Hierarchical forecasting with a top-down alignment of independent level  forecasts",
    "abstract": "Hierarchical forecasting with a top-down alignment of independent level  forecasts",
    "descriptor": "",
    "authors": [
      "Matthias Anderer",
      "Feng Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.08250"
  },
  {
    "id": "arXiv:2103.08263",
    "title": "Construction D' Lattices for Power-Constrained Communications",
    "abstract": "Comments: 13 pages, 6 figures, submitted to IEEE Transactions on Communications",
    "descriptor": "\nComments: 13 pages, 6 figures, submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Fan Zhou",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.08263"
  },
  {
    "id": "arXiv:2103.09523",
    "title": "A Universal LiDAR SLAM Accelerator System on Low-cost FPGA",
    "abstract": "A Universal LiDAR SLAM Accelerator System on Low-cost FPGA",
    "descriptor": "",
    "authors": [
      "Keisuke Sugiura",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2103.09523"
  },
  {
    "id": "arXiv:2103.10415",
    "title": "Refining Language Models with Compositional Explanations",
    "abstract": "Comments: Accepted to NeurIPS 2021. Camera-ready version. Code: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Camera-ready version. Code: this https URL\n",
    "authors": [
      "Huihan Yao",
      "Ying Chen",
      "Qinyuan Ye",
      "Xisen Jin",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10415"
  },
  {
    "id": "arXiv:2103.11569",
    "title": "Convex Parameterization and Optimization for Robust Tracking of a  Magnetically Levitated Planar Positioning System",
    "abstract": "Comments: 11 pages, 9 figures",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Jun Ma",
      "Zilong Cheng",
      "Haiyue Zhu",
      "Xiaocong Li",
      "Masayoshi Tomizuka",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.11569"
  },
  {
    "id": "arXiv:2103.12360",
    "title": "Discovering Emotion and Reasoning its Flip in Multi-Party Conversations  using Masked Memory Network and Transformer",
    "abstract": "Comments: Accepted in Knowledge-Based Systems; 34 pages, 4 figures, 15 tables",
    "descriptor": "\nComments: Accepted in Knowledge-Based Systems; 34 pages, 4 figures, 15 tables\n",
    "authors": [
      "Shivani Kumar",
      "Anubhav Shrimal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12360"
  },
  {
    "id": "arXiv:2103.12656",
    "title": "Replacing Rewards with Examples: Example-Based Policy Search via  Recursive Classification",
    "abstract": "Comments: NeurIPS 2021 (oral). Website with code, videos, and blog post: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 (oral). Website with code, videos, and blog post: this https URL\n",
    "authors": [
      "Benjamin Eysenbach",
      "Sergey Levine",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.12656"
  },
  {
    "id": "arXiv:2103.14847",
    "title": "Approval-Based Committee Voting under Incomplete Information",
    "abstract": "Approval-Based Committee Voting under Incomplete Information",
    "descriptor": "",
    "authors": [
      "Aviram Imber",
      "Jonas Israel",
      "Markus Brill",
      "Benny Kimelfeld"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.14847"
  },
  {
    "id": "arXiv:2103.15290",
    "title": "Transitional Learning: Exploring the Transition States of Degradation  for Blind Super-resolution",
    "abstract": "Comments: 16 pages, submitted to IEEE Transactions, code is available at github.com/YuanfeiHuang/TLSR",
    "descriptor": "\nComments: 16 pages, submitted to IEEE Transactions, code is available at github.com/YuanfeiHuang/TLSR\n",
    "authors": [
      "Yuanfei Huang",
      "Jie Li",
      "Yanting Hu",
      "Xinbo Gao",
      "Hua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15290"
  },
  {
    "id": "arXiv:2104.02709",
    "title": "Adaptive Variants of Optimal Feedback Policies",
    "abstract": "Comments: Major revision. New theoretical results tested on mountain car domain",
    "descriptor": "\nComments: Major revision. New theoretical results tested on mountain car domain\n",
    "authors": [
      "Brett T. Lopez",
      "Jean-Jacques E. Slotine"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.02709"
  },
  {
    "id": "arXiv:2104.03043",
    "title": "Two-Stage Robust Optimization Problems with Two-Stage Uncertainty",
    "abstract": "Two-Stage Robust Optimization Problems with Two-Stage Uncertainty",
    "descriptor": "",
    "authors": [
      "Marc Goerigk",
      "Stefan Lendl",
      "Lasse Wulf"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.03043"
  },
  {
    "id": "arXiv:2104.04925",
    "title": "MPPI-VS: Sampling-Based Model Predictive Control Strategy for  Constrained Image-Based and Position-Based Visual Servoing",
    "abstract": "Comments: 16 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: 16 pages, 12 figures, 3 tables\n",
    "authors": [
      "Ihab S. Mohamed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.04925"
  },
  {
    "id": "arXiv:2104.06125",
    "title": "IRS-aided MIMO Systems over Double-scattering Channels: Impact of  Channel Rank Deficiency",
    "abstract": "Comments: This paper has been accepted to IEEE Wireless Communications and Networking Conference, Austin, TX, USA, Apr. 2022",
    "descriptor": "\nComments: This paper has been accepted to IEEE Wireless Communications and Networking Conference, Austin, TX, USA, Apr. 2022\n",
    "authors": [
      "Xin Zhang",
      "Xianghao Yu",
      "S.H. Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.06125"
  },
  {
    "id": "arXiv:2104.09366",
    "title": "Simple Type Theory is not too Simple: Grothendieck's Schemes without  Dependent Types",
    "abstract": "Comments: Our code can be found in the Archive of Formal Proofs, see this https URL",
    "descriptor": "\nComments: Our code can be found in the Archive of Formal Proofs, see this https URL\n",
    "authors": [
      "Anthony Bordg",
      "Lawrence Paulson",
      "Wenda Li"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.09366"
  },
  {
    "id": "arXiv:2104.12678",
    "title": "Semi-Decentralized Federated Edge Learning for Fast Convergence on  Non-IID Data",
    "abstract": "Semi-Decentralized Federated Edge Learning for Fast Convergence on  Non-IID Data",
    "descriptor": "",
    "authors": [
      "Yuchang Sun",
      "Jiawei Shao",
      "Yuyi Mao",
      "Jessie Hui Wang",
      "Jun Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12678"
  },
  {
    "id": "arXiv:2104.13739",
    "title": "Linear Additives",
    "abstract": "Comments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305",
    "descriptor": "\nComments: In Proceedings Linearity&TLLA 2020, arXiv:2112.14305\n",
    "authors": [
      "Gianluca Curzi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.13739"
  },
  {
    "id": "arXiv:2105.01893",
    "title": "Full-Sentence Models Perform Better in Simultaneous Translation Using  the Information Enhanced Decoding Strategy",
    "abstract": "Comments: This paper was published out of a shallow and simple idea. Now I find that the research is still not detailed enough. So I submit withdrawal",
    "descriptor": "\nComments: This paper was published out of a shallow and simple idea. Now I find that the research is still not detailed enough. So I submit withdrawal\n",
    "authors": [
      "Zhengxin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.01893"
  },
  {
    "id": "arXiv:2105.04976",
    "title": "Designing an Automatic Agent for Repeated Language based Persuasion  Games",
    "abstract": "Comments: Accepted for TACL in December 2021",
    "descriptor": "\nComments: Accepted for TACL in December 2021\n",
    "authors": [
      "Maya Raifer",
      "Guy Rotman",
      "Reut Apel",
      "Moshe Tennenholtz",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04976"
  },
  {
    "id": "arXiv:2105.07085",
    "title": "MutualNet: Adaptive ConvNet via Mutual Learning from Different Model  Configurations",
    "abstract": "Comments: Extended version of arXiv:1909.12978. Updated analyses and results. Accepted to TPAMI",
    "descriptor": "\nComments: Extended version of arXiv:1909.12978. Updated analyses and results. Accepted to TPAMI\n",
    "authors": [
      "Taojiannan Yang",
      "Sijie Zhu",
      "Matias Mendieta",
      "Pu Wang",
      "Ravikumar Balakrishnan",
      "Minwoo Lee",
      "Tao Han",
      "Mubarak Shah",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07085"
  },
  {
    "id": "arXiv:2105.09497",
    "title": "Bayesian Calibration for Large-Scale Fluid Structure Interaction  Problems Under Embedded/Immersed Boundary Framework",
    "abstract": "Comments: 24pages, 14 figures",
    "descriptor": "\nComments: 24pages, 14 figures\n",
    "authors": [
      "Shunxiang Cao",
      "Daniel Zhengyu Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.09497"
  },
  {
    "id": "arXiv:2105.10066",
    "title": "A GAN-Like Approach for Physics-Based Imitation Learning and Interactive  Character Control",
    "abstract": "Comments: Proceedings of the 20th ACM SIGGRAPH/Eurographics Symposium on Computer Animation. Project webpage: this https URL",
    "descriptor": "\nComments: Proceedings of the 20th ACM SIGGRAPH/Eurographics Symposium on Computer Animation. Project webpage: this https URL\n",
    "authors": [
      "Pei Xu",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10066"
  },
  {
    "id": "arXiv:2105.10766",
    "title": "Embedding Information onto a Dynamical System",
    "abstract": "Embedding Information onto a Dynamical System",
    "descriptor": "",
    "authors": [
      "G Manjunath"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10766"
  },
  {
    "id": "arXiv:2105.11082",
    "title": "Simplifying Software Defect Prediction (via the \"early bird\" Heuristic)",
    "abstract": "Comments: 41 pages (Under Review)",
    "descriptor": "\nComments: 41 pages (Under Review)\n",
    "authors": [
      "N.C. Shrikanth",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11082"
  },
  {
    "id": "arXiv:2105.12723",
    "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and  Interpretable Visual Understanding",
    "abstract": "Comments: AAAI2022",
    "descriptor": "\nComments: AAAI2022\n",
    "authors": [
      "Zizhao Zhang",
      "Han Zhang",
      "Long Zhao",
      "Ting Chen",
      "Sercan O. Arik",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12723"
  },
  {
    "id": "arXiv:2105.13484",
    "title": "High-Order Multirate Explicit Time-Stepping Schemes for the  Baroclinic-Barotropic Split Dynamics in Primitive Equations",
    "abstract": "High-Order Multirate Explicit Time-Stepping Schemes for the  Baroclinic-Barotropic Split Dynamics in Primitive Equations",
    "descriptor": "",
    "authors": [
      "Rihui Lan",
      "Lili Ju",
      "Zhu Wang",
      "Max Gunzburger",
      "Philip Jones"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13484"
  },
  {
    "id": "arXiv:2105.14633",
    "title": "A learning-based projection method for model order reduction of  transport problems",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Zhichao Peng",
      "Min Wang",
      "Fengyan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14633"
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: Attack by Multi-Identity Surrogates",
    "abstract": "Comments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks",
    "descriptor": "\nComments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks\n",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.15010"
  },
  {
    "id": "arXiv:2106.00168",
    "title": "Rethinking Pseudo Labels for Semi-Supervised Object Detection",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Hengduo Li",
      "Zuxuan Wu",
      "Abhinav Shrivastava",
      "Larry S. Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00168"
  },
  {
    "id": "arXiv:2106.05124",
    "title": "PCNet: A Structure Similarity Enhancement Method for Multispectral and  Multimodal Image Registration",
    "abstract": "Comments: 14 pages, 16 figures",
    "descriptor": "\nComments: 14 pages, 16 figures\n",
    "authors": [
      "Si-Yuan Cao",
      "Hui-Liang Shen",
      "Lun Luo",
      "Shu-Jie Chen",
      "Chunguang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05124"
  },
  {
    "id": "arXiv:2106.05642",
    "title": "U2++: Unified Two-pass Bidirectional End-to-end Model for Speech  Recognition",
    "abstract": "U2++: Unified Two-pass Bidirectional End-to-end Model for Speech  Recognition",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Binbin Zhang",
      "Chao Yang",
      "Zhendong Peng",
      "Wenjing Xia",
      "Xiaoyu Chen",
      "Xin Lei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.05642"
  },
  {
    "id": "arXiv:2106.11612",
    "title": "Uniform-PAC Bounds for Reinforcement Learning with Linear Function  Approximation",
    "abstract": "Comments: 27 pages. In NeurIPS 2021",
    "descriptor": "\nComments: 27 pages. In NeurIPS 2021\n",
    "authors": [
      "Jiafan He",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11612"
  },
  {
    "id": "arXiv:2106.11644",
    "title": "NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial  Perturbations",
    "abstract": "Comments: Preprint version",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Sungmin Cha",
      "Naeun Ko",
      "Youngjoon Yoo",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11644"
  },
  {
    "id": "arXiv:2106.11888",
    "title": "Notes on the H-measure of classifier performance",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "D. J. Hand",
      "C. Anagnostopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11888"
  },
  {
    "id": "arXiv:2106.12331",
    "title": "Optimal Transmission Switching Problem Solving:Parallelization and  Benchmarks",
    "abstract": "Optimal Transmission Switching Problem Solving:Parallelization and  Benchmarks",
    "descriptor": "",
    "authors": [
      "Anton Hinneck",
      "David Pozo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12331"
  },
  {
    "id": "arXiv:2106.13543",
    "title": "Louvain-like Methods for Community Detection in Multiplex Networks",
    "abstract": "Louvain-like Methods for Community Detection in Multiplex Networks",
    "descriptor": "",
    "authors": [
      "Sara Venturini",
      "Andrea Cristofari",
      "Francesco Rinaldi",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13543"
  },
  {
    "id": "arXiv:2106.16026",
    "title": "High-order finite element methods for nonlinear convection-diffusion  equation on time-varying domain",
    "abstract": "High-order finite element methods for nonlinear convection-diffusion  equation on time-varying domain",
    "descriptor": "",
    "authors": [
      "Chuwen Ma",
      "Weiying Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.16026"
  },
  {
    "id": "arXiv:2107.01125",
    "title": "On Measuring and Controlling the Spectral Bias of the Deep Image Prior",
    "abstract": "Comments: IJCV 2022; Spectral bias; Deep image prior; 24 pages",
    "descriptor": "\nComments: IJCV 2022; Spectral bias; Deep image prior; 24 pages\n",
    "authors": [
      "Zenglin Shi",
      "Pascal Mettes",
      "Subhransu Maji",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01125"
  },
  {
    "id": "arXiv:2107.01153",
    "title": "A Survey on Deep Learning Technique for Video Segmentation",
    "abstract": "Comments: Website: this https URL",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Wenguan Wang",
      "Tianfei Zhou",
      "Fatih Porikli",
      "David Crandall",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01153"
  },
  {
    "id": "arXiv:2107.03439",
    "title": "The Risk of Hidden Failures to the United States Electrical Grid and  Potential for Mitigation",
    "abstract": "Comments: 6 pages. 7 figures",
    "descriptor": "\nComments: 6 pages. 7 figures\n",
    "authors": [
      "Arthur K. Barnes",
      "Adam Mate",
      "Jose E. Tabarez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.03439"
  },
  {
    "id": "arXiv:2107.04094",
    "title": "Robust Control Barrier Functions under High Relative Degree and Input  Constraints for Satellite Trajectories",
    "abstract": "Comments: 19 pages, extended version. Submitted to Automatica, v2",
    "descriptor": "\nComments: 19 pages, extended version. Submitted to Automatica, v2\n",
    "authors": [
      "Joseph Breeden",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.04094"
  },
  {
    "id": "arXiv:2107.07964",
    "title": "Blockchain Technology: Bitcoins, Cryptocurrency and Applications",
    "abstract": "Comments: 7 Pages, 4 Figures",
    "descriptor": "\nComments: 7 Pages, 4 Figures\n",
    "authors": [
      "Bosubabu Sambana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07964"
  },
  {
    "id": "arXiv:2107.11648",
    "title": "Fair Allocation with Interval Scheduling Constraints",
    "abstract": "Comments: To appear in Neurips 2021",
    "descriptor": "\nComments: To appear in Neurips 2021\n",
    "authors": [
      "Bo Li",
      "Minming Li",
      "Ruilong Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.11648"
  },
  {
    "id": "arXiv:2107.11960",
    "title": "Temporal Alignment Prediction for Few-Shot Video Classification",
    "abstract": "Temporal Alignment Prediction for Few-Shot Video Classification",
    "descriptor": "",
    "authors": [
      "Fei Pan",
      "Chunlei Xu",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11960"
  },
  {
    "id": "arXiv:2107.12375",
    "title": "Geometric Deep Learning on Molecular Representations",
    "abstract": "Geometric Deep Learning on Molecular Representations",
    "descriptor": "",
    "authors": [
      "Kenneth Atz",
      "Francesca Grisoni",
      "Gisbert Schneider"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2107.12375"
  },
  {
    "id": "arXiv:2107.12854",
    "title": "Audio-to-Score Alignment Using Deep Automatic Music Transcription",
    "abstract": "Comments: IEEE MMSP 2021 - ERRATUM",
    "descriptor": "\nComments: IEEE MMSP 2021 - ERRATUM\n",
    "authors": [
      "Federico Simonetta",
      "Stavros Ntalampiras",
      "Federico Avanzini"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.12854"
  },
  {
    "id": "arXiv:2108.05322",
    "title": "Mathematical modelling and virtual decomposition control of heavy-duty  parallel$-$serial hydraulic manipulators",
    "abstract": "Comments: 30 pages, 11 figures",
    "descriptor": "\nComments: 30 pages, 11 figures\n",
    "authors": [
      "Goran R. Petrovi\u0107",
      "Jouni Mattila"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.05322"
  },
  {
    "id": "arXiv:2108.06201",
    "title": "Data-driven advice for interpreting local and global model predictions  in bioinformatics problems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2003.12043. text overlap with arXiv:1905.04610 by other authors",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.12043. text overlap with arXiv:1905.04610 by other authors\n",
    "authors": [
      "Markus Loecher",
      "Qi Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.06201"
  },
  {
    "id": "arXiv:2108.06585",
    "title": "Relaxation Based Modeling of GMD Induced Cascading Failures in  PowerModelsGMD.jl",
    "abstract": "Comments: 7 pages. 5 figures. 3 tables",
    "descriptor": "\nComments: 7 pages. 5 figures. 3 tables\n",
    "authors": [
      "Adam Mate",
      "Arthur K. Barnes",
      "Steven K. Morley",
      "Jacob A. Friz-Trillo",
      "Eduardo Cotilla-Sanchez",
      "Sean P. Blake"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.06585"
  },
  {
    "id": "arXiv:2108.07761",
    "title": "VisBuddy -- A Smart Wearable Assistant for the Visually Challenged",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ishwarya Sivakumar",
      "Nishaali Meenakshisundaram",
      "Ishwarya Ramesh",
      "Shiloah Elizabeth D",
      "Sunil Retmin Raj C"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07761"
  },
  {
    "id": "arXiv:2109.01183",
    "title": "roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs",
    "abstract": "roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs",
    "descriptor": "",
    "authors": [
      "Arnav Vaibhav Malawade",
      "Shih-Yuan Yu",
      "Brandon Hsu",
      "Harsimrat Kaeley",
      "Anurag Karra",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01183"
  },
  {
    "id": "arXiv:2109.01817",
    "title": "Low SNR Capacity of Keyhole MIMO Channel in Nakagami-m Fading With Full  CSI",
    "abstract": "Low SNR Capacity of Keyhole MIMO Channel in Nakagami-m Fading With Full  CSI",
    "descriptor": "",
    "authors": [
      "Kamal Singh",
      "Chandradeep Singh",
      "Chia-Hsiang Lin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.01817"
  },
  {
    "id": "arXiv:2109.03159",
    "title": "Analysis of Regularized Learning in Banach Spaces",
    "abstract": "Comments: 32 pages, 1 figure",
    "descriptor": "\nComments: 32 pages, 1 figure\n",
    "authors": [
      "Qi Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.03159"
  },
  {
    "id": "arXiv:2109.04266",
    "title": "An objective function for order preserving hierarchical clustering",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Daniel Bakkelund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.04266"
  },
  {
    "id": "arXiv:2109.04453",
    "title": "Tube-Certified Trajectory Tracking for Nonlinear Systems With Robust  Control Contraction Metrics",
    "abstract": "Comments: Shorter version submitted to IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Shorter version submitted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Pan Zhao",
      "Arun Lakshmanan",
      "Kasey Ackerman",
      "Aditya Gahlawat",
      "Marco Pavone",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04453"
  },
  {
    "id": "arXiv:2109.04791",
    "title": "ANTASID: A Novel Temporal Adjustment to Shannon's Index of Difficulty  for Quantifying the Perceived Difficulty of Uncontrolled Pointing Tasks",
    "abstract": "Comments: 14 pages, 7 figures, 7 tables",
    "descriptor": "\nComments: 14 pages, 7 figures, 7 tables\n",
    "authors": [
      "Mohammad Ridwan Kabir",
      "Mohammad Ishrak Abedin",
      "Rizvi Ahmed",
      "Hasan Mahmud",
      "Md. Kamrul Hasan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04791"
  },
  {
    "id": "arXiv:2109.07548",
    "title": "Learning the Regularization in DCE-MR Image Reconstruction for  Functional Imaging of Kidneys",
    "abstract": "Learning the Regularization in DCE-MR Image Reconstruction for  Functional Imaging of Kidneys",
    "descriptor": "",
    "authors": [
      "Aziz Ko\u00e7anao\u011fullar\u0131",
      "Cemre Ariyurek",
      "Onur Afacan",
      "Sila Kurugol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07548"
  },
  {
    "id": "arXiv:2109.10523",
    "title": "Investigating and Modeling the Dynamics of Long Ties",
    "abstract": "Comments: 54 pages, 23 figures",
    "descriptor": "\nComments: 54 pages, 23 figures\n",
    "authors": [
      "Ding Lyu",
      "Yuan Yuan",
      "Lin Wang",
      "Xiaofan Wang",
      "Alex Pentland"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.10523"
  },
  {
    "id": "arXiv:2109.10563",
    "title": "Improving 360 Monocular Depth Estimation via Non-local Dense Prediction  Transformer and Joint Supervised and Self-supervised Learning",
    "abstract": "Comments: 14 pages, Accepted to AAAI22, conference preprint version",
    "descriptor": "\nComments: 14 pages, Accepted to AAAI22, conference preprint version\n",
    "authors": [
      "Ilwi Yun",
      "Hyuk-Jae Lee",
      "Chae Eun Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10563"
  },
  {
    "id": "arXiv:2109.12271",
    "title": "BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor  Segmentation",
    "abstract": "Comments: Accepted by MICCAI BrainLes 2021",
    "descriptor": "\nComments: Accepted by MICCAI BrainLes 2021\n",
    "authors": [
      "Qiran Jia",
      "Hai Shu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12271"
  },
  {
    "id": "arXiv:2109.12409",
    "title": "Motivating Learners in Multi-Orchestrator Mobile Edge Learning: A  Stackelberg Game Approach",
    "abstract": "Motivating Learners in Multi-Orchestrator Mobile Edge Learning: A  Stackelberg Game Approach",
    "descriptor": "",
    "authors": [
      "Mhd Saria Allahham",
      "Sameh Sorour",
      "Amr Mohamed",
      "Aiman Erbad",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.12409"
  },
  {
    "id": "arXiv:2109.13811",
    "title": "An Efficient Epileptic Seizure Detection Technique using Discrete  Wavelet Transform and Machine Learning Classifiers",
    "abstract": "Comments: Accepted in International Conference on Smart Technologies for Sustainable Development (ICSTSD2021)",
    "descriptor": "\nComments: Accepted in International Conference on Smart Technologies for Sustainable Development (ICSTSD2021)\n",
    "authors": [
      "Rabel Guharoy",
      "Nanda Dulal Jana",
      "Suparna Biswas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13811"
  },
  {
    "id": "arXiv:2110.01440",
    "title": "Some Statistic and Information-theoretic Results on Arithmetic Average  Density Fusion",
    "abstract": "Comments: 11 pages, 11 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 11 figures, 2 tables\n",
    "authors": [
      "Tiancheng Li",
      "Yue Xin",
      "Yan Song",
      "Enbin Song",
      "Hongqi Fan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.01440"
  },
  {
    "id": "arXiv:2110.05977",
    "title": "Datasets are not Enough: Challenges in Labeling Network Traffic",
    "abstract": "Datasets are not Enough: Challenges in Labeling Network Traffic",
    "descriptor": "",
    "authors": [
      "Jorge Guerra",
      "Carlos Catania",
      "Eduardo Veas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05977"
  },
  {
    "id": "arXiv:2110.06394",
    "title": "Reward-Free Model-Based Reinforcement Learning with Linear Function  Approximation",
    "abstract": "Comments: 29 pages, 1 figure, 1 table. In NeurIPS 2021",
    "descriptor": "\nComments: 29 pages, 1 figure, 1 table. In NeurIPS 2021\n",
    "authors": [
      "Weitong Zhang",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06394"
  },
  {
    "id": "arXiv:2110.08012",
    "title": "A Survey on State-of-the-art Techniques for Knowledge Graphs  Construction and Challenges ahead",
    "abstract": "A Survey on State-of-the-art Techniques for Knowledge Graphs  Construction and Challenges ahead",
    "descriptor": "",
    "authors": [
      "Ali Hur",
      "Naeem Janjua",
      "Mohiuddin Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08012"
  },
  {
    "id": "arXiv:2110.09344",
    "title": "ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification",
    "abstract": "ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification",
    "descriptor": "",
    "authors": [
      "Hongyu Guo",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09344"
  },
  {
    "id": "arXiv:2110.10790",
    "title": "Human-Centered Explainable AI (XAI): From Algorithms to User Experiences",
    "abstract": "Comments: draft for a book chapter",
    "descriptor": "\nComments: draft for a book chapter\n",
    "authors": [
      "Q. Vera Liao",
      "Kush R. Varshney"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10790"
  },
  {
    "id": "arXiv:2110.15557",
    "title": "Crowd-sensing Enhanced Parking Patrol using Trajectories of Sharing  Bikes",
    "abstract": "Crowd-sensing Enhanced Parking Patrol using Trajectories of Sharing  Bikes",
    "descriptor": "",
    "authors": [
      "Tianfu He",
      "Jie Bao",
      "Yexin Li",
      "Hui He",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15557"
  },
  {
    "id": "arXiv:2111.01201",
    "title": "Unintended Selection: Persistent Qualification Rate Disparities and  Interventions",
    "abstract": "Comments: 39 pages, 10 figures, to be published in the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 39 pages, 10 figures, to be published in the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Reilly Raab",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01201"
  },
  {
    "id": "arXiv:2111.02434",
    "title": "Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling",
    "abstract": "Comments: 31 pages, 19 figures. Advances in Neural Information Processing Systems (NeurIPS), 2021. Animations at this https URL, code at this https URL",
    "descriptor": "\nComments: 31 pages, 19 figures. Advances in Neural Information Processing Systems (NeurIPS), 2021. Animations at this https URL, code at this https URL\n",
    "authors": [
      "Greg Ver Steeg",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02434"
  },
  {
    "id": "arXiv:2111.03048",
    "title": "Imagine Networks",
    "abstract": "Comments: This paper is the part of the artificial association neural networks series we are studying",
    "descriptor": "\nComments: This paper is the part of the artificial association neural networks series we are studying\n",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.03048"
  },
  {
    "id": "arXiv:2111.04870",
    "title": "A toolkit for data-driven discovery of governing equations in high-noise  regimes",
    "abstract": "Comments: Body 21 pages. Total length with Appendix 32 pages. 17 Figures, 8 Tables",
    "descriptor": "\nComments: Body 21 pages. Total length with Appendix 32 pages. 17 Figures, 8 Tables\n",
    "authors": [
      "Charles B. Delahunt",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04870"
  },
  {
    "id": "arXiv:2111.06521",
    "title": "Refinement for community structures of bipartite networks",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Sang Hoon Lee"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.06521"
  },
  {
    "id": "arXiv:2111.08629",
    "title": "Communication by means of Modulated Johnson Noise",
    "abstract": "Communication by means of Modulated Johnson Noise",
    "descriptor": "",
    "authors": [
      "Zerina Kapetanovic",
      "Joshua R. Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08629"
  },
  {
    "id": "arXiv:2111.08878",
    "title": "CONFAIR: Configurable and Interpretable Algorithmic Fairness",
    "abstract": "Comments: Updated Algorithm name, removed redundant mentions",
    "descriptor": "\nComments: Updated Algorithm name, removed redundant mentions\n",
    "authors": [
      "Ankit Kulshrestha",
      "Ilya Safro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.08878"
  },
  {
    "id": "arXiv:2111.08888",
    "title": "Random Graph-Based Neuromorphic Learning with a Layer-Weaken Structure",
    "abstract": "Random Graph-Based Neuromorphic Learning with a Layer-Weaken Structure",
    "descriptor": "",
    "authors": [
      "Ruiqi Mao",
      "Rongxin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.08888"
  },
  {
    "id": "arXiv:2111.08897",
    "title": "ARKitScenes -- A Diverse Real-World Dataset For 3D Indoor Scene  Understanding Using Mobile RGB-D Data",
    "abstract": "ARKitScenes -- A Diverse Real-World Dataset For 3D Indoor Scene  Understanding Using Mobile RGB-D Data",
    "descriptor": "",
    "authors": [
      "Gilad Baruch",
      "Zhuoyuan Chen",
      "Afshin Dehghan",
      "Tal Dimry",
      "Yuri Feigin",
      "Peter Fu",
      "Thomas Gebauer",
      "Brandon Joffe",
      "Daniel Kurz",
      "Arik Schwartz",
      "Elad Shulman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08897"
  },
  {
    "id": "arXiv:2111.09547",
    "title": "QGTC: Accelerating Quantized Graph Neural Networks via GPU Tensor Core",
    "abstract": "QGTC: Accelerating Quantized Graph Neural Networks via GPU Tensor Core",
    "descriptor": "",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Yufei Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.09547"
  },
  {
    "id": "arXiv:2111.11190",
    "title": "The EOSC-Synergy cloud services implementation for the Latin American  Giant Observatory (LAGO)",
    "abstract": "Comments: [30Dic21. No changes in the paper. Corrected mistake in ArXiv' metadata: swapping given name order: Juan Antonio Rubio-Montero -&gt; Antonio Juan Rubio-Montero]",
    "descriptor": "\nComments: [30Dic21. No changes in the paper. Corrected mistake in ArXiv' metadata: swapping given name order: Juan Antonio Rubio-Montero -&gt; Antonio Juan Rubio-Montero]\n",
    "authors": [
      "Antonio Juan Rubio-Montero",
      "Ra\u00fal Pag\u00e1n-Mu\u00f1oz",
      "Rafael Mayo-Garc\u00eda",
      "Alfonso Pardo-Diaz",
      "Iv\u00e1n Sidelnik",
      "Hern\u00e1n Asorey"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.11190"
  },
  {
    "id": "arXiv:2111.12933",
    "title": "ML-Decoder: Scalable and Versatile Classification Head",
    "abstract": "ML-Decoder: Scalable and Versatile Classification Head",
    "descriptor": "",
    "authors": [
      "Tal Ridnik",
      "Gilad Sharir",
      "Avi Ben-Cohen",
      "Emanuel Ben-Baruch",
      "Asaf Noy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12933"
  },
  {
    "id": "arXiv:2111.13208",
    "title": "Evaluation of Interpretability for Deep Learning algorithms in EEG  Emotion Recognition: A case study in Autism",
    "abstract": "Evaluation of Interpretability for Deep Learning algorithms in EEG  Emotion Recognition: A case study in Autism",
    "descriptor": "",
    "authors": [
      "Juan Manuel Mayor-Torres",
      "Sara Medina-DeVilliers",
      "Tessa Clarkson",
      "Matthew D. Lerner",
      "Giuseppe Riccardi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13208"
  },
  {
    "id": "arXiv:2111.15645",
    "title": "Survey Descent: A Multipoint Generalization of Gradient Descent for  Nonsmooth Optimization",
    "abstract": "Survey Descent: A Multipoint Generalization of Gradient Descent for  Nonsmooth Optimization",
    "descriptor": "",
    "authors": [
      "X.Y. Han",
      "Adrian S. Lewis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15645"
  },
  {
    "id": "arXiv:2112.00124",
    "title": "CryoCiM: Cryogenic Compute-in-Memory based on the Quantum Anomalous Hall  Effect",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Shamiul Alam",
      "Md Mazharul Islam",
      "Md Shafayat Hossain",
      "Akhilesh Jaiswal",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00124"
  },
  {
    "id": "arXiv:2112.01177",
    "title": "MutualFormer: Multi-Modality Representation Learning via Mutual  Transformer",
    "abstract": "MutualFormer: Multi-Modality Representation Learning via Mutual  Transformer",
    "descriptor": "",
    "authors": [
      "Xixi Wang",
      "Bo Jiang",
      "Xiao Wang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01177"
  },
  {
    "id": "arXiv:2112.02498",
    "title": "Consistent Training and Decoding For End-to-end Speech Recognition Using  Lattice-free MMI",
    "abstract": "Consistent Training and Decoding For End-to-end Speech Recognition Using  Lattice-free MMI",
    "descriptor": "",
    "authors": [
      "Jinchuan Tian",
      "Jianwei Yu",
      "Chao Weng",
      "Shi-Xiong Zhang",
      "Dan Su",
      "Dong Yu",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.02498"
  },
  {
    "id": "arXiv:2112.02545",
    "title": "New Properties and Invariants of Harmonic Polygons",
    "abstract": "Comments: 18 pages, 9 figures, 3 tables, 8 videos",
    "descriptor": "\nComments: 18 pages, 9 figures, 3 tables, 8 videos\n",
    "authors": [
      "Ronaldo Garcia",
      "Dan Reznik",
      "Pedro Roitman"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.02545"
  },
  {
    "id": "arXiv:2112.02719",
    "title": "A Survey on Deep learning based Document Image Enhancement",
    "abstract": "A Survey on Deep learning based Document Image Enhancement",
    "descriptor": "",
    "authors": [
      "Zahra Anvari",
      "Vassilis Athitsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02719"
  },
  {
    "id": "arXiv:2112.03665",
    "title": "Data-Driven Controllability Analysis and Stabilization for Linear  Descriptor Systems",
    "abstract": "Data-Driven Controllability Analysis and Stabilization for Linear  Descriptor Systems",
    "descriptor": "",
    "authors": [
      "Jiabao He",
      "Xuan Zhang",
      "Feng Xu",
      "Junbo Tan",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03665"
  },
  {
    "id": "arXiv:2112.04688",
    "title": "Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single  Lane Representations of Traffic",
    "abstract": "Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single  Lane Representations of Traffic",
    "descriptor": "",
    "authors": [
      "Abdul Rahman Kreidieh",
      "Yibo Zhao",
      "Samyak Parajuli",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04688"
  },
  {
    "id": "arXiv:2112.06596",
    "title": "SAC-GAN: Structure-Aware Image-to-Image Composition for Self-Driving",
    "abstract": "Comments: The co-authors of the paper are against publishing this before acceptance",
    "descriptor": "\nComments: The co-authors of the paper are against publishing this before acceptance\n",
    "authors": [
      "Hang Zhou",
      "Ali Mahdavi-Amiri",
      "Rui Ma",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06596"
  },
  {
    "id": "arXiv:2112.07068",
    "title": "Score-Based Generative Modeling with Critically-Damped Langevin  Diffusion",
    "abstract": "Score-Based Generative Modeling with Critically-Damped Langevin  Diffusion",
    "descriptor": "",
    "authors": [
      "Tim Dockhorn",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07068"
  },
  {
    "id": "arXiv:2112.07110",
    "title": "Non Asymptotic Bounds for Optimization via Online Multiplicative  Stochastic Gradient Descent",
    "abstract": "Non Asymptotic Bounds for Optimization via Online Multiplicative  Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Riddhiman Bhattacharya"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.07110"
  },
  {
    "id": "arXiv:2112.07918",
    "title": "M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search",
    "abstract": "M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search",
    "descriptor": "",
    "authors": [
      "Huiyu Kuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07918"
  },
  {
    "id": "arXiv:2112.09124",
    "title": "Sparse Euclidean Spanners with Tiny Diameter: A Tight Lower Bound",
    "abstract": "Sparse Euclidean Spanners with Tiny Diameter: A Tight Lower Bound",
    "descriptor": "",
    "authors": [
      "Hung Le",
      "Lazar Milenkovic",
      "Shay Solomon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.09124"
  },
  {
    "id": "arXiv:2112.10319",
    "title": "Tutorial on Asymptotic Properties of Regularized Least Squares Estimator  for Finite Impulse Response Model",
    "abstract": "Tutorial on Asymptotic Properties of Regularized Least Squares Estimator  for Finite Impulse Response Model",
    "descriptor": "",
    "authors": [
      "Yue Ju",
      "Tianshi Chen",
      "Biqiang Mu",
      "Lennart Ljung"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.10319"
  },
  {
    "id": "arXiv:2112.10970",
    "title": "On a deterministic particle-FEM discretization to micro-macro models of  dilute polymeric fluids",
    "abstract": "On a deterministic particle-FEM discretization to micro-macro models of  dilute polymeric fluids",
    "descriptor": "",
    "authors": [
      "Xuelian Bao",
      "Chun Liu",
      "Yiwei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.10970"
  },
  {
    "id": "arXiv:2112.11632",
    "title": "Diformer: Directional Transformer for Neural Machine Translation",
    "abstract": "Diformer: Directional Transformer for Neural Machine Translation",
    "descriptor": "",
    "authors": [
      "Minghan Wang",
      "Jiaxin Guo",
      "Yuxia Wang",
      "Daimeng Wei",
      "Hengchao Shang",
      "Chang Su",
      "Yimeng Chen",
      "Yinglu Li",
      "Min Zhang",
      "Shimin Tao",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.11632"
  },
  {
    "id": "arXiv:2112.11663",
    "title": "Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex  Minimax Machine Learning",
    "abstract": "Comments: 12 pages, 1 figure. arXiv admin note: text overlap with arXiv:2102.04653",
    "descriptor": "\nComments: 12 pages, 1 figure. arXiv admin note: text overlap with arXiv:2102.04653\n",
    "authors": [
      "Ziyi Chen",
      "Shaocong Ma",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.11663"
  },
  {
    "id": "arXiv:2112.11691",
    "title": "CLEVR3D: Compositional Language and Elementary Visual Reasoning for  Question Answering in 3D Real-World Scenes",
    "abstract": "CLEVR3D: Compositional Language and Elementary Visual Reasoning for  Question Answering in 3D Real-World Scenes",
    "descriptor": "",
    "authors": [
      "Xu Yan",
      "Zhihao Yuan",
      "Yuhao Du",
      "Yinghong Liao",
      "Yao Guo",
      "Zhen Li",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11691"
  },
  {
    "id": "arXiv:2112.11879",
    "title": "Lifting C Semantics for Dataflow Optimization",
    "abstract": "Lifting C Semantics for Dataflow Optimization",
    "descriptor": "",
    "authors": [
      "Alexandru Calotoiu",
      "Tal Ben-Nun",
      "Grzegorz Kwasniewski",
      "Johannes de Fine Licht",
      "Timo Schneider",
      "Philipp Schaad",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.11879"
  },
  {
    "id": "arXiv:2112.12134",
    "title": "A Unified Analysis Method for Online Optimization in Normed Vector Space",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Qing-xin Meng",
      "Jian-wei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.12134"
  },
  {
    "id": "arXiv:2112.12344",
    "title": "Learning multiple regularization parameters for generalized Tikhonov  regularization using multiple data sets without true data",
    "abstract": "Learning multiple regularization parameters for generalized Tikhonov  regularization using multiple data sets without true data",
    "descriptor": "",
    "authors": [
      "Michael J. Byrne",
      "Rosemary A. Renaut"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12344"
  },
  {
    "id": "arXiv:2112.12545",
    "title": "A Deep Reinforcement Learning Approach for Solving the Traveling  Salesman Problem with Drone",
    "abstract": "A Deep Reinforcement Learning Approach for Solving the Traveling  Salesman Problem with Drone",
    "descriptor": "",
    "authors": [
      "Aigerim Bogyrbayeva",
      "Taehyun Yoon",
      "Hanbum Ko",
      "Sungbin Lim",
      "Hyokun Yun",
      "Changhyun Kwon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12545"
  },
  {
    "id": "arXiv:2112.12833",
    "title": "Dense anomaly detection by robust learning on synthetic negative data",
    "abstract": "Dense anomaly detection by robust learning on synthetic negative data",
    "descriptor": "",
    "authors": [
      "Matej Grci\u0107",
      "Petra Bevandi\u0107",
      "Zoran Kalafati\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12833"
  },
  {
    "id": "arXiv:2112.12961",
    "title": "Optimal Model Averaging of Support Vector Machines in Diverging Model  Spaces",
    "abstract": "Comments: On page 7 of the paper, the condition description has some problems and needs to be revised",
    "descriptor": "\nComments: On page 7 of the paper, the condition description has some problems and needs to be revised\n",
    "authors": [
      "Chaoxia Yuan",
      "Chao Ying",
      "Zhou Yu",
      "Fang Fang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12961"
  },
  {
    "id": "arXiv:2112.12970",
    "title": "SGTR: End-to-end Scene Graph Generation with Transformer",
    "abstract": "SGTR: End-to-end Scene Graph Generation with Transformer",
    "descriptor": "",
    "authors": [
      "Rongjie Li",
      "Songyang Zhang",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12970"
  },
  {
    "id": "arXiv:2112.13378",
    "title": "A lowest-order locking-free nonconforming virtual element method based  on the reduced integration technique for linear elasticity problems",
    "abstract": "Comments: vem",
    "descriptor": "\nComments: vem\n",
    "authors": [
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.13378"
  },
  {
    "id": "arXiv:2112.13848",
    "title": "A lowest-order locking-free conforming virtual element method based on  the reduced integration technique for linear elasticity problems",
    "abstract": "Comments: Some mistakes in the proof",
    "descriptor": "\nComments: Some mistakes in the proof\n",
    "authors": [
      "Jianguo Huang",
      "Sen Lin",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.13848"
  },
  {
    "id": "arXiv:2112.13889",
    "title": "Human View Synthesis using a Single Sparse RGB-D Input",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Phong Nguyen",
      "Nikolaos Sarafianos",
      "Christoph Lassner",
      "Janne Heikkila",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.13889"
  },
  {
    "id": "arXiv:2112.13901",
    "title": "Expected hypervolume improvement for simultaneous multi-objective and  multi-fidelity optimization",
    "abstract": "Expected hypervolume improvement for simultaneous multi-objective and  multi-fidelity optimization",
    "descriptor": "",
    "authors": [
      "Faran Irshad",
      "Stefan Karsch",
      "Andreas D\u00f6pp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Accelerator Physics (physics.acc-ph)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.13901"
  },
  {
    "id": "arXiv:2112.14024",
    "title": "Unsourced Random Massive Access with Beam-Space Tree Decoding",
    "abstract": "Comments: Accepted by IEEE JSAC special issue on Next Generation Multiple Access",
    "descriptor": "\nComments: Accepted by IEEE JSAC special issue on Next Generation Multiple Access\n",
    "authors": [
      "Jingze Che",
      "Zhaoyang Zhang",
      "Zhaohui Yang",
      "Xiaoming Chen",
      "Caijun Zhong",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.14024"
  },
  {
    "id": "arXiv:2112.14075",
    "title": "Financial Vision Based Differential Privacy Applications",
    "abstract": "Comments: 11 pages, 10 figures",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Jun-Hao Chen",
      "Yi-Jen Wang",
      "Yun-Cheng Tsai",
      "Samuel Yen-Chi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14075"
  },
  {
    "id": "arXiv:2112.14206",
    "title": "A survey on product codes and 2-D codes",
    "abstract": "Comments: 40 pages, typos corrected, references added. arXiv admin note: text overlap with arXiv:1512.06690, arXiv:1505.02238, arXiv:1301.6231 by other authors",
    "descriptor": "\nComments: 40 pages, typos corrected, references added. arXiv admin note: text overlap with arXiv:1512.06690, arXiv:1505.02238, arXiv:1301.6231 by other authors\n",
    "authors": [
      "Amajit Sarma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.14206"
  },
  {
    "id": "arXiv:2112.14278",
    "title": "Beta-VAE Reproducibility: Challenges and Extensions",
    "abstract": "Beta-VAE Reproducibility: Challenges and Extensions",
    "descriptor": "",
    "authors": [
      "Miroslav Fil",
      "Munib Mesinovic",
      "Matthew Morris",
      "Jonas Wildberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14278"
  },
  {
    "id": "arXiv:2112.14387",
    "title": "Training Time Minimization for Federated Edge Learning with Optimized  Gradient Quantization and Bandwidth Allocation",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Peixi Liu",
      "Jiamo Jiang",
      "Guangxu Zhu",
      "Lei Cheng",
      "Wei Jiang",
      "Wu Luo",
      "Ying Du",
      "Zhiqin Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.14387"
  },
  {
    "id": "arXiv:2112.14417",
    "title": "Control Theoretic Analysis of Temporal Difference Learning",
    "abstract": "Control Theoretic Analysis of Temporal Difference Learning",
    "descriptor": "",
    "authors": [
      "Donghwan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14417"
  },
  {
    "id": "arXiv:2112.14446",
    "title": "How Powerful are Interest Diffusion on Purchasing Prediction: A Case  Study of Taocode",
    "abstract": "How Powerful are Interest Diffusion on Purchasing Prediction: A Case  Study of Taocode",
    "descriptor": "",
    "authors": [
      "Xuanwen Huang",
      "Yang Yang",
      "Ziqiang Cheng",
      "Shen Fan",
      "Zhongyao Wang",
      "Juren Li",
      "Jun Zhang",
      "Jingmin Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.14446"
  },
  {
    "id": "arXiv:2112.14663",
    "title": "MetaGraspNet: A Large-Scale Benchmark Dataset for Vision-driven Robotic  Grasping via Physics-based Metaverse Synthesis",
    "abstract": "MetaGraspNet: A Large-Scale Benchmark Dataset for Vision-driven Robotic  Grasping via Physics-based Metaverse Synthesis",
    "descriptor": "",
    "authors": [
      "Yuhao Chen",
      "E. Zhixuan Zeng",
      "Maximilian Gilles",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.14663"
  },
  {
    "id": "arXiv:2112.14714",
    "title": "Automated Code Optimization with E-Graphs",
    "abstract": "Comments: Bachelor Thesis in Computer Science, University of Pisa",
    "descriptor": "\nComments: Bachelor Thesis in Computer Science, University of Pisa\n",
    "authors": [
      "Alessandro Cheli",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.14714"
  }
]
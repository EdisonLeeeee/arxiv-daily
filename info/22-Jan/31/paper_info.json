[
  {
    "id": "arXiv:2201.11742",
    "title": "Continual Learning in Embodied Neuro-Inspired Developmental  Neuroevolution -- Preliminary Results",
    "abstract": "A profound challenge for A-Life is to construct agents whose behavior is\n'life-like' in a deep way. We propose an architecture and approach to\nconstructing networks driving artificial agents, using processes analogous to\nthe processes that construct and sculpt the brains of animals. Furthermore the\ninstantiation of action is dynamic: the whole network responds in real-time to\nsensory inputs to activate effectors, rather than computing a representation of\nthe optimal behavior and sending off an encoded representation to effector\ncontrollers. There are many parameters and we use an evolutionary algorithm to\nselect them, in the context of a specific prey-capture task. We think this\narchitecture may be useful for controlling small autonomous robots or drones,\nbecause it allows for a rapid response to changes in sensor inputs.",
    "descriptor": "\nComments: 7 pages, 4 figures, 1 appendix page\n",
    "authors": [
      "Mark Reimers",
      "Nick Sabaj",
      "Addison Wood",
      "Richard Liu",
      "Jory Schossau"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.11742"
  },
  {
    "id": "arXiv:2201.11745",
    "title": "Exploring Graph Representation of Chorales",
    "abstract": "This work explores areas overlapping music, graph theory, and machine\nlearning. An embedding representation of a node, in a weighted undirected graph\n$\\mathcal{G}$, is a representation that captures the meaning of nodes in an\nembedding space. In this work, 383 Bach chorales were compiled and represented\nas a graph. Two application cases were investigated in this paper (i) learning\nnode embedding representation using \\emph{Continuous Bag of Words (CBOW),\nskip-gram}, and \\emph{node2vec} algorithms, and (ii) learning node labels from\nneighboring nodes based on a collective classification approach. The results of\nthis exploratory study ascertains many salient features of the graph-based\nrepresentation approach applicable to music applications.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Somnuk Phon-Amnuaisuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11745"
  },
  {
    "id": "arXiv:2201.11760",
    "title": "Unsupervised Denoising of Retinal OCT with Diffusion Probabilistic Model",
    "abstract": "Optical coherence tomography (OCT) is a prevalent non-invasive imaging method\nwhich provides high resolution volumetric visualization of retina. However, its\ninherent defect, the speckle noise, can seriously deteriorate the tissue\nvisibility in OCT. Deep learning based approaches have been widely used for\nimage restoration, but most of these require a noise-free reference image for\nsupervision. In this study, we present a diffusion probabilistic model that is\nfully unsupervised to learn from noise instead of signal. A diffusion process\nis defined by adding a sequence of Gaussian noise to self-fused OCT b-scans.\nThen the reverse process of diffusion, modeled by a Markov chain, provides an\nadjustable level of denoising. Our experiment results demonstrate that our\nmethod can significantly improve the image quality with a simple working\npipeline and a small amount of training data.",
    "descriptor": "\nComments: SPIE medical imaging, 2022\n",
    "authors": [
      "Dewei Hu",
      "Yuankai K. Tao",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11760"
  },
  {
    "id": "arXiv:2201.11764",
    "title": "A TOCTOU Attack on DICE Attestation",
    "abstract": "A major security challenge for modern Internet of Things (IoT) deployments is\nto ensure that the devices run legitimate firmware free from malware. This\nchallenge can be addressed through a security primitive called attestation\nwhich allows a remote backend to verify the firmware integrity of the devices\nit manages. In order to accelerate broad attestation adoption in the IoT domain\nthe Trusted Computing Group (TCG) has introduced the Device Identifier\nComposition Engine (DICE) series of specifications. DICE is a hardware-software\narchitecture for constrained, e.g., microcontroller-based IoT devices where the\nfirmware is divided into successively executed layers.\nIn this paper, we demonstrate a remote Time-Of-Check Time-Of-Use (TOCTOU)\nattack on DICE-based attestation. We demonstrate that it is possible to install\npersistent malware in the flash memory of a constrained microcontroller that\ncannot be detected through DICE-based attestation. The main idea of our attack\nis to install malware during runtime of application logic in the top firmware\nlayer. The malware reads the valid attestation key and stores it on the\ndevice's flash memory. After reboot, the malware uses the previously stored key\nfor all subsequent attestations to the backend. We conduct the installation of\nmalware and copying of the key through Return-Oriented Programming (ROP). As a\nplatform for our demonstration, we use the Cortex-M-based nRF52840\nmicrocontroller. We provide a discussion of several possible countermeasures\nwhich can mitigate the shortcomings of the DICE specifications.",
    "descriptor": "\nComments: 10 pages, 3 figures, to appear at CODASPY'22\n",
    "authors": [
      "Stefan Hristozov",
      "Moritz Wettermann",
      "Manuel Huber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11764"
  },
  {
    "id": "arXiv:2201.11766",
    "title": "Recursive Decoding: A Situated Cognition Approach to Compositional  Generation in Grounded Language Understanding",
    "abstract": "Compositional generalization is a troubling blind spot for neural language\nmodels. Recent efforts have presented techniques for improving a model's\nability to encode novel combinations of known inputs, but less work has focused\non generating novel combinations of known outputs. Here we focus on this latter\n\"decode-side\" form of generalization in the context of gSCAN, a synthetic\nbenchmark for compositional generalization in grounded language understanding.\nWe present Recursive Decoding (RD), a novel procedure for training and using\nseq2seq models, targeted towards decode-side generalization. Rather than\ngenerating an entire output sequence in one pass, models are trained to predict\none token at a time. Inputs (i.e., the external gSCAN environment) are then\nincrementally updated based on predicted tokens, and re-encoded for the next\ndecoder time step. RD thus decomposes a complex, out-of-distribution sequence\ngeneration task into a series of incremental predictions that each resemble\nwhat the model has already seen during training. RD yields dramatic improvement\non two previously neglected generalization tasks in gSCAN. We provide analyses\nto elucidate these gains over failure of a baseline, and then discuss\nimplications for generalization in naturalistic grounded language\nunderstanding, and seq2seq more generally.",
    "descriptor": "",
    "authors": [
      "Matthew Setzler",
      "Scott Howland",
      "Lauren Phillips"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11766"
  },
  {
    "id": "arXiv:2201.11769",
    "title": "Design Optimization of a Three-Phase Transformer Using Ansys-Maxwell",
    "abstract": "Optimization of design parameters of a transformer is a crucial task to\nincrease efficiency and lower the material cost. This research presents an\napproach to model a three-phase transformer and optimize design parameters to\nminimize the volume and loss. ANSYS Maxwell 2D is used to model the transformer\nand analyze it for different design parameters. The multi-objective\ndifferential evolution algorithm is used to find optimum design parameters that\nminimize the volume and loss. In this paper, we present the optimum design\nparameters for a 1 kVA transformer with a particular input and output voltage\nspecification. The transformer with these optimum design parameters is then\ntested for different loading conditions and power factor values. The results\nshow that the maximum efficiency is obtained for 75% loading condition with\nunity power factor. As the power factor decreases, the efficiency decreases as\nwell.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Ahmet Furkan Hacan",
      "Bilal Kabas",
      "Samet Oguten"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11769"
  },
  {
    "id": "arXiv:2201.11770",
    "title": "Going Extreme: Comparative Analysis of Hate Speech in Parler and Gab",
    "abstract": "Social platforms such as Gab and Parler, branded as `free-speech' networks,\nhave seen a significant growth of their user base in recent years. This\npopularity is mainly attributed to the stricter moderation enforced by\nmainstream platforms such as Twitter, Facebook, and Reddit. In this work we\nprovide the first large scale analysis of hate-speech on Parler.\nWe experiment with an array of algorithms for hate-speech detection,\ndemonstrating limitations of transfer learning in that domain, given the\nillusive and ever changing nature of the ways hate-speech is delivered. In\norder to improve classification accuracy we annotated 10K Parler posts, which\nwe use to fine-tune a BERT classifier. Classification of individual posts is\nthen leveraged for the classification of millions of users via label\npropagation over the social network. Classifying users by their propensity to\ndisseminate hate, we find that hate mongers make 16.1\\% of Parler active users,\nand that they have distinct characteristics comparing to other user groups. We\nfind that hate mongers are more active, more central and express distinct\nlevels of sentiment and convey a distinct array of emotions like anger and\nsadness. We further complement our analysis by comparing the trends discovered\nin Parler and those found in Gab.\nTo the best of our knowledge, this is among the first works to analyze hate\nspeech in Parler in a quantitative manner and on the user level, and the first\nannotated dataset to be made available to the community.",
    "descriptor": "",
    "authors": [
      "Abraham Israeli",
      "Oren Tsur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11770"
  },
  {
    "id": "arXiv:2201.11775",
    "title": "The Effect of Diversity in Meta-Learning",
    "abstract": "Few-shot learning aims to learn representations that can tackle novel tasks\ngiven a small number of examples. Recent studies show that task distribution\nplays a vital role in the model's performance. Conventional wisdom is that task\ndiversity should improve the performance of meta-learning. In this work, we\nfind evidence to the contrary; we study different task distributions on a\nmyriad of models and datasets to evaluate the effect of task diversity on\nmeta-learning algorithms. For this experiment, we train on multiple datasets,\nand with three broad classes of meta-learning models - Metric-based (i.e.,\nProtonet, Matching Networks), Optimization-based (i.e., MAML, Reptile, and\nMetaOptNet), and Bayesian meta-learning models (i.e., CNAPs). Our experiments\ndemonstrate that the effect of task diversity on all these algorithms follows a\nsimilar trend, and task diversity does not seem to offer any benefits to the\nlearning of the model. Furthermore, we also demonstrate that even a handful of\ntasks, repeated over multiple batches, would be sufficient to achieve a\nperformance similar to uniform sampling and draws into question the need for\nadditional tasks to create better models.",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11775"
  },
  {
    "id": "arXiv:2201.11779",
    "title": "Convolutional Self-Attention-Based Multi-User MIMO Demapper",
    "abstract": "In orthogonal frequency division multiplexing (OFDM)-based wireless\ncommunication systems, the bit error rate (BER) performance is heavily\ndependent on the accuracy of channel estimation. It is important for a good\nchannel estimator to be capable of handling the changes in the wireless channel\nconditions that occur due to the mobility of the users. In recent years, the\nfocus has been on developing complex neural network (NN)- based channel\nestimators that enable an error performance close to that of a genie-aided\nchannel estimator. This work considers the other alternative which is to have a\nsimple channel estimator but a more complex NN-based demapper for the\ngeneration of soft information for each transmitted bit. In particular, the\nproblem of reversing the adverse effects of an imperfect channel estimator is\naddressed, and a convolutional self-attention-based neural demapper that\nsignificantly outperforms the baseline is proposed.",
    "descriptor": "",
    "authors": [
      "Athur Michon",
      "Fay\u00e7al Ait Aoudia",
      "K. Pavan Srinath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11779"
  },
  {
    "id": "arXiv:2201.11780",
    "title": "Minotaur: Multi-Resource Blockchain Consensus",
    "abstract": "Resource-based consensus is the backbone of permissionless distributed ledger\nsystems. The security of such protocols relies fundamentally on the level of\nresources actively engaged in the system. The variety of different resources\n(and related proof protocols, some times referred to as PoX in the literature)\nraises the fundamental question whether it is possible to utilize many of them\nin tandem and build multi-resource consensus protocols. The challenge in\ncombining different resources is to achieve fungibility between them, in the\nsense that security would hold as long as the cumulative adversarial power\nacross all resources is bounded.\nIn this work, we put forth Minotaur, a multi-resource blockchain consensus\nprotocol that combines proof of work (PoW) and proof-of-stake (PoS), and we\nprove it optimally fungible. At the core of our design, Minotaur operates in\nepochs while continuously sampling the active computational power to provide a\nfair exchange between the two resources, work and stake. Further, we\ndemonstrate the ability of Minotaur to handle a higher degree of work\nfluctuation as compared to the Bitcoin blockchain; we also generalize Minotaur\nto any number of resources.\nWe demonstrate the simplicity of Minotaur via implementing a full stack\nclient in Rust (available open source). We use the client to test the\nrobustness of Minotaur to variable mining power and combined work/stake attacks\nand demonstrate concrete empirical evidence towards the suitability of Minotaur\nto serve as the consensus layer of a real-world blockchain.",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "Matthias Fitzi",
      "Xuechao Wang",
      "Sreeram Kannan",
      "Aggelos Kiayias",
      "Nikos Leonardos",
      "Pramod Viswanath",
      "Gerui Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11780"
  },
  {
    "id": "arXiv:2201.11782",
    "title": "An Empirical Analysis of Recurrent Learning Algorithms In Neural Lossy  Image Compression Systems",
    "abstract": "Recent advances in deep learning have resulted in image compression\nalgorithms that outperform JPEG and JPEG 2000 on the standard Kodak benchmark.\nHowever, they are slow to train (due to backprop-through-time) and, to the best\nof our knowledge, have not been systematically evaluated on a large variety of\ndatasets. In this paper, we perform the first large-scale comparison of recent\nstate-of-the-art hybrid neural compression algorithms, while exploring the\neffects of alternative training strategies (when applicable). The hybrid\nrecurrent neural decoder is a former state-of-the-art model (recently overtaken\nby a Google model) that can be trained using backprop-through-time (BPTT) or\nwith alternative algorithms like sparse attentive backtracking (SAB), unbiased\nonline recurrent optimization (UORO), and real-time recurrent learning (RTRL).\nWe compare these training alternatives along with the Google models (GOOG and\nE2E) on 6 benchmark datasets. Surprisingly, we found that the model trained\nwith SAB performs better (outperforming even BPTT), resulting in faster\nconvergence and a better peak signal-to-noise ratio.",
    "descriptor": "\nComments: Accepted at DCC 2021, 15 pages\n",
    "authors": [
      "Ankur Mali",
      "Alexander Ororbia",
      "Daniel Kifer",
      "Lee Giles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11782"
  },
  {
    "id": "arXiv:2201.11783",
    "title": "Rethinking Learning Dynamics in RL using Adversarial Networks",
    "abstract": "We present a learning mechanism for reinforcement learning of closely related\nskills parameterized via a skill embedding space. Our approach is grounded on\nthe intuition that nothing makes you learn better than a coevolving adversary.\nThe main contribution of our work is to formulate an adversarial training\nregime for reinforcement learning with the help of entropy-regularized policy\ngradient formulation. We also adapt existing measures of causal attribution to\ndraw insights from the skills learned. Our experiments demonstrate that the\nadversarial process leads to a better exploration of multiple solutions and\nunderstanding the minimum number of different skills necessary to solve a given\nset of tasks.",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11783"
  },
  {
    "id": "arXiv:2201.11794",
    "title": "A Survey on Visual Transfer Learning using Knowledge Graphs",
    "abstract": "Recent approaches of computer vision utilize deep learning methods as they\nperform quite well if training and testing domains follow the same underlying\ndata distribution. However, it has been shown that minor variations in the\nimages that occur when using these methods in the real world can lead to\nunpredictable errors. Transfer learning is the area of machine learning that\ntries to prevent these errors. Especially, approaches that augment image data\nusing auxiliary knowledge encoded in language embeddings or knowledge graphs\n(KGs) have achieved promising results in recent years. This survey focuses on\nvisual transfer learning approaches using KGs. KGs can represent auxiliary\nknowledge either in an underlying graph-structured schema or in a vector-based\nknowledge graph embedding. Intending to enable the reader to solve visual\ntransfer learning problems with the help of specific KG-DL configurations we\nstart with a description of relevant modeling structures of a KG of various\nexpressions, such as directed labeled graphs, hypergraphs, and hyper-relational\ngraphs. We explain the notion of feature extractor, while specifically\nreferring to visual and semantic features. We provide a broad overview of\nknowledge graph embedding methods and describe several joint training\nobjectives suitable to combine them with high dimensional visual embeddings.\nThe main section introduces four different categories on how a KG can be\ncombined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge\nGraph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as\na Peer. To help researchers find evaluation benchmarks, we provide an overview\nof generic KGs and a set of image processing datasets and benchmarks including\nvarious types of auxiliary knowledge. Last, we summarize related surveys and\ngive an outlook about challenges and open issues for future research.",
    "descriptor": "\nComments: Semantic Web Journal (SWJ)\n",
    "authors": [
      "Sebastian Monka",
      "Lavdim Halilaj",
      "Achim Rettinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11794"
  },
  {
    "id": "arXiv:2201.11796",
    "title": "A Privacy-Protecting Framework of Autonomous Contact Tracing for  SARS-CoV-2 and Beyond",
    "abstract": "Controlling the spread of infectious diseases, such as the ongoing SARS-CoV-2\npandemic, is one of the most challenging problems for human civilization. The\nworld is more populous and connected than ever before, and therefore, the rate\nof contagion for such diseases often becomes stupendous. The development and\ndistribution of testing kits cannot keep up with the demand, making it\nimpossible to test everyone. The next best option is to identify and isolate\nthe people who come in close contact with an infected person. However, this\napparently simple process, commonly known as - contact tracing, suffers from\ntwo major pitfalls: the requirement of a large amount of manpower to track the\ninfected individuals manually and the breach in privacy and security while\nautomating the process. Here, we propose a Bluetooth based contact tracing\nhardware with anonymous IDs to solve both the drawbacks of the existing\napproaches. The hardware will be a wearable device that every user can carry\nconveniently. This device will measure the distance between two users and\nexchange the IDs anonymously in the case of a close encounter. The anonymous\nIDs stored in the device of any newly infected individual will be used to trace\nthe risky contacts and the status of the IDs will be updated consequently by\nauthorized personnel. To demonstrate the concept, we simulate the working\nprocedure and highlight the effectiveness of our technique to curb the spread\nof any contagious disease.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Shamiul Alam",
      "Md Shafayat Hossain",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11796"
  },
  {
    "id": "arXiv:2201.11799",
    "title": "Graph-based Algorithm Unfolding for Energy-aware Power Allocation in  Wireless Networks",
    "abstract": "We develop a novel graph-based trainable framework to maximize the weighted\nsum energy efficiency (WSEE) for power allocation in wireless communication\nnetworks. To address the non-convex nature of the problem, the proposed method\nconsists of modular structures inspired by a classical iterative suboptimal\napproach and enhanced with learnable components. More precisely, we propose a\ndeep unfolding of the successive concave approximation (SCA) method. In our\nunfolded SCA (USCA) framework, the originally preset parameters are now\nlearnable via graph convolutional neural networks (GCNs) that directly exploit\nmulti-user channel state information as the underlying graph adjacency matrix.\nWe show the permutation equivariance of the proposed architecture, which\npromotes generalizability across different network topologies of varying size,\ndensity, and channel distribution. The USCA framework is trained through a\nstochastic gradient descent approach using a progressive training strategy. The\nunsupervised loss is carefully devised to feature the monotonic property of the\nobjective under maximum power constraints. Comprehensive numerical results\ndemonstrate outstanding performance and robustness of USCA over\nstate-of-the-art benchmarks.",
    "descriptor": "",
    "authors": [
      "Boning Li",
      "Gunjan Verma",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11799"
  },
  {
    "id": "arXiv:2201.11802",
    "title": "A Knowledge-Based Decision Support System for In Vitro Fertilization  Treatment",
    "abstract": "In Vitro Fertilization (IVF) is the most widely used Assisted Reproductive\nTechnology (ART). IVF usually involves controlled ovarian stimulation, oocyte\nretrieval, fertilization in the laboratory with subsequent embryo transfer. The\nfirst two steps correspond with follicular phase of females and ovulation in\ntheir menstrual cycle. Therefore, we refer to it as the treatment cycle in our\npaper. The treatment cycle is crucial because the stimulation medications in\nIVF treatment are applied directly on patients. In order to optimize the\nstimulation effects and lower the side effects of the stimulation medications,\nprompt treatment adjustments are in need. In addition, the quality and quantity\nof the retrieved oocytes have a significant effect on the outcome of the\nfollowing procedures. To improve the IVF success rate, we propose a\nknowledge-based decision support system that can provide medical advice on the\ntreatment protocol and medication adjustment for each patient visit during IVF\ntreatment cycle. Our system is efficient in data processing and light-weighted\nwhich can be easily embedded into electronic medical record systems. Moreover,\nan oocyte retrieval oriented evaluation demonstrates that our system performs\nwell in terms of accuracy of advice for the protocols and medications.",
    "descriptor": "\nComments: 8 pages, 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM). IEEE, 2021\n",
    "authors": [
      "Xizhe Wang",
      "Ning Zhang",
      "Jia Wang",
      "Jing Ni",
      "Xinzi Sun",
      "John Zhang",
      "Zitao Liu",
      "Yu Cao",
      "Benyuan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11802"
  },
  {
    "id": "arXiv:2201.11803",
    "title": "On the Convergence of Heterogeneous Federated Learning with Arbitrary  Adaptive Online Model Pruning",
    "abstract": "One of the biggest challenges in Federated Learning (FL) is that client\ndevices often have drastically different computation and communication\nresources for local updates. To this end, recent research efforts have focused\non training heterogeneous local models obtained by pruning a shared global\nmodel. Despite empirical success, theoretical guarantees on convergence remain\nan open question. In this paper, we present a unifying framework for\nheterogeneous FL algorithms with {\\em arbitrary} adaptive online model pruning\nand provide a general convergence analysis. In particular, we prove that under\ncertain sufficient conditions and on both IID and non-IID data, these\nalgorithms converges to a stationary point of standard FL for general smooth\ncost functions, with a convergence rate of $O(\\frac{1}{\\sqrt{Q}})$. Moreover,\nwe illuminate two key factors impacting convergence: pruning-induced noise and\nminimum coverage index, advocating a joint design of local pruning masks for\nefficient training.",
    "descriptor": "\nComments: pre-print\n",
    "authors": [
      "Hanhan Zhou",
      "Tian Lan",
      "Guru Venkataramani",
      "Wenbo Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11803"
  },
  {
    "id": "arXiv:2201.11807",
    "title": "Taxonomy of Security Weaknesses in Java and Kotlin Android Apps",
    "abstract": "Android is nowadays the most popular operating system in the world, not only\nin the realm of mobile devices, but also when considering desktop and laptop\ncomputers. Such a popularity makes it an attractive target for security\nattacks, also due to the sensitive information often manipulated by mobile\napps. The latter are going through a transition in which the Android ecosystem\nis moving from the usage of Java as the official language for developing apps,\nto the adoption of Kotlin as the first choice supported by Google. While\nprevious studies have partially studied security weaknesses affecting Java\nAndroid apps, there is no comprehensive empirical investigation studying\nsoftware security weaknesses affecting Android apps considering (and comparing)\nthe two main languages used for their development, namely Java and Kotlin. We\npresent an empirical study in which we: (i) manually analyze 681 commits\nincluding security weaknesses fixed by developers in Java and Kotlin apps, with\nthe goal of defining a taxonomy highlighting the types of software security\nweaknesses affecting Java and Kotlin Android apps; (ii) survey 43 Android\ndevelopers to validate and complement our taxonomy. Based on our findings, we\npropose a list of future actions that could be performed by researchers and\npractitioners to improve the security of Android apps.",
    "descriptor": "\nComments: Accepted to JSS journal\n",
    "authors": [
      "Alejandro Mazuera-Rozo",
      "Camilo Escobar-Vel\u00e1squez",
      "Juan Espitia-Acero",
      "David Vega-Guzm\u00e1n",
      "Catia Trubiani",
      "Mario Linares-V\u00e1squez",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11807"
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "abstract": "Despite the state-of-the-art performance of deep convolutional neural\nnetworks, they are susceptible to bias and malfunction in unseen situations.\nThe complex computation behind their reasoning is not sufficiently\nhuman-understandable to develop trust. External explainer methods have tried to\ninterpret the network decisions in a human-understandable way, but they are\naccused of fallacies due to their assumptions and simplifications. On the other\nside, the inherent self-interpretability of models, while being more robust to\nthe mentioned fallacies, cannot be applied to the already trained models. In\nthis work, we propose a new attention-based pooling layer, called Local\nAttention Pooling (LAP), that accomplishes self-interpretability and the\npossibility for knowledge injection while improving the model's performance.\nMoreover, several weakly-supervised knowledge injection methodologies are\nprovided to enhance the process of training. We verified our claims by\nevaluating several LAP-extended models on three different datasets, including\nImagenet. The proposed framework offers more valid human-understandable and\nmore faithful-to-the-model interpretations than the commonly used white-box\nexplainer methods.",
    "descriptor": "",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11808"
  },
  {
    "id": "arXiv:2201.11811",
    "title": "Porting OpenACC to OpenMP on heterogeneous systems",
    "abstract": "This documentation is designed for beginners in Graphics Processing Unit\n(GPU)-programming and who want to get familiar with OpenACC and OpenMP\noffloading models. Here we present an overview of these two programming models\nas well as of the GPU-architectures. Specifically, we provide some insights\ninto the functionality of these models and perform experiments involving\ndifferent directives and discuss their performance. This is achieved through\nthe use of a mini-application based on solving numerically the Laplace\nequation. Such experiments reveal the benefit of the use of GPU, which in our\ncase manifests by an increase of the performance by almost a factor of 52. We\nfurther carry out a comparative study between the OpenACC and OpenMP models in\nthe aim of converting OpenACC to OpenMP on heterogeneous systems. In this\ncontext, we present a short overview of the open-source OpenACC compiler Clacc,\nwhich is designed based on translating OpenACC to OpenMP in Clang.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Hichan Agueny"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11811"
  },
  {
    "id": "arXiv:2201.11812",
    "title": "A Transfer Learning and Optimized CNN Based Intrusion Detection System  for Internet of Vehicles",
    "abstract": "Modern vehicles, including autonomous vehicles and connected vehicles, are\nincreasingly connected to the external world, which enables various\nfunctionalities and services. However, the improving connectivity also\nincreases the attack surfaces of the Internet of Vehicles (IoV), causing its\nvulnerabilities to cyber-threats. Due to the lack of authentication and\nencryption procedures in vehicular networks, Intrusion Detection Systems (IDSs)\nare essential approaches to protect modern vehicle systems from network\nattacks. In this paper, a transfer learning and ensemble learning-based IDS is\nproposed for IoV systems using convolutional neural networks (CNNs) and\nhyper-parameter optimization techniques. In the experiments, the proposed IDS\nhas demonstrated over 99.25% detection rates and F1-scores on two well-known\npublic benchmark IoV security datasets: the Car-Hacking dataset and the\nCICIDS2017 dataset. This shows the effectiveness of the proposed IDS for\ncyber-attack detection in both intra-vehicle and external vehicular networks.",
    "descriptor": "\nComments: Accepted and to appear in IEEE International Conference on Communications (ICC); Code is available at Github link: this https URL\n",
    "authors": [
      "Li Yang",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11812"
  },
  {
    "id": "arXiv:2201.11813",
    "title": "Eigenvalues of Autoencoders in Training and at Initialization",
    "abstract": "In this paper, we investigate the evolution of autoencoders near their\ninitialization. In particular, we study the distribution of the eigenvalues of\nthe Jacobian matrices of autoencoders early in the training process, training\non the MNIST data set. We find that autoencoders that have not been trained\nhave eigenvalue distributions that are qualitatively different from those which\nhave been trained for a long time ($>$100 epochs). Additionally, we find that\neven at early epochs, these eigenvalue distributions rapidly become\nqualitatively similar to those of the fully trained autoencoders. We also\ncompare the eigenvalues at initialization to pertinent theoretical work on the\neigenvalues of random matrices and the products of such matrices.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Benjamin Dees",
      "Susama Agarwala",
      "Corey Lowman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11813"
  },
  {
    "id": "arXiv:2201.11815",
    "title": "Consolidated learning -- a domain-specific model-free optimization  strategy with examples for XGBoost and MIMIC-IV",
    "abstract": "For many machine learning models, a choice of hyperparameters is a crucial\nstep towards achieving high performance. Prevalent meta-learning approaches\nfocus on obtaining good hyperparameters configurations with a limited\ncomputational budget for a completely new task based on the results obtained\nfrom the prior tasks. This paper proposes a new formulation of the tuning\nproblem, called consolidated learning, more suited to practical challenges\nfaced by model developers, in which a large number of predictive models are\ncreated on similar data sets. In such settings, we are interested in the total\noptimization time rather than tuning for a single task. We show that a\ncarefully selected static portfolio of hyperparameters yields good results for\nanytime optimization, maintaining ease of use and implementation. Moreover, we\npoint out how to construct such a portfolio for specific domains. The\nimprovement in the optimization is possible due to more efficient transfer of\nhyperparameter configurations between similar tasks. We demonstrate the\neffectiveness of this approach through an empirical study for XGBoost algorithm\nand the collection of predictive tasks extracted from the MIMIC-IV medical\ndatabase; however, consolidated learning is applicable in many others fields.",
    "descriptor": "",
    "authors": [
      "Katarzyna Wo\u017anica",
      "Mateusz Grzyb",
      "Zuzanna Trafas",
      "Przemys\u0142aw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11815"
  },
  {
    "id": "arXiv:2201.11816",
    "title": "A positivity preserving strategy for entropy stable discontinuous  Galerkin discretizations of the compressible Euler and Navier-Stokes  equations",
    "abstract": "High-order entropy-stable discontinuous Galerkin methods for the compressible\nEuler and Navier-Stokes equations require the positivity of thermodynamic\nquantities in order to guarantee their well-posedness. In this work, we\nintroduce a positivity limiting strategy for entropy-stable discontinuous\nGalerkin discretizations based on convex limiting. The key ingredient in the\nlimiting procedure is a low order positivity-preserving discretization based on\ngraph viscosity terms. The proposed limiting strategy is both positivity\npreserving and discretely entropy-stable for the compressible Euler and\nNavier-Stokes equations. Numerical experiments confirm the high order accuracy\nand robustness of the proposed strategy.",
    "descriptor": "",
    "authors": [
      "Yimin Lin",
      "Jesse Chan",
      "Ignacio Tomas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11816"
  },
  {
    "id": "arXiv:2201.11817",
    "title": "Exploration With a Finite Brain",
    "abstract": "Equipping artificial agents with useful exploration mechanisms remains a\nchallenge to this day. Humans, on the other hand, seem to manage the trade-off\nbetween exploration and exploitation effortlessly. In the present article, we\nput forward the hypothesis that they accomplish this by making optimal use of\nlimited computational resources. We study this hypothesis by meta-learning\nreinforcement learning algorithms that sacrifice performance for a shorter\ndescription length. The emerging class of models captures human exploration\nbehavior better than previously considered approaches, such as Boltzmann\nexploration, upper confidence bound algorithms, and Thompson sampling. We\nadditionally demonstrate that changes in description length produce the\nintended effects: reducing description length captures the behavior of\nbrain-lesioned patients while increasing it echoes cognitive development during\nadolescence.",
    "descriptor": "",
    "authors": [
      "Marcel Binz",
      "Eric Schulz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11817"
  },
  {
    "id": "arXiv:2201.11819",
    "title": "Closed-Loop Control of Direct Ink Writing via Reinforcement Learning",
    "abstract": "Enabling additive manufacturing to employ a wide range of novel, functional\nmaterials can be a major boost to this technology. However, making such\nmaterials printable requires painstaking trial-and-error by an expert operator,\nas they typically tend to exhibit peculiar rheological or hysteresis\nproperties. Even in the case of successfully finding the process parameters,\nthere is no guarantee of print-to-print consistency due to material differences\nbetween batches. These challenges make closed-loop feedback an attractive\noption where the process parameters are adjusted on-the-fly. There are several\nchallenges for designing an efficient controller: the deposition parameters are\ncomplex and highly coupled, artifacts occur after long time horizons,\nsimulating the deposition is computationally costly, and learning on hardware\nis intractable. In this work, we demonstrate the feasibility of learning a\nclosed-loop control policy for additive manufacturing using reinforcement\nlearning. We show that approximate, but efficient, numerical simulation is\nsufficient as long as it allows learning the behavioral patterns of deposition\nthat translate to real-world experiences. In combination with reinforcement\nlearning, our model can be used to discover control policies that outperform\nbaseline controllers. Furthermore, the recovered policies have a minimal\nsim-to-real gap. We showcase this by applying our control policy in-vivo on a\nsingle-layer, direct ink writing printer.",
    "descriptor": "",
    "authors": [
      "Michal Piovarci",
      "Michael Foshey",
      "Jie Xu",
      "Timothy Erps",
      "Vahid Babaei",
      "Piotr Didyk",
      "Szymon Rusinkiewicz",
      "Wojciech Matusik",
      "Bernd Bickel"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.11819"
  },
  {
    "id": "arXiv:2201.11821",
    "title": "An Empirical Study of Yanked Releases in the Rust Package Registry",
    "abstract": "Cargo, the software packaging manager of Rust, provides a yank mechanism to\nsupport release-level deprecation, which can prevent packages from depending on\nyanked releases. Most prior studies focused on code-level (i.e., deprecated\nAPIs) and package-level deprecation (i.e., deprecated packages). However, few\nstudies have focused on release-level deprecation. In this study, we\ninvestigate how often and how the yank mechanism is used, the rationales behind\nits usage, and the adoption of yanked releases in the Cargo ecosystem. Our\nstudy shows that 9.6% of the packages in Cargo have at least one yanked\nrelease, and the proportion of yanked releases kept increasing from 2014 to\n2020. Package owners yank releases for other reasons than withdrawing a\ndefective release, such as fixing a release that does not follow semantic\nversioning or indicating a package is removed or replaced. In addition, we\nfound that 46% of the packages directly adopted at least one yanked release and\nthe yanked releases propagated through the dependency network, which leads to\n1.4% of the releases in the ecosystem having unresolved dependencies.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Hao Li",
      "Filipe R. Cogo",
      "Cor-Paul Bezemer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11821"
  },
  {
    "id": "arXiv:2201.11824",
    "title": "Empirical Estimates on Hand Manipulation are Recoverable: A Step Towards  Individualized and Explainable Robotic Support in Everyday Activities",
    "abstract": "A key challenge for robotic systems is to figure out the behavior of another\nagent. The capability to draw correct inferences is crucial to derive human\nbehavior from examples.\nProcessing correct inferences is especially challenging when (confounding)\nfactors are not controlled experimentally (observational evidence). For this\nreason, robots that rely on inferences that are correlational risk a biased\ninterpretation of the evidence.\nWe propose equipping robots with the necessary tools to conduct observational\nstudies on people. Specifically, we propose and explore the feasibility of\nstructural causal models with non-parametric estimators to derive empirical\nestimates on hand behavior in the context of object manipulation in a virtual\nkitchen scenario. In particular, we focus on inferences under (the weaker)\nconditions of partial confounding (the model covering only some factors) and\nconfront estimators with hundreds of samples instead of the typical order of\nthousands. Studying these conditions explores the boundaries of the approach\nand its viability.\nDespite the challenging conditions, the estimates inferred from the\nvalidation data are correct. Moreover, these estimates are stable against three\nrefutation strategies where four estimators are in agreement. Furthermore, the\ncausal quantity for two individuals reveals the sensibility of the approach to\ndetect positive and negative effects.\nThe validity, stability and explainability of the approach are encouraging\nand serve as the foundation for further research.",
    "descriptor": "",
    "authors": [
      "Alexander Wich",
      "Holger Schultheis",
      "Michael Beetz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11824"
  },
  {
    "id": "arXiv:2201.11825",
    "title": "Adam-based Augmented Random Search for Control Policies for Distributed  Energy Resource Cyber Attack Mitigation",
    "abstract": "Volt-VAR and Volt-Watt control functions are mechanisms that are included in\ndistributed energy resource (DER) power electronic inverters to mitigate\nexcessively high or low voltages in distribution systems. In the event that a\nsubset of DER have had their Volt-VAR and Volt-Watt settings compromised as\npart of a cyber-attack, we propose a mechanism to control the remaining set of\nnon-compromised DER to ameliorate large oscillations in system voltages and\nlarge voltage imbalances in real time. To do so, we construct control policies\nfor individual non-compromised DER, directly searching the policy space using\nan Adam-based augmented random search (ARS). In this paper we show that,\ncompared to previous efforts aimed at training policies for DER cybersecurity\nusing deep reinforcement learning (DRL), the proposed approach is able to learn\noptimal (and sometimes linear) policies an order of magnitude faster than\nconventional DRL techniques (e.g., Proximal Policy Optimization).",
    "descriptor": "",
    "authors": [
      "Daniel Arnold",
      "Sy-Toan Ngo",
      "Ciaran Roberts",
      "Yize Chen",
      "Anna Scaglione",
      "Sean Peisert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11825"
  },
  {
    "id": "arXiv:2201.11826",
    "title": "Sentiment-Aware Automatic Speech Recognition pre-training for enhanced  Speech Emotion Recognition",
    "abstract": "We propose a novel multi-task pre-training method for Speech Emotion\nRecognition (SER). We pre-train SER model simultaneously on Automatic Speech\nRecognition (ASR) and sentiment classification tasks to make the acoustic ASR\nmodel more ``emotion aware''. We generate targets for the sentiment\nclassification using text-to-sentiment model trained on publicly available\ndata. Finally, we fine-tune the acoustic ASR on emotion annotated speech data.\nWe evaluated the proposed approach on the MSP-Podcast dataset, where we\nachieved the best reported concordance correlation coefficient (CCC) of 0.41\nfor valence prediction.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Ayoub Ghriss",
      "Bo Yang",
      "Viktor Rozgic",
      "Elizabeth Shriberg",
      "Chao Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11826"
  },
  {
    "id": "arXiv:2201.11827",
    "title": "Matching-Game for User-Fog Assignment",
    "abstract": "Fog computing has emerged as a new paradigm in mobile network communications,\naiming to equip the edge of the network with the computing and storing\ncapabilities to deal with the huge amount of data and processing needs\ngenerated by the users' devices and sensors. Optimizing the assignment of users\nto fogs is, however, still an open issue. In this paper, we formulated the\nproblem of users-fogs association, as a matching game with minimum and maximum\nquota constraints, and proposed a Multi-Stage Differed Acceptance (MSDA) in\norder to balance the use of fogs resources and offer a better response time for\nusers. Simulations results show that the performance of the proposed model\ncompared to a baseline matching of users, achieves lowers delays for users.",
    "descriptor": "",
    "authors": [
      "Amine Abouaomar",
      "Abdellatif Kobbane",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11827"
  },
  {
    "id": "arXiv:2201.11828",
    "title": "Pressure Eye: In-bed Contact Pressure Estimation via Contact-less  Imaging",
    "abstract": "Computer vision has achieved great success in interpreting semantic meanings\nfrom images, yet estimating underlying (non-visual) physical properties of an\nobject is often limited to their bulk values rather than reconstructing a dense\nmap. In this work, we present our pressure eye (PEye) approach to estimate\ncontact pressure between a human body and the surface she is lying on with high\nresolution from vision signals directly. PEye approach could ultimately enable\nthe prediction and early detection of pressure ulcers in bed-bound patients,\nthat currently depends on the use of expensive pressure mats. Our PEye network\nis configured in a dual encoding shared decoding form to fuse visual cues and\nsome relevant physical parameters in order to reconstruct high resolution\npressure maps (PMs). We also present a pixel-wise resampling approach based on\nNaive Bayes assumption to further enhance the PM regression performance. A\npercentage of correct sensing (PCS) tailored for sensing estimation accuracy\nevaluation is also proposed which provides another perspective for performance\nevaluation under varying error tolerances. We tested our approach via a series\nof extensive experiments using multimodal sensing technologies to collect data\nfrom 102 subjects while lying on a bed. The individual's high resolution\ncontact pressure data could be estimated from their RGB or long wavelength\ninfrared (LWIR) images with 91.8% and 91.2% estimation accuracies in\n$PCS_{efs0.1}$ criteria, superior to state-of-the-art methods in the related\nimage regression/translation tasks.",
    "descriptor": "",
    "authors": [
      "Shuangjun Liu",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11828"
  },
  {
    "id": "arXiv:2201.11829",
    "title": "A Resources Representation For Resource Allocation In Fog Computing  Networks",
    "abstract": "Fog computing is emerging as a new paradigm to deal with latency-sensitive\napplications, by making data processing and analysis close to their source. Due\nto the heterogeneity of devices in the fog, it is important to devise novel\nsolutions which take into account the diverse physical resources available in\neach device to efficiently and dynamically distribute the processing. In this\npaper, we propose a resource representation scheme which allows exposing the\nresources of each device through Mobile Edge Computing Application Programming\nInterfaces (MEC APIs) in order to optimize resource allocation by the\nsupervising entity in the fog. Then, we formulate the resource allocation\nproblem as a Lyapunov optimization and we discuss the impact of our proposed\napproach on latency. Simulation results show that our proposed approach can\nminimize latency and improve the performance of the system.",
    "descriptor": "",
    "authors": [
      "Amine Abouaomar",
      "Soumaya Cherkaoui",
      "Abdellatif Kobbane",
      "Oussama Abderrahmane Dambri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11829"
  },
  {
    "id": "arXiv:2201.11830",
    "title": "Mean-Field Game and Reinforcement Learning MEC Resource Provisioning for  SFC",
    "abstract": "In this paper, we address the resource provisioning problem for service\nfunction chaining (SFC) in terms of the placement and chaining of virtual\nnetwork functions (VNFs) within a multi-access edge computing (MEC)\ninfrastructure to reduce service delay. We consider the VNFs as the main\nentities of the system and propose a mean-field game (MFG) framework to model\ntheir behavior for their placement and chaining. Then, to achieve the optimal\nresource provisioning policy without considering the system control parameters,\nwe reduce the proposed MFG to a Markov decision process (MDP). In this way, we\nleverage reinforcement learning with an actor-critic approach for MEC nodes to\nlearn complex placement and chaining policies. Simulation results show that our\nproposed approach outperforms benchmark state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Amine Abouaomar",
      "Soumaya Cherkaoui",
      "Zoubeir Mlika",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11830"
  },
  {
    "id": "arXiv:2201.11831",
    "title": "A Deep Reinforcement Learning Approach for Service Migration in  MEC-enabled Vehicular Networks",
    "abstract": "Multi-access edge computing (MEC) is a key enabler to reduce the latency of\nvehicular network. Due to the vehicles mobility, their requested services\n(e.g., infotainment services) should frequently be migrated across different\nMEC servers to guarantee their stringent quality of service requirements. In\nthis paper, we study the problem of service migration in a MEC-enabled\nvehicular network in order to minimize the total service latency and migration\ncost. This problem is formulated as a nonlinear integer program and is\nlinearized to help obtaining the optimal solution using off-the-shelf solvers.\nThen, to obtain an efficient solution, it is modeled as a multi-agent Markov\ndecision process and solved by leveraging deep Q learning (DQL) algorithm. The\nproposed DQL scheme performs a proactive services migration while ensuring\ntheir continuity under high mobility constraints. Finally, simulations results\nshow that the proposed DQL scheme achieves close-to-optimal performance.",
    "descriptor": "",
    "authors": [
      "Amine Abouaomar",
      "Zoubeir Mlika",
      "Abderrahime Filali",
      "Soumaya Cherkaoui",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11831"
  },
  {
    "id": "arXiv:2201.11837",
    "title": "Resource Provisioning in Edge Computing for Latency Sensitive  Applications",
    "abstract": "Low-Latency IoT applications such as autonomous vehicles, augmented/virtual\nreality devices and security applications require high computation resources to\nmake decisions on the fly. However, these kinds of applications cannot tolerate\noffloading their tasks to be processed on a cloud infrastructure due to the\nexperienced latency. Therefore, edge computing is introduced to enable low\nlatency by moving the tasks processing closer to the users at the edge of the\nnetwork. The edge of the network is characterized by the heterogeneity of edge\ndevices forming it; thus, it is crucial to devise novel solutions that take\ninto account the different physical resources of each edge device. In this\npaper, we propose a resource representation scheme, allowing each edge device\nto expose its resource information to the supervisor of the edge node through\nthe mobile edge computing application programming interfaces proposed by\nEuropean Telecommunications Standards Institute. The information about the edge\ndevice resource is exposed to the supervisor of the EN each time a resource\nallocation is required. To this end, we leverage a Lyapunov optimization\nframework to dynamically allocate resources at the edge devices. To test our\nproposed model, we performed intensive theoretical and experimental simulations\non a testbed to validate the proposed scheme and its impact on different\nsystem's parameters. The simulations have shown that our proposed approach\noutperforms other benchmark approaches and provides low latency and optimal\nresource consumption.",
    "descriptor": "",
    "authors": [
      "Amine Abouaomar",
      "Soumaya Cherkaoui",
      "Zoubeir Mlika",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11837"
  },
  {
    "id": "arXiv:2201.11838",
    "title": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical  sequences",
    "abstract": "Transformers-based models, such as BERT, have dramatically improved the\nperformance for various natural language processing tasks. The clinical\nknowledge enriched model, namely ClinicalBERT, also achieved state-of-the-art\nresults when performed on clinical named entity recognition and natural\nlanguage inference tasks. One of the core limitations of these transformers is\nthe substantial memory consumption due to their full self-attention mechanism.\nTo overcome this, long sequence transformer models, e.g. Longformer and\nBigBird, were proposed with the idea of sparse attention mechanism to reduce\nthe memory usage from quadratic to the sequence length to a linear scale. These\nmodels extended the maximum input sequence length from 512 to 4096, which\nenhanced the ability of modeling long-term dependency and consequently achieved\noptimal results in a variety of tasks. Inspired by the success of these long\nsequence transformer models, we introduce two domain enriched language models,\nnamely Clinical-Longformer and Clinical-BigBird, which are pre-trained from\nlarge-scale clinical corpora. We evaluate both pre-trained models using 10\nbaseline tasks including named entity recognition, question answering, and\ndocument classification tasks. The results demonstrate that Clinical-Longformer\nand Clinical-BigBird consistently and significantly outperform ClinicalBERT as\nwell as other short-sequence transformers in all downstream tasks. We have made\nthe pre-trained models available for public download at:\n[https://huggingface.co/yikuan8/Clinical-Longformer].",
    "descriptor": "",
    "authors": [
      "Yikuan Li",
      "Ramsey M. Wehbe",
      "Faraz S. Ahmad",
      "Hanyin Wang",
      "Yuan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11838"
  },
  {
    "id": "arXiv:2201.11840",
    "title": "MSCCL: Microsoft Collective Communication Library",
    "abstract": "Machine learning models made up of millions or billions of parameters are\noften trained and served on large multi-GPU systems. As models grow in size and\nexecute on more GPUs, the collective communications used in these applications\nbecomes a bottleneck. Custom collective algorithms optimized for both\nparticular network topologies and application specific communication patterns\ncan alleviate this bottleneck and thus help these applications scale.\nThis paper introduces MSCCL, a system designed to make GPU communication\nprogrammable. MSCCL provides a data oriented domain specific language for\nwriting custom collective communication algorithms and an optimizing compiler\nfor lowering them to an executable form, which can be executed efficiently and\nflexibly in an interpreter based runtime. We used MSCCL to write novel\ncollective implementations for AllReduce and AllToAll that are up to 48% and\n20% faster than optimized vendor implementations, respectively. We also\ndemonstrate how directly implementing an application specific collective called\nAllToNext in MSCCL results in a 14.5 speedup over the baseline.",
    "descriptor": "",
    "authors": [
      "Meghan Cowan",
      "Saeed Maleki",
      "Madanlal Musuvathi",
      "Olli Saarikivi",
      "Yifan Xiong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11840"
  },
  {
    "id": "arXiv:2201.11843",
    "title": "Discriminative Supervised Subspace Learning for Cross-modal Retrieval",
    "abstract": "Nowadays the measure between heterogeneous data is still an open problem for\ncross-modal retrieval. The core of cross-modal retrieval is how to measure the\nsimilarity between different types of data. Many approaches have been developed\nto solve the problem. As one of the mainstream, approaches based on subspace\nlearning pay attention to learning a common subspace where the similarity among\nmulti-modal data can be measured directly. However, many of the existing\napproaches only focus on learning a latent subspace. They ignore the full use\nof discriminative information so that the semantically structural information\nis not well preserved. Therefore satisfactory results can not be achieved as\nexpected. We in this paper propose a discriminative supervised subspace\nlearning for cross-modal retrieval(DS2L), to make full use of discriminative\ninformation and better preserve the semantically structural information.\nSpecifically, we first construct a shared semantic graph to preserve the\nsemantic structure within each modality. Subsequently, the Hilbert-Schmidt\nIndependence Criterion(HSIC) is introduced to preserve the consistence between\nfeature-similarity and semantic-similarity of samples. Thirdly, we introduce a\nsimilarity preservation term, thus our model can compensate for the\nshortcomings of insufficient use of discriminative data and better preserve the\nsemantically structural information within each modality. The experimental\nresults obtained on three well-known benchmark datasets demonstrate the\neffectiveness and competitiveness of the proposed method against the compared\nclassic subspace learning approaches.",
    "descriptor": "",
    "authors": [
      "Haoming Zhang",
      "Xiao-Jun Wu",
      "Tianyang Xu",
      "Donglin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11843"
  },
  {
    "id": "arXiv:2201.11844",
    "title": "Speckle-based optical cryptosystem and its application for human face  recognition via deep learning",
    "abstract": "Face recognition has recently become ubiquitous in many scenes for\nauthentication or security purposes. Meanwhile, there are increasing concerns\nabout the privacy of face images, which are sensitive biometric data that\nshould be carefully protected. Software-based cryptosystems are widely adopted\nnowadays to encrypt face images, but the security level is limited by\ninsufficient digital secret key length or computing power. Hardware-based\noptical cryptosystems can generate enormously longer secret keys and enable\nencryption at light speed, but most reported optical methods, such as double\nrandom phase encryption, are less compatible with other systems due to system\ncomplexity. In this study, a plain yet high-efficient speckle-based optical\ncryptosystem is proposed and implemented. A scattering ground glass is\nexploited to generate physical secret keys of gigabit length and encrypt face\nimages via seemingly random optical speckles at light speed. Face images can\nthen be decrypted from the random speckles by a well-trained decryption neural\nnetwork, such that face recognition can be realized with up to 98% accuracy.\nThe proposed cryptosystem has wide applicability, and it may open a new avenue\nfor high-security complex information encryption and decryption by utilizing\noptical speckles.",
    "descriptor": "",
    "authors": [
      "Qi Zhao",
      "Huanhao Li",
      "Zhipeng Yu",
      "Chi Man Woo",
      "Tianting Zhong",
      "Shengfu Cheng",
      "Yuanjin Zheng",
      "Honglin Liu",
      "Jie Tian",
      "Puxiang Lai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2201.11844"
  },
  {
    "id": "arXiv:2201.11851",
    "title": "Enhancing Performance of Cloud-based Software Applications with GraalVM  and Quarkus",
    "abstract": "Increased complexity of network-based software solutions and the ever-rising\nnumber of concurrent users forced a shift of the IT industry to cloud\ncomputing. Conventional network software systems commonly based on monolithic\napplication stack running on costly physical single-purpose servers are\naffected by significant problems of resource management, computing power\ndistribution, and scalability.Such implementation is restricting applications\nto be reduced to smaller, independent services that can be more easily\ndeployed, managed, and scaled dynamically; therefore, embellishing\nenvironmental uniformity across development, testing, and production. Current\ncloud-based infrastructure frequently runs on containers placed in Kubernetes\nor Docker-based cluster, and the system configuration is considerably different\ncompared to the environment prevailed with common virtualizations. This paper\ndiscusses the usage of GraalVM, a polyglot high-performance virtual machine for\nJVM-based and other languages, combined with new Kubernetes native Java\ntailored stacked framework named Quarkus, formed from enhanced Java libraries.\nMoreover, our research explores GraalVMs creation of native images using\nAhead-Of-Time (AOT) compilation and Quarkus deployment to Kubernetes.\nFurthermore, we examined the architectures of given systems, various\nperformance variables, and differing memory usage cases within our academic\ntesting environment and presented the comparison results of selected\nperformance measures with other traditional and contemporary solutions",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table\n",
    "authors": [
      "M. Sipek",
      "D. Muharemagic",
      "B. Mihaljevic",
      "A. Radovan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11851"
  },
  {
    "id": "arXiv:2201.11852",
    "title": "Towards an Automatic Diagnosis of Peripheral and Central Palsy Using  Machine Learning on Facial Features",
    "abstract": "Central palsy is a form of facial paralysis that requires urgent medical\nattention and has to be differentiated from other, similar conditions such as\nperipheral palsy. To aid in fast and accurate diagnosis of this condition, we\npropose a machine learning approach to automatically classify peripheral and\ncentral facial palsy. The Palda dataset is used, which contains 103 peripheral\npalsy images, 40 central palsy, and 60 healthy people. Experiments are run on\nfive machine learning algorithms. The best performing algorithms were found to\nbe the SVM (total accuracy of 85.1%) and the Gaussian naive Bayes (80.7%). The\nlowest false negative rate on central palsy was achieved by the naive Bayes\napproach (80% compared to 70%). This condition could prove to be the most\nsevere, and thus its sensitivity is another good way to compare algorithms. By\nextrapolation, a dataset size of 334 total pictures is estimated to achieve a\ncentral palsy sensitivity of 95%. All code used for these machine learning\nexperiments is freely available online at https://github.com/cvvletter/palsy.",
    "descriptor": "\nComments: 9 pages, 10 tables, 10 figures\n",
    "authors": [
      "C.V. Vletter",
      "H.L. Burger",
      "H. Alers",
      "N. Sourlos",
      "Z. Al-Ars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11852"
  },
  {
    "id": "arXiv:2201.11853",
    "title": "Prediction of GPU Failures Under Deep Learning Workloads",
    "abstract": "Graphics processing units (GPUs) are the de facto standard for processing\ndeep learning (DL) tasks. Meanwhile, GPU failures, which are inevitable, cause\nsevere consequences in DL tasks: they disrupt distributed trainings, crash\ninference services, and result in service level agreement violations. To\nmitigate the problem caused by GPU failures, we propose to predict failures by\nusing ML models. This paper is the first to study prediction models of GPU\nfailures under large-scale production deep learning workloads. As a starting\npoint, we evaluate classic prediction models and observe that predictions of\nthese models are both inaccurate and unstable. To improve the precision and\nstability of predictions, we propose several techniques, including parallel and\ncascade model-ensemble mechanisms and a sliding training method. We evaluate\nthe performances of our various techniques on a four-month production dataset\nincluding 350 million entries. The results show that our proposed techniques\nimprove the prediction precision from 46.3\\% to 84.0\\%.",
    "descriptor": "",
    "authors": [
      "Heting Liu",
      "Zhichao Li",
      "Cheng Tan",
      "Rongqiu Yang",
      "Guohong Cao",
      "Zherui Liu",
      "Chuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11853"
  },
  {
    "id": "arXiv:2201.11854",
    "title": "Decentralized Fictitious Play Converges Near a Nash Equilibrium in  Near-Potential Games",
    "abstract": "We investigate convergence of decentralized fictitious play (DFP) in\nnear-potential games, wherein agents preferences can almost be captured by a\npotential function. In DFP agents keep local estimates of other agents'\nempirical frequencies, best-respond against these estimates, and receive\ninformation over a time-varying communication network. We prove that empirical\nfrequencies of actions generated by DFP converge around a single Nash\nEquilibrium (NE) assuming that there are only finitely many Nash equilibria,\nand the difference in utility functions resulting from unilateral deviations is\nclose enough to the difference in the potential function values. This result\nassures that DFP has the same convergence properties of standard Fictitious\nplay (FP) in near-potential games.",
    "descriptor": "\nComments: 5 pages, Accepted to 2021 The Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Sarper Aydin",
      "Sina Arefizadeh",
      "Ceyhun Eksin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11854"
  },
  {
    "id": "arXiv:2201.11855",
    "title": "Accountability and Insurance in IoT Supply Chain",
    "abstract": "Supply chain security has become a growing concern in security risk analysis\nof the Internet of Things (IoT) systems. Their highly connected structures have\nsignificantly enlarged the attack surface, making it difficult to track the\nsource of the risk posed by malicious or compromised suppliers. This chapter\npresents a system-scientific framework to study the accountability in IoT\nsupply chains and provides a holistic risk analysis technologically and\nsocio-economically. We develop stylized models and quantitative approaches to\nevaluate the accountability of the suppliers. Two case studies are used to\nillustrate accountability measures for scenarios with single and multiple\nagents. Finally, we present the contract design and cyber insurance as economic\nsolutions to mitigate supply chain risks. They are incentive-compatible\nmechanisms that encourage truth-telling of the supplier and facilitate reliable\naccountability investigation for the buyer.",
    "descriptor": "",
    "authors": [
      "Yunfei Ge",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11855"
  },
  {
    "id": "arXiv:2201.11857",
    "title": "Using Shape Metrics to Describe 2D Data Points",
    "abstract": "Traditional machine learning (ML) algorithms, such as multiple regression,\nrequire human analysts to make decisions on how to treat the data. These\ndecisions can make the model building process subjective and difficult to\nreplicate for those who did not build the model. Deep learning approaches\nbenefit by allowing the model to learn what features are important once the\nhuman analyst builds the architecture. Thus, a method for automating certain\nhuman decisions for traditional ML modeling would help to improve the\nreproducibility and remove subjective aspects of the model building process. To\nthat end, we propose to use shape metrics to describe 2D data to help make\nanalyses more explainable and interpretable. The proposed approach provides a\nfoundation to help automate various aspects of model building in an\ninterpretable and explainable fashion. This is particularly important in\napplications in the medical community where the `right to explainability' is\ncrucial. We provide various simulated data sets ranging from probability\ndistributions, functions, and model quality control checks (such as QQ-Plots\nand residual analyses from ordinary least squares) to showcase the breadth of\nthis approach.",
    "descriptor": "",
    "authors": [
      "William Franz Lamberti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11857"
  },
  {
    "id": "arXiv:2201.11859",
    "title": "Distributed Stochastic Model Predictive Control for Human-Leading  Heavy-Duty Truck Platoon",
    "abstract": "Human-leading truck platooning systems have been proposed to leverage the\nbenefits of both human supervision and vehicle autonomy. Equipped with human\nguidance and autonomous technology, human-leading truck platooning systems are\nmore versatile to handle uncertain traffic conditions than fully automated\nplatooning systems. This paper presents a novel distributed stochastic model\npredictive control (DSMPC) design for a human-leading heavy-duty truck platoon.\nThe proposed DSMPC design integrates the stochastic driver behavior model of\nthe human-driven leader truck with a distributed formation control design for\nthe following automated trucks in the platoon. The driver behavior of the\nhuman-driven leader truck is learned by a stochastic inverse reinforcement\nlearning (SIRL) approach. The proposed stochastic driver behavior model aims to\nlearn a distribution of cost function, which represents the richness and\nuniqueness of human driver behaviors, with a given set of driver-specific\ndemonstrations. The distributed formation control includes a serial DSMPC with\nguaranteed recursive feasibility, closed-loop chance constraint satisfaction,\nand string stability. Simulation studies are conducted to investigate the\nefficacy of the proposed design under several realistic traffic scenarios.\nCompared to the baseline platoon control strategy (deterministic distributed\nmodel predictive control), the proposed DSMPC achieves superior controller\nperformance in constraint violations and spacing errors.",
    "descriptor": "\nComments: To appear in IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Yao Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11859"
  },
  {
    "id": "arXiv:2201.11860",
    "title": "On the Anonymity of Peer-To-Peer Network Anonymity Schemes Used by  Cryptocurrencies",
    "abstract": "Cryptocurrency systems can be subject to deanonymization attacks by\nexploiting the network-level communication on their peer-to-peer network.\nAdversaries who control a set of colluding node(s) within the peer-to-peer\nnetwork can observe transactions being exchanged and infer the parties\ninvolved. Thus, various network anonymity schemes have been proposed to\nmitigate this problem, with some solutions providing theoretical anonymity\nguarantees.\nIn this work, we model such peer-to-peer network anonymity solutions and\nevaluate their anonymity guarantees. To do so, we propose a novel framework\nthat uses Bayesian inference to obtain the probability distributions linking\ntransactions to their possible originators. We characterize transaction\nanonymity with those distributions, using entropy as metric of adversarial\nuncertainty on the originator's identity. In particular, we model Dandelion,\nDandelion++ and Lightning Network. We study different configurations and\ndemonstrate that none of them offers acceptable anonymity to their users. For\ninstance, our analysis reveals that in the widely deployed Lightning Network,\nwith just 5 strategically chosen colluding nodes the adversary can uniquely\ndetermine the originator for 67% of the transactions. In Dandelion, an\nadversary that controls 15% of the nodes has on average uncertainty among only\n4 possible originators. Moreover, we observe that due to the way Dandelion and\nDandelion++ are designed, increasing the network size does not correspond to an\nincrease in the anonymity set of potential originators, highlighting the\nlimitations of existing proposals.",
    "descriptor": "",
    "authors": [
      "Piyush Kumar Sharma",
      "Devashish Gosain",
      "Claudia Diaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11860"
  },
  {
    "id": "arXiv:2201.11861",
    "title": "The Challenges of Exploration for Offline Reinforcement Learning",
    "abstract": "Offline Reinforcement Learning (ORL) enablesus to separately study the two\ninterlinked processes of reinforcement learning: collecting informative\nexperience and inferring optimal behaviour. The second step has been widely\nstudied in the offline setting, but just as critical to data-efficient RL is\nthe collection of informative data. The task-agnostic setting for data\ncollection, where the task is not known a priori, is of particular interest due\nto the possibility of collecting a single dataset and using it to solve several\ndownstream tasks as they arise. We investigate this setting via curiosity-based\nintrinsic motivation, a family of exploration methods which encourage the agent\nto explore those states or transitions it has not yet learned to model. With\nExplore2Offline, we propose to evaluate the quality of collected data by\ntransferring the collected data and inferring policies with reward relabelling\nand standard offline RL algorithms. We evaluate a wide variety of data\ncollection strategies, including a new exploration agent, Intrinsic Model\nPredictive Control (IMPC), using this scheme and demonstrate their performance\non various tasks. We use this decoupled framework to strengthen intuitions\nabout exploration and the data prerequisites for effective offline RL.",
    "descriptor": "",
    "authors": [
      "Nathan Lambert",
      "Markus Wulfmeier",
      "William Whitney",
      "Arunkumar Byravan",
      "Michael Bloesch",
      "Vibhavari Dasagi",
      "Tim Hertweck",
      "Martin Riedmiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11861"
  },
  {
    "id": "arXiv:2201.11865",
    "title": "FedLite: A Scalable Approach for Federated Learning on  Resource-constrained Clients",
    "abstract": "In classical federated learning, the clients contribute to the overall\ntraining by communicating local updates for the underlying model on their\nprivate data to a coordinating server. However, updating and communicating the\nentire model becomes prohibitively expensive when resource-constrained clients\ncollectively aim to train a large machine learning model. Split learning\nprovides a natural solution in such a setting, where only a small part of the\nmodel is stored and trained on clients while the remaining large part of the\nmodel only stays at the servers. However, the model partitioning employed in\nsplit learning introduces a significant amount of communication cost. This\npaper addresses this issue by compressing the additional communication using a\nnovel clustering scheme accompanied by a gradient correction method. Extensive\nempirical evaluations on image and text benchmarks show that the proposed\nmethod can achieve up to $490\\times$ communication cost reduction with minimal\ndrop in accuracy, and enables a desirable performance vs. communication\ntrade-off.",
    "descriptor": "",
    "authors": [
      "Jianyu Wang",
      "Hang Qi",
      "Ankit Singh Rawat",
      "Sashank Reddi",
      "Sagar Waghmare",
      "Felix X. Yu",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11865"
  },
  {
    "id": "arXiv:2201.11867",
    "title": "Neural-FST Class Language Model for End-to-End Speech Recognition",
    "abstract": "We propose Neural-FST Class Language Model (NFCLM) for end-to-end speech\nrecognition, a novel method that combines neural network language models\n(NNLMs) and finite state transducers (FSTs) in a mathematically consistent\nframework. Our method utilizes a background NNLM which models generic\nbackground text together with a collection of domain-specific entities modeled\nas individual FSTs. Each output token is generated by a mixture of these\ncomponents; the mixture weights are estimated with a separately trained neural\ndecider. We show that NFCLM significantly outperforms NNLM by 15.8% relative in\nterms of Word Error Rate. NFCLM achieves similar performance as traditional\nNNLM and FST shallow fusion while being less prone to overbiasing and 12 times\nmore compact, making it more suitable for on-device usage.",
    "descriptor": "",
    "authors": [
      "Antoine Bruguier",
      "Duc Le",
      "Rohit Prabhavalkar",
      "Dangna Li",
      "Zhe Liu",
      "Bo Wang",
      "Eun Chang",
      "Fuchun Peng",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11867"
  },
  {
    "id": "arXiv:2201.11870",
    "title": "Multiple-Source Domain Adaptation via Coordinated Domain Encoders and  Paired Classifiers",
    "abstract": "We present a novel multiple-source unsupervised model for text classification\nunder domain shift. Our model exploits the update rates in document\nrepresentations to dynamically integrate domain encoders. It also employs a\nprobabilistic heuristic to infer the error rate in the target domain in order\nto pair source classifiers. Our heuristic exploits data transformation cost and\nthe classifier accuracy in the target feature space. We have used real world\nscenarios of Domain Adaptation to evaluate the efficacy of our algorithm. We\nalso used pretrained multi-layer transformers as the document encoder in the\nexperiments to demonstrate whether the improvement achieved by domain\nadaptation models can be delivered by out-of-the-box language model\npretraining. The experiments testify that our model is the top performing\napproach in this setting.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Payam Karisani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11870"
  },
  {
    "id": "arXiv:2201.11871",
    "title": "Infrastructure-Based Object Detection and Tracking for Cooperative  Driving Automation: A Survey",
    "abstract": "Object detection plays a fundamental role in enabling Cooperative Driving\nAutomation (CDA), which is regarded as the revolutionary solution to addressing\nsafety, mobility, and sustainability issues of contemporary transportation\nsystems. Although current computer vision technologies could provide\nsatisfactory object detection results in occlusion-free scenarios, the\nperception performance of onboard sensors could be inevitably limited by the\nrange and occlusion. Owing to flexible position and pose for sensor\ninstallation, infrastructure-based detection and tracking systems can enhance\nthe perception capability for connected vehicles and thus quickly become one of\nthe most popular research topics. In this paper, we review the research\nprogress for infrastructure-based object detection and tracking systems.\nArchitectures of roadside perception systems based on different types of\nsensors are reviewed to show a high-level description of the workflows for\ninfrastructure-based perception systems. Roadside sensors and different\nperception methodologies are reviewed and analyzed with detailed literature to\nprovide a low-level explanation for specific methods followed by Datasets and\nSimulators to draw an overall landscape of infrastructure-based object\ndetection and tracking methods. Discussions are conducted to point out current\nopportunities, open problems, and anticipated future trends.",
    "descriptor": "",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Xuewei Qi",
      "Yongkang Liu",
      "Kentaro Oguchi",
      "Matthew J. Barth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11871"
  },
  {
    "id": "arXiv:2201.11872",
    "title": "Local Latent Space Bayesian Optimization over Structured Inputs",
    "abstract": "Bayesian optimization over the latent spaces of deep autoencoder models\n(DAEs) has recently emerged as a promising new approach for optimizing\nchallenging black-box functions over structured, discrete, hard-to-enumerate\nsearch spaces (e.g., molecules). Here the DAE dramatically simplifies the\nsearch space by mapping inputs into a continuous latent space where familiar\nBayesian optimization tools can be more readily applied. Despite this\nsimplification, the latent space typically remains high-dimensional. Thus, even\nwith a well-suited latent space, these approaches do not necessarily provide a\ncomplete solution, but may rather shift the structured optimization problem to\na high-dimensional one. In this paper, we propose LOL-BO, which adapts the\nnotion of trust regions explored in recent work on high-dimensional Bayesian\noptimization to the structured setting. By reformulating the encoder to\nfunction as both an encoder for the DAE globally and as a deep kernel for the\nsurrogate model within a trust region, we better align the notion of local\noptimization in the latent space with local optimization in the input space.\nLOL-BO achieves as much as 20 times improvement over state-of-the-art latent\nspace Bayesian optimization methods across six real-world benchmarks,\ndemonstrating that improvement in optimization strategies is as important as\ndeveloping better DAE models.",
    "descriptor": "",
    "authors": [
      "Natalie Maus",
      "Haydn T. Jones",
      "Juston S. Moore",
      "Matt J. Kusner",
      "John Bradshaw",
      "Jacob R. Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11872"
  },
  {
    "id": "arXiv:2201.11876",
    "title": "Regionalized optimization",
    "abstract": "Yedidia, Freeman, Weiss have shown in their reference article, \"Constructing\nFree Energy Approximations and Generalized Belief Propagation Algorithms\", that\nthere is a variational principle underlying the General Belief Propagation, by\nintroducing a region-based free energy approximation of the MaxEnt free energy,\nthat we will call the Generalized Bethe free energy. They sketched a proof that\nfixed points of the General Belief Propagation are critical points of this free\nenergy, this proof was completed in the thesis of Peltre. In this paper we\nidentify a class of optimization problems defined as patching local\noptimization problems and associated message passing algorithms for which such\ncorrespondence between critical points and fix points of the algorithms holds.\nThis framework holds many applications one of which being a PCA for filtered\ndata and a region-based approximation of MaxEnT with stochastic compatibility\nconstraints on the region probabilities. Such approach is particularly adapted\nfor inference with multimodal integration, inference on scenes with multiple\nviews.",
    "descriptor": "",
    "authors": [
      "Gr\u00e9goire Sergeant-Perthuis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11876"
  },
  {
    "id": "arXiv:2201.11878",
    "title": "Research on Wearable Technologies for Learning: A Systematic Review",
    "abstract": "A good amount of research has explored the use of wearables for educational\nor learning purposes. We have now reached a point when much literature can be\nfound on that topic, but few attempts have been made to make sense of that\nliterature from a holistic perspective. This paper presents a systematic review\nof the literature on wearables for learning. Literature was sourced from\nconferences and journals pertaining to technology and education, and through an\nad hoc search. Our review focuses on identifying the ways that wearables have\nbeen used to support learning and provides perspectives on that issue from a\nhistorical dimension, and with regards to the types of wearables used, the\npopulations targeted, and the settings addressed. Seven different ways of how\nwearables have been used to support learning were identified. We propose a\nframework identifying five main components that have been addressed in existing\nresearch on how wearables can support learning and present our interpretations\nof unaddressed research directions based on our review results.",
    "descriptor": "",
    "authors": [
      "Sharon Lynn Chu",
      "Brittany M. Garcia",
      "Neha Rani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11878"
  },
  {
    "id": "arXiv:2201.11879",
    "title": "Random Caching Design for Multi-User Multi-Antenna HetNets with  Interference Nulling",
    "abstract": "The strong interference suffered by users can be a severe problem in\ncache-enabled networks (CENs) due to the content-centric user association\nmechanism. To tackle this issue, multi-antenna technology may be employed for\ninterference management. In this paper, we consider a user-centric interference\nnulling (IN) scheme in two-tier multi-user multi-antenna CEN, with a hybrid\nmost-popular and random caching policy at macro base stations (MBSs) and small\nbase stations (SBSs) to provide file diversity. All the interfering SBSs within\nthe IN range of a user are requested to suppress the interference at this user\nusing zero-forcing beamforming. Using stochastic geometry analysis techniques,\nwe derive a tractable expression for the area spectral efficiency (ASE). A\nlower bound on the ASE is also obtained, with which we then consider ASE\nmaximization, by optimizing the caching policy and IN coefficient. To solve the\nresultant mixed integer programming problem, we design an alternating\noptimization algorithm to minimize the lower bound of the ASE. Our numerical\nresults demonstrate that the proposed caching policy yields performance that is\nclose to the optimum, and it outperforms several existing baselines.",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Tianming Feng",
      "Xuemai Gu",
      "Ben Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11879"
  },
  {
    "id": "arXiv:2201.11884",
    "title": "Making the Unaccountable Internet: The Changing Meaning of Accounting in  the Design of the Early Internet",
    "abstract": "Contemporary concerns over the governance of technological systems often run\nup against compelling narratives about technical (in)feasibility of designing\nmechanisms for accountability. While in recent FAccT literature these concerns\nhave been deliberated predominantly in relation to machine learning, other\ninstances in the history of computing also presented circumstances in which\ncomputer scientists needed to un-muddle what it means to design (un)accountable\nsystems. One such a compelling narrative can frequently be found in canonical\nhistories of the Internet that highlight how its original designers' commitment\nto the \"End-to-End\" architectural principle precluded other features from being\nimplemented, resulting in the fast-growing, generative, but ultimately\nunaccountable network we have today. This paper offers a critique of such\ntechnologically essentialist notions of accountability and the characterization\nof the \"unaccountable Internet\" as an unintended consequence. We explore the\nchanging meaning of accounting and its relationship to accountability in a\nselected corpus of requests for comments (RFCs) concerning the early Internet's\ndesign from the 1970s and 80s. We characterize 4 phases of conceptualizing\naccounting: as billing, as measurement, as management, and as policy, and\ndemonstrate how an understanding of accountability was constituted through\nthese shifting meanings. Recovering this history is not only important for\nunderstanding the processes that shaped the Internet, but also serves as a\nstarting point for unpacking the complicated political choices that are\ninvolved in designing accountability mechanisms for other technological systems\ntoday.",
    "descriptor": "\nComments: Under submission. Preprint\n",
    "authors": [
      "A. Feder Cooper",
      "Gili Vidan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11884"
  },
  {
    "id": "arXiv:2201.11885",
    "title": "Boosting Entity Mention Detection for Targetted Twitter Streams with  Global Contextual Embeddings",
    "abstract": "Microblogging sites, like Twitter, have emerged as ubiquitous sources of\ninformation. Two important tasks related to the automatic extraction and\nanalysis of information in Microblogs are Entity Mention Detection (EMD) and\nEntity Detection (ED). The state-of-the-art EMD systems aim to model the\nnon-literary nature of microblog text by training upon offline static datasets.\nThey extract a combination of surface-level features -- orthographic, lexical,\nand semantic -- from individual messages for noisy text modeling and entity\nextraction. But given the constantly evolving nature of microblog streams,\ndetecting all entity mentions from such varying yet limited context of short\nmessages remains a difficult problem. To this end, we propose a framework named\nEMD Globalizer, better suited for the execution of EMD learners on microblog\nstreams. It deviates from the processing of isolated microblog messages by\nexisting EMD systems, where learned knowledge from the immediate context of a\nmessage is used to suggest entities. After an initial extraction of entity\ncandidates by an EMD system, the proposed framework leverages occurrence mining\nto find additional candidate mentions that are missed during this first\ndetection. Aggregating the local contextual representations of these mentions,\na global embedding is drawn from the collective context of an entity candidate\nwithin a stream. The global embeddings are then utilized to separate entities\nwithin the candidates from false positives. All mentions of said entities from\nthe stream are produced in the framework's final outputs. Our experiments show\nthat EMD Globalizer can enhance the effectiveness of all existing EMD systems\nthat we tested (on average by 25.61%) with a small additional computational\noverhead.",
    "descriptor": "",
    "authors": [
      "Satadisha Saha Bhowmick",
      "Eduard C. Dragut",
      "Weiyi Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11885"
  },
  {
    "id": "arXiv:2201.11891",
    "title": "Function Computation Without Secure Links: Information and Leakage Rates",
    "abstract": "Consider L users, who each holds private data, and one fusion center who must\ncompute a function of the private data of the L users. To accomplish this task,\neach user can make a single use of a public and noiseless broadcast channel. In\nthis setting, and in the absence of any additional resources such as secure\nlinks, we study the optimal communication rates and minimum information\nleakages on the private user data that are achievable. Specifically, we study\nthe information leakage of the user data at the fusion center (beyond the\nknowledge of the function output), as well as at predefined groups of colluding\nusers who eavesdrop one another. We derive the capacity region when the user\ndata is independent, and inner and outer regions for the capacity region when\nthe user data is correlated.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Remi A. Chou",
      "Joerg Kliewer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11891"
  },
  {
    "id": "arXiv:2201.11893",
    "title": "A New High Energy Efficiency Scheme Based on Two-Dimension Resource  Blocks in Wireless Communication Systems",
    "abstract": "Energy efficiency (EE) plays a key role in future wireless communication\nnetwork and it is easily to achieve high EE performance in low SNR regime. In\nthis paper, a new high EE scheme is proposed for a MIMO wireless communication\nsystem working in the low SNR regime by using two dimension resource\nallocation. First, we define the high EE area based on the relationship between\nthe transmission power and the SNR. To meet the constraint of the high EE area,\nboth frequency and space dimension are needed. Besides analysing them\nseparately, we decided to consider frequency and space dimensions as a unit and\nproposed a two-dimension scheme. Furthermore, considering communication in the\nhigh EE area may cause decline of the communication quality, we add\nquality-of-service(QoS) constraint into the consideration and derive the\ncorresponding EE performance based on the effective capacity. We also derive an\napproximate expression to simplify the complex EE performance. Finally, our\nnumerical results demonstrate the effectiveness of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Kang Liu",
      "Zaichen Zhang",
      "Jian Dang",
      "Liang Wu",
      "Bingchen Zhu",
      "Lei Wang",
      "Chuan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11893"
  },
  {
    "id": "arXiv:2201.11895",
    "title": "The CARE Dataset for Affective Response Detection",
    "abstract": "Social media plays an increasing role in our communication with friends and\nfamily, and our consumption of information and entertainment. Hence, to design\neffective ranking functions for posts on social media, it would be useful to\npredict the affective response to a post (e.g., whether the user is likely to\nbe humored, inspired, angered, informed). Similar to work on emotion\nrecognition (which focuses on the affect of the publisher of the post), the\ntraditional approach to recognizing affective response would involve an\nexpensive investment in human annotation of training data.\nWe introduce CARE$_{db}$, a dataset of 230k social media posts annotated\naccording to 7 affective responses using the Common Affective Response\nExpression (CARE) method. The CARE method is a means of leveraging the signal\nthat is present in comments that are posted in response to a post, providing\nhigh-precision evidence about the affective response of the readers to the post\nwithout human annotation. Unlike human annotation, the annotation process we\ndescribe here can be iterated upon to expand the coverage of the method,\nparticularly for new affective responses. We present experiments that\ndemonstrate that the CARE annotations compare favorably with crowd-sourced\nannotations. Finally, we use CARE$_{db}$ to train competitive BERT-based models\nfor predicting affective response as well as emotion detection, demonstrating\nthe utility of the dataset for related tasks.",
    "descriptor": "",
    "authors": [
      "Jane A. Yu",
      "Alon Y. Halevy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11895"
  },
  {
    "id": "arXiv:2201.11897",
    "title": "Identifying Emergent Leadership in OSS Projects Based on Communication  Styles",
    "abstract": "In open source software (OSS) communities, existing leadership indicators are\ndominantly measured by code contribution or community influence. Recent studies\non emergent leadership shed light on additional dimensions such as intellectual\nstimulation in collaborative communications. To that end, this paper proposes\nan automated approach, named iLead, to mine communication styles and identify\nemergent leadership behaviors in OSS communities, using issue comments data. We\nstart with the construction of 6 categories of leadership behaviors based on\nexisting leadership studies. Then, we manually label leadership behaviors in\n10,000 issue comments from 10 OSS projects, and extract 304 heuristic\nlinguistic patterns which represent different types of emergent leadership\nbehaviors in flexible and concise manners. Next, an automated algorithm is\ndeveloped to merge and consolidate different pattern sets extracted from\nmultiple projects into a final pattern ranking list, which can be applied for\nthe automatic leadership identification. The evaluation results show that iLead\ncan achieve a median precision of 0.82 and recall of 0.78, outperforming ten\nmachine/deep learning baselines. To demonstrate practical usefulness, we also\nconduct empirical analysis and human evaluation of the identified leadership\nbehaviors from iLead. We argue that emergent leadership behaviors in issue\ndiscussion should be taken into consideration to broaden existing OSS\nleadership viewpoints. Practical insights on community building and leadership\nskill development are offered for OSS community and individual developers,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Yuekai Huang",
      "Ye Yang",
      "Junjie Wang",
      "Wei Zheng",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11897"
  },
  {
    "id": "arXiv:2201.11898",
    "title": "Indicative Image Retrieval: Turning Blackbox Learning into Grey",
    "abstract": "Deep learning became the game changer for image retrieval soon after it was\nintroduced. It promotes the feature extraction (by representation learning) as\nthe core of image retrieval, with the relevance/matching evaluation being\ndegenerated into simple similarity metrics. In many applications, we need the\nmatching evidence to be indicated rather than just have the ranked list (e.g.,\nthe locations of the target proteins/cells/lesions in medical images). It is\nlike the matched words need to be highlighted in search engines. However, this\nis not easy to implement without explicit relevance/matching modeling. The deep\nrepresentation learning models are not feasible because of their blackbox\nnature. In this paper, we revisit the importance of relevance/matching modeling\nin deep learning era with an indicative retrieval setting. The study shows that\nit is possible to skip the representation learning and model the matching\nevidence directly. By removing the dependency on the pre-trained models, it has\navoided a lot of related issues (e.g., the domain gap between classification\nand retrieval, the detail-diffusion caused by convolution, and so on). More\nimportantly, the study demonstrates that the matching can be explicitly modeled\nand backtracked later for generating the matching evidence indications. It can\nimprove the explainability of deep inference. Our method obtains a best\nperformance in literature on both Oxford-5k and Paris-6k, and sets a new record\nof 97.77% on Oxford-5k (97.81% on Paris-6k) without extracting any deep\nfeatures.",
    "descriptor": "",
    "authors": [
      "Xulu Zhang",
      "Zhenqun Yang",
      "Hao Tian",
      "Qing Li",
      "Xiaoyong Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11898"
  },
  {
    "id": "arXiv:2201.11899",
    "title": "Private Classical Communication over Quantum Multiple-Access Channels",
    "abstract": "We study private classical communication over quantum multiple-access\nchannels. For an arbitrary number of transmitters, we derive a regularized\nexpression of the capacity region. In the case of degradable channels, we\nestablish a single-letter expression for the best achievable sum-rate and prove\nthat this quantity also corresponds to the best achievable sum-rate for quantum\ncommunication over degradable quantum multiple-access channels. In our\nachievability result, we decouple the reliability and privacy constraints,\nwhich are handled via source coding with quantum side information and universal\nhashing, respectively. Hence, we also establish that the multi-user coding\nproblem under consideration can be handled solely via point-to-point coding\ntechniques. As a by-product of independent interest, we derive a distributed\nleftover hash lemma against quantum side information that ensures privacy in\nour achievability result.",
    "descriptor": "\nComments: 13 pages, two-column, accepted to IEEE Transactions on Information Theory, part of the results was presented at the 2021 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "Remi A. Chou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.11899"
  },
  {
    "id": "arXiv:2201.11902",
    "title": "Geometric instability of out of distribution data across autoencoder  architecture",
    "abstract": "We study the map learned by a family of autoencoders trained on MNIST, and\nevaluated on ten different data sets created by the random selection of pixel\nvalues according to ten different distributions. Specifically, we study the\neigenvalues of the Jacobians defined by the weight matrices of the autoencoder\nat each training and evaluation point. For high enough latent dimension, we\nfind that each autoencoder reconstructs all the evaluation data sets as similar\n\\emph{generalized characters}, but that this reconstructed \\emph{generalized\ncharacter} changes across autoencoder. Eigenvalue analysis shows that even when\nthe reconstructed image appears to be an MNIST character for all out of\ndistribution data sets, not all have latent representations that are close to\nthe latent representation of MNIST characters. All told, the eigenvalue\nanalysis demonstrated a great deal of geometric instability of the autoencoder\nboth as a function on out of distribution inputs, and across architectures on\nthe same set of inputs.",
    "descriptor": "",
    "authors": [
      "Susama Agarwala",
      "Ben Dees",
      "Corey Lowman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11902"
  },
  {
    "id": "arXiv:2201.11903",
    "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "abstract": "Although scaling up language model size has reliably improved performance on\na range of NLP tasks, even the largest models currently struggle with certain\nreasoning tasks such as math word problems, symbolic manipulation, and\ncommonsense reasoning. This paper explores the ability of language models to\ngenerate a coherent chain of thought -- a series of short sentences that mimic\nthe reasoning process a person might have when responding to a question.\nExperiments show that inducing a chain of thought via prompting can enable\nsufficiently large language models to better perform reasoning tasks that\notherwise have flat scaling curves.",
    "descriptor": "",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Ed Chi",
      "Quoc Le",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11903"
  },
  {
    "id": "arXiv:2201.11910",
    "title": "Coupled power generators require stability buffers in addition to  inertia",
    "abstract": "Increasing the inertia is widely considered to be the solution to resolving\nunstable interactions between coupled oscillators. In power grids, Virtual\nSynchronous Generators (VSGs) are proposed to compensate the reducing inertia\nas rotating synchronous generators are being phased out. Yet, modeling how VSGs\nand rotating generators simultaneously contribute energy and inertia, we\nsurprisingly find that instabilities of a small-signal nature could arise\ndespite fairly high system inertia. Importantly, we show there exist both an\noptimal and a maximum number of such VSGs that can be safely supported, a\npreviously unknown result directly useful for power utilities in long-term\nplanning and prosumer contracting. Meanwhile, to resolve instabilities in the\nshort term, we argue that the new market should include another commodity that\nwe call stability storage, whereby -- analogous to energy storage buffering\nenergy imbalances -- VSGs act as decentralized stability buffers. While\ndemonstrating the effectiveness of this concept for a wide range of energy\nfutures, we provide policymakers and utilities with a roadmap towards achieving\na 100% renewable grid.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Gurupraanesh Raman",
      "Gururaghav Raman",
      "Jimmy Chih-Hsien Peng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11910"
  },
  {
    "id": "arXiv:2201.11915",
    "title": "The fine line between dead neurons and sparsity in binarized spiking  neural networks",
    "abstract": "Spiking neural networks can compensate for quantization error by encoding\ninformation either in the temporal domain, or by processing discretized\nquantities in hidden states of higher precision. In theory, a wide dynamic\nrange state-space enables multiple binarized inputs to be accumulated together,\nthus improving the representational capacity of individual neurons. This may be\nachieved by increasing the firing threshold, but make it too high and sparse\nspike activity turns into no spike emission. In this paper, we propose the use\nof `threshold annealing' as a warm-up method for firing thresholds. We show it\nenables the propagation of spikes across multiple layers where neurons would\notherwise cease to fire, and in doing so, achieve highly competitive results on\nfour diverse datasets, despite using binarized weights. Source code is\navailable at https://github.com/jeshraghian/snn-tha/",
    "descriptor": "",
    "authors": [
      "Jason K. Eshraghian",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.11915"
  },
  {
    "id": "arXiv:2201.11916",
    "title": "Constraint-based Formation of Drone Swarms",
    "abstract": "Drone swarms are required for the simultaneous delivery of multiple packages.\nWe demonstrate a multi-stop drone swarm-based delivery in a smart city. We\nleverage formation flying to conserve energy and increase the flight range of a\ndrone swarm. An adaptive formation is presented in which a swarm adjusts to\nextrinsic constraints and changes the formation pattern in-flight. We utilize\nthe existing building rooftops in a city and build a line-of-sight skyway\nnetwork to safely operate the swarms. We use a heuristic-based A* algorithm to\nroute a drone swarm in a skyway network.",
    "descriptor": "\nComments: 3 pages, 6 figures. This is an accepted paper and it is going to appear in the Proceedings of the 20th International Conference on Pervasive Computing and Communications (PerCom 2022)\n",
    "authors": [
      "Xijing Liu",
      "Kevin Lam",
      "Balsam Alkouz",
      "Babar Shahzaad",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11916"
  },
  {
    "id": "arXiv:2201.11917",
    "title": "Task-Aware Network Coding Over Butterfly Network",
    "abstract": "Network coding allows distributed information sources such as sensors to\nefficiently compress and transmit data to distributed receivers across a\nbandwidth-limited network. Classical network coding is largely task-agnostic --\nthe coding schemes mainly aim to faithfully reconstruct data at the receivers,\nregardless of what ultimate task the received data is used for. In this paper,\nwe analyze a new task-driven network coding problem, where distributed\nreceivers pass transmitted data through machine learning (ML) tasks, which\nprovides an opportunity to improve efficiency by transmitting salient\ntask-relevant data representations. Specifically, we formulate a task-aware\nnetwork coding problem over a butterfly network in real-coordinate space, where\nlossy analog compression through principal component analysis (PCA) can be\napplied. A lower bound for the total loss function for the formulated problem\nis given, and necessary and sufficient conditions for achieving this lower\nbound are also provided. We introduce ML algorithms to solve the problem in the\ngeneral case, and our evaluation demonstrates the effectiveness of task-aware\nnetwork coding.",
    "descriptor": "",
    "authors": [
      "Jiangnan Cheng",
      "Sandeep Chinchali",
      "Ao Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11917"
  },
  {
    "id": "arXiv:2201.11921",
    "title": "Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed  Bandits",
    "abstract": "In this paper, we generalize the concept of heavy-tailed multi-armed bandits\nto adversarial environments, and develop robust best-of-both-worlds algorithms\nfor heavy-tailed multi-armed bandits (MAB), where losses have $\\alpha$-th\n($1<\\alpha\\le 2$) moments bounded by $\\sigma^\\alpha$, while the variances may\nnot exist. Specifically, we design an algorithm \\texttt{HTINF}, when the\nheavy-tail parameters $\\alpha$ and $\\sigma$ are known to the agent,\n\\texttt{HTINF} simultaneously achieves the optimal regret for both stochastic\nand adversarial environments, without knowing the actual environment type\na-priori. When $\\alpha,\\sigma$ are unknown, \\texttt{HTINF} achieves a $\\log\nT$-style instance-dependent regret in stochastic cases and $o(T)$ no-regret\nguarantee in adversarial cases. We further develop an algorithm\n\\texttt{AdaTINF}, achieving $\\mathcal O(\\sigma K^{1-\\nicefrac\n1\\alpha}T^{\\nicefrac{1}{\\alpha}})$ minimax optimal regret even in adversarial\nsettings, without prior knowledge on $\\alpha$ and $\\sigma$. This result matches\nthe known regret lower-bound (Bubeck et al., 2013), which assumed a stochastic\nenvironment and $\\alpha$ and $\\sigma$ are both known. To our knowledge, the\nproposed \\texttt{HTINF} algorithm is the first to enjoy a best-of-both-worlds\nregret guarantee, and \\texttt{AdaTINF} is the first algorithm that can adapt to\nboth $\\alpha$ and $\\sigma$ to achieve optimal gap-indepedent regret bound in\nclassical heavy-tailed stochastic MAB setting and our novel adversarial\nformulation.",
    "descriptor": "",
    "authors": [
      "Jiatai Huang",
      "Yan Dai",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11921"
  },
  {
    "id": "arXiv:2201.11924",
    "title": "Close the Visual Domain Gap by Physics-Grounded Active Stereovision  Depth Sensor Simulation",
    "abstract": "In this paper, we focus on the simulation of active stereovision depth\nsensors, which are popular in both academic and industry communities. Inspired\nby the underlying mechanism of the sensors, we designed a fully\nphysics-grounded simulation pipeline, which includes material acquisition, ray\ntracing based infrared (IR) image rendering, IR noise simulation, and depth\nestimation. The pipeline is able to generate depth maps with material-dependent\nerror patterns similar to a real depth sensor. We conduct extensive experiments\nto show that perception algorithms and reinforcement learning policies trained\nin our simulation platform could transfer well to real world test cases without\nany fine-tuning. Furthermore, due to the high degree of realism of this\nsimulation, our depth sensor simulator can be used as a convenient testbed to\nevaluate the algorithm performance in the real world, which will largely reduce\nthe human effort in developing robotic algorithms. The entire pipeline has been\nintegrated into the SAPIEN simulator and is open-sourced to promote the\nresearch of vision and robotics communities.",
    "descriptor": "\nComments: 20 pages, 15 figures, 10 tables\n",
    "authors": [
      "Xiaoshuai Zhang",
      "Rui Chen",
      "Fanbo Xiang",
      "Yuzhe Qin",
      "Jiayuan Gu",
      "Zhan Ling",
      "Minghua Liu",
      "Peiyu Zeng",
      "Songfang Han",
      "Zhiao Huang",
      "Tongzhou Mu",
      "Jing Xu",
      "Hao Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11924"
  },
  {
    "id": "arXiv:2201.11925",
    "title": "POLYLLA: Polygonal meshing algorithm based on terminal-edge regions",
    "abstract": "This paper presents an algorithm to generate a new kind of polygonal mesh\nobtained from triangulations. Each polygon is built from a terminal-edge region\nsurrounded by edges that are not the longest-edge of any of the two triangles\nthat share them. The algorithm is divided into three phases. The first phase\nconsists of labeling each edge and triangle of the input triangulation\naccording to its size; the second phase builds polygons (simple or not) from\nterminal-edges regions using the label system; and the third phase transforms\neach non simple polygon into simple ones. The final mesh contains polygons with\nconvex and nonconvex shape. Since Voronoi based meshes are currently the most\nused polygonal meshes, we compare some geometric properties of our meshes\nagainst constrained Voronoi meshes. Several experiments are run to compare the\nshape and size of polygons, the number of final mesh points and polygons.\nFinally, we validate these polygonal meshes by solving a Laplace equation on an\nL-shaped domain using the Virtual Element Method (VEM) and show the optimal\nconvergence rate of the numerical solution.",
    "descriptor": "",
    "authors": [
      "Sergio Salinas",
      "Nancy Hitschfeld",
      "Alejandro Ortiz-Bernardin",
      "Hang Si"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11925"
  },
  {
    "id": "arXiv:2201.11927",
    "title": "Constrained Variational Policy Optimization for Safe Reinforcement  Learning",
    "abstract": "Safe reinforcement learning (RL) aims to learn policies that satisfy certain\nconstraints before deploying to safety-critical applications. Primal-dual as a\nprevalent constrained optimization framework suffers from instability issues\nand lacks optimality guarantees. This paper overcomes the issues from a novel\nprobabilistic inference perspective and proposes an Expectation-Maximization\nstyle approach to learn safe policy. We show that the safe RL problem can be\ndecomposed to 1) a convex optimization phase with a non-parametric variational\ndistribution and 2) a supervised learning phase. We show the unique advantages\nof constrained variational policy optimization by proving its optimality and\npolicy improvement stability. A wide range of experiments on continuous robotic\ntasks show that the proposed method achieves significantly better performance\nin terms of constraint satisfaction and sample efficiency than primal-dual\nbaselines.",
    "descriptor": "\nComments: 22 pages, 12 figures. Under review\n",
    "authors": [
      "Zuxin Liu",
      "Zhepeng Cen",
      "Vladislav Isenbaev",
      "Wei Liu",
      "Zhiwei Steven Wu",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11927"
  },
  {
    "id": "arXiv:2201.11928",
    "title": "Quadruped Capturability and Push Recovery via a Switched-Systems  Characterization of Dynamic Balance",
    "abstract": "This paper studies capturability and push recovery for quadrupedal\nlocomotion. Despite the rich literature on capturability analysis and push\nrecovery control for legged robots, existing tools are developed mainly for\nbipeds or humanoids. Distinct quadrupedal features such as point contacts and\nmultiple swinging legs prevent direct application of these methods. To address\nthis gap, we propose a switched systems model for quadruped dynamics, and\ninstantiate the abstract viability concept for quadrupedal locomotion with a\ntime-based gait. Capturability is characterized through a novel specification\nof dynamically balanced states that addresses the time-varying nature of\nquadrupedal locomotion and balance. A linear inverted pendulum (LIP) model is\nadopted to demonstrate the theory and show how the newly developed quadrupedal\ncapturability can be used in motion planning for quadrupedal push recovery. We\nformulate and solve an explicit model predictive control (EMPC) problem whose\noptimal solution fully characterizes quadrupedal capturability with the LIP.\nGiven this analysis, an optimization-based planning scheme is devised for\ndetermining footsteps and center of mass references during push recovery. To\nvalidate the effectiveness of the overall framework, we conduct numerous\nsimulation and hardware experiments. Simulation results illustrate the\nnecessity of considering dynamic balance for quadrupedal capturability, and the\nsignificant improvement in disturbance rejection with the proposed strategy.\nExperimental validations on a replica of the Mini Cheetah quadruped demonstrate\nan up to 100% improvement as compared with state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Hua Chen",
      "Zejun Hong",
      "Shunpeng Yang",
      "Patrick M. Wensing",
      "Wei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11928"
  },
  {
    "id": "arXiv:2201.11929",
    "title": "Positive Rate Binary Interactive Error Correcting Codes Resilient to  $>\\frac12$ Adversarial Erasures",
    "abstract": "An interactive error correcting code ($\\mathsf{iECC}$) is an interactive\nprotocol with the guarantee that the receiver can correctly determine the\nsender's message, even in the presence of noise. This generalizes the concept\nof an error correcting code ($\\mathsf{ECC}$), which is a non-interactive\n$\\mathsf{iECC}$ that is known to have erasure resilience capped at $\\frac12$.\nThe work of \\cite{GuptaTZ21} constructed the first $\\mathsf{iECC}$ resilient to\n$> \\frac12$ adversarial erasures. However, their $\\mathsf{iECC}$ has\ncommunication complexity quadratic in the message size. In our work, we\nconstruct the first positive rate $\\mathsf{iECC}$ resilient to $> \\frac12$\nadversarial erasures. For any $\\epsilon > 0$, our $\\mathsf{iECC}$ is resilient\nto $\\frac6{11} - \\epsilon$ adversarial erasures and has size $O_\\epsilon(n)$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.04181\n",
    "authors": [
      "Meghal Gupta",
      "Rachel Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11929"
  },
  {
    "id": "arXiv:2201.11931",
    "title": "Fast Interpretable Greedy-Tree Sums (FIGS)",
    "abstract": "Modern machine learning has achieved impressive prediction performance, but\noften sacrifices interpretability, a critical consideration in many problems.\nHere, we propose Fast Interpretable Greedy-Tree Sums (FIGS), an algorithm for\nfitting concise rule-based models. Specifically, FIGS generalizes the CART\nalgorithm to simultaneously grow a flexible number of trees in a summation. The\ntotal number of splits across all the trees can be restricted by a\npre-specified threshold, thereby keeping both the size and number of its trees\nunder control. When both are small, the fitted tree-sum can be easily\nvisualized and written out by hand, making it highly interpretable. A partially\noracle theoretical result hints at the potential for FIGS to overcome a key\nweakness of single-tree models by disentangling additive components of\ngenerative additive models, thereby reducing redundancy from repeated splits on\nthe same feature. Furthermore, given oracle access to optimal tree structures,\nwe obtain L2 generalization bounds for such generative models in the case of C1\ncomponent functions, matching known minimax rates in some cases. Extensive\nexperiments across a wide array of real-world datasets show that FIGS achieves\nstate-of-the-art prediction performance (among all popular rule-based methods)\nwhen restricted to just a few splits (e.g. less than 20). We find empirically\nthat FIGS is able to avoid repeated splits, and often provides more concise\ndecision rules than fitted decision trees, without sacrificing predictive\nperformance. All code and models are released in a full-fledged package on\nGithub \\url{https://github.com/csinva/imodels}.",
    "descriptor": "",
    "authors": [
      "Yan Shuo Tan",
      "Chandan Singh",
      "Keyan Nasseri",
      "Abhineet Agarwal",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11931"
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": "Periodic graphs are graphs consisting of repetitive local structures, such as\ncrystal nets and polygon mesh. Their generative modeling has great potential in\nreal-world applications such as material design and graphics synthesis.\nClassical models either rely on domain-specific predefined generation\nprinciples (e.g., in crystal net design), or follow geometry-based prescribed\nrules. Recently, deep generative models has shown great promise in\nautomatically generating general graphs. However, their advancement into\nperiodic graphs have not been well explored due to several key challenges in 1)\nmaintaining graph periodicity; 2) disentangling local and global patterns; and\n3) efficiency in learning repetitive patterns. To address them, this paper\nproposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a\nnew deep generative models for periodic graphs that can automatically learn,\ndisentangle, and generate local and global graph patterns. Specifically, we\ndevelop a new periodic graph encoder consisting of global-pattern encoder and\nlocal-pattern encoder that ensures to disentangle the representation into\nglobal and local semantics. We then propose a new periodic graph decoder\nconsisting of local structure decoder, neighborhood decoder, and global\nstructure decoder, as well as the assembler of their outputs that guarantees\nperiodicity. Moreover, we design a new model learning objective that helps\nensure the invariance of local-semantic representations for the graphs with the\nsame local structure. Comprehensive experimental evaluations have been\nconducted to demonstrate the effectiveness of the proposed method. The code of\nproposed PGD-VAE is availabe at https://github.com/shi-yu-wang/PGD-VAE.",
    "descriptor": "",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11932"
  },
  {
    "id": "arXiv:2201.11934",
    "title": "A Secure and Efficient Federated Learning Framework for NLP",
    "abstract": "In this work, we consider the problem of designing secure and efficient\nfederated learning (FL) frameworks. Existing solutions either involve a trusted\naggregator or require heavyweight cryptographic primitives, which degrades\nperformance significantly. Moreover, many existing secure FL designs work only\nunder the restrictive assumption that none of the clients can be dropped out\nfrom the training protocol. To tackle these problems, we propose SEFL, a secure\nand efficient FL framework that (1) eliminates the need for the trusted\nentities; (2) achieves similar and even better model accuracy compared with\nexisting FL designs; (3) is resilient to client dropouts. Through extensive\nexperimental studies on natural language processing (NLP) tasks, we demonstrate\nthat the SEFL achieves comparable accuracy compared to existing FL solutions,\nand the proposed pruning technique can improve runtime performance up to 13.7x.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Jieren Deng",
      "Chenghong Wang",
      "Xianrui Meng",
      "Yijue Wang",
      "Ji Li",
      "Sheng Lin",
      "Shuo Han",
      "Fei Miao",
      "Sanguthevar Rajasekaran",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11934"
  },
  {
    "id": "arXiv:2201.11935",
    "title": "Sequential Decoding of Convolutional Codes for Synchronization Errors",
    "abstract": "In this work, a sequential decoder for convolutional codes over channels that\nare vulnerable to insertion, deletion, and substitution errors, is described\nand analyzed. The decoder expands the code trellis by introducing a new channel\nstate variable, called drift state, as proposed by Davey-MacKay. A suitable\ndecoding metric on that trellis for sequential decoding is derived, in a manner\nthat generalizes the original Fano metric. Under low-noise environments, this\napproach reduces the decoding complexity by a couple orders of magnitude in\ncomparison to Viterbi's algorithm, albeit at relatively higher frame error\nrates. An analytical method to determine the computational cutoff rate is also\nsuggested. This analysis is supported with numerical evaluations of frame error\nrates and computational complexity, which are compared with respect to optimal\nViterbi decoding.",
    "descriptor": "",
    "authors": [
      "Anisha Banerjee",
      "Andreas Lenz",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11935"
  },
  {
    "id": "arXiv:2201.11936",
    "title": "Consistent Collaborative Filtering via Tensor Decomposition",
    "abstract": "Collaborative filtering is the de facto standard for analyzing users'\nactivities and building recommendation systems for items. In this work we\ndevelop Sliced Anti-symmetric Decomposition (SAD), a new model for\ncollaborative filtering based on implicit feedback. In contrast to traditional\ntechniques where a latent representation of users (user vectors) and items\n(item vectors) are estimated, SAD introduces one additional latent vector to\neach item, using a novel three-way tensor view of user-item interactions. This\nnew vector extends user-item preferences calculated by standard dot products to\ngeneral inner products, producing interactions between items when evaluating\ntheir relative preferences. SAD reduces to state-of-the-art (SOTA)\ncollaborative filtering models when the vector collapses to one, while in this\npaper we allow its value to be estimated from data. The proposed SAD model is\nsimple, resulting in an efficient group stochastic gradient descent (SGD)\nalgorithm. We demonstrate the efficiency of SAD in both simulated and real\nworld datasets containing over 1M user-item interactions. By comparing SAD with\nseven alternative SOTA collaborative filtering models, we show that SAD is able\nto more consistently estimate personalized preferences.",
    "descriptor": "",
    "authors": [
      "Shiwen Zhao",
      "Charles Crissman",
      "Guillermo R Sapiro"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11936"
  },
  {
    "id": "arXiv:2201.11937",
    "title": "Stereo Matching with Cost Volume based Sparse Disparity Propagation",
    "abstract": "Stereo matching is crucial for binocular stereo vision. Existing methods\nmainly focus on simple disparity map fusion to improve stereo matching, which\nrequire multiple dense or sparse disparity maps. In this paper, we propose a\nsimple yet novel scheme, termed feature disparity propagation, to improve\ngeneral stereo matching based on matching cost volume and sparse matching\nfeature points. Specifically, our scheme first calculates a reliable sparse\ndisparity map by local feature matching, and then refines the disparity map by\npropagating reliable disparities to neighboring pixels in the matching cost\ndomain. In addition, considering the gradient and multi-scale information of\nlocal disparity regions, we present a $\\rho$-Census cost measure based on the\nwell-known AD-Census, which guarantees the robustness of cost volume even\nwithout the cost aggregation step. Extensive experiments on Middlebury stereo\nbenchmark V3 demonstrate that our scheme achieves promising performance\ncomparable to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Wei Xue",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11937"
  },
  {
    "id": "arXiv:2201.11939",
    "title": "With Greater Distance Comes Worse Performance: On the Perspective of  Layer Utilization and Model Generalization",
    "abstract": "Generalization of deep neural networks remains one of the main open problems\nin machine learning. Previous theoretical works focused on deriving tight\nbounds of model complexity, while empirical works revealed that neural networks\nexhibit double descent with respect to both training sample counts and the\nneural network size. In this paper, we empirically examined how different\nlayers of neural networks contribute differently to the model; we found that\nearly layers generally learn representations relevant to performance on both\ntraining data and testing data. Contrarily, deeper layers only minimize\ntraining risks and fail to generalize well with testing or mislabeled data. We\nfurther illustrate the distance of trained weights to its initial value of\nfinal layers has high correlation to generalization errors and can serve as an\nindicator of an overfit of model. Moreover, we show evidence to support\npost-training regularization by re-initializing weights of final layers. Our\nfindings provide an efficient method to estimate the generalization capability\nof neural networks, and the insight of those quantitative results may inspire\nderivation to better generalization bounds that take the internal structure of\nneural networks into consideration.",
    "descriptor": "",
    "authors": [
      "James Wang",
      "Cheng-Lin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11939"
  },
  {
    "id": "arXiv:2201.11940",
    "title": "Wassersplines for Stylized Neural Animation",
    "abstract": "Much of computer-generated animation is created by manipulating meshes with\nrigs. While this approach works well for animating articulated objects like\nanimals, it has limited flexibility for animating less structured creatures\nsuch as the Drunn in \"Raya and the Last Dragon.\" We introduce Wassersplines, a\nnovel trajectory inference method for animating unstructured densities based on\nrecent advances in continuous normalizing flows and optimal transport. The key\nidea is to train a neurally-parameterized velocity field that represents the\nmotion between keyframes. Trajectories are then computed by pushing keyframes\nthrough the velocity field. We solve an additional Wasserstein barycenter\ninterpolation problem to guarantee strict adherence to keyframes. Our tool can\nstylize trajectories through a variety of PDE-based regularizers to create\ndifferent visual effects. We demonstrate our tool on various keyframe\ninterpolation problems to produce temporally-coherent animations without\nmeshing or rigging.",
    "descriptor": "",
    "authors": [
      "Paul Zhang",
      "Dmitriy Smirnov",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11940"
  },
  {
    "id": "arXiv:2201.11944",
    "title": "DICP: Doppler Iterative Closest Point Algorithm",
    "abstract": "In this paper, we present a novel algorithm for point cloud registration for\nrange sensors capable of measuring per-return instantaneous radial velocity:\nDoppler ICP. Existing variants of ICP that solely rely on geometry or other\nfeatures generally fail to estimate the motion of the sensor correctly in\nscenarios that have non-distinctive features and/or repetitive geometric\nstructures such as hallways, tunnels, highways, and bridges. We propose a new\nDoppler velocity objective function that exploits the compatibility of each\npoint's Doppler measurement and the sensor's current motion estimate. We\njointly optimize the Doppler velocity objective function and the geometric\nobjective function which sufficiently constrains the point cloud alignment\nproblem even in feature-denied environments. Furthermore, the correspondence\nmatches used for the alignment are improved by pruning away the points from\ndynamic targets which generally degrade the ICP solution. We evaluate our\nmethod on data collected from real sensors and from simulation. Our results\nshow a significant performance improvement in terms of the registration\naccuracy with the added benefit of faster convergence guided by the Doppler\nvelocity gradients.",
    "descriptor": "\nComments: 10 pages, 7 figures, Submitted to Robotics: Science and Systems (RSS) Conference 2022\n",
    "authors": [
      "Bruno Hexsel",
      "Heethesh Vhavle",
      "Yi Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11944"
  },
  {
    "id": "arXiv:2201.11945",
    "title": "Learning Proximal Operators to Discover Multiple Optima",
    "abstract": "Finding multiple solutions of non-convex optimization problems is a\nubiquitous yet challenging task. Typical existing solutions either apply\nsingle-solution optimization methods from multiple random initial guesses or\nsearch in the vicinity of found solutions using ad hoc heuristics. We present\nan end-to-end method to learn the proximal operator across a family of\nnon-convex problems, which can then be used to recover multiple solutions for\nunseen problems at test time. Our method only requires access to the objectives\nwithout needing the supervision of ground truth solutions. Notably, the added\nproximal regularization term elevates the convexity of our formulation: by\napplying recent theoretical results, we show that for weakly-convex objectives\nand under mild regularity conditions, training of the proximal operator\nconverges globally in the over-parameterized setting. We further present a\nbenchmark for multi-solution optimization including a wide range of\napplications and evaluate our method to demonstrate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Lingxiao Li",
      "Noam Aigerman",
      "Vladimir G. Kim",
      "Jiajin Li",
      "Kristjan Greenewald",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11945"
  },
  {
    "id": "arXiv:2201.11949",
    "title": "Higher Order Correlation Analysis for Multi-View Learning",
    "abstract": "Multi-view learning is frequently used in data science. The pairwise\ncorrelation maximization is a classical approach for exploring the consensus of\nmultiple views. Since the pairwise correlation is inherent for two views, the\nextensions to more views can be diversified and the intrinsic interconnections\namong views are generally lost. To address this issue, we propose to maximize\nhigher order correlations. This can be formulated as a low rank approximation\nproblem with the higher order correlation tensor of multi-view data. We use the\ngenerating polynomial method to solve the low rank approximation problem.\nNumerical results on real multi-view data demonstrate that this method\nconsistently outperforms prior existing methods.",
    "descriptor": "",
    "authors": [
      "Jiawang Nie",
      "Li Wang",
      "Zequn Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11949"
  },
  {
    "id": "arXiv:2201.11950",
    "title": "Time-Series Anomaly Detection with Implicit Neural Representation",
    "abstract": "Detecting anomalies in multivariate time-series data is essential in many\nreal-world applications. Recently, various deep learning-based approaches have\nshown considerable improvements in time-series anomaly detection. However,\nexisting methods still have several limitations, such as long training time due\nto their complex model designs or costly tuning procedures to find optimal\nhyperparameters (e.g., sliding window length) for a given dataset. In our\npaper, we propose a novel method called Implicit Neural Representation-based\nAnomaly Detection (INRAD). Specifically, we train a simple multi-layer\nperceptron that takes time as input and outputs corresponding values at that\ntime. Then we utilize the representation error as an anomaly score for\ndetecting anomalies. Experiments on five real-world datasets demonstrate that\nour proposed method outperforms other state-of-the-art methods in performance,\ntraining speed, and robustness.",
    "descriptor": "",
    "authors": [
      "Kyeong-Joong Jeong",
      "Yong-Min Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11950"
  },
  {
    "id": "arXiv:2201.11952",
    "title": "Data-Driven Modeling of Aggregate Flexibility under Uncertain and  Non-Convex Load Models",
    "abstract": "Bundling a large number of distributed energy resources through a load\naggregator has been advocated as an effective means to integrate such resources\ninto whole-sale energy markets. To ease market clearing, system operators allow\naggregators to submit bidding models of simple prespecified polytopic shapes.\nAggregators need to carefully design and commit to a polytope that best\ncaptures their energy flexibility along a day-ahead scheduling horizon. This\nwork puts forth a model-informed data-based optimal flexibility design for\naggregators, which deals with the time-coupled, uncertain, and non-convex\nmodels of individual loads. The proposed solution first generates efficiently a\nlabeled dataset of (non)-disaggregatable schedules. The feasible set of the\naggregator is then approximated by an ellipsoid upon training a convex\nquadratic classifier using the labeled dataset. The ellipsoid is subsequently\ninner approximated by a polytope. Using Farkas lemma, the obtained polytope is\nfinally inner approximated by the polytopic shape dictated by the market.\nNumerical tests show the effectiveness of the proposed flexibility design\nframework for designing the feasible sets of small- and large-sized aggregators\ncoordinating solar photovoltaics, thermostatically-controlled loads, batteries,\nand electric vehicles. The tests further demonstrate that it is crucial for the\naggregator to consider time-coupling and uncertainties in optimal flexibility\ndesign.",
    "descriptor": "",
    "authors": [
      "Sina Taheri",
      "Vassilis Kekatos",
      "Harsha Veeramachaneni",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11952"
  },
  {
    "id": "arXiv:2201.11963",
    "title": "Shuffle Augmentation of Features from Unlabeled Data for Unsupervised  Domain Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA), a branch of transfer learning where\nlabels for target samples are unavailable, has been widely researched and\ndeveloped in recent years with the help of adversarially trained models.\nAlthough existing UDA algorithms are able to guide neural networks to extract\ntransferable and discriminative features, classifiers are merely trained under\nthe supervision of labeled source data. Given the inevitable discrepancy\nbetween source and target domains, the classifiers can hardly be aware of the\ntarget classification boundaries. In this paper, Shuffle Augmentation of\nFeatures (SAF), a novel UDA framework, is proposed to address the problem by\nproviding the classifier with supervisory signals from target feature\nrepresentations. SAF learns from the target samples, adaptively distills\nclass-aware target features, and implicitly guides the classifier to find\ncomprehensive class borders. Demonstrated by extensive experiments, the SAF\nmodule can be integrated into any existing adversarial UDA models to achieve\nperformance improvements.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Changwei Xu",
      "Jianfei Yang",
      "Haoran Tang",
      "Han Zou",
      "Cheng Lu",
      "Tianshuo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11963"
  },
  {
    "id": "arXiv:2201.11964",
    "title": "Dynamic Temporal Reconciliation by Reinforcement learning",
    "abstract": "Planning based on long and short term time series forecasts is a common\npractice across many industries. In this context, temporal aggregation and\nreconciliation techniques have been useful in improving forecasts, reducing\nmodel uncertainty, and providing a coherent forecast across different time\nhorizons. However, an underlying assumption spanning all these techniques is\nthe complete availability of data across all levels of the temporal hierarchy,\nwhile this offers mathematical convenience but most of the time low frequency\ndata is partially completed and it is not available while forecasting. On the\nother hand, high frequency data can significantly change in a scenario like the\nCOVID pandemic and this change can be used to improve forecasts that will\notherwise significantly diverge from long term actuals. We propose a dynamic\nreconciliation method whereby we formulate the problem of informing low\nfrequency forecasts based on high frequency actuals as a Markov Decision\nProcess (MDP) allowing for the fact that we do not have complete information\nabout the dynamics of the process. This allows us to have the best long term\nestimates based on the most recent data available even if the low frequency\ncycles have only been partially completed. The MDP has been solved using a Time\nDifferenced Reinforcement learning (TDRL) approach with customizable actions\nand improves the long terms forecasts dramatically as compared to relying\nsolely on historical low frequency data. The result also underscores the fact\nthat while low frequency forecasts can improve the high frequency forecasts as\nmentioned in the temporal reconciliation literature (based on the assumption\nthat low frequency forecasts have lower noise to signal ratio) the high\nfrequency forecasts can also be used to inform the low frequency forecasts.",
    "descriptor": "",
    "authors": [
      "Himanshi Charotia",
      "Abhishek Garg",
      "Gaurav Dhama",
      "Naman Maheshwari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11964"
  },
  {
    "id": "arXiv:2201.11965",
    "title": "Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with  Non-stationary Objectives and Constraints",
    "abstract": "We consider primal-dual-based reinforcement learning (RL) in episodic\nconstrained Markov decision processes (CMDPs) with non-stationary objectives\nand constraints, which play a central role in ensuring the safety of RL in\ntime-varying environments. In this problem, the reward/utility functions and\nthe state transition functions are both allowed to vary arbitrarily over time\nas long as their cumulative variations do not exceed certain known variation\nbudgets. Designing safe RL algorithms in time-varying environments is\nparticularly challenging because of the need to integrate the constraint\nviolation reduction, safe exploration, and adaptation to the non-stationarity.\nTo this end, we propose a Periodically Restarted Optimistic Primal-Dual\nProximal Policy Optimization (PROPD-PPO) algorithm that features three\nmechanisms: periodic-restart-based policy improvement, dual update with dual\nregularization, and periodic-restart-based optimistic policy evaluation. We\nestablish a dynamic regret bound and a constraint violation bound for the\nproposed algorithm in both the linear kernel CMDP function approximation\nsetting and the tabular CMDP setting. This paper provides the first provably\nefficient algorithm for non-stationary CMDPs with safe exploration.",
    "descriptor": "",
    "authors": [
      "Yuhao Ding",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11965"
  },
  {
    "id": "arXiv:2201.11967",
    "title": "Pseudo-Differential Integral Operator for Learning Solution Operators of  Partial Differential Equations",
    "abstract": "Learning mapping between two function spaces has attracted considerable\nresearch attention. However, learning the solution operator of partial\ndifferential equations (PDEs) remains a challenge in scientific computing.\nTherefore, in this study, we propose a novel pseudo-differential integral\noperator (PDIO) inspired by a pseudo-differential operator, which is a\ngeneralization of a differential operator and characterized by a certain\nsymbol. We parameterize the symbol by using a neural network and show that the\nneural-network-based symbol is contained in a smooth symbol class.\nSubsequently, we prove that the PDIO is a bounded linear operator, and thus is\ncontinuous in the Sobolev space. We combine the PDIO with the neural operator\nto develop a pseudo-differential neural operator (PDNO) to learn the nonlinear\nsolution operator of PDEs. We experimentally validate the effectiveness of the\nproposed model by using Burgers' equation, Darcy flow, and the Navier-Stokes\nequation. The results reveal that the proposed PDNO outperforms the existing\nneural operator approaches in most experiments.",
    "descriptor": "\nComments: 16 pages, 12 figures. This paper is under review on the Thirty-ninth International Conference on Machine Learning\n",
    "authors": [
      "Jin Young Shin",
      "Jae Yong Lee",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11967"
  },
  {
    "id": "arXiv:2201.11968",
    "title": "Training invariances and the low-rank phenomenon: beyond linear networks",
    "abstract": "The implicit bias induced by the training of neural networks has become a\ntopic of rigorous study. In the limit of gradient flow and gradient descent\nwith appropriate step size, it has been shown that when one trains a deep\nlinear network with logistic or exponential loss on linearly separable data,\nthe weights converge to rank-$1$ matrices. In this paper, we extend this\ntheoretical result to the much wider class of nonlinear ReLU-activated\nfeedforward networks containing fully-connected layers and skip connections. To\nthe best of our knowledge, this is the first time a low-rank phenomenon is\nproven rigorously for these architectures, and it reflects empirical results in\nthe literature. The proof relies on specific local training invariances,\nsometimes referred to as alignment, which we show to hold for a wide set of\nReLU architectures. Our proof relies on a specific decomposition of the network\ninto a multilinear function and another ReLU network whose weights are constant\nunder a certain parameter directional convergence.",
    "descriptor": "\nComments: 25 pages, 3 figures, ICLR2022\n",
    "authors": [
      "Thien Le",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11968"
  },
  {
    "id": "arXiv:2201.11969",
    "title": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "abstract": "Incorporating symmetry as an inductive bias into neural network architecture\nhas led to improvements in generalization, data efficiency, and physical\nconsistency in dynamics modeling. Methods such as CNN or equivariant neural\nnetworks use weight tying to enforce symmetries such as shift invariance or\nrotational equivariance. However, despite the fact that physical laws obey many\nsymmetries, real-world dynamical data rarely conforms to strict mathematical\nsymmetry either due to noisy or incomplete data or to symmetry breaking\nfeatures in the underlying dynamical system. We explore approximately\nequivariant networks which are biased towards preserving symmetry but are not\nstrictly constrained to do so. By relaxing equivariance constraints, we find\nthat our models can outperform both baselines with no symmetry bias and\nbaselines with overly strict symmetry in both simulated turbulence domains and\nreal-world multi-stream jet flow.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11969"
  },
  {
    "id": "arXiv:2201.11975",
    "title": "Generalized Visual Quality Assessment of GAN-Generated Face Images",
    "abstract": "Recent years have witnessed the dramatically increased interest in face\ngeneration with generative adversarial networks (GANs). A number of successful\nGAN algorithms have been developed to produce vivid face images towards\ndifferent application scenarios. However, little work has been dedicated to\nautomatic quality assessment of such GAN-generated face images (GFIs), even\nless have been devoted to generalized and robust quality assessment of GFIs\ngenerated with unseen GAN model. Herein, we make the first attempt to study the\nsubjective and objective quality towards generalized quality assessment of\nGFIs. More specifically, we establish a large-scale database consisting of GFIs\nfrom four GAN algorithms, the pseudo labels from image quality assessment (IQA)\nmeasures, as well as the human opinion scores via subjective testing.\nSubsequently, we develop a quality assessment model that is able to deliver\naccurate quality predictions for GFIs from both available and unseen GAN\nalgorithms based on meta-learning. In particular, to learn shared knowledge\nfrom GFIs pairs that are born of limited GAN algorithms, we develop the\nconvolutional block attention (CBA) and facial attributes-based analysis (ABA)\nmodules, ensuring that the learned knowledge tends to be consistent with human\nvisual perception. Extensive experiments exhibit that the proposed model\nachieves better performance compared with the state-of-the-art IQA models, and\nis capable of retaining the effectiveness when evaluating GFIs from the unseen\nGAN algorithms.",
    "descriptor": "\nComments: 12 pages, 8 figures, journal paper\n",
    "authors": [
      "Yu Tian",
      "Zhangkai Ni",
      "Baoliang Chen",
      "Shiqi Wang",
      "Hanli Wang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.11975"
  },
  {
    "id": "arXiv:2201.11976",
    "title": "Learning to Simulate Unseen Physical Systems with Graph Neural Networks",
    "abstract": "Simulation of the dynamics of physical systems is essential to the\ndevelopment of both science and engineering. Recently there is an increasing\ninterest in learning to simulate the dynamics of physical systems using neural\nnetworks. However, existing approaches fail to generalize to physical\nsubstances not in the training set, such as liquids with different viscosities\nor elastomers with different elasticities. Here we present a machine learning\nmethod embedded with physical priors and material parameters, which we term as\n\"Graph-based Physics Engine\" (GPE), to efficiently model the physical dynamics\nof different substances in a wide variety of scenarios. We demonstrate that GPE\ncan generalize to materials with different properties not seen in the training\nset and perform well from single-step predictions to multi-step roll-out\nsimulations. In addition, introducing the law of momentum conservation in the\nmodel significantly improves the efficiency and stability of learning, allowing\nconvergence to better models with fewer training steps.",
    "descriptor": "\nComments: 9 pages, 5 figures, NeurIPS 2021 Workshop on AI for Science\n",
    "authors": [
      "Ce Yang",
      "Weihao Gao",
      "Di Wu",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11976"
  },
  {
    "id": "arXiv:2201.11978",
    "title": "Testable Array Multipliers for a Better Utilization of C-Testability and  Bijectivity",
    "abstract": "This paper presents a design for test (DFT)architecture for fast and scalable\ntesting of array multipliers (MULTs). Regardless of the MULT size, our proposed\ntestable architecture, without major changes in the original architecture,\nrequires only five test vectors. Test pattern generation (TPG) is done by\ncombining C-testability, bijectivity and deterministic TPG methods.\nExperimental results show 100% fault coverage for single stuck-at faults. The\nproposed method requires minor testability hardware insertion into the\nmultiplier with extra delay and area overhead of less than 0.5% for a 64-bit\nmultiplier.",
    "descriptor": "\nComments: 6 pages,8 figures\n",
    "authors": [
      "Fatemeh Sheikh Shoaei",
      "Alireza Nahvy",
      "Zainalabedin Navabi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11978"
  },
  {
    "id": "arXiv:2201.11981",
    "title": "Transfering Hierarchical Structure with Dual Meta Imitation Learning",
    "abstract": "Hierarchical Imitation Learning (HIL) is an effective way for robots to learn\nsub-skills from long-horizon unsegmented demonstrations. However, the learned\nhierarchical structure lacks the mechanism to transfer across multi-tasks or to\nnew tasks, which makes them have to learn from scratch when facing a new\nsituation. Transferring and reorganizing modular sub-skills require fast\nadaptation ability of the whole hierarchical structure. In this work, we\npropose Dual Meta Imitation Learning (DMIL), a hierarchical meta imitation\nlearning method where the high-level network and sub-skills are iteratively\nmeta-learned with model-agnostic meta-learning. DMIL uses the likelihood of\nstate-action pairs from each sub-skill as the supervision for the high-level\nnetwork adaptation, and use the adapted high-level network to determine\ndifferent data set for each sub-skill adaptation. We theoretically prove the\nconvergence of the iterative training process of DMIL and establish the\nconnection between DMIL and Expectation-Maximization algorithm. Empirically, we\nachieve state-of-the-art few-shot imitation learning performance on the\nMeta-world \\cite{metaworld} benchmark and competitive results on long-horizon\ntasks of Kitchen environments.",
    "descriptor": "",
    "authors": [
      "Chongkai Gao",
      "Yizhou Jiang",
      "Feng Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11981"
  },
  {
    "id": "arXiv:2201.11984",
    "title": "The need for and feasibility of alternative ground robots to traverse  sandy and rocky extraterrestrial terrain",
    "abstract": "Robotic spacecraft have helped expand our reach for many planetary\nexploration missions. Most ground mobile planetary exploration robots use\nwheeled or modified wheeled platforms. Although extraordinarily successful at\ncompleting intended mission goals, because of the limitations of wheeled\nlocomotion, they have been largely limited to benign, solid terrain and avoided\nextreme terrain with loose soil/sand and large rocks. Unfortunately, such\nchallenging terrain is often scientifically interesting for planetary geology.\nAlthough many animals traverse such terrain at ease, robots have not matched\ntheir performance and robustness. This is in major part due to a lack of\nfundamental understanding of how effective locomotion can be generated from\ncontrolled interaction with complex terrain on the same level of flight\naerodynamics and underwater vehicle hydrodynamics. Early fundamental\nunderstanding of legged and limbless locomotor-ground interaction has already\nenabled stable and efficient bio-inspired robot locomotion on relatively flat\nground with small obstacles. Recent progress in the new field of terradynamics\nof locomotor-terrain interaction begins to reveal the principles of\nbio-inspired locomotion on loose soil/sand and over large obstacles.\nMulti-legged and limbless platforms using terradynamics insights hold the\npromise for serving as robust alternative platforms for traversing extreme\nextraterrestrial terrain and expanding our reach in planetary exploration.",
    "descriptor": "",
    "authors": [
      "Chen Li",
      "Kevin Lewis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.11984"
  },
  {
    "id": "arXiv:2201.11986",
    "title": "Gradient Masked Averaging for Federated Learning",
    "abstract": "Federated learning is an emerging paradigm that permits a large number of\nclients with heterogeneous data to coordinate learning of a unified global\nmodel without the need to share data amongst each other. Standard federated\nlearning algorithms involve averaging of model parameters or gradient updates\nto approximate the global model at the server. However, in heterogeneous\nsettings averaging can result in information loss and lead to poor\ngeneralization due to the bias induced by dominant clients. We hypothesize that\nto generalize better across non-i.i.d datasets as in FL settings, the\nalgorithms should focus on learning the invariant mechanism that is constant\nwhile ignoring spurious mechanisms that differ across clients. Inspired from\nrecent work in the Out-of-Distribution literature, we propose a gradient masked\naveraging approach for federated learning as an alternative to the standard\naveraging of client updates. This client update aggregation technique can be\nadapted as a drop-in replacement in most existing federated algorithms. We\nperform extensive experiments with gradient masked approach on multiple FL\nalgorithms with in-distribution, real-world, and out-of-distribution (as the\nworst case scenario) test dataset and show that it provides consistent\nimprovements, particularly in the case of heterogeneous clients.",
    "descriptor": "",
    "authors": [
      "Irene Tenison",
      "Sai Aravind Sreeramadas",
      "Vaikkunth Mugunthan",
      "Edouard Oyallon",
      "Eugene Belilovsky",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11986"
  },
  {
    "id": "arXiv:2201.11989",
    "title": "Using Constant Learning Rate of Two Time-Scale Update Rule for Training  Generative Adversarial Networks",
    "abstract": "Previous numerical results have shown that a two time-scale update rule\n(TTUR) using constant learning rates is practically useful for training\ngenerative adversarial networks (GANs). Meanwhile, a theoretical analysis of\nTTUR to find a stationary local Nash equilibrium of a Nash equilibrium problem\nwith two players, a discriminator and a generator, has been given using\ndecaying learning rates. In this paper, we give a theoretical analysis of TTUR\nusing constant learning rates to bridge the gap between theory and practice. In\nparticular, we show that, for TTUR using constant learning rates, the number of\nsteps needed to find a stationary local Nash equilibrium decreases as the batch\nsize increases. We also provide numerical results to support our theoretical\nanalyzes.",
    "descriptor": "",
    "authors": [
      "Naoki Sato",
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11989"
  },
  {
    "id": "arXiv:2201.11990",
    "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A  Large-Scale Generative Language Model",
    "abstract": "Pretrained general-purpose language models can achieve state-of-the-art\naccuracies in various natural language processing domains by adapting to\ndownstream tasks via zero-shot, few-shot and fine-tuning techniques. Because of\ntheir success, the size of these models has increased rapidly, requiring\nhigh-performance hardware, software, and algorithmic techniques to enable\ntraining such large models. As the result of a joint effort between Microsoft\nand NVIDIA, we present details on the training of the largest monolithic\ntransformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530\nbillion parameters. In this paper, we first focus on the infrastructure as well\nas the 3D parallelism methodology used to train this model using DeepSpeed and\nMegatron. Next, we detail the training process, the design of our training\ncorpus, and our data curation techniques, which we believe is a key ingredient\nto the success of the model. Finally, we discuss various evaluation results, as\nwell as other interesting observations and new properties exhibited by MT-NLG.\nWe demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning\naccuracies on several NLP benchmarks and establishes new state-of-the-art\nresults. We believe that our contributions will help further the development of\nlarge-scale training infrastructures, large-scale language models, and natural\nlanguage generations.",
    "descriptor": "\nComments: *Equal contribution\n",
    "authors": [
      "Shaden Smith",
      "Mostofa Patwary",
      "Brandon Norick",
      "Patrick LeGresley",
      "Samyam Rajbhandari",
      "Jared Casper",
      "Zhun Liu",
      "Shrimai Prabhumoye",
      "George Zerveas",
      "Vijay Korthikanti",
      "Elton Zhang",
      "Rewon Child",
      "Reza Yazdani Aminabadi",
      "Julie Bernauer",
      "Xia Song",
      "Mohammad Shoeybi",
      "Yuxiong He",
      "Michael Houston",
      "Saurabh Tiwary",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11990"
  },
  {
    "id": "arXiv:2201.11994",
    "title": "FCMNet: Full Communication Memory Net]{FCMNet: Full Communication Memory  Net for Team-Level Cooperation in Multi-Agent Systems",
    "abstract": "Decentralized cooperation in partially-observable multi-agent systems\nrequires effective communications among agents. To support this effort, this\nwork focuses on the class of problems where global communications are available\nbut may be unreliable, thus precluding differentiable communication learning\nmethods. We introduce FCMNet, a reinforcement learning based approach that\nallows agents to simultaneously learn a) an effective multi-hop communications\nprotocol and b) a common, decentralized policy that enables team-level\ndecision-making. Specifically, our proposed method utilizes the hidden states\nof multiple directional recurrent neural networks as communication messages\namong agents. Using a simple multi-hop topology, we endow each agent with the\nability to receive information sequentially encoded by every other agent at\neach time step, leading to improved global cooperation. We demonstrate FCMNet\non a challenging set of StarCraft II micromanagement tasks with shared rewards,\nas well as a collaborative multi-agent pathfinding task with individual\nrewards. There, our comparison results show that FCMNet outperforms\nstate-of-the-art communication-based reinforcement learning methods in all\nStarCraft II micromanagement tasks, and value decomposition methods in certain\ntasks. We further investigate the robustness of FCMNet under realistic\ncommunication disturbances, such as random message loss or binarized messages\n(i.e., non-differentiable communication channels), to showcase FMCNet's\npotential applicability to robotic tasks under a variety of real-world\nconditions.",
    "descriptor": "\nComments: To appear in the International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2022)\n",
    "authors": [
      "Yutong Wang",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.11994"
  },
  {
    "id": "arXiv:2201.11995",
    "title": "Hybrid Contrastive Learning with Cluster Ensemble for Unsupervised  Person Re-identification",
    "abstract": "Unsupervised person re-identification (ReID) aims to match a query image of a\npedestrian to the images in gallery set without supervision labels. The most\npopular approaches to tackle unsupervised person ReID are usually performing a\nclustering algorithm to yield pseudo labels at first and then exploit the\npseudo labels to train a deep neural network. However, the pseudo labels are\nnoisy and sensitive to the hyper-parameter(s) in clustering algorithm. In this\npaper, we propose a Hybrid Contrastive Learning (HCL) approach for unsupervised\nperson ReID, which is based on a hybrid between instance-level and\ncluster-level contrastive loss functions. Moreover, we present a\nMulti-Granularity Clustering Ensemble based Hybrid Contrastive Learning\n(MGCE-HCL) approach, which adopts a multi-granularity clustering ensemble\nstrategy to mine priority information among the pseudo positive sample pairs\nand defines a priority-weighted hybrid contrastive loss for better tolerating\nthe noises in the pseudo positive samples. We conduct extensive experiments on\ntwo benchmark datasets Market-1501 and DukeMTMC-reID. Experimental results\nvalidate the effectiveness of our proposals.",
    "descriptor": "\nComments: accepted by ACPR2021\n",
    "authors": [
      "He Sun",
      "Mingkun Li",
      "Chun-Guang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11995"
  },
  {
    "id": "arXiv:2201.11999",
    "title": "Dual Learning Music Composition and Dance Choreography",
    "abstract": "Music and dance have always co-existed as pillars of human activities,\ncontributing immensely to the cultural, social, and entertainment functions in\nvirtually all societies. Notwithstanding the gradual systematization of music\nand dance into two independent disciplines, their intimate connection is\nundeniable and one art-form often appears incomplete without the other. Recent\nresearch works have studied generative models for dance sequences conditioned\non music. The dual task of composing music for given dances, however, has been\nlargely overlooked. In this paper, we propose a novel extension, where we\njointly model both tasks in a dual learning approach. To leverage the duality\nof the two modalities, we introduce an optimal transport objective to align\nfeature embeddings, as well as a cycle consistency loss to foster overall\nconsistency. Experimental results demonstrate that our dual learning framework\nimproves individual task performance, delivering generated music compositions\nand dance choreographs that are realistic and faithful to the conditioned\ninputs.",
    "descriptor": "\nComments: ACMMM 2021 (Oral)\n",
    "authors": [
      "Shuang Wu",
      "Zhenguang Li",
      "Shijian Lu",
      "Li Cheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11999"
  },
  {
    "id": "arXiv:2201.12005",
    "title": "GTac: A Biomimetic Tactile Sensor with Skin-like Heterogeneous Force  Feedback for Robots",
    "abstract": "The tactile sensing capabilities of human hands are essential in performing\ndaily activities. Simultaneously perceiving normal and shear forces via the\nmechanoreceptors integrated into the hands enables humans to achieve daily\ntasks like grasping delicate objects. In this paper, we design and fabricate a\nnovel biomimetic tactile sensor with skin-like heterogeneity that perceives\nnormal and shear contact forces simultaneously. It mimics the multilayers of\nmechanoreceptors by combining an extrinsic layer (piezoresistive sensors) and\nan intrinsic layer (a Hall sensor) so that it can perform estimation of contact\nforce directions, locations, and joint-level torque. By integrating our\nsensors, a robotic gripper can obtain contact force feedback at fingertips;\naccordingly, robots can perform challenging tasks, such as tweezers usage, and\negg grasping. This insightful sensor design can be customized and applied in\ndifferent areas of robots and provide them with heterogeneous force sensing,\npotentially supporting robotics in acquiring skin-like tactile feedback.",
    "descriptor": "",
    "authors": [
      "Zeyu Lu",
      "Xingyu Gao",
      "Haoyong Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12005"
  },
  {
    "id": "arXiv:2201.12006",
    "title": "Provably Improving Expert Predictions with Conformal Prediction",
    "abstract": "Automated decision support systems promise to help human experts solve tasks\nmore efficiently and accurately. However, existing systems typically require\nexperts to understand when to cede agency to the system or when to exercise\ntheir own agency. Moreover, if the experts develop a misplaced trust in the\nsystem, their performance may worsen. In this work, we lift the above\nrequirement and develop automated decision support systems that, by design, do\nnot require experts to understand when to trust them to provably improve their\nperformance. To this end, we focus on multiclass classification tasks and\nconsider automated decision support systems that, for each data sample, use a\nclassifier to recommend a subset of labels to a human expert. We first show\nthat, by looking at the design of such systems from the perspective of\nconformal prediction, we can ensure that the probability that the recommended\nsubset of labels contains the true label matches almost exactly a target\nprobability value. Then, we identify the set of target probability values under\nwhich the human expert is provably better off predicting a label among those in\nthe recommended subset and develop an efficient practical method to find a\nnear-optimal target probability value. Experiments on synthetic and real data\ndemonstrate that our system can help the experts make more accurate predictions\nand is robust to the accuracy of the classifier it relies on.",
    "descriptor": "",
    "authors": [
      "Eleni Straitouri",
      "Lequng Wang",
      "Nastaran Okati",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12006"
  },
  {
    "id": "arXiv:2201.12010",
    "title": "Unfolding a blurred image",
    "abstract": "We present a solution for the goal of extracting a video from a single motion\nblurred image to sequentially reconstruct the clear views of a scene as beheld\nby the camera during the time of exposure. We first learn motion representation\nfrom sharp videos in an unsupervised manner through training of a convolutional\nrecurrent video autoencoder network that performs a surrogate task of video\nreconstruction. Once trained, it is employed for guided training of a motion\nencoder for blurred images. This network extracts embedded motion information\nfrom the blurred image to generate a sharp video in conjunction with the\ntrained recurrent video decoder. As an intermediate step, we also design an\nefficient architecture that enables real-time single image deblurring and\noutperforms competing methods across all factors: accuracy, speed, and\ncompactness. Experiments on real scenes and standard datasets demonstrate the\nsuperiority of our framework over the state-of-the-art and its ability to\ngenerate a plausible sequence of temporally consistent sharp frames.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1804.02913\n",
    "authors": [
      "Kuldeep Purohit",
      "Anshul Shah",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12010"
  },
  {
    "id": "arXiv:2201.12011",
    "title": "A MADM method for network selection in heterogeneous wireless networks",
    "abstract": "The coexistence of different Radio Access Technologies (RATs) in the same\narea has enabled the researchers to get profit from the available networks by\nthe selection of the best RAT at each moment to satisfy the user requirements.\nThe challenge is to achieve the Always Best Connected (ABC) concept; the main\nissue is the automatic choice of the suitable Radio Access Technology (RAT)\nfrom the list of the available RATs. This decision is called network selection\n(NS). In this paper, we propose a modified Simple Additive Weigh (modified-SAW)\nfunction to deal with the drawbacks of the existing solutions. Indeed, the\nexisting Multiple Attribute Decision Making (MADM) methods suffer mainly from\nthe famous problem of rank reversal once an alternative is added or removed,\nother problems occur in the legacy MADMs. We modify the SAW method\nintelligently and we use it to solve the NS problem. Finally, we compare the\nperformance of our solution with the previous works in different scenarios; the\nsimulations show that our proposal outperforms the other existing methods",
    "descriptor": "",
    "authors": [
      "Bendaoud Fayssal",
      "Abdennebi Marwen",
      "Didi Fedoua"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.12011"
  },
  {
    "id": "arXiv:2201.12014",
    "title": "Convergence of a continuous Galerkin method for mixed  hyperbolic-parabolic systems",
    "abstract": "We study the numerical approximation by space-time finite element methods of\na multi-physics system coupling hyperbolic elastodynamics with parabolic\ntransport and modelling poro- and thermoelasticity. The equations are rewritten\nas a first-order system in time. Discretizations by continuous Galerkin methods\nin space and time with inf-sup stable pairs of finite elements for the spatial\napproximation of the unknowns are investigated. Optimal order error estimates\nof energy-type are proven. Superconvergence at the time nodes is addressed\nbriefly. The error analysis can be extended to discontinuous and enriched\nGalerkin space discretizations. The error estimates are confirmed by numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Markus Bause",
      "Uwe K\u00f6cher",
      "Florin A. Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12014"
  },
  {
    "id": "arXiv:2201.12015",
    "title": "Design of magnetic coupling-based anti-biofouling mechanism for  underwater optical sensors",
    "abstract": "Water monitoring is crucial for environmental monitoring, transportation,\nenergy and telecommunication. One of the main problems in aquatic environmental\nmonitoring is biofouling. The simplest method among the current antifouling\nstrategies is the use of wiper technologies like brushes and wipers which apply\nmechanical pressure. In designing built-in strategies however, manufacturers\nusually build the sensor around the biofouling system. The current\nstate-of-the-art is a fully integrated central wiper in the sensor that enables\ncleaning of all probes mounted on the sonde. Improvements in antifouling\nstrategies lag rapid advancements in sensor technologies such as in\nminiaturization, specialization, and costs. Hence, improving built-in designs\nby decreasing size and complexity will decrease maintenance and overall costs.\nThis design is targeted for the EU project Robocoenosis since bio-hybrid\nsystems in this project incorporate living organisms. This technology targets\nselective proliferation of the organisms which only prevents biofilms on\ncomponents where they are unwanted. Beyond this, the use of autonomous\nactivation based on image processing may likely be advantageous for minimizing\nthe need for human inspection and maintenance. In addition to Robocoenosis, we\nalso aim at incorporating this design in another project entitled Heterogeneous\nSwarm of Underwater Autonomous Vehicles where a swarm of heterogeneous\nunderwater robotic fish is being developed.",
    "descriptor": "\nComments: 6 pages, 10 figures\n",
    "authors": [
      "Jane Pauline Ramirez",
      "Cesare Stefanini",
      "Giulia De Masi",
      "Donato Romano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12015"
  },
  {
    "id": "arXiv:2201.12018",
    "title": "Transfer Learning In Differential Privacy's Hybrid-Model",
    "abstract": "The hybrid-model (Avent et al 2017) in Differential Privacy is a an\naugmentation of the local-model where in addition to N local-agents we are\nassisted by one special agent who is in fact a curator holding the sensitive\ndetails of n additional individuals. Here we study the problem of machine\nlearning in the hybrid-model where the n individuals in the curators dataset\nare drawn from a different distribution than the one of the general population\n(the local-agents). We give a general scheme -- Subsample-Test-Reweigh -- for\nthis transfer learning problem, which reduces any curator-model DP-learner to a\nhybrid-model learner in this setting using iterative subsampling and reweighing\nof the n examples held by the curator based on a smooth variation of the\nMultiplicative-Weights algorithm (introduced by Bun et al, 2020). Our scheme\nhas a sample complexity which relies on the chi-squared divergence between the\ntwo distributions. We give worst-case analysis bounds on the sample complexity\nrequired for our private reduction. Aiming to reduce said sample complexity, we\ngive two specific instances our sample complexity can be drastically reduced\n(one instance is analyzed mathematically, while the other - empirically) and\npose several directions for follow-up work.",
    "descriptor": "",
    "authors": [
      "Refael Kohen",
      "Or Sheffet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.12018"
  },
  {
    "id": "arXiv:2201.12021",
    "title": "Network Selection schemes in Heterogeneous Wireless Networks",
    "abstract": "Heterogeneous Wireless Networks HWNs are combined networks made of different\nRadio Access Technologies RAT. Next-Generation Networks NGN will provide high\nbandwidth connectivity and high data throughput with smooth support for the\nuser's QoS requirements, in this context, users with multi-interface terminals\nwill be able to connect to different wireless technologies such as 802.16,\n802.11 families and cellular families UMTS, HSPA and LTE in the same time. The\nidea of NGN is that users will not be tied with a contract with one single\noperator but, users will be able to choose the Radio Access Network RAT\nconsidering the user's QoS requested. This paper focuses on the network\nselection strategies and the inter technologies Handoff, we will present a\ndescription of the existed methods of network selection, we will discuss the\nmerits and the weakness of such method and we will give our point of view.",
    "descriptor": "",
    "authors": [
      "Bendaoud Fayssal",
      "Abdennebi Marwen",
      "Didi Fedoua"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.12021"
  },
  {
    "id": "arXiv:2201.12022",
    "title": "High-order integrators for Lagrangian systems on homogeneous spaces via  nonholonomic mechanics",
    "abstract": "In this paper, high-order numerical integrators on homogeneous spaces will be\npresented as an application of nonholonomic partitioned Runge-Kutta Munthe-Kaas\n(RKMK) methods on Lie groups.\nA homogeneous space $M$ is a manifold where a group $G$ acts transitively.\nSuch a space can be understood as a quotient $M \\cong G/H$, where $H$ a closed\nLie subgroup, is the isotropy group of each point of $M$. The Lie algebra of\n$G$ may be decomposed into $\\mathfrak{g} = \\mathfrak{m} \\oplus \\mathfrak{h}$,\nwhere $\\mathfrak{h}$ is the subalgebra that generates $H$ and $\\mathfrak{m}$ is\na subspace. Thus, variational problems on $M$ can be treated as\nnonholonomically constrained problems on $G$, by requiring variations to remain\non $\\mathfrak{m}$.\nNonholonomic partitioned RKMK integrators are derived as a modification of\nthose obtained by a discrete variational principle on Lie groups, and can be\ninterpreted as obeying a discrete Chetaev principle. These integrators tend to\npreserve several properties of their purely variational counterparts.",
    "descriptor": "\nComments: 14 figures. Part of NUMDIFF16\n",
    "authors": [
      "Rodrigo T. Sato Mart\u00edn de Almagro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2201.12022"
  },
  {
    "id": "arXiv:2201.12023",
    "title": "Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed  Deep Learning",
    "abstract": "Alpa automates model-parallel training of large deep learning (DL) models by\ngenerating execution plans that unify data, operator, and pipeline parallelism.\nExisting model-parallel training systems either require users to manually\ncreate a parallelization plan or automatically generate one from a limited\nspace of model parallelism configurations, which does not suffice to scale out\ncomplex DL models on distributed compute devices. Alpa distributes the training\nof large DL models by viewing parallelisms as two hierarchical levels:\ninter-operator and intra-operator parallelisms. Based on it, Alpa constructs a\nnew hierarchical space for massive model-parallel execution plans. Alpa designs\na number of compilation passes to automatically derive the optimal parallel\nexecution plan in each independent parallelism level and implements an\nefficient runtime to orchestrate the two-level parallel execution on\ndistributed compute devices. Our evaluation shows Alpa generates\nparallelization plans that match or outperform hand-tuned model-parallel\ntraining systems even on models they are designed for. Unlike specialized\nsystems, Alpa also generalizes to models with heterogeneous architectures and\nmodels without manually-designed plans.",
    "descriptor": "",
    "authors": [
      "Lianmin Zheng",
      "Zhuohan Li",
      "Hao Zhang",
      "Yonghao Zhuang",
      "Zhifeng Chen",
      "Yanping Huang",
      "Yida Wang",
      "Yuanzhong Xu",
      "Danyang Zhuo",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12023"
  },
  {
    "id": "arXiv:2201.12026",
    "title": "Dynamic pricing and discounts by means of interactive presentation  systems in stationary point of sales",
    "abstract": "The main purpose of this article was to create a model and simulate the\nprofitability conditions of an interactive presentation system (IPS) with the\nrecommender system (RS) used in the kiosk. 90 million simulations have been run\nin Python with SymPy to address the problem of discount recommendation offered\nto the clients according to their usage of the IPS.",
    "descriptor": "",
    "authors": [
      "Marcin Lewicki",
      "Tomasz Kajdanowicz",
      "Piotr Br\u00f3dka",
      "Janusz Sobecki"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12026"
  },
  {
    "id": "arXiv:2201.12027",
    "title": "Puppeteer: A Random Forest-based Manager for Hardware Prefetchers across  the Memory Hierarchy",
    "abstract": "Over the years, processor throughput has steadily increased. However, the\nmemory throughput has not increased at the same rate, which has led to the\nmemory wall problem in turn increasing the gap between effective and\ntheoretical peak processor performance. To cope with this, there has been an\nabundance of work in the area of data/instruction prefetcher designs. Broadly,\nprefetchers predict future data/instruction address accesses and proactively\nfetch data/instructions in the memory hierarchy with the goal of lowering\ndata/instruction access latency. To this end, one or more prefetchers are\ndeployed at each level of the memory hierarchy, but typically, each prefetcher\ngets designed in isolation without comprehensively accounting for other\nprefetchers in the system. As a result, individual prefetchers do not always\ncomplement each other, and that leads to lower average performance gains and/or\nmany negative outliers. In this work, we propose Puppeteer, which is a hardware\nprefetcher manager that uses a suite of random forest regressors to determine\nat runtime which prefetcher should be ON at each level in the memory hierarchy,\nsuch that the prefetchers complement each other and we reduce the\ndata/instruction access latency. Compared to a design with no prefetchers,\nusing Puppeteer we improve IPC by 46.0% in 1 Core (1C), 25.8% in 4 Core (4C),\nand 11.9% in 8 Core (8C) processors on average across traces generated from\nSPEC2017, SPEC2006, and Cloud suites with ~10KB overhead. Moreover, we also\nreduce the number of negative outliers by over 89%, and the performance loss of\nthe worst-case negative outlier from 25% to only 5% compared to the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Furkan Eris",
      "Marcia S. Louis",
      "Kubra Eris",
      "Jose L. Abellan",
      "Ajay Joshi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.12027"
  },
  {
    "id": "arXiv:2201.12031",
    "title": "1-2-3 Reproducibility for Quantum Software Experiments",
    "abstract": "Various fields of science face a reproducibility crisis. For quantum software\nengineering as an emerging field, it is therefore imminent to focus on proper\nreproducibility engineering from the start. Yet the provision of reproduction\npackages is almost universally lacking. Actionable advice on how to build such\npackages is rare, particularly unfortunate in a field with many contributions\nfrom researchers with backgrounds outside computer science. In this article, we\nargue how to rectify this deficiency by proposing a 1-2-3~approach to\nreproducibility engineering for quantum software experiments: Using a\nmeta-generation mechanism, we generate DOI-safe, long-term functioning and\ndependency-free reproduction packages. They are designed to satisfy the\nrequirements of professional and learned societies solely on the basis of\nproject-specific research artefacts (source code, measurement and configuration\ndata), and require little temporal investment by researchers. Our scheme\nascertains long-term traceability even when the quantum processor itself is no\nlonger accessible. By drastically lowering the technical bar, we foster the\nproliferation of reproduction packages in quantum software experiments and ease\nthe inclusion of non-CS researchers entering the field.",
    "descriptor": "\nComments: Q-SANER@SANER 2022 (to appear)\n",
    "authors": [
      "Wolfgang Mauerer",
      "Stefanie Scherzinger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.12031"
  },
  {
    "id": "arXiv:2201.12032",
    "title": "Neural Approximation of Extended Persistent Homology on Graphs",
    "abstract": "Persistent homology is a widely used theory in topological data analysis. In\nthe context of graph learning, topological features based on persistent\nhomology have been used to capture potentially high-order structural\ninformation so as to augment existing graph neural network methods. However,\ncomputing extended persistent homology summaries remains slow for large and\ndense graphs, especially since in learning applications one has to carry out\nthis computation potentially many times. Inspired by recent success in neural\nalgorithmic reasoning, we propose a novel learning method to compute extended\npersistence diagrams on graphs. The proposed neural network aims to simulate a\nspecific algorithm and learns to compute extended persistence diagrams for new\ngraphs efficiently. Experiments on approximating extended persistence diagrams\nand several downstream graph representation learning tasks demonstrate the\neffectiveness of our method. Our method is also efficient; on large and dense\ngraphs, we accelerate the computation by nearly 100 times.",
    "descriptor": "",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12032"
  },
  {
    "id": "arXiv:2201.12038",
    "title": "A survey on flexible/restricted skyline and their applicability",
    "abstract": "Skyline and Top-k are two of the most important method to extract information\nfrom dataset, but both come with their own drawbacks, that's why lately some\nnew technics that try to mix the features of the two have been studied, in this\nsurvey three new operators are analyzed, F-Skyline, ORU/ORD and\n${\\epsilon}$-Skyline, after giving the main ideas behind those and their\nproperties, they are compered on 3 fundamental features such as\npersonalization, cardinality control and generalization to guide the user to\nchoose the best one for any task.",
    "descriptor": "",
    "authors": [
      "Davide Canali"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.12038"
  },
  {
    "id": "arXiv:2201.12044",
    "title": "Generative GaitNet",
    "abstract": "Understanding the relation between anatomy andgait is key to successful\npredictive gait simulation. Inthis paper, we present Generative GaitNet, which\nisa novel network architecture based on deep reinforce-ment learning for\ncontrolling a comprehensive, full-body, musculoskeletal model with 304\nHill-type mus-culotendons. The Generative Gait is a pre-trained, in-tegrated\nsystem of artificial neural networks learnedin a 618-dimensional continuous\ndomain of anatomyconditions (e.g., mass distribution, body proportion,bone\ndeformity, and muscle deficits) and gait condi-tions (e.g., stride and\ncadence). The pre-trained Gait-Net takes anatomy and gait conditions as input\nandgenerates a series of gait cycles appropriate to theconditions through\nphysics-based simulation. We willdemonstrate the efficacy and expressive power\nof Gen-erative GaitNet to generate a variety of healthy andpathologic human\ngaits in real-time physics-based sim-ulation.",
    "descriptor": "\nComments: 12 pages, 6 figures and 1 table\n",
    "authors": [
      "Jungnam Park",
      "Sehee Min",
      "Phil Sik Chang",
      "Jaedong Lee",
      "Moonseok Park",
      "Jehee Lee"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12044"
  },
  {
    "id": "arXiv:2201.12046",
    "title": "TSSB-3M: Mining single statement bugs at massive scale",
    "abstract": "Single statement bugs are one of the most important ingredients in the\nevaluation of modern bug detection and automatic program repair methods. By\naffecting only a single statement, single statement bugs represent a type of\nbug often overlooked by developers, while still being small enough to be\ndetected and fixed by automatic methods. With the rise of data-driven automatic\nrepair the availability of single statement bugs at the scale of millionth of\nexamples is more important than ever; not only for testing these methods but\nalso for providing sufficient real world examples for training. To provide\naccess to bug fix datasets of this scale, we are releasing two datasets called\nSSB-9M and TSSB-3M. While SSB-9M provides access to a collection of over 9M\ngeneral single statement bug fixes from over 500K open source Python projects ,\nTSSB-3M focuses on over 3M single statement bugs which can be fixed solely by a\nsingle statement change. To facilitate future research and empirical\ninvestigations, we annotated each bug fix with one of 20 single statement bug\n(SStuB) patterns typical for Python together with a characterization of the\ncode change as a sequence of AST modifications. Our initial investigation shows\nthat at least 40% of all single statement bug fixes mined fit at least one\nSStuB pattern, and that the majority of 72% of all bugs can be fixed with the\nsame syntactic modifications as needed for fixing SStuBs.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Cedric Richter",
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12046"
  },
  {
    "id": "arXiv:2201.12047",
    "title": "RGB-D SLAM Using Attention Guided Frame Association",
    "abstract": "Deep learning models as an emerging topic have shown great progress in\nvarious fields. Especially, visualization tools such as class activation\nmapping methods provided visual explanation on the reasoning of convolutional\nneural networks (CNNs). By using the gradients of the network layers, it is\npossible to demonstrate where the networks pay attention during a specific\nimage recognition task. Moreover, these gradients can be integrated with CNN\nfeatures for localizing more generalized task dependent attentive (salient)\nobjects in scenes. Despite this progress, there is not much explicit usage of\nthis gradient (network attention) information to integrate with CNN\nrepresentations for object semantics. This can be very useful for visual tasks\nsuch as simultaneous localization and mapping (SLAM) where CNN representations\nof spatially attentive object locations may lead to improved performance.\nTherefore, in this work, we propose the use of task specific network attention\nfor RGB-D indoor SLAM. To do so, we integrate layer-wise object attention\ninformation (layer gradients) with CNN layer representations to improve frame\nassociation performance in a state-of-the-art RGB-D indoor SLAM method.\nExperiments show promising initial results with improved performance.",
    "descriptor": "\nComments: 5 pages, 3 figures, 1 table\n",
    "authors": [
      "Ali Caglayan",
      "Nevrez Imamoglu",
      "Oguzhan Guclu",
      "Ali Osman Serhatoglu",
      "Weimin Wang",
      "Ahmet Burak Can",
      "Ryosuke Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12047"
  },
  {
    "id": "arXiv:2201.12048",
    "title": "The FreshPRINCE: A Simple Transformation Based Pipeline Time Series  Classifier",
    "abstract": "There have recently been significant advances in the accuracy of algorithms\nproposed for time series classification (TSC). However, a commonly asked\nquestion by real world practitioners and data scientists less familiar with the\nresearch topic, is whether the complexity of the algorithms considered state of\nthe art is really necessary. Many times the first approach suggested is a\nsimple pipeline of summary statistics or other time series feature extraction\napproaches such as TSFresh, which in itself is a sensible question; in\npublications on TSC algorithms generalised for multiple problem types, we\nrarely see these approaches considered or compared against. We experiment with\nbasic feature extractors using vector based classifiers shown to be effective\nwith continuous attributes in current state-of-the-art time series classifiers.\nWe test these approaches on the UCR time series dataset archive, looking to see\nif TSC literature has overlooked the effectiveness of these approaches. We find\nthat a pipeline of TSFresh followed by a rotation forest classifier, which we\nname FreshPRINCE, performs best. It is not state of the art, but it is\nsignificantly more accurate than nearest neighbour with dynamic time warping,\nand represents a reasonable benchmark for future comparison.",
    "descriptor": "",
    "authors": [
      "Matthew Middlehurst",
      "Anthony Bagnall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12048"
  },
  {
    "id": "arXiv:2201.12050",
    "title": "Fast multipole boundary element method for the acoustic analysis of  finite periodic structures",
    "abstract": "In this work, two fast multipole boundary element formulations for the linear\ntime-harmonic acoustic analysis of finite periodic structures are presented.\nFinite periodic structures consist of a bounded number of unit cell\nreplications in one or more directions of periodicity. Such structures can be\ndesigned to efficiently control and manipulate sound waves and are referred to\nas acoustic metamaterials or sonic crystals. Our methods subdivide the geometry\ninto boxes which correspond to the unit cell. A boundary element discretization\nis applied and interactions between well separated boxes are approximated by a\nfast multipole expansion. Due to the periodicity of the underlying geometry,\ncertain operators of the expansion become block Toeplitz matrices. This allows\nto express matrix-vector products as circular convolutions which significantly\nreduces the computational effort and the overall memory requirements. The\nefficiency of the presented techniques is shown based on an acoustic scattering\nproblem. In addition, a study on the design of sound barriers is presented\nwhere the performance of a wall-like sound barrier is compared to the\nperformance of two sonic crystal sound barriers.",
    "descriptor": "",
    "authors": [
      "Christopher Jelich",
      "Wenchang Zhao",
      "Haibo Chen",
      "Steffen Marburg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.12050"
  },
  {
    "id": "arXiv:2201.12051",
    "title": "Detection of fake faces in videos",
    "abstract": ": Deep learning methodologies have been used to create applications that can\ncause threats to privacy, democracy and national security and could be used to\nfurther amplify malicious activities. One of those deep learning-powered\napplications in recent times is synthesized videos of famous personalities.\nAccording to Forbes, Generative Adversarial Networks(GANs) generated fake\nvideos growing exponentially every year and the organization known as Deeptrace\nhad estimated an increase of deepfakes by 84% from the year 2018 to 2019. They\nare used to generate and modify human faces, where most of the existing fake\nvideos are of prurient non-consensual nature, of which its estimates to be\naround 96% and some carried out impersonating personalities for cyber crime. In\nthis paper, available video datasets are identified and a pretrained model\nBlazeFace is used to detect faces, and a ResNet and Xception ensembled\narchitectured neural network trained on the dataset to achieve the goal of\ndetection of fake faces in videos. The model is optimized over a loss value and\nlog loss values and evaluated over its F1 score. Over a sample of data, it is\nobserved that focal loss provides better accuracy, F1 score and loss as the\ngamma of the focal loss becomes a hyper parameter. This provides a k-folded\naccuracy of around 91% at its peak in a training cycle with the real world\naccuracy subjected to change over time as the model decays.",
    "descriptor": "\nComments: 5 pages, 11 figures\n",
    "authors": [
      "M. Shamanth",
      "Russel Mathias",
      "Dr Vijayalakshmi MN"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12051"
  },
  {
    "id": "arXiv:2201.12052",
    "title": "Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks",
    "abstract": "We study the overparametrization bounds required for the global convergence\nof stochastic gradient descent algorithm for a class of one hidden layer\nfeed-forward neural networks, considering most of the activation functions used\nin practice, including ReLU. We improve the existing state-of-the-art results\nin terms of the required hidden layer width. We introduce a new proof technique\ncombining nonlinear analysis with properties of random initializations of the\nnetwork. First, we establish the global convergence of continuous solutions of\nthe differential inclusion being a nonsmooth analogue of the gradient flow for\nthe MSE loss. Second, we provide a technical result (working also for general\napproximators) relating solutions of the aforementioned differential inclusion\nto the (discrete) stochastic gradient descent sequences, hence establishing\nlinear convergence towards zero loss for the stochastic gradient descent\niterations.",
    "descriptor": "",
    "authors": [
      "Bart\u0142omiej Polaczyk",
      "Jacek Cyranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12052"
  },
  {
    "id": "arXiv:2201.12054",
    "title": "Regularized minimal-norm solution of an overdetermined system of first  kind integral equations",
    "abstract": "Overdetermined systems of first kind integral equations appear in many\napplications. When the right-hand side is discretized, the resulting\nfinite-data problem is ill-posed and admits infinitely many solutions. We\npropose a numerical method to compute the minimal-norm solution in the presence\nof boundary constraints. The algorithm stems from the Riesz representation\ntheorem and operates in a reproducing kernel Hilbert space. Since the resulting\nlinear system is strongly ill-conditioned, we construct a regularization method\ndepending on a discrete parameter. It is based on the expansion of the\nminimal-norm solution in terms of the singular functions of the integral\noperator defining the problem. Two estimation techniques are tested for the\nautomatic determination of the regularization parameter, namely, the\ndiscrepancy principle and the L-curve method. Numerical results concerning two\nartificial test problems demonstrate the excellent performance of the proposed\nmethod. Finally, a particular model typical of geophysical applications, which\nreproduces the readings of a frequency domain electromagnetic induction device,\nis investigated. The results show that the new method is extremely effective\nwhen the sought solution is smooth, but gives significant information on the\nsolution even for non-smooth solutions.",
    "descriptor": "",
    "authors": [
      "Patricia D\u00edaz de Alba",
      "Luisa Fermo",
      "Federica Pes",
      "Giuseppe Rodriguez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12054"
  },
  {
    "id": "arXiv:2201.12055",
    "title": "Automated Feature Extraction on AsMap for Emotion Classification using  EEG",
    "abstract": "Emotion recognition using EEG has been widely studied to address the\nchallenges associated with affective computing. Using manual feature extraction\nmethod on EEG signals result in sub-optimal performance by the learning models.\nWith the advancements in deep learning as a tool for automated feature\nengineering, in this work a hybrid of manual and automatic feature extraction\nmethod has been proposed. The asymmetry in the different brain regions are\ncaptured in a 2-D vector, termed as AsMap from the differential entropy (DE)\nfeatures of EEG signals. These AsMaps are then used to extract features\nautomatically using Convolutional Neural Network (CNN) model. The proposed\nfeature extraction method has been compared with DE and other DE-based feature\nextraction methods such as RASM, DASM and DCAU. Experiments are conducted using\nDEAP and SEED dataset on different classification problems based on number of\nclasses. Results obtained indicate that the proposed method of feature\nextraction results in higher classification accuracy outperforming the DE based\nfeature extraction methods. Highest classification accuracy of 97.10% is\nachieved on 3-class classification problem using SEED dataset. Further, the\nimpact of window size on classification accuracy has also been assessed in this\nwork.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Md. Zaved Iqubal Ahmed",
      "Nidul Sinha",
      "Souvik Phadikar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12055"
  },
  {
    "id": "arXiv:2201.12059",
    "title": "Learning Summary Statistics for Bayesian Inference with Autoencoders",
    "abstract": "For stochastic models with intractable likelihood functions, approximate\nBayesian computation offers a way of approximating the true posterior through\nrepeated comparisons of observations with simulated model outputs in terms of a\nsmall set of summary statistics. These statistics need to retain the\ninformation that is relevant for constraining the parameters but cancel out the\nnoise. They can thus be seen as thermodynamic state variables, for general\nstochastic models. For many scientific applications, we need strictly more\nsummary statistics than model parameters to reach a satisfactory approximation\nof the posterior. Therefore, we propose to use the inner dimension of deep\nneural network based Autoencoders as summary statistics. To create an incentive\nfor the encoder to encode all the parameter-related information but not the\nnoise, we give the decoder access to explicit or implicit information on the\nnoise that has been used to generate the training data. We validate the\napproach empirically on two types of stochastic models.",
    "descriptor": "",
    "authors": [
      "Carlo Albert",
      "Simone Ulzega",
      "Firat Ozdemir",
      "Fernando Perez-Cruz",
      "Antonietta Mira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12059"
  },
  {
    "id": "arXiv:2201.12071",
    "title": "What is Legitimate Decision Support?",
    "abstract": "Decision support is the science and associated practice that consist in\nproviding recommendations to decision makers facing problems, based on\navailable theoretical knowledge and empirical data. Although this activity is\noften seen as being concerned with solving mathematical problems and conceiving\nalgorithms, it is essentially an empirical and socially framed activity, where\ninteractions between clients and analysts, and between them and concerned third\nparties, play a crucial role. Since the 80s, two concepts have structured the\nliterature devoted to analysing this aspect of decision support: validity and\nlegitimacy. Whereas validity is focused on the interactions between the client\nand the analyst, legitimacy refers to the broader picture: the organisational\ncontext, the overall problem situation, the environment, culture, history.\nDespite its importance, this concept has not received the attention it deserves\nin the literature in decision support. The present paper aims at filling this\ngap. For that purpose, we review the literature in other disciplines relevant\nto elaborate a concept of legitimacy useful in decision support contexts. Based\non this review, we propose a general theory of legitimacy, adapted to decision\nsupport contexts, encompassing the relevant contributions we found in the\nliterature. According to this general theory, a legitimate decision support\nintervention is one for which the decision support provider produces a\njustification that satisfies two conditions: (i) it effectively convinces the\ndecision support provider's interlocutors (effectiveness condition) and (ii) it\nis organised around the active elicitation of as many and as diverse\ncounterarguments as possible (truthfulness condition). Despite its conceptual\nsimplicity, legitimacy, understood in this sense, is a very exacting\nrequirement, opening ambitious research avenues that we delineate.",
    "descriptor": "",
    "authors": [
      "Yves Meinard",
      "Alexis Tsouki\u00e0s"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.12071"
  },
  {
    "id": "arXiv:2201.12078",
    "title": "You Only Cut Once: Boosting Data Augmentation with a Single Cut",
    "abstract": "We present You Only Cut Once (YOCO) for performing data augmentations. YOCO\ncuts one image into two pieces and performs data augmentations individually\nwithin each piece. Applying YOCO improves the diversity of the augmentation per\nsample and encourages neural networks to recognize objects from partial\ninformation. YOCO enjoys the properties of parameter-free, easy usage, and\nboosting almost all augmentations for free. Thorough experiments are conducted\nto evaluate its effectiveness. We first demonstrate that YOCO can be seamlessly\napplied to varying data augmentations, neural network architectures, and brings\nperformance gains on CIFAR and ImageNet classification tasks, sometimes\nsurpassing conventional image-level augmentation by large margins. Moreover, we\nshow YOCO benefits contrastive pre-training toward a more powerful\nrepresentation that can be better transferred to multiple downstream tasks.\nFinally, we study a number of variants of YOCO and empirically analyze the\nperformance for respective settings. Code is available at GitHub.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Junlin Han",
      "Pengfei Fang",
      "Weihao Li",
      "Jie Hong",
      "Mohammad Ali Armin",
      "Ian Reid",
      "Lars Petersson",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12078"
  },
  {
    "id": "arXiv:2201.12082",
    "title": "Interplay between depth of neural networks and locality of target  functions",
    "abstract": "It has been recognized that heavily overparameterized deep neural networks\n(DNNs) exhibit surprisingly good generalization performance in various\nmachine-learning tasks. Although benefits of depth have been investigated from\ndifferent perspectives such as the approximation theory and the statistical\nlearning theory, existing theories do not adequately explain the empirical\nsuccess of overparameterized DNNs. In this work, we report a remarkable\ninterplay between depth and locality of a target function. We introduce\n$k$-local and $k$-global functions, and find that depth is beneficial for\nlearning local functions but detrimental to learning global functions. This\ninterplay is not properly captured by the neural tangent kernel, which\ndescribes an infinitely wide neural network within the lazy learning regime.",
    "descriptor": "\nComments: 15 pages. This paper is a revised version of arXiv:2005.12488\n",
    "authors": [
      "Takashi Mori",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12082"
  },
  {
    "id": "arXiv:2201.12083",
    "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing",
    "abstract": "Recently, MLP-like vision models have achieved promising performances on\nmainstream visual recognition tasks. In contrast with vision transformers and\nCNNs, the success of MLP-like models shows that simple information fusion\noperations among tokens and channels can yield a good representation power for\ndeep recognition models. However, existing MLP-like models fuse tokens through\nstatic fusion operations, lacking adaptability to the contents of the tokens to\nbe mixed. Thus, customary information fusion procedures are not effective\nenough. To this end, this paper presents an efficient MLP-like network\narchitecture, dubbed DynaMixer, resorting to dynamic information fusion.\nCritically, we propose a procedure, on which the DynaMixer model relies, to\ndynamically generate mixing matrices by leveraging the contents of all the\ntokens to be mixed. To reduce the time complexity and improve the robustness, a\ndimensionality reduction technique and a multi-segment fusion mechanism are\nadopted. Our proposed DynaMixer model (97M parameters) achieves 84.3\\% top-1\naccuracy on the ImageNet-1K dataset without extra training data, performing\nfavorably against the state-of-the-art vision MLP models. When the number of\nparameters is reduced to 26M, it still achieves 82.7\\% top-1 accuracy,\nsurpassing the existing MLP-like models with a similar capacity. The\nimplementation of DynaMixer will be made available to the public.",
    "descriptor": "",
    "authors": [
      "Ziyu Wang",
      "Wenhao Jiang",
      "Yiming Zhu",
      "Li Yuan",
      "Yibing Song",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12083"
  },
  {
    "id": "arXiv:2201.12084",
    "title": "Psychophysical Evaluation of Human Performance in Detecting Digital Face  Image Manipulations",
    "abstract": "In recent years, increasing deployment of face recognition technology in\nsecurity-critical settings, such as border control or law enforcement, has led\nto considerable interest in the vulnerability of face recognition systems to\nattacks utilising legitimate documents, which are issued on the basis of\ndigitally manipulated face images. As automated manipulation and attack\ndetection remains a challenging task, conventional processes with human\ninspectors performing identity verification remain indispensable. These\ncircumstances merit a closer investigation of human capabilities in detecting\nmanipulated face images, as previous work in this field is sparse and often\nconcentrated only on specific scenarios and biometric characteristics.\nThis work introduces a web-based, remote visual discrimination experiment on\nthe basis of principles adopted from the field of psychophysics and\nsubsequently discusses interdisciplinary opportunities with the aim of\nexamining human proficiency in detecting different types of digitally\nmanipulated face images, specifically face swapping, morphing, and retouching.\nIn addition to analysing appropriate performance measures, a possible metric of\ndetectability is explored. Experimental data of 306 probands indicate that\ndetection performance is widely distributed across the population and detection\nof certain types of face image manipulations is much more challenging than\nothers.",
    "descriptor": "",
    "authors": [
      "Robert Nichols",
      "Christian Rathgeb",
      "Pawel Drozdowski",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12084"
  },
  {
    "id": "arXiv:2201.12085",
    "title": "Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint  Moves",
    "abstract": "Mobile apps are indispensable for people's daily life. Complementing with\nautomated GUI testing, manual testing is the last line of defence for app\nquality. However, the repeated actions and easily missing of functionalities\nmake manual testing time-consuming and inefficient. Inspired by the game candy\ncrush with flashy candies as hint moves for players, we propose an approach\nnamed NaviDroid for navigating testers via highlighted next operations for more\neffective and efficient testing. Within NaviDroid, we construct an enriched\nstate transition graph with the triggering actions as the edges for two\ninvolved states. Based on it, we utilize the dynamic programming algorithm to\nplan the exploration path, and augment the GUI with visualized hints for\ntesters to quickly explore untested activities and avoid duplicate\nexplorations. The automated experiments demonstrate the high coverage and\nefficient path planning of NaviDroid and a user study further confirms its\nusefulness. The NaviDroid can help us develop more robust software that works\nin more mission-critical settings, not only by performing more thorough testing\nwith the same effort that has been put in before, but also by integrating these\ntechniques into different parts of development pipeline.",
    "descriptor": "\nComments: Accepted to CHI Conference on Human Factors in Computing Systems (CHI'22)\n",
    "authors": [
      "Zhe Liu",
      "Chunyang Chen",
      "Junjie Wang",
      "Yuekai Huang",
      "Jun Hu",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12085"
  },
  {
    "id": "arXiv:2201.12086",
    "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified  Vision-Language Understanding and Generation",
    "abstract": "Vision-Language Pre-training (VLP) has advanced the performance for many\nvision-language tasks. However, most existing pre-trained models only excel in\neither understanding-based tasks or generation-based tasks. Furthermore,\nperformance improvement has been largely achieved by scaling up the dataset\nwith noisy image-text pairs collected from the web, which is a suboptimal\nsource of supervision. In this paper, we propose BLIP, a new VLP framework\nwhich transfers flexibly to both vision-language understanding and generation\ntasks. BLIP effectively utilizes the noisy web data by bootstrapping the\ncaptions, where a captioner generates synthetic captions and a filter removes\nthe noisy ones. We achieve state-of-the-art results on a wide range of\nvision-language tasks, such as image-text retrieval (+2.7% in average\nrecall@1), image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score).\nBLIP also demonstrates strong generalization ability when directly transferred\nto video-language tasks in a zero-shot manner. Code, models, and datasets are\nreleased at https://github.com/salesforce/BLIP.",
    "descriptor": "",
    "authors": [
      "Junnan Li",
      "Dongxu Li",
      "Caiming Xiong",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12086"
  },
  {
    "id": "arXiv:2201.12088",
    "title": "On feedforward control using physics-guided neural networks: Training  cost regularization and optimized initialization",
    "abstract": "Performance of model-based feedforward controllers is typically limited by\nthe accuracy of the inverse system dynamics model. Physics-guided neural\nnetworks (PGNN), where a known physical model cooperates in parallel with a\nneural network, were recently proposed as a method to achieve high accuracy of\nthe identified inverse dynamics. However, the flexible nature of neural\nnetworks can create overparameterization when employed in parallel with a\nphysical model, which results in a parameter drift during training. This drift\nmay result in parameters of the physical model not corresponding to their\nphysical values, which increases vulnerability of the PGNN to operating\nconditions not present in the training data. To address this problem, this\npaper proposes a regularization method via identified physical parameters, in\ncombination with an optimized training initialization that improves training\nconvergence. The regularized PGNN framework is validated on a real-life\nindustrial linear motor, where it delivers better tracking accuracy and\nextrapolation.",
    "descriptor": "",
    "authors": [
      "Max Bolderman",
      "Mircea Lazar",
      "Hans Butler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12088"
  },
  {
    "id": "arXiv:2201.12089",
    "title": "Label uncertainty-guided multi-stream model for disease screening",
    "abstract": "The annotation of disease severity for medical image datasets often relies on\ncollaborative decisions from multiple human graders. The intra-observer\nvariability derived from individual differences always persists in this\nprocess, yet the influence is often underestimated. In this paper, we cast the\nintra-observer variability as an uncertainty problem and incorporate the label\nuncertainty information as guidance into the disease screening model to improve\nthe final decision. The main idea is dividing the images into simple and hard\ncases by uncertainty information, and then developing a multi-stream network to\ndeal with different cases separately. Particularly, for hard cases, we\nstrengthen the network's capacity in capturing the correct disease features and\nresisting the interference of uncertainty. Experiments on a fundus image-based\nglaucoma screening case study show that the proposed model outperforms several\nbaselines, especially in screening hard cases.",
    "descriptor": "\nComments: To appear in ISBI 2022\n",
    "authors": [
      "Chi Liu",
      "Zongyuan Ge",
      "Mingguang He",
      "Xiaotong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12089"
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": "Modern neural models trained on textual data rely on pre-trained\nrepresentations that emerge without direct supervision. As these\nrepresentations are increasingly being used in real-world applications, the\ninability to \\emph{control} their content becomes an increasingly important\nproblem.\nWe formulate the problem of identifying and erasing a linear subspace that\ncorresponds to a given concept, in order to prevent linear predictors from\nrecovering the concept. We model this problem as a constrained, linear minimax\ngame, and show that existing solutions are generally not optimal for this task.\nWe derive a closed-form solution for certain objectives, and propose a convex\nrelaxation, R-LACE, that works well for others. When evaluated in the context\nof binary gender removal, the method recovers a low-dimensional subspace whose\nremoval mitigates bias by intrinsic and extrinsic evaluation. We show that the\nmethod -- despite being linear -- is highly expressive, effectively mitigating\nbias in deep nonlinear classifiers while maintaining tractability and\ninterpretability.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12091"
  },
  {
    "id": "arXiv:2201.12093",
    "title": "PCL: Peer-Contrastive Learning with Diverse Augmentations for  Unsupervised Sentence Embeddings",
    "abstract": "Learning sentence embeddings in an unsupervised manner is fundamental in\nnatural language processing. Recent common practice is to couple pre-trained\nlanguage models with unsupervised contrastive learning, whose success relies on\naugmenting a sentence with a semantically-close positive instance to construct\ncontrastive pairs. Nonetheless, existing approaches usually depend on a\nmono-augmenting strategy, which causes learning shortcuts towards the\naugmenting biases and thus corrupts the quality of sentence embeddings. A\nstraightforward solution is resorting to more diverse positives from a\nmulti-augmenting strategy, while an open question remains about how to\nunsupervisedly learn from the diverse positives but with uneven augmenting\nqualities in the text field. As one answer, we propose a novel Peer-Contrastive\nLearning (PCL) with diverse augmentations. PCL constructs diverse contrastive\npositives and negatives at the group level for unsupervised sentence\nembeddings. PCL can perform peer-positive contrast as well as peer-network\ncooperation, which offers an inherent anti-bias ability and an effective way to\nlearn from diverse augmentations. Experiments on STS benchmarks verify the\neffectiveness of our PCL against its competitors in unsupervised sentence\nembeddings.",
    "descriptor": "",
    "authors": [
      "Qiyu Wu",
      "Chongyang Tao",
      "Tao Shen",
      "Can Xu",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12093"
  },
  {
    "id": "arXiv:2201.12094",
    "title": "Neighborhood-aware Geometric Encoding Network for Point Cloud  Registration",
    "abstract": "The distinguishing geometric features determine the success of point cloud\nregistration. However, most point clouds are partially overlapping, corrupted\nby noise, and comprised of indistinguishable surfaces, which makes it a\nchallenge to extract discriminative features. Here, we propose the\nNeighborhood-aware Geometric Encoding Network (NgeNet) for accurate point cloud\nregistration. NgeNet utilizes a geometric guided encoding module to take\ngeometric characteristics into consideration, a multi-scale architecture to\nfocus on the semantically rich regions in different scales, and a consistent\nvoting strategy to select features with proper neighborhood size and reject the\nspecious features. The awareness of adaptive neighborhood points is obtained\nthrough the multi-scale architecture accompanied by voting. Specifically, the\nproposed techniques in NgeNet are model-agnostic, which could be easily\nmigrated to other networks. Comprehensive experiments on indoor, outdoor and\nobject-centric synthetic datasets demonstrate that NgeNet surpasses all of the\npublished state-of-the-art methods. The code will be available at\nhttps://github.com/zhulf0804/NgeNet.",
    "descriptor": "",
    "authors": [
      "Lifa Zhu",
      "Haining Guan",
      "Changwei Lin",
      "Renmin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12094"
  },
  {
    "id": "arXiv:2201.12096",
    "title": "Mask-based Latent Reconstruction for Reinforcement Learning",
    "abstract": "For deep reinforcement learning (RL) from pixels, learning effective state\nrepresentations is crucial for achieving high performance. However, in\npractice, limited experience and high-dimensional input prevent effective\nrepresentation learning. To address this, motivated by the success of masked\nmodeling in other research fields, we introduce mask-based reconstruction to\npromote state representation learning in RL. Specifically, we propose a simple\nyet effective self-supervised method, Mask-based Latent Reconstruction (MLR),\nto predict the complete state representations in the latent space from the\nobservations with spatially and temporally masked pixels. MLR enables the\nbetter use of context information when learning state representations to make\nthem more informative, which facilitates RL agent training. Extensive\nexperiments show that our MLR significantly improves the sample efficiency in\nRL and outperforms the state-of-the-art sample-efficient RL methods on multiple\ncontinuous benchmark environments.",
    "descriptor": "",
    "authors": [
      "Tao Yu",
      "Zhizheng Zhang",
      "Cuiling Lan",
      "Zhibo Chen",
      "Yan Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12096"
  },
  {
    "id": "arXiv:2201.12098",
    "title": "Autonomous, Mobile Manipulation in a Wall-building Scenario: Team LARICS  at MBZIRC 2020",
    "abstract": "In this paper we present our hardware design and control approaches for a\nmobile manipulation platform used in Challenge 2 of the MBZIRC 2020\ncompetition. In this challenge, a team of UAVs and a single UGV collaborate in\nan autonomous, wall-building scenario, motivated by construction automation and\nlarge-scale robotic 3D printing. The robots must be able, autonomously, to\ndetect, manipulate, and transport bricks in an unstructured, outdoor\nenvironment. Our control approach is based on a state machine that dictates\nwhich controllers are active at each stage of the Challenge. In the first stage\nour UGV uses visual servoing and local controllers to approach the target\nobject without considering its orientation. The second stage consists of\ndetecting the object's global pose using OpenCV-based processing of RGB-D image\nand point-cloud data, and calculating an alignment goal within a global map.\nThe map is built with Google Cartographer and is based on onboard LIDAR, IMU,\nand GPS data. Motion control in the second stage is realized using the ROS Move\nBase package with Time-Elastic Band trajectory optimization. Visual servo\nalgorithms guide the vehicle in local object-approach movement and the arm in\nmanipulating bricks. To ensure a stable grasp of the brick's magnetic patch, we\ndeveloped a passively-compliant, electromagnetic gripper with tactile feedback.\nOur fully-autonomous UGV performed well in Challenge 2 and in post-competition\nevaluations of its brick pick-and-place algorithms.",
    "descriptor": "",
    "authors": [
      "Ivo Vatavuk",
      "Marsela Poli\u0107",
      "Ivan Hrabar",
      "Frano Petri\u0107",
      "Matko Orsag",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12098"
  },
  {
    "id": "arXiv:2201.12099",
    "title": "Detecting Owner-member Relationship with Graph Convolution Network in  Fisheye Camera System",
    "abstract": "The owner-member relationship between wheels and vehicles contributes\nsignificantly to the 3D perception of vehicles, especially in embedded\nenvironments. However, to leverage this relationship we must face two major\nchallenges: i) Traditional IoU-based heuristics have difficulty handling\noccluded traffic congestion scenarios. ii) The effectiveness and applicability\nof the solution in a vehicle-mounted system is difficult. To address these\nissues, we propose an innovative relationship prediction method, DeepWORD, by\ndesigning a graph convolutional network (GCN). Specifically, to improve the\ninformation richness, we use feature maps with local correlation as input to\nthe nodes. Subsequently, we introduce a graph attention network (GAT) to\ndynamically correct the a priori estimation bias. Finally, we designed a\ndataset as a large-scale benchmark which has annotated owner-member\nrelationship, called WORD. In the experiments we learned that the proposed\nmethod achieved state-of-the-art accuracy and real-time performance. The WORD\ndataset is made publicly available at\nhttps://github.com/NamespaceMain/ownermember-relationship-dataset.",
    "descriptor": "\nComments: Accepted by Pattern Recognition. arXiv admin note: substantial text overlap with arXiv:2103.16099\n",
    "authors": [
      "Zizhang Wu",
      "Jason Wang",
      "Tianhao Xu",
      "Fan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12099"
  },
  {
    "id": "arXiv:2201.12105",
    "title": "Improving End-to-End Models for Set Prediction in Spoken Language  Understanding",
    "abstract": "The goal of spoken language understanding (SLU) systems is to determine the\nmeaning of the input speech signal, unlike speech recognition which aims to\nproduce verbatim transcripts. Advances in end-to-end (E2E) speech modeling have\nmade it possible to train solely on semantic entities, which are far cheaper to\ncollect than verbatim transcripts. We focus on this set prediction problem,\nwhere entity order is unspecified. Using two classes of E2E models, RNN\ntransducers and attention based encoder-decoders, we show that these models\nwork best when the training entity sequence is arranged in spoken order. To\nimprove E2E SLU models when entity spoken order is unknown, we propose a novel\ndata augmentation technique along with an implicit attention based alignment\nmethod to infer the spoken order. F1 scores significantly increased by more\nthan 11% for RNN-T and about 2% for attention based encoder-decoder SLU models,\noutperforming previously reported results.",
    "descriptor": "\nComments: ICASSP \\c{opyright}2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Hong-Kwang J. Kuo",
      "Zoltan Tuske",
      "Samuel Thomas",
      "Brian Kingsbury",
      "George Saon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.12105"
  },
  {
    "id": "arXiv:2201.12107",
    "title": "Feature Visualization within an Automated Design Assessment leveraging  Explainable Artificial Intelligence Methods",
    "abstract": "Not only automation of manufacturing processes but also automation of\nautomation procedures itself become increasingly relevant to automation\nresearch. In this context, automated capability assessment, mainly leveraged by\ndeep learning systems driven from 3D CAD data, have been presented. Current\nassessment systems may be able to assess CAD data with regards to abstract\nfeatures, e.g. the ability to automatically separate components from bulk\ngoods, or the presence of gripping surfaces. Nevertheless, they suffer from the\nfactor of black box systems, where an assessment can be learned and generated\neasily, but without any geometrical indicator about the reasons of the system's\ndecision. By utilizing explainable AI (xAI) methods, we attempt to open up the\nblack box. Explainable AI methods have been used in order to assess whether a\nneural network has successfully learned a given task or to analyze which\nfeatures of an input might lead to an adversarial attack. These methods aim to\nderive additional insights into a neural network, by analyzing patterns from a\ngiven input and its impact to the network output. Within the NeuroCAD Project,\nxAI methods are used to identify geometrical features which are associated with\na certain abstract feature. Within this work, a sensitivity analysis (SA), the\nlayer-wise relevance propagation (LRP), the Gradient-weighted Class Activation\nMapping (Grad-CAM) method as well as the Local Interpretable Model-Agnostic\nExplanations (LIME) have been implemented in the NeuroCAD environment, allowing\nnot only to assess CAD models but also to identify features which have been\nrelevant for the network decision. In the medium run, this might enable to\nidentify regions of interest supporting product designers to optimize their\nmodels with regards to assembly processes.",
    "descriptor": "\nComments: CIRP Design 2021, 10.1016/j.procir.2021.05.075\n",
    "authors": [
      "Raoul Sch\u00f6nhof",
      "Artem Werner",
      "Jannes Elstner",
      "Boldizsar Zopcsak",
      "Ramez Awad",
      "Marco Huber"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12107"
  },
  {
    "id": "arXiv:2201.12109",
    "title": "Protum: A New Method For Prompt Tuning Based on \"[MASK]\"",
    "abstract": "Recently, prompt tuning \\cite{lester2021power} has gradually become a new\nparadigm for NLP, which only depends on the representation of the words by\nfreezing the parameters of pre-trained language models (PLMs) to obtain\nremarkable performance on downstream tasks. It maintains the consistency of\nMasked Language Model (MLM) \\cite{devlin2018bert} task in the process of\npre-training, and avoids some issues that may happened during fine-tuning.\nNaturally, we consider that the \"[MASK]\" tokens carry more useful information\nthan other tokens because the model combines with context to predict the masked\ntokens. Among the current prompt tuning methods, there will be a serious\nproblem of random composition of the answer tokens in prediction when they\npredict multiple words so that they have to map tokens to labels with the help\nverbalizer. In response to the above issue, we propose a new \\textbf{Pro}mpt\n\\textbf{Tu}ning based on \"[\\textbf{M}ASK]\" (\\textbf{Protum}) method in this\npaper, which constructs a classification task through the information carried\nby the hidden layer of \"[MASK]\" tokens and then predicts the labels directly\nrather than the answer tokens. At the same time, we explore how different\nhidden layers under \"[MASK]\" impact on our classification model on many\ndifferent data sets. Finally, we find that our \\textbf{Protum} can achieve much\nbetter performance than fine-tuning after continuous pre-training with less\ntime consumption. Our model facilitates the practical application of large\nmodels in NLP.",
    "descriptor": "\nComments: under review in ICML\n",
    "authors": [
      "Pan He",
      "Yuxi Chen",
      "Yan Wang",
      "Yanru Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12109"
  },
  {
    "id": "arXiv:2201.12112",
    "title": "Practical lowest distortion mapping",
    "abstract": "Construction of optimal deformations is one of the long standing problems of\ncomputational mathematics. We consider the problem of computing quasi-isometric\ndeformations with minimal possible quasi-isometry constant (global estimate for\nrelative length change).We build our technique upon [Garanzha et al. 2021a], a\nrecently proposed numerical optimization scheme that provably untangles 2D and\n3D meshes with inverted elements by partially solving a finite number of\nminimization problems. In this paper we show the similarity between\ncontinuation problems for mesh untangling and for attaining prescribed\ndeformation quality threshold. Both problems can be solved by a finite number\nof partial solutions of optimization problems which are based on finite element\napproximations of parameter-dependent hyperelastic functionals. Our method is\nbased on a polyconvex functional which admits a well-posed variational problem.\nTo sum up, we reliably build 2D and 3D mesh deformations with smallest known\ndistortion estimates (quasi-isometry constants) as well as stable quasi\nconformal parameterizations for very stiff problems.",
    "descriptor": "",
    "authors": [
      "Vladimir Garanzha",
      "Igor Kaporin",
      "Liudmila Kudryavtseva",
      "Fran\u00e7ois Protais",
      "David Desobry",
      "Dmitry Sokolov"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12112"
  },
  {
    "id": "arXiv:2201.12113",
    "title": "HEAT: Hyperedge Attention Networks",
    "abstract": "Learning from structured data is a core machine learning task. Commonly, such\ndata is represented as graphs, which normally only consider (typed) binary\nrelationships between pairs of nodes. This is a substantial limitation for many\ndomains with highly-structured data. One important such domain is source code,\nwhere hypergraph-based representations can better capture the semantically rich\nand structured nature of code.\nIn this work, we present HEAT, a neural model capable of representing typed\nand qualified hypergraphs, where each hyperedge explicitly qualifies how\nparticipating nodes contribute. It can be viewed as a generalization of both\nmessage passing neural networks and Transformers. We evaluate HEAT on knowledge\nbase completion and on bug detection and repair using a novel hypergraph\nrepresentation of programs. In both settings, it outperforms strong baselines,\nindicating its power and generality.",
    "descriptor": "",
    "authors": [
      "Dobrik Georgiev",
      "Marc Brockschmidt",
      "Miltiadis Allamanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.12113"
  },
  {
    "id": "arXiv:2201.12114",
    "title": "Rethinking Attention-Model Explainability through Faithfulness Violation  Test",
    "abstract": "Attention mechanisms are dominating the explainability of deep models. They\nproduce probability distributions over the input, which are widely deemed as\nfeature-importance indicators. However, in this paper, we find one critical\nlimitation in attention explanations: weakness in identifying the polarity of\nfeature impact. This would be somehow misleading -- features with higher\nattention weights may not faithfully contribute to model predictions; instead,\nthey can impose suppression effects. With this finding, we reflect on the\nexplainability of current attention-based techniques, such as\nAttentio$\\odot$Gradient and LRP-based attention explanations. We first propose\nan actionable diagnostic methodology (henceforth faithfulness violation test)\nto measure the consistency between explanation weights and the impact polarity.\nThrough the extensive experiments, we then show that most tested explanation\nmethods are unexpectedly hindered by the faithfulness violation issue,\nespecially the raw attention. Empirical analyses on the factors affecting\nviolation issues further provide useful observations for adopting explanation\nmethods in attention models.",
    "descriptor": "",
    "authors": [
      "Yibing Liu",
      "Haoliang Li",
      "Yangyang Guo",
      "Chenqi Kong",
      "Jing Li",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12114"
  },
  {
    "id": "arXiv:2201.12122",
    "title": "Can Wikipedia Help Offline Reinforcement Learning?",
    "abstract": "Fine-tuning reinforcement learning (RL) models has been challenging because\nof a lack of large scale off-the-shelf datasets as well as high variance in\ntransferability among different environments. Recent work has looked at\ntackling offline RL from the perspective of sequence modeling with improved\nresults as result of the introduction of the Transformer architecture. However,\nwhen the model is trained from scratch, it suffers from slow convergence\nspeeds. In this paper, we look to take advantage of this formulation of\nreinforcement learning as sequence modeling and investigate the transferability\nof pre-trained sequence models on other domains (vision, language) when\nfinetuned on offline RL tasks (control, games). To this end, we also propose\ntechniques to improve transfer between these domains. Results show consistent\nperformance gains in terms of both convergence speed and reward on a variety of\nenvironments, accelerating training by 3-6x and achieving state-of-the-art\nperformance in a variety of tasks using Wikipedia-pretrained and GPT2 language\nmodels. We hope that this work not only brings light to the potentials of\nleveraging generic sequence modeling techniques and pre-trained models for RL,\nbut also inspires future work on sharing knowledge between generative modeling\ntasks of completely different domains.",
    "descriptor": "",
    "authors": [
      "Machel Reid",
      "Yutaro Yamada",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12122"
  },
  {
    "id": "arXiv:2201.12123",
    "title": "DELAUNAY: a dataset of abstract art for psychophysical and machine  learning research",
    "abstract": "Image datasets are commonly used in psychophysical experiments and in machine\nlearning research. Most publicly available datasets are comprised of images of\nrealistic and natural objects. However, while typical machine learning models\nlack any domain specific knowledge about natural objects, humans can leverage\nprior experience for such data, making comparisons between artificial and\nnatural learning challenging. Here, we introduce DELAUNAY, a dataset of\nabstract paintings and non-figurative art objects labelled by the artists'\nnames. This dataset provides a middle ground between natural images and\nartificial patterns and can thus be used in a variety of contexts, for example\nto investigate the sample efficiency of humans and artificial neural networks.\nFinally, we train an off-the-shelf convolutional neural network on DELAUNAY,\nhighlighting several of its intriguing features.",
    "descriptor": "",
    "authors": [
      "Camille Gontier",
      "Jakob Jordan",
      "Mihai A. Petrovici"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.12123"
  },
  {
    "id": "arXiv:2201.12124",
    "title": "Adaptive Optimizer for Automated Hyperparameter Optimization Problem",
    "abstract": "The choices of hyperparameters have critical effects on the performance of\nmachine learning models. In this paper, we present a general framework that is\nable to construct an adaptive optimizer, which automatically adjust the\nappropriate algorithm and parameters in the process of optimization. Examining\nthe method of adaptive optimizer, we product an example of using genetic\nalgorithm to construct an adaptive optimizer based on Bayesian Optimizer and\ncompared effectiveness with original optimizer. Especially, It has great\nadvantages in parallel optimization.",
    "descriptor": "",
    "authors": [
      "Huayuan Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12124"
  },
  {
    "id": "arXiv:2201.12126",
    "title": "Leveraging class abstraction for commonsense reinforcement learning via  residual policy gradient methods",
    "abstract": "Enabling reinforcement learning (RL) agents to leverage a knowledge base\nwhile learning from experience promises to advance RL in knowledge intensive\ndomains. However, it has proven difficult to leverage knowledge that is not\nmanually tailored to the environment. We propose to use the subclass\nrelationships present in open-source knowledge graphs to abstract away from\nspecific objects. We develop a residual policy gradient method that is able to\nintegrate knowledge across different abstraction levels in the class hierarchy.\nOur method results in improved sample efficiency and generalisation to unseen\nobjects in commonsense games, but we also investigate failure modes, such as\nexcessive noise in the extracted class knowledge or environments with little\nclass structure.",
    "descriptor": "",
    "authors": [
      "Niklas H\u00f6pner",
      "Ilaria Tiddi",
      "Herke van Hoof"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12126"
  },
  {
    "id": "arXiv:2201.12129",
    "title": "Impact of Phase-Noise and Spatial Correlation on Double-RIS-Assisted  Multiuser MISO Networks",
    "abstract": "We study the performance of a phase-noise impaired double reconfigurable\nintelligent surface (RIS)-aided multiuser (MU) multiple-input single-output\n(MISO) system under spatial correlation at both RISs and base-station (BS). The\ndownlink achievable rate is derived in closed-form under maximum ratio\ntransmission (MRT) precoding. In addition, we obtain the optimal phase-shift\ndesign at both RISs in closed-form for the considered channel and phase-noise\nmodels. Numerical results validate the analytical expressions, and highlight\nthe effects of different system parameters on the achievable rate. In\nparticular, it is demonstrated that while phase-noise at RISs and spatial\ncorrelation at BS are capacity limiting factors, the spatial correlation at\nboth RISs is essential to obtain high achievable rates.",
    "descriptor": "",
    "authors": [
      "Zaid Abdullah",
      "Anastasios Papazafeiropoulos",
      "Steven Kisseleff",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12129"
  },
  {
    "id": "arXiv:2201.12133",
    "title": "O-ViT: Orthogonal Vision Transformer",
    "abstract": "Inspired by the tremendous success of the self-attention mechanism in natural\nlanguage processing, the Vision Transformer (ViT) creatively applies it to\nimage patch sequences and achieves incredible performance. However, the scaled\ndot-product self-attention of ViT brings about scale ambiguity to the structure\nof the original feature space. To address this problem, we propose a novel\nmethod named Orthogonal Vision Transformer (O-ViT), to optimize ViT from the\ngeometric perspective. O-ViT limits parameters of self-attention blocks to be\non the norm-keeping orthogonal manifold, which can keep the geometry of the\nfeature space. Moreover, O-ViT achieves both orthogonal constraints and cheap\noptimization overhead by adopting a surjective mapping between the orthogonal\ngroup and its Lie algebra.We have conducted comparative experiments on image\nrecognition tasks to demonstrate O-ViT's validity and experiments show that\nO-ViT can boost the performance of ViT by up to 3.6%.",
    "descriptor": "",
    "authors": [
      "Yanhong Fei",
      "Yingjie Liu",
      "Xian Wei",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12133"
  },
  {
    "id": "arXiv:2201.12135",
    "title": "Multi-objective learner performance-based behavior algorithm with five  multi-objective real-world engineering problems",
    "abstract": "In this work, a new multiobjective optimization algorithm called\nmultiobjective learner performance-based behavior algorithm is proposed. The\nproposed algorithm is based on the process of transferring students from high\nschool to college. The proposed technique produces a set of non-dominated\nsolutions. To judge the ability and efficacy of the proposed multiobjective\nalgorithm, it is evaluated against a group of benchmarks and five real-world\nengineering optimization problems. Additionally, to evaluate the proposed\ntechnique quantitatively, several most widely used metrics are applied.\nMoreover, the results are confirmed statistically. The proposed work is then\ncompared with three multiobjective algorithms, which are MOWCA, NSGA-II, and\nMODA. Similar to the proposed technique, the other algorithms in the literature\nwere run against the benchmarks, and the real-world engineering problems\nutilized in the paper. The algorithms are compared with each other employing\ndescriptive, tabular, and graphical demonstrations. The results proved the\nability of the proposed work in providing a set of non-dominated solutions, and\nthat the algorithm outperformed the other participated algorithms in most of\nthe cases.",
    "descriptor": "\nComments: 22 pages. Neural Comput & Applic., 2022\n",
    "authors": [
      "Chnoor M. Rahman",
      "Tarik A. Rashid",
      "Aram Mahmood Ahmed",
      "Seyedali Mirjalili"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12135"
  },
  {
    "id": "arXiv:2201.12143",
    "title": "Locally Invariant Explanations: Towards Stable and Unidirectional  Explanations through Local Invariant Learning",
    "abstract": "Locally interpretable model agnostic explanations (LIME) method is one of the\nmost popular methods used to explain black-box models at a per example level.\nAlthough many variants have been proposed, few provide a simple way to produce\nhigh fidelity explanations that are also stable and intuitive. In this work, we\nprovide a novel perspective by proposing a model agnostic local explanation\nmethod inspired by the invariant risk minimization (IRM) principle --\noriginally proposed for (global) out-of-distribution generalization -- to\nprovide such high fidelity explanations that are also stable and unidirectional\nacross nearby examples. Our method is based on a game theoretic formulation\nwhere we theoretically show that our approach has a strong tendency to\neliminate features where the gradient of the black-box function abruptly\nchanges sign in the locality of the example we want to explain, while in other\ncases it is more careful and will choose a more conservative (feature)\nattribution, a behavior which can be highly desirable for recourse.\nEmpirically, we show on tabular, image and text data that the quality of our\nexplanations with neighborhoods formed using random perturbations are much\nbetter than LIME and in some cases even comparable to other methods that use\nrealistic neighbors sampled from the data manifold. This is desirable given\nthat learning a manifold to either create realistic neighbors or to project\nexplanations is typically expensive or may even be impossible. Moreover, our\nalgorithm is simple and efficient to train, and can ascertain stable input\nfeatures for local decisions of a black-box without access to side information\nsuch as a (partial) causal graph as has been seen in some recent works.",
    "descriptor": "",
    "authors": [
      "Amit Dhurandhar",
      "Karthikeyan Ramamurthy",
      "Kartik Ahuja",
      "Vijay Arya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12143"
  },
  {
    "id": "arXiv:2201.12150",
    "title": "Learning Curves for Decision Making in Supervised Machine Learning -- A  Survey",
    "abstract": "Learning curves are a concept from social sciences that has been adopted in\nthe context of machine learning to assess the performance of a learning\nalgorithm with respect to a certain resource, e.g. the number of training\nexamples or the number of training iterations. Learning curves have important\napplications in several contexts of machine learning, most importantly for the\ncontext of data acquisition, early stopping of model training and model\nselection. For example, by modelling the learning curves, one can assess at an\nearly stage whether the algorithm and hyperparameter configuration have the\npotential to be a suitable choice, often speeding up the algorithm selection\nprocess. A variety of approaches has been proposed to use learning curves for\ndecision making. Some models answer the binary decision question of whether a\ncertain algorithm at a certain budget will outperform a certain reference\nperformance, whereas more complex models predict the entire learning curve of\nan algorithm. We contribute a framework that categorizes learning curve\napproaches using three criteria: the decision situation that they address, the\nintrinsic learning curve question that they answer and the type of resources\nthat they use. We survey papers from literature and classify them into this\nframework.",
    "descriptor": "",
    "authors": [
      "Felix Mohr",
      "Jan N. van Rijn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12150"
  },
  {
    "id": "arXiv:2201.12153",
    "title": "Improving Pre-movement Pattern Detection with Filter Bank Selection",
    "abstract": "Pre-movement decoding plays an important role in movement detection and is\nable to detect movement onset with low-frequency electroencephalogram (EEG)\nsignals before the limb moves. In related studies, pre-movement decoding with\nstandard task-related component analysis (STRCA) has been demonstrated to be\nefficient for classification between movement state and resting state. However,\nthe accuracies of STRCA differ among subbands in the frequency domain. Due to\nindividual differences, the best subband differs among subjects and is\ndifficult to be determined. This study aims to improve the performance of the\nSTRCA method by a feature selection on multiple subbands and avoid the\nselection of best subbands. This study first compares three frequency range\nsettings ($M_1$: subbands with equally spaced bandwidths; $M_2$: subbands whose\nhigh cut-off frequencies are twice the low cut-off frequencies; $M_3$: subbands\nthat start at some specific fixed frequencies and end at the frequencies in an\narithmetic sequence.). Then, we develop a mutual information based technique to\nselect the features in these subbands. A binary support vector machine\nclassifier is used to classify the selected essential features. The results\nshow that $M_3$ is a better setting than the other two settings. With the\nfilter banks in $M_3$, the classification accuracy of the proposed FBTRCA\nachieves 0.8700$\\pm$0.1022, which means a significantly improved performance\ncompared to STRCA (0.8287$\\pm$0.1101) as well as to the cross validation and\ntesting method (0.8431$\\pm$0.1078).",
    "descriptor": "",
    "authors": [
      "Hao Jia",
      "Zhe Sun",
      "Feng Duan",
      "Yu Zhang",
      "Cesar F. Caiafa",
      "Jordi Sol\u00e9-Casals"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12153"
  },
  {
    "id": "arXiv:2201.12155",
    "title": "Reducing language context confusion for end-to-end code-switching  automatic speech recognition",
    "abstract": "Code-switching is about dealing with alternative languages in the\ncommunication process. Training end-to-end (E2E) automatic speech recognition\n(ASR) systems for code-switching is known to be a challenging problem because\nof the lack of data compounded by the increased language context confusion due\nto the presence of more than one language. In this paper, we propose a\nlanguage-related attention mechanism to reduce multilingual context confusion\nfor the E2E code-switching ASR model based on the Equivalence Constraint Theory\n(EC). The linguistic theory requires that any monolingual fragment that occurs\nin the code-switching sentence must occur in one of the monolingual sentences.\nIt establishes a bridge between monolingual data and code-switching data. By\ncalculating the respective attention of multiple languages, our method can\nefficiently transfer language knowledge from rich monolingual data. We evaluate\nour method on ASRU 2019 Mandarin-English code-switching challenge dataset.\nCompared with the baseline model, the proposed method achieves 11.37% relative\nmix error rate reduction.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.14798\n",
    "authors": [
      "Shuai Zhang",
      "Jiangyan Yi",
      "Zhengkun Tian",
      "Jianhua Tao",
      "Yu Ting Yeung",
      "Liqun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.12155"
  },
  {
    "id": "arXiv:2201.12157",
    "title": "Towards Multi-class Pre-movement Classification",
    "abstract": "In non-invasive brain-computer interface systems, pre-movement decoding plays\nan important role in the detection of movement before limbs actually move.\nMovement-related cortical potential is a kind of brain activity associated with\npre-movement decoding. In current studies, patterns decoded from movement are\nmainly applied to the binary classification between movement state and resting\nstate, such as elbow flexion and rest. The classifications between two movement\nstates and among multiple movement states are still challenging. This study\nproposes a new method, the star-arrangement spectral filtering (SASF), to solve\nthe multi-class pre-movement classification problem. We first design a\nreferenced task-related component analysis (RTRCA) framework that consists of\ntwo modules. This first module is the classification between movement state and\nresting state; the second module is the classification of multiple movement\nstates. SASF is developed by optimizing the features in RTRCA. In SASF, feature\nselection on filter banks is used on the first module of RTRCA, and feature\nselection on time windows is used on the second module of RTRCA. A linear\ndiscriminant analysis classifier is used to classify the optimized features. In\nthe binary classification between two motions, the classification accuracy of\nSASF achieves 0.9670$\\pm$0.0522, which is significantly higher than the result\nprovided by the deep convolutional neural network (0.6247$\\pm$0.0680) and the\ndiscriminative spatial pattern method (0.4400$\\pm$0.0700). In the multi-class\nclassification of 7 states, the classification accuracy of SASF is\n0.9491$\\pm$0.0372. The proposed SASF greatly improves the classification\nbetween two motions and enables the classification among multiple motions. The\nresult shows that the movement can be decoded from EEG signals before the\nactual limb movement.",
    "descriptor": "",
    "authors": [
      "Hao Jia",
      "Zhe Sun",
      "Feng Duan",
      "Yu Zhang",
      "Cesar F. Caiafa",
      "Jordi Sol\u00e9-Casals"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12157"
  },
  {
    "id": "arXiv:2201.12158",
    "title": "Stagnation Detection meets Fast Mutation",
    "abstract": "Two mechanisms have recently been proposed that can significantly speed up\nfinding distant improving solutions via mutation, namely using a random\nmutation rate drawn from a heavy-tailed distribution (\"fast mutation\", Doerr et\nal. (2017)) and increasing the mutation strength based on stagnation detection\n(Rajabi and Witt (2020)). Whereas the latter can obtain the asymptotically best\nprobability of finding a single desired solution in a given distance, the\nformer is more robust and performs much better when many improving solutions in\nsome distance exist.\nIn this work, we propose a mutation strategy that combines ideas of both\nmechanisms. We show that it can also obtain the best possible probability of\nfinding a single distant solution. However, when several improving solutions\nexist, it can outperform both the stagnation-detection approach and fast\nmutation. The new operator is more than an interleaving of the two previous\nmechanisms and it also outperforms any such interleaving.",
    "descriptor": "\nComments: 27 pages. Full version of a paper appearing at EvoCOP 2022\n",
    "authors": [
      "Benjamin Doerr",
      "Amirhossein Rajabi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12158"
  },
  {
    "id": "arXiv:2201.12163",
    "title": "Biases in In Silico Evaluation of Molecular Optimization Methods and  Bias-Reduced Evaluation Methodology",
    "abstract": "We are interested in in silico evaluation methodology for molecular\noptimization methods. Given a sample of molecules and their properties of our\ninterest, we wish not only to train an agent that can find molecules optimized\nwith respect to the target property but also to evaluate its performance. A\ncommon practice is to train a predictor of the target property on the sample\nand use it for both training and evaluating the agent. We show that this\nevaluator potentially suffers from two biases; one is due to misspecification\nof the predictor and the other to reusing the same sample for training and\nevaluation. We discuss bias reduction methods for each of the biases\ncomprehensively, and empirically investigate their effectiveness.",
    "descriptor": "",
    "authors": [
      "Hiroshi Kajino",
      "Kohei Miyaguchi",
      "Takayuki Osogami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12163"
  },
  {
    "id": "arXiv:2201.12165",
    "title": "Graph autoencoder with constant dimensional latent space",
    "abstract": "Invertible transformation of large graphs into constant dimensional vectors\n(embeddings) remains a challenge. In this paper we address it with recursive\nneural networks: The encoder and the decoder. The encoder network transforms\nembeddings of subgraphs into embeddings of larger subgraphs, and eventually\ninto the embedding of the input graph. The decoder does the opposite. The\ndimension of the embeddings is constant regardless of the size of the\n(sub)graphs. Simulation experiments presented in this paper confirm that our\nproposed graph autoencoder can handle graphs with even thousands of vertices.",
    "descriptor": "\nComments: Submitted to ICML\n",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12165"
  },
  {
    "id": "arXiv:2201.12168",
    "title": "Robotic Tissue Sampling for Safe Post-mortem Biopsy in Infectious  Corpses",
    "abstract": "In pathology and legal medicine, the histopathological and microbiological\nanalysis of tissue samples from infected deceased is a valuable information for\ndeveloping treatment strategies during a pandemic such as COVID-19. However, a\nconventional autopsy carries the risk of disease transmission and may be\nrejected by relatives. We propose minimally invasive biopsy with robot\nassistance under CT guidance to minimize the risk of disease transmission\nduring tissue sampling and to improve accuracy. A flexible robotic system for\nbiopsy sampling is presented, which is applied to human corpses placed inside\nprotective body bags. An automatic planning and decision system estimates\noptimal insertion point. Heat maps projected onto the segmented skin visualize\nthe distance and angle of insertions and estimate the minimum cost of a\npuncture while avoiding bone collisions. Further, we test multiple insertion\npaths concerning feasibility and collisions. A custom end effector is designed\nfor inserting needles and extracting tissue samples under robotic guidance. Our\nrobotic post-mortem biopsy (RPMB) system is evaluated in a study during the\nCOVID-19 pandemic on 20 corpses and 10 tissue targets, 5 of them being infected\nwith SARS-CoV-2. The mean planning time including robot path planning is\n(5.72+-1.67) s. Mean needle placement accuracy is (7.19+-4.22) mm.",
    "descriptor": "",
    "authors": [
      "Maximilian Neidhardt",
      "Stefan Gerlach",
      "Robin Mieling",
      "Max-Heinrich Laves",
      "Thorben Wei\u00df",
      "Martin Gromniak",
      "Antonia Fitzek",
      "Dustin M\u00f6bius",
      "Inga Kniep",
      "Alexandra Ron",
      "Julia Sch\u00e4dler",
      "Axel Heinemann",
      "Klaus P\u00fcschel",
      "Benjamin Ondruschka",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2201.12168"
  },
  {
    "id": "arXiv:2201.12170",
    "title": "Unsupervised Single-shot Depth Estimation using Perceptual  Reconstruction",
    "abstract": "Real-time estimation of actual object depth is a module that is essential to\nperforming various autonomous system tasks such as 3D reconstruction, scene\nunderstanding and condition assessment of machinery parts. During the last\ndecade of machine learning, extensive deployment of deep learning methods to\ncomputer vision tasks has yielded approaches that succeed in achieving\nrealistic depth synthesis out of a simple RGB modality. While most of these\nmodels are based on paired depth data or availability of video sequences and\nstereo images, methods for single-view depth synthesis in a fully unsupervised\nsetting have hardly been explored. This study presents the most recent advances\nin the field of generative neural networks, leveraging them to perform fully\nunsupervised single-shot depth synthesis. Two generators for RGB-to-depth and\ndepth-to-RGB transfer are implemented and simultaneously optimized using the\nWasserstein-1 distance and a novel perceptual reconstruction term. To ensure\nthat the proposed method is plausible, we comprehensively evaluate the models\nusing industrial surface depth data as well as the Texas 3D Face Recognition\nDatabase and the SURREAL dataset that records body depth. The success observed\nin this study suggests the great potential for unsupervised single-shot depth\nestimation in real-world applications.",
    "descriptor": "\nComments: submitted to the International Conference on Machine Learning (ICML) 2022. arXiv admin note: text overlap with arXiv:2103.16938\n",
    "authors": [
      "Christoph Angermann",
      "Matthias Schwab",
      "Markus Haltmeier",
      "Christian Laubichler",
      "Steinbj\u00f6rn J\u00f3nsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12170"
  },
  {
    "id": "arXiv:2201.12175",
    "title": "Safe Policy Improvement Approaches on Discrete Markov Decision Processes",
    "abstract": "Safe Policy Improvement (SPI) aims at provable guarantees that a learned\npolicy is at least approximately as good as a given baseline policy. Building\non SPI with Soft Baseline Bootstrapping (Soft-SPIBB) by Nadjahi et al., we\nidentify theoretical issues in their approach, provide a corrected theory, and\nderive a new algorithm that is provably safe on finite Markov Decision\nProcesses (MDP). Additionally, we provide a heuristic algorithm that exhibits\nthe best performance among many state of the art SPI algorithms on two\ndifferent benchmarks. Furthermore, we introduce a taxonomy of SPI algorithms\nand empirically show an interesting property of two classes of SPI algorithms:\nwhile the mean performance of algorithms that incorporate the uncertainty as a\npenalty on the action-value is higher, actively restricting the set of policies\nmore consistently produces good policies and is, thus, safer.",
    "descriptor": "\nComments: 12 pages, International Conference on Agents and Artificial Intelligence 2022\n",
    "authors": [
      "Philipp Scholl",
      "Felix Dietrich",
      "Clemens Otte",
      "Steffen Udluft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12175"
  },
  {
    "id": "arXiv:2201.12176",
    "title": "Generative Coarse-Graining of Molecular Conformations",
    "abstract": "Coarse-graining (CG) of molecular simulations simplifies the particle\nrepresentation by grouping selected atoms into pseudo-beads and therefore\ndrastically accelerates simulation. However, such CG procedure induces\ninformation losses, which makes accurate backmapping, i.e., restoring\nfine-grained (FG) coordinates from CG coordinates, a long-standing challenge.\nInspired by the recent progress in generative models and equivariant networks,\nwe propose a novel model that rigorously embeds the vital probabilistic nature\nand geometric consistency requirements of the backmapping transformation. Our\nmodel encodes the FG uncertainties into an invariant latent space and decodes\nthem back to FG geometries via equivariant convolutions. To standardize the\nevaluation of this domain, we further provide three comprehensive benchmarks\nbased on molecular dynamics trajectories. Extensive experiments show that our\napproach always recovers more realistic structures and outperforms existing\ndata-driven methods with a significant margin.",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Wujie Wang",
      "Minkai Xu",
      "Chen Cai",
      "Benjamin Kurt Miller",
      "Tess Smidt",
      "Yusu Wang",
      "Jian Tang",
      "Rafael G\u00f3mez-Bombarelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.12176"
  },
  {
    "id": "arXiv:2201.12177",
    "title": "Detecting Discussions of Technical Debt",
    "abstract": "Technical debt (TD) refers to suboptimal choices during software development\nthat achieve short-term goals at the expense of long-term quality. Although\ndevelopers often informally discuss TD, the concept has not yet crystalized\ninto a consistently applied label when describing issues in most repositories.\nWe apply machine learning to understand developer insights into TD when\ndiscussing tickets in an issue tracker. We generate expert labels that indicate\nwhether discussion of TD occurs in the free text associated with each ticket in\na sample of more than 1,900 tickets in the Chromium issue tracker. We then use\nthese labels to train a classifier that estimates labels for the remaining\n475,000 tickets. We conclude that discussion of TD appears in about 16% of the\ntracked Chromium issues. If we can effectively classify TD-related issues, we\ncan focus on what practices could be most useful for their timely resolution.",
    "descriptor": "\nComments: 12 pages, 5 figures, 5 tables\n",
    "authors": [
      "Ipek Ozkaya",
      "Zachary Kurtz",
      "Robert L. Nord",
      "Raghvinder S. Sangwan",
      "Satish M. Srinivasan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.12177"
  },
  {
    "id": "arXiv:2201.12178",
    "title": "Compositionality-Aware Graph2Seq Learning",
    "abstract": "Graphs are a highly expressive data structure, but it is often difficult for\nhumans to find patterns from a complex graph. Hence, generating\nhuman-interpretable sequences from graphs have gained interest, called\ngraph2seq learning. It is expected that the compositionality in a graph can be\nassociated to the compositionality in the output sequence in many graph2seq\ntasks. Therefore, applying compositionality-aware GNN architecture would\nimprove the model performance. In this study, we adopt the multi-level\nattention pooling (MLAP) architecture, that can aggregate graph representations\nfrom multiple levels of information localities. As a real-world example, we\ntake up the extreme source code summarization task, where a model estimate the\nname of a program function from its source code. We demonstrate that the model\nhaving the MLAP architecture outperform the previous state-of-the-art model\nwith more than seven times fewer parameters than it.",
    "descriptor": "\nComments: 8 pages, 1 figure, 2 tables\n",
    "authors": [
      "Takeshi D. Itoh",
      "Takatomi Kubo",
      "Kazushi Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12178"
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": "Model inversion attacks (MIAs) aim to create synthetic images that reflect\nthe class-wise characteristics from a target classifier's training data by\nexploiting the model's learned knowledge. Previous research has developed\ngenerative MIAs using generative adversarial networks (GANs) as image priors\nthat are tailored to a specific target model. This makes the attacks time- and\nresource-consuming, inflexible, and susceptible to distributional shifts\nbetween datasets. To overcome these drawbacks, we present Plug & Play Attacks\nthat loosen the dependency between the target model and image prior and enable\nthe use of a single trained GAN to attack a broad range of targets with only\nminor attack adjustments needed. Moreover, we show that powerful MIAs are\npossible even with publicly available pre-trained GANs and under strong\ndistributional shifts, whereas previous approaches fail to produce meaningful\nresults. Our extensive evaluation confirms the improved robustness and\nflexibility of Plug & Play Attacks and their ability to create high-quality\nimages revealing sensitive class characteristics.",
    "descriptor": "\nComments: 21 pages, 10 figures, 10 tables\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12179"
  },
  {
    "id": "arXiv:2201.12181",
    "title": "Cause-Effect Preservation and Classification using Neurochaos Learning",
    "abstract": "Discovering cause-effect from observational data is an important but\nchallenging problem in science and engineering. In this work, a recently\nproposed brain inspired learning algorithm namely-\\emph{Neurochaos Learning}\n(NL) is used for the classification of cause-effect from simulated data. The\ndata instances used are generated from coupled AR processes, coupled 1D chaotic\nskew tent maps, coupled 1D chaotic logistic maps and a real-world prey-predator\nsystem. The proposed method consistently outperforms a five layer Deep Neural\nNetwork architecture for coupling coefficient values ranging from $0.1$ to\n$0.7$. Further, we investigate the preservation of causality in the feature\nextracted space of NL using Granger Causality (GC) for coupled AR processes and\nand Compression-Complexity Causality (CCC) for coupled chaotic systems and\nreal-world prey-predator dataset. This ability of NL to preserve causality\nunder a chaotic transformation and successfully classify cause and effect time\nseries (including a transfer learning scenario) is highly desirable in causal\nmachine learning applications.",
    "descriptor": "\nComments: 13 pages, 16 figures, 2 tables\n",
    "authors": [
      "Harikrishnan N B",
      "Aditi Kathpalia",
      "Nithin Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12181"
  },
  {
    "id": "arXiv:2201.12183",
    "title": "Signaling in Posted Price Auctions",
    "abstract": "We study single-item single-unit Bayesian posted price auctions, where buyers\narrive sequentially and their valuations for the item being sold depend on a\nrandom, unknown state of nature. The seller has complete knowledge of the\nactual state and can send signals to the buyers so as to disclose information\nabout it. For instance, the state of nature may reflect the condition and/or\nsome particular features of the item, which are known to the seller only. The\nproblem faced by the seller is about how to partially disclose information\nabout the state so as to maximize revenue. Unlike classical signaling problems,\nin this setting, the seller must also correlate the signals being sent to the\nbuyers with some price proposals for them. This introduces additional\nchallenges compared to standard settings. We consider two cases: the one where\nthe seller can only send signals publicly visible to all buyers, and the case\nin which the seller can privately send a different signal to each buyer. As a\nfirst step, we prove that, in both settings, the problem of maximizing the\nseller's revenue does not admit an FPTAS unless P=NP, even for basic instances\nwith a single buyer. As a result, in the rest of the paper, we focus on\ndesigning PTASs. In order to do so, we first introduce a unifying framework\nencompassing both public and private signaling, whose core result is a\ndecomposition lemma that allows focusing on a finite set of possible buyers'\nposteriors. This forms the basis on which our PTASs are developed. In\nparticular, in the public signaling setting, our PTAS employs some ad hoc\ntechniques based on linear programming, while our PTAS for the private setting\nrelies on the ellipsoid method to solve an exponentially-sized LP in polynomial\ntime. In the latter case, we need a custom approximate separation oracle, which\nwe implement with a dynamic programming approach.",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Giulia Romano",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.12183"
  },
  {
    "id": "arXiv:2201.12184",
    "title": "A tomographic workflow to enable deep learning for X-ray based foreign  object detection",
    "abstract": "Detection of unwanted (`foreign') objects within products is a common\nprocedure in many branches of industry for maintaining production quality.\nX-ray imaging is a fast, non-invasive and widely applicable method for foreign\nobject detection. Deep learning has recently emerged as a powerful approach for\nrecognizing patterns in radiographs (i.e., X-ray images), enabling automated\nX-ray based foreign object detection. However, these methods require a large\nnumber of training examples and manual annotation of these examples is a\nsubjective and laborious task. In this work, we propose a Computed Tomography\n(CT) based method for producing training data for supervised learning of\nforeign object detection, with minimal labour requirements. In our approach, a\nfew representative objects are CT scanned and reconstructed in 3D. The\nradiographs that have been acquired as part of the CT-scan data serve as input\nfor the machine learning method. High-quality ground truth locations of the\nforeign objects are obtained through accurate 3D reconstructions and\nsegmentations. Using these segmented volumes, corresponding 2D segmentations\nare obtained by creating virtual projections. We outline the benefits of\nobjectively and reproducibly generating training data in this way compared to\nconventional radiograph annotation. In addition, we show how the accuracy\ndepends on the number of objects used for the CT reconstructions. The results\nshow that in this workflow generally only a relatively small number of\nrepresentative objects (i.e., fewer than 10) are needed to achieve adequate\ndetection performance in an industrial setting. Moreover, for real experimental\ndata we show that the workflow leads to higher foreign object detection\naccuracies than with standard radiograph annotation.",
    "descriptor": "\nComments: This paper is under consideration at Expert Systems with Applications. 22 pages, 15 figures\n",
    "authors": [
      "Math\u00e9 T. Zeegers",
      "Tristan van Leeuwen",
      "Dani\u00ebl M. Pelt",
      "Sophia Bethany Coban",
      "Robert van Liere",
      "Kees Joost Batenburg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.12184"
  },
  {
    "id": "arXiv:2201.12186",
    "title": "ERASE: Energy Efficient Task Mapping and Resource Management for Work  Stealing Runtimes",
    "abstract": "Parallel applications often rely on work stealing schedulers in combination\nwith fine-grained tasking to achieve high performance and scalability. However,\nreducing the total energy consumption in the context of work stealing runtimes\nis still challenging, particularly when using asymmetric architectures with\ndifferent types of CPU cores. A common approach for energy savings involves\ndynamic voltage and frequency scaling (DVFS) wherein throttling is carried out\nbased on factors like task parallelism, stealing relations and task\ncriticality. This paper makes the following observations: (i) leveraging DVFS\non a per-task basis is impractical when using fine-grained tasking and in\nenvironments with cluster/chip-level DVFS; (ii) task moldability, wherein a\nsingle task can execute on multiple threads/cores via work-sharing, can help to\nreduce energy consumption; and (iii) mismatch between tasks and assigned\nresources (i.e.~core type and number of cores) can detrimentally impact energy\nconsumption. In this paper, we propose ERASE (EneRgy Aware SchedulEr), an\nintra-application task scheduler on top of work stealing runtimes that aims to\nreduce the total energy consumption of parallel applications. It achieves\nenergy savings by guiding scheduling decisions based on per-task energy\nconsumption predictions of different resource configurations. In addition,\nERASE is capable of adapting to both given static frequency settings and\nexternally controlled DVFS. Overall, ERASE achieves up to 31% energy savings\nand improves performance by 44% on average, compared to the state-of-the-art\nDVFS-based schedulers.",
    "descriptor": "",
    "authors": [
      "Jing Chen",
      "Madhavan Manivannan",
      "Mustafa Abduljabbar",
      "Miquel Peric\u00e0s"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.12186"
  },
  {
    "id": "arXiv:2201.12191",
    "title": "Adversarial Concept Erasure in Kernel Space",
    "abstract": "The representation space of neural models for textual data emerges in an\nunsupervised manner during training. Understanding how human-interpretable\nconcepts, such as gender, are encoded in these representations would improve\nthe ability of users to \\emph{control} the content of these representations and\nanalyze the working of the models that rely on them. One prominent approach to\nthe control problem is the identification and removal of linear concept\nsubspaces -- subspaces in the representation space that correspond to a given\nconcept. While those are tractable and interpretable, neural network do not\nnecessarily represent concepts in linear subspaces.\nWe propose a kernalization of the linear concept-removal objective of\n[Ravfogel et al. 2022], and show that it is effective in guarding against the\nability of certain nonlinear adversaries to recover the concept. Interestingly,\nour findings suggest that the division between linear and nonlinear models is\noverly simplistic: when considering the concept of binary gender and its\nneutralization, we do not find a single kernel space that exclusively contains\nall the concept-related information. It is therefore challenging to protect\nagainst \\emph{all} nonlinear adversaries at once.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Shauli Ravfogel",
      "Francisco Vargas",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12191"
  },
  {
    "id": "arXiv:2201.12192",
    "title": "Stochastic Chaining and Strengthened Information-Theoretic  Generalization Bounds",
    "abstract": "We propose a new approach to apply the chaining technique in conjunction with\ninformation-theoretic measures to bound the generalization error of machine\nlearning algorithms. Different from the deterministic chaining approach based\non hierarchical partitions of a metric space, previously proposed by Asadi et\nal., we propose a stochastic chaining approach, which replaces the hierarchical\npartitions with an abstracted Markovian model borrowed from successive\nrefinement source coding. This approach has three benefits over deterministic\nchaining: 1) the metric space is not necessarily bounded, 2) facilitation of\nsubsequent analysis to yield more explicit bound, and 3) further opportunity to\noptimize the bound by removing the geometric rigidity of the partitions. The\nproposed approach includes the traditional chaining as a special case, and can\ntherefore also utilize any deterministic chaining construction. We illustrate\nthese benefits using the problem of estimating Gaussian mean and that of phase\nretrieval. For the former, we derive a bound that provides an order-wise\nimprovement over previous results, and for the latter we provide a stochastic\nchain that allows optimization over the chaining parameter.",
    "descriptor": "\nComments: 18 pages, 1 figure\n",
    "authors": [
      "Ruida Zhou",
      "Chao Tian",
      "Tie Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12192"
  },
  {
    "id": "arXiv:2201.12193",
    "title": "Moment-based multi-resolution HWENO scheme for hyperbolic conservation  laws",
    "abstract": "In this paper, a high-order moment-based multi-resolution Hermite weighted\nessentially non-oscillatory (HWENO) scheme is designed for hyperbolic\nconservation laws. The main idea of this scheme is derived from our previous\nwork [J. Comput. Phys., 446 (2021) 110653], in which the integral averages of\nthe function and its first order derivative are used to reconstruct both the\nfunction and its first order derivative values at the boundaries. However, in\nthis paper, only the function values at the Gauss-Lobatto points in the one or\ntwo dimensional case need to be reconstructed by using the information of the\nzeroth and first order moments. In addition, an extra modification procedure is\nused to modify those first order moments in the troubled-cells, which leads to\nan improvement of stability and an enhancement of resolution near\ndiscontinuities. To obtain the same order of accuracy, the size of the stencil\nrequired by this moment-based multi-resolution HWENO scheme is still the same\nas the general HWENO scheme and is more compact than the general WENO scheme.\nMoreover, the linear weights can also be any positive numbers as long as their\nsum equals one and the CFL number can still be 0.6 whether for the one or two\ndimensional case. Extensive numerical examples are given to demonstrate the\nstability and resolution of such moment-based multi-resolution HWENO scheme.",
    "descriptor": "\nComments: 36pages, 8 figures\n",
    "authors": [
      "Jiayin Li",
      "Chi-Wang Shu",
      "Jianxian Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12193"
  },
  {
    "id": "arXiv:2201.12194",
    "title": "Perfectly-Secure Synchronous MPC with Asynchronous Fallback Guarantees",
    "abstract": "Secure multi-party computation (MPC) is a fundamental problem in secure\ndistributed computing. The optimal resilience for perfectly-secure MPC in\nsynchronous and asynchronous networks is $t < n/3$ and $t < n/4$ respectively,\nwhere $n$ is the number of parties and $t$ is the number of corruptions. A\nnatural question is whether there exists a protocol tolerating $t_s < n/3$\ncorruptions in a synchronous network and $t_a < n/4$ corruptions in an\nasynchronous network. We design such a protocol, if $3t_s + t_a < n$. For our\nprotocol, we present a perfectly-secure Byzantine agreement (BA) protocol,\ntolerating $t < n/3$ corruptions in any network and a perfectly-secure\nverifiable secret-sharing (VSS) protocol, tolerating $t_s$ and $t_a$\ncorruptions in a synchronous and an asynchronous network respectively.",
    "descriptor": "\nComments: 62 pages, 18 figures\n",
    "authors": [
      "Ananya Appan",
      "Anirudh Chandramouli",
      "Ashish Choudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12194"
  },
  {
    "id": "arXiv:2201.12198",
    "title": "Limitation of characterizing implicit regularization by data-independent  functions",
    "abstract": "In recent years, understanding the implicit regularization of neural networks\n(NNs) has become a central task of deep learning theory. However, implicit\nregularization is in itself not completely defined and well understood. In this\nwork, we make an attempt to mathematically define and study the implicit\nregularization. Importantly, we explore the limitation of a common approach of\ncharacterizing the implicit regularization by data-independent functions. We\npropose two dynamical mechanisms, i.e., Two-point and One-point Overlapping\nmechanisms, based on which we provide two recipes for producing classes of\none-hidden-neuron NNs that provably cannot be fully characterized by a type of\nor all data-independent functions. Our results signify the profound\ndata-dependency of implicit regularization in general, inspiring us to study in\ndetail the data-dependency of NN implicit regularization in the future.",
    "descriptor": "",
    "authors": [
      "Leyang Zhang",
      "Zhi-Qin John Xu",
      "Tao Luo",
      "Yaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12198"
  },
  {
    "id": "arXiv:2201.12200",
    "title": "Blue Ceramics: Co-designing Morphing Ceramics for Seagrass Meadow  Restoration",
    "abstract": "Seagrass meadows are twice as efficient as forests at capturing and storing\ncarbon, but over the last two decades they have been disappearing due to human\nactivities. We take a nature-centered design approach using contextual inquiry\nand iterative participatory designs methods to consolidate knowledge from the\nmarine and material sciences to industrial design. The sketches and renders\ndocumented evolved into the design and fabrication guidelines. This pictorial\ndocuments a dialogue between designers and scientists to design an ecological\nintervention using digital fabrication to manufacture morphing ceramics for\nseagrass meadow restoration.",
    "descriptor": "\nComments: 12 pages with 32 figures, ACM C&C Pictorial\n",
    "authors": [
      "Rachel Arredondo",
      "Ofri Dar",
      "Kylon Chiang",
      "Arielle Blonder",
      "Linning Yao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12200"
  },
  {
    "id": "arXiv:2201.12204",
    "title": "From data to functa: Your data point is a function and you should treat  it like one",
    "abstract": "It is common practice in deep learning to represent a measurement of the\nworld on a discrete grid, e.g. a 2D grid of pixels. However, the underlying\nsignal represented by these measurements is often continuous, e.g. the scene\ndepicted in an image. A powerful continuous alternative is then to represent\nthese measurements using an implicit neural representation, a neural function\ntrained to output the appropriate measurement value for any input spatial\nlocation. In this paper, we take this idea to its next level: what would it\ntake to perform deep learning on these functions instead, treating them as\ndata? In this context we refer to the data as functa, and propose a framework\nfor deep learning on functa. This view presents a number of challenges around\nefficient conversion from data to functa, compact representation of functa, and\neffectively solving downstream tasks on functa. We outline a recipe to overcome\nthese challenges and apply it to a wide range of data modalities including\nimages, 3D shapes, neural radiance fields (NeRF) and data on manifolds. We\ndemonstrate that this approach has various compelling properties across data\nmodalities, in particular on the canonical tasks of generative modeling, data\nimputation, novel view synthesis and classification.",
    "descriptor": "",
    "authors": [
      "Emilien Dupont",
      "Hyunjik Kim",
      "S. M. Ali Eslami",
      "Danilo Rezende",
      "Dan Rosenbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12204"
  },
  {
    "id": "arXiv:2201.12208",
    "title": "Star Temporal Classification: Sequence Classification with Partially  Labeled Data",
    "abstract": "We develop an algorithm which can learn from partially labeled and\nunsegmented sequential data. Most sequential loss functions, such as\nConnectionist Temporal Classification (CTC), break down when many labels are\nmissing. We address this problem with Star Temporal Classification (STC) which\nuses a special star token to allow alignments which include all possible tokens\nwhenever a token could be missing. We express STC as the composition of\nweighted finite-state transducers (WFSTs) and use GTN (a framework for\nautomatic differentiation with WFSTs) to compute gradients. We perform\nextensive experiments on automatic speech recognition. These experiments show\nthat STC can recover most of the performance of supervised baseline when up to\n70% of the labels are missing. We also perform experiments in handwriting\nrecognition to show that our method easily applies to other sequence\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Vineel Pratap",
      "Awni Hannun",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12208"
  },
  {
    "id": "arXiv:2201.12211",
    "title": "Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That  Backfire",
    "abstract": "Malicious agents in collaborative learning and outsourced data collection\nthreaten the training of clean models. Backdoor attacks, where an attacker\npoisons a model during training to successfully achieve targeted\nmisclassification, are a major concern to train-time robustness. In this paper,\nwe investigate a multi-agent backdoor attack scenario, where multiple attackers\nattempt to backdoor a victim model simultaneously. A consistent backfiring\nphenomenon is observed across a wide range of games, where agents suffer from a\nlow collective attack success rate. We examine different modes of backdoor\nattack configurations, non-cooperation / cooperation, joint distribution\nshifts, and game setups to return an equilibrium attack success rate at the\nlower bound. The results motivate the re-evaluation of backdoor defense\nresearch for practical environments.",
    "descriptor": "",
    "authors": [
      "Siddhartha Datta",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.12211"
  },
  {
    "id": "arXiv:2201.12212",
    "title": "M\u00f6bius Convolutions for Spherical CNNs",
    "abstract": "M\\\"{o}bius transformations play an important role in both geometry and\nspherical image processing -- they are the group of conformal automorphisms of\n2D surfaces and the spherical equivalent of homographies. Here we present a\nnovel, M\\\"{o}bius-equivariant spherical convolution operator which we call\nM\\\"{o}bius convolution, and with it, develop the foundations for\nM\\\"{o}bius-equivariant spherical CNNs. Our approach is based on a simple\nobservation: to achieve equivariance, we only need to consider the\nlower-dimensional subgroup which transforms the positions of points as seen in\nthe frames of their neighbors. To efficiently compute M\\\"{o}bius convolutions\nat scale we derive an approximation of the action of the transformations on\nspherical filters, allowing us to compute our convolutions in the spectral\ndomain with the fast Spherical Harmonic Transform. The resulting framework is\nboth flexible and descriptive, and we demonstrate its utility by achieving\npromising results in both shape classification and image segmentation tasks.",
    "descriptor": "",
    "authors": [
      "Thomas W. Mitchel",
      "Noam Aigerman",
      "Vladimir G. Kim",
      "Michael Kazhdan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2201.12212"
  },
  {
    "id": "arXiv:2201.12216",
    "title": "Self-paced learning to improve text row detection in historical  documents with missing lables",
    "abstract": "An important preliminary step of optical character recognition systems is the\ndetection of text rows. To address this task in the context of historical data\nwith missing labels, we propose a self-paced learning algorithm capable of\nimproving the row detection performance. We conjecture that pages with more\nground-truth bounding boxes are less likely to have missing annotations. Based\non this hypothesis, we sort the training examples in descending order with\nrespect to the number of ground-truth bounding boxes, and organize them into k\nbatches. Using our self-paced learning method, we train a row detector over k\niterations, progressively adding batches with less ground-truth annotations. At\neach iteration, we combine the ground-truth bounding boxes with pseudo-bounding\nboxes (bounding boxes predicted by the model itself) using non-maximum\nsuppression, and we include the resulting annotations at the next training\niteration. We demonstrate that our self-paced learning strategy brings\nsignificant performance gains on two data sets of historical documents,\nimproving the average precision of YOLOv4 with more than 12% on one data set\nand 39% on the other.",
    "descriptor": "",
    "authors": [
      "Mihaela Gaman",
      "Lida Ghadamiyan",
      "Radu Tudor Ionescu",
      "Marius Popescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12216"
  },
  {
    "id": "arXiv:2201.12219",
    "title": "Towards a Broad Coverage Named Entity Resource: A Data-Efficient  Approach for Many Diverse Languages",
    "abstract": "Parallel corpora are ideal for extracting a multilingual named entity (MNE)\nresource, i.e., a dataset of names translated into multiple languages. Prior\nwork on extracting MNE datasets from parallel corpora required resources such\nas large monolingual corpora or word aligners that are unavailable or perform\npoorly for underresourced languages. We present CLC-BN, a new method for\ncreating an MNE resource, and apply it to the Parallel Bible Corpus, a corpus\nof more than 1000 languages. CLC-BN learns a neural transliteration model from\nparallel-corpus statistics, without requiring any other bilingual resources,\nword aligners, or seed data. Experimental results show that CLC-BN clearly\noutperforms prior work. We release an MNE resource for 1340 languages and\ndemonstrate its effectiveness in two downstream tasks: knowledge graph\naugmentation and bilingual lexicon induction.",
    "descriptor": "",
    "authors": [
      "Silvia Severini",
      "Ayyoob Imani",
      "Philipp Dufter",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12219"
  },
  {
    "id": "arXiv:2201.12220",
    "title": "Neural Optimal Transport",
    "abstract": "We present a novel neural-networks-based algorithm to compute optimal\ntransport maps and plans for strong and weak transport costs. To justify the\nusage of neural networks, we prove that they are universal approximators of\ntransport plans between probability distributions. We evaluate the performance\nof our optimal transport algorithm on toy examples and on the unpaired\nimage-to-image style translation task.",
    "descriptor": "",
    "authors": [
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12220"
  },
  {
    "id": "arXiv:2201.12224",
    "title": "Learning Stationary Nash Equilibrium Policies in $n$-Player Stochastic  Games with Independent Chains via Dual Mirror Descent",
    "abstract": "We consider a subclass of $n$-player stochastic games, in which players have\ntheir own internal state/action spaces while they are coupled through their\npayoff functions. It is assumed that players' internal chains are driven by\nindependent transition probabilities. Moreover, players can only receive\nrealizations of their payoffs but not the actual functions, nor can they\nobserve each others' states/actions. Under some assumptions on the structure of\nthe payoff functions, we develop efficient learning algorithms based on Dual\nAveraging and Dual Mirror Descent, which provably converge almost surely or in\nexpectation to the set of $\\epsilon$-Nash equilibrium policies. In particular,\nwe derive upper bounds on the number of iterates that scale polynomially in\nterms of the game parameters to achieve an $\\epsilon$-Nash equilibrium policy.\nBesides Markov potential games and linear-quadratic stochastic games, this work\nprovides another interesting subclass of $n$-player stochastic games that under\nsome assumption provably admit polynomial-time learning algorithm for finding\ntheir $\\epsilon$-Nash equilibrium policies.",
    "descriptor": "",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12224"
  },
  {
    "id": "arXiv:2201.12226",
    "title": "Differential Polarization Shift Keying Through Reconfigurable  Intelligent Surfaces",
    "abstract": "We propose a novel reconfigurable intelligent surface (RIS)-aided\ndifferential polarization shift keying modulation scheme for a line-of-sight\nenvironment. In this scheme, the RIS exploits the state of polarization (SoP)\nof the reflected waves over two successive reflection frames to encode the data\nbit. In particular, the RIS either preserves the SoP of the reflected wave\nsimilar to the previous reflection frame or switches it to another orthogonal\nSoP as a function of the information data bits. The proposed scheme allows\nnon-coherent data detection without the need for polarization mismatch\nestimation and compensation processes at the receiver.",
    "descriptor": "\nComments: 4 pages, 5 figures, submitted to IEEE Communication Letters. arXiv admin note: substantial text overlap with arXiv:2112.08172\n",
    "authors": [
      "Emad Ibrahim",
      "Rickard Nilsson",
      "Jaap van de Beek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.12226"
  },
  {
    "id": "arXiv:2201.12230",
    "title": "Agent-based modeling and simulation for malware spreading in D2D  networks",
    "abstract": "This paper presents a new multi-agent model for simulating malware\npropagation in device-to-device (D2D) 5G networks. This model allows to\nunderstand and analyze mobile malware-spreading dynamics in such highly\ndynamical networks. Additionally, we present a theoretical study to validate\nand benchmark our proposed approach for some basic scenarios that are less\ncomplicated to model mathematically and also to highlight the key parameters of\nthe model. Our simulations identify critical thresholds for \"no propagation\"\nand for \"maximum malware propagation\" and make predictions on the\nmalware-spread velocity as well as device-infection rates. To the best of our\nknowledge, this paper is the first study applying agent-based simulations for\nmalware propagation in D2D.",
    "descriptor": "\nComments: 9 pages, 4 figures, accepted at AAMAS 2022\n",
    "authors": [
      "Ziyad Benomar",
      "Chaima Ghribi",
      "Elie Cali",
      "Alexander Hinsen",
      "Benedikt Jahnel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.12230"
  },
  {
    "id": "arXiv:2201.12231",
    "title": "Overcoming Exploration: Deep Reinforcement Learning in Complex  Environments from Temporal Logic Specifications",
    "abstract": "We present a Deep Reinforcement Learning (DRL) algorithm for a task-guided\nrobot with unknown continuous-time dynamics deployed in a large-scale complex\nenvironment. Linear Temporal Logic (LTL) is applied to express a rich robotic\nspecification. To overcome the environmental challenge, we propose a novel path\nplanning-guided reward scheme that is dense over the state space, and\ncrucially, robust to infeasibility of computed geometric paths due to the\nunknown robot dynamics. To facilitate LTL satisfaction, our approach decomposes\nthe LTL mission into sub-tasks that are solved using distributed DRL, where the\nsub-tasks are trained in parallel, using Deep Policy Gradient algorithms. Our\nframework is shown to significantly improve performance (effectiveness,\nefficiency) and exploration of robots tasked with complex missions in\nlarge-scale complex environments.",
    "descriptor": "",
    "authors": [
      "Mingyu Cai",
      "Erfan Aasi",
      "Calin Belta",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12231"
  },
  {
    "id": "arXiv:2201.12238",
    "title": "Coding schemes for locally balanced constraints",
    "abstract": "Motivated by applications in DNA-based storage, we study explicit encoding\nand decoding schemes of binary strings satisfying locally balanced constraints,\nwhere the $(\\ell,\\delta)$-locally balanced constraint requires that the weight\nof any consecutive substring of length $\\ell$ is between\n$\\frac{\\ell}{2}-\\delta$ and $\\frac{\\ell}{2}+\\delta$. In this paper we present\ncoding schemes for the strongly locally balanced constraints and the locally\nbalanced constraints, respectively. Moreover, we introduce an additional result\non the linear recurrence formula of the number of binary strings which are\n$(6,1)$-locally balanced, as a further attempt to both capacity\ncharacterization and new coding strategies for locally balanced constraints.",
    "descriptor": "\nComments: Submitted to ISIT2022\n",
    "authors": [
      "Chen Wang",
      "Ziyang Lu",
      "Zhaojun Lan",
      "Gennian Ge",
      "Yiwei Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12238"
  },
  {
    "id": "arXiv:2201.12240",
    "title": "Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs)",
    "abstract": "Implicit deep learning architectures, like Neural ODEs and Deep Equilibrium\nModels (DEQs), separate the definition of a layer from the description of its\nsolution process. While implicit layers allow features such as depth to adapt\nto new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. Numerous authors have noted that\nimplicit layer techniques can be more computationally intensive than explicit\nlayer methods. In this manuscript, we address the question: is there a way to\nsimultaneously achieve the robustness of implicit layers while allowing the\nreduced computational expense of an explicit layer? To solve this we develop\nSkip DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an\nexplicit prediction followed by an implicit correction. We show that training\nthis explicit layer is free and even decreases the training time by 2.5x and\nprediction time by 3.4x. We then further increase the \"implicitness\" of the DEQ\nby redefining the method in terms of an infinite time neural ODE which\nparadoxically decreases the training cost over a standard neural ODE by not\nrequiring backpropagation through time. We demonstrate how the resulting\nContinuous Skip DEQ architecture trains more robustly than the original DEQ\nwhile achieving faster training and prediction times. Together, this manuscript\nshows how bridging the dichotomy of implicit and explicit deep learning can\ncombine the advantages of both techniques.",
    "descriptor": "",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.12240"
  },
  {
    "id": "arXiv:2201.12242",
    "title": "Large Scale Generation of Labeled Type Data for Python",
    "abstract": "Recently, dynamically typed languages, such as Python, have gained\nunprecedented popularity. Although these languages alleviate the need for\nmandatory type annotations, types still play a critical role in program\nunderstanding and preventing runtime errors. An attractive option is to infer\ntypes automatically to get static guarantees without writing types. Existing\ninference techniques rely mostly on static typing tools such as PyType for\ndirect type inference; more recently, neural type inference has been proposed.\nHowever, neural type inference is data hungry, and depends on collecting\nlabeled data based on static typing. Such tools, however, are poor at inferring\nuser defined types. Furthermore, type annotation by developers in these\nlanguages is quite sparse. In this work, we propose novel techniques for\ngenerating high quality types using 1) information retrieval techniques that\nwork on well documented libraries to extract types and 2) usage patterns by\nanalyzing a large repository of programs. Our results show that these\ntechniques are more precise and address the weaknesses of static tools, and can\nbe useful for generating a large labeled dataset for type inference by machine\nlearning methods. F1 scores are 0.52-0.58 for our techniques, compared to\nstatic typing tools which are at 0.06, and we use them to generate over 37,000\ntypes for over 700 modules.",
    "descriptor": "",
    "authors": [
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12242"
  },
  {
    "id": "arXiv:2201.12243",
    "title": "Joint Differentiable Optimization and Verification for Certified  Reinforcement Learning",
    "abstract": "In model-based reinforcement learning for safety-critical control systems, it\nis important to formally certify system properties (e.g., safety, stability)\nunder the learned controller. However, as existing methods typically apply\nformal verification \\emph{after} the controller has been learned, it is\nsometimes difficult to obtain any certificate, even after many iterations\nbetween learning and verification. To address this challenge, we propose a\nframework that jointly conducts reinforcement learning and formal verification\nby formulating and solving a novel bilevel optimization problem, which is\ndifferentiable by the gradients from the value function and certificates.\nExperiments on a variety of examples demonstrate the significant advantages of\nour framework over the model-based stochastic value gradient (SVG) method and\nthe model-free proximal policy optimization (PPO) method in finding feasible\ncontrollers with barrier functions and Lyapunov functions that ensure system\nsafety and stability.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Yixuan Wang",
      "Chao Huang",
      "Zhaoran Wang",
      "Zhuoran Yang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12243"
  },
  {
    "id": "arXiv:2201.12245",
    "title": "Wasserstein Iterative Networks for Barycenter Estimation",
    "abstract": "Wasserstein barycenters have become popular due to their ability to represent\nthe average of probability measures in a geometrically meaningful way. In this\npaper, we present an algorithm to approximate the Wasserstein-2 barycenters of\ncontinuous measures via a generative model. Previous approaches rely on\nregularization (entropic/quadratic) which introduces bias or on input convex\nneural networks which are not expressive enough for large-scale tasks. In\ncontrast, our algorithm does not introduce bias and allows using arbitrary\nneural networks. In addition, based on the celebrity faces dataset, we\nconstruct Ave, celeba! dataset which can be used for quantitative evaluation of\nbarycenter algorithms by using standard metrics of generative models such as\nFID.",
    "descriptor": "",
    "authors": [
      "Alexander Korotin",
      "Vage Egiazarian",
      "Lingxiao Li",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12245"
  },
  {
    "id": "arXiv:2201.12249",
    "title": "Agent-based simulations for coverage extensions in 5G networks and  beyond",
    "abstract": "Device-to-device (D2D) communications is one of the key emerging technologies\nfor the fifth generation (5G) networks and beyond. It enables direct\ncommunication between mobile users and thereby extends coverage for devices\nlacking direct access to the cellular infrastructure and hence enhances network\ncapacity. D2D networks are complex, highly dynamic and will be strongly\naugmented by intelligence for decision making at both the edge and core of the\nnetwork, which makes them particularly difficult to predict and analyze.\nConventionally, D2D systems are evaluated, investigated and analyzed using\nanalytical and probabilistic models (e.g., from stochastic geometry). However,\napplying classical simulation and analytical tools to such a complex system is\noften hard to track and inaccurate. In this paper, we present a modeling and\nsimulation framework from the perspective of complex-systems science and\nexhibit an agent-based model for the simulation of D2D coverage extensions. We\nalso present a theoretical study to benchmark our proposed approach for a basic\nscenario that is less complicated to model mathematically. Our simulation\nresults show that we are indeed able to predict coverage extensions for\nmulti-hop scenarios and quantify the effects of street-system characteristics\nand pedestrian mobility on the connection time of devices to the base station\n(BS). To our knowledge, this is the first study that applies agent-based\nsimulations for coverage extensions in D2D.",
    "descriptor": "\nComments: 8 pages, 5 figures, accepted at ICIN 2022\n",
    "authors": [
      "Chaima Ghribi",
      "Elie Cali",
      "Christian Hirsch",
      "Benedikt Jahnel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.12249"
  },
  {
    "id": "arXiv:2201.12250",
    "title": "Gradient Descent on Neurons and its Link to Approximate Second-Order  Optimization",
    "abstract": "Second-order optimizers are thought to hold the potential to speed up neural\nnetwork training, but due to the enormous size of the curvature matrix, they\ntypically require approximations to be computationally tractable. The most\nsuccessful family of approximations are Kronecker-Factored, block-diagonal\ncurvature estimates (KFAC). Here, we combine tools from prior work to evaluate\nexact second-order updates with careful ablations to establish a surprising\nresult: Due to its approximations, KFAC is not closely related to second-order\nupdates, and in particular, it significantly outperforms true second-order\nupdates. This challenges widely held believes and immediately raises the\nquestion why KFAC performs so well. We answer this question by showing that\nKFAC approximates a first-order algorithm, which performs gradient descent on\nneurons rather than weights. Finally, we show that this optimizer often\nimproves over KFAC in terms of computational cost and data-efficiency.",
    "descriptor": "",
    "authors": [
      "Frederik Benzing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12250"
  },
  {
    "id": "arXiv:2201.12263",
    "title": "RiskNet: Neural Risk Assessment in Networks of Unreliable Resources",
    "abstract": "We propose a graph neural network (GNN)-based method to predict the\ndistribution of penalties induced by outages in communication networks, where\nconnections are protected by resources shared between working and backup paths.\nThe GNN-based algorithm is trained only with random graphs generated with the\nBarab\\'asi-Albert model. Even though, the obtained test results show that we\ncan precisely model the penalties in a wide range of various existing\ntopologies. GNNs eliminate the need to simulate complex outage scenarios for\nthe network topologies under study. In practice, the whole design operation is\nlimited by 4ms on modern hardware. This way, we can gain as much as over 12,000\ntimes in the speed improvement.",
    "descriptor": "\nComments: This paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Krzysztof Rusek",
      "Piotr Bory\u0142o",
      "Piotr Jaglarz",
      "Fabien Geyer",
      "Albert Cabellos",
      "Piotr Cho\u0142da"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12263"
  },
  {
    "id": "arXiv:2201.12265",
    "title": "3D-FlowNet: Event-based optical flow estimation with 3D representation",
    "abstract": "Event-based cameras can overpass frame-based cameras limitations for\nimportant tasks such as high-speed motion detection during self-driving cars\nnavigation in low illumination conditions. The event cameras' high temporal\nresolution and high dynamic range, allow them to work in fast motion and\nextreme light scenarios. However, conventional computer vision methods, such as\nDeep Neural Networks, are not well adapted to work with event data as they are\nasynchronous and discrete. Moreover, the traditional 2D-encoding representation\nmethods for event data, sacrifice the time resolution. In this paper, we first\nimprove the 2D-encoding representation by expanding it into three dimensions to\nbetter preserve the temporal distribution of the events. We then propose\n3D-FlowNet, a novel network architecture that can process the 3D input\nrepresentation and output optical flow estimations according to the new\nencoding methods. A self-supervised training strategy is adopted to compensate\nthe lack of labeled datasets for the event-based camera. Finally, the proposed\nnetwork is trained and evaluated with the Multi-Vehicle Stereo Event Camera\n(MVSEC) dataset. The results show that our 3D-FlowNet outperforms\nstate-of-the-art approaches with less training epoch (30 compared to 100 of\nSpike-FlowNet).",
    "descriptor": "",
    "authors": [
      "Haixin Sun",
      "Minh-Quan Dao",
      "Vincent Fremont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12265"
  },
  {
    "id": "arXiv:2201.12266",
    "title": "Six Questions about 6G",
    "abstract": "Although 5G (Fifth Generation) mobile technology is still in the rollout\nphase, research and development of 6G (Sixth Generation) wireless have already\nbegun. This paper is an introduction to 6G wireless networks, covering the main\ndrivers for 6G, some of the expected use cases, some of the technical\nchallenges in 6G, example areas that will require research and new\ntechnologies, the expected timeline for 6G development and rollout, and a list\nof some important 6G initiatives world-wide. It was compiled as part of a\nseries of workshops about 6G as a joint communication and sensing platform held\nby Thinknet 6G and MUENCHNER KREIS in 2021.",
    "descriptor": "\nComments: 6 pages, 3 figures, document also available in German, document available in a more attractive format, www.thinknet-6g.de\n",
    "authors": [
      "Kimberley Parsons Trommler",
      "Matthias Hafner",
      "Prof. Dr. Wolfgang Kellerer",
      "Peter Merz",
      "Sigurd Schuster",
      "Josef Urban",
      "Uwe Baeder",
      "Dr. Bertram Gunzelmann",
      "Andreas Kornbichler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.12266"
  },
  {
    "id": "arXiv:2201.12269",
    "title": "HSADML: Hyper-Sphere Angular Deep Metric based Learning for Brain Tumor  Classification",
    "abstract": "Brain Tumors are abnormal mass of clustered cells penetrating regions of\nbrain. Their timely identification and classification help doctors to provide\nappropriate treatment. However, Classifi-cation of Brain Tumors is quite\nintricate because of high-intra class similarity and low-inter class\nvariability. Due to morphological similarity amongst various MRI-Slices of\ndifferent classes the challenge deepens more. This all leads to hampering\ngeneralizability of classification models. To this end, this paper proposes\nHSADML, a novel framework which enables deep metric learning (DML) using\nSphereFace Loss. SphereFace loss embeds the features into a\nhyperspheric-manifold and then imposes margin on the embeddings to enhance\ndifferentiability between the classes. With utilization of SphereFace loss\nbased deep metric learning it is ensured that samples from class clustered\ntogether while the different ones are pushed apart. Results reflects the\npromi-nence in the approach, the proposed framework achieved state-of-the-art\n98.69% validation accu-racy using k-NN (k=1) and this is significantly higher\nthan normal SoftMax Loss training which though obtains 98.47% validation\naccuracy but that too with limited inter-class separability and intra-class\ncloseness. Experimental analysis done over various classifiers and loss\nfunction set-tings suggests potential in the approach.",
    "descriptor": "",
    "authors": [
      "Aman Verma",
      "Vibhav Prakash Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12269"
  },
  {
    "id": "arXiv:2201.12271",
    "title": "An Empirical Investigation of Personalization Factors on TikTok",
    "abstract": "TikTok currently is the fastest growing social media platform with over 1\nbillion active monthly users of which the majority is from generation Z.\nArguably, its most important success driver is its recommendation system.\nDespite the importance of TikTok's algorithm to the platform's success and\ncontent distribution, little work has been done on the empirical analysis of\nthe algorithm. Our work lays the foundation to fill this research gap. Using a\nsock-puppet audit methodology with a custom algorithm developed by us, we\ntested and analysed the effect of the language and location used to access\nTikTok, follow- and like-feature, as well as how the recommended content\nchanges as a user watches certain posts longer than others. We provide evidence\nthat all the tested factors influence the content recommended to TikTok users.\nFurther, we identified that the follow-feature has the strongest influence,\nfollowed by the like-feature and video view rate. We also discuss the\nimplications of our findings in the context of the formation of filter bubbles\non TikTok and the proliferation of problematic content.",
    "descriptor": "\nComments: Accepted for publication at the Web Conference 2022\n",
    "authors": [
      "Maximilian Boeker",
      "Aleksandra Urman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.12271"
  },
  {
    "id": "arXiv:2201.12273",
    "title": "Placing Green Bridges Optimally, with Habitats Inducing Cycles",
    "abstract": "Choosing the placement of wildlife crossings (i.e., green bridges) to\nreconnect animal species' fragmented habitats is among the 17 goals towards\nsustainable development by the UN. We consider the following established model:\nGiven a graph whose vertices represent the fragmented habitat areas and whose\nweighted edges represent possible green bridge locations, as well as the\nhabitable vertex set for each species, find the cheapest set of edges such that\neach species' habitat is connected. We study this problem from a theoretical\n(algorithms and complexity) and an experimental perspective, while focusing on\nthe case where habitats induce cycles. We prove that the NP-hardness persists\nin this case even if the graph structure is restricted. If the habitats\nadditionally induce faces in plane graphs however, the problem becomes\nefficiently solvable. In our empirical evaluation we compare this algorithm as\nwell as ILP formulations for more general variants and an approximation\nalgorithm with another. Our evaluation underlines that each specialization is\nbeneficial in terms of running time, whereas the approximation provides highly\ncompetitive solutions in practice.",
    "descriptor": "",
    "authors": [
      "Maike Herkenrath",
      "Till Fluschnik",
      "Francesco Grothe",
      "Leon Kellerhals"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.12273"
  },
  {
    "id": "arXiv:2201.12275",
    "title": "Efficiency of Ad Auctions with Price Displaying",
    "abstract": "Most of the economic reports forecast that almost half of the worldwide\nmarket value unlocked by AI over the next decade (up to 6 trillion USD per\nyear) will be in marketing&sales. In particular, AI will enable the\noptimization of more and more intricate economic settings, in which multiple\ndifferent activities need to be jointly automated. This is the case of, e.g.,\nGoogle Hotel Ads and Tripadvisor, where auctions are used to display ads of\nsimilar products or services together with their prices. As in classical ad\nauctions, the ads are ranked depending on the advertisers' bids, whereas,\ndifferently from classical settings, ads are displayed together with their\nprices, so as to provide a direct comparison among them. This dramatically\naffects users' behavior, as well as the properties of ad auctions. We show\nthat, in such settings, social welfare maximization can be achieved by means of\na direct-revelation mechanism that jointly optimizes, in polynomial time, the\nads allocation and the advertisers' prices to be displayed with them. However,\nin practice it is unlikely that advertisers allow the mechanism to choose\nprices on their behalf. Indeed, in commonly-adopted mechanisms, ads allocation\nand price optimization are decoupled, so that the advertisers optimize prices\nand bids, while the mechanism does so for the allocation, once prices and bids\nare given. We investigate how this decoupling affects the efficiency of\nmechanisms. In particular, we study the Price of Anarchy (PoA) and the Price of\nStability (PoS) of indirect-revelation mechanisms with both VCG and GSP\npayments, showing that the PoS for the revenue may be unbounded even with two\nslots, and the PoA for the social welfare may be as large as the number of\nslots. Nevertheless, we show that, under some assumptions, simple modifications\nto the indirect-revelation mechanism with VCG payments achieve a PoS of 1 for\nthe revenue.",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Diodato Ferraioli",
      "Nicola Gatti",
      "Alberto Marchesi",
      "Giulia Romano"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.12275"
  },
  {
    "id": "arXiv:2201.12278",
    "title": "Quantitative Resilience of Linear Systems",
    "abstract": "Actuator malfunctions may have disastrous consequences for systems not\ndesigned to mitigate them. We focus on the loss of control authority over\nactuators, where some actuators are uncontrolled but remain fully capable. To\ncounteract the undesirable outputs of these malfunctioning actuators, we use\nreal-time measurements and redundant actuators. In this setting, a system that\ncan still reach its target is deemed resilient. To quantify the resilience of a\nsystem, we compare the shortest time for the undamaged system to reach the\ntarget with the worst-case shortest time for the malfunctioning system to reach\nthe same target, i.e., when the malfunction makes that time the longest.\nContrary to prior work on driftless linear systems, the absence of analytical\nexpression for time-optimal controls of general linear systems prevents an\nexact calculation of quantitative resilience. Instead, relying on Lyapunov\ntheory we derive analytical bounds on the nominal and malfunctioning reach\ntimes in order to bound quantitative resilience. We illustrate our work on a\ntemperature control system.",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Bouvier",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12278"
  },
  {
    "id": "arXiv:2201.12285",
    "title": "Benchmarking Conventional Vision Models on Neuromorphic Fall Detection  and Action Recognition Dataset",
    "abstract": "Neuromorphic vision-based sensors are gaining popularity in recent years with\ntheir ability to capture Spatio-temporal events with low power sensing. These\nsensors record events or spikes over traditional cameras which helps in\npreserving the privacy of the subject being recorded. These events are captured\nas per-pixel brightness changes and the output data stream is encoded with\ntime, location, and pixel intensity change information. This paper proposes and\nbenchmarks the performance of fine-tuned conventional vision models on\nneuromorphic human action recognition and fall detection datasets. The\nSpatio-temporal event streams from the Dynamic Vision Sensing cameras are\nencoded into a standard sequence image frames. These video frames are used for\nbenchmarking conventional deep learning-based architectures. In this proposed\napproach, we fine-tuned the state-of-the-art vision models for this Dynamic\nVision Sensing (DVS) application and named these models as DVS-R2+1D, DVS-CSN,\nDVS-C2D, DVS-SlowFast, DVS-X3D, and DVS-MViT. Upon comparing the performance of\nthese models, we see the current state-of-the-art MViT based architecture\nDVS-MViT outperforms all the other models with an accuracy of 0.958 and an F-1\nscore of 0.958. The second best is the DVS-C2D with an accuracy of 0.916 and an\nF-1 score of 0.916. Third and Fourth are DVS-R2+1D and DVS-SlowFast with an\naccuracy of 0.875 and 0.833 and F-1 score of 0.875 and 0.861 respectively.\nDVS-CSN and DVS-X3D were the least performing models with an accuracy of 0.708\nand 0.625 and an F1 score of 0.722 and 0.625 respectively.",
    "descriptor": "\nComments: 6 Pages, 2 Figures\n",
    "authors": [
      "Karthik Sivarama Krishnan",
      "Koushik Sivarama Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12285"
  },
  {
    "id": "arXiv:2201.12288",
    "title": "VRT: A Video Restoration Transformer",
    "abstract": "Video restoration (e.g., video super-resolution) aims to restore high-quality\nframes from low-quality frames. Different from single image restoration, video\nrestoration generally requires to utilize temporal information from multiple\nadjacent but usually misaligned video frames. Existing deep methods generally\ntackle with this by exploiting a sliding window strategy or a recurrent\narchitecture, which either is restricted by frame-by-frame restoration or lacks\nlong-range modelling ability. In this paper, we propose a Video Restoration\nTransformer (VRT) with parallel frame prediction and long-range temporal\ndependency modelling abilities. More specifically, VRT is composed of multiple\nscales, each of which consists of two kinds of modules: temporal mutual self\nattention (TMSA) and parallel warping. TMSA divides the video into small clips,\non which mutual attention is applied for joint motion estimation, feature\nalignment and feature fusion, while self attention is used for feature\nextraction. To enable cross-clip interactions, the video sequence is shifted\nfor every other layer. Besides, parallel warping is used to further fuse\ninformation from neighboring frames by parallel feature warping. Experimental\nresults on three tasks, including video super-resolution, video deblurring and\nvideo denoising, demonstrate that VRT outperforms the state-of-the-art methods\nby large margins ($\\textbf{up to 2.16dB}$) on nine benchmark datasets.",
    "descriptor": "\nComments: Sota results (+up to 2.16dB) on video SR, video deblurring and video denoising. Code: this https URL\n",
    "authors": [
      "Jingyun Liang",
      "Jiezhang Cao",
      "Yuchen Fan",
      "Kai Zhang",
      "Rakesh Ranjan",
      "Yawei Li",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.12288"
  },
  {
    "id": "arXiv:2201.12293",
    "title": "Understanding Why Generalized Reweighting Does Not Improve Over ERM",
    "abstract": "Empirical risk minimization (ERM) is known in practice to be non-robust to\ndistributional shift where the training and the test distributions are\ndifferent. A suite of approaches, such as importance weighting, and variants of\ndistributionally robust optimization (DRO), have been proposed to solve this\nproblem. But a line of recent work has empirically shown that these approaches\ndo not significantly improve over ERM in real applications with distribution\nshift. The goal of this work is to obtain a comprehensive theoretical\nunderstanding of this intriguing phenomenon. We first posit the class of\nGeneralized Reweighting (GRW) algorithms, as a broad category of approaches\nthat iteratively update model parameters based on iterative reweighting of the\ntraining samples. We show that when overparameterized models are trained under\nGRW, the resulting models are close to that obtained by ERM. We also show that\nadding small regularization which does not greatly affect the empirical\ntraining accuracy does not help. Together, our results show that a broad\ncategory of what we term GRW approaches are not able to achieve\ndistributionally robust generalization. Our work thus has the following\nsobering takeaway: to make progress towards distributionally robust\ngeneralization, we either have to develop non-GRW approaches, or perhaps devise\nnovel classification/regression loss functions that are adapted to the class of\nGRW approaches.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Runtian Zhai",
      "Chen Dan",
      "Zico Kolter",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12293"
  },
  {
    "id": "arXiv:2201.12296",
    "title": "Benchmarking Robustness of 3D Point Cloud Recognition Against Common  Corruptions",
    "abstract": "Deep neural networks on 3D point cloud data have been widely used in the real\nworld, especially in safety-critical applications. However, their robustness\nagainst corruptions is less studied. In this paper, we present ModelNet40-C,\nthe first comprehensive benchmark on 3D point cloud corruption robustness,\nconsisting of 15 common and realistic corruptions. Our evaluation shows a\nsignificant gap between the performances on ModelNet40 and ModelNet40-C for\nstate-of-the-art (SOTA) models. To reduce the gap, we propose a simple but\neffective method by combining PointCutMix-R and TENT after evaluating a wide\nrange of augmentation and test-time adaptation strategies. We identify a number\nof critical insights for future studies on corruption robustness in point cloud\nrecognition. For instance, we unveil that Transformer-based architectures with\nproper training recipes achieve the strongest robustness. We hope our in-depth\nanalysis will motivate the development of robust training strategies or\narchitecture designs in the 3D point cloud domain. Our codebase and dataset are\nincluded in https://github.com/jiachens/ModelNet40-C",
    "descriptor": "\nComments: Codebase and dataset are included in this https URL\n",
    "authors": [
      "Jiachen Sun",
      "Qingzhao Zhang",
      "Bhavya Kailkhura",
      "Zhiding Yu",
      "Chaowei Xiao",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12296"
  },
  {
    "id": "arXiv:2201.12300",
    "title": "Efficient Embedding of Semantic Similarity in Control Policies via  Entangled Bisimulation",
    "abstract": "Learning generalizeable policies from visual input in the presence of visual\ndistractions is a challenging problem in reinforcement learning. Recently,\nthere has been renewed interest in bisimulation metrics as a tool to address\nthis issue; these metrics can be used to learn representations that are, in\nprinciple, invariant to irrelevant distractions by measuring behavioural\nsimilarity between states. An accurate, unbiased, and scalable estimation of\nthese metrics has proved elusive in continuous state and action scenarios. We\npropose entangled bisimulation, a bisimulation metric that allows the\nspecification of the distance function between states, and can be estimated\nwithout bias in continuous state and action spaces. We show how entangled\nbisimulation can meaningfully improve over previous methods on the Distracting\nControl Suite (DCS), even when added on top of data augmentation techniques.",
    "descriptor": "",
    "authors": [
      "Martin Bertran",
      "Walter Talbott",
      "Nitish Srivastava",
      "Joshua Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12300"
  },
  {
    "id": "arXiv:2201.12301",
    "title": "On the algorithm of best approximation by low rank matrices in the  Chebyshev norm",
    "abstract": "The low-rank matrix approximation problem is ubiquitous in computational\nmathematics. Traditionally, this problem is solved in spectral or Frobenius\nnorms, where the accuracy of the approximation is related to the rate of\ndecrease of the singular values of the matrix. However, recent results indicate\nthat this requirement is not necessary for other norms. In this paper, we\npropose a method for solving the low-rank approximation problem in the\nChebyshev norm, which is capable of efficiently constructing accurate\napproximations for matrices, whose singular values do not decrease or decrease\nslowly.",
    "descriptor": "",
    "authors": [
      "Stanislav Morozov",
      "Nikolai Zamarashkin",
      "Eugene Tyrtyshnikov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12301"
  },
  {
    "id": "arXiv:2201.12303",
    "title": "The Price of Majority Support",
    "abstract": "We consider the problem of finding a compromise between the opinions of a\ngroup of individuals on a number of mutually independent, binary topics. In\nthis paper, we quantify the loss in representativeness that results from\nrequiring the outcome to have majority support, in other words, the \"price of\nmajority support\". Each individual is assumed to support an outcome if they\nagree with the outcome on at least as many topics as they disagree on. Our\nresults can also be seen as quantifying Anscombes paradox which states that\ntopic-wise majority outcome may not be supported by a majority. To measure the\nrepresentativeness of an outcome, we consider two metrics. First, we look for\nan outcome that agrees with a majority on as many topics as possible. We prove\nthat the maximum number such that there is guaranteed to exist an outcome that\nagrees with a majority on this number of topics and has majority support,\nequals $\\ceil{(t+1)/2}$ where $t$ is the total number of topics. Second, we\ncount the number of times a voter opinion on a topic matches the outcome on\nthat topic. The goal is to find the outcome with majority support with the\nlargest number of matches. We consider the ratio between this number and the\nnumber of matches of the overall best outcome which may not have majority\nsupport. We try to find the maximum ratio such that an outcome with majority\nsupport and this ratio of matches compared to the overall best is guaranteed to\nexist. For 3 topics, we show this ratio to be $5/6\\approx 0.83$. In general, we\nprove an upper bound that comes arbitrarily close to $2\\sqrt{6}-4\\approx 0.90$\nas $t$ tends to infinity. Furthermore, we numerically compute a better upper\nand a non-matching lower bound in the relevant range for $t$.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Robin Fritsch",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.12303"
  },
  {
    "id": "arXiv:2201.12306",
    "title": "Statistical anonymity: Quantifying reidentification risks without  reidentifying users",
    "abstract": "Data anonymization is an approach to privacy-preserving data release aimed at\npreventing participants reidentification, and it is an important alternative to\ndifferential privacy in applications that cannot tolerate noisy data. Existing\nalgorithms for enforcing $k$-anonymity in the released data assume that the\ncurator performing the anonymization has complete access to the original data.\nReasons for limiting this access range from undesirability to complete\ninfeasibility. This paper explores ideas -- objectives, metrics, protocols, and\nextensions -- for reducing the trust that must be placed in the curator, while\nstill maintaining a statistical notion of $k$-anonymity. We suggest trust\n(amount of information provided to the curator) and privacy (anonymity of the\nparticipants) as the primary objectives of such a framework. We describe a\nclass of protocols aimed at achieving these goals, proposing new metrics of\nprivacy in the process, and proving related bounds. We conclude by discussing a\nnatural extension of this work that completely removes the need for a central\ncurator.",
    "descriptor": "",
    "authors": [
      "Gecia Bravo-Hermsdorff",
      "Robert Busa-Fekete",
      "Lee M. Gunderson",
      "Andr\u00e9s Mun\u00f5z Medina",
      "Umar Syed"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.12306"
  },
  {
    "id": "arXiv:2201.12311",
    "title": "REET: Robustness Evaluation and Enhancement Toolbox for Computational  Pathology",
    "abstract": "Motivation: Digitization of pathology laboratories through digital slide\nscanners and advances in deep learning approaches for objective histological\nassessment have resulted in rapid progress in the field of computational\npathology (CPath) with wide-ranging applications in medical and pharmaceutical\nresearch as well as clinical workflows. However, the estimation of robustness\nof CPath models to variations in input images is an open problem with a\nsignificant impact on the down-stream practical applicability, deployment and\nacceptability of these approaches. Furthermore, development of domain-specific\nstrategies for enhancement of robustness of such models is of prime importance\nas well.\nImplementation and Availability: In this work, we propose the first\ndomain-specific Robustness Evaluation and Enhancement Toolbox (REET) for\ncomputational pathology applications. It provides a suite of algorithmic\nstrategies for enabling robustness assessment of predictive models with respect\nto specialized image transformations such as staining, compression, focusing,\nblurring, changes in spatial resolution, brightness variations, geometric\nchanges as well as pixel-level adversarial perturbations. Furthermore, REET\nalso enables efficient and robust training of deep learning pipelines in\ncomputational pathology. REET is implemented in Python and is available at the\nfollowing URL: https://github.com/alexjfoote/reetoolbox.\nContact: Fayyaz.minhas@warwick.ac.uk",
    "descriptor": "",
    "authors": [
      "Alex Foote",
      "Amina Asif",
      "Nasir Rajpoot",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12311"
  },
  {
    "id": "arXiv:2201.12320",
    "title": "Generative Cooperative Networks for Natural Language Generation",
    "abstract": "Generative Adversarial Networks (GANs) have known a tremendous success for\nmany continuous generation tasks, especially in the field of image generation.\nHowever, for discrete outputs such as language, optimizing GANs remains an open\nproblem with many instabilities, as no gradient can be properly back-propagated\nfrom the discriminator output to the generator parameters. An alternative is to\nlearn the generator network via reinforcement learning, using the discriminator\nsignal as a reward, but such a technique suffers from moving rewards and\nvanishing gradient problems. Finally, it often falls short compared to direct\nmaximum-likelihood approaches. In this paper, we introduce Generative\nCooperative Networks, in which the discriminator architecture is cooperatively\nused along with the generation policy to output samples of realistic texts for\nthe task at hand. We give theoretical guarantees of convergence for our\napproach, and study various efficient decoding schemes to empirically achieve\nstate-of-the-art results in two main NLG tasks.",
    "descriptor": "",
    "authors": [
      "Sylvain Lamprier",
      "Thomas Scialom",
      "Antoine Chaffin",
      "Vincent Claveau",
      "Ewa Kijak",
      "Jacopo Staiano",
      "Benjamin Piwowarski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12320"
  },
  {
    "id": "arXiv:2201.12322",
    "title": "Bioinspired Cortex-based Fast Codebook Generation",
    "abstract": "A major archetype of artificial intelligence is developing algorithms\nfacilitating temporal efficiency and accuracy while boosting the generalization\nperformance. Even with the latest developments in machine learning, a key\nlimitation has been the inefficient feature extraction from the initial data,\nwhich is essential in performance optimization. Here, we introduce a feature\nextraction method inspired by sensory cortical networks in the brain. Dubbed as\nbioinspired cortex, the algorithm provides convergence to orthogonal features\nfrom streaming signals with superior computational efficiency while processing\ndata in compressed form. We demonstrate the performance of the new algorithm\nusing artificially created complex data by comparing it with the commonly used\ntraditional clustering algorithms, such as Birch, GMM, and K-means. While the\ndata processing time is significantly reduced, seconds versus hours, encoding\ndistortions remain essentially the same in the new algorithm providing a basis\nfor better generalization. Although we show herein the superior performance of\nthe cortex model in clustering and vector quantization, it also provides potent\nimplementation opportunities for machine learning fundamental components, such\nas reasoning, anomaly detection and classification in large scope applications,\ne.g., finance, cybersecurity, and healthcare.",
    "descriptor": "\nComments: 17 pages, 6 Figures in Main Text, 5 Figures in Methods plus Appendix, and 54 references cited\n",
    "authors": [
      "Meric Yucel",
      "Serdar Bagis",
      "Ahmet Sertbas",
      "Mehmet Sarikaya",
      "Burak Berk Ustundag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12322"
  },
  {
    "id": "arXiv:2201.12323",
    "title": "Summarizing Differences between Text Distributions with Natural Language",
    "abstract": "How do two distributions of texts differ? Humans are slow at answering this,\nsince discovering patterns might require tediously reading through hundreds of\nsamples. We propose to automatically summarize the differences by \"learning a\nnatural language hypothesis\": given two distributions $D_{0}$ and $D_{1}$, we\nsearch for a description that is more often true for $D_{1}$, e.g., \"is\nmilitary-related.\" To tackle this problem, we fine-tune GPT-3 to propose\ndescriptions with the prompt: \"[samples of $D_{0}$] + [samples of $D_{1}$] +\nthe difference between them is _____\". We then re-rank the descriptions by\nchecking how often they hold on a larger set of samples with a learned\nverifier. On a benchmark of 54 real-world binary classification tasks, while\nGPT-3 Curie (13B) only generates a description similar to human annotation 7%\nof the time, the performance reaches 61% with fine-tuning and re-ranking, and\nour best system using GPT-3 Davinci (175B) reaches 76%. We apply our system to\ndescribe distribution shifts, debug dataset shortcuts, summarize unknown tasks,\nand label text clusters, and present analyses based on automatically generated\ndescriptions.",
    "descriptor": "",
    "authors": [
      "Ruiqi Zhong",
      "Charlie Snell",
      "Dan Klein",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12323"
  },
  {
    "id": "arXiv:2201.12324",
    "title": "Optimal Transport Tools (OTT): A JAX Toolbox for all things Wasserstein",
    "abstract": "Optimal transport tools (OTT-JAX) is a Python toolbox that can solve optimal\ntransport problems between point clouds and histograms. The toolbox builds on\nvarious JAX features, such as automatic and custom reverse mode\ndifferentiation, vectorization, just-in-time compilation and accelerators\nsupport. The toolbox covers elementary computations, such as the resolution of\nthe regularized OT problem, and more advanced extensions, such as barycenters,\nGromov-Wasserstein, low-rank solvers, estimation of convex maps, differentiable\ngeneralizations of quantiles and ranks, and approximate OT between Gaussian\nmixtures. The toolbox code is available at\n\\texttt{https://github.com/ott-jax/ott}",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Marco Cuturi",
      "Laetitia Meng-Papaxanthos",
      "Yingtao Tian",
      "Charlotte Bunne",
      "Geoff Davis",
      "Olivier Teboul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12324"
  },
  {
    "id": "arXiv:2201.12325",
    "title": "Improving Group Testing via Gradient Descent",
    "abstract": "We study the problem of group testing with non-identical, independent priors.\nSo far, the pooling strategies that have been proposed in the literature take\nthe following approach: a hand-crafted test design along with a decoding\nstrategy is proposed, and guarantees are provided on how many tests are\nsufficient in order to identify all infections in a population. In this paper,\nwe take a different, yet perhaps more practical, approach: we fix the decoder\nand the number of tests, and we ask, given these, what is the best test design\none could use? We explore this question for the Definite Non-Defectives (DND)\ndecoder. We formulate a (non-convex) optimization problem, where the objective\nfunction is the expected number of errors for a particular design. We find\napproximate solutions via gradient descent, which we further optimize with\ninformed initialization. We illustrate through simulations that our method can\nachieve significant performance improvement over traditional approaches.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Sundara Rajan Srinivasavaradhan",
      "Pavlos Nikolopoulos",
      "Christina Fragouli",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.12325"
  },
  {
    "id": "arXiv:2201.12327",
    "title": "Communication Cost of Two-Database Symmetric Private Information  Retrieval: A Conditional Disclosure of Multiple Secrets Perspective",
    "abstract": "We consider the total (upload plus download) communication cost of\ntwo-database symmetric private information retrieval (SPIR) through its\nrelationship to conditional disclosure of secrets (CDS). In SPIR, a user wishes\nto retrieve a message out of $K$ messages from $N$ non-colluding and replicated\ndatabases without learning anything beyond the retrieved message, while no\nindividual database learns the retrieved message index. In CDS, two parties\neach holding an individual input and sharing a common secret wish to disclose\nthis secret to an external party in an efficient manner if and only if their\ninputs satisfy a public deterministic function. As a natural extension of CDS,\nwe introduce conditional disclosure of multiple secrets (CDMS) where two\nparties share multiple i.i.d.~common secrets rather than a single common secret\nas in CDS. We show that a special configuration of CDMS is equivalent to\ntwo-database SPIR. Inspired by this equivalence, we design download cost\nefficient SPIR schemes using bipartite graph representation of CDS and CDMS,\nand determine the exact minimum total communication cost of $N=2$ database SPIR\nfor $K=3$ messages.",
    "descriptor": "",
    "authors": [
      "Zhusheng Wang",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.12327"
  },
  {
    "id": "arXiv:2201.12328",
    "title": "Toward Training at ImageNet Scale with Differential Privacy",
    "abstract": "Differential privacy (DP) is the de facto standard for training machine\nlearning (ML) models, including neural networks, while ensuring the privacy of\nindividual examples in the training set. Despite a rich literature on how to\ntrain ML models with differential privacy, it remains extremely challenging to\ntrain real-life, large neural networks with both reasonable accuracy and\nprivacy.\nWe set out to investigate how to do this, using ImageNet image classification\nas a poster example of an ML task that is very challenging to resolve\naccurately with DP right now. This paper shares initial lessons from our\neffort, in the hope that it will inspire and inform other researchers to\nexplore DP training at scale. We show approaches which help to make DP training\nfaster, as well as model types and settings of the training process that tend\nto work better for DP. Combined, the methods we discuss let us train a\nResnet-18 with differential privacy to 47.9% accuracy and privacy parameters\n$\\epsilon = 10, \\delta = 10^{-6}$, a significant improvement over \"naive\"\nDP-SGD training of Imagenet models but a far cry from the $75\\%$ accuracy that\ncan be obtained by the same network without privacy. We share our code at\nhttps://github.com/google-research/dp-imagenet calling for others to join us in\nmoving the needle further on DP at scale.",
    "descriptor": "\nComments: 23 pages, 5 figures. Code available at this https URL\n",
    "authors": [
      "Alexey Kurakin",
      "Steve Chien",
      "Shuang Song",
      "Roxana Geambasu",
      "Andreas Terzis",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12328"
  },
  {
    "id": "arXiv:2201.12329",
    "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
    "abstract": "We present in this paper a novel query formulation using dynamic anchor boxes\nfor DETR (DEtection TRansformer) and offer a deeper understanding of the role\nof queries in DETR. This new formulation directly uses box coordinates as\nqueries in Transformer decoders and dynamically updates them layer-by-layer.\nUsing box coordinates not only helps using explicit positional priors to\nimprove the query-to-feature similarity and eliminate the slow training\nconvergence issue in DETR, but also allows us to modulate the positional\nattention map using the box width and height information. Such a design makes\nit clear that queries in DETR can be implemented as performing soft ROI pooling\nlayer-by-layer in a cascade manner. As a result, it leads to the best\nperformance on MS-COCO benchmark among the DETR-like detection models under the\nsame setting, e.g., AP 45.7\\% using ResNet50-DC5 as backbone trained in 50\nepochs. We also conducted extensive experiments to confirm our analysis and\nverify the effectiveness of our methods. Code is available at\n\\url{https://github.com/SlongLiu/DAB-DETR}.",
    "descriptor": "",
    "authors": [
      "Shilong Liu",
      "Feng Li",
      "Hao Zhang",
      "Xiao Yang",
      "Xianbiao Qi",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12329"
  },
  {
    "id": "arXiv:2201.12332",
    "title": "On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces",
    "abstract": "We focus on parameterized policy search for reinforcement learning over\ncontinuous action spaces. Typically, one assumes the score function associated\nwith a policy is bounded, which {fails to hold even for Gaussian policies. } To\nproperly address this issue, one must introduce an exploration tolerance\nparameter to quantify the region in which it is bounded. Doing so incurs a\npersistent bias that appears in the attenuation rate of the expected policy\ngradient norm, which is inversely proportional to the radius of the action\nspace. To mitigate this hidden bias, heavy-tailed policy parameterizations may\nbe used, which exhibit a bounded score function, but doing so can cause\ninstability in algorithmic updates. To address these issues, in this work, we\nstudy the convergence of policy gradient algorithms under heavy-tailed\nparameterizations, which we propose to stabilize with a combination of mirror\nascent-type updates and gradient tracking. Our main theoretical contribution is\nthe establishment that this scheme converges with constant step and batch\nsizes, whereas prior works require these parameters to respectively shrink to\nnull or grow to infinity. Experimentally, this scheme under a heavy-tailed\npolicy parameterization yields improved reward accumulation across a variety of\nsettings as compared with standard benchmarks.",
    "descriptor": "",
    "authors": [
      "Amrit Singh Bedi",
      "Souradip Chakraborty",
      "Anjaly Parayil",
      "Brian Sadler",
      "Pratap Tokekar",
      "Alec Koppel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12332"
  },
  {
    "id": "arXiv:2201.12333",
    "title": "A Joint Exponential Mechanism For Differentially Private Top-$k$",
    "abstract": "We present a differentially private algorithm for releasing the sequence of\n$k$ elements with the highest counts from a data domain of $d$ elements. The\nalgorithm is a \"joint\" instance of the exponential mechanism, and its output\nspace consists of all $O(d^k)$ length-$k$ sequences. Our main contribution is a\nmethod to sample this exponential mechanism in time $O(dk\\log(k) + d\\log(d))$\nand space $O(dk)$. Experiments show that this approach outperforms existing\npure differential privacy methods and improves upon even approximate\ndifferential privacy methods for moderate $k$.",
    "descriptor": "",
    "authors": [
      "Jennifer Gillenwater",
      "Matthew Joseph",
      "Andr\u00e9s Mu\u00f1oz Medina",
      "M\u00f3nica Ribero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.12333"
  },
  {
    "id": "arXiv:2201.12338",
    "title": "Machine Learning Based Relative Orbit Transfer for Swarm Spacecraft  Motion Planning",
    "abstract": "In this paper we describe a machine learning based framework for spacecraft\nswarm trajectory planning. In particular, we focus on coordinating motions of\nmulti-spacecraft in formation flying through passive relative orbit(PRO)\ntransfers. Accounting for spacecraft dynamics while avoiding collisions between\nthe agents makes spacecraft swarm trajectory planning difficult. Centralized\napproaches can be used to solve this problem, but are computationally demanding\nand scale poorly with the number of agents in the swarm. As a result,\ncentralized algorithms are ill-suited for real time trajectory planning on\nboard small spacecraft (e.g. CubeSats) comprising the swarm. In our approach a\nneural network is used to approximate solutions of a centralized method. The\nnecessary training data is generated using a centralized convex optimization\nframework through which several instances of the n=10 spacecraft swarm\ntrajectory planning problem are solved. We are interested in answering the\nfollowing questions which will give insight on the potential utility of deep\nlearning-based approaches to the multi-spacecraft motion planning problem: 1)\nCan neural networks produce feasible trajectories that satisfy safety\nconstraints (e.g. collision avoidance) and low in fuel cost? 2) Can a neural\nnetwork trained using n spacecraft data be used to solve problems for\nspacecraft swarms of differing size?",
    "descriptor": "",
    "authors": [
      "Alex Sabol",
      "Kyongsik Yun",
      "Muhammad Adil",
      "Changrak Choi",
      "Ramtin Madani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.12338"
  },
  {
    "id": "arXiv:2106.14092",
    "title": "Network utility maximization by updating individual transmission rates",
    "abstract": "This paper discusses the problem of maximizing the total data transmission\nutility of the computer network. The total utility is defined as the sum of the\nindividual (corresponding to each node in the network) utilities that are\nconcave functions of the data transmission rate. For the case of non-strongly\nconcave utilities, we propose an approach based on the use of a fast gradient\nmethod to optimize a dually smoothed objective function. As an alternative\napproach, we introduce stochastic oracles for the problem under consideration\nand interpret them as the messages on the state of some individual node to use\nrandomized switching mirror descent to solve the problem above. We propose\ninterpretations of both described approaches allowing the effective\nimplementation of the protocols of their operation in the real-life computer\nnetworks environment, taking into account the distributed information storage\nand the restricted communication capabilities. The numerical experiments were\ncarried out to compare the proposed approaches on sythetic examples of network\narchitectures.",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Dmitry Pasechnyuk"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.14092"
  },
  {
    "id": "arXiv:2201.11748",
    "title": "Reducing COVID-19 Cases and Deaths by Applying Blockchain in Vaccination  Rollout Management",
    "abstract": "Because a fast vaccination rollout against coronavirus disease 2019\n(COVID-19) is critical to restore daily life and avoid virus mutations, it is\ntempting to have a relaxed vaccination-administration management system.\nHowever, a robust management system can support the enforcement of preventive\nmeasures, and in turn, reduce incidence and deaths. Here, we model a trustable\nand reliable management system based on blockchain for vaccine distribution by\nextending the Susceptible-Exposed-Infected-Recovery (SEIR) model. The model\nincludes prevention measures such as mask-wearing, social distance, vaccination\nrate, and vaccination efficiency. It also considers negative social behavior,\nsuch as violations of social distance and attempts of using illegitimate\nvaccination proofs. By evaluating the model, we show that the proposed system\ncan reduce up to 2.5 million cases and half a million deaths in the most\ndemanding scenarios.",
    "descriptor": "\nComments: Peer reviewed\n",
    "authors": [
      "Jorge Medina",
      "Roberto Rojas-Cessa",
      "Vatcharapan Umpaichitra"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11748"
  },
  {
    "id": "arXiv:2201.11776",
    "title": "Low-Cost Inertial Aiding for Deep-Urban Tightly-Coupled Multi-Antenna  Precise GNSS",
    "abstract": "A vehicular pose estimation technique is presented that tightly couples\nmulti-antenna carrier-phase differential GNSS (CDGNSS) with a low-cost MEMS\ninertial sensor and vehicle dynamics constraints. This work is the first to\nexplore the use of consumer-grade inertial sensors for tightly-coupled urban\nCDGNSS, and first to explore the tightly-coupled combination of multi-antenna\nCDGNSS and inertial sensing (of any quality) for urban navigation. An unscented\nlinearization permits ambiguity resolution using traditional integer least\nsquares while both implicitly enforcing known-baseline-length constraints and\nexploiting the multi-baseline problem's inter-baseline correlations. A novel\nfalse fix detection and recovery technique is developed to mitigate the effect\nof conditioning the filter state on incorrect integers. When evaluated on the\npublicly-available TEX-CUP urban positioning dataset, the proposed technique\nachieves, with consumer- and industrial-grade inertial sensors, respectively, a\n96.6% and 97.5% integer fix availability, and 12.0 cm and 10.1 cm overall (fix\nand float) 95th percentile horizontal positioning error.",
    "descriptor": "\nComments: 16 pages, 10 figures, submitted for review to NAVIGATION: Journal of the Institute of Navigation\n",
    "authors": [
      "James E. Yoder",
      "Todd E. Humphreys"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11776"
  },
  {
    "id": "arXiv:2201.11793",
    "title": "Denoising Diffusion Restoration Models",
    "abstract": "Many interesting tasks in image restoration can be cast as linear inverse\nproblems. A recent family of approaches for solving these problems uses\nstochastic algorithms that sample from the posterior distribution of natural\nimages given the measurements. However, efficient solutions often require\nproblem-specific supervised training to model the posterior, whereas\nunsupervised methods that are not problem-specific typically rely on\ninefficient iterative methods. This work addresses these issues by introducing\nDenoising Diffusion Restoration Models (DDRM), an efficient, unsupervised\nposterior sampling method. Motivated by variational inference, DDRM takes\nadvantage of a pre-trained denoising diffusion generative model for solving any\nlinear inverse problem. We demonstrate DDRM's versatility on several image\ndatasets for super-resolution, deblurring, inpainting, and colorization under\nvarious amounts of measurement noise. DDRM outperforms the current leading\nunsupervised methods on the diverse ImageNet dataset in reconstruction quality,\nperceptual quality, and runtime, being 5x faster than the nearest competitor.\nDDRM also generalizes well for natural images out of the distribution of the\nobserved ImageNet training set.",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Bahjat Kawar",
      "Michael Elad",
      "Stefano Ermon",
      "Jiaming Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11793"
  },
  {
    "id": "arXiv:2201.11795",
    "title": "Neural JPEG: End-to-End Image Compression Leveraging a Standard JPEG  Encoder-Decoder",
    "abstract": "Recent advances in deep learning have led to superhuman performance across a\nvariety of applications. Recently, these methods have been successfully\nemployed to improve the rate-distortion performance in the task of image\ncompression. However, current methods either use additional post-processing\nblocks on the decoder end to improve compression or propose an end-to-end\ncompression scheme based on heuristics. For the majority of these, the trained\ndeep neural networks (DNNs) are not compatible with standard encoders and would\nbe difficult to deply on personal computers and cellphones. In light of this,\nwe propose a system that learns to improve the encoding performance by\nenhancing its internal neural representations on both the encoder and decoder\nends, an approach we call Neural JPEG. We propose frequency domain pre-editing\nand post-editing methods to optimize the distribution of the DCT coefficients\nat both encoder and decoder ends in order to improve the standard compression\n(JPEG) method. Moreover, we design and integrate a scheme for jointly learning\nquantization tables within this hybrid neural compression framework.Experiments\ndemonstrate that our approach successfully improves the rate-distortion\nperformance over JPEG across various quality metrics, such as PSNR and MS-SSIM,\nand generates visually appealing images with better color retention quality.",
    "descriptor": "\nComments: Accepted in DCC 2022, 11 pages. arXiv admin note: text overlap with arXiv:2009.12927 by other authors\n",
    "authors": [
      "Ankur Mali",
      "Alexander Ororbia",
      "Daniel Kifer",
      "Lee Giles"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11795"
  },
  {
    "id": "arXiv:2201.11846",
    "title": "The Western Australian Optical Ground Station",
    "abstract": "Free-space communications at optical wavelengths offers the potential for\norders-of-magnitude improvement in data rates over conventional radio\nwavelengths, and this will be needed to meet the demand of future\nspace-to-ground applications. Supporting this new paradigm necessitates a\nglobal network of optical ground stations. This paper describes the\narchitecture and commissioning of the Western Australian Optical Ground\nStation, to be installed on the roof of the physics building at the University\nof Western Australia. This ground station will incorporate amplitude- and\nphase-stabilisation technology, previously demonstrated over horizontal\nfree-space links, into the ground station's optical telescope. Trialling this\nadvanced amplitude- and phase-stabilisation technology, the ground station will\novercome turbulence-induced noise to establish stable, coherent free-space\nlinks between ground-to-air and ground-to-space. These links will enable\nsignificant advances in high-speed and quantum-secured communications;\npositioning, navigation, and timing; and fundamental physics.",
    "descriptor": "\nComments: To be published in the Proceedings of the International Communications Satellite Systems Conference (ICSSC), 26th-29th September 2021, Arlington, Virginia, USA\n",
    "authors": [
      "Shane Walsh",
      "Alex Frost",
      "William Anderson",
      "Toby Digney",
      "Benjamin Dix-Matthews",
      "David Gozzard",
      "Charles Gravestock",
      "Lewis Howard",
      "Skevos Karpathakis",
      "Ayden McCann",
      "Sascha Schediwy"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11846"
  },
  {
    "id": "arXiv:2201.11864",
    "title": "Classification of White Blood Cell Leukemia with Low Number of  Interpretable and Explainable Features",
    "abstract": "White Blood Cell (WBC) Leukaemia is detected through image-based\nclassification. Convolutional Neural Networks are used to learn the features\nneeded to classify images of cells a malignant or healthy. However, this type\nof model requires learning a large number of parameters and is difficult to\ninterpret and explain. Explainable AI (XAI) attempts to alleviate this issue by\nproviding insights to how models make decisions. Therefore, we present an XAI\nmodel which uses only 24 explainable and interpretable features and is highly\ncompetitive to other approaches by outperforming them by about 4.38\\%. Further,\nour approach provides insight into which variables are the most important for\nthe classification of the cells. This insight provides evidence that when labs\ntreat the WBCs differently, the importance of various metrics changes\nsubstantially. Understanding the important features for classification is vital\nin medical imaging diagnosis and, by extension, understanding the AI models\nbuilt in scientific pursuits.",
    "descriptor": "",
    "authors": [
      "William Franz Lamberti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11864"
  },
  {
    "id": "arXiv:2201.11866",
    "title": "Calibrating Histopathology Image Classifiers using Label Smoothing",
    "abstract": "The classification of histopathology images fundamentally differs from\ntraditional image classification tasks because histopathology images naturally\nexhibit a range of diagnostic features, resulting in a diverse range of\nannotator agreement levels. However, examples with high annotator disagreement\nare often either assigned the majority label or discarded entirely when\ntraining histopathology image classifiers. This widespread practice often\nyields classifiers that do not account for example difficulty and exhibit poor\nmodel calibration. In this paper, we ask: can we improve model calibration by\nendowing histopathology image classifiers with inductive biases about example\ndifficulty?\nWe propose several label smoothing methods that utilize per-image annotator\nagreement. Though our methods are simple, we find that they substantially\nimprove model calibration, while maintaining (or even improving) accuracy. For\ncolorectal polyp classification, a common yet challenging task in\ngastrointestinal pathology, we find that our proposed agreement-aware label\nsmoothing methods reduce calibration error by almost 70%. Moreover, we find\nthat using model confidence as a proxy for annotator agreement also improves\ncalibration and accuracy, suggesting that datasets without multiple annotators\ncan still benefit from our proposed label smoothing methods via our proposed\nconfidence-aware label smoothing methods.\nGiven the importance of calibration (especially in histopathology image\nanalysis), the improvements from our proposed techniques merit further\nexploration and potential implementation in other histopathology image\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Jerry Wei",
      "Lorenzo Torresani",
      "Jason Wei",
      "Saeed Hassanpour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11866"
  },
  {
    "id": "arXiv:2201.11926",
    "title": "Simplifying deflation for non-convex optimization with applications in  Bayesian inference and topology optimization",
    "abstract": "Non-convex optimization problems have multiple local optimal solutions.\nNon-convex optimization problems are commonly found in numerous applications.\nOne of the methods recently proposed to efficiently explore multiple local\noptimal solutions without random re-initialization relies on the concept of\ndeflation. In this paper, different ways to use deflation in non-convex\noptimization and nonlinear system solving are discussed. A simple, general and\nnovel deflation constraint is proposed to enable the use of deflation together\nwith existing nonlinear programming solvers or nonlinear system solvers. The\nconnection between the proposed deflation constraint and a minimum distance\nconstraint is presented. Additionally, a number of variations of deflation\nconstraints and their limitations are discussed. Finally, a number of\napplications of the proposed methodology in the fields of approximate Bayesian\ninference and topology optimization are presented.",
    "descriptor": "",
    "authors": [
      "Mohamed Tarek",
      "Yijiang Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.11926"
  },
  {
    "id": "arXiv:2201.11941",
    "title": "Unifying Pairwise Interactions in Complex Dynamics",
    "abstract": "Scientists have developed hundreds of techniques to measure the interactions\nbetween pairs of processes in complex systems. But these computational methods\n-- from correlation coefficients to causal inference -- rely on distinct\nquantitative theories that remain largely disconnected. Here we introduce a\nlibrary of 249 statistics for pairwise interactions and assess their behavior\non 1053 multivariate time series from a wide range of real-world and\nmodel-generated systems. Our analysis highlights new commonalities between\ndifferent mathematical formulations, providing a unified picture of a rich,\ninterdisciplinary literature. We then show that leveraging many methods from\nacross science can uncover those most suitable for addressing a given problem,\nyielding high accuracy and interpretable understanding. Our framework is\nprovided in extendable open software, enabling comprehensive data-driven\nanalysis by integrating decades of methodological advances.",
    "descriptor": "",
    "authors": [
      "Oliver M. Cliff",
      "Joseph T. Lizier",
      "Naotsugu Tsuchiya",
      "Ben D. Fulcher"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11941"
  },
  {
    "id": "arXiv:2201.11954",
    "title": "Sharp Threshold for the Frechet Mean (or Median) of Inhomogeneous  Erdos-Renyi Random Graphs",
    "abstract": "We address the following foundational question: what is the population, and\nsample, Frechet mean (or median) graph of an ensemble of inhomogeneous\nErdos-Renyi random graphs? We prove that if we use the Hamming distance to\ncompute distances between graphs, then the Frechet mean (or median) graph of an\nensemble of inhomogeneous random graphs is obtained by thresholding the\nexpected adjacency matrix of the ensemble. We show that the result also holds\nfor the sample mean (or median) when the population expected adjacency matrix\nis replaced with the sample mean adjacency matrix. Consequently, the Frechet\nmean (or median) graph of inhomogeneous Erdos-Renyi random graphs exhibits a\nsharp threshold: it is either the empty graph, or the complete graph. This\nnovel theoretical result has some significant practical consequences; for\ninstance, the Frechet mean of an ensemble of sparse inhomogeneous random graphs\nis always the empty graph.",
    "descriptor": "",
    "authors": [
      "Francois G. Meyer"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11954"
  },
  {
    "id": "arXiv:2201.11957",
    "title": "Global-Reasoned Multi-Task Learning Model for Surgical Scene  Understanding",
    "abstract": "Global and local relational reasoning enable scene understanding models to\nperform human-like scene analysis and understanding. Scene understanding\nenables better semantic segmentation and object-to-object interaction\ndetection. In the medical domain, a robust surgical scene understanding model\nallows the automation of surgical skill evaluation, real-time monitoring of\nsurgeon's performance and post-surgical analysis. This paper introduces a\nglobally-reasoned multi-task surgical scene understanding model capable of\nperforming instrument segmentation and tool-tissue interaction detection. Here,\nwe incorporate global relational reasoning in the latent interaction space and\nintroduce multi-scale local (neighborhood) reasoning in the coordinate space to\nimprove segmentation. Utilizing the multi-task model setup, the performance of\nthe visual-semantic graph attention network in interaction detection is further\nenhanced through global reasoning. The global interaction space features from\nthe segmentation module are introduced into the graph network, allowing it to\ndetect interactions based on both node-to-node and global interaction\nreasoning. Our model reduces the computation cost compared to running two\nindependent single-task models by sharing common modules, which is\nindispensable for practical applications. Using a sequential optimization\ntechnique, the proposed multi-task model outperforms other state-of-the-art\nsingle-task models on the MICCAI endoscopic vision challenge 2018 dataset.\nAdditionally, we also observe the performance of the multi-task model when\ntrained using the knowledge distillation technique. The official code\nimplementation is made available in GitHub.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Lalithkumar Seenivasan",
      "Sai Mitheran",
      "Mobarakol Islam",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11957"
  },
  {
    "id": "arXiv:2201.11972",
    "title": "DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising  Diffusion GANs",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) are expressive generative\nmodels that have been used to solve a variety of speech synthesis problems.\nHowever, because of their high sampling costs, DDPMs are difficult to use in\nreal-time speech processing applications. In this paper, we introduce\nDiffGAN-TTS, a novel DDPM-based text-to-speech (TTS) model achieving\nhigh-fidelity and efficient speech synthesis. DiffGAN-TTS is based on denoising\ndiffusion generative adversarial networks (GANs), which adopt an\nadversarially-trained expressive model to approximate the denoising\ndistribution. We show with multi-speaker TTS experiments that DiffGAN-TTS can\ngenerate high-fidelity speech samples within only 4 denoising steps. We present\nan active shallow diffusion mechanism to further speed up inference. A\ntwo-stage training scheme is proposed, with a basic TTS acoustic model trained\nat stage one providing valuable prior information for a DDPM trained at stage\ntwo. Our experiments show that DiffGAN-TTS can achieve high synthesis\nperformance with only 1 denoising step.",
    "descriptor": "\nComments: Preprint. 16 pages\n",
    "authors": [
      "Songxiang Liu",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.11972"
  },
  {
    "id": "arXiv:2201.11980",
    "title": "Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics",
    "abstract": "We analyse the privacy leakage of noisy stochastic gradient descent by\nmodeling R\\'enyi divergence dynamics with Langevin diffusions. Inspired by\nrecent work on non-stochastic algorithms, we derive similar desirable\nproperties in the stochastic setting. In particular, we prove that the privacy\nloss converges exponentially fast for smooth and strongly convex objectives\nunder constant step size, which is a significant improvement over previous\nDP-SGD analyses. We also extend our analysis to arbitrary sequences of varying\nstep sizes and derive new utility bounds. Last, we propose an implementation\nand our experiments show the practical utility of our approach compared to\nclassical DP-SGD libraries.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Ryffel",
      "Francis Bach",
      "David Pointcheval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11980"
  },
  {
    "id": "arXiv:2201.11983",
    "title": "Inertial Navigation Using an Inertial Sensor Array",
    "abstract": "We present a comprehensive framework for fusing measurements from multiple\nand generally placed accelerometers and gyroscopes to perform inertial\nnavigation. Using the angular acceleration provided by the accelerometer array,\nwe show that the numerical integration of the orientation can be done with\nsecond-order accuracy, which is more accurate compared to the traditional\nfirst-order accuracy that can be achieved when only using the gyroscopes. Since\norientation errors are the most significant error source in inertial\nnavigation, improving the orientation estimation reduces the overall navigation\nerror. The practical performance benefit depends on prior knowledge of the\ninertial sensor array, and therefore we present four different state-space\nmodels using different underlying assumptions regarding the orientation\nmodeling. The models are evaluated using a Lie Group Extended Kalman filter\nthrough simulations and real-world experiments. We also show how individual\naccelerometer biases are unobservable and can be replaced by a six-dimensional\nbias term whose dimension is fixed and independent of the number of\naccelerometers.",
    "descriptor": "\nComments: 13 pages, 6 figures, for code, see this https URL\n",
    "authors": [
      "H\u00e5kan Carlsson",
      "Isaac Skog",
      "Gustaf Hendeby",
      "Joakim Jald\u00e9n"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11983"
  },
  {
    "id": "arXiv:2201.11987",
    "title": "Computer-aided Recognition and Assessment of a Porous Bioelastomer on  Ultrasound Images for Regenerative Medicine Applications",
    "abstract": "Biodegradable elastic scaffolds have attracted more and more attention in the\nfield of soft tissue repair and tissue engineering. These scaffolds made of\nporous bioelastomers support tissue ingrowth along with their own degradation.\nIt is necessary to develop a computer-aided analyzing method based on\nultrasound images to identify the degradation performance of the scaffold, not\nonly to obviate the need to do destructive testing, but also to monitor the\nscaffold's degradation and tissue ingrowth over time. It is difficult using a\nsingle traditional image processing algorithm to extract continuous and\naccurate contour of a porous bioelastomer. This paper proposes a joint\nalgorithm for the bioelastomer's contour detection and a texture feature\nextraction method for monitoring the degradation behavior of the bioelastomer.\nMean-shift clustering method is used to obtain the bioelastomer's and native\ntissue's clustering feature information. Then the OTSU image binarization\nmethod automatically selects the optimal threshold value to convert the\ngrayscale ultrasound image into a binary image. The Canny edge detector is used\nto extract the complete bioelastomer's contour. The first-order and\nsecond-order statistical features of texture are extracted. The proposed joint\nalgorithm not only achieves the ideal extraction of the bioelastomer's contours\nin ultrasound images, but also gives valuable feedback of the degradation\nbehavior of the bioelastomer at the implant site based on the changes of\ntexture characteristics and contour area. The preliminary results of this study\nsuggest that the proposed computer-aided image processing techniques have\nvalues and potentials in the non-invasive analysis of tissue scaffolds in vivo\nbased on ultrasound images and may help tissue engineers evaluate the tissue\nscaffold's degradation and cellular ingrowth progress and improve the scaffold\ndesigns.",
    "descriptor": "",
    "authors": [
      "Dun Wang",
      "Kaixuan Guo",
      "Yanying Zhu",
      "Jia Sun",
      "Aliona Dreglea",
      "Zhengwei You",
      "Jiao Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.11987"
  },
  {
    "id": "arXiv:2201.11996",
    "title": "Deep Networks for Image and Video Super-Resolution",
    "abstract": "Efficiency of gradient propagation in intermediate layers of convolutional\nneural networks is of key importance for super-resolution task. To this end, we\npropose a deep architecture for single image super-resolution (SISR), which is\nbuilt using efficient convolutional units we refer to as mixed-dense connection\nblocks (MDCB). The design of MDCB combines the strengths of both residual and\ndense connection strategies, while overcoming their limitations. To enable\nsuper-resolution for multiple factors, we propose a scale-recurrent framework\nwhich reutilizes the filters learnt for lower scale factors recursively for\nhigher factors. This leads to improved performance and promotes parametric\nefficiency for higher factors. We train two versions of our network to enhance\ncomplementary image qualities using different loss configurations. We further\nemploy our network for video super-resolution task, where our network learns to\naggregate information from multiple frames and maintain spatio-temporal\nconsistency. The proposed networks lead to qualitative and quantitative\nimprovements over state-of-the-art techniques on image and video\nsuper-resolution benchmarks.",
    "descriptor": "",
    "authors": [
      "Kuldeep Purohit",
      "Srimanta Mandal",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11996"
  },
  {
    "id": "arXiv:2201.11998",
    "title": "Image Superresolution using Scale-Recurrent Dense Network",
    "abstract": "Recent advances in the design of convolutional neural network (CNN) have\nyielded significant improvements in the performance of image super-resolution\n(SR). The boost in performance can be attributed to the presence of residual or\ndense connections within the intermediate layers of these networks. The\nefficient combination of such connections can reduce the number of parameters\ndrastically while maintaining the restoration quality. In this paper, we\npropose a scale recurrent SR architecture built upon units containing series of\ndense connections within a residual block (Residual Dense Blocks (RDBs)) that\nallow extraction of abundant local features from the image. Our scale recurrent\ndesign delivers competitive performance for higher scale factors while being\nparametrically more efficient as compared to current state-of-the-art\napproaches. To further improve the performance of our network, we employ\nmultiple residual connections in intermediate layers (referred to as\nMulti-Residual Dense Blocks), which improves gradient propagation in existing\nlayers. Recent works have discovered that conventional loss functions can guide\na network to produce results which have high PSNRs but are perceptually\ninferior. We mitigate this issue by utilizing a Generative Adversarial Network\n(GAN) based framework and deep feature (VGG) losses to train our network. We\nexperimentally demonstrate that different weighted combinations of the VGG loss\nand the adversarial loss enable our network outputs to traverse along the\nperception-distortion curve. The proposed networks perform favorably against\nexisting methods, both perceptually and objectively (PSNR-based) with fewer\nparameters.",
    "descriptor": "",
    "authors": [
      "Kuldeep Purohit",
      "Srimanta Mandal",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11998"
  },
  {
    "id": "arXiv:2201.12003",
    "title": "BCDAG: An R package for Bayesian structure and Causal learning of  Gaussian DAGs",
    "abstract": "Directed Acyclic Graphs (DAGs) provide a powerful framework to model causal\nrelationships among variables in multivariate settings; in addition, through\nthe do-calculus theory, they allow for the identification and estimation of\ncausal effects between variables also from pure observational data. In this\nsetting, the process of inferring the DAG structure from the data is referred\nto as causal structure learning or causal discovery. We introduce BCDAG, an R\npackage for Bayesian causal discovery and causal effect estimation from\nGaussian observational data, implementing the Markov chain Monte Carlo (MCMC)\nscheme proposed by Castelletti & Mascaro (2021). Our implementation scales\nefficiently with the number of observations and, whenever the DAGs are\nsufficiently sparse, with the number of variables in the dataset. The package\nalso provides functions for convergence diagnostics and for visualizing and\nsummarizing posterior inference. In this paper, we present the key features of\nthe underlying methodology along with its implementation in BCDAG. We then\nillustrate the main functions and algorithms on both real and simulated\ndatasets.",
    "descriptor": "",
    "authors": [
      "Federico Castelletti",
      "Alessandro Mascaro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2201.12003"
  },
  {
    "id": "arXiv:2201.12020",
    "title": "A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data",
    "abstract": "This paper tackles the problem of missing data imputation for noisy and\nnon-Gaussian data. A classical imputation method, the Expectation Maximization\n(EM) algorithm for Gaussian mixture models, has shown interesting properties\nwhen compared to other popular approaches such as those based on k-nearest\nneighbors or on multiple imputations by chained equations. However, Gaussian\nmixture models are known to be not robust to heterogeneous data, which can lead\nto poor estimation performance when the data is contaminated by outliers or\ncome from a non-Gaussian distributions. To overcome this issue, a new\nexpectation maximization algorithm is investigated for mixtures of elliptical\ndistributions with the nice property of handling potential missing data. The\ncomplete-data likelihood associated with mixtures of elliptical distributions\nis well adapted to the EM framework thanks to its conditional distribution,\nwhich is shown to be a Student distribution. Experimental results on synthetic\ndata demonstrate that the proposed algorithm is robust to outliers and can be\nused with non-Gaussian data. Furthermore, experiments conducted on real-world\ndatasets show that this algorithm is very competitive when compared to other\nclassical imputation methods.",
    "descriptor": "",
    "authors": [
      "Florian Mouret",
      "Alexandre Hippert-Ferrer",
      "Fr\u00e9d\u00e9ric Pascal",
      "Jean-Yves Tourneret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12020"
  },
  {
    "id": "arXiv:2201.12039",
    "title": "A DNN Based Post-Filter to Enhance the Quality of Coded Speech in MDCT  Domain",
    "abstract": "Frequency domain processing, and in particular the use of Modified Discrete\nCosine Transform (MDCT), is the most widespread approach to audio coding.\nHowever, at low bitrates, audio quality, especially for speech, degrades\ndrastically due to the lack of available bits to directly code the transform\ncoefficients. Traditionally, post-filtering has been used to mitigate artefacts\nin the coded speech by exploiting a-priori information of the source and extra\ntransmitted parameters. Recently, data-driven post-filters have shown better\nresults, but at the cost of significant additional complexity and delay. In\nthis work, we propose a mask-based post-filter operating directly in MDCT\ndomain of the codec, inducing no extra delay. The real-valued mask is applied\nto the quantized MDCT coefficients and is estimated from a relatively\nlightweight convolutional encoder-decoder network. Our solution is tested on\nthe recently standardized low-delay, low-complexity codec (LC3) at lowest\npossible bitrate of 16 kbps. Objective and subjective assessments clearly show\nthe advantage of this approach over the conventional post-filter, with an\naverage improvement of 10 MUSHRA points over the LC3 coded speech.",
    "descriptor": "",
    "authors": [
      "Kishan Gupta",
      "Srikanth Korse",
      "Bernd Edler",
      "Guillaume Fuchs"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.12039"
  },
  {
    "id": "arXiv:2201.12041",
    "title": "Leveraging deep learning for fully automated NMR protein structure  determination",
    "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is one of the major techniques\nin structural biology with over 11800 protein structures deposited in the\nProtein Data Bank. NMR can elucidate structures and dynamics of small and\nmedium size proteins in solution, living cells, and solids, but has been\nlimited by the tedious data analysis process. It typically requires weeks or\nmonths of manual work of trained expert to turn NMR measurements into a protein\nstructure. Automation of this process is an open problem, formulated in the\nfield over 30 years ago. Here, we present the first approach that addresses\nthis challenge. Our method, ARTINA, uses as input only NMR spectra and the\nprotein sequence, delivering a structure strictly without any human\nintervention. Tested on a 100-protein benchmark (1329 2D/3D/4D NMR spectra),\nARTINA demonstrated its ability to solve structures with 1.44 {\\AA} median RMSD\nto the PDB reference and 91.36% correct NMR resonance assignments. ARTINA can\nbe used by non-experts, reducing the effort for a protein structure\ndetermination by NMR essentially to the preparation of the sample and the\nspectra measurements.",
    "descriptor": "",
    "authors": [
      "Piotr Klukowski",
      "Roland Riek",
      "Peter G\u00fcntert"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12041"
  },
  {
    "id": "arXiv:2201.12056",
    "title": "Outage performance analysis of RIS-assisted UAV wireless systems under  disorientation and misalignment",
    "abstract": "In this paper, we analyze the performance of a reconfigurable intelligent\nsurface (RIS)-assisted unmanned aerial vehicle (UAV) wireless system that is\naffected by mixture-gamma small-scale fading, stochastic disorientation, and\nmisalignment, as well as transceivers hardware imperfections. First, we\nstatistically characterize the end-to-end channel for both cases, i.e., in the\nabsence as well as in the presence of disorientation and misalignment, by\nextracting closed-form formulas for the probability density function (PDF) and\nthe cumulative distribution function (CDF). Building on the aforementioned\nexpressions, we extract novel closed-form expressions for the outage\nprobability (OP) in the absence and the presence of disorientation and\nmisalignment as well as hardware imperfections. In addition, high\nsignal-to-noise ratio OP approximations are derived, leading to the extraction\nof the diversity order. Finally, an OP floor due to disorientation and\nmisalignment is presented.",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Alexandros-Apostolos A. Boulogeorgos",
      "Angeliki Alexiou",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12056"
  },
  {
    "id": "arXiv:2201.12064",
    "title": "Multiscale Graph Comparison via the Embedded Laplacian Distance",
    "abstract": "We introduce a simple and fast method for comparing graphs of different\nsizes. Existing approaches are often either limited to comparing graphs with\nthe same number of vertices or are computationally unscalable. We propose the\nEmbedded Laplacian Distance (ELD) for comparing graphs of potentially vastly\ndifferent sizes. Our approach first projects the graphs onto a common,\nlow-dimensional Laplacian embedding space that respects graphical structure.\nThis reduces the problem to that of comparing point clouds in a Euclidean\nspace. A distance can then be computed efficiently via a natural sliced\nWasserstein approach. We show that the ELD is a pseudo-metric and is invariant\nunder graph isomorphism. We provide intuitive interpretations of the ELD using\ntools from spectral graph theory. We test the efficacy of the ELD approach\nextensively on both simulated and real data. Results obtained are excellent.",
    "descriptor": "",
    "authors": [
      "Edric Tam",
      "David Dunson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12064"
  },
  {
    "id": "arXiv:2201.12090",
    "title": "Approximate Bayesian Computation with Domain Expert in the Loop",
    "abstract": "Approximate Bayesian computation (ABC) is a popular likelihood-free inference\nmethod for models with intractable likelihood functions. As ABC methods usually\nrely on comparing summary statistics of observed and simulated data, the choice\nof the statistics is crucial. This choice involves a trade-off between loss of\ninformation and dimensionality reduction, and is often determined based on\ndomain knowledge. However, handcrafting and selecting suitable statistics is a\nlaborious task involving multiple trial-and-error steps. In this work, we\nintroduce an active learning method for ABC statistics selection which reduces\nthe domain expert's work considerably. By involving the experts, we are able to\nhandle misspecified models, unlike the existing dimension reduction methods.\nMoreover, empirical results show better posterior estimates than with existing\nmethods, when the simulation budget is limited.",
    "descriptor": "",
    "authors": [
      "Ayush Bharti",
      "Louis Filstroff",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12090"
  },
  {
    "id": "arXiv:2201.12151",
    "title": "Sampling Theorems for Learning from Incomplete Measurements",
    "abstract": "In many real-world settings, only incomplete measurement data are available\nwhich can pose a problem for learning. Unsupervised learning of the signal\nmodel using a fixed incomplete measurement process is impossible in general, as\nthere is no information in the nullspace of the measurement operator. This\nlimitation can be overcome by using measurements from multiple operators. While\nthis idea has been successfully applied in various applications, a precise\ncharacterization of the conditions for learning is still lacking. In this\npaper, we fill this gap by presenting necessary and sufficient conditions for\nlearning the signal model which indicate the interplay between the number of\ndistinct measurement operators $G$, the number of measurements per operator\n$m$, the dimension of the model $k$ and the dimension of the signals $n$. In\nparticular, we show that generically unsupervised learning is possible if each\noperator obtains at least $m>k+n/G$ measurements. Our results are agnostic of\nthe learning algorithm and have implications in a wide range of practical\nalgorithms, from low-rank matrix recovery to deep neural networks.",
    "descriptor": "",
    "authors": [
      "Juli\u00e1n Tachella",
      "Dongdong Chen",
      "Mike Davies"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.12151"
  },
  {
    "id": "arXiv:2201.12152",
    "title": "Carotid artery wall segmentation in ultrasound image sequences using a  deep convolutional neural network",
    "abstract": "The objective of this study is the segmentation of the intima-media complex\nof the common carotid artery, on longitudinal ultrasound images, to measure its\nthickness. We propose a fully automatic region-based segmentation method,\ninvolving a supervised region-based deep-learning approach based on a dilated\nU-net network. It was trained and evaluated using a 5-fold cross-validation on\na multicenter database composed of 2176 images annotated by two experts. The\nresulting mean absolute difference (<120 um) compared to reference annotations\nwas less than the inter-observer variability (180 um). With a 98.7% success\nrate, i.e., only 1.3% cases requiring manual correction, the proposed method\nhas been shown to be robust and thus may be recommended for use in clinical\npractice.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Nolann Lain\u00e9",
      "Guillaume Zahnd",
      "Herv \u00e9 Liebgott",
      "Maciej Orkisz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12152"
  },
  {
    "id": "arXiv:2201.12195",
    "title": "Measure Estimation in the Barycentric Coding Model",
    "abstract": "This paper considers the problem of measure estimation under the barycentric\ncoding model (BCM), in which an unknown measure is assumed to belong to the set\nof Wasserstein-2 barycenters of a finite set of known measures. Estimating a\nmeasure under this model is equivalent to estimating the unknown barycenteric\ncoordinates. We provide novel geometrical, statistical, and computational\ninsights for measure estimation under the BCM, consisting of three main\nresults. Our first main result leverages the Riemannian geometry of\nWasserstein-2 space to provide a procedure for recovering the barycentric\ncoordinates as the solution to a quadratic optimization problem assuming access\nto the true reference measures. The essential geometric insight is that the\nparameters of this quadratic problem are determined by inner products between\nthe optimal displacement maps from the given measure to the reference measures\ndefining the BCM. Our second main result then establishes an algorithm for\nsolving for the coordinates in the BCM when all the measures are observed\nempirically via i.i.d. samples. We prove precise rates of convergence for this\nalgorithm -- determined by the smoothness of the underlying measures and their\ndimensionality -- thereby guaranteeing its statistical consistency. Finally, we\ndemonstrate the utility of the BCM and associated estimation procedures in\nthree application areas: (i) covariance estimation for Gaussian measures; (ii)\nimage processing; and (iii) natural language processing.",
    "descriptor": "",
    "authors": [
      "Matthew Werenski",
      "Ruijie Jiang",
      "Abiy Tasissa",
      "Shuchin Aeron",
      "James M. Murphy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.12195"
  },
  {
    "id": "arXiv:2201.12222",
    "title": "Solving a percolation inverse problem with a divide-and-concur algorithm",
    "abstract": "We present a percolation inverse problem for diode networks: Given\ninformation about which pairs of nodes allow current to percolate from one to\nthe other, can one construct a diode network consistent with the observed\ncurrents? We implement a divide-and-concur iterative projection method for\nsolving the problem and demonstrate the supremacy of our method over an\nexhaustive approach for nontrivial instances of the problem. We find that the\nproblem is most difficult when some but not all of the percolation data are\nhidden, and that the most difficult networks to reconstruct generally are those\nfor which the currents are most sensitive to the addition or removal of a\nsingle diode.",
    "descriptor": "",
    "authors": [
      "Sean Deyo"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2201.12222"
  },
  {
    "id": "arXiv:2201.12235",
    "title": "Simulating surface height and terminus position for marine outlet  glaciers using a level set method with data assimilation",
    "abstract": "We implement a data assimilation framework for integrating ice surface and\nterminus position observations into a numerical ice-flow model. The model uses\nthe well-known shallow shelf approximation (SSA) coupled to a level set method\nto capture ice motion and changes in the glacier geometry. The level set method\nexplicitly tracks the evolving ice-atmosphere and ice-ocean boundaries for a\nmarine outlet glacier. We use an Ensemble Transform Kalman Filter to assimilate\nobservations of ice surface elevation and lateral ice extent by updating the\nlevel set function that describes the ice interface. Numerical experiments on\nan idealized marine-terminating glacier demonstrate the effectiveness of our\ndata assimilation approach for tracking seasonal and multi-year glacier advance\nand retreat cycles. The model is also applied to simulate Helheim Glacier, a\nmajor tidewater-terminating glacier of the Greenland Ice Sheet that has\nexperienced a recent history of rapid retreat. By assimilating observations\nfrom remotely-sensed surface elevation profiles we are able to more accurately\ntrack the migrating glacier terminus and glacier surface changes. These results\nsupport the use of data assimilation methodologies for obtaining more accurate\npredictions of short-term ice sheet dynamics.",
    "descriptor": "\nComments: 30 pages, 22 figures\n",
    "authors": [
      "M. Alamgir Hossaina",
      "Sam Pimentel",
      "John M. Stockie"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.12235"
  },
  {
    "id": "arXiv:2201.12237",
    "title": "Experiences with managing data parallel computational workflows for  High-throughput Fragment Molecular Orbital (FMO) Calculations",
    "abstract": "Fragment Molecular Orbital (FMO) calculations provide a framework to speed up\nquantum mechanical calculations and so can be used to explore structure-energy\nrelationships in large and complex biomolecular systems. These calculations are\nstill onerous, especially when applied to large sets of molecules. Therefore,\ncyberinfrastructure that provides mechanisms and user interfaces that manage\njob submissions, failed job resubmissions, data retrieval, and data storage for\nthese calculations are needed. Motivated by the need to rapidly identify drugs\nthat are likely to bind to targets implicated in SARS-CoV-2, the virus that\ncauses COVID-19, we developed a static parameter sweeping framework with Apache\nAiravata middleware to apply to complexes formed between SARS-CoV-2 M-pro (the\nmain protease in SARS-CoV-2) and 2820 small-molecules in a drug-repurposing\nlibrary. Here we describe the implementation of our framework for managing the\nexecutions of the high-throughput FMO calculations. The approach is general and\nso should find utility in large-scale FMO calculations on biomolecular systems.",
    "descriptor": "",
    "authors": [
      "Dimuthu Wannipurage",
      "Indrajit Deb",
      "Eroma Abeysinghe",
      "Sudhakar Pamidighantam",
      "Suresh Marru",
      "Marlon Pierce",
      "Aaron T. Frank"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.12237"
  },
  {
    "id": "arXiv:2201.12248",
    "title": "Graphs with $G^p$-connected medians",
    "abstract": "The median of a graph $G$ with weighted vertices is the set of all vertices\n$x$ minimizing the sum of weighted distances from $x$ to the vertices of $G$.\nFor any integer $p\\ge 2$, we characterize the graphs in which, with respect to\nany non-negative weights, median sets always induce connected subgraphs in the\n$p$th power $G^p$ of $G$. This extends some characterizations of graphs with\nconnected medians (case $p=1$) provided by Bandelt and Chepoi (2002). The\ncharacteristic conditions can be tested in polynomial time for any $p$. We also\nshow that several important classes of graphs in metric graph theory, including\nbridged graphs (and thus chordal graphs), graphs with convex balls, bucolic\ngraphs, and bipartite absolute retracts, have $G^2$-connected medians.\nExtending the result of Bandelt and Chepoi that basis graphs of matroids are\ngraphs with connected medians, we characterize the isometric subgraphs of\nJohnson graphs and of halved-cubes with connected medians.",
    "descriptor": "\nComments: 31 pages, 5 figures\n",
    "authors": [
      "Laurine B\u00e9n\u00e9teau",
      "J\u00e9r\u00e9mie Chalopin",
      "Victor Chepoi",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12248"
  },
  {
    "id": "arXiv:2201.12260",
    "title": "A Review on Deep-Learning Algorithms for Fetal Ultrasound-Image Analysis",
    "abstract": "Deep-learning (DL) algorithms are becoming the standard for processing\nultrasound (US) fetal images. Despite a large number of survey papers already\npresent in this field, most of them are focusing on a broader area of\nmedical-image analysis or not covering all fetal US DL applications. This paper\nsurveys the most recent work in the field, with a total of 145 research papers\npublished after 2017. Each paper is analyzed and commented on from both the\nmethodology and application perspective. We categorized the papers in (i) fetal\nstandard-plane detection, (ii) anatomical-structure analysis, and (iii)\nbiometry parameter estimation. For each category, main limitations and open\nissues are presented. Summary tables are included to facilitate the comparison\namong the different approaches. Publicly-available datasets and performance\nmetrics commonly used to assess algorithm performance are summarized, too. This\npaper ends with a critical summary of the current state of the art on DL\nalgorithms for fetal US image analysis and a discussion on current challenges\nthat have to be tackled by researchers working in the field to translate the\nresearch methodology into the actual clinical practice.",
    "descriptor": "",
    "authors": [
      "Maria Chiara Fiorentino",
      "Francesca Pia Villani",
      "Mariachiara Di Cosmo",
      "Emanuele Frontoni",
      "Sara Moccia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12260"
  },
  {
    "id": "arXiv:2201.12281",
    "title": "The propagation of transient waves in two-dimensional square lattices",
    "abstract": "The aim of this article is to study the attenuation of transient\nlow-frequency waves in 2D lattices in both plane and antiplane problems. The\nmain idea of this article is that analytical solutions to problems of mechanics\nof discrete periodic media can be obtained by a method of asymptotic inversion\nof the Laplace and Fourier transforms in the vicinity of the quasi-front of\ninfinitely long waves; moreover, in this method it is possible to take into\naccount the contribution of short waves. Using this method, we obtain\nasymptotics of perturbations in lattices in plane and antiplane formulations\nunder a local transient load. Besides, we show that equations describing 2D\nplane motion of a square lattice can be represented in the form of two linearly\nindependent wave equations, each of which contains one unknown function only.\nBy analogy with the theory of elasticity, one equation describes the\npropagation of shear waves in the lattice, while the other equation describes\nthe propagation of longitudinal waves. As a result, it is shown that, in a\nhomogeneous infinite lattice, a load can be specified in such a manner that\neither predominantly longitudinal or predominantly shear waves are formed. The\nproblems under study are also solved by a finite difference method. The\nqualitative and quantitative correspondence of asymptotic and numerical\nsolutions is shown.",
    "descriptor": "\nComments: 36 pages, 20 figures\n",
    "authors": [
      "Nadezhda I. Aleksandrova"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12281"
  },
  {
    "id": "arXiv:2201.12283",
    "title": "Predicting The Stock Trend Using News Sentiment Analysis and Technical  Indicators in Spark",
    "abstract": "Predicting the stock market trend has always been challenging since its\nmovement is affected by many factors. Here, we approach the future trend\nprediction problem as a machine learning classification problem by creating\ntomorrow_trend feature as our label to be predicted. Different features are\ngiven to help the machine learning model predict the label of a given day;\nwhether it is an uptrend or downtrend, those features are technical indicators\ngenerated from the stock's price history. In addition, as financial news plays\na vital role in changing the investor's behavior, the overall sentiment score\non a given day is created from all news released on that day and added to the\nmodel as another feature. Three different machine learning models are tested in\nSpark (big-data computing platform), Logistic Regression, Random Forest, and\nGradient Boosting Machine. Random Forest was the best performing model with a\n63.58% test accuracy.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Taylan Kabbani",
      "Fatih Enes Usta"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12283"
  },
  {
    "id": "arXiv:2201.12286",
    "title": "A Stock Trading System for a Medium Volatile Asset using Multi Layer  Perceptron",
    "abstract": "Stock market forecasting is a lucrative field of interest with promising\nprofits but not without its difficulties and for some people could be even\ncauses of failure. Financial markets by their nature are complex, non-linear\nand chaotic, which implies that accurately predicting the prices of assets that\nare part of it becomes very complicated. In this paper we propose a stock\ntrading system having as main core the feed-forward deep neural networks (DNN)\nto predict the price for the next 30 days of open market, of the shares issued\nby Abercrombie & Fitch Co. (ANF) in the stock market of the New York Stock\nExchange (NYSE).\nThe system we have elaborated calculates the most effective technical\nindicator, applying it to the predictions computed by the DNNs, for generating\ntrades. The results showed an increase in values such as Expectancy Ratio of\n2.112% of profitable trades with Sharpe, Sortino, and Calmar Ratios of 2.194,\n3.340, and 12.403 respectively. As a verification, we adopted a backtracking\nsimulation module in our system, which maps trades to actual test data\nconsisting of the last 30 days of open market on the ANF asset. Overall, the\nresults were promising bringing a total profit factor of 3.2% in just one month\nfrom a very modest budget of $100. This was possible because the system reduced\nthe number of trades by choosing the most effective and efficient trades,\nsaving on commissions and slippage costs.",
    "descriptor": "",
    "authors": [
      "Ivan Letteri",
      "Giuseppe Della Penna",
      "Giovanni De Gasperis",
      "Abeer Dyoub"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12286"
  },
  {
    "id": "arXiv:2201.12291",
    "title": "Simulating Using Deep Learning The World Trade Forecasting of  Export-Import Exchange Rate Convergence Factor During COVID-19",
    "abstract": "By trade we usually mean the exchange of goods between states and countries.\nInternational trade acts as a barometer of the economic prosperity index and\nevery country is overly dependent on resources, so international trade is\nessential. Trade is significant to the global health crisis, saving lives and\nlivelihoods. By collecting the dataset called \"Effects of COVID19 on trade\"\nfrom the state website NZ Tatauranga Aotearoa, we have developed a sustainable\nprediction process on the effects of COVID-19 in world trade using a deep\nlearning model. In the research, we have given a 180-day trade forecast where\nthe ups and downs of daily imports and exports have been accurately predicted\nin the Covid-19 period. In order to fulfill this prediction, we have taken data\nfrom 1st January 2015 to 30th May 2021 for all countries, all commodities, and\nall transport systems and have recovered what the world trade situation will be\nin the next 180 days during the Covid-19 period. The deep learning method has\nreceived equal attention from both investors and researchers in the field of\nin-depth observation. This study predicts global trade using the Long-Short\nTerm Memory. Time series analysis can be useful to see how a given asset,\nsecurity, or economy changes over time. Time series analysis plays an important\nrole in past analysis to get different predictions of the future and it can be\nobserved that some factors affect a particular variable from period to period.\nThrough the time series it is possible to observe how various economic changes\nor trade effects change over time. By reviewing these changes, one can be aware\nof the steps to be taken in the future and a country can be more careful in\nterms of imports and exports accordingly. From our time series analysis, it can\nbe said that the LSTM model has given a very gracious thought of the future\nworld import and export situation in terms of trade.",
    "descriptor": "\nComments: Accepted in ICDLAIR 2021\n",
    "authors": [
      "Effat Ara Easmin Lucky",
      "Md. Mahadi Hasan Sany",
      "Mumenunnesa Keya",
      "Md. Moshiur Rahaman",
      "Umme Habiba Happy",
      "Sharun Akter Khushbu",
      "Md. Arid Hasan"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12291"
  },
  {
    "id": "arXiv:2201.12302",
    "title": "Adaptive Accelerated (Extra-)Gradient Methods with Variance Reduction",
    "abstract": "In this paper, we study the finite-sum convex optimization problem focusing\non the general convex case. Recently, the study of variance reduced (VR)\nmethods and their accelerated variants has made exciting progress. However, the\nstep size used in the existing VR algorithms typically depends on the\nsmoothness parameter, which is often unknown and requires tuning in practice.\nTo address this problem, we propose two novel adaptive VR algorithms: Adaptive\nVariance Reduced Accelerated Extra-Gradient (AdaVRAE) and Adaptive Variance\nReduced Accelerated Gradient (AdaVRAG). Our algorithms do not require knowledge\nof the smoothness parameter. AdaVRAE uses $\\mathcal{O}\\left(n\\log\\log\nn+\\sqrt{\\frac{n\\beta}{\\epsilon}}\\right)$ gradient evaluations and AdaVRAG uses\n$\\mathcal{O}\\left(n\\log\\log n+\\sqrt{\\frac{n\\beta\\log\\beta}{\\epsilon}}\\right)$\ngradient evaluations to attain an $\\mathcal{O}(\\epsilon)$-suboptimal solution,\nwhere $n$ is the number of functions in the finite sum and $\\beta$ is the\nsmoothness parameter. This result matches the best-known convergence rate of\nnon-adaptive VR methods and it improves upon the convergence of the state of\nthe art adaptive VR method, AdaSVRG. We demonstrate the superior performance of\nour algorithms compared with previous methods in experiments on real-world\ndatasets.",
    "descriptor": "",
    "authors": [
      "Zijian Liu",
      "Ta Duy Nguyen",
      "Alina Ene",
      "Huy L. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12302"
  },
  {
    "id": "arXiv:2201.12312",
    "title": "Isomorphism testing of $k$-spanning tournaments is Fixed Parameter  Tractable",
    "abstract": "An arc-colored tournament is said to be $k$-spanning for an integer $k\\geq 1$\nif the union of its arc-color classes of maximal valency at most $k$ is the arc\nset of a strongly connected digraph. It is proved that isomorphism testing of\n$k$-spanning tournaments is fixed-parameter tractable.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Vikraman Arvind",
      "Ilia Ponomarenko",
      "Grigory Ryabov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.12312"
  },
  {
    "id": "arXiv:1802.01268",
    "title": "ASMCNN: An Efficient Brain Extraction Using Active Shape Model and  Convolutional Neural Networks",
    "abstract": "Comments: 47 pages, 20 figures",
    "descriptor": "\nComments: 47 pages, 20 figures\n",
    "authors": [
      "Duy H. M. Nguyen",
      "Duy M. Nguyen",
      "Mai T. N. Truong",
      "Thu Nguyen",
      "Khanh T. Tran",
      "Nguyen A. Triet",
      "Pham T. Bao",
      "Binh T. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1802.01268"
  },
  {
    "id": "arXiv:1807.03712",
    "title": "Certified dimension reduction in nonlinear Bayesian inverse problems",
    "abstract": "Certified dimension reduction in nonlinear Bayesian inverse problems",
    "descriptor": "",
    "authors": [
      "Olivier Zahm",
      "Tiangang Cui",
      "Kody Law",
      "Alessio Spantini",
      "Youssef Marzouk"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1807.03712"
  },
  {
    "id": "arXiv:1906.01756",
    "title": "Group Chat Ecology in Enterprise Instant Messaging: How Employees  Collaborate Through Multi-User Chat Channels on Slack",
    "abstract": "Comments: Accepted at ACM CSCW'22",
    "descriptor": "\nComments: Accepted at ACM CSCW'22\n",
    "authors": [
      "Dakuo Wang",
      "Haoyu Wang",
      "Mo Yu",
      "Zahra Ashktorab",
      "Ming Tan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.01756"
  },
  {
    "id": "arXiv:1907.00497",
    "title": "Universal Online Convex Optimization with Minimax Optimal Second-Order  Dynamic Regret",
    "abstract": "Comments: 22 pages, 4 figure, preprint",
    "descriptor": "\nComments: 22 pages, 4 figure, preprint\n",
    "authors": [
      "Hakan Gokcesu",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.00497"
  },
  {
    "id": "arXiv:1909.07533",
    "title": "Analog Subspace Coding: A New Approach to Coding for Non-Coherent  Wireless Networks",
    "abstract": "Analog Subspace Coding: A New Approach to Coding for Non-Coherent  Wireless Networks",
    "descriptor": "",
    "authors": [
      "Mahdi Soleymani",
      "Hessam Mahdavifar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.07533"
  },
  {
    "id": "arXiv:2003.14025",
    "title": "Central Limit Theorems for Martin-L\u00f6f Random Numbers",
    "abstract": "Comments: 17 pages, no figures",
    "descriptor": "\nComments: 17 pages, no figures\n",
    "authors": [
      "Anton Vuerinckx",
      "Yves Moreau"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2003.14025"
  },
  {
    "id": "arXiv:2006.03847",
    "title": "Learning Inconsistent Preferences with Gaussian Processes",
    "abstract": "Learning Inconsistent Preferences with Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Siu Lun Chau",
      "Javier Gonz\u00e1lez",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.03847"
  },
  {
    "id": "arXiv:2006.08085",
    "title": "Optimal Complexity in Decentralized Training",
    "abstract": "Optimal Complexity in Decentralized Training",
    "descriptor": "",
    "authors": [
      "Yucheng Lu",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08085"
  },
  {
    "id": "arXiv:2007.07781",
    "title": "Least Squares Estimation Using Sketched Data with Heteroskedastic Errors",
    "abstract": "Comments: 37 pages, 3 tables. The title of the paper is changed from the previous version",
    "descriptor": "\nComments: 37 pages, 3 tables. The title of the paper is changed from the previous version\n",
    "authors": [
      "Sokbae Lee",
      "Serena Ng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2007.07781"
  },
  {
    "id": "arXiv:2007.14009",
    "title": "The Minimum Description Length Principle for Pattern Mining: A Survey",
    "abstract": "The Minimum Description Length Principle for Pattern Mining: A Survey",
    "descriptor": "",
    "authors": [
      "Esther Galbrun"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.14009"
  },
  {
    "id": "arXiv:2009.01235",
    "title": "Quantum Discriminator for Binary Classification",
    "abstract": "Quantum Discriminator for Binary Classification",
    "descriptor": "",
    "authors": [
      "Prasanna Date",
      "Wyatt Smith"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.01235"
  },
  {
    "id": "arXiv:2009.04550",
    "title": "Biclustering with Alternating K-Means",
    "abstract": "Biclustering with Alternating K-Means",
    "descriptor": "",
    "authors": [
      "Nicolas Fraiman",
      "Zichao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04550"
  },
  {
    "id": "arXiv:2010.03933",
    "title": "Assessing Classifier Fairness with Collider Bias",
    "abstract": "Comments: 16 pages, 7 figures and 9 tables. The work has been accepted by PAKDD2022",
    "descriptor": "\nComments: 16 pages, 7 figures and 9 tables. The work has been accepted by PAKDD2022\n",
    "authors": [
      "Zhenlong Xu",
      "Ziqi Xu",
      "Jixue Liu",
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Ke Wang",
      "Ziqi Xu",
      "Zhenlong Xu contributed equally to this paper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.03933"
  },
  {
    "id": "arXiv:2010.05997",
    "title": "Look It Up: Bilingual Dictionaries Improve Neural Machine Translation",
    "abstract": "Look It Up: Bilingual Dictionaries Improve Neural Machine Translation",
    "descriptor": "",
    "authors": [
      "Xing Jie Zhong",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05997"
  },
  {
    "id": "arXiv:2010.12227",
    "title": "Geometric Separability using Orthogonal Objects",
    "abstract": "Comments: 9 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 9 pages, 3 figures, 1 table\n",
    "authors": [
      "Abidha V P",
      "Pradeesha Ashok"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2010.12227"
  },
  {
    "id": "arXiv:2011.15013",
    "title": "Modularising Verification Of Durable Opacity",
    "abstract": "Modularising Verification Of Durable Opacity",
    "descriptor": "",
    "authors": [
      "Eleni Bila",
      "John Derrick",
      "Simon Doherty",
      "Brijesh Dongol",
      "Gerhard Schellhorn",
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.15013"
  },
  {
    "id": "arXiv:2012.04835",
    "title": "A Topological Filter for Learning with Label Noise",
    "abstract": "Comments: NeurIPS 2020, fixed some typos",
    "descriptor": "\nComments: NeurIPS 2020, fixed some typos\n",
    "authors": [
      "Pengxiang Wu",
      "Songzhu Zheng",
      "Mayank Goswami",
      "Dimitris Metaxas",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.04835"
  },
  {
    "id": "arXiv:2012.12060",
    "title": "Information Leakage Games: Exploring Information as a Utility Function",
    "abstract": "Comments: The journal version of GameSec'17 paper (arXiv:1705.05030), accepted in ACM Transactions on Privacy and Security (TOPS)",
    "descriptor": "\nComments: The journal version of GameSec'17 paper (arXiv:1705.05030), accepted in ACM Transactions on Privacy and Security (TOPS)\n",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Konstantinos Chatzikokolakis",
      "Yusuke Kawamoto",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.12060"
  },
  {
    "id": "arXiv:2101.01703",
    "title": "Detecting Bias in the Presence of Spatial Autocorrelation",
    "abstract": "Comments: Oral presentation in NeurIPS-2021 workshop on Algorithmic Fairness through the Lens of Causality and Robustness",
    "descriptor": "\nComments: Oral presentation in NeurIPS-2021 workshop on Algorithmic Fairness through the Lens of Causality and Robustness\n",
    "authors": [
      "Subhabrata Majumdar",
      "Cheryl Flynn",
      "Ritwik Mitra"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2101.01703"
  },
  {
    "id": "arXiv:2101.10050",
    "title": "Learning Parametrised Graph Shift Operators",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "George Dasoulas",
      "Johannes Lutzeyer",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.10050"
  },
  {
    "id": "arXiv:2102.00473",
    "title": "Information fusion between knowledge and data in Bayesian network  structure learning",
    "abstract": "Information fusion between knowledge and data in Bayesian network  structure learning",
    "descriptor": "",
    "authors": [
      "Anthony C. Constantinou",
      "Zhigao Guo",
      "Neville K. Kitson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.00473"
  },
  {
    "id": "arXiv:2102.06828",
    "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing",
    "abstract": "Domain Adaptation for Time Series Forecasting via Attention Sharing",
    "descriptor": "",
    "authors": [
      "Xiaoyong Jin",
      "Youngsuk Park",
      "Danielle C. Maddix",
      "Hao Wang",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06828"
  },
  {
    "id": "arXiv:2102.08803",
    "title": "Effects of Early Warning Emails on Student Performance",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1906.09864",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1906.09864\n",
    "authors": [
      "Till Massing",
      "Natalie Reckmann",
      "Jens Klenke",
      "Benjamin Otto",
      "Christoph Hanck",
      "Michael Goedicke"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.08803"
  },
  {
    "id": "arXiv:2102.10869",
    "title": "Introducing a Novel Data over Voice Technique for Secure Voice  Communication",
    "abstract": "Comments: 22 pages, 43 figures; submitted to Wireless Personal Communications, Springer on 17 Jul 2020; initially accepted on 13 Apr 2021; revised on 27 Apr 2021; published on 25 Jun 2022",
    "descriptor": "\nComments: 22 pages, 43 figures; submitted to Wireless Personal Communications, Springer on 17 Jul 2020; initially accepted on 13 Apr 2021; revised on 27 Apr 2021; published on 25 Jun 2022\n",
    "authors": [
      "Piotr Krasnowski",
      "Jerome Lebrun",
      "Bruno Martin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.10869"
  },
  {
    "id": "arXiv:2102.11582",
    "title": "Deep Deterministic Uncertainty: A Simple Baseline",
    "abstract": "Deep Deterministic Uncertainty: A Simple Baseline",
    "descriptor": "",
    "authors": [
      "Jishnu Mukhoti",
      "Andreas Kirsch",
      "Joost van Amersfoort",
      "Philip H.S. Torr",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11582"
  },
  {
    "id": "arXiv:2103.02381",
    "title": "Human-AI Interactions in Public Sector Decision-Making: \"Automation  Bias\" and \"Selective Adherence\" to Algorithmic Advice",
    "abstract": "Comments: Pre-print version (January 2022). Paper accepted for publication in Journal of Public Administration Research and Theory",
    "descriptor": "\nComments: Pre-print version (January 2022). Paper accepted for publication in Journal of Public Administration Research and Theory\n",
    "authors": [
      "Saar Alon-Barkat",
      "Madalina Busuioc"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.02381"
  },
  {
    "id": "arXiv:2103.03500",
    "title": "ShEF: Shielded Enclaves for Cloud FPGAs",
    "abstract": "ShEF: Shielded Enclaves for Cloud FPGAs",
    "descriptor": "",
    "authors": [
      "Mark Zhao",
      "Mingyu Gao",
      "Christos Kozyrakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2103.03500"
  },
  {
    "id": "arXiv:2103.04046",
    "title": "Simplicial Complex Representation Learning",
    "abstract": "Comments: MACHINE LEARNING ON GRAPHS, MLoG Workshop at WSDM'22",
    "descriptor": "\nComments: MACHINE LEARNING ON GRAPHS, MLoG Workshop at WSDM'22\n",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Vasileios Maroulas",
      "Theodore Papamarkou",
      "Xuanting Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.04046"
  },
  {
    "id": "arXiv:2103.13956",
    "title": "Shadoks Approach to Low-Makespan Coordinated Motion Planning",
    "abstract": "Shadoks Approach to Low-Makespan Coordinated Motion Planning",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Crombez",
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Aldo Gonzalez-Lorenzo",
      "Pascal Lafourcade",
      "Luc Libralesso"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.13956"
  },
  {
    "id": "arXiv:2103.15552",
    "title": "Energy Decay Network (EDeN)",
    "abstract": "Energy Decay Network (EDeN)",
    "descriptor": "",
    "authors": [
      "Jamie Nicholas Shelley",
      "Optishell Consultancy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.15552"
  },
  {
    "id": "arXiv:2104.00788",
    "title": "The Effects of Spectral Dimensionality Reduction on Hyperspectral Pixel  Classification: A Case Study",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Kiran Mantripragada",
      "Phuong D. Dao",
      "Yuhong He",
      "Faisal Z. Qureshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.00788"
  },
  {
    "id": "arXiv:2104.01641",
    "title": "TATL: Task Agnostic Transfer Learning for Skin Attributes Detection",
    "abstract": "Comments: This version has been accepted at Medical Image Analysis",
    "descriptor": "\nComments: This version has been accepted at Medical Image Analysis\n",
    "authors": [
      "Duy M. H. Nguyen",
      "Thu T. Nguyen",
      "Huong Vu",
      "Quang Pham",
      "Manh-Duy Nguyen",
      "Binh T. Nguyen",
      "Daniel Sonntag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01641"
  },
  {
    "id": "arXiv:2104.05488",
    "title": "CNN Encoding of Acoustic Parameters for Prominence Detection",
    "abstract": "Comments: 5 pages, 2 figures, 6 tables, Submitted to INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 2 figures, 6 tables, Submitted to INTERSPEECH 2021\n",
    "authors": [
      "Kamini Sabu",
      "Mithilesh Vaidya",
      "Preeti Rao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.05488"
  },
  {
    "id": "arXiv:2104.07855",
    "title": "Distributed TD(0) with Almost No Communication",
    "abstract": "Distributed TD(0) with Almost No Communication",
    "descriptor": "",
    "authors": [
      "Rui Liu",
      "Alex Olshevsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07855"
  },
  {
    "id": "arXiv:2104.08741",
    "title": "CEAR: Cross-Entity Aware Reranker for Knowledge Base Completion",
    "abstract": "Comments: We found a bug in the code that invalidates the reported results for FB15k-237 and WN18RR. The results for OLPBench hold the same. We are in process of updating the paper",
    "descriptor": "\nComments: We found a bug in the code that invalidates the reported results for FB15k-237 and WN18RR. The results for OLPBench hold the same. We are in process of updating the paper\n",
    "authors": [
      "Keshav Kolluru",
      "Mayank Singh Chauhan",
      "Yatin Nandwani",
      "Parag Singla",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08741"
  },
  {
    "id": "arXiv:2104.10029",
    "title": "Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images:  Techniques and Clinical Applications",
    "abstract": "Comments: Accepted to appear in IEEE Journal of Biomedical And Health Informatics",
    "descriptor": "\nComments: Accepted to appear in IEEE Journal of Biomedical And Health Informatics\n",
    "authors": [
      "Yang Ma",
      "Chaoyi Zhang",
      "Mariano Cabezas",
      "Yang Song",
      "Zihao Tang",
      "Dongnan Liu",
      "Weidong Cai",
      "Michael Barnett",
      "Chenyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.10029"
  },
  {
    "id": "arXiv:2104.11883",
    "title": "Carrying out CNN Channel Pruning in a White Box",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS)\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Chia-Wen Lin",
      "Jie Chen",
      "Feiyue Huang",
      "Yongjian Wu",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11883"
  },
  {
    "id": "arXiv:2104.13026",
    "title": "The Hessian Screening Rule",
    "abstract": "The Hessian Screening Rule",
    "descriptor": "",
    "authors": [
      "Johan Larsson",
      "Jonas Wallin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.13026"
  },
  {
    "id": "arXiv:2104.13753",
    "title": "Sum-of-norms clustering does not separate nearby balls",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Alexander Dunlap",
      "Jean-Christophe Mourrat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.13753"
  },
  {
    "id": "arXiv:2105.04906",
    "title": "VICReg: Variance-Invariance-Covariance Regularization for  Self-Supervised Learning",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Adrien Bardes",
      "Jean Ponce",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04906"
  },
  {
    "id": "arXiv:2105.05763",
    "title": "Iltis: Learning Logic in the Web",
    "abstract": "Iltis: Learning Logic in the Web",
    "descriptor": "",
    "authors": [
      "Gaetano Geck",
      "Christine Quenkert",
      "Marko Schmellenkamp",
      "Jonas Schmidt",
      "Felix Tschirbs",
      "Fabian Vehlken",
      "Thomas Zeume"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.05763"
  },
  {
    "id": "arXiv:2105.10019",
    "title": "Enhancing Cross-Sectional Currency Strategies by Context-Aware Learning  to Rank with Self-Attention",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Daniel Poh",
      "Bryan Lim",
      "Stefan Zohren",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.10019"
  },
  {
    "id": "arXiv:2105.13602",
    "title": "ResearchGate and Google Scholar: How much do they differ in  publications, citations and different metrics and why?",
    "abstract": "Comments: Pre-print",
    "descriptor": "\nComments: Pre-print\n",
    "authors": [
      "Vivek Kumar Singh",
      "Satya Swarup Srichandan",
      "Hiran H. Lathabai"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.13602"
  },
  {
    "id": "arXiv:2106.02488",
    "title": "Evaluating Local Explanations using White-box Models",
    "abstract": "Comments: Submitted to ACM FaCCT 2022 Jan 21 2022, 13 pages, 4 Figures",
    "descriptor": "\nComments: Submitted to ACM FaCCT 2022 Jan 21 2022, 13 pages, 4 Figures\n",
    "authors": [
      "Amir Hossein Akhavan Rahnama",
      "Judith Butepage",
      "Pierre Geurts",
      "Henrik Bostrom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02488"
  },
  {
    "id": "arXiv:2106.02701",
    "title": "Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction",
    "abstract": "Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction",
    "descriptor": "",
    "authors": [
      "Thomas L. Athey",
      "Daniel J. Tward",
      "Ulrich Mueller",
      "Joshua T. Vogelstein",
      "Michael I. Miller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02701"
  },
  {
    "id": "arXiv:2106.04170",
    "title": "Conditional Deep Inverse Rosenblatt Transports",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Tiangang Cui",
      "Sergey Dolgov",
      "Olivier Zahm"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.04170"
  },
  {
    "id": "arXiv:2106.05658",
    "title": "Conditional COT-GAN for Video Prediction with Kernel Smoothing",
    "abstract": "Conditional COT-GAN for Video Prediction with Kernel Smoothing",
    "descriptor": "",
    "authors": [
      "Tianlin Xu",
      "Beatrice Acciaio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05658"
  },
  {
    "id": "arXiv:2106.07677",
    "title": "Planning to Fairly Allocate: Probabilistic Fairness in the Restless  Bandit Setting",
    "abstract": "Planning to Fairly Allocate: Probabilistic Fairness in the Restless  Bandit Setting",
    "descriptor": "",
    "authors": [
      "Christine Herlihy",
      "Aviva Prins",
      "Aravind Srinivasan",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07677"
  },
  {
    "id": "arXiv:2106.07967",
    "title": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "abstract": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07967"
  },
  {
    "id": "arXiv:2106.10139",
    "title": "Stochastic parareal: an application of probabilistic methods to  time-parallelisation",
    "abstract": "Stochastic parareal: an application of probabilistic methods to  time-parallelisation",
    "descriptor": "",
    "authors": [
      "Kamran Pentland",
      "Massimiliano Tamborrino",
      "D. Samaddar",
      "L. C. Appel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10139"
  },
  {
    "id": "arXiv:2106.10800",
    "title": "Lossy Compression for Lossless Prediction",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yann Dubois",
      "Benjamin Bloem-Reddy",
      "Karen Ullrich",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10800"
  },
  {
    "id": "arXiv:2106.12059",
    "title": "Stochastic Batch Acquisition for Deep Active Learning",
    "abstract": "Stochastic Batch Acquisition for Deep Active Learning",
    "descriptor": "",
    "authors": [
      "Andreas Kirsch",
      "Sebastian Farquhar",
      "Parmida Atighehchian",
      "Andrew Jesson",
      "Frederic Branchaud-Charron",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12059"
  },
  {
    "id": "arXiv:2106.13384",
    "title": "Finite elements for div and divdiv conforming symmetric tensors in  arbitrary dimension",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13384"
  },
  {
    "id": "arXiv:2106.13863",
    "title": "Steerable 3D Spherical Neurons",
    "abstract": "Steerable 3D Spherical Neurons",
    "descriptor": "",
    "authors": [
      "Pavlo Melnyk",
      "Michael Felsberg",
      "M\u00e5rten Wadenb\u00e4ck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13863"
  },
  {
    "id": "arXiv:2106.14080",
    "title": "Model-Advantage and Value-Aware Models for Model-Based Reinforcement  Learning: Bridging the Gap in Theory and Practice",
    "abstract": "Model-Advantage and Value-Aware Models for Model-Based Reinforcement  Learning: Bridging the Gap in Theory and Practice",
    "descriptor": "",
    "authors": [
      "Nirbhay Modhe",
      "Harish Kamath",
      "Dhruv Batra",
      "Ashwin Kalyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14080"
  },
  {
    "id": "arXiv:2107.02220",
    "title": "Graph Convolution for Re-ranking in Person Re-identification",
    "abstract": "Graph Convolution for Re-ranking in Person Re-identification",
    "descriptor": "",
    "authors": [
      "Yuqi Zhang",
      "Qian Qi",
      "Chong Liu",
      "Weihua Chen",
      "Fan Wang",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02220"
  },
  {
    "id": "arXiv:2107.02578",
    "title": "Noisy Boolean Hidden Matching with Applications",
    "abstract": "Noisy Boolean Hidden Matching with Applications",
    "descriptor": "",
    "authors": [
      "Michael Kapralov",
      "Amulya Musipatla",
      "Jakab Tardos",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.02578"
  },
  {
    "id": "arXiv:2107.04468",
    "title": "Revisiting Non-Convexity in Topology Optimization of Compliance  Minimization Problems",
    "abstract": "Revisiting Non-Convexity in Topology Optimization of Compliance  Minimization Problems",
    "descriptor": "",
    "authors": [
      "Mohamed Abdelhamid",
      "Aleksander Czekanski"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.04468"
  },
  {
    "id": "arXiv:2107.08596",
    "title": "Equivariant Manifold Flows",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Isay Katsman",
      "Aaron Lou",
      "Derek Lim",
      "Qingxuan Jiang",
      "Ser-Nam Lim",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2107.08596"
  },
  {
    "id": "arXiv:2107.09896",
    "title": "Terahertz Meets Untrusted UAV-Relaying: Minimum Secrecy Energy  Efficiency Maximization via Trajectory and Communication Co-design",
    "abstract": "Comments: 16 pages, 10 figures, this work has been submitted for possible journal publication",
    "descriptor": "\nComments: 16 pages, 10 figures, this work has been submitted for possible journal publication\n",
    "authors": [
      "Milad Tatar Mamaghani",
      "Yi Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.09896"
  },
  {
    "id": "arXiv:2107.10064",
    "title": "Few Shots Are All You Need: A Progressive Few Shot Learning Approach for  Low Resource Handwriting Recognition",
    "abstract": "Comments: Under Revision at Pattern Recognition Letters",
    "descriptor": "\nComments: Under Revision at Pattern Recognition Letters\n",
    "authors": [
      "Mohamed Ali Souibgui",
      "Alicia Forn\u00e9s",
      "Yousri Kessentini",
      "Be\u00e1ta Megyesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10064"
  },
  {
    "id": "arXiv:2107.12711",
    "title": "Inclusion, equality and bias in designing online mass deliberative  platforms",
    "abstract": "Comments: Updated paper following feedback",
    "descriptor": "\nComments: Updated paper following feedback\n",
    "authors": [
      "Ruth Shortall",
      "Anatol Itten",
      "Michiel van der Meer",
      "Pradeep K. Murukannaiah",
      "Catholijn M. Jonker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.12711"
  },
  {
    "id": "arXiv:2108.04486",
    "title": "Explicit non-normal modal logic",
    "abstract": "Explicit non-normal modal logic",
    "descriptor": "",
    "authors": [
      "Atefeh Rohani",
      "Thomas Studer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.04486"
  },
  {
    "id": "arXiv:2108.04941",
    "title": "Arbitrage-Free Implied Volatility Surface Generation with Variational  Autoencoders",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Brian Ning",
      "Sebastian Jaimungal",
      "Xiaorong Zhang",
      "Maxime Bergeron"
    ],
    "subjectives": [
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.04941"
  },
  {
    "id": "arXiv:2108.08842",
    "title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for  Federated Learning",
    "abstract": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for  Federated Learning",
    "descriptor": "",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.08842"
  },
  {
    "id": "arXiv:2108.09125",
    "title": "Uncertainties and output feedback in rollout event-triggered control",
    "abstract": "Comments: 12 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 3 figures, 1 table\n",
    "authors": [
      "Stefan Wildhagen",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.09125"
  },
  {
    "id": "arXiv:2108.09183",
    "title": "Boosting of Head Pose Estimation by Knowledge Distillation",
    "abstract": "Boosting of Head Pose Estimation by Knowledge Distillation",
    "descriptor": "",
    "authors": [
      "Andrey Sheka",
      "Victor Samun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09183"
  },
  {
    "id": "arXiv:2108.11845",
    "title": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "abstract": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11845"
  },
  {
    "id": "arXiv:2108.12699",
    "title": "Density estimation in RKHS with application to Korobov spaces in high  dimensions",
    "abstract": "Density estimation in RKHS with application to Korobov spaces in high  dimensions",
    "descriptor": "",
    "authors": [
      "Yoshihito Kazashi",
      "Fabio Nobile"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.12699"
  },
  {
    "id": "arXiv:2108.13865",
    "title": "InSeGAN: A Generative Approach to Segmenting Identical Instances in  Depth Images",
    "abstract": "Comments: Accepted at ICCV 2021. Code & data @ this https URL",
    "descriptor": "\nComments: Accepted at ICCV 2021. Code & data @ this https URL\n",
    "authors": [
      "Anoop Cherian",
      "Goncalo Dias Pais",
      "Siddarth Jain",
      "Tim K. Marks",
      "Alan Sullivan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13865"
  },
  {
    "id": "arXiv:2109.03099",
    "title": "Optimizing model-agnostic Random Subspace ensembles",
    "abstract": "Optimizing model-agnostic Random Subspace ensembles",
    "descriptor": "",
    "authors": [
      "V\u00e2n Anh Huynh-Thu",
      "Pierre Geurts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03099"
  },
  {
    "id": "arXiv:2109.03709",
    "title": "Speeding up PCA with priming",
    "abstract": "Speeding up PCA with priming",
    "descriptor": "",
    "authors": [
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03709"
  },
  {
    "id": "arXiv:2109.04428",
    "title": "Improved Online Algorithm for Fractional Knapsack in the Random Order  Model",
    "abstract": "Comments: Accepted at WAOA 2021",
    "descriptor": "\nComments: Accepted at WAOA 2021\n",
    "authors": [
      "Jeff Giliberti",
      "Andreas Karrenbauer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04428"
  },
  {
    "id": "arXiv:2109.06116",
    "title": "Blood vessel segmentation in en-face OCTA images: a frequency based  method",
    "abstract": "Blood vessel segmentation in en-face OCTA images: a frequency based  method",
    "descriptor": "",
    "authors": [
      "Anna Breger",
      "Felix Goldbach",
      "Bianca S. Gerendas",
      "Ursula Schmidt-Erfurth",
      "Martin Ehler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06116"
  },
  {
    "id": "arXiv:2109.08857",
    "title": "Modern Evolution Strategies for Creativity: Fitting Concrete Images and  Abstract Concepts",
    "abstract": "Modern Evolution Strategies for Creativity: Fitting Concrete Images and  Abstract Concepts",
    "descriptor": "",
    "authors": [
      "Yingtao Tian",
      "David Ha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08857"
  },
  {
    "id": "arXiv:2109.09705",
    "title": "Neural forecasting at scale",
    "abstract": "Neural forecasting at scale",
    "descriptor": "",
    "authors": [
      "Philippe Chatigny",
      "Shengrui Wang",
      "Jean-Marc Patenaude",
      "Boris N. Oreshkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09705"
  },
  {
    "id": "arXiv:2109.12769",
    "title": "Heterogeneous Treatment Effect Estimation using machine learning for  Healthcare application: tutorial and benchmark",
    "abstract": "Comments: 52 pages, 8 figures",
    "descriptor": "\nComments: 52 pages, 8 figures\n",
    "authors": [
      "Yaobin Ling",
      "Pulakesh Upadhyaya",
      "Luyao Chen",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.12769"
  },
  {
    "id": "arXiv:2109.15273",
    "title": "DAAS: Differentiable Architecture and Augmentation Policy Search",
    "abstract": "DAAS: Differentiable Architecture and Augmentation Policy Search",
    "descriptor": "",
    "authors": [
      "Xiaoxing Wang",
      "Xiangxiang Chu",
      "Junchi Yan",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.15273"
  },
  {
    "id": "arXiv:2110.00153",
    "title": "On the design of fixed-gain tracking filters by pole placement: Or an  introduction to applied signals-and-systems theory for engineers",
    "abstract": "Comments: Added Morrison and Brookner refs",
    "descriptor": "\nComments: Added Morrison and Brookner refs\n",
    "authors": [
      "Hugh Lachlan Kennedy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.00153"
  },
  {
    "id": "arXiv:2110.01664",
    "title": "Estimating Potential Outcome Distributions with Collaborating Causal  Networks",
    "abstract": "Comments: 21 pages, 13 figures",
    "descriptor": "\nComments: 21 pages, 13 figures\n",
    "authors": [
      "Tianhui Zhou",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01664"
  },
  {
    "id": "arXiv:2110.01684",
    "title": "Irreversibility of Structure Tensors of Modules",
    "abstract": "Comments: Suggestions applied",
    "descriptor": "\nComments: Suggestions applied\n",
    "authors": [
      "Maciej Wojtala"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.01684"
  },
  {
    "id": "arXiv:2110.01984",
    "title": "Differential Privacy of Dirichlet Posterior Sampling",
    "abstract": "Comments: The privacy guarantees have been rewritten in terms of R\\'enyi Differential Privacy",
    "descriptor": "\nComments: The privacy guarantees have been rewritten in terms of R\\'enyi Differential Privacy\n",
    "authors": [
      "Donlapark Ponnoprat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01984"
  },
  {
    "id": "arXiv:2110.02510",
    "title": "Cycle Representation Learning for Inductive Relation Prediction",
    "abstract": "Cycle Representation Learning for Inductive Relation Prediction",
    "descriptor": "",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02510"
  },
  {
    "id": "arXiv:2110.02802",
    "title": "Self-conditioning pre-trained language models",
    "abstract": "Comments: 8 pages and supplementary material",
    "descriptor": "\nComments: 8 pages and supplementary material\n",
    "authors": [
      "Xavier Suau",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02802"
  },
  {
    "id": "arXiv:2110.03605",
    "title": "One Thing to Fool them All: Generating Interpretable, Universal, and  Physically-Realizable Adversarial Features",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03605"
  },
  {
    "id": "arXiv:2110.03681",
    "title": "Neural Tangent Kernel Empowered Federated Learning",
    "abstract": "Neural Tangent Kernel Empowered Federated Learning",
    "descriptor": "",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Ryan Pilgrim",
      "Chau-Wai Wong",
      "Dror Baron",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03681"
  },
  {
    "id": "arXiv:2110.04227",
    "title": "Universal Joint Approximation of Manifolds and Densities by Simple  Injective Flows",
    "abstract": "Comments: 24 pages, 4 figures",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Michael Puthawala",
      "Matti Lassas",
      "Ivan Dokmani\u0107",
      "Maarten de Hoop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04227"
  },
  {
    "id": "arXiv:2110.04274",
    "title": "Kernel Interpolation as a Bayes Point Machine",
    "abstract": "Kernel Interpolation as a Bayes Point Machine",
    "descriptor": "",
    "authors": [
      "Jeremy Bernstein",
      "Alex Farhang",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04274"
  },
  {
    "id": "arXiv:2110.04624",
    "title": "Iterative Refinement Graph Neural Network for Antibody  Sequence-Structure Co-design",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Wengong Jin",
      "Jeremy Wohlwend",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04624"
  },
  {
    "id": "arXiv:2110.05792",
    "title": "Aspect-driven User Preference and News Representation Learning for News  Recommendation",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Rongyao Wang",
      "Wenpeng Lu",
      "Shoujin Wang",
      "Xueping Peng",
      "Hao Wu",
      "Qian Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05792"
  },
  {
    "id": "arXiv:2110.06460",
    "title": "Data-Time Tradeoffs for Optimal k-Thresholding Algorithms in Compressed  Sensing",
    "abstract": "Comments: 13 pages, 2 figures",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Jialiang Xu",
      "Xu Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06460"
  },
  {
    "id": "arXiv:2110.06485",
    "title": "Communication-Efficient Triangle Counting under Local Differential  Privacy",
    "abstract": "Comments: Full version of the paper accepted at USENIX Security 2022; The first and second authors made equal contribution",
    "descriptor": "\nComments: Full version of the paper accepted at USENIX Security 2022; The first and second authors made equal contribution\n",
    "authors": [
      "Jacob Imola",
      "Takao Murakami",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06485"
  },
  {
    "id": "arXiv:2110.07954",
    "title": "HTTPA: HTTPS Attestable Protocol",
    "abstract": "Comments: 10 pages, 8 figures",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Gordon King",
      "Hans Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.07954"
  },
  {
    "id": "arXiv:2110.09780",
    "title": "Improving Emotional Speech Synthesis by Using SUS-Constrained VAE and  Text Encoder Aggregation",
    "abstract": "Comments: accepted by ICASSP2022",
    "descriptor": "\nComments: accepted by ICASSP2022\n",
    "authors": [
      "Fengyu Yang",
      "Jian Luan",
      "Yujun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09780"
  },
  {
    "id": "arXiv:2110.10249",
    "title": "Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics",
    "abstract": "Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics",
    "descriptor": "",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier",
      "Andris Gerasimovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10249"
  },
  {
    "id": "arXiv:2110.10972",
    "title": "Sliced-Wasserstein Gradient Flows",
    "abstract": "Sliced-Wasserstein Gradient Flows",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Bonet",
      "Nicolas Courty",
      "Fran\u00e7ois Septier",
      "Lucas Drumetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10972"
  },
  {
    "id": "arXiv:2110.11688",
    "title": "Differentially Private Coordinate Descent for Composite Empirical Risk  Minimization",
    "abstract": "Comments: 30 pages, 3 figures",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "Paul Mangold",
      "Aur\u00e9lien Bellet",
      "Joseph Salmon",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11688"
  },
  {
    "id": "arXiv:2110.13179",
    "title": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "abstract": "Comments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF",
    "descriptor": "\nComments: Probabilistic Hierarchical Forecasting, Neural Networks, Poisson Mixtures, Preprint submitted to IJF\n",
    "authors": [
      "Kin G. Olivares",
      "O. Nganba Meetei",
      "Ruijun Ma",
      "Rohan Reddy",
      "Mengfei Cao",
      "Lee Dicker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13179"
  },
  {
    "id": "arXiv:2110.13790",
    "title": "A Map of Science in Wikipedia",
    "abstract": "A Map of Science in Wikipedia",
    "descriptor": "",
    "authors": [
      "Puyu Yang",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13790"
  },
  {
    "id": "arXiv:2110.14045",
    "title": "The Computational Complexity of Finding Arithmetic Expressions With and  Without Parentheses",
    "abstract": "Comments: 15 pages, 1 figure, writing and presentation edited",
    "descriptor": "\nComments: 15 pages, 1 figure, writing and presentation edited\n",
    "authors": [
      "Jayson Lynch",
      "Weng"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.14045"
  },
  {
    "id": "arXiv:2111.01701",
    "title": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "abstract": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Yujie Tang",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01701"
  },
  {
    "id": "arXiv:2111.02493",
    "title": "Roadmap on Signal Processing for Next Generation Measurement Systems",
    "abstract": "Comments: 48 pages, this https URL",
    "descriptor": "\nComments: 48 pages, this https URL\n",
    "authors": [
      "D.K. Iakovidis",
      "M. Ooi",
      "Y.C. Kuang",
      "S. Demidenko",
      "A. Shestakov",
      "V. Sinitsin",
      "M. Henry",
      "A. Sciacchitano",
      "A. Discetti",
      "S. Donati",
      "M. Norgia",
      "A. Menychtas",
      "I. Maglogiannis",
      "S.C. Wriessnegger",
      "L.A. Barradas Chacon",
      "G. Dimas",
      "D. Filos",
      "A.H. Aletras",
      "J. T\u00f6ger",
      "F. Dong",
      "S. Ren",
      "A. Uhl",
      "J. Paziewski",
      "J. Geng",
      "F. Fioranelli",
      "R.M. Narayanan",
      "C. Fernandez",
      "C. Stiller",
      "K. Malamousi",
      "S. Kamnis",
      "K. Delibasis",
      "D. Wang",
      "J. Zhang",
      "R.X. Gao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2111.02493"
  },
  {
    "id": "arXiv:2111.03881",
    "title": "Abstraction for Crash-Resilient Objects (Extended Version)",
    "abstract": "Abstraction for Crash-Resilient Objects (Extended Version)",
    "descriptor": "",
    "authors": [
      "Artem Khyzha",
      "Ori Lahav"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.03881"
  },
  {
    "id": "arXiv:2111.05196",
    "title": "NATURE: Natural Auxiliary Text Utterances for Realistic Spoken Language  Evaluation",
    "abstract": "Comments: 20 pages, 4 figures, accepted to NeurIPS 2021 Track Datasets and Benchmarks",
    "descriptor": "\nComments: 20 pages, 4 figures, accepted to NeurIPS 2021 Track Datasets and Benchmarks\n",
    "authors": [
      "David Alfonso-Hermelo",
      "Ahmad Rashid",
      "Abbas Ghaddar",
      "Philippe Langlais",
      "Mehdi Rezagholizadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.05196"
  },
  {
    "id": "arXiv:2111.05974",
    "title": "User Centered Design (VII): From Automated Flight Deck to Intelligent  Flight Deck",
    "abstract": "Comments: in Chinese language",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Wei Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.05974"
  },
  {
    "id": "arXiv:2111.06150",
    "title": "Improving Novelty Detection using the Reconstructions of Nearest  Neighbours",
    "abstract": "Improving Novelty Detection using the Reconstructions of Nearest  Neighbours",
    "descriptor": "",
    "authors": [
      "Michael Mesarcik",
      "Elena Ranguelova",
      "Albert-Jan Boonstra",
      "Rob V. van Nieuwpoort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06150"
  },
  {
    "id": "arXiv:2111.08799",
    "title": "DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus",
    "abstract": "Comments: 7 pages, 4 figures, 7 tables",
    "descriptor": "\nComments: 7 pages, 4 figures, 7 tables\n",
    "authors": [
      "Ruben Wiersma",
      "Ahmad Nasikun",
      "Elmar Eisemann",
      "Klaus Hildebrandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08799"
  },
  {
    "id": "arXiv:2111.08851",
    "title": "Deep Neural Networks for Rank-Consistent Ordinal Regression Based On  Conditional Probabilities",
    "abstract": "Comments: This paper is currently under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: This paper is currently under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Xintong Shi",
      "Wenzhi Cao",
      "Sebastian Raschka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08851"
  },
  {
    "id": "arXiv:2111.11650",
    "title": "Aerial Intelligent Reflecting Surface Enabled Terahertz Covert  Communications in Beyond-5G Internet of Things",
    "abstract": "Comments: 23 pages, 14 figures, submitted for possible journal publication",
    "descriptor": "\nComments: 23 pages, 14 figures, submitted for possible journal publication\n",
    "authors": [
      "Milad Tatar Mamaghani",
      "Yi Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.11650"
  },
  {
    "id": "arXiv:2111.12332",
    "title": "Securing Proof-of-Stake Nakamoto Consensus Under Bandwidth Constraint",
    "abstract": "Securing Proof-of-Stake Nakamoto Consensus Under Bandwidth Constraint",
    "descriptor": "",
    "authors": [
      "Joachim Neu",
      "Srivatsan Sridhar",
      "Lei Yang",
      "David Tse",
      "Mohammad Alizadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.12332"
  },
  {
    "id": "arXiv:2111.12860",
    "title": "Comprehensive Review of Exoskeleton Technology: State of the art and  development of physical and cognitive human-robot interface",
    "abstract": "Comprehensive Review of Exoskeleton Technology: State of the art and  development of physical and cognitive human-robot interface",
    "descriptor": "",
    "authors": [
      "Farhad Nazari",
      "Navid Mohajer",
      "Darius Nahavandi",
      "Abbas Khosravi",
      "Saeid Nahavandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12860"
  },
  {
    "id": "arXiv:2111.15068",
    "title": "MISS: Multi-Interest Self-Supervised Learning Framework for  Click-Through Rate Prediction",
    "abstract": "Comments: Accepted by ICDE2022",
    "descriptor": "\nComments: Accepted by ICDE2022\n",
    "authors": [
      "Wei Guo",
      "Can Zhang",
      "Zhicheng He",
      "Jiarui Qin",
      "Huifeng Guo",
      "Bo Chen",
      "Ruiming Tang",
      "Xiuqiang He",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.15068"
  },
  {
    "id": "arXiv:2112.01641",
    "title": "Hamiltonian Operator Disentanglement of Content and Motion in Image  Sequences",
    "abstract": "Hamiltonian Operator Disentanglement of Content and Motion in Image  Sequences",
    "descriptor": "",
    "authors": [
      "Asif Khan",
      "Amos Storkey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01641"
  },
  {
    "id": "arXiv:2112.01730",
    "title": "Action Units That Constitute Trainable Micro-expressions (and A  Large-scale Synthetic Dataset)",
    "abstract": "Action Units That Constitute Trainable Micro-expressions (and A  Large-scale Synthetic Dataset)",
    "descriptor": "",
    "authors": [
      "Yuchi Liu",
      "Zhongdao Wang",
      "Tom Gedeon",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01730"
  },
  {
    "id": "arXiv:2112.02424",
    "title": "Variational Wasserstein gradient flow",
    "abstract": "Variational Wasserstein gradient flow",
    "descriptor": "",
    "authors": [
      "Jiaojiao Fan",
      "Qinsheng Zhang",
      "Amirhossein Taghvaei",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02424"
  },
  {
    "id": "arXiv:2112.03376",
    "title": "Convergence Guarantees for Deep Epsilon Greedy Policy Learning",
    "abstract": "Convergence Guarantees for Deep Epsilon Greedy Policy Learning",
    "descriptor": "",
    "authors": [
      "Michael Rawson",
      "Radu Balan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.03376"
  },
  {
    "id": "arXiv:2112.06024",
    "title": "Towards automated optimisation of residual convolutional neural networks  for electrocardiogram classification",
    "abstract": "Towards automated optimisation of residual convolutional neural networks  for electrocardiogram classification",
    "descriptor": "",
    "authors": [
      "Zeineb Fki",
      "Boudour Ammar",
      "Mounir Ben Ayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06024"
  },
  {
    "id": "arXiv:2112.09161",
    "title": "Constraint-based graph network simulator",
    "abstract": "Constraint-based graph network simulator",
    "descriptor": "",
    "authors": [
      "Yulia Rubanova",
      "Alvaro Sanchez-Gonzalez",
      "Tobias Pfaff",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09161"
  },
  {
    "id": "arXiv:2112.09418",
    "title": "Audio Retrieval with Natural Language Queries: A Benchmark Study",
    "abstract": "Comments: Submitted to Transactions on Multimedia. arXiv admin note: substantial text overlap with arXiv:2105.02192",
    "descriptor": "\nComments: Submitted to Transactions on Multimedia. arXiv admin note: substantial text overlap with arXiv:2105.02192\n",
    "authors": [
      "A. Sophia Koepke",
      "Andreea-Maria Oncescu",
      "Jo\u00e3o F. Henriques",
      "Zeynep Akata",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.09418"
  },
  {
    "id": "arXiv:2112.09762",
    "title": "Reproducible and Portable Big Data Analytics in the Cloud",
    "abstract": "Reproducible and Portable Big Data Analytics in the Cloud",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Pei Guo",
      "Xingyan Li",
      "Jianwu Wang",
      "Aryya Gangopadhyay",
      "Carl E. Busart",
      "Jade Freeman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.09762"
  },
  {
    "id": "arXiv:2112.11925",
    "title": "SOLIS -- The MLOps journey from data acquisition to actionable insights",
    "abstract": "SOLIS -- The MLOps journey from data acquisition to actionable insights",
    "descriptor": "",
    "authors": [
      "Razvan Ciobanu",
      "Alexandru Purdila",
      "Laurentiu Piciu",
      "Andrei Damian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11925"
  },
  {
    "id": "arXiv:2112.12228",
    "title": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "abstract": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Julien Roy",
      "Roger Girgis",
      "Joshua Romoff",
      "Pierre-Luc Bacon",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12228"
  },
  {
    "id": "arXiv:2112.13121",
    "title": "The Curse of Zero Task Diversity: On the Failure of Transfer Learning to  Outperform MAML and their Empirical Equivalence",
    "abstract": "Comments: 17 pages, 2 figures",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Brando Miranda",
      "Yu-Xiong Wang",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.13121"
  },
  {
    "id": "arXiv:2112.13261",
    "title": "Interference Nulling Using Reconfigurable Intelligent Surface",
    "abstract": "Comments: This paper is accepted in IEEE Journal on Selected Areas in Communications",
    "descriptor": "\nComments: This paper is accepted in IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Tao Jiang",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.13261"
  },
  {
    "id": "arXiv:2112.14829",
    "title": "On the Number of Incidences when Avoiding the Klan",
    "abstract": "On the Number of Incidences when Avoiding the Klan",
    "descriptor": "",
    "authors": [
      "Sariel Har-Peled"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.14829"
  },
  {
    "id": "arXiv:2112.15072",
    "title": "Deep Learning Models for Knowledge Tracing: Review and Empirical  Evaluation",
    "abstract": "Comments: 72 pages, 9 figures, submitted to JEDM, added acknowledgments",
    "descriptor": "\nComments: 72 pages, 9 figures, submitted to JEDM, added acknowledgments\n",
    "authors": [
      "Sami Sarsa",
      "Juho Leinonen",
      "Arto Hellas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15072"
  },
  {
    "id": "arXiv:2201.02711",
    "title": "Block Walsh-Hadamard Transform Based Binary Layers in Deep Neural  Networks",
    "abstract": "Comments: This paper has been accepted by ACM Transactions on Embedded Computing Systems",
    "descriptor": "\nComments: This paper has been accepted by ACM Transactions on Embedded Computing Systems\n",
    "authors": [
      "Hongyi Pan",
      "Diaa Badawi",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.02711"
  },
  {
    "id": "arXiv:2201.02771",
    "title": "A Sneak Attack on Segmentation of Medical Images Using Deep Neural  Network Classifiers",
    "abstract": "Comments: 8 pages, 10 figures. Accepted by IEEE AIPR 2021 (Oral)",
    "descriptor": "\nComments: 8 pages, 10 figures. Accepted by IEEE AIPR 2021 (Oral)\n",
    "authors": [
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02771"
  },
  {
    "id": "arXiv:2201.05673",
    "title": "Adaptive Information Belief Space Planning",
    "abstract": "Adaptive Information Belief Space Planning",
    "descriptor": "",
    "authors": [
      "Moran Barenboim",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05673"
  },
  {
    "id": "arXiv:2201.06104",
    "title": "A phase-space discontinuous Galerkin approximation for the radiative  transfer equation in slab geometry",
    "abstract": "A phase-space discontinuous Galerkin approximation for the radiative  transfer equation in slab geometry",
    "descriptor": "",
    "authors": [
      "Olena Palii",
      "Matthias Schlottbom"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.06104"
  },
  {
    "id": "arXiv:2201.06701",
    "title": "Motion Inbetweening via Deep $\u0394$-Interpolator",
    "abstract": "Motion Inbetweening via Deep $\u0394$-Interpolator",
    "descriptor": "",
    "authors": [
      "Boris N. Oreshkin",
      "Antonios Valkanas",
      "F\u00e9lix G. Harvey",
      "Louis-Simon M\u00e9nard",
      "Florent Bocquelet",
      "Mark J. Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06701"
  },
  {
    "id": "arXiv:2201.07322",
    "title": "Interpretable Single-Cell Set Classification with Kernel Mean Embeddings",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Siyuan Shan",
      "Vishal Baskaran",
      "Haidong Yi",
      "Jolene Ranek",
      "Natalie Stanley",
      "Junier Oliva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2201.07322"
  },
  {
    "id": "arXiv:2201.07417",
    "title": "Defining Security Requirements with the Common Criteria: Applications,  Adoptions, and Challenges",
    "abstract": "Defining Security Requirements with the Common Criteria: Applications,  Adoptions, and Challenges",
    "descriptor": "",
    "authors": [
      "Nan Sun",
      "Chang-Tsun Li",
      "Hin Chan",
      "Ba Dung Le",
      "MD Zahidul Islam",
      "Leo Yu Zhang",
      "MD Rafiqul Islam",
      "Warren Armstrong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.07417"
  },
  {
    "id": "arXiv:2201.07833",
    "title": "Hybrid Reinforcement Learning-Based Eco-Driving Strategy for Connected  and Automated Vehicles at Signalized Intersections",
    "abstract": "Comments: Accepted by the IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Accepted by the IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Zhengwei Bai",
      "Peng Hao",
      "Wei Shangguan",
      "Baigen Cai",
      "Matthew J. Barth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07833"
  },
  {
    "id": "arXiv:2201.08277",
    "title": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual  Sentiment Analysis",
    "abstract": "Comments: Submitted to LREC 2022, 13 pages, 2 figures",
    "descriptor": "\nComments: Submitted to LREC 2022, 13 pages, 2 figures\n",
    "authors": [
      "Shamsuddeen Hassan Muhammad",
      "David Ifeoluwa Adelani",
      "Sebastian Ruder",
      "Ibrahim Said Ahmad",
      "Idris Abdulmumin",
      "Bello Shehu Bello",
      "Monojit Choudhury",
      "Chris Chinenye Emezue",
      "Saheed Salahudeen Abdullahi",
      "Anuoluwapo Aremu",
      "Alipio Jeorge",
      "Pavel Brazdil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08277"
  },
  {
    "id": "arXiv:2201.08464",
    "title": "On Good Infinite Families of Toric Codes or the Lack Thereof",
    "abstract": "On Good Infinite Families of Toric Codes or the Lack Thereof",
    "descriptor": "",
    "authors": [
      "Mallory Dolorfino",
      "Cordelia Horch",
      "Kelly Jabbusch",
      "Ryan Martinez"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08464"
  },
  {
    "id": "arXiv:2201.08944",
    "title": "DCNGAN: A Deformable Convolutional-Based GAN with QP Adaptation for  Perceptual Quality Enhancement of Compressed Video",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Saiping Zhang",
      "Luis Herranz",
      "Marta Mrak",
      "Marc Gorriz Blanch",
      "Shuai Wan",
      "Fuzheng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.08944"
  },
  {
    "id": "arXiv:2201.09050",
    "title": "Scheduling Policies for Stability and Optimal Server Running Cost in  Cloud Computing Platforms",
    "abstract": "Scheduling Policies for Stability and Optimal Server Running Cost in  Cloud Computing Platforms",
    "descriptor": "",
    "authors": [
      "Haritha K",
      "Chandramani Singh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.09050"
  },
  {
    "id": "arXiv:2201.09280",
    "title": "SpiroMask: Measuring Lung Function Using Consumer-Grade Masks",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Rishiraj Adhikary",
      "Dhruvi Lodhavia",
      "Chris Francis",
      "Rohit Patil",
      "Tanmay Srivastava",
      "Prerna Khanna",
      "Nipun Batra",
      "Joe Breda",
      "Jacob Peplinski",
      "Shwetak Patel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09280"
  },
  {
    "id": "arXiv:2201.09376",
    "title": "ReconFormer: Accelerated MRI Reconstruction Using Recurrent Transformer",
    "abstract": "ReconFormer: Accelerated MRI Reconstruction Using Recurrent Transformer",
    "descriptor": "",
    "authors": [
      "Pengfei Guo",
      "Yiqun Mei",
      "Jinyuan Zhou",
      "Shanshan Jiang",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09376"
  },
  {
    "id": "arXiv:2201.09635",
    "title": "Hierarchical Reinforcement Learning with Adversarially Guided Subgoals",
    "abstract": "Hierarchical Reinforcement Learning with Adversarially Guided Subgoals",
    "descriptor": "",
    "authors": [
      "Vivienne Huiling Wang",
      "Joni Pajarinen",
      "Tinghuai Wang",
      "Joni K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09635"
  },
  {
    "id": "arXiv:2201.10328",
    "title": "ML4CO-KIDA: Knowledge Inheritance in Data Aggregation",
    "abstract": "Comments: NeurIPS 2021 ML4CO dual task 1st solution",
    "descriptor": "\nComments: NeurIPS 2021 ML4CO dual task 1st solution\n",
    "authors": [
      "Zixuan Cao",
      "Yang Xu",
      "Zhewei Huang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10328"
  },
  {
    "id": "arXiv:2201.10410",
    "title": "Comparison of Evaluation Metrics for Landmark Detection in CMR Images",
    "abstract": "Comments: Accepted at Bildverarbeitung f\\\"ur die Medizin (BVM), Informatik aktuell. Springer Vieweg, Wiesbaden 2022",
    "descriptor": "\nComments: Accepted at Bildverarbeitung f\\\"ur die Medizin (BVM), Informatik aktuell. Springer Vieweg, Wiesbaden 2022\n",
    "authors": [
      "Sven Koehler",
      "Lalith Sharan",
      "Julian Kuhm",
      "Arman Ghanaat",
      "Jelizaveta Gordejeva",
      "Nike K. Simon",
      "Niko M. Grell",
      "Florian Andr\u00e9",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10410"
  },
  {
    "id": "arXiv:2201.10711",
    "title": "Sparsity Regularization For Cold-Start Recommendation",
    "abstract": "Sparsity Regularization For Cold-Start Recommendation",
    "descriptor": "",
    "authors": [
      "Aksheshkumar Ajaykumar Shah",
      "Hemanth Venkateswara"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10711"
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "abstract": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.10737"
  },
  {
    "id": "arXiv:2201.10809",
    "title": "A two-step backward compatible fullband speech enhancement system",
    "abstract": "A two-step backward compatible fullband speech enhancement system",
    "descriptor": "",
    "authors": [
      "Xu Zhang",
      "Lianwu Chen",
      "Xiguang Zheng",
      "Xinlei Ren",
      "Chen Zhang",
      "Liang Guo",
      "Bing Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.10809"
  },
  {
    "id": "arXiv:2201.10992",
    "title": "Unpredictable dynamics in congestion games: memory loss can prevent  chaos",
    "abstract": "Comments: 30 pages, 4 figures",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Jakub Bielawski",
      "Thiparat Chotibut",
      "Fryderyk Falniowski",
      "Michal Misiurewicz",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2201.10992"
  },
  {
    "id": "arXiv:2201.11059",
    "title": "Generalization Error Bounds on Deep Learning with Markov Datasets",
    "abstract": "Comments: 62 pages. Updated extensions to higher-order Markov chains and a mixture of Markov chains. arXiv admin note: text overlap with arXiv:math/0405343 by other authors",
    "descriptor": "\nComments: 62 pages. Updated extensions to higher-order Markov chains and a mixture of Markov chains. arXiv admin note: text overlap with arXiv:math/0405343 by other authors\n",
    "authors": [
      "Lan V. Truong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.11059"
  },
  {
    "id": "arXiv:2201.11176",
    "title": "DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence",
    "abstract": "Comments: v2: small fixes in the abstract",
    "descriptor": "\nComments: v2: small fixes in the abstract\n",
    "authors": [
      "Wei Zhao",
      "Michael Strube",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11176"
  },
  {
    "id": "arXiv:2201.11207",
    "title": "Discovering Phonetic Inventories with Crosslingual Automatic Speech  Recognition",
    "abstract": "Comments: Accepted for publication in Computer Speech and Language",
    "descriptor": "\nComments: Accepted for publication in Computer Speech and Language\n",
    "authors": [
      "Piotr \u017belasko",
      "Siyuan Feng",
      "Laureano Moro Velazquez",
      "Ali Abavisani",
      "Saurabhchand Bhati",
      "Odette Scharenborg",
      "Mark Hasegawa-Johnson",
      "Najim Dehak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11207"
  },
  {
    "id": "arXiv:2201.11302",
    "title": "Wireless Energy Transfer in RIS-Aided Cell-Free Massive MIMO Systems:  Opportunities and Challenges",
    "abstract": "Comments: to appear IEEE ComMag",
    "descriptor": "\nComments: to appear IEEE ComMag\n",
    "authors": [
      "Enyu Shi",
      "Jiayi Zhang",
      "Shuaifei Chen",
      "Jiakang Zheng",
      "Yan Zhang",
      "Derrick Wing Kwan Ng",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11302"
  },
  {
    "id": "arXiv:2201.11369",
    "title": "$c^3$-Locally Testable Codes from Lossless Expanders",
    "abstract": "$c^3$-Locally Testable Codes from Lossless Expanders",
    "descriptor": "",
    "authors": [
      "Ting-Chun Lin",
      "Min-Hsiu Hsieh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.11369"
  },
  {
    "id": "arXiv:2201.11539",
    "title": "Coded Caching with Private Demands and Caches",
    "abstract": "Comments: 7 pages, 4 tables",
    "descriptor": "\nComments: 7 pages, 4 tables\n",
    "authors": [
      "Ali Gholami",
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11539"
  },
  {
    "id": "arXiv:2201.11542",
    "title": "An improved judgement algorithm of point in-out convex polygons",
    "abstract": "Comments: in Chinese language Problem of font was fixed",
    "descriptor": "\nComments: in Chinese language Problem of font was fixed\n",
    "authors": [
      "Sun Yixuan",
      "Zhu Zhehao"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11542"
  },
  {
    "id": "arXiv:2201.11578",
    "title": "KRCORE: a microsecond-scale RDMA control plane for elastic computing",
    "abstract": "KRCORE: a microsecond-scale RDMA control plane for elastic computing",
    "descriptor": "",
    "authors": [
      "Xingda Wei",
      "Fangming Lu",
      "Rong Chen",
      "Haibo Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11578"
  },
  {
    "id": "arXiv:2201.11674",
    "title": "Vision Checklist: Towards Testable Error Analysis of Image Models to  Help System Designers Interrogate Model Capabilities",
    "abstract": "Comments: 17 pages, 18 figures",
    "descriptor": "\nComments: 17 pages, 18 figures\n",
    "authors": [
      "Xin Du",
      "Benedicte Legastelois",
      "Bhargavi Ganesh",
      "Ajitha Rajan",
      "Hana Chockler",
      "Vaishak Belle",
      "Stuart Anderson",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11674"
  },
  {
    "id": "arXiv:2201.11701",
    "title": "Model Agnostic Interpretability for Multiple Instance Learning",
    "abstract": "Comments: 25 pages (9 content, 2 acknowledgement + references, 14 appendix). 16 figures (3 main content, 13 appendix). Submitted and accepted to ICLR 22, see this http URL . Revision: added additional acknowledgements",
    "descriptor": "\nComments: 25 pages (9 content, 2 acknowledgement + references, 14 appendix). 16 figures (3 main content, 13 appendix). Submitted and accepted to ICLR 22, see this http URL . Revision: added additional acknowledgements\n",
    "authors": [
      "Joseph Early",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11701"
  }
]
[
  {
    "id": "arXiv:2201.08387",
    "title": "Understanding and Detecting Hateful Content using Contrastive Learning",
    "abstract": "The spread of hate speech and hateful imagery on the Web is a significant\nproblem that needs to be mitigated to improve our Web experience. This work\ncontributes to research efforts to detect and understand hateful content on the\nWeb by undertaking a multimodal analysis of Antisemitism and Islamophobia on\n4chan's /pol/ using OpenAI's CLIP. This large pre-trained model uses the\nContrastive Learning paradigm. We devise a methodology to identify a set of\nAntisemitic and Islamophobic hateful textual phrases using Google's Perspective\nAPI and manual annotations. Then, we use OpenAI's CLIP to identify images that\nare highly similar to our Antisemitic/Islamophobic textual phrases. By running\nour methodology on a dataset that includes 66M posts and 5.8M images shared on\n4chan's /pol/ for 18 months, we detect 573,513 posts containing 92K\nAntisemitic/Islamophobic images and 246K posts that include 420 hateful\nphrases. Among other things, we find that we can use OpenAI's CLIP model to\ndetect hateful content with an accuracy score of 0.84 (F1 score = 0.58). Also,\nwe find that Antisemitic/Islamophobic imagery is shared in 2x more posts on\n4chan's /pol/ compared to Antisemitic/Islamophobic textual phrases,\nhighlighting the need to design more tools for detecting hateful imagery.\nFinally, we make publicly available a dataset of 420 Antisemitic/Islamophobic\nphrases and 92K images that can assist researchers in further understanding\nAntisemitism/Islamophobia and developing more accurate hate speech detection\nmodels.",
    "descriptor": "",
    "authors": [
      "Felipe Gonz\u00e1lez-Pizarro",
      "Savvas Zannettou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08387"
  },
  {
    "id": "arXiv:2201.08413",
    "title": "Unicorn: Reasoning about Configurable System Performance through the  lens of Causality",
    "abstract": "Modern computer systems are highly configurable, with the variability space\nsometimes larger than the number of atoms in the universe. Understanding and\nreasoning about the performance behavior of highly configurable systems, due to\na vast variability space, is challenging. State-of-the-art methods for\nperformance modeling and analyses rely on predictive machine learning models,\ntherefore, they become (i) unreliable in unseen environments (e.g., different\nhardware, workloads), and (ii) produce incorrect explanations. To this end, we\npropose a new method, called Unicorn, which (a) captures intricate interactions\nbetween configuration options across the software-hardware stack and (b)\ndescribes how such interactions impact performance variations via causal\ninference. We evaluated Unicorn on six highly configurable systems, including\nthree on-device machine learning systems, a video encoder, a database\nmanagement system, and a data analytics pipeline. The experimental results\nindicate that Unicorn outperforms state-of-the-art performance optimization and\ndebugging methods. Furthermore, unlike the existing methods, the learned causal\nperformance models reliably predict performance for new environments.",
    "descriptor": "\nComments: EuroSys 2022\n",
    "authors": [
      "Md Shahriar Iqbal",
      "Rahul Krishna",
      "Mohammad Ali Javidian",
      "Baishakhi Ray",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.08413"
  },
  {
    "id": "arXiv:2201.08414",
    "title": "On the time-domain full waveform inversion for time-dissipative and  dispersive poroelastic media",
    "abstract": "This paper concerns the Time-Domain Full Waveform Inversion (FWI) for\ndispersive and dissipative poroelastic materials. The forward problem is an\ninitial boundary value problem (IBVP) of the poroelastic equations with a\nmemory term; the FWI is formulated as a minimization problem of a least-square\nmisfit function with the (IBVP) as the constraint. In this paper, we derive the\nadjoint problem of this minimization problem, whose solution can be applied to\ncomputed the direction of steepest descent in the iterative process for\nminimization. The adjoint problem has a similar numerical structure as the\nforward problem and hence can be solved by the same numerical solver. Because\nthe tracking of the energy evolution plays an important role in the FWI for\ndissipative and dispersive equations, the energy analysis of the forward system\nis also carried out in this paper.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Miao-jung Yvonne Ou",
      "Petr Plech\u00e1\u010d",
      "Jiangming Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.08414"
  },
  {
    "id": "arXiv:2201.08417",
    "title": "Scalable Sampling for Nonsymmetric Determinantal Point Processes",
    "abstract": "A determinantal point process (DPP) on a collection of $M$ items is a model,\nparameterized by a symmetric kernel matrix, that assigns a probability to every\nsubset of those items. Recent work shows that removing the kernel symmetry\nconstraint, yielding nonsymmetric DPPs (NDPPs), can lead to significant\npredictive performance gains for machine learning applications. However,\nexisting work leaves open the question of scalable NDPP sampling. There is only\none known DPP sampling algorithm, based on Cholesky decomposition, that can\ndirectly apply to NDPPs as well. Unfortunately, its runtime is cubic in $M$,\nand thus does not scale to large item collections. In this work, we first note\nthat this algorithm can be transformed into a linear-time one for kernels with\nlow-rank structure. Furthermore, we develop a scalable sublinear-time rejection\nsampling algorithm by constructing a novel proposal distribution. Additionally,\nwe show that imposing certain structural constraints on the NDPP kernel enables\nus to bound the rejection rate in a way that depends only on the kernel rank.\nIn our experiments we compare the speed of all of these samplers for a variety\nof real-world tasks.",
    "descriptor": "",
    "authors": [
      "Insu Han",
      "Mike Gartrell",
      "Jennifer Gillenwater",
      "Elvis Dohmatob",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08417"
  },
  {
    "id": "arXiv:2201.08424",
    "title": "An Analysis of Approximation Algorithms for Iterated Stochastic  Integrals and a Julia and MATLAB Simulation Toolbox",
    "abstract": "For the approximation and simulation of twofold iterated stochastic integrals\nand the corresponding L\\'{e}vy areas w.r.t. a multi-dimensional Wiener process,\nwe review four algorithms based on a Fourier series approach. Especially, the\nvery efficient algorithm due to Wiktorsson and a newly proposed algorithm due\nto Mrongowius and R\\\"ossler are considered. To put recent advances into\ncontext, we analyse the four Fourier-based algorithms in a unified framework to\nhighlight differences and similarities in their derivation. A comparison of\ntheoretical properties is complemented by a numerical simulation that reveals\nthe order of convergence for each algorithm. Further, concrete instructions for\nthe choice of the optimal algorithm and parameters for the simulation of\nsolutions for stochastic (partial) differential equations are given.\nAdditionally, we provide advice for an efficient implementation of the\nconsidered algorithms and incorporated these insights into an open source\ntoolbox that is freely available for both Julia and MATLAB programming\nlanguages. The performance of this toolbox is analysed by comparing it to some\nexisting implementations, where we observe a significant speed-up.",
    "descriptor": "",
    "authors": [
      "Felix Kastner",
      "Andreas R\u00f6\u00dfler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.08424"
  },
  {
    "id": "arXiv:2201.08425",
    "title": "FaceOcc: A Diverse, High-quality Face Occlusion Dataset for Human Face  Extraction",
    "abstract": "Occlusions often occur in face images in the wild, troubling face-related\ntasks such as landmark detection, 3D reconstruction, and face recognition. It\nis beneficial to extract face regions from unconstrained face images\naccurately. However, current face segmentation datasets suffer from small data\nvolumes, few occlusion types, low resolution, and imprecise annotation,\nlimiting the performance of data-driven-based algorithms. This paper proposes a\nnovel face occlusion dataset with manually labeled face occlusions from the\nCelebA-HQ and the internet. The occlusion types cover sunglasses, spectacles,\nhands, masks, scarfs, microphones, etc. To the best of our knowledge, it is by\nfar the largest and most comprehensive face occlusion dataset. Combining it\nwith the attribute mask in CelebAMask-HQ, we trained a straightforward face\nsegmentation model but obtained SOTA performance, convincingly demonstrating\nthe effectiveness of the proposed dataset.",
    "descriptor": "",
    "authors": [
      "Xiangnan Yin",
      "Liming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08425"
  },
  {
    "id": "arXiv:2201.08429",
    "title": "A Visual Analytics Approach to Building Logistic Regression Models and  its Application to Health Records",
    "abstract": "Multidimensional data analysis has become increasingly important in many\nfields, mainly due to current vast data availability and the increasing demand\nto extract knowledge from it. In most applications, the role of the final user\nis crucial to build proper machine learning models and to explain the patterns\nfound in data. In this paper, we present an open unified approach for\ngenerating, evaluating, and applying regression models in high-dimensional data\nsets within a user-guided process. The approach is based on exposing a broad\ncorrelation panorama for attributes, by which the user can select relevant\nattributes to build and evaluate prediction models for one or more contexts. We\nname the approach UCReg (User-Centered Regression). We demonstrate\neffectiveness and efficiency of UCReg through the application of our framework\nto the analysis of Covid-19 and other synthetic and real health records data.",
    "descriptor": "\nComments: 16 pages and 13 figures\n",
    "authors": [
      "Erasmo Artur",
      "Rosane Minghim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.08429"
  },
  {
    "id": "arXiv:2201.08430",
    "title": "Reproducibility in Learning",
    "abstract": "We introduce the notion of a reproducible algorithm in the context of\nlearning. A reproducible learning algorithm is resilient to variations in its\nsamples -- with high probability, it returns the exact same output when run on\ntwo samples from the same underlying distribution. We begin by unpacking the\ndefinition, clarifying how randomness is instrumental in balancing accuracy and\nreproducibility. We initiate a theory of reproducible algorithms, showing how\nreproducibility implies desirable properties such as data reuse and efficient\ntestability. Despite the exceedingly strong demand of reproducibility, there\nare efficient reproducible algorithms for several fundamental problems in\nstatistics and learning. First, we show that any statistical query algorithm\ncan be made reproducible with a modest increase in sample complexity, and we\nuse this to construct reproducible algorithms for finding approximate\nheavy-hitters and medians. Using these ideas, we give the first reproducible\nalgorithm for learning halfspaces via a reproducible weak learner and a\nreproducible boosting algorithm. Finally, we initiate the study of lower bounds\nand inherent tradeoffs for reproducible algorithms, giving nearly tight sample\ncomplexity upper and lower bounds for reproducible versus nonreproducible SQ\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Russell Impagliazzo",
      "Rex Lei",
      "Toniann Pitassi",
      "Jessica Sorrell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08430"
  },
  {
    "id": "arXiv:2201.08433",
    "title": "Finite difference and finite element methods for partial differential  equations on fractals",
    "abstract": "In this paper, we present numerical procedures to compute solutions of\npartial differential equations posed on fractals. In particular, we consider\nthe strong form of the equation using standard graph Laplacian matrices and\nalso weak forms of the equation derived using standard length or area measure\non a discrete approximation of the fractal set. We then introduce a numerical\nprocedure to normalize the obtained diffusions, that is, a way to compute the\nrenormalization constant needed in the definitions of the actual partial\ndifferential equation on the fractal set. A particular case that is studied in\ndetail is the solution of the Dirichlet problem in the Sierpinski triangle.\nOther examples are also presented including a non-planar Hata tree.",
    "descriptor": "",
    "authors": [
      "Fernando Contreras",
      "Juan Galvis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08433"
  },
  {
    "id": "arXiv:2201.08434",
    "title": "DROPO: Sim-to-Real Transfer with Offline Domain Randomization",
    "abstract": "In recent years, domain randomization has gained a lot of traction as a\nmethod for sim-to-real transfer of reinforcement learning policies in robotic\nmanipulation; however, finding optimal randomization distributions can be\ndifficult. In this paper, we introduce DROPO, a novel method for estimating\ndomain randomization distributions for safe sim-to-real transfer. Unlike prior\nwork, DROPO only requires a limited, precollected offline dataset of\ntrajectories, and explicitly models parameter uncertainty to match real data.\nWe demonstrate that DROPO is capable of recovering dynamic parameter\ndistributions in simulation and finding a distribution capable of compensating\nfor an unmodelled phenomenon. We also evaluate the method in two zero-shot\nsim-to-real transfer scenarios, showing successful domain transfer and improved\nperformance over prior methods.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Gabriele Tiboni",
      "Karol Arndt",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08434"
  },
  {
    "id": "arXiv:2201.08440",
    "title": "A Guide to Particle Advection Performance",
    "abstract": "The performance of particle advection-based flow visualization techniques is\ncomplex, since computational work can vary based on many factors, including\nnumber of particles, duration, and mesh type. Further, while many approaches\nhave been introduced to optimize performance, the efficacy of a given approach\ncan be similarly complex. In this work, we seek to establish a guide for\nparticle advection performance by conducting a comprehensive survey of the\narea. We begin by identifying the building blocks for particle advection and\nestablishing a simple cost model incorporating these building blocks. We then\nsurvey existing optimizations for particle advection, using two high-level\ncategories: algorithmic optimizations and hardware efficiency. The\nsub-categories of algorithmic optimizations include solvers, cell locators, I/O\nefficiency, and precomputation, while the sub-categories of hardware efficiency\nall involve parallelism: shared-memory, distributed-memory, and hybrid.\nFinally, we conclude the survey by identifying current gaps in particle\nadvection performance, and in particular on achieving a workflow for predicting\nperformance under various optimizations.",
    "descriptor": "\nComments: 19 pages, survey paper submitted to TVCG (Transactions in Visualization and Computer Graphics)\n",
    "authors": [
      "Abhishek Yenpure",
      "Sudhanshu Sane",
      "Roba Binyahib",
      "David Pugmire",
      "Christoph Garth",
      "Hank Childs"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Graphics (cs.GR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.08440"
  },
  {
    "id": "arXiv:2201.08441",
    "title": "VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase  for Python",
    "abstract": "Context: Identifying potential vulnerable code is important to improve the\nsecurity of our software systems. However, the manual detection of software\nvulnerabilities requires expert knowledge and is time-consuming, and must be\nsupported by automated techniques. Objective: Such automated vulnerability\ndetection techniques should achieve a high accuracy, point developers directly\nto the vulnerable code fragments, scale to real-world software, generalize\nacross the boundaries of a specific software project, and require no or only\nmoderate setup or configuration effort. Method: In this article, we present\nVUDENC (Vulnerability Detection with Deep Learning on a Natural Codebase), a\ndeep learning-based vulnerability detection tool that automatically learns\nfeatures of vulnerable code from a large and real-world Python codebase. VUDENC\napplies a word2vec model to identify semantically similar code tokens and to\nprovide a vector representation. A network of long-short-term memory cells\n(LSTM) is then used to classify vulnerable code token sequences at a\nfine-grained level, highlight the specific areas in the source code that are\nlikely to contain vulnerabilities, and provide confidence levels for its\npredictions. Results: To evaluate VUDENC, we used 1,009 vulnerability-fixing\ncommits from different GitHub repositories that contain seven different types\nof vulnerabilities (SQL injection, XSS, Command injection, XSRF, Remote code\nexecution, Path disclosure, Open redirect) for training. In the experimental\nevaluation, VUDENC achieves a recall of 78%-87%, a precision of 82%-96%, and an\nF1 score of 80%-90%. VUDENC's code, the datasets for the vulnerabilities, and\nthe Python corpus for the word2vec model are available for reproduction.\nConclusions: Our experimental results suggest...",
    "descriptor": "\nComments: Accepted Manuscript\n",
    "authors": [
      "Laura Wartschinski",
      "Yannic Noller",
      "Thomas Vogel",
      "Timo Kehrer",
      "Lars Grunske"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08441"
  },
  {
    "id": "arXiv:2201.08442",
    "title": "Neural Network Quantization with AI Model Efficiency Toolkit (AIMET)",
    "abstract": "While neural networks have advanced the frontiers in many machine learning\napplications, they often come at a high computational cost. Reducing the power\nand latency of neural network inference is vital to integrating modern networks\ninto edge devices with strict power and compute requirements. Neural network\nquantization is one of the most effective ways of achieving these savings, but\nthe additional noise it induces can lead to accuracy degradation. In this white\npaper, we present an overview of neural network quantization using AI Model\nEfficiency Toolkit (AIMET). AIMET is a library of state-of-the-art quantization\nand compression algorithms designed to ease the effort required for model\noptimization and thus drive the broader AI ecosystem towards low latency and\nenergy-efficient inference. AIMET provides users with the ability to simulate\nas well as optimize PyTorch and TensorFlow models. Specifically for\nquantization, AIMET includes various post-training quantization (PTQ, cf.\nchapter 4) and quantization-aware training (QAT, cf. chapter 5) techniques that\nguarantee near floating-point accuracy for 8-bit fixed-point inference. We\nprovide a practical guide to quantization via AIMET by covering PTQ and QAT\nworkflows, code examples and practical tips that enable users to efficiently\nand effectively quantize models using AIMET and reap the benefits of low-bit\ninteger inference.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.08295\n",
    "authors": [
      "Sangeetha Siddegowda",
      "Marios Fournarakis",
      "Markus Nagel",
      "Tijmen Blankevoort",
      "Chirag Patel",
      "Abhijit Khobare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08442"
  },
  {
    "id": "arXiv:2201.08445",
    "title": "A Prescriptive Dirichlet Power Allocation Policy with Deep Reinforcement  Learning",
    "abstract": "Prescribing optimal operation based on the condition of the system and,\nthereby, potentially prolonging the remaining useful lifetime has a large\npotential for actively managing the availability, maintenance and costs of\ncomplex systems. Reinforcement learning (RL) algorithms are particularly\nsuitable for this type of problems given their learning capabilities. A special\ncase of a prescriptive operation is the power allocation task, which can be\nconsidered as a sequential allocation problem, where the action space is\nbounded by a simplex constraint. A general continuous action-space solution of\nsuch sequential allocation problems has still remained an open research\nquestion for RL algorithms. In continuous action-space, the standard Gaussian\npolicy applied in reinforcement learning does not support simplex constraints,\nwhile the Gaussian-softmax policy introduces a bias during training. In this\nwork, we propose the Dirichlet policy for continuous allocation tasks and\nanalyze the bias and variance of its policy gradients. We demonstrate that the\nDirichlet policy is bias-free and provides significantly faster convergence,\nbetter performance and better hyperparameters robustness over the\nGaussian-softmax policy. Moreover, we demonstrate the applicability of the\nproposed algorithm on a prescriptive operation case, where we propose the\nDirichlet power allocation policy and evaluate the performance on a case study\nof a set of multiple lithium-ion (Li-I) battery systems. The experimental\nresults show the potential to prescribe optimal operation, improve the\nefficiency and sustainability of multi-power source systems.",
    "descriptor": "",
    "authors": [
      "Yuan Tian",
      "Minghao Han",
      "Chetan Kulkarni",
      "Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08445"
  },
  {
    "id": "arXiv:2201.08446",
    "title": "Dealing with elementary paths in the Kidney Exchange Problem",
    "abstract": "We study an elementary path problem which appears in the pricing step of a\ncolumn generation scheme solving the kidney exchange problem. The latter aims\nat finding exchanges of donations in a pool of patients and donors of kidney\ntransplantations. Informally, the problem is to determine a set of cycles and\nchains of limited length maximizing a medical benefit in a directed graph. The\ncycle formulation, a large-scale model of the problem restricted to cycles of\ndonation, is efficiently solved via branch-and-price. When including chains of\ndonation however, the pricing subproblem becomes NP-hard. This article proposes\na new complete column generation scheme that takes into account these chains\ninitiated by altruistic donors. The development of non-exact dynamic approaches\nfor the pricing problem, the NG-route relaxation and the color coding\nheuristic, leads to an efficient column generation process.",
    "descriptor": "",
    "authors": [
      "Lucie Pansart",
      "Hadrien Cambazard",
      "Nicolas Catusse"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.08446"
  },
  {
    "id": "arXiv:2201.08448",
    "title": "Kinit Classification in Ethiopian Chants, Azmaris and Modern Music: A  New Dataset and CNN Benchmark",
    "abstract": "In this paper, we create EMIR, the first-ever Music Information Retrieval\ndataset for Ethiopian music. EMIR is freely available for research purposes and\ncontains 600 sample recordings of Orthodox Tewahedo chants, traditional Azmari\nsongs and contemporary Ethiopian secular music. Each sample is classified by\nfive expert judges into one of four well-known Ethiopian Kinits, Tizita, Bati,\nAmbassel and Anchihoye. Each Kinit uses its own pentatonic scale and also has\nits own stylistic characteristics. Thus, Kinit classification needs to combine\nscale identification with genre recognition. After describing the dataset, we\npresent the Ethio Kinits Model (EKM), based on VGG, for classifying the EMIR\nclips. In Experiment 1, we investigated whether Filterbank, Mel-spectrogram,\nChroma, or Mel-frequency Cepstral coefficient (MFCC) features work best for\nKinit classification using EKM. MFCC was found to be superior and was therefore\nadopted for Experiment 2, where the performance of EKM models using MFCC was\ncompared using three different audio sample lengths. 3s length gave the best\nresults. In Experiment 3, EKM and four existing models were compared on the\nEMIR dataset: AlexNet, ResNet50, VGG16 and LSTM. EKM was found to have the best\naccuracy (95.00%) as well as the fastest training time. We hope this work will\nencourage others to explore Ethiopian music and to experiment with other models\nfor Kinit classification.",
    "descriptor": "\nComments: 11 pages, 4 tables, 3 figures\n",
    "authors": [
      "Ephrem A. Retta",
      "Richard Sutcliffe",
      "Eiad Almekhlafi",
      "Yosef K. Enku",
      "Eyob Alemu",
      "Tigist D. Gemechu",
      "Michael A. Berwo",
      "Mustafa Mhamed",
      "Jun Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.08448"
  },
  {
    "id": "arXiv:2201.08450",
    "title": "Automatic Item Generation of Figural Analogy Problems: A Review and  Outlook",
    "abstract": "Figural analogy problems have long been a widely used format in human\nintelligence tests. In the past four decades, more and more research has\ninvestigated automatic item generation for figural analogy problems, i.e.,\nalgorithmic approaches for systematically and automatically creating such\nproblems. In cognitive science and psychometrics, this research can deepen our\nunderstandings of human analogical ability and psychometric properties of\nfigural analogies. With the recent development of data-driven AI models for\nreasoning about figural analogies, the territory of automatic item generation\nof figural analogies has further expanded. This expansion brings new challenges\nas well as opportunities, which demand reflection on previous item generation\nresearch and planning future studies. This paper reviews the important works of\nautomatic item generation of figural analogies for both human intelligence\ntests and data-driven AI models. From an interdisciplinary perspective, the\nprinciples and technical details of these works are analyzed and compared, and\ndesiderata for future research are suggested.",
    "descriptor": "\nComments: Presented at The Ninth Advances in Cognitive Systems (ACS) Conference 2021 (arXiv:2201.06134)\n",
    "authors": [
      "Yuan Yang",
      "Deepayan Sanyal",
      "Joel Michelson",
      "James Ainooson",
      "Maithilee Kunda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08450"
  },
  {
    "id": "arXiv:2201.08451",
    "title": "Regional Negative Bias in Word Embeddings Predicts Racial Animus--but  only via Name Frequency",
    "abstract": "The word embedding association test (WEAT) is an important method for\nmeasuring linguistic biases against social groups such as ethnic minorities in\nlarge text corpora. It does so by comparing the semantic relatedness of words\nprototypical of the groups (e.g., names unique to those groups) and attribute\nwords (e.g., 'pleasant' and 'unpleasant' words). We show that anti-black WEAT\nestimates from geo-tagged social media data at the level of metropolitan\nstatistical areas strongly correlate with several measures of racial\nanimus--even when controlling for sociodemographic covariates. However, we also\nshow that every one of these correlations is explained by a third variable: the\nfrequency of Black names in the underlying corpora relative to White names.\nThis occurs because word embeddings tend to group positive (negative) words and\nfrequent (rare) words together in the estimated semantic space. As the\nfrequency of Black names on social media is strongly correlated with Black\nAmericans' prevalence in the population, this results in spurious anti-Black\nWEAT estimates wherever few Black Americans live. This suggests that research\nusing the WEAT to measure bias should consider term frequency, and also\ndemonstrates the potential consequences of using black-box models like word\nembeddings to study human cognition and behavior.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Austin van Loon",
      "Salvatore Giorgi",
      "Robb Willer",
      "Johannes Eichstaedt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08451"
  },
  {
    "id": "arXiv:2201.08452",
    "title": "npm-filter: Automating the mining of dynamic information from npm  packages",
    "abstract": "The static properties of code repositories, e.g., lines of code, dependents,\ndependencies, etc. can be readily scraped from code hosting platforms such as\nGitHub, and from package management systems such as npm for JavaScript;\nAlthough no less important, information related to the dynamic properties of\nprograms, e.g., number of tests in a test suite that pass or fail is less\nreadily available. This dynamic information could be immensely useful to\nresearchers conducting corpus analyses, as it would give them the ability to\ndifferentiate projects based on properties of the projects that can only be\nobserved by running them.\nIn this paper, we present npm-filter, an automated tool that can download,\ninstall, build, test, and run custom user scripts over the source code of\nJavaScript projects available on npm, the most popular JavaScript package\nmanager. We outline this tool, describe its implementation, and show that\nnpm-filter has already been useful in developing evaluation suites for multiple\nJavaScript tools.",
    "descriptor": "\nComments: 5 pages; this work is being submitted to the MSR tool track\n",
    "authors": [
      "Ellen Arteca",
      "Alexi Turcotte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08452"
  },
  {
    "id": "arXiv:2201.08454",
    "title": "An error estimate for the Gauss-Jacobi-Lobatto quadrature rule",
    "abstract": "An error estimate for the Gauss-Lobatto quadrature formula for integration\nover the interval $[-1, 1]$, relative to the Jacobi weight function\n$w^{\\alpha,\\beta}(t)=(1-t)^\\alpha(1+t)^\\beta$, $\\alpha,\\beta>-1$, is obtained.\nThis estimate holds true for functions belonging to some Sobolev-type subspaces\nof the weighted space $L_{w^{\\alpha,\\beta}}^1([-1,1])$.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Concetta Laurita"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08454"
  },
  {
    "id": "arXiv:2201.08455",
    "title": "Hybrid Graph Models for Logic Optimization via Spatio-Temporal  Information",
    "abstract": "Despite the stride made by machine learning (ML) based performance modeling,\ntwo major concerns that may impede production-ready ML applications in EDA are\nstringent accuracy requirements and generalization capability. To this end, we\npropose hybrid graph neural network (GNN) based approaches towards highly\naccurate quality-of-result (QoR) estimations with great generalization\ncapability, specifically targeting logic synthesis optimization. The key idea\nis to simultaneously leverage spatio-temporal information from hardware designs\nand logic synthesis flows to forecast performance (i.e., delay/area) of various\nsynthesis flows on different designs. The structural characteristics inside\nhardware designs are distilled and represented by GNNs; the temporal knowledge\n(i.e., relative ordering of logic transformations) in synthesis flows can be\nimposed on hardware designs by combining a virtually added supernode or a\nsequence processing model with conventional GNN models. Evaluation on 3.3\nmillion data points shows that the testing mean absolute percentage error\n(MAPE) on designs seen and unseen during training are no more than 1.2% and\n3.1%, respectively, which are 7-15X lower than existing studies.",
    "descriptor": "",
    "authors": [
      "Nan Wu",
      "Jiwon Lee",
      "Yuan Xie",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.08455"
  },
  {
    "id": "arXiv:2201.08456",
    "title": "Towards Web of Things Middleware: A Systematic Review",
    "abstract": "Advancements of the Web technology provide this opportunity for Internet of\nThings (IoT) to take steps towards Web of Things (WoT). By increasing trend of\nreusing Web techniques to create a monolithic environment to control, monitor,\nand compose the smart objects, a mature WoT architecture is finally emerged in\nfour layers to be a solution for IoT-middleware. Although WoT architecture\nfacilitates addressing requirements of IoT in architectural or service aspects,\nbut the effectiveness of this solution is indeterminate to meet IoT-middleware\nobjectives. The most surveys and related reviews in this field just investigate\nIoT-middleware and WoT separately and thereby, report some new technologies or\nprotocols on various middlewares or WoT models. In this paper a comprehensive\nsurvey is proposed on common area of IoT and WoT disciplines by leveraging\nSystematic Literature Review (SLR) as research methodology. This survey\nclassifies variant types of IoT-middleware and WoT architecture to specifies\ntheir requirements and characteristics, respectively. Hence, WoT requirements\ncould be categorized by comparing and analyzing IoT-middleware requirements and\nWoT characteristics. This research heavily reviews existing academic and\nindustrial contributions to select potential platforms (or frameworks) and\nassess them against proposed WoT requirements. As a result of this survey,\nstrengths and weaknesses of WoT architecture, as a IoT-middleware, are\npresented. Finally, this research attempts to open new horizon for the WoT\narchitecture to enable researchers to dig role of WoT technologies in the IoT.",
    "descriptor": "",
    "authors": [
      "Habib Larian",
      "Ali Larian",
      "Mahdi Sharifi",
      "Homa Movahednejad"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.08456"
  },
  {
    "id": "arXiv:2201.08459",
    "title": "Federated Learning with Heterogeneous Architectures using Graph  HyperNetworks",
    "abstract": "Standard Federated Learning (FL) techniques are limited to clients with\nidentical network architectures. This restricts potential use-cases like\ncross-platform training or inter-organizational collaboration when both data\nprivacy and architectural proprietary are required. We propose a new FL\nframework that accommodates heterogeneous client architecture by adopting a\ngraph hypernetwork for parameter sharing. A property of the graph hyper network\nis that it can adapt to various computational graphs, thereby allowing\nmeaningful parameter sharing across models. Unlike existing solutions, our\nframework does not limit the clients to share the same architecture type, makes\nno use of external data and does not require clients to disclose their model\narchitecture. Compared with distillation-based and non-graph hypernetwork\nbaselines, our method performs notably better on standard benchmarks. We\nadditionally show encouraging generalization performance to unseen\narchitectures.",
    "descriptor": "",
    "authors": [
      "Or Litany",
      "Haggai Maron",
      "David Acuna",
      "Jan Kautz",
      "Gal Chechik",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08459"
  },
  {
    "id": "arXiv:2201.08460",
    "title": "Your Tweets Matter: How Social Media Sentiments Associate with COVID-19  Vaccination Rates in the US",
    "abstract": "Objective: The aims of the study were to examine the association between\nsocial media sentiments surrounding COVID-19 vaccination and the effects on\nvaccination rates in the United States (US), as well as other contributing\nfactors to the COVID-19 vaccine hesitancy.\nMethod: The dataset used in this study consists of vaccine-related English\ntweets collected in real-time from January 4 - May 11, 2021, posted within the\nUS, as well as health literacy (HL), social vulnerability index (SVI), and\nvaccination rates at the state level.\nResults: The findings presented in this study demonstrate a significant\ncorrelation between the sentiments of the tweets and the vaccination rate in\nthe US. The results also suggest a significant negative association between HL\nand SVI and that the state demographics correlate with both HL and SVI.\nDiscussion: Social media activity provides insights into public opinion about\nvaccinations and helps determine the required public health interventions to\nincrease the vaccination rate in the US.\nConclusion: Health literacy, social vulnerability index and monitoring of\nsocial media sentiments need to be considered in public health interventions as\npart of vaccination campaigns.",
    "descriptor": "",
    "authors": [
      "Ana Aleksandric",
      "Mercy Jesuloluwa Obasanya",
      "Sarah Melcher",
      "Shirin Nilizadeh",
      "Gabriela Mustata Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.08460"
  },
  {
    "id": "arXiv:2201.08461",
    "title": "Polytope: Practical Memory Access Control for C++ Applications",
    "abstract": "Designing and implementing secure software is inarguably more important than\never. However, despite years of research into privilege separating programs, it\nremains difficult to actually do so and such efforts can take years of\nlabor-intensive engineering to reach fruition. At the same time, new\nintra-process isolation primitives make strong data isolation and privilege\nseparation more attractive from a performance perspective. Yet, substituting\nintra-process security boundaries for time-tested process boundaries opens the\ndoor to subtle but devastating privilege leaks. In this work, we present\nPolytope, a language extension to C++ that aims to make efficient privilege\nseparation accessible to a wider audience of developers. Polytope defines a\npolicy language encoded as C++11 attributes that separate code and data into\ndistinct program partitions. A modified Clang front-end embeds source-level\npolicy as metadata nodes in the LLVM IR. An LLVM pass interprets embedded\npolicy and instruments an IR with code to enforce the source-level policy using\nIntel MPK. A run-time support library manages partitions, protection keys,\ndynamic memory operations, and indirect call target privileges. An evaluation\ndemonstrates that Polytope provides equivalent protection to prior systems with\na low annotation burden and comparable performance overhead. Polytope also\nrenders privilege leaks that contradict intended policy impossible to express.",
    "descriptor": "",
    "authors": [
      "Ioannis Agadakos",
      "Manuel Egele",
      "William Robertson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08461"
  },
  {
    "id": "arXiv:2201.08465",
    "title": "An Empirical Investigation of Model-to-Model Distribution Shifts in  Trained Convolutional Filters",
    "abstract": "We present first empirical results from our ongoing investigation of\ndistribution shifts in image data used for various computer vision tasks.\nInstead of analyzing the original training and test data, we propose to study\nshifts in the learned weights of trained models. In this work, we focus on the\nproperties of the distributions of dominantly used 3x3 convolution filter\nkernels. We collected and publicly provide a data set with over half a billion\nfilters from hundreds of trained CNNs, using a wide range of data sets,\narchitectures, and vision tasks. Our analysis shows interesting distribution\nshifts (or the lack thereof) between trained filters along different axes of\nmeta-parameters, like data type, task, architecture, or layer depth. We argue,\nthat the observed properties are a valuable source for further investigation\ninto a better understanding of the impact of shifts in the input data to the\ngeneralization abilities of CNN models and novel methods for more robust\ntransfer-learning in this domain. Data available at:\nhttps://github.com/paulgavrikov/CNN-Filter-DB/.",
    "descriptor": "",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08465"
  },
  {
    "id": "arXiv:2201.08468",
    "title": "Android Malware Detection using Feature Ranking of Permissions",
    "abstract": "We investigate the use of Android permissions as the vehicle to allow for\nquick and effective differentiation between benign and malware apps. To this\nend, we extract all Android permissions, eliminating those that have zero\nimpact, and apply two feature ranking algorithms namely Chi-Square test and\nFisher's Exact test to rank and additionally filter them, resulting in a\ncomparatively small set of relevant permissions. Then we use Decision Tree,\nSupport Vector Machine, and Random Forest Classifier algorithms to detect\nmalware apps. Our analysis indicates that this approach can result in better\naccuracy and F-score value than other reported approaches. In particular, when\nrandom forest is used as the classifier with the combination of Fisher's Exact\ntest, we achieve 99.34\\% in accuracy and 92.17\\% in F-score with the false\npositive rate of 0.56\\% for the dataset in question, with results improving to\n99.82\\% in accuracy and 95.28\\% in F-score with the false positive rate as low\nas 0.05\\% when only malware from three most popular malware families are\nconsidered.",
    "descriptor": "",
    "authors": [
      "Muhammad Suleman Saleem",
      "Jelena Mi\u0161i\u0107",
      "Vojislav B. Mi\u0161i\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08468"
  },
  {
    "id": "arXiv:2201.08470",
    "title": "RoboMal: Malware Detection for Robot Network Systems",
    "abstract": "Robot systems are increasingly integrating into numerous avenues of modern\nlife. From cleaning houses to providing guidance and emotional support, robots\nnow work directly with humans. Due to their far-reaching applications and\nprogressively complex architecture, they are being targeted by adversarial\nattacks such as sensor-actuator attacks, data spoofing, malware, and network\nintrusion. Therefore, security for robotic systems has become crucial. In this\npaper, we address the underserved area of malware detection in robotic\nsoftware. Since robots work in close proximity to humans, often with direct\ninteractions, malware could have life-threatening impacts. Hence, we propose\nthe RoboMal framework of static malware detection on binary executables to\ndetect malware before it gets a chance to execute. Additionally, we address the\ngreat paucity of data in this space by providing the RoboMal dataset comprising\ncontroller executables of a small-scale autonomous car. The performance of the\nframework is compared against widely used supervised learning models: GRU, CNN,\nand ANN. Notably, the LSTM-based RoboMal model outperforms the other models\nwith an accuracy of 85% and precision of 87% in 10-fold cross-validation, hence\nproving the effectiveness of the proposed framework.",
    "descriptor": "\nComments: Published in the proceedings of 2021 5th IEEE International Conference on Robotic Computing (IRC)\n",
    "authors": [
      "Upinder Kaur",
      "Haozhe Zhou",
      "Xiaxin Shen",
      "Byung-Cheol Min",
      "Richard M. Voyles"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08470"
  },
  {
    "id": "arXiv:2201.08471",
    "title": "Transfer Learning Approaches for Building Cross-Language Dense Retrieval  Models",
    "abstract": "The advent of transformer-based models such as BERT has led to the rise of\nneural ranking models. These models have improved the effectiveness of\nretrieval systems well beyond that of lexical term matching models such as\nBM25. While monolingual retrieval tasks have benefited from large-scale\ntraining collections such as MS MARCO and advances in neural architectures,\ncross-language retrieval tasks have fallen behind these advancements. This\npaper introduces ColBERT-X, a generalization of the ColBERT\nmulti-representation dense retrieval model that uses the XLM-RoBERTa (XLM-R)\nencoder to support cross-language information retrieval (CLIR). ColBERT-X can\nbe trained in two ways. In zero-shot training, the system is trained on the\nEnglish MS MARCO collection, relying on the XLM-R encoder for cross-language\nmappings. In translate-train, the system is trained on the MS MARCO English\nqueries coupled with machine translations of the associated MS MARCO passages.\nResults on ad hoc document ranking tasks in several languages demonstrate\nsubstantial and statistically significant improvements of these trained dense\nretrieval models over traditional lexical CLIR baselines.",
    "descriptor": "\nComments: Accepted at ECIR 2022 (Full paper)\n",
    "authors": [
      "Suraj Nair",
      "Eugene Yang",
      "Dawn Lawrie",
      "Kevin Duh",
      "Paul McNamee",
      "Kenton Murray",
      "James Mayfield",
      "Douglas W. Oard"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.08471"
  },
  {
    "id": "arXiv:2201.08472",
    "title": "Weighted Sum-Rate Maximization for Rate-Splitting Multiple Access Based  Secure Communication",
    "abstract": "As investigations on physical layer security evolve from point-to-point\nsystems to multi-user scenarios, multi-user interference (MUI) is introduced\nand becomes an unavoidable issue. Different from treating MUI totally as noise\nin conventional secure communications, in this paper, we propose a\nrate-splitting multiple access (RSMA)-based secure beamforming design, where\nuser messages are split and encoded into common and private streams. Each user\nnot only decodes the common stream and the intended private stream, but also\ntries to eavesdrop the private streams of other users. We formulate a weighted\nsum-rate (WSR) maximization problem subject to the secrecy rate requirements of\nall users. To tackle the non-convexity of the formulated problem, a successive\nconvex approximation (SCA)-based approach is adopted to convert the original\nnon-convex and intractable problem into a low-complexity suboptimal iterative\nalgorithm. Numerical results demonstrate that the proposed secure beamforming\nscheme outperforms the conventional multi-user linear precoding (MULP)\ntechnique in terms of the WSR performance while ensuring user secrecy rate\nrequirements.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Huiyun Xia",
      "Yijie Mao",
      "Bruno Clerckx",
      "Xiaokang Zhou",
      "Shuai Han",
      "Cheng Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08472"
  },
  {
    "id": "arXiv:2201.08473",
    "title": "Assembling a Cyber Range to Evaluate Artificial Intelligence / Machine  Learning (AI/ML) Security Tools",
    "abstract": "In this case study, we describe the design and assembly of a cyber security\ntestbed at Oak Ridge National Laboratory in Oak Ridge, TN, USA. The range is\ndesigned to provide agile reconfigurations to facilitate a wide variety of\nexperiments for evaluations of cyber security tools -- particularly those\ninvolving AI/ML. In particular, the testbed provides realistic test\nenvironments while permitting control and programmatic observations/data\ncollection during the experiments. We have designed in the ability to repeat\nthe evaluations, so additional tools can be evaluated and compared at a later\ntime. The system is one that can be scaled up or down for experiment sizes. At\nthe time of the conference we will have completed two full-scale, national,\ngovernment challenges on this range. These challenges are evaluating the\nperformance and operating costs for AI/ML-based cyber security tools for\napplication into large, government-sized networks. These evaluations will be\ndescribed as examples providing motivation and context for various design\ndecisions and adaptations we have made. The first challenge measured end-point\nsecurity tools against 100K file samples (benignware and malware) chosen across\na range of file types. The second is an evaluation of network intrusion\ndetection systems efficacy in identifying multi-step adversarial campaigns --\ninvolving reconnaissance, penetration and exploitations, lateral movement, etc.\n-- with varying levels of covertness in a high-volume business network. The\nscale of each of these challenges requires automation systems to repeat, or\nsimultaneously mirror identical the experiments for each ML tool under test.\nProviding an array of easy-to-difficult malicious activity for sussing out the\ntrue abilities of the AI/ML tools has been a particularly interesting and\nchallenging aspect of designing and executing these challenge events.",
    "descriptor": "\nComments: ICCWS 2021 16th International Conference on Cyber Warfare and Security. Academic Conferences Limited, 2021\n",
    "authors": [
      "Jeffrey A. Nichols",
      "Kevin D. Spakes",
      "Cory L. Watson",
      "Robert A. Bridges"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08473"
  },
  {
    "id": "arXiv:2201.08474",
    "title": "Post-Training Detection of Backdoor Attacks for Two-Class and  Multi-Attack Scenarios",
    "abstract": "Backdoor attacks (BAs) are an emerging threat to deep neural network\nclassifiers. A victim classifier will predict to an attacker-desired target\nclass whenever a test sample is embedded with the same backdoor pattern (BP)\nthat was used to poison the classifier's training set. Detecting whether a\nclassifier is backdoor attacked is not easy in practice, especially when the\ndefender is, e.g., a downstream user without access to the classifier's\ntraining set. This challenge is addressed here by a reverse-engineering defense\n(RED), which has been shown to yield state-of-the-art performance in several\ndomains. However, existing REDs are not applicable when there are only {\\it two\nclasses} or when {\\it multiple attacks} are present. These scenarios are first\nstudied in the current paper, under the practical constraints that the defender\nneither has access to the classifier's training set nor to supervision from\nclean reference classifiers trained for the same domain. We propose a detection\nframework based on BP reverse-engineering and a novel {\\it expected\ntransferability} (ET) statistic. We show that our ET statistic is effective\n{\\it using the same detection threshold}, irrespective of the classification\ndomain, the attack configuration, and the BP reverse-engineering algorithm that\nis used. The excellent performance of our method is demonstrated on six\nbenchmark datasets. Notably, our detection framework is also applicable to\nmulti-class scenarios with multiple attacks.",
    "descriptor": "\nComments: Accepted to ICLR2022\n",
    "authors": [
      "Zhen Xiang",
      "David J. Miller",
      "George Kesidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08474"
  },
  {
    "id": "arXiv:2201.08475",
    "title": "GenGNN: A Generic FPGA Framework for Graph Neural Network Acceleration",
    "abstract": "Graph neural networks (GNNs) have recently exploded in popularity thanks to\ntheir broad applicability to ubiquitous graph-related problems such as quantum\nchemistry, drug discovery, and high energy physics. However, meeting demand for\nnovel GNN models and fast inference simultaneously is challenging because of\nthe gap between the difficulty in developing efficient FPGA accelerators and\nthe rapid pace of creation of new GNN models. Prior art focuses on the\nacceleration of specific classes of GNNs but lacks the generality to work\nacross existing models or to extend to new and emerging GNN models. In this\nwork, we propose a generic GNN acceleration framework using High-Level\nSynthesis (HLS), named GenGNN, with two-fold goals. First, we aim to deliver\nultra-fast GNN inference without any graph pre-processing for real-time\nrequirements. Second, we aim to support a diverse set of GNN models with the\nextensibility to flexibly adapt to new models. The framework features an\noptimized message-passing structure applicable to all models, combined with a\nrich library of model-specific components. We verify our implementation\non-board on the Xilinx Alveo U50 FPGA and observe a speed-up of up to 25x\nagainst CPU (6226R) baseline and 13x against GPU (A6000) baseline. Our HLS code\nwill be open-source on GitHub upon acceptance.",
    "descriptor": "\nComments: 10 pages, 9 figures. The first three authors contributed equally. Submitted to FCCM 2022\n",
    "authors": [
      "Stefan Abi-Karam",
      "Yuqi He",
      "Rishov Sarkar",
      "Lakshmi Sathidevi",
      "Zihang Qiao",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.08475"
  },
  {
    "id": "arXiv:2201.08481",
    "title": "Classic Graph Structural Features Outperform Factorization-Based Graph  Embedding Methods on Community Labeling",
    "abstract": "Graph representation learning (also called graph embeddings) is a popular\ntechnique for incorporating network structure into machine learning models.\nUnsupervised graph embedding methods aim to capture graph structure by learning\na low-dimensional vector representation (the embedding) for each node. Despite\nthe widespread use of these embeddings for a variety of downstream transductive\nmachine learning tasks, there is little principled analysis of the\neffectiveness of this approach for common tasks. In this work, we provide an\nempirical and theoretical analysis for the performance of a class of embeddings\non the common task of pairwise community labeling. This is a binary variant of\nthe classic community detection problem, which seeks to build a classifier to\ndetermine whether a pair of vertices participate in a community. In line with\nour goal of foundational understanding, we focus on a popular class of\nunsupervised embedding techniques that learn low rank factorizations of a\nvertex proximity matrix (this class includes methods like GraRep, DeepWalk,\nnode2vec, NetMF). We perform detailed empirical analysis for community labeling\nover a variety of real and synthetic graphs with ground truth. In all cases we\nstudied, the models trained from embedding features perform poorly on community\nlabeling. In constrast, a simple logistic model with classic graph structural\nfeatures handily outperforms the embedding models. For a more principled\nunderstanding, we provide a theoretical analysis for the (in)effectiveness of\nthese embeddings in capturing the community structure. We formally prove that\npopular low-dimensional factorization methods either cannot produce community\nstructure, or can only produce ``unstable\" communities. These communities are\ninherently unstable under small perturbations.",
    "descriptor": "",
    "authors": [
      "Andrew Stolman",
      "Caleb Levy",
      "C. Seshadhri",
      "Aneesh Sharma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.08481"
  },
  {
    "id": "arXiv:2201.08484",
    "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine  Decentralized Teaming",
    "abstract": "Information sharing is key in building team cognition and enables\ncoordination and cooperation. High-performing human teams also benefit from\nacting strategically with hierarchical levels of iterated communication and\nrationalizability, meaning a human agent can reason about the actions of their\nteammates in their decision-making. Yet, the majority of prior work in\nMulti-Agent Reinforcement Learning (MARL) does not support iterated\nrationalizability and only encourage inter-agent communication, resulting in a\nsuboptimal equilibrium cooperation strategy. In this work, we show that\nreformulating an agent's policy to be conditional on the policies of its\nneighboring teammates inherently maximizes Mutual Information (MI) lower-bound\nwhen optimizing under Policy Gradient (PG). Building on the idea of\ndecision-making under bounded rationality and cognitive hierarchy theory, we\nshow that our modified PG approach not only maximizes local agent rewards but\nalso implicitly reasons about MI between agents without the need for any\nexplicit ad-hoc regularization terms. Our approach, InfoPG, outperforms\nbaselines in learning emergent collaborative behaviors and sets the\nstate-of-the-art in decentralized cooperative MARL tasks. Our experiments\nvalidate the utility of InfoPG by achieving higher sample efficiency and\nsignificantly larger cumulative reward in several complex cooperative\nmulti-agent domains.",
    "descriptor": "\nComments: To be published in ICLR 2022. The first two authors contributed equally to this work\n",
    "authors": [
      "Sachin Konan",
      "Esmaeil Seraj",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.08484"
  },
  {
    "id": "arXiv:2201.08494",
    "title": "TOFU: Towards Obfuscated Federated Updates by Encoding Weight Updates  into Gradients from Proxy Data",
    "abstract": "Advances in Federated Learning and an abundance of user data have enabled\nrich collaborative learning between multiple clients, without sharing user\ndata. This is done via a central server that aggregates learning in the form of\nweight updates. However, this comes at the cost of repeated expensive\ncommunication between the clients and the server, and concerns about\ncompromised user privacy. The inversion of gradients into the data that\ngenerated them is termed data leakage. Encryption techniques can be used to\ncounter this leakage, but at added expense. To address these challenges of\ncommunication efficiency and privacy, we propose TOFU, a novel algorithm which\ngenerates proxy data that encodes the weight updates for each client in its\ngradients. Instead of weight updates, this proxy data is now shared. Since\ninput data is far lower in dimensional complexity than weights, this encoding\nallows us to send much lesser data per communication round. Additionally, the\nproxy data resembles noise, and even perfect reconstruction from data leakage\nattacks would invert the decoded gradients into unrecognizable noise, enhancing\nprivacy. We show that TOFU enables learning with less than 1% and 7% accuracy\ndrops on MNIST and on CIFAR-10 datasets, respectively. This drop can be\nrecovered via a few rounds of expensive encrypted gradient exchange. This\nenables us to learn to near-full accuracy in a federated setup, while being 4x\nand 6.6x more communication efficient than the standard Federated Averaging\nalgorithm on MNIST and CIFAR-10, respectively.",
    "descriptor": "\nComments: First two authors contributed equally to the paper\n",
    "authors": [
      "Isha Garg",
      "Manish Nagaraj",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08494"
  },
  {
    "id": "arXiv:2201.08495",
    "title": "SciBERTSUM: Extractive Summarization for Scientific Documents",
    "abstract": "The summarization literature focuses on the summarization of news articles.\nThe news articles in the CNN-DailyMail are relatively short documents with\nabout 30 sentences per document on average. We introduce SciBERTSUM, our\nsummarization framework designed for the summarization of long documents like\nscientific papers with more than 500 sentences. SciBERTSUM extends BERTSUM to\nlong documents by 1) adding a section embedding layer to include section\ninformation in the sentence vector and 2) applying a sparse attention mechanism\nwhere each sentences will attend locally to nearby sentences and only a small\nnumber of sentences attend globally to all other sentences. We used slides\ngenerated by the authors of scientific papers as reference summaries since they\ncontain the technical details from the paper. The results show the superiority\nof our model in terms of ROUGE scores.",
    "descriptor": "",
    "authors": [
      "Athar Sefid",
      "C Lee Giles"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08495"
  },
  {
    "id": "arXiv:2201.08498",
    "title": "What Makes the Recognition Problem Hard for Classes Related to Segment  and String graphs?",
    "abstract": "We explore what could make recognition of particular intersection-defined\nclasses hard. We focus mainly on unit grid intersection graphs (UGIGs), i.e.,\nintersection graphs of unit-length axis-aligned segments and grid intersection\ngraphs (GIGs, which are defined like UGIGs without unit-length restriction) and\nstring graphs, intersection graphs of arc-connected curves in a plane.\nWe show that the explored graph classes are NP-hard to recognized even when\nrestricted on graphs with arbitrarily large girth, i.e., length of a shortest\ncycle. As well, we show that the recognition of these classes remains hard even\nfor graphs with restricted degree (4, 5 and 8 depending on a particular class).\nFor UGIGs we present structural results on the size of a possible\nrepresentation, too.",
    "descriptor": "",
    "authors": [
      "Irina Mustata",
      "Martin Pergel"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.08498"
  },
  {
    "id": "arXiv:2201.08501",
    "title": "Incomplete sets in P for logspace-reduction",
    "abstract": "In this article, we investigate the behaviour of TMs with time limit and tape\nspace limit. This problem is in P when the time limit is unary coded. If both\nlimits go to infinity, it is undecidable which limit is exceeded first. Thus\nlogspace-incomplete sets in P can be constructed. This implies L $\\not=$ P.",
    "descriptor": "",
    "authors": [
      "Reiner Czerwinski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.08501"
  },
  {
    "id": "arXiv:2201.08507",
    "title": "High-Dimensional Inference over Networks: Linear Convergence and  Statistical Guarantees",
    "abstract": "We study sparse linear regression over a network of agents, modeled as an\nundirected graph and no server node. The estimation of the $s$-sparse parameter\nis formulated as a constrained LASSO problem wherein each agent owns a subset\nof the $N$ total observations. We analyze the convergence rate and statistical\nguarantees of a distributed projected gradient tracking-based algorithm under\nhigh-dimensional scaling, allowing the ambient dimension $d$ to grow with (and\npossibly exceed) the sample size $N$. Our theory shows that, under standard\nnotions of restricted strong convexity and smoothness of the loss functions,\nsuitable conditions on the network connectivity and algorithm tuning, the\ndistributed algorithm converges globally at a {\\it linear} rate to an estimate\nthat is within the centralized {\\it statistical precision} of the model,\n$O(s\\log d/N)$. When $s\\log d/N=o(1)$, a condition necessary for statistical\nconsistency, an $\\varepsilon$-optimal solution is attained after\n$\\mathcal{O}(\\kappa \\log (1/\\varepsilon))$ gradient computations and $O\n(\\kappa/(1-\\rho) \\log (1/\\varepsilon))$ communication rounds, where $\\kappa$ is\nthe restricted condition number of the loss function and $\\rho$ measures the\nnetwork connectivity. The computation cost matches that of the centralized\nprojected gradient algorithm despite having data distributed; whereas the\ncommunication rounds reduce as the network connectivity improves. Overall, our\nstudy reveals interesting connections between statistical efficiency, network\nconnectivity \\& topology, and convergence rate in high dimensions.",
    "descriptor": "\nComments: 50 pages, 7 figures\n",
    "authors": [
      "Ying Sun",
      "Marie Maros",
      "Gesualdo Scutari",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.08507"
  },
  {
    "id": "arXiv:2201.08514",
    "title": "How does unlabeled data improve generalization in self-training? A  one-hidden-layer theoretical analysis",
    "abstract": "Self-training, a semi-supervised learning algorithm, leverages a large amount\nof unlabeled data to improve learning when the labeled data are limited.\nDespite empirical successes, its theoretical characterization remains elusive.\nTo the best of our knowledge, this work establishes the first theoretical\nanalysis for the known iterative self-training paradigm and proves the benefits\nof unlabeled data in both training convergence and generalization ability. To\nmake our theoretical analysis feasible, we focus on the case of\none-hidden-layer neural networks. However, theoretical understanding of\niterative self-training is non-trivial even for a shallow neural network. One\nof the key challenges is that existing neural network landscape analysis built\nupon supervised learning no longer holds in the (semi-supervised) self-training\nparadigm. We address this challenge and prove that iterative self-training\nconverges linearly with both convergence rate and generalization accuracy\nimproved in the order of $1/\\sqrt{M}$, where $M$ is the number of unlabeled\nsamples. Experiments from shallow neural networks to deep neural networks are\nalso provided to justify the correctness of our established theoretical\ninsights on self-training.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Shuai Zhang",
      "Meng Wang",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Jinjun Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08514"
  },
  {
    "id": "arXiv:2201.08516",
    "title": "LRSVRG-IMC: An SVRG-Based Algorithm for LowRank Inductive Matrix  Completion",
    "abstract": "Low-rank inductive matrix completion (IMC) is currently widely used in IoT\ndata completion, recommendation systems, and so on, as the side information in\nIMC has demonstrated great potential in reducing sample point remains a major\nobstacle for the convergence of the nonconvex solutions to IMC. What's more,\ncarefully choosing the initial solution alone does not usually help remove the\nsaddle points. To address this problem, we propose a stocastic variance\nreduction gradient-based algorithm called LRSVRG-IMC. LRSVRG-IMC can escape\nfrom the saddle points under various low-rank and sparse conditions with a\nproperly chosen initial input. We also prove that LRSVVRG-IMC achieves both a\nlinear convergence rate and a near-optimal sample complexity. The superiority\nand applicability of LRSVRG-IMC are verified via experiments on synthetic\ndatasets.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Shangrong Yu",
      "Yuxin Chen",
      "Hejun Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08516"
  },
  {
    "id": "arXiv:2201.08517",
    "title": "Unmanned Aerial Vehicle Swarm-Enabled Edge Computing: Potentials,  Promising Technologies, and Challenges",
    "abstract": "Unmanned aerial vehicle (UAV) swarm enabled edge computing is envisioned to\nbe promising in the sixth generation wireless communication networks due to\ntheir wide application sensories and flexible deployment. However, most of the\nexisting works focus on edge computing enabled by a single or a small scale\nUAVs, which are very different from UAV swarm-enabled edge computing. In order\nto facilitate the practical applications of UAV swarm-enabled edge computing,\nthe state of the art research is presented in this article. The potential\napplications, architectures and implementation considerations are illustrated.\nMoreover, the promising enabling technologies for UAV swarm-enabled edge\ncomputing are discussed. Furthermore, we outline challenges and open issues in\norder to shed light on the future research directions.",
    "descriptor": "\nComments: 17 pages, 5 figures, to be published in IEEE Wireless Communications Magazine\n",
    "authors": [
      "Wei Wu",
      "Fuhui Zhou",
      "Baoyun Wang",
      "Qihui Wu",
      "Chao Dong",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08517"
  },
  {
    "id": "arXiv:2201.08520",
    "title": "Learning Two-Step Hybrid Policy for Graph-Based Interpretable  Reinforcement Learning",
    "abstract": "We present a two-step hybrid reinforcement learning (RL) policy that is\ndesigned to generate interpretable and robust hierarchical policies on the RL\nproblem with graph-based input. Unlike prior deep reinforcement learning\npolicies parameterized by an end-to-end black-box graph neural network, our\napproach disentangles the decision-making process into two steps. The first\nstep is a simplified classification problem that maps the graph input to an\naction group where all actions share a similar semantic meaning. The second\nstep implements a sophisticated rule-miner that conducts explicit one-hop\nreasoning over the graph and identifies decisive edges in the graph input\nwithout the necessity of heavy domain knowledge. This two-step hybrid policy\npresents human-friendly interpretations and achieves better performance in\nterms of generalization and robustness. Extensive experimental studies on four\nlevels of complex text-based games have demonstrated the superiority of the\nproposed method compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Tongzhou Mu",
      "Kaixiang Lin",
      "Feiyang Niu",
      "Govind Thattai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08520"
  },
  {
    "id": "arXiv:2201.08522",
    "title": "Orthonormal Sketches for Secure Coded Regression}",
    "abstract": "In this work, we propose a method for speeding up linear regression\ndistributively, while ensuring security. We leverage randomized sketching\ntechniques, and improve straggler resilience in asynchronous systems.\nSpecifically, we apply a random orthonormal matrix and then subsample in\n\\textit{blocks}, to simultaneously secure the information and reduce the\ndimension of the regression problem. In our setup, the transformation\ncorresponds to an encoded encryption in an \\textit{approximate} gradient coding\nscheme, and the subsampling corresponds to the responses of the non-straggling\nworkers; in a centralized coded computing network. We focus on the special case\nof the \\textit{Subsampled Randomized Hadamard Transform}, which we generalize\nto block sampling; and discuss how it can be used to secure the data. We\nillustrate the performance through numerical experiments.",
    "descriptor": "\nComments: 3 figures, 5 pages excluding appendices\n",
    "authors": [
      "Neophytos Charalambides",
      "Hessam Mahdavifar",
      "Mert Pilanci",
      "Alfred O. Hero III"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08522"
  },
  {
    "id": "arXiv:2201.08526",
    "title": "Can Machines Generate Personalized Music? A Hybrid Favorite-aware Method  for User Preference Music Transfer",
    "abstract": "User preference music transfer (UPMT) is a new problem in music style\ntransfer that can be applied to many scenarios but remains understudied.",
    "descriptor": "",
    "authors": [
      "Zhejing Hu",
      "Yan Liu",
      "Gong Chen",
      "Yongxu Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.08526"
  },
  {
    "id": "arXiv:2201.08528",
    "title": "To SMOTE, or not to SMOTE?",
    "abstract": "In imbalanced binary classification problems the objective metric is often\nnon-symmetric and associates a higher penalty with the minority samples. On the\nother hand, the loss function used for training is usually symmetric - equally\npenalizing majority and minority samples. Balancing schemes, that augment the\ndata to be more balanced before training the model, were proposed to address\nthis discrepancy and were shown to improve prediction performance empirically\non tabular data. However, recent studies of consistent classifiers suggest that\nthe metric discrepancy might not hinder prediction performance. In light of\nthese recent theoretical results, we carefully revisit the empirical study of\nbalancing tabular data. Our extensive experiments, on 73 datasets, show that\ngenerally, in accordance with theory, best prediction is achieved by using a\nstrong consistent classifier and balancing is not beneficial. We further\nidentity several scenarios for which balancing is effective and observe that\nprior studies mainly focus on these settings.",
    "descriptor": "",
    "authors": [
      "Yotam Elor",
      "Hadar Elor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08528"
  },
  {
    "id": "arXiv:2201.08531",
    "title": "Black-box Prompt Learning for Pre-trained Language Models",
    "abstract": "Domain-specific fine-tuning strategies for large pre-trained models received\nvast attention in recent years. In previously studied settings, the model\narchitectures and parameters are tunable or at least visible, which we refer to\nas white-box settings. This work considers a new scenario, where we do not have\naccess to a pre-trained model, except for its outputs given inputs, and we call\nthis problem black-box fine-tuning. To illustrate our approach, we first\nintroduce the black-box setting formally on text classification, where the\npre-trained model is not only frozen but also invisible. We then propose our\nsolution black-box prompt, a new technique in the prompt-learning family, which\ncan leverage the knowledge learned by pre-trained models from the pre-training\ncorpus. Our experiments demonstrate that the proposed method achieved the\nstate-of-the-art performance on eight datasets. Further analyses on different\nhuman-designed objectives, prompt lengths, and intuitive explanations\ndemonstrate the robustness and flexibility of our method.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Shizhe Diao",
      "Xuechun Li",
      "Yong Lin",
      "Zhichao Huang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08531"
  },
  {
    "id": "arXiv:2201.08538",
    "title": "Computation of Regions of Attraction for Hybrid Limit Cycles Using  Reachability: An Application to Walking Robots",
    "abstract": "Contact-rich robotic systems, such as legged robots and manipulators, are\noften represented as hybrid systems. However, the stability analysis and\nregion-of-attraction computation for these systems are often challenging\nbecause of the discontinuous state changes upon contact (also referred to as\nstate resets). In this work, we cast the computation of region-ofattraction as\na Hamilton-Jacobi (HJ) reachability problem. This enables us to leverage HJ\nreachability tools that are compatible with general nonlinear system dynamics,\nand can formally deal with state and input constraints as well as bounded\ndisturbances. Our main contribution is the generalization of HJ reachability\nframework to account for the discontinuous state changes originating from state\nresets, which has remained a challenge until now. We apply our approach for\ncomputing region-of-attractions for several underactuated walking robots and\ndemonstrate that the proposed approach can (a) recover a bigger\nregion-of-attraction than state-of-the-art approaches, (b) handle state resets,\nnonlinear dynamics, external disturbances, and input constraints, and (c) also\nprovides a stabilizing controller for the system that can leverage the state\nresets for enhancing system stability.",
    "descriptor": "\nComments: Submitted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Jason J. Choi",
      "Ayush Agrawal",
      "Koushil Sreenath",
      "Claire J. Tomlin",
      "Somil Bansal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08538"
  },
  {
    "id": "arXiv:2201.08539",
    "title": "AutoDistill: an End-to-End Framework to Explore and Distill  Hardware-Efficient Language Models",
    "abstract": "Recently, large pre-trained models have significantly improved the\nperformance of various Natural LanguageProcessing (NLP) tasks but they are\nexpensive to serve due to long serving latency and large memory usage. To\ncompress these models, knowledge distillation has attracted an increasing\namount of interest as one of the most effective methods for model compression.\nHowever, existing distillation methods have not yet addressed the unique\nchallenges of model serving in datacenters, such as handling fast evolving\nmodels, considering serving performance, and optimizing for multiple\nobjectives. To solve these problems, we propose AutoDistill, an end-to-end\nmodel distillation framework integrating model architecture exploration and\nmulti-objective optimization for building hardware-efficient NLP pre-trained\nmodels. We use Bayesian Optimization to conduct multi-objective Neural\nArchitecture Search for selecting student model architectures. The proposed\nsearch comprehensively considers both prediction accuracy and serving latency\non target hardware. The experiments on TPUv4i show the finding of seven model\narchitectures with better pre-trained accuracy (up to 3.2% higher) and lower\ninference latency (up to 1.44x faster) than MobileBERT. By running downstream\nNLP tasks in the GLUE benchmark, the model distilled for pre-training by\nAutoDistill with 28.5M parameters achieves an 81.69 average score, which is\nhigher than BERT_BASE, DistillBERT, TinyBERT, NAS-BERT, and MobileBERT. The\nmost compact model found by AutoDistill contains only 20.6M parameters but\nstill outperform BERT_BASE(109M), DistillBERT(67M), TinyBERT(67M), and\nMobileBERT(25.3M) regarding the average GLUE score. By evaluating on SQuAD, a\nmodel found by AutoDistill achieves an 88.4% F1 score with 22.8M parameters,\nwhich reduces parameters by more than 62% while maintaining higher accuracy\nthan DistillBERT, TinyBERT, and NAS-BERT.",
    "descriptor": "",
    "authors": [
      "Xiaofan Zhang",
      "Zongwei Zhou",
      "Deming Chen",
      "Yu Emma Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08539"
  },
  {
    "id": "arXiv:2201.08542",
    "title": "Can Model Compression Improve NLP Fairness",
    "abstract": "Model compression techniques are receiving increasing attention; however, the\neffect of compression on model fairness is still under explored. This is the\nfirst paper to examine the effect of distillation and pruning on the toxicity\nand bias of generative language models. We test Knowledge Distillation and\nPruning methods on the GPT2 model and found a consistent pattern of toxicity\nand bias reduction after model distillation; this result can be potentially\ninterpreted by existing line of research which describes model compression as a\nregularization technique; our work not only serves as a reference for safe\ndeployment of compressed models, but also extends the discussion of\n\"compression as regularization\" into the setting of neural LMs, and hints at\nthe possibility of using compression to develop fairer models.",
    "descriptor": "",
    "authors": [
      "Guangxuan Xu",
      "Qingyuan Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08542"
  },
  {
    "id": "arXiv:2201.08548",
    "title": "Classification and count of binary linear complementary dual group codes",
    "abstract": "We establish a complete classification of binary group codes with\ncomplementary duals for a finite group and explicitly determine the number of\nlinear complementary dual (LCD) cyclic group codes by using cyclotomic cosets.\nThe dimension and the minimum distance for LCD group codes are explored.\nFinally, we find a connection between LCD MDS group codes and maximal ideals.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ankan Shaw",
      "Sanjit Bhowmick",
      "Satya Bagchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2201.08548"
  },
  {
    "id": "arXiv:2201.08549",
    "title": "Fair Node Representation Learning via Adaptive Data Augmentation",
    "abstract": "Node representation learning has demonstrated its efficacy for various\napplications on graphs, which leads to increasing attention towards the area.\nHowever, fairness is a largely under-explored territory within the field, which\nmay lead to biased results towards underrepresented groups in ensuing tasks. To\nthis end, this work theoretically explains the sources of bias in node\nrepresentations obtained via Graph Neural Networks (GNNs). Our analysis reveals\nthat both nodal features and graph structure lead to bias in the obtained\nrepresentations. Building upon the analysis, fairness-aware data augmentation\nframeworks on nodal features and graph structure are developed to reduce the\nintrinsic bias. Our analysis and proposed schemes can be readily employed to\nenhance the fairness of various GNN-based learning mechanisms. Extensive\nexperiments on node classification and link prediction are carried out over\nreal networks in the context of graph contrastive learning. Comparison with\nmultiple benchmarks demonstrates that the proposed augmentation strategies can\nimprove fairness in terms of statistical parity and equal opportunity, while\nproviding comparable utility to state-of-the-art contrastive methods.",
    "descriptor": "\nComments: 25 pages, 4 figures, 16 tables\n",
    "authors": [
      "O. Deniz Kose",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08549"
  },
  {
    "id": "arXiv:2201.08550",
    "title": "What Can Machine Vision Do for Lymphatic Histopathology Image Analysis:  A Comprehensive Review",
    "abstract": "In the past ten years, the computing power of machine vision (MV) has been\ncontinuously improved, and image analysis algorithms have developed rapidly. At\nthe same time, histopathological slices can be stored as digital images.\nTherefore, MV algorithms can provide doctors with diagnostic references. In\nparticular, the continuous improvement of deep learning algorithms has further\nimproved the accuracy of MV in disease detection and diagnosis. This paper\nreviews the applications of image processing technology based on MV in lymphoma\nhistopathological images in recent years, including segmentation,\nclassification and detection. Finally, the current methods are analyzed, some\nmore potential methods are proposed, and further prospects are made.",
    "descriptor": "",
    "authors": [
      "Xiaoqi Li",
      "Haoyuan Chen",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Xintong Li",
      "Jian Wu",
      "Xiaoyan Li",
      "Hongzan Sun",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08550"
  },
  {
    "id": "arXiv:2201.08551",
    "title": "Blockchain-based Collaborated Federated Learning for Improved Security,  Privacy and Reliability",
    "abstract": "Federated Learning (FL) provides privacy preservation by allowing the model\ntraining at edge devices without the need of sending the data from edge to a\ncentralized server. FL has distributed the implementation of ML. Another\nvariant of FL which is well suited for the Internet of Things (IoT) is known as\nCollaborated Federated Learning (CFL), which does not require an edge device to\nhave a direct link to the model aggregator. Instead, the devices can connect to\nthe central model aggregator via other devices using them as relays. Although,\nFL and CFL protect the privacy of edge devices but raises security challenges\nfor a centralized server that performs model aggregation. The centralized\nserver is prone to malfunction, backdoor attacks, model corruption, adversarial\nattacks and external attacks. Moreover, edge device to centralized server data\nexchange is not required in FL and CFL, but model parameters are sent from the\nmodel aggregator (global model) to edge devices (local model), which is still\nprone to cyber-attacks. These security and privacy concerns can be potentially\naddressed by Blockchain technology. The blockchain is a decentralized and\nconsensus-based chain where devices can share consensus ledgers with increased\nreliability and security, thus significantly reducing the cyberattacks on an\nexchange of information. In this work, we will investigate the efficacy of\nblockchain-based decentralized exchange of model parameters and relevant\ninformation among edge devices and from a centralized server to edge devices.\nMoreover, we will be conducting the feasibility analysis for blockchain-based\nCFL models for different application scenarios like the internet of vehicles,\nand the internet of things. The proposed study aims to improve the security,\nreliability and privacy preservation by the use of blockchain-powered CFL.",
    "descriptor": "\nComments: Preliminary work\n",
    "authors": [
      "Amir Afaq",
      "Zeeshan Ahmed",
      "Noman Haider",
      "Muhammad Imran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.08551"
  },
  {
    "id": "arXiv:2201.08552",
    "title": "The Collector, the Glitcher, and the Denkbilder: Towards a Critical  Aesthetic Theory of Video Games",
    "abstract": "To examine the aesthetics of video games, this paper proposes to consider\nvideo games as a contemporary multi-media version of the so-called \"Denkbild,\"\nor \"thought-image,\" an experimental genre of philosophical writing employed by\nmembers of the Frankfurt School. A poetic mode of writing, the Denkbild takes\nliterary snapshots of philosophical, political, and cultural insights that\ninterrupt and challenge the enigmatic form of traditional philosophical\nthinking. Thinking of video games through the lens of the Denkbild allows us to\nunderstand the diversity, conditionality, and incommensurability of video game\nas a form without reducing it to separate pieces to be examined within their\nrespective disciplines too quickly. By presenting two snapshots of video game\nplayers, the collector and the glitcher, this paper argues that the concept of\nDenkbild allows us to better understand the relationships between game, gamers,\nand the socio-political context in terms of unexpected bonds, accidental\nbreakthroughs, and moments of absolute freedom.",
    "descriptor": "",
    "authors": [
      "Jan Cao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08552"
  },
  {
    "id": "arXiv:2201.08554",
    "title": "Enhancing Hyperbolic Graph Embeddings via Contrastive Learning",
    "abstract": "Recently, hyperbolic space has risen as a promising alternative for\nsemi-supervised graph representation learning. Many efforts have been made to\ndesign hyperbolic versions of neural network operations. However, the inspiring\ngeometric properties of this unique geometry have not been fully explored yet.\nThe potency of graph models powered by the hyperbolic space is still largely\nunderestimated. Besides, the rich information carried by abundant unlabelled\nsamples is also not well utilized. Inspired by the recently active and emerging\nself-supervised learning, in this study, we attempt to enhance the\nrepresentation power of hyperbolic graph models by drawing upon the advantages\nof contrastive learning. More specifically, we put forward a novel Hyperbolic\nGraph Contrastive Learning (HGCL) framework which learns node representations\nthrough multiple hyperbolic spaces to implicitly capture the hierarchical\nstructure shared between different views. Then, we design a hyperbolic position\nconsistency (HPC) constraint based on hyperbolic distance and the homophily\nassumption to make contrastive learning fit into hyperbolic space. Experimental\nresults on multiple real-world datasets demonstrate the superiority of the\nproposed HGCL as it consistently outperforms competing methods by considerable\nmargins for the node classification task.",
    "descriptor": "\nComments: Accepted by NeurIPS'21@2nd Workshop on Self-Supervised Learning\n",
    "authors": [
      "Jiahong Liu",
      "Menglin Yang",
      "Min Zhou",
      "Shanshan Feng",
      "Philippe Fournier-Viger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08554"
  },
  {
    "id": "arXiv:2201.08555",
    "title": "Identifying Adversarial Attacks on Text Classifiers",
    "abstract": "The landscape of adversarial attacks against text classifiers continues to\ngrow, with new attacks developed every year and many of them available in\nstandard toolkits, such as TextAttack and OpenAttack. In response, there is a\ngrowing body of work on robust learning, which reduces vulnerability to these\nattacks, though sometimes at a high cost in compute time or accuracy. In this\npaper, we take an alternate approach -- we attempt to understand the attacker\nby analyzing adversarial text to determine which methods were used to create\nit. Our first contribution is an extensive dataset for attack detection and\nlabeling: 1.5~million attack instances, generated by twelve adversarial attacks\ntargeting three classifiers trained on six source datasets for sentiment\nanalysis and abuse detection in English. As our second contribution, we use\nthis dataset to develop and benchmark a number of classifiers for attack\nidentification -- determining if a given text has been adversarially\nmanipulated and by which attack. As a third contribution, we demonstrate the\neffectiveness of three classes of features for these tasks: text properties,\ncapturing content and presentation of text; language model properties,\ndetermining which tokens are more or less probable throughout the input; and\ntarget model properties, representing how the text classifier is influenced by\nthe attack, including internal node activations. Overall, this represents a\nfirst step towards forensics for adversarial attacks against text classifiers.",
    "descriptor": "",
    "authors": [
      "Zhouhang Xie",
      "Jonathan Brophy",
      "Adam Noack",
      "Wencong You",
      "Kalyani Asthana",
      "Carter Perkins",
      "Sabrina Reis",
      "Sameer Singh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08555"
  },
  {
    "id": "arXiv:2201.08557",
    "title": "Robust Unsupervised Graph Representation Learning via Mutual Information  Maximization",
    "abstract": "Recent studies have shown that GNNs are vulnerable to adversarial attack.\nThus, many approaches are proposed to improve the robustness of GNNs against\nadversarial attacks. Nevertheless, most of these methods measure the model\nrobustness based on label information and thus become infeasible when labels\ninformation is not available. Therefore, this paper focuses on robust\nunsupervised graph representation learning. In particular, to quantify the\nrobustness of GNNs without label information, we propose a robustness measure,\nnamed graph representation robustness (GRR), to evaluate the mutual information\nbetween adversarially perturbed node representations and the original graph.\nThere are mainly two challenges to estimate GRR: 1) mutual information\nestimation upon adversarially attacked graphs; 2) high complexity of\nadversarial attack to perturb node features and graph structure jointly in the\ntraining procedure. To tackle these problems, we further propose an effective\nmutual information estimator with subgraph-level summary and an efficient\nadversarial training strategy with only feature perturbations. Moreover, we\ntheoretically establish a connection between our proposed GRR measure and the\nrobustness of downstream classifiers, which reveals that GRR can provide a\nlower bound to the adversarial risk of downstream classifiers. Extensive\nexperiments over several benchmarks demonstrate the effectiveness and\nsuperiority of our proposed method.",
    "descriptor": "",
    "authors": [
      "Jihong Wang",
      "Minnan Luo",
      "Jundong Li",
      "Ziqi Liu",
      "Jun Zhou",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08557"
  },
  {
    "id": "arXiv:2201.08558",
    "title": "RHONN Modelling-enabled Nonlinear Predictive Control for Lateral  Dynamics Stabilization of An In-wheel Motor Driven Vehicle",
    "abstract": "Featuring the fast response and flexibility in control allocation, an\nelectric vehicle with in-wheel motors is a good platform for implementing\nadvanced vehicle dynamics control. Among many active safety functions of an\nin-wheel motor driven vehicle (IMDV), lateral stability control is a key\ntechnology, which can be realized through torque vectoring. To further advance\nthe lateral stabilization performance of the IMDV, in this paper a novel\ndata-driven nonlinear model predictive control (NMPC) is proposed based the\nrecurrent high-order neural network (RHONN) modelling method. First, the new\nRHONN model is developed to represent vehicle's nonlinear dynamic behaviors.\nDifferent from the conventional physics-based modelling method, the RHONN model\nonly needs data and forms high-order polynomials. Based on the RHONN model, the\nsteady-state responses of vehicle's yaw rate and sideslip angle are iteratively\noptimized and set as the control objectives for low-level controller, aiming to\nimprove the system robustness. Besides, a nonlinear model predictive controller\nis designed based on the RHONN, which is expected to improve the prediction\naccuracy during the receding horizon control. Further, a constrained\noptimization problem is formulated to derive the required yaw moment for\nvehicle lateral dynamics stabilization. Finally, the performance of the\ndeveloped RHONN-based nonlinear MPC is validated on an IMDV in the\nCarSim/Simulink simulation environment. The validation results show that the\ndeveloped approach outperforms the conventional method, and further improves\nthe stable margin of the system. It is able to enhance the lateral\nstabilization performance of the IMDV under various driving scenarios,\ndemonstrating the feasibility and effectiveness of the proposed approach.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Hao Chen",
      "Junzhi Zhang",
      "Chen Lv"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08558"
  },
  {
    "id": "arXiv:2201.08559",
    "title": "Individual Treatment Effect Estimation Through Controlled Neural Network  Training in Two Stages",
    "abstract": "We develop a Causal-Deep Neural Network (CDNN) model trained in two stages to\ninfer causal impact estimates at an individual unit level. Using only the\npre-treatment features in stage 1 in the absence of any treatment information,\nwe learn an encoding for the covariates that best represents the outcome. In\nthe $2^{nd}$ stage we further seek to predict the unexplained outcome from\nstage 1, by introducing the treatment indicator variables alongside the encoded\ncovariates. We prove that even without explicitly computing the treatment\nresidual, our method still satisfies the desirable local Neyman orthogonality,\nmaking it robust to small perturbations in the nuisance parameters.\nFurthermore, by establishing connections with the representation learning\napproaches, we create a framework from which multiple variants of our algorithm\ncan be derived. We perform initial experiments on the publicly available data\nsets to compare these variants and get guidance in selecting the best variant\nof our CDNN method. On evaluating CDNN against the state-of-the-art approaches\non three benchmarking datasets, we observe that CDNN is highly competitive and\noften yields the most accurate individual treatment effect estimates. We\nhighlight the strong merits of CDNN in terms of its extensibility to multiple\nuse cases.",
    "descriptor": "",
    "authors": [
      "Naveen Nair",
      "Karthik S. Gurumoorthy",
      "Dinesh Mandalapu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08559"
  },
  {
    "id": "arXiv:2201.08560",
    "title": "Bit-GraphBLAS: Bit-Level Optimizations of Matrix-Centric Graph  Processing on GPU",
    "abstract": "In a general graph data structure like an adjacency matrix, when edges are\nhomogeneous, the connectivity of two nodes can be sufficiently represented\nusing a single bit. This insight has, however, not yet been adequately\nexploited by the existing matrix-centric graph processing frameworks. This work\nfills the void by systematically exploring the bit-level representation of\ngraphs and the corresponding optimizations to the graph operations. It proposes\na two-level representation named Bit-Block Compressed Sparse Row (B2SR) and\npresents a series of optimizations to the graph operations on B2SR by\nleveraging the intrinsics of modern GPUs. Evaluations on NVIDIA Pascal and\nVolta GPUs show that the optimizations bring up to $40\\times$ and $6555\\times$\nfor essential GraphBLAS kernels SpMV and SpGEMM, respectively, making\nGraphBLAS-based BFS accelerate up to $433\\times$, SSSP, PR, and CC up to\n$35\\times$, and TC up to $52\\times$.",
    "descriptor": "\nComments: To appear in 36th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2022)\n",
    "authors": [
      "Jou-An Chen",
      "Hsin-Hsuan Sung",
      "Nathan Tallent",
      "Kevin Barker",
      "Xipeng Shen",
      "Ang Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.08560"
  },
  {
    "id": "arXiv:2201.08561",
    "title": "A convergent numerical scheme to a parabolic equation with a nonlocal  boundary condition",
    "abstract": "In this paper, a numerical scheme for a nonlinear McKendrick-von Foerster\nequation with diffusion in age (MV-D) with the Dirichlet boundary condition is\nproposed. The main idea to derive the scheme is to use the discretization based\non the method of characteristics to the convection part, and the finite\ndifference method to the rest of the terms. The nonlocal terms are dealt with\nthe quadrature methods. As a result, an implicit scheme is obtained for the\nboundary value problem under consideration. The consistency and the convergence\nof the proposed numerical scheme is established. Moreover, numerical\nsimulations are presented to validate the theoretical results.",
    "descriptor": "\nComments: 18 pages, 5 figure files\n",
    "authors": [
      "Bhargav Kumar Kakumani",
      "Suman Kumar Tumuluri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08561"
  },
  {
    "id": "arXiv:2201.08564",
    "title": "Hold On and Swipe: A Touch-Movement Based Continuous Authentication  Schema based on Machine Learning",
    "abstract": "In recent years the amount of secure information being stored on mobile\ndevices has grown exponentially. However, current security schemas for mobile\ndevices such as physiological biometrics and passwords are not secure enough to\nprotect this information. Behavioral biometrics have been heavily researched as\na possible solution to this security deficiency for mobile devices. This study\naims to contribute to this innovative research by evaluating the performance of\na multimodal behavioral biometric based user authentication scheme using touch\ndynamics and phone movement. This study uses a fusion of two popular publicly\navailable datasets the Hand Movement Orientation and Grasp dataset and the\nBioIdent dataset. This study evaluates our model performance using three common\nmachine learning algorithms which are Random Forest Support Vector Machine and\nK-Nearest Neighbor reaching accuracy rates as high as 82% with each algorithm\nperforming respectively for all success metrics reported.",
    "descriptor": "",
    "authors": [
      "Rushit Dave",
      "Naeem Seliya",
      "Laura Pryor",
      "Mounika Vanamala",
      "Evelyn Sowells",
      "Jacob mallet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08564"
  },
  {
    "id": "arXiv:2201.08565",
    "title": "Human Activity Recognition models using Limited Consumer Device Sensors  and Machine Learning",
    "abstract": "Human activity recognition has grown in popularity with its increase of\napplications within daily lifestyles and medical environments. The goal of\nhaving efficient and reliable human activity recognition brings benefits such\nas accessible use and better allocation of resources; especially in the medical\nindustry. Activity recognition and classification can be obtained using many\nsophisticated data recording setups, but there is also a need in observing how\nperformance varies among models that are strictly limited to using sensor data\nfrom easily accessible devices: smartphones and smartwatches. This paper\npresents the findings of different models that are limited to train using such\nsensors. The models are trained using either the k-Nearest Neighbor, Support\nVector Machine, or Random Forest classifier algorithms. Performance and\nevaluations are done by comparing various model performances using different\ncombinations of mobile sensors and how they affect recognitive performances of\nmodels. Results show promise for models trained strictly using limited sensor\ndata collected from only smartphones and smartwatches coupled with traditional\nmachine learning concepts and algorithms.",
    "descriptor": "",
    "authors": [
      "Rushit Dave",
      "Naeem Seliya",
      "Mounika Vanamala",
      "Wei Tee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08565"
  },
  {
    "id": "arXiv:2201.08570",
    "title": "An empirical study on Java method name suggestion: are we there yet?",
    "abstract": "A large-scale evaluation for current naming approaches substantiates that\nsuch approaches are accurate. However, it is less known about which categories\nof method names work well via such naming approaches and how's the performance\nof naming approaches. To point out the superiority of the current naming\napproach, in this paper, we conduct an empirical study on such approaches in a\nnew dataset. Moreover, we analyze the successful naming approaches above and\nfind that: (1) around 60% of the accepted recommendation names are made on\nprefixes within get, set, is, and test. (2) A large portion (19.3%) of method\nnames successfully recommended could be derived from the given method bodies.\nThe comparisons also demonstrate the superior performance of the empirical\nstudy.",
    "descriptor": "",
    "authors": [
      "Weidong Wang",
      "Yujian Kang",
      "Dian Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08570"
  },
  {
    "id": "arXiv:2201.08571",
    "title": "A Sequential Discontinuous Galerkin Method for Two-Phase Flow in  Deformable Porous Media",
    "abstract": "We formulate a numerical method for solving the two-phase flow poroelasticity\nequations. The scheme employs the interior penalty discontinuous Galerkin\nmethod and a sequential time-stepping method. The unknowns are the phase\npressures and the displacement. Existence of the solution is proved.\nThree-dimensional numerical results show the accuracy and robustness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Boqian Shen",
      "Beatrice Riviere"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08571"
  },
  {
    "id": "arXiv:2201.08574",
    "title": "Classroom Slide Narration System",
    "abstract": "Slide presentations are an effective and efficient tool used by the teaching\ncommunity for classroom communication. However, this teaching model can be\nchallenging for blind and visually impaired (VI) students. The VI student\nrequired personal human assistance for understand the presented slide. This\nshortcoming motivates us to design a Classroom Slide Narration System (CSNS)\nthat generates audio descriptions corresponding to the slide content. This\nproblem poses as an image-to-markup language generation task. The initial step\nis to extract logical regions such as title, text, equation, figure, and table\nfrom the slide image. In the classroom slide images, the logical regions are\ndistributed based on the location of the image. To utilize the location of the\nlogical regions for slide image segmentation, we propose the architecture,\nClassroom Slide Segmentation Network (CSSN). The unique attributes of this\narchitecture differs from most other semantic segmentation networks. Publicly\navailable benchmark datasets such as WiSe and SPaSe are used to validate the\nperformance of our segmentation architecture. We obtained 9.54 segmentation\naccuracy improvement in WiSe dataset. We extract content (information) from the\nslide using four well-established modules such as optical character recognition\n(OCR), figure classification, equation description, and table structure\nrecognizer. With this information, we build a Classroom Slide Narration System\n(CSNS) to help VI students understand the slide content. The users have given\nbetter feedback on the quality output of the proposed CSNS in comparison to\nexisting systems like Facebooks Automatic Alt-Text (AAT) and Tesseract.",
    "descriptor": "",
    "authors": [
      "Jobin K.V.",
      "Ajoy Mondal",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.08574"
  },
  {
    "id": "arXiv:2201.08580",
    "title": "Trustworthy Knowledge Graph Completion Based on Multi-sourced Noisy Data",
    "abstract": "Knowledge graphs (KGs) have become a valuable asset for many AI applications.\nAlthough some KGs contain plenty of facts, they are widely acknowledged as\nincomplete. To address this issue, many KG completion methods are proposed.\nAmong them, open KG completion methods leverage the Web to find missing facts.\nHowever, noisy data collected from diverse sources may damage the completion\naccuracy. In this paper, we propose a new trustworthy method that exploits\nfacts for a KG based on multi-sourced noisy data and existing facts in the KG.\nSpecifically, we introduce a graph neural network with a holistic scoring\nfunction to judge the plausibility of facts with various value types. We design\nvalue alignment networks to resolve the heterogeneity between values and map\nthem to entities even outside the KG. Furthermore, we present a truth inference\nmodel that incorporates data source qualities into the fact scoring function,\nand design a semi-supervised learning way to infer the truths from\nheterogeneous values. We conduct extensive experiments to compare our method\nwith the state-of-the-arts. The results show that our method achieves superior\naccuracy not only in completing missing facts but also in discovering new\nfacts.",
    "descriptor": "\nComments: Accepted in the ACM Web Conference (WWW 2022)\n",
    "authors": [
      "Jiacheng Huang",
      "Yao Zhao",
      "Wei Hu",
      "Zhen Ning",
      "Qijin Chen",
      "Xiaoxia Qiu",
      "Chengfu Huo",
      "Weijun Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.08580"
  },
  {
    "id": "arXiv:2201.08598",
    "title": "Taxonomy Enrichment with Text and Graph Vector Representations",
    "abstract": "Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a\ntaxonomic backbone that allows the arrangement and structuring of various\nconcepts in accordance with the hypo-hypernym (\"class-subclass\") relationship.\nWith the rapid growth of lexical resources for specific domains, the problem of\nautomatic extension of the existing knowledge bases with new words is becoming\nmore and more widespread. In this paper, we address the problem of taxonomy\nenrichment which aims at adding new words to the existing taxonomy.\nWe present a new method that allows achieving high results on this task with\nlittle effort. It uses the resources which exist for the majority of languages,\nmaking the method universal. We extend our method by incorporating deep\nrepresentations of graph structures like node2vec, Poincar\\'e embeddings, GCN\netc. that have recently demonstrated promising results on various NLP tasks.\nFurthermore, combining these representations with word embeddings allows us to\nbeat the state of the art.\nWe conduct a comprehensive study of the existing approaches to taxonomy\nenrichment based on word and graph vector representations and their fusion\napproaches. We also explore the ways of using deep learning architectures to\nextend the taxonomic backbones of knowledge graphs. We create a number of\ndatasets for taxonomy extension for English and Russian. We achieve\nstate-of-the-art results across different datasets and provide an in-depth\nerror analysis of mistakes.",
    "descriptor": "",
    "authors": [
      "Irina Nikishina",
      "Mikhail Tikhomirov",
      "Varvara Logacheva",
      "Yuriy Nazarov",
      "Alexander Panchenko",
      "Natalia Loukachevitch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08598"
  },
  {
    "id": "arXiv:2201.08603",
    "title": "Trireme: Exploring Hierarchical Multi-Level Parallelism for Domain  Specific Hardware Acceleration",
    "abstract": "The design of heterogeneous systems that include domain specific accelerators\nis a challenging and time-consuming process. While taking into account area\nconstraints, designers must decide which parts of an application to accelerate\nin hardware and which to leave in software. Moreover, applications in domains\nsuch as Extended Reality (XR) offer opportunities for various forms of parallel\nexecution, including loop level, task level and pipeline parallelism. To assist\nthe design process and expose every possible level of parallelism, we present\nTrireme, a fully automated tool-chain that explores multiple levels of\nparallelism and produces domain specific accelerator designs and configurations\nthat maximize performance, given an area budget. Experiments on demanding\nbenchmarks from the XR domain revealed a speedup of up to 20x, as well as a\nspeedup of up to 37x for smaller applications, compared to software-only\nimplementations.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Georgios Zacharopoulos",
      "Adel Ejjeh",
      "Ying Jing",
      "En-Yu Yang",
      "Tianyu Jia",
      "Iulian Brumar",
      "Jeremy Intan",
      "Muhammad Huzaifa",
      "Sarita Adve",
      "Vikram Adve",
      "Gu-Yeon Wei",
      "David Brooks"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.08603"
  },
  {
    "id": "arXiv:2201.08605",
    "title": "Seamless and Energy Efficient Maritime Coverage in Coordinated 6G  Space-Air-Sea Non-Terrestrial Networks",
    "abstract": "Non-terrestrial networks (NTNs), which integrate space and aerial networks\nwith terrestrial systems, are a key area in the emerging sixth-generation (6G)\nwireless networks. As part of 6G, NTNs must provide pervasive connectivity to a\nwide range of devices, including smartphones, vehicles, sensors, robots, and\nmaritime users. However, due to the high mobility and deployment of NTNs,\nmanaging the space-air-sea (SAS) NTN resources, i.e., energy, power, and\nchannel allocation, is a major challenge. The design of a SAS-NTN for\nenergy-efficient resource allocation is investigated in this study. The goal is\nto maximize system energy efficiency (EE) by collaboratively optimizing user\nequipment (UE) association, power control, and unmanned aerial vehicle (UAV)\ndeployment. Given the limited payloads of UAVs, this work focuses on minimizing\nthe total energy cost of UAVs (trajectory and transmission) while meeting EE\nrequirements. A mixed-integer nonlinear programming problem is proposed,\nfollowed by the development of an algorithm to decompose, and solve each\nproblem distributedly. The binary (UE association) and continuous (power,\ndeployment) variables are separated using the Bender decomposition (BD), and\nthen the Dinkelbach algorithm (DA) is used to convert fractional programming\ninto an equivalent solvable form in the subproblem. A standard optimization\nsolver is utilized to deal with the complexity of the master problem for binary\nvariables. The alternating direction method of multipliers (ADMM) algorithm is\nused to solve the subproblem for the continuous variables. Our proposed\nalgorithm provides a suboptimal solution, and simulation results demonstrate\nthat the proposed algorithm achieves better EE than baselines.",
    "descriptor": "",
    "authors": [
      "Sheikh Salman Hassan",
      "Do Hyeon Kim",
      "Yan Kyaw Tun",
      "Nguyen H. Tran",
      "Walid Saad",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.08605"
  },
  {
    "id": "arXiv:2201.08609",
    "title": "Reputation analysis of news sources in Twitter: Particular case of  Spanish presidential election in 2019",
    "abstract": "Fake news are affecting a large proportion of the population even becoming a\ndanger to the society. Mostly, this disinformation flow take place through\nInternet. Being aware of that problem, in this work we propose a synthetic\nindicator that measures the user reputation in Twitter in order to analyze the\ncredibility of the content in this social network. In order to show the\nindicator utility, we have analyzed data from some political topics in Spain\nfrom 2019 to 2020 and we have checked that bots plays a decisive role into the\nspread of news and, as might be expected, the link among popularity and\nreputation reports about the event credibility.",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables,9 references\n",
    "authors": [
      "Aar\u00f3n L\u00f3pez-Garc\u00eda",
      "Rafael Ben\u00edtez"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2201.08609"
  },
  {
    "id": "arXiv:2201.08610",
    "title": "Deep Q-learning: a robust control approach",
    "abstract": "In this paper, we place deep Q-learning into a control-oriented perspective\nand study its learning dynamics with well-established techniques from robust\ncontrol. We formulate an uncertain linear time-invariant model by means of the\nneural tangent kernel to describe learning. We show the instability of learning\nand analyze the agent's behavior in frequency-domain. Then, we ensure\nconvergence via robust controllers acting as dynamical rewards in the loss\nfunction. We synthesize three controllers: state-feedback gain scheduling\n$\\mathcal{H}_2$, dynamic $\\mathcal{H}_\\infty$, and constant gain\n$\\mathcal{H}_\\infty$ controllers. Setting up the learning agent with a\ncontrol-oriented tuning methodology is more transparent and has\nwell-established literature compared to the heuristics in reinforcement\nlearning. In addition, our approach does not use a target network and\nrandomized replay memory. The role of the target network is overtaken by the\ncontrol input, which also exploits the temporal dependency of samples (opposed\nto a randomized memory buffer). Numerical simulations in different OpenAI Gym\nenvironments suggest that the $\\mathcal{H}_\\infty$ controlled learning performs\nslightly better than Double deep Q-learning.",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs Varga",
      "Bal\u00e1zs Kulcs\u00e1r",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08610"
  },
  {
    "id": "arXiv:2201.08612",
    "title": "Insertion and Deletion Correction in Polymer-based Data Storage",
    "abstract": "Synthetic polymer-based storage seems to be a particularly promising\ncandidate that could help to cope with the ever-increasing demand for archival\nstorage requirements. It involves designing molecules of distinct masses to\nrepresent the respective bits $\\{0,1\\}$, followed by the synthesis of a polymer\nof molecular units that reflects the order of bits in the information string.\nReading out the stored data requires the use of a tandem mass spectrometer,\nthat fragments the polymer into shorter substrings and provides their\ncorresponding masses, from which the \\emph{composition}, i.e. the number of\n$1$s and $0$s in the concerned substring can be inferred. Prior works have\ndealt with the problem of unique string reconstruction from the set of all\npossible compositions, called \\emph{composition multiset}. This was\naccomplished either by determining which string lengths always allow unique\nreconstruction, or by formulating coding constraints to facilitate the same for\nall string lengths. Additionally, error-correcting schemes to deal with\nsubstitution errors caused by imprecise fragmentation during the readout\nprocess, have also been suggested. This work builds on this research by\ngeneralizing previously considered error models, mainly confined to\nsubstitution of compositions. To this end, we define new error models that\nconsider insertions of spurious compositions and deletions of existing ones,\nthereby corrupting the composition multiset. We analyze if the reconstruction\ncodebook proposed by Pattabiraman \\emph{et al.} is indeed robust to such\nerrors, and if not, propose new coding constraints to remedy this.",
    "descriptor": "",
    "authors": [
      "Anisha Banerjee",
      "Antonia Wachter-Zeh",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08612"
  },
  {
    "id": "arXiv:2201.08613",
    "title": "Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint  Localization",
    "abstract": "Localizing keypoints of an object is a basic visual problem. However,\nsupervised learning of a keypoint localization network often requires a large\namount of data, which is expensive and time-consuming to obtain. To remedy\nthis, there is an ever-growing interest in semi-supervised learning (SSL),\nwhich leverages a small set of labeled data along with a large set of unlabeled\ndata. Among these SSL approaches, pseudo-labeling (PL) is one of the most\npopular. PL approaches apply pseudo-labels to unlabeled data, and then train\nthe model with a combination of the labeled and pseudo-labeled data\niteratively. The key to the success of PL is the selection of high-quality\npseudo-labeled samples. Previous works mostly select training samples by\nmanually setting a single confidence threshold. We propose to automatically\nselect reliable pseudo-labeled samples with a series of dynamic thresholds,\nwhich constitutes a learning curriculum. Extensive experiments on six keypoint\nlocalization benchmark datasets demonstrate that the proposed approach\nsignificantly outperforms the previous state-of-the-art SSL approaches.",
    "descriptor": "\nComments: To appear on ICLR2022\n",
    "authors": [
      "Can Wang",
      "Sheng Jin",
      "Yingda Guan",
      "Wentao Liu",
      "Chen Qian",
      "Ping Luo",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08613"
  },
  {
    "id": "arXiv:2201.08614",
    "title": "Consumer Fairness in Recommender Systems: Contextualizing Definitions  and Mitigations",
    "abstract": "Enabling non-discrimination for end-users of recommender systems by\nintroducing consumer fairness is a key problem, widely studied in both academia\nand industry. Current research has led to a variety of notions, metrics, and\nunfairness mitigation procedures. The evaluation of each procedure has been\nheterogeneous and limited to a mere comparison with models not accounting for\nfairness. It is hence hard to contextualize the impact of each mitigation\nprocedure w.r.t. the others. In this paper, we conduct a systematic analysis of\nmitigation procedures against consumer unfairness in rating prediction and\ntop-n recommendation tasks. To this end, we collected 15 procedures proposed in\nrecent top-tier conferences and journals. Only 8 of them could be reproduced.\nUnder a common evaluation protocol, based on two public data sets, we then\nstudied the extent to which recommendation utility and consumer fairness are\nimpacted by these procedures, the interplay between two primary fairness\nnotions based on equity and independence, and the demographic groups harmed by\nthe disparate impact. Our study finally highlights open challenges and future\ndirections in this field. The source code is available at\nhttps://github.com/jackmedda/C-Fairness-RecSys.",
    "descriptor": "\nComments: Accepted at the 44th European Conference on Information Retrieval (ECIR 2022)\n",
    "authors": [
      "Ludovico Boratto",
      "Gianni Fenu",
      "Mirko Marras",
      "Giacomo Medda"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.08614"
  },
  {
    "id": "arXiv:2201.08616",
    "title": "Diffusion Multi-unit Auctions with Diminishing Marginal Utility Buyers",
    "abstract": "We consider an auction mechanism design problem where a seller sells multiple\nhomogeneous items to a set of buyers who are connected to form a network. Each\nbuyer only knows the buyers he directly connects with and has a diminishing\nmarginal utility valuation for the items. The seller initially also only\nconnects to some of the buyers. The goal is to design an auction to incentivize\nthe buyers who are aware of the auction to further invite their neighbors to\njoin the auction. This is challenging because the buyers are competing for the\nitems and they would not invite each other by default. Solutions have been\nproposed recently for the settings where each buyer requires at most one unit\nand demonstrated the difficulties for the design even in the simple settings.\nWe move this forward to propose the very first diffusion auction for the\nmulti-unit demand settings. We also show that it improves both the social\nwelfare and the revenue to incentivize the seller to apply it.",
    "descriptor": "",
    "authors": [
      "Haolin Liu",
      "Xinyuan Lian",
      "Dengji Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.08616"
  },
  {
    "id": "arXiv:2201.08619",
    "title": "Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object  Detectors in the Physical World",
    "abstract": "Deep learning models have been shown to be vulnerable to recent backdoor\nattacks. A backdoored model behaves normally for inputs containing no\nattacker-secretly-chosen trigger and maliciously for inputs with the trigger.\nTo date, backdoor attacks and countermeasures mainly focus on image\nclassification tasks. And most of them are implemented in the digital world\nwith digital triggers. Besides the classification tasks, object detection\nsystems are also considered as one of the basic foundations of computer vision\ntasks. However, there is no investigation and understanding of the backdoor\nvulnerability of the object detector, even in the digital world with digital\ntriggers. For the first time, this work demonstrates that existing object\ndetectors are inherently susceptible to physical backdoor attacks. We use a\nnatural T-shirt bought from a market as a trigger to enable the cloaking\neffect--the person bounding-box disappears in front of the object detector. We\nshow that such a backdoor can be implanted from two exploitable attack\nscenarios into the object detector, which is outsourced or fine-tuned through a\npretrained model. We have extensively evaluated three popular object detection\nalgorithms: anchor-based Yolo-V3, Yolo-V4, and anchor-free CenterNet. Building\nupon 19 videos shot in real-world scenes, we confirm that the backdoor attack\nis robust against various factors: movement, distance, angle, non-rigid\ndeformation, and lighting. Specifically, the attack success rate (ASR) in most\nvideos is 100% or close to it, while the clean data accuracy of the backdoored\nmodel is the same as its clean counterpart. The latter implies that it is\ninfeasible to detect the backdoor behavior merely through a validation set. The\naveraged ASR still remains sufficiently high to be 78% in the transfer learning\nattack scenarios evaluated on CenterNet. See the demo video on\nhttps://youtu.be/Q3HOF4OobbY.",
    "descriptor": "",
    "authors": [
      "Hua Ma",
      "Yinshan Li",
      "Yansong Gao",
      "Alsharif Abuadbba",
      "Zhi Zhang",
      "Anmin Fu",
      "Hyoungshick Kim",
      "Said F. Al-Sarawi",
      "Nepal Surya",
      "Derek Abbott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08619"
  },
  {
    "id": "arXiv:2201.08620",
    "title": "Extended Randomized Kaczmarz Method for Sparse Least Squares and  Impulsive Noise Problems",
    "abstract": "The Extended Randomized Kaczmarz method is a well known iterative scheme\nwhich can find the Moore-Penrose inverse solution of a possibly inconsistent\nlinear system and requires only one additional column of the system matrix in\neach iteration in comparison with the standard randomized Kaczmarz method.\nAlso, the Sparse Randomized Kaczmarz method has been shown to converge linearly\nto a sparse solution of a consistent linear system. Here, we combine both ideas\nand propose an Extended Sparse Randomized Kaczmarz method. We show linear\nexpected convergence to a sparse least squares solution in the sense that an\nextended variant of the regularized basis pursuit problem is solved. Moreover,\nwe generalize the additional step in the method and prove convergence to a more\nabstract optimization problem. We demonstrate numerically that our method can\nfind sparse least squares solutions of real and complex systems if the noise is\nconcentrated in the complement of the range of the system matrix and that our\ngeneralization can handle impulsive noise.",
    "descriptor": "",
    "authors": [
      "Frank Sch\u00f6pfer",
      "Dirk A Lorenz",
      "Lionel Tondji",
      "Maximilian Winkler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.08620"
  },
  {
    "id": "arXiv:2201.08622",
    "title": "Reproducing Personalised Session Search over the AOL Query Log",
    "abstract": "Despite its troubled past, the AOL Query Log continues to be an important\nresource to the research community -- particularly for tasks like search\npersonalisation. When using the query log these ranking experiments, little\nattention is usually paid to the document corpus. Recent work typically uses a\ncorpus containing versions of the documents collected long after the log was\nproduced. Given that web documents are prone to change over time, we study the\ndifferences present between a version of the corpus containing documents as\nthey appeared in 2017 (which has been used by several recent works) and a new\nversion we construct that includes documents close to as they appeared at the\ntime the query log was produced (2006). We demonstrate that this new version of\nthe corpus has a far higher coverage of documents present in the original log\n(93%) than the 2017 version (55%). Among the overlapping documents, the content\noften differs substantially. Given these differences, we re-conduct session\nsearch experiments that originally used the 2017 corpus and find that when\nusing our corpus for training or evaluation, system performance improves. We\nplace the results in context by introducing recent adhoc ranking baselines. We\nalso confirm the navigational nature of the queries in the AOL corpus by\nshowing that including the URL substantially improves performance across a\nvariety of models. Our version of the corpus can be easily reconstructed by\nother researchers and is included in the ir-datasets package.",
    "descriptor": "\nComments: ECIR 2022 (reproducibility)\n",
    "authors": [
      "Sean MacAvaney",
      "Craig Macdonald",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.08622"
  },
  {
    "id": "arXiv:2201.08625",
    "title": "VIPriors 2: Visual Inductive Priors for Data-Efficient Deep Learning  Challenges",
    "abstract": "The second edition of the \"VIPriors: Visual Inductive Priors for\nData-Efficient Deep Learning\" challenges featured five data-impaired\nchallenges, where models are trained from scratch on a reduced number of\ntraining samples for various key computer vision tasks. To encourage new and\ncreative ideas on incorporating relevant inductive biases to improve the data\nefficiency of deep learning models, we prohibited the use of pre-trained\ncheckpoints and other transfer learning techniques. The provided baselines are\noutperformed by a large margin in all five challenges, mainly thanks to\nextensive data augmentation policies, model ensembling, and data efficient\nnetwork architectures.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Attila Lengyel",
      "Robert-Jan Bruintjes",
      "Marcos Baptista Rios",
      "Osman Semih Kayhan",
      "Davide Zambrano",
      "Nergis Tomen",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08625"
  },
  {
    "id": "arXiv:2201.08627",
    "title": "A Systematic Literature Review of Empirical Research on Quality  Requirements",
    "abstract": "Quality requirements deal with how well a product should perform the intended\nfunctionality, such as start-up time and learnability. Researchers argue they\nare important and at the same time studies indicate there are deficiencies in\npractice.\nOur goal is to review the state of evidence for quality requirements. We want\nto understand the empirical research on quality requirements topics as well as\nevaluations of quality requirements solutions.\nWe used a hybrid method for our systematic literature review. We defined a\nstart set based on two literature reviews combined with a keyword-based search\nfrom selected publication venues. We snowballed based on the start set.\nWe screened 530 papers and included 84 papers in our review. Case study\nmethod is the most common (43), followed by surveys (15) and tests (13). We\nfound no replication studies. The two most commonly studied themes are 1)\nDifferentiating characteristics of quality requirements compared to other types\nof requirements, 2) the importance and prevalence of quality requirements.\nQuality models, QUPER, and the NFR method are evaluated in several studies,\nwith positive indications. Goal modeling is the only modeling approach\nevaluated. However, all studies are small scale and long-term costs and impact\nare not studied.\nWe conclude that more research is needed as empirical research on quality\nrequirements is not increasing at the same rate as software engineering\nresearch in general. We see a gap between research and practice. The solutions\nproposed are usually evaluated in an academic context and surveys on quality\nrequirements in industry indicate unsystematic handling of quality\nrequirements.",
    "descriptor": "\nComments: Accepted for publication in the Requiremeng Engineering journal\n",
    "authors": [
      "Thomas Olsson",
      "Severine Sentilles",
      "Efi Papatheocharous"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08627"
  },
  {
    "id": "arXiv:2201.08633",
    "title": "Multi-view Monocular Depth and Uncertainty Prediction with Deep SfM in  Dynamic Environments",
    "abstract": "3D reconstruction of depth and motion from monocular video in dynamic\nenvironments is a highly ill-posed problem due to scale ambiguities when\nprojecting to the 2D image domain. In this work, we investigate the performance\nof the current State-of-the-Art (SotA) deep multi-view systems in such\nenvironments. We find that current supervised methods work surprisingly well\ndespite not modelling individual object motions, but make systematic errors due\nto a lack of dense ground truth data. To detect such errors during usage, we\nextend the cost volume based Deep Video to Depth (DeepV2D) framework\n\\cite{teed2018deepv2d} with a learned uncertainty. Our Deep Video to certain\nDepth (DeepV2cD) model allows i) to perform en par or better with current SotA\nand ii) achieve a better uncertainty measure than the naive Shannon entropy.\nOur experiments show that a simple filter strategy based on the uncertainty can\nsignificantly reduce systematic errors. This results in cleaner reconstructions\nboth on static and dynamic parts of the scene.",
    "descriptor": "\nComments: 20 pages, 5 figures, 3 tables, submitted to ICPRAI 2022\n",
    "authors": [
      "Christian Homeyer",
      "Oliver Lange",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08633"
  },
  {
    "id": "arXiv:2201.08636",
    "title": "Conceptor Learning for Class Activation Mapping",
    "abstract": "Class Activation Mapping (CAM) has been widely adopted to generate saliency\nmaps which provides visual explanations for deep neural networks (DNNs). The\nsaliency maps are conventionally generated by fusing the channels of the target\nfeature map using a weighted average scheme. It is a weak model for the\ninter-channel relation, in the sense that it only models the relation among\nchannels in a contrastive way (i.e., channels that play key roles in the\nprediction are given higher weights for them to stand out in the fusion). The\ncollaborative relation, which makes the channels work together to provide cross\nreference, has been ignored. Furthermore, the model has neglected the\nintra-channel relation thoroughly.In this paper, we address this problem by\nintroducing Conceptor learning into CAM generation. Conceptor leaning has been\noriginally proposed to model the patterns of state changes in recurrent neural\nnetworks (RNNs). By relaxing the dependency of Conceptor learning to RNNs, we\nmake Conceptor-CAM not only generalizable to more DNN architectures but also\nable to learn both the inter- and intra-channel relations for better saliency\nmap generation. Moreover, we have enabled the use of Boolean operations to\ncombine the positive and pseudo-negative evidences, which has made the CAM\ninference more robust and comprehensive. The effectiveness of Conceptor-CAM has\nbeen validated with both formal verifications and experiments on the dataset of\nthe largest scale in literature. The experimental results show that\nConceptor-CAM is compatible with and can bring significant improvement to all\nwell recognized CAM-based methods, and has outperformed the state-of-the-art\nmethods by 43.14%~72.79% (88.39%~168.15%) on ILSVRC2012 in Average Increase\n(Drop), 15.42%~42.55% (47.09%~372.09%) on VOC, and 17.43%~31.32%\n(47.54%~206.45%) on COCO, respectively.",
    "descriptor": "",
    "authors": [
      "Guangwu Qian",
      "Zhen-Qun Yang",
      "Xu-Lu Zhang",
      "Yaowei Wang",
      "Qing Li",
      "Xiao-Yong Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08636"
  },
  {
    "id": "arXiv:2201.08638",
    "title": "Approximation approach to the fractional BVP with the Dirichlet type  boundary conditions",
    "abstract": "We use a numerical-analytic technique to construct a sequence of successive\napproximations to the solution of a system of fractional differential\nequations, subject to Dirichlet boundary conditions. We prove the uniform\nconvergence of the sequence of approximations to a limit function, which is the\nunique solution to the boundary value problem under consideration, and give\nnecessary and sufficient conditions for the existence of solutions. The\nobtained theoretical results are confirmed by a model example.",
    "descriptor": "\nComments: This article has been submitted to Constructive Approximation\n",
    "authors": [
      "Kateryna Marynets",
      "Dona Pantova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08638"
  },
  {
    "id": "arXiv:2201.08640",
    "title": "First electrical White Rabbit absolute calibration inter-comparison",
    "abstract": "A time transfer link consisting of PTP White Rabbit (PTP-WR) devices can\ntransfer time with sub-nanosecond accuracy. Originally White Rabbit devices\nwere calibrated as a set of two devices. Progress in calibration makes\nindividual absolute calibrated PTP-WR devices possible. This enables exchange\nof PTP-WR devices without the need for expensive in-situ end-to-end\ncalibrations.\nElectrical absolute calibration is the basis of absolute calibration. It\ncalibrates the time relationship between the internal timestamp and the\nexternal electrical time reference plane. In this paper we examine the\nelectrical time transfer accuracy when a link is setup using electrical\nabsolute calibrated PTP-WR devices calibrated by different laboratories.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "P.P.M. Jansweijer",
      "N.A.D. Boukadida",
      "K. Hanhij\u00e4rvi",
      "A. Wallin",
      "B. Eglin",
      "E. Laier English"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2201.08640"
  },
  {
    "id": "arXiv:2201.08641",
    "title": "Robust a posteriori estimates for the stochastic Cahn-Hilliard equation",
    "abstract": "We derive a posteriori error estimates for a fully discrete finite element\napproximation of the stochastic Cahn-Hilliard equation. The a posteriori bound\nis obtained by a splitting of the equation into a linear stochastic partial\ndifferential equation (SPDE) and a nonlinear random partial differential\nequation (RPDE). The resulting estimate is robust with respect to the\ninterfacial width parameter and is computable since it involves the discrete\nprincipal eigenvalue of a linearized (stochastic) Cahn-Hilliard operator.\nFurthermore, the estimate is robust with respect to topological changes as well\nas the intensity of the stochastic noise. We provide numerical simulations to\ndemonstrate the practicability of the proposed adaptive algorithm.",
    "descriptor": "",
    "authors": [
      "\u013dubom\u00edr Ba\u0148as",
      "Christian Vieth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08641"
  },
  {
    "id": "arXiv:2201.08643",
    "title": "Text Style Transfer for Bias Mitigation using Masked Language Modeling",
    "abstract": "It is well known that textual data on the internet and other digital\nplatforms contain significant levels of bias and stereotypes. Although many\nsuch texts contain stereotypes and biases that inherently exist in natural\nlanguage for reasons that are not necessarily malicious, there are crucial\nreasons to mitigate these biases. For one, these texts are being used as\ntraining corpus to train language models for salient applications like\ncv-screening, search engines, and chatbots; such applications are turning out\nto produce discriminatory results. Also, several research findings have\nconcluded that biased texts have significant effects on the target demographic\ngroups. For instance, masculine-worded job advertisements tend to be less\nappealing to female applicants.\nIn this paper, we present a text style transfer model that can be used to\nautomatically debias textual data. Our style transfer model improves on the\nlimitations of many existing style transfer techniques such as loss of content\ninformation. Our model solves such issues by combining latent content encoding\nwith explicit keyword replacement. We will show that this technique produces\nbetter content preservation whilst maintaining good style transfer accuracy.",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables\n",
    "authors": [
      "Ewoenam Kwaku Tokpo",
      "Toon Calders"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08643"
  },
  {
    "id": "arXiv:2201.08647",
    "title": "An Approximation Algorithm for $K$-best Enumeration of Minimal Connected  Edge Dominating Sets with Cardinality Constraints",
    "abstract": "\\emph{$K$-best enumeration}, which asks to output $k$ best solutions without\nduplication, plays an important role in data analysis for many fields. In such\nfields, data can be typically represented by graphs, and thus subgraph\nenumeration has been paid much attention to. However, $k$-best enumeration\ntends to be intractable since, in many cases, finding one optimum solution is\n\\NP-hard. To overcome this difficulty, we combine $k$-best enumeration with a\nnew concept of enumeration algorithms called \\emph{approximation enumeration\nalgorithms}, which has been recently proposed. As a main result, we propose an\n$\\alpha$-approximation algorithm for minimal connected edge dominating sets\nwhich outputs $k$ minimal solutions with cardinality at most\n$\\alpha\\cdot\\overline{\\rm OPT}$, where $\\overline{\\rm OPT}$ is the cardinality\nof a mini\\emph{mum} solution which is \\emph{not} outputted by the algorithm,\nand $\\alpha$ is constant. Moreover, our proposed algorithm runs in\n$O(nm^2\\Delta)$ delay, where $n$, $m$, $\\Delta$ are the number of vertices, the\nnumber of edges, and the maximum degree of an input graph.",
    "descriptor": "",
    "authors": [
      "Kazuhiro Kurita",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.08647"
  },
  {
    "id": "arXiv:2201.08648",
    "title": "Moment Propagation Through Carleman Linearization with Application to  Probabilistic Safety Analysis",
    "abstract": "We develop a method to approximate the moments of a discrete-time stochastic\npolynomial system. Our method is built upon Carleman linearization with\ntruncation. Specifically, we take a stochastic polynomial system with finitely\nmany states and transform it into an infinite-dimensional system with linear\ndeterministic dynamics, which describe the exact evolution of the moments of\nthe original polynomial system. We then truncate this deterministic system to\nobtain a finite-dimensional linear system, and use it for moment approximation\nby iteratively propagating the moments along the finite-dimensional linear\ndynamics across time. We provide efficient online computation methods for this\npropagation scheme with several error bounds for the approximation. Our result\nalso shows that precise values of certain moments can be obtained when the\ntruncated system is sufficiently large. Furthermore, we investigate techniques\nto reduce the offline computation load using reduced Kronecker power. Based on\nthe obtained approximate moments and their errors, we also provide probability\nbounds for the state to be outside of given hyperellipsoidal regions. Those\nbounds allow us to conduct probabilistic safety analysis online through convex\noptimization. We demonstrate our results on a logistic map with stochastic\ndynamics and a vehicle dynamics subject to stochastic disturbance.",
    "descriptor": "\nComments: Preprint submitted to Automatica. arXiv admin note: substantial text overlap with arXiv:1911.12683\n",
    "authors": [
      "Sasinee Pruekprasert",
      "J\u00e9r\u00e9my Dubut",
      "Toru Takisaka",
      "Clovis Eberhart",
      "Ahmet Cetinkaya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08648"
  },
  {
    "id": "arXiv:2201.08650",
    "title": "Exploring the acceptability of digital contact tracing for UK students",
    "abstract": "Contact tracing systems control the spread of disease by discovering the set\nof people an infectious individual has come into contact with. Students are\noften mobile and sociable and therefore can contribute to the spread of\ndisease. Controls on the movement of students studying in the UK were put in\nplace during the Covid-19 pandemic, and some restrictions may be necessary over\nseveral years. App based digital contact tracing may help ease restrictions by\nenabling students to make informed decisions and take precautions. However,\ndesigning for the end user acceptability of these apps remains under-explored.\nThis study with 22 students from UK Universities (inc. 11 international\nstudents) uses a fictional user interface to prompt in-depth interviews on the\nacceptability of contact tracing tools. We explore intended uptake, usage and\ncompliance with contact tracing apps, finding students are positive, although\nconcerned about privacy, security, and burden of participating.",
    "descriptor": "",
    "authors": [
      "Dave Murray-Rust",
      "Luis Soares",
      "Katya Gorkovenko",
      "John Rooksby"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08650"
  },
  {
    "id": "arXiv:2201.08656",
    "title": "Dustin: A 16-Cores Parallel Ultra-Low-Power Cluster with 2b-to-32b Fully  Flexible Bit-Precision and Vector Lockstep Execution Mode",
    "abstract": "Computationally intensive algorithms such as Deep Neural Networks (DNNs) are\nbecoming killer applications for edge devices. Porting heavily data-parallel\nalgorithms on resource-constrained and battery-powered devices poses several\nchallenges related to memory footprint, computational throughput, and energy\nefficiency. Low-bitwidth and mixed-precision arithmetic have been proven to be\nvalid strategies for tackling these problems. We present Dustin, a fully\nprogrammable compute cluster integrating 16 RISC-V cores capable of 2- to\n32-bit arithmetic and all possible mixed-precision permutations. In addition to\na conventional Multiple-Instruction Multiple-Data (MIMD) processing paradigm,\nDustin introduces a Vector Lockstep Execution Mode (VLEM) to minimize power\nconsumption in highly data-parallel kernels. In VLEM, a single leader core\nfetches instructions and broadcasts them to the 15 follower cores. Clock gating\nInstruction Fetch (IF) stages and private caches of the follower cores leads to\n38\\% power reduction with minimal performance overhead (<3%). The cluster,\nimplemented in 65 nm CMOS technology, achieves a peak performance of 58 GOPS\nand a peak efficiency of 1.15 TOPS/W.",
    "descriptor": "\nComments: 13 pages, 17 figures, 2 tables, Journal\n",
    "authors": [
      "Gianmarco Ottavi",
      "Angelo Garofalo",
      "Giuseppe Tagliavini",
      "Francesco Conti",
      "Alfio Di Mauro",
      "Luca Benini",
      "Davide Rossi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.08656"
  },
  {
    "id": "arXiv:2201.08657",
    "title": "Enhancing Pseudo Label Quality for Semi-SupervisedDomain-Generalized  Medical Image Segmentation",
    "abstract": "Generalizing the medical image segmentation algorithms tounseen domains is an\nimportant research topic for computer-aided diagnosis and surgery. Most\nexisting methods requirea fully labeled dataset in each source domain. Although\n(Liuet al. 2021b) developed a semi-supervised domain general-ized method, it\nstill requires the domain labels. This paperpresents a novel confidence-aware\ncross pseudo supervisionalgorithm for semi-supervised domain generalized\nmedicalimage segmentation. The main goal is to enhance the pseudolabel quality\nfor unlabeled images from unknown distribu-tions. To achieve it, we perform the\nFourier transformationto learn low-level statistic information across domains\nandaugment the images to incorporate cross-domain information.With these\naugmentations as perturbations, we feed the inputto a confidence-aware cross\npseudo supervision network tomeasure the variance of pseudo labels and\nregularize the net-work to learn with more confident pseudo labels. Our\nmethodsets new records on public datasets,i.e., M&Ms and SCGM.Notably, without\nusing domain labels, our method surpassesthe prior art that even uses domain\nlabels by 11.67% on Diceon M&Ms dataset with 2% labeled data. Code will be\navail-able after the conference.",
    "descriptor": "",
    "authors": [
      "Huifeng Yao",
      "Xiaowei Hu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08657"
  },
  {
    "id": "arXiv:2201.08658",
    "title": "Approximating moving point sources in hyperbolic partial differential  equations",
    "abstract": "We consider point sources in hyperbolic equations discretized by finite\ndifferences. If the source is stationary, appropriate source discretization has\nbeen shown to preserve the accuracy of the finite difference method. Moving\npoint sources, however, pose two challenges that do not appear in the\nstationary case. First, the discrete source must not excite modes that\npropagate with the source velocity. Second, the discrete source spectrum\namplitude must be independent of the source position. We derive a source\ndiscretization that meets these requirements and prove design-order convergence\nof the numerical solution for the one-dimensional advection equation. Numerical\nexperiments indicate design-order convergence also for the acoustic wave\nequation in two dimensions. The source discretization covers on the order of\n$\\sqrt{N}$ grid points on an $N$-point grid and is applicable for source\ntrajectories that do not touch domain boundaries.",
    "descriptor": "",
    "authors": [
      "Ylva Ljungberg Rydin",
      "Martin Almquist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08658"
  },
  {
    "id": "arXiv:2201.08659",
    "title": "Unity Smoothing for Handling Inconsistent Evidence in Bayesian Networks  and Unity Propagation for Faster Inference",
    "abstract": "We propose Unity Smoothing (US) for handling inconsistencies between a\nBayesian network model and new unseen observations. We show that prediction\naccuracy, using the junction tree algorithm with US is comparable to that of\nLaplace smoothing. Moreover, in applications were sparsity of the data\nstructures is utilized, US outperforms Laplace smoothing in terms of memory\nusage. Furthermore, we detail how to avoid redundant calculations that must\notherwise be performed during the message passing scheme in the junction tree\nalgorithm which we refer to as Unity Propagation (UP). Experimental results\nshows that it is always faster to exploit UP on top of the\nLauritzen-Spigelhalter message passing scheme for the junction tree algorithm.",
    "descriptor": "",
    "authors": [
      "Mads Lindskou",
      "Torben Tvedebrink",
      "Poul Svante Eriksen",
      "S\u00f8ren H\u00f8jsgaard",
      "Niels Morling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08659"
  },
  {
    "id": "arXiv:2201.08660",
    "title": "On the adaptation of recurrent neural networks for system identification",
    "abstract": "This paper presents a transfer learning approach which enables fast and\nefficient adaptation of Recurrent Neural Network (RNN) models of dynamical\nsystems. A nominal RNN model is first identified using available measurements.\nThe system dynamics are then assumed to change, leading to an unacceptable\ndegradation of the nominal model performance on the perturbed system. To cope\nwith the mismatch, the model is augmented with an additive correction term\ntrained on fresh data from the new dynamic regime. The correction term is\nlearned through a Jacobian Feature Regression (JFR) method defined in terms of\nthe features spanned by the model's Jacobian with respect to its nominal\nparameters. A non-parametric view of the approach is also proposed, which\nextends recent work on Gaussian Process (GP) with Neural Tangent Kernel\n(NTK-GP) to the RNN case (RNTK-GP). This can be more efficient for very large\nnetworks or when only few data points are available. Implementation aspects for\nfast and efficient computation of the correction term, as well as the initial\nstate estimation for the RNN model are described. Numerical examples show the\neffectiveness of the proposed methodology in presence of significant system\nvariations.",
    "descriptor": "",
    "authors": [
      "Marco Forgione",
      "Aneri Muni",
      "Dario Piga",
      "Marco Gallieri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08660"
  },
  {
    "id": "arXiv:2201.08661",
    "title": "The Security of Deep Learning Defences for Medical Imaging",
    "abstract": "Deep learning has shown great promise in the domain of medical image\nanalysis. Medical professionals and healthcare providers have been adopting the\ntechnology to speed up and enhance their work. These systems use deep neural\nnetworks (DNN) which are vulnerable to adversarial samples; images with\nimperceivable changes that can alter the model's prediction. Researchers have\nproposed defences which either make a DNN more robust or detect the adversarial\nsamples before they do harm. However, none of these works consider an informed\nattacker which can adapt to the defence mechanism. We show that an informed\nattacker can evade five of the current state of the art defences while\nsuccessfully fooling the victim's deep learning model, rendering these defences\nuseless. We then suggest better alternatives for securing healthcare DNNs from\nsuch attacks: (1) harden the system's security and (2) use digital signatures.",
    "descriptor": "",
    "authors": [
      "Moshe Levy",
      "Guy Amit",
      "Yuval Elovici",
      "Yisroel Mirsky"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.08661"
  },
  {
    "id": "arXiv:2201.08663",
    "title": "Fast Differentiable Matrix Square Root",
    "abstract": "Computing the matrix square root or its inverse in a differentiable manner is\nimportant in a variety of computer vision tasks. Previous methods either adopt\nthe Singular Value Decomposition (SVD) to explicitly factorize the matrix or\nuse the Newton-Schulz iteration (NS iteration) to derive the approximate\nsolution. However, both methods are not computationally efficient enough in\neither the forward pass or in the backward pass. In this paper, we propose two\nmore efficient variants to compute the differentiable matrix square root. For\nthe forward propagation, one method is to use Matrix Taylor Polynomial (MTP),\nand the other method is to use Matrix Pad\\'e Approximants (MPA). The backward\ngradient is computed by iteratively solving the continuous-time Lyapunov\nequation using the matrix sign function. Both methods yield considerable\nspeed-up compared with the SVD or the Newton-Schulz iteration. Experimental\nresults on the de-correlated batch normalization and second-order vision\ntransformer demonstrate that our methods can also achieve competitive and even\nslightly better performances. The code is available at\n\\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.",
    "descriptor": "\nComments: Accpeted by ICLR 2022\n",
    "authors": [
      "Yue Song",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08663"
  },
  {
    "id": "arXiv:2201.08669",
    "title": "Dynamic Deep Convolutional Candlestick Learner",
    "abstract": "Candlestick pattern is one of the most fundamental and valuable graphical\ntools in financial trading that supports traders observing the current market\nconditions to make the proper decision. This task has a long history and, most\nof the time, human experts. Recently, efforts have been made to automatically\nclassify these patterns with the deep learning models. The GAF-CNN model is a\nwell-suited way to imitate how human traders capture the candlestick pattern by\nintegrating spatial features visually. However, with the great potential of the\nGAF encoding, this classification task can be extended to a more complicated\nobject detection level. This work presents an innovative integration of modern\nobject detection techniques and GAF time-series encoding on candlestick pattern\ntasks. We make crucial modifications to the representative yet straightforward\nYOLO version 1 model based on our time-series encoding method and the property\nof such data type. Powered by the deep neural networks and the unique\narchitectural design, the proposed model performs pretty well in candlestick\nclassification and location recognition. The results show tremendous potential\nin applying modern object detection techniques on time-series tasks in a\nreal-time manner.",
    "descriptor": "\nComments: 11 pages, 9 figures, 2 tables\n",
    "authors": [
      "Jun-Hao Chen",
      "Yun-Cheng Tsai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08669"
  },
  {
    "id": "arXiv:2201.08670",
    "title": "Context-Tuning: Learning Contextualized Prompts for Natural Language  Generation",
    "abstract": "Recently, pretrained language models (PLMs) have made exceptional success in\nlanguage generation. To leverage the rich knowledge encoded by PLMs, a simple\nyet powerful mechanism is to use prompts, in the form of either discrete tokens\nor continuous embeddings. In existing studies, manual prompts are\ntime-consuming and require domain expertise, while continuous prompts are\ntypically independent of the inputs. To address this issue, we propose a novel\ncontinuous prompting approach, called Context-Tuning, to fine-tuning PLMs for\nnatural language generation. Firstly, the prompts are derived based on the\ninput text, so that they can elicit useful knowledge from PLMs for generation.\nWe refer to such prompts as contextualized prompts. Secondly, to further\nenhance the relevance of the generated text to the inputs, we utilize\ncontinuous inverse prompting to refine the process of natural language\ngeneration by modeling an inverse generation process from output to input.\nMoreover, we propose a lightweight contexttuning, fine-tuning only 0.4% of\nparameters while retaining well performance.",
    "descriptor": "\nComments: 13 pages, 6 figures, 6 tables\n",
    "authors": [
      "Tianyi Tang",
      "Junyi Li",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08670"
  },
  {
    "id": "arXiv:2201.08671",
    "title": "Random Noise vs State-of-the-Art Probabilistic Forecasting Methods : A  Case Study on CRPS-Sum Discrimination Ability",
    "abstract": "The recent developments in the machine learning domain have enabled the\ndevelopment of complex multivariate probabilistic forecasting models.\nTherefore, it is pivotal to have a precise evaluation method to gauge the\nperformance and predictability power of these complex methods. To do so,\nseveral evaluation metrics have been proposed in the past (such as Energy\nScore, Dawid-Sebastiani score, variogram score), however, they cannot reliably\nmeasure the performance of a probabilistic forecaster. Recently, CRPS-sum has\ngained a lot of prominence as a reliable metric for multivariate probabilistic\nforecasting. This paper presents a systematic evaluation of CRPS-sum to\nunderstand its discrimination ability. We show that the statistical properties\nof target data affect the discrimination ability of CRPS-Sum. Furthermore, we\nhighlight that CRPS-Sum calculation overlooks the performance of the model on\neach dimension. These flaws can lead us to an incorrect assessment of model\nperformance. Finally, with experiments on the real-world dataset, we\ndemonstrate that the shortcomings of CRPS-Sum provide a misleading indication\nof the probabilistic forecasting performance method. We show that it is easily\npossible to have a better CRPS-Sum for a dummy model, which looks like random\nnoise, in comparison to the state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Alireza Koochali",
      "Peter Schichtel",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08671"
  },
  {
    "id": "arXiv:2201.08673",
    "title": "Exploring Fusion Strategies for Accurate RGBT Visual Object Tracking",
    "abstract": "We address the problem of multi-modal object tracking in video and explore\nvarious options of fusing the complementary information conveyed by the visible\n(RGB) and thermal infrared (TIR) modalities including pixel-level,\nfeature-level and decision-level fusion. Specifically, different from the\nexisting methods, paradigm of image fusion task is heeded for fusion at pixel\nlevel. Feature-level fusion is fulfilled by attention mechanism with channels\nexcited optionally. Besides, at decision level, a novel fusion strategy is put\nforward since an effortless averaging configuration has shown the superiority.\nThe effectiveness of the proposed decision-level fusion strategy owes to a\nnumber of innovative contributions, including a dynamic weighting of the RGB\nand TIR contributions and a linear template update operation. A variant of\nwhich produced the winning tracker at the Visual Object Tracking Challenge 2020\n(VOT-RGBT2020). The concurrent exploration of innovative pixel- and\nfeature-level fusion strategies highlights the advantages of the proposed\ndecision-level fusion method. Extensive experimental results on three\nchallenging datasets, \\textit{i.e.}, GTOT, VOT-RGBT2019, and VOT-RGBT2020,\ndemonstrate the effectiveness and robustness of the proposed method, compared\nto the state-of-the-art approaches. Code will be shared at\n\\textcolor{blue}{\\emph{https://github.com/Zhangyong-Tang/DFAT}.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Zhangyong Tang",
      "Tianyang Xu",
      "Hui Li",
      "Xiao-Jun Wu",
      "Xuefeng Zhu",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08673"
  },
  {
    "id": "arXiv:2201.08675",
    "title": "Gender Bias in Text: Labeled Datasets and Lexicons",
    "abstract": "Language has a profound impact on our thoughts, perceptions, and conceptions\nof gender roles. Gender-inclusive language is, therefore, a key tool to promote\nsocial inclusion and contribute to achieving gender equality. Consequently,\ndetecting and mitigating gender bias in texts is instrumental in halting its\npropagation and societal implications. However, there is a lack of gender bias\ndatasets and lexicons for automating the detection of gender bias using\nsupervised and unsupervised machine learning (ML) and natural language\nprocessing (NLP) techniques. Therefore, the main contribution of this work is\nto publicly provide labeled datasets and exhaustive lexicons by collecting,\nannotating, and augmenting relevant sentences to facilitate the detection of\ngender bias in English text. Towards this end, we present an updated version of\nour previously proposed taxonomy by re-formalizing its structure, adding a new\nbias type, and mapping each bias subtype to an appropriate detection\nmethodology. The released datasets and lexicons span multiple bias subtypes\nincluding: Generic He, Generic She, Explicit Marking of Sex, and Gendered\nNeologisms. We leveraged the use of word embedding models to further augment\nthe collected lexicons. The underlying motivation of our work is to enable the\ntechnical community to combat gender bias in text and halt its propagation\nusing ML and NLP techniques.",
    "descriptor": "",
    "authors": [
      "Jad Doughman",
      "Wael Khreich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08675"
  },
  {
    "id": "arXiv:2201.08676",
    "title": "Distance-Ratio-Based Formulation for Metric Learning",
    "abstract": "In metric learning, the goal is to learn an embedding so that data points\nwith the same class are close to each other and data points with different\nclasses are far apart. We propose a distance-ratio-based (DR) formulation for\nmetric learning. Like softmax-based formulation for metric learning, it models\n$p(y=c|x')$, which is a probability that a query point $x'$ belongs to a class\n$c$. The DR formulation has two useful properties. First, the corresponding\nloss is not affected by scale changes of an embedding. Second, it outputs the\noptimal (maximum or minimum) classification confidence scores on representing\npoints for classes. To demonstrate the effectiveness of our formulation, we\nconduct few-shot classification experiments using softmax-based and DR\nformulations on CUB and mini-ImageNet datasets. The results show that DR\nformulation generally enables faster and more stable metric learning than the\nsoftmax-based formulation. As a result, using DR formulation achieves improved\nor comparable generalization performances.",
    "descriptor": "\nComments: 17 pages. Codes for our experiments are available in this https URL . Perhaps, we will write a new version with experiments using normalized embedding and common metric learning performance metrics\n",
    "authors": [
      "Hyeongji Kim",
      "Pekka Parviainen",
      "Ketil Malde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08676"
  },
  {
    "id": "arXiv:2201.08677",
    "title": "Scales and Hedges in a Logic with Analogous Semantics",
    "abstract": "Logics with analogous semantics, such as Fuzzy Logic, have a number of\nexplanatory and application advantages, the most well-known being the ability\nto help experts develop control systems. From a cognitive systems perspective,\nsuch languages also have the advantage of being grounded in perception. For\nsocial decision making in humans, it is vital that logical conclusions about\nothers (cognitive empathy) are grounded in empathic emotion (affective\nempathy). Classical Fuzzy Logic, however, has several disadvantages: it is not\nobvious how complex formulae, e.g., the description of events in a text, can be\n(a) formed, (b) grounded, and (c) used in logical reasoning. The two-layered\nContext Logic (CL) was designed to address these issue. Formally based on a\nlattice semantics, like classical Fuzzy Logic, CL also features an analogous\nsemantics for complex fomulae. With the Activation Bit Vector Machine (ABVM),\nit has a simple and classical logical reasoning mechanism with an inherent\nimagery process based on the Vector Symbolic Architecture (VSA) model of\ndistributed neuronal processing. This paper adds to the existing theory how\nscales, as necessary for adjective and verb semantics can be handled by the\nsystem.",
    "descriptor": "\nComments: Presented at The Ninth Advances in Cognitive Systems (ACS) Conference 2021 (arXiv:2201.06134)\n",
    "authors": [
      "Hedda R. Schmidtke",
      "Sara Coelho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08677"
  },
  {
    "id": "arXiv:2201.08678",
    "title": "Attack of the Clones: Measuring the Maintainability, Originality and  Security of Bitcoin 'Forks' in the Wild",
    "abstract": "Since Bitcoin appeared in 2009, over 6,000 different cryptocurrency projects\nhave followed. The cryptocurrency world may be the only technology where a\nmassive number of competitors offer similar services yet claim unique benefits,\nincluding scalability, fast transactions, and security. But are these projects\nreally offering unique features and significant enhancements over their\ncompetitors? To answer this question, we conducted a large-scale empirical\nanalysis of code maintenance activities, originality and security across 592\ncrypto projects. We found that about half of these projects have not been\nupdated for the last six months; over two years, about three-quarters of them\ndisappeared, or were reported as scams or inactive. We also investigated\nwhether 11 security vulnerabilities patched in Bitcoin were also patched in\nother projects. We found that about 80% of 510 C-language-based cryptocurrency\nprojects have at least one unpatched vulnerability, and the mean time taken to\nfix the vulnerability is 237.8 days. Among those 510 altcoins, we found that at\nleast 157 altcoins are likely to have been forked from Bitcoin, about a third\nof them containing only slight changes from the Bitcoin version from which they\nwere forked. As case studies, we did a deep dive into 20 altcoins (e.g.,\nLitecoin, FujiCoin, and Feathercoin) similar to the version of Bitcoin used for\nthe fork. About half of them did not make any technically meaningful change -\nfailing to comply with the promises (e.g., about using Proof of Stake) made in\ntheir whitepapers.",
    "descriptor": "",
    "authors": [
      "Jusop Choi",
      "Wonseok Choi",
      "William Aiken",
      "Hyoungshick Kim",
      "Jun Ho Huh",
      "Taesoo Kim",
      "Yongdae Kim",
      "Ross Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08678"
  },
  {
    "id": "arXiv:2201.08679",
    "title": "Strategic Issues on Implementing a Software Process Improvement Program",
    "abstract": "Software technology has high impact on the global economy as in many sectors\nof contemporary society. As a product enabling the most varied daily\nactivities, the software product has to be produced reflecting high quality.\nSoftware quality is dependent on its development that is based in a large set\nof software development processes. However, the implementation and continuous\nimprovement of software process aimed at software product should be carefully\ninstitutionalized by software development organizations such as software\nfactories, testing factories, V&V organizations, among others. The\ninstitutionalization of programs such as a Software Process Improvement\nProgram, or SPI Program, require a strategic planning, which is addressed in\nthis article from the perspective of specific models and frameworks, as well as\nreflections based on software process engineering models and standards. In\naddition, a set of strategic drivers is proposed to assist the implementation\nof a Strategic Plan for a SPI Program which can be considered by the\norganizations before starting this kind of Program.",
    "descriptor": "\nComments: InSITE Conference - Tampa, USA - 2015\n",
    "authors": [
      "Rogerio Rossi",
      "Kechi Hirama"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08679"
  },
  {
    "id": "arXiv:2201.08680",
    "title": "Minrank of Embedded Index Coding Problems and its Relation to  Connectedness of a Bipartite Graph",
    "abstract": "This paper deals with embedded index coding problem (EICP), introduced by A.\nPorter and M. Wootters, which is a decentralized communication problem among\nusers with side information. An alternate definition of the parameter minrank\nof an EICP, which has reduced computational complexity compared to the existing\ndefinition, is presented. A graphical representation for an EICP is given using\ndirected bipartite graphs, called bipartite problem graph, and the side\ninformation alone is represented using an undirected bipartite graph called the\nside information bipartite graph. Inspired by the well-studied single unicast\nindex coding problem (SUICP), graphical structures, similar to cycles and\ncliques in the side information graph of an SUICP, are identified in the side\ninformation bipartite graph of a single unicast embedded index coding problem\n(SUEICP). Transmission schemes based on these graphical structures, called tree\ncover scheme and bi-clique cover scheme are also presented for an SUEICP. Also,\na relation between connectedness of the side information bipartite graph and\nthe number of transmissions required in a scalar linear solution of an EICP is\nestablished.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Anjana A Mahesh",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08680"
  },
  {
    "id": "arXiv:2201.08683",
    "title": "A Comprehensive Study of Vision Transformers on Dense Prediction Tasks",
    "abstract": "Convolutional Neural Networks (CNNs), architectures consisting of\nconvolutional layers, have been the standard choice in vision tasks. Recent\nstudies have shown that Vision Transformers (VTs), architectures based on\nself-attention modules, achieve comparable performance in challenging tasks\nsuch as object detection and semantic segmentation. However, the image\nprocessing mechanism of VTs is different from that of conventional CNNs. This\nposes several questions about their generalizability, robustness, reliability,\nand texture bias when used to extract features for complex tasks. To address\nthese questions, we study and compare VT and CNN architectures as feature\nextractors in object detection and semantic segmentation. Our extensive\nempirical results show that the features generated by VTs are more robust to\ndistribution shifts, natural corruptions, and adversarial attacks in both\ntasks, whereas CNNs perform better at higher image resolutions in object\ndetection. Furthermore, our results demonstrate that VTs in dense prediction\ntasks produce more reliable and less texture-biased predictions.",
    "descriptor": "\nComments: 17th International Conference on Computer Vision Theory and Applications (VISAP, 2022)\n",
    "authors": [
      "Kishaan Jeeveswaran",
      "Senthilkumar Kathiresan",
      "Arnav Varma",
      "Omar Magdy",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08683"
  },
  {
    "id": "arXiv:2201.08684",
    "title": "VisQualdex -- the comprehensive guide to good data visualization",
    "abstract": "The rapid influx of low-quality data visualisations is one of the main\nchallenges in today's communication. Misleading, unreadable, or confusing\nvisualisations spread misinformation, failing to fulfill their purpose. The\nlack of proper tooling further heightens the problem of the quality assessment\nprocess. Therefore, we propose VisQualdex, a systematic set of guidelines\nisnpired by the Grammar of Graphics for evaluating the quality of data\nvisualisations. To increase the practical impact of VisQualdex, we make these\nguidelines available in the form of the web server, visqual.info.",
    "descriptor": "",
    "authors": [
      "Jan Sawicki",
      "Micha\u0142 Burdukiewicz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.08684"
  },
  {
    "id": "arXiv:2201.08686",
    "title": "Modelling Agent-Skipping Attacks in Message Forwarding Protocols",
    "abstract": "Message forwarding protocols are protocols in which a chain of agents handles\ntransmission of a message. Each agent forwards the received message to the next\nagent in the chain. For example, TLS middleboxes act as intermediary agents in\nTLS, adding functionality such as filtering or compressing data. In such\nprotocols, an attacker may attempt to bypass one or more intermediary agents.\nSuch an agent-skipping attack can the violate security requirements of the\nprotocol. Using the multiset rewriting model in the symbolic setting, we\nconstruct a comprehensive framework of such path protocols. In particular, we\nintroduce a set of security goals related to path integrity: the notion that a\nmessage faithfully travels through participants in the order intended by the\ninitiating agent. We perform a security analysis of several such protocols,\nhighlighting key attacks on modern protocols.",
    "descriptor": "",
    "authors": [
      "Zach Smith",
      "Hugo Jonker",
      "Sjouke Mauw",
      "Hyunwoo Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08686"
  },
  {
    "id": "arXiv:2201.08687",
    "title": "A Comparative Study on Language Models for Task-Oriented Dialogue  Systems",
    "abstract": "The recent development of language models has shown promising results by\nachieving state-of-the-art performance on various natural language tasks by\nfine-tuning pretrained models. In task-oriented dialogue (ToD) systems,\nlanguage models can be used for end-to-end training without relying on dialogue\nstate tracking to track the dialogue history but allowing the language models\nto generate responses according to the context given as input. This paper\nconducts a comparative study to show the effectiveness and strength of using\nrecent pretrained models for fine-tuning, such as BART and T5, on endto-end ToD\nsystems. The experimental results show substantial performance improvements\nafter language model fine-tuning. The models produce more fluent responses\nafter adding knowledge to the context that guides the model to avoid\nhallucination and generate accurate entities in the generated responses.\nFurthermore, we found that BART and T5 outperform GPT-based models in BLEU and\nF1 scores and achieve state-of-the-art performance in a ToD system.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Vinsen Marselino Andreas",
      "Genta Indra Winata",
      "Ayu Purwarianti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08687"
  },
  {
    "id": "arXiv:2201.08688",
    "title": "Physical Activity Recognition by Utilising Smartphone Sensor Signals",
    "abstract": "Human physical motion activity identification has many potential applications\nin various fields, such as medical diagnosis, military sensing, sports\nanalysis, and human-computer security interaction. With the recent advances in\nsmartphones and wearable technologies, it has become common for such devices to\nhave embedded motion sensors that are able to sense even small body movements.\nThis study collected human activity data from 60 participants across two\ndifferent days for a total of six activities recorded by gyroscope and\naccelerometer sensors in a modern smartphone. The paper investigates to what\nextent different activities can be identified by utilising machine learning\nalgorithms using approaches such as majority algorithmic voting. More analyses\nare also provided that reveal which time and frequency domain based features\nwere best able to identify individuals motion activity types. Overall, the\nproposed approach achieved a classification accuracy of 98 percent in\nidentifying four different activities: walking, walking upstairs, walking\ndownstairs, and sitting while the subject is calm and doing a typical\ndesk-based activity.",
    "descriptor": "\nComments: 10 pages, 10 figures, conference\n",
    "authors": [
      "Abdulrahman Alruban",
      "Hind Alobaidi",
      "Nathan Clarke' Fudong Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08688"
  },
  {
    "id": "arXiv:2201.08690",
    "title": "A deep learning energy method for hyperelasticity and viscoelasticity",
    "abstract": "The potential energy formulation and deep learning are merged to solve\npartial differential equations governing the deformation in hyperelastic and\nviscoelastic materials. The presented deep energy method (DEM) is\nself-contained and meshfree. It can accurately capture the three-dimensional\n(3D) mechanical response without requiring any time-consuming training data\ngeneration by classical numerical methods such as the finite element method.\nOnce the model is appropriately trained, the response can be attained almost\ninstantly at any point in the physical domain, given its spatial coordinates.\nTherefore, the deep energy method is potentially a promising standalone method\nfor solving partial differential equations describing the mechanical\ndeformation of materials or structural systems and other physical phenomena.",
    "descriptor": "",
    "authors": [
      "Diab W. Abueidda",
      "Seid Koric",
      "Rashid Abu Al-Rub",
      "Corey M. Parrott",
      "Kai A. James",
      "Nahil A. Sobh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08690"
  },
  {
    "id": "arXiv:2201.08697",
    "title": "Verilay: A Verifiable Proof of Stake Chain Relay",
    "abstract": "Blockchain relay schemes enable cross-chain state proofs without requiring\ntrusted intermediaries. This is achieved by applying the source blockchain's\nconsensus validation protocol on the target blockchain. Existing chain relays\nallow for the validation of blocks created using the Proof of Work (PoW)\nprotocol. Since PoW entails high energy consumption, limited throughput, and no\nguaranteed finality, Proof of Stake (PoS) blockchain protocols are increasingly\npopular for addressing these shortcomings. We propose Verilay, the first chain\nrelay scheme that enables validating PoS protocols that produce finalized\nblocks, for example, Ethereum 2.0, Cosmos, and Polkadot. The concept does not\nrequire changes to the source blockchain protocols or validator operations.\nSignatures of block proposers are validated by a dedicated relay smart contract\non the target blockchain. In contrast to basic PoW chain relays, Verilay\nrequires only a subset of block headers to be submitted in order to maintain\nfull verifiability. This yields enhanced scalability. We provide a prototypical\nimplementation that facilitates the validation of Ethereum 2.0 beacon chain\nheaders within the Ethereum Virtual Machine (EVM). Our evaluation proves the\napplicability to Ethereum 1.0's mainnet and confirms that only a fraction of\ntransaction costs are required compared to PoW chain relay updates.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Martin Westerkamp",
      "Maximilian Diez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08697"
  },
  {
    "id": "arXiv:2201.08698",
    "title": "Natural Attack for Pre-trained Models of Code",
    "abstract": "Pre-trained models of code have achieved success in many important software\nengineering tasks. However, these powerful models are vulnerable to adversarial\nattacks that slightly perturb model inputs to make a victim model produce wrong\noutputs. Current works mainly attack models of code with examples that preserve\noperational program semantics but ignore a fundamental requirement for\nadversarial example generation: perturbations should be natural to human\njudges, which we refer to as naturalness requirement.\nIn this paper, we propose ALERT (nAturaLnEss AwaRe ATtack), a black-box\nattack that adversarially transforms inputs to make victim models produce wrong\noutputs. Different from prior works, this paper considers the natural semantic\nof generated examples at the same time as preserving the operational semantic\nof original inputs. Our user study demonstrates that human developers\nconsistently consider that adversarial examples generated by ALERT are more\nnatural than those generated by the state-of-the-art work by Zhang et al. that\nignores the naturalness requirement. On attacking CodeBERT, our approach can\nachieve attack success rates of 53.62%, 27.79%, and 35.78% across three\ndownstream tasks: vulnerability prediction, clone detection and code authorship\nattribution. On GraphCodeBERT, our approach can achieve average success rates\nof 76.95%, 7.96% and 61.47% on the three tasks. The above outperforms the\nbaseline by 14.07% and 18.56% on the two pre-trained models on average.\nFinally, we investigated the value of the generated adversarial examples to\nharden victim models through an adversarial fine-tuning procedure and\ndemonstrated the accuracy of CodeBERT and GraphCodeBERT against ALERT-generated\nadversarial examples increased by 87.59% and 92.32%, respectively.",
    "descriptor": "\nComments: Accepted to the Technical Track of ICSE 2022\n",
    "authors": [
      "Zhou Yang",
      "Jieke Shi",
      "Junda He",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08698"
  },
  {
    "id": "arXiv:2201.08701",
    "title": "SmartSync: Cross-Blockchain Smart Contract Interaction and  Synchronization",
    "abstract": "Cross-Blockchain communication has gained traction due to the increasing\nfragmentation of blockchain networks and scalability solutions such as\nside-chaining and sharding. With SmartSync, we propose a novel concept for\ncross-blockchain smart contract interactions that creates client contracts on\narbitrary blockchain networks supporting the same execution environment. Client\ncontracts mirror the logic and state of the original instance and enable\nseamless on-chain function executions providing recent states. Synchronized\ncontracts supply instant read-only function calls to other applications hosted\non the target blockchain. Hereby, current limitations in cross-chain\ncommunication are alleviated and new forms of contract interactions are\nenabled. State updates are transmitted in a verifiable manner using Merkle\nproofs and do not require trusted intermediaries. To permit lightweight\nsynchronizations, we introduce transition confirmations that facilitate the\napplication of verifiable state transitions without re-executing transactions\nof the source blockchain. We prove the concept's soundness by providing a\nprototypical implementation that enables smart contract forks, state\nsynchronizations, and on-chain validation on EVM-compatible blockchains. Our\nevaluation demonstrates SmartSync's applicability for presented use cases\nproviding access to recent states to third-party contracts on the target\nblockchain. Execution costs scale sub-linearly with the number of value updates\nand depend on the depth and index of corresponding Merkle proofs.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Martin Westerkamp",
      "Axel K\u00fcpper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.08701"
  },
  {
    "id": "arXiv:2201.08702",
    "title": "Dual Contrastive Learning: Text Classification via Label-Aware Data  Augmentation",
    "abstract": "Contrastive learning has achieved remarkable success in representation\nlearning via self-supervision in unsupervised settings. However, effectively\nadapting contrastive learning to supervised learning tasks remains as a\nchallenge in practice. In this work, we introduce a dual contrastive learning\n(DualCL) framework that simultaneously learns the features of input samples and\nthe parameters of classifiers in the same space. Specifically, DualCL regards\nthe parameters of the classifiers as augmented samples associating to different\nlabels and then exploits the contrastive learning between the input samples and\nthe augmented samples. Empirical studies on five benchmark text classification\ndatasets and their low-resource version demonstrate the improvement in\nclassification accuracy and confirm the capability of learning discriminative\nrepresentations of DualCL.",
    "descriptor": "\nComments: 8 pages, 4 figures, under review\n",
    "authors": [
      "Qianben Chen",
      "Richong Zhang",
      "Yaowei Zheng",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08702"
  },
  {
    "id": "arXiv:2201.08704",
    "title": "Adaptive Data Analysis with Correlated Observations",
    "abstract": "The vast majority of the work on adaptive data analysis focuses on the case\nwhere the samples in the dataset are independent. Several approaches and tools\nhave been successfully applied in this context, such as differential privacy,\nmax-information, compression arguments, and more. The situation is far less\nwell-understood without the independence assumption.\nWe embark on a systematic study of the possibilities of adaptive data\nanalysis with correlated observations. First, we show that, in some cases,\ndifferential privacy guarantees generalization even when there are dependencies\nwithin the sample, which we quantify using a notion we call Gibbs-dependence.\nWe complement this result with a tight negative example. Second, we show that\nthe connection between transcript-compression and adaptive data analysis can be\nextended to the non-iid setting.",
    "descriptor": "",
    "authors": [
      "Aryeh Kontorovich",
      "Menachem Sadigurschi",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08704"
  },
  {
    "id": "arXiv:2201.08717",
    "title": "Personality Type Based on Myers-Briggs Type Indicator with Text Posting  Style by using Traditional and Deep Learning",
    "abstract": "The term personality may be expressed in terms of the individual differences\nin characteristics pattern of thinking, feeling, and behavior. This work\npresents several machine learning techniques including Naive Bayes, Support\nVector Machines, and Recurrent Neural Networks to predict people personality\nfrom text based on Myers-Briggs Type Indicator (MBTI). Furthermore, this\nproject applies CRISP-DM, which stands for Cross-Industry Standard Process for\nData Mining, to guide the learning process. Since, CRISP-DM is kind of\niterative development, we have adopted it with agile methodology, which is a\nrapid iterative software development method, in order to reduce the development\ncycle to be minimal.",
    "descriptor": "\nComments: 10 pages, 14 figures, this work was presented at the 11th Joint Symposium on Computational Intelligence (JSCI11)\n",
    "authors": [
      "Sakdipat Ontoum",
      "Jonathan H. Chan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08717"
  },
  {
    "id": "arXiv:2201.08718",
    "title": "Health literacy in e-oncology care: challenges and strategies",
    "abstract": "Given the impact of health literacy (HL) on patients outcomes, limited health\nliteracy (LHL) is a major barrier in cancer care globally. HL refers to the\ndegree in which an individual is able to acquire, process and comprehend\ninformation in a way to be actively involved in their health decisions.\nPrevious research found that almost half of the population in developed\ncountries have difficulties in understanding health related information. With\nthe gradual shift toward the shared decision making (SDM) process and digital\ntransformation in oncology, the need for dealing with low HL issues is more\ncrucial. Decision making in oncology is often accompanied by considerable\nconsequences on patients lives, which requires patients to understand complex\ninformation and be able to compare treatment methods by considering their own\nvalues. How health information is perceived by patients is influenced by\nvarious factors including patients characteristics and the way information is\npresented to patients. Based on the findings, identifying patients with low HL\nand using simple data visualizations are the best practice to help patients and\nclinicians in dealing with LHL. Furthermore, preparing reliable sources of\ninformation in tools such as patient decision aids (PDA), as well as involving\nHL mediators in consultation sessions supports patients to make sense of\ncomplex information.",
    "descriptor": "",
    "authors": [
      "Hajar Hasannejadasl",
      "Cheryl Roumen",
      "Yolba Smit",
      "Andre Dekker",
      "Rianne Fijten"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.08718"
  },
  {
    "id": "arXiv:2201.08720",
    "title": "Cyber-physical components of an autonomous and scalable SLES",
    "abstract": "Adding renewable energy sources and storage units to an electric grid has led\nto a change in the way energy is generated and billed. This shift cannot be\nmanaged without a unified view of energy systems and their components. This\nunified view is captured within the idea of a Smart Local Energy System (SLES).\nCurrently, various isolated control and market elements are proposed to resolve\nnetwork constraints, demand side response and utility optimisation. They rely\non topology estimations, forecasting and fault detection methods to complete\ntheir tasks. This disjointed design has led to most systems being capable of\nfulfilling only a single role or being resistant to change and extensions in\nfunctionality. By allocating roles, functional responsibilities and technical\nrequirements to bounded systems a more unified view of energy systems can be\nachieved. This is made possible by representing an energy system as a\ndistributed peer-to-peer (P2P) environment where each individual demand energy\nresource (DER) on the consumer's side of the meter is responsible for their\nportion of the network and can facilitate trade with numerous entities\nincluding the grid. Advances in control engineering, markets and services such\nas forecasting, topology identification and cyber-security can enable such\ntrading and communication to be done securely and robustly. To enable this\nadvantage however, we need to redefine how we view the design of the\nsub-systems and interconnections within smart local energy systems (SLES). In\nthis paper we describe a way in which whole system design could be achieved by\nintegrating control, markets and analytics into each system. We propose the use\nof physical, control, market and service layers to create system of systems\nrepresentation.",
    "descriptor": "\nComments: 14 Pages White paper\n",
    "authors": [
      "Nandor Verba",
      "Pablo Baldivieso-Monasterios",
      "Siyuan Dong",
      "Andrei Braitor",
      "George Konstantopoulos",
      "Elena Gaura",
      "Euan Morris",
      "Alison Halford",
      "Colin Stephen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.08720"
  },
  {
    "id": "arXiv:2201.08721",
    "title": "Less is Less: When Are Snippets Insufficient for Human vs Machine  Relevance Estimation?",
    "abstract": "Traditional information retrieval (IR) ranking models process the full text\nof documents. Newer models based on Transformers, however, would incur a high\ncomputational cost when processing long texts, so typically use only snippets\nfrom the document instead. The model's input based on a document's URL, title,\nand snippet (UTS) is akin to the summaries that appear on a search engine\nresults page (SERP) to help searchers decide which result to click. This raises\nquestions about when such summaries are sufficient for relevance estimation by\nthe ranking model or the human assessor, and whether humans and machines\nbenefit from the document's full text in similar ways. To answer these\nquestions, we study human and neural model based relevance assessments on 12k\nquery-documents sampled from Bing's search logs. We compare changes in the\nrelevance assessments when only the document summaries and when the full text\nis also exposed to assessors, studying a range of query and document\nproperties, e.g., query type, snippet length. Our findings show that the full\ntext is beneficial for humans and a BERT model for similar query and document\ntypes, e.g., tail, long queries. A closer look, however, reveals that humans\nand machines respond to the additional input in very different ways. Adding the\nfull text can also hurt the ranker's performance, e.g., for navigational\nqueries.",
    "descriptor": "",
    "authors": [
      "Gabriella Kazai",
      "Bhaskar Mitra",
      "Anlei Dong",
      "Nick Craswell",
      "Linjun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08721"
  },
  {
    "id": "arXiv:2201.08724",
    "title": "Sequential Item Recommendation in the MOBA Game Dota 2",
    "abstract": "Multiplayer Online Battle Arena (MOBA) games such as Dota 2 attract hundreds\nof thousands of players every year. Despite the large player base, it is still\nimportant to attract new players to prevent the community of a game from\nbecoming inactive. Entering MOBA games is, however, often demanding, requiring\nthe player to learn numerous skills at once. An important factor of success is\nbuying the correct items which forms a complex task depending on various\nin-game factors such as already purchased items, the team composition, or\navailable resources. A recommendation system can support players by reducing\nthe mental effort required to choose a suitable item, helping, e.g., newer\nplayers or players returning to the game after a longer break, to focus on\nother aspects of the game. Since Sequential Item Recommendation (SIR) has\nproven to be effective in various domains (e.g. e-commerce, movie\nrecommendation or playlist continuation), we explore the applicability of\nwell-known SIR models in the context of purchase recommendations in Dota 2. To\nfacilitate this research, we collect, analyze and publish Dota-350k, a new\nlarge dataset based on recent Dota 2 matches. We find that SIR models can be\nemployed effectively for item recommendation in Dota 2. Our results show that\nmodels that consider the order of purchases are the most effective. In contrast\nto other domains, we find RNN-based models to outperform the more recent\nTransformer-based architectures on Dota-350k.",
    "descriptor": "",
    "authors": [
      "Alexander Dallmann",
      "Johannes Kohlmann",
      "Daniel Zoller",
      "Andreas Hotho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.08724"
  },
  {
    "id": "arXiv:2201.08731",
    "title": "Low-Interception Waveform: To Prevent the Recognition of Spectrum  Waveform Modulation via Adversarial Examples",
    "abstract": "Deep learning is applied to many complex tasks in the field of wireless\ncommunication, such as modulation recognition of spectrum waveforms, because of\nits convenience and efficiency. This leads to the problem of a malicious third\nparty using a deep learning model to easily recognize the modulation format of\nthe transmitted waveform. Some existing works address this problem directly\nusing the concept of adversarial examples in the image domain without fully\nconsidering the characteristics of the waveform transmission in the physical\nworld. Therefore, we propose a low-intercept waveform~(LIW) generation method\nthat can reduce the probability of the modulation being recognized by a third\nparty without affecting the reliable communication of the friendly party. Our\nLIW exhibits significant low-interception performance even in the physical\nhardware experiment, decreasing the accuracy of the state of the art model to\napproximately $15\\%$ with small perturbations.",
    "descriptor": "\nComments: 4 pages, 4 figures, published in 2021 34th General Assembly and Scientific Symposium of the International Union of Radio Science, URSI GASS 2021\n",
    "authors": [
      "Haidong Xie",
      "Jia Tan",
      "Xiaoying Zhang",
      "Nan Ji",
      "Haihua Liao",
      "Zuguo Yu",
      "Xueshuang Xiang",
      "Naijin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08731"
  },
  {
    "id": "arXiv:2201.08732",
    "title": "Meta Learning MDPs with Linear Transition Models",
    "abstract": "We study meta-learning in Markov Decision Processes (MDP) with linear\ntransition models in the undiscounted episodic setting. Under a task sharedness\nmetric based on model proximity we study task families characterized by a\ndistribution over models specified by a bias term and a variance component. We\nthen propose BUC-MatrixRL, a version of the UC-Matrix RL algorithm, and show it\ncan meaningfully leverage a set of sampled training tasks to quickly solve a\ntest task sampled from the same task distribution by learning an estimator of\nthe bias parameter of the task distribution. The analysis leverages and extends\nresults in the learning to learn linear regression and linear bandit setting to\nthe more general case of MDP's with linear transition models. We prove that\ncompared to learning the tasks in isolation, BUC-Matrix RL provides significant\nimprovements in the transfer regret for high bias low variance task\ndistributions.",
    "descriptor": "",
    "authors": [
      "Robert M\u00fcller",
      "Aldo Pacchiano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08732"
  },
  {
    "id": "arXiv:2201.08738",
    "title": "Bounds for Privacy-Utility Trade-off with Non-zero Leakage",
    "abstract": "The design of privacy mechanisms for two scenarios is studied where the\nprivate data is hidden or observable. In the first scenario, an agent observes\nuseful data $Y$, which is correlated with private data $X$, and wants to\ndisclose the useful information to a user. A privacy mechanism is employed to\ngenerate data $U$ that maximizes the revealed information about $Y$ while\nsatisfying a privacy criterion. In the second scenario, the agent has\nadditionally access to the private data. To this end, the Functional\nRepresentation Lemma and Strong Functional Representation Lemma are extended\nrelaxing the independence condition and thereby allowing a certain leakage.\nLower bounds on privacy-utility trade-off are derived for the second scenario\nas well as upper bounds for both scenarios. In particular, for the case where\nno leakage is allowed, our upper and lower bounds improve previous bounds.",
    "descriptor": "",
    "authors": [
      "Amirreza Zamani",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08738"
  },
  {
    "id": "arXiv:2201.08739",
    "title": "Privacy Policies Across the Ages: Content and Readability of Privacy  Policies 1996--2021",
    "abstract": "It is well-known that most users do not read privacy policies, but almost all\nusers tick the box to agree with them. In this paper, we analyze the 25-year\nhistory of privacy policies using methods from transparency research, machine\nlearning, and natural language processing. Specifically, we collect a\nlarge-scale longitudinal corpus of privacy policies from 1996 to 2021 and\nanalyze the length and readability of privacy policies as well as their content\nin terms of the data practices they describe, the rights they grant to users,\nand the rights they reserve for their organizations. We pay particular\nattention to changes in response to recent privacy regulations such as the GDPR\nand CCPA. Our results show that policies are getting longer and harder to read,\nespecially after new regulations take effect, and we find a range of concerning\ndata practices. Our results allow us to speculate why privacy policies are\nrarely read and propose changes that would make privacy policies serve their\nreaders instead of their writers.",
    "descriptor": "\nComments: submitted\n",
    "authors": [
      "Isabel Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08739"
  },
  {
    "id": "arXiv:2201.08742",
    "title": "Towards Building Economic Models of Conversational Search",
    "abstract": "Various conceptual and descriptive models of conversational search have been\nproposed in the literature -- while useful, they do not provide insights into\nhow interaction between the agent and user would change in response to the\ncosts and benefits of the different interactions. In this paper, we develop two\neconomic models of conversational search based on patterns previously observed\nduring conversational search sessions, which we refer to as: Feedback First\nwhere the agent asks clarifying questions then presents results, and Feedback\nAfter where the agent presents results, and then asks follow up questions. Our\nmodels show that the amount of feedback given/requested depends on its\nefficiency at improving the initial or subsequent query and the relative cost\nof providing said feedback. This theoretical framework for conversational\nsearch provides a number of insights that can be used to guide and inform the\ndevelopment of conversational search agents. However, empirical work is needed\nto estimate the parameters in order to make predictions specific to a given\nconversational search setting.",
    "descriptor": "\nComments: To appear in ECIR 2022\n",
    "authors": [
      "Leif Azzopardi",
      "Mohammad Aliannejadi",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08742"
  },
  {
    "id": "arXiv:2201.08744",
    "title": "Impacts of Students Academic Performance Trajectories on Final Academic  Success",
    "abstract": "Many studies in the field of education analytics have identified student\ngrade point averages (GPA) as an important indicator and predictor of students'\nfinal academic outcomes (graduate or halt). And while semester-to-semester\nfluctuations in GPA are considered normal, significant changes in academic\nperformance may warrant more thorough investigation and consideration,\nparticularly with regards to final academic outcomes. However, such an approach\nis challenging due to the difficulties of representing complex academic\ntrajectories over an academic career. In this study, we apply a Hidden Markov\nModel (HMM) to provide a standard and intuitive classification over students'\nacademic-performance levels, which leads to a compact representation of\nacademic-performance trajectories. Next, we explore the relationship between\ndifferent academic-performance trajectories and their correspondence to final\nacademic success. Based on student transcript data from University of Central\nFlorida, our proposed HMM is trained using sequences of students' course grades\nfor each semester. Through the HMM, our analysis follows the expected finding\nthat higher academic performance levels correlate with lower halt rates.\nHowever, in this paper, we identify that there exist many scenarios in which\nboth improving or worsening academic-performance trajectories actually\ncorrelate to higher graduation rates. This counter-intuitive finding is made\npossible through the proposed and developed HMM model.",
    "descriptor": "",
    "authors": [
      "Shahab Boumi",
      "Adan Vela"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08744"
  },
  {
    "id": "arXiv:2201.08746",
    "title": "ERS: a novel comprehensive endoscopy image dataset for machine learning,  compliant with the MST 3.0 specification",
    "abstract": "The article presents a new multi-label comprehensive image dataset from\nflexible endoscopy, colonoscopy and capsule endoscopy, named ERS. The\ncollection has been labeled according to the full medical specification of\n'Minimum Standard Terminology 3.0' (MST 3.0), describing all possible findings\nin the gastrointestinal tract (104 possible labels), extended with an\nadditional 19 labels useful in common machine learning applications.\nThe dataset contains around 6000 precisely and 115,000 approximately labeled\nframes from endoscopy videos, 3600 precise and 22,600 approximate segmentation\nmasks, and 1.23 million unlabeled frames from flexible and capsule endoscopy\nvideos. The labeled data cover almost entirely the MST 3.0 standard. The data\ncame from 1520 videos of 1135 patients.\nAdditionally, this paper proposes and describes four exemplary experiments in\ngastrointestinal image classification task performed using the created dataset.\nThe obtained results indicate the high usefulness and flexibility of the\ndataset in training and testing machine learning algorithms in the field of\nendoscopic data analysis.",
    "descriptor": "",
    "authors": [
      "Jan Cychnerski",
      "Tomasz Dziubich",
      "Adam Brzeski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08746"
  },
  {
    "id": "arXiv:2201.08753",
    "title": "Fixed-point cycles and EFX allocations",
    "abstract": "We study edge-labelings of the complete bidirected graph\n$\\overset{\\tiny\\leftrightarrow}{K}_n$ with functions from the set $[d] = \\{1,\n\\dots, d\\}$ to itself. We call a cycle in $\\overset{\\tiny\\leftrightarrow}{K}_n$\na fixed-point cycle if composing the labels of its edges results in a map that\nhas a fixed point, and we say that a labeling is fixed-point-free if no\nfixed-point cycle exists. For a given $d$, we ask for the largest value of $n$,\ndenoted $R_f(d)$, for which there exists a fixed-point-free labeling of\n$\\overset{\\tiny\\leftrightarrow}{K}_n$. Determining $R_f(d)$ for all $d >0$ is a\nnatural Ramsey-type question, generalizing some well-studied zero-sum problems\nin extremal combinatorics. The problem was recently introduced by Chaudhury,\nGarg, Mehlhorn, Mehta, and Misra, who proved that $d \\leq R_f(d) \\leq d^4+d$\nand showed that the problem has close connections to EFX allocations, a central\nproblem of fair allocation in social choice theory.\nIn this paper we show the improved bound $R_f(d) \\leq d^{2 + o(1)}$, yielding\nan efficient ${{(1-\\varepsilon)}}$-EFX allocation with $n$ agents and\n$O(n^{0.67})$ unallocated goods for any constant $\\varepsilon \\in (0,1/2]$;\nthis improves the bound of $O(n^{0.8})$ of Chaudhury, Garg, Mehlhorn, Mehta,\nand Misra.\nAdditionally, we prove the stronger upper bound $2d-2$, in the case where all\nedge-labels are permulations. A very special case of this problem, that of\nfinding zero-sum cycles in digraphs whose edges are labeled with elements of\n$\\mathbb{Z}_d$, was recently considered by Alon and Krivelevich and by\nM\\'{e}sz\\'{a}ros and Steiner. Our result improves the bounds obtained by these\nauthors and extends them to labelings from an arbitrary (not necessarily\ncommutative) group, while also simplifying the proof.",
    "descriptor": "",
    "authors": [
      "Benjamin Aram Berendsohn",
      "Simona Boyadzhiyska",
      "L\u00e1szl\u00f3 Kozma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08753"
  },
  {
    "id": "arXiv:2201.08763",
    "title": "Object Detection in Aerial Images: What Improves the Accuracy?",
    "abstract": "Object detection is a challenging and popular computer vision problem. The\nproblem is even more challenging in aerial images due to significant variation\nin scale and viewpoint in a diverse set of object categories. Recently, deep\nlearning-based object detection approaches have been actively explored for the\nproblem of object detection in aerial images. In this work, we investigate the\nimpact of Faster R-CNN for aerial object detection and explore numerous\nstrategies to improve its performance for aerial images. We conduct extensive\nexperiments on the challenging iSAID dataset. The resulting adapted Faster\nR-CNN obtains a significant mAP gain of 4.96% over its vanilla baseline\ncounterpart on the iSAID validation set, demonstrating the impact of different\nstrategies investigated in this work.",
    "descriptor": "\nComments: 8 pages, 14 Figures\n",
    "authors": [
      "Hashmat Shadab Malik",
      "Ikboljon Sobirov",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08763"
  },
  {
    "id": "arXiv:2201.08768",
    "title": "On probability-raising causality in Markov decision processes",
    "abstract": "The purpose of this paper is to introduce a notion of causality in Markov\ndecision processes based on the probability-raising principle and to analyze\nits algorithmic properties. The latter includes algorithms for checking\ncause-effect relationships and the existence of probability-raising causes for\ngiven effect scenarios. Inspired by concepts of statistical analysis, we study\nquality measures (recall, coverage ratio and f-score) for causes and develop\nalgorithms for their computation. Finally, the computational complexity for\nfinding optimal causes with respect to these measures is analyzed.",
    "descriptor": "\nComments: This is the extended version of a conference version accepted for publication at FoSSaCS 2022\n",
    "authors": [
      "Christel Baier",
      "Florian Funke",
      "Jakob Piribauer",
      "Robin Ziemek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.08768"
  },
  {
    "id": "arXiv:2201.08770",
    "title": "Evaluating Generalization in Classical and Quantum Generative Models",
    "abstract": "Defining and accurately measuring generalization in generative models remains\nan ongoing challenge and a topic of active research within the machine learning\ncommunity. This is in contrast to discriminative models, where there is a clear\ndefinition of generalization, i.e., the model's classification accuracy when\nfaced with unseen data. In this work, we construct a simple and unambiguous\napproach to evaluate the generalization capabilities of generative models.\nUsing the sample-based generalization metrics proposed here, any generative\nmodel, from state-of-the-art classical generative models such as GANs to\nquantum models such as Quantum Circuit Born Machines, can be evaluated on the\nsame ground on a concrete well-defined framework. In contrast to other\nsample-based metrics for probing generalization, we leverage constrained\noptimization problems (e.g., cardinality constrained problems) and use these\ndiscrete datasets to define specific metrics capable of unambiguously measuring\nthe quality of the samples and the model's generalization capabilities for\ngenerating data beyond the training set but still within the valid solution\nspace. Additionally, our metrics can diagnose trainability issues such as mode\ncollapse and overfitting, as we illustrate when comparing GANs to\nquantum-inspired models built out of tensor networks. Our simulation results\nshow that our quantum-inspired models have up to a $68 \\times$ enhancement in\ngenerating unseen unique and valid samples compared to GANs, and a ratio of\n61:2 for generating samples with better quality than those observed in the\ntraining set. We foresee these metrics as valuable tools for rigorously\ndefining practical quantum advantage in the domain of generative modeling.",
    "descriptor": "\nComments: 24 pages, 14 figures\n",
    "authors": [
      "Kaitlin Gili",
      "Marta Mauri",
      "Alejandro Perdomo-Ortiz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08770"
  },
  {
    "id": "arXiv:2201.08772",
    "title": "Under-Approximating Expected Total Rewards in POMDPs",
    "abstract": "We consider the problem: is the optimal expected total reward to reach a goal\nstate in a partially observable Markov decision process (POMDP) below a given\nthreshold? We tackle this -- generally undecidable -- problem by computing\nunder-approximations on these total expected rewards. This is done by\nabstracting finite unfoldings of the infinite belief MDP of the POMDP. The key\nissue is to find a suitable under-approximation of the value function. We\nprovide two techniques: a simple (cut-off) technique that uses a good policy on\nthe POMDP, and a more advanced technique (belief clipping) that uses minimal\nshifts of probabilities between beliefs. We use mixed-integer linear\nprogramming (MILP) to find such minimal probability shifts and experimentally\nshow that our techniques scale quite well while providing tight lower bounds on\nthe expected total reward.",
    "descriptor": "\nComments: Technical report for TACAS 2022 paper with the same title\n",
    "authors": [
      "Alexander Bork",
      "Joost-Pieter Katoen",
      "Tim Quatmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.08772"
  },
  {
    "id": "arXiv:2201.08774",
    "title": "Two for One $\\&$ One for All: Two-Sided Manipulation in Matching Markets",
    "abstract": "Strategic behavior in two-sided matching markets has been traditionally\nstudied in a \"one-sided\" manipulation setting where the agent who misreports is\nalso the intended beneficiary. Our work investigates \"two-sided\" manipulation\nof the deferred acceptance algorithm where the misreporting agent and the\nmanipulator (or beneficiary) are on different sides. Specifically, we\ngeneralize the recently proposed accomplice manipulation model (where a man\nmisreports on behalf of a woman) along two complementary dimensions: (a) the\ntwo for one model, with a pair of misreporting agents (man and woman) and a\nsingle beneficiary (the misreporting woman), and (b) the one for all model,\nwith one misreporting agent (man) and a coalition of beneficiaries (all women).\nOur main contribution is to develop polynomial-time algorithms for finding an\noptimal manipulation in both settings. We obtain these results despite the fact\nthat an optimal one for all strategy fails to be inconspicuous, while it is\nunclear whether an optimal two for one strategy satisfies the inconspicuousness\nproperty. We also study the conditions under which stability of the resulting\nmatching is preserved. Experimentally, we show that two-sided manipulations are\nmore frequently available and offer better quality matches than their one-sided\ncounterparts.",
    "descriptor": "",
    "authors": [
      "Hadi Hosseini",
      "Fatima Umar",
      "Rohit Vaish"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.08774"
  },
  {
    "id": "arXiv:2201.08778",
    "title": "Mitigating Smart Jammers in MU-MIMO via Joint Channel Estimation and  Data Detection",
    "abstract": "Wireless systems must be resilient to jamming attacks. Existing mitigation\nmethods require knowledge of the jammer's transmit characteristics. However,\nthis knowledge may be difficult to acquire, especially for smart jammers that\nattack only specific instants during transmission in order to evade mitigation.\nWe propose a novel method that mitigates attacks by smart jammers on massive\nmulti-user multiple-input multiple-output (MU-MIMO) basestations (BSs). Our\napproach builds on recent progress in joint channel estimation and data\ndetection (JED) and exploits the fact that a jammer cannot change its subspace\nwithin a coherence interval. Our method, called MAED (short for MitigAtion,\nEstimation, and Detection), uses a novel problem formulation that combines\njammer estimation and mitigation, channel estimation, and data detection,\ninstead of separating these tasks. We solve the problem approximately with an\nefficient iterative algorithm. Our results show that MAED effectively mitigates\na wide range of smart jamming attacks without having any a priori knowledge\nabout the attack type.",
    "descriptor": "",
    "authors": [
      "Gian Marti",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08778"
  },
  {
    "id": "arXiv:2201.08779",
    "title": "Contrastive and Selective Hidden Embeddings for Medical Image  Segmentation",
    "abstract": "Medical image segmentation has been widely recognized as a pivot procedure\nfor clinical diagnosis, analysis, and treatment planning. However, the\nlaborious and expensive annotation process lags down the speed of further\nadvances. Contrastive learning-based weight pre-training provides an\nalternative by leveraging unlabeled data to learn a good representation. In\nthis paper, we investigate how contrastive learning benefits the general\nsupervised medical segmentation tasks. To this end, patch-dragsaw contrastive\nregularization (PDCR) is proposed to perform patch-level tugging and repulsing\nwith the extent controlled by a continuous affinity score. And a new structure\ndubbed uncertainty-aware feature selection block (UAFS) is designed to perform\nthe feature selection process, which can handle the learning target shift\ncaused by minority features with high uncertainty. By plugging the proposed 2\nmodules into the existing segmentation architecture, we achieve\nstate-of-the-art results across 8 public datasets from 6 domains. Newly\ndesigned modules further decrease the amount of training data to a quarter\nwhile achieving comparable, if not better, performances. From this perspective,\nwe take the opposite direction of the original self/un-supervised contrastive\nlearning by further excavating information contained within the label.",
    "descriptor": "",
    "authors": [
      "Zhuowei Li",
      "Zihao Liu",
      "Zhiqiang Hu",
      "Qing Xia",
      "Ruiqin Xiong",
      "Shaoting Zhang",
      "Dimitris Metaxas",
      "Tingting Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08779"
  },
  {
    "id": "arXiv:2201.08780",
    "title": "Real-Time Seizure Detection using EEG: A Comprehensive Comparison of  Recent Approaches under a Realistic Setting",
    "abstract": "Electroencephalogram (EEG) is an important diagnostic test that physicians\nuse to record brain activity and detect seizures by monitoring the signals.\nThere have been several attempts to detect seizures and abnormalities in EEG\nsignals with modern deep learning models to reduce the clinical burden.\nHowever, they cannot be fairly compared against each other as they were tested\nin distinct experimental settings. Also, some of them are not trained in\nreal-time seizure detection tasks, making it hard for on-device applications.\nTherefore in this work, for the first time, we extensively compare multiple\nstate-of-the-art models and signal feature extractors in a real-time seizure\ndetection framework suitable for real-world application, using various\nevaluation metrics including a new one we propose to evaluate more practical\naspects of seizure detection models. Our code is available at\nhttps://github.com/AITRICS/EEG_real_time_seizure_detection.",
    "descriptor": "\nComments: Real-Time Seizure Detection with EEG\n",
    "authors": [
      "Kwanhyung Lee",
      "Hyewon Jeong",
      "Seyun Kim",
      "Donghwa Yang",
      "Hoon-Chul Kang",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08780"
  },
  {
    "id": "arXiv:2201.08786",
    "title": "FedComm: Federated Learning as a Medium for Covert Communication",
    "abstract": "Proposed as a solution to mitigate the privacy implications related to the\nadoption of deep learning solutions, Federated Learning (FL) enables large\nnumbers of participants to successfully train deep neural networks without\nhaving to reveal the actual private training data. To date, a substantial\namount of research has investigated the security and privacy properties of FL,\nresulting in a plethora of innovative attack and defense strategies. This paper\nthoroughly investigates the communication capabilities of an FL scheme. In\nparticular, we show that a party involved in the FL learning process can use FL\nas a covert communication medium to send an arbitrary message. We introduce\nFedComm, a novel covert-communication technique that enables robust sharing and\ntransfer of targeted payloads within the FL framework. Our extensive\ntheoretical and empirical evaluations show that FedComm provides a stealthy\ncommunication channel, with minimal disruptions to the training process. Our\nexperiments show that FedComm, allowed us to successfully deliver 100% of a\npayload in the order of kilobits before the FL procedure converges. Our\nevaluation also shows that FedComm is independent of the application domain and\nthe neural network architecture used by the underlying FL scheme.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Dorjan Hitaj",
      "Giulio Pagnotta",
      "Briland Hitaj",
      "Fernando Perez-Cruz",
      "Luigi V. Mancini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08786"
  },
  {
    "id": "arXiv:2201.08788",
    "title": "A Note on Hardness of Multiprocessor Scheduling with Scheduling Solution  Space Tree",
    "abstract": "We study the computational complexity of the non-preemptive scheduling\nproblem of a list of independent jobs on a set of identical parallel processors\nwith a makespan minimization objective. We make a maiden attempt to explore the\ncombinatorial structure showing the exhaustive solution space of the problem by\ndefining the \\textit{Scheduling Solution Space Tree (SSST)} data structure. The\nproperties of the \\textit{SSST} are formally defined and characterized through\nour analytical results. We develop a unique technique to show the problem\n$\\mathcal{NP}$ using the SSST and the \\textit{Weighted Scheduling Solution\nSpace Tree (WSSST)} data structures. We design the first non-deterministic\npolynomial-time algorithm named \\textit{Magic Scheduling (MS)} for the problem\nbased on the reduction framework. We also define a new variant of\nmultiprocessor scheduling by including the user as an additional input\nparameter. We formally establish the complexity class of the variant by the\nreduction principle. Finally, we conclude the article by exploring several\ninteresting open problems for future research investigation.",
    "descriptor": "\nComments: 21 pages, 4 figures, 1 table\n",
    "authors": [
      "Debasis Dwibedy",
      "Rakesh Mohanty"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.08788"
  },
  {
    "id": "arXiv:2201.08789",
    "title": "AiTLAS: Artificial Intelligence Toolbox for Earth Observation",
    "abstract": "The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)\nincludes state-of-the-art machine learning methods for exploratory and\npredictive analysis of satellite imagery as well as repository of AI-ready\nEarth Observation (EO) datasets. It can be easily applied for a variety of\nEarth Observation tasks, such as land use and cover classification, crop type\nprediction, localization of specific objects (semantic segmentation), etc. The\nmain goal of AiTLAS is to facilitate better usability and adoption of novel AI\nmethods (and models) by EO experts, while offering easy access and standardized\nformat of EO datasets to AI experts which further allows benchmarking of\nvarious existing and novel AI methods tailored for EO data.",
    "descriptor": "",
    "authors": [
      "Ivica Dimitrovski",
      "Ivan Kitanovski",
      "Pan\u010de Panov",
      "Nikola Simidjievski",
      "Dragi Kocev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08789"
  },
  {
    "id": "arXiv:2201.08796",
    "title": "Harmonic structures of Beethoven quartets: a complex network approach",
    "abstract": "We propose a complex network approach to the harmonic structure underpinning\nwestern tonal music. From a database of Beethoven's string quartets, we\nconstruct a directed network whose nodes are musical chords and edges connect\nchords following each other. We show that the network is scale-free and has\nspecific properties when ranking algorithms are applied. We explore its\ncommunity structure and its musical interpretation, and propose statistical\nmeasures stemming from network theory allowing to distinguish stylistically\nbetween periods of composition. Our work opens the way to a network approach of\nstructural properties of tonal harmony.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Th\u00e9o Frottier",
      "Bertrand Georgeot",
      "Olivier Giraud"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08796"
  },
  {
    "id": "arXiv:2201.08802",
    "title": "Deconfounding to Explanation Evaluation in Graph Neural Networks",
    "abstract": "Explainability of graph neural networks (GNNs) aims to answer ``Why the GNN\nmade a certain prediction?'', which is crucial to interpret the model\nprediction. The feature attribution framework distributes a GNN's prediction to\nits input features (e.g., edges), identifying an influential subgraph as the\nexplanation. When evaluating the explanation (i.e., subgraph importance), a\nstandard way is to audit the model prediction based on the subgraph solely.\nHowever, we argue that a distribution shift exists between the full graph and\nthe subgraph, causing the out-of-distribution problem. Furthermore, with an\nin-depth causal analysis, we find the OOD effect acts as the confounder, which\nbrings spurious associations between the subgraph importance and model\nprediction, making the evaluation less reliable. In this work, we propose\nDeconfounded Subgraph Evaluation (DSE) which assesses the causal effect of an\nexplanatory subgraph on the model prediction. While the distribution shift is\ngenerally intractable, we employ the front-door adjustment and introduce a\nsurrogate variable of the subgraphs. Specifically, we devise a generative model\nto generate the plausible surrogates that conform to the data distribution,\nthus approaching the unbiased estimation of subgraph importance. Empirical\nresults demonstrate the effectiveness of DSE in terms of explanation fidelity.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Ying-Xin",
      "Xiang Wang",
      "An Zhang",
      "Xia Hu",
      "Fuli Feng",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08802"
  },
  {
    "id": "arXiv:2201.08808",
    "title": "Conversational Information Seeking",
    "abstract": "Conversational information seeking (CIS) is concerned with a sequence of\ninteractions between one or more users and an information system. Interactions\nin CIS are primarily based on natural language dialogue, while they may include\nother types of interactions, such as click, touch, and body gestures. This\nmonograph provides a thorough overview of CIS definitions, applications,\ninteractions, interfaces, design, implementation, and evaluation. This\nmonograph views CIS applications as including conversational search,\nconversational question answering, and conversational recommendation. Our aim\nis to provide an overview of past research related to CIS, introduce the\ncurrent state-of-the-art in CIS, highlight the challenges still being faced in\nthe community. and suggest future directions.",
    "descriptor": "\nComments: Draft Version 1.0\n",
    "authors": [
      "Hamed Zamani",
      "Johanne R. Trippas",
      "Jeff Dalton",
      "Filip Radlinski"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.08808"
  },
  {
    "id": "arXiv:2201.08810",
    "title": "GAP-Gen: Guided Automatic Python Code Generation",
    "abstract": "Automatic code generation from natural language descriptions can be highly\nbeneficial during the process of software development. In this work, we propose\nGAP-Gen, an automatic code generation method guided by Python syntactic\nconstraints and semantic constraints. We first introduce Python syntactic\nconstraints in the form of Syntax-Flow, which is a simplified version of\nAbstract Syntax Tree (AST) reducing the size and high complexity of Abstract\nSyntax Tree but maintaining the crucial syn-tactic information of Python code.\nIn addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable\nand function names consistently throughout the code. In our work, rather than\npre-training, we focus on modifying the fine-tuning process which reduces\ncomputational requirements but retains high generation performance on automatic\nPython code generation task. GAP-Gen fine-tunes the transformer-based language\nmodels T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet,\nCodeSearchNet AdvTest, and Code-Docstring-Corpus from EdinburghNLP. Our\nexperiments show that GAP-Gen achieves better results on automatic Python code\ngeneration task than previous works",
    "descriptor": "\nComments: 11 pages, 2 figures, 3 tables\n",
    "authors": [
      "Junchen Zhao",
      "Yurun Song",
      "Junlin Wang",
      "Ian G. Harris"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08810"
  },
  {
    "id": "arXiv:2201.08811",
    "title": "Incoherent coherences",
    "abstract": "This article explores a generic framework of well-typed and well-scoped\nsyntaxes, with a signature-axiom approach resembling traditional abstract\nalgebra. The boilerplate code needed in defining operations on syntaxes is\nidentified and abstracted away. Some of the frequent boilerplate proofs are\nalso generalized.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Xu Huang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.08811"
  },
  {
    "id": "arXiv:2201.08812",
    "title": "Realtime 3D Object Detection for Headsets",
    "abstract": "Mobile headsets should be capable of understanding 3D physical environments\nto offer a truly immersive experience for augmented/mixed reality (AR/MR).\nHowever, their small form-factor and limited computation resources make it\nextremely challenging to execute in real-time 3D vision algorithms, which are\nknown to be more compute-intensive than their 2D counterparts. In this paper,\nwe propose DeepMix, a mobility-aware, lightweight, and hybrid3D object\ndetection framework for improving the user experience of AR/MR on mobile\nheadsets. Motivated by our analysis and evaluation of state-of-the-art 3D\nobject detection models, DeepMix intelligently combines edge-assisted 2D object\ndetection and novel, on-device 3D bounding box estimations that leverage depth\ndata captured by headsets. This leads to low end-to-end latency and\nsignificantly boosts detection accuracy in mobile scenarios.",
    "descriptor": "",
    "authors": [
      "Yongjie Guan",
      "Xueyu Hou",
      "Nan Wu",
      "Bo Han",
      "Tao Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08812"
  },
  {
    "id": "arXiv:2201.08813",
    "title": "Active Predictive Coding Networks: A Neural Solution to the Problem of  Learning Reference Frames and Part-Whole Hierarchies",
    "abstract": "We introduce Active Predictive Coding Networks (APCNs), a new class of neural\nnetworks that solve a major problem posed by Hinton and others in the fields of\nartificial intelligence and brain modeling: how can neural networks learn\nintrinsic reference frames for objects and parse visual scenes into part-whole\nhierarchies by dynamically allocating nodes in a parse tree? APCNs address this\nproblem by using a novel combination of ideas: (1) hypernetworks are used for\ndynamically generating recurrent neural networks that predict parts and their\nlocations within intrinsic reference frames conditioned on higher object-level\nembedding vectors, and (2) reinforcement learning is used in conjunction with\nbackpropagation for end-to-end learning of model parameters. The APCN\narchitecture lends itself naturally to multi-level hierarchical learning and is\nclosely related to predictive coding models of cortical function. Using the\nMNIST, Fashion-MNIST and Omniglot datasets, we demonstrate that APCNs can (a)\nlearn to parse images into part-whole hierarchies, (b) learn compositional\nrepresentations, and (c) transfer their knowledge to unseen classes of objects.\nWith their ability to dynamically generate parse trees with part locations for\nobjects, APCNs offer a new framework for explainable AI that leverages advances\nin deep learning while retaining interpretability and compositionality.",
    "descriptor": "",
    "authors": [
      "Dimitrios C. Gklezakos",
      "Rajesh P. N. Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08813"
  },
  {
    "id": "arXiv:2201.08815",
    "title": "Learning from One and Only One Shot",
    "abstract": "Humans can generalize from only a few examples and from little pre-training\non similar tasks. Yet, machine learning (ML) typically requires large data to\nlearn or pre-learn to transfer. Inspired by nativism, we directly model basic\nhuman-innate priors in abstract visual tasks e.g., character/doodle\nrecognition. This yields a white-box model that learns general-appearance\nsimilarity -- how any two images look in general -- by mimicking how humans\nnaturally \"distort\" an object at first sight. Using simply the nearest-neighbor\nclassifier on this similarity space, we achieve human-level character\nrecognition using only 1--10 examples per class and nothing else (no\npre-training). This differs from few-shot learning (FSL) using significant\npre-training. On standard benchmarks MNIST/EMNIST and the Omniglot challenge,\nwe outperform both neural-network-based and classical ML in the \"tiny-data\"\nregime, including FSL pre-trained on large data. Our model enables unsupervised\nlearning too: by learning the non-Euclidean, general-appearance similarity\nspace in a k-means style, we can generate human-intuitive archetypes as cluster\n``centroids''.",
    "descriptor": "",
    "authors": [
      "Haizi Yu",
      "Igor Mineyev",
      "Lav R. Varshney",
      "James A. Evans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08815"
  },
  {
    "id": "arXiv:2201.08816",
    "title": "Skyline variations allow estimating distance to trees on landscape  photos using semantic segmentation",
    "abstract": "Approximate distance estimation can be used to determine fundamental\nlandscape properties including complexity and openness. We show that variations\nin the skyline of landscape photos can be used to estimate distances to trees\non the horizon. A methodology based on the variations of the skyline has been\ndeveloped and used to investigate potential relationships with the distance to\nskyline objects. The skyline signal, defined by the skyline height expressed in\npixels, was extracted for several Land Use/Cover Area frame Survey (LUCAS)\nlandscape photos. Photos were semantically segmented with DeepLabV3+ trained\nwith the Common Objects in Context (COCO) dataset. This provided pixel-level\nclassification of the objects forming the skyline. A Conditional Random Fields\n(CRF) algorithm was also applied to increase the details of the skyline signal.\nThree metrics, able to capture the skyline signal variations, were then\nconsidered for the analysis. These metrics shows a functional relationship with\ndistance for the class of trees, whose contours have a fractal nature. In\nparticular, regression analysis was performed against 475 ortho-photo based\ndistance measurements, and, in the best case, a R2 score equal to 0.47 was\nachieved. This is an encouraging result which shows the potential of skyline\nvariation metrics for inferring distance related information.",
    "descriptor": "",
    "authors": [
      "Laura Martinez-Sanchez",
      "Daniele Borio",
      "Rapha\u00ebl d'Andrimont",
      "Marijn van der Velde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.08816"
  },
  {
    "id": "arXiv:2201.08817",
    "title": "Biochemical Space Language in Relation to Multiset Rewriting Systems",
    "abstract": "This technical report relates Biochemical Space Language (BCSL) to Multiset\nrewriting systems (MRS). For a BCSL model, the semantics are defined in terms\nof transition systems, while for an MRS, they are defined in terms of a set of\nruns. In this report, we relate BCSL to MRS by first showing how the transition\nsystem is related to a set of runs and consequently showing how for every BCSL\nmodel, an MRS can be constructed such that both represent the same set of runs.\nThe motivation of this step is to establish BCSL in the context of a more\ngeneral rewriting system and benefit from properties shown for them. Finally,\nwe show that regulations defined for MRS can be consequently used in the BCSL\nmodel.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Matej Troj\u00e1k",
      "David \u0160afr\u00e1nek",
      "Lubo\u0161 Brim"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08817"
  },
  {
    "id": "arXiv:2201.08821",
    "title": "Representing Long-Range Context for Graph Neural Networks with Global  Attention",
    "abstract": "Graph neural networks are powerful architectures for structured datasets.\nHowever, current methods struggle to represent long-range dependencies. Scaling\nthe depth or width of GNNs is insufficient to broaden receptive fields as\nlarger GNNs encounter optimization instabilities such as vanishing gradients\nand representation oversmoothing, while pooling-based approaches have yet to\nbecome as universally useful as in computer vision. In this work, we propose\nthe use of Transformer-based self-attention to learn long-range pairwise\nrelationships, with a novel \"readout\" mechanism to obtain a global graph\nembedding. Inspired by recent computer vision results that find\nposition-invariant attention performant in learning long-range relationships,\nour method, which we call GraphTrans, applies a permutation-invariant\nTransformer module after a standard GNN module. This simple architecture leads\nto state-of-the-art results on several graph classification tasks,\noutperforming methods that explicitly encode graph structure. Our results\nsuggest that purely-learning-based approaches without graph structure may be\nsuitable for learning high-level, long-range relationships on graphs. Code for\nGraphTrans is available at https://github.com/ucbrise/graphtrans.",
    "descriptor": "\nComments: NeurIPS 2021. The first two authors contributed equally to this work\n",
    "authors": [
      "Zhanghao Wu",
      "Paras Jain",
      "Matthew A. Wright",
      "Azalia Mirhoseini",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08821"
  },
  {
    "id": "arXiv:2201.08830",
    "title": "APack: Off-Chip, Lossless Data Compression for Efficient Deep Learning  Inference",
    "abstract": "Data accesses between on- and off-chip memories account for a large fraction\nof overall energy consumption during inference with deep learning networks. We\npresent APack, a simple and effective, lossless, off-chip memory compression\ntechnique for fixed-point quantized models. APack reduces data widths by\nexploiting the non-uniform value distribution in deep learning applications.\nAPack can be used to increase the effective memory capacity, to reduce off-chip\ntraffic, and/or to achieve the desired performance/energy targets while using\nsmaller off-chip memories. APack builds upon arithmetic coding, encoding each\nvalue as an arithmetically coded variable length prefix, plus an offset. To\nmaximize compression ratio a heuristic software algorithm partitions the value\nspace into groups each sharing a common prefix. APack exploits memory access\nparallelism by using several, pipelined encoder/decoder units in parallel and\nkeeps up with the high data bandwidth demands of deep learning. APack can be\nused with any machine learning accelerator. In the demonstrated configuration,\nAPack is placed just before the off-chip memory controller so that he rest of\nthe on-chip memory and compute units thus see the original data stream. We\nimplemented the APack compressor and decompressor in Verilog and in a 65nm tech\nnode demonstrating its performance and energy efficiency. Indicatively, APack\nreduces data footprint of weights and activations to 60% and 48% respectively\non average over a wide set of 8-bit quantized models. It naturally adapts and\ncompresses models that use even more aggressive quantization methods. When\nintegrated with a Tensorcore-based accelerator, APack boosts the speedup and\nenergy efficiency to 1.44X and 1.37X respectively.",
    "descriptor": "",
    "authors": [
      "Alberto Delmas Lascorz",
      "Mostafa Mahmoud",
      "Andreas Moshovos"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08830"
  },
  {
    "id": "arXiv:2201.08831",
    "title": "Reliable Detection of Doppelg\u00e4ngers based on Deep Face Representations",
    "abstract": "Doppelg\\\"angers (or lookalikes) usually yield an increased probability of\nfalse matches in a facial recognition system, as opposed to random face image\npairs selected for non-mated comparison trials. In this work, we assess the\nimpact of doppelg\\\"angers on the HDA Doppelg\\\"anger and Disguised Faces in The\nWild databases using a state-of-the-art face recognition system. It is found\nthat doppelg\\\"anger image pairs yield very high similarity scores resulting in\na significant increase of false match rates. Further, we propose a\ndoppelg\\\"anger detection method which distinguishes doppelg\\\"angers from mated\ncomparison trials by analysing differences in deep representations obtained\nfrom face image pairs. The proposed detection system employs a machine\nlearning-based classifier, which is trained with generated doppelg\\\"anger image\npairs utilising face morphing techniques. Experimental evaluations conducted on\nthe HDA Doppelg\\\"anger and Look-Alike Face databases reveal a detection equal\nerror rate of approximately 2.7% for the task of separating mated\nauthentication attempts from doppelg\\\"angers.",
    "descriptor": "",
    "authors": [
      "Christian Rathgeb",
      "Daniel Fischer",
      "Pawel Drozdowski",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08831"
  },
  {
    "id": "arXiv:2201.08832",
    "title": "Occupancy Information Ratio: Infinite-Horizon, Information-Directed,  Parameterized Policy Search",
    "abstract": "We develop a new measure of the exploration/exploitation trade-off in\ninfinite-horizon reinforcement learning problems called the occupancy\ninformation ratio (OIR), which is comprised of a ratio between the\ninfinite-horizon average cost of a policy and the entropy of its long-term\nstate occupancy measure. The OIR ensures that no matter how many trajectories\nan RL agent traverses or how well it learns to minimize cost, it maintains a\nhealthy skepticism about its environment, in that it defines an optimal policy\nwhich induces a high-entropy occupancy measure. Different from earlier\ninformation ratio notions, OIR is amenable to direct policy search over\nparameterized families, and exhibits hidden quasiconcavity through invocation\nof the perspective transformation. This feature ensures that under appropriate\npolicy parameterizations, the OIR optimization problem has no spurious\nstationary points, despite the overall problem's nonconvexity. We develop for\nthe first time policy gradient and actor-critic algorithms for OIR optimization\nbased upon a new entropy gradient theorem, and establish both asymptotic and\nnon-asymptotic convergence results with global optimality guarantees. In\nexperiments, these methodologies outperform several deep RL baselines in\nproblems with sparse rewards, where many trajectories may be uninformative and\nskepticism about the environment is crucial to success.",
    "descriptor": "",
    "authors": [
      "Wesley A. Suttle",
      "Alec Koppel",
      "Ji Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.08832"
  },
  {
    "id": "arXiv:2201.08837",
    "title": "Marginal Effects for Non-Linear Prediction Functions",
    "abstract": "Beta coefficients for linear regression models represent the ideal form of an\ninterpretable feature effect. However, for non-linear models and especially\ngeneralized linear models, the estimated coefficients cannot be interpreted as\na direct feature effect on the predicted outcome. Hence, marginal effects are\ntypically used as approximations for feature effects, either in the shape of\nderivatives of the prediction function or forward differences in prediction due\nto a change in a feature value. While marginal effects are commonly used in\nmany scientific fields, they have not yet been adopted as a model-agnostic\ninterpretation method for machine learning models. This may stem from their\ninflexibility as a univariate feature effect and their inability to deal with\nthe non-linearities found in black box models. We introduce a new class of\nmarginal effects termed forward marginal effects. We argue to abandon\nderivatives in favor of better-interpretable forward differences. Furthermore,\nwe generalize marginal effects based on forward differences to multivariate\nchanges in feature values. To account for the non-linearity of prediction\nfunctions, we introduce a non-linearity measure for marginal effects. We argue\nagainst summarizing feature effects of a non-linear prediction function in a\nsingle metric such as the average marginal effect. Instead, we propose to\npartition the feature space to compute conditional average marginal effects on\nfeature subspaces, which serve as conditional feature effect estimates.",
    "descriptor": "",
    "authors": [
      "Christian A. Scholbeck",
      "Giuseppe Casalicchio",
      "Christoph Molnar",
      "Bernd Bischl",
      "Christian Heumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08837"
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": "Volumetric neural rendering methods like NeRF generate high-quality view\nsynthesis results but are optimized per-scene leading to prohibitive\nreconstruction time. On the other hand, deep multi-view stereo methods can\nquickly reconstruct scene geometry via direct network inference. Point-NeRF\ncombines the advantages of these two approaches by using neural 3D point\nclouds, with associated neural features, to model a radiance field. Point-NeRF\ncan be rendered efficiently by aggregating neural point features near scene\nsurfaces, in a ray marching-based rendering pipeline. Moreover, Point-NeRF can\nbe initialized via direct inference of a pre-trained deep network to produce a\nneural point cloud; this point cloud can be finetuned to surpass the visual\nquality of NeRF with 30X faster training time. Point-NeRF can be combined with\nother 3D reconstruction methods and handles the errors and outliers in such\nmethods via a novel pruning and growing mechanism.",
    "descriptor": "",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08845"
  },
  {
    "id": "arXiv:2201.07794",
    "title": "A Non-Expert's Introduction to Data Ethics for Mathematicians",
    "abstract": "I give a short introduction to data ethics. My focal audience is\nmathematicians, but I hope that my discussion will also be useful to others. I\nam not an expert about data ethics, and my article is only a starting point. I\nencourage readers to examine the resources that I discuss and to continue to\nreflect carefully on data ethics and on the societal implications of data and\ndata analysis throughout their lives.",
    "descriptor": "\nComments: working paper (associated with my data-ethics lecture at the 2021 AMS Short Course on Mathematical and Computational Methods for Complex Social Systems); not yet refereed; private comments and suggestions are appreciated\n",
    "authors": [
      "Mason A. Porter"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.07794"
  },
  {
    "id": "arXiv:2201.08385",
    "title": "Improving Specificity in Mammography Using Cross-correlation between  Wavelet and Fourier Transform",
    "abstract": "Breast cancer is in the most common malignant tumor in women. It accounted\nfor 30% of new malignant tumor cases. Although the incidence of breast cancer\nremains high around the world, the mortality rate has been continuously\nreduced. This is mainly due to recent developments in molecular biology\ntechnology and improved level of comprehensive diagnosis and standard\ntreatment. Early detection by mammography is an integral part of that. The most\ncommon breast abnormalities that may indicate breast cancer are masses and\ncalcifications. Previous detection approaches usually obtain relatively high\nsensitivity but unsatisfactory specificity. We will investigate an approach\nthat applies the discrete wavelet transform and Fourier transform to parse the\nimages and extracts statistical features that characterize an image's content,\nsuch as the mean intensity and the skewness of the intensity. A naive Bayesian\nclassifier uses these features to classify the images. We expect to achieve an\noptimal high specificity.",
    "descriptor": "",
    "authors": [
      "Liuhua Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08385"
  },
  {
    "id": "arXiv:2201.08388",
    "title": "Steerable Pyramid Transform Enables Robust Left Ventricle Quantification",
    "abstract": "Although multifarious variants of convolutional neural networks (CNNs) have\nproved successful in cardiac index quantification, they seem vulnerable to mild\ninput perturbations, e.g., spatial transformations, image distortions, and\nadversarial attacks. Such brittleness erodes our trust in CNN-based automated\ndiagnosis of various cardiovascular diseases. In this work, we describe a\nsimple and effective method to learn robust CNNs for left ventricle (LV)\nquantification, including cavity and myocardium areas, directional dimensions,\nand regional wall thicknesses. The key to the success of our approach is the\nuse of the biologically-inspired steerable pyramid transform (SPT) as fixed\nfront-end processing, which brings three computational advantages to LV\nquantification. First, the basis functions of SPT match the anatomical\nstructure of the LV as well as the geometric characteristics of the estimated\nindices. Second, SPT enables sharing a CNN across different orientations as a\nform of parameter regularization, and explicitly captures the scale variations\nof the LV in a natural way. Third, the residual highpass subband can be\nconveniently discarded to further encourage robust feature learning. A concise\nand effective metric, named Robustness Ratio, is proposed to evaluate the\nrobustness under various input perturbations. Extensive experiments on 145\ncardiac sequences show that our SPT-augmented method performs favorably against\nstate-of-the-art algorithms in terms of prediction accuracy, but is\nsignificantly more robust under input perturbations.",
    "descriptor": "\nComments: 10 pages, 13 figures, journal paper\n",
    "authors": [
      "Xiangyang Zhu",
      "Kede Ma",
      "Wufeng Xue"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08388"
  },
  {
    "id": "arXiv:2201.08418",
    "title": "SoftDropConnect (SDC) -- Effective and Efficient Quantification of the  Network Uncertainty in Deep MR Image Analysis",
    "abstract": "Recently, deep learning has achieved remarkable successes in medical image\nanalysis. Although deep neural networks generate clinically important\npredictions, they have inherent uncertainty. Such uncertainty is a major\nbarrier to report these predictions with confidence. In this paper, we propose\na novel yet simple Bayesian inference approach called SoftDropConnect (SDC) to\nquantify the network uncertainty in medical imaging tasks with gliomas\nsegmentation and metastases classification as initial examples. Our key idea is\nthat during training and testing SDC modulates network parameters continuously\nso as to allow affected information processing channels still in operation,\ninstead of disabling them as Dropout or DropConnet does. When compared with\nthree popular Bayesian inference methods including Bayes By Backprop, Dropout,\nand DropConnect, our SDC method (SDC-W after optimization) outperforms the\nthree competing methods with a substantial margin. Quantitatively, our proposed\nmethod generates results withsubstantially improved prediction accuracy (by\n10.0%, 5.4% and 3.7% respectively for segmentation in terms of dice score; by\n11.7%, 3.9%, 8.7% on classification in terms of test accuracy) and greatly\nreduced uncertainty in terms of mutual information (by 64%, 33% and 70% on\nsegmentation; 98%, 88%, and 88% on classification). Our approach promises to\ndeliver better diagnostic performance and make medical AI imaging more\nexplainable and trustworthy.",
    "descriptor": "",
    "authors": [
      "Qing Lyu",
      "Christopher T. Whitlow",
      "Ge Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08418"
  },
  {
    "id": "arXiv:2201.08435",
    "title": "Noisy linear inverse problems under convex constraints: Exact risk  asymptotics in high dimensions",
    "abstract": "In the standard Gaussian linear measurement model $Y=X\\mu_0+\\xi \\in\n\\mathbb{R}^m$ with a fixed noise level $\\sigma>0$, we consider the problem of\nestimating the unknown signal $\\mu_0$ under a convex constraint $\\mu_0 \\in K$,\nwhere $K$ is a closed convex set in $\\mathbb{R}^n$. We show that the risk of\nthe natural convex constrained least squares estimator (LSE)\n$\\hat{\\mu}(\\sigma)$ can be characterized exactly in high dimensional limits, by\nthat of the convex constrained LSE $\\hat{\\mu}_K^{\\mathsf{seq}}$ in the\ncorresponding Gaussian sequence model at a different noise level. The\ncharacterization holds (uniformly) for risks in the maximal regime that ranges\nfrom constant order all the way down to essentially the parametric rate, as\nlong as certain necessary non-degeneracy condition is satisfied for\n$\\hat{\\mu}(\\sigma)$.\nThe precise risk characterization reveals a fundamental difference between\nnoiseless (or low noise limit) and noisy linear inverse problems in terms of\nthe sample complexity for signal recovery. A concrete example is given by the\nisotonic regression problem: While exact recovery of a general monotone signal\nrequires $m\\gg n^{1/3}$ samples in the noiseless setting, consistent signal\nrecovery in the noisy setting requires as few as $m\\gg \\log n$ samples. Such a\ndiscrepancy occurs when the low and high noise risk behavior of\n$\\hat{\\mu}_K^{\\mathsf{seq}}$ differ significantly. In statistical languages,\nthis occurs when $\\hat{\\mu}_K^{\\mathsf{seq}}$ estimates $0$ at a faster\n`adaptation rate' than the slower `worst-case rate' for general signals.\nSeveral other examples, including non-negative least squares and generalized\nLasso (in constrained forms), are also worked out to demonstrate the concrete\napplicability of the theory in problems of different types.",
    "descriptor": "",
    "authors": [
      "Qiyang Han"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.08435"
  },
  {
    "id": "arXiv:2201.08436",
    "title": "A Method of Sequential Log-Convex Programming for Engineering Design",
    "abstract": "A method of Sequential Log-Convex Programming (SLCP) is constructed that\nexploits the log-convex structure present in many engineering design problems.\nThe mathematical structure of Geometric Programming (GP) is combined with the\nability of Sequential Quadratic Program (SQP) to accommodate a wide range of\nobjective and constraint functions, resulting in a practical algorithm that can\nbe adopted with little to no modification of existing design practices. Three\ntest problems are considered to demonstrate the SLCP algorithm, comparing it\nwith SQP and the modified Logspace Sequential Quadratic Programming (LSQP). In\nthese cases, SLCP shows up to a 77% reduction in number of iterations compared\nto SQP, and an 11% reduction compared to LSQP. The airfoil analysis code XFOIL\nis integrated into one of the case studies to show how SLCP can be used to\nevolve the fidelity of design problems that have initially been modeled as GP\ncompatible. Finally, a methodology for design based on GP and SLCP is briefly\ndiscussed.",
    "descriptor": "\nComments: 27 pages, 9 figures, 4 tables. Submitted to the Journal of Optimization and Engineering\n",
    "authors": [
      "Cody Karcher",
      "Robert Haimes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.08436"
  },
  {
    "id": "arXiv:2201.08443",
    "title": "Diversifying the Genomic Data Science Research Community",
    "abstract": "Over the last 20 years, there has been an explosion of genomic data collected\nfor disease association, functional analyses, and other large-scale\ndiscoveries. At the same time, there have been revolutions in cloud computing\nthat enable computational and data science research, while making data\naccessible to anyone with a web browser and an internet connection. However,\nstudents at institutions with limited resources have received relatively little\nexposure to curricula or professional development opportunities that lead to\ncareers in genomic data science. To broaden participation in genomics research,\nthe scientific community needs to support students, faculty, and administrators\nat Underserved Institutions (UIs) including Community Colleges, Historically\nBlack Colleges and Universities, Hispanic-Serving Institutions, and Tribal\nColleges and Universities in taking advantage of these tools in local\neducational and research programs. We have formed the Genomic Data Science\nCommunity Network (this http URL) to identify opportunities and support\nbroadening access to cloud-enabled genomic data science. Here, we provide a\nsummary of the priorities for faculty members at UIs, as well as\nadministrators, funders, and R1 researchers to consider as we create a more\ndiverse genomic data science community.",
    "descriptor": "\nComments: 42 pages, 1 figure\n",
    "authors": [
      "Genomic Data Science Community Network",
      "Rosa Alcazar",
      "Maria Alvarez",
      "Rachel Arnold",
      "Mentewab Ayalew",
      "Lyle G. Best",
      "Michael C. Campbell",
      "Kamal Chowdhury",
      "Katherine E. L. Cox",
      "Christina Daulton",
      "Youping Deng",
      "Carla Easter",
      "Karla Fuller",
      "Shazia Tabassum Hakim",
      "Ava M. Hoffman",
      "Natalie Kucher",
      "Andrew Lee",
      "Joslynn Lee",
      "Jeffrey T. Leek",
      "Robert Meller",
      "Loyda B. M\u00e9ndez",
      "Miguel P. M\u00e9ndez-Gonz\u00e1lez",
      "Stephen Mosher",
      "Michele Nishiguchi",
      "Siddharth Pratap",
      "Tiffany Rolle",
      "Sourav Roy",
      "Rachel Saidi",
      "Michael C. Schatz",
      "Shurjo Sen",
      "James Sniezek",
      "Edu Suarez Martinez",
      "Frederick Tan",
      "Jennifer Vessio",
      "Karriem Watson",
      "Wendy Westbroek"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08443"
  },
  {
    "id": "arXiv:2201.08464",
    "title": "On Good Infinite Families of Toric Codes or the Lack Thereof",
    "abstract": "A toric code, introduced by Hansen to extend the Reed-Solomon code as a\n$k$-dimensional subspace of $\\mathbb{F}_q^n$, is determined by a toric variety\nor its associated integral convex polytope $P \\subseteq [0,q-2]^n$, where $k=|P\n\\cap \\mathbb{Z}^n|$ (the number of integer lattice points of $P$). There are\ntwo relevant parameters that determine the quality of a code: the information\nrate, which measures how much information is contained in a single bit of each\ncodeword; and the relative minimum distance, which measures how many errors can\nbe corrected relative to how many bits each codeword has. Soprunov and\nSoprunova defined a good infinite family of codes to be a sequence of codes of\nunbounded polytope dimension such that neither the corresponding information\nrates nor relative minimum distances go to 0 in the limit. We examine different\nways of constructing families of codes by considering polytope operations such\nas the join and direct sum. In doing so, we give conditions under which no good\nfamily can exist and strong evidence that there is no such good family of\ncodes.",
    "descriptor": "",
    "authors": [
      "Mallory Dolorfino",
      "Cordelia Horch",
      "Kelly Jabbusch",
      "Ryan Martinez"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08464"
  },
  {
    "id": "arXiv:2201.08477",
    "title": "DDPG-Driven Deep-Unfolding with Adaptive Depth for Channel Estimation  with Sparse Bayesian Learning",
    "abstract": "Deep-unfolding neural networks (NNs) have received great attention since they\nachieve satisfactory performance with relatively low complexity. Typically,\nthese deep-unfolding NNs are restricted to a fixed-depth for all inputs.\nHowever, the optimal number of layers required for convergence changes with\ndifferent inputs. In this paper, we first develop a framework of deep\ndeterministic policy gradient (DDPG)-driven deep-unfolding with adaptive depth\nfor different inputs, where the trainable parameters of deep-unfolding NN are\nlearned by DDPG, rather than updated by the stochastic gradient descent\nalgorithm directly. Specifically, the optimization variables, trainable\nparameters, and architecture of deep-unfolding NN are designed as the state,\naction, and state transition of DDPG, respectively. Then, this framework is\nemployed to deal with the channel estimation problem in massive multiple-input\nmultiple-output systems. Specifically, first of all we formulate the channel\nestimation problem with an off-grid basis and develop a sparse Bayesian\nlearning (SBL)-based algorithm to solve it. Secondly, the SBL-based algorithm\nis unfolded into a layer-wise structure with a set of introduced trainable\nparameters. Thirdly, the proposed DDPG-driven deep-unfolding framework is\nemployed to solve this channel estimation problem based on the unfolded\nstructure of the SBL-based algorithm. To realize adaptive depth, we design the\nhalting score to indicate when to stop, which is a function of the channel\nreconstruction error. Furthermore, the proposed framework is extended to\nrealize the adaptive depth of the general deep neural networks (DNNs).\nSimulation results show that the proposed algorithm outperforms the\nconventional optimization algorithms and DNNs with fixed depth with much\nreduced number of layers.",
    "descriptor": "\nComments: 14 pages, 15 figures\n",
    "authors": [
      "Qiyu Hu",
      "Shuhan Shi",
      "Yunlong Cai",
      "Guanding Yu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08477"
  },
  {
    "id": "arXiv:2201.08482",
    "title": "Deep Attention-Based Supernovae Classification of Multi-Band  Light-Curves",
    "abstract": "In astronomical surveys, such as the Zwicky Transient Facility (ZTF),\nsupernovae (SNe) are relatively uncommon objects compared to other classes of\nvariable events. Along with this scarcity, the processing of multi-band\nlight-curves is a challenging task due to the highly irregular cadence, long\ntime gaps, missing-values, low number of observations, etc. These issues are\nparticularly detrimental for the analysis of transient events with SN-like\nlight-curves. In this work, we offer three main contributions. First, based on\ntemporal modulation and attention mechanisms, we propose a Deep Attention model\ncalled TimeModAttn to classify multi-band light-curves of different SN types,\navoiding photometric or hand-crafted feature computations, missing-values\nassumptions, and explicit imputation and interpolation methods. Second, we\npropose a model for the synthetic generation of SN multi-band light-curves\nbased on the Supernova Parametric Model (SPM). This allows us to increase the\nnumber of samples and the diversity of the cadence. The TimeModAttn model is\nfirst pre-trained using synthetic light-curves in a semi-supervised learning\nscheme. Then, a fine-tuning process is performed for domain adaptation. The\nproposed TimeModAttn model outperformed a Random Forest classifier, increasing\nthe balanced-$F_1$score from $\\approx.525$ to $\\approx.596$. The TimeModAttn\nmodel also outperformed other Deep Learning models, based on Recurrent Neural\nNetworks (RNNs), in two scenarios: late-classification and\nearly-classification. Finally, we conduct interpretability experiments. High\nattention scores are obtained for observations earlier than and close to the SN\nbrightness peaks, which are supported by an early and highly expressive learned\ntemporal modulation.",
    "descriptor": "\nComments: Submitted to AJ on 14-Jan-2022\n",
    "authors": [
      "\u00d3scar Pimentel",
      "Pablo A. Est\u00e9vez",
      "Francisco F\u00f6rster"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08482"
  },
  {
    "id": "arXiv:2201.08504",
    "title": "Deep reinforcement learning under signal temporal logic constraints  using Lagrangian relaxation",
    "abstract": "Deep reinforcement learning (DRL) has attracted much attention as an approach\nto solve sequential decision making problems without mathematical models of\nsystems or environments. In general, a constraint may be imposed on the\ndecision making. In this study, we consider the optimal decision making\nproblems with constraints to complete temporal high-level tasks in the\ncontinuous state-action domain. We describe the constraints using signal\ntemporal logic (STL), which is useful for time sensitive control tasks since it\ncan specify continuous signals within a bounded time interval. To deal with the\nSTL constraints, we introduce an extended constrained Markov decision process\n(CMDP), which is called a $\\tau$-CMDP. We formulate the STL constrained optimal\ndecision making problem as the $\\tau$-CMDP and propose a two-phase constrained\nDRL algorithm using the Lagrangian relaxation method. Through simulations, we\nalso demonstrate the learning performance of the proposed algorithm.",
    "descriptor": "\nComments: 9 pages, 10 figures. arXiv admin note: text overlap with arXiv:2108.01317\n",
    "authors": [
      "Junya Ikemoto",
      "Toshimitsu Ushio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08504"
  },
  {
    "id": "arXiv:2201.08506",
    "title": "alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty  quantification from exoplanet astrometry to black hole feature extraction",
    "abstract": "Inference is crucial in modern astronomical research, where hidden\nastrophysical features and patterns are often estimated from indirect and noisy\nmeasurements. Inferring the posterior of hidden features, conditioned on the\nobserved measurements, is essential for understanding the uncertainty of\nresults and downstream scientific interpretations. Traditional approaches for\nposterior estimation include sampling-based methods and variational inference.\nHowever, sampling-based methods are typically slow for high-dimensional inverse\nproblems, while variational inference often lacks estimation accuracy. In this\npaper, we propose alpha-DPI, a deep learning framework that first learns an\napproximate posterior using alpha-divergence variational inference paired with\na generative neural network, and then produces more accurate posterior samples\nthrough importance re-weighting of the network samples. It inherits strengths\nfrom both sampling and variational inference methods: it is fast, accurate, and\nscalable to high-dimensional problems. We apply our approach to two high-impact\nastronomical inference problems using real data: exoplanet astrometry and black\nhole feature extraction.",
    "descriptor": "",
    "authors": [
      "He Sun",
      "Katherine L. Bouman",
      "Paul Tiede",
      "Jason J. Wang",
      "Sarah Blunt",
      "Dimitri Mawet"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08506"
  },
  {
    "id": "arXiv:2201.08512",
    "title": "Vertical Federated Edge Learning with Distributed Integrated Sensing and  Communication",
    "abstract": "This letter studies a vertical federated edge learning (FEEL) system for\ncollaborative objects/human motion recognition by exploiting the distributed\nintegrated sensing and communication (ISAC). In this system, distributed edge\ndevices first send wireless signals to sense targeted objects/human, and then\nexchange intermediate computed vectors (instead of raw sensing data) for\ncollaborative recognition while preserving data privacy. To boost the spectrum\nand hardware utilization efficiency for FEEL, we exploit ISAC for both target\nsensing and data exchange, by employing dedicated frequency-modulated\ncontinuous-wave (FMCW) signals at each edge device. Under this setup, we\npropose a vertical FEEL framework for realizing the recognition based on the\ncollected multi-view wireless sensing data. In this framework, each edge device\nowns an individual local L-model to transform its sensing data into an\nintermediate vector with relatively low dimensions, which is then transmitted\nto a coordinating edge device for final output via a common downstream S-model.\nBy considering a human motion recognition task, experimental results show that\nour vertical FEEL based approach achieves recognition accuracy up to 98\\% with\nan improvement up to 8\\% compared to the benchmarks, including on-device\ntraining and horizontal FEEL.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Peixi Liu",
      "Guangxu Zhu",
      "Wei Jiang",
      "Wu Luo",
      "Jie Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.08512"
  },
  {
    "id": "arXiv:2201.08518",
    "title": "Optimal variance-reduced stochastic approximation in Banach spaces",
    "abstract": "We study the problem of estimating the fixed point of a contractive operator\ndefined on a separable Banach space. Focusing on a stochastic query model that\nprovides noisy evaluations of the operator, we analyze a variance-reduced\nstochastic approximation scheme, and establish non-asymptotic bounds for both\nthe operator defect and the estimation error, measured in an arbitrary\nsemi-norm. In contrast to worst-case guarantees, our bounds are\ninstance-dependent, and achieve the local asymptotic minimax risk\nnon-asymptotically. For linear operators, contractivity can be relaxed to\nmulti-step contractivity, so that the theory can be applied to problems like\naverage reward policy evaluation problem in reinforcement learning. We\nillustrate the theory via applications to stochastic shortest path problems,\ntwo-player zero-sum Markov games, as well as policy evaluation and $Q$-learning\nfor tabular Markov decision processes.",
    "descriptor": "",
    "authors": [
      "Wenlong Mou",
      "Koulik Khamaru",
      "Martin J. Wainwright",
      "Peter L. Bartlett",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08518"
  },
  {
    "id": "arXiv:2201.08530",
    "title": "Spatiotemporal Analysis Using Riemannian Composition of Diffusion  Operators",
    "abstract": "Multivariate time-series have become abundant in recent years, as many\ndata-acquisition systems record information through multiple sensors\nsimultaneously. In this paper, we assume the variables pertain to some geometry\nand present an operator-based approach for spatiotemporal analysis. Our\napproach combines three components that are often considered separately: (i)\nmanifold learning for building operators representing the geometry of the\nvariables, (ii) Riemannian geometry of symmetric positive-definite matrices for\nmultiscale composition of operators corresponding to different time samples,\nand (iii) spectral analysis of the composite operators for extracting different\ndynamic modes. We propose a method that is analogous to the classical wavelet\nanalysis, which we term Riemannian multi-resolution analysis (RMRA). We provide\nsome theoretical results on the spectral analysis of the composite operators,\nand we demonstrate the proposed method on simulations and on real data.",
    "descriptor": "\nComments: 48 pages, 13 figures\n",
    "authors": [
      "Tal Shnitzer",
      "Hau-Tieng Wu",
      "Ronen Talmon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08530"
  },
  {
    "id": "arXiv:2201.08536",
    "title": "Instance-Dependent Confidence and Early Stopping for Reinforcement  Learning",
    "abstract": "Various algorithms for reinforcement learning (RL) exhibit dramatic variation\nin their convergence rates as a function of problem structure. Such\nproblem-dependent behavior is not captured by worst-case analyses and has\naccordingly inspired a growing effort in obtaining instance-dependent\nguarantees and deriving instance-optimal algorithms for RL problems. This\nresearch has been carried out, however, primarily within the confines of\ntheory, providing guarantees that explain \\textit{ex post} the performance\ndifferences observed. A natural next step is to convert these theoretical\nguarantees into guidelines that are useful in practice. We address the problem\nof obtaining sharp instance-dependent confidence regions for the policy\nevaluation problem and the optimal value estimation problem of an MDP, given\naccess to an instance-optimal algorithm. As a consequence, we propose a\ndata-dependent stopping rule for instance-optimal algorithms. The proposed\nstopping rule adapts to the instance-specific difficulty of the problem and\nallows for early termination for problems with favorable structure.",
    "descriptor": "",
    "authors": [
      "Koulik Khamaru",
      "Eric Xia",
      "Martin J. Wainwright",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08536"
  },
  {
    "id": "arXiv:2201.08543",
    "title": "Deep Learning-Accelerated 3D Carbon Storage Reservoir Pressure  Forecasting Based on Data Assimilation Using Surface Displacement from InSAR",
    "abstract": "Fast forecasting of reservoir pressure distribution in geologic carbon\nstorage (GCS) by assimilating monitoring data is a challenging problem. Due to\nhigh drilling cost, GCS projects usually have spatially sparse measurements\nfrom wells, leading to high uncertainties in reservoir pressure prediction. To\naddress this challenge, we propose to use low-cost Interferometric\nSynthetic-Aperture Radar (InSAR) data as monitoring data to infer reservoir\npressure build up. We develop a deep learning-accelerated workflow to\nassimilate surface displacement maps interpreted from InSAR and to forecast\ndynamic reservoir pressure. Employing an Ensemble Smoother Multiple Data\nAssimilation (ES-MDA) framework, the workflow updates three-dimensional (3D)\ngeologic properties and predicts reservoir pressure with quantified\nuncertainties. We use a synthetic commercial-scale GCS model with bimodally\ndistributed permeability and porosity to demonstrate the efficacy of the\nworkflow. A two-step CNN-PCA approach is employed to parameterize the bimodal\nfields. The computational efficiency of the workflow is boosted by two residual\nU-Net based surrogate models for surface displacement and reservoir pressure\npredictions, respectively. The workflow can complete data assimilation and\nreservoir pressure forecasting in half an hour on a personal computer.",
    "descriptor": "",
    "authors": [
      "Hewei Tang",
      "Pengcheng Fu",
      "Honggeun Jo",
      "Su Jiang",
      "Christopher S. Sherman",
      "Fran\u00e7ois Hamon",
      "Nicholas A. Azzolina",
      "Joseph P. Morris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08543"
  },
  {
    "id": "arXiv:2201.08582",
    "title": "SegTransVAE: Hybrid CNN -- Transformer with Regularization for medical  image segmentation",
    "abstract": "Current research on deep learning for medical image segmentation exposes\ntheir limitations in learning either global semantic information or local\ncontextual information. To tackle these issues, a novel network named\nSegTransVAE is proposed in this paper. SegTransVAE is built upon\nencoder-decoder architecture, exploiting transformer with the variational\nautoencoder (VAE) branch to the network to reconstruct the input images jointly\nwith segmentation. To the best of our knowledge, this is the first method\ncombining the success of CNN, transformer, and VAE. Evaluation on various\nrecently introduced datasets shows that SegTransVAE outperforms previous\nmethods in Dice Score and $95\\%$-Haudorff Distance while having comparable\ninference time to a simple CNN-based architecture network. The source code is\navailable at: https://github.com/itruonghai/SegTransVAE.",
    "descriptor": "\nComments: Accepted for publication in 2020 IEEE ISBI: 4 pages, 3 figures\n",
    "authors": [
      "Quan-Dung Pham",
      "Hai Nguyen-Truong",
      "Nam Nguyen Phuong",
      "Khoa N. A. Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08582"
  },
  {
    "id": "arXiv:2201.08596",
    "title": "Nilpotent dynamics on signed interaction graphs and weak converses of  Thomas' rules",
    "abstract": "A finite dynamical system with $n$ components is a function $f:X\\to X$ where\n$X=X_1\\times\\dots\\times X_n$ is a product of $n$ finite intervals of integers.\nThe structure of such a system $f$ is represented by a signed digraph $G$,\ncalled interaction graph: there are $n$ vertices, one per component, and the\nsigned arcs describe the positive and negative influences between them. Finite\ndynamical systems are usual models for gene networks. In this context, it is\noften assumed that $f$ is {\\em degree-bounded}, that is, the size of each $X_i$\nis at most the out-degree of $i$ in $G$ plus one. Assuming that $G$ is\nconnected and that $f$ is degree-bounded, we prove the following: if $G$ is not\na cycle, then $f^{n+1}$ may be a constant. In that case, $f$ describes a very\nsimple dynamics: a global convergence toward a unique fixed point in $n+1$\niterations. This shows that, in the degree-bounded case, the fact that $f$\ndescribes a complex dynamics {\\em cannot} be deduced from its interaction\ngraph. We then widely generalize the above result, obtaining, as immediate\nconsequences, other limits on what can be deduced from the interaction graph\nonly, as the following weak converses of Thomas' rules: if $G$ is connected and\nhas a positive (negative) cycle, then $f$ may have two (no) fixed points.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.08596"
  },
  {
    "id": "arXiv:2201.08600",
    "title": "Positive and negative cycles in Boolean networks",
    "abstract": "We review and discuss some results about the influence of positive and\nnegative feedback cycles in asynchronous Boolean networks. These results merge\nseveral ideas of Thomas: positive and negative feedback cycles have been\nlargely emphasized by Thomas, through the so called Thomas' rules, and\nasynchronous Boolean networks have been introduced by Thomas as a model for the\ndynamics of gene networks, which is nowadays very popular.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.08600"
  },
  {
    "id": "arXiv:2201.08623",
    "title": "Learning deterministic hydrodynamic equations from stochastic active  particle dynamics",
    "abstract": "We present a principled data-driven strategy for learning deterministic\nhydrodynamic models directly from stochastic non-equilibrium active particle\ntrajectories. We apply our method to learning a hydrodynamic model for the\npropagating density lanes observed in self-propelled particle systems and to\nlearning a continuum description of cell dynamics in epithelial tissues. We\nalso infer from stochastic particle trajectories the latent phoretic fields\ndriving chemotaxis. This demonstrates that statistical learning theory combined\nwith physical priors can enable discovery of multi-scale models of\nnon-equilibrium stochastic processes characteristic of collective movement in\nliving systems.",
    "descriptor": "",
    "authors": [
      "Suryanarayana Maddu",
      "Quentin Vagne",
      "Ivo F. Sbalzarini"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2201.08623"
  },
  {
    "id": "arXiv:2201.08629",
    "title": "Training Hybrid Classical-Quantum Classifiers via Stochastic Variational  Optimization",
    "abstract": "Quantum machine learning has emerged as a potential practical application of\nnear-term quantum devices. In this work, we study a two-layer hybrid\nclassical-quantum classifier in which a first layer of quantum stochastic\nneurons implementing generalized linear models (QGLMs) is followed by a second\nclassical combining layer. The input to the first, hidden, layer is obtained\nvia amplitude encoding in order to leverage the exponential size of the fan-in\nof the quantum neurons in the number of qubits per neuron. To facilitate\nimplementation of the QGLMs, all weights and activations are binary. While the\nstate of the art on training strategies for this class of models is limited to\nexhaustive search and single-neuron perceptron-like bit-flip strategies, this\nletter introduces a stochastic variational optimization approach that enables\nthe joint training of quantum and classical layers via stochastic gradient\ndescent. Experiments show the advantages of the approach for a variety of\nactivation functions implemented by QGLM neurons.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Ivana Nikoloska",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08629"
  },
  {
    "id": "arXiv:2201.08652",
    "title": "A phase transition for finding needles in nonlinear haystacks with LASSO  artificial neural networks",
    "abstract": "To fit sparse linear associations, a LASSO sparsity inducing penalty with a\nsingle hyperparameter provably allows to recover the important features\n(needles) with high probability in certain regimes even if the sample size is\nsmaller than the dimension of the input vector (haystack). More recently\nlearners known as artificial neural networks (ANN) have shown great successes\nin many machine learning tasks, in particular fitting nonlinear associations.\nSmall learning rate, stochastic gradient descent algorithm and large training\nset help to cope with the explosion in the number of parameters present in deep\nneural networks. Yet few ANN learners have been developed and studied to find\nneedles in nonlinear haystacks. Driven by a single hyperparameter, our ANN\nlearner, like for sparse linear associations, exhibits a phase transition in\nthe probability of retrieving the needles, which we do not observe with other\nANN learners. To select our penalty parameter, we generalize the universal\nthreshold of Donoho and Johnstone (1994) which is a better rule than the\nconservative (too many false detections) and expensive cross-validation. In the\nspirit of simulated annealing, we propose a warm-start sparsity inducing\nalgorithm to solve the high-dimensional, non-convex and non-differentiable\noptimization problem. We perform precise Monte Carlo simulations to show the\neffectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Ma",
      "Sylvain Sardy",
      "Nick Hengartner",
      "Nikolai Bobenko",
      "Yen Ting Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08652"
  },
  {
    "id": "arXiv:2201.08662",
    "title": "A Comprehensive Study of Bug Fixes in Quantum Programs",
    "abstract": "As quantum programming evolves, more and more quantum programming languages\nare being developed. As a result, debugging and testing quantum programs have\nbecome increasingly important. While bug fixing in classical programs has come\na long way, there is a lack of research in quantum programs. To this end, this\npaper presents a comprehensive study on bug fixing in quantum programs. We\ncollect and investigate 96 real-world bugs and their fixes from four popular\nquantum programming languages Qiskit, Cirq, Q#, and ProjectQ). Our study shows\nthat a high proportion of bugs in quantum programs are quantum-specific bugs\n(over 80%), which requires further research in the bug fixing domain. We also\nsummarize and extend the bug patterns in quantum programs and subdivide the\nmost critical part, math-related bugs, to make it more applicable to the study\nof quantum programs. Our findings summarize the characteristics of bugs in\nquantum programs and provide a basis for studying testing and debugging quantum\nprograms.",
    "descriptor": "",
    "authors": [
      "Junjie Luo",
      "Pengzhan Zhao",
      "Zhongtao Miao",
      "Shuhan Lan",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08662"
  },
  {
    "id": "arXiv:2201.08668",
    "title": "Clipped DeepControl: deep neural network two-dimensional pulse design  with an amplitude constraint layer",
    "abstract": "Advanced radio-frequency pulse design used in magnetic resonance imaging has\nrecently been demonstrated with deep learning of (convolutional) neural\nnetworks and reinforcement learning. For two-dimensionally selective\nradio-frequency pulses, the (convolutional) neural network pulse prediction\ntime (few milliseconds) was in comparison more than three orders of magnitude\nfaster than the conventional optimal control computation. The network pulses\nwere from the supervised training capable of compensating scan-subject\ndependent inhomogeneities of B0 and B+1 fields. Unfortunately, the network\npresented with a non-negligible percentage of pulse amplitude overshoots in the\ntest subset, despite the optimal control pulses used in training were fully\nconstrained. Here, we have extended the convolutional neural network with a\ncustom-made clipping layer that completely eliminates the risk of pulse\namplitude overshoots, while preserving the ability to compensate the\ninhomogeneous field conditions.",
    "descriptor": "",
    "authors": [
      "Mads Sloth Vinding",
      "Torben Ellegaard Lund"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08668"
  },
  {
    "id": "arXiv:2201.08706",
    "title": "SparseAlign: A Super-Resolution Algorithm for Automatic Marker  Localization and Deformation Estimation in Cryo-Electron Tomography",
    "abstract": "Tilt-series alignment is crucial to obtaining high-resolution reconstructions\nin cryo-electron tomography. Beam-induced local deformation of the sample is\nhard to estimate from the low-contrast sample alone, and often requires\nfiducial gold bead markers. The state-of-the-art approach for deformation\nestimation uses (semi-)manually labelled marker locations in projection data to\nfit the parameters of a polynomial deformation model. Manually-labelled marker\nlocations are difficult to obtain when data are noisy or markers overlap in\nprojection data. We propose an alternative mathematical approach for\nsimultaneous marker localization and deformation estimation by extending a\ngrid-free super-resolution algorithm first proposed in the context of\nsingle-molecule localization microscopy. Our approach does not require labelled\nmarker locations; instead, we use an image-based loss where we compare the\nforward projection of markers with the observed data. We equip this marker\nlocalization scheme with an additional deformation estimation component and\nsolve for a reduced number of deformation parameters. Using extensive numerical\nstudies on marker-only samples, we show that our approach automatically finds\nmarkers and reliably estimates sample deformation without labelled marker data.\nWe further demonstrate the applicability of our approach for a broad range of\nmodel mismatch scenarios, including experimental electron tomography data of\ngold markers on ice.",
    "descriptor": "",
    "authors": [
      "Poulami Somanya Ganguly",
      "Felix Lucka",
      "Holger Kohr",
      "Erik Franken",
      "Hermen Jan Hupkes",
      "K Joost Batenburg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2201.08706"
  },
  {
    "id": "arXiv:2201.08712",
    "title": "Improved Random Features for Dot Product Kernels",
    "abstract": "Dot product kernels, such as polynomial and exponential (softmax) kernels,\nare among the most widely used kernels in machine learning, as they enable\nmodeling the interactions between input features, which is crucial in\napplications like computer vision, natural language processing, and recommender\nsystems. We make several novel contributions for improving the efficiency of\nrandom feature approximations for dot product kernels, to make these kernels\nmore useful in large scale learning. First, we present a generalization of\nexisting random feature approximations for polynomial kernels, such as\nRademacher and Gaussian sketches and TensorSRHT, using complex-valued random\nfeatures. We show empirically that the use of complex features can\nsignificantly reduce the variances of these approximations. Second, we provide\na theoretical analysis for understanding the factors affecting the efficiency\nof various random feature approximations, by deriving closed-form expressions\nfor their variances. These variance formulas elucidate conditions under which\ncertain approximations (e.g., TensorSRHT) achieve lower variances than others\n(e.g, Rademacher sketch), and conditions under which the use of complex\nfeatures leads to lower variances than real features. Third, by using these\nvariance formulas, which can be evaluated in practice, we develop a data-driven\noptimization approach to random feature approximations for general dot product\nkernels, which is also applicable to the Gaussian kernel. We describe the\nimprovements brought by these contributions with extensive experiments on a\nvariety of tasks and datasets.",
    "descriptor": "\nComments: 71 pages\n",
    "authors": [
      "Jonas Wacker",
      "Motonobu Kanagawa",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08712"
  },
  {
    "id": "arXiv:2201.08714",
    "title": "Equivalent Distance Geometry Error for Molecular Conformation Comparison",
    "abstract": "Straight-forward conformation generation models, which generate 3-D\nstructures directly from input molecular graphs, play an important role in\nvarious molecular tasks with machine learning, such as 3D-QSAR and virtual\nscreening in drug design. However, existing loss functions in these models\neither cost overmuch time or fail to guarantee the equivalence during\noptimization, which means treating different items unfairly, resulting in poor\nlocal geometry in generated conformation. So, we propose Equivalent Distance\nGeometry Error (EDGE) to calculate the differential discrepancy between\nconformations where the essential factors of three kinds in conformation\ngeometry (i.e. bond lengths, bond angles and dihedral angles) are equivalently\noptimized with certain weights. And in the improved version of our method, the\noptimization features minimizing linear transformations of atom-pair distances\nwithin 3-hop. Extensive experiments show that, compared with existing loss\nfunctions, EDGE performs effectively and efficiently in two tasks under the\nsame backbones.",
    "descriptor": "",
    "authors": [
      "Shuwen Yang",
      "Tianyu Wen",
      "Ziyao Li",
      "Guojie Song"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08714"
  },
  {
    "id": "arXiv:2201.08741",
    "title": "Improving Across-Dataset Brain Tissue Segmentation Using Transformer",
    "abstract": "Brain tissue segmentation has demonstrated great utility in quantifying MRI\ndata through Voxel-Based Morphometry and highlighting subtle structural changes\nassociated with various conditions within the brain. However, manual\nsegmentation is highly labor-intensive, and automated approaches have struggled\ndue to properties inherent to MRI acquisition, leaving a great need for an\neffective segmentation tool. Despite the recent success of deep convolutional\nneural networks (CNNs) for brain tissue segmentation, many such solutions do\nnot generalize well to new datasets, which is critical for a reliable solution.\nTransformers have demonstrated success in natural image segmentation and have\nrecently been applied to 3D medical image segmentation tasks due to their\nability to capture long-distance relationships in the input where the local\nreceptive fields of CNNs struggle. This study introduces a novel\nCNN-Transformer hybrid architecture designed for brain tissue segmentation. We\nvalidate our model's performance across four multi-site T1w MRI datasets,\ncovering different vendors, field strengths, scan parameters, time points, and\nneuropsychiatric conditions. In all situations, our model achieved the greatest\ngenerality and reliability. Out method is inherently robust and can serve as a\nvaluable tool for brain-related T1w MRI studies. The code for the TABS network\nis available at: https://github.com/raovish6/TABS.",
    "descriptor": "",
    "authors": [
      "Vishwanatha M. Rao",
      "Zihan Wan",
      "David J. Ma",
      "Pin-Yu Lee",
      "Ye Tian",
      "Andrew F. Laine",
      "Jia Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08741"
  },
  {
    "id": "arXiv:2201.08747",
    "title": "Inferring Brain Dynamics via Multimodal Joint Graph Representation  EEG-fMRI",
    "abstract": "Recent studies have shown that multi-modeling methods can provide new\ninsights into the analysis of brain components that are not possible when each\nmodality is acquired separately. The joint representations of different\nmodalities is a robust model to analyze simultaneously acquired\nelectroencephalography and functional magnetic resonance imaging (EEG-fMRI).\nAdvances in precision instruments have given us the ability to observe the\nspatiotemporal neural dynamics of the human brain through non-invasive\nneuroimaging techniques such as EEG & fMRI. Nonlinear fusion methods of streams\ncan extract effective brain components in different dimensions of temporal and\nspatial. Graph-based analyzes, which have many similarities to brain structure,\ncan overcome the complexities of brain mapping analysis. Throughout, we outline\nthe correlations of several different media in time shifts from one source with\ngraph-based and deep learning methods. Determining overlaps can provide a new\nperspective for diagnosing functional changes in neuroplasticity studies.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Jalal Mirakhorli"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08747"
  },
  {
    "id": "arXiv:2201.08814",
    "title": "Separating polynomial $\u03c7$-boundedness from $\u03c7$-boundedness",
    "abstract": "Extending the idea from the recent paper by Carbonero, Hompe, Moore, and\nSpirkl, for every function $f\\colon\\mathbb{N}\\to\\mathbb{N}$ we construct a\n$\\chi$-bounded hereditary class of graphs $\\mathcal{C}$ with the property that\nfor every integer $n\\ge 2$ there is a graph in $\\mathcal{C}$ with clique number\nat most $n$ and chromatic number at least $f(n)$. In particular, this proves\nthat there are hereditary classes of graphs that are $\\chi$-bounded but not\npolynomially $\\chi$-bounded.",
    "descriptor": "",
    "authors": [
      "Marcin Bria\u0144ski",
      "James Davies",
      "Bartosz Walczak"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.08814"
  },
  {
    "id": "arXiv:2201.08820",
    "title": "Conformal Metasurfaces: a Novel Solution for Vehicular Communications",
    "abstract": "In future 6G millimeter wave (mmWave)/sub-THz vehicle-to-everything (V2X)\ncommunication systems, vehicles are expected to be equipped with massive\nantenna arrays to realize beam-based links capable of compensating for the\nsevere path loss. However, vehicle-to-vehicle (V2V) direct links are prone to\nbe blocked by surrounding vehicles. Emerging metasurface technologies enable\nthe control of the electromagnetic wave reflection towards the desired\ndirection, enriching the channel scattering to boost communication performance.\nReconfigurable intelligent surfaces (RIS), and mostly the pre-configured\ncounterpart intelligent reflecting surfaces (IRS), are a promising low-cost\nrelaying system for 6G. This paper proposes using conformal metasurfaces\n(either C-RIS or C-IRS) deployed on vehicles' body to mitigate the blockage\nimpact in a highway multi-lane scenario. In particular, conformal metasurfaces\ncreate artificial reflections to mitigate blockage by compensating for the\nnon-flat shape of the vehicle's body, such as the lateral doors, with proper\nphase patterns. We analytically derive the phase pattern to apply to a\ncylindrical C-RIS/C-IRS approximating the shape of the car body, as a function\nof both incidence and reflection angles, considering cylindrical RIS/IRS as a\ngeneralization of conventional planar ones. We propose a novel design for\noptimally pre-configured C-IRS to mimic the behavior of an EM flat surface on\ncar doors, proving the benefits of C-RIS and C-IRS in a multi-lane V2V highway\nscenario. The results show a consistent reduction of blockage probability when\nexploiting C-RIS/C-IRS, 20% for pre-configured C-IRS, and 70% for C-RIS, as\nwell as a remarkable improvement in terms of average signal-to-noise ratio,\nrespectively 10-20 dB for C-IRS and 30-40 dB for C-RIS.",
    "descriptor": "",
    "authors": [
      "Marouan Mizmizi",
      "Reza Aghazadeh Ayoubi",
      "Dario Tagliaferri",
      "Kai Dong",
      "Gian Guido Gentili",
      "Umberto Spagnolini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08820"
  },
  {
    "id": "arXiv:2201.08822",
    "title": "Ensemble of Opinion Dynamics Models to Understand the Role of the  Undecided in the Vaccination Debate",
    "abstract": "We present three models used to describe the recruitment of the undecided\npopulation by pro-vax and no-vax factions. Starting from real-world data of\nFacebook pages, we compare three opinion dynamics models that catch different\nbehaviours of the undecided population.\nThe first one is a variation of the SIS model, where undecided position is\nconsidered indifferent. Neutrals can be \"infected\" by one of the two extreme\nfactions, joining their side, and they \"recover\" when they lose interest in the\ndebate and go back to neutrality.\nThe second model is a three parties Voters model: neutral pages represent a\ncentrist position. They lean their original ideas, that are different from both\nthe other parties.\nThe last is the Bilingual model adapted to the vaccination debate: neutral\nindividuals are in agreement with both pro-, ad anti-vax factions, with a\nposition of compromise between the extremes (\"bilingualism''). If they have a\none-sided neighbourhood, the convenience to agree with both parties comes out,\nand bi-linguists can become mono-linguists.\nOur results depicts an agreement between the three models: anti-vax opinion\npropagates more than pro-vax, thanks to an initial strategic position in the\nonline social network (even if they start with a smaller population). While\nmost of the pro-vaccines nodes are segregated in their own communities,\nno-vaccines ones are entangled at the core of the network, where the majority\nof undecided population is located.\nIn the last section, we propose and compare some policies that could be\napplied on the network to prevent anti-vax overcome: they lead us to conclude\nthat censoring strategies are not effective, as well as segregating scenarios\nbased on unfollowing decisions, while the addition of links in the network\nfavours the containment of the pro-vax domain, reducing the distance between\npro-vaxxers and undecided population.",
    "descriptor": "",
    "authors": [
      "Jacopo Lenti",
      "Giancarlo Ruffo"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.08822"
  },
  {
    "id": "arXiv:2201.08825",
    "title": "Short-Range Microwave Networks to Scale Superconducting Quantum  Computation",
    "abstract": "A core challenge for superconducting quantum computers is to scale up the\nnumber of qubits in each processor without increasing noise or cross-talk.\nDistributing a quantum computer across nearby small qubit arrays, known as\nchiplets, could solve many problems associated with size. We propose a chiplet\narchitecture over microwave links with potential to exceed monolithic\nperformance on near-term hardware. We model and evaluate the chiplet\narchitecture in a way that bridges the physical and network layers. We find\nconcrete evidence that distributed quantum computing may accelerate the path\ntoward useful and ultimately scalable quantum computers. In the long-term,\nshort-range networks may underlie quantum computers just as local area networks\nunderlie classical datacenters and supercomputers today.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Nicholas LaRacuente",
      "Kaitlin N. Smith",
      "Poolad Imany",
      "Kevin L. Silverman",
      "Frederic T. Chong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.08825"
  },
  {
    "id": "arXiv:2201.08836",
    "title": "A Matheuristic Approach for Solving a Simultaneous Lot Sizing and  Scheduling Problem with Client Prioritization in Tire Industry",
    "abstract": "This paper introduces an integrated lot sizing and scheduling problem\ninspired from a real-world application in off-the-road tire industry. This\nproblem considers the assignment of different items on parallel machines with\ncomplex eligibility constraints within a finite planning horizon. It also\nconsiders a large panel of specific constraints such as: backordering, a\nlimited number of setups, upstream resources saturation and customers\nprioritization. A novel mixed integer formulation is proposed with the\nobjective of optimizing different normalized criteria related to the inventory\nand service level performance. Based on this mathematical formulation, a\nproblem-based matheuristic method that solves the lot sizing and assignment\nproblems separately is proposed to solve the industrial case. A computational\nstudy and sensitivity analysis are carried out based on real-world data with up\nto 170 products, 70 unrelated parallel machines and 42 periods. The obtained\nresults show the effectiveness of the proposed approach on improving the\ncompany's solution. Indeed, the two most important KPIs for the management have\nbeen optimized of respectively 32% for the backorders and 13% for the\noverstock. Moreover, the computational time have been reduced significantly.",
    "descriptor": "",
    "authors": [
      "Cyril Koch",
      "Taha Arbaoui",
      "Yassine Ouazene",
      "Farouk Yalaoui",
      "Humbert De Brunier",
      "Nicolas Jaunet",
      "Antoine De Wulf"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.08836"
  },
  {
    "id": "arXiv:2201.08839",
    "title": "Dynamic Infection Spread Model Based Group Testing",
    "abstract": "We study a dynamic infection spread model, inspired by the discrete time SIR\nmodel, where infections are spread via non-isolated infected individuals. While\ninfection keeps spreading over time, a limited capacity testing is performed at\neach time instance as well. In contrast to the classical, static, group testing\nproblem, the objective in our setup is not to find the minimum number of\nrequired tests to identify the infection status of every individual in the\npopulation, but to control the infection spread by detecting and isolating the\ninfections over time by using the given, limited number of tests. In order to\nanalyze the performance of the proposed algorithms, we focus on the mean-sense\nanalysis of the number of individuals that remain non-infected throughout the\nprocess of controlling the infection. We propose two dynamic algorithms that\nboth use given limited number of tests to identify and isolate the infections\nover time, while the infection spreads. While the first algorithm is a dynamic\nrandomized individual testing algorithm, in the second algorithm we employ the\ngroup testing approach similar to the original work of Dorfman. By considering\nweak versions of our algorithms, we obtain lower bounds for the performance of\nour algorithms. Finally, we implement our algorithms and run simulations to\ngather numerical results and compare our algorithms and theoretical\napproximation results under different sets of system parameters.",
    "descriptor": "",
    "authors": [
      "Batuhan Arasli",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Data Structures and Algorithms (cs.DS)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2201.08839"
  },
  {
    "id": "arXiv:1601.06070",
    "title": "Efficient Globally Optimal 2D-to-3D Deformable Shape Matching",
    "abstract": "Comments: Extended chapter of conference paper in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2016 to be published in Shape Analysis: Euclidean, Discrete and Algebraic Geometric Methods by Springer",
    "descriptor": "\nComments: Extended chapter of conference paper in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2016 to be published in Shape Analysis: Euclidean, Discrete and Algebraic Geometric Methods by Springer\n",
    "authors": [
      "Zorah L\u00e4hner",
      "Emanuele Rodol\u00e0",
      "Frank R. Schmidt",
      "Michael M. Bronstein",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1601.06070"
  },
  {
    "id": "arXiv:1901.05031",
    "title": "Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs",
    "abstract": "Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs",
    "descriptor": "",
    "authors": [
      "Mauricio Flores Rios",
      "Jeff Calder",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/1901.05031"
  },
  {
    "id": "arXiv:1904.05269",
    "title": "Planar graphs have bounded nonrepetitive chromatic number",
    "abstract": "Planar graphs have bounded nonrepetitive chromatic number",
    "descriptor": "",
    "authors": [
      "Vida Dujmovi\u0107",
      "Louis Esperet",
      "Gwena\u00ebl Joret",
      "Bartosz Walczak",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1904.05269"
  },
  {
    "id": "arXiv:1905.00457",
    "title": "Truthful Aggregation of Budget Proposals",
    "abstract": "Comments: 28 pages, final journal version",
    "descriptor": "\nComments: 28 pages, final journal version\n",
    "authors": [
      "Rupert Freeman",
      "David M. Pennock",
      "Dominik Peters",
      "Jennifer Wortman Vaughan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1905.00457"
  },
  {
    "id": "arXiv:1906.00398",
    "title": "Cost-sensitive Boosting Pruning Trees for depression detection on  Twitter",
    "abstract": "Comments: 15 pages, 7 figures, Accepted by IEEE transactions on Affective Computing",
    "descriptor": "\nComments: 15 pages, 7 figures, Accepted by IEEE transactions on Affective Computing\n",
    "authors": [
      "Lei Tong",
      "Zhihua Liu",
      "Zheheng Jiang",
      "Feixiang Zhou",
      "Long Chen",
      "Jialin Lyu",
      "Xiangrong Zhang",
      "Qianni Zhang",
      "Abdul Sadka Senior",
      "Yinhai Wang",
      "Ling Li",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.00398"
  },
  {
    "id": "arXiv:2001.07649",
    "title": "Integrating data science ethics into an undergraduate major",
    "abstract": "Integrating data science ethics into an undergraduate major",
    "descriptor": "",
    "authors": [
      "Benjamin S. Baumer",
      "Randi L. Garcia",
      "Albert Y. Kim",
      "Katherine M. Kinnaird",
      "Miles Q. Ott"
    ],
    "subjectives": [
      "Other Statistics (stat.OT)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2001.07649"
  },
  {
    "id": "arXiv:2006.13823",
    "title": "Preventing Value Function Collapse in Ensemble {Q}-Learning by  Maximizing Representation Diversity",
    "abstract": "Comments: Accepted in Deep Reinforcement Learning Workshop at NeurIPS 2020",
    "descriptor": "\nComments: Accepted in Deep Reinforcement Learning Workshop at NeurIPS 2020\n",
    "authors": [
      "Hassam Ullah Sheikh",
      "Ladislau B\u00f6l\u00f6ni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13823"
  },
  {
    "id": "arXiv:2007.06549",
    "title": "Preferences Single-Peaked on a Tree: Multiwinner Elections and  Structural Results",
    "abstract": "Comments: 44 pages, extends works published at AAAI 2016 and IJCAI 2013, published version",
    "descriptor": "\nComments: 44 pages, extends works published at AAAI 2016 and IJCAI 2013, published version\n",
    "authors": [
      "Dominik Peters",
      "Lan Yu",
      "Hau Chan",
      "Edith Elkind"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.06549"
  },
  {
    "id": "arXiv:2007.09024",
    "title": "Perturbation Bounds for (Nearly) Orthogonally Decomposable Tensors",
    "abstract": "Perturbation Bounds for (Nearly) Orthogonally Decomposable Tensors",
    "descriptor": "",
    "authors": [
      "Arnab Auddy",
      "Ming Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.09024"
  },
  {
    "id": "arXiv:2008.02352",
    "title": "Efficient Compactions Between Storage Tiers with PrismDB",
    "abstract": "Efficient Compactions Between Storage Tiers with PrismDB",
    "descriptor": "",
    "authors": [
      "Ashwini Raina",
      "Jianan Lu",
      "Asaf Cidon",
      "Michael J. Freedman"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2008.02352"
  },
  {
    "id": "arXiv:2009.12232",
    "title": "From Pixel to Patch: Synthesize Context-aware Features for Zero-shot  Semantic Segmentation",
    "abstract": "Comments: accepted by TNNLS",
    "descriptor": "\nComments: accepted by TNNLS\n",
    "authors": [
      "Zhangxuan Gu",
      "Siyuan Zhou",
      "Li Niu",
      "Zihan Zhao",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.12232"
  },
  {
    "id": "arXiv:2010.07061",
    "title": "GiantMIDI-Piano: A large-scale MIDI dataset for classical piano music",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Qiuqiang Kong",
      "Bochen Li",
      "Jitong Chen",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.07061"
  },
  {
    "id": "arXiv:2010.09553",
    "title": "Survey on Causal-based Machine Learning Fairness Notions",
    "abstract": "Survey on Causal-based Machine Learning Fairness Notions",
    "descriptor": "",
    "authors": [
      "Karima Makhlouf",
      "Sami Zhioua",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09553"
  },
  {
    "id": "arXiv:2010.12808",
    "title": "Pairwise Representation Learning for Event Coreference",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xiaodong Yu",
      "Wenpeng Yin",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12808"
  },
  {
    "id": "arXiv:2010.15618",
    "title": "Sampling and Reconstruction of Sparse Signals in Shift-Invariant Spaces:  Generalized Shannon's Theorem Meets Compressive Sensing",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Tin Vla\u0161i\u0107",
      "Damir Ser\u0161i\u0107"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.15618"
  },
  {
    "id": "arXiv:2011.02034",
    "title": "The Role of Time, Weather and Google Trends in Understanding and  Predicting Web Survey Response",
    "abstract": "Comments: Published in Survey Research Methods. See this https URL",
    "descriptor": "\nComments: Published in Survey Research Methods. See this https URL\n",
    "authors": [
      "Qixiang Fang",
      "Joep Burger",
      "Ralph Meijers",
      "Kees van Berkel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.02034"
  },
  {
    "id": "arXiv:2012.00489",
    "title": "Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information",
    "abstract": "Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information",
    "descriptor": "",
    "authors": [
      "Filippo Simini",
      "Gianni Barlacchi",
      "Massimiliano Luca",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.00489"
  },
  {
    "id": "arXiv:2012.08752",
    "title": "Graph Neural Networks: Taxonomy, Advances and Trends",
    "abstract": "Comments: 42 pages, 7 figures",
    "descriptor": "\nComments: 42 pages, 7 figures\n",
    "authors": [
      "Yu Zhou",
      "Haixia Zheng",
      "Xin Huang",
      "Shufeng Hao",
      "Dengao Li",
      "Jumin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08752"
  },
  {
    "id": "arXiv:2101.11231",
    "title": "Designing for Engaging with News using Moral Framing towards Bridging  Ideological Divides",
    "abstract": "Comments: Accepted to ACM GROUP 2022",
    "descriptor": "\nComments: Accepted to ACM GROUP 2022\n",
    "authors": [
      "Jessica Wang",
      "Amy Zhang",
      "David Karger"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.11231"
  },
  {
    "id": "arXiv:2102.00491",
    "title": "Learning elliptic partial differential equations with randomized linear  algebra",
    "abstract": "Comments: 25 pages, 4 figures",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Nicolas Boull\u00e9",
      "Alex Townsend"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.00491"
  },
  {
    "id": "arXiv:2102.01466",
    "title": "Individual dynamic prediction of clinical endpoint from large  dimensional longitudinal biomarker history: a landmark approach",
    "abstract": "Individual dynamic prediction of clinical endpoint from large  dimensional longitudinal biomarker history: a landmark approach",
    "descriptor": "",
    "authors": [
      "Anthony Devaux",
      "Robin Genuer",
      "Karine P\u00e9r\u00e8s",
      "C\u00e9cile Proust-Lima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01466"
  },
  {
    "id": "arXiv:2102.03406",
    "title": "Symbolic Behaviour in Artificial Intelligence",
    "abstract": "Symbolic Behaviour in Artificial Intelligence",
    "descriptor": "",
    "authors": [
      "Adam Santoro",
      "Andrew Lampinen",
      "Kory Mathewson",
      "Timothy Lillicrap",
      "David Raposo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03406"
  },
  {
    "id": "arXiv:2102.07003",
    "title": "On the convergence of group-sparse autoencoders",
    "abstract": "On the convergence of group-sparse autoencoders",
    "descriptor": "",
    "authors": [
      "Emmanouil Theodosis",
      "Bahareh Tolooshams",
      "Pranay Tankala",
      "Abiy Tasissa",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07003"
  },
  {
    "id": "arXiv:2102.11605",
    "title": "A tier-based typed programming language characterizing Feasible  Functionals",
    "abstract": "A tier-based typed programming language characterizing Feasible  Functionals",
    "descriptor": "",
    "authors": [
      "Emmanuel Hainry",
      "Bruce M. Kapron",
      "Jean-Yves Marion",
      "Romain P\u00e9choux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.11605"
  },
  {
    "id": "arXiv:2103.00858",
    "title": "CARMI: A Cache-Aware Learned Index with a Cost-based Construction  Algorithm",
    "abstract": "Comments: 21 pages, 24 figures, 8 tables",
    "descriptor": "\nComments: 21 pages, 24 figures, 8 tables\n",
    "authors": [
      "Jiaoyi Zhang",
      "Yihan Gao"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00858"
  },
  {
    "id": "arXiv:2103.15154",
    "title": "Active RIS vs. Passive RIS: Which Will Prevail in 6G?",
    "abstract": "Comments: Unlike the existing passive RIS, active RIS that can actively amplify the reflected signals is proposed to break the fundamental limit of multiplicative fading effect of RIS. The new signal model of active RIS is validated through experimental measurements. Measurement data and simulation codes will be provided at: this http URL",
    "descriptor": "\nComments: Unlike the existing passive RIS, active RIS that can actively amplify the reflected signals is proposed to break the fundamental limit of multiplicative fading effect of RIS. The new signal model of active RIS is validated through experimental measurements. Measurement data and simulation codes will be provided at: this http URL\n",
    "authors": [
      "Zijian Zhang",
      "Linglong Dai",
      "Xibi Chen",
      "Changhao Liu",
      "Fan Yang",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.15154"
  },
  {
    "id": "arXiv:2104.07713",
    "title": "Contrastive Learning with Stronger Augmentations",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Xiao Wang",
      "Guo-Jun Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07713"
  },
  {
    "id": "arXiv:2104.08980",
    "title": "Sampling Polynomial Trajectories for LTL Verification",
    "abstract": "Comments: Published in Theoretical Computer Science. Definition 7 and Remark 4 have been updated to correct an oversight in the published version",
    "descriptor": "\nComments: Published in Theoretical Computer Science. Definition 7 and Remark 4 have been updated to correct an oversight in the published version\n",
    "authors": [
      "Daniel Selvaratnam",
      "Michael Cantoni",
      "J. M. Davoren",
      "Iman Shames"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.08980"
  },
  {
    "id": "arXiv:2104.11222",
    "title": "On Aliased Resizing and Surprising Subtleties in GAN Evaluation",
    "abstract": "Comments: GitHub: this https URL Website: this https URL",
    "descriptor": "\nComments: GitHub: this https URL Website: this https URL\n",
    "authors": [
      "Gaurav Parmar",
      "Richard Zhang",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11222"
  },
  {
    "id": "arXiv:2104.11574",
    "title": "CapillaryNet: An Automated System to Quantify Skin Capillary Density and  Red Blood Cell Velocity from Handheld Vital Microscopy",
    "abstract": "Comments: Improved overall English text and added few more sections",
    "descriptor": "\nComments: Improved overall English text and added few more sections\n",
    "authors": [
      "Maged Helmy",
      "Anastasiya Dykyy",
      "Tuyen Trung Truong",
      "Paulo Ferreira",
      "Eric Jul"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11574"
  },
  {
    "id": "arXiv:2104.14659",
    "title": "End-to-End Jet Classification of Boosted Top Quarks with the CMS Open  Data",
    "abstract": "Comments: 9 pages, 3 figures, 4 tables; v3: unpublished",
    "descriptor": "\nComments: 9 pages, 3 figures, 4 tables; v3: unpublished\n",
    "authors": [
      "Michael Andrews",
      "Bjorn Burkle",
      "Yi-fan Chen",
      "Davide DiCroce",
      "Sergei Gleyzer",
      "Ulrich Heintz",
      "Meenakshi Narain",
      "Manfred Paulini",
      "Nikolas Pervan",
      "Yusef Shafi",
      "Wei Sun",
      "Emanuele Usai",
      "Kun Yang"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2104.14659"
  },
  {
    "id": "arXiv:2105.07332",
    "title": "A Complete algorithm for local inversion of maps: Application to  Cryptanalysis",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Virendra Sule"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07332"
  },
  {
    "id": "arXiv:2105.13052",
    "title": "A generalization of the randomized singular value decomposition",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Nicolas Boull\u00e9",
      "Alex Townsend"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13052"
  },
  {
    "id": "arXiv:2105.13440",
    "title": "Non-negative matrix factorization algorithms greatly improve topic model  fits",
    "abstract": "Non-negative matrix factorization algorithms greatly improve topic model  fits",
    "descriptor": "",
    "authors": [
      "Peter Carbonetto",
      "Abhishek Sarkar",
      "Zihao Wang",
      "Matthew Stephens"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.13440"
  },
  {
    "id": "arXiv:2105.15164",
    "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
    "abstract": "Comments: Accepted for publication at ICLR 2022",
    "descriptor": "\nComments: Accepted for publication at ICLR 2022\n",
    "authors": [
      "Asma Ghandeharioun",
      "Been Kim",
      "Chun-Liang Li",
      "Brendan Jou",
      "Brian Eoff",
      "Rosalind W. Picard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15164"
  },
  {
    "id": "arXiv:2106.01908",
    "title": "You Never Cluster Alone",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yuming Shen",
      "Ziyi Shen",
      "Menghan Wang",
      "Jie Qin",
      "Philip H.S. Torr",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01908"
  },
  {
    "id": "arXiv:2106.01981",
    "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose",
    "abstract": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose",
    "descriptor": "",
    "authors": [
      "Boris N. Oreshkin",
      "Florent Bocquelet",
      "F\u00e9lix G. Harvey",
      "Bay Raitt",
      "Dominic Laflamme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01981"
  },
  {
    "id": "arXiv:2106.02811",
    "title": "Full-Dimensional Rate Enhancement for UAV-Enabled Communications via  Intelligent Omni-Surface",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Yifan Liu",
      "Bin Duo",
      "Qingqing Wu",
      "Xiaojun Yuan",
      "Yonghui Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02811"
  },
  {
    "id": "arXiv:2106.04155",
    "title": "Review Polarity-wise Recommender",
    "abstract": "Review Polarity-wise Recommender",
    "descriptor": "",
    "authors": [
      "Han Liu",
      "Yangyang Guo",
      "Jianhua Yin",
      "Zan Gao",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.04155"
  },
  {
    "id": "arXiv:2106.10201",
    "title": "A time and space optimal stable population protocol solving exact  majority",
    "abstract": "Comments: Applied FOCS reviewers' comments",
    "descriptor": "\nComments: Applied FOCS reviewers' comments\n",
    "authors": [
      "David Doty",
      "Mahsa Eftekhari",
      "Leszek G\u0105sieniec",
      "Eric Severson",
      "Grzegorz Stachowiak",
      "Przemys\u0142aw Uzna\u0144ski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10201"
  },
  {
    "id": "arXiv:2106.11535",
    "title": "Particle Cloud Generation with Message Passing Generative Adversarial  Networks",
    "abstract": "Comments: 14 pages, 4 figures, 2 tables, and an 8 page appendix. Accepted to the Thirty-fifth Conference on Neural Information Processing Systems",
    "descriptor": "\nComments: 14 pages, 4 figures, 2 tables, and an 8 page appendix. Accepted to the Thirty-fifth Conference on Neural Information Processing Systems\n",
    "authors": [
      "Raghav Kansal",
      "Javier Duarte",
      "Hao Su",
      "Breno Orzari",
      "Thiago Tomei",
      "Maurizio Pierini",
      "Mary Touranakou",
      "Jean-Roch Vlimant",
      "Dimitrios Gunopulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2106.11535"
  },
  {
    "id": "arXiv:2107.00068",
    "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning  (With Outliers) Problems",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Zixiu Wang",
      "Yiwen Guo",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00068"
  },
  {
    "id": "arXiv:2107.09139",
    "title": "Constrained Policy Gradient Method for Safe and Fast Reinforcement  Learning: a Neural Tangent Kernel Based Approach",
    "abstract": "Constrained Policy Gradient Method for Safe and Fast Reinforcement  Learning: a Neural Tangent Kernel Based Approach",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs Varga",
      "Bal\u00e1zs Kulcs\u00e1r",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09139"
  },
  {
    "id": "arXiv:2108.00710",
    "title": "Multi-Objective Path-Based D* Lite",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Maxim Likhachev",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00710"
  },
  {
    "id": "arXiv:2108.03492",
    "title": "Clio: A Hardware-Software Co-Designed Disaggregated Memory System",
    "abstract": "Comments: 16 pages, 22 figures. Accepted to ASPLOS'22",
    "descriptor": "\nComments: 16 pages, 22 figures. Accepted to ASPLOS'22\n",
    "authors": [
      "Zhiyuan Guo",
      "Yizhou Shan",
      "Xuhao Luo",
      "Yutong Huang",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.03492"
  },
  {
    "id": "arXiv:2108.06040",
    "title": "Knowledge Graph Reasoning with Relational Digraph",
    "abstract": "Knowledge Graph Reasoning with Relational Digraph",
    "descriptor": "",
    "authors": [
      "Yongqi Zhang",
      "Quanming Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.06040"
  },
  {
    "id": "arXiv:2108.07808",
    "title": "Simulating COVID19 Transmission From Observed Movement: An Agent-Based  Model of Classroom Dispersion",
    "abstract": "Simulating COVID19 Transmission From Observed Movement: An Agent-Based  Model of Classroom Dispersion",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Yudong Tao",
      "Mei-Ling Shyu",
      "Lynn K. Perry",
      "Prem R. Warde",
      "Daniel S. Messinger",
      "Chaoming Song"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.07808"
  },
  {
    "id": "arXiv:2108.08708",
    "title": "Czech News Dataset for Semantic Textual Similarity",
    "abstract": "Czech News Dataset for Semantic Textual Similarity",
    "descriptor": "",
    "authors": [
      "Jakub Sido",
      "Michal Sej\u00e1k",
      "Ond\u0159ej Pra\u017e\u00e1k",
      "Miloslav Konop\u00edk",
      "V\u00e1clav Moravec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.08708"
  },
  {
    "id": "arXiv:2108.09098",
    "title": "A fuzzy-rough uncertainty measure to discover bias encoded explicitly or  implicitly in features of structured pattern classification datasets",
    "abstract": "A fuzzy-rough uncertainty measure to discover bias encoded explicitly or  implicitly in features of structured pattern classification datasets",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Lisa Koutsoviti Koumeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09098"
  },
  {
    "id": "arXiv:2108.09373",
    "title": "Understanding Data Storage and Ingestion for Large-Scale Deep  Recommendation Model Training",
    "abstract": "Understanding Data Storage and Ingestion for Large-Scale Deep  Recommendation Model Training",
    "descriptor": "",
    "authors": [
      "Mark Zhao",
      "Niket Agarwal",
      "Aarti Basant",
      "Bugra Gedik",
      "Satadru Pan",
      "Mustafa Ozdal",
      "Rakesh Komuravelli",
      "Jerry Pan",
      "Tianshu Bao",
      "Haowei Lu",
      "Sundaram Narayanan",
      "Jack Langman",
      "Kevin Wilfong",
      "Harsha Rastogi",
      "Carole-Jean Wu",
      "Christos Kozyrakis",
      "Parik Pol"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09373"
  },
  {
    "id": "arXiv:2108.12056",
    "title": "Continual learning under domain transfer with sparse synaptic bursting",
    "abstract": "Continual learning under domain transfer with sparse synaptic bursting",
    "descriptor": "",
    "authors": [
      "Shawn L. Beaulieu",
      "Jeff Clune",
      "Nick Cheney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12056"
  },
  {
    "id": "arXiv:2109.00161",
    "title": "Simultaneous Neural Network Approximation for Smooth Functions",
    "abstract": "Simultaneous Neural Network Approximation for Smooth Functions",
    "descriptor": "",
    "authors": [
      "Sean Hon",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.00161"
  },
  {
    "id": "arXiv:2109.09428",
    "title": "Energy-stable discretization of two-phase flows in deformable porous  media with frictional contact at matrix-fracture interfaces",
    "abstract": "Energy-stable discretization of two-phase flows in deformable porous  media with frictional contact at matrix-fracture interfaces",
    "descriptor": "",
    "authors": [
      "Francesco Bonaldi",
      "J\u00e9r\u00f4me Droniou",
      "Roland Masson",
      "Antoine Pasteau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.09428"
  },
  {
    "id": "arXiv:2109.11673",
    "title": "Modeling calcium dynamics in neurons with endoplasmic reticulum:  existence, uniqueness and an implicit-explicit finite element scheme",
    "abstract": "Comments: 35 pages, 7 figures",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "Qingguang Guan",
      "Gillian Queisser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.11673"
  },
  {
    "id": "arXiv:2109.11774",
    "title": "Paving the Way for Distributed Artificial Intelligence over the Air",
    "abstract": "Paving the Way for Distributed Artificial Intelligence over the Air",
    "descriptor": "",
    "authors": [
      "Guoqing Ma",
      "Shuping Dang",
      "Chuanting Zhang",
      "Basem Shihada"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.11774"
  },
  {
    "id": "arXiv:2109.15166",
    "title": "PortaSpeech: Portable and High-Quality Generative Text-to-Speech",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yi Ren",
      "Jinglin Liu",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.15166"
  },
  {
    "id": "arXiv:2110.00530",
    "title": "A survey on datasets for fairness-aware machine learning",
    "abstract": "Comments: 56 pages, 36 figures, 20 tables",
    "descriptor": "\nComments: 56 pages, 36 figures, 20 tables\n",
    "authors": [
      "Tai Le Quy",
      "Arjun Roy",
      "Vasileios Iosifidis",
      "Wenbin Zhang",
      "Eirini Ntoutsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00530"
  },
  {
    "id": "arXiv:2110.02022",
    "title": "VESPo: Verified Evaluation of Secret Polynomials",
    "abstract": "VESPo: Verified Evaluation of Secret Polynomials",
    "descriptor": "",
    "authors": [
      "Jean-Guillaume Dumas",
      "Aude Maignan",
      "Cl\u00e9ment Pernet",
      "Daniel S. Roche"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.02022"
  },
  {
    "id": "arXiv:2110.02551",
    "title": "A Review of Computer Vision Technologies for Fish Tracking",
    "abstract": "Comments: We are working on the structure of this paper, optimizing the concepts and classification of detectors and trackers which are prone to ambiguity in Section 3",
    "descriptor": "\nComments: We are working on the structure of this paper, optimizing the concepts and classification of detectors and trackers which are prone to ambiguity in Section 3\n",
    "authors": [
      "Zhenbo Li",
      "Weiran Li",
      "Fei Li",
      "Meng Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02551"
  },
  {
    "id": "arXiv:2110.02870",
    "title": "Capturing Structural Locality in Non-parametric Language Models",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Frank F. Xu",
      "Junxian He",
      "Graham Neubig",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02870"
  },
  {
    "id": "arXiv:2110.03906",
    "title": "Nash Convergence of Mean-Based Learning Algorithms in First Price  Auctions",
    "abstract": "Comments: 38 pages, 5 figures",
    "descriptor": "\nComments: 38 pages, 5 figures\n",
    "authors": [
      "Xiaotie Deng",
      "Xinyan Hu",
      "Tao Lin",
      "Weiqiang Zheng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.03906"
  },
  {
    "id": "arXiv:2110.04638",
    "title": "Satisficing Paths and Independent Multi-Agent Reinforcement Learning in  Stochastic Games",
    "abstract": "Satisficing Paths and Independent Multi-Agent Reinforcement Learning in  Stochastic Games",
    "descriptor": "",
    "authors": [
      "Bora Yongacoglu",
      "G\u00fcrdal Arslan",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04638"
  },
  {
    "id": "arXiv:2110.06607",
    "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "abstract": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "descriptor": "",
    "authors": [
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06607"
  },
  {
    "id": "arXiv:2110.08009",
    "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without  Retraining",
    "abstract": "Comments: ICLR Accepted version, 28 pages, 23 figures",
    "descriptor": "\nComments: ICLR Accepted version, 28 pages, 23 figures\n",
    "authors": [
      "Ahmed Imtiaz Humayun",
      "Randall Balestriero",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08009"
  },
  {
    "id": "arXiv:2110.08743",
    "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
    "abstract": "Comments: To appear at ICLR 2022",
    "descriptor": "\nComments: To appear at ICLR 2022\n",
    "authors": [
      "Yuxian Meng",
      "Shi Zong",
      "Xiaoya Li",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08743"
  },
  {
    "id": "arXiv:2110.09722",
    "title": "Lipschitz Bandits with Batched Feedback",
    "abstract": "Lipschitz Bandits with Batched Feedback",
    "descriptor": "",
    "authors": [
      "Yasong Feng",
      "Zengfeng Huang",
      "Tianyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09722"
  },
  {
    "id": "arXiv:2110.11337",
    "title": "User Multi-Interest Modeling for Behavioral Cognition",
    "abstract": "Comments: during peer review",
    "descriptor": "\nComments: during peer review\n",
    "authors": [
      "Bei Yang",
      "Ke Liu",
      "Xiaoxiao Xu",
      "Renjun Xu",
      "Qinghui Sun",
      "Hong Liu",
      "Huan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11337"
  },
  {
    "id": "arXiv:2110.11511",
    "title": "Energy-conserving explicit and implicit time integration methods for the  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",
    "abstract": "Energy-conserving explicit and implicit time integration methods for the  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",
    "descriptor": "",
    "authors": [
      "Cecilia Pagliantini",
      "Gianmarco Manzini",
      "Oleksandr Koshkarov",
      "Gian Luca Delzanno",
      "Vadim Roytershteyn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11511"
  },
  {
    "id": "arXiv:2110.14300",
    "title": "Multi-Agent Reinforcement Learning for Active Voltage Control on Power  Distribution Networks",
    "abstract": "Comments: Published on NeurIPS 2021",
    "descriptor": "\nComments: Published on NeurIPS 2021\n",
    "authors": [
      "Jianhong Wang",
      "Wangkun Xu",
      "Yunjie Gu",
      "Wenbin Song",
      "Tim C. Green"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.14300"
  },
  {
    "id": "arXiv:2111.00775",
    "title": "PP-ShiTu: A Practical Lightweight Image Recognition System",
    "abstract": "Comments: 9 pages, 5 figures, 9 tables. arXiv admin note: text overlap with arXiv:2109.03144",
    "descriptor": "\nComments: 9 pages, 5 figures, 9 tables. arXiv admin note: text overlap with arXiv:2109.03144\n",
    "authors": [
      "Shengyu Wei",
      "Ruoyu Guo",
      "Cheng Cui",
      "Bin Lu",
      "Shuilong Dong",
      "Tingquan Gao",
      "Yuning Du",
      "Ying Zhou",
      "Xueying Lyu",
      "Qiwen Liu",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00775"
  },
  {
    "id": "arXiv:2111.01953",
    "title": "Optimal Parameter Inflation to Enhance the Availability of  Single-Frequency GBAS for Intelligent Air Transportation",
    "abstract": "Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Halim Lee",
      "Sam Pullen",
      "Jiyun Lee",
      "Byoungwoon Park",
      "Moonseok Yoon",
      "Jiwon Seo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.01953"
  },
  {
    "id": "arXiv:2111.02985",
    "title": "A QoE Model in Point Cloud Video Streaming",
    "abstract": "Comments: The thesis still needs to be revised. There are some problems in the structure of the thesis",
    "descriptor": "\nComments: The thesis still needs to be revised. There are some problems in the structure of the thesis\n",
    "authors": [
      "Jie Li",
      "Xiao Wang",
      "Zhi Liu",
      "Qiyue Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.02985"
  },
  {
    "id": "arXiv:2111.03654",
    "title": "Asymptotically Good Quantum and Locally Testable Classical LDPC Codes",
    "abstract": "Comments: Updated the introduction, corrected some misprints, clarified some proofs, added some new bibliography including arXiv:2005.01045 containing an independent construction of good LTCs",
    "descriptor": "\nComments: Updated the introduction, corrected some misprints, clarified some proofs, added some new bibliography including arXiv:2005.01045 containing an independent construction of good LTCs\n",
    "authors": [
      "Pavel Panteleev",
      "Gleb Kalachev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.03654"
  },
  {
    "id": "arXiv:2111.04718",
    "title": "Directional Message Passing on Molecular Graphs via Synthetic  Coordinates",
    "abstract": "Comments: Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Johannes Klicpera",
      "Chandan Yeshwanth",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.04718"
  },
  {
    "id": "arXiv:2111.05593",
    "title": "Numerical approximation of viscous contact problems applied to glacial  sliding",
    "abstract": "Numerical approximation of viscous contact problems applied to glacial  sliding",
    "descriptor": "",
    "authors": [
      "Gonzalo G. de Diego",
      "Patrick E. Farrell",
      "Ian J. Hewitt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.05593"
  },
  {
    "id": "arXiv:2111.05613",
    "title": "Conservative Hybrid Automata from Development Artifacts",
    "abstract": "Conservative Hybrid Automata from Development Artifacts",
    "descriptor": "",
    "authors": [
      "Niklas Metzger",
      "Sanny Schmitt",
      "Maximilian Schwenger"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.05613"
  },
  {
    "id": "arXiv:2111.05803",
    "title": "Gradients are Not All You Need",
    "abstract": "Gradients are Not All You Need",
    "descriptor": "",
    "authors": [
      "Luke Metz",
      "C. Daniel Freeman",
      "Samuel S. Schoenholz",
      "Tal Kachman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05803"
  },
  {
    "id": "arXiv:2111.10438",
    "title": "Multi-Sensory HMI for Human-Centric Industrial Digital Twins: A 6G  Vision of Future Industry",
    "abstract": "Comments: Submitted to EuCNC 2022",
    "descriptor": "\nComments: Submitted to EuCNC 2022\n",
    "authors": [
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10438"
  },
  {
    "id": "arXiv:2111.12399",
    "title": "Dictionary-based Low-Rank Approximations and the Mixed Sparse Coding  problem",
    "abstract": "Dictionary-based Low-Rank Approximations and the Mixed Sparse Coding  problem",
    "descriptor": "",
    "authors": [
      "Jeremy E. Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12399"
  },
  {
    "id": "arXiv:2111.14844",
    "title": "Evaluation of Machine Learning Techniques for Forecast Uncertainty  Quantification",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Maximiliano A. Sacco",
      "Juan J. Ruiz",
      "Manuel Pulido",
      "Pierre Tandeo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.14844"
  },
  {
    "id": "arXiv:2112.01218",
    "title": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence  Analyses",
    "abstract": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence  Analyses",
    "descriptor": "",
    "authors": [
      "Wei Ma",
      "Mengjie Zhao",
      "Ezekiel Soremekun",
      "Qiang Hu",
      "Jie Zhang",
      "Mike Papadakis",
      "Maxime Cordy",
      "Xiaofei Xie",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.01218"
  },
  {
    "id": "arXiv:2112.01529",
    "title": "BEVT: BERT Pretraining of Video Transformers",
    "abstract": "Comments: Updated SOTA results with ImageNet-1k pretrained PeCo tokenizer",
    "descriptor": "\nComments: Updated SOTA results with ImageNet-1k pretrained PeCo tokenizer\n",
    "authors": [
      "Rui Wang",
      "Dongdong Chen",
      "Zuxuan Wu",
      "Yinpeng Chen",
      "Xiyang Dai",
      "Mengchen Liu",
      "Yu-Gang Jiang",
      "Luowei Zhou",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01529"
  },
  {
    "id": "arXiv:2112.06435",
    "title": "Competitive Car Racing with Multiple Vehicles using a Parallelized  Optimization with Safety Guarantee using Control Barrier Functions",
    "abstract": "Comments: 8 pages (long version), a brief version submitted to 2022 International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 8 pages (long version), a brief version submitted to 2022 International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Suiyi He",
      "Jun Zeng",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.06435"
  },
  {
    "id": "arXiv:2112.07022",
    "title": "Learning Body-Aware 3D Shape Generative Models",
    "abstract": "Comments: 11 pages, 8 figures",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Bryce Blinn",
      "Alexander Ding",
      "R. Kenny Jones",
      "Manolis Savva",
      "Srinath Sridhar",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07022"
  },
  {
    "id": "arXiv:2112.09245",
    "title": "Automated Deep Learning: Neural Architecture Search Is Not the End",
    "abstract": "Comments: 65 pages, 9 tables, 4 figures",
    "descriptor": "\nComments: 65 pages, 9 tables, 4 figures\n",
    "authors": [
      "Xuanyi Dong",
      "David Jacob Kedziora",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09245"
  },
  {
    "id": "arXiv:2112.10321",
    "title": "English-to-Chinese Transliteration with Phonetic Back-transliteration",
    "abstract": "Comments: There are many new experiments need to be added, and current experiments need to be explained with more details. A new version will be released later",
    "descriptor": "\nComments: There are many new experiments need to be added, and current experiments need to be explained with more details. A new version will be released later\n",
    "authors": [
      "Shi Cheng",
      "Zhuofei Ding",
      "Songpeng Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.10321"
  },
  {
    "id": "arXiv:2112.11446",
    "title": "Scaling Language Models: Methods, Analysis & Insights from Training  Gopher",
    "abstract": "Comments: 120 pages",
    "descriptor": "\nComments: 120 pages\n",
    "authors": [
      "Jack W. Rae",
      "Sebastian Borgeaud",
      "Trevor Cai",
      "Katie Millican",
      "Jordan Hoffmann",
      "Francis Song",
      "John Aslanides",
      "Sarah Henderson",
      "Roman Ring",
      "Susannah Young",
      "Eliza Rutherford",
      "Tom Hennigan",
      "Jacob Menick",
      "Albin Cassirer",
      "Richard Powell",
      "George van den Driessche",
      "Lisa Anne Hendricks",
      "Maribeth Rauh",
      "Po-Sen Huang",
      "Amelia Glaese",
      "Johannes Welbl",
      "Sumanth Dathathri",
      "Saffron Huang",
      "Jonathan Uesato",
      "John Mellor",
      "Irina Higgins",
      "Antonia Creswell",
      "Nat McAleese",
      "Amy Wu",
      "Erich Elsen",
      "Siddhant Jayakumar",
      "Elena Buchatskaya",
      "David Budden",
      "Esme Sutherland",
      "Karen Simonyan",
      "Michela Paganini",
      "Laurent Sifre",
      "Lena Martens",
      "Xiang Lorraine Li",
      "Adhiguna Kuncoro",
      "Aida Nematzadeh",
      "Elena Gribovskaya",
      "Domenic Donato",
      "Angeliki Lazaridou",
      "Arthur Mensch",
      "Jean-Baptiste Lespiau",
      "Maria Tsimpoukelli",
      "Nikolai Grigorev",
      "Doug Fritz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.11446"
  },
  {
    "id": "arXiv:2112.11664",
    "title": "Polarize, Catalyze, Stabilize: Conscience and the evolution of  cooperation",
    "abstract": "Comments: 22 pages, 7 figures. Edits: clarifications in introduction and discussion, headlines for captions, keywords, cleaner formatting, typos",
    "descriptor": "\nComments: 22 pages, 7 figures. Edits: clarifications in introduction and discussion, headlines for captions, keywords, cleaner formatting, typos\n",
    "authors": [
      "Victor Vikram Odouard",
      "Diana Smirnova",
      "Shimon Edelman"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.11664"
  },
  {
    "id": "arXiv:2112.12268",
    "title": "An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG",
    "abstract": "An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG",
    "descriptor": "",
    "authors": [
      "Carla Mascia",
      "Enrico Piccione",
      "Massimiliano Sala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2112.12268"
  },
  {
    "id": "arXiv:2201.01391",
    "title": "Self-Supervised Approach to Addressing Zero-Shot Learning Problem",
    "abstract": "Self-Supervised Approach to Addressing Zero-Shot Learning Problem",
    "descriptor": "",
    "authors": [
      "Ademola Okerinde",
      "Sam Hoggatt",
      "Divya Vani Lakkireddy",
      "Nolan Brubaker",
      "William Hsu",
      "Lior Shamir",
      "Brian Spiesman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01391"
  },
  {
    "id": "arXiv:2201.02627",
    "title": "Learning with Less Labels in Digital Pathology via Scribble Supervision  from Natural Images",
    "abstract": "Comments: To appear in IEEE International Symposium on Biomedical Imaging (ISBI) 2022",
    "descriptor": "\nComments: To appear in IEEE International Symposium on Biomedical Imaging (ISBI) 2022\n",
    "authors": [
      "Eu Wern Teh",
      "Graham W. Taylor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02627"
  },
  {
    "id": "arXiv:2201.04122",
    "title": "In Defense of the Unitary Scalarization for Deep Multi-Task Learning",
    "abstract": "In Defense of the Unitary Scalarization for Deep Multi-Task Learning",
    "descriptor": "",
    "authors": [
      "Vitaly Kurin",
      "Alessandro De Palma",
      "Ilya Kostrikov",
      "Shimon Whiteson",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04122"
  },
  {
    "id": "arXiv:2201.04469",
    "title": "Optimal Fixed-Budget Best Arm Identification using the Augmented Inverse  Probability Weighting Estimator in Two-Armed Gaussian Bandits with Unknown  Variances",
    "abstract": "Optimal Fixed-Budget Best Arm Identification using the Augmented Inverse  Probability Weighting Estimator in Two-Armed Gaussian Bandits with Unknown  Variances",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Kaito Ariu",
      "Masaaki Imaizumi",
      "Masatoshi Uehara",
      "Masahiro Nomura",
      "Chao Qin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.04469"
  },
  {
    "id": "arXiv:2201.04876",
    "title": "Towards a Reference Software Architecture for Human-AI Teaming in Smart  Manufacturing",
    "abstract": "Comments: Conference: ICSE-NIER 2022 - The 44th International Conference on Software Engineering, 5 pages, 1 figure",
    "descriptor": "\nComments: Conference: ICSE-NIER 2022 - The 44th International Conference on Software Engineering, 5 pages, 1 figure\n",
    "authors": [
      "Philipp Haindl",
      "Georg Buchgeher",
      "Maqbool Khan",
      "Bernhard Moser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.04876"
  },
  {
    "id": "arXiv:2201.05469",
    "title": "PageRank Algorithm using Eigenvector Centrality -- New Approach",
    "abstract": "PageRank Algorithm using Eigenvector Centrality -- New Approach",
    "descriptor": "",
    "authors": [
      "Suvarna Saumya Chandrashekhar",
      "Mashrin Srivastava",
      "B. Jaganathan",
      "Pankaj Shukla"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.05469"
  },
  {
    "id": "arXiv:2201.05624",
    "title": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "abstract": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "descriptor": "",
    "authors": [
      "Salvatore Cuomo",
      "Vincenzo Schiano di Cola",
      "Fabio Giampaolo",
      "Gianluigi Rozza",
      "Maizar Raissi",
      "Francesco Piccialli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2201.05624"
  },
  {
    "id": "arXiv:2201.05675",
    "title": "Transformers in Action: Weakly Supervised Action Segmentation",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "John Ridley",
      "Huseyin Coskun",
      "David Joseph Tan",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05675"
  },
  {
    "id": "arXiv:2201.05809",
    "title": "Weighting and Pruning based Ensemble Deep Random Vector Functional Link  Network for Tabular Data Classification",
    "abstract": "Comments: 8 tables, 8 figures, 31 pages",
    "descriptor": "\nComments: 8 tables, 8 figures, 31 pages\n",
    "authors": [
      "Qiushi Shi",
      "Ponnuthurai Nagaratnam Suganthan",
      "Rakesh Katuwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.05809"
  },
  {
    "id": "arXiv:2201.05810",
    "title": "Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for  Flexible Video Compressive Sensing",
    "abstract": "Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for  Flexible Video Compressive Sensing",
    "descriptor": "",
    "authors": [
      "Siming Zheng",
      "Xiaoyu Yang",
      "Xin Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05810"
  },
  {
    "id": "arXiv:2201.05842",
    "title": "UDC: Unified DNAS for Compressible TinyML Models",
    "abstract": "UDC: Unified DNAS for Compressible TinyML Models",
    "descriptor": "",
    "authors": [
      "Igor Fedorov",
      "Ramon Matas",
      "Hokchhay Tann",
      "Chuteng Zhou",
      "Matthew Mattina",
      "Paul Whatmough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05842"
  },
  {
    "id": "arXiv:2201.06159",
    "title": "YOLO -- You only look 10647 times",
    "abstract": "YOLO -- You only look 10647 times",
    "descriptor": "",
    "authors": [
      "Christian Limberg",
      "Andrew Melnik",
      "Augustin Harter",
      "Helge Ritter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06159"
  },
  {
    "id": "arXiv:2201.07341",
    "title": "Learning grammar with a divide-and-concur neural network",
    "abstract": "Learning grammar with a divide-and-concur neural network",
    "descriptor": "",
    "authors": [
      "Sean Deyo",
      "Veit Elser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.07341"
  },
  {
    "id": "arXiv:2201.07351",
    "title": "A Taxonomy of HTML5 Canvas Bugs",
    "abstract": "Comments: 11 pages, 4 figures; alignment of listings fixed",
    "descriptor": "\nComments: 11 pages, 4 figures; alignment of listings fixed\n",
    "authors": [
      "Finlay Macklon",
      "Markos Viggiato",
      "Cor-Paul Bezemer",
      "Natalia Romanova",
      "Chris Buzon",
      "Dale Paas"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.07351"
  },
  {
    "id": "arXiv:2201.07989",
    "title": "Self-supervised Video Representation Learning with Cascade Positive  Retrieval",
    "abstract": "Self-supervised Video Representation Learning with Cascade Positive  Retrieval",
    "descriptor": "",
    "authors": [
      "Cheng-En Wu",
      "Farley Lai",
      "Yu Hen Hu",
      "Asim Kadav"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.07989"
  },
  {
    "id": "arXiv:2201.08022",
    "title": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks",
    "abstract": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks",
    "descriptor": "",
    "authors": [
      "Su Zheng",
      "Zhen Li",
      "Yao Lu",
      "Jingbo Gao",
      "Jide Zhang",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08022"
  },
  {
    "id": "arXiv:2201.08050",
    "title": "TerViT: An Efficient Ternary Vision Transformer",
    "abstract": "TerViT: An Efficient Ternary Vision Transformer",
    "descriptor": "",
    "authors": [
      "Sheng Xu",
      "Yanjing Li",
      "Teli Ma",
      "Bohan Zeng",
      "Baochang Zhang",
      "Peng Gao",
      "Jinhu Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08050"
  },
  {
    "id": "arXiv:2201.08054",
    "title": "VISA: An Ambiguous Subtitles Dataset for Visual Scene-Aware Machine  Translation",
    "abstract": "Comments: Submitted to LREC2022",
    "descriptor": "\nComments: Submitted to LREC2022\n",
    "authors": [
      "Yihang Li",
      "Shuichiro Shimizu",
      "Weiqi Gu",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08054"
  },
  {
    "id": "arXiv:2201.08099",
    "title": "JEDI: These aren't the JSON documents you're looking for... (Extended  Version*)",
    "abstract": "Comments: This is an extended version of an upcoming publication at ACM SIGMOD 2022. Please cite the original SIGMOD version",
    "descriptor": "\nComments: This is an extended version of an upcoming publication at ACM SIGMOD 2022. Please cite the original SIGMOD version\n",
    "authors": [
      "Thomas H\u00fctter",
      "Nikolaus Augsten",
      "Christoph M. Kirsch",
      "Michael J. Carey",
      "Chen Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.08099"
  },
  {
    "id": "arXiv:2201.08102",
    "title": "Safe Deep RL in 3D Environments using Human Feedback",
    "abstract": "Safe Deep RL in 3D Environments using Human Feedback",
    "descriptor": "",
    "authors": [
      "Matthew Rahtz",
      "Vikrant Varma",
      "Ramana Kumar",
      "Zachary Kenton",
      "Shane Legg",
      "Jan Leike"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08102"
  },
  {
    "id": "arXiv:2201.08281",
    "title": "Symplectic Momentum Neural Networks -- Using Discrete Variational  Mechanics as a prior in Deep Learning",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Saul Santos",
      "Monica Ekal",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08281"
  },
  {
    "id": "arXiv:2201.08295",
    "title": "DIVA-DAF: A Deep Learning Framework for Historical Document Image  Analysis",
    "abstract": "DIVA-DAF: A Deep Learning Framework for Historical Document Image  Analysis",
    "descriptor": "",
    "authors": [
      "Lars V\u00f6gtlin",
      "Paul Maergner",
      "Rolf Ingold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08295"
  },
  {
    "id": "arXiv:2201.08321",
    "title": "TOAST: Trajectory Optimization and Simultaneous Tracking using Shared  Neural Network Dynamics",
    "abstract": "Comments: Our video can be found at this https URL",
    "descriptor": "\nComments: Our video can be found at this https URL\n",
    "authors": [
      "Taekyung Kim",
      "Hojin Lee",
      "Seongil Hong",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08321"
  },
  {
    "id": "arXiv:2201.08361",
    "title": "Stitch it in Time: GAN-Based Facial Editing of Real Videos",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Rotem Tzaban",
      "Ron Mokady",
      "Rinon Gal",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08361"
  }
]
[
  {
    "id": "arXiv:2201.11124",
    "title": "Using Hybrid Scheduling Algorithms for Solving Blockchain Allocation on  Cloud",
    "abstract": "Companies are rushing to deliver their services and solutions through the\ncloud. The scheduling process is very critical in reducing delays. Scheduling\nalso has a role in accessing resources without excessive waiting time. All this\nin context of modern advances in infrastructure and the emergence of\nBlockchain-as-a-service. What if integration is done between a hybrid\nscheduling algorithm and blockchain technology via the cloud. This integration\naims to enhance and provide the service uninterruptedly. This method is\ndistinguished, compared to other scheduling algorithms such as\nshortest-job-first and priority scheduling, that it does not suffer from\nstarvation and it has a balanced load on resources. Based on analytical\nperformance, the proposed hybrid scheduling has the markable result.",
    "descriptor": "",
    "authors": [
      "M A El-Dosuky",
      "Gamal H Eladl"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11124"
  },
  {
    "id": "arXiv:2201.11125",
    "title": "SQRQuerier: A Visual Querying Framework for Cross-national Survey Data  Recycling",
    "abstract": "Public opinion surveys constitute a powerful tool to study peoples' attitudes\nand behaviors in comparative perspectives. However, even worldwide surveys\nprovide only partial geographic and time coverage, which hinders comprehensive\nknowledge production. To broaden the scope of comparison, social scientists\nturn to ex-post harmonization of variables from datasets that cover similar\ntopics but in different populations and/or years. The resulting new datasets\ncan be analyzed as a single source, which can be flexibly accessed through many\ndata portals. However, such portals offer little guidance to explore the data\nin-depth or query data with user-customized needs. As a result, it is still\nchallenging for social scientists to efficiently identify related data for\ntheir studies and evaluate their theoretical models based on the sliced data.\nTo overcome them, in the Survey Data Recycling (SDR) international cooperation\nresearch project, we propose SDRQuerier and apply it to the harmonized SDR\ndatabase, which features over two million respondents interviewed in a total of\n1,721 national surveys that are part of 22 well-known international projects.\nWe design the SDRQuerier to solve three practical challenges that social\nscientists routinely face. First, a BERT-based model provides customized data\nqueries through research questions or keywords. Second, we propose a new visual\ndesign to showcase the availability of the harmonized data at different levels,\nthus helping users decide if empirical data exist to address a given research\nquestion. Lastly, SDRQuerier discloses the underlying relational patterns among\nsubstantive and methodological variables in the database, to help social\nscientists rigorously evaluate or even improve their regression models. Through\ncase studies with multiple social scientists in solving their daily challenges,\nwe demonstrated the novelty, effectiveness of SDRQuerier.",
    "descriptor": "",
    "authors": [
      "Yamei Tu",
      "Olga Li",
      "Junpeng Wang",
      "Han-Wei Shen",
      "Przemek Powalko",
      "Irina Tomescu-Dubrow",
      "Kazimierz M. Slomczynski",
      "Spyros Blanas",
      "J. Craig Jenkins"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11125"
  },
  {
    "id": "arXiv:2201.11137",
    "title": "Born-Infeld (BI) for AI: Energy-Conserving Descent (ECD) for  Optimization",
    "abstract": "We introduce a novel framework for optimization based on energy-conserving\nHamiltonian dynamics in a strongly mixing (chaotic) regime and establish its\nkey properties analytically and numerically. The prototype is a discretization\nof Born-Infeld dynamics, with a squared relativistic speed limit depending on\nthe objective function. This class of frictionless, energy-conserving\noptimizers proceeds unobstructed until slowing naturally near the minimal loss,\nwhich dominates the phase space volume of the system. Building from studies of\nchaotic systems such as dynamical billiards, we formulate a specific algorithm\nwith good performance on machine learning and PDE-solving tasks, including\ngeneralization. It cannot stop at a high local minimum and cannot overshoot the\nglobal minimum, yielding an advantage in non-convex loss functions, and\nproceeds faster than GD+momentum in shallow valleys.",
    "descriptor": "\nComments: 9 pages + Appendix, 8 figures. Code available online\n",
    "authors": [
      "G. Bruno De Luca",
      "Eva Silverstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "High Energy Physics - Theory (hep-th)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11137"
  },
  {
    "id": "arXiv:2201.11146",
    "title": "Machine-learning of nonlocal kernels for anomalous subsurface transport  from breakthrough curves",
    "abstract": "Anomalous behavior is ubiquitous in subsurface solute transport due to the\npresence of high degrees of heterogeneity at different scales in the media.\nAlthough fractional models have been extensively used to describe the anomalous\ntransport in various subsurface applications, their application is hindered by\ncomputational challenges. Simpler nonlocal models characterized by integrable\nkernels and finite interaction length represent a computationally feasible\nalternative to fractional models; yet, the informed choice of their kernel\nfunctions still remains an open problem. We propose a general data-driven\nframework for the discovery of optimal kernels on the basis of very small and\nsparse data sets in the context of anomalous subsurface transport. Using\nspatially sparse breakthrough curves recovered from fine-scale particle-density\nsimulations, we learn the best coarse-scale nonlocal model using a nonlocal\noperator regression technique. Predictions of the breakthrough curves obtained\nusing the optimal nonlocal model show good agreement with fine-scale simulation\nresults even at locations and time intervals different from the ones used to\ntrain the kernel, confirming the excellent generalization properties of the\nproposed algorithm. A comparison with trained classical models and with\nblack-box deep neural networks confirms the superiority of the predictive\ncapability of the proposed model.",
    "descriptor": "",
    "authors": [
      "Xiao Xu",
      "Marta D'Elia",
      "Christian Glusa",
      "John T. Foster"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11146"
  },
  {
    "id": "arXiv:2201.11148",
    "title": "Autonomous Cyber Defense Introduces Risk: Can We Manage the Risk?",
    "abstract": "From denial-of-service attacks to spreading of ransomware or other malware\nacross an organization's network, it is possible that manually operated\ndefenses are not able to respond in real time at the scale required, and when a\nbreach is detected and remediated the damage is already made. Autonomous cyber\ndefenses therefore become essential to mitigate the risk of successful attacks\nand their damage, especially when the response time, effort and accuracy\nrequired in those defenses is impractical or impossible through defenses\noperated exclusively by humans. Autonomous agents have the potential to use ML\nwith large amounts of data about known cyberattacks as input, in order to learn\npatterns and predict characteristics of future attacks. Moreover, learning from\npast and present attacks enable defenses to adapt to new threats that share\ncharacteristics with previous attacks. On the other hand, autonomous cyber\ndefenses introduce risks of unintended harm. Actions arising from autonomous\ndefense agents may have harmful consequences of functional, safety, security,\nethical, or moral nature. Here we focus on machine learning training,\nalgorithmic feedback, and algorithmic constraints, with the aim of motivating a\ndiscussion on achieving trust in autonomous cyber defenses.",
    "descriptor": "",
    "authors": [
      "Alexandre K. Ligo",
      "Alexander Kott",
      "Igor Linkov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11148"
  },
  {
    "id": "arXiv:2201.11149",
    "title": "DoF of a Cooperative X-Channel with an Application to Distributed  Computing",
    "abstract": "We consider a cooperative X-channel with $\\sf K$ transmitters (TXs) and $\\sf\nK$ receivers (Rxs) where Txs and Rxs are gathered into groups of size $\\sf r$\nrespectively. Txs belonging to the same group cooperate to jointly transmit a\nmessage to each of the $\\sf K- \\sf r$ Rxs in all other groups, and each Rx\nindividually decodes all its intended messages. By introducing a new\ninterference alignment (IA) scheme, we prove that when $\\sf K/\\sf r$ is an\ninteger the sum Degrees of Freedom (SDoF) of this channel is lower bounded by\n$2\\sf r$ if $\\sf K/\\sf r \\in \\{2,3\\}$ and by $\\frac{\\sf K(\\sf K-\\sf r)-\\sf\nr}{2\\sf K-3\\sf r}$ if $\\sf K/\\sf r \\geq 4$. We also prove that the SDoF is\nupper bounded by $\\frac{\\sf K(\\sf K-\\sf r)}{2\\sf K-3\\sf r}$. The proposed IA\nscheme finds application in a wireless distributed MapReduce framework, where\nit improves the normalized data delivery time (NDT) compared to the state of\nthe art.",
    "descriptor": "",
    "authors": [
      "Yue Bi",
      "Mich\u00e8le Wigger",
      "Philippe Ciblat",
      "Yue Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11149"
  },
  {
    "id": "arXiv:2201.11150",
    "title": "Adversarial Torn-paper Codes",
    "abstract": "This paper studies the adversarial torn-paper channel. This problem is\nmotivated by applications in DNA data storage where the DNA strands that carry\nthe information may break into smaller pieces that are received out of order.\nOur model extends the previously researched probabilistic setting to the\nworst-case. We develop code constructions for any parameters of the channel for\nwhich non-vanishing asymptotic rate is possible and show our constructions\nachieve optimal asymptotic rate while allowing for efficient encoding and\ndecoding. Finally, we extend our results to related settings included\nmulti-strand storage, presence of substitution errors, or incomplete coverage.",
    "descriptor": "\nComments: Shortened version to be submitted to ISIT'22\n",
    "authors": [
      "Daniella Bar-Lev",
      "Sagi Marcovich",
      "Eitan Yaakobi",
      "Yonatan Yehezkeally"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11150"
  },
  {
    "id": "arXiv:2201.11152",
    "title": "Cyber Resilience: by Design or by Intervention?",
    "abstract": "The term \"cyber resilience by design\" is growing in popularity. Here, by\ncyber resilience we refer to the ability of the system to resist, minimize and\nmitigate a degradation caused by a successful cyber-attack on a system or\nnetwork of computing and communicating devices. Some use the term \"by design\"\nwhen arguing that systems must be designed and implemented in a provable\nmission assurance fashion, with the system's intrinsic properties ensuring that\na cyber-adversary is unable to cause a meaningful degradation. Others recommend\nthat a system should include a built-in autonomous intelligent agent\nresponsible for thinking and acting towards continuous observation, detection,\nminimization and remediation of a cyber degradation. In all cases, the\nqualifier \"by design\" indicates that the source of resilience is somehow\ninherent in the structure and operation of the system. But what, then, is the\nother resilience, not by design? Clearly, there has to be another type of\nresilience, otherwise what's the purpose of the qualifier \"by design\"? Indeed,\nwhile mentioned less frequently, there exists an alternative form of resilience\ncalled \"resilience by intervention.\" In this article we explore differences and\nmutual reliance of resilience by design and resilience by intervention.",
    "descriptor": "",
    "authors": [
      "Alexander Kott",
      "Maureen S. Golan",
      "Benjamin D. Trump",
      "Igor Linkov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11152"
  },
  {
    "id": "arXiv:2201.11153",
    "title": "Addressing Issues of Cross-Linguality in Open-Retrieval Question  Answering Systems For Emergent Domains",
    "abstract": "Open-retrieval question answering systems are generally trained and tested on\nlarge datasets in well-established domains. However, low-resource settings such\nas new and emerging domains would especially benefit from reliable question\nanswering systems. Furthermore, multilingual and cross-lingual resources in\nemergent domains are scarce, leading to few or no such systems. In this paper,\nwe demonstrate a cross-lingual open-retrieval question answering system for the\nemergent domain of COVID-19. Our system adopts a corpus of scientific articles\nto ensure that retrieved documents are reliable. To address the scarcity of\ncross-lingual training data in emergent domains, we present a method utilizing\nautomatic translation, alignment, and filtering to produce English-to-all\ndatasets. We show that a deep semantic retriever greatly benefits from training\non our English-to-all data and significantly outperforms a BM25 baseline in the\ncross-lingual setting. We illustrate the capabilities of our system with\nexamples and release all code necessary to train and deploy such a system.",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Alon Albalak",
      "Sharon Levy",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11153"
  },
  {
    "id": "arXiv:2201.11154",
    "title": "Sketching for low-rank nonnegative matrix approximation: a numerical  study",
    "abstract": "We propose new approximate alternating projection methods, based on\nrandomized sketching, for the low-rank nonnegative matrix approximation\nproblem: find a low-rank approximation of a nonnegative matrix that is\nnonnegative, but whose factors can be arbitrary. We calculate the computational\ncomplexities of the proposed methods and evaluate their performance in\nnumerical experiments. The comparison with the known deterministic alternating\nprojection methods shows that the randomized approaches are faster and exhibit\nsimilar convergence properties.",
    "descriptor": "\nComments: 21 pages (18+3), 8 figures, 4 tables\n",
    "authors": [
      "Sergey A. Matveev",
      "Stanislav Budzinskiy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11154"
  },
  {
    "id": "arXiv:2201.11155",
    "title": "Explainable Patterns for Distinction and Prediction of Moral Judgement  on Reddit",
    "abstract": "The forum r/AmITheAsshole in Reddit hosts discussion on moral issues based on\nconcrete narratives presented by users. Existing analysis of the forum focuses\non its comments, and does not make the underlying data publicly available. In\nthis paper we build a new dataset of comments and also investigate the\nclassification of the posts in the forum. Further, we identify textual patterns\nassociated with the provocation of moral judgement by posts, with the\nexpression of moral stance in comments, and with the decisions of trained\nclassifiers of posts and comments.",
    "descriptor": "\nComments: 1st Workshop on Human and Machine Decisions (WHMD 2021) at NeurIPS 2021\n",
    "authors": [
      "Ion Stagkos Efstathiadis",
      "Guilherme Paulino-Passos",
      "Francesca Toni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11155"
  },
  {
    "id": "arXiv:2201.11165",
    "title": "First-Order Context-Specific Likelihood Weighting in Hybrid  Probabilistic Logic Programs",
    "abstract": "Statistical relational AI and probabilistic logic programming have so far\nmostly focused on discrete probabilistic models. The reasons for this is that\none needs to provide constructs to succinctly model the independencies in such\nmodels, and also provide efficient inference.\nThree types of independencies are important to represent and exploit for\nscalable inference in hybrid models: conditional independencies elegantly\nmodeled in Bayesian networks, context-specific independencies naturally\nrepresented by logical rules, and independencies amongst attributes of related\nobjects in relational models succinctly expressed by combining rules.\nThis paper introduces a hybrid probabilistic logic programming language, DC#,\nwhich integrates distributional clauses' syntax and semantics principles of\nBayesian logic programs. It represents the three types of independencies\nqualitatively. More importantly, we also introduce the scalable inference\nalgorithm FO-CS-LW for DC#. FO-CS-LW is a first-order extension of the\ncontext-specific likelihood weighting algorithm (CS-LW), a novel sampling\nmethod that exploits conditional independencies and context-specific\nindependencies in ground models. The FO-CS-LW algorithm upgrades CS-LW with\nunification and combining rules to the first-order case.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.09791\n",
    "authors": [
      "Nitesh Kumar",
      "Ondrej Kuzelka",
      "Luc De Raedt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11165"
  },
  {
    "id": "arXiv:2201.11166",
    "title": "Analyzing Ta-Shma's Code via the Expander Mixing Lemma",
    "abstract": "Random walks in expander graphs and their various derandomizations (e.g.,\nreplacement/zigzag product) are invaluable tools from pseudorandomness.\nRecently, Ta-Shma used s-wide replacement walks in his breakthrough\nconstruction of a binary linear code almost matching the Gilbert-Varshamov\nbound (STOC 2017). Ta-Shma's original analysis was entirely linear algebraic,\nand subsequent developments have inherited this viewpoint. In this work, we\nrederive Ta-Shma's analysis from a combinatorial point of view using repeated\napplication of the expander mixing lemma. We hope that this alternate\nperspective will yield a better understanding of Ta-Shma's construction. As an\nadditional application of our techniques, we give an alternate proof of the\nexpander hitting set lemma.",
    "descriptor": "",
    "authors": [
      "Silas Richelson",
      "Sourya Roy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11166"
  },
  {
    "id": "arXiv:2201.11167",
    "title": "Artificial Emotional Intelligence in Socially Assistive Robots for Older  Adults: A Pilot Study",
    "abstract": "This paper presents our recent research on integrating artificial emotional\nintelligence in a social robot (Ryan) and studies the robot's effectiveness in\nengaging older adults. Ryan is a socially assistive robot designed to provide\ncompanionship for older adults with depression and dementia through\nconversation. We used two versions of Ryan for our study, empathic and\nnon-empathic. The empathic Ryan utilizes a multimodal emotion recognition\nalgorithm and a multimodal emotion expression system. Using different input\nmodalities for emotion, i.e. facial expression and speech sentiment, the\nempathic Ryan detects users' emotional state and utilizes an affective dialogue\nmanager to generate a response. On the other hand, the non-empathic Ryan lacks\nfacial expression and uses scripted dialogues that do not factor in the users'\nemotional state. We studied these two versions of Ryan with 10 older adults\nliving in a senior care facility. The statistically significant improvement in\nthe users' reported face-scale mood measurement indicates an overall positive\neffect from the interaction with both the empathic and non-empathic versions of\nRyan. However, the number of spoken words measurement and the exit survey\nanalysis suggest that the users perceive the empathic Ryan as more engaging and\nlikable.",
    "descriptor": "\nComments: To be published in IEEE Transactions on Affective Computing\n",
    "authors": [
      "Hojjat Abdollahi",
      "Mohammad H. Mahoor",
      "Rohola Zandie",
      "Jarid Siewierski",
      "Sara H. Qualls"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11167"
  },
  {
    "id": "arXiv:2201.11172",
    "title": "Tackling data scarcity in speech translation using zero-shot  multilingual machine translation techniques",
    "abstract": "Recently, end-to-end speech translation (ST) has gained significant attention\nas it avoids error propagation. However, the approach suffers from data\nscarcity. It heavily depends on direct ST data and is less efficient in making\nuse of speech transcription and text translation data, which is often more\neasily available. In the related field of multilingual text translation,\nseveral techniques have been proposed for zero-shot translation. A main idea is\nto increase the similarity of semantically similar sentences in different\nlanguages. We investigate whether these ideas can be applied to speech\ntranslation, by building ST models trained on speech transcription and text\ntranslation data. We investigate the effects of data augmentation and auxiliary\nloss function. The techniques were successfully applied to few-shot ST using\nlimited ST data, with improvements of up to +12.9 BLEU points compared to\ndirect end-to-end ST and +3.1 BLEU points compared to ST models fine-tuned from\nASR model.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted to IEEE ICASSP 2022. arXiv admin note: text overlap with arXiv:2107.06010\n",
    "authors": [
      "Tu Anh Dinh",
      "Danni Liu",
      "Jan Niehues"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11172"
  },
  {
    "id": "arXiv:2201.11176",
    "title": "DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence",
    "abstract": "Recently has there been a growing interest in the creation of text generation\nsystems from a discourse coherence perspective, e.g., modeling the\ninterdependence between sentences. Still, recent BERT-based evaluation metrics\ncannot recognize coherence and fail to punish incoherent elements in system\noutputs. In this work, we introduce DiscoScore, a discourse metric with\nmultiple variants, which uses BERT to model discourse coherence from different\nperspectives, driven by Centering theory. Our experiments encompass 16\nnon-discourse and discourse metrics, including DiscoScore and popular coherence\nmodels, evaluated on summarization and document-level machine translation (MT).\nWe find that (i) the majority of BERT-based metrics correlate much worse with\nhuman rated coherence than early discourse metrics, invented a decade ago; (ii)\nthe recent state-of-the-art BARTScore is weak when operated at system level --\nwhich is particularly problematic as systems are typically compared in this\nmanner. DiscoScore, in contrast, achieves strong system-level correlation with\nhuman ratings, not only in coherence but also in factual consistency and other\naspects, and surpasses BARTScore by over 10 correlation points on average.\nFurther, aiming to understand DiscoScore, we provide justifications to the\nimportance of discourse coherence for evaluation metrics, and explain the\nsuperiority of one variant over another. Our code is available at\n\\url{https://github.com/AIPHES/DiscoScore}.",
    "descriptor": "",
    "authors": [
      "Wei Zhao",
      "Michael Strube",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11176"
  },
  {
    "id": "arXiv:2201.11178",
    "title": "Rapid solution for searching similar audio items",
    "abstract": "A naive approach for finding similar audio items would be to compare each\nentry from the feature vector of the test example with each feature vector of\nthe candidates in a k-nearest neighbors fashion. There are already two problems\nwith this approach: audio signals are represented by high dimensional vectors\nand the number of candidates can be very large - think thousands. The search\nprocess would have a high complexity. Our paper will treat this problem through\nhashing methodologies more specifically the Locality Sensitive Hashing. This\nproject will be in the spirit of classification and clustering problems. The\ncomputer sound production principles will be used to determine which features\nthat describe an audio signal are the most useful. That will down-sample the\nsize of the feature vectors and speed up the process subsequently.",
    "descriptor": "\nComments: 4 pages, 5 figures, 2 pseudo-code blocks\n",
    "authors": [
      "Kastriot Kadriu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11178"
  },
  {
    "id": "arXiv:2201.11181",
    "title": "Searching, Learning, and Subtopic Ordering: A Simulation-based Analysis",
    "abstract": "Complex search tasks - such as those from the Search as Learning (SAL) domain\n- often result in users developing an information need composed of several\naspects. However, current models of searcher behaviour assume that individuals\nhave an atomic need, regardless of the task. While these models generally work\nwell for simpler informational needs, we argue that searcher models need to be\ndeveloped further to allow for the decomposition of a complex search task into\nmultiple aspects. As no searcher model yet exists that considers both aspects\nand the SAL domain, we propose, by augmenting the Complex Searcher Model (CSM),\nthe Subtopic Aware Complex Searcher Model (SACSM) - modelling aspects as\nsubtopics to the user's need. We then instantiate several agents (i.e.,\nsimulated users), with different subtopic selection strategies, which can be\nconsidered as different prototypical learning strategies (e.g., should I deeply\nexamine one subtopic at a time, or shallowly cover several subtopics?).\nFinally, we report on the first large-scale simulated analysis of user\nbehaviours in the SAL domain. Results demonstrate that the SACSM, under certain\nconditions, simulates user behaviours accurately.",
    "descriptor": "\nComments: 15 pages, 5 figures. Part of the proceedings of BCS-IRSG ECIR 2022 in Stavanger, Norway\n",
    "authors": [
      "Arthur C\u00e2mara",
      "David Maxwell",
      "Claudia Hauff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11181"
  },
  {
    "id": "arXiv:2201.11182",
    "title": "Hyperparameter Tuning for Deep Reinforcement Learning Applications",
    "abstract": "Reinforcement learning (RL) applications, where an agent can simply learn\noptimal behaviors by interacting with the environment, are quickly gaining\ntremendous success in a wide variety of applications from controlling simple\npendulums to complex data centers. However, setting the right hyperparameters\ncan have a huge impact on the deployed solution performance and reliability in\nthe inference models, produced via RL, used for decision-making. Hyperparameter\nsearch itself is a laborious process that requires many iterations and\ncomputationally expensive to find the best settings that produce the best\nneural network architectures. In comparison to other neural network\narchitectures, deep RL has not witnessed much hyperparameter tuning, due to its\nalgorithm complexity and simulation platforms needed. In this paper, we propose\na distributed variable-length genetic algorithm framework to systematically\ntune hyperparameters for various RL applications, improving training time and\nrobustness of the architecture, via evolution. We demonstrate the scalability\nof our approach on many RL problems (from simple gyms to complex applications)\nand compared with Bayesian approach. Our results show that with more\ngenerations, optimal solutions that require fewer training episodes and are\ncomputationally cheap while being more robust for deployment. Our results are\nimperative to advance deep reinforcement learning controllers for real-world\nproblems.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Mariam Kiran",
      "Melis Ozyildirim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.11182"
  },
  {
    "id": "arXiv:2201.11183",
    "title": "A dual approach for federated learning",
    "abstract": "We study the federated optimization problem from a dual perspective and\npropose a new algorithm termed federated dual coordinate descent (FedDCD),\nwhich is based on a type of coordinate descent method developed by Necora et\nal. [Journal of Optimization Theory and Applications, 2017]. Additionally, we\nenhance the FedDCD method with inexact gradient oracles and Nesterov's\nacceleration. We demonstrate theoretically that our proposed approach achieves\nbetter convergence rates than the state-of-the-art primal federated\noptimization algorithms under mild conditions. Numerical experiments on\nreal-world datasets support our analysis.",
    "descriptor": "",
    "authors": [
      "Zhenan Fan",
      "Huang Fang",
      "Michael P. Friedlander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11183"
  },
  {
    "id": "arXiv:2201.11187",
    "title": "DIREG3D: DIrectly REGress 3D Hands from Multiple Cameras",
    "abstract": "In this paper, we present DIREG3D, a holistic framework for 3D Hand Tracking.\nThe proposed framework is capable of utilizing camera intrinsic parameters, 3D\ngeometry, intermediate 2D cues, and visual information to regress parameters\nfor accurately representing a Hand Mesh model. Our experiments show that\ninformation like the size of the 2D hand, its distance from the optical center,\nand radial distortion is useful for deriving highly reliable 3D poses in camera\nspace from just monocular information. Furthermore, we extend these results to\na multi-view camera setup by fusing features from different viewpoints.",
    "descriptor": "",
    "authors": [
      "Ashar Ali",
      "Upal Mahbub",
      "Gokce Dane",
      "Gerhard Reitmayr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.11187"
  },
  {
    "id": "arXiv:2201.11192",
    "title": "ReforesTree: A Dataset for Estimating Tropical Forest Carbon Stock with  Deep Learning and Aerial Imagery",
    "abstract": "Forest biomass is a key influence for future climate, and the world urgently\nneeds highly scalable financing schemes, such as carbon offsetting\ncertifications, to protect and restore forests. Current manual forest carbon\nstock inventory methods of measuring single trees by hand are time, labour, and\ncost-intensive and have been shown to be subjective. They can lead to\nsubstantial overestimation of the carbon stock and ultimately distrust in\nforest financing. The potential for impact and scale of leveraging advancements\nin machine learning and remote sensing technologies is promising but needs to\nbe of high quality in order to replace the current forest stock protocols for\ncertifications.\nIn this paper, we present ReforesTree, a benchmark dataset of forest carbon\nstock in six agro-forestry carbon offsetting sites in Ecuador. Furthermore, we\nshow that a deep learning-based end-to-end model using individual tree\ndetection from low cost RGB-only drone imagery is accurately estimating forest\ncarbon stock within official carbon offsetting certification standards.\nAdditionally, our baseline CNN model outperforms state-of-the-art\nsatellite-based forest biomass and carbon stock estimates for this type of\nsmall-scale, tropical agro-forestry sites. We present this dataset to encourage\nmachine learning research in this area to increase accountability and\ntransparency of monitoring, verification and reporting (MVR) in carbon\noffsetting projects, as well as scaling global reforestation financing through\naccurate remote sensing.",
    "descriptor": "\nComments: Accepted paper for the AI for Social Impact Track at the AAAI 2022\n",
    "authors": [
      "Gyri Reiersen",
      "David Dao",
      "Bj\u00f6rn L\u00fctjens",
      "Konstantin Klemmer",
      "Kenza Amara",
      "Attila Steinegger",
      "Ce Zhang",
      "Xiaoxiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11192"
  },
  {
    "id": "arXiv:2201.11194",
    "title": "Attention cannot be an Explanation",
    "abstract": "Attention based explanations (viz. saliency maps), by providing\ninterpretability to black box models such as deep neural networks, are assumed\nto improve human trust and reliance in the underlying models. Recently, it has\nbeen shown that attention weights are frequently uncorrelated with\ngradient-based measures of feature importance. Motivated by this, we ask a\nfollow-up question: \"Assuming that we only consider the tasks where attention\nweights correlate well with feature importance, how effective are these\nattention based explanations in increasing human trust and reliance in the\nunderlying models?\". In other words, can we use attention as an explanation? We\nperform extensive human study experiments that aim to qualitatively and\nquantitatively assess the degree to which attention based explanations are\nsuitable in increasing human trust and reliance. Our experiment results show\nthat attention cannot be used as an explanation.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.01401, arXiv:1909.06907\n",
    "authors": [
      "Arjun R Akula",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11194"
  },
  {
    "id": "arXiv:2201.11195",
    "title": "Explaining Preferences by Multiple Patterns in Voters' Behavior",
    "abstract": "In some preference aggregation scenarios, voters' preferences are highly\nstructured: e.g., the set of candidates may have one-dimensional structure (so\nthat voters' preferences are single-peaked) or be described by a binary\ndecision tree (so that voters' preferences are group-separable). However,\nsometimes a single axis or a decision tree is insufficient to capture the\nvoters' preferences; rather, there is a small number $k$ of axes or decision\ntrees such that each vote in the profile is consistent with one of these axes\n(resp., trees). In this work, we study the complexity of deciding whether\nvoters' preferences can be explained in this manner. For $k=2$, we obtain a\npolynomial-time algorithm for several domains: single-peaked preferences\n(thereby answering a question left open by Erdelyi, Lackner and Pfandler\n(JAIR'17), value-restricted preferences, group-separable preferences, and a\nnatural subdomain of group-separable preferences, namely, caterpillar\ngroup-separable preferences. For $k\\ge 3$, the problem is known to be hard for\nsingle-peaked preferences; we show that this is also the case for\nvalue-restricted and group-separable preferences. Our positive results for\n$k=2$ make use of forbidden minor characterizations of the respective domains;\nin particular, we establish that the domain of caterpillar group-separable\npreferences admits a forbidden minor characterization.",
    "descriptor": "",
    "authors": [
      "Sonja Kraiczy",
      "Edith Elkind"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.11195"
  },
  {
    "id": "arXiv:2201.11196",
    "title": "IMACS: Image Model Attribution Comparison Summaries",
    "abstract": "Developing a suitable Deep Neural Network (DNN) often requires significant\niteration, where different model versions are evaluated and compared. While\nmetrics such as accuracy are a powerful means to succinctly describe a model's\nperformance across a dataset or to directly compare model versions,\npractitioners often wish to gain a deeper understanding of the factors that\ninfluence a model's predictions. Interpretability techniques such as\ngradient-based methods and local approximations can be used to examine small\nsets of inputs in fine detail, but it can be hard to determine if results from\nsmall sets generalize across a dataset. We introduce IMACS, a method that\ncombines gradient-based model attributions with aggregation and visualization\ntechniques to summarize differences in attributions between two DNN image\nmodels. More specifically, IMACS extracts salient input features from an\nevaluation dataset, clusters them based on similarity, then visualizes\ndifferences in model attributions for similar input features. In this work, we\nintroduce a framework for aggregating, summarizing, and comparing the\nattribution information for two models across a dataset; present visualizations\nthat highlight differences between 2 image classification models; and show how\nour technique can uncover behavioral differences caused by domain shift between\ntwo models trained on satellite images.",
    "descriptor": "",
    "authors": [
      "Eldon Schoop",
      "Ben Wedin",
      "Andrei Kapishnikov",
      "Tolga Bolukbasi",
      "Michael Terry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11196"
  },
  {
    "id": "arXiv:2201.11197",
    "title": "Challenges and Opportunities for Machine Learning Classification of  Behavior and Mental State from Images",
    "abstract": "Computer Vision (CV) classifiers which distinguish and detect nonverbal\nsocial human behavior and mental state can aid digital diagnostics and\ntherapeutics for psychiatry and the behavioral sciences. While CV classifiers\nfor traditional and structured classification tasks can be developed with\nstandard machine learning pipelines for supervised learning consisting of data\nlabeling, preprocessing, and training a convolutional neural network, there are\nseveral pain points which arise when attempting this process for behavioral\nphenotyping. Here, we discuss the challenges and corresponding opportunities in\nthis space, including handling heterogeneous data, avoiding biased models,\nlabeling massive and repetitive data sets, working with ambiguous or compound\nclass labels, managing privacy concerns, creating appropriate representations,\nand personalizing models. We discuss current state-of-the-art research\nendeavors in CV such as data curation, data augmentation, crowdsourced\nlabeling, active learning, reinforcement learning, generative models,\nrepresentation learning, federated learning, and meta-learning. We highlight at\nleast some of the machine learning advancements needed for imaging classifiers\nto detect human social cues successfully and reliably.",
    "descriptor": "\nComments: 30 pages, 1 figure, 1 table\n",
    "authors": [
      "Peter Washington",
      "Cezmi Onur Mutlu",
      "Aaron Kline",
      "Kelley Paskov",
      "Nate Tyler Stockham",
      "Brianna Chrisman",
      "Nick Deveau",
      "Mourya Surhabi",
      "Nick Haber",
      "Dennis P. Wall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11197"
  },
  {
    "id": "arXiv:2201.11198",
    "title": "Implementation of Advanced Wind Turbine Controllers for Scaled Turbine  Testing in a Wind Tunnel",
    "abstract": "Based on a series of two experimental campaigns testing advanced controllers\non a scaled wind turbine operating in a wind tunnel, this contribution\ndescribes the overall experimental method, challenges faced, lessons learned,\nand opportunities for future work. The two campaigns, run in Fall 2018 and Fall\n2019, tested unconstrained and constrained optimal blade pitch controllers,\nrespectively, using preview disturbance measurements of the oncoming wind.\nSpecifically, the first study considered an extension to the linear-quadratic\nregulator to include feedforward action, while the second deployed model\npredictive control to incorporate actuator constraints into the optimal control\nproblem. The results of the campaigns have already been published in technical\nconference and journal papers on control systems; however, detail on how the\ncontrollers were implemented was not included in those works. We aim to fill\nthat gap with this contribution, which is targeted at the wind energy\ncommunity. We describe several aspects of the experimental setup, in particular\nproviding details of the software and hardware used for the controller; share\ninsight on several aspects of the procedure that were difficult and how we\novercame those challenges; and summarize the key differences between\nsimulation-based studies and physical testing. By doing so, we hope to share\nwhat we learned during our experimental campaigns and provide a point of\nreference for others looking to carry out experiments on scaled wind turbines\noperating in wind tunnel facilities.",
    "descriptor": "\nComments: Proceedings of the EAWE PhD Seminar on Wind Energy\n",
    "authors": [
      "Michael Sinner",
      "Vlaho Petrovi\u0107",
      "Lucy Y. Pao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11198"
  },
  {
    "id": "arXiv:2201.11202",
    "title": "Low-Resolution Precoding for Multi-Antenna Downlink Channels and OFDM",
    "abstract": "Downlink precoding is considered for multi-path multi-user multi-input\nsingle-output (MU-MISO) channels where the base station uses orthogonal\nfrequency-division multiplexing and low-resolution signaling. A quantized\ncoordinate minimization (QCM) algorithm is proposed and its performance is\ncompared to other precoding algorithms including squared infinity-norm\nrelaxation (SQUID), multi-antenna greedy iterative quantization (MAGIQ), and\nmaximum safety margin precoding. MAGIQ and QCM achieve the highest information\nrates and QCM has the lowest complexity measured in the number of\nmultiplications. The information rates are computed for pilot-aided channel\nestimation and a blind detector that performs joint data and channel\nestimation. Bit error rates for a 5G low-density parity-check code confirm the\ninformation-theoretic calculations. Simulations with imperfect channel\nknowledge at the transmitter show that the performance of QCM and SQUID\ndegrades in a similar fashion as zero-forcing precoding with high resolution\nquantizers.",
    "descriptor": "",
    "authors": [
      "Andrei Stefan Nedelcu",
      "Fabian Steiner",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11202"
  },
  {
    "id": "arXiv:2201.11204",
    "title": "On the Convergence of mSGD and AdaGrad for Stochastic Optimization",
    "abstract": "As one of the most fundamental stochastic optimization algorithms, stochastic\ngradient descent (SGD) has been intensively developed and extensively applied\nin machine learning in the past decade. There have been some modified SGD-type\nalgorithms, which outperform the SGD in many competitions and applications in\nterms of convergence rate and accuracy, such as momentum-based SGD (mSGD) and\nadaptive gradient algorithm (AdaGrad). Despite these empirical successes, the\ntheoretical properties of these algorithms have not been well established due\nto technical difficulties. With this motivation, we focus on convergence\nanalysis of mSGD and AdaGrad for any smooth (possibly non-convex) loss\nfunctions in stochastic optimization. First, we prove that the iterates of mSGD\nare asymptotically convergent to a connected set of stationary points with\nprobability one, which is more general than existing works on subsequence\nconvergence or convergence of time averages. Moreover, we prove that the loss\nfunction of mSGD decays at a certain rate faster than that of SGD. In addition,\nwe prove the iterates of AdaGrad are asymptotically convergent to a connected\nset of stationary points with probability one. Also, this result extends the\nresults from the literature on subsequence convergence and the convergence of\ntime averages. Despite the generality of the above convergence results, we have\nrelaxed some assumptions of gradient noises, convexity of loss functions, as\nwell as boundedness of iterates.",
    "descriptor": "",
    "authors": [
      "Ruinan Jin",
      "Yu Xing",
      "Xingkang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11204"
  },
  {
    "id": "arXiv:2201.11205",
    "title": "Generative Trees: Adversarial and Copycat",
    "abstract": "While Generative Adversarial Networks (GANs) achieve spectacular results on\nunstructured data like images, there is still a gap on tabular data, data for\nwhich state of the art supervised learning still favours to a large extent\ndecision tree (DT)-based models. This paper proposes a new path forward for the\ngeneration of tabular data, exploiting decades-old understanding of the\nsupervised task's best components for DT induction, from losses (properness),\nmodels (tree-based) to algorithms (boosting). The \\textit{properness} condition\non the supervised loss -- which postulates the optimality of Bayes rule --\nleads us to a variational GAN-style loss formulation which is \\textit{tight}\nwhen discriminators meet a calibration property trivially satisfied by DTs,\nand, under common assumptions about the supervised loss, yields \"one loss to\ntrain against them all\" for the generator: the $\\chi^2$. We then introduce\ntree-based generative models, \\textit{generative trees} (GTs), meant to mirror\non the generative side the good properties of DTs for classifying tabular data,\nwith a boosting-compliant \\textit{adversarial} training algorithm for GTs. We\nalso introduce \\textit{copycat training}, in which the generator copies at run\ntime the underlying tree (graph) of the discriminator DT and completes it for\nthe hardest discriminative task, with boosting compliant convergence. We test\nour algorithms on tasks including fake/real distinction, training from fake\ndata and missing data imputation. Each one of these tasks displays that GTs can\nprovide comparatively simple -- and interpretable -- contenders to\nsophisticated state of the art methods for data generation (using neural\nnetwork models) or missing data imputation (relying on multiple imputation by\nchained equations with complex tree-based modeling).",
    "descriptor": "",
    "authors": [
      "Richard Nock",
      "Mathieu Guillame-Bert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11205"
  },
  {
    "id": "arXiv:2201.11206",
    "title": "Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov  Decision Processes",
    "abstract": "Reward-free reinforcement learning (RL) considers the setting where the agent\ndoes not have access to a reward function during exploration, but must propose\na near-optimal policy for an arbitrary reward function revealed only after\nexploring. In the the tabular setting, it is well known that this is a more\ndifficult problem than PAC RL -- where the agent has access to the reward\nfunction during exploration -- with optimal sample complexities in the two\nsettings differing by a factor of $|\\mathcal{S}|$, the size of the state space.\nWe show that this separation does not exist in the setting of linear MDPs. We\nfirst develop a computationally efficient algorithm for reward-free RL in a\n$d$-dimensional linear MDP with sample complexity scaling as\n$\\mathcal{O}(d^2/\\epsilon^2)$. We then show a matching lower bound of\n$\\Omega(d^2/\\epsilon^2)$ on PAC RL. To our knowledge, our approach is the first\ncomputationally efficient algorithm to achieve optimal $d$ dependence in linear\nMDPs, even in the single-reward PAC setting. Our algorithm relies on a novel\nprocedure which efficiently traverses a linear MDP, collecting samples in any\ngiven \"feature direction\", and enjoys a sample complexity scaling optimally in\nthe (linear MDP equivalent of the) maximal state visitation probability. We\nshow that this exploration procedure can also be applied to solve the problem\nof obtaining \"well-conditioned\" covariates in linear MDPs.",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11206"
  },
  {
    "id": "arXiv:2201.11207",
    "title": "Discovering Phonetic Inventories with Crosslingual Automatic Speech  Recognition",
    "abstract": "The high cost of data acquisition makes Automatic Speech Recognition (ASR)\nmodel training problematic for most existing languages, including languages\nthat do not even have a written script, or for which the phone inventories\nremain unknown. Past works explored multilingual training, transfer learning,\nas well as zero-shot learning in order to build ASR systems for these\nlow-resource languages. While it has been shown that the pooling of resources\nfrom multiple languages is helpful, we have not yet seen a successful\napplication of an ASR model to a language unseen during training. A crucial\nstep in the adaptation of ASR from seen to unseen languages is the creation of\nthe phone inventory of the unseen language. The ultimate goal of our work is to\nbuild the phone inventory of a language unseen during training in an\nunsupervised way without any knowledge about the language. In this paper, we 1)\ninvestigate the influence of different factors (i.e., model architecture,\nphonotactic model, type of speech representation) on phone recognition in an\nunknown language; 2) provide an analysis of which phones transfer well across\nlanguages and which do not in order to understand the limitations of and areas\nfor further improvement for automatic phone inventory creation; and 3) present\ndifferent methods to build a phone inventory of an unseen language in an\nunsupervised way. To that end, we conducted mono-, multi-, and crosslingual\nexperiments on a set of 13 phonetically diverse languages and several in-depth\nanalyses. We found a number of universal phone tokens (IPA symbols) that are\nwell-recognized cross-linguistically. Through a detailed analysis of results,\nwe conclude that unique sounds, similar sounds, and tone languages remain a\nmajor challenge for phonetic inventory discovery.",
    "descriptor": "\nComments: 55 pages (57 including the graphical abstract and highlights)\n",
    "authors": [
      "Piotr \u017belasko",
      "Siyuan Feng",
      "Laureano Moro Velazquez",
      "Ali Abavisani",
      "Saurabhchand Bhati",
      "Odette Scharenborg",
      "Mark Hasegawa-Johnson",
      "Najim Dehak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11207"
  },
  {
    "id": "arXiv:2201.11209",
    "title": "On The Energy Statistics of Feature Maps in Pruning of Neural Networks  with Skip-Connections",
    "abstract": "We propose a new structured pruning framework for compressing Deep Neural\nNetworks (DNNs) with skip connections, based on measuring the statistical\ndependency of hidden layers and predicted outputs. The dependence measure\ndefined by the energy statistics of hidden layers serves as a model-free\nmeasure of information between the feature maps and the output of the network.\nThe estimated dependence measure is subsequently used to prune a collection of\nredundant and uninformative layers. Model-freeness of our measure guarantees\nthat no parametric assumptions on the feature map distribution are required,\nmaking it computationally appealing for very high dimensional feature space in\nDNNs. Extensive numerical experiments on various architectures show the\nefficacy of the proposed pruning approach with competitive performance to\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Mohammadreza Soltani",
      "Suya Wu",
      "Yuerong Li",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.11209"
  },
  {
    "id": "arXiv:2201.11216",
    "title": "Serverless Architecture for Bulk Email Management",
    "abstract": "Sending emails in large quantities can be tedious considering free services\ndo not cover bulk email and paid services can be costly and are not easy to\ncustomize. Traditional email client used for basic emailing services fail to be\nuseful in larger volumes of emails to target people or spread information to\nconsented individuals. This paper proposes a serverless architecture to tackle\nsuch problems by using one such offering from the Amazon Web Services(AWS) API\nwhich can be easily replaced by a software architects choice of service. The\nconstraints help to make an architecture using components that can fit most of\nthe needs of a serverless backend and extend it to scenarios such mobile\nnotifications, One Time Password (OTP) systems or other means of communication\nto minimize single point of failure and also decrease the dependency on\nphysical servers for such operations offering a comparable solution within the\ncloud. The architecture proposed is tested to find the time taken to send the\nemails of various quantities and see how it affects the cost. The architecture\nwas successful able to send multiple emails in a quick and single invocation\nand has demonstrated a higher level of scalability compared to conventional\nmethods.",
    "descriptor": "",
    "authors": [
      "Bazaru Priyatham Sai Chand"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11216"
  },
  {
    "id": "arXiv:2201.11218",
    "title": "DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for  Layer Fusion in DNN Accelerators",
    "abstract": "Dataflow/mapping decides the compute and energy efficiency of DNN\naccelerators. Many mappers have been proposed to tackle the intra-layer\nmap-space. However, mappers for inter-layer map-space (aka layer-fusion\nmap-space), have been rarely discussed. In this work, we propose a mapper,\nDNNFuser, specifically focusing on this layer-fusion map-space. While existing\nSOTA DNN mapping explorations rely on search-based mappers, this is the first\nwork, to the best of our knowledge, to propose a one-shot inference-based\nmapper. We leverage a famous language model GPT as our DNN architecture to\nlearn layer-fusion optimization as a sequence modeling problem. Further, the\ntrained DNNFuser can generalize its knowledge and infer new solutions for\nunseen conditions. Within one inference pass, DNNFuser can infer solutions with\ncompatible performance to the ones found by a highly optimized search-based\nmapper while being 66x-127x faster.",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Xiaoyu Huang",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11218"
  },
  {
    "id": "arXiv:2201.11220",
    "title": "DiGamma: Domain-aware Genetic Algorithm for HW-Mapping Co-optimization  for DNN Accelerators",
    "abstract": "The design of DNN accelerators includes two key parts: HW resource\nconfiguration and mapping strategy. Intensive research has been conducted to\noptimize each of them independently. Unfortunately, optimizing for both\ntogether is extremely challenging due to the extremely large cross-coupled\nsearch space. To address this, in this paper, we propose a HW-Mapping\nco-optimization framework, an efficient encoding of the immense design space\nconstructed by HW and Mapping, and a domain-aware genetic algorithm, named\nDiGamma, with specialized operators for improving search efficiency. We\nevaluate DiGamma with seven popular DNNs models with different properties. Our\nevaluations show DiGamma can achieve (geomean) 3.0x and 10.0x speedup,\ncomparing to the best-performing baseline optimization algorithms, in edge and\ncloud settings.",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Michael Pellauer",
      "Angshuman Parashar",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11220"
  },
  {
    "id": "arXiv:2201.11221",
    "title": "Linear lambda-calculus is linear",
    "abstract": "We prove a linearity theorem for an extension of linear logic with addition\nand multiplication by a scalar: the proofs of some propositions in this logic\nare linear in the algebraic sense. This work is part of a wider research\nprogram that aims at defining a logic whose proof language is a quantum\nprogramming language.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Alejandro D\u00edaz-Caro",
      "Gilles Dowek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11221"
  },
  {
    "id": "arXiv:2201.11222",
    "title": "Online Change Point Detection for Weighted and Directed Random Dot  Product Graphs",
    "abstract": "Given a sequence of random (directed and weighted) graphs, we address the\nproblem of online monitoring and detection of changes in the underlying data\ndistribution. Our idea is to endow sequential change-point detection (CPD)\ntechniques with a graph representation learning substrate based on the\nversatile Random Dot Product Graph (RDPG) model. We consider efficient, online\nupdates of a judicious monitoring function, which quantifies the discrepancy\nbetween the streaming graph observations and the nominal RDPG. This reference\ndistribution is inferred via spectral embeddings of the first few graphs in the\nsequence. We characterize the distribution of this running statistic to select\nthresholds that guarantee error-rate control, and under simplifying\napproximations we offer insights on the algorithm's detection resolution and\ndelay. The end result is a lightweight online CPD algorithm, that is also\nexplainable by virtue of the well-appreciated interpretability of RDPG\nembeddings. This is in stark contrast with most existing graph CPD approaches,\nwhich either rely on extensive computation, or they store and process the\nentire observed time series. An apparent limitation of the RDPG model is its\nsuitability for undirected and unweighted graphs only, a gap we aim to close\nhere to broaden the scope of the CPD framework. Unlike previous proposals, our\nnon-parametric RDPG model for weighted graphs does not require a priori\nspecification of the weights' distribution to perform inference and estimation.\nThis network modeling contribution is of independent interest beyond CPD. We\noffer an open-source implementation of the novel online CPD algorithm for\nweighted and direct graphs, whose effectiveness and efficiency are demonstrated\nvia (reproducible) synthetic and real network data experiments.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Signal and Information Processing over Networks\n",
    "authors": [
      "Bernardo Marenco",
      "Paola Bermolen",
      "Marcelo Fiori",
      "Federico Larroca",
      "Gonzalo Mateos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11222"
  },
  {
    "id": "arXiv:2201.11226",
    "title": "An Exploration of Captioning Practices and Challenges of Individual  Content Creators on YouTube for People with Hearing Impairments",
    "abstract": "Deaf and Hard-of-Hearing (DHH) audiences have long complained about caption\nqualities for many online videos created by individual content creators on\nvideo-sharing platforms (e.g., YouTube). However, there lack explorations of\npractices, challenges, and perceptions of online video captions from the\nperspectives of both individual content creators and DHH audiences. In this\nwork, we first explore DHH audiences' feedback on and reactions to YouTube\nvideo captions through interviews with 13 DHH individuals, and uncover DHH\naudiences' experiences, challenges, and perceptions on watching videos created\nby individual content creators (e.g., manually added caption tags could create\nadditional confidence and trust in caption qualities for DHH audiences). We\nthen discover individual content creators' practices, challenges, and\nperceptions on captioning their videos (e.g., back-captioning problems) by\nconducting a YouTube video analysis with 189 captioning-related YouTube videos,\nfollowed by a survey with 62 individual content creators. Overall, our findings\nprovide an in-depth understanding of captions generated by individual content\ncreators and bridge the knowledge gap mutually between content creators and DHH\naudiences on captions.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Franklin Mingzhe Li",
      "Cheng Lu",
      "Zhicong Lu",
      "Patrick Carrington",
      "Khai N. Truong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11226"
  },
  {
    "id": "arXiv:2201.11227",
    "title": "Synchromesh: Reliable code generation from pre-trained language models",
    "abstract": "Large pre-trained language models have been used to generate code,providing a\nflexible interface for synthesizing programs from natural language\nspecifications. However, they often violate syntactic and semantic rules of\ntheir output language, limiting their practical usability. In this paper, we\npropose Synchromesh: a framework for substantially improving the reliability of\npre-trained models for code generation. Synchromesh comprises two components.\nFirst, it retrieves few-shot examples from a training bank using Target\nSimilarity Tuning (TST), a novel method for semantic example selection. TST\nlearns to recognize utterances that describe similar target programs despite\ndifferences in surface natural language features. Then, Synchromesh feeds the\nexamples to a pre-trained language model and samples programs using Constrained\nSemantic Decoding (CSD): a general framework for constraining the output to a\nset of valid programs in the target language. CSD leverages constraints on\npartial outputs to sample complete correct programs, and needs neither\nre-training nor fine-tuning of the language model. We evaluate our methods by\nsynthesizing code from natural language descriptions using GPT-3 and Codex in\nthree real-world languages: SQL queries, Vega-Lite visualizations and SMCalFlow\nprograms. These domains showcase rich constraints that CSD is able to enforce,\nincluding syntax, scope, typing rules, and contextual logic. We observe\nsubstantial complementary gains from CSD and TST in prediction accuracy and in\neffectively preventing run-time errors.",
    "descriptor": "\nComments: 10 pages, 9 additional pages of Appendix\n",
    "authors": [
      "Gabriel Poesia",
      "Oleksandr Polozov",
      "Vu Le",
      "Ashish Tiwari",
      "Gustavo Soares",
      "Christopher Meek",
      "Sumit Gulwani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.11227"
  },
  {
    "id": "arXiv:2201.11228",
    "title": "Continuous Examination by Automatic Quiz Assessment Using Spiral Codes  and Image Processing",
    "abstract": "We describe a technical solution implemented at Halmstad University to\nautomatise assessment and reporting of results of paper-based quiz exams. Paper\nquizzes are affordable and within reach of campus education in classrooms.\nOffering and taking them is accepted as they cause fewer issues with\nreliability and democratic access, e.g. a large number of students can take\nthem without a trusted mobile device, internet, or battery. By contrast,\ncorrection of the quiz is a considerable obstacle. We suggest mitigating the\nissue by a novel image processing technique using harmonic spirals that aligns\nanswer sheets in sub-pixel accuracy to read student identity and answers and to\nemail results within minutes, all fully automatically. Using the described\nmethod, we carry out regular weekly examinations in two master courses at the\nmentioned centre without a significant workload increase. The employed solution\nalso enables us to assign a unique identifier to each quiz (e.g. week 1, week\n2. . . ) while allowing us to have an individualised quiz for each student.",
    "descriptor": "\nComments: Accepted at 13th IEEE Global Engineering Education Conference, EDUCON, Tunis, Tunisia, 28-31 March 2022 (Educational Conference)\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Josef Bigun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11228"
  },
  {
    "id": "arXiv:2201.11230",
    "title": "Objective Prediction of Tomorrow's Affect Using Multi-Modal  Physiological Data and Personal Chronicles: A Study of Monitoring College  Student Well-being in 2020",
    "abstract": "Monitoring and understanding affective states are important aspects of\nhealthy functioning and treatment of mood-based disorders. Recent advancements\nof ubiquitous wearable technologies have increased the reliability of such\ntools in detecting and accurately estimating mental states (e.g., mood, stress,\netc.), offering comprehensive and continuous monitoring of individuals over\ntime. Previous attempts to model an individual's mental state were limited to\nsubjective approaches or the inclusion of only a few modalities (i.e., phone,\nwatch). Thus, the goal of our study was to investigate the capacity to more\naccurately predict affect through a fully automatic and objective approach\nusing multiple commercial devices. Longitudinal physiological data and daily\nassessments of emotions were collected from a sample of college students using\nsmart wearables and phones for over a year. Results showed that our model was\nable to predict next-day affect with accuracy comparable to state of the art\nmethods.",
    "descriptor": "",
    "authors": [
      "Salar Jafarlou",
      "Jocelyn Lai",
      "Zahra Mousavi",
      "Sina Labbaf",
      "Ramesh Jain",
      "Nikil Dutt",
      "Jessica Borelli",
      "Amir Rahmani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11230"
  },
  {
    "id": "arXiv:2201.11231",
    "title": "Gap Minimization for Knowledge Sharing and Transfer",
    "abstract": "Learning from multiple related tasks by knowledge sharing and transfer has\nbecome increasingly relevant over the last two decades. In order to\nsuccessfully transfer information from one task to another, it is critical to\nunderstand the similarities and differences between the domains. In this paper,\nwe introduce the notion of \\emph{performance gap}, an intuitive and novel\nmeasure of the distance between learning tasks. Unlike existing measures which\nare used as tools to bound the difference of expected risks between tasks\n(e.g., $\\mathcal{H}$-divergence or discrepancy distance), we theoretically show\nthat the performance gap can be viewed as a data- and algorithm-dependent\nregularizer, which controls the model complexity and leads to finer guarantees.\nMore importantly, it also provides new insights and motivates a novel principle\nfor designing strategies for knowledge sharing and transfer: gap minimization.\nWe instantiate this principle with two algorithms: 1. {gapBoost}, a novel and\nprincipled boosting algorithm that explicitly minimizes the performance gap\nbetween source and target domains for transfer learning; and 2. {gapMTNN}, a\nrepresentation learning algorithm that reformulates gap minimization as\nsemantic conditional matching for multitask learning. Our extensive evaluation\non both transfer learning and multitask learning benchmark data sets shows that\nour methods outperform existing baselines.",
    "descriptor": "",
    "authors": [
      "Boyu Wang",
      "Jorge Mendez",
      "Changjian Shui",
      "Fan Zhou",
      "Di Wu",
      "Christian Gagn\u00e9",
      "Eric Eaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11231"
  },
  {
    "id": "arXiv:2201.11232",
    "title": "Assessment of Sustainable Funding Impact by Exploiting Research  Performance Indicators and Semantic Techniques",
    "abstract": "This paper deploys bibliometric indices and semantic techniques for\nunderstanding to what extent research grants are likely to impact publications,\nresearch direction, and co-authorship rate of principal investigators. The\nnovelty of this paper lies within the fact that it includes semantic analysis\nin the research funding evaluation process in order to effectively study\nshort-term and long-term funding impact in terms of publication outputs. Our\ndataset consists of researchers that receive research grants from the National\nICT Research and Development funding program of Pakistan. We show a number of\ninteresting case studies to conclude that bibliometric-based quantitative\nassessment combined with semantics can lead to building better sustainable\npathways to deploy evaluation frameworks for research funding effectively.",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Muhammad Umar",
      "Saeed-Ul Hassan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.11232"
  },
  {
    "id": "arXiv:2201.11239",
    "title": "Diagnosing AI Explanation Methods with Folk Concepts of Behavior",
    "abstract": "When explaining AI behavior to humans, how is the communicated information\nbeing comprehended by the human explainee, and does it match what the\nexplanation attempted to communicate? When can we say that an explanation is\nexplaining something? We aim to provide an answer by leveraging theory of mind\nliterature about the folk concepts that humans use to understand behavior. We\nestablish a framework of social attribution by the human explainee, which\ndescribes the function of explanations: the concrete information that humans\ncomprehend from them. Specifically, effective explanations should be coherent\n(communicate information which generalizes to other contrast cases), complete\n(communicating an explicit contrast case, objective causes, and subjective\ncauses), and interactive (surfacing and resolving contradictions to the\ngeneralization property through iterations). We demonstrate that many XAI\nmechanisms can be mapped to folk concepts of behavior. This allows us to\nuncover their modes of failure that prevent current methods from explaining\neffectively, and what is necessary to enable coherent explanations.",
    "descriptor": "",
    "authors": [
      "Alon Jacovi",
      "Jasmijn Bastings",
      "Sebastian Gehrmann",
      "Yoav Goldberg",
      "Katja Filippova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11239"
  },
  {
    "id": "arXiv:2201.11242",
    "title": "Heterogeneous Peer Effects in the Linear Threshold Model",
    "abstract": "The Linear Threshold Model is a widely used model that describes how\ninformation diffuses through a social network. According to this model, an\nindividual adopts an idea or product after the proportion of their neighbors\nwho have adopted it reaches a certain threshold. Typical applications of the\nLinear Threshold Model assume that thresholds are either the same for all\nnetwork nodes or randomly distributed, even though some people may be more\nsusceptible to peer pressure than others. To address individual-level\ndifferences, we propose causal inference methods for estimating individual\nthresholds that can more accurately predict whether and when individuals will\nbe affected by their peers. We introduce the concept of heterogeneous peer\neffects and develop a Structural Causal Model which corresponds to the Linear\nThreshold Model and supports heterogeneous peer effect identification and\nestimation. We develop two algorithms for individual threshold estimation, one\nbased on causal trees and one based on causal meta-learners. Our experimental\nresults on synthetic and real-world datasets show that our proposed models can\nbetter predict individual-level thresholds in the Linear Threshold Model and\nthus more precisely predict which nodes will get activated over time.",
    "descriptor": "\nComments: To be published in the 36th AAAI Conference on Artificial Intelligence (2022)\n",
    "authors": [
      "Christopher Tran",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11242"
  },
  {
    "id": "arXiv:2201.11247",
    "title": "Data-Quality Based Scheduling for Federated Edge Learning",
    "abstract": "FEderated Edge Learning (FEEL) has emerged as a leading technique for\nprivacy-preserving distributed training in wireless edge networks, where edge\ndevices collaboratively train machine learning (ML) models with the\norchestration of a server. However, due to frequent communication, FEEL needs\nto be adapted to the limited communication bandwidth. Furthermore, the\nstatistical heterogeneity of local datasets' distributions, and the uncertainty\nabout the data quality pose important challenges to the training's convergence.\nTherefore, a meticulous selection of the participating devices and an analogous\nbandwidth allocation are necessary. In this paper, we propose a data-quality\nbased scheduling (DQS) algorithm for FEEL. DQS prioritizes reliable devices\nwith rich and diverse datasets. In this paper, we define the different\ncomponents of the learning algorithm and the data-quality evaluation. Then, we\nformulate the device selection and the bandwidth allocation problem. Finally,\nwe present our DQS algorithm for FEEL, and we evaluate it in different data\npoisoning scenarios.",
    "descriptor": "\nComments: 2021 IEEE 46th Conference on Local Computer Networks (LCN)\n",
    "authors": [
      "Afaf Taik",
      "Hajar Moudoud",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11247"
  },
  {
    "id": "arXiv:2201.11248",
    "title": "Electrical Load Forecasting Using Edge Computing and Federated Learning",
    "abstract": "In the smart grid, huge amounts of consumption data are used to train deep\nlearning models for applications such as load monitoring and demand response.\nHowever, these applications raise concerns regarding security and have high\naccuracy requirements. In one hand, the data used is privacy-sensitive. For\ninstance, the fine-grained data collected by a smart meter at a consumer's home\nmay reveal information on the appliances and thus the consumer's behaviour at\nhome. On the other hand, the deep learning models require big data volumes with\nenough variety and to be trained adequately. In this paper, we evaluate the use\nof Edge computing and federated learning, a decentralized machine learning\nscheme that allows to increase the volume and diversity of data used to train\nthe deep learning models without compromising privacy. This paper reports, to\nthe best of our knowledge, the first use of federated learning for household\nload forecasting and achieves promising results. The simulations were done\nusing Tensorflow Federated on the data from 200 houses from Texas, USA.",
    "descriptor": "\nComments: ICC 2020-2020 IEEE International Conference on Communications (ICC)\n",
    "authors": [
      "Afaf Taik",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.11248"
  },
  {
    "id": "arXiv:2201.11249",
    "title": "Jointly Learning Knowledge Embedding and Neighborhood Consensus with  Relational Knowledge Distillation for Entity Alignment",
    "abstract": "Entity alignment aims at integrating heterogeneous knowledge from different\nknowledge graphs. Recent studies employ embedding-based methods by first\nlearning the representation of Knowledge Graphs and then performing entity\nalignment via measuring the similarity between entity embeddings. However, they\nfailed to make good use of the relation semantic information due to the\ntrade-off problem caused by the different objectives of learning knowledge\nembedding and neighborhood consensus. To address this problem, we propose\nRelational Knowledge Distillation for Entity Alignment (RKDEA), a Graph\nConvolutional Network (GCN) based model equipped with knowledge distillation\nfor entity alignment. We adopt GCN-based models to learn the representation of\nentities by considering the graph structure and incorporating the relation\nsemantic information into GCN via knowledge distillation. Then, we introduce a\nnovel adaptive mechanism to transfer relational knowledge so as to jointly\nlearn entity embedding and neighborhood consensus. Experimental results on\nseveral benchmarking datasets demonstrate the effectiveness of our proposed\nmodel.",
    "descriptor": "",
    "authors": [
      "Xinhang Li",
      "Yong Zhang",
      "Chunxiao Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11249"
  },
  {
    "id": "arXiv:2201.11250",
    "title": "Neuro-Symbolic Entropy Regularization",
    "abstract": "In structured prediction, the goal is to jointly predict many output\nvariables that together encode a structured object -- a path in a graph, an\nentity-relation triple, or an ordering of objects. Such a large output space\nmakes learning hard and requires vast amounts of labeled data. Different\napproaches leverage alternate sources of supervision. One approach -- entropy\nregularization -- posits that decision boundaries should lie in low-probability\nregions. It extracts supervision from unlabeled examples, but remains agnostic\nto the structure of the output space. Conversely, neuro-symbolic approaches\nexploit the knowledge that not every prediction corresponds to a valid\nstructure in the output space. Yet, they does not further restrict the learned\noutput distribution. This paper introduces a framework that unifies both\napproaches. We propose a loss, neuro-symbolic entropy regularization, that\nencourages the model to confidently predict a valid object. It is obtained by\nrestricting entropy regularization to the distribution over only valid\nstructures. This loss is efficiently computed when the output constraint is\nexpressed as a tractable logic circuit. Moreover, it seamlessly integrates with\nother neuro-symbolic losses that eliminate invalid predictions. We demonstrate\nthe efficacy of our approach on a series of semi-supervised and\nfully-supervised structured-prediction experiments, where we find that it leads\nto models whose predictions are more accurate and more likely to be valid.",
    "descriptor": "",
    "authors": [
      "Kareem Ahmed",
      "Eric Wang",
      "Kai-Wei Chang",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11250"
  },
  {
    "id": "arXiv:2201.11251",
    "title": "Reinforcement Learning Based Query Vertex Ordering Model for Subgraph  Matching",
    "abstract": "Subgraph matching is a fundamental problem in various fields that use graph\nstructured data. Subgraph matching algorithms enumerate all isomorphic\nembeddings of a query graph q in a data graph G. An important branch of\nmatching algorithms exploit the backtracking search approach which recursively\nextends intermediate results following a matching order of query vertices. It\nhas been shown that the matching order plays a critical role in time efficiency\nof these backtracking based subgraph matching algorithms. In recent years, many\nadvanced techniques for query vertex ordering (i.e., matching order generation)\nhave been proposed to reduce the unpromising intermediate results according to\nthe preset heuristic rules. In this paper, for the first time we apply the\nReinforcement Learning (RL) and Graph Neural Networks (GNNs) techniques to\ngenerate the high-quality matching order for subgraph matching algorithms.\nInstead of using the fixed heuristics to generate the matching order, our model\ncould capture and make full use of the graph information, and thus determine\nthe query vertex order with the adaptive learning-based rule that could\nsignificantly reduces the number of redundant enumerations. With the help of\nthe reinforcement learning framework, our model is able to consider the\nlong-term benefits rather than only consider the local information at current\nordering step.Extensive experiments on six real-life data graphs demonstrate\nthat our proposed matching order generation technique could reduce up to two\norders of magnitude of query processing time compared to the state-of-the-art\nalgorithms.",
    "descriptor": "\nComments: Accepted by ICDE 2022\n",
    "authors": [
      "Hanchen Wang",
      "Ying Zhang",
      "Lu Qin",
      "Wei Wang",
      "Wenjie Zhang",
      "Xuemin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.11251"
  },
  {
    "id": "arXiv:2201.11252",
    "title": "Semantic Code Classification for Automated Machine Learning",
    "abstract": "A range of applications for automatic machine learning need the generation\nprocess to be controllable. In this work, we propose a way to control the\noutput via a sequence of simple actions, that are called semantic code classes.\nFinally, we present a semantic code classification task and discuss methods for\nsolving this problem on the Natural Language to Machine Learning (NL2ML)\ndataset.",
    "descriptor": "\nComments: 15 pages including references, New In ML workshop at NeurIPS'21\n",
    "authors": [
      "Polina Guseva",
      "Anastasia Drozdova",
      "Natalia Denisenko",
      "Daria Sapozhnikova",
      "Ivan Pyaternev",
      "Anna Scherbakova",
      "Andrey Ustuzhanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11252"
  },
  {
    "id": "arXiv:2201.11253",
    "title": "Mapping the Buried Cable by Ground Penetrating Radar and  Gaussian-Process Regression",
    "abstract": "With the rapid expansion of urban areas and the increasingly use of\nelectricity, the need for locating buried cables is becoming urgent. In this\npaper, a noval method to locate underground cables based on Ground Penetrating\nRadar (GPR) and Gaussian-process regression is proposed. Firstly, the\ncoordinate system of the detected area is conducted, and the input and output\nof locating buried cables are determined. The GPR is moved along the\nestablished parallel detection lines, and the hyperbolic signatures generated\nby buried cables are identified and fitted, thus the positions and depths of\nsome points on the cable could be derived. On the basis of the established\ncoordinate system and the derived points on the cable, the clustering method\nand cable fitting algorithm based on Gaussian-process regression are proposed\nto find the most likely locations of the underground cables. Furthermore, the\nconfidence intervals of the cable's locations are also obtained. Both the\nposition and depth noises are taken into account in our method, ensuring the\nrobustness and feasibility in different environments and equipments.\nExperiments on real-world datasets are conducted, and the obtained results\ndemonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiren Zhou",
      "Qiuju Chen",
      "Shengfei Lyu",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11253"
  },
  {
    "id": "arXiv:2201.11255",
    "title": "Skeleton-stabilized divergence-conforming B-spline discretizations for  highly advective incompressible flow problems",
    "abstract": "We consider a stabilization method for divergence-conforming B-spline\ndiscretizations of the incompressible Navier--Stokes problem wherein jumps in\nhigh-order normal derivatives of the velocity field are penalized across\ninterior mesh facets. We prove that this method is pressure robust, consistent,\nand energy stable, and we show how to select the stabilization parameter\nappearing in the method so that excessive numerical dissipation is avoided in\nboth the cross-wind direction and in the diffusion-dominated regime. We examine\nthe efficacy of the method using a suite of numerical experiments, and we find\nthe method yields optimal $\\textbf{L}^2$ and $\\textbf{H}^1$ convergence rates\nfor the velocity field, eliminates spurious small-scale structures that pollute\nGalerkin approximations, and is effective as an Implicit Large Eddy Simulation\n(ILES) methodology.",
    "descriptor": "",
    "authors": [
      "Guoxiang Grayson Tong",
      "David Kamensky",
      "John A. Evans"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2201.11255"
  },
  {
    "id": "arXiv:2201.11258",
    "title": "Learning How to Translate North Korean through South Korean",
    "abstract": "South and North Korea both use the Korean language. However, Korean NLP\nresearch has focused on South Korean only, and existing NLP systems of the\nKorean language, such as neural machine translation (NMT) models, cannot\nproperly handle North Korean inputs. Training a model using North Korean data\nis the most straightforward approach to solving this problem, but there is\ninsufficient data to train NMT models. In this study, we create data for North\nKorean NMT models using a comparable corpus. First, we manually create\nevaluation data for automatic alignment and machine translation. Then, we\ninvestigate automatic alignment methods suitable for North Korean. Finally, we\nverify that a model trained by North Korean bilingual data without human\nannotation can significantly boost North Korean translation accuracy compared\nto existing South Korean models in zero-shot settings.",
    "descriptor": "\nComments: 8 pages, 1 figures, 8 tables\n",
    "authors": [
      "Hwichan Kim",
      "Sangwhan Moon",
      "Naoaki Okazaki",
      "Mamoru Komachi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11258"
  },
  {
    "id": "arXiv:2201.11259",
    "title": "Controlling Directions Orthogonal to a Classifier",
    "abstract": "We propose to identify directions invariant to a given classifier so that\nthese directions can be controlled in tasks such as style transfer. While\northogonal decomposition is directly identifiable when the given classifier is\nlinear, we formally define a notion of orthogonality in the non-linear case. We\nalso provide a surprisingly simple method for constructing the orthogonal\nclassifier (a classifier utilizing directions other than those of the given\nclassifier). Empirically, we present three use cases where controlling\northogonal variation is important: style transfer, domain adaptation, and\nfairness. The orthogonal classifier enables desired style transfer when domains\nvary in multiple aspects, improves domain adaptation with label shifts and\nmitigates the unfairness as a predictor. The code is available at\nthis http URL",
    "descriptor": "\nComments: accepted by ICLR 2022\n",
    "authors": [
      "Yilun Xu",
      "Hao He",
      "Tianxiao Shen",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11259"
  },
  {
    "id": "arXiv:2201.11260",
    "title": "To what extent should we trust AI models when they extrapolate?",
    "abstract": "Many applications affecting human lives rely on models that have come to be\nknown under the umbrella of machine learning and artificial intelligence. These\nAI models are usually complicated mathematical functions that map from an input\nspace to an output space. Stakeholders are interested to know the rationales\nbehind models' decisions and functional behavior. We study this functional\nbehavior in relation to the data used to create the models. On this topic,\nscholars have often assumed that models do not extrapolate, i.e., they learn\nfrom their training samples and process new input by interpolation. This\nassumption is questionable: we show that models extrapolate frequently; the\nextent of extrapolation varies and can be socially consequential. We\ndemonstrate that extrapolation happens for a substantial portion of datasets\nmore than one would consider reasonable. How can we trust models if we do not\nknow whether they are extrapolating? Given a model trained to recommend\nclinical procedures for patients, can we trust the recommendation when the\nmodel considers a patient older or younger than all the samples in the training\nset? If the training set is mostly Whites, to what extent can we trust its\nrecommendations about Black and Hispanic patients? Which dimension (race,\ngender, or age) does extrapolation happen? Even if a model is trained on people\nof all races, it still may extrapolate in significant ways related to race. The\nleading question is, to what extent can we trust AI models when they process\ninputs that fall outside their training set? This paper investigates several\nsocial applications of AI, showing how models extrapolate without notice. We\nalso look at different sub-spaces of extrapolation for specific individuals\nsubject to AI models and report how these extrapolations can be interpreted,\nnot mathematically, but from a humanistic point of view.",
    "descriptor": "",
    "authors": [
      "Roozbeh Yousefzadeh",
      "Xuenan Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11260"
  },
  {
    "id": "arXiv:2201.11271",
    "title": "Clustered Vehicular Federated Learning: Process and Optimization",
    "abstract": "Federated Learning (FL) is expected to play a prominent role for\nprivacy-preserving machine learning (ML) in autonomous vehicles. FL involves\nthe collaborative training of a single ML model among edge devices on their\ndistributed datasets while keeping data locally. While FL requires less\ncommunication compared to classical distributed learning, it remains hard to\nscale for large models. In vehicular networks, FL must be adapted to the\nlimited communication resources, the mobility of the edge nodes, and the\nstatistical heterogeneity of data distributions. Indeed, a judicious\nutilization of the communication resources alongside new perceptive\nlearning-oriented methods are vital. To this end, we propose a new architecture\nfor vehicular FL and corresponding learning and scheduling processes. The\narchitecture utilizes vehicular-to-vehicular(V2V) resources to bypass the\ncommunication bottleneck where clusters of vehicles train models simultaneously\nand only the aggregate of each cluster is sent to the multi-access edge (MEC)\nserver. The cluster formation is adapted for single and multi-task learning,\nand takes into account both communication and learning aspects. We show through\nsimulations that the proposed process is capable of improving the learning\naccuracy in several non-independent and-identically-distributed (non-i.i.d) and\nunbalanced datasets distributions, under mobility constraints, in comparison to\nstandard FL.",
    "descriptor": "",
    "authors": [
      "Afaf Taik",
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.11271"
  },
  {
    "id": "arXiv:2201.11275",
    "title": "Wireless IoT Energy Sharing Platform",
    "abstract": "Wireless energy sharing is a novel convenient alternative to charge IoT\ndevices. In this demo paper, we present a peer-to-peer wireless energy sharing\nplatform. The platform enables users to exchange energy wirelessly with nearby\nIoT devices. The energy sharing platform allows IoT users to send and receive\nenergy wirelessly. The platform consists of (i) a mobile application that\nmonitors and synchronizes the energy transfer among two IoT devices and (ii)\nand a backend to register energy providers and consumers and store their energy\ntransfer transactions. The eveloped framework allows the collection of a real\nwireless energy sharing dataset. A set of preliminary experiments has been\nconducted on the collected dataset to analyze and demonstrate the behavior of\nthe current wireless energy sharing technology.",
    "descriptor": "\nComments: 3 pages, 3 figures, PERCOM 2022 , Demo Paper\n",
    "authors": [
      "Jessica Yao",
      "Amani Abusafia",
      "Abdallah Lakhdari",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11275"
  },
  {
    "id": "arXiv:2201.11278",
    "title": "Hierarchical Visual Interface for Lecture Video Retrieval and  Summarization",
    "abstract": "With the emergence of large-scale open online courses and online academic\nconferences, it has become increasingly feasible and convenient to access\nonline educational resources. However, it is time consuming and challenging to\neffectively retrieve and present numerous lecture videos for common users. In\nthis work, we propose a hierarchical visual interface for retrieving and\nsummarizing lecture videos. Users can utilize the proposed interface to\neffectively explore the required video information through the results of the\nvideo summary generation in different layers. We retrieve the input keywords\nwith the corresponding video layer with timestamps, a frame layer with slides,\nand the poster layer with summarization of the lecture videos. We verified the\nproposed interface with our user study by comparing it with other conventional\ninterfaces. The results from our user study confirmed that the proposed\ninterface can achieve high retrieval accuracy and good user experience.see\nvideo here https://www.youtube.com/watch?v=zrnejwsOVpc .",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted in Proceedings of International Workshop on Advanced Image Technology 2022\n",
    "authors": [
      "Jiaohao Weng",
      "Chao Zhang",
      "Xi Yang",
      "Haoran Xie"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11278"
  },
  {
    "id": "arXiv:2201.11279",
    "title": "Revisiting RCAN: Improved Training for Image Super-Resolution",
    "abstract": "Image super-resolution (SR) is a fast-moving field with novel architectures\nattracting the spotlight. However, most SR models were optimized with dated\ntraining strategies. In this work, we revisit the popular RCAN model and\nexamine the effect of different training options in SR. Surprisingly (or\nperhaps as expected), we show that RCAN can outperform or match nearly all the\nCNN-based SR architectures published after RCAN on standard benchmarks with a\nproper training strategy and minimal architecture change. Besides, although\nRCAN is a very large SR architecture with more than four hundred convolutional\nlayers, we draw a notable conclusion that underfitting is still the main\nproblem restricting the model capability instead of overfitting. We observe\nsupportive evidence that increasing training iterations clearly improves the\nmodel performance while applying regularization techniques generally degrades\nthe predictions. We denote our simply revised RCAN as RCAN-it and recommend\npractitioners to use it as baselines for future research. Code is publicly\navailable at https://github.com/zudi-lin/rcan-it.",
    "descriptor": "\nComments: 13 pages with 10 tables and 4 figures\n",
    "authors": [
      "Zudi Lin",
      "Prateek Garg",
      "Atmadeep Banerjee",
      "Salma Abdel Magid",
      "Deqing Sun",
      "Yulun Zhang",
      "Luc Van Gool",
      "Donglai Wei",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11279"
  },
  {
    "id": "arXiv:2201.11281",
    "title": "Network slicing for vehicular communications: a multi-agent deep  reinforcement learning approach",
    "abstract": "This paper studies the multi-agent resource allocation problem in vehicular\nnetworks using non-orthogonal multiple access (NOMA) and network slicing. To\nensure heterogeneous service requirements for different vehicles, we propose a\nnetwork slicing architecture. We focus on a non-cellular network scenario where\nvehicles communicate by the broadcast approach via the direct device-to-device\ninterface. In such a vehicular network, resource allocation among vehicles is\nvery difficult, mainly due to (i) the rapid variation of wireless channels\namong highly mobile vehicles and (ii) the lack of a central coordination point.\nThus, the possibility of acquiring instantaneous channel state information to\nperform centralized resource allocation is precluded. The resource allocation\nproblem considered is therefore very complex. It includes not only the usual\nspectrum and power allocation, but also coverage selection (which target\nvehicles to broadcast to) and packet selection (which network slice to use).\nThis problem must be solved jointly since selected packets can be overlaid\nusing NOMA and therefore spectrum and power must be carefully allocated for\nbetter vehicle coverage. To do so, we provide a optimization approach and study\nthe NP-hardness of the problem. Then, we model the problem using multi-agent\nMarkov decision process. Finally, we use a deep reinforcement learning (DRL)\napproach to solve the problem. The proposed DRL algorithm is practical because\nit can be implemented in an online and distributed manner. We show that our\napproach is robust and efficient when faced with different variations of the\nnetwork parameters and compared to centralized benchmarks.",
    "descriptor": "",
    "authors": [
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11281"
  },
  {
    "id": "arXiv:2201.11282",
    "title": "A block triangular preconditioner for a class of three-by-three block  saddle point problems",
    "abstract": "This paper deals with solving a class of three-by-three block saddle point\nproblems. The systems are solved by preconditioning techniques. Based on an\niterative method, we construct a block upper triangular preconditioner. The\nconvergence of the presented method is studied in details. Finally, some\nnumerical experiments are given to demonstrate the superiority of the proposed\npreconditioner over some existing ones.",
    "descriptor": "\nComments: 13 pages, submitted\n",
    "authors": [
      "Hamed Aslani",
      "Davod Khojasteh Salkuyeh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11282"
  },
  {
    "id": "arXiv:2201.11284",
    "title": "Interactive 3D Character Modeling from 2D Orthogonal Drawings with  Annotations",
    "abstract": "We propose an interactive 3D character modeling approach from orthographic\ndrawings (e.g., front and side views) based on 2D-space annotations. First, the\nsystem builds partial correspondences between the input drawings and generates\na base mesh with sweeping splines according to edge information in 2D images.\nNext, users annotates the desired parts on the input drawings (e.g., the eyes\nand mouth) by using two type of strokes, called addition and erosion, and the\nsystem re-optimizes the shape of the base mesh. By repeating the 2D-space\noperations (i.e., revising and modifying the annotations), users can design a\ndesired character model. To validate the efficiency and quality of our system,\nwe verified the generated results with state-of-the-art methods.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted in Proceedings of International Workshop on Advanced Image Technology 2022\n",
    "authors": [
      "Zhengyu Huang",
      "Haoran Xie",
      "Tsukasa Fukusato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.11284"
  },
  {
    "id": "arXiv:2201.11287",
    "title": "Sketch-based 3D Shape Modeling from Sparse Point Clouds",
    "abstract": "3D modeling based on point clouds is an efficient way to reconstruct and\ncreate detailed 3D content. However, the geometric procedure may lose accuracy\ndue to high redundancy and the absence of an explicit structure. In this work,\nwe propose a human-in-the-loop sketch-based point cloud reconstruction\nframework to leverage users cognitive abilities in geometry extraction. We\npresent an interactive drawing interface for 3D model creation from point cloud\ndata with the help of user sketches. We adopt an optimization method in which\nthe user can continuously edit the contours extracted from the obtained 3D\nmodel and retrieve the model iteratively. Finally, we verify the proposed user\ninterface for modeling from sparse point clouds. see video here\nhttps://www.youtube.com/watch?v=0H19NyXDRJE .",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted in Proceedings of International Workshop on Advanced Image Technology 2022\n",
    "authors": [
      "Xusheng Du",
      "Yi He",
      "Xi Yang",
      "Chia-Ming Chang",
      "Haoran Xie"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11287"
  },
  {
    "id": "arXiv:2201.11290",
    "title": "Stock2Vec: An Embedding to Improve Predictive Models for Companies",
    "abstract": "Building predictive models for companies often relies on inference using\nhistorical data of companies in the same industry sector. However, companies\nare similar across a variety of dimensions that should be leveraged in relevant\nprediction problems. This is particularly true for large, complex organizations\nwhich may not be well defined by a single industry and have no clear peers. To\nenable prediction using company information across a variety of dimensions, we\ncreate an embedding of company stocks, Stock2Vec, which can be easily added to\nany prediction model that applies to companies with associated stock prices. We\ndescribe the process of creating this rich vector representation from stock\nprice fluctuations, and characterize what the dimensions represent. We then\nconduct comprehensive experiments to evaluate this embedding in applied machine\nlearning problems in various business contexts. Our experiment results\ndemonstrate that the four features in the Stock2Vec embedding can readily\naugment existing cross-company models and enhance cross-company predictions.",
    "descriptor": "",
    "authors": [
      "Ziruo Yi",
      "Ting Xiao",
      "Kaz-Onyeakazi Ijeoma",
      "Ratnam Cheran",
      "Yuvraj Baweja",
      "Phillip Nelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11290"
  },
  {
    "id": "arXiv:2201.11291",
    "title": "SoK: An Overview of PPG's Application in Authentication",
    "abstract": "Biometric authentication prospered during the 2010s. Vulnerability to\nspoofing attacks remains an inherent problem with traditional biometrics.\nRecently, unobservable physiological signals (e.g., Electroencephalography,\nPhotoplethysmography, Electrocardiography) as biometrics have been considered a\npotential solution to this problem. In particular, Photoplethysmography (PPG)\nmeasures the change of blood flow of the human body by an optical method.\nClinically, researchers commonly use PPG signals to obtain patients' blood\noxygen saturation, heart rate, and other information to assist in diagnosing\nheart-related diseases. Since PPG signals are easy to obtain and contain a\nwealth of individual cardiac information, researchers have begun to explore its\npotential applications in information security. The unique advantages (simple\nacquisition, difficult to steal, and live detection) of the PPG signal allow it\nto improve the security and usability of the authentication in various aspects.\nHowever, the research on PPG-based authentication is still in its infancy. The\nlack of systematization hinders new research in this field. We conduct a\ncomprehensive study of PPG-based authentication and discuss these applications'\nlimitations before pointing out future research directions.",
    "descriptor": "",
    "authors": [
      "Lin Li",
      "Chao Chen",
      "Lei Pan",
      "Jun Zhang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11291"
  },
  {
    "id": "arXiv:2201.11292",
    "title": "Excavation Reinforcement Learning Using Geometric Representation",
    "abstract": "Excavation of irregular rigid objects in clutter, such as fragmented rocks\nand wood blocks, is very challenging due to their complex interaction dynamics\nand highly variable geometries. In this paper, we adopt reinforcement learning\n(RL) to tackle this challenge and learn policies to plan for a sequence of\nexcavation trajectories for irregular rigid objects, given point clouds of\nexcavation scenes. Moreover, we separately learn a compact representation of\nthe point cloud on geometric tasks that do not require human labeling. We show\nthat using the representation reduces training time for RL, while achieving\nsimilar asymptotic performance compare to an end-to-end RL algorithm. When\nusing a policy trained in simulation directly on a real scene, we show that the\npolicy trained with the representation outperforms end-to-end RL. To our best\nknowledge, this paper presents the first application of RL to plan a sequence\nof excavation trajectories of irregular rigid objects in clutter.",
    "descriptor": "",
    "authors": [
      "Qingkai Lu",
      "Yifan Zhu",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11292"
  },
  {
    "id": "arXiv:2201.11294",
    "title": "Highly Generalizable Models for Multilingual Hate Speech Detection",
    "abstract": "Hate speech detection has become an important research topic within the past\ndecade. More private corporations are needing to regulate user generated\ncontent on different platforms across the globe. In this paper, we introduce a\nstudy of multilingual hate speech classification. We compile a dataset of 11\nlanguages and resolve different taxonomies by analyzing the combined data with\nbinary labels: hate speech or not hate speech. Defining hate speech in a single\nway across different languages and datasets may erase cultural nuances to the\ndefinition, therefore, we utilize language agnostic embeddings provided by\nLASER and MUSE in order to develop models that can use a generalized definition\nof hate speech across datasets. Furthermore, we evaluate prior state of the art\nmethodologies for hate speech detection under our expanded dataset. We conduct\nthree types of experiments for a binary hate speech classification task:\nMultilingual-Train Monolingual-Test, MonolingualTrain Monolingual-Test and\nLanguage-Family-Train Monolingual Test scenarios to see if performance\nincreases for each language due to learning more from other language data.",
    "descriptor": "",
    "authors": [
      "Neha Deshpande",
      "Nicholas Farris",
      "Vidhur Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11294"
  },
  {
    "id": "arXiv:2201.11295",
    "title": "Network Slicing with MEC and Deep Reinforcement Learning for the  Internet of Vehicles",
    "abstract": "The interconnection of vehicles in the future fifth generation (5G) wireless\necosystem forms the so-called Internet of vehicles (IoV). IoV offers new kinds\nof applications requiring delay-sensitive, compute-intensive and\nbandwidth-hungry services. Mobile edge computing (MEC) and network slicing (NS)\nare two of the key enabler technologies in 5G networks that can be used to\noptimize the allocation of the network resources and guarantee the diverse\nrequirements of IoV applications.\nAs traditional model-based optimization techniques generally end up with\nNP-hard and strongly non-convex and non-linear mathematical programming\nformulations, in this paper, we introduce a model-free approach based on deep\nreinforcement learning (DRL) to solve the resource allocation problem in\nMEC-enabled IoV network based on network slicing. Furthermore, the solution\nuses non-orthogonal multiple access (NOMA) to enable a better exploitation of\nthe scarce channel resources. The considered problem addresses jointly the\nchannel and power allocation, the slice selection and the vehicles selection\n(vehicles grouping). We model the problem as a single-agent Markov decision\nprocess. Then, we solve it using DRL using the well-known DQL algorithm. We\nshow that our approach is robust and effective under different network\nconditions compared to benchmark solutions.",
    "descriptor": "",
    "authors": [
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11295"
  },
  {
    "id": "arXiv:2201.11296",
    "title": "Efficient divide-and-conquer registration of UAV and ground LiDAR point  clouds through canopy shape context",
    "abstract": "Registration of unmanned aerial vehicle laser scanning (ULS) and ground light\ndetection and ranging (LiDAR) point clouds in forests is critical to create a\ndetailed representation of a forest structure and an accurate inversion of\nforest parameters. However, forest occlusion poses challenges for marker-based\nregistration methods, and some marker-free automated registration methods have\nlow efficiency due to the process of object (e.g., tree, crown) segmentation.\nTherefore, we use a divide-and-conquer strategy and propose an automated and\nefficient method to register ULS and ground LiDAR point clouds in forests.\nRegistration involves coarse alignment and fine registration, where the coarse\nalignment of point clouds is divided into vertical and horizontal alignment.\nThe vertical alignment is achieved by ground alignment, which is achieved by\nthe transformation relationship between normal vectors of the ground point\ncloud and the horizontal plane, and the horizontal alignment is achieved by\ncanopy projection image matching. During image matching, vegetation points are\nfirst distinguished by the ground filtering algorithm, and then, vegetation\npoints are projected onto the horizontal plane to obtain two binary images. To\nmatch the two images, a matching strategy is used based on canopy shape context\nfeatures, which are described by a two-point congruent set and canopy overlap.\nFinally, we implement coarse alignment of ULS and ground LiDAR datasets by\ncombining the results of ground alignment and image matching and finish fine\nregistration. Also, the effectiveness, accuracy, and efficiency of the proposed\nmethod are demonstrated by field measurements of forest plots. Experimental\nresults show that the ULS and ground LiDAR data in different plots are\nregistered, of which the horizontal alignment errors are less than 0.02 m, and\nthe average runtime of the proposed method is less than 1 second.",
    "descriptor": "",
    "authors": [
      "Jie Shao",
      "Wei Yao",
      "Peng Wan",
      "Lei Luo",
      "Jiaxin Lyu",
      "Wuming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11296"
  },
  {
    "id": "arXiv:2201.11297",
    "title": "Generation Matrix: An Embeddable Matrix Representation for Hierarchical  Trees",
    "abstract": "Starting from the local structures to study hierarchical trees is a common\nresearch method. However, the cumbersome analysis and description make the\nnaive method challenging to adapt to the increasingly complex hierarchical tree\nproblems. To improve the efficiency of hierarchical tree research, we propose\nan embeddable matrix representation for hierarchical trees, called Generation\nMatrix. It can transform the abstract hierarchical tree into a concrete matrix\nrepresentation and then take the hierarchical tree as a whole to study, which\ndramatically reduces the complexity of research. Mathematical analysis shows\nthat Generation Matrix can simulate various recursive algorithms without\naccessing local structures and provides a variety of interpretable matrix\noperations to support the research of hierarchical trees. Applying Generation\nMatrix to differential privacy hierarchical tree release, we propose a\nGeneration Matrix-based optimally consistent release algorithm (GMC). It\nprovides an exceptionally concise process description so that we can describe\nits core steps as a simple matrix expression rather than multiple complicated\nrecursive processes like existing algorithms. Our experiments show that GMC\ntakes only a few seconds to complete a release for large-scale datasets with\nmore than 10 million nodes. The calculation efficiency is increased by up to\n100 times compared with the state-of-the-art schemes.",
    "descriptor": "\nComments: 25 pages, 10 figures\n",
    "authors": [
      "Jianping Cai",
      "Ximeng Liu",
      "Jiayin Li",
      "Shuangyue Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11297"
  },
  {
    "id": "arXiv:2201.11299",
    "title": "Iteratively Weighted MMSE Uplink Precoding for Cell-Free Massive MIMO",
    "abstract": "In this paper, we investigate a cell-free massive MIMO system with both\naccess points and user equipments equipped with multiple antennas over the\nWeichselberger Rayleigh fading channel. We study the uplink spectral efficiency\n(SE) based on a two-layer decoding structure with maximum ratio (MR) or local\nminimum mean-square error (MMSE) combining applied in the first layer and\noptimal large-scale fading decoding method implemented in the second layer,\nrespectively. To maximize the weighted sum SE, an uplink precoding structure\nbased on an Iteratively Weighted sum-MMSE (I-WMMSE) algorithm using only\nchannel statistics is proposed. Furthermore, with MR combining applied in the\nfirst layer, we derive novel achievable SE expressions and optimal precoding\nstructures in closed-form. Numerical results validate our proposed results and\nshow that the I-WMMSE precoding can achieve excellent sum SE performance.",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted by IEEE ICC 2022\n",
    "authors": [
      "Zhe Wang",
      "Jiayi Zhang",
      "Hien Quoc Ngo",
      "Bo Ai",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11299"
  },
  {
    "id": "arXiv:2201.11300",
    "title": "Geo-indistinguishable Mechanisms for Spatial Crowdsourcing via  Multi-Objective Evolutionary Optimization",
    "abstract": "Industrial Internet of Things (IIoT) has exploded key revolutions in several\nleading industries, such as energy, agriculture, mining, transportation, and\nhealthcare. Due to the nature of high capacity and fast transmission speed, 5G\nplays a pivot role in enhancing the industrial procedures, practices and\nguidelines, such as crowdsourcing, cloud outsourcing and platform\nsubcontracting. Spatial crowdsourcing (SC)-servers (such as offered by DiDi,\nMeiTuan and Uber) assign different tasks based on workers' location\ninformation.However, SC-servers are often untrustworthy and have the threat of\nrevealing workers' privacy. In this paper, we introduce a framework Geo-MOEA\n(Multi-Objective Evolutionary Algorithm) to protect location privacy of workers\ninvolved on SC platform in 5G environment. We propose an adaptive regionalized\nobfuscation mechanism with inference error bounds based on\ngeo-indistinguishability (a strong notion of differential privacy), which is\nsuitable for the context of large-scale location data and task allocations.\nThis offers locally generated pseudo-locations of workers to be reported\ninstead of their actual locations.Further, to optimize the trade-off between SC\nservice availability and privacy protection, we utilize MOEA to improve the\nglobal applicability of the mechanism in 5G environment. Finally, by simulating\nthe location scenario, the visual results on experiments show that the\nmechanism can not only protect location privacy, but also achieve high\navailability of services as desired.",
    "descriptor": "",
    "authors": [
      "Shun Zhang",
      "Tao Zhang",
      "Stan Z. Li",
      "Shenghui Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11300"
  },
  {
    "id": "arXiv:2201.11302",
    "title": "Wireless Energy Transfer in RIS-Aided Cell-Free Massive MIMO Systems:  Opportunities and Challenges",
    "abstract": "In future sixth-generation (6G) mobile networks, the Internet-of-Everything\n(IoE) is expected to provide extremely massive connectivity for small\nbattery-powered devices. Indeed, massive devices with limited energy storage\ncapacity impose persistent energy demand hindering the lifetime of\ncommunication networks. As a remedy, wireless energy transfer (WET) is a key\ntechnology to address these critical energy supply issues. On the other hand,\ncell-free (CF) massive multiple-input multiple-output (MIMO) systems offer an\nefficient network architecture to realize the roll-out of the IoE. In this\narticle, we first propose the paradigm of reconfigurable intelligent surface\n(RIS)-aided CF massive MIMO systems for WET, including its potential\napplication scenarios and system architecture. The four-stage transmission\nprocedure is discussed and analyzed to illustrate the practicality of the\narchitecture. Then we put forward and analyze the hardware design of RIS.\nParticularly, we discuss the three corresponding operating modes and the\namalgamation of WET technology and RIS-aided CF massive MIMO. Representative\nsimulation results are given to confirm the superior performance achieved by\nour proposed schemes. Also, we investigate the optimal location of deploying\nmultiple RISs to achieve the best system performance. Finally, several\nimportant research directions of RIS-aided CF massive MIMO systems with WET are\npresented to inspire further potential investigation.",
    "descriptor": "",
    "authors": [
      "Enyu Shi",
      "Jiayi Zhang",
      "Shuaifei Chen",
      "Jiakang Zheng",
      "Yan Zhang",
      "Derrick Wing Kwan Ng",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11302"
  },
  {
    "id": "arXiv:2201.11303",
    "title": "Mutation Analysis: Answering the Fuzzing Challenge",
    "abstract": "Fuzzing is one of the fastest growing fields in software testing. The idea\nbehind fuzzing is to check the behavior of software against a large number of\nrandomly generated inputs, trying to cover all interesting parts of the input\nspace, while observing the tested software for anomalous behaviour. One of the\nbiggest challenges facing fuzzer users is how to validate software behavior,\nand how to improve the quality of oracles used. While mutation analysis is the\npremier technique for evaluating the quality of software test oracles, mutation\nscore is rarely used as a metric for evaluating fuzzer quality. Unless mutation\nanalysis researchers can solve multiple problems that make applying mutation\nanalysis to fuzzing challenging, mutation analysis may be permanently sidelined\nin one of the most important areas of testing and security research. This paper\nattempts to understand the main challenges in applying mutation analysis for\nevaluating fuzzers, so that researchers can focus on solving these challenges.",
    "descriptor": "",
    "authors": [
      "Rahul Gopinath",
      "Philipp G\u00f6rz",
      "Alex Groce"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11303"
  },
  {
    "id": "arXiv:2201.11305",
    "title": "The Quadratic Wasserstein Metric With Squaring Scaling For Seismic  Velocity Inversion",
    "abstract": "The quadratic Wasserstein metric has shown its power in measuring the\ndifference between probability densities, which benefits optimization objective\nfunction with better convexity and is insensitive to data noise. Nevertheless,\nit is always an important question to make the seismic signals suitable for\ncomparison using the quadratic Wasserstein metric. The squaring scaling is\nworth exploring since it guarantees the convexity caused by data shift.\nHowever, as mentioned in [Commun. Inf. Syst., 2019, 19:95-145], the squaring\nscaling may lose uniqueness and result in more local minima to the misfit\nfunction. In our previous work [J. Comput. Phys., 2018, 373:188-209], the\nquadratic Wasserstein metric with squaring scaling was successfully applied to\nthe earthquake location problem. But it only discussed the inverse problem with\nfew degrees of freedom. In this work, we will present a more in-depth study on\nthe combination of squaring scaling technique and the quadratic Wasserstein\nmetric. By discarding some inapplicable data, picking seismic phases, and\ndeveloping a new normalization method, we successfully invert the seismic\nvelocity structure based on the squaring scaling technique and the quadratic\nWasserstein metric. The numerical experiments suggest that this newly proposed\nmethod is an efficient approach to obtain more accurate inversion results.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Zhengyang Li",
      "Yijia Tang",
      "Jing Chen",
      "Hao Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11305"
  },
  {
    "id": "arXiv:2201.11307",
    "title": "Dissecting the impact of different loss functions with gradient surgery",
    "abstract": "Pair-wise loss is an approach to metric learning that learns a semantic\nembedding by optimizing a loss function that encourages images from the same\nsemantic class to be mapped closer than images from different classes. The\nliterature reports a large and growing set of variations of the pair-wise loss\nstrategies. Here we decompose the gradient of these loss functions into\ncomponents that relate to how they push the relative feature positions of the\nanchor-positive and anchor-negative pairs. This decomposition allows the\nunification of a large collection of current pair-wise loss functions.\nAdditionally, explicitly constructing pair-wise gradient updates to separate\nout these effects gives insights into which have the biggest impact, and leads\nto a simple algorithm that beats the state of the art for image retrieval on\nthe CAR, CUB and Stanford Online products datasets.",
    "descriptor": "",
    "authors": [
      "Hong Xuan",
      "Robert Pless"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11307"
  },
  {
    "id": "arXiv:2201.11308",
    "title": "Calibration with Privacy in Peer Review",
    "abstract": "Reviewers in peer review are often miscalibrated: they may be strict,\nlenient, extreme, moderate, etc. A number of algorithms have previously been\nproposed to calibrate reviews. Such attempts of calibration can however leak\nsensitive information about which reviewer reviewed which paper. In this paper,\nwe identify this problem of calibration with privacy, and provide a\nfoundational building block to address it. Specifically, we present a\ntheoretical study of this problem under a simplified-yet-challenging model\ninvolving two reviewers, two papers, and an MAP-computing adversary. Our main\nresults establish the Pareto frontier of the tradeoff between privacy\n(preventing the adversary from inferring reviewer identity) and utility\n(accepting better papers), and design explicit computationally-efficient\nalgorithms that we prove are Pareto optimal.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Wenxin Ding",
      "Gautam Kamath",
      "Weina Wang",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11308"
  },
  {
    "id": "arXiv:2201.11311",
    "title": "Towards a Secure and Reliable Federated Learning using Blockchain",
    "abstract": "Federated learning (FL) is a distributed machine learning (ML) technique that\nenables collaborative training in which devices perform learning using a local\ndataset while preserving their privacy. This technique ensures privacy,\ncommunication efficiency, and resource conservation. Despite these advantages,\nFL still suffers from several challenges related to reliability (i.e.,\nunreliable participating devices in training), tractability (i.e., a large\nnumber of trained models), and anonymity. To address these issues, we propose a\nsecure and trustworthy blockchain framework (SRB-FL) tailored to FL, which uses\nblockchain features to enable collaborative model training in a fully\ndistributed and trustworthy manner. In particular, we design a secure FL based\non the blockchain sharding that ensures data reliability, scalability, and\ntrustworthiness. In addition, we introduce an incentive mechanism to improve\nthe reliability of FL devices using subjective multi-weight logic. The results\nshow that our proposed SRB-FL framework is efficient and scalable, making it a\npromising and suitable solution for federated learning.",
    "descriptor": "\nComments: This paper has been accepted for publication by IEEE Global Communications Conference (GLOBECOM). The final version will be published by the IEEE\n",
    "authors": [
      "Hajar Moudoud",
      "Soumaya Cherkaoui",
      "Lyes Khoukhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11311"
  },
  {
    "id": "arXiv:2201.11312",
    "title": "A Higher-Order Semantic Dependency Parser",
    "abstract": "Higher-order features bring significant accuracy gains in semantic dependency\nparsing. However, modeling higher-order features with exact inference is\nNP-hard. Graph neural networks (GNNs) have been demonstrated to be an effective\ntool for solving NP-hard problems with approximate inference in many graph\nlearning tasks. Inspired by the success of GNNs, we investigate building a\nhigher-order semantic dependency parser by applying GNNs. Instead of explicitly\nextracting higher-order features from intermediate parsing graphs, GNNs\naggregate higher-order information concisely by stacking multiple GNN layers.\nExperimental results show that our model outperforms the previous\nstate-of-the-art parser on the SemEval 2015 Task 18 English datasets.",
    "descriptor": "",
    "authors": [
      "Bin Li",
      "Yunlong Fan",
      "Yikemaiti Sataer",
      "Zhiqiang Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11312"
  },
  {
    "id": "arXiv:2201.11313",
    "title": "Learning Deep Semantic Model for Code Search using CodeSearchNet Corpus",
    "abstract": "Semantic code search is the task of retrieving relevant code snippet given a\nnatural language query. Different from typical information retrieval tasks,\ncode search requires to bridge the semantic gap between the programming\nlanguage and natural language, for better describing intrinsic concepts and\nsemantics. Recently, deep neural network for code search has been a hot\nresearch topic. Typical methods for neural code search first represent the code\nsnippet and query text as separate embeddings, and then use vector distance\n(e.g. dot-product or cosine) to calculate the semantic similarity between them.\nThere exist many different ways for aggregating the variable length of code or\nquery tokens into a learnable embedding, including bi-encoder, cross-encoder,\nand poly-encoder. The goal of the query encoder and code encoder is to produce\nembeddings that are close with each other for a related pair of query and the\ncorresponding desired code snippet, in which the choice and design of encoder\nis very significant.\nIn this paper, we propose a novel deep semantic model which makes use of the\nutilities of not only the multi-modal sources, but also feature extractors such\nas self-attention, the aggregated vectors, combination of the intermediate\nrepresentations. We apply the proposed model to tackle the CodeSearchNet\nchallenge about semantic code search. We align cross-lingual embedding for\nmulti-modality learning with large batches and hard example mining, and combine\ndifferent learned representations for better enhancing the representation\nlearning. Our model is trained on CodeSearchNet corpus and evaluated on the\nheld-out data, the final model achieves 0.384 NDCG and won the first place in\nthis benchmark. Models and code are available at\nhttps://github.com/overwindows/SemanticCodeSearch.git.",
    "descriptor": "",
    "authors": [
      "Chen Wu",
      "Ming Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11313"
  },
  {
    "id": "arXiv:2201.11316",
    "title": "Transformer Module Networks for Systematic Generalization in Visual  Question Answering",
    "abstract": "Transformer-based models achieve great performance on Visual Question\nAnswering (VQA). However, when we evaluate them on systematic generalization,\ni.e., handling novel combinations of known concepts, their performance\ndegrades. Neural Module Networks (NMNs) are a promising approach for systematic\ngeneralization that consists on composing modules, i.e., neural networks that\ntackle a sub-task. Inspired by Transformers and NMNs, we propose Transformer\nModule Network (TMN), a novel Transformer-based model for VQA that dynamically\ncomposes modules into a question-specific Transformer network. TMNs achieve\nstate-of-the-art systematic generalization performance in three VQA datasets,\nnamely, CLEVR-CoGenT, CLOSURE and GQA-SGL, in some cases improving more than\n30% over standard Transformers.",
    "descriptor": "",
    "authors": [
      "Moyuru Yamada",
      "Vanessa D'Amario",
      "Kentaro Takemoto",
      "Xavier Boix",
      "Tomotake Sasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11316"
  },
  {
    "id": "arXiv:2201.11319",
    "title": "Dynamic Rectification Knowledge Distillation",
    "abstract": "Knowledge Distillation is a technique which aims to utilize dark knowledge to\ncompress and transfer information from a vast, well-trained neural network\n(teacher model) to a smaller, less capable neural network (student model) with\nimproved inference efficiency. This approach of distilling knowledge has gained\npopularity as a result of the prohibitively complicated nature of such\ncumbersome models for deployment on edge computing devices. Generally, the\nteacher models used to teach smaller student models are cumbersome in nature\nand expensive to train. To eliminate the necessity for a cumbersome teacher\nmodel completely, we propose a simple yet effective knowledge distillation\nframework that we termed Dynamic Rectification Knowledge Distillation (DR-KD).\nOur method transforms the student into its own teacher, and if the self-teacher\nmakes wrong predictions while distilling information, the error is rectified\nprior to the knowledge being distilled. Specifically, the teacher targets are\ndynamically tweaked by the agency of ground-truth while distilling the\nknowledge gained from traditional training. Our proposed DR-KD performs\nremarkably well in the absence of a sophisticated cumbersome teacher model and\nachieves comparable performance to existing state-of-the-art teacher-free\nknowledge distillation frameworks when implemented by a low-cost dynamic\nmannered teacher. Our approach is all-encompassing and can be utilized for any\ndeep neural network training that requires categorization or object\nrecognition. DR-KD enhances the test accuracy on Tiny ImageNet by 2.65% over\nprominent baseline models, which is significantly better than any other\nknowledge distillation approach while requiring no additional training costs.",
    "descriptor": "",
    "authors": [
      "Fahad Rahman Amik",
      "Ahnaf Ismat Tasin",
      "Silvia Ahmed",
      "M. M. Lutfe Elahi",
      "Nabeel Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11319"
  },
  {
    "id": "arXiv:2201.11324",
    "title": "Efficient Distributed Learning in Stochastic Non-cooperative Games  without Information Exchange",
    "abstract": "In this work, we study stochastic non-cooperative games, where only noisy\nblack-box function evaluations are available to estimate the cost function for\neach player. Since each player's cost function depends on both its own decision\nvariables and its rivals' decision variables, local information needs to be\nexchanged through a center/network in most existing work for seeking the Nash\nequilibrium. We propose a new stochastic distributed learning algorithm that\ndoes not require communications among players. The proposed algorithm uses\nsimultaneous perturbation method to estimate the gradient of each cost\nfunction, and uses mirror descent method to search for the Nash equilibrium. We\nprovide asymptotic analysis for the bias and variance of gradient estimates,\nand show the proposed algorithm converges to the Nash equilibrium in mean\nsquare for the class of strictly monotone games at a rate faster than the\nexisting algorithms. The effectiveness of the proposed method is buttressed in\na numerical experiment.",
    "descriptor": "",
    "authors": [
      "Haidong Li",
      "Anzhi Sheng",
      "Yijie Peng",
      "Long Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.11324"
  },
  {
    "id": "arXiv:2201.11326",
    "title": "High-order Line Graphs of Non-uniform Hypergraphs: Algorithms,  Applications, and Experimental Analysis",
    "abstract": "Hypergraphs offer flexible and robust data representations for many\napplications, but methods that work directly on hypergraphs are not readily\navailable and tend to be prohibitively expensive. Much of the current analysis\nof hypergraphs relies on first performing a graph expansion -- either based on\nthe nodes (clique expansion), or on the edges (line graph) -- and then running\nstandard graph analytics on the resulting representative graph. However, this\napproach suffers from massive space complexity and high computational cost with\nincreasing hypergraph size. Here, we present efficient, parallel algorithms to\naccelerate and reduce the memory footprint of higher-order graph expansions of\nhypergraphs. Our results focus on the edge-based $s$-line graph expansion, but\nthe methods we develop work for higher-order clique expansions as well. To the\nbest of our knowledge, ours is the first framework to enable hypergraph\nspectral analysis of a large dataset on a single shared-memory machine. Our\nmethods enable the analysis of datasets from many domains that previous\ngraph-expansion-based models are unable to provide. The proposed $s$-line graph\ncomputation algorithms are orders of magnitude faster than state-of-the-art\nsparse general matrix-matrix multiplication methods, and obtain approximately\n$5-31{\\times}$ speedup over a prior state-of-the-art heuristic-based algorithm\nfor $s$-line graph computation.",
    "descriptor": "\nComments: Accepted at \"36th IEEE International Parallel & Distributed Processing Symposium (IPDPS '22)\"\n",
    "authors": [
      "Xu T. Liu",
      "Jesun Firoz",
      "Sinan Aksoy",
      "Ilya Amburg",
      "Andrew Lumsdaine",
      "Cliff Joslyn",
      "Assefaw H. Gebremedhin",
      "Brenda Praggastis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.11326"
  },
  {
    "id": "arXiv:2201.11327",
    "title": "Aspect-Based API Review Classification: How Far Can Pre-Trained  Transformer Model Go?",
    "abstract": "APIs (Application Programming Interfaces) are reusable software libraries and\nare building blocks for modern rapid software development. Previous research\nshows that programmers frequently share and search for reviews of APIs on the\nmainstream software question and answer (Q&A) platforms like Stack Overflow,\nwhich motivates researchers to design tasks and approaches related to process\nAPI reviews automatically. Among these tasks, classifying API reviews into\ndifferent aspects (e.g., performance or security), which is called the\naspect-based API review classification, is of great importance. The current\nstate-of-the-art (SOTA) solution to this task is based on the traditional\nmachine learning algorithm. Inspired by the great success achieved by\npre-trained models on many software engineering tasks, this study fine-tunes\nsix pre-trained models for the aspect-based API review classification task and\ncompares them with the current SOTA solution on an API review benchmark\ncollected by Uddin et al. The investigated models include four models (BERT,\nRoBERTa, ALBERT and XLNet) that are pre-trained on natural languages,\nBERTOverflow that is pre-trained on text corpus extracted from posts on Stack\nOverflow, and CosSensBERT that is designed for handling imbalanced data. The\nresults show that all the six fine-tuned models outperform the traditional\nmachine learning-based tool. More specifically, the improvement on the F1-score\nranges from 21.0% to 30.2%. We also find that BERTOverflow, a model pre-trained\non the corpus from Stack Overflow, does not show better performance than BERT.\nThe result also suggests that CosSensBERT also does not exhibit better\nperformance than BERT in terms of F1, but it is still worthy of being\nconsidered as it achieves better performance on MCC and AUC.",
    "descriptor": "\nComments: Accepted by Research Track in SANER 2022\n",
    "authors": [
      "chengran Yang",
      "Bowen Xu",
      "Junaed younus Khan",
      "Gias Uddin",
      "Donggyun Han",
      "Zhou Yang",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11327"
  },
  {
    "id": "arXiv:2201.11330",
    "title": "IMEXLBM 1.0: A Proxy Application based on the Lattice Boltzmann Method  for solving Computational Fluid Dynamic problems on GPUs",
    "abstract": "The US Department of Energy launched the Exascale Computing Project (ECP) in\n2016 as part of a coordinated effort to achieve the next generation of\nhigh-performance computing (HPC) and to accelerate scientific discovery. The\nExascale Proxy Applications Project began within the ECP to: (1) improve the\nquality of proxies created by the ECP (2) provide small, simplified codes which\nshare important features of large applications and (3) capture programming\nmethods and styles that drive requirements for compilers and other elements of\nthe tool chain. This article describes one Proxy Application (or \"proxy app\")\nsuite called IMEXLBM which is an open-source, self-contained code unit, with\nminimal dependencies, that is capable of running on heterogeneous platforms\nlike those with graphic processing units (GPU) for accelerating the\ncalculation. In particular, we demonstrate functionality by solving a benchmark\nproblem in computational fluid dynamics (CFD) on the ThetaGPU machine at the\nArgonne Leadership Computing Facility (ALCF). Our method makes use of a\ndomain-decomposition technique in conjunction with the message-passing\ninterface (MPI) standard for distributed memory systems. The OpenMP application\nprogramming interface (API) is employed for shared-memory multi-processing and\noffloading critical kernels to the device (i.e. GPU). We also verify our effort\nby comparing data generated via CPU-only calculations with data generated with\nCPU+GPU calculations. While we demonstrate efficacy for single-phase fluid\nproblems, the code-unit is designed to be versatile and enable new physical\nmodels that can capture complex phenomena such as two-phase flow with interface\ncapture.",
    "descriptor": "",
    "authors": [
      "Geng Liu",
      "Saumil Patel",
      "Ramesh Balakrishnan",
      "Taehun Lee"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.11330"
  },
  {
    "id": "arXiv:2201.11331",
    "title": "Epistemic AI platform accelerates innovation by connecting biomedical  knowledge",
    "abstract": "Epistemic AI accelerates biomedical discovery by finding hidden connections\nin the network of biomedical knowledge. The Epistemic AI web-based software\nplatform embodies the concept of knowledge mapping, an interactive process that\nrelies on a knowledge graph in combination with natural language processing\n(NLP), information retrieval, relevance feedback, and network analysis.\nKnowledge mapping reduces information overload, prevents costly mistakes, and\nminimizes missed opportunities in the research process. The platform combines\nstate-of-the-art methods for information extraction with machine learning,\nartificial intelligence and network analysis. Starting from a single biological\nentity, such as a gene or disease, users may: a) construct a map of connections\nto that entity, b) map an entire domain of interest, and c) gain insight into\nlarge biological networks of knowledge. Knowledge maps provide clarity and\norganization, simplifying the day-to-day research processes.",
    "descriptor": "\nComments: 12 pages, 2 main figures\n",
    "authors": [
      "Emily Koo",
      "Heather Bowling",
      "Kenneth Ashworth",
      "David J. Heeger",
      "Stefano Pacifico"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11331"
  },
  {
    "id": "arXiv:2201.11332",
    "title": "Ontology-enhanced Prompt-tuning for Few-shot Learning",
    "abstract": "Few-shot Learning (FSL) is aimed to make predictions based on a limited\nnumber of samples. Structured data such as knowledge graphs and ontology\nlibraries has been leveraged to benefit the few-shot setting in various tasks.\nHowever, the priors adopted by the existing methods suffer from challenging\nknowledge missing, knowledge noise, and knowledge heterogeneity, which hinder\nthe performance for few-shot learning. In this study, we explore knowledge\ninjection for FSL with pre-trained language models and propose\nontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the\nontology transformation based on the external knowledge graph to address the\nknowledge missing issue, which fulfills and converts structure knowledge to\ntext. We further introduce span-sensitive knowledge injection via a visible\nmatrix to select informative knowledge to handle the knowledge noise issue. To\nbridge the gap between knowledge and text, we propose a collective training\nalgorithm to optimize representations jointly. We evaluate our proposed\nOntoPrompt in three tasks, including relation extraction, event extraction, and\nknowledge graph completion, with eight datasets. Experimental results\ndemonstrate that our approach can obtain better few-shot performance than\nbaselines.",
    "descriptor": "\nComments: Accepted by WWW2022\n",
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Shumin Deng",
      "Xiang Chen",
      "Hui Chen",
      "Feiyu Xiong",
      "Xi Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11332"
  },
  {
    "id": "arXiv:2201.11335",
    "title": "On the Convergence of Orthogonal/Vector AMP: Long-Memory Message-Passing  Strategy",
    "abstract": "This paper proves the convergence of Bayes-optimal orthogonal/vector\napproximate message-passing (AMP) to a fixed point (FP) in the large system\nlimit. The proof is based on Bayes-optimal long-memory (LM) message-passing\n(MP) that converges in principle. The dynamics of Bayes-optimal LM-MP is\nanalyzed via an existing state evolution framework. The obtained state\nevolution recursions are proved to converge. The convergence of Bayes-optimal\northogonal/vector AMP is proved by confirming an exact reduction of the state\nevolution recursions to those for Bayes-optimal orthogonal/vector AMP.",
    "descriptor": "\nComments: submitted to ISIT2022\n",
    "authors": [
      "Keigo Takeuchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11335"
  },
  {
    "id": "arXiv:2201.11337",
    "title": "Towards a Scalable and Trustworthy Blockchain: IoT Use Case",
    "abstract": "Recently, blockchain has gained momentum as a novel technology that gives\nrise to a plethora of new decentralized applications (e.g., Internet of Things\n(IoT)). However, its integration with the IoT is still facing several problems\n(e.g., scalability, flexibility). Provisioning resources to enable a large\nnumber of connected IoT devices implies having a scalable and flexible\nblockchain. To address these issues, we propose a scalable and trustworthy\nblockchain (STB) architecture that is suitable for the IoT; which uses\nblockchain sharding and oracles to establish trust among unreliable IoT devices\nin a fully distributed and trustworthy manner. In particular, we design a\nPeer-To-Peer oracle network that ensures data reliability, scalability,\nflexibility, and trustworthiness. Furthermore, we introduce a new lightweight\nconsensus algorithm that scales the blockchain dramatically while ensuring the\ninteroperability among participants of the blockchain. The results show that\nour proposed STB architecture achieves flexibility, efficiency, and scalability\nmaking it a promising solution that is suitable for the IoT context.",
    "descriptor": "\nComments: This paper has been accepted for publication by ICC 2021-IEEE International Conference on Communications. The final version will be published by the IEEE\n",
    "authors": [
      "Hajar Moudoud",
      "Soumaya Cherkaoui",
      "Lyes Khoukhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11337"
  },
  {
    "id": "arXiv:2201.11341",
    "title": "Towards Agnostic Feature-based Dynamic Pricing: Linear Policies vs  Linear Valuation with Unknown Noise",
    "abstract": "In feature-based dynamic pricing, a seller sets appropriate prices for a\nsequence of products (described by feature vectors) on the fly by learning from\nthe binary outcomes of previous sales sessions (\"Sold\" if valuation $\\geq$\nprice, and \"Not Sold\" otherwise). Existing works either assume noiseless linear\nvaluation or precisely-known noise distribution, which limits the applicability\nof those algorithms in practice when these assumptions are hard to verify. In\nthis work, we study two more agnostic models: (a) a \"linear policy\" problem\nwhere we aim at competing with the best linear pricing policy while making no\nassumptions on the data, and (b) a \"linear noisy valuation\" problem where the\nrandom valuation is linear plus an unknown and assumption-free noise. For the\nformer model, we show a $\\tilde{\\Theta}(d^{\\frac13}T^{\\frac23})$ minimax regret\nup to logarithmic factors. For the latter model, we present an algorithm that\nachieves an $\\tilde{O}(T^{\\frac34})$ regret, and improve the best-known lower\nbound from $\\Omega(T^{\\frac35})$ to $\\tilde{\\Omega}(T^{\\frac23})$. These\nresults demonstrate that no-regret learning is possible for feature-based\ndynamic pricing under weak assumptions, but also reveal a disappointing fact\nthat the seemingly richer pricing feedback is not significantly more useful\nthan the bandit-feedback in regret reduction.",
    "descriptor": "\nComments: 20 pages, 1 figure (including 2 subfigures)\n",
    "authors": [
      "Jianyu Xu",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11341"
  },
  {
    "id": "arXiv:2201.11342",
    "title": "Smart City Defense Game: Strategic Resource Management during  Socio-Cyber-Physical Attacks",
    "abstract": "Ensuring public safety in a Smart City (SC) environment is a critical and\nincreasingly complicated task due to the involvement of multiple agencies and\nthe city's expansion across cyber and social layers. In this paper, we propose\nan extensive form perfect information game to model interactions and optimal\ncity resource allocations when a Terrorist Organization (TO) performs attacks\non multiple targets across two conceptual SC levels, a physical, and a\ncyber-social. The Smart City Defense Game (SCDG) considers three players that\ninitially are entitled to a specific finite budget. Two SC agencies that have\nto defend their physical or social territories respectively, fight against a\ncommon enemy, the TO. Each layer consists of multiple targets and the attack\noutcome depends on whether the resources allocated there by the associated\nagency, exceed or not the TO's. Each player's utility is equal to the number of\nsuccessfully defended targets. The two agencies are allowed to make budget\ntransfers provided that it is beneficial for both. We completely characterize\nthe Sub-game Perfect Nash Equilibrium (SPNE) of the SCDG that consists of\nstrategies for optimal resource exchanges between SC agencies and accounts for\nthe TO's budget allocation across the physical and social targets. Also, we\npresent numerical and comparative results demonstrating that when the SC\nplayers act according to the SPNE, they maximize the number of successfully\ndefended targets. The SCDG is shown to be a promising solution for modeling\ncritical resource allocations between SC parties in the face of multi-layer\nsimultaneous terrorist attacks.",
    "descriptor": "",
    "authors": [
      "Dimitrios Sikeridis",
      "Michael Devetsikiotis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11342"
  },
  {
    "id": "arXiv:2201.11345",
    "title": "Exploring Global Diversity and Local Context for Video Summarization",
    "abstract": "Video summarization aims to automatically generate a diverse and concise\nsummary which is useful in large-scale video processing. Most of methods tend\nto adopt self attention mechanism across video frames, which fails to model the\ndiversity of video frames. To alleviate this problem, we revisit the pairwise\nsimilarity measurement in self attention mechanism and find that the existing\ninner-product affinity leads to discriminative features rather than diversified\nfeatures. In light of this phenomenon, we propose global diverse attention by\nusing the squared Euclidean distance instead to compute the affinities.\nMoreover, we model the local contextual information by proposing local\ncontextual attention to remove the redundancy in the video. By combining these\ntwo attention mechanism, a video \\textbf{SUM}marization model with Diversified\nContextual Attention scheme is developed and named as SUM-DCA. Extensive\nexperiments are conducted on benchmark data sets to verify the effectiveness\nand the superiority of SUM-DCA in terms of F-score and rank-based evaluation\nwithout any bells and whistles.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Yingchao Pan",
      "Ouhan Huang",
      "Qinghao Ye",
      "Zhongjin Li",
      "Wenjiang Wang",
      "Guodun Li",
      "Yuxing Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11345"
  },
  {
    "id": "arXiv:2201.11346",
    "title": "Design of Battery management system for Residential applications",
    "abstract": "Battery management system plays an important role for modern battery-powered\napplication such as Electric vehicles, portable electronic equipment and\nstorage for renewable energy sources. It also increases the life-cycle of the\nbattery, battery state and efficiency. Monitoring the state of charge of the\nbattery is a crucial factor for battery management system. This paper deals\nwith monitoring the state of charge of the battery along with temperature,\ncurrent for Solar panel fitted with battery for residential application.\nMicrocontroller is used for controlling purpose, analog sensors are used for\nsensing the parameters of voltage, current. The information of the battery is\ngiven with tabular form and shown in photograph. Battery parameters are\ndisplayed with the LCD screen.",
    "descriptor": "\nComments: 6 Pages, No of figures- 14, Published with International Journal of Engineering Trends and Technology (IJETT)\n",
    "authors": [
      "Poushali Pal",
      "Devabalaji K.R",
      "S. Priyadarshini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11346"
  },
  {
    "id": "arXiv:2201.11349",
    "title": "Confidence May Cheat: Self-Training on Graph Neural Networks under  Distribution Shift",
    "abstract": "Graph Convolutional Networks (GCNs) have recently attracted vast interest and\nachieved state-of-the-art performance on graphs, but its success could\ntypically hinge on careful training with amounts of expensive and\ntime-consuming labeled data. To alleviate labeled data scarcity, self-training\nmethods have been widely adopted on graphs by labeling high-confidence\nunlabeled nodes and then adding them to the training step. In this line, we\nempirically make a thorough study for current self-training methods on graphs.\nSurprisingly, we find that high-confidence unlabeled nodes are not always\nuseful, and even introduce the distribution shift issue between the original\nlabeled dataset and the augmented dataset by self-training, severely hindering\nthe capability of self-training on graphs. To this end, in this paper, we\npropose a novel Distribution Recovered Graph Self-Training framework (DR-GST),\nwhich could recover the distribution of the original labeled dataset.\nSpecifically, we first prove the equality of loss function in self-training\nframework under the distribution shift case and the population distribution if\neach pseudo-labeled node is weighted by a proper coefficient. Considering the\nintractability of the coefficient, we then propose to replace the coefficient\nwith the information gain after observing the same changing trend between them,\nwhere information gain is respectively estimated via both dropout variational\ninference and dropedge variational inference in DR-GST. However, such a\nweighted loss function will enlarge the impact of incorrect pseudo labels. As a\nresult, we apply the loss correction method to improve the quality of pseudo\nlabels. Both our theoretical analysis and extensive experiments on five\nbenchmark datasets demonstrate the effectiveness of the proposed DR-GST, as\nwell as each well-designed component in DR-GST.",
    "descriptor": "\nComments: Accepted to the ACM Web Conference (WWW)2022. Work done during internship at Ant Group\n",
    "authors": [
      "Hongrui Liu",
      "Binbin Hu",
      "Xiao Wang",
      "Chuan Shi",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11349"
  },
  {
    "id": "arXiv:2201.11351",
    "title": "Effective Shortcut Technique for GAN",
    "abstract": "In recent years, generative adversarial network (GAN)-based image generation\ntechniques design their generators by stacking up multiple residual blocks. The\nresidual block generally contains a shortcut, \\ie skip connection, which\neffectively supports information propagation in the network. In this paper, we\npropose a novel shortcut method, called the gated shortcut, which not only\nembraces the strength point of the residual block but also further boosts the\nGAN performance. More specifically, based on the gating mechanism, the proposed\nmethod leads the residual block to keep (or remove) information that is\nrelevant (or irrelevant) to the image being generated. To demonstrate that the\nproposed method brings significant improvements in the GAN performance, this\npaper provides extensive experimental results on the various standard datasets\nsuch as CIFAR-10, CIFAR-100, LSUN, and tiny-ImageNet. Quantitative evaluations\nshow that the gated shortcut achieves the impressive GAN performance in terms\nof Frechet inception distance (FID) and Inception score (IS). For instance, the\nproposed method improves the FID and IS scores on the tiny-ImageNet dataset\nfrom 35.13 to 27.90 and 20.23 to 23.42, respectively.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.14968\n",
    "authors": [
      "Seung Park",
      "Cheol-Hwan Yoo",
      "Yong-Goo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11351"
  },
  {
    "id": "arXiv:2201.11356",
    "title": "Benchmarking learned non-Cartesian k-space trajectories and  reconstruction networks",
    "abstract": "We benchmark the current existing methods to jointly learn non-Cartesian\nk-space trajectory and reconstruction: PILOT, BJORK, and compare them with\nthose obtained from the recently developed generalized hybrid learning\n(HybLearn) framework. We present the advantages of using projected gradient\ndescent to enforce MR scanner hardware constraints as compared to using added\npenalties in the cost function. Further, we use the novel HybLearn scheme to\njointly learn and compare our results through a retrospective study on fastMRI\nvalidation dataset.",
    "descriptor": "",
    "authors": [
      "Chaithya G R",
      "Philippe Ciuciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11356"
  },
  {
    "id": "arXiv:2201.11358",
    "title": "Fairness implications of encoding protected categorical attributes",
    "abstract": "Protected attributes are often presented as categorical features that need to\nbe encoded before feeding them into a machine learning algorithm. Encoding\nthese attributes is paramount as they determine the way the algorithm will\nlearn from the data. Categorical feature encoding has a direct impact on the\nmodel performance and fairness. In this work, we compare the accuracy and\nfairness implications of the two most well-known encoders: one-hot encoding and\ntarget encoding. We distinguish between two types of induced bias that can\narise while using these encodings and can lead to unfair models. The first\ntype, irreducible bias, is due to direct group category discrimination and a\nsecond type, reducible bias, is due to large variance in less statistically\nrepresented groups. We take a deeper look into how regularization methods for\ntarget encoding can improve the induced bias while encoding categorical\nfeatures. Furthermore, we tackle the problem of intersectional fairness that\narises when mixing two protected categorical features leading to higher\ncardinality. This practice is a powerful feature engineering technique used for\nboosting model performance. We study its implications on fairness as it can\nincrease both types of induced bias",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Carlos Mougan",
      "Jose M. Alvarez",
      "Gourab K Patro",
      "Salvatore Ruggieri",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11358"
  },
  {
    "id": "arXiv:2201.11362",
    "title": "HYPERLOCK: In-Memory Hyperdimensional Encryption in Memristor Crossbar  Array",
    "abstract": "We present a novel cryptography architecture based on memristor crossbar\narray, binary hypervectors, and neural network. Utilizing the stochastic and\nunclonable nature of memristor crossbar and error tolerance of binary\nhypervectors and neural network, implementation of the algorithm on memristor\ncrossbar simulation is made possible. We demonstrate that with an increasing\ndimension of the binary hypervectors, the non-idealities in the memristor\ncircuit can be effectively controlled. At the fine level of controlled crossbar\nnon-ideality, noise from memristor circuit can be used to encrypt data while\nbeing sufficiently interpretable by neural network for decryption. We applied\nour algorithm on image cryptography for proof of concept, and to text\nen/decryption with 100% decryption accuracy despite crossbar noises. Our work\nshows the potential and feasibility of using memristor crossbars as an\nunclonable stochastic encoder unit of cryptography on top of their existing\nfunctionality as a vector-matrix multiplication acceleration device.",
    "descriptor": "\nComments: Accepted to IEEE ISCAS 2022\n",
    "authors": [
      "Jack Cai",
      "Amirali Amirsoleimani",
      "Roman Genov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11362"
  },
  {
    "id": "arXiv:2201.11367",
    "title": "Pan More Gold from the Sand: Refining Open-domain Dialogue Training with  Noisy Self-Retrieval Generation",
    "abstract": "Real human conversation data are complicated, heterogeneous, and noisy, from\nwhom building open-domain dialogue systems remains a challenging task. In fact,\nsuch dialogue data can still contain a wealth of information and knowledge,\nhowever, they are not fully explored. In this paper, we show existing\nopen-domain dialogue generation methods by memorizing context-response paired\ndata with causal or encode-decode language models underutilize the training\ndata. Different from current approaches, using external knowledge, we explore a\nretrieval-generation training framework that can increase the usage of training\ndata by directly considering the heterogeneous and noisy training data as the\n\"evidence\". Experiments over publicly available datasets demonstrate that our\nmethod can help models generate better responses, even such training data are\nusually impressed as low-quality data. Such performance gain is comparable with\nthose improved by enlarging the training set, even better. We also found that\nthe model performance has a positive correlation with the relevance of the\nretrieved evidence. Moreover, our method performed well on zero-shot\nexperiments, which indicates that our method can be more robust to real-world\ndata.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Yihe Wang",
      "Yitong Li",
      "Yasheng Wang",
      "Fei Mi",
      "Pingyi Zhou",
      "Xin Wang",
      "Jin Liu",
      "Qun Liu",
      "Xin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11367"
  },
  {
    "id": "arXiv:2201.11368",
    "title": "Prediction and Detection of FDIA and DDoS Attacks in 5G Enabled IoT",
    "abstract": "Security in the fifth generation (5G) networks has become one of the prime\nconcerns in the telecommunication industry. 5G security challenges come from\nthe fact that 5G networks involve different stakeholders using different\nsecurity requirements and measures. Deficiencies in security management between\nthese stakeholders can lead to security attacks. Therefore, security solutions\nshould be conceived for the safe deployment of different 5G verticals (e.g.,\nindustry 4.0, Internet of Things (IoT), etc.). The interdependencies among 5G\nand fully connected systems, such as IoT, entail some standard security\nrequirements, namely integrity, availability, and confidentiality. In this\narticle, we propose a hierarchical architecture for securing 5G enabled IoT\nnetworks, and a security model for the prediction and detection of False Data\nInjection Attacks (FDIA) and Distributed Denial of Service attacks (DDoS). The\nproposed security model is based on a Markov stochastic process, which is used\nto observe the behavior of each network device, and employ a range-based\nbehavior sifting policy. Simulation results demonstrate the effectiveness of\nthe proposed architecture and model in detecting and predicting FDIA and DDoS\nattacks in the context of 5G enabled IoT.",
    "descriptor": "\nComments: This paper has been accepted for publication by the IEEE Network. The final version will be published by the IEEE\n",
    "authors": [
      "Hajar Moudoud",
      "Lyes Khoukhi",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11368"
  },
  {
    "id": "arXiv:2201.11369",
    "title": "$c^3$-Local Testable Codes from Lossless Expanders",
    "abstract": "A locally testable code (LTC) is an error correcting code with a property\ntester. The tester tests if a word is codeword by reading constant random bits\nand rejects the word with probability proportional to the distance from the\nword to the closest codeword. An important open question until recently is\nwhether there exist $c^3$-LTCs which are LTCs with constant rate, constant\nrelative distance and constant locality. In this work, we construct a new LTC\nfamily using 1-sided lossless expanders and balanced products.",
    "descriptor": "",
    "authors": [
      "Ting-Chun Lin",
      "Min-Hsiu Hsieh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.11369"
  },
  {
    "id": "arXiv:2201.11370",
    "title": "An IoT Blockchain Architecture Using Oracles and Smart Contracts: the  Use-Case of a Food Supply Chain",
    "abstract": "The blockchain is a distributed technology which allows establishing trust\namong unreliable users who interact and perform transactions with each other.\nWhile blockchain technology has been mainly used for crypto-currency, it has\nemerged as an enabling technology for establishing trust in the realm of the\nInternet of Things (IoT). Nevertheless, a naive usage of the blockchain for IoT\nleads to high delays and extensive computational power. In this paper, we\npropose a blockchain architecture dedicated to being used in a supply chain\nwhich comprises different distributed IoT entities. We propose a lightweight\nconsensus for this architecture, called LC4IoT. The consensus is evaluated\nthrough extensive simulations. The results show that the proposed consensus\nuses low computational power, storage capability and latency.",
    "descriptor": "\nComments: This paper has been accepted for publication by IEEE 30th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC). The final version will be published by the IEEE\n",
    "authors": [
      "Hajar Moudoud",
      "Soumaya Cherkaoui",
      "Lyes Khoukhi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11370"
  },
  {
    "id": "arXiv:2201.11374",
    "title": "Systematic Investigation of Strategies Tailored for Low-Resource  Settings for Sanskrit Dependency Parsing",
    "abstract": "Existing state of the art approaches for Sanskrit Dependency Parsing (SDP),\nare hybrid in nature, and rely on a lexicon-driven shallow parser for\nlinguistically motivated feature engineering. However, these methods fail to\nhandle out of vocabulary (OOV) words, which limits their applicability in\nrealistic scenarios. On the other hand, purely data-driven approaches do not\nmatch the performance of hybrid approaches due to the labelled data sparsity.\nThus, in this work, we investigate the following question: How far can we push\na purely data-driven approach using recently proposed strategies for\nlow-resource settings? We experiment with five strategies, namely, data\naugmentation, sequential transfer learning, cross-lingual/mono-lingual\npretraining, multi-task learning and self-training. Our proposed ensembled\nsystem outperforms the purely data-driven state of the art system by 2.8/3.9\npoints (Unlabelled Attachment Score (UAS)/Labelled Attachment Score (LAS))\nabsolute gain. Interestingly, it also supersedes the performance of the state\nof the art hybrid system by 1.2 points (UAS) absolute gain and shows comparable\nperformance in terms of LAS. Code and data will be publicly available at:\n\\url{https://github.com/Jivnesh/SanDP}.",
    "descriptor": "\nComments: 13 pages, The work is submitted at SI on Recent Advances in Computational Linguistics for Asian languages, TALLIP-22\n",
    "authors": [
      "Jivnesh Sandhan",
      "Laxmidhar Behera",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11374"
  },
  {
    "id": "arXiv:2201.11377",
    "title": "CacheFX: A Framework for Evaluating Cache Security",
    "abstract": "Over the last two decades, the danger of sharing resources between programs\nhas been repeatedly highlighted. Multiple side-channel attacks, which seek to\nexploit shared components for leaking information, have been devised, mostly\ntargeting shared caching components. In response, the research community has\nproposed multiple cache designs that aim at curbing the source of side\nchannels. With multiple competing designs, there is a need for assessing the\nlevel of security against side-channel attacks that each design offers.\nIn this work we propose CacheFX, a flexible framework for assessing and\nevaluating the resilience of cache designs to side-channel attacks. CacheFX\nallows the evaluator to implement various cache designs, victims, and\nattackers, as well as to exercise them for assessing the leakage of information\nvia the cache.\nTo demonstrate the power of CacheFX, we implement multiple cache designs and\nreplacement algorithms, and devise three evaluation metrics that measure\ndifferent aspects of the caches:(1) the entropy induced by a memory access; (2)\nthe complexity of building an eviction set; and (3) protection against\ncryptographic attacks. Our experiments highlight that different security\nmetrics give different insights to designs, making a comprehensive analysis\nmandatory. For instance, while eviction-set building was fastest for randomized\nskewed caches, these caches featured lower eviction entropy and higher\npractical attack complexity. Our experiments show that all non-partitioned\ndesigns allow for effective cryptographic attacks. However, in state-of-the-art\nsecure caches, eviction-based attacks are more difficult to mount than\noccupancy-based attacks, highlighting the need to consider the latter in cache\ndesign.",
    "descriptor": "",
    "authors": [
      "Daniel Genkin",
      "William Kosasih",
      "Fangfei Liu",
      "Anna Trikalinou",
      "Thomas Unterluggauer",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11377"
  },
  {
    "id": "arXiv:2201.11379",
    "title": "Deep Confidence Guided Distance for 3D Partial Shape Registration",
    "abstract": "We present a novel non-iterative learnable method for partial-to-partial 3D\nshape registration. The partial alignment task is extremely complex, as it\njointly tries to match between points and identify which points do not appear\nin the corresponding shape, causing the solution to be non-unique and ill-posed\nin most cases.\nUntil now, two principal methodologies have been suggested to solve this\nproblem: sample a subset of points that are likely to have correspondences or\nperform soft alignment between the point clouds and try to avoid a match to an\noccluded part. These heuristics work when the partiality is mild or when the\ntransformation is small but fails for severe occlusions or when outliers are\npresent. We present a unique approach named Confidence Guided Distance Network\n(CGD-net), where we fuse learnable similarity between point embeddings and\nspatial distance between point clouds, inducing an optimized solution for the\noverlapping points while ignoring parts that only appear in one of the shapes.\nThe point feature generation is done by a self-supervised architecture that\nrepels far points to have different embeddings, therefore succeeds to align\npartial views of shapes, even with excessive internal symmetries or acute\nrotations. We compare our network to recently presented learning-based and\naxiomatic methods and report a fundamental boost in performance.",
    "descriptor": "",
    "authors": [
      "Dvir Ginzburg",
      "Dan Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11379"
  },
  {
    "id": "arXiv:2201.11380",
    "title": "Achieving Personalized Federated Learning with Sparse Local Models",
    "abstract": "Federated learning (FL) is vulnerable to heterogeneously distributed data,\nsince a common global model in FL may not adapt to the heterogeneous data\ndistribution of each user. To counter this issue, personalized FL (PFL) was\nproposed to produce dedicated local models for each individual user. However,\nPFL is far from its maturity, because existing PFL solutions either demonstrate\nunsatisfactory generalization towards different model architectures or cost\nenormous extra computation and memory. In this work, we propose federated\nlearning with personalized sparse mask (FedSpa), a novel PFL scheme that\nemploys personalized sparse masks to customize sparse local models on the edge.\nInstead of training an intact (or dense) PFL model, FedSpa only maintains a\nfixed number of active parameters throughout training (aka sparse-to-sparse\ntraining), which enables users' models to achieve personalization with cheap\ncommunication, computation, and memory cost. We theoretically show that the\niterates obtained by FedSpa converge to the local minimizer of the formulated\nSPFL problem at rate of $\\mathcal{O}(\\frac{1}{\\sqrt{T}})$. Comprehensive\nexperiments demonstrate that FedSpa significantly saves communication and\ncomputation costs, while simultaneously achieves higher model accuracy and\nfaster convergence speed against several state-of-the-art PFL methods.",
    "descriptor": "",
    "authors": [
      "Tiansheng Huang",
      "Shiwei Liu",
      "Li Shen",
      "Fengxiang He",
      "Weiwei Lin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11380"
  },
  {
    "id": "arXiv:2201.11383",
    "title": "Capacity of First Arrival Position Channel in Diffusion-Based Molecular  Communication",
    "abstract": "In [1], the impulse response of the first arrival position (FAP) channel of\n2D and 3D spaces in molecular communication (MC) is derived, but its Shannon\ncapacity remains open. The main difficulty of depicting the FAP channel\ncapacity comes from the fact that the FAP density becomes a multi-dimensional\nCauchy distribution when the drift velocity approaches zero. As a result, the\ncommonly used techniques in maximizing the mutual information no longer work\nbecause the first and second moments of Cauchy distributions do not exist.\nOur main contribution in this paper is a complete characterization of the\nzero-drift FAP channel capacity for the 2D and 3D spaces. The capacity formula\nfor FAP channel turns out to have a similar form compared to the Gaussian\nchannel case (under second-moment power constraint). It is also worth\nmentioning that the capacity value of 3D FAP channel is twice as large as 2D\nFAP channel. This is an evidence that the FAP channel has larger capacity as\nthe spatial dimension grows. Finally, our technical contributions are the\napplication of a modified logarithmic constraint as a replacement of the usual\npower constraint, and the choice of output signal constraint as a substitution\nto input signal constraint in order to keep the resulting formula concise.",
    "descriptor": "",
    "authors": [
      "Yen-Chi Lee",
      "Min-Hsiu Hsieh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11383"
  },
  {
    "id": "arXiv:2201.11385",
    "title": "An Overview of Blockchain and 5G Networks",
    "abstract": "The 5G wireless networks are potentially revolutionizing future technologies.\nThe 5G technologies are expected to foresee demands of diverse vertical\napplications with diverse requirements including high traffic volume, massive\nconnectivity, high quality of service, and low latency. To fulfill such\nrequirements in 5G and beyond, new emerging technologies such as SDN, NFV, MEC,\nand CC are being deployed. However, these technologies raise several issues\nregarding transparency, decentralization, and reliability. Furthermore, 5G\nnetworks are expected to connect many heterogeneous devices and machines which\nwill raise several security concerns regarding users' confidentiality, data\nprivacy, and trustworthiness. To work seamlessly and securely in such\nscenarios, future 5G networks need to deploy smarter and more efficient\nsecurity functions. Motivated by the aforementioned issues, blockchain was\nproposed by researchers to overcome 5G issues because of its capacities to\nensure transparency, data reliability, trustworthiness, immutability in a\ndistributed environment. Indeed, blockchain has gained momentum as a novel\ntechnology that gives rise to a plethora of new decentralized technologies. In\nthis chapter, we discuss the integration of the blockchain with 5G networks and\nbeyond. We then present how blockchain applications in 5G networks and beyond\ncould facilitate enabling various services at the edge and the core.",
    "descriptor": "",
    "authors": [
      "Hajar Moudoud",
      "Soumaya Cherkaoui",
      "Lyes Khoukhi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11385"
  },
  {
    "id": "arXiv:2201.11388",
    "title": "Contrastive Embedding Distribution Refinement and Entropy-Aware  Attention for 3D Point Cloud Classification",
    "abstract": "Learning a powerful representation from point clouds is a fundamental and\nchallenging problem in the field of computer vision. Different from images\nwhere RGB pixels are stored in the regular grid, for point clouds, the\nunderlying semantic and structural information of point clouds is the spatial\nlayout of the points. Moreover, the properties of challenging in-context and\nbackground noise pose more challenges to point cloud analysis. One assumption\nis that the poor performance of the classification model can be attributed to\nthe indistinguishable embedding feature that impedes the search for the optimal\nclassifier. This work offers a new strategy for learning powerful\nrepresentations via a contrastive learning approach that can be embedded into\nany point cloud classification network. First, we propose a supervised\ncontrastive classification method to implement embedding feature distribution\nrefinement by improving the intra-class compactness and inter-class\nseparability. Second, to solve the confusion problem caused by small\ninter-class compactness and inter-class separability. Second, to solve the\nconfusion problem caused by small inter-class variations between some\nsimilar-looking categories, we propose a confusion-prone class mining strategy\nto alleviate the confusion effect. Finally, considering that outliers of the\nsample clusters in the embedding space may cause performance degradation, we\ndesign an entropy-aware attention module with information entropy theory to\nidentify the outlier cases and the unstable samples by measuring the\nuncertainty of predicted probability. The results of extensive experiments\ndemonstrate that our method outperforms the state-of-the-art approaches by\nachieving 82.9% accuracy on the real-world ScanObjectNN dataset and substantial\nperformance gains up to 2.9% in DCGNN, 3.1% in PointNet++, and 2.4% in GBNet.",
    "descriptor": "\nComments: 15 pages, 10figures\n",
    "authors": [
      "Feng Yang",
      "Yichao Cao",
      "Qifan Xue",
      "Shuai Jin",
      "Xuanpeng Li",
      "Weigong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11388"
  },
  {
    "id": "arXiv:2201.11391",
    "title": "Prabhupadavani: A Code-mixed Speech Translation Data for 25 Languages",
    "abstract": "Nowadays, code-mixing has become ubiquitous in Natural Language Processing\n(NLP); however, no efforts have been made to address this phenomenon for Speech\nTranslation (ST) task. This can be solely attributed to the lack of code-mixed\nST task labelled data. Thus, we introduce Prabhupadavani, a multilingual\ncode-mixed ST dataset for 25 languages, covering ten language families,\ncontaining 94 hours of speech by 130+ speakers, manually aligned with\ncorresponding text in the target language. Prabhupadvani is the first\ncode-mixed ST dataset available in the ST literature to the best of our\nknowledge. This data also can be used for a code-mixed machine translation\ntask. All the dataset and code can be accessed at:\n\\url{https://github.com/frozentoad9/CMST}",
    "descriptor": "\nComments: 5 pages, The work is submitted at LREC22\n",
    "authors": [
      "Jivnesh Sandhan",
      "Ayush Daksh",
      "Om Adideva Paranjay",
      "Laxmidhar Behera",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11391"
  },
  {
    "id": "arXiv:2201.11400",
    "title": "The MSXF TTS System for ICASSP 2022 ADD Challenge",
    "abstract": "This paper presents our MSXF TTS system for Task 3.1 of the Audio Deep\nSynthesis Detection (ADD) Challenge 2022. We use an end to end text to speech\nsystem, and add a constraint loss to the system when training stage. The end to\nend TTS system is VITS, and the pre-training self-supervised model is wav2vec\n2.0. And we also explore the influence of the speech speed and volume in\nspoofing. The faster speech means the less the silence part in audio, the\neasier to fool the detector. We also find the smaller the volume, the better\nspoofing ability, though we normalize volume for submission. Our team is\nidentified as C2, and we got the fourth place in the challenge.",
    "descriptor": "\nComments: Deep Synthesis Detection Challenge 2022\n",
    "authors": [
      "Chunyong Yang",
      "Pengfei Liu",
      "Yanli Chen",
      "Hongbin Wang",
      "Min Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.11400"
  },
  {
    "id": "arXiv:2201.11403",
    "title": "Generalised Image Outpainting with U-Transformer",
    "abstract": "While most present image outpainting conducts horizontal extrapolation, we\nstudy the generalised image outpainting problem that extrapolates visual\ncontext all-side around a given image. To this end, we develop a novel\ntransformer-based generative adversarial network called U-Transformer able to\nextend image borders with plausible structure and details even for complicated\nscenery images. Specifically, we design a generator as an encoder-to-decoder\nstructure embedded with the popular Swin Transformer blocks. As such, our novel\nframework can better cope with image long-range dependencies which are\ncrucially important for generalised image outpainting. We propose additionally\na U-shaped structure and multi-view Temporal Spatial Predictor network to\nreinforce image self-reconstruction as well as unknown-part prediction smoothly\nand realistically. We experimentally demonstrate that our proposed method could\nproduce visually appealing results for generalized image outpainting against\nthe state-of-the-art image outpainting approaches.",
    "descriptor": "",
    "authors": [
      "Penglei Gao",
      "Xi Yang",
      "Rui Zhang",
      "Kaizhu Huang",
      "Yujie Geng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11403"
  },
  {
    "id": "arXiv:2201.11404",
    "title": "Online Planning in POMDPs with Self-Improving Simulators",
    "abstract": "How can we plan efficiently in a large and complex environment when the time\nbudget is limited? Given the original simulator of the environment, which may\nbe computationally very demanding, we propose to learn online an approximate\nbut much faster simulator that improves over time. To plan reliably and\nefficiently while the approximate simulator is learning, we develop a method\nthat adaptively decides which simulator to use for every simulation, based on a\nstatistic that measures the accuracy of the approximate simulator. This allows\nus to use the approximate simulator to replace the original simulator for\nfaster simulations when it is accurate enough under the current context, thus\ntrading off simulation speed and accuracy. Experimental results in two large\ndomains show that when integrated with POMCP, our approach allows to plan with\nimproving efficiency over time.",
    "descriptor": "",
    "authors": [
      "Jinke He",
      "Miguel Suau",
      "Hendrik Baier",
      "Michael Kaisers",
      "Frans A. Oliehoek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11404"
  },
  {
    "id": "arXiv:2201.11406",
    "title": "Report: State of the Art Solutions for Privacy Preserving Machine  Learning in the Medical Context",
    "abstract": "Machine Learning on Big Data gets more and more attention in various fields.\nEven so privacy-preserving techniques become more important, even necessary due\nto legal regulations such as the General Data Protection Regulation (GDPR). On\nthe other hand data is often distributed among various parties. Especially in\nthe medical context there are several data holders, e.g. hospitals and we need\nto deal with highly sensitive values. A real world scenario would be data that\nis held in an electronic patient record that is available in many countries by\nnow. The medical data is encrypted. Users (e.g. physicians, hospitals) can only\ndecrypt the data after patient authorization. One of the main questions\nconcerning this scenario is whether it is possible to process the data for\nresearch purposes without violating the privacy of the data owner. We want to\nevaluate which cryptographic mechanism - homomorphic encryption, multiparty\ncomputation or trusted execution environements - can be used for this task.",
    "descriptor": "\nComments: 23 pages, 3 figures, 3 tables\n",
    "authors": [
      "Jasmin Zalonis",
      "Frederik Armknecht",
      "Bj\u00f6rn Grohmann",
      "Manuel Koch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11406"
  },
  {
    "id": "arXiv:2201.11407",
    "title": "Non-linear Motion Estimation for Video Frame Interpolation using  Space-time Convolutions",
    "abstract": "Video frame interpolation aims to synthesize one or multiple frames between\ntwo consecutive frames in a video. It has a wide range of applications\nincluding slow-motion video generation, frame-rate up-scaling and developing\nvideo codecs. Some older works tackled this problem by assuming per-pixel\nlinear motion between video frames. However, objects often follow a non-linear\nmotion pattern in the real domain and some recent methods attempt to model\nper-pixel motion by non-linear models (e.g., quadratic). A quadratic model can\nalso be inaccurate, especially in the case of motion discontinuities over time\n(i.e. sudden jerks) and occlusions, where some of the flow information may be\ninvalid or inaccurate.\nIn our paper, we propose to approximate the per-pixel motion using a\nspace-time convolution network that is able to adaptively select the motion\nmodel to be used. Specifically, we are able to softly switch between a linear\nand a quadratic model. Towards this end, we use an end-to-end 3D CNN\nencoder-decoder architecture over bidirectional optical flows and occlusion\nmaps to estimate the non-linear motion model of each pixel. Further, a motion\nrefinement module is employed to refine the non-linear motion and the\ninterpolated frames are estimated by a simple warping of the neighboring frames\nwith the estimated per-pixel motion. Through a set of comprehensive\nexperiments, we validate the effectiveness of our model and show that our\nmethod outperforms state-of-the-art algorithms on four datasets (Vimeo, DAVIS,\nHD and GoPro).",
    "descriptor": "",
    "authors": [
      "Saikat Dutta",
      "Arulkumar Subramaniam",
      "Anurag Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11407"
  },
  {
    "id": "arXiv:2201.11409",
    "title": "On the RTL Implementation of FINN Matrix Vector Compute Unit",
    "abstract": "FPGA-based accelerators are becoming more popular for deep neural network due\nto the ability to scale performance with increasing degree of specialization\nwith dataflow architectures or custom data types. To reduce the barrier for\nsoftware engineers and data scientists to adopt FPGAs, C++- and OpenCL-based\ndesign entries with high-level synthesis (HLS) have been introduced. They\nprovide higher abstraction compared to register-transfer level (RTL)-based\ndesign. HLS offers faster development time, better maintainability and more\nflexibility in code exploration, when evaluating options for multi-dimension\ntensors, convolutional layers or parallelism. Thus, HLS has been adopted by DNN\naccelerator generation frameworks such as FINN and hls4ml.\nIn this paper, we present an alternative backend RTL library for FINN. We\ninvestigate and evaluate, across a spectrum of design dimensions, an RTL-based\nimplementation versus the original HLS variant. We show that for smaller design\nparameters, RTL produces significantly smaller circuits. For larger circuits,\nhowever, the look-up table (LUT) count of RTL-based design is slightly higher,\nup to around $15\\%$. On the other hand, HLS consistently requires more\nflip-flops (FFs) (orders-of-magnitude increase) and block RAMs (BRAMs)\n($2\\times$ more). This also impacts the critical path delay, with RTL producing\nsignificantly faster circuits, up to $80\\%$. Furthermore, RTL also benefits\nfrom at-least a $10\\times$ reduction in synthesis time. Finally the results\nwere practically validated using a real-world use case of a multi-layer\nperceptron (MLP) network used in network intrusion detection. Overall, since\nHLS frameworks code-generate the hardware design, the benefits of the ease in\nthe design entry is less important as compared to synthesis time reduction\ntogther with resource benefits, this might make the RTL abstraction an\nattractive alternative.",
    "descriptor": "\nComments: 22 pages, 7 tables, 16 figures\n",
    "authors": [
      "Syed Asad Alam",
      "David Gregg",
      "Giulio Gambardella",
      "Michael Preusser",
      "Michaela Blott"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.11409"
  },
  {
    "id": "arXiv:2201.11410",
    "title": "Reinforcement Learning-Empowered Mobile Edge Computing for 6G Edge  Intelligence",
    "abstract": "Mobile edge computing (MEC) is considered a novel paradigm for\ncomputation-intensive and delay-sensitive tasks in fifth generation (5G)\nnetworks and beyond. However, its uncertainty, referred to as dynamic and\nrandomness, from the mobile device, wireless channel, and edge network sides,\nresults in high-dimensional, nonconvex, nonlinear, and NP-hard optimization\nproblems. Thanks to the evolved reinforcement learning (RL), upon iteratively\ninteracting with the dynamic and random environment, its trained agent can\nintelligently obtain the optimal policy in MEC. Furthermore, its evolved\nversions, such as deep RL (DRL), can achieve higher convergence speed\nefficiency and learning accuracy based on the parametric approximation for the\nlarge-scale state-action space. This paper provides a comprehensive research\nreview on RL-enabled MEC and offers insight for development in this area. More\nimportantly, associated with free mobility, dynamic channels, and distributed\nservices, the MEC challenges that can be solved by different kinds of RL\nalgorithms are identified, followed by how they can be solved by RL solutions\nin diverse mobile applications. Finally, the open challenges are discussed to\nprovide helpful guidance for future research in RL training and learning MEC.",
    "descriptor": "\nComments: 34 pages, 5 figures, 11 tables\n",
    "authors": [
      "Peng Wei",
      "Kun Guo",
      "Ye Li",
      "Jue Wang",
      "Wei Feng",
      "Shi Jin",
      "Ning Ge",
      "Ying-Chang Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11410"
  },
  {
    "id": "arXiv:2201.11412",
    "title": "Reduction of Two-Dimensional Data for Speeding Up Convex Hull  Computation",
    "abstract": "An incremental approach for computation of convex hull for data points in\ntwo-dimensions is presented. The algorithm is not output-sensitive and costs a\ntime that is linear in the size of data points at input. Graham's scan is\napplied only on a subset of the data points, represented at the extremal of the\ndataset. Points are classified for extremal, in proportion with the modular\ndistance, about an imaginary point interior to the region bounded by convex\nhull of the dataset assumed for origin or center in polar coordinate. A subset\nof the data is arrived by terminating at until an event of no change in maximal\npoints is observed per bin, for iteratively and exponentially decreasing\nintervals.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Debashis Mukherjee"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11412"
  },
  {
    "id": "arXiv:2201.11422",
    "title": "Fast Moving Natural Evolution Strategy for High-Dimensional Problems",
    "abstract": "In this work, we propose a new variant of natural evolution strategies (NES)\nfor high-dimensional black-box optimization problems. The proposed method,\nCR-FM-NES, extends a recently proposed state-of-the-art NES, Fast Moving\nNatural Evolution Strategy (FM-NES), in order to be applicable in\nhigh-dimensional problems. CR-FM-NES builds on an idea using a restricted\nrepresentation of a covariance matrix instead of using a full covariance\nmatrix, while inheriting an efficiency of FM-NES. The restricted representation\nof the covariance matrix enables CR-FM-NES to update parameters of a\nmultivariate normal distribution in linear time and space complexity, which can\nbe applied to high-dimensional problems. Our experimental results reveal that\nCR-FM-NES does not lose the efficiency of FM-NES, and on the contrary,\nCR-FM-NES has achieved significant speedup compared to FM-NES on some benchmark\nproblems. Furthermore, our numerical experiments using 200, 600, and\n1000-dimensional benchmark problems demonstrate that CR-FM-NES is effective\nover scalable baseline methods, VD-CMA and Sep-CMA.",
    "descriptor": "",
    "authors": [
      "Masahiro Nomura",
      "Isao Ono"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11422"
  },
  {
    "id": "arXiv:2201.11429",
    "title": "GMRES using pseudo-inverse for range symmetric singular systems",
    "abstract": "Consider solving large sparse range symmetric singular linear systems $A{\\bf\nx} = {\\bf b}$ which arise, for instance, in the discretization of convection\ndiffusion equations with periodic boundary conditions, and partial differential\nequations for electromagnetic fields using the edge-based finite element\nmethod.\nIn theory, the Generalized Minimal Residual (GMRES) method converges to the\nleast squares solution for inconsistent systems if the coefficient matrix $A$\nis range symmetric, i.e. ${\\rm R}(A)={ {\\rm R}(A^{\\rm T} })$, where ${\\rm\nR}(A)$ is the range space of $A$.\nHowever, in practice, GMRES may not converge due to numerical instability. In\norder to improve the convergence, we propose using the pseudo-inverse for the\nsolution of the severely ill-conditioned Hessenberg systems in GMRES. Numerical\nexperiments on semi-definite inconsistent systems indicate that the method is\nefficient and robust. Finally, we further improve the convergence of the\nmethod, by reorthogonalizing the Modified Gram-Schmidt procedure.",
    "descriptor": "",
    "authors": [
      "Kota Sugihara",
      "Ken Hayami",
      "Liao Zeyu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11429"
  },
  {
    "id": "arXiv:2201.11432",
    "title": "System Modeling and Performance Evaluation of Predictive QoS for Future  Tele-Operated Driving",
    "abstract": "Future Tele-operated Driving (ToD) applications place challenging Quality of\nService (QoS) demands on existing mobile communication networks that are of\nhighly important to comply with for safe operation. New remote control and\nplatooning services will emerge and pose high data rate and latency\nrequirements. One key enabler for these applications is the newly available 5G\nNew Radio (NR) promising higher bandwidth and lower latency than its\npredecessors. In addition to that, public 5G networks do not consistently\ndeliver and do not guarantee the required data rates and latency of ToD. In\nthis paper, we discuss the communication-related requirements of tele-operated\ndriving. ToD is regarded as a complex system consisting of multiple research\nareas. One key aspect of ToD is the provision and maintenance of the required\ndata rate for teleoperation by the mobile network. An in-advance prediction\nmethod of the end-to-end data rate based on so-called Radio Environmental Maps\n(REMs) is discussed. Furthermore, a novel approach improving the prediction\naccuracy is introduced and it features individually optimized REM layers.\nFinally, we analyze the implementation of tele-operated driving applications on\na scaled vehicular platform combined with a cyber-physical test environment\nconsisting of real and virtual objects. This approach enables large-scale\ntesting of remote operation and autonomous applications.",
    "descriptor": "",
    "authors": [
      "Hendrik Schippers",
      "Cedrik Sch\u00fcler",
      "Benjamin Sliwa",
      "Christian Wietfeld"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11432"
  },
  {
    "id": "arXiv:2201.11433",
    "title": "ETAP: Energy-aware Timing Analysis of Intermittent Programs",
    "abstract": "Energy harvesting battery-free embedded devices rely only on ambient energy\nharvesting that enables stand-alone and sustainable IoT applications. These\ndevices execute programs when the harvested ambient energy in their energy\nreservoir is sufficient to operate and stop execution abruptly (and start\ncharging) otherwise. These intermittent programs have varying timing behavior\nunder different energy conditions, hardware configurations, and program\nstructures. This paper presents Energy-aware Timing Analysis of intermittent\nPrograms (ETAP), a probabilistic symbolic execution approach that analyzes the\ntiming and energy behavior of intermittent programs at compile time. ETAP\nsymbolically executes the given program while taking time and energy cost\nmodels for ambient energy and dynamic energy consumption into account. We\nevaluated ETAP on several intermittent programs and compared the compile-time\nanalysis results with executions on real hardware. The results show that ETAP's\nnormalized prediction accuracy is 99.5%, and it speeds up the timing analysis\nby at least two orders of magnitude compared to manual testing.",
    "descriptor": "",
    "authors": [
      "Ferhat Erata",
      "Arda Goknil",
      "Eren Y\u0131ld\u0131z",
      "Kas\u0131m Sinan Y\u0131ld\u0131r\u0131m",
      "Ruzika Piskac",
      "Jakup Szfer",
      "G\u00f6k\u00e7in Sezgin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11433"
  },
  {
    "id": "arXiv:2201.11438",
    "title": "DocSegTr: An Instance-Level End-to-End Document Image Segmentation  Transformer",
    "abstract": "Understanding documents with rich layouts is an essential step towards\ninformation extraction. Business intelligence processes often require the\nextraction of useful semantic content from documents at a large scale for\nsubsequent decision-making tasks. In this context, instance-level segmentation\nof different document objects(title, sections, figures, tables and so on) has\nemerged as an interesting problem for the document layout analysis community.\nTo advance the research in this direction, we present a transformer-based model\nfor end-to-end segmentation of complex layouts in document images. To our\nknowledge, this is the first work on transformer-based document segmentation.\nExtensive experimentation on the PubLayNet dataset shows that our model\nachieved comparable or better segmentation performance than the existing\nstate-of-the-art approaches. We hope our simple and flexible framework could\nserve as a promising baseline for instance-level recognition tasks in document\nimages.",
    "descriptor": "\nComments: Submitted to International Workshop on Document Analysis Systems (DAS) 2022\n",
    "authors": [
      "Sanket Biswas",
      "Ayan Banerjee",
      "Josep Llad\u00f3s",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11438"
  },
  {
    "id": "arXiv:2201.11440",
    "title": "An Analysis on Ensemble Learning optimized Medical Image Classification  with Deep Convolutional Neural Networks",
    "abstract": "Novel and high-performance medical image classification pipelines are heavily\nutilizing ensemble learning strategies. The idea of ensemble learning is to\nassemble diverse models or multiple predictions and, thus, boost prediction\nperformance. However, it is still an open question to what extent as well as\nwhich ensemble learning strategies are beneficial in deep learning based\nmedical image classification pipelines. In this work, we proposed a\nreproducible medical image classification pipeline for analyzing the\nperformance impact of the following ensemble learning techniques: Augmenting,\nStacking, and Bagging. The pipeline consists of state-of-the-art preprocessing\nand image augmentation methods as well as 9 deep convolution neural network\narchitectures. It was applied on four popular medical imaging datasets with\nvarying complexity. Furthermore, 12 pooling functions for combining multiple\npredictions were analyzed, ranging from simple statistical functions like\nunweighted averaging up to more complex learning-based functions like support\nvector machines. Our results revealed that Stacking achieved the largest\nperformance gain of up to 13% F1-score increase. Augmenting showed consistent\nimprovement capabilities by up to 4% and is also applicable to single model\nbased pipelines. Cross-validation based Bagging demonstrated to be the most\ncomplex ensemble learning method, which resulted in an F1-score decrease in all\nanalyzed datasets (up to -10%). Furthermore, we demonstrated that simple\nstatistical pooling functions are equal or often even better than more complex\npooling functions. We concluded that the integration of Stacking and\nAugmentation ensemble learning techniques is a powerful method for any medical\nimage classification pipeline to improve robustness and boost performance.",
    "descriptor": "\nComments: Code: this https URL ; Supplementary Material: this https URL\n",
    "authors": [
      "Dominik M\u00fcller",
      "I\u00f1aki Soto-Rey",
      "Frank Kramer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11440"
  },
  {
    "id": "arXiv:2201.11441",
    "title": "Human-centered mechanism design with Democratic AI",
    "abstract": "Building artificial intelligence (AI) that aligns with human values is an\nunsolved problem. Here, we developed a human-in-the-loop research pipeline\ncalled Democratic AI, in which reinforcement learning is used to design a\nsocial mechanism that humans prefer by majority. A large group of humans played\nan online investment game that involved deciding whether to keep a monetary\nendowment or to share it with others for collective benefit. Shared revenue was\nreturned to players under two different redistribution mechanisms, one designed\nby the AI and the other by humans. The AI discovered a mechanism that redressed\ninitial wealth imbalance, sanctioned free riders, and successfully won the\nmajority vote. By optimizing for human preferences, Democratic AI may be a\npromising method for value-aligned policy innovation.",
    "descriptor": "\nComments: 18 pages, 4 figures, 54 pages including supplemental materials\n",
    "authors": [
      "Raphael Koster",
      "Jan Balaguer",
      "Andrea Tacchetti",
      "Ari Weinstein",
      "Tina Zhu",
      "Oliver Hauser",
      "Duncan Williams",
      "Lucy Campbell-Gillingham",
      "Phoebe Thacker",
      "Matthew Botvinick",
      "Christopher Summerfield"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2201.11441"
  },
  {
    "id": "arXiv:2201.11443",
    "title": "Yes-Yes-Yes: Donation-based Peer Reviewing Data Collection for ACL  Rolling Review and Beyond",
    "abstract": "Peer review is the primary gatekeeper of scientific merit and quality, yet it\nis prone to bias and suffers from low efficiency. This demands\ncross-disciplinary scrutiny of the processes that underlie peer reviewing;\nhowever, quantitative research is limited by the data availability, as most of\nthe peer reviewing data across research disciplines is never made public.\nExisting data collection efforts focus on few scientific domains and do not\naddress a range of ethical, license- and confidentiality-related issues\nassociated with peer reviewing data, preventing wide-scale research and\napplication development. While recent methods for peer review analysis and\nprocessing show promise, a solid data foundation for computational research in\npeer review is still missing. To address this, we present an in-depth\ndiscussion of peer reviewing data, outline the ethical and legal desiderata for\npeer reviewing data collection, and propose the first continuous,\ndonation-based data collection workflow that meets these requirements. We\nreport on the ongoing implementation of this workflow at the ACL Rolling Review\nand deliver the first insights obtained with the newly collected data.",
    "descriptor": "",
    "authors": [
      "Nils Dycke",
      "Ilia Kuznetsov",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11443"
  },
  {
    "id": "arXiv:2201.11448",
    "title": "Uncertainty Assessment of Dynamic Thermal Line Rating for Operational  Use at Transmission System Operators",
    "abstract": "Transmission system operators (TSOs) in recent years have faced challenges in\norder to ensure maximum transmission capacity of the system to satisfy market\nneeds, while maintaining operational safety and permissible impact on the\nenvironment. A great help in the decision-making process was introduced with\nthe Dynamic Thermal Rating (DTR) - an instrument to monitor and predict the\nmaximal allowed ampacity of the power grid based on weather measurements and\nforecast. However, the introduction of DTR raises a number of questions related\nto the accuracy and uncertainty of the results of thermal assessment and the\nlevel of acceptable risk and its management. In this paper, we present a\nsolution for estimating DTR uncertainty, appropriate for operational use at\nTSOs. With the help of conductor surface temperature measurements, weather\nmeasurements and predicted weather data, we also estimate the error of the\nweather forecast and the DTR itself. Following the results of the data\nanalyses, we build an operative solution for estimating the ampacity\nuncertainty based on Monte Carlo random simulations and integrate it into the\noperational environment of ELES - the operator of the Slovenian electric power\ntransmission network.",
    "descriptor": "",
    "authors": [
      "Aleksandra Rashkovska",
      "Mitja Jan\u010di\u010d",
      "Matja\u017e Depolli",
      "Janko Kosma\u010d",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11448"
  },
  {
    "id": "arXiv:2201.11449",
    "title": "A Generalization of the Stratonovich's Value of Information and  Application to Privacy-Utility Trade-off",
    "abstract": "The Stratonovich's value of information (VoI) is quantity that measure how\nmuch inferential gain is obtained from a perturbed sample under information\nleakage constraint. In this paper, we introduce a generalized VoI for a general\nloss function and general information leakage. Then we derive an upper bound of\nthe generalized VoI. Moreover, for a classical loss function, we provide a\nachievable condition of the upper bound which is weaker than that of in\nprevious studies. Since VoI can be viewed as a formulation of a privacy-utility\ntrade-off (PUT) problem, we provide an interpretation of the achievable\ncondition in the PUT context.",
    "descriptor": "",
    "authors": [
      "Akira Kamatsuka",
      "Takahiro Yoshida",
      "Toshiyasu Matsushima"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11449"
  },
  {
    "id": "arXiv:2201.11450",
    "title": "In Defense of Kalman Filtering for Polyp Tracking from Colonoscopy  Videos",
    "abstract": "Real-time and robust automatic detection of polyps from colonoscopy videos\nare essential tasks to help improve the performance of doctors during this\nexam. The current focus of the field is on the development of accurate but\ninefficient detectors that will not enable a real-time application. We advocate\nthat the field should instead focus on the development of simple and efficient\ndetectors that an be combined with effective trackers to allow the\nimplementation of real-time polyp detectors. In this paper, we propose a Kalman\nfiltering tracker that can work together with powerful, but efficient\ndetectors, enabling the implementation of real-time polyp detectors. In\nparticular, we show that the combination of our Kalman filtering with the\ndetector PP-YOLO shows state-of-the-art (SOTA) detection accuracy and real-time\nprocessing. More specifically, our approach has SOTA results on the\nCVC-ClinicDB dataset, with a recall of 0.740, precision of 0.869, $F_1$ score\nof 0.799, an average precision (AP) of 0.837, and can run in real time (i.e.,\n30 frames per second). We also evaluate our method on a subset of the\nHyper-Kvasir annotated by our clinical collaborators, resulting in SOTA\nresults, with a recall of 0.956, precision of 0.875, $F_1$ score of 0.914, AP\nof 0.952, and can run in real time.",
    "descriptor": "\nComments: Paper accepted to the International Symposium on Biomedical Imaging (ISBI) 2022\n",
    "authors": [
      "David Butler",
      "Yuan Zhang",
      "Tim Chen",
      "Seon Ho Shin",
      "Rajvinder Singh",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11450"
  },
  {
    "id": "arXiv:2201.11451",
    "title": "Setting AI in context: A case study on defining the context and  operational design domain for automated driving",
    "abstract": "[Context and motivation] For automated driving systems, the operational\ncontext needs to be known in order to state guarantees on performance and\nsafety. The operational design domain (ODD) is an abstraction of the\noperational context, and its definition is an integral part of the system\ndevelopment process. [Question / problem] There are still major uncertainties\nin how to clearly define and document the operational context in a diverse and\ndistributed development environment such as the automotive industry. This case\nstudy investigates the challenges with context definitions for the development\nof perception functions that use machine learning for automated driving.\n[Principal ideas/results] Based on qualitative analysis of data from\nsemi-structured interviews, the case study shows that there is a lack of\nstandardisation for context definitions across the industry, ambiguities in the\nprocesses that lead to deriving the ODD, missing documentation of assumptions\nabout the operational context, and a lack of involvement of function developers\nin the context definition. [Contribution] The results outline challenges\nexperienced by an automotive supplier company when defining the operational\ncontext for systems using machine learning. Furthermore, the study collected\nideas for potential solutions from the perspective of practitioners.",
    "descriptor": "\nComments: Accepted for the 28th International Working Conference on Requirement Engineering: Foundation for Software Quality\n",
    "authors": [
      "Hans-Martin Heyn",
      "Padmini Subbiash",
      "Jennifer Linder",
      "Eric Knauss",
      "Olof Eriksson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11451"
  },
  {
    "id": "arXiv:2201.11454",
    "title": "Estimating the Capacities of Function-as-a-Service Functions",
    "abstract": "Serverless computing is a cloud computing paradigm that allows developers to\nfocus exclusively on business logic as cloud service providers manage resource\nmanagement tasks. Serverless applications follow this model, where the\napplication is decomposed into a set of fine-grained Function-as-a-Service\n(FaaS) functions. However, the obscurities of the underlying system\ninfrastructure and dependencies between FaaS functions within the application\npose a challenge for estimating the performance of FaaS functions. To\ncharacterize the performance of a FaaS function that is relevant for the user,\nwe define Function Capacity (FC) as the maximal number of concurrent\ninvocations the function can serve in a time without violating the\nService-Level Objective (SLO).\nThe paper addresses the challenge of quantifying the FC individually for each\nFaaS function within a serverless application. This challenge is addressed by\nsandboxing a FaaS function and building its performance model. To this end, we\ndevelop FnCapacitor - an end-to-end automated Function Capacity estimation\ntool. We demonstrate the functioning of our tool on Google Cloud Functions\n(GCF) and AWS Lambda. FnCapacitor estimates the FCs on different deployment\nconfigurations (allocated memory & maximum function instances) by conducting\ntime-framed load tests and building various models using statistical: linear,\nridge, and polynomial regression, and Deep Neural Network (DNN) methods on the\nacquired performance data. Our evaluation of different FaaS functions shows\nrelatively accurate predictions, with an accuracy greater than 75% using DNN\nfor both cloud providers.",
    "descriptor": "\nComments: 8 pages, Accepted at CloudAM'21 Workshop (UCC)\n",
    "authors": [
      "Anshul Jindal",
      "Mohak Chadha",
      "Shajulin Benedict",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2201.11454"
  },
  {
    "id": "arXiv:2201.11460",
    "title": "RelTR: Relation Transformer for Scene Graph Generation",
    "abstract": "Different objects in the same scene are more or less related to each other,\nbut only a limited number of these relationships are noteworthy. Inspired by\nDETR, which excels in object detection, we view scene graph generation as a set\nprediction problem and propose an end-to-end scene graph generation model RelTR\nwhich has an encoder-decoder architecture. The encoder reasons about the visual\nfeature context while the decoder infers a fixed-size set of triplets\nsubject-predicate-object using different types of attention mechanisms with\ncoupled subject and object queries. We design a set prediction loss performing\nthe matching between the ground truth and predicted triplets for the end-to-end\ntraining. In contrast to most existing scene graph generation methods, RelTR is\na one-stage method that predicts a set of relationships directly only using\nvisual appearance without combining entities and labeling all possible\npredicates. Extensive experiments on the Visual Genome and Open Images V6\ndatasets demonstrate the superior performance and fast inference of our model.",
    "descriptor": "",
    "authors": [
      "Yuren Cong",
      "Michael Ying Yang",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11460"
  },
  {
    "id": "arXiv:2201.11462",
    "title": "Multiple-antenna Placement Delivery Array for Cache-aided MISO Systems",
    "abstract": "We consider the cache-aided multiple-input single-output (MISO) broadcast\nchannel, which consists of a server with $L$ antennas and $K$ single-antenna\nusers, where the server contains $N$ files of equal length and each user is\nequipped with a local cache of size $M$ files. Each user requests an arbitrary\nfile from library. The objective is to design a coded caching scheme based on\nuncoded placement and one-shot linear delivery phases, to achieve the maximum\nworst-case sum Degree-of-Freedom (sum-DoF) with low subpacketization.\nPreviously proposed schemes for this setting incurred either an exponential\nsubpacketization order in $K$, or required specific conditions in the system\nparameters $L$, $K$, $M$ and $N$. In this paper, we propose a new combinatorial\nstructure called multiple-antenna placement delivery array (MAPDA). Based on\nMAPDA and Latin square, the first proposed scheme achieves the sum-DoF\n$L+\\frac{KM}{N}$ with the subpacketization of $K$ when $\\frac{KM}{N}+L=K$.\nSubsequently, for the general case we propose a transformation approach to\nconstruct an MAPDA from any $g$-regular PDA (a class of PDA where each integer\nin the array occurs $g$ times) for the original shared-link coded caching\nproblem. If the original PDA is the seminal coded caching scheme proposed by\nMaddah-Ali and Niesen, the resulting scheme can achieve the sum-DoF\n$L+\\frac{KM}{N}$ with reduced subpacketization than the existing schemes.The\nwork can be extended to the multiple independent single-antenna transmitters\n(servers) corresponding to the cache-aided interference channel proposed by\nNaderializadeh et al. and the scenario of transmitters equipped with multiple\nantennas.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Ting Yang",
      "Kai Wan",
      "Minquan Cheng",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11462"
  },
  {
    "id": "arXiv:2201.11463",
    "title": "Quantile-Based Policy Optimization for Reinforcement Learning",
    "abstract": "Classical reinforcement learning (RL) aims to optimize the expected\ncumulative rewards. In this work, we consider the RL setting where the goal is\nto optimize the quantile of the cumulative rewards. We parameterize the policy\ncontrolling actions by neural networks and propose a novel policy gradient\nalgorithm called Quantile-Based Policy Optimization (QPO) and its variant\nQuantile-Based Proximal Policy Optimization (QPPO) to solve deep RL problems\nwith quantile objectives. QPO uses two coupled iterations running at different\ntime scales for simultaneously estimating quantiles and policy parameters and\nis shown to converge to the global optimal policy under certain conditions. Our\nnumerical results demonstrate that the proposed algorithms outperform the\nexisting baseline algorithms under the quantile criterion.",
    "descriptor": "",
    "authors": [
      "Jinyang Jiang",
      "Jiaqiao Hu",
      "Yijie Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11463"
  },
  {
    "id": "arXiv:2201.11464",
    "title": "Foundations for Entailment Checking in Quantitative Separation Logic  (extended version)",
    "abstract": "Quantitative separation logic (QSL) is an extension of separation logic (SL)\nfor the verification of probabilistic pointer programs. In QSL, formulae\nevaluate to real numbers instead of truth values, e.g., the probability of\nmemory-safe termination in a given symbolic heap. As with \\SL, one of the key\nproblems when reasoning with QSL is \\emph{entailment}: does a formula f entail\nanother formula g?\nWe give a generic reduction from entailment checking in QSL to entailment\nchecking in SL. This allows to leverage the large body of SL research for the\nautomated verification of probabilistic pointer programs. We analyze the\ncomplexity of our approach and demonstrate its applicability. In particular, we\nobtain the first decidability results for the verification of such programs by\napplying our reduction to a quantitative extension of the well-known\nsymbolic-heap fragment of separation logic.",
    "descriptor": "\nComments: Extended version of ESOP'22 paper\n",
    "authors": [
      "Kevin Batz",
      "Ira Fesefeldt",
      "Marvin Jansen",
      "Joost-Pieter Katoen",
      "Florian Ke\u00dfler",
      "Christoph Matheja",
      "Thomas Noll"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.11464"
  },
  {
    "id": "arXiv:2201.11465",
    "title": "Coded Caching for Two-Dimensional Multi-Access Networks",
    "abstract": "This paper studies a novel multi-access coded caching (MACC) model in\ntwo-dimensional (2D) topology, which is a generalization of the one-dimensional\n(1D) MACC model proposed by Hachem et al. We formulate a 2D MACC coded caching\nmodel, formed by a server containing $N$ files, $K_1\\times K_2$ cache-nodes\nwith limited memory $M$ which are placed on a grid with $K_1$ rows and $K_2$\ncolumns, and $K_1\\times K_2$ cache-less users such that each user is connected\nto $L^2$ nearby cache-nodes. More precisely, for each row (or column), every\nuser can access $L$ consecutive cache-nodes, referred to as row (or column) 1D\nMACC problem in the 2D MACC model. The server is connected to the users through\nan error-free shared link, while the users can retrieve the cached content of\nthe connected cache-nodes without cost. Our objective is to minimize the\nworst-case transmission load among all possible users' demands. In this paper,\nwe propose a baseline scheme which directly extends an existing 1D MACC scheme\nto the 2D model by using a Minimum Distance Separable (MDS) code, and two\nimproved schemes. In the first scheme referred to as grouping scheme, which\nworks when $K_1$ and $K_2$ are divisible by $L$, we partition the cache-nodes\nand users into $L^2$ groups according to their positions, such that no two\nusers in the same group share any cache-node, and we utilize the seminal\nshared-link coded caching scheme proposed by Maddah-Ali and Niesen for each\ngroup. Subsequently, for any model parameters satisfying $\\min\\{K_1,K_2\\}>L$ we\npropose the second scheme, referred to as hybrid scheme, consisting in a highly\nnon-trivial way to construct a 2D MACC scheme through a vertical and a\nhorizontal 1D MACC schemes.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Mingming Zhang",
      "Kai Wan",
      "Minquan Cheng",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11465"
  },
  {
    "id": "arXiv:2201.11473",
    "title": "Reasoning Like Program Executors",
    "abstract": "Reasoning over natural language is a long-standing goal for the research\ncommunity. However, studies have shown that existing language models are\ninadequate in reasoning. To address the issue, we present POET, a new\npre-training paradigm. Through pre-training language models with programs and\ntheir execution results, POET empowers language models to harvest the reasoning\nknowledge possessed in program executors via a data-driven approach. POET is\nconceptually simple and can be instantiated by different kinds of programs. In\nthis paper, we show three empirically powerful instances, i.e., POET-Math,\nPOET-Logic, and POET-SQL. Experimental results on six benchmarks demonstrate\nthat POET can significantly boost model performance on natural language\nreasoning, such as numerical reasoning, logical reasoning, and multi-hop\nreasoning. Taking the DROP benchmark as a representative example, POET improves\nthe F1 metric of BART from 69.2% to 80.6%. Furthermore, POET shines in giant\nlanguage models, pushing the F1 metric of T5-11B to 87.6% and achieving a new\nstate-of-the-art performance on DROP. POET opens a new gate on\nreasoning-enhancement pre-training and we hope our analysis would shed light on\nthe future research of reasoning like program executors.",
    "descriptor": "\nComments: Work in progress.The first two authors contributed equally\n",
    "authors": [
      "Xinyu Pi",
      "Qian Liu",
      "Bei Chen",
      "Morteza Ziyadi",
      "Zeqi Lin",
      "Yan Gao",
      "Qiang Fu",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2201.11473"
  },
  {
    "id": "arXiv:2201.11479",
    "title": "Eye-focused Detection of Bell's Palsy in Videos",
    "abstract": "In this paper, we present how Bell's Palsy, a neurological disorder, can be\ndetected just from a subject's eyes in a video. We notice that Bell's Palsy\npatients often struggle to blink their eyes on the affected side. As a result,\nwe can observe a clear contrast between the blinking patterns of the two eyes.\nAlthough previous works did utilize images/videos to detect this disorder, none\nhave explicitly focused on the eyes. Most of them require the entire face. One\nobvious advantage of having an eye-focused detection system is that subjects'\nanonymity is not at risk. Also, our AI decisions based on simple blinking\npatterns make them explainable and straightforward. Specifically, we develop a\nnovel feature called blink similarity, which measures the similarity between\nthe two blinking patterns. Our extensive experiments demonstrate that the\nproposed feature is quite robust, for it helps in Bell's Palsy detection even\nwith very few labels. Our proposed eye-focused detection system is not only\ncheaper but also more convenient than several existing methods.",
    "descriptor": "\nComments: Published in the Proceedings of the 34th Canadian Conference on Artificial Intelligence. Please cite this paper in the following manner: S. A. Ansari, K. R. Jerripothula, P. Nagpal, and A. Mittal. \"Eye-focused Detection of Bell's Palsy in Videos\". In: Proceedings of the 34th Canadian Conference on Artificial Intelligence (June 8, 2021). doi: 10.21428/594757db.d2f8342b\n",
    "authors": [
      "Sharik Ali Ansari",
      "Koteswar Rao Jerripothula",
      "Pragya Nagpal",
      "Ankush Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.11479"
  },
  {
    "id": "arXiv:2201.11481",
    "title": "Multi-Access Cache-Aided Multi-User Private Information Retrieval",
    "abstract": "In this paper we consider the problem of multi-access cache-aided multi-user\nPrivate Information Retrieval (MuPIR). In this problem, several files are\nreplicated across multiple servers. There are multiple users and multiple cache\nnodes. Each user can access several cache nodes and every cache node can be\naccessed by several users. Each user wants to retrieve one file from the\nservers, but users don't want servers to know their demands. This problem is an\nextension of dedicated cache-aided MuPIR problem, which itself generalizes\nsingle user PIR setup. In this paper, we propose an order optimal MuPIR scheme\nthat utilizes multi-access setup of the coded caching problem.",
    "descriptor": "\nComments: 15 pages, 11 figures, 2 tables\n",
    "authors": [
      "Kanishak Vaidya",
      "B Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11481"
  },
  {
    "id": "arXiv:2201.11483",
    "title": "Edge effects in radial porosity profiles from CT measurements and melt  pool signal intensities for laser powder bed fusion",
    "abstract": "Limited process control can cause metallurgical defect formation and\ninhomogeneous relative density in laser powder bed fusion manufactured parts.\nIn this study, cylindrical 15-5 PH stainless steel specimens are investigated\nby computer tomography; it shows an edge enhanced relative density profile.\nAdditionally, the on axis monitoring signal, obtained from recording the\nthermal radiation of the melt pool, is considered. Analyzing data for the full\nduration of the building process results in a statistically increased melt pool\nsignature close to the edge corresponding to the density profile. Edge specific\npatterns in the on axis signal are found by unsupervised times series\nclustering. The observations are interpreted using finite element method\nmodeling: For exemplary points at the center and edge it shows different local\nthermal histories attributed to the chosen laser scan pattern. The results\nmotivate a route towards future design of components with locally dependent\nmaterial parameters.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jorrit Voigt",
      "Thomas Bock",
      "Uwe Hilpert",
      "Ralf Hellmann",
      "Michael Moeckel"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2201.11483"
  },
  {
    "id": "arXiv:2201.11486",
    "title": "FinGAN: Generative Adversarial Network for Analytical Customer  Relationship Management in Banking and Insurance",
    "abstract": "Churn prediction in credit cards, fraud detection in insurance, and loan\ndefault prediction are important analytical customer relationship management\n(ACRM) problems. Since frauds, churns and defaults happen less frequently, the\ndatasets for these problems turn out to be naturally highly unbalanced.\nConsequently, all supervised machine learning classifiers tend to yield\nsubstantial false-positive rates when trained on such unbalanced datasets. We\npropose two ways of data balancing. In the first, we propose an oversampling\nmethod to generate synthetic samples of minority class using Generative\nAdversarial Network (GAN). We employ Vanilla GAN [1], Wasserstein GAN [2] and\nCTGAN [3] separately to oversample the minority class samples. In order to\nassess the efficacy of our proposed approach, we use a host of machine learning\nclassifiers, including Random Forest, Decision Tree, support vector machine\n(SVM), and Logistic Regression on the data balanced by GANs. In the second\nmethod, we introduce a hybrid method to handle data imbalance. In this second\nway, we utilize the power of undersampling and over-sampling together by\naugmenting the synthetic minority class data oversampled by GAN with the\nundersampled majority class data obtained by one-class support vigor machine\n(OCSVM) [4]. We combine both over-sampled data generated by GAN and the data\nunder-sampled by OCSVM [4] and pass the resultant data to classifiers. When we\ncompared our results to those of Farquad et al. [5], Sundarkumar, Ravi, and\nSiddeshwar [6], our proposed methods outperform the previous results in terms\nof the area under the ROC curve (AUC) on all datasets.",
    "descriptor": "\nComments: 22 pages; 3 figures; 15 tables\n",
    "authors": [
      "Prateek Kate",
      "Vadlamani Ravi",
      "Akhilesh Gangwar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.11486"
  },
  {
    "id": "arXiv:2201.11489",
    "title": "The Implicit Bias of Benign Overfitting",
    "abstract": "The phenomenon of benign overfitting, where a predictor perfectly fits noisy\ntraining data while attaining low expected loss, has received much attention in\nrecent years, but still remains not fully understood beyond simple linear\nregression setups. In this paper, we show that for regression, benign\noverfitting is \"biased\" towards certain types of problems, in the sense that\nits existence on one learning problem excludes its existence on other learning\nproblems. On the negative side, we use this to argue that one should not expect\nbenign overfitting to occur in general, for several natural extensions of the\nplain linear regression problems studied so far. We then turn to classification\nproblems, and show that the situation there is much more favorable.\nSpecifically, we consider a model where an arbitrary input distribution of some\nfixed dimension $k$ is concatenated with a high-dimensional distribution, and\nprove that the max-margin predictor (to which gradient-based methods are known\nto converge in direction) is asymptotically biased towards minimizing the\nexpected *squared hinge loss* w.r.t. the $k$-dimensional distribution. This\nallows us to reduce the question of benign overfitting in classification to the\nsimpler question of whether this loss is a good surrogate for the prediction\nerror, and use it to show benign overfitting in some new settings.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11489"
  },
  {
    "id": "arXiv:2201.11491",
    "title": "Almost-$C^1$ splines: Biquadratic splines on unstructured quadrilateral  meshes and their application to fourth order problems",
    "abstract": "Isogeometric Analysis generalizes classical finite element analysis and\nintends to integrate it with the field of Computer-Aided Design. A central\nproblem in achieving this objective is the reconstruction of analysis-suitable\nmodels from Computer-Aided Design models, which is in general a non-trivial and\ntime-consuming task. In this article, we present a novel spline construction,\nthat enables model reconstruction as well as simulation of high-order PDEs on\nthe reconstructed models. The proposed almost-$C^1$ are biquadratic splines on\nfully unstructured quadrilateral meshes (without restrictions on placements or\nnumber of extraordinary vertices). They are $C^1$ smooth almost everywhere,\nthat is, at all vertices and across most edges, and in addition almost (i.e.\napproximately) $C^1$ smooth across all other edges. Thus, the splines form\n$H^2$-nonconforming analysis-suitable discretization spaces. This is the\nlowest-degree unstructured spline construction that can be used to solve\nfourth-order problems. The associated spline basis is non-singular and has\nseveral B-spline-like properties (e.g., partition of unity, non-negativity,\nlocal support), the almost-$C^1$ splines are described in an explicit\nB\\'ezier-extraction-based framework that can be easily implemented. Numerical\ntests suggest that the basis is well-conditioned and exhibits optimal\napproximation behavior.",
    "descriptor": "",
    "authors": [
      "Thomas Takacs",
      "Deepesh Toshniwal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11491"
  },
  {
    "id": "arXiv:2201.11494",
    "title": "GraphTune: A Learning-based Graph Generative Model with Tunable  Structural Features",
    "abstract": "Generative models for graphs have been actively studied for decades, and they\nhave a wide range of applications. Recently, learning-based graph generation\nthat reproduces real-world graphs has gradually attracted the attention of many\nresearchers. Several generative models that utilize modern machine learning\ntechnologies have been proposed, though a conditional generation of general\ngraphs is less explored in the field. In this paper, we propose a generative\nmodel that allows us to tune a value of a global-level structural feature as a\ncondition. Our model called GraphTune enables to tune a value of any structural\nfeature of generated graphs using Long Short Term Memory (LSTM) and Conditional\nVariational AutoEncoder (CVAE). We performed comparative evaluations of\nGraphTune and conventional models with a real graph dataset. The evaluations\nshow that GraphTune enables to clearly tune a value of a global-level\nstructural feature compared to the conventional models.",
    "descriptor": "\nComments: An earlier and short version of this paper was presented at the 41st IEEE International Conference on Distributed Computing Systems (ICDCS 2021) Poster Track\n",
    "authors": [
      "Shohei Nakazawa",
      "Yoshiki Sato",
      "Sho Tsugawa",
      "Kenji Nakagawa",
      "Kohei Watabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11494"
  },
  {
    "id": "arXiv:2201.11500",
    "title": "Head and eye egocentric gesture recognition for human-robot interaction  using eyewear cameras",
    "abstract": "Non-verbal communication plays a particularly important role in a wide range\nof scenarios in Human-Robot Interaction (HRI). Accordingly, this work addresses\nthe problem of human gesture recognition. In particular, we focus on head and\neye gestures, and adopt an egocentric (first-person) perspective using eyewear\ncameras. We argue that this egocentric view offers a number of conceptual and\ntechnical benefits over scene- or robot-centric perspectives.\nA motion-based recognition approach is proposed, which operates at two\ntemporal granularities. Locally, frame-to-frame homographies are estimated with\na convolutional neural network (CNN). The output of this CNN is input to a long\nshort-term memory (LSTM) to capture longer-term temporal visual relationships,\nwhich are relevant to characterize gestures.\nRegarding the configuration of the network architecture, one particularly\ninteresting finding is that using the output of an internal layer of the\nhomography CNN increases the recognition rate with respect to using the\nhomography matrix itself. While this work focuses on action recognition, and no\nrobot or user study has been conducted yet, the system has been de signed to\nmeet real-time constraints. The encouraging results suggest that the proposed\negocentric perspective is viable, and this proof-of-concept work provides novel\nand useful contributions to the exciting area of HRI.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Javier Marina-Miranda",
      "V. Javier Traver"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11500"
  },
  {
    "id": "arXiv:2201.11501",
    "title": "From Motion to Muscle",
    "abstract": "Voluntary human motion is the product of muscle activity that results from\nupstream motion planning of the motor cortical areas. We show that muscle\nactivity can be artificially generated based on motion features such as\nposition, velocity, and acceleration. For this purpose, we specifically develop\nan approach based on recurrent neural network that is trained in a supervised\nlearning session; additional neural network architectures are considered and\nevaluated. The performance is evaluated by a new score called the zero-line\nscore. The latter adaptively rescales the loss function of the generated signal\nfor all channels comparing the overall range of muscle activity and thus\ndynamically evaluates similarities between both signals. The model achieves\nremarkable precision for previously trained movements and maintains\nsignificantly high precision for new movements that have not been previously\ntrained. Further, these models are trained on multiple subjects and thus are\nable to generalize across individuals. In addition, we distinguish between a\ngeneral model that has been trained on several subjects, a subject-specific\nmodel, and a specific pre-trained model that uses the general model as a basis\nand is adapted to a specific subject afterward. The subject-specific generation\nof muscle activity can be further used to improve the rehabilitation of\nneuromuscular diseases with myoelectric prostheses and functional electric\nstimulation.",
    "descriptor": "",
    "authors": [
      "Marie Dominique Schmidt",
      "Tobias Glasmachers",
      "Ioannis Iossifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11501"
  },
  {
    "id": "arXiv:2201.11503",
    "title": "Surprisingly Robust In-Hand Manipulation: An Empirical Study",
    "abstract": "We present in-hand manipulation skills on a dexterous, compliant,\nanthropomorphic hand. Even though these skills were derived in a simplistic\nmanner, they exhibit surprising robustness to variations in shape, size,\nweight, and placement of the manipulated object. They are also very insensitive\nto variation of execution speeds, ranging from highly dynamic to quasi-static.\nThe robustness of the skills leads to compositional properties that enable\nextended and robust manipulation programs. To explain the surprising robustness\nof the in-hand manipulation skills, we performed a detailed, empirical analysis\nof the skills' performance. From this analysis, we identify three principles\nfor skill design: 1) Exploiting the hardware's innate ability to drive\nhard-to-model contact dynamics. 2) Taking actions to constrain these\ninteractions, funneling the system into a narrow set of possibilities. 3)\nComposing such action sequences into complex manipulation programs. We believe\nthat these principles constitute an important foundation for robust robotic\nin-hand manipulation, and possibly for manipulation in general.",
    "descriptor": "\nComments: Published in Robotics: Science and Systems 2021. Proceedings at this http URL Spotlight talk at this https URL Complete video playlist at this https URL\n",
    "authors": [
      "Aditya Bhatt",
      "Adrian Sieler",
      "Steffen Puhlmann",
      "Oliver Brock"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11503"
  },
  {
    "id": "arXiv:2201.11506",
    "title": "Anomaly Detection in Retinal Images using Multi-Scale Deep Feature  Sparse Coding",
    "abstract": "Convolutional Neural Network models have successfully detected retinal\nillness from optical coherence tomography (OCT) and fundus images. These CNN\nmodels frequently rely on vast amounts of labeled data for training, difficult\nto obtain, especially for rare diseases. Furthermore, a deep learning system\ntrained on a data set with only one or a few diseases cannot detect other\ndiseases, limiting the system's practical use in disease identification. We\nhave introduced an unsupervised approach for detecting anomalies in retinal\nimages to overcome this issue. We have proposed a simple, memory efficient,\neasy to train method which followed a multi-step training technique that\nincorporated autoencoder training and Multi-Scale Deep Feature Sparse Coding\n(MDFSC), an extended version of normal sparse coding, to accommodate diverse\ntypes of retinal datasets. We achieve relative AUC score improvement of 7.8\\%,\n6.7\\% and 12.1\\% over state-of-the-art SPADE on Eye-Q, IDRiD and OCTID datasets\nrespectively.",
    "descriptor": "\nComments: Accepted to ISBI 2022.\\copyright IEEE\n",
    "authors": [
      "Sourya Dipta Das",
      "Saikat Dutta",
      "Nisarg A. Shah",
      "Dwarikanath Mahapatra",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11506"
  },
  {
    "id": "arXiv:2201.11511",
    "title": "Density-Aware Hyper-Graph Neural Networks for Graph-based  Semi-supervised Node Classification",
    "abstract": "Graph-based semi-supervised learning, which can exploit the connectivity\nrelationship between labeled and unlabeled data, has been shown to outperform\nthe state-of-the-art in many artificial intelligence applications. One of the\nmost challenging problems for graph-based semi-supervised node classification\nis how to use the implicit information among various data to improve the\nperformance of classifying. Traditional studies on graph-based semi-supervised\nlearning have focused on the pairwise connections among data. However, the data\ncorrelation in real applications could be beyond pairwise and more complicated.\nThe density information has been demonstrated to be an important clue, but it\nis rarely explored in depth among existing graph-based semi-supervised node\nclassification methods. To develop a flexible and effective model for\ngraph-based semi-supervised node classification, we propose a novel\nDensity-Aware Hyper-Graph Neural Networks (DA-HGNN). In our proposed approach,\nhyper-graph is provided to explore the high-order semantic correlation among\ndata, and a density-aware hyper-graph attention network is presented to explore\nthe high-order connection relationship. Extensive experiments are conducted in\nvarious benchmark datasets, and the results demonstrate the effectiveness of\nthe proposed approach.",
    "descriptor": "",
    "authors": [
      "Jianpeng Liao",
      "Qian Tao",
      "Jun Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11511"
  },
  {
    "id": "arXiv:2201.11513",
    "title": "Robust topology optimization of structures under uncertain propagation  of imprecise stochastic-based uncertain field",
    "abstract": "This study introduces a novel computational framework for Robust Topology\nOptimization (RTO) considering imprecise random field parameters. Unlike the\nworst-case approach, the present method provides upper and lower bounds for the\nmean and standard deviation of compliance as well as the optimized topological\nlayouts of a structure for various scenarios. In the proposed approach, the\nimprecise random field variables are determined utilizing parameterized p-boxes\nwith different confidence intervals. The Karhunen-Lo\\`eve (K-L) expansion is\nextended to provide a spectral description of the imprecise random field. The\nlinear superposition method in conjunction with a linear combination of\northogonal functions is employed to obtain explicit mathematical expressions\nfor the first and second order statistical moments of the structural\ncompliance. Then, an interval sensitivity analysis is carried out, applying the\nOrthogonal Similarity Transformation (OST) method with the boundaries of each\nof the intermediate variable searched efficiently at every iteration using a\nCombinatorial Approach (CA). Finally, the validity, accuracy, and applicability\nof the work are rigorously checked by comparing the outputs of the proposed\napproach with those obtained using the particle swarm optimization (PSO) and\nQuasi-Monte-Carlo Simulation (QMCS) methods. Three different numerical examples\nwith imprecise random field loads are presented to show the effectiveness and\nfeasibility of the study.",
    "descriptor": "",
    "authors": [
      "Kang Gao",
      "Duy Minh Doc",
      "Sheng Chu",
      "Gang Wu",
      "H. Alicia Kim",
      "Carol A. Featherston"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.11513"
  },
  {
    "id": "arXiv:2201.11515",
    "title": "Study on the Data Processing of the IOT Sensor Network Based on Hadoop  Cloud Platform and TWLGA Scheduling Algorithm",
    "abstract": "The Internet of Things (IOT) sensor network is an effective solution for\nmonitoring environment condition. IOT sensor network generates massive data,\nand the abilities of massive data storage, processing and query become\ntechnical challenges. To solve the problem, a Hadoop cloud platform is\nproposed. With the help of time and workload genetic algorithm (TWLGA), the\ndata processing platform provides the work of one node to share with others,\nwhich not only raises efficiency of one single node, but also provides the\ncompatibility support to reduce the possible risk of software and hardware. In\nthe experiment, a Hadoop cluster platform with TWLGA scheduling algorithm is\nbuilt, and the performance of the platform is tested. The results show that the\nHadoop cloud platform is suitable for big data processing of the IOT sensor\nnetwork.",
    "descriptor": "\nComments: 9 pages,5 figures,Journal of Information Processing Systems\n",
    "authors": [
      "Guoyu Li",
      "Kang Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11515"
  },
  {
    "id": "arXiv:2201.11516",
    "title": "Survey on some optimization possibilities for data plane applications",
    "abstract": "By programming both the data plane and the control plane, network operators\ncan customize their networks based on their needs, regardless of the hardware\nmanufacturer. Control plane programming, a major component of the SDN (Software\nDefined Network) concept, has been developed for more than 10 years and\nsuccessfully implemented in real networks. Efforts to develop reconfigurable\ndata planes and high-level network programming languages make it truly possible\nto program data planes. Therefore, the programmable data planes and SDNs offer\ngreat flexibility in network customization, allowing many innovations to be\nintroduced on the network. The general focus of research on the data plane is\ndata-plane abstractions, languages and compilers, data plane algorithms, and\napplications. This paper outlines some emerging applications on the data plane\nand offers opportunities for further improvement and optimization.",
    "descriptor": "\nComments: Keywords: Data plane, load balancing, in-network caching, in-network computing, in-network data aggregation, INT\n",
    "authors": [
      "Gereltsetseg Altangerel",
      "Tejfel M\u00e1t\u00e9"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11516"
  },
  {
    "id": "arXiv:2201.11522",
    "title": "High-level Synthesis using the Julia Language",
    "abstract": "The growing proliferation of FPGAs and High-level Synthesis (HLS) tools has\nled to a large interest in designing hardware accelerators for complex\noperations and algorithms. However, existing HLS toolflows typically require a\nsignificant amount of user knowledge or training to be effective in both\nindustrial and research applications. In this paper, we propose using the Julia\nlanguage as the basis for an HLS tool. The Julia HLS tool aims to decrease the\nbarrier to entry for hardware acceleration by taking advantage of the\nreadability of the Julia language and by allowing the use of the existing large\nlibrary of standard mathematical functions written in Julia. We present a\nprototype Julia HLS tool, written in Julia, that transforms Julia code to VHDL.\nWe highlight how features of Julia and its compiler simplified the creation of\nthis tool, and we discuss potential directions for future work.",
    "descriptor": "",
    "authors": [
      "Benjamin Biggs",
      "Ian McInerney",
      "Eric C. Kerrigan",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.11522"
  },
  {
    "id": "arXiv:2201.11523",
    "title": "ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing  Images Semantic Segmentation",
    "abstract": "The performance of a semantic segmentation model for remote sensing (RS)\nimages pretrained on an annotated dataset would greatly decrease when testing\non another unannotated dataset because of the domain gap. Adversarial\ngenerative methods, e.g., DualGAN, are utilized for unpaired image-to-image\ntranslation to minimize the pixel-level domain gap, which is one of the common\napproaches for unsupervised domain adaptation (UDA). However, existing image\ntranslation methods are facing two problems when performing RS images\ntranslation: 1) ignoring the scale discrepancy between two RS datasets which\ngreatly affect the accuracy performance of scale-invariant objects, 2) ignoring\nthe characteristic of real-to-real translation of RS images which brings an\nunstable factor for the training of the models. In this paper, ResiDualGAN is\nproposed for RS images translation, where a resizer module is used for\naddressing the scale discrepancy of RS datasets, and a residual connection is\nused for strengthening the stability of real-to-real images translation and\nimproving the performance in cross-domain semantic segmentation tasks.\nCombining with an output space adaptation method, the proposed method greatly\nimproves the accuracy performance on common benchmarks, which demonstrates the\nsuperiority and reliability of ResiDuanGAN. At the end of the paper, a thorough\ndiscussion is also conducted to give a reasonable explanation for the\nimprovement of ResiDualGAN.",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Han Gao",
      "Peng Guo",
      "Zihao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11523"
  },
  {
    "id": "arXiv:2201.11524",
    "title": "Probabilistic Query Evaluation with Bag Semantics",
    "abstract": "Typically, probabilistic databases (PDBs) are probability distributions over\nthe subsets of a finite set of facts. However, many practical implementations\nof relational databases use a bag semantics that allows multiple copies of a\nfact. As facts may appear arbitrarily often, extending PDBs to a bag semantics\nnaturally leads to infinite PDBs, the mathematical framework of which as only\nbeen introduced recently by Grohe and Lindner (PODS 2019, ICDT 2020).\nIn this paper, we study the problem of query evaluation over PDBs with bag\nsemantics (bag PDBs). We focus on tuple-independent bag PDBs, which means that\nthe multiplicities of different facts are independent. In the set-based\nsetting, the complexity of probabilistic query evaluation is well-understood\nfor unions of conjunctive queries (UCQs): it is either in polynomial time, or\n#P-hard (Dalvi and Suciu, JACM 2012). The setting with bag semantics differs\nsubstantially. As PDBs are no longer finite, we need feasible representations.\nMoreover, the answer to a Boolean query is a probability distribution over\nnumbers, rather than a single probability. This yields different reasonable\ndefinitions of the query evaluation problem. First, we discuss computing the\nexpectation and variance of query answers. Surprisingly, under mild assumptions\non the representation, both problems are solvable in polynomial time for all\nUCQs. Second, we investigate the problem of computing the probability that the\nanswer is at most k, where k is a parameter. While key arguments from prior\nwork do not carry over to our setting, we show that the original dichotomy for\nBoolean self-join free CQs persists for most representations. Still, there are\nrepresentation systems where the problem is always solvable in polynomial time.",
    "descriptor": "",
    "authors": [
      "Martin Grohe",
      "Peter Lindner",
      "Christoph Standke"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.11524"
  },
  {
    "id": "arXiv:2201.11527",
    "title": "On the Mitigation of Read Disturbances in Neuromorphic Inference  Hardware",
    "abstract": "Non-Volatile Memory (NVM) cells are used in neuromorphic hardware to store\nmodel parameters, which are programmed as resistance states. NVMs suffer from\nthe read disturb issue, where the programmed resistance state drifts upon\nrepeated access of a cell during inference. Resistance drifts can lower the\ninference accuracy. To address this, it is necessary to periodically reprogram\nmodel parameters (a high overhead operation). We study read disturb failures of\nan NVM cell. Our analysis show both a strong dependency on model\ncharacteristics such as synaptic activation and criticality, and on the voltage\nused to read resistance states during inference. We propose a system software\nframework to incorporate such dependencies in programming model parameters on\nNVM cells of a neuromorphic hardware. Our framework consists of a convex\noptimization formulation which aims to implement synaptic weights that have\nmore activations and are critical, i.e., those that have high impact on\naccuracy on NVM cells that are exposed to lower voltages during inference. In\nthis way, we increase the time interval between two consecutive reprogramming\nof model parameters. We evaluate our system software with many emerging\ninference models on a neuromorphic hardware simulator and show a significant\nreduction in the system overhead.",
    "descriptor": "\nComments: Accepted for publications in IEEE Design and Test\n",
    "authors": [
      "Ankita Paul",
      "Shihao Song",
      "Twisha Titirsha",
      "Anup Das"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.11527"
  },
  {
    "id": "arXiv:2201.11528",
    "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for  Black-box Domains",
    "abstract": "Adversarial examples have posed a severe threat to deep neural networks due\nto their transferable nature. Currently, various works have paid great efforts\nto enhance the cross-model transferability, which mostly assume the substitute\nmodel is trained in the same domain as the target model. However, in reality,\nthe relevant information of the deployed model is unlikely to leak. Hence, it\nis vital to build a more practical black-box threat model to overcome this\nlimitation and evaluate the vulnerability of deployed models. In this paper,\nwith only the knowledge of the ImageNet domain, we propose a Beyond ImageNet\nAttack (BIA) to investigate the transferability towards black-box domains\n(unknown classification tasks). Specifically, we leverage a generative model to\nlearn the adversarial function for disrupting low-level features of input\nimages. Based on this framework, we further propose two variants to narrow the\ngap between the source and target domains from the data and model perspectives,\nrespectively. Extensive experiments on coarse-grained and fine-grained domains\ndemonstrate the effectiveness of our proposed methods. Notably, our methods\noutperform state-of-the-art approaches by up to 7.71\\% (towards coarse-grained\ndomains) and 25.91\\% (towards fine-grained domains) on average. Our code is\navailable at \\url{https://github.com/qilong-zhang/Beyond-ImageNet-Attack}.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Qilong Zhang",
      "Xiaodan Li",
      "Yuefeng Chen",
      "Jingkuan Song",
      "Lianli Gao",
      "Yuan He",
      "Hui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11528"
  },
  {
    "id": "arXiv:2201.11533",
    "title": "Transfer Portal: Accurately Forecasting the Impact of a Player Transfer  in Soccer",
    "abstract": "One of the most important and challenging problems in football is predicting\nfuture player performance when transferred to another club within and between\ndifferent leagues. In addition to being the most valuable prediction a team\nmakes, it is also the most complex analytics task to perform as it needs to\ntake into consideration: a) differences in playing style between the player's\ncurrent team and target team, b) differences in style and ability of other\nplayers on each team, c) differences in league quality and style, and d) the\nrole the player is desired to play. In this paper, we present a method which\naddresses these issues and enables us to make accurate predictions of future\nperformance. Our Transfer Portal model utilizes a personalized neural network\naccounting for both stylistic and ability level input representations for\nplayers, teams, and leagues to simulate future player performance at any chosen\nclub. Furthermore, we use a Bayesian updating framework to dynamically modify\nplayer and team representations over time which enables us to generate\npredictions for rising stars with small amounts of data.",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Daniel Dinsdale",
      "Joe Gallagher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11533"
  },
  {
    "id": "arXiv:2201.11538",
    "title": "Capacity and Achievable Rates of Fading Few-mode MIMO IM/DD Optical  Fiber Channels",
    "abstract": "The optical fiber multiple-input multiple-output (MIMO) channel with\nintensity modulation and direct detection (IM/DD) per spatial path is treated.\nThe spatial dimensions represent the multiple modes employed for transmission\nand the cross-talk between them originates in the multiplexers and\ndemultiplexers, which are polarization dependent and thus timevarying. The\nupper bounds from free-space IM/DD MIMO channels are adapted to the fiber case,\nand the constellation constrained capacity is constructively estimated using\nthe Blahut-Arimoto algorithm. An autoencoder is then proposed to optimize a\npractical MIMO transmission in terms of pre-coder and detector assuming channel\ndistribution knowledge at the transmitter. The pre-coders are shown to be\nrobust to changes in the channel.",
    "descriptor": "\nComments: International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Metodi P. Yankov",
      "Francesco Da Ros",
      "S\u00f8ren Forchhammer",
      "Lars Gruner-Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11538"
  },
  {
    "id": "arXiv:2201.11539",
    "title": "Coded Caching with Private Demands and Caches",
    "abstract": "Coded caching has been shown as a promissing method to reduce the network\nload in peak-traffic hours. In the coded caching literature, the notion of\nprivacy is considered only against demands. On the motivation that multi-round\ntransmissions almost appear everywhere in real communication systems, this\npaper formulates the coded caching problem with private demands and caches.\nOnly one existing private caching scheme, which is based on introducing virtual\nusers, can preserve the privacy of demands and caches simultaneously, but with\nan extremely large subpacketization exponential to the product of the numbers\nof users and files in the system. In order to reduce the subpacketization while\nsatisfying the privacy constraint, we propose a novel approach which constructs\nprivate coded caching schemes through private information retrieval (PIR).\nBased on this approach, we propose novel schemes with private demands and\ncaches which have a subpacketization level in the order exponential to $K$\n(number of users) against $NK$ in the virtual user scheme where $N$ stands for\nthe numbers of files. As a by-product, for the coded caching problem with\nprivate demands, a private coded caching scheme could be obtained from the\nproposed approach, which generally improves the memory-load tradeoff of the\nprivate coded caching scheme by Yan and Tuninetti.",
    "descriptor": "\nComments: 7 pages, 4 tables\n",
    "authors": [
      "Ali Gholami",
      "Kai Wan",
      "Hua Sun",
      "Mingyu Ji",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11539"
  },
  {
    "id": "arXiv:2201.11542",
    "title": "An improved judgement algorithm of point in-out convex polygons",
    "abstract": "This paper proposed a method to judge whether the point is inside or outside\nof the simple convex polygon by the intersection of the vertical line. It\ndetermined the point to an area enclosed by two straight lines, then convert\nthe problem of determining whether a point is inside or outside of a convex\npolygon into the problem of determining whether a point is inside or outside of\na quadrilateral. After that, use the ray method to judge it. The complexity of\nthis algorithm is O(1) to O(n). As the experimental results show, the algorithm\nhas fewer intersections and greatly improves the efficiency of the judgment.",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Sun Yixuan",
      "Zhu Zhehao"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11542"
  },
  {
    "id": "arXiv:2201.11547",
    "title": "ASOC: Adaptive Self-aware Object Co-localization",
    "abstract": "The primary goal of this paper is to localize objects in a group of\nsemantically similar images jointly, also known as the object co-localization\nproblem. Most related existing works are essentially weakly-supervised, relying\nprominently on the neighboring images' weak-supervision. Although weak\nsupervision is beneficial, it is not entirely reliable, for the results are\nquite sensitive to the neighboring images considered. In this paper, we combine\nit with a self-awareness phenomenon to mitigate this issue. By self-awareness\nhere, we refer to the solution derived from the image itself in the form of\nsaliency cue, which can also be unreliable if applied alone. Nevertheless,\ncombining these two paradigms together can lead to a better co-localization\nability. Specifically, we introduce a dynamic mediator that adaptively strikes\na proper balance between the two static solutions to provide an optimal\nsolution. Therefore, we call this method \\textit{ASOC}: Adaptive Self-aware\nObject Co-localization. We perform exhaustive experiments on several benchmark\ndatasets and validate that weak-supervision supplemented with self-awareness\nhas superior performance outperforming several compared competing methods.",
    "descriptor": "\nComments: Published in IEEE ICME 2021. Please cite this paper in the following manner: K. R. Jerripothula and P. Mukherjee, \"ASOC: Adaptive Self-Aware Object Co-Localization,\" 2021 IEEE International Conference on Multimedia and Expo (ICME), 2021, pp. 1-6, doi: 10.1109/ICME51207.2021.9428191\n",
    "authors": [
      "Koteswar Rao Jerripothula",
      "Prerana Mukherjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.11547"
  },
  {
    "id": "arXiv:2201.11550",
    "title": "Predecessor on the Ultra-Wide Word RAM",
    "abstract": "We consider the predecessor problem on the ultra-wide word RAM model of\ncomputation, which extends the word RAM model with 'ultrawords' consisting of\n$w^2$ bits [TAMC, 2015]. The model supports arithmetic and boolean operations\non ultrawords, in addition to 'scattered' memory operations that access or\nmodify $w$ (potentially non-contiguous) memory addresses simultaneously. The\nultra-wide word RAM model captures (and idealizes) modern vector processor\narchitectures.\nOur main result is a simple, linear space data structure that supports\npredecessor in constant time and updates in amortized, expected constant time.\nThis improves the space of the previous constant time solution that uses space\nin the order of the size of the universe.\nOur result is based on a new implementation of the classic $x$-fast trie data\nstructure of Willard [Inform.~Process.~Lett. 17(2), 1983] combined with a new\ndictionary data structure that supports fast parallel lookups.",
    "descriptor": "",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz",
      "Tord Stordalen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.11550"
  },
  {
    "id": "arXiv:2201.11569",
    "title": "Human Interpretation of Saliency-based Explanation Over Text",
    "abstract": "While a lot of research in explainable AI focuses on producing effective\nexplanations, less work is devoted to the question of how people understand and\ninterpret the explanation. In this work, we focus on this question through a\nstudy of saliency-based explanations over textual data. Feature-attribution\nexplanations of text models aim to communicate which parts of the input text\nwere more influential than others towards the model decision. Many current\nexplanation methods, such as gradient-based or Shapley value-based methods,\nprovide measures of importance which are well-understood mathematically. But\nhow does a person receiving the explanation (the explainee) comprehend it? And\ndoes their understanding match what the explanation attempted to communicate?\nWe empirically investigate the effect of various factors of the input, the\nfeature-attribution explanation, and visualization procedure, on laypeople's\ninterpretation of the explanation. We query crowdworkers for their\ninterpretation on tasks in English and German, and fit a GAMM model to their\nresponses considering the factors of interest. We find that people often\nmis-interpret the explanations: superficial and unrelated factors, such as word\nlength, influence the explainees' importance assignment despite the explanation\ncommunicating importance directly. We then show that some of this distortion\ncan be attenuated: we propose a method to adjust saliencies based on model\nestimates of over- and under-perception, and explore bar charts as an\nalternative to heatmap saliency visualization. We find that both approaches can\nattenuate the distorting effect of specific factors, leading to\nbetter-calibrated understanding of the explanation.",
    "descriptor": "",
    "authors": [
      "Hendrik Schuff",
      "Alon Jacovi",
      "Heike Adel",
      "Yoav Goldberg",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11569"
  },
  {
    "id": "arXiv:2201.11576",
    "title": "Grad2Task: Improved Few-shot Text Classification Using Gradients for  Task Representation",
    "abstract": "Large pretrained language models (LMs) like BERT have improved performance in\nmany disparate natural language processing (NLP) tasks. However, fine tuning\nsuch models requires a large number of training examples for each target task.\nSimultaneously, many realistic NLP problems are \"few shot\", without a\nsufficiently large training set. In this work, we propose a novel conditional\nneural process-based approach for few-shot text classification that learns to\ntransfer from other diverse tasks with rich annotation. Our key idea is to\nrepresent each task using gradient information from a base model and to train\nan adaptation network that modulates a text classifier conditioned on the task\nrepresentation. While previous task-aware few-shot learners represent tasks by\ninput encoding, our novel task representation is more powerful, as the gradient\ncaptures input-output relationships of a task. Experimental results show that\nour approach outperforms traditional fine-tuning, sequential transfer learning,\nand state-of-the-art meta learning approaches on a collection of diverse\nfew-shot tasks. We further conducted analysis and ablations to justify our\ndesign choices.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jixuan Wang",
      "Kuan-Chieh Wang",
      "Frank Rudzicz",
      "Michael Brudno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11576"
  },
  {
    "id": "arXiv:2201.11577",
    "title": "On the Impact of Network Delays on Time-to-Live Caching",
    "abstract": "We consider Time-to-Live (TTL) caches that tag every object in cache with a\nspecific (and possibly renewable) expiration time. State-of-the-art models for\nTTL caches assume zero object fetch delay, i.e., the time required to fetch a\nrequested object that is not in cache from a different cache or the origin\nserver. Particularly, in cache hierarchies, this delay has a significant impact\non performance metrics such as the object hit probability. Recent work suggests\nthat the impact of the object fetch delay on the cache performance will\ncontinue to increase due to the scaling mismatch between shrinking\ninter-request times (due to higher data center link rates) in contrast to\nprocessing and memory access times.\nIn this paper, we analyze tree-based cache hierarchies with random object\nfetch delays and provide an exact analysis of the corresponding object hit\nprobability. Our analysis allows understanding the impact of random delays and\nTTLs on cache metrics for a wide class of request stream models characterized\nthrough Markov arrival processes. This is expressed through a metric that we\ndenote delay impairment of the hit probability. In addition, we analyze and\nextend state-of-the-art approximations of the hit probability to take the delay\ninto account. We provide numerical and trace-based simulation-based evaluation\nresults showing that larger TTLs do not efficiently compensate for the\ndetrimental effect of object fetch delays. Our evaluations also show that\nunlike our exact model the state-of-the-art approximations do not capture the\nimpact of the object fetch delay well especially for cache hierarchies.\nSurprisingly, we show that the impact of this delay on the hit probability is\nnot monotonic but depends on the request stream properties, as well as, the\nTTL.",
    "descriptor": "",
    "authors": [
      "Karim Elsayed",
      "Amr Rizk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11577"
  },
  {
    "id": "arXiv:2201.11578",
    "title": "KRCORE: a microsecond-scale RDMA control plane for elastic computing",
    "abstract": "Elastic computing such as disaggregated storage systems increasingly adopts\nRDMA to accelerate data plane operations (e.g., get and put). However, such\ncomputing systems usually require ephemeral operations to scale out computing\nresources, which demands fast control plane operations such as starting\ncontainers and establishing network connections. Unfortunately, building a\nconnection for RDMA usually requires several or tens of milliseconds, which is\n180-1800X higher than the execution time of typical RDMA-enabled systems\n(10-100 {\\mu}s) requiring elasticity. Such a high control plane cost may\nsignificantly reduce the efficiency of such systems when scaling out the\ncomputing resources. This paper presents KRCORE, an RDMA library with a\nmicrosecond-scale control plane on commodity RDMA-capable network interface\ncards. KRCORE can establish a network connection to any node in the cluster\nwithin 10{\\mu}s, while only maintaining a (small) fixed size of connection\nmetadata at each node, regardless of the cluster scale. The key ideas include\nvirtualizing a pre-initialized kernel-space RDMA connection instead of creating\none from scratch, and retrofiting advanced RDMA dynamic connected transport\nwith static transport for low connection overhead and high resource\nutilization. KRCORE shortens the worker bootstrap time of existing\ndisaggregated key-value store by 98% under load spikes. In serverless\ncomputing, another popular elastic and ephemeral computing system, KRCORE can\nreduce the latency for transferring data through RDMA by 99%.",
    "descriptor": "",
    "authors": [
      "Xingda Wei",
      "Fangming Lu",
      "Rong Chen",
      "Haibo Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11578"
  },
  {
    "id": "arXiv:2201.11579",
    "title": "Total variation-based phase retrieval for diffraction tomography",
    "abstract": "In optical diffraction tomography (ODT), the three-dimensional scattering\npotential of a microscopic object rotating around its center is recovered by a\nseries of illuminations with coherent light. Reconstruction algorithms such as\nthe filtered backpropagation require knowledge of the complex-valued wave at\nthe measurement plane, whereas often only intensities, i.e., phaseless\nmeasurements, are available in practice.\nWe propose a new reconstruction approach for ODT with unknown phase\ninformation based on three key ingredients. First, the light propagation is\nmodeled using Born's approximation enabling us to use the Fourier diffraction\ntheorem. Second, we stabilize the inversion of the non-uniform discrete Fourier\ntransform via total variation regularization utilizing a primal-dual iteration,\nwhich also yields a novel numerical inversion formula for ODT with known phase.\nThe third ingredient is a hybrid input-output scheme. We achieved convincing\nnumerical results, which indicate that ODT with phaseless data is possible. The\nso-obtained 2D and 3D reconstructions are even comparable to the ones with\nknown phase.",
    "descriptor": "",
    "authors": [
      "Robert Beinert",
      "Michael Quellmalz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2201.11579"
  },
  {
    "id": "arXiv:2201.11580",
    "title": "DecisionHoldem: Safe Depth-Limited Solving With Diverse Opponents for  Imperfect-Information Games",
    "abstract": "An imperfect-information game is a type of game with asymmetric information.\nIt is more common in life than perfect-information game. Artificial\nintelligence (AI) in imperfect-information games, such like poker, has made\nconsiderable progress and success in recent years. The great success of\nsuperhuman poker AI, such as Libratus and Deepstack, attracts researchers to\npay attention to poker research. However, the lack of open-source code limits\nthe development of Texas hold'em AI to some extent. This article introduces\nDecisionHoldem, a high-level AI for heads-up no-limit Texas hold'em with safe\ndepth-limited subgame solving by considering possible ranges of opponent's\nprivate hands to reduce the exploitability of the strategy. Experimental\nresults show that DecisionHoldem defeats the strongest openly available agent\nin heads-up no-limit Texas hold'em poker, namely Slumbot, and a high-level\nreproduction of Deepstack, viz, Openstack, by more than 730 mbb/h\n(one-thousandth big blind per round) and 700 mbb/h. Moreover, we release the\nsource codes and tools of DecisionHoldem to promote AI development in\nimperfect-information games.",
    "descriptor": "",
    "authors": [
      "Qibin Zhou",
      "Dongdong Bai",
      "Junge Zhang",
      "Fuqing Duan",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11580"
  },
  {
    "id": "arXiv:2201.11582",
    "title": "GUDN A novel guide network for extreme multi-label text classification",
    "abstract": "The problem of extreme multi-label text classification (XMTC) is to recall\nsome most relevant labels for a text from an extremely large label set. Though\nthe methods based on deep pre-trained models have reached significant\nachievement, the pre-trained models are still not fully utilized. Label\nsemantics has not attracted much attention so far, and the latent space between\ntexts and labels has not been effectively explored. This paper constructs a\nnovel guide network (GUDN) to help fine-tune the pre-trained model to instruct\nclassification later. Also, we use the raw label semantics to effectively\nexplore the latent space between texts and labels, which can further improve\npredicted accuracy. Experimental results demonstrate that GUDN outperforms\nstate-of-the-art methods on several popular datasets. Our source code is\nreleased at https://github.com/wq2581/GUDN.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Qing Wang",
      "Hongji Shu",
      "Jia Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11582"
  },
  {
    "id": "arXiv:2201.11587",
    "title": "Two-Commodity Flow is Equivalent to Linear Programming under  Nearly-Linear Time Reductions",
    "abstract": "We give a nearly-linear time reduction that encodes any linear program as a\n2-commodity flow problem with only a small blow-up in size. Under mild\nassumptions similar to those employed by modern fast solvers for linear\nprograms, our reduction causes only a polylogarithmic multiplicative increase\nin the size of the program and runs in nearly-linear time. Our reduction\napplies to high-accuracy approximation algorithms and exact algorithms. Given\nan approximate solution to the 2-commodity flow problem, we can extract a\nsolution to the linear program in linear time with only a polynomial factor\nincrease in the error. This implies that any algorithm that solves the\n2-commodity flow problem can solve linear programs in essentially the same\ntime. Given a directed graph with edge capacities and two source-sink pairs,\nthe goal of the 2-commodity flow problem is to maximize the sum of the flows\nrouted between the two source-sink pairs subject to edge capacities and flow\nconservation. A 2-commodity flow can be directly written as a linear program,\nand thus we establish a nearly-tight equivalence between these two classes of\nproblems.\nOur proof follows the outline of Itai's polynomial-time reduction of a linear\nprogram to a 2-commodity flow problem (JACM'78). Itai's reduction shows that\nexactly solving 2-commodity flow and exactly solving linear programming are\npolynomial-time equivalent. We improve Itai's reduction to nearly preserve the\nproblem representation size in each step. In addition, we establish an error\nbound for approximately solving each intermediate problem in the reduction, and\nshow that the accumulated error is polynomially bounded. We remark that our\nreduction does not run in strongly polynomial time and that it is open whether\n2-commodity flow and linear programming are equivalent in strongly polynomial\ntime.",
    "descriptor": "\nComments: 65 pages, 6 figures\n",
    "authors": [
      "Ming Ding",
      "Rasmus Kyng",
      "Peng Zhang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11587"
  },
  {
    "id": "arXiv:2201.11590",
    "title": "Analysis and Optimization of the Latency Budget in Wireless Systems with  Mobile Edge Computing",
    "abstract": "We present a framework to analyse the latency budget in wireless systems with\nMobile Edge Computing (MEC). Our focus is on teleoperation and telerobotics, as\nuse cases that are representative of mission-critical uplink-intensive IoT\nsystems with requirements on low latency and high reliability. The study is\nmotivated by a general question: What is the optimal compression strategy in\nreliability and latency constrained systems? We address this question by\nstudying the latency of an uplink connection from a multi-sensor IoT device to\nthe base station. This is a critical link tasked with a timely and reliable\ntransfer of potentially significant amount of data from the multitude of\nsensors. We introduce a comprehensive model for the latency budget,\nincorporating data compression and data transmission. The uplink latency is a\nrandom variable whose distribution depends on the computational capabilities of\nthe device and on the properties of the wireless link. We formulate two\noptimization problems corresponding to two transmission strategies: (1)\nOutage-constrained, and (2) Latency-constrained. We derive the optimal system\nparameters under a reliability criterion. We show that the obtained results are\nsuperior compared to the ones based on the optimization of the expected\nlatency.",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Communications (ICC) 2022, Seoul, South Korea\n",
    "authors": [
      "Suraj Suman",
      "Cedomir Stefanovic",
      "Strahinja Do\u0161en",
      "Petar Popovski"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11590"
  },
  {
    "id": "arXiv:2201.11596",
    "title": "FairMod: Fair Link Prediction and Recommendation via Graph Modification",
    "abstract": "As machine learning becomes more widely adopted across domains, it is\ncritical that researchers and ML engineers think about the inherent biases in\nthe data that may be perpetuated by the model. Recently, many studies have\nshown that such biases are also imbibed in Graph Neural Network (GNN) models if\nthe input graph is biased. In this work, we aim to mitigate the bias learned by\nGNNs through modifying the input graph. To that end, we propose FairMod, a Fair\nGraph Modification methodology with three formulations: the Global Fairness\nOptimization (GFO), Community Fairness Optimization (CFO), and Fair Edge\nWeighting (FEW) models. Our proposed models perform either microscopic or\nmacroscopic edits to the input graph while training GNNs and learn node\nembeddings that are both accurate and fair under the context of link\nrecommendations. We demonstrate the effectiveness of our approach on four real\nworld datasets and show that we can improve the recommendation fairness by\nseveral factors at negligible cost to link prediction accuracy.",
    "descriptor": "\nComments: 15 pages, 2 figures, 4 tables\n",
    "authors": [
      "Sean Current",
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11596"
  },
  {
    "id": "arXiv:2201.11601",
    "title": "Would You Mind Me if I Pass by You? Socially-Appropriate Behaviour for  an Omni-based Social Robot in Narrow Environment",
    "abstract": "Interacting physically with robots and sharing environment with them leads to\nsituations where humans and robots have to cross each other in narrow\ncorridors. In these cases, the robot has to make space for the human to pass.\nFrom observation of human-human crossing behaviours, we isolated two main\nfactors in this avoiding behaviour: body rotation and sliding motion. We\nimplemented a robot controller able to vary these factors and explored how this\nvariation impacted on people's perception. Results from a within-participants\nstudy involving 23 participants show that people prefer a robot rotating its\nbody when crossing them. Additionally, a sliding motion is rated as being\nwarmer. These results show the importance of social avoidance when interacting\nwith humans.",
    "descriptor": "\nComments: Accepted at HRI 2020, March 24-26, 2020, Virtual Event, UK. (this https URL)\n",
    "authors": [
      "Emmanuel Senft",
      "Satoru Satake",
      "Takayuki Kanda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11601"
  },
  {
    "id": "arXiv:2201.11602",
    "title": "Budgeted Steiner Networks: Three Terminals with Equal Path Weights",
    "abstract": "Given a set of terminals in 2D/3D, the network with the shortest total length\nthat connects all terminals is a Steiner tree. On the other hand, with enough\nbudget, every terminal can be connected to every other terminals via a straight\nedge, yielding a complete graph over all terminals. In this work, we study a\ngeneralization of Steiner trees asking what happens in between these two\nextremes. Focusing on three terminals with equal pairwise path weights, we\ncharacterize the full evolutionary pathway between the Steiner tree and the\ncomplete graph, which contains intriguing intermediate structures.",
    "descriptor": "",
    "authors": [
      "Mario Szegedy",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.11602"
  },
  {
    "id": "arXiv:2201.11603",
    "title": "Plume: Differential Privacy at Scale",
    "abstract": "Differential privacy has become the standard for private data analysis, and\nan extensive literature now offers differentially private solutions to a wide\nvariety of problems. However, translating these solutions into practical\nsystems often requires confronting details that the literature ignores or\nabstracts away: users may contribute multiple records, the domain of possible\nrecords may be unknown, and the eventual system must scale to large volumes of\ndata. Failure to carefully account for all three issues can severely impair a\nsystem's quality and usability.\nWe present Plume, a system built to address these problems. We describe a\nnumber of sometimes subtle implementation issues and offer practical solutions\nthat, together, make an industrial-scale system for differentially private data\nanalysis possible. Plume is currently deployed at Google and is routinely used\nto process datasets with trillions of records.",
    "descriptor": "",
    "authors": [
      "Kareem Amin",
      "Jennifer Gillenwater",
      "Matthew Joseph",
      "Alex Kulesza",
      "Sergei Vassilvitskii"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11603"
  },
  {
    "id": "arXiv:2201.11605",
    "title": "The Role of Reusable and Single-Use Side Information in Private  Information Retrieval",
    "abstract": "This paper introduces the problem of Private Information Retrieval with\nReusable and Single-use Side Information (PIR-RSSI). In this problem, one or\nmore remote servers store identical copies of a set of $K$ messages, and there\nis a user that initially knows $M$ of these messages, and wants to privately\nretrieve one other message from the set of $K$ messages. The objective is to\ndesign a retrieval scheme in which the user downloads the minimum amount of\ninformation from the server(s) while the identity of the message wanted by the\nuser and the identities of an $M_1$-subset of the $M$ messages known by the\nuser (referred to as reusable side information) are protected, but the\nidentities of the remaining $M_2=M-M_1$ messages known by the user (referred to\nas single-use side information) do not need to be protected. The PIR-RSSI\nproblem reduces to the classical Private Information Retrieval (PIR) problem\nwhen ${M_1=M_2=0}$, and reduces to the problem of PIR with Private Side\nInformation or PIR with Side Information when ${M_1\\geq 1,M_2=0}$ or\n${M_1=0,M_2\\geq 1}$, respectively. In this work, we focus on the single-server\nsetting of the PIR-RSSI problem. We characterize the capacity of this setting\nfor the cases of ${M_1=1,M_2\\geq 1}$ and ${M_1\\geq 1,M_2=1}$, where the\ncapacity is defined as the maximum achievable download rate over all PIR-RSSI\nschemes. Our results show that for sufficiently small values of $K$, the\nsingle-use side information messages can help in reducing the download cost\nonly if they are kept private; and for larger values of $K$, the reusable side\ninformation messages cannot help in reducing the download cost.",
    "descriptor": "",
    "authors": [
      "Anoosheh Heidarzadeh",
      "Alex Sprintson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11605"
  },
  {
    "id": "arXiv:2201.11608",
    "title": "A Probabilistic Framework for Dynamic Object Recognition in 3D  Environment With A Novel Continuous Ground Estimation Method",
    "abstract": "In this thesis a probabilistic framework is developed and proposed for\nDynamic Object Recognition in 3D Environments. A software package is developed\nusing C++ and Python in ROS that performs the detection and tracking task.\nFurthermore, a novel Gaussian Process Regression (GPR) based method is\ndeveloped to detect ground points in different urban scenarios of regular,\nsloped and rough. The ground surface behavior is assumed to only demonstrate\nlocal input-dependent smoothness. kernel's length-scales are obtained. Bayesian\ninference is implemented sing \\textit{Maximum a Posteriori} criterion. The\nlog-marginal likelihood function is assumed to be a multi-task objective\nfunction, to represent a whole-frame unbiased view of the ground at each frame\nbecause adjacent segments may not have similar ground structure in an uneven\nscene while having shared hyper-parameter values. Simulation results shows the\neffectiveness of the proposed method in uneven and rough scenes which\noutperforms similar Gaussian process based ground segmentation methods.",
    "descriptor": "\nComments: Master's Thesis Submitted in Partial Fulfillment of The Requirements For The Degree of Master of Science in Electrical Engineerin\n",
    "authors": [
      "Pouria Mehrabi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11608"
  },
  {
    "id": "arXiv:2201.11611",
    "title": "Asymmetric Coded Caching for Multi-Antenna Location-Dependent Content  Delivery",
    "abstract": "Efficient usage of in-device storage and computation capabilities are key\nsolutions to support data-intensive applications such as immersive digital\nexperience. This paper proposes a location-dependent multi-antenna coded\ncaching -based content delivery scheme tailored specifically for wireless\nimmersive viewing applications. First, a memory assignment phase is performed\nwhere the content relevant to the identified wireless bottleneck areas are\nincentivized. As a result, unequal fractions of location-dependent multimedia\ncontent are cached at each user. Then, a novel packet generation process is\ncarried out given asymmetric cache placement. During the subsequent delivery\nphase, the number of packets transmitted to each user is the same, while the\nsizes of the packets are proportional to the corresponding location-dependent\ncache ratios. Finally, each user is served with location-specific content using\njoint multicast beamforming and multi-rate modulation scheme that\nsimultaneously benefits from global caching and spatial multiplexing gains.\nNumerical experiments and mathematical analysis demonstrate significant\nperformance gains compared to the state-of-the-art.",
    "descriptor": "\nComments: 6 pages, 5 figures, conference paper. arXiv admin note: text overlap with arXiv:2102.02518\n",
    "authors": [
      "Hamidreza Bakhshzad Mahmoodi",
      "MohammadJavad Salehi",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11611"
  },
  {
    "id": "arXiv:2201.11613",
    "title": "Domain-Invariant Representation Learning from EEG with Private Encoders",
    "abstract": "Deep learning based electroencephalography (EEG) signal processing methods\nare known to suffer from poor test-time generalization due to the changes in\ndata distribution. This becomes a more challenging problem when\nprivacy-preserving representation learning is of interest such as in clinical\nsettings. To that end, we propose a multi-source learning architecture where we\nextract domain-invariant representations from dataset-specific private\nencoders. Our model utilizes a maximum-mean-discrepancy (MMD) based domain\nalignment approach to impose domain-invariance for encoded representations,\nwhich outperforms state-of-the-art approaches in EEG-based emotion\nclassification. Furthermore, representations learned in our pipeline preserve\ndomain privacy as dataset-specific private encoding alleviates the need for\nconventional, centralized EEG-based deep neural network training approaches\nwith shared parameters.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "David Bethge",
      "Philipp Hallgarten",
      "Tobias Grosse-Puppendahl",
      "Mohamed Kari",
      "Ralf Mikut",
      "Albrecht Schmidt",
      "Ozan \u00d6zdenizci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11613"
  },
  {
    "id": "arXiv:2201.11616",
    "title": "On the Role of Multi-Objective Optimization to the Transit Network  Design Problem",
    "abstract": "Ongoing traffic changes, including those triggered by the COVID-19 pandemic,\nreveal the necessity to adapt our public transport systems to the ever-changing\nusers' needs. This work shows that single and multi objective stances can be\nsynergistically combined to better answer the transit network design problem\n(TNDP). Single objective formulations are dynamically inferred from the rating\nof networks in the approximated (multi-objective) Pareto Front, where a\nregression approach is used to infer the optimal weights of transfer needs,\ntimes, distances, coverage, and costs. As a guiding case study, the solution is\napplied to the multimodal public transport network in the city of Lisbon,\nPortugal. The system takes individual trip data given by smartcard validations\nat CARRIS buses and METRO subway stations and uses them to estimate the\norigin-destination demand in the city. Then, Genetic Algorithms are used,\nconsidering both single and multi objective approaches, to redesign the bus\nnetwork that better fits the observed traffic demand. The proposed TNDP\noptimization proved to improve results, with reductions in objective functions\nof up to 28.3%. The system managed to extensively reduce the number of routes,\nand all passenger related objectives, including travel time and transfers per\ntrip, significantly improve. Grounded on automated fare collection data, the\nsystem can incrementally redesign the bus network to dynamically handle ongoing\nchanges to the city traffic.",
    "descriptor": "",
    "authors": [
      "Vasco D. Silva",
      "Anna Finamore",
      "Rui Henriques"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11616"
  },
  {
    "id": "arXiv:2201.11617",
    "title": "List Decoding of 2-Interleaved Binary Alternant Codes",
    "abstract": "This paper is concerned with list decoding of $2$-interleaved binary\nalternant codes. The principle of the proposed algorithm is based on a\ncombination of a list decoding algorithm for (interleaved) Reed-Solomon codes\nand an algorithm for (non-interleaved) alternant codes. The decoding radius\nexceeds the binary Johnson radius and the newly derived upper bound on the\nreturned list size scales polynomially in the code parameters. Further, we\nprovide simulation results on the probability of successful decoding by the\nproposed algorithm.",
    "descriptor": "\nComments: 6 pages, 2 figures, submitted to ISIT 2022\n",
    "authors": [
      "Chih-Chiang Huang",
      "Hedongliang Liu",
      "Lukas Holzbaur",
      "Sven Puchinger",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11617"
  },
  {
    "id": "arXiv:2201.11619",
    "title": "Positive First-order Logic on Words and Graphs",
    "abstract": "We study FO+, a fragment of first-order logic on finite words, where monadic\npredicates can only appear positively. We show that there is an FO-definable\nlanguage that is monotone in monadic predicates but not definable in FO+. This\nprovides a simple proof that Lyndon's preservation theorem fails on finite\nstructures. We lift this example language to finite graphs, thereby providing a\nnew result of independent interest for FO-definable graph classes: negation\nmight be needed even when the class is closed under addition of edges. We\nfinally show that given a regular language of finite words, it is undecidable\nwhether it is definable in FO+.",
    "descriptor": "\nComments: LMCS, extended version of LICS 2021. arXiv admin note: substantial text overlap with arXiv:2101.01968\n",
    "authors": [
      "Denis Kuperberg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11619"
  },
  {
    "id": "arXiv:2201.11620",
    "title": "Domain generalization in deep learning-based mass detection in  mammography: A large-scale multi-center study",
    "abstract": "Computer-aided detection systems based on deep learning have shown great\npotential in breast cancer detection. However, the lack of domain\ngeneralization of artificial neural networks is an important obstacle to their\ndeployment in changing clinical environments. In this work, we explore the\ndomain generalization of deep learning methods for mass detection in digital\nmammography and analyze in-depth the sources of domain shift in a large-scale\nmulti-center setting. To this end, we compare the performance of eight\nstate-of-the-art detection methods, including Transformer-based models, trained\nin a single domain and tested in five unseen domains. Moreover, a single-source\nmass detection training pipeline is designed to improve the domain\ngeneralization without requiring images from the new domain. The results show\nthat our workflow generalizes better than state-of-the-art transfer\nlearning-based approaches in four out of five domains while reducing the domain\nshift caused by the different acquisition protocols and scanner manufacturers.\nSubsequently, an extensive analysis is performed to identify the covariate\nshifts with bigger effects on the detection performance, such as due to\ndifferences in patient age, breast density, mass size, and mass malignancy.\nUltimately, this comprehensive study provides key insights and best practices\nfor future research on domain generalization in deep learning-based breast\ncancer detection.",
    "descriptor": "",
    "authors": [
      "Lidia Garrucho",
      "Kaisar Kushibar",
      "Socayna Jouide",
      "Oliver Diaz",
      "Laura Igual",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11620"
  },
  {
    "id": "arXiv:2201.11621",
    "title": "eQETIC: A Maturity Model for Online Education",
    "abstract": "Digital solutions have substantially contributed to the growth and\ndissemination of education. The distance education modality has been presented\nas an opportunity for worldwide students in many types of courses. However,\nprojects of digital educational platforms require different expertise including\nknowledge areas such as pedagogy, psychology, computing, and digital\ntechnologies associated with education that allow the correct development and\napplication of these solutions. To support the evolution of such solutions with\nsatisfactory quality indicators, this research presents a model focused on\nquality of online educational solutions grounded in an approach aimed to\ncontinuous process improvement. The model considers of three maturity levels\nand six common entities that address the specific practices for planning and\ndeveloping digital educational solutions, targeting quality standards that\nsatisfy their users, such as students, teachers, tutors, and other people\ninvolved in development and use of these kinds of educational solutions.",
    "descriptor": "\nComments: Volume 11, 2015\n",
    "authors": [
      "Rogerio Rossi",
      "Pollyana Notargiacomo Mustaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11621"
  },
  {
    "id": "arXiv:2201.11624",
    "title": "LiteLSTM Architecture for Deep Recurrent Neural Networks",
    "abstract": "Long short-term memory (LSTM) is a robust recurrent neural network\narchitecture for learning spatiotemporal sequential data. However, it requires\nsignificant computational power for learning and implementing from both\nsoftware and hardware aspects. This paper proposes a novel LiteLSTM\narchitecture based on reducing the computation components of the LSTM using the\nweights sharing concept to reduce the overall architecture cost and maintain\nthe architecture performance. The proposed LiteLSTM can be significant for\nlearning big data where time-consumption is crucial such as the security of IoT\ndevices and medical data. Moreover, it helps to reduce the CO2 footprint. The\nproposed model was evaluated and tested empirically on two different datasets\nfrom computer vision and cybersecurity domains.",
    "descriptor": "\nComments: Accepted in the IEEE International Symposium on Circuits and Systems (ISCAS) 2022\n",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Anthony S. Maida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11624"
  },
  {
    "id": "arXiv:2201.11625",
    "title": "SemRob: Towards Semantic Stream Reasoning for Robotic Operating Systems",
    "abstract": "Stream processing and reasoning is getting considerable attention in various\napplication domains such as IoT, Industry IoT and Smart Cities. In parallel,\nreasoning and knowledge-based features have attracted research into many areas\nof robotics, such as robotic mapping, perception and interaction. To this end,\nthe Semantic Stream Reasoning (SSR) framework can unify the representations of\nsymbolic/semantic streams with deep neural networks, to integrate\nhigh-dimensional data streams, such as video streams and LiDAR point clouds,\nwith traditional graph or relational stream data. As such, this positioning and\nsystem paper will outline our approach to build a platform to facilitate\nsemantic stream reasoning capabilities on a robotic operating system called\nSemRob.",
    "descriptor": "",
    "authors": [
      "Manh Nguyen-Duc",
      "Anh Le-Tuan",
      "Manfred Hauswirth",
      "David Bowden",
      "Danh Le-Phuoc"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11625"
  },
  {
    "id": "arXiv:2201.11628",
    "title": "Early Detection of Network Attacks Using Deep Learning",
    "abstract": "The Internet has become a prime subject to security attacks and intrusions by\nattackers. These attacks can lead to system malfunction, network breakdown,\ndata corruption or theft. A network intrusion detection system (IDS) is a tool\nused for identifying unauthorized and malicious behavior by observing the\nnetwork traffic. State-of-the-art intrusion detection systems are designed to\ndetect an attack by inspecting the complete information about the attack. This\nmeans that an IDS would only be able to detect an attack after it has been\nexecuted on the system under attack and might have caused damage to the system.\nIn this paper, we propose an end-to-end early intrusion detection system to\nprevent network attacks before they could cause any more damage to the system\nunder attack while preventing unforeseen downtime and interruption. We employ a\ndeep neural network-based classifier for attack identification. The network is\ntrained in a supervised manner to extract relevant features from raw network\ntraffic data instead of relying on a manual feature selection process used in\nmost related approaches. Further, we introduce a new metric, called earliness,\nto evaluate how early our proposed approach detects attacks. We have\nempirically evaluated our approach on the CICIDS2017 dataset. The results show\nthat our approach performed well and attained an overall 0.803 balanced\naccuracy.",
    "descriptor": "\nComments: Submitted to ITEQS 2022 Workshop\n",
    "authors": [
      "Tanwir Ahmad",
      "Dragos Truscan",
      "Juri Vain",
      "Ivan Porres"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11628"
  },
  {
    "id": "arXiv:2201.11631",
    "title": "Towards Greener Applications: Enabling Sustainable Cloud Native  Applications Design",
    "abstract": "Data centers energy demand is increasing. While a great deal of effort has\nbeen made to reduce the amount of CO$_2$ generated by large cloud providers,\ntoo little has been done from the application perspective. We claim that\napplication developers can impact the environmental footprint by enhancing the\napplication design with additional features. Following the proposed Sustainable\nApplication Design Process (SADP), the application design is enriched with\ninformation that can be leveraged by cloud providers to manage application\nexecution in an energy-aware manner. This exploratory work aims to emphasize\nthe awareness on the sustainability of applications by proposing a methodology\nfor its evaluation. To this end, we first suggest possible actions to enrich\nthe application design towards sustainability, and finally describe how this\nadditional information can be leveraged in the application workflow. We discuss\nthe feasibility of our methodology by referring to existing tools and\ntechnologies capable of supporting the design features proposed in a production\nenvironment.",
    "descriptor": "\nComments: submitted to CAiSE2022\n",
    "authors": [
      "Monica Vitali"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11631"
  },
  {
    "id": "arXiv:2201.11632",
    "title": "Deep Video Prior for Video Consistency and Propagation",
    "abstract": "Applying an image processing algorithm independently to each video frame\noften leads to temporal inconsistency in the resulting video. To address this\nissue, we present a novel and general approach for blind video temporal\nconsistency. Our method is only trained on a pair of original and processed\nvideos directly instead of a large dataset. Unlike most previous methods that\nenforce temporal consistency with optical flow, we show that temporal\nconsistency can be achieved by training a convolutional neural network on a\nvideo with Deep Video Prior (DVP). Moreover, a carefully designed iteratively\nreweighted training strategy is proposed to address the challenging multimodal\ninconsistency problem. We demonstrate the effectiveness of our approach on 7\ncomputer vision tasks on videos. Extensive quantitative and perceptual\nexperiments show that our approach obtains superior performance than\nstate-of-the-art methods on blind video temporal consistency. We further extend\nDVP to video propagation and demonstrate its effectiveness in propagating three\ndifferent types of information (color, artistic style, and object\nsegmentation). A progressive propagation strategy with pseudo labels is also\nproposed to enhance DVP's performance on video propagation. Our source codes\nare publicly available at https://github.com/ChenyangLEI/deep-video-prior.",
    "descriptor": "\nComments: Accepted by TPAMI in Dec 2021; extension of NeurIPS2020 Blind Video Temporal Consistency via Deep Video Prior. arXiv admin note: substantial text overlap with arXiv:2010.11838\n",
    "authors": [
      "Chenyang Lei",
      "Yazhou Xing",
      "Hao Ouyang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11632"
  },
  {
    "id": "arXiv:2201.11638",
    "title": "Reuse-Aware Cache Partitioning Framework for Data-Sharing Multicore  Systems",
    "abstract": "Multi-core processors improve performance, but they can create\nunpredictability owing to shared resources such as caches interfering. Cache\npartitioning is used to alleviate the Worst-Case Execution Time (WCET)\nestimation by isolating the shared cache across each thread to reduce\ninterference. It does, however, prohibit data from being transferred between\nparallel threads running on different cores. In this paper we present (SRCP) a\ncache replacement mechanism for partitioned caches that is aware of data being\nshared across threads, prevents shared data from being replicated across\npartitions and frequently used data from being evicted from caches. Our\ntechnique outperforms TA-DRRIP and EHC, which are existing state-of-the-art\ncache replacement algorithms, by 13.34% in cache hit-rate and 10.4% in\nperformance over LRU (least recently used) cache replacement policy.",
    "descriptor": "\nComments: 2 pages. 7th IEEE International Symposium on Smart Electronic Systems (iSES) 2021\n",
    "authors": [
      "Soma N. Ghosh",
      "Vineet Sahula",
      "Lava Bhargava"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11638"
  },
  {
    "id": "arXiv:2201.11639",
    "title": "Capacity of Finite State Channels with Feedback: Algorithmic and  Optimization Theoretic Properties",
    "abstract": "The capacity of finite state channels (FSCs) with feedback has been shown to\nbe a limit of a sequence of multi-letter expressions. Despite many efforts, a\nclosed-form single-letter capacity characterization is unknown to date. In this\npaper, the feedback capacity is studied from a fundamental algorithmic point of\nview by addressing the question of whether or not the capacity can be\nalgorithmically computed. To this aim, the concept of Turing machines is used,\nwhich provides fundamental performance limits of digital computers. It is shown\nthat the feedback capacity of FSCs is not Banach-Mazur computable and therefore\nnot Turing computable. As a consequence, it is shown that either achievability\nor converse is not Banach-Mazur computable, which means that there are FSCs for\nwhich it is impossible to find computable tight upper and lower bounds.\nFurthermore, it is shown that the feedback capacity cannot be characterized as\nthe maximization of a finite-letter formula of entropic quantities.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.13270\n",
    "authors": [
      "Andrea Grigorescu",
      "Holger Boche",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11639"
  },
  {
    "id": "arXiv:2201.11640",
    "title": "Towards Data-driven LQR with KoopmanizingFlows",
    "abstract": "We propose a novel framework for learning linear time-invariant (LTI) models\nfor a class of continuous-time non-autonomous nonlinear dynamics based on a\nrepresentation of Koopman operators. In general, the operator is\ninfinite-dimensional but, crucially, linear. To utilize it for efficient LTI\ncontrol, we learn a finite representation of the Koopman operator that is\nlinear in controls while concurrently learning meaningful lifting coordinates.\nFor the latter, we rely on KoopmanizingFlows - a diffeomorphism-based\nrepresentation of Koopman operators. With such a learned model, we can replace\nthe nonlinear infinite-horizon optimal control problem with quadratic costs to\nthat of a linear quadratic regulator (LQR), facilitating efficacious optimal\ncontrol for nonlinear systems. The prediction and control efficacy of the\nproposed method is verified on simulation examples.",
    "descriptor": "\nComments: This work has been submitted to 6th IFAC Conference on Intelligent Control and Automation Sciences for possible publication. arXiv admin note: text overlap with arXiv:2112.04085\n",
    "authors": [
      "Petar Bevanda",
      "Max Beier",
      "Shahab Heshmati-Alamdari",
      "Stefan Sosnowski",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11640"
  },
  {
    "id": "arXiv:2201.11650",
    "title": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrence",
    "abstract": "The need to analyze information from streams arises in a variety of\napplications. One of the fundamental research directions is to mine sequential\npatterns over data streams. Current studies mine series of items based on the\nexistence of the pattern in transactions but pay no attention to the series of\nitemsets and their multiple occurrences. The pattern over a window of itemsets\nstream and their multiple occurrences, however, provides additional capability\nto recognize the essential characteristics of the patterns and the\ninter-relationships among them that are unidentifiable by the existing items\nand existence based studies. In this paper, we study such a new sequential\npattern mining problem and propose a corresponding efficient sequential miner\nwith novel strategies to prune search space efficiently. Experiments on both\nreal and synthetic data show the utility of our approach.",
    "descriptor": "",
    "authors": [
      "Thomas Guyet",
      "Wenbin Zhang",
      "Albert Bifet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11650"
  },
  {
    "id": "arXiv:2201.11651",
    "title": "Bit-serial Weight Pools: Compression and Arbitrary Precision Execution  of Neural Networks on Resource Constrained Processors",
    "abstract": "Applications of neural networks on edge systems have proliferated in recent\nyears but the ever-increasing model size makes neural networks not able to\ndeploy on resource-constrained microcontrollers efficiently. We propose\nbit-serial weight pools, an end-to-end framework that includes network\ncompression and acceleration of arbitrary sub-byte precision. The framework can\nachieve up to 8x compression compared to 8-bit networks by sharing a pool of\nweights across the entire network. We further propose a bit-serial lookup based\nsoftware implementation that allows runtime-bitwidth tradeoff and is able to\nachieve more than 2.8x speedup and 7.5x storage compression compared to 8-bit\nweight pool networks, with less than 1% accuracy drop.",
    "descriptor": "\nComments: 10 pages, 8 figures, accepted in the 5th MLSys conference\n",
    "authors": [
      "Shurui Li",
      "Puneet Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.11651"
  },
  {
    "id": "arXiv:2201.11653",
    "title": "Representation learnt by SGD and Adaptive learning rules -- Conditions  that Vary Sparsity and Selectivity in Neural Network",
    "abstract": "From the point of view of the human brain, continual learning can perform\nvarious tasks without mutual interference. An effective way to reduce mutual\ninterference can be found in sparsity and selectivity of neurons. According to\nAljundi et al. and Hadsell et al., imposing sparsity at the representational\nlevel is advantageous for continual learning because sparse neuronal\nactivations encourage less overlap between parameters, resulting in less\ninterference. Similarly, highly selective neural networks are likely to induce\nless interference since particular response in neurons will reduce the chance\nof overlap with other parameters. Considering that the human brain performs\ncontinual learning over the lifespan, finding conditions where sparsity and\nselectivity naturally arises may provide insight for understanding how the\nbrain functions. This paper investigates various conditions that naturally\nincrease sparsity and selectivity in a neural network. This paper tested\ndifferent optimizers with Hoyer's sparsity metric and CCMAS selectivity metric\nin MNIST classification task. It is essential to note that investigations on\nthe natural occurrence of sparsity and selectivity concerning various\nconditions have not been acknowledged in any sector of neuroscience nor machine\nlearning until this day. This paper found that particular conditions increase\nsparsity and selectivity such as applying a large learning rate and lowering a\nbatch size. In addition to the relationship between the condition, sparsity,\nand selectivity, the following will be discussed based on empirical analysis:\n1. The relationship between sparsity and selectivity and 2. The relationship\nbetween test accuracy, sparsity, and selectivity.",
    "descriptor": "",
    "authors": [
      "Jinhyun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11653"
  },
  {
    "id": "arXiv:2201.11654",
    "title": "Model Generalization in Arrival Runway Occupancy Time Prediction by  Feature Equivalences",
    "abstract": "General real-time runway occupancy time prediction modelling for multiple\nairports is a current research gap. An attempt to generalize a real-time\nprediction model for Arrival Runway Occupancy Time (AROT) is presented in this\npaper by substituting categorical features by their numerical equivalences.\nThree days of data, collected from Saab Sensis' Aerobahn system at three US\nairports, has been used for this work. Three tree-based machine learning\nalgorithms: Decision Tree, Random Forest and Gradient Boosting are used to\nassess the generalizability of the model using numerical equivalent features.\nWe have shown that the model trained on numerical equivalent features not only\nhave performances at least on par with models trained on categorical features\nbut also can make predictions on unseen data from other airports.",
    "descriptor": "\nComments: ICRAT 2020 Technical Papers & Presentations\n",
    "authors": [
      "An-Dan Nguyen",
      "Duc-Thinh Pham",
      "Nimrod Lilith",
      "Sameer Alam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11654"
  },
  {
    "id": "arXiv:2201.11655",
    "title": "BFS based distributed algorithm for parallel local directed sub-graph  enumeration",
    "abstract": "Estimating the frequency of sub-graphs is of importance for many tasks,\nincluding sub-graph isomorphism, kernel-based anomaly detection, and network\nstructure analysis. While multiple algorithms were proposed for full\nenumeration or sampling-based estimates, these methods fail in very large\ngraphs. Recent advances in parallelization allow for estimates of total\nsub-graphs counts in very large graphs. The task of counting the frequency of\neach sub-graph associated with each vertex also received excellent solutions\nfor undirected graphs. However, there is currently no good solution for very\nlarge directed graphs.\nWe here propose VDMC (Vertex specific Distributed Motif Counting) -- a fully\ndistributed algorithm to optimally count all the 3 and 4 vertices connected\ndirected graphs (sub-graph motifs) associated with each vertex of a graph. VDMC\ncounts each motif only once and its efficacy is linear in the number of counted\nmotifs. It is fully parallelized to be efficient in GPU-based computation. VDMC\nis based on three main elements: 1) Ordering the vertices and only counting\nmotifs containing increasing order vertices, 2) sub-ordering motifs based on\nthe average length of the BFS composing the motif, and 3) removing isomorphisms\nonly once for the entire graph. We here compare VDMC to analytical estimates of\nthe expected number of motifs and show its accuracy. VDMC is available as a\nhighly efficient CPU and GPU code with a novel data structure for efficient\ngraph manipulation. We show the efficacy of VDMC and real-world graphs. VDMC\nallows for the precise analysis of sub-graph frequency around each vertex in\nlarge graphs and opens the way for the extension of methods until now limited\nto graphs of thousands of edges to graphs with millions of edges and above.\nGIT: https://github.com/louzounlab/graph-measures",
    "descriptor": "",
    "authors": [
      "Itay Levinas",
      "Roy Scherz",
      "Yoram Louzoun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.11655"
  },
  {
    "id": "arXiv:2201.11656",
    "title": "Symmetries in Linear Programming for Information Inequalities",
    "abstract": "We study properties of secret sharing schemes, where a random secret value is\ntransformed into shares distributed among several participants in such a way\nthat only the qualified groups of participants can recover the secret value. We\nimprove the lower bounds on the sizes of shares for several specific problems\nof secret sharing. To this end, we use the method of non-Shannon type\ninformation inequalities going back to Z. Zhang and R.W. Yeung. We extend and\nemploy the linear programming technique that allows to apply new information\ninequalities indirectly, without even writing them down explicitly. To reduce\nthe complexity of the problems of linear programming involved in the bounds we\nuse extensively symmetry considerations.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Emirhan G\u00fcrp\u0131nar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11656"
  },
  {
    "id": "arXiv:2201.11657",
    "title": "LAGOON: An Analysis Tool for Open Source Communities",
    "abstract": "This paper presents LAGOON -- an open source platform for understanding the\ncomplex ecosystems of Open Source Software (OSS) communities. The platform\ncurrently utilizes spatiotemporal graphs to store and investigate the artifacts\nproduced by these communities, and help analysts identify bad actors who might\ncompromise an OSS project's security. LAGOON provides ingest of artifacts from\nseveral common sources, including source code repositories, issue trackers,\nmailing lists and scraping content from project websites. Ingestion utilizes a\nmodular architecture, which supports incremental updates from data sources and\nprovides a generic identity fusion process that can recognize the same\ncommunity members across disparate accounts. A user interface is provided for\nvisualization and exploration of an OSS project's complete sociotechnical\ngraph. Scripts are provided for applying machine learning to identify patterns\nwithin the data. While current focus is on the identification of bad actors in\nthe Python community, the platform's reusability makes it easily extensible\nwith new data and analyses, paving the way for LAGOON to become a comprehensive\nmeans of assessing various OSS-based projects and their communities.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)\n",
    "authors": [
      "Sourya Dey",
      "Walt Woods"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11657"
  },
  {
    "id": "arXiv:2201.11661",
    "title": "TrustAL: Trustworthy Active Learning using Knowledge Distillation",
    "abstract": "Active learning can be defined as iterations of data labeling, model\ntraining, and data acquisition, until sufficient labels are acquired. A\ntraditional view of data acquisition is that, through iterations, knowledge\nfrom human labels and models is implicitly distilled to monotonically increase\nthe accuracy and label consistency. Under this assumption, the most recently\ntrained model is a good surrogate for the current labeled data, from which data\nacquisition is requested based on uncertainty/diversity. Our contribution is\ndebunking this myth and proposing a new objective for distillation. First, we\nfound example forgetting, which indicates the loss of knowledge learned across\niterations. Second, for this reason, the last model is no longer the best\nteacher -- For mitigating such forgotten knowledge, we select one of its\npredecessor models as a teacher, by our proposed notion of \"consistency\". We\nshow that this novel distillation is distinctive in the following three\naspects; First, consistency ensures to avoid forgetting labels. Second,\nconsistency improves both uncertainty/diversity of labeled data. Lastly,\nconsistency redeems defective labels produced by human annotators.",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Beong-woo Kwak",
      "Youngwook Kim",
      "Yu Jin Kim",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11661"
  },
  {
    "id": "arXiv:2201.11662",
    "title": "MeltpoolNet: Melt pool Characteristic Prediction in Metal Additive  Manufacturing Using Machine Learning",
    "abstract": "Characterizing meltpool shape and geometry is essential in metal Additive\nManufacturing (MAM) to control the printing process and avoid defects.\nPredicting meltpool flaws based on process parameters and powder material is\ndifficult due to the complex nature of MAM process. Machine learning (ML)\ntechniques can be useful in connecting process parameters to the type of flaws\nin the meltpool. In this work, we introduced a comprehensive framework for\nbenchmarking ML for melt pool characterization. An extensive experimental\ndataset has been collected from more than 80 MAM articles containing MAM\nprocessing conditions, materials, meltpool dimensions, meltpool modes and flaw\ntypes. We introduced physics-aware MAM featurization, versatile ML models, and\nevaluation metrics to create a comprehensive learning framework for meltpool\ndefect and geometry prediction. This benchmark can serve as a basis for melt\npool control and process optimization. In addition, data-driven explicit models\nhave been identified to estimate meltpool geometry from process parameters and\nmaterial properties which outperform Rosenthal estimation for meltpool geometry\nwhile maintaining interpretability.",
    "descriptor": "",
    "authors": [
      "Parand Akbari",
      "Francis Ogoke",
      "Ning-Yu Kao",
      "Kazem Meidani",
      "Chun-Yu Yeh",
      "William Lee",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11662"
  },
  {
    "id": "arXiv:2201.11663",
    "title": "A Machine Learning-based Characterization Framework for Parametric  Representation of Nonlinear Sloshing",
    "abstract": "The growing interest in creating a parametric representation of liquid\nsloshing inside a container stems from its practical applications in modern\nengineering systems. The resonant excitation, on the other hand, can cause\nunstable and nonlinear water waves, resulting in chaotic motions and\nnon-Gaussian signals. This paper presents a novel machine learning-based\nframework for nonlinear liquid sloshing representation learning. The proposed\nmethod is a parametric modeling technique that is based on sequential learning\nand sparse regularization. The dynamics are categorized into two parts: linear\nevolution and nonlinear forcing. The former advances the dynamical system in\ntime on an embedded manifold, while the latter causes divergent behaviors in\ntemporal evolution, such as bursting and switching. The proposed framework's\nmerit is demonstrated using an experimental dataset of liquid sloshing in a\ntank under horizontal excitation with a wide frequency range and various\nvertical slat screen settings.",
    "descriptor": "\nComments: 30 pages, 13 figures\n",
    "authors": [
      "Xihaier Luo",
      "Ahsan Kareem",
      "Liting Yu",
      "Shinjae Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2201.11663"
  },
  {
    "id": "arXiv:2201.11664",
    "title": "Team Yao at Factify 2022: Utilizing Pre-trained Models and Co-attention  Networks for Multi-Modal Fact Verification",
    "abstract": "In recent years, social media has enabled users to get exposed to a myriad of\nmisinformation and disinformation; thus, misinformation has attracted a great\ndeal of attention in research fields and as a social issue. To address the\nproblem, we propose a framework, Pre-CoFact, composed of two pre-trained models\nfor extracting features from text and images, and multiple co-attention\nnetworks for fusing the same modality but different sources and different\nmodalities. Besides, we adopt the ensemble method by using different\npre-trained models in Pre-CoFact to achieve better performance. We further\nillustrate the effectiveness from the ablation study and examine different\npre-trained models for comparison. Our team, Yao, won the fifth prize\n(F1-score: 74.585\\%) in the Factify challenge hosted by De-Factify @ AAAI 2022,\nwhich demonstrates that our model achieved competitive performance without\nusing auxiliary tasks or extra information. The source code of our work is\npublicly available at\nhttps://github.com/wywyWang/Multi-Modal-Fact-Verification-2021",
    "descriptor": "\nComments: Accepted by AAAI 2022 De-Factify Workshop: First Workshop on Multimodal Fact-Checking and Hate Speech Detection\n",
    "authors": [
      "Wei-Yao Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.11664"
  },
  {
    "id": "arXiv:2201.11665",
    "title": "Error-driven Input Modulation: Solving the Credit Assignment Problem  without a Backward Pass",
    "abstract": "Supervised learning in artificial neural networks typically relies on\nbackpropagation, where the weights are updated based on the error-function\ngradients and sequentially propagated from the output layer to the input layer.\nAlthough this approach has proven effective in a wide domain of applications,\nit lacks biological plausibility in many regards, including the weight symmetry\nproblem, the dependence of learning on non-local signals, the freezing of\nneural activity during error propagation, and the update locking problem.\nAlternative training schemes - such as sign symmetry, feedback alignment, and\ndirect feedback alignment - have been introduced, but invariably rely on a\nbackward pass that hinders the possibility of solving all the issues\nsimultaneously. Here, we propose to replace the backward pass with a second\nforward pass in which the input signal is modulated based on the error of the\nnetwork. We show that this novel learning rule comprehensively addresses all\nthe above-mentioned issues and can be applied to both fully connected and\nconvolutional models. We test this learning rule on MNIST, CIFAR-10, and\nCIFAR-100. These results help incorporate biological principles into machine\nlearning.",
    "descriptor": "",
    "authors": [
      "Giorgia Dellaferrera",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.11665"
  },
  {
    "id": "arXiv:2201.11668",
    "title": "Efficient Hierarchical Storage Management Framework Empowered by  Reinforcement Learning",
    "abstract": "With the rapid development of big data and cloud computing, data management\nhas become increasingly challenging. Over the years, a number of frameworks for\ndata management and storage with various characteristics and features have\nbecome available. Most of these are highly efficient, but ultimately create\ndata silos. It becomes difficult to move and work coherently with data as new\nrequirements emerge as no single framework can efficiently fulfill the data\nmanagement needs of diverse applications. A possible solution is to design\nsmart and efficient hierarchical (multi-tier) storage solutions. A hierarchical\nstorage system (HSS) is a meta solution that consists of different storage\nframeworks organized as a jointly constructed large storage pool. It brings a\nnumber of benefits including better utilization of the storage,\ncost-efficiency, and use of different features provided by the underlying\nstorage frameworks. In order to maximize the gains of hierarchical storage\nsolutions, it is important that they include intelligent and autonomous\nmechanisms for data management grounded in the features of the different\nunderlying frameworks. These decisions should be made according to the\ncharacteristics of the dataset, tier status, and access patterns. These are\nhighly dynamic parameters and defining a policy based on the mentioned\nparameters is a non-trivial task. This paper presents an open-source\nhierarchical storage framework with a dynamic migration policy based on\nreinforcement learning (RL). We present a mathematical model, a software\narchitecture, and an implementation based on both simulations and a live\ncloud-based environment. We compare the proposed RL-based strategy to a\nbaseline of three rule-based policies, showing that the RL-based policy\nachieves significantly higher efficiency and optimal data distribution in\ndifferent scenarios compared to the dynamic rule-based policies.",
    "descriptor": "\nComments: 20 pages, 13 figures\n",
    "authors": [
      "Tianru Zhang",
      "Salman Toor",
      "Andreas Hellander"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11668"
  },
  {
    "id": "arXiv:2201.11670",
    "title": "Strong Converse Theorem for Source Encryption under Side-Channel Attacks",
    "abstract": "We pose and investigate the security problem of a source encryption using\ncommon key under the side channel attacks. This cryptosystem includes the\nsecrecy problem for encrypted sources under the side channel attacks, which was\npreviously studied by Santoso and Oohama. In this paper we propose a new\nsecurity criterion based on the mutual information between the plaintext and\nthe ciphertext. Under this criterion, we establish the necessary and sufficient\ncondition for the secure transmission of correlated sources.",
    "descriptor": "\nComments: 8 pages, 6 figures. arXiv admin note: text overlap with arXiv:1801.02563\n",
    "authors": [
      "Yasutada Oohama",
      "Bagus Santoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11670"
  },
  {
    "id": "arXiv:2201.11674",
    "title": "Vision Checklist: Towards Testable Error Analysis of Image Models to  Help System Designers Interrogate Model Capabilities",
    "abstract": "Using large pre-trained models for image recognition tasks is becoming\nincreasingly common owing to the well acknowledged success of recent models\nlike vision transformers and other CNN-based models like VGG and Resnet. The\nhigh accuracy of these models on benchmark tasks has translated into their\npractical use across many domains including safety-critical applications like\nautonomous driving and medical diagnostics. Despite their widespread use, image\nmodels have been shown to be fragile to changes in the operating environment,\nbringing their robustness into question. There is an urgent need for methods\nthat systematically characterise and quantify the capabilities of these models\nto help designers understand and provide guarantees about their safety and\nrobustness. In this paper, we propose Vision Checklist, a framework aimed at\ninterrogating the capabilities of a model in order to produce a report that can\nbe used by a system designer for robustness evaluations. This framework\nproposes a set of perturbation operations that can be applied on the underlying\ndata to generate test samples of different types. The perturbations reflect\npotential changes in operating environments, and interrogate various properties\nranging from the strictly quantitative to more qualitative. Our framework is\nevaluated on multiple datasets like Tinyimagenet, CIFAR10, CIFAR100 and\nCamelyon17 and for models like ViT and Resnet. Our Vision Checklist proposes a\nspecific set of evaluations that can be integrated into the previously proposed\nconcept of a model card. Robustness evaluations like our checklist will be\ncrucial in future safety evaluations of visual perception modules, and be\nuseful for a wide range of stakeholders including designers, deployers, and\nregulators involved in the certification of these systems. Source code of\nVision Checklist would be open for public use.",
    "descriptor": "\nComments: 17 pages, 18 figures\n",
    "authors": [
      "Xin Du",
      "Benedicte Legastelois",
      "Bhargavi Ganesh",
      "Ajitha Rajan",
      "Hana Chockler",
      "Vaishak Belle",
      "Stuart Anderson",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11674"
  },
  {
    "id": "arXiv:2201.11675",
    "title": "Learning Stance Embeddings from Signed Social Graphs",
    "abstract": "A key challenge in social network analysis is understanding the position, or\nstance, of people in the graph on a large set of topics. While past work has\nmodeled (dis)agreement in social networks using signed graphs, these approaches\nhave not modeled agreement patterns across a range of correlated topics. For\ninstance, disagreement on one topic may make disagreement(or agreement) more\nlikely for related topics. We propose the Stance Embeddings Model(SEM), which\njointly learns embeddings for each user and topic in signed social graphs with\ndistinct edge types for each topic. By jointly learning user and topic\nembeddings, SEM is able to perform cold-start topic stance detection,\npredicting the stance of a user on topics for which we have not observed their\nengagement. We demonstrate the effectiveness of SEM using two large-scale\nTwitter signed graph datasets we open-source. One dataset, TwitterSG, labels\n(dis)agreements using engagements between users via tweets to derive\ntopic-informed, signed edges. The other, BirdwatchSG, leverages community\nreports on misinformation and misleading content. On TwitterSG and BirdwatchSG,\nSEM shows a 39% and 26% error reduction respectively against strong baselines.",
    "descriptor": "",
    "authors": [
      "John Pougu\u00e9-Biyong",
      "Akshay Gupta",
      "Aria Haghighi",
      "Ahmed El-Kishky"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11675"
  },
  {
    "id": "arXiv:2201.11676",
    "title": "Monitoring Model Deterioration with Explainable Uncertainty Estimation  via Non-parametric Bootstrap",
    "abstract": "Monitoring machine learning models once they are deployed is challenging. It\nis even more challenging to decide when to retrain models in real-case\nscenarios when labeled data is beyond reach, and monitoring performance metrics\nbecomes unfeasible. In this work, we use non-parametric bootstrapped\nuncertainty estimates and SHAP values to provide explainable uncertainty\nestimation as a technique that aims to monitor the deterioration of machine\nlearning models in deployment environments, as well as determine the source of\nmodel deterioration when target labels are not available. Classical methods are\npurely aimed at detecting distribution shift, which can lead to false positives\nin the sense that the model has not deteriorated despite a shift in the data\ndistribution. To estimate model uncertainty we construct prediction intervals\nusing a novel bootstrap method, which improves upon the work of Kumar &\nSrivastava (2012). We show that both our model deterioration detection system\nas well as our uncertainty estimation method achieve better performance than\nthe current state-of-the-art. Finally, we use explainable AI techniques to gain\nan understanding of the drivers of model deterioration. We release an open\nsource Python package, doubt, which implements our proposed methods, as well as\nthe code used to reproduce our experiments.",
    "descriptor": "\nComments: 8+3 pages\n",
    "authors": [
      "Carlos Mougan",
      "Dan Saattrup Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11676"
  },
  {
    "id": "arXiv:2201.11678",
    "title": "Unsupervised Change Detection using DRE-CUSUM",
    "abstract": "This paper presents DRE-CUSUM, an unsupervised density-ratio estimation (DRE)\nbased approach to determine statistical changes in time-series data when no\nknowledge of the pre-and post-change distributions are available. The core idea\nbehind the proposed approach is to split the time-series at an arbitrary point\nand estimate the ratio of densities of distribution (using a parametric model\nsuch as a neural network) before and after the split point. The DRE-CUSUM\nchange detection statistic is then derived from the cumulative sum (CUSUM) of\nthe logarithm of the estimated density ratio. We present a theoretical\njustification as well as accuracy guarantees which show that the proposed\nstatistic can reliably detect statistical changes, irrespective of the split\npoint. While there have been prior works on using density ratio based methods\nfor change detection, to the best of our knowledge, this is the first\nunsupervised change detection approach with a theoretical justification and\naccuracy guarantees. The simplicity of the proposed framework makes it readily\napplicable in various practical settings (including high-dimensional\ntime-series data); we also discuss generalizations for online change detection.\nWe experimentally show the superiority of DRE-CUSUM using both synthetic and\nreal-world datasets over existing state-of-the-art unsupervised algorithms\n(such as Bayesian online change detection, its variants as well as several\nother heuristic methods).",
    "descriptor": "",
    "authors": [
      "Sudarshan Adiga",
      "Ravi Tandon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11678"
  },
  {
    "id": "arXiv:2201.11679",
    "title": "DropNAS: Grouped Operation Dropout for Differentiable Architecture  Search",
    "abstract": "Neural architecture search (NAS) has shown encouraging results in automating\nthe architecture design. Recently, DARTS relaxes the search process with a\ndifferentiable formulation that leverages weight-sharing and SGD where all\ncandidate operations are trained simultaneously. Our empirical results show\nthat such procedure results in the co-adaption problem and Matthew Effect:\noperations with fewer parameters would be trained maturely earlier. This causes\ntwo problems: firstly, the operations with more parameters may never have the\nchance to express the desired function since those with less have already done\nthe job; secondly, the system will punish those underperforming operations by\nlowering their architecture parameter, and they will get smaller loss\ngradients, which causes the Matthew Effect. In this paper, we systematically\nstudy these problems and propose a novel grouped operation dropout algorithm\nnamed DropNAS to fix the problems with DARTS. Extensive experiments demonstrate\nthat DropNAS solves the above issues and achieves promising performance.\nSpecifically, DropNAS achieves 2.26% test error on CIFAR-10, 16.39% on\nCIFAR-100 and 23.4% on ImageNet (with the same training hyperparameters as\nDARTS for a fair comparison). It is also observed that DropNAS is robust across\nvariants of the DARTS search space. Code is available at\nhttps://github.com/wiljohnhong/DropNAS.",
    "descriptor": "",
    "authors": [
      "Weijun Hong",
      "Guilin Li",
      "Weinan Zhang",
      "Ruiming Tang",
      "Yunhe Wang",
      "Zhenguo Li",
      "Yong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11679"
  },
  {
    "id": "arXiv:2201.11683",
    "title": "An analysis of least-squares oversampled collocation methods for  compactly perturbed boundary integral equations in two dimensions",
    "abstract": "In recent work (Maierhofer & Huybrechs, 2022, Adv. Comput. Math.), the\nauthors showed that least-squares oversampling can improve the convergence\nproperties of collocation methods for boundary integral equations involving\noperators of certain pseudo-differential form. The underlying principle is that\nthe discrete method approximates a Bubnov$-$Galerkin method in a suitable\nsense. In the present work, we extend this analysis to the case when the\nintegral operator is perturbed by a compact operator $\\mathcal{K}$ which is\ncontinuous as a map on Sobolev spaces on the boundary,\n$\\mathcal{K}:H^{p}\\rightarrow H^{q}$ for all $p,q\\in\\mathbb{R}$.\nThis study is complicated by the fact that both the test and trial functions\nin the discrete Bubnov-Galerkin orthogonality conditions are modified over the\nunperturbed setting. Our analysis guarantees that previous results concerning\noptimal convergence rates and sufficient rates of oversampling are preserved in\nthe more general case. Indeed, for the first time, this analysis provides a\ncomplete explanation of the advantages of least-squares oversampled collocation\nfor boundary integral formulations of the Laplace equation on arbitrary smooth\nJordan curves in 2D. Our theoretical results are shown to be in very good\nagreement with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Georg Maierhofer",
      "Daan Huybrechs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11683"
  },
  {
    "id": "arXiv:2201.11684",
    "title": "Optimal control of Hopf bifurcations",
    "abstract": "We introduce a numerical technique for controlling the location and stability\nproperties of Hopf bifurcations in dynamical systems. The algorithm consists of\nsolving an optimization problem constrained by an extended system of nonlinear\npartial differential equations that characterizes Hopf bifurcation points. The\nflexibility and robustness of the method allows us to advance or delay a Hopf\nbifurcation to a target value of the bifurcation parameter, as well as\ncontrolling the oscillation frequency with respect to a parameter of the system\nor the shape of the domain on which solutions are defined. Numerical\napplications are presented in systems arising from biology and fluid dynamics,\nsuch as the FitzHugh-Nagumo model, Ginzburg-Landau equation, Rayleigh-B\\'enard\nconvection problem, and Navier-Stokes equations, where the control of the\nlocation and oscillation frequency of periodic solutions is of high interest.",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Nicolas Boull\u00e9",
      "Patrick E. Farrell",
      "Marie E. Rognes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11684"
  },
  {
    "id": "arXiv:2201.11685",
    "title": "Generative Adversarial Exploration for Reinforcement Learning",
    "abstract": "Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.",
    "descriptor": "",
    "authors": [
      "Weijun Hong",
      "Menghui Zhu",
      "Minghuan Liu",
      "Weinan Zhang",
      "Ming Zhou",
      "Yong Yu",
      "Peng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11685"
  },
  {
    "id": "arXiv:2201.11691",
    "title": "Recursive Binding for Similarity-Preserving Hypervector Representations  of Sequences",
    "abstract": "Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC/VSA models.",
    "descriptor": "\nComments: 8 pages, 4, figures, 2 tables. arXiv admin note: text overlap with arXiv:2112.15475\n",
    "authors": [
      "Dmitri A. Rachkovskij",
      "Denis Kleyko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11691"
  },
  {
    "id": "arXiv:2201.11692",
    "title": "SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained  Encoders",
    "abstract": "Self-supervised learning is an emerging machine learning (ML) paradigm.\nCompared to supervised learning that leverages high-quality labeled datasets to\nachieve good performance, self-supervised learning relies on unlabeled datasets\nto pre-train powerful encoders which can then be treated as feature extractors\nfor various downstream tasks. The huge amount of data and computational\nresources consumption makes the encoders themselves become a valuable\nintellectual property of the model owner. Recent research has shown that the ML\nmodel's copyright is threatened by model stealing attacks, which aims to train\na surrogate model to mimic the behavior of a given model. We empirically show\nthat pre-trained encoders are highly vulnerable to model stealing attacks.\nHowever, most of the current efforts of copyright protection algorithms such as\nfingerprinting and watermarking concentrate on classifiers. Meanwhile, the\nintrinsic challenges of pre-trained encoder's copyright protection remain\nlargely unstudied. We fill the gap by proposing SSLGuard, the first\nwatermarking algorithm for pre-trained encoders. Given a clean pre-trained\nencoder, SSLGuard embeds a watermark into it and outputs a watermarked version.\nThe shadow training technique is also applied to preserve the watermark under\npotential model stealing attacks. Our extensive evaluation shows that SSLGuard\nis effective in watermark injection and verification, and is robust against\nmodel stealing and other watermark removal attacks such as pruning and\nfinetuning.",
    "descriptor": "",
    "authors": [
      "Tianshuo Cong",
      "Xinlei He",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11692"
  },
  {
    "id": "arXiv:2201.11697",
    "title": "Constrained Structure Learning for Scene Graph Generation",
    "abstract": "As a structured prediction task, scene graph generation aims to build a\nvisually-grounded scene graph to explicitly model objects and their\nrelationships in an input image. Currently, the mean field variational Bayesian\nframework is the de facto methodology used by the existing methods, in which\nthe unconstrained inference step is often implemented by a message passing\nneural network. However, such formulation fails to explore other inference\nstrategies, and largely ignores the more general constrained optimization\nmodels. In this paper, we present a constrained structure learning method, for\nwhich an explicit constrained variational inference objective is proposed.\nInstead of applying the ubiquitous message-passing strategy, a generic\nconstrained optimization method - entropic mirror descent - is utilized to\nsolve the constrained variational inference step. We validate the proposed\ngeneric model on various popular scene graph generation benchmarks and show\nthat it outperforms the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Daqi Liu",
      "Miroslaw Bober",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11697"
  },
  {
    "id": "arXiv:2201.11701",
    "title": "Model Agnostic Interpretability for Multiple Instance Learning",
    "abstract": "In Multiple Instance Learning (MIL), models are trained using bags of\ninstances, where only a single label is provided for each bag. A bag label is\noften only determined by a handful of key instances within a bag, making it\ndifficult to interpret what information a classifier is using to make\ndecisions. In this work, we establish the key requirements for interpreting MIL\nmodels. We then go on to develop several model-agnostic approaches that meet\nthese requirements. Our methods are compared against existing inherently\ninterpretable MIL models on several datasets, and achieve an increase in\ninterpretability accuracy of up to 30%. We also examine the ability of the\nmethods to identify interactions between instances and scale to larger\ndatasets, improving their applicability to real-world problems.",
    "descriptor": "\nComments: 25 pages (9 content, 2 acknowledgement + references, 14 appendix). 16 figures (3 main content, 13 appendix). Submitted and accepted to ICLR 22, see this http URL\n",
    "authors": [
      "Joseph Early",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11701"
  },
  {
    "id": "arXiv:2201.11706",
    "title": "A Systematic Study of Bias Amplification",
    "abstract": "Recent research suggests that predictions made by machine-learning models can\namplify biases present in the training data. When a model amplifies bias, it\nmakes certain predictions at a higher rate for some groups than expected based\non training-data statistics. Mitigating such bias amplification requires a deep\nunderstanding of the mechanics in modern machine learning that give rise to\nthat amplification. We perform the first systematic, controlled study into when\nand how bias amplification occurs. To enable this study, we design a simple\nimage-classification problem in which we can tightly control (synthetic)\nbiases. Our study of this problem reveals that the strength of bias\namplification is correlated to measures such as model accuracy, model capacity,\nmodel overconfidence, and amount of training data. We also find that bias\namplification can vary greatly during training. Finally, we find that bias\namplification may depend on the difficulty of the classification task relative\nto the difficulty of recognizing group membership: bias amplification appears\nto occur primarily when it is easier to recognize group membership than class\nmembership. Our results suggest best practices for training machine-learning\nmodels that we hope will help pave the way for the development of better\nmitigation strategies.",
    "descriptor": "",
    "authors": [
      "Melissa Hall",
      "Laurens van der Maaten",
      "Laura Gustafson",
      "Aaron Adcock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11706"
  },
  {
    "id": "arXiv:2201.11709",
    "title": "OtherTube: Facilitating Content Discovery and Reflection by Exchanging  YouTube Recommendations with Strangers",
    "abstract": "To promote engagement, recommendation algorithms on platforms like YouTube\nincreasingly personalize users' feeds, limiting users' exposure to diverse\ncontent and depriving them of opportunities to reflect on their interests\ncompared to others'. In this work, we investigate how exchanging\nrecommendations with strangers can help users discover new content and reflect.\nWe tested this idea by developing OtherTube -- a browser extension for YouTube\nthat displays strangers' personalized YouTube recommendations. OtherTube allows\nusers to (i) create an anonymized profile for social comparison, (ii) share\ntheir recommended videos with others, and (iii) browse strangers' YouTube\nrecommendations. We conducted a 10-day-long user study (n=41) followed by a\npost-study interview (n=11). Our results reveal that users discovered and\ndeveloped new interests from seeing OtherTube recommendations. We identified\nuser and content characteristics that affect interaction and engagement with\nexchanged recommendations; for example, younger users interacted more with\nOtherTube, while the perceived irrelevance of some content discouraged users\nfrom watching certain videos. Users reflected on their interests as well as\nothers', recognizing similarities and differences. Our work shows promise for\ndesigns leveraging the exchange of personalized recommendations with strangers.",
    "descriptor": "\nComments: CHI 2022, 17 pages\n",
    "authors": [
      "Md Momen Bhuiyan",
      "Carlos Augusto Bautista Isaza",
      "Tanushree Mitra",
      "Sang Won Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.11709"
  },
  {
    "id": "arXiv:2201.11710",
    "title": "Variable-Length Stop-Feedback Codes With Finite Optimal Decoding Times  for BI-AWGN Channels",
    "abstract": "In this paper, we are interested in the performance of a variable-length\nstop-feedback (VLSF) code with $m$ optimal decoding times for the binary-input\nadditive white Gaussian noise (BI-AWGN) channel. We first develop tight\napproximations on the tail probability of length-$n$ cumulative information\ndensity. Building on the work of Yavas \\emph{et al.}, we formulate the problem\nof minimizing the upper bound on average blocklength subject to the error\nprobability, minimum gap, and integer constraints. For this integer program, we\nshow that for a given error constraint, a VLSF code that decodes after every\nsymbol attains the maximum achievable rate. We also present a greedy algorithm\nthat yields possibly suboptimal integer decoding times. By allowing a positive\nreal-valued decoding time, we develop the gap-constrained sequential\ndifferential optimization (SDO) procedure. Numerical evaluation shows that the\ngap-constrained SDO can provide a good estimate on achievable rate of VLSF\ncodes with $m$ optimal decoding times and that a finite $m$ suffices to attain\nPolyanskiy's bound for VLSF codes with $m = \\infty$.",
    "descriptor": "\nComments: 6 pages; 3 figures; a short version of this preprint is submitted to ISIT 2022\n",
    "authors": [
      "Hengjie Yang",
      "Recep Can Yavas",
      "Victoria Kostina",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11710"
  },
  {
    "id": "arXiv:2201.11711",
    "title": "Algorithm Selection for Software Verification using Graph Attention  Networks",
    "abstract": "The field of software verification has produced a wide array of algorithmic\ntechniques that can prove a variety of properties of a given program. It has\nbeen demonstrated that the performance of these techniques can vary up to 4\norders of magnitude on the same verification problem. Even for verification\nexperts, it is difficult to decide which tool will perform best on a given\nproblem. For general users, deciding the best tool for their verification\nproblem is effectively impossible.\nIn this work, we present Graves, a selection strategy based on graph neural\nnetworks (GNNs). Graves generates a graph representation of a program from\nwhich a GNN predicts a score for a verifier that indicates its performance on\nthe program.\nWe evaluate Graves on a set of 10 verification tools and over 8000\nverification problems and find that it improves the state-of-the-art in\nverification algorithm selection by 11\\%. We conjecture this is in part due to\nGraves' use of GNNs with attention mechanisms. Through a qualitative study on\nmodel interpretability, we find strong evidence that the Graves' GNN-based\nmodel learns to base its predictions on factors that relate to the unique\nfeatures of the algorithmic techniques.",
    "descriptor": "\nComments: 29 pages, 7 figures, 5 tables, submitted to ACM Transactions on Software Engineering and Methodology\n",
    "authors": [
      "Will Leeson",
      "Matthew B Dwyer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11711"
  },
  {
    "id": "arXiv:2201.11722",
    "title": "Change Detection of Markov Kernels with Unknown Post Change Kernel using  Maximum Mean Discrepancy",
    "abstract": "In this paper, we develop a new change detection algorithm for detecting a\nchange in the Markov kernel over a metric space in which the post-change kernel\nis unknown. Under the assumption that the pre- and post-change Markov kernel is\ngeometrically ergodic, we derive an upper bound on the mean delay and a lower\nbound on the mean time between false alarms.",
    "descriptor": "",
    "authors": [
      "Hao Chen",
      "Jiacheng Tang",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11722"
  },
  {
    "id": "arXiv:2201.11726",
    "title": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "abstract": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Claus Aranha",
      "Gabriela Ochoa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11726"
  },
  {
    "id": "arXiv:2201.11727",
    "title": "Reinforced Cooperative Load Balancing in Data Center",
    "abstract": "Network load balancers are central components in modern data centers, that\ncooperatively distribute workloads of high arrival rates across application\nservers, thereby contribute to offering scalable services. The independent and\n\"selfish\" load balancing strategy is not necessarily the globally optimal one.\nThis paper represents the load balancing problem as a cooperative team-game\nwith limited observations over system states, and adopts multi-agent\nreinforcement learning methods to make fair load balancing decisions without\ninducing additional processing latency. On both a simulation and an emulation\nsystem, the proposed method is evaluated against other load balancing\nalgorithms, including state-of-the-art heuristics and learning-based\nstrategies. Experiments under different settings and complexities show the\nadvantageous performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding",
      "Thomas Clausen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11727"
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.",
    "descriptor": "",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11729"
  },
  {
    "id": "arXiv:2201.11731",
    "title": "An Algorithmic Framework for Locally Constrained Homomorphisms",
    "abstract": "A homomorphism $f$ from a guest graph $G$ to a host graph $H$ is locally\nbijective, injective or surjective if for every $u\\in V(G)$, the restriction of\n$f$ to the neighbourhood of $u$ is bijective, injective or surjective,\nrespectively. The corresponding decision problems, LBHOM, LIHOM and LSHOM, are\nwell studied both on general graphs and on special graph classes. Apart from\ncomplexity results when the problems are parameterized by the treewidth and\nmaximum degree of the guest graph, the three problems still lack a thorough\nstudy of their parameterized complexity. This paper fills this gap: we prove a\nnumber of new FPT, W[1]-hard and para-NP-complete results by considering a\nhierarchy of parameters of the guest graph $G$. For our FPT results, we do this\nthrough the development of a new algorithmic framework that involves a general\nILP model. To illustrate the applicability of the new framework, we also use it\nto prove FPT results for the Role Assignment problem, which originates from\nsocial network theory and is closely related to locally surjective\nhomomorphisms.",
    "descriptor": "",
    "authors": [
      "Laurent Bulteau",
      "Konrad K. Dabrowski",
      "Noleen K\u00f6hler",
      "Sebastian Ordyniak",
      "Dani\u00ebl Paulusma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.11731"
  },
  {
    "id": "arXiv:2201.11732",
    "title": "IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and  Languages",
    "abstract": "Reliable evaluation benchmarks designed for replicability and\ncomprehensiveness have driven progress in machine learning. Due to the lack of\na multilingual benchmark, however, vision-and-language research has mostly\nfocused on English language tasks. To fill this gap, we introduce the\nImage-Grounded Language Understanding Evaluation benchmark. IGLUE brings\ntogether - by both aggregating pre-existing datasets and creating new ones -\nvisual question answering, cross-modal retrieval, grounded reasoning, and\ngrounded entailment tasks across 20 diverse languages. Our benchmark enables\nthe evaluation of multilingual multimodal models for transfer learning, not\nonly in a zero-shot setting, but also in newly defined few-shot learning\nsetups. Based on the evaluation of the available state-of-the-art models, we\nfind that translate-test transfer is superior to zero-shot transfer and that\nfew-shot learning is hard to harness for many tasks. Moreover, downstream\nperformance is partially explained by the amount of available unlabelled\ntextual data for pretraining, and only weakly by the typological distance of\ntarget-source languages. We hope to encourage future research efforts in this\narea by releasing the benchmark to the community.",
    "descriptor": "",
    "authors": [
      "Emanuele Bugliarello",
      "Fangyu Liu",
      "Jonas Pfeiffer",
      "Siva Reddy",
      "Desmond Elliott",
      "Edoardo Maria Ponti",
      "Ivan Vuli\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11732"
  },
  {
    "id": "arXiv:2201.11736",
    "title": "Ranking Info Noise Contrastive Estimation: Boosting Contrastive Learning  via Ranked Positives",
    "abstract": "This paper introduces Ranking Info Noise Contrastive Estimation (RINCE), a\nnew member in the family of InfoNCE losses that preserves a ranked ordering of\npositive samples. In contrast to the standard InfoNCE loss, which requires a\nstrict binary separation of the training pairs into similar and dissimilar\nsamples, RINCE can exploit information about a similarity ranking for learning\na corresponding embedding space. We show that the proposed loss function learns\nfavorable embeddings compared to the standard InfoNCE whenever at least noisy\nranking information can be obtained or when the definition of positives and\nnegatives is blurry. We demonstrate this for a supervised classification task\nwith additional superclass labels and noisy similarity scores. Furthermore, we\nshow that RINCE can also be applied to unsupervised training with experiments\non unsupervised representation learning from videos. In particular, the\nembedding yields higher classification accuracy, retrieval rates and performs\nbetter in out-of-distribution detection than the standard InfoNCE loss.",
    "descriptor": "\nComments: AAAI 2022 (Main Track)\n",
    "authors": [
      "David T. Hoffmann",
      "Nadine Behrmann",
      "Juergen Gall",
      "Thomas Brox",
      "Mehdi Noroozi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11736"
  },
  {
    "id": "arXiv:2201.11739",
    "title": "Robust Augmentation for Multivariate Time Series Classification",
    "abstract": "Neural networks are capable of learning powerful representations of data, but\nthey are susceptible to overfitting due to the number of parameters. This is\nparticularly challenging in the domain of time series classification, where\ndatasets may contain fewer than 100 training examples. In this paper, we show\nthat the simple methods of cutout, cutmix, mixup, and window warp improve the\nrobustness and overall performance in a statistically significant way for\nconvolutional, recurrent, and self-attention based architectures for time\nseries classification. We evaluate these methods on 26 datasets from the\nUniversity of East Anglia Multivariate Time Series Classification (UEA MTSC)\narchive and analyze how these methods perform on different types of time series\ndata.. We show that the InceptionTime network with augmentation improves\naccuracy by 1% to 45% in 18 different datasets compared to without\naugmentation. We also show that augmentation improves accuracy for recurrent\nand self attention based architectures.",
    "descriptor": "",
    "authors": [
      "Hong Yang",
      "Travis Desell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11739"
  },
  {
    "id": "arXiv:1811.07415",
    "title": "MALTS: Matching After Learning to Stretch",
    "abstract": "We introduce a flexible framework that produces high-quality almost-exact\nmatches for causal inference. Most prior work in matching uses ad-hoc distance\nmetrics, often leading to poor quality matches, particularly when there are\nirrelevant covariates. In this work, we learn an interpretable distance metric\nfor matching, which leads to substantially higher quality matches. The learned\ndistance metric stretches the covariate space according to each covariate's\ncontribution to outcome prediction: this stretching means that mismatches on\nimportant covariates carry a larger penalty than mismatches on irrelevant\ncovariates. Our ability to learn flexible distance metrics leads to matches\nthat are interpretable and useful for the estimation of conditional average\ntreatment effects.",
    "descriptor": "\nComments: 40 pages, 5 Tables, 12 Figures\n",
    "authors": [
      "Harsh Parikh",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/1811.07415"
  },
  {
    "id": "arXiv:2201.09200",
    "title": "Asymptotics for Outlier Hypothesis Testing",
    "abstract": "We revisit the outlier hypothesis testing framework of Li \\emph{et al.} (TIT\n2014) and derive fundamental limits for the optimal test. In outlier hypothesis\ntesting, one is given multiple observed sequences, where most sequences are\ngenerated i.i.d. from a nominal distribution. The task is to discern the set of\noutlying sequences that are generated according to anomalous distributions. The\nnominal and anomalous distributions are \\emph{unknown}. We consider the case of\nmultiple outliers where the number of outliers is unknown and each outlier can\nfollow a different anomalous distribution. Under this setting, we study the\ntradeoff among the probabilities of misclassification error, false alarm and\nfalse reject. Specifically, we propose a threshold-based test that ensures\nexponential decay of misclassification error and false alarm probabilities. We\nstudy two constraints on the false reject probability, with one constraint\nbeing that it is a non-vanishing constant and the other being that it has an\nexponential decay rate. For both cases, we characterize bounds on the false\nreject probability, as a function of the threshold, for each tuple of nominal\nand anomalous distributions. Finally, we demonstrate the asymptotic optimality\nof our test under the generalized Neyman-Pearson criterion.",
    "descriptor": "\nComments: Submitted to ISIT 2022; this version is a short version of our IT submission arXiv:2009.03505\n",
    "authors": [
      "Lin Zhou",
      "Yun Wei",
      "Alfred Hero"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.09200"
  },
  {
    "id": "arXiv:2201.09845",
    "title": "A Generalized Quantum Inner Product and Applications to Financial  Engineering",
    "abstract": "In this paper we present a canonical quantum computing method to estimate the\nweighted sum w(k)f(k) of the values taken by a discrete function f and real\nweights w(k). The canonical aspect of the method comes from relying on a single\nlinear function encoded in the amplitudes of a quantum state, and using\nregister entangling to encode the function f.\nWe further expand this framework by mapping function values to hashes in\norder to estimate weighted sums w(k)h(f(k)) of hashed function values with real\nhashes h. This generalization allows the computation of restricted weighted\nsums such as value at risk, comparators, as well as Lebesgue integrals and\npartial moments of statistical distributions.\nWe also introduce essential building blocks such as efficient encodings of\nstandardized linear quantum states and normal distributions.",
    "descriptor": "\nComments: 17 pages, 22 figures\n",
    "authors": [
      "Vanio Markov",
      "Charlee Stefanski",
      "Abhijit Rao",
      "Constantin Gonciulea"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2201.09845"
  },
  {
    "id": "arXiv:2201.11133",
    "title": "Inference-optimized AI and high performance computing for gravitational  wave detection at scale",
    "abstract": "We introduce an ensemble of artificial intelligence models for gravitational\nwave detection that we trained in the Summit supercomputer using 32 nodes,\nequivalent to 192 NVIDIA V100 GPUs, within 2 hours. Once fully trained, we\noptimized these models for accelerated inference using NVIDIA TensorRT. We\ndeployed our inference-optimized AI ensemble in the ThetaGPU supercomputer at\nArgonne Leadership Computer Facility to conduct distributed inference. Using\nthe entire ThetaGPU supercomputer, consisting of 20 nodes each of which has 8\nNVIDIA A100 Tensor Core GPUs and 2 AMD Rome CPUs, our NVIDIA TensorRT-optimized\nAI ensemble porcessed an entire month of advanced LIGO data (including Hanford\nand Livingston data streams) within 50 seconds. Our inference-optimized AI\nensemble retains the same sensitivity of traditional AI models, namely, it\nidentifies all known binary black hole mergers previously identified in this\nadvanced LIGO dataset and reports no misclassifications, while also providing a\n3X inference speedup compared to traditional artificial intelligence models. We\nused time slides to quantify the performance of our AI ensemble to process up\nto 5 years worth of advanced LIGO data. In this synthetically enhanced dataset,\nour AI ensemble reports an average of one misclassification for every month of\nsearched advanced LIGO data. We also present the receiver operating\ncharacteristic curve of our AI ensemble using this 5 year long advanced LIGO\ndataset. This approach provides the required tools to conduct accelerated,\nAI-driven gravitational wave detection at scale.",
    "descriptor": "\nComments: 19 pages, 8 figure\n",
    "authors": [
      "Pranshu Chaturvedi",
      "Asad Khan",
      "Minyang Tian",
      "E. A. Huerta",
      "Huihuo Zheng"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11133"
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": "Self-supervised protein language models have proved their effectiveness in\nlearning the proteins representations. With the increasing computational power,\ncurrent protein language models pre-trained with millions of diverse sequences\ncan advance the parameter scale from million-level to billion-level and achieve\nremarkable improvement. However, those prevailing approaches rarely consider\nincorporating knowledge graphs (KGs), which can provide rich structured\nknowledge facts for better protein representations. We argue that informative\nbiology knowledge in KGs can enhance protein representation with external\nknowledge. In this work, we propose OntoProtein, the first general framework\nthat makes use of structure in GO (Gene Ontology) into protein pre-training\nmodels. We construct a novel large-scale knowledge graph that consists of GO\nand its related proteins, and gene annotation texts or protein sequences\ndescribe all nodes in the graph. We propose novel contrastive learning with\nknowledge-aware negative sampling to jointly optimize the knowledge graph and\nprotein embedding during pre-training. Experimental results show that\nOntoProtein can surpass state-of-the-art methods with pre-trained protein\nlanguage models in TAPE benchmark and yield better performance compared with\nbaselines in protein-protein interaction and protein function prediction. Code\nand datasets are available in https://github.com/zjunlp/OntoProtein.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11147"
  },
  {
    "id": "arXiv:2201.11157",
    "title": "Policy Optimization over Submanifolds for Constrained Feedback Synthesis",
    "abstract": "In this paper, we study linearly constrained policy optimizations over the\nmanifold of Schur stabilizing controllers, equipped with a Riemannian metric\nthat emerges naturally in the context of optimal control problems. We provide\nextrinsic analysis of a generic constrained smooth cost function, that\nsubsequently facilitates subsuming any such constrained problem into this\nframework. By studying the second order geometry of this manifold, we provide a\nNewton-type algorithm with local convergence guarantees that exploits this\ninherent geometry without relying on the exponential mapping nor a retraction.\nThe algorithm hinges instead upon the developed stability certificate and the\nlinear structure of the constraints. We then apply our methodology to two\nwell-known constrained optimal control problems. Finally, several numerical\nexamples showcase the performance of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Shahriar Talebi",
      "Mehran Mesbahi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2201.11157"
  },
  {
    "id": "arXiv:2201.11162",
    "title": "Self-Certifying Classification by Linearized Deep Assignment",
    "abstract": "We propose a novel class of deep stochastic predictors for classifying metric\ndata on graphs within the PAC-Bayes risk certification paradigm. Classifiers\nare realized as linearly parametrized deep assignment flows with random initial\nconditions. Building on the recent PAC-Bayes literature and data-dependent\npriors, this approach enables (i) to use risk bounds as training objectives for\nlearning posterior distributions on the hypothesis space and (ii) to compute\ntight out-of-sample risk certificates of randomized classifiers more\nefficiently than related work. Comparison with empirical test set errors\nillustrates the performance and practicality of this self-certifying\nclassification method.",
    "descriptor": "",
    "authors": [
      "Bastian Boll",
      "Alexander Zeilmann",
      "Stefania Petra",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11162"
  },
  {
    "id": "arXiv:2201.11188",
    "title": "Crystal structure prediction with machine learning-based element  substitution",
    "abstract": "The prediction of energetically stable crystal structures formed by a given\nchemical composition is a central problem in solid-state physics. In principle,\nthe crystalline state of assembled atoms can be determined by optimizing the\nenergy surface, which in turn can be evaluated using first-principles\ncalculations. However, performing the iterative gradient descent on the\npotential energy surface using first-principles calculations is prohibitively\nexpensive for complex systems, such as those with many atoms per unit cell.\nHere, we present a unique methodology for crystal structure prediction (CSP)\nthat relies on a machine learning algorithm called metric learning. It is shown\nthat a binary classifier, trained on a large number of already identified\ncrystal structures, can determine the isomorphism of crystal structures formed\nby two given chemical compositions with an accuracy of approximately 96.4\\%.\nFor a given query composition with an unknown crystal structure, the model is\nused to automatically select from a crystal structure database a set of\ntemplate crystals with nearly identical stable structures to which element\nsubstitution is to be applied. Apart from the local relaxation calculation of\nthe identified templates, the proposed method does not use ab initio\ncalculations. The potential of this substation-based CSP is demonstrated for a\nwide variety of crystal systems.",
    "descriptor": "",
    "authors": [
      "Minoru Kusaba",
      "Chang Liu",
      "Ryo Yoshida"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11188"
  },
  {
    "id": "arXiv:2201.11211",
    "title": "Learning Mixtures of Linear Dynamical Systems",
    "abstract": "We study the problem of learning a mixture of multiple linear dynamical\nsystems (LDSs) from unlabeled short sample trajectories, each generated by one\nof the LDS models. Despite the wide applicability of mixture models for\ntime-series data, learning algorithms that come with end-to-end performance\nguarantees are largely absent from existing literature. There are multiple\nsources of technical challenges, including but not limited to (1) the presence\nof latent variables (i.e. the unknown labels of trajectories); (2) the\npossibility that the sample trajectories might have lengths much smaller than\nthe dimension $d$ of the LDS models; and (3) the complicated temporal\ndependence inherent to time-series data. To tackle these challenges, we develop\na two-stage meta-algorithm, which is guaranteed to efficiently recover each\nground-truth LDS model up to error $\\tilde{O}(\\sqrt{d/T})$, where $T$ is the\ntotal sample size. We validate our theoretical studies with numerical\nexperiments, confirming the efficacy of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Yanxi Chen",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.11211"
  },
  {
    "id": "arXiv:2201.11215",
    "title": "Predicting Succinylation Sites in Proteins with Improved Deep Learning  Architecture",
    "abstract": "Post-translational modifications (PTMs) in proteins occur after the process\nof translation. PTMs account for many cellular processes such as\ndeoxyribonucleic acid (DNA) repair, cell signaling and cell death. One of the\nrecent PTMs is succinylation. Succinylation modifies lysine residue from $-1$\nto $+1$. Locating succinylation sites using experimental methods, such as mass\nspectrometry is very laborious. Hence, computational methods are favored using\nmachine learning techniques. This paper proposes a deep learning architecture\nto predict succinylation sites. The performance of the proposed architecture is\ncompared to the state-of-the-art deep learning architecture and other\ntraditional machine learning techniques for succinylation. It is shown from the\nperformance metrics that the proposed architecture provides a good trade-off\nbetween speed of computation and classification accuracy.",
    "descriptor": "",
    "authors": [
      "Olusola Odeyomi",
      "Gergely Zaruba"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11215"
  },
  {
    "id": "arXiv:2201.11246",
    "title": "HistoKT: Cross Knowledge Transfer in Computational Pathology",
    "abstract": "The lack of well-annotated datasets in computational pathology (CPath)\nobstructs the application of deep learning techniques for classifying medical\nimages. %Since pathologist time is expensive, dataset curation is intrinsically\ndifficult. Many CPath workflows involve transferring learned knowledge between\nvarious image domains through transfer learning. Currently, most transfer\nlearning research follows a model-centric approach, tuning network parameters\nto improve transfer results over few datasets. In this paper, we take a\ndata-centric approach to the transfer learning problem and examine the\nexistence of generalizable knowledge between histopathological datasets. First,\nwe create a standardization workflow for aggregating existing histopathological\ndata. We then measure inter-domain knowledge by training ResNet18 models across\nmultiple histopathological datasets, and cross-transferring between them to\ndetermine the quantity and quality of innate shared knowledge. Additionally, we\nuse weight distillation to share knowledge between models without additional\ntraining. We find that hard to learn, multi-class datasets benefit most from\npretraining, and a two stage learning framework incorporating a large source\ndomain such as ImageNet allows for better utilization of smaller datasets.\nFurthermore, we find that weight distillation enables models trained on purely\nhistopathological features to outperform models using external natural image\ndata.",
    "descriptor": "\nComments: Accepted in ICASSP2022\n",
    "authors": [
      "Ryan Zhang",
      "Jiadai Zhu",
      "Stephen Yang",
      "Mahdi S. Hosseini",
      "Angelo Genovese",
      "Lina Chen",
      "Corwyn Rowsell",
      "Savvas Damaskinos",
      "Sonal Varma",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11246"
  },
  {
    "id": "arXiv:2201.11306",
    "title": "Multi-view learning with privileged weighted twin support vector machine",
    "abstract": "Weighted twin support vector machines (WLTSVM) mines as much potential\nsimilarity information in samples as possible to improve the common\nshort-coming of non-parallel plane classifiers. Compared with twin support\nvector machines (TWSVM), it reduces the time complexity by deleting the\nsuperfluous constraints using the inter-class K-Nearest Neighbor (KNN).\nMulti-view learning (MVL) is a newly developing direction of machine learning,\nwhich focuses on learning acquiring information from the data indicated by\nmultiple feature sets. In this paper, we propose multi-view learning with\nprivileged weighted twin support vector machines (MPWTSVM). It not only\ninherits the advantages of WLTSVM but also has its characteristics. Firstly, it\nenhances generalization ability by mining intra-class information from the same\nperspective. Secondly, it reduces the redundancy constraints with the help of\ninter-class information, thus improving the running speed. Most importantly, it\ncan follow both the consensus and the complementarity principle simultaneously\nas a multi-view classification model. The consensus principle is realized by\nminimizing the coupling items of the two views in the original objective\nfunction. The complementary principle is achieved by establishing privileged\ninformation paradigms and MVL. A standard quadratic programming solver is used\nto solve the problem. Compared with multi-view classification models such as\nSVM-2K, MVTSVM, MCPK, and PSVM-2V, our model has better accuracy and\nclassification efficiency. Experimental results on 45 binary data sets prove\nthe effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Ruxin Xu",
      "Huiru Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11306"
  },
  {
    "id": "arXiv:2201.11320",
    "title": "Deep Recurrent Learning for Heart Sounds Segmentation based on  Instantaneous Frequency Features",
    "abstract": "In this work, a novel stack of well-known technologies is presented to\ndetermine an automatic method to segment the heart sounds in a phonocardiogram\n(PCG). We will show a deep recurrent neural network (DRNN) capable of\nsegmenting a PCG into its main components and a very specific way of extracting\ninstantaneous frequency that will play an important role in the training and\ntesting of the proposed model. More specifically, it involves a Long Short-Term\nMemory (LSTM) neural network accompanied by the Fourier Synchrosqueezed\nTransform (FSST) used to extract instantaneous time-frequency features from a\nPCG. The present approach was tested on heart sound signals longer than 5\nseconds and shorter than 35 seconds from freely-available databases. This\napproach proved that, with a relatively small architecture, a small set of\ndata, and the right features, this method achieved an almost state-of-the-art\nperformance, showing an average sensitivity of 89.5%, an average positive\npredictive value of 89.3\\% and an average accuracy of 91.3%.",
    "descriptor": "\nComments: 7 figures, 6 pages, journal\n",
    "authors": [
      "Alvaro Joaqu\u00edn Gaona",
      "Pedro David Arini"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11320"
  },
  {
    "id": "arXiv:2201.11329",
    "title": "Quantum algorithm for dense kernel matrices using hierarchical splitting",
    "abstract": "Kernel matrices, which arise from discretizing a kernel function $k(x,x')$,\nhave a variety of applications in mathematics and engineering. Classically, the\ncelebrated fast multipole method was designed to perform matrix multiplication\non kernel matrices of dimension $N$ in time almost linear in $N$ by using\ntechniques later generalized into the linear algebraic framework of\nhierarchical matrices. In light of this success, we propose a quantum algorithm\nfor efficiently performing matrix operations on hierarchical matrices by\nimplementing a quantum block-encoding of the hierarchical matrix structure.\nWhen applied to many kernel matrices, our quantum algorithm can solve quantum\nlinear systems of dimension $N$ in time $O(\\kappa\n\\operatorname{polylog}(\\frac{N}{\\varepsilon}))$, where $\\kappa$ and\n$\\varepsilon$ are the condition number and error bound of the matrix operation.\nThis runtime is exponentially faster than any existing quantum algorithms for\nimplementing dense kernel matrices. Finally, we discuss possible applications\nof our methodology in solving integral equations or accelerating computations\nin N-body problems.",
    "descriptor": "",
    "authors": [
      "Quynh The Nguyen",
      "Bobak Toussi Kiani",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11329"
  },
  {
    "id": "arXiv:2201.11333",
    "title": "Few-shot Transfer Learning for Holographic Image Reconstruction using a  Recurrent Neural Network",
    "abstract": "Deep learning-based methods in computational microscopy have been shown to be\npowerful but in general face some challenges due to limited generalization to\nnew types of samples and requirements for large and diverse training data.\nHere, we demonstrate a few-shot transfer learning method that helps a\nholographic image reconstruction deep neural network rapidly generalize to new\ntypes of samples using small datasets. We pre-trained a convolutional recurrent\nneural network on a large dataset with diverse types of samples, which serves\nas the backbone model. By fixing the recurrent blocks and transferring the rest\nof the convolutional blocks of the pre-trained model, we reduced the number of\ntrainable parameters by ~90% compared with standard transfer learning, while\nachieving equivalent generalization. We validated the effectiveness of this\napproach by successfully generalizing to new types of samples using small\nholographic datasets for training, and achieved (i) ~2.5-fold convergence speed\nacceleration, (ii) ~20% computation time reduction per epoch, and (iii)\nimproved reconstruction performance over baseline network models trained from\nscratch. This few-shot transfer learning approach can potentially be applied in\nother microscopic imaging methods, helping to generalize to new types of\nsamples without the need for extensive training time and data.",
    "descriptor": "\nComments: 10 Pages, 3 Figures\n",
    "authors": [
      "Luzhe Huang",
      "Xilin Yang",
      "Tairan Liu",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11333"
  },
  {
    "id": "arXiv:2201.11343",
    "title": "Distributed gradient-based optimization in the presence of dependent  aperiodic communication",
    "abstract": "Iterative distributed optimization algorithms involve multiple agents that\ncommunicate with each other, over time, in order to minimize/maximize a global\nobjective. In the presence of unreliable communication networks, the\nAge-of-Information (AoI), which measures the freshness of data received, may be\nlarge and hence hinder algorithmic convergence. In this paper, we study the\nconvergence of general distributed gradient-based optimization algorithms in\nthe presence of communication that neither happens periodically nor at\nstochastically independent points in time. We show that convergence is\nguaranteed provided the random variables associated with the AoI processes are\nstochastically dominated by a random variable with finite first moment. This\nimproves on previous requirements of boundedness of more than the first moment.\nWe then introduce stochastically strongly connected (SSC) networks, a new\nstochastic form of strong connectedness for time-varying networks. We show: If\nfor any $p \\ge0$ the processes that describe the success of communication\nbetween agents in a SSC network are $\\alpha$-mixing with $n^{p-1}\\alpha(n)$\nsummable, then the associated AoI processes are stochastically dominated by a\nrandom variable with finite $p$-th moment. In combination with our first\ncontribution, this implies that distributed stochastic gradient descend\nconverges in the presence of AoI, if $\\alpha(n)$ is summable.",
    "descriptor": "",
    "authors": [
      "Adrian Redder",
      "Arunselvan Ramaswamy",
      "Holger Karl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.11343"
  },
  {
    "id": "arXiv:2201.11378",
    "title": "Rational Solutions of First Order Algebraic Ordinary Differential  Equations",
    "abstract": "Let $f(t,y,y')=\\sum_{i=0}^n a_i(t,y)y'^i=0$ be an irreducible first order\nordinary differential equation with polynomial coefficients. Eremenko in 1998\nproved that there exists a constant $C$ such that every rational solution of\n$f(t,y,y')=0$ is of degree not greater than $C$. Examples show that this degree\nbound $C$ depends not only on the degrees of $f$ in $t,y,y'$ but also on the\ncoefficients of $f$ viewed as the polynomial in $t,y,y'$. In this paper, we\nshow that if $f$ satisfies $deg(f,y)<deg(f,y')$ or $\\max_{i=0}^n\n\\{deg(a_i,y)-2(n-i)\\}>0 $ then the degree bound $C$ only depends on the degrees\nof $f$ in $t,y,y'$, and furthermore we present an explicit expression for $C$\nin terms of the degrees of $f$ in $t,y,y'$.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2005.01289\n",
    "authors": [
      "Shuang Feng",
      "Li-Yong Shen"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2201.11378"
  },
  {
    "id": "arXiv:2201.11384",
    "title": "Phase Retrieval for Radar Waveform Design",
    "abstract": "The ability of a radar to discriminate in both range and Doppler velocity is\ncompletely characterized by the ambiguity function (AF) of its transmit\nwaveform. Mathematically, it is obtained by correlating the waveform with its\nDoppler-shifted and delayed replicas. We consider the inverse problem of\ndesigning a radar transmit waveform that satisfies the specified AF magnitude.\nThis process can be viewed as a signal reconstruction with some variation of\nphase retrieval methods. We provide a trust-region algorithm that minimizes a\nsmoothed non-convex least-squares objective function to iteratively recover the\nunderlying signal-of-interest for either time- or band-limited support. The\nmethod first approximates the signal using an iterative spectral algorithm and\nthen refines the attained initialization based upon a sequence of gradient\niterations. Our theoretical analysis shows that unique signal reconstruction is\npossible using signal samples no more than thrice the number of signal\nfrequencies or time samples. Numerical experiments demonstrate that our method\nrecovers both time- and band-limited signals from even sparsely and randomly\nsampled AFs with mean-square-error of $1\\times 10^{-6}$ and $9\\times 10^{-2}$\nfor the full noiseless samples and sparse noisy samples, respectively.",
    "descriptor": "\nComments: 18 pages, 12 figures, 1 table\n",
    "authors": [
      "Samuel Pinilla",
      "Kumar Vijay Mishra",
      "Brian M. Sadler",
      "Henry Arguello"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11384"
  },
  {
    "id": "arXiv:2201.11389",
    "title": "Multi-Frame Quality Enhancement On Compressed Video Using Quantised Data  of Deep Belief Networks",
    "abstract": "In the age of streaming and surveillance compressed video enhancement has\nbecome a problem in need of constant improvement. Here, we investigate a way of\nimproving the Multi-Frame Quality Enhancement approach. This approach consists\nof making use of the frames that have the peak quality in the region to improve\nthose that have a lower quality in that region. This approach consists of\nobtaining quantized data from the videos using a deep belief network. The\nquantized data is then fed into the MF-CNN architecture to improve the\ncompressed video. We further investigate the impact of using a Bi-LSTM for\ndetecting the peak quality frames. Our approach obtains better results than the\nfirst approach of the MFQE which uses an SVM for PQF detection. On the other\nhand, our MFQE approach does not outperform the latest version of the MQFE\napproach that uses a Bi-LSTM for PQF detection.",
    "descriptor": "\nComments: 7 pages, 11 figures and 3 tables\n",
    "authors": [
      "Dionne Takudzwa Chasi",
      "Mkhuseli Ngxande"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11389"
  },
  {
    "id": "arXiv:2201.11411",
    "title": "Restarted Nonconvex Accelerated Gradient Descent: No More  Polylogarithmic Factor in the $O(\u03b5^{-7/4})$ Complexity",
    "abstract": "This paper studies the accelerated gradient descent for general nonconvex\nproblems under the gradient Lipschitz and Hessian Lipschitz assumptions. We\nestablish that a simple restarted accelerated gradient descent (AGD) finds an\n$\\epsilon$-approximate first-order stationary point in $O(\\epsilon^{-7/4})$\ngradient computations with simple proofs. Our complexity does not hide any\npolylogarithmic factors, and thus it improves over the state-of-the-art one by\nthe $O(\\log\\frac{1}{\\epsilon})$ factor. Our simple algorithm only consists of\nNesterov's classical AGD and a restart mechanism, and it does not need the\nnegative curvature exploitation or the optimization of regularized surrogate\nfunctions. Technically, our simple proof does not invoke the analysis for the\nstrongly convex AGD, which is crucial to remove the $O(\\log\\frac{1}{\\epsilon})$\nfactor.",
    "descriptor": "",
    "authors": [
      "Huan Li",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11411"
  },
  {
    "id": "arXiv:2201.11446",
    "title": "Pan-Tumor CAnine cuTaneous Cancer Histology (CATCH) Dataset",
    "abstract": "Due to morphological similarities, the differentiation of histologic sections\nof cutaneous tumors into individual subtypes can be challenging. Recently, deep\nlearning-based approaches have proven their potential for supporting\npathologists in this regard. However, many of these supervised algorithms\nrequire a large amount of annotated data for robust development. We present a\npublicly available dataset consisting of 350 whole slide images of seven\ndifferent canine cutaneous tumors complemented by 12,424 polygon annotations\nfor 13 histologic classes including seven cutaneous tumor subtypes. Regarding\nsample size and annotation extent, this exceeds most publicly available\ndatasets which are oftentimes limited to the tumor area or merely provide\npatch-level annotations. We validated our model for tissue segmentation,\nachieving a class-averaged Jaccard coefficient of 0.7047, and 0.9044 for tumor\nin particular. For tumor subtype classification, we achieve a slide-level\naccuracy of 0.9857. Since canine cutaneous tumors possess various histologic\nhomologies to human tumors, we believe that the added value of this dataset is\nnot limited to veterinary pathology but extends to more general fields of\napplication.",
    "descriptor": "\nComments: Submitted to Scientific Data. 12 pages, 6 figures, 5 tables\n",
    "authors": [
      "Frauke Wilm",
      "Marco Fragoso",
      "Christian Marzahl",
      "Jingna Qiu",
      "Christof A. Bertram",
      "Robert Klopfleisch",
      "Andreas Maier",
      "Katharina Breininger",
      "Marc Aubreville"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11446"
  },
  {
    "id": "arXiv:2201.11459",
    "title": "Alleviating the Transit Timing Variations bias in transit surveys. II.  RIVERS: Twin resonant Earth-sized planets around Kepler-1972 recovered from  Kepler's false positive",
    "abstract": "Transit Timing Variations (TTVs) can provide useful information for systems\nobserved by transit, by putting constraints on the masses and eccentricities of\nthe observed planets, or even constrain the existence of non-transiting\ncompanions. However, TTVs can also prevent the detection of small planets in\ntransit surveys, or bias the recovered planetary and transit parameters. Here\nwe show that Kepler-1972 c, initially the \"not transit-like\" false positive\nKOI-3184.02, is an Earth-sized planet whose orbit is perturbed by Kepler-1972 b\n(initially KOI-3184.01). The pair is locked in a 3:2 Mean-motion resonance,\neach planet displaying TTVs of more than 6h hours of amplitude over the\nduration of the Kepler mission. The two planets have similar masses $m_b/m_c\n=0.956_{-0.051}^{+0.056}$ and radii $R_b=0.802_{-0.041}^{+0.042}R_{Earth}$,\n$R_c=0.868_{-0.050}^{+0.051}R_{Earth}$, and the whole system, including the\ninner candidate KOI-3184.03, appear to be coplanar. Despite the faintness of\nthe signals (SNR of 1.35 for each transit of Kepler-1972 b and 1.10 for\nKepler-1972 c), we recovered the transits of the planets using the RIVERS\nmethod, based on the recognition of the tracks of planets in river diagrams\nusing machine learning, and a photo-dynamic fit of the lightcurve. Recovering\nthe correct ephemerides of the planets is essential to have a complete picture\nof the observed planetary systems. In particular, we show that in Kepler-1972,\nnot taking into account planet-planet interactions yields an error of $\\sim\n30\\%$ on the radii of planets b and c, in addition to generating in-transit\nscatter, which leads to mistake KOI3184.02 for a false positive. Alleviating\nthis bias is essential for an unbiased view of Kepler systems, some of the TESS\nstars, and the upcoming PLATO mission.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.06825\n",
    "authors": [
      "A. Leleu",
      "J.-B. Delisle",
      "R. Mardling",
      "S. Udry",
      "G. Chatel",
      "Y. Alibert",
      "P. Eggenberger"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11459"
  },
  {
    "id": "arXiv:2201.11509",
    "title": "An experimental data-driven mass-spring model of flexible Calliphora  wings",
    "abstract": "Insect wings can undergo significant deformation during flapping motion owing\nto inertial, elastic and aerodynamic forces. Changes in shape then alter\naerodynamic forces, resulting in a fully coupled Fluid-Structure Interaction\n(FSI) problem. Here, we present detailed three-dimensional FSI simulations of\ndeformable blowfly (Calliphora vomitoria) wings in flapping flight. A wing\nmodel is proposed using a multi-parameter mass-spring approach, chosen for its\nimplementation simplicity and computational efficiency. We train the model to\nreproduce static elasticity measurements by optimizing its parameters using a\ngenetic algorithm with covariance matrix adaptation (CMA-ES). Wing models\ntrained with experimental data are then coupled to a high-performance flow\nsolver run on massively parallel supercomputers. Different features of the\nmodeling approach and the intra-species variability of elastic properties are\ndiscussed. We found that individuals with different wing stiffness exhibit\nsimilar aerodynamic properties characterized by dimensionless forces and power\nat the same Reynolds number. We further study the influence of wing flexibility\nby comparing between the flexible wings and their rigid counterparts. Under\nequal prescribed kinematic conditions for rigid and flexible wings, wing\nflexibility improves lift-to-drag ratio as well as lift-to-power ratio and\nreduces peak force observed during wing rotation.",
    "descriptor": "",
    "authors": [
      "Hung Truong",
      "Thomas Engels",
      "Henja Wehmann",
      "Dmitry Kolomenskiy",
      "Fritz-Olaf Lehmann",
      "Kai Schneider"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.11509"
  },
  {
    "id": "arXiv:2201.11510",
    "title": "Efficient Quantum Computation of the Fermionic Boundary Operator",
    "abstract": "The boundary operator is a linear operator that acts on a collection of\nhigh-dimensional binary points (simplices) and maps them to their boundaries.\nThis boundary map is one of the key components in numerous applications,\nincluding differential equations, machine learning, computational geometry,\nmachine vision and control systems. We consider the problem of representing the\nfull boundary operator on a quantum computer. We first prove that the boundary\noperator has a special structure in the form of a complete sum of fermionic\ncreation and annihilation operators. We then use the fact that these operators\npairwise anticommute to produce an $\\mathcal{O}(n)$-depth circuit that exactly\nimplements the boundary operator without any Trotterization or Taylor series\napproximation errors. Having fewer errors reduces the number of shots required\nto obtain desired accuracies.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Ismail Yunus Akhalwaya",
      "Yang-Hui He",
      "Lior Horesh",
      "Vishnu Jejjala",
      "William Kirby",
      "Kugendran Naidoo",
      "Shashanka Ubaru"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Numerical Analysis (math.NA)",
      "Quantum Algebra (math.QA)"
    ],
    "url": "https://arxiv.org/abs/2201.11510"
  },
  {
    "id": "arXiv:2201.11517",
    "title": "Multimodal neural networks better explain multivoxel patterns in the  hippocampus",
    "abstract": "The human hippocampus possesses \"concept cells\", neurons that fire when\npresented with stimuli belonging to a specific concept, regardless of the\nmodality. Recently, similar concept cells were discovered in a multimodal\nnetwork called CLIP (Radford et at., 2021). Here, we ask whether CLIP can\nexplain the fMRI activity of the human hippocampus better than a purely visual\n(or linguistic) model. We extend our analysis to a range of publicly available\nuni- and multi-modal models. We demonstrate that \"multimodality\" stands out as\na key component when assessing the ability of a network to explain the\nmultivoxel activity in the hippocampus.",
    "descriptor": "\nComments: Oral at SVRHM Workshop (NeurIPS 2021)\n",
    "authors": [
      "Bhavin Choksi",
      "Milad Mozafari",
      "Rufin VanRullen",
      "Leila Reddy"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.11517"
  },
  {
    "id": "arXiv:2201.11526",
    "title": "A distributed computing infrastructure for LOFAR Italian community",
    "abstract": "The LOw-Frequency ARray is a low-frequency radio interferometer composed by\nobservational stations spread across Europe and it is the largest precursor of\nSKA in terms of effective area and generated data rates. In 2018, the Italian\ncommunity officially joined LOFAR project, and it deployed a distributed\ncomputing and storage infrastructure dedicated to LOFAR data analysis. The\ninfrastructure is based on 4 nodes distributed in different Italian locations\nand it offers services for pipelines execution, storage of final and\nintermediate results and support for the use of the software and\ninfrastructure. As the analysis of the LOw-Frequency ARray data requires a very\ncomplex computational procedure, a container-based approach has been adopted to\ndistribute software environments to the different computing resources. A\nscience platform approach is used to facilitate interactive access to\ncomputational resources. In this paper, we describe the architecture and main\nfeatures of the infrastructure.",
    "descriptor": "\nComments: In Astronomical Data Analysis Software and Systems (ADASS) XXXI\n",
    "authors": [
      "Giuliano Taffoni",
      "Ugo Becciani",
      "Annalisa Bonafede",
      "Etienne Bonnassieux",
      "Gianfranco Brunetti",
      "Marisa Brienza",
      "Claudio Gheller",
      "Stefano A. Russo",
      "Fabio Vitello"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11526"
  },
  {
    "id": "arXiv:2201.11548",
    "title": "Vizing's and Shannon's Theorems for defective edge colouring",
    "abstract": "We call a multigraph $(k,d)$-edge colourable if its edge set can be\npartitioned into $k$ subgraphs of maximum degree at most $d$ and denote as\n$\\chi'_{d}(G)$ the minimum $k$ such that $G$ is $(k,d)$-edge colourable. We\nprove that for every integer $d$, every multigraph $G$ with maximum degree\n$\\Delta$ is $(\\lceil \\frac{\\Delta}{d} \\rceil, d)$-edge colourable if $d$ is\neven and $(\\lceil \\frac{3\\Delta - 1}{3d - 1} \\rceil, d)$-edge colourable if $d$\nis odd and these bounds are tight. We also prove that for every simple graph\n$G$, $\\chi'_{d}(G) \\in \\{ \\lceil \\frac{\\Delta}{d} \\rceil, \\lceil\n\\frac{\\Delta+1}{d} \\rceil \\}$ and characterize the values of $d$ and $\\Delta$\nfor which it is NP-complete to compute $\\chi'_d(G)$. These results generalize\nseveral classic results on the chromatic index of a graph by Shannon, Vizing,\nHolyer, Leven and Galil.",
    "descriptor": "",
    "authors": [
      "Pierre Aboulker",
      "Guillaume Aubian",
      "Chien-Chung Huang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.11548"
  },
  {
    "id": "arXiv:2201.11571",
    "title": "Synthesizing Dysarthric Speech Using Multi-talker TTS for Dysarthric  Speech Recognition",
    "abstract": "Dysarthria is a motor speech disorder often characterized by reduced speech\nintelligibility through slow, uncoordinated control of speech production\nmuscles. Automatic Speech recognition (ASR) systems may help dysarthric talkers\ncommunicate more effectively. To have robust dysarthria-specific ASR,\nsufficient training speech is required, which is not readily available. Recent\nadvances in Text-To-Speech (TTS) synthesis multi-speaker end-to-end TTS systems\nsuggest the possibility of using synthesis for data augmentation. In this\npaper, we aim to improve multi-speaker end-to-end TTS systems to synthesize\ndysarthric speech for improved training of a dysarthria-specific DNN-HMM ASR.\nIn the synthesized speech, we add dysarthria severity level and pause insertion\nmechanisms to other control parameters such as pitch, energy, and duration.\nResults show that a DNN-HMM model trained on additional synthetic dysarthric\nspeech achieves WER improvement of 12.2% compared to the baseline, the addition\nof the severity level and pause insertion controls decrease WER by 6.5%,\nshowing the effectiveness of adding these parameters. Audio samples are\navailable at",
    "descriptor": "\nComments: Accepted ICASSP 2022\n",
    "authors": [
      "Mohammad Soleymanpour",
      "Michael T. Johnson",
      "Rahim Soleymanpour",
      "Jeffrey Berry"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.11571"
  },
  {
    "id": "arXiv:2201.11627",
    "title": "Internal language model estimation through explicit context vector  learning for attention-based encoder-decoder ASR",
    "abstract": "An end-to-end (E2E) speech recognition model implicitly learns a biased\ninternal language model (ILM) during training. To fused an external LM during\ninference, the scores produced by the biased ILM need to be estimated and\nsubtracted. In this paper we propose two novel approaches to estimate the\nbiased ILM based on Listen-Attend-Spell (LAS) models. The simpler method is to\nreplace the context vector of the LAS decoder at every time step with a\nlearnable vector. The other more advanced method is to use a simple\nfeed-forward network to directly map query vectors to context vectors, making\nthe generation of the context vectors independent of the LAS encoder. Both the\nlearnable vector and the mapping network are trained on the transcriptions of\nthe training data to minimize the perplexity while all the other parameters of\nthe LAS model is fixed. Experiments show that the ILMs estimated by the\nproposed methods achieve the lowest perplexity. In addition, they also\nsignificantly outperform the shallow fusion method and two previously proposed\nInternal Language Model Estimation (ILME) approaches on multiple datasets.",
    "descriptor": "",
    "authors": [
      "Yufei Liu",
      "Rao Ma",
      "Haihua Xu",
      "Yi He",
      "Zejun Ma",
      "Weibin Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.11627"
  },
  {
    "id": "arXiv:2201.11630",
    "title": "Automatic Classification of Neuromuscular Diseases in Children Using  Photoacoustic Imaging",
    "abstract": "Neuromuscular diseases (NMDs) cause a significant burden for both healthcare\nsystems and society. They can lead to severe progressive muscle weakness,\nmuscle degeneration, contracture, deformity and progressive disability. The\nNMDs evaluated in this study often manifest in early childhood. As subtypes of\ndisease, e.g. Duchenne Muscular Dystropy (DMD) and Spinal Muscular Atrophy\n(SMA), are difficult to differentiate at the beginning and worsen quickly, fast\nand reliable differential diagnosis is crucial. Photoacoustic and ultrasound\nimaging has shown great potential to visualize and quantify the extent of\ndifferent diseases. The addition of automatic classification of such image data\ncould further improve standard diagnostic procedures. We compare deep\nlearning-based 2-class and 3-class classifiers based on VGG16 for\ndifferentiating healthy from diseased muscular tissue. This work shows\npromising results with high accuracies above 0.86 for the 3-class problem and\ncan be used as a proof of concept for future approaches for earlier diagnosis\nand therapeutic monitoring of NMDs.",
    "descriptor": "\nComments: accepted by BVM conference proceedings 2022\n",
    "authors": [
      "Maja Schlereth",
      "Daniel Stromer",
      "Katharina Breininger",
      "Alexandra Wagner",
      "Lina Tan",
      "Andreas Maier",
      "Ferdinand Knieling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11630"
  },
  {
    "id": "arXiv:2201.11643",
    "title": "From the Ravine method to the Nesterov method and vice versa: a  dynamical system perspective",
    "abstract": "We revisit the Ravine method of Gelfand and Tsetlin from a dynamical system\nperspective, study its convergence properties, and highlight its similarities\nand differences with the Nesterov accelerated gradient method. The two methods\nare closely related. They can be deduced from each other by reversing the order\nof the extrapolation and gradient operations in their definitions. They benefit\nfrom similar fast convergence of values and convergence of iterates for general\nconvex objective functions. We will also establish the high resolution ODE of\nthe Ravine and Nesterov methods, and reveal an additional geometric damping\nterm driven by the Hessian for both methods. This will allow us to prove fast\nconvergence towards zero of the gradients not only for the Ravine method but\nalso for the Nesterov method for the first time. We also highlight connections\nto other algorithms stemming from more subtle discretization schemes, and\nfinally describe a Ravine version of the proximal-gradient algorithms for\ngeneral structured smooth + non-smooth convex optimization problems.",
    "descriptor": "",
    "authors": [
      "H. Attouch",
      "J. Fadili"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11643"
  },
  {
    "id": "arXiv:2201.11649",
    "title": "Grid-friendly Matching Control of Synchronous Machines by DC/AC  Converters in Bulk Power Networks",
    "abstract": "An islanded inverter-based microgrid is a collection of heterogeneous DC\nenergy resources, e.g., photovoltaic arrays, fuel cells, and energy-storage\ndevices, interfaced to an AC distribution network and operated independently\nfrom the bulk power system. Energy conversion is typically managed by power\nelectronics in voltage source inverters. Drawing from the control of\nsynchronous machines in bulk power systems, different control schemes have been\nrecently adopted in order to achieve a stable network operation. The vast\nmajority of academic and industrial efforts opt for these strategies during\nreal-time operation.\nStarting with a dynamical averaged DC/AC converter model, we review different\ncontrollers by presenting their main scope analytically and through\nsimulations. Next, we explore a new alternative of controlling DC/AC converters\nin bulk power systems by matching traditional synchronous machines with\nemphasis on the role that DC-circuit can play in control architecture, usually\nneglected in conventional strategies. Compared to standard emulation methods,\nour controller relies solely on readily available DC-side measurements and\ntakes into account the natural DC and AC storage elements. As a result, our\ncontroller is generally faster and less vulnerable to delays and measurement\ninaccuracies. We additionally provide insightful interpretations of the\nsuggested control, various plug-and-play properties of the closed-loop, such as\nsteady-state power flow analysis, passivity with respect to the DC and AC\nports, stability proof as well as high-level control architectures contributing\nto enhancing the controller performance and attaining further control goals,\nwhich we illustrate in both analysis and simulation.",
    "descriptor": "\nComments: 117 pages, Master thesis defended on June 9, 2016 at the Institute of Systems Theory and Control (IST) - University of Stuttgart\n",
    "authors": [
      "Taouba Jouini"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11649"
  },
  {
    "id": "arXiv:2201.11671",
    "title": "Capture Agent Free Biosensing using Porous Silicon Arrays and Machine  Learning",
    "abstract": "Biosensors are an essential tool for medical diagnostics, environmental\nmonitoring and food safety. Typically, biosensors are designed to detect\nspecific analytes through functionalization with the appropriate capture\nagents. However, the use of capture agents limits the number of analytes that\ncan be simultaneously detected and reduces the robustness of the biosensor. In\nthis work, we report a versatile, capture agent free biosensor platform based\non an array of porous silicon (PSi) thin films, which has the potential to\nrobustly detect a wide variety of analytes based on their physical and chemical\nproperties in the nanoscale porous media. The ability of this system to\nreproducibly classify, quantify, and discriminate three proteins is\ndemonstrated to concentrations down to at least 0.02g/L (between 300nM and\n450nM) by utilizing PSi array elements with a unique combination of pore size\nand buffer pH, employing linear discriminant analysis for dimensionality\nreduction, and using support vector machines as a classifier. This approach\nrepresents a significant step towards a low cost, simple and robust biosensor\nplatform that is able to detect a vast range of biomolecules.",
    "descriptor": "\nComments: 15 pages, 3 figures, 2 tables\n",
    "authors": [
      "Simon J. Ward",
      "Tengfei Cao",
      "Xiang Zhou",
      "Catie Chang",
      "Sharon M. Weiss"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2201.11671"
  },
  {
    "id": "arXiv:2201.11677",
    "title": "Parallel black-box optimization of expensive high-dimensional multimodal  functions via magnitude",
    "abstract": "Building on the recently developed theory of magnitude, we introduce the\noptimization algorithm EXPLO2 and carefully benchmark it. EXPLO2 advances the\nstate of the art for optimizing high-dimensional ($D \\gtrapprox 40$) multimodal\nfunctions that are expensive to compute and for which derivatives are not\navailable, such as arise in hyperparameter optimization or via simulations.",
    "descriptor": "",
    "authors": [
      "Steve Huntsman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.11677"
  },
  {
    "id": "arXiv:2201.11700",
    "title": "Matched Illumination",
    "abstract": "In previous work, it was shown that a camera can theoretically be made more\ncolorimetric - its RGBs become more linearly related to XYZ tristimuli - by\nplacing a specially designed color filter in the optical path. While the prior\nart demonstrated the principle, the optimal color-correction filters were not\nactually manufactured. In this paper, we provide a novel way of creating the\ncolor filtering effect without making a physical filter: we modulate the\nspectrum of the light source by using a spectrally tunable lighting system to\nrecast the prefiltering effect from a lighting perspective. According to our\nmethod, if we wish to measure color under a D65 light, we relight the scene\nwith a modulated D65 spectrum where the light modulation mimics the effect of\ncolor prefiltering in the prior art. We call our optimally modulated light, the\nmatched illumination. In the experiments, using synthetic and real\nmeasurements, we show that color measurement errors can be reduced by about 50%\nor more on simulated data and 25% or more on real images when the matched\nillumination is used.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Yuteng Zhu",
      "Graham D. Finlayson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11700"
  },
  {
    "id": "arXiv:2201.11720",
    "title": "Simplicial Convolutional Filters",
    "abstract": "We study linear filters for processing signals supported on abstract\ntopological spaces modeled as simplicial complexes, which may be interpreted as\ngeneralizations of graphs that account for nodes, edges, triangular faces etc.\nTo process such signals, we develop simplicial convolutional filters defined as\nmatrix polynomials of the lower and upper Hodge Laplacians. First, we study the\nproperties of these filters and show that they are linear and shift-invariant,\nas well as permutation and orientation equivariant. These filters can also be\nimplemented in a distributed fashion with a low computational complexity, as\nthey involve only (multiple rounds of) simplicial shifting between upper and\nlower adjacent simplices. Second, focusing on edge-flows, we study the\nfrequency responses of these filters and examine how we can use the\nHodge-decomposition to delineate gradient, curl and harmonic frequencies. We\ndiscuss how these frequencies correspond to the lower- and the upper-adjacent\ncouplings and the kernel of the Hodge Laplacian, respectively, and can be tuned\nindependently by our filter designs. Third, we study different procedures for\ndesigning simplicial convolutional filters and discuss their relative\nadvantages. Finally, we corroborate our simplicial filters in several\napplications: to extract different frequency components of a simplicial signal,\nto denoise edge flows, and to analyze financial markets and traffic networks.",
    "descriptor": "\nComments: 15 pages, 13 figures, 2 tables\n",
    "authors": [
      "Maosheng Yang",
      "Elvin Isufi",
      "Michael T. Schaub",
      "Geert Leus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11720"
  },
  {
    "id": "arXiv:2201.11733",
    "title": "A simple and constructive proof to a generalization of L\u00fcroth's  theorem",
    "abstract": "A generalization of L{\\\"u}roth's theorem expresses that every transcendence\ndegree 1 subfield of the rational function field is a simple extension. In this\nnote we show that a classical proof of this theorem also holds to prove this\ngeneralization.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Fran\u00e7ois Ollivier",
      "Brahim Sadik"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Symbolic Computation (cs.SC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2201.11733"
  },
  {
    "id": "arXiv:2201.11737",
    "title": "PRNU Based Source Camera Identification for Webcam and Smartphone Videos",
    "abstract": "This communication is about an application of image forensics where we use\ncamera sensor fingerprints to identify source camera (SCI: Source Camera\nIdentification) in webcam/smartphone videos. Sensor or camera fingerprints are\nbased on computing the intrinsic noise that is always present in this kind of\nsensors due to manufacturing imperfections. This is an unavoidable\ncharacteristic that links each sensor with its noise pattern. PRNU (Photo\nResponse Non-Uniformity) has become the default technique to compute a camera\nfingerprint. There are many applications nowadays dealing with PRNU patterns\nfor camera identification using still images. In this work we focus on video,\nfirst on webcam video and afterwards on smartphone video. Webcams and\nsmartphones are the most used video cameras nowadays. Three possible methods\nfor SCI are implemented and assessed in this work.",
    "descriptor": "\nComments: 4 pages, 5 figures, 4 tables. arXiv admin note: substantial text overlap with arXiv:2107.01885\n",
    "authors": [
      "Fernando Mart\u00edn-Rodr\u00edguez",
      "Fernando Isasi-de-Vicente"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11737"
  },
  {
    "id": "arXiv:1712.00378",
    "title": "Time Limits in Reinforcement Learning",
    "abstract": "Comments: ICML 2018, NIPS 2017 Deep RL Symposium, code and videos: this https URL",
    "descriptor": "\nComments: ICML 2018, NIPS 2017 Deep RL Symposium, code and videos: this https URL\n",
    "authors": [
      "Fabio Pardo",
      "Arash Tavakoli",
      "Vitaly Levdik",
      "Petar Kormushev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1712.00378"
  },
  {
    "id": "arXiv:1808.04878",
    "title": "Latent Agents in Networks: Estimation and Targeting",
    "abstract": "Comments: 106 pages",
    "descriptor": "\nComments: 106 pages\n",
    "authors": [
      "Baris Ata",
      "Alexandre Belloni",
      "Ozan Candogan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Theoretical Economics (econ.TH)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1808.04878"
  },
  {
    "id": "arXiv:1901.05031",
    "title": "Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs",
    "abstract": "Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs",
    "descriptor": "",
    "authors": [
      "Mauricio Flores",
      "Jeff Calder",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/1901.05031"
  },
  {
    "id": "arXiv:1905.12375",
    "title": "Scalable Spike Source Localization in Extracellular Recordings using  Amortized Variational Inference",
    "abstract": "Scalable Spike Source Localization in Extracellular Recordings using  Amortized Variational Inference",
    "descriptor": "",
    "authors": [
      "Cole L. Hurwitz",
      "Kai Xu",
      "Akash Srivastava",
      "Alessio P. Buccino",
      "Matthias H. Hennig"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.12375"
  },
  {
    "id": "arXiv:1908.01686",
    "title": "Likelihood Contribution based Multi-scale Architecture for Generative  Flows",
    "abstract": "Likelihood Contribution based Multi-scale Architecture for Generative  Flows",
    "descriptor": "",
    "authors": [
      "Hari Prasanna Das",
      "Pieter Abbeel",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.01686"
  },
  {
    "id": "arXiv:1908.02734",
    "title": "Stochastic First-order Methods for Convex and Nonconvex Functional  Constrained Optimization",
    "abstract": "Comments: 36 pages, final version, accepted at Math Programming",
    "descriptor": "\nComments: 36 pages, final version, accepted at Math Programming\n",
    "authors": [
      "Digvijay Boob",
      "Qi Deng",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.02734"
  },
  {
    "id": "arXiv:1910.03960",
    "title": "Input-output equations and identifiability of linear ODE models",
    "abstract": "Input-output equations and identifiability of linear ODE models",
    "descriptor": "",
    "authors": [
      "Alexey Ovchinnikov",
      "Gleb Pogudin",
      "Peter Thompson"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/1910.03960"
  },
  {
    "id": "arXiv:2002.07957",
    "title": "Massive IoT Access With NOMA in 5G Networks and Beyond Using Online  Competitiveness and Learning",
    "abstract": "Massive IoT Access With NOMA in 5G Networks and Beyond Using Online  Competitiveness and Learning",
    "descriptor": "",
    "authors": [
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2002.07957"
  },
  {
    "id": "arXiv:2003.11139",
    "title": "Cheating in online gaming spreads through observation and victimization",
    "abstract": "Cheating in online gaming spreads through observation and victimization",
    "descriptor": "",
    "authors": [
      "Ji Eun Kim",
      "Milena Tsvetkova"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2003.11139"
  },
  {
    "id": "arXiv:2006.08167",
    "title": "Improved Complexities for Stochastic Conditional Gradient Methods under  Interpolation-like Conditions",
    "abstract": "Improved Complexities for Stochastic Conditional Gradient Methods under  Interpolation-like Conditions",
    "descriptor": "",
    "authors": [
      "Tesi Xiao",
      "Krishnakumar Balasubramanian",
      "Saeed Ghadimi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08167"
  },
  {
    "id": "arXiv:2006.09500",
    "title": "Logic of Machine Learning",
    "abstract": "Logic of Machine Learning",
    "descriptor": "",
    "authors": [
      "Marina Sapir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09500"
  },
  {
    "id": "arXiv:2007.09182",
    "title": "Budget-balanced and strategy-proof auctions for multi-passenger  ridesharing",
    "abstract": "Comments: 27 pages with 1 figure",
    "descriptor": "\nComments: 27 pages with 1 figure\n",
    "authors": [
      "Leonardo Y. Schwarzstein",
      "Rafael C. S. Schouery"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.09182"
  },
  {
    "id": "arXiv:2008.08977",
    "title": "Generating Adjacency Matrix for Video Relocalization",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2007.09877",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.09877\n",
    "authors": [
      "Yuan Zhou",
      "Mingfei Wang",
      "Ruolin Wang",
      "Shuwei Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.08977"
  },
  {
    "id": "arXiv:2008.10774",
    "title": "Image Colorization: A Survey and Dataset",
    "abstract": "Image Colorization: A Survey and Dataset",
    "descriptor": "",
    "authors": [
      "Saeed Anwar",
      "Muhammad Tahir",
      "Chongyi Li",
      "Ajmal Mian",
      "Fahad Shahbaz Khan",
      "Abdul Wahab Muzaffar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.10774"
  },
  {
    "id": "arXiv:2008.12834",
    "title": "An Efficient Augmented Lagrangian Method with Semismooth Newton Solver  for Total Generalized Variation",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1911.10968",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.10968\n",
    "authors": [
      "Hongpeng Sun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.12834"
  },
  {
    "id": "arXiv:2009.00081",
    "title": "Federated Edge Learning : Design Issues and Challenges",
    "abstract": "Comments: Submitted to IEEE Network Magazine",
    "descriptor": "\nComments: Submitted to IEEE Network Magazine\n",
    "authors": [
      "Afaf Ta\u00efk",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.00081"
  },
  {
    "id": "arXiv:2009.14799",
    "title": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and  Feedback-Aware Attention",
    "abstract": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and  Feedback-Aware Attention",
    "descriptor": "",
    "authors": [
      "Carson Eisenach",
      "Yagna Patel",
      "Dhruv Madeka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.14799"
  },
  {
    "id": "arXiv:2010.00952",
    "title": "Distributed Proximal Splitting Algorithms with Rates and Acceleration",
    "abstract": "Distributed Proximal Splitting Algorithms with Rates and Acceleration",
    "descriptor": "",
    "authors": [
      "Laurent Condat",
      "Grigory Malinovsky",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.00952"
  },
  {
    "id": "arXiv:2010.01792",
    "title": "Can we Generalize and Distribute Private Representation Learning?",
    "abstract": "Comments: In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022",
    "descriptor": "\nComments: In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Sheikh Shams Azam",
      "Taejin Kim",
      "Seyyedali Hosseinalipour",
      "Carlee Joe-Wong",
      "Saurabh Bagchi",
      "Christopher Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01792"
  },
  {
    "id": "arXiv:2010.02469",
    "title": "Generalized Matrix Factorization: efficient algorithms for fitting  generalized linear latent variable models to large data arrays",
    "abstract": "Generalized Matrix Factorization: efficient algorithms for fitting  generalized linear latent variable models to large data arrays",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Kidzi\u0144ski",
      "Francis K.C. Hui",
      "David I. Warton",
      "Trevor Hastie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02469"
  },
  {
    "id": "arXiv:2010.07522",
    "title": "Named Entity Recognition and Relation Extraction using Enhanced Table  Filling by Contextualized Representations",
    "abstract": "Comments: An extended version of this paper has been accepted at Journal of Natural Language Processing",
    "descriptor": "\nComments: An extended version of this paper has been accepted at Journal of Natural Language Processing\n",
    "authors": [
      "Youmi Ma",
      "Tatsuya Hiraoka",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.07522"
  },
  {
    "id": "arXiv:2011.09899",
    "title": "MixMix: All You Need for Data-Free Compression Are Feature and Data  Mixing",
    "abstract": "MixMix: All You Need for Data-Free Compression Are Feature and Data  Mixing",
    "descriptor": "",
    "authors": [
      "Yuhang Li",
      "Feng Zhu",
      "Ruihao Gong",
      "Mingzhu Shen",
      "Xin Dong",
      "Fengwei Yu",
      "Shaoqing Lu",
      "Shi Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.09899"
  },
  {
    "id": "arXiv:2011.10534",
    "title": "Ambiguity through the lens of measure theory",
    "abstract": "Ambiguity through the lens of measure theory",
    "descriptor": "",
    "authors": [
      "Olivier Carton"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2011.10534"
  },
  {
    "id": "arXiv:2011.11961",
    "title": "MODNet: Real-Time Trimap-Free Portrait Matting via Objective  Decomposition",
    "abstract": "MODNet: Real-Time Trimap-Free Portrait Matting via Objective  Decomposition",
    "descriptor": "",
    "authors": [
      "Zhanghan Ke",
      "Jiayu Sun",
      "Kaican Li",
      "Qiong Yan",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11961"
  },
  {
    "id": "arXiv:2011.13492",
    "title": "Spectral Analysis and Fixed Point Stability of Deep Neural Dynamics",
    "abstract": "Comments: Submitted to 4th Annual Learning for Dynamics & Control Conference. 21 pages",
    "descriptor": "\nComments: Submitted to 4th Annual Learning for Dynamics & Control Conference. 21 pages\n",
    "authors": [
      "Jan Drgona",
      "Elliott Skomski",
      "Soumya Vasisht",
      "Aaron Tuor",
      "Draguna Vrabie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.13492"
  },
  {
    "id": "arXiv:2012.05858",
    "title": "SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image  Classifiers",
    "abstract": "SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image  Classifiers",
    "descriptor": "",
    "authors": [
      "Bingyao Huang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05858"
  },
  {
    "id": "arXiv:2012.10231",
    "title": "Controlling conditional expectations by zero-determinant strategies",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Masahiko Ueda"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.10231"
  },
  {
    "id": "arXiv:2012.11955",
    "title": "An Approach to Implement Photovoltaic Self-Consumption and Ramp-Rate  Control Algorithm with a Vanadium Redox Flow Battery Day-to-Day Forecast  Charging",
    "abstract": "Comments: Keywords: Photovoltaic solar energy; energy storage; self-consumption; ramp rate; VRFB; energy management strategies",
    "descriptor": "\nComments: Keywords: Photovoltaic solar energy; energy storage; self-consumption; ramp rate; VRFB; energy management strategies\n",
    "authors": [
      "Ana Foles",
      "Luis Fialho",
      "Manuel Collares-Pereira",
      "Pedro Horta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.11955"
  },
  {
    "id": "arXiv:2101.11306",
    "title": "Learning Non-linear Wavelet Transformation via Normalizing Flow",
    "abstract": "Comments: Main text: 8 pages, 4 figures. Supplement: 9 pages, 2 figures. Github link: this https URL",
    "descriptor": "\nComments: Main text: 8 pages, 4 figures. Supplement: 9 pages, 2 figures. Github link: this https URL\n",
    "authors": [
      "Shuo-Hui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11306"
  },
  {
    "id": "arXiv:2102.00485",
    "title": "Exploring the Geometry and Topology of Neural Network Loss Landscapes",
    "abstract": "Comments: Accepted at the 20th Symposium on Intelligent Data Analysis (IDA) 2022",
    "descriptor": "\nComments: Accepted at the 20th Symposium on Intelligent Data Analysis (IDA) 2022\n",
    "authors": [
      "Stefan Horoi",
      "Jessie Huang",
      "Bastian Rieck",
      "Guillaume Lajoie",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00485"
  },
  {
    "id": "arXiv:2102.03110",
    "title": "A study of referencing changes in preprint-publication pairs across  multiple fields",
    "abstract": "Comments: Manuscripts; Peer Review; Preprints; Reference Lists Changes; Publications",
    "descriptor": "\nComments: Manuscripts; Peer Review; Preprints; Reference Lists Changes; Publications\n",
    "authors": [
      "Aliakbar Akbaritabar",
      "Dimity Stephen",
      "Flaminio Squazzoni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2102.03110"
  },
  {
    "id": "arXiv:2102.03432",
    "title": "Advanced Stationary and Non-Stationary Kernel Designs for Domain-Aware  Gaussian Processes",
    "abstract": "Advanced Stationary and Non-Stationary Kernel Designs for Domain-Aware  Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Marcus M. Noack",
      "James A. Sethian"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03432"
  },
  {
    "id": "arXiv:2102.05737",
    "title": "Emojis predict dropouts of remote workers: An empirical study of emoji  usage on GitHub",
    "abstract": "Emojis predict dropouts of remote workers: An empirical study of emoji  usage on GitHub",
    "descriptor": "",
    "authors": [
      "Xuan Lu",
      "Wei Ai",
      "Zhenpeng Chen",
      "Yanbin Cao",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05737"
  },
  {
    "id": "arXiv:2102.05926",
    "title": "Diffusion of new products with heterogeneous consumers",
    "abstract": "Comments: 39 pages, 11 figures",
    "descriptor": "\nComments: 39 pages, 11 figures\n",
    "authors": [
      "Gadi Fibich",
      "Amit Golan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.05926"
  },
  {
    "id": "arXiv:2102.08363",
    "title": "COMBO: Conservative Offline Model-Based Policy Optimization",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tianhe Yu",
      "Aviral Kumar",
      "Rafael Rafailov",
      "Aravind Rajeswaran",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.08363"
  },
  {
    "id": "arXiv:2102.09491",
    "title": "Data-Aware Device Scheduling for Federated Edge Learning",
    "abstract": "Data-Aware Device Scheduling for Federated Edge Learning",
    "descriptor": "",
    "authors": [
      "Afaf Taik",
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09491"
  },
  {
    "id": "arXiv:2102.10931",
    "title": "Unifying Hidden-Variable Problems from Quantum Mechanics by Logics of  Dependence and Independence",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Rafael Albert",
      "Erich Gr\u00e4del"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.10931"
  },
  {
    "id": "arXiv:2102.12206",
    "title": "PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen  Domains",
    "abstract": "Comments: Accepted for publication at TACL in January 2022. First two authors contributed equally to this work. Our code and data are available at: this https URL",
    "descriptor": "\nComments: Accepted for publication at TACL in January 2022. First two authors contributed equally to this work. Our code and data are available at: this https URL\n",
    "authors": [
      "Eyal Ben-David",
      "Nadav Oved",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12206"
  },
  {
    "id": "arXiv:2103.04077",
    "title": "Show Me What You Can Do: Capability Calibration on Reachable Workspace  for Human-Robot Collaboration",
    "abstract": "Comments: 8 pages, 6 figures, IEEE Robotics and Automation Letters (RA-L), 2022",
    "descriptor": "\nComments: 8 pages, 6 figures, IEEE Robotics and Automation Letters (RA-L), 2022\n",
    "authors": [
      "Xiaofeng Gao",
      "Luyao Yuan",
      "Tianmin Shu",
      "Hongjing Lu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.04077"
  },
  {
    "id": "arXiv:2103.05684",
    "title": "Monotonic Alpha-divergence Minimisation for Variational Inference",
    "abstract": "Monotonic Alpha-divergence Minimisation for Variational Inference",
    "descriptor": "",
    "authors": [
      "Kam\u00e9lia Daudel",
      "Randal Douc",
      "Fran\u00e7ois Roueff"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2103.05684"
  },
  {
    "id": "arXiv:2103.14829",
    "title": "Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using  Spatial and Temporal Transformers",
    "abstract": "Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using  Spatial and Temporal Transformers",
    "descriptor": "",
    "authors": [
      "Tianyu Zhu",
      "Markus Hiller",
      "Mahsa Ehsanpour",
      "Rongkai Ma",
      "Tom Drummond",
      "Ian Reid",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14829"
  },
  {
    "id": "arXiv:2103.16608",
    "title": "The nature of synchronisation in power systems: inspirations from  communication systems",
    "abstract": "The nature of synchronisation in power systems: inspirations from  communication systems",
    "descriptor": "",
    "authors": [
      "Yunjie Gu",
      "Yitong Li",
      "Timothy C. Green"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16608"
  },
  {
    "id": "arXiv:2103.17055",
    "title": "A Neighbourhood Framework for Resource-Lean Content Flagging",
    "abstract": "Comments: Accepted to appear in Transactions of the Association for Computational Linguistics (TACL) -- this is a pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to appear in Transactions of the Association for Computational Linguistics (TACL) -- this is a pre-MIT Press publication version\n",
    "authors": [
      "Sheikh Muhammad Sarwar",
      "Dimitrina Zlatkova",
      "Momchil Hardalov",
      "Yoan Dinkov",
      "Isabelle Augenstein",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.17055"
  },
  {
    "id": "arXiv:2104.00735",
    "title": "Graph Attention Networks for Channel Estimation in RIS-assisted  Satellite IoT Communications",
    "abstract": "Comments: 10 pages, 12 figures",
    "descriptor": "\nComments: 10 pages, 12 figures\n",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.00735"
  },
  {
    "id": "arXiv:2104.04070",
    "title": "A Strategy for Advancing Research and Impact in New Computing Paradigms",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Rajkumar Buyya",
      "Sukhpal Singh Gill",
      "Satish Narayana Srirama",
      "Rami Bahsoon",
      "San Murugesan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.04070"
  },
  {
    "id": "arXiv:2104.05522",
    "title": "Neural basis expansion analysis with exogenous variables: Forecasting  electricity prices with NBEATSx",
    "abstract": "Comments: 30 pages, 7 figures, 4 tables",
    "descriptor": "\nComments: 30 pages, 7 figures, 4 tables\n",
    "authors": [
      "Kin G. Olivares",
      "Cristian Challu",
      "Grzegorz Marcjasz",
      "Rafa\u0142 Weron",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05522"
  },
  {
    "id": "arXiv:2104.10446",
    "title": "Lacon-, Shrub- and Parity-Decompositions: Characterizing Transductions  of Bounded Expansion Classes",
    "abstract": "Comments: published in the proceedings of LICS 2021",
    "descriptor": "\nComments: published in the proceedings of LICS 2021\n",
    "authors": [
      "Jan Dreier"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.10446"
  },
  {
    "id": "arXiv:2104.10901",
    "title": "Self-Supervised Learning from Semantically Imprecise Data",
    "abstract": "Comments: 9 pages. Accepted for publication at VISAPP 2022",
    "descriptor": "\nComments: 9 pages. Accepted for publication at VISAPP 2022\n",
    "authors": [
      "Clemens-Alexander Brust",
      "Bj\u00f6rn Barz",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10901"
  },
  {
    "id": "arXiv:2104.13997",
    "title": "MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple  Accelerator Cores",
    "abstract": "MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple  Accelerator Cores",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.13997"
  },
  {
    "id": "arXiv:2105.05231",
    "title": "Soft BIBD and Product Gradient Codes",
    "abstract": "Comments: New results in Section III-A and Section IV, references added. Presented in part at the IEEE International Symposiums on Topics in Coding (ISTC) 2021 and in part at the Information-Theoretic Methods for Rigorous, Responsible, and Reliable Machine Learning (ITR3) Workshop in International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: New results in Section III-A and Section IV, references added. Presented in part at the IEEE International Symposiums on Topics in Coding (ISTC) 2021 and in part at the Information-Theoretic Methods for Rigorous, Responsible, and Reliable Machine Learning (ITR3) Workshop in International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Animesh Sakorikar",
      "Lele Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.05231"
  },
  {
    "id": "arXiv:2105.05949",
    "title": "Categorical composable cryptography",
    "abstract": "Comments: To appear in proceedings of FoSSaCS 2022. This arXiv version has an appendix containing proofs and discussions of asymptotic security & set-up assumptions, but the proceedings version will be published without the appendix",
    "descriptor": "\nComments: To appear in proceedings of FoSSaCS 2022. This arXiv version has an appendix containing proofs and discussions of asymptotic security & set-up assumptions, but the proceedings version will be published without the appendix\n",
    "authors": [
      "Anne Broadbent",
      "Martti Karvonen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.05949"
  },
  {
    "id": "arXiv:2105.07074",
    "title": "Closed-form Characterization of the MGF of AoI in Energy Harvesting  Status Update Systems",
    "abstract": "Comments: To appear in IEEE Transactions on Information Theory",
    "descriptor": "\nComments: To appear in IEEE Transactions on Information Theory\n",
    "authors": [
      "Mohamed A. Abd-Elmagid",
      "Harpreet S. Dhillon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.07074"
  },
  {
    "id": "arXiv:2105.07789",
    "title": "Temporal Prediction and Evaluation of Brassica Growth in the Field using  Conditional Generative Adversarial Networks",
    "abstract": "Comments: 38 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 38 pages, 10 figures, 2 tables\n",
    "authors": [
      "Lukas Drees",
      "Laura Verena Junker-Frohn",
      "Jana Kierdorf",
      "Ribana Roscher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.07789"
  },
  {
    "id": "arXiv:2105.10225",
    "title": "Finding all minimum cost flows and a faster algorithm for the K best  flow problem",
    "abstract": "Finding all minimum cost flows and a faster algorithm for the K best  flow problem",
    "descriptor": "",
    "authors": [
      "David K\u00f6nen",
      "Daniel R. Schmidt",
      "Christiane Spisla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.10225"
  },
  {
    "id": "arXiv:2105.12931",
    "title": "YOLO5Face: Why Reinventing a Face Detector",
    "abstract": "YOLO5Face: Why Reinventing a Face Detector",
    "descriptor": "",
    "authors": [
      "Delong Qi",
      "Weijun Tan",
      "Qi Yao",
      "Jingfeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12931"
  },
  {
    "id": "arXiv:2105.13094",
    "title": "Revisiting Grid-Forming and Grid-Following Inverters: A Duality Theory",
    "abstract": "Revisiting Grid-Forming and Grid-Following Inverters: A Duality Theory",
    "descriptor": "",
    "authors": [
      "Yitong Li",
      "Yunjie Gu",
      "Timothy C. Green"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13094"
  },
  {
    "id": "arXiv:2105.14944",
    "title": "The effectiveness of feature attribution methods and its correlation  with automatic evaluation scores",
    "abstract": "Comments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix",
    "descriptor": "\nComments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix\n",
    "authors": [
      "Giang Nguyen",
      "Daeyoung Kim",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14944"
  },
  {
    "id": "arXiv:2106.01489",
    "title": "Mutual Distillation of Confident Knowledge",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Ziyun Li",
      "Xinshao Wang",
      "Di Hu",
      "Neil M. Robertson",
      "David A. Clifton",
      "Christoph Meinel",
      "Haojin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01489"
  },
  {
    "id": "arXiv:2106.05299",
    "title": "Grover's Algorithm for Question Answering",
    "abstract": "Comments: Accepted for publication at Quantum Information Processing. 16 pages, 9 figures",
    "descriptor": "\nComments: Accepted for publication at Quantum Information Processing. 16 pages, 9 figures\n",
    "authors": [
      "A. D. Correia",
      "M. Moortgat",
      "H. T. C. Stoof"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.05299"
  },
  {
    "id": "arXiv:2106.10069",
    "title": "Point-of-Interest Recommender Systems based on Location-Based Social  Networks: A Survey from an Experimental Perspective",
    "abstract": "Comments: Submitted in Jul 2020 (revised in September 2021, accepted in January 2022, online January 2022)",
    "descriptor": "\nComments: Submitted in Jul 2020 (revised in September 2021, accepted in January 2022, online January 2022)\n",
    "authors": [
      "Pablo S\u00e1nchez",
      "Alejandro Bellog\u00edn"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.10069"
  },
  {
    "id": "arXiv:2106.14969",
    "title": "Hop-Constrained Metric Embeddings and their Applications",
    "abstract": "Hop-Constrained Metric Embeddings and their Applications",
    "descriptor": "",
    "authors": [
      "Arnold Filtser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.14969"
  },
  {
    "id": "arXiv:2106.15577",
    "title": "As easy as APC: overcoming missing data and class imbalance in time  series with self-supervised learning",
    "abstract": "Comments: Accepted to the NeurIPS 2021 Workshop on Self-Supervised Learning: Theory and Practice",
    "descriptor": "\nComments: Accepted to the NeurIPS 2021 Workshop on Self-Supervised Learning: Theory and Practice\n",
    "authors": [
      "Fiorella Wever",
      "T. Anderson Keller",
      "Laura Symul",
      "Victor Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15577"
  },
  {
    "id": "arXiv:2107.03591",
    "title": "Relation-Based Associative Joint Location for Human Pose Estimation in  Videos",
    "abstract": "Relation-Based Associative Joint Location for Human Pose Estimation in  Videos",
    "descriptor": "",
    "authors": [
      "Yonghao Dang",
      "Jianqin Yin",
      "Shaojie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03591"
  },
  {
    "id": "arXiv:2107.03832",
    "title": "Serverless Computing: A Security Perspective",
    "abstract": "Serverless Computing: A Security Perspective",
    "descriptor": "",
    "authors": [
      "Eduard Marin",
      "Diego Perino",
      "Roberto Di Pietro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.03832"
  },
  {
    "id": "arXiv:2107.03916",
    "title": "Balanced Allocations with Incomplete Information: The Power of Two  Queries",
    "abstract": "Comments: Full version of ITCS 2022 paper, 51 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: Full version of ITCS 2022 paper, 51 pages, 8 figures, 2 tables\n",
    "authors": [
      "Dimitrios Los",
      "Thomas Sauerwald"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.03916"
  },
  {
    "id": "arXiv:2107.04184",
    "title": "Greedy structure learning from data that contains systematic missing  values",
    "abstract": "Greedy structure learning from data that contains systematic missing  values",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Anthony C. Constantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04184"
  },
  {
    "id": "arXiv:2107.04537",
    "title": "Modality specific U-Net variants for biomedical image segmentation: A  survey",
    "abstract": "Modality specific U-Net variants for biomedical image segmentation: A  survey",
    "descriptor": "",
    "authors": [
      "Narinder Singh Punn",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04537"
  },
  {
    "id": "arXiv:2107.05419",
    "title": "A New Approach for Active Automata Learning Based on Apartness",
    "abstract": "A New Approach for Active Automata Learning Based on Apartness",
    "descriptor": "",
    "authors": [
      "Frits Vaandrager",
      "Bharat Garhewal",
      "Jurriaan Rot",
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2107.05419"
  },
  {
    "id": "arXiv:2107.07164",
    "title": "The Feedback Capacity of Noisy Output is the STate (NOST) Channels",
    "abstract": "Comments: 33 pages, 7 figures",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Eli Shemuel",
      "Oron Sabag",
      "Haim Permuter"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07164"
  },
  {
    "id": "arXiv:2108.06808",
    "title": "Implicit Regularization of Bregman Proximal Point Algorithm and Mirror  Descent on Separable Data",
    "abstract": "Comments: Additional CIFAR-100 experiments with BPPA added",
    "descriptor": "\nComments: Additional CIFAR-100 experiments with BPPA added\n",
    "authors": [
      "Yan Li",
      "Caleb Ju",
      "Ethan X. Fang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06808"
  },
  {
    "id": "arXiv:2108.09147",
    "title": "Convolutional Neural Network (CNN) vs Vision Transformer (ViT) for  Digital Holography",
    "abstract": "Comments: 6 pages, 11 figures, ICCCR 2022 Conference",
    "descriptor": "\nComments: 6 pages, 11 figures, ICCCR 2022 Conference\n",
    "authors": [
      "St\u00e9phane Cuenat",
      "Rapha\u00ebl Couturier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2108.09147"
  },
  {
    "id": "arXiv:2108.10155",
    "title": "Construction Cost Index Forecasting: A Multi-feature Fusion Approach",
    "abstract": "Construction Cost Index Forecasting: A Multi-feature Fusion Approach",
    "descriptor": "",
    "authors": [
      "Tianxiang Zhan",
      "Yuanpeng He",
      "Fuyuan Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10155"
  },
  {
    "id": "arXiv:2108.11845",
    "title": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "abstract": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11845"
  },
  {
    "id": "arXiv:2108.13161",
    "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot  Learners",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Ningyu Zhang",
      "Luoqiu Li",
      "Xiang Chen",
      "Shumin Deng",
      "Zhen Bi",
      "Chuanqi Tan",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13161"
  },
  {
    "id": "arXiv:2109.01991",
    "title": "Optimal transport weights for causal inference",
    "abstract": "Optimal transport weights for causal inference",
    "descriptor": "",
    "authors": [
      "Eric Dunipace"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01991"
  },
  {
    "id": "arXiv:2109.06668",
    "title": "Exploration in Deep Reinforcement Learning: A Comprehensive Survey",
    "abstract": "Comments: Include more related exploration methods and provide more insights for future research direction",
    "descriptor": "\nComments: Include more related exploration methods and provide more insights for future research direction\n",
    "authors": [
      "Tianpei Yang",
      "Hongyao Tang",
      "Chenjia Bai",
      "Jinyi Liu",
      "Jianye Hao",
      "Zhaopeng Meng",
      "Peng Liu",
      "Zhen Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.06668"
  },
  {
    "id": "arXiv:2109.07461",
    "title": "MPC-Friendly Commitments for Publicly Verifiable Covert Security",
    "abstract": "Comments: Appeared at ACM CCS 2021",
    "descriptor": "\nComments: Appeared at ACM CCS 2021\n",
    "authors": [
      "Nitin Agrawal",
      "James Bell",
      "Adri\u00e0 Gasc\u00f3n",
      "Matt J. Kusner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07461"
  },
  {
    "id": "arXiv:2109.07509",
    "title": "Learning to Aggregate and Refine Noisy Labels for Visual Sentiment  Analysis",
    "abstract": "Learning to Aggregate and Refine Noisy Labels for Visual Sentiment  Analysis",
    "descriptor": "",
    "authors": [
      "Wei Zhu",
      "Zihe Zheng",
      "Haitian Zheng",
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07509"
  },
  {
    "id": "arXiv:2109.08660",
    "title": "Predicting the effects of waning vaccine immunity against COVID-19  through high-resolution agent-based modeling",
    "abstract": "Comments: 56 pages; 15 figures; accepted for publication in Advanced Theory and Simulations",
    "descriptor": "\nComments: 56 pages; 15 figures; accepted for publication in Advanced Theory and Simulations\n",
    "authors": [
      "Agnieszka Truszkowska",
      "Lorenzo Zino",
      "Sachit Butail",
      "Emanuele Caroppo",
      "Zhong-Ping Jiang",
      "Alessandro Rizzo",
      "Maurizio Porfiri"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.08660"
  },
  {
    "id": "arXiv:2110.00434",
    "title": "Towards Protecting Face Embeddings in Mobile Face Verification Scenarios",
    "abstract": "Comments: This (third) version of the paper corresponds to the manuscript accepted for publication in IEEE T-BIOM. Consists of: 18 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: This (third) version of the paper corresponds to the manuscript accepted for publication in IEEE T-BIOM. Consists of: 18 pages, 7 figures, 5 tables\n",
    "authors": [
      "Vedrana Krivoku\u0107a Hahn",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.00434"
  },
  {
    "id": "arXiv:2110.00926",
    "title": "Information-Theoretic Characterization of the Generalization Error for  Iterative Semi-Supervised Learning",
    "abstract": "Comments: 36 pages, 15 figures",
    "descriptor": "\nComments: 36 pages, 15 figures\n",
    "authors": [
      "Haiyun He",
      "Hanshu Yan",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.00926"
  },
  {
    "id": "arXiv:2110.03010",
    "title": "AECMOS: A speech quality assessment metric for echo impairment",
    "abstract": "AECMOS: A speech quality assessment metric for echo impairment",
    "descriptor": "",
    "authors": [
      "Marju Purin",
      "Sten Sootla",
      "Mateja Sponza",
      "Ando Saabas",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03010"
  },
  {
    "id": "arXiv:2110.03072",
    "title": "FOD-A: A Dataset for Foreign Object Debris in Airports",
    "abstract": "Comments: This paper has been accepted for publication by 20th IEEE International Conference on Machine Learning and Applications. The copyright is with the IEEE",
    "descriptor": "\nComments: This paper has been accepted for publication by 20th IEEE International Conference on Machine Learning and Applications. The copyright is with the IEEE\n",
    "authors": [
      "Travis Munyer",
      "Pei-Chi Huang",
      "Chenyu Huang",
      "Xin Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03072"
  },
  {
    "id": "arXiv:2110.04684",
    "title": "Can Audio Captions Be Evaluated with Image Caption Metrics?",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Zelin Zhou",
      "Zhiling Zhang",
      "Xuenan Xu",
      "Zeyu Xie",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04684"
  },
  {
    "id": "arXiv:2110.05036",
    "title": "Multi-View Self-Attention Based Transformer for Speaker Recognition",
    "abstract": "Comments: Paper to appear at ICASSP 2022",
    "descriptor": "\nComments: Paper to appear at ICASSP 2022\n",
    "authors": [
      "Rui Wang",
      "Junyi Ao",
      "Long Zhou",
      "Shujie Liu",
      "Zhihua Wei",
      "Tom Ko",
      "Qing Li",
      "Yu Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05036"
  },
  {
    "id": "arXiv:2110.05044",
    "title": "Biometric Template Protection for Neural-Network-based Face Recognition  Systems: A Survey of Methods and Evaluation Techniques",
    "abstract": "Comments: Main additions to Version 2 include an explanation of BTP versus B-PET, plus 2 new references. Consists of: 28 pages, 2 figures, 9 tables. Submitted to: IEEE TIFS",
    "descriptor": "\nComments: Main additions to Version 2 include an explanation of BTP versus B-PET, plus 2 new references. Consists of: 28 pages, 2 figures, 9 tables. Submitted to: IEEE TIFS\n",
    "authors": [
      "Vedrana Krivoku\u0107a Hahn",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05044"
  },
  {
    "id": "arXiv:2110.06898",
    "title": "Representing Matrices Using Algebraic ZX-calculus",
    "abstract": "Comments: 38 pages, lots of diagrams, added an application section",
    "descriptor": "\nComments: 38 pages, lots of diagrams, added an application section\n",
    "authors": [
      "Quanlong Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06898"
  },
  {
    "id": "arXiv:2110.08122",
    "title": "Effects of Different Optimization Formulations in Evolutionary  Reinforcement Learning on Diverse Behavior Generation",
    "abstract": "Effects of Different Optimization Formulations in Evolutionary  Reinforcement Learning on Diverse Behavior Generation",
    "descriptor": "",
    "authors": [
      "Victor Villin",
      "Naoki Masuyama",
      "Yusuke Nojima"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08122"
  },
  {
    "id": "arXiv:2110.10187",
    "title": "Sky Is Not the Limit: Tighter Rank Bounds for Elevator Automata in  B\u00fcchi Automata Complementation (Technical Report)",
    "abstract": "Comments: An extended version of a paper accepted to TACAS'22",
    "descriptor": "\nComments: An extended version of a paper accepted to TACAS'22\n",
    "authors": [
      "Vojt\u011bch Havlena",
      "Ond\u0159ej Leng\u00e1l",
      "Barbora \u0160mahl\u00edkov\u00e1"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.10187"
  },
  {
    "id": "arXiv:2110.15032",
    "title": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "abstract": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Xinqi Li",
      "Cheng Cheng",
      "Juncheng Liu",
      "Ran Guo",
      "Shenghang Cai",
      "Chi Yao",
      "Fei Yang",
      "Xiaodong Yi",
      "Chuan Wu",
      "Haoran Zhang",
      "Jie Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15032"
  },
  {
    "id": "arXiv:2110.15811",
    "title": "CVAD: A generic medical anomaly detector based on Cascade VAE",
    "abstract": "Comments: 6 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 6 pages, 4 figures, 4 tables\n",
    "authors": [
      "Xiaoyuan Guo",
      "Judy Wawira Gichoya",
      "Saptarshi Purkayastha",
      "Imon Banerjee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15811"
  },
  {
    "id": "arXiv:2111.00909",
    "title": "Multi-Attribute Balanced Sampling for Disentangled GAN Controls",
    "abstract": "Multi-Attribute Balanced Sampling for Disentangled GAN Controls",
    "descriptor": "",
    "authors": [
      "Perla Doubinsky",
      "Nicolas Audebert",
      "Michel Crucianu",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00909"
  },
  {
    "id": "arXiv:2111.01654",
    "title": "Automating Public Announcement Logic with Relativized Common Knowledge  as a Fragment of HOL in LogiKEy",
    "abstract": "Comments: 28 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:2010.00810",
    "descriptor": "\nComments: 28 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:2010.00810\n",
    "authors": [
      "Christoph Benzm\u00fcller",
      "Sebastian Reiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01654"
  },
  {
    "id": "arXiv:2111.03452",
    "title": "Generalized Radiograph Representation Learning via Cross-supervision  between Images and Free-text Radiology Reports",
    "abstract": "Comments: Accepted by Nature Machine Intelligence. The official version is at this https URL Codes are available at this https URL",
    "descriptor": "\nComments: Accepted by Nature Machine Intelligence. The official version is at this https URL Codes are available at this https URL\n",
    "authors": [
      "Hong-Yu Zhou",
      "Xiaoyu Chen",
      "Yinghao Zhang",
      "Ruibang Luo",
      "Liansheng Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03452"
  },
  {
    "id": "arXiv:2111.05535",
    "title": "Optimal Delay-Outage Analysis for Noise-Limited Wireless Networks with  Caching, Computing, and Communications -- Derivations and Proofs",
    "abstract": "Optimal Delay-Outage Analysis for Noise-Limited Wireless Networks with  Caching, Computing, and Communications -- Derivations and Proofs",
    "descriptor": "",
    "authors": [
      "Ming-Chun Lee",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.05535"
  },
  {
    "id": "arXiv:2111.07832",
    "title": "iBOT: Image BERT Pre-Training with Online Tokenizer",
    "abstract": "iBOT: Image BERT Pre-Training with Online Tokenizer",
    "descriptor": "",
    "authors": [
      "Jinghao Zhou",
      "Chen Wei",
      "Huiyu Wang",
      "Wei Shen",
      "Cihang Xie",
      "Alan Yuille",
      "Tao Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07832"
  },
  {
    "id": "arXiv:2111.09451",
    "title": "Efficient deep learning models for land cover image classification",
    "abstract": "Efficient deep learning models for land cover image classification",
    "descriptor": "",
    "authors": [
      "Ioannis Papoutsis",
      "Nikolaos-Ioannis Bountos",
      "Angelos Zavras",
      "Dimitrios Michail",
      "Christos Tryfonopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09451"
  },
  {
    "id": "arXiv:2111.09758",
    "title": "CSI Clustering with Variational Autoencoding",
    "abstract": "Comments: Changed phrasings at some points",
    "descriptor": "\nComments: Changed phrasings at some points\n",
    "authors": [
      "Michael Baur",
      "Michael W\u00fcrth",
      "Michael Koller",
      "Vlad-Costin Andrei",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09758"
  },
  {
    "id": "arXiv:2111.11980",
    "title": "Scalable Learning for Optimal Load Shedding Under Power Grid Emergency  Operations",
    "abstract": "Scalable Learning for Optimal Load Shedding Under Power Grid Emergency  Operations",
    "descriptor": "",
    "authors": [
      "Yuqi Zhou",
      "Jeehyun Park",
      "Hao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.11980"
  },
  {
    "id": "arXiv:2111.12143",
    "title": "Critical Initialization of Wide and Deep Neural Networks through Partial  Jacobians: General Theory and Applications",
    "abstract": "Comments: 43 pages, 9 figures. Added residual connections and MLP-Mixer",
    "descriptor": "\nComments: 43 pages, 9 figures. Added residual connections and MLP-Mixer\n",
    "authors": [
      "Darshil Doshi",
      "Tianyu He",
      "Andrey Gromov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12143"
  },
  {
    "id": "arXiv:2111.13902",
    "title": "A Quantum-like Model for Predicting Human Decisions in the Entangled  Social Systems",
    "abstract": "Comments: This manuscript is accepted to be published by the IEEE Transactions on Cybernetics in 2021. 10.1109/TCYB.2021.3134688",
    "descriptor": "\nComments: This manuscript is accepted to be published by the IEEE Transactions on Cybernetics in 2021. 10.1109/TCYB.2021.3134688\n",
    "authors": [
      "Aghdas. Meghdadi",
      "M. R. Akbarzadeh-T.",
      "Kourosh Javidan"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.13902"
  },
  {
    "id": "arXiv:2111.14259",
    "title": "3D High-Quality Magnetic Resonance Image Restoration in Clinics Using  Deep Learning",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Hao Li",
      "Jianan Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.14259"
  },
  {
    "id": "arXiv:2112.03432",
    "title": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "abstract": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03432"
  },
  {
    "id": "arXiv:2112.04395",
    "title": "On anti-stochastic properties of unlabeled graphs",
    "abstract": "On anti-stochastic properties of unlabeled graphs",
    "descriptor": "",
    "authors": [
      "Sergei Kiselev",
      "Andrey Kupavskii",
      "Oleg Verbitsky",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.04395"
  },
  {
    "id": "arXiv:2112.11909",
    "title": "Few-shot Multi-hop Question Answering over Knowledge Base",
    "abstract": "Few-shot Multi-hop Question Answering over Knowledge Base",
    "descriptor": "",
    "authors": [
      "Meihao Fan",
      "Lei Zhang",
      "Siyao Xiao",
      "Yuru Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.11909"
  },
  {
    "id": "arXiv:2201.01337",
    "title": "ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling",
    "abstract": "Comments: Accepted at PROPOR 2022: 15th International Conference on Computational Processing of Portuguese",
    "descriptor": "\nComments: Accepted at PROPOR 2022: 15th International Conference on Computational Processing of Portuguese\n",
    "authors": [
      "Alexandre Alcoforado",
      "Thomas Palmeira Ferraz",
      "Rodrigo Gerber",
      "Enzo Bustos",
      "Andr\u00e9 Seidel Oliveira",
      "Bruno Miguel Veloso",
      "Fabio Levy Siqueira",
      "Anna Helena Reali Costa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01337"
  },
  {
    "id": "arXiv:2201.02298",
    "title": "Local and Global Convergence of General Burer-Monteiro Tensor  Optimizations",
    "abstract": "Local and Global Convergence of General Burer-Monteiro Tensor  Optimizations",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Qiuwei Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.02298"
  },
  {
    "id": "arXiv:2201.02373",
    "title": "Mirror Learning: A Unifying Framework of Policy Optimisation",
    "abstract": "Mirror Learning: A Unifying Framework of Policy Optimisation",
    "descriptor": "",
    "authors": [
      "Jakub Grudzien Kuba",
      "Christian Schroeder de Witt",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.02373"
  },
  {
    "id": "arXiv:2201.03492",
    "title": "Interpretation and inference for altmetric indicators arising from  sparse data statistics",
    "abstract": "Comments: To appear in the Journal of Informetrics",
    "descriptor": "\nComments: To appear in the Journal of Informetrics\n",
    "authors": [
      "Lawrence Smolinsky",
      "Bernhard Klingenberg",
      "Brian D. Marx"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.03492"
  },
  {
    "id": "arXiv:2201.04416",
    "title": "Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using  Adversarial Learning",
    "abstract": "Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using  Adversarial Learning",
    "descriptor": "",
    "authors": [
      "Sauman Das"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04416"
  },
  {
    "id": "arXiv:2201.04699",
    "title": "The Recurrent Reinforcement Learning Crypto Agent",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2110.04745",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.04745\n",
    "authors": [
      "Gabriel Borrageiro",
      "Nick Firoozye",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2201.04699"
  },
  {
    "id": "arXiv:2201.05072",
    "title": "SparseP: Towards Efficient Sparse Matrix Vector Multiplication on Real  Processing-In-Memory Systems",
    "abstract": "Comments: To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS) 2022 and the ACM SIGMETRICS 2022 conference",
    "descriptor": "\nComments: To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS) 2022 and the ACM SIGMETRICS 2022 conference\n",
    "authors": [
      "Christina Giannoula",
      "Ivan Fernandez",
      "Juan G\u00f3mez-Luna",
      "Nectarios Koziris",
      "Georgios Goumas",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.05072"
  },
  {
    "id": "arXiv:2201.05089",
    "title": "Using Computational Intelligence for solving the Ornstein-Zernike  equation",
    "abstract": "Comments: 100 pages, 20 figures, Completed Master's Thesis",
    "descriptor": "\nComments: 100 pages, 20 figures, Completed Master's Thesis\n",
    "authors": [
      "Edwin Bedolla"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05089"
  },
  {
    "id": "arXiv:2201.07986",
    "title": "Unsupervised Graph Poisoning Attack via Contrastive Loss  Back-propagation",
    "abstract": "Unsupervised Graph Poisoning Attack via Contrastive Loss  Back-propagation",
    "descriptor": "",
    "authors": [
      "Sixiao Zhang",
      "Hongxu Chen",
      "Xiangguo Sun",
      "Yicong Li",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.07986"
  },
  {
    "id": "arXiv:2201.08177",
    "title": "Category-Association Based Similarity Matching for Novel Object  Pick-and-Place Task",
    "abstract": "Comments: Published by the IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Published by the IEEE Robotics and Automation Letters\n",
    "authors": [
      "Hao Chen",
      "Takuya Kiyokawa",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08177"
  },
  {
    "id": "arXiv:2201.08452",
    "title": "npm-filter: Automating the mining of dynamic information from npm  packages",
    "abstract": "Comments: 5 pages; this work is being submitted to the MSR tool track",
    "descriptor": "\nComments: 5 pages; this work is being submitted to the MSR tool track\n",
    "authors": [
      "Ellen Arteca",
      "Alexi Turcotte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08452"
  },
  {
    "id": "arXiv:2201.08543",
    "title": "Deep Learning-Accelerated 3D Carbon Storage Reservoir Pressure  Forecasting Based on Data Assimilation Using Surface Displacement from InSAR",
    "abstract": "Deep Learning-Accelerated 3D Carbon Storage Reservoir Pressure  Forecasting Based on Data Assimilation Using Surface Displacement from InSAR",
    "descriptor": "",
    "authors": [
      "Hewei Tang",
      "Pengcheng Fu",
      "Honggeun Jo",
      "Su Jiang",
      "Christopher S. Sherman",
      "Fran\u00e7ois Hamon",
      "Nicholas A. Azzolina",
      "Joseph P. Morris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08543"
  },
  {
    "id": "arXiv:2201.09149",
    "title": "Multi-Agent Adversarial Attacks for Multi-Channel Communications",
    "abstract": "Multi-Agent Adversarial Attacks for Multi-Channel Communications",
    "descriptor": "",
    "authors": [
      "Juncheng Dong",
      "Suya Wu",
      "Mohammadreza Sultani",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09149"
  },
  {
    "id": "arXiv:2201.09263",
    "title": "Differential Geometry in Neural Implicits",
    "abstract": "Differential Geometry in Neural Implicits",
    "descriptor": "",
    "authors": [
      "Tiago Novello",
      "Vinicius da Silva",
      "Helio Lopes",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Luiz Velho"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09263"
  },
  {
    "id": "arXiv:2201.09332",
    "title": "Investigating Expressiveness of Transformer in Spectral Domain for  Graphs",
    "abstract": "Investigating Expressiveness of Transformer in Spectral Domain for  Graphs",
    "descriptor": "",
    "authors": [
      "Anson Bastos",
      "Abhishek Nadgeri",
      "Kuldeep Singh",
      "Hiroki Kanezashi",
      "Toyotaro Suzumura",
      "Isaiah Onando Mulang'"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09332"
  },
  {
    "id": "arXiv:2201.09457",
    "title": "Homotopic Policy Mirror Descent: Policy Convergence, Implicit  Regularization, and Improved Sample Complexity",
    "abstract": "Homotopic Policy Mirror Descent: Policy Convergence, Implicit  Regularization, and Improved Sample Complexity",
    "descriptor": "",
    "authors": [
      "Yan Li",
      "Tuo Zhao",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.09457"
  },
  {
    "id": "arXiv:2201.09636",
    "title": "Neural Implicit Surfaces in Higher Dimension",
    "abstract": "Neural Implicit Surfaces in Higher Dimension",
    "descriptor": "",
    "authors": [
      "Tiago Novello",
      "Vinicius da Silva",
      "Helio Lopes",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Luiz Velho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.09636"
  },
  {
    "id": "arXiv:2201.09745",
    "title": "Table Pre-training: A Survey on Model Architectures, Pretraining  Objectives, and Downstream Tasks",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Haoyu Dong",
      "Zhoujun Cheng",
      "Xinyi He",
      "Mengyu Zhou",
      "Anda Zhou",
      "Fan Zhou",
      "Ao Liu",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.09745"
  },
  {
    "id": "arXiv:2201.10577",
    "title": "Shared Cache Coded Caching Schemes with known User-to-Cache Association  Profile using Placement Delivery Arrays",
    "abstract": "Comments: Some typos in the previous version fixed. 7 pages, 1 figure",
    "descriptor": "\nComments: Some typos in the previous version fixed. 7 pages, 1 figure\n",
    "authors": [
      "Elizabath Peter",
      "K. K. Krishnan Namboodiri",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.10577"
  },
  {
    "id": "arXiv:2201.10711",
    "title": "Sparsity Regularization For Cold-Start Recommendation",
    "abstract": "Sparsity Regularization For Cold-Start Recommendation",
    "descriptor": "",
    "authors": [
      "Aksheshkumar Ajaykumar Shah",
      "Hemanth Venkateswara"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10711"
  },
  {
    "id": "arXiv:2201.10758",
    "title": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "abstract": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "descriptor": "",
    "authors": [
      "Daniel Beaglehole"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.10758"
  },
  {
    "id": "arXiv:2201.10782",
    "title": "Causality and Correlation Graph Modeling for Effective and Explainable  Session-based Recommendation",
    "abstract": "Comments: submitted to TOIS",
    "descriptor": "\nComments: submitted to TOIS\n",
    "authors": [
      "Cong Geng",
      "Huizi Wu",
      "Hui Fang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.10782"
  },
  {
    "id": "arXiv:2201.10803",
    "title": "Exploiting Semantic Epsilon Greedy Exploration Strategy in Multi-Agent  Reinforcement Learning",
    "abstract": "Exploiting Semantic Epsilon Greedy Exploration Strategy in Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Hon Tik Tse",
      "Ho-fung Leung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.10803"
  },
  {
    "id": "arXiv:2201.10809",
    "title": "A two-step backward compatible fullband speech enhancement system",
    "abstract": "A two-step backward compatible fullband speech enhancement system",
    "descriptor": "",
    "authors": [
      "Xu Zhang",
      "Lianwu Chen",
      "Xiguang Zheng",
      "Xinlei Ren",
      "Chen Zhang",
      "Liang Guo",
      "Bing Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.10809"
  },
  {
    "id": "arXiv:2201.10972",
    "title": "How Robust are Discriminatively Trained Zero-Shot Learning Models?",
    "abstract": "How Robust are Discriminatively Trained Zero-Shot Learning Models?",
    "descriptor": "",
    "authors": [
      "Mehmet Kerim Yucel",
      "Ramazan Gokberk Cinbis",
      "Pinar Duygulu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10972"
  },
  {
    "id": "arXiv:2201.11018",
    "title": "A global sharing mechanism of resources: modeling a crucial step in the  fight against pandemics",
    "abstract": "Comments: 12 pages, 5 figures. (16 pages, 6 figures when including the appendix.)",
    "descriptor": "\nComments: 12 pages, 5 figures. (16 pages, 6 figures when including the appendix.)\n",
    "authors": [
      "G.K. den Nijs",
      "J. Edivaldo",
      "B.D.L. Chatel",
      "J.F. Uleman",
      "M. Olde Rikkert",
      "H. Wertheim",
      "R. Quax"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.11018"
  },
  {
    "id": "arXiv:2201.11080",
    "title": "A Comparative User Study of Human Predictions in Algorithm-Supported  Recidivism Risk Assessment",
    "abstract": "A Comparative User Study of Human Predictions in Algorithm-Supported  Recidivism Risk Assessment",
    "descriptor": "",
    "authors": [
      "Manuel Portela",
      "Carlos Castillo",
      "Song\u00fcl Tolan",
      "Marzieh Karimi-Haghighi",
      "Antonio Andres Pueyo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11080"
  },
  {
    "id": "arXiv:2201.11104",
    "title": "Combining optimal path search with task-dependent learning in a neural  network",
    "abstract": "Combining optimal path search with task-dependent learning in a neural  network",
    "descriptor": "",
    "authors": [
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11104"
  }
]
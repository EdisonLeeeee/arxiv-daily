[
  {
    "id": "arXiv:2209.11229",
    "title": "Decomposition horizons: from graph sparsity to model-theoretic dividing  lines",
    "abstract": "Let $\\mathscr C$ be a hereditary class of graphs. Assume that for every $p$\nthere is a hereditary NIP class $\\mathscr D_p$ with the property that the\nvertex set of every graph $G\\in\\mathscr C$ can be partitioned into $N_p=N_p(G)$\nparts in such a way that the union of any $p$ parts induce a subgraph in\n$\\mathscr D_p$ and $\\log N_p(G)\\in o(\\log |G|)$. We prove that $\\mathscr C$ is\n(monadically) NIP. Similarly, if every $\\mathscr D_p$ is stable, then $\\mathscr\nC$ is (monadically) stable. Results of this type lead to the definition of\ndecomposition horizons as closure operators. We establish some of their basic\nproperties and provide several further examples of decomposition horizons.",
    "descriptor": "",
    "authors": [
      "Samuel Braunfeld",
      "Jaroslav Ne\u0161et\u0159il",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.11229"
  },
  {
    "id": "arXiv:2209.11234",
    "title": "Artificial Intelligence in Material Engineering: A review on  applications of AI in Material Engineering",
    "abstract": "Recently, there has been extensive use of artificial Intelligence (AI) in the\nfield of material engineering. This can be attributed to the development of\nhigh performance computing and thereby feasibility to test deep learning models\nwith large parameters. In this article we tried to review some of the latest\ndevelopments in the applications of AI in material engineering.",
    "descriptor": "\nComments: V1\n",
    "authors": [
      "Lipichanda Goswami",
      "Manoj Deka",
      "Mohendra Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11234"
  },
  {
    "id": "arXiv:2209.11252",
    "title": "XF2T: Cross-lingual Fact-to-Text Generation for Low-Resource Languages",
    "abstract": "Multiple business scenarios require an automated generation of descriptive\nhuman-readable text from structured input data. Hence, fact-to-text generation\nsystems have been developed for various downstream tasks like generating soccer\nreports, weather and financial reports, medical reports, person biographies,\netc. Unfortunately, previous work on fact-to-text (F2T) generation has focused\nprimarily on English mainly due to the high availability of relevant datasets.\nOnly recently, the problem of cross-lingual fact-to-text (XF2T) was proposed\nfor generation across multiple languages alongwith a dataset, XALIGN for eight\nlanguages. However, there has been no rigorous work on the actual XF2T\ngeneration problem. We extend XALIGN dataset with annotated data for four more\nlanguages: Punjabi, Malayalam, Assamese and Oriya. We conduct an extensive\nstudy using popular Transformer-based text generation models on our extended\nmulti-lingual dataset, which we call XALIGNV2. Further, we investigate the\nperformance of different text generation strategies: multiple variations of\npretraining, fact-aware embeddings and structure-aware input encoding. Our\nextensive experiments show that a multi-lingual mT5 model which uses fact-aware\nembeddings with structure-aware input encoding leads to best results on average\nacross the twelve languages. We make our code, dataset and model publicly\navailable, and hope that this will help advance further research in this\ncritical area.",
    "descriptor": "",
    "authors": [
      "Shivprasad Sagare",
      "Tushar Abhishek",
      "Bhavyajeet Singh",
      "Anubhav Sharma",
      "Manish Gupta",
      "Vasudeva Varma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11252"
  },
  {
    "id": "arXiv:2209.11255",
    "title": "3DPCT: 3D Point Cloud Transformer with Dual Self-attention",
    "abstract": "Transformers have resulted in remarkable achievements in the field of image\nprocessing. Inspired by this great success, the application of Transformers to\n3D point cloud processing has drawn more and more attention. This paper\npresents a novel point cloud representational learning network, 3D Point Cloud\nTransformer with Dual Self-attention (3DPCT) and an encoder-decoder structure.\nSpecifically, 3DPCT has a hierarchical encoder, which contains two local-global\ndual-attention modules for the classification task (three modules for the\nsegmentation task), with each module consisting of a Local Feature Aggregation\n(LFA) block and a Global Feature Learning (GFL) block. The GFL block is dual\nself-attention, with both point-wise and channel-wise self-attention to improve\nfeature extraction. Moreover, in LFA, to better leverage the local information\nextracted, a novel point-wise self-attention model, named as Point-Patch\nSelf-Attention (PPSA), is designed. The performance is evaluated on both\nclassification and segmentation datasets, containing both synthetic and\nreal-world data. Extensive experiments demonstrate that the proposed method\nachieved state-of-the-art results on both classification and segmentation\ntasks.",
    "descriptor": "\nComments: 10 pages, 5 figures, 4 tables\n",
    "authors": [
      "Dening Lu",
      "Kyle Gao",
      "Qian Xie",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11255"
  },
  {
    "id": "arXiv:2209.11260",
    "title": "Piercing Diametral Disks Induced by Edges of Maximum Spanning Tree",
    "abstract": "Let $P$ be a set of points in the plane and let $T$ be a maximum-weight\nspanning tree of $P$. For an edge $(p,q)$, let $D_{pq}$ be the diametral disk\ninduced by $(p,q)$, i.e., the disk having the segment $\\overline{pq}$ as its\ndiameter. Let $\\cal{D_T}$ be the set of the diametral disks induced by the\nedges of $T$. In this paper, we show that one point is sufficient to pierce all\nthe disks in $\\cal{D_T}$, thus, the set $\\cal{D_T}$ is Helly. Actually, we show\nthat the center of the smallest enclosing circle of $P$ is contained in all the\ndisks of $\\cal{D_T}$, and thus the piercing point can be computed in linear\ntime.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "A. Karim Abu-Affash",
      "Paz Carmi",
      "Meytal Maman"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2209.11260"
  },
  {
    "id": "arXiv:2209.11266",
    "title": "The Microsoft System for VoxCeleb Speaker Recognition Challenge 2022",
    "abstract": "In this report, we describe our submitted system for track 2 of the VoxCeleb\nSpeaker Recognition Challenge 2022 (VoxSRC-22). We fuse a variety of\ngood-performing models ranging from supervised models to self-supervised\nlearning(SSL) pre-trained models. The supervised models, trained using\nVoxCeleb-2 dev data, consist of ECAPA-TDNN and Res2Net in a very deep\nstructure. The SSL pre-trained models, wav2vec and wavLM, are trained using\nlarge scale unlabeled speech data up to million hours. These models are\ncascaded with ECAPA-TDNN and further fine-tuned in a supervised fashion to\nextract the speaker representations. All 13 models are applied with score\nnormalization and calibration and then fused into the the submitted system. We\nalso explore the audio quality measures in the calibration stage such as\nduration, SNR, T60, and MOS. The best submitted system achieves 0.073 in minDCF\nand 1.436% in EER on the VoxSRC-22 evaluation set.",
    "descriptor": "\nComments: 3 pages, 3 tables, VoxSRC2022\n",
    "authors": [
      "Gang Liu",
      "Tianyan Zhou",
      "Yong Zhao",
      "Yu Wu",
      "Zhuo Chen",
      "Yao Qian",
      "Jian Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.11266"
  },
  {
    "id": "arXiv:2209.11268",
    "title": "Recurrence-free Survival Prediction under the Guidance of Automatic  Gross Tumor Volume Segmentation for Head and Neck Cancers",
    "abstract": "For Head and Neck Cancers (HNC) patient management, automatic gross tumor\nvolume (GTV) segmentation and accurate pre-treatment cancer recurrence\nprediction are of great importance to assist physicians in designing\npersonalized management plans, which have the potential to improve the\ntreatment outcome and quality of life for HNC patients. In this paper, we\ndeveloped an automated primary tumor (GTVp) and lymph nodes (GTVn) segmentation\nmethod based on combined pre-treatment positron emission tomography/computed\ntomography (PET/CT) scans of HNC patients. We extracted radiomics features from\nthe segmented tumor volume and constructed a multi-modality tumor\nrecurrence-free survival (RFS) prediction model, which fused the prediction\nresults from separate CT radiomics, PET radiomics, and clinical models. We\nperformed 5-fold cross-validation to train and evaluate our methods on the\nMICCAI 2022 HEad and neCK TumOR segmentation and outcome prediction challenge\n(HECKTOR) dataset. The ensemble prediction results on the testing cohort\nachieved Dice scores of 0.77 and 0.73 for GTVp and GTVn segmentation,\nrespectively, and a C-index value of 0.67 for RFS prediction. The code is\npublicly available (https://github.com/wangkaiwan/HECKTOR-2022-AIRT). Our\nteam's name is AIRT.",
    "descriptor": "\nComments: MICCAI 2022, HECKTOR Challenge Submission\n",
    "authors": [
      "Kai Wang",
      "Yunxiang Li",
      "Michael Dohopolski",
      "Tao Peng",
      "Weiguo Lu",
      "You Zhang",
      "Jing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11268"
  },
  {
    "id": "arXiv:2209.11272",
    "title": "Optimization of FPGA-based CNN Accelerators Using Metaheuristics",
    "abstract": "In recent years, convolutional neural networks (CNNs) have demonstrated their\nability to solve problems in many fields and with accuracy that was not\npossible before. However, this comes with extensive computational requirements,\nwhich made general CPUs unable to deliver the desired real-time performance. At\nthe same time, FPGAs have seen a surge in interest for accelerating CNN\ninference. This is due to their ability to create custom designs with different\nlevels of parallelism. Furthermore, FPGAs provide better performance per watt\ncompared to GPUs. The current trend in FPGA-based CNN accelerators is to\nimplement multiple convolutional layer processors (CLPs), each of which is\ntailored for a subset of layers. However, the growing complexity of CNN\narchitectures makes optimizing the resources available on the target FPGA\ndevice to deliver optimal performance more challenging. In this paper, we\npresent a CNN accelerator and an accompanying automated design methodology that\nemploys metaheuristics for partitioning available FPGA resources to design a\nMulti-CLP accelerator. Specifically, the proposed design tool adopts simulated\nannealing (SA) and tabu search (TS) algorithms to find the number of CLPs\nrequired and their respective configurations to achieve optimal performance on\na given target FPGA device. Here, the focus is on the key specifications and\nhardware resources, including digital signal processors, block RAMs, and\noff-chip memory bandwidth. Experimental results and comparisons using four\nwell-known benchmark CNNs are presented demonstrating that the proposed\nacceleration framework is both encouraging and promising. The SA-/TS-based\nMulti-CLP achieves 1.31x - 2.37x higher throughput than the state-of-the-art\nSingle-/Multi-CLP approaches in accelerating AlexNet, SqueezeNet 1.1, VGGNet,\nand GoogLeNet architectures on the Xilinx VC707 and VC709 FPGA boards.",
    "descriptor": "\nComments: 23 pages, 7 figures, 9 tables. in The Journal of Supercomputing, 2022\n",
    "authors": [
      "Sadiq M. Sait",
      "Aiman El-Maleh",
      "Mohammad Altakrouri",
      "Ahmad Shawahna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2209.11272"
  },
  {
    "id": "arXiv:2209.11274",
    "title": "Trusted IP solution in multi-tenant cloud FPGA platform",
    "abstract": "Because FPGAs outperform traditional processing cores like CPUs and GPUs in\nterms of performance per watt and flexibility, they are being used more and\nmore in cloud and data center applications. There are growing worries about the\nsecurity risks posed by multi-tenant sharing as the demand for hardware\nacceleration increases and gradually gives way to FPGA multi-tenancy in the\ncloud. The confidentiality, integrity, and availability of FPGA-accelerated\napplications may be compromised if space-shared FPGAs are made available to\nmany cloud tenants. We propose a root of trust-based trusted execution\nmechanism called \\textbf{TrustToken} to prevent harmful software-level\nattackers from getting unauthorized access and jeopardizing security. With safe\nkey creation and truly random sources, \\textbf{TrustToken} creates a security\nblock that serves as the foundation of trust-based IP security. By offering\ncrucial security characteristics, such as secure, isolated execution and\ntrusted user interaction, \\textbf{TrustToken} only permits trustworthy\nconnection between the non-trusted third-party IP and the rest of the SoC\nenvironment. The suggested approach does this by connecting the third-party IP\ninterface to the \\textbf{TrustToken} Controller and running run-time checks on\nthe correctness of the IP authorization(Token) signals. With an emphasis on\nsoftware-based assaults targeting unauthorized access and information leakage,\nwe offer a noble hardware/software architecture for trusted execution in\nFPGA-accelerated clouds and data centers.",
    "descriptor": "",
    "authors": [
      "Muhammed Kawser Ahmed",
      "Sujan Kumar Saha",
      "Christophe Bobda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11274"
  },
  {
    "id": "arXiv:2209.11275",
    "title": "Minimizing Human Assistance: Augmenting a Single Demonstration for Deep  Reinforcement Learning",
    "abstract": "The use of human demonstrations in reinforcement learning has proven to\nsignificantly improve agent performance. However, any requirement for a human\nto manually 'teach' the model is somewhat antithetical to the goals of\nreinforcement learning. This paper attempts to minimize human involvement in\nthe learning process while still retaining the performance advantages by using\na single human example collected through a simple-to-use virtual reality\nsimulation to assist with RL training. Our method augments a single\ndemonstration to generate numerous human-like demonstrations that, when\ncombined with Deep Deterministic Policy Gradients and Hindsight Experience\nReplay (DDPG + HER), significantly improve training time on simple tasks and\nallows the agent to solve a complex task (block stacking) that DDPG + HER alone\ncannot solve. The model achieves this significant training advantage using a\nsingle human example, requiring less than a minute of human input.",
    "descriptor": "\nComments: 7 pages, 11 figures\n",
    "authors": [
      "Abraham George",
      "Alison Bartsch",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11275"
  },
  {
    "id": "arXiv:2209.11276",
    "title": "Capsule Network based Contrastive Learning of Unsupervised Visual  Representations",
    "abstract": "Capsule Networks have shown tremendous advancement in the past decade,\noutperforming the traditional CNNs in various task due to it's equivariant\nproperties. With the use of vector I/O which provides information of both\nmagnitude and direction of an object or it's part, there lies an enormous\npossibility of using Capsule Networks in unsupervised learning environment for\nvisual representation tasks such as multi class image classification. In this\npaper, we propose Contrastive Capsule (CoCa) Model which is a Siamese style\nCapsule Network using Contrastive loss with our novel architecture, training\nand testing algorithm. We evaluate the model on unsupervised image\nclassification CIFAR-10 dataset and achieve a top-1 test accuracy of 70.50% and\ntop-5 test accuracy of 98.10%. Due to our efficient architecture our model has\n31 times less parameters and 71 times less FLOPs than the current SOTA in both\nsupervised and unsupervised learning.",
    "descriptor": "",
    "authors": [
      "Harsh Panwar",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11276"
  },
  {
    "id": "arXiv:2209.11277",
    "title": "FusionVAE: A Deep Hierarchical Variational Autoencoder for RGB Image  Fusion",
    "abstract": "Sensor fusion can significantly improve the performance of many computer\nvision tasks. However, traditional fusion approaches are either not data-driven\nand cannot exploit prior knowledge nor find regularities in a given dataset or\nthey are restricted to a single application. We overcome this shortcoming by\npresenting a novel deep hierarchical variational autoencoder called FusionVAE\nthat can serve as a basis for many fusion tasks. Our approach is able to\ngenerate diverse image samples that are conditioned on multiple noisy,\noccluded, or only partially visible input images. We derive and optimize a\nvariational lower bound for the conditional log-likelihood of FusionVAE. In\norder to assess the fusion capabilities of our model thoroughly, we created\nthree novel datasets for image fusion based on popular computer vision\ndatasets. In our experiments, we show that FusionVAE learns a representation of\naggregated information that is relevant to fusion tasks. The results\ndemonstrate that our approach outperforms traditional methods significantly.\nFurthermore, we present the advantages and disadvantages of different design\nchoices.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Fabian Duffhauss",
      "Ngo Anh Vien",
      "Hanna Ziesche",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11277"
  },
  {
    "id": "arXiv:2209.11279",
    "title": "Environment Optimization for Multi-Agent Navigation",
    "abstract": "Traditional approaches to the design of multi-agent navigation algorithms\nconsider the environment as a fixed constraint, despite the obvious influence\nof spatial constraints on agents' performance. Yet hand-designing improved\nenvironment layouts and structures is inefficient and potentially expensive.\nThe goal of this paper is to consider the environment as a decision variable in\na system-level optimization problem, where both agent performance and\nenvironment cost can be accounted for. We begin by proposing a novel\nenvironment optimization problem. We show, through formal proofs, under which\nconditions the environment can change while guaranteeing completeness (i.e.,\nall agents reach their navigation goals). Our solution leverages a model-free\nreinforcement learning approach. In order to accommodate a broad range of\nimplementation scenarios, we include both online and offline optimization, and\nboth discrete and continuous environment representations. Numerical results\ncorroborate our theoretical findings and validate our approach.",
    "descriptor": "",
    "authors": [
      "Zhan Gao",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.11279"
  },
  {
    "id": "arXiv:2209.11280",
    "title": "Scalable Gaussian Process Hyperparameter Optimization via Coverage  Regularization",
    "abstract": "Gaussian processes (GPs) are Bayesian non-parametric models popular in a\nvariety of applications due to their accuracy and native uncertainty\nquantification (UQ). Tuning GP hyperparameters is critical to ensure the\nvalidity of prediction accuracy and uncertainty; uniquely estimating multiple\nhyperparameters in, e.g. the Matern kernel can also be a significant challenge.\nMoreover, training GPs on large-scale datasets is a highly active area of\nresearch: traditional maximum likelihood hyperparameter training requires\nquadratic memory to form the covariance matrix and has cubic training\ncomplexity. To address the scalable hyperparameter tuning problem, we present a\nnovel algorithm which estimates the smoothness and length-scale parameters in\nthe Matern kernel in order to improve robustness of the resulting prediction\nuncertainties. Using novel loss functions similar to those in conformal\nprediction algorithms in the computational framework provided by the\nhyperparameter estimation algorithm MuyGPs, we achieve improved UQ over\nleave-one-out likelihood maximization while maintaining a high degree of\nscalability as demonstrated in numerical experiments.",
    "descriptor": "\nComments: 4 pages content, 3 figures, 6 tables\n",
    "authors": [
      "Killian Wood",
      "Alec M. Dunton",
      "Amanda Muyskens",
      "Benjamin W. Priest"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11280"
  },
  {
    "id": "arXiv:2209.11284",
    "title": "The Impact of Social Media in Learning and Teaching: A  Bibliometric-based Citation Analysis",
    "abstract": "This paper presents the results of a systematic review of the literature on\nthe impact of social media in learning and teaching through bibliometric based\nCitation analysis. The objective of the review was to map the evolution of the\ncurrent literature and identify the leading sources of knowledge in terms of\nthe most influential journals, authors, and articles. From a total of 50 top\nmost relevant articles selected from the Scopus database, a detailed citation\nanalysis was conducted. The study explored the overall theoretical foundation\nof social media research involving in learning and studying and identified the\nleading sources of knowledge in terms of and papers and revealed research\ntrends over the last four years by citation analysis. The analysis of citation\ndata showed that International Journal of Management Education is the leading\njournal in social media in learning and teaching research. Author Abdullah Z\nwas found to be the leading author in this field in terms of a total number of\npublications, total citations, and h index, while the most cited article was\nauthored by Baaran S. and by Bapitha L. The contribution of this study is to\nclearly outline the current state of knowledge regarding social media in\nlearning and teaching services in the literature.",
    "descriptor": "\nComments: 14 Pages\n",
    "authors": [
      "Abdul Shaikh",
      "Saqib Ali",
      "Ramla Al-Maamari"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.11284"
  },
  {
    "id": "arXiv:2209.11287",
    "title": "Computing Double Precision Euclidean Distances using GPU Tensor Cores",
    "abstract": "Tensor cores (TCs) are a type of Application-Specific Integrated Circuit\n(ASIC) and are a recent addition to Graphics Processing Unit (GPU)\narchitectures. As such, TCs are purposefully designed to greatly improve the\nperformance of Matrix Multiply-Accumulate (MMA) operations. While TCs are\nheavily studied for machine learning and closely related fields, where their\nhigh efficiency is undeniable, MMA operations are not unique to these fields.\nMore generally, any computation that can be expressed as MMA operations can\nleverage TCs, and potentially benefit from their higher computational\nthroughput compared to other general-purpose cores, such as CUDA cores on\nNvidia GPUs. In this paper, we propose the first double precision (FP64)\nEuclidean distance calculation algorithm, which is expressed as MMA operations\nto leverage TCs on Nvidia GPUs, rather than the more commonly used CUDA cores.\nTo show that the Euclidean distance can be accelerated in a real-world\napplication, we evaluate our proposed TC algorithm on the distance similarity\nself-join problem, as the most computationally intensive part of the algorithm\nconsists of computing distances in a multi-dimensional space. We find that the\nperformance gain from using the tensor core algorithm over the CUDA core\nalgorithm depends weakly on the dataset size and distribution, but is strongly\ndependent on data dimensionality. Overall, TCs are a compelling alternative to\nCUDA cores, particularly when the data dimensionality is low ($\\leq{4}$), as we\nachieve an average speedup of $1.28\\times$ and up to $2.23\\times$ against a\nstate-of-the-art GPU distance similarity self-join algorithm. Furthermore,\nbecause this paper is among the first to explore the use of TCs for FP64\ngeneral-purpose computation, future research is promising.",
    "descriptor": "\nComments: Accepted for publication\n",
    "authors": [
      "Benoit Gallet",
      "Michael Gowanlock"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.11287"
  },
  {
    "id": "arXiv:2209.11293",
    "title": "A Framework for Single-Item NFT Auction Mechanism Design",
    "abstract": "Lately, Non-Fungible Tokens (NFTs), i.e., uniquely discernible assets on a\nblockchain, have skyrocketed in popularity by addressing a broad audience.\nHowever, the typical NFT auctioning procedures are conducted in various, ad hoc\nways, while mostly ignoring the context that the blockchain provides. One of\nthe main targets of this work is to shed light on the vastly unexplored design\nspace of NFT Auction Mechanisms, especially in those characteristics that\nfundamentally differ from traditional and more contemporaneous forms of\nauctions. We focus on the case that bidders have a valuation for the auctioned\nNFT, i.e., what we term the single-item NFT auction case. In this setting, we\nformally define an NFT Auction Mechanism, give the properties that we would\nideally like a perfect mechanism to satisfy (broadly known as incentive\ncompatibility and collusion resistance) and prove that it is impossible to have\nsuch a perfect mechanism. Even though we cannot have an all-powerful protocol\nlike that, we move on to consider relaxed notions of those properties that we\nmay desire the protocol to satisfy, as a trade-off between implementability and\neconomic guarantees. Specifically, we define the notion of an\nequilibrium-truthful auction, where neither the seller nor the bidders can\nimprove their utility by acting non-truthfully, so long as the counter-party\nacts truthfully. We also define asymptotically second-price auctions, in which\nthe seller does not lose asymptotically any revenue in comparison to the\ntheoretically-optimal (static) second-price sealed-bid auction, in the case\nthat the bidders' valuations are drawn independently from some distribution. We\nshowcase why these two are very desirable properties for an auction mechanism\nto enjoy, and construct the first known NFT Auction Mechanism which provably\npossesses such formal guarantees.",
    "descriptor": "\nComments: To appear in ACM DeFi 2022. 17 pages\n",
    "authors": [
      "Jason Milionis",
      "Dean Hirsch",
      "Andy Arditi",
      "Pranav Garimidi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2209.11293"
  },
  {
    "id": "arXiv:2209.11294",
    "title": "T2FPV: Constructing High-Fidelity First-Person View Datasets From  Real-World Pedestrian Trajectories",
    "abstract": "Predicting pedestrian motion is essential for developing socially-aware\nrobots that interact in a crowded environment. While the natural visual\nperspective for a social interaction setting is an egocentric view, the\nmajority of existing work in trajectory prediction has been investigated purely\nin the top-down trajectory space. To support first-person view trajectory\nprediction research, we present T2FPV, a method for constructing high-fidelity\nfirst-person view datasets given a real-world, top-down trajectory dataset; we\nshowcase our approach on the ETH/UCY pedestrian dataset to generate the\negocentric visual data of all interacting pedestrians. We report that the\nbird's-eye view assumption used in the original ETH/UCY dataset, i.e., an agent\ncan observe everyone in the scene with perfect information, does not hold in\nthe first-person views; only a fraction of agents are fully visible during each\n20-timestep scene used commonly in existing work. We evaluate existing\ntrajectory prediction approaches under varying levels of realistic perception\n-- displacement errors suffer a 356% increase compared to the top-down, perfect\ninformation setting. To promote research in first-person view trajectory\nprediction, we release our T2FPV-ETH dataset and software tools.",
    "descriptor": "",
    "authors": [
      "Benjamin Stoler",
      "Meghdeep Jana",
      "Soonmin Hwang",
      "Jean Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11294"
  },
  {
    "id": "arXiv:2209.11295",
    "title": "Outage Probability Analysis of Mixed RF-FSO System Influenced by  Fisher-Snedecor Fading and Gamma-Gamma Atmospheric Turbulence",
    "abstract": "In this paper, we investigate a dual-hop relaying system, composed of radio\nfrequency (RF) and free-space optical (FSO) link. Decode-and-forward (DF) relay\nis employed to integrate the first RF link and the second line-of-sight FSO\nlinks. The RF channel is assumed to be subject to recently proposed\nFisher-Snedecor fading model, which was shown to be convenient for modeling in\nrealistic wireless communication scenarios. The FSO channel is affected by\nGamma-Gamma distributed atmospheric turbulence. Expression for the outage\nprobability is derived and utilized to present numerical results. Based on\npresented results, the effects of various RF and FSO channels parameters on the\noverall system performance are examined and discussed.",
    "descriptor": "\nComments: Presented at 2018 26th Telecommunications Forum (TELFOR)\n",
    "authors": [
      "Milica I. Petkovic",
      "Predrag N. Ivanis",
      "Goran T. Djordjevic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11295"
  },
  {
    "id": "arXiv:2209.11299",
    "title": "Deep Domain Adaptation for Detecting Bomb Craters in Aerial Images",
    "abstract": "The aftermath of air raids can still be seen for decades after the\ndevastating events. Unexploded ordnance (UXO) is an immense danger to human\nlife and the environment. Through the assessment of wartime images, experts can\ninfer the occurrence of a dud. The current manual analysis process is expensive\nand time-consuming, thus automated detection of bomb craters by using deep\nlearning is a promising way to improve the UXO disposal process. However, these\nmethods require a large amount of manually labeled training data. This work\nleverages domain adaptation with moon surface images to address the problem of\nautomated bomb crater detection with deep learning under the constraint of\nlimited training data. This paper contributes to both academia and practice (1)\nby providing a solution approach for automated bomb crater detection with\nlimited training data and (2) by demonstrating the usability and associated\nchallenges of using synthetic images for domain adaptation.",
    "descriptor": "\nComments: 56th Annual Hawaii International Conference on System Sciences (HICSS-56)\n",
    "authors": [
      "Marco Geiger",
      "Dominik Martin",
      "Niklas K\u00fchl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11299"
  },
  {
    "id": "arXiv:2209.11302",
    "title": "ProgPrompt: Generating Situated Robot Task Plans using Large Language  Models",
    "abstract": "Task planning can require defining myriad domain knowledge about the world in\nwhich a robot needs to act. To ameliorate that effort, large language models\n(LLMs) can be used to score potential next actions during task planning, and\neven generate action sequences directly, given an instruction in natural\nlanguage with no additional domain information. However, such methods either\nrequire enumerating all possible next steps for scoring, or generate free-form\ntext that may contain actions not possible on a given robot in its current\ncontext. We present a programmatic LLM prompt structure that enables plan\ngeneration functional across situated environments, robot capabilities, and\ntasks. Our key insight is to prompt the LLM with program-like specifications of\nthe available actions and objects in an environment, as well as with example\nprograms that can be executed. We make concrete recommendations about prompt\nstructure and generation constraints through ablation experiments, demonstrate\nstate of the art success rates in VirtualHome household tasks, and deploy our\nmethod on a physical robot arm for tabletop tasks. Website at\nprogprompt.github.io",
    "descriptor": "",
    "authors": [
      "Ishika Singh",
      "Valts Blukis",
      "Arsalan Mousavian",
      "Ankit Goyal",
      "Danfei Xu",
      "Jonathan Tremblay",
      "Dieter Fox",
      "Jesse Thomason",
      "Animesh Garg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11302"
  },
  {
    "id": "arXiv:2209.11303",
    "title": "An Investigation of the Bias-Variance Tradeoff in Meta-Gradients",
    "abstract": "Meta-gradients provide a general approach for optimizing the meta-parameters\nof reinforcement learning (RL) algorithms. Estimation of meta-gradients is\ncentral to the performance of these meta-algorithms, and has been studied in\nthe setting of MAML-style short-horizon meta-RL problems. In this context,\nprior work has investigated the estimation of the Hessian of the RL objective,\nas well as tackling the problem of credit assignment to pre-adaptation behavior\nby making a sampling correction. However, we show that Hessian estimation,\nimplemented for example by DiCE and its variants, always adds bias and can also\nadd variance to meta-gradient estimation. Meanwhile, meta-gradient estimation\nhas been studied less in the important long-horizon setting, where\nbackpropagation through the full inner optimization trajectories is not\nfeasible. We study the bias and variance tradeoff arising from truncated\nbackpropagation and sampling correction, and additionally compare to evolution\nstrategies, which is a recently popular alternative strategy to long-horizon\nmeta-learning. While prior work implicitly chooses points in this bias-variance\nspace, we disentangle the sources of bias and variance and present an empirical\nstudy that relates existing estimators to each other.",
    "descriptor": "",
    "authors": [
      "Risto Vuorio",
      "Jacob Beck",
      "Shimon Whiteson",
      "Jakob Foerster",
      "Gregory Farquhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11303"
  },
  {
    "id": "arXiv:2209.11304",
    "title": "Colonoscopy Landmark Detection using Vision Transformers",
    "abstract": "Colonoscopy is a routine outpatient procedure used to examine the colon and\nrectum for any abnormalities including polyps, diverticula and narrowing of\ncolon structures. A significant amount of the clinician's time is spent in\npost-processing snapshots taken during the colonoscopy procedure, for\nmaintaining medical records or further investigation. Automating this step can\nsave time and improve the efficiency of the process. In our work, we have\ncollected a dataset of 120 colonoscopy videos and 2416 snapshots taken during\nthe procedure, that have been annotated by experts. Further, we have developed\na novel, vision-transformer based landmark detection algorithm that identifies\nkey anatomical landmarks (the appendiceal orifice, ileocecal valve/cecum\nlandmark and rectum retroflexion) from snapshots taken during colonoscopy. Our\nalgorithm uses an adaptive gamma correction during preprocessing to maintain a\nconsistent brightness for all images. We then use a vision transformer as the\nfeature extraction backbone and a fully connected network based classifier head\nto categorize a given frame into four classes: the three landmarks or a\nnon-landmark frame. We compare the vision transformer (ViT-B/16) backbone with\nResNet-101 and ConvNext-B backbones that have been trained similarly. We report\nan accuracy of 82% with the vision transformer backbone on a test dataset of\nsnapshots.",
    "descriptor": "",
    "authors": [
      "Aniruddha Tamhane",
      "Tse'ela Mida",
      "Erez Posner",
      "Moshe Bouhnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11304"
  },
  {
    "id": "arXiv:2209.11306",
    "title": "StyleTime: Style Transfer for Synthetic Time Series Generation",
    "abstract": "Neural style transfer is a powerful computer vision technique that can\nincorporate the artistic \"style\" of one image to the \"content\" of another. The\nunderlying theory behind the approach relies on the assumption that the style\nof an image is represented by the Gram matrix of its features, which is\ntypically extracted from pre-trained convolutional neural networks (e.g.,\nVGG-19). This idea does not straightforwardly extend to time series stylization\nsince notions of style for two-dimensional images are not analogous to notions\nof style for one-dimensional time series. In this work, a novel formulation of\ntime series style transfer is proposed for the purpose of synthetic data\ngeneration and enhancement. We introduce the concept of stylized features for\ntime series, which is directly related to the time series realism properties,\nand propose a novel stylization algorithm, called StyleTime, that uses explicit\nfeature extraction techniques to combine the underlying content (trend) of one\ntime series with the style (distributional properties) of another. Further, we\ndiscuss evaluation metrics, and compare our work to existing state-of-the-art\ntime series generation and augmentation schemes. To validate the effectiveness\nof our methods, we use stylized synthetic data as a means for data augmentation\nto improve the performance of recurrent neural network models on several\nforecasting tasks.",
    "descriptor": "",
    "authors": [
      "Yousef El-Laham",
      "Svitlana Vyetrenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11306"
  },
  {
    "id": "arXiv:2209.11311",
    "title": "Spatial model personalization in Gboard",
    "abstract": "We introduce a framework for adapting a virtual keyboard to individual user\nbehavior by modifying a Gaussian spatial model to use personalized key center\noffset means and, optionally, learned covariances. Through numerous real-world\nstudies, we determine the importance of training data quantity and weights, as\nwell as the number of clusters into which to group keys to avoid overfitting.\nWhile past research has shown potential of this technique using\nartificially-simple virtual keyboards and games or fixed typing prompts, we\ndemonstrate effectiveness using the highly-tuned Gboard app with a\nrepresentative set of users and their real typing behaviors. Across a variety\nof top languages, we achieve small-but-significant improvements in both typing\nspeed and decoder accuracy.",
    "descriptor": "\nComments: 17 pages, to be published in the Proceedings of the 24th International Conference on Mobile Human-Computer Interaction (MobileHCI 2022)\n",
    "authors": [
      "Gary Sivek",
      "Michael Riley"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11311"
  },
  {
    "id": "arXiv:2209.11312",
    "title": "Deep Learning for Multi-User Proactive Beam Handoff: A 6G Application",
    "abstract": "This paper demonstrates the use of deep learning and time series data\ngenerated from user equipment (UE) beam measurements and positions collected by\nthe base station (BS) to enable handoffs between beams that belong to the same\nor different BSs. We propose the use of long short-term memory (LSTM) recurrent\nneural networks with three different approaches and vary the number of number\nof lookbacks of the beam measurements to study the prediction accuracy.\nSimulations show that at a sufficiently large number of lookbacks, the UE\npositions become irrelevant to the prediction accuracy since the LSTMs are able\nto learn the optimal beam based on implicitly defined positions from the\ntime-defined trajectories.",
    "descriptor": "\nComments: 22 pages, 9 figures. Submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Faris B. Mismar",
      "Alperen Gundogan",
      "Aliye Ozge Kaya",
      "Oleg Chistyakov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.11312"
  },
  {
    "id": "arXiv:2209.11316",
    "title": "FuTH-Net: Fusing Temporal Relations and Holistic Features for Aerial  Video Classification",
    "abstract": "Unmanned aerial vehicles (UAVs) are now widely applied to data acquisition\ndue to its low cost and fast mobility. With the increasing volume of aerial\nvideos, the demand for automatically parsing these videos is surging. To\nachieve this, current researches mainly focus on extracting a holistic feature\nwith convolutions along both spatial and temporal dimensions. However, these\nmethods are limited by small temporal receptive fields and cannot adequately\ncapture long-term temporal dependencies which are important for describing\ncomplicated dynamics. In this paper, we propose a novel deep neural network,\ntermed FuTH-Net, to model not only holistic features, but also temporal\nrelations for aerial video classification. Furthermore, the holistic features\nare refined by the multi-scale temporal relations in a novel fusion module for\nyielding more discriminative video representations. More specially, FuTH-Net\nemploys a two-pathway architecture: (1) a holistic representation pathway to\nlearn a general feature of both frame appearances and shortterm temporal\nvariations and (2) a temporal relation pathway to capture multi-scale temporal\nrelations across arbitrary frames, providing long-term temporal dependencies.\nAfterwards, a novel fusion module is proposed to spatiotemporal integrate the\ntwo features learned from the two pathways. Our model is evaluated on two\naerial video classification datasets, ERA and Drone-Action, and achieves the\nstate-of-the-art results. This demonstrates its effectiveness and good\ngeneralization capacity across different recognition tasks (event\nclassification and human action recognition). To facilitate further research,\nwe release the code at https://gitlab.lrz.de/ai4eo/reasoning/futh-net.",
    "descriptor": "",
    "authors": [
      "Pu Jin",
      "Lichao Mou",
      "Yuansheng Hua",
      "Gui-Song Xia",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11316"
  },
  {
    "id": "arXiv:2209.11318",
    "title": "OpenPneu: Compact platform for pneumatic actuation with multi-channels",
    "abstract": "This paper presents a compact system, OpenPneu, to support the pneumatic\nactuation for multi-chambers on soft robots. Micro-pumps are employed in the\nsystem to generate airflow and therefore no extra input as compressed air is\nneeded. Our system conducts modular design to provide good scalability, which\nhas been demonstrated on a prototype with ten air channels. Each air channel of\nOpenPneu is equipped with both the inflation and the deflation functions to\nprovide a full range pressure supply from positive to negative with a maximal\nflow rate at 1.7 L/min. High precision closed-loop control of pressures has\nbeen built into our system to achieve stable and efficient dynamic performance\nin actuation. An open-source control interface and API in Python are provided.\nWe also demonstrate the functionality of OpenPneu on three soft robotic systems\nwith up to 10 chambers.",
    "descriptor": "",
    "authors": [
      "Yingjun Tian",
      "Renbo Su",
      "Xilong Wang",
      "Nur Banu Altin",
      "Guoxin Fang",
      "Charlie C. L. Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11318"
  },
  {
    "id": "arXiv:2209.11320",
    "title": "Blockchain-Oriented Services Computing in Action: Insights from a User  Study",
    "abstract": "Blockchain architectures promise disruptive innovation but factually they\npose many architectural restrictions to classical service-based applications\nand show considerable design, implementation, and operations overhead.\nFurthermore, the relation between such overheads and user benefits is not clear\nyet. To shed light on the aforementioned relations, a service-based blockchain\narchitecture was designed and deployed as part of a field study in real-life\nexperimentation. An observational approach was then performed to elaborate on\nthe technology-acceptance of the service-based blockchain architecture in\nquestion. Evidence shows that the resulting architecture is, in principle, not\ndifferent than other less complex equivalents; furthermore, the architectural\nlimitations posed by the blockchain-oriented design demand a significant\nadditional effort to be put onto even the simplest of functionalities. We\nconclude that further research shall be invested in clarifying further the\ndesign principles we learned as part of this study as well as any trade-offs\nposed by blockchain-oriented service design and operation.",
    "descriptor": "",
    "authors": [
      "Giovanni Quattrocchi",
      "Damian Andrew Tamburri",
      "WIllem-Jan Van Den Heuvel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.11320"
  },
  {
    "id": "arXiv:2209.11321",
    "title": "Sensing Aided OTFS Channel Estimation for Massive MIMO Systems",
    "abstract": "Orthogonal time frequency space (OTFS) modulation has the potential to enable\nrobust communications in highly-mobile scenarios. Estimating the channels for\nOTFS systems, however, is associated with high pilot signaling overhead that\nscales with the maximum delay and Doppler spreads. This becomes particularly\nchallenging for massive MIMO systems where the overhead also scales with the\nnumber of antennas. An important observation however is that the delay,\nDoppler, and angle of departure/arrival information are directly related to the\ndistance, velocity, and direction information of the mobile user and the\nvarious scatterers in the environment. With this motivation, we propose to\nleverage radar sensing to obtain this information about the mobile users and\nscatterers in the environment and leverage it to aid the OTFS channel\nestimation in massive MIMO systems.\nAs one approach to realize our vision, this paper formulates the OTFS channel\nestimation problem in massive MIMO systems as a sparse recovery problem and\nutilizes the radar sensing information to determine the support (locations of\nthe non-zero delay-Doppler taps). The proposed radar sensing aided sparse\nrecovery algorithm is evaluated based on an accurate 3D ray-tracing framework\nwith co-existing radar and communication data. The results show that the\ndeveloped sensing-aided solution consistently outperforms the standard sparse\nrecovery algorithms (that do not leverage radar sensing data) and leads to a\nsignificant reduction in the pilot overhead, which highlights a promising\ndirection for OTFS based massive MIMO systems.",
    "descriptor": "\nComments: submitted to IEEE\n",
    "authors": [
      "Shuaifeng Jiang",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.11321"
  },
  {
    "id": "arXiv:2209.11324",
    "title": "Outdoor and indoor path loss modeling at the sub-THz band",
    "abstract": "In this letter, we present new measurement results to model large-scale path\nloss at the sub-THz (141-145 GHz) band, for both indoor and outdoor scenarios.\nExtensive measurement campaigns have been carried out, taking into account both\nline-of-sight (LoS) and non line-of-sight (NLoS) propagation. For all\nconsidered propagation scenarios, existing omni-directional and directional\npath loss model have been developed, based on the so-called close-in (CI)\nfree-space reference distance model. Moreover, path loss modeling is applied\nfor the 2nd and 3rd strongest multipath components (MPCs). Thus, path loss\nexponent and large-scale shadow fading estimates are provided. Moreover, power\nangular spread analysis is depicted, using power angular information up to the\n3rd strongest MPC",
    "descriptor": "",
    "authors": [
      "Dimitrios G. Selimis",
      "Mar Francis De Guzman",
      "Kostas P. Peppas",
      "Fotis I. Lazarakis",
      "Katsuyuki Haneda"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11324"
  },
  {
    "id": "arXiv:2209.11326",
    "title": "Towards Faithful Model Explanation in NLP: A Survey",
    "abstract": "End-to-end neural NLP architectures are notoriously difficult to understand,\nwhich gives rise to numerous efforts towards model explainability in recent\nyears. An essential principle of model explanation is Faithfulness, i.e., an\nexplanation should accurately represent the reasoning process behind the\nmodel's prediction. This survey first discusses the definition and evaluation\nof Faithfulness, as well as its significance for explainability. We then\nintroduce the recent advances in faithful explanation by grouping approaches\ninto five categories: similarity methods, analysis of model-internal\nstructures, backpropagation-based methods, counterfactual intervention, and\nself-explanatory models. Each category will be illustrated with its\nrepresentative studies, advantages, and shortcomings. Finally, we discuss all\nthe above methods in terms of their common virtues and limitations, and reflect\non future work directions towards faithful explainability. For researchers\ninterested in studying interpretability, this survey will offer an accessible\nand comprehensive overview of the area, laying the basis for further\nexploration. For users hoping to better understand their own models, this\nsurvey will be an introductory manual helping with choosing the most suitable\nexplanation method(s).",
    "descriptor": "\nComments: 62 pages\n",
    "authors": [
      "Qing Lyu",
      "Marianna Apidianaki",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11326"
  },
  {
    "id": "arXiv:2209.11328",
    "title": "Learning Certifiably Robust Controllers Using Fragile Perception",
    "abstract": "Advances in computer vision and machine learning enable robots to perceive\ntheir surroundings in powerful new ways, but these perception modules have\nwell-known fragilities. We consider the problem of synthesizing a safe\ncontroller that is robust despite perception errors. The proposed method\nconstructs a state estimator based on Gaussian processes with input-dependent\nnoises. This estimator computes a high-confidence set for the actual state\ngiven a perceived state. Then, a robust neural network controller is\nsynthesized that can provably handle the state uncertainty. Furthermore, an\nadaptive sampling algorithm is proposed to jointly improve the estimator and\ncontroller. Simulation experiments, including a realistic vision-based\nlane-keeping example in CARLA, illustrate the promise of the proposed approach\nin synthesizing robust controllers with deep-learning-based perception.",
    "descriptor": "",
    "authors": [
      "Dawei Sun",
      "Negin Musavi",
      "Geir Dullerud",
      "Sanjay Shakkottai",
      "Sayan Mitra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11328"
  },
  {
    "id": "arXiv:2209.11332",
    "title": "Dynamic Control of Soft Robotic Arm: An Experimental Study",
    "abstract": "In this paper, a reinforced soft robot prototype with a custom-designed\nactuator-space string encoder are created to investigate dynamic soft robotic\ntrajectory tracking. The soft robot prototype embedded with the proposed\nadaptive passivity control and efficient dynamic model make the challenging\ntrajectory tracking tasks possible. We focus on the exploration of tracking\naccuracy as well as the full potential of the proposed control strategy by\nperforming experimental validations at different operation scenarios: various\ntracking speed and external disturbance. In all experimental scenarios, the\nproposed adaptive passivity control outperforms the conventional PD feedback\nlinearization control. The experimental analysis details the advantage and\nshortcoming of the proposed approach, and points out the next steps for future\nsoft robot dynamic control.",
    "descriptor": "\nComments: 7 pages, 12 figures\n",
    "authors": [
      "Milad Azizkhani",
      "Anthony L. Gunderman",
      "Isuru S. Godage",
      "Yue Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11332"
  },
  {
    "id": "arXiv:2209.11335",
    "title": "Privacy-Preserving Person Detection Using Low-Resolution Infrared  Cameras",
    "abstract": "In intelligent building management, knowing the number of people and their\nlocation in a room are important for better control of its illumination,\nventilation, and heating with reduced costs and improved comfort. This is\ntypically achieved by detecting people using compact embedded devices that are\ninstalled on the room's ceiling, and that integrate low-resolution infrared\ncamera, which conceals each person's identity. However, for accurate detection,\nstate-of-the-art deep learning models still require supervised training using a\nlarge annotated dataset of images. In this paper, we investigate cost-effective\nmethods that are suitable for person detection based on low-resolution infrared\nimages. Results indicate that for such images, we can reduce the amount of\nsupervision and computation, while still achieving a high level of detection\naccuracy. Going from single-shot detectors that require bounding box\nannotations of each person in an image, to auto-encoders that only rely on\nunlabelled images that do not contain people, allows for considerable savings\nin terms of annotation costs, and for models with lower computational costs. We\nvalidate these experimental findings on two challenging top-view datasets with\nlow-resolution infrared images.",
    "descriptor": "",
    "authors": [
      "Thomas Dubail",
      "Fidel Alejandro Guerrero Pe\u00f1a",
      "Heitor Rapela Medeiros",
      "Masih Aminbeidokhti",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11335"
  },
  {
    "id": "arXiv:2209.11336",
    "title": "UNav: An Infrastructure-Independent Vision-Based Navigation System for  People with Blindness and Low vision",
    "abstract": "Vision-based localization approaches now underpin newly emerging navigation\npipelines for myriad use cases from robotics to assistive technologies.\nCompared to sensor-based solutions, vision-based localization does not require\npre-installed sensor infrastructure, which is costly, time-consuming, and/or\noften infeasible at scale. Herein, we propose a novel vision-based localization\npipeline for a specific use case: navigation support for end-users with\nblindness and low vision. Given a query image taken by an end-user on a mobile\napplication, the pipeline leverages a visual place recognition (VPR) algorithm\nto find similar images in a reference image database of the target space. The\ngeolocations of these similar images are utilized in downstream tasks that\nemploy a weighted-average method to estimate the end-user's location and a\nperspective-n-point (PnP) algorithm to estimate the end-user's direction.\nAdditionally, this system implements Dijkstra's algorithm to calculate a\nshortest path based on a navigable map that includes trip origin and\ndestination. The topometric map used for localization and navigation is built\nusing a customized graphical user interface that projects a 3D reconstructed\nsparse map, built from a sequence of images, to the corresponding a priori 2D\nfloor plan. Sequential images used for map construction can be collected in a\npre-mapping step or scavenged through public databases/citizen science. The\nend-to-end system can be installed on any internet-accessible device with a\ncamera that hosts a custom mobile application. For evaluation purposes, mapping\nand localization were tested in a complex hospital environment. The evaluation\nresults demonstrate that our system can achieve localization with an average\nerror of less than 1 meter without knowledge of the camera's intrinsic\nparameters, such as focal length.",
    "descriptor": "",
    "authors": [
      "Anbang Yang",
      "Mahya Beheshti",
      "Todd E Hudson",
      "Rajesh Vedanthan",
      "Wachara Riewpaiboon",
      "Pattanasak Mongkolwat",
      "Chen Feng",
      "John-Ross Rizzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11336"
  },
  {
    "id": "arXiv:2209.11338",
    "title": "A domain adaptive deep learning solution for scanpath prediction of  paintings",
    "abstract": "Cultural heritage understanding and preservation is an important issue for\nsociety as it represents a fundamental aspect of its identity. Paintings\nrepresent a significant part of cultural heritage, and are the subject of study\ncontinuously. However, the way viewers perceive paintings is strictly related\nto the so-called HVS (Human Vision System) behaviour. This paper focuses on the\neye-movement analysis of viewers during the visual experience of a certain\nnumber of paintings. In further details, we introduce a new approach to\npredicting human visual attention, which impacts several cognitive functions\nfor humans, including the fundamental understanding of a scene, and then extend\nit to painting images. The proposed new architecture ingests images and returns\nscanpaths, a sequence of points featuring a high likelihood of catching\nviewers' attention. We use an FCNN (Fully Convolutional Neural Network), in\nwhich we exploit a differentiable channel-wise selection and Soft-Argmax\nmodules. We also incorporate learnable Gaussian distributions onto the network\nbottleneck to simulate visual attention process bias in natural scene images.\nFurthermore, to reduce the effect of shifts between different domains (i.e.\nnatural images, painting), we urge the model to learn unsupervised general\nfeatures from other domains using a gradient reversal classifier. The results\nobtained by our model outperform existing state-of-the-art ones in terms of\naccuracy and efficiency.",
    "descriptor": "\nComments: Accepted at CBMI2022 graz, austria\n",
    "authors": [
      "Mohamed Amine Kerkouri",
      "Marouane Tliba",
      "Aladine Chetouani",
      "Alessandro Bruno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11338"
  },
  {
    "id": "arXiv:2209.11342",
    "title": "Fast Disparity Estimation from a Single Compressed Light Field  Measurement",
    "abstract": "The abundant spatial and angular information from light fields has allowed\nthe development of multiple disparity estimation approaches. However, the\nacquisition of light fields requires high storage and processing cost, limiting\nthe use of this technology in practical applications. To overcome these\ndrawbacks, the compressive sensing (CS) theory has allowed the development of\noptical architectures to acquire a single coded light field measurement. This\nmeasurement is decoded using an optimization algorithm or deep neural network\nthat requires high computational costs. The traditional approach for disparity\nestimation from compressed light fields requires first recovering the entire\nlight field and then a post-processing step, thus requiring long times. In\ncontrast, this work proposes a fast disparity estimation from a single\ncompressed measurement by omitting the recovery step required in traditional\napproaches. Specifically, we propose to jointly optimize an optical\narchitecture for acquiring a single coded light field snapshot and a\nconvolutional neural network (CNN) for estimating the disparity maps.\nExperimentally, the proposed method estimates disparity maps comparable with\nthose obtained from light fields reconstructed using deep learning approaches.\nFurthermore, the proposed method is 20 times faster in training and inference\nthan the best method that estimates the disparity from reconstructed light\nfields.",
    "descriptor": "",
    "authors": [
      "Emmanuel Martinez",
      "Edwin Vargas",
      "Henry Arguello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.11342"
  },
  {
    "id": "arXiv:2209.11344",
    "title": "Exploring The Design of Prompts For Applying GPT-3 based Chatbots: A  Mental Wellbeing Case Study on Mechanical Turk",
    "abstract": "Large-Language Models like GPT-3 have the potential to enable HCI designers\nand researchers to create more human-like and helpful chatbots for specific\napplications. But evaluating the feasibility of these chatbots and designing\nprompts that optimize GPT-3 for a specific task is challenging. We present a\ncase study in tackling these questions, applying GPT-3 to a brief 5-minute\nchatbot that anyone can talk to better manage their mood. We report a\nrandomized factorial experiment with 945 participants on Mechanical Turk that\ntests three dimensions of prompt design to initialize the chatbot (identity,\nintent, and behaviour), and present both quantitative and qualitative analyses\nof conversations and user perceptions of the chatbot. We hope other HCI\ndesigners and researchers can build on this case study, for other applications\nof GPT-3 based chatbots to specific tasks, and build on and extend the methods\nwe use for prompt design, and evaluation of the prompt design.",
    "descriptor": "",
    "authors": [
      "Harsh Kumar",
      "Ilya Musabirov",
      "Jiakai Shi",
      "Adele Lauzon",
      "Kwan Kiu Choy",
      "Ofek Gross",
      "Dana Kulzhabayeva",
      "Joseph Jay Williams"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.11344"
  },
  {
    "id": "arXiv:2209.11345",
    "title": "Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and  Restoration",
    "abstract": "Compression plays an important role on the efficient transmission and storage\nof images and videos through band-limited systems such as streaming services,\nvirtual reality or videogames. However, compression unavoidably leads to\nartifacts and the loss of the original information, which may severely degrade\nthe visual quality. For these reasons, quality enhancement of compressed images\nhas become a popular research topic. While most state-of-the-art image\nrestoration methods are based on convolutional neural networks, other\ntransformers-based methods such as SwinIR, show impressive performance on these\ntasks.\nIn this paper, we explore the novel Swin Transformer V2, to improve SwinIR\nfor image super-resolution, and in particular, the compressed input scenario.\nUsing this method we can tackle the major issues in training transformer vision\nmodels, such as training instability, resolution gaps between pre-training and\nfine-tuning, and hunger on data. We conduct experiments on three representative\ntasks: JPEG compression artifacts removal, image super-resolution (classical\nand lightweight), and compressed image super-resolution. Experimental results\ndemonstrate that our method, Swin2SR, can improve the training convergence and\nperformance of SwinIR, and is a top-5 solution at the \"AIM 2022 Challenge on\nSuper-Resolution of Compressed Image and Video\".",
    "descriptor": "\nComments: European Conference on Computer Vision (ECCV 2022) Workshops\n",
    "authors": [
      "Marcos V. Conde",
      "Ui-Jin Choi",
      "Maxime Burchi",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.11345"
  },
  {
    "id": "arXiv:2209.11349",
    "title": "A new reduced order model of linear parabolic PDEs",
    "abstract": "How to build an accurate reduced order model (ROM) for multidimensional time\ndependent partial differential equations (PDEs) is quite open. In this paper,\nwe propose a new ROM for linear parabolic PDEs. We prove that our new method\ncan be orders of magnitude faster than standard solvers, and is also much less\nmemory intensive. Under some assumptions on the problem data, we prove that the\nconvergence rates of the new method is the same with standard solvers.\nNumerical experiments are presented to confirm our theoretical result.",
    "descriptor": "",
    "authors": [
      "Noel Walkington",
      "Franziska Weber",
      "Yangwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11349"
  },
  {
    "id": "arXiv:2209.11350",
    "title": "Oracle Analysis of Representations for Deep Open Set Detection",
    "abstract": "The problem of detecting a novel class at run time is known as Open Set\nDetection & is important for various real-world applications like medical\napplication, autonomous driving, etc. Open Set Detection within context of deep\nlearning involves solving two problems: (i) Must map the input images into a\nlatent representation that contains enough information to detect the outliers,\nand (ii) Must learn an anomaly scoring function that can extract this\ninformation from the latent representation to identify the anomalies. Research\nin deep anomaly detection methods has progressed slowly. One reason may be that\nmost papers simultaneously introduce new representation learning techniques and\nnew anomaly scoring approaches. The goal of this work is to improve this\nmethodology by providing ways of separately measuring the effectiveness of the\nrepresentation learning and anomaly scoring. This work makes two methodological\ncontributions. The first is to introduce the notion of Oracle anomaly detection\nfor quantifying the information available in a learned latent representation.\nThe second is to introduce Oracle representation learning, which produces a\nrepresentation that is guaranteed to be sufficient for accurate anomaly\ndetection. These two techniques help researchers to separate the quality of the\nlearned representation from the performance of the anomaly scoring mechanism so\nthat they can debug and improve their systems. The methods also provide an\nupper limit on how much open category detection can be improved through better\nanomaly scoring mechanisms. The combination of the two oracles gives an upper\nlimit on the performance that any open category detection method could achieve.\nThis work introduces these two oracle techniques and demonstrates their utility\nby applying them to several leading open category detection methods.",
    "descriptor": "",
    "authors": [
      "Risheek Garrepalli",
      "Alan Fern",
      "Thomas G. Dietterich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11350"
  },
  {
    "id": "arXiv:2209.11351",
    "title": "Software Sustainability: A Design Case for Achieving Sustainable Pension  Services in Developing Country",
    "abstract": "The need for efficient and sustainable software to improve business and\nachieve goals cannot be over-emphasized. Sustainable digital services and\nproduct delivery cannot be achieved without embracing sustainable software\ndesign practices. Despite the current research progress on software\nsustainability, most software development practitioners in developing countries\nare unclear about what constitutes software sustainability and often lack the\nproper understanding of how to implement it in their specific industry domain.\nResearch efforts from software engineering focused on promoting software\nsustainability awareness in developed countries, and fewer efforts have been\nchanneled to studying the same awareness in developing countries. This has\naffected the level of awareness about sustainable software design practices in\nmost developing countries. This research investigates the awareness of software\nsustainability in the Nigerian pension industry and its challenges among\npractitioners. The software development practitioners were engaged and\ninterviewed. We offered ways to mitigate the identified challenges and promote\nthe awareness of software sustainability in the pension industry. Our findings\nfurther show that, with the right sustainability knowledge, the software\npractitioners in the pension industry have the potential to support their\norganization's sustainable culture and improve the efficiency of product design\nand service delivery.",
    "descriptor": "",
    "authors": [
      "Mikhail Ola Adisa",
      "Shola Oyedeji",
      "Jari Porras"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.11351"
  },
  {
    "id": "arXiv:2209.11354",
    "title": "Convolutional Learning on Multigraphs",
    "abstract": "Graph convolutional learning has led to many exciting discoveries in diverse\nareas. However, in some applications, traditional graphs are insufficient to\ncapture the structure and intricacies of the data. In such scenarios,\nmultigraphs arise naturally as discrete structures in which complex dynamics\ncan be embedded. In this paper, we develop convolutional information processing\non multigraphs and introduce convolutional multigraph neural networks (MGNNs).\nTo capture the complex dynamics of information diffusion within and across each\nof the multigraph's classes of edges, we formalize a convolutional signal\nprocessing model, defining the notions of signals, filtering, and frequency\nrepresentations on multigraphs. Leveraging this model, we develop a multigraph\nlearning architecture, including a sampling procedure to reduce computational\ncomplexity. The introduced architecture is applied towards optimal wireless\nresource allocation and a hate speech localization task, offering improved\nperformance over traditional graph neural networks.",
    "descriptor": "",
    "authors": [
      "Landon Butler",
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.11354"
  },
  {
    "id": "arXiv:2209.11355",
    "title": "Learning Interpretable Dynamics from Images of a Freely Rotating 3D  Rigid Body",
    "abstract": "In many real-world settings, image observations of freely rotating 3D rigid\nbodies, such as satellites, may be available when low-dimensional measurements\nare not. However, the high-dimensionality of image data precludes the use of\nclassical estimation techniques to learn the dynamics and a lack of\ninterpretability reduces the usefulness of standard deep learning methods. In\nthis work, we present a physics-informed neural network model to estimate and\npredict 3D rotational dynamics from image sequences. We achieve this using a\nmulti-stage prediction pipeline that maps individual images to a latent\nrepresentation homeomorphic to $\\mathbf{SO}(3)$, computes angular velocities\nfrom latent pairs, and predicts future latent states using the Hamiltonian\nequations of motion with a learned representation of the Hamiltonian. We\ndemonstrate the efficacy of our approach on a new rotating rigid-body dataset\nwith sequences of rotating cubes and rectangular prisms with uniform and\nnon-uniform density.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Justice Mason",
      "Christine Allen-Blanchette",
      "Nicholas Zolman",
      "Elizabeth Davison",
      "Naomi Leonard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11355"
  },
  {
    "id": "arXiv:2209.11356",
    "title": "NasHD: Efficient ViT Architecture Performance Ranking using  Hyperdimensional Computing",
    "abstract": "Neural Architecture Search (NAS) is an automated architecture engineering\nmethod for deep learning design automation, which serves as an alternative to\nthe manual and error-prone process of model development, selection, evaluation\nand performance estimation. However, one major obstacle of NAS is the extremely\ndemanding computation resource requirements and time-consuming iterations\nparticularly when the dataset scales. In this paper, targeting at the emerging\nvision transformer (ViT), we present NasHD, a hyperdimensional computing based\nsupervised learning model to rank the performance given the architectures and\nconfigurations. Different from other learning based methods, NasHD is faster\nthanks to the high parallel processing of HDC architecture. We also evaluated\ntwo HDC encoding schemes: Gram-based and Record-based of NasHD on their\nperformance and efficiency. On the VIMER-UFO benchmark dataset of 8\napplications from a diverse range of domains, NasHD Record can rank the\nperformance of nearly 100K vision transformer models with about 1 minute while\nstill achieving comparable results with sophisticated models.",
    "descriptor": "",
    "authors": [
      "Dongning Ma",
      "Pengfei Zhao",
      "Xun Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.11356"
  },
  {
    "id": "arXiv:2209.11359",
    "title": "CUTS: A Fully Unsupervised Framework for Medical Image Segmentation",
    "abstract": "In this work we introduce CUTS (Contrastive and Unsupervised Training for\nSegmentation) the first fully unsupervised deep learning framework for medical\nimage segmentation, facilitating the use of the vast majority of imaging data\nthat is not labeled or annotated. Segmenting medical images into regions of\ninterest is a critical task for facilitating both patient diagnoses and\nquantitative research. A major limiting factor in this segmentation is the lack\nof labeled data, as getting expert annotations for each new set of imaging data\nor task can be expensive, labor intensive, and inconsistent across annotators:\nthus, we utilize self-supervision based on pixel-centered patches from the\nimages themselves. Our unsupervised approach is based on a training objective\nwith both contrastive learning and autoencoding aspects. Previous contrastive\nlearning approaches for medical image segmentation have focused on image-level\ncontrastive training, rather than our intra-image patch-level approach or have\nused this as a pre-training task where the network needed further supervised\ntraining afterwards. By contrast, we build the first entirely unsupervised\nframework that operates at the pixel-centered-patch level. Specifically, we add\nnovel augmentations, a patch reconstruction loss, and introduce a new pixel\nclustering and identification framework. Our model achieves improved results on\nseveral key medical imaging tasks, as verified by held-out expert annotations\non the task of segmenting geographic atrophy (GA) regions of images of the\nretina.",
    "descriptor": "",
    "authors": [
      "Matthew Amodio",
      "Feng Gao",
      "Arman Avesta",
      "Sanjay Aneja",
      "Lucian V. Del Priore",
      "Jay Wang",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11359"
  },
  {
    "id": "arXiv:2209.11364",
    "title": "Incorporation of Human Knowledge into Data Embeddings to Improve Pattern  Significance and Interpretability",
    "abstract": "Embedding is a common technique for analyzing multi-dimensional data.\nHowever, the embedding projection cannot always form significant and\ninterpretable visual structures that foreshadow underlying data patterns. We\npropose an approach that incorporates human knowledge into data embeddings to\nimprove pattern significance and interpretability. The core idea is (1)\nexternalizing tacit human knowledge as explicit sample labels and (2) adding a\nclassification loss in the embedding network to encode samples' classes. The\napproach pulls samples of the same class with similar data features closer in\nthe projection, leading to more compact (significant) and class-consistent\n(interpretable) visual structures. We give an embedding network with a\ncustomized classification loss to implement the idea and integrate the network\ninto a visualization system to form a workflow that supports flexible class\ncreation and pattern exploration. Patterns found on open datasets in case\nstudies, subjects' performance in a user study, and quantitative experiment\nresults illustrate the general usability and effectiveness of the approach.",
    "descriptor": "\nComments: IEEE VIS 2022\n",
    "authors": [
      "Jie Li",
      "Chun-qi Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11364"
  },
  {
    "id": "arXiv:2209.11366",
    "title": "A Jensen-Shannon Divergence Based Loss Function for Bayesian Neural  Networks",
    "abstract": "Kullback-Leibler (KL) divergence is widely used for variational inference of\nBayesian Neural Networks (BNNs). However, the KL divergence has limitations\nsuch as unboundedness and asymmetry. We examine the Jensen-Shannon (JS)\ndivergence that is more general, bounded, and symmetric. We formulate a novel\nloss function for BNNs based on the geometric JS divergence and show that the\nconventional KL divergence-based loss function is its special case. We evaluate\nthe divergence part of the proposed loss function in a closed form for a\nGaussian prior. For any other general prior, Monte Carlo approximations can be\nused. We provide algorithms for implementing both of these cases. We\ndemonstrate that the proposed loss function offers an additional parameter that\ncan be tuned to control the degree of regularisation. We derive the conditions\nunder which the proposed loss function regularises better than the KL\ndivergence-based loss function for Gaussian priors and posteriors. We\ndemonstrate performance improvements over the state-of-the-art KL\ndivergence-based BNN on the classification of a noisy CIFAR data set and a\nbiased histopathology data set.",
    "descriptor": "\nComments: To be submitted for peer review in IEEE\n",
    "authors": [
      "Ponkrshnan Thiagarajan",
      "Susanta Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11366"
  },
  {
    "id": "arXiv:2209.11367",
    "title": "Towards Robust Autonomous Grasping with Reflexes Using High-Bandwidth  Sensing and Actuation",
    "abstract": "Modern robotic manipulation systems fall short of human manipulation skills\npartly because they rely on closing feedback loops exclusively around vision\ndata, which reduces system bandwidth and speed. By developing autonomous\ngrasping reflexes that rely on high-bandwidth force, contact, and proximity\ndata, the overall system speed and robustness can be increased while reducing\nreliance on vision data. We are developing a new system built around a\nlow-inertia, high-speed arm with nimble fingers that combines a high-level\ntrajectory planner operating at less than 1 Hz with low-level autonomous reflex\ncontrollers running upwards of 300 Hz. We characterize the reflex system by\ncomparing the volume of the set of successful grasps for a naive baseline\ncontroller and variations of our reflexive grasping controller, finding that\nour controller expands the set of successful grasps by 55% relative to the\nbaseline. We also deploy our reflexive grasping controller with a simple\nvision-based planner in an autonomous clutter clearing task, achieving a grasp\nsuccess rate above 90% while clearing over 100 items.",
    "descriptor": "\nComments: 6 pages, 1 page of references, supplementary video at this https URL Submitted to ICRA 2023\n",
    "authors": [
      "Andrew SaLoutos",
      "Hongmin Kim",
      "Elijah Stanger-Jones",
      "Menglong Guo",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11367"
  },
  {
    "id": "arXiv:2209.11368",
    "title": "Design of a Multimodal Fingertip Sensor for Dynamic Manipulation",
    "abstract": "We introduce a spherical fingertip sensor for dynamic manipulation. It is\nbased on barometric pressure and time-of-flight proximity sensors and is\nlow-latency, compact, and physically robust. The sensor uses a trained neural\nnetwork to estimate the contact location and three-axis contact forces based on\ndata from the pressure sensors, which are embedded within the sensor's sphere\nof polyurethane rubber. The time-of-flight sensors face in three different\noutward directions, and an integrated microcontroller samples each of the\nindividual sensors at up to 200 Hz. To quantify the effect of system latency on\ndynamic manipulation performance, we develop and analyze a metric called the\ncollision impulse ratio and characterize the end-to-end latency of our new\nsensor. We also present experimental demonstrations with the sensor, including\nmeasuring contact transitions, performing coarse mapping, maintaining a contact\nforce with a moving object, and reacting to avoid collisions.",
    "descriptor": "\nComments: 6 pages, 2 pages of references, supplementary video at this https URL Submitted to ICRA 2023\n",
    "authors": [
      "Andrew SaLoutos",
      "Elijah Stanger-Jones",
      "Menglong Guo",
      "Hongmin Kim",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11368"
  },
  {
    "id": "arXiv:2209.11372",
    "title": "Tensor-Based Multi-Modality Feature Selection and Regression for  Alzheimer's Disease Diagnosis",
    "abstract": "The assessment of Alzheimer's Disease (AD) and Mild Cognitive Impairment\n(MCI) associated with brain changes remains a challenging task. Recent studies\nhave demonstrated that combination of multi-modality imaging techniques can\nbetter reflect pathological characteristics and contribute to more accurate\ndiagnosis of AD and MCI. In this paper, we propose a novel tensor-based\nmulti-modality feature selection and regression method for diagnosis and\nbiomarker identification of AD and MCI from normal controls. Specifically, we\nleverage the tensor structure to exploit high-level correlation information\ninherent in the multi-modality data, and investigate tensor-level sparsity in\nthe multilinear regression model. We present the practical advantages of our\nmethod for the analysis of ADNI data using three imaging modalities (VBM- MRI,\nFDG-PET and AV45-PET) with clinical parameters of disease severity and\ncognitive scores. The experimental results demonstrate the superior performance\nof our proposed method against the state-of-the-art for the disease diagnosis\nand the identification of disease-specific regions and modality-related\ndifferences. The code for this work is publicly available at\nhttps://github.com/junfish/BIOS22.",
    "descriptor": "",
    "authors": [
      "Jun Yu",
      "Zhaoming Kong",
      "Liang Zhan",
      "Li Shen",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11372"
  },
  {
    "id": "arXiv:2209.11377",
    "title": "UniKW-AT: Unified Keyword Spotting and Audio Tagging",
    "abstract": "Within the audio research community and the industry, keyword spotting (KWS)\nand audio tagging (AT) are seen as two distinct tasks and research fields.\nHowever, from a technical point of view, both of these tasks are identical:\nthey predict a label (keyword in KWS, sound event in AT) for some fixed-sized\ninput audio segment. This work proposes UniKW-AT: An initial approach for\njointly training both KWS and AT. UniKW-AT enhances the noise-robustness for\nKWS, while also being able to predict specific sound events and enabling\nconditional wake-ups on sound events. Our approach extends the AT pipeline with\nadditional labels describing the presence of a keyword. Experiments are\nconducted on the Google Speech Commands V1 (GSCV1) and the balanced Audioset\n(AS) datasets. The proposed MobileNetV2 model achieves an accuracy of 97.53% on\nthe GSCV1 dataset and an mAP of 33.4 on the AS evaluation set. Further, we show\nthat significant noise-robustness gains can be observed on a real-world KWS\ndataset, greatly outperforming standard KWS approaches. Our study shows that\nKWS and AT can be merged into a single framework without significant\nperformance degradation.",
    "descriptor": "\nComments: Accepted in Interspeech2022\n",
    "authors": [
      "Heinrich Dinkel",
      "Yongqing Wang",
      "Zhiyong Yan",
      "Junbo Zhang",
      "Yujun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.11377"
  },
  {
    "id": "arXiv:2209.11378",
    "title": "Extending Word-Level Quality Estimation for Post-Editing Assistance",
    "abstract": "We define a novel concept called extended word alignment in order to improve\npost-editing assistance efficiency. Based on extended word alignment, we\nfurther propose a novel task called refined word-level QE that outputs refined\ntags and word-level correspondences. Compared to original word-level QE, the\nnew task is able to directly point out editing operations, thus improves\nefficiency. To extract extended word alignment, we adopt a supervised method\nbased on mBERT. To solve refined word-level QE, we firstly predict original QE\ntags by training a regression model for sequence tagging based on mBERT and\nXLM-R. Then, we refine original word tags with extended word alignment. In\naddition, we extract source-gap correspondences, meanwhile, obtaining gap tags.\nExperiments on two language pairs show the feasibility of our method and give\nus inspirations for further improvement.",
    "descriptor": "",
    "authors": [
      "Yizhen Wei",
      "Takehito Utsuro",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11378"
  },
  {
    "id": "arXiv:2209.11379",
    "title": "Do Current Multi-Task Optimization Methods in Deep Learning Even Help?",
    "abstract": "Recent research has proposed a series of specialized optimization algorithms\nfor deep multi-task models. It is often claimed that these multi-task\noptimization (MTO) methods yield solutions that are superior to the ones found\nby simply optimizing a weighted average of the task losses. In this paper, we\nperform large-scale experiments on a variety of language and vision tasks to\nexamine the empirical validity of these claims. We show that, despite the added\ndesign and computational complexity of these algorithms, MTO methods do not\nyield any performance improvements beyond what is achievable via traditional\noptimization approaches. We highlight alternative strategies that consistently\nyield improvements to the performance profile and point out common training\npitfalls that might cause suboptimal results. Finally, we outline challenges in\nreliably evaluating the performance of MTO algorithms and discuss potential\nsolutions.",
    "descriptor": "",
    "authors": [
      "Derrick Xin",
      "Behrooz Ghorbani",
      "Ankush Garg",
      "Orhan Firat",
      "Justin Gilmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11379"
  },
  {
    "id": "arXiv:2209.11382",
    "title": "Zero-Forcing Based Downlink Virtual MIMO-NOMA Communications in IoT  Networks",
    "abstract": "To support massive connectivity and boost spectral efficiency for internet of\nthings (IoT), a downlink scheme combining virtual multiple-input\nmultiple-output (MIMO) and nonorthogonal multiple access (NOMA) is proposed.\nAll the single-antenna IoT devices in each cluster cooperate with each other to\nestablish a virtual MIMO entity, and multiple independent data streams are\nrequested by each cluster. NOMA is employed to superimpose all the requested\ndata streams, and each cluster leverages zero-forcing detection to de-multiplex\nthe input data streams. Only statistical channel state information (CSI) is\navailable at base station to avoid the waste of the energy and bandwidth on\nfrequent CSI estimations. The outage probability and goodput of the virtual\nMIMO-NOMA system are thoroughly investigated by considering Kronecker model,\nwhich embraces both the transmit and receive correlations. Furthermore, the\nasymptotic results facilitate not only the exploration of physical insights but\nalso the goodput maximization. In particular, the asymptotic outage expressions\nprovide quantitative impacts of various system parameters and enable the\ninvestigation of diversity-multiplexing tradeoff (DMT). Moreover, power\nallocation coefficients and/or transmission rates can be properly chosen to\nachieve the maximal goodput. By favor of Karush-Kuhn-Tucker conditions, the\ngoodput maximization problems can be solved in closed-form, with which the\njoint power and rate selection is realized by using alternately iterating\noptimization.Besides, the optimization algorithms tend to allocate more power\nto clusters under unfavorable channel conditions and support clusters with\nhigher transmission rate under benign channel conditions.",
    "descriptor": "",
    "authors": [
      "Zheng Shi",
      "Hong Wang",
      "Yaru Fu",
      "Guanghua Yang",
      "Shaodan Ma",
      "Fen Hou",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.11382"
  },
  {
    "id": "arXiv:2209.11386",
    "title": "Improving Conversational Recommender System via Contextual and  Time-Aware Modeling with Less Domain-Specific Knowledge",
    "abstract": "Conversational Recommender Systems (CRS) has become an emerging research\ntopic seeking to perform recommendations through interactive conversations,\nwhich generally consist of generation and recommendation modules. Prior work on\nCRS tends to incorporate more external and domain-specific knowledge like item\nreviews to enhance performance. Despite the fact that the collection and\nannotation of the external domain-specific information needs much human effort\nand degenerates the generalizability, too much extra knowledge introduces more\ndifficulty to balance among them. Therefore, we propose to fully discover and\nextract internal knowledge from the context. We capture both entity-level and\ncontextual-level representations to jointly model user preferences for the\nrecommendation, where a time-aware attention is designed to emphasize the\nrecently appeared items in entity-level representations. We further use the\npre-trained BART to initialize the generation module to alleviate the data\nscarcity and enhance the context modeling. In addition to conducting\nexperiments on a popular dataset (ReDial), we also include a multi-domain\ndataset (OpenDialKG) to show the effectiveness of our model. Experiments on\nboth datasets show that our model achieves better performance on most\nevaluation metrics with less external knowledge and generalizes well to other\ndomains. Additional analyses on the recommendation and generation tasks\ndemonstrate the effectiveness of our model in different scenarios.",
    "descriptor": "",
    "authors": [
      "Lingzhi Wang",
      "Shafiq Joty",
      "Wei Gao",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11386"
  },
  {
    "id": "arXiv:2209.11387",
    "title": "Achievable Diversity Order of HARQ-Aided Downlink NOMA Systems",
    "abstract": "The combination between non-orthogonal multiple access (NOMA) and hybrid\nautomatic repeat request (HARQ) is capable of realizing ultra-reliability, high\nthroughput and many concurrent connections particularly for emerging\ncommunication systems. This paper focuses on characterizing the asymptotic\nscaling law of the outage probability of HARQ-aided NOMA systems with respect\nto the transmit power, i.e., diversity order. The analysis of diversity order\nis carried out for three basic types of HARQ-aided downlink NOMA systems,\nincluding Type I HARQ, HARQ with chase combining (HARQ-CC) and HARQ with\nincremental redundancy (HARQ-IR). The diversity orders of three HARQ-aided\ndownlink NOMA systems are derived in closed-form, where an integration domain\npartition trick is developed to obtain the bounds of the outage probability\nspecially for HARQ-CC and HARQ-IR-aided NOMA systems. The analytical results\nshow that the diversity order is a decreasing step function of transmission\nrate, and full time diversity can only be achieved under a sufficiently low\ntransmission rate. It is also revealed that HARQ-IR-aided NOMA systems have the\nlargest diversity order, followed by HARQ-CC-aided and then Type I HARQ-aided\nNOMA systems. Additionally, the users' diversity orders follow a descending\norder according to their respective average channel gains. Furthermore, we\nexpand discussions on the cases of power-efficient transmissions and imperfect\nchannel state information (CSI). Monte Carlo simulations finally confirm our\nanalysis.",
    "descriptor": "",
    "authors": [
      "Zheng Shi",
      "Chenmeng Zhang",
      "Yaru Fu",
      "Hong Wang",
      "Guanghua Yang",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11387"
  },
  {
    "id": "arXiv:2209.11388",
    "title": "LGDN: Language-Guided Denoising Network for Video-Language Modeling",
    "abstract": "Video-language modeling has attracted much attention with the rapid growth of\nweb videos. Most existing methods assume that the video frames and text\ndescription are semantically correlated, and focus on video-language modeling\nat video level. However, this hypothesis often fails for two reasons: (1) With\nthe rich semantics of video contents, it is difficult to cover all frames with\na single video-level description; (2) A raw video typically has\nnoisy/meaningless information (e.g., scenery shot, transition or teaser).\nAlthough a number of recent works deploy attention mechanism to alleviate this\nproblem, the irrelevant/noisy information still makes it very difficult to\naddress. To overcome such challenge, we thus propose an efficient and effective\nmodel, termed Language-Guided Denoising Network (LGDN), for video-language\nmodeling. Different from most existing methods that utilize all extracted video\nframes, LGDN dynamically filters out the misaligned or redundant frames under\nthe language supervision and obtains only 2--4 salient frames per video for\ncross-modal token-level alignment. Extensive experiments on five public\ndatasets show that our LGDN outperforms the state-of-the-arts by large margins.\nWe also provide detailed ablation study to reveal the critical importance of\nsolving the noise issue, in hope of inspiring future video-language work.",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Haoyu Lu",
      "Mingyu Ding",
      "Nanyi Fei",
      "Yuqi Huo",
      "Zhiwu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11388"
  },
  {
    "id": "arXiv:2209.11390",
    "title": "Outage Performance and Optimal Design of MIMO-NOMA Enhanced Small Cell  Networks With Imperfect Channel-State Information",
    "abstract": "This paper focuses on boosting the performance of small cell networks (SCNs)\nby integrating multiple-input multiple-output (MIMO) and non-orthogonal\nmultiple access (NOMA) in consideration of imperfect channel-state information\n(CSI). The estimation error and the spatial randomness of base stations (BSs)\nare characterized by using Kronecker model and Poisson point process (PPP),\nrespectively. The outage probabilities of MIMO-NOMA enhanced SCNs are first\nderived in closed-form by taking into account two grouping policies, including\nrandom grouping and distance-based grouping. It is revealed that the average\noutage probabilities are irrelevant to the intensity of BSs in the\ninterference-limited regime, while the outage performance deteriorates if the\nintensity is sufficiently low. Besides, as the channel uncertainty lessens, the\nasymptotic analyses manifest that the target rates must be restricted up to a\nbound to achieve an arbitrarily low outage probability in the absence of the\ninter-cell interference.Moreover, highly correlated estimation error\nameliorates the outage performance under a low quality of CSI, otherwise it\nbehaves oppositely. Afterwards, the goodput is maximized by choosing\nappropriate precoding matrix, receiver filters and transmission rates. In the\nend, the numerical results verify our analysis and corroborate the superiority\nof our proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Zheng Shi",
      "Hong Wang",
      "Yaru Fu",
      "Guanghua Yang",
      "Shaodan Ma",
      "Xinrong Ye"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11390"
  },
  {
    "id": "arXiv:2209.11395",
    "title": "Achieve the Minimum Width of Neural Networks for Universal Approximation",
    "abstract": "The universal approximation property (UAP) of neural networks is fundamental\nfor deep learning, and it is well known that wide neural networks are universal\napproximators of continuous functions within both the $L^p$ norm and the\ncontinuous/uniform norm. However, the exact minimum width, $w_{\\min}$, for the\nUAP has not been studied thoroughly. Recently, using a\ndecoder-memorizer-encoder scheme, \\citet{Park2021Minimum} found that $w_{\\min}\n= \\max(d_x+1,d_y)$ for both the $L^p$-UAP of ReLU networks and the $C$-UAP of\nReLU+STEP networks, where $d_x,d_y$ are the input and output dimensions,\nrespectively. In this paper, we consider neural networks with an arbitrary set\nof activation functions. We prove that both $C$-UAP and $L^p$-UAP for functions\non compact domains share a universal lower bound of the minimal width; that is,\n$w^*_{\\min} = \\max(d_x,d_y)$. In particular, the critical width, $w^*_{\\min}$,\nfor $L^p$-UAP can be achieved by leaky-ReLU networks, provided that the input\nor output dimension is larger than one. Our construction is based on the\napproximation power of neural ordinary differential equations and the ability\nto approximate flow maps by neural networks. The nonmonotone or discontinuous\nactivation functions case and the one-dimensional case are also discussed.",
    "descriptor": "",
    "authors": [
      "Yongqiang Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11395"
  },
  {
    "id": "arXiv:2209.11396",
    "title": "Conversational QA Dataset Generation with Answer Revision",
    "abstract": "Conversational question--answer generation is a task that automatically\ngenerates a large-scale conversational question answering dataset based on\ninput passages. In this paper, we introduce a novel framework that extracts\nquestion-worthy phrases from a passage and then generates corresponding\nquestions considering previous conversations. In particular, our framework\nrevises the extracted answers after generating questions so that answers\nexactly match paired questions. Experimental results show that our simple\nanswer revision approach leads to significant improvement in the quality of\nsynthetic data. Moreover, we prove that our framework can be effectively\nutilized for domain adaptation of conversational question answering.",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Seonjeong Hwang",
      "Gary Geunbae Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11396"
  },
  {
    "id": "arXiv:2209.11397",
    "title": "A Game of Simulation: Modeling and Analyzing the Dragons of Game of  Thrones",
    "abstract": "This paper outlines two approaches for mathematical, simulation, modeling,\nand analysis of hypothetical creatures, in particular, the dragons of HBO's\ntelevision series Game of Thrones (GOT). Our first approach, the forward model,\nutilizes quasi-empirical observations of various features of GOT dragons. We\nthen mathematically derive the growth rate, other dimensions, energy\nconsumption, etc. In the backward model, we use projected energy consumption by\ngiven ecological impact to model an expected dragon in terms of physical\nfeatures. We compare and contrast both models to examine the plausibility of a\nreal-world existence for our titular dragons and provide brief analyses of\npotential impacts on ecology.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Zheng Cao",
      "Brody Bottrell",
      "Jiayi Gao",
      "Mark Pock",
      "Vinsensius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11397"
  },
  {
    "id": "arXiv:2209.11404",
    "title": "Towards Frame Rate Agnostic Multi-Object Tracking",
    "abstract": "Multi-Object Tracking (MOT) is one of the most fundamental computer vision\ntasks which contributes to a variety of video analysis applications. Despite\nthe recent promising progress, current MOT research is still limited to a fixed\nsampling frame rate of the input stream. In fact, we empirically find that the\naccuracy of all recent state-of-the-art trackers drops dramatically when the\ninput frame rate changes. For a more intelligent tracking solution, we shift\nthe attention of our research work to the problem of Frame Rate Agnostic MOT\n(FraMOT). In this paper, we propose a Frame Rate Agnostic MOT framework with\nPeriodic training Scheme (FAPS) to tackle the FraMOT problem for the first\ntime. Specifically, we propose a Frame Rate Agnostic Association Module (FAAM)\nthat infers and encodes the frame rate information to aid identity matching\nacross multi-frame-rate inputs, improving the capability of the learned model\nin handling complex motion-appearance relations in FraMOT. Besides, the\nassociation gap between training and inference is enlarged in FraMOT because\nthose post-processing steps not included in training make a larger difference\nin lower frame rate scenarios. To address it, we propose Periodic Training\nScheme (PTS) to reflect all post-processing steps in training via tracking\npattern matching and fusion. Along with the proposed approaches, we make the\nfirst attempt to establish an evaluation method for this new task of FraMOT in\ntwo different modes, i.e., known frame rate and unknown frame rate, aiming to\nhandle a more complex situation. The quantitative experiments on the\nchallenging MOT datasets (FraMOT version) have clearly demonstrated that the\nproposed approaches can handle different frame rates better and thus improve\nthe robustness against complicated scenarios.",
    "descriptor": "\nComments: 21 pages; Author version\n",
    "authors": [
      "Weitao Feng",
      "Lei Bai",
      "Yongqiang Yao",
      "Fengwei Yu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11404"
  },
  {
    "id": "arXiv:2209.11405",
    "title": "Quantum Locally Testable Code with Exotic Parameters",
    "abstract": "In this paper, we present a few simple constructions of quantum locally\ntestable codes that achieve interesting parameters which were previously\nunknown. We introduce an operation which we give the name check product, and\nshow how this operation gives rise to quantum locally testable codes of\nconstant soundness and linear rate, with varying distance and locality.",
    "descriptor": "",
    "authors": [
      "Andrew Cross",
      "Zhiyang He",
      "Anand Natarajan",
      "Mario Szegedy",
      "Guanyu Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.11405"
  },
  {
    "id": "arXiv:2209.11407",
    "title": "IDEA: Interactive DoublE Attentions from Label Embedding for Text  Classification",
    "abstract": "Current text classification methods typically encode the text merely into\nembedding before a naive or complicated classifier, which ignores the\nsuggestive information contained in the label text. As a matter of fact, humans\nclassify documents primarily based on the semantic meaning of the\nsubcategories. We propose a novel model structure via siamese BERT and\ninteractive double attentions named IDEA ( Interactive DoublE Attentions) to\ncapture the information exchange of text and label names. Interactive double\nattentions enable the model to exploit the inter-class and intra-class\ninformation from coarse to fine, which involves distinguishing among all labels\nand matching the semantical subclasses of ground truth labels. Our proposed\nmethod outperforms the state-of-the-art methods using label texts significantly\nwith more stable results.",
    "descriptor": "\nComments: Accepted by ICTAI2022\n",
    "authors": [
      "Ziyuan Wang",
      "Hailiang Huang",
      "Songqiao Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11407"
  },
  {
    "id": "arXiv:2209.11409",
    "title": "Zero-shot Domain Adaptation for Neural Machine Translation with  Retrieved Phrase-level Prompts",
    "abstract": "Domain adaptation is an important challenge for neural machine translation.\nHowever, the traditional fine-tuning solution requires multiple extra training\nand yields a high cost. In this paper, we propose a non-tuning paradigm,\nresolving domain adaptation with a prompt-based method. Specifically, we\nconstruct a bilingual phrase-level database and retrieve relevant pairs from it\nas a prompt for the input sentences. By utilizing Retrieved Phrase-level\nPrompts (RePP), we effectively boost the translation quality. Experiments show\nthat our method improves domain-specific machine translation for 6.2 BLEU\nscores and improves translation constraints for 11.5% accuracy without\nadditional training.",
    "descriptor": "",
    "authors": [
      "Zewei Sun",
      "Qingnan Jiang",
      "Shujian Huang",
      "Jun Cao",
      "Shanbo Cheng",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11409"
  },
  {
    "id": "arXiv:2209.11414",
    "title": "Relation Embedding based Graph Neural Networks for Handling  Heterogeneous Graph",
    "abstract": "Heterogeneous graph learning has drawn significant attentions in recent\nyears, due to the success of graph neural networks (GNNs) and the broad\napplications of heterogeneous information networks. Various heterogeneous graph\nneural networks have been proposed to generalize GNNs for processing the\nheterogeneous graphs. Unfortunately, these approaches model the heterogeneity\nvia various complicated modules. This paper aims to propose a simple yet\nefficient framework to make the homogeneous GNNs have adequate ability to\nhandle heterogeneous graphs. Specifically, we propose Relation Embedding based\nGraph Neural Networks (RE-GNNs), which employ only one parameter per relation\nto embed the importance of edge type relations and self-loop connections. To\noptimize these relation embeddings and the other parameters simultaneously, a\ngradient scaling factor is proposed to constrain the embeddings to converge to\nsuitable values. Besides, we theoretically demonstrate that our RE-GNNs have\nmore expressive power than the meta-path based heterogeneous GNNs. Extensive\nexperiments on the node classification tasks validate the effectiveness of our\nproposed method.",
    "descriptor": "",
    "authors": [
      "Junfu Wang",
      "Yuanfang Guo",
      "Liang Yang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11414"
  },
  {
    "id": "arXiv:2209.11420",
    "title": "Overtwisting and Coiling Highly Enhances Strain Generation of Twisted  String Actuators",
    "abstract": "Twisted string actuators (TSAs) have exhibited great promise in robotic\napplications by generating high translational force with low input torque. To\nfurther facilitate their robotic applications, it is strongly desirable but\nchallenging to enhance their consistent strain generation while maintaining\ncompliance. Existing studies predominantly considered overtwisting and coiling\nafter the regular twisting stage to be undesirable non-uniform and\nunpredictable knots, entanglements, and coils formed to create an unstable and\nfailure-prone structure. Overtwisting would work well for TSAs when uniform\ncoils can be consistently formed. In this study, we realize uniform and\nconsistent coil formation in overtwisted TSAs, which greatly increases their\nstrain. Furthermore, we investigate methods for enabling uniform coil formation\nupon overtwisting the strings in a TSA and present a procedure to\nsystematically \"train\" the strings. To the authors' best knowledge, this is the\nfirst study to experimentally investigate overtwisting for TSAs with different\nstiffnesses and realize consistent uniform coil formation. Ultra-high\nmolecular-weight polyethylene (UHMWPE) strings form the stiff TSAs whereas\ncompliant TSAs are realized with stretchable and conductive supercoiled polymer\n(SCP) strings. The strain, force, velocity, and torque of each overtwisted TSA\nwas studied. Overtwisting and coiling resulted in approximately 70% strain in\nstiff TSAs and approximately 60% strain in compliant TSAs. This is more than\ntwice the strain achieved through regular twisting. Lastly, the overtwisted TSA\nwas successfully demonstrated in a robotic bicep.",
    "descriptor": "",
    "authors": [
      "Revanth Konda",
      "David Bombara",
      "Jun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11420"
  },
  {
    "id": "arXiv:2209.11422",
    "title": "LEADER: Learning Attention over Driving Behaviors for Planning under  Uncertainty",
    "abstract": "Uncertainty on human behaviors poses a significant challenge to autonomous\ndriving in crowded urban environments. The partially observable Markov decision\nprocesses (POMDPs) offer a principled framework for planning under uncertainty,\noften leveraging Monte Carlo sampling to achieve online performance for complex\ntasks. However, sampling also raises safety concerns by potentially missing\ncritical events. To address this, we propose a new algorithm, LEarning\nAttention over Driving bEhavioRs (LEADER), that learns to attend to critical\nhuman behaviors during planning. LEADER learns a neural network generator to\nprovide attention over human behaviors in real-time situations. It integrates\nthe attention into a belief-space planner, using importance sampling to bias\nreasoning towards critical events. To train the algorithm, we let the attention\ngenerator and the planner form a min-max game. By solving the min-max game,\nLEADER learns to perform risk-aware planning without human labeling.",
    "descriptor": "\nComments: CoRL 2022 (oral)\n",
    "authors": [
      "Mohamad H. Danesh",
      "Panpan Cai",
      "David Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11422"
  },
  {
    "id": "arXiv:2209.11425",
    "title": "RIS-Aided MIMO Systems with Hardware Impairments: Robust Beamforming  Design and Analysis",
    "abstract": "Reconfigurable intelligent surface (RIS) has been anticipated to be a novel\ncost-effective technology to improve the performance of future wireless\nsystems. In this paper, we investigate a practical RIS-aided\nmultiple-input-multiple-output (MIMO) system in the presence of transceiver\nhardware impairments, RIS phase noise and imperfect channel state information\n(CSI). Joint design of the MIMO transceiver and RIS reflection matrix to\nminimize the total average mean-square-error (MSE) of all data streams is\nparticularly considered. This joint design problem is non-convex and\nchallenging to solve due to the newly considered practical imperfections. To\ntackle the issue, we first analyze the total average MSE by incorporating the\nimpacts of the above system imperfections. Then, in order to handle the tightly\ncoupled optimization variables and non-convex NP-hard constraints, an efficient\niterative algorithm based on alternating optimization (AO) framework is\nproposed with guaranteed convergence, where each subproblem admits a\nclosed-form optimal solution by leveraging the majorization-minimization (MM)\ntechnique. Moreover, via exploiting the special structure of the unit-modulus\nconstraints, we propose a modified Riemannian gradient ascent (RGA) algorithm\nfor the discrete RIS phase shift optimization. Furthermore, the optimality of\nthe proposed algorithm is validated under line-of-sight (LoS) channel\nconditions, and the irreducible MSE floor effect induced by imperfections of\nboth hardware and CSI is also revealed in the high signal-to-noise ratio (SNR)\nregime. Numerical results show the superior MSE performance of our proposed\nalgorithm over the adopted benchmark schemes, and demonstrate that increasing\nthe number of RIS elements is not always beneficial under the above system\nimperfections.",
    "descriptor": "\nComments: 30 pages, 8 figures. This paper has been submitted to IEEE journal for possible publication\n",
    "authors": [
      "Jintao Wang",
      "Shiqi Gong",
      "Qingqing Wu",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.11425"
  },
  {
    "id": "arXiv:2209.11426",
    "title": "The Beauty of Repetition in Machine Composition Scenarios",
    "abstract": "Repetition, a basic form of artistic creation, appears in most musical works\nand delivers enthralling aesthetic experiences.",
    "descriptor": "\nComments: Published on ACM Multimedia 2022\n",
    "authors": [
      "Zhejing Hu",
      "Xiao Ma",
      "Yan Liu",
      "Gong Chen",
      "Yongxu Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11426"
  },
  {
    "id": "arXiv:2209.11427",
    "title": "A Robust and Explainable Data-Driven Anomaly Detection Approach For  Power Electronics",
    "abstract": "Timely and accurate detection of anomalies in power electronics is becoming\nincreasingly critical for maintaining complex production systems. Robust and\nexplainable strategies help decrease system downtime and preempt or mitigate\ninfrastructure cyberattacks. This work begins by explaining the types of\nuncertainty present in current datasets and machine learning algorithm outputs.\nThree techniques for combating these uncertainties are then introduced and\nanalyzed. We further present two anomaly detection and classification\napproaches, namely the Matrix Profile algorithm and anomaly transformer, which\nare applied in the context of a power electronic converter dataset.\nSpecifically, the Matrix Profile algorithm is shown to be well suited as a\ngeneralizable approach for detecting real-time anomalies in streaming\ntime-series data. The STUMPY python library implementation of the iterative\nMatrix Profile is used for the creation of the detector. A series of custom\nfilters is created and added to the detector to tune its sensitivity, recall,\nand detection accuracy. Our numerical results show that, with simple parameter\ntuning, the detector provides high accuracy and performance in a variety of\nfault scenarios.",
    "descriptor": "",
    "authors": [
      "Alexander Beattie",
      "Pavol Mulinka",
      "Subham Sahoo",
      "Ioannis T. Christou",
      "Charalampos Kalalas",
      "Daniel Gutierrez-Rojas",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11427"
  },
  {
    "id": "arXiv:2209.11429",
    "title": "News Category Dataset",
    "abstract": "People rely on news to know what is happening around the world and inform\ntheir daily lives. In today's world, when the proliferation of fake news is\nrampant, having a large-scale and high-quality source of authentic news\narticles with the published category information is valuable to learning\nauthentic news' Natural Language syntax and semantics. As part of this work, we\npresent a News Category Dataset that contains around 200k news headlines from\nthe year 2012 to 2018 obtained from HuffPost, along with useful metadata to\nenable various NLP tasks. In this paper, we also produce some novel insights\nfrom the dataset and describe various existing and potential applications of\nour dataset.",
    "descriptor": "",
    "authors": [
      "Rishabh Misra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11429"
  },
  {
    "id": "arXiv:2209.11432",
    "title": "Automatic Sign Reading and Localization for Semantic Mapping with an  Office Robot",
    "abstract": "Semantic mapping is the task of providing a robot with a map of its\nenvironment beyond the open, navigable space of traditional Simultaneous\nLocalization and Mapping (SLAM) algorithms by attaching semantics to locations.\nThe system presented in this work reads door placards to annotate the locations\nof offices. Whereas prior work on this system developed hand-crafted detectors,\nthis system leverages YOLOv5 for sign detection and EAST for text recognition.\nPlacards are localized by computing their pose from a point cloud in a RGB-D\ncamera frame localized by a modified ORB-SLAM. Semantic mapping is accomplished\nin a post-processing step after robot exploration from video recording. System\nperformance is reported in terms of the number of placards identified, the\naccuracy of their placement onto a SLAM map, the accuracy of the map built, and\nthe correctness transcribed placard text.",
    "descriptor": "",
    "authors": [
      "David Balaban",
      "Justin Hart"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11432"
  },
  {
    "id": "arXiv:2209.11436",
    "title": "Understanding Open-Set Recognition by Jacobian Norm of Representation",
    "abstract": "In contrast to conventional closed-set recognition, open-set recognition\n(OSR) assumes the presence of an unknown class, which is not seen to a model\nduring training. One predominant approach in OSR is metric learning, where a\nmodel is trained to separate the inter-class representations of known class\ndata. Numerous works in OSR reported that, even though the models are trained\nonly with the known class data, the models become aware of the unknown, and\nlearn to separate the unknown class representations from the known class\nrepresentations. This paper analyzes this emergent phenomenon by observing the\nJacobian norm of representation. We theoretically show that minimizing the\nintra-class distances within the known set reduces the Jacobian norm of known\nclass representations while maximizing the inter-class distances within the\nknown set increases the Jacobian norm of the unknown class. The closed-set\nmetric learning thus separates the unknown from the known by forcing their\nJacobian norm values to differ. We empirically validate our theoretical\nframework with ample pieces of evidence using standard OSR datasets. Moreover,\nunder our theoretical framework, we explain how the standard deep learning\ntechniques can be helpful for OSR and use the framework as a guiding principle\nto develop an effective OSR model.",
    "descriptor": "",
    "authors": [
      "Jaewoo Park",
      "Hojin Park",
      "Eunju Jeong",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11436"
  },
  {
    "id": "arXiv:2209.11448",
    "title": "Rethinking Performance Gains in Image Dehazing Networks",
    "abstract": "Image dehazing is an active topic in low-level vision, and many image\ndehazing networks have been proposed with the rapid development of deep\nlearning. Although these networks' pipelines work fine, the key mechanism to\nimproving image dehazing performance remains unclear. For this reason, we do\nnot target to propose a dehazing network with fancy modules; rather, we make\nminimal modifications to popular U-Net to obtain a compact dehazing network.\nSpecifically, we swap out the convolutional blocks in U-Net for residual blocks\nwith the gating mechanism, fuse the feature maps of main paths and skip\nconnections using the selective kernel, and call the resulting U-Net variant\ngUNet. As a result, with a significantly reduced overhead, gUNet is superior to\nstate-of-the-art methods on multiple image dehazing datasets. Finally, we\nverify these key designs to the performance gain of image dehazing networks\nthrough extensive ablation studies.",
    "descriptor": "",
    "authors": [
      "Yuda Song",
      "Yang Zhou",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11448"
  },
  {
    "id": "arXiv:2209.11449",
    "title": "Motion Guided Deep Dynamic 3D Garments",
    "abstract": "Realistic dynamic garments on animated characters have many AR/VR\napplications. While authoring such dynamic garment geometry is still a\nchallenging task, data-driven simulation provides an attractive alternative,\nespecially if it can be controlled simply using the motion of the underlying\ncharacter. In this work, we focus on motion guided dynamic 3D garments,\nespecially for loose garments. In a data-driven setup, we first learn a\ngenerative space of plausible garment geometries. Then, we learn a mapping to\nthis space to capture the motion dependent dynamic deformations, conditioned on\nthe previous state of the garment as well as its relative position with respect\nto the underlying body. Technically, we model garment dynamics, driven using\nthe input character motion, by predicting per-frame local displacements in a\ncanonical state of the garment that is enriched with frame-dependent skinning\nweights to bring the garment to the global space. We resolve any remaining\nper-frame collisions by predicting residual local displacements. The resultant\ngarment geometry is used as history to enable iterative rollout prediction. We\ndemonstrate plausible generalization to unseen body shapes and motion inputs,\nand show improvements over multiple state-of-the-art alternatives.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Meng Zhang",
      "Duygu Ceylan",
      "Niloy J. Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2209.11449"
  },
  {
    "id": "arXiv:2209.11450",
    "title": "A Second-Order TGV Discretization with Some Invariance Properties",
    "abstract": "In this work, we propose a new discretization for second-order total\ngeneralized variation (TGV) with some distinct properties compared to existing\ndiscrete formulations. The introduced model is based on same design principles\nas Condat's discrete total variation model ({SIAM J. Imaging Sci}., 10(3),\n1258--1290, 2017) and shares its benefits, in particular, improved quality for\nthe solution of imaging problems. An algorithm for image denoising with\nsecond-order TGV using the new discretization is proposed. Numerical results\nobtained with this algorithm demonstrate the discretization's advantages.\nMoreover, in order to compare invariance properties of the new model, an\nalgorithm for calculating the TGV value with respect to the new discretization\nmodel is given.",
    "descriptor": "\nComments: 25 pages, 8 Figures, full research paper\n",
    "authors": [
      "Alireza Hosseini",
      "Kristian Bredies"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11450"
  },
  {
    "id": "arXiv:2209.11451",
    "title": "Towards Auditing the Sensitive Information Leakage During Data Trading  and Data Computing",
    "abstract": "Data markets enable users to own their data and trade their data for profits.\nExisting data market designs allow these data owners to directly sell or\nprovide computation services on their private data in a secure and\nprivacy-preserving way. However, an important problem that is neglected in\nprevious work is that the transferred data or computation results over the data\ncan leak information about other sensitive features that are not involved in\nthe data market. To tackle this problem, we propose an auditing system based on\nsmart contracts and zero-knowledge proof to measure and manage the sensitive\ninformation leakage risk in Web3 data markets. Primary results on the\ninformation leakage estimation show that even a small percent of information\nleakage can lead to significant predictability by simple machine learning\nmodels.",
    "descriptor": "\nComments: 7 pages, 2 figures, initial submission\n",
    "authors": [
      "Shuhao Zheng",
      "Yanxi Lin",
      "Yang Yu",
      "Ye Yuan",
      "Yongzheng Jia",
      "Xue Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11451"
  },
  {
    "id": "arXiv:2209.11453",
    "title": "A Preliminary Investigation of MLOps Practices in GitHub",
    "abstract": "Background. The rapid and growing popularity of machine learning (ML)\napplications has led to an increasing interest in MLOps, that is, the practice\nof continuous integration and deployment (CI/CD) of ML-enabled systems. Aims.\nSince changes may affect not only the code but also the ML model parameters and\nthe data themselves, the automation of traditional CI/CD needs to be extended\nto manage model retraining in production. Method. In this paper, we present an\ninitial investigation of the MLOps practices implemented in a set of ML-enabled\nsystems retrieved from GitHub, focusing on GitHub Actions and CML, two\nsolutions to automate the development workflow. Results. Our preliminary\nresults suggest that the adoption of MLOps workflows in open-source GitHub\nprojects is currently rather limited. Conclusions. Issues are also identified,\nwhich can guide future research work.",
    "descriptor": "\nComments: Presented at ESEM '22, the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement\n",
    "authors": [
      "Fabio Calefato",
      "Filippo Lanubile",
      "Luigi Quaranta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11453"
  },
  {
    "id": "arXiv:2209.11459",
    "title": "TeST: Test-time Self-Training under Distribution Shift",
    "abstract": "Despite their recent success, deep neural networks continue to perform poorly\nwhen they encounter distribution shifts at test time. Many recently proposed\napproaches try to counter this by aligning the model to the new distribution\nprior to inference. With no labels available this requires unsupervised\nobjectives to adapt the model on the observed test data. In this paper, we\npropose Test-Time Self-Training (TeST): a technique that takes as input a model\ntrained on some source data and a novel data distribution at test time, and\nlearns invariant and robust representations using a student-teacher framework.\nWe find that models adapted using TeST significantly improve over baseline\ntest-time adaptation algorithms. TeST achieves competitive performance to\nmodern domain adaptation algorithms, while having access to 5-10x less data at\ntime of adaption. We thoroughly evaluate a variety of baselines on two tasks:\nobject detection and image segmentation and find that models adapted with TeST.\nWe find that TeST sets the new state-of-the art for test-time domain adaptation\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Peter Gehler",
      "Francesco Locatello",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11459"
  },
  {
    "id": "arXiv:2209.11461",
    "title": "Spatio-Temporal Contrastive Learning Enhanced GNNs for Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) systems aim to utilize the user's\nshort-term behavior sequence to predict the next item without the detailed user\nprofile. Most recent works try to model the user preference by treating the\nsessions as between-item transition graphs and utilize various graph neural\nnetworks (GNNs) to encode the representations of pair-wise relations among\nitems and their neighbors. Some of the existing GNN-based models mainly focus\non aggregating information from the view of spatial graph structure, which\nignores the temporal relations within neighbors of an item during message\npassing and the information loss results in a sub-optimal problem. Other works\nembrace this challenge by incorporating additional temporal information but\nlack sufficient interaction between the spatial and temporal patterns. To\naddress this issue, inspired by the uniformity and alignment properties of\ncontrastive learning techniques, we propose a novel framework called\nSession-based Recommendation with Spatio-Temporal Contrastive Learning Enhanced\nGNNs (RESTC). The idea is to supplement the GNN-based main supervised\nrecommendation task with the temporal representation via an auxiliary\ncross-view contrastive learning mechanism. Furthermore, a novel global\ncollaborative filtering graph (CFG) embedding is leveraged to enhance the\nspatial view in the main task. Extensive experiments demonstrate the\nsignificant performance of RESTC compared with the state-of-the-art baselines\ne.g., with an improvement as much as 27.08% gain on HR@20 and 20.10% gain on\nMRR@20.",
    "descriptor": "\nComments: Under reviewing draft of IEEE TKDE\n",
    "authors": [
      "Zhongwei Wan",
      "Benyou Wang",
      "Xin Liu",
      "Jiezhong Qiu",
      "Boyu Li",
      "Ting Guo",
      "Guangyong Chen",
      "Yang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.11461"
  },
  {
    "id": "arXiv:2209.11462",
    "title": "A New Communication Paradigm in Wiretap Channels: Simultaneous  Information Transmission and Cooperative Jamming",
    "abstract": "This paper considers a Gaussian vector wiretap channel with two users, where\nuser $1$ is secrecy-sensitive and transmits both secret and open\n(non-confidential) messages, and user $2$ is secrecy non-sensitive and\ntransmits only open messages. We provide an achievable rate region and show\nthat by introducing `garbage' messages and applying random coding, simultaneous\ninformation transmission and cooperative jamming (SIT-CJ) can be achieved,\ni.e., user $2$ can transmit useful information to the legitimate receiver and\nat the same time act as a friendly jammer for user $1$. To evaluate the\nperformance of SIT-CJ, we maximize the secrecy rate and compare with the\nNo-jamming case, where there is only user $1$, and also the Gaussian noise (GN)\njamming scheme, where user $2$ jams by transmitting Gaussian noise. For the\nSIMO case, we prove that though non-convex, the power control problems for all\njamming schemes can be optimally solved. Things are much more complicated in\nthe MIMO case. However, we show that by using matrix simultaneous\ndiagonalization, all precoder design problems can be efficiently solved with a\nlow complexity. Simulation results show that the proposed SIT-CJ scheme can\nhelp greatly enhance the secrecy of user $1$, and outperforms the GN-jamming\nscheme in secrecy improvement. Moreover, since besides confidential\ninformation, all users transmit open messages, the system's spectral efficiency\ncan be dramatically increased by SIT-CJ compared with the GN-jamming scheme and\nalso the case where only secret messages of user $1$ are considered.",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Hao Xu",
      "Kai-Kit Wong",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11462"
  },
  {
    "id": "arXiv:2209.11464",
    "title": "Smart Active Sampling to enhance Quality Assurance Efficiency",
    "abstract": "We propose a new sampling strategy, called smart active sapling, for quality\ninspections outside the production line. Based on the principles of active\nlearning a machine learning model decides which samples are sent to quality\ninspection. On the one hand, this minimizes the production of scrap parts due\nto earlier detection of quality violations. On the other hand, quality\ninspection costs are reduced for smooth operation.",
    "descriptor": "",
    "authors": [
      "Clemens Heistracher",
      "Stefan Stricker",
      "Pedro Casas",
      "Daniel Schall",
      "Jana Kemnitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11464"
  },
  {
    "id": "arXiv:2209.11468",
    "title": "Exponential Convergence of hp FEM for the Integral Fractional Laplacian  in Polygons",
    "abstract": "We prove exponential convergence in the energy norm of $hp$ finite element\ndiscretizations for the integral fractional diffusion operator of order $2s\\in\n(0,2)$ subject to homogeneous Dirichlet boundary conditions in bounded\npolygonal domains $\\Omega\\subset \\mathbb{R}^2$. Key ingredient in the analysis\nare the weighted analytic regularity from our previous work and meshes that\nfeature anisotropic geometric refinement towards $\\partial\\Omega$.",
    "descriptor": "",
    "authors": [
      "Markus Faustmann",
      "Carlo Marcati",
      "Jens Markus Melenk",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11468"
  },
  {
    "id": "arXiv:2209.11469",
    "title": "Optimizing Class Distribution in Memory for Multi-Label Online Continual  Learning",
    "abstract": "Online continual learning, especially when task identities and task\nboundaries are unavailable, is a challenging continual learning setting. One\nrepresentative kind of methods for online continual learning is replay-based\nmethods, in which a replay buffer called memory is maintained to keep a small\npart of past samples for overcoming catastrophic forgetting. When tackling with\nonline continual learning, most existing replay-based methods focus on\nsingle-label problems in which each sample in the data stream has only one\nlabel. But multi-label problems may also happen in the online continual\nlearning setting in which each sample may have more than one label. In the\nonline setting with multi-label samples, the class distribution in data stream\nis typically highly imbalanced, and it is challenging to control class\ndistribution in memory since changing the number of samples belonging to one\nclass may affect the number of samples belonging to other classes. But class\ndistribution in memory is critical for replay-based memory to get good\nperformance, especially when the class distribution in data stream is highly\nimbalanced. In this paper, we propose a simple but effective method, called\noptimizing class distribution in memory (OCDM), for multi-label online\ncontinual learning. OCDM formulates the memory update mechanism as an\noptimization problem and updates the memory by solving this problem.\nExperiments on two widely used multi-label datasets show that OCDM can control\nthe class distribution in memory well and can outperform other state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Yan-Shuo Liang",
      "Wu-Jun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11469"
  },
  {
    "id": "arXiv:2209.11471",
    "title": "Modeling and Leveraging Prerequisite Context in Recommendation",
    "abstract": "Prerequisites can play a crucial role in users' decision-making yet\nrecommendation systems have not fully utilized such contextual background\nknowledge. Traditional recommendation systems (RS) mostly enrich user-item\ninteractions where the context consists of static user profiles and item\ndescriptions, ignoring the contextual logic and constraints that underlie them.\nFor example, an RS may recommend an item on the condition that the user has\ninteracted with another item as its prerequisite. Modeling prerequisite context\nfrom conceptual side information can overcome this weakness. We propose\nPrerequisite Driven Recommendation (PDR), a generic context-aware framework\nwhere prerequisite context is explicitly modeled to facilitate recommendation.\nWe first design a Prerequisite Knowledge Linking (PKL) algorithm, to curate\ndatasets facilitating PDR research. Employing it, we build a 75k+ high-quality\nprerequisite concept dataset which spans three domains. We then contribute\nPDRS, a neural instantiation of PDR. By jointly optimizing both the\nprerequisite learning and recommendation tasks through multi-layer perceptrons,\nwe find PDRS consistently outperforms baseline models in all three domains, by\nan average margin of 7.41%. Importantly, PDRS performs especially well in\ncold-start scenarios with improvements of up to 17.65%.",
    "descriptor": "\nComments: Accepted by CARS@RecSys'22\n",
    "authors": [
      "Hengchang Hu",
      "Liangming Pan",
      "Yiding Ran",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.11471"
  },
  {
    "id": "arXiv:2209.11475",
    "title": "Unsupervised Hashing with Semantic Concept Mining",
    "abstract": "Recently, to improve the unsupervised image retrieval performance, plenty of\nunsupervised hashing methods have been proposed by designing a semantic\nsimilarity matrix, which is based on the similarities between image features\nextracted by a pre-trained CNN model. However, most of these methods tend to\nignore high-level abstract semantic concepts contained in images. Intuitively,\nconcepts play an important role in calculating the similarity among images. In\nreal-world scenarios, each image is associated with some concepts, and the\nsimilarity between two images will be larger if they share more identical\nconcepts. Inspired by the above intuition, in this work, we propose a novel\nUnsupervised Hashing with Semantic Concept Mining, called UHSCM, which\nleverages a VLP model to construct a high-quality similarity matrix.\nSpecifically, a set of randomly chosen concepts is first collected. Then, by\nemploying a vision-language pretraining (VLP) model with the prompt engineering\nwhich has shown strong power in visual representation learning, the set of\nconcepts is denoised according to the training images. Next, the proposed\nmethod UHSCM applies the VLP model with prompting again to mine the concept\ndistribution of each image and construct a high-quality semantic similarity\nmatrix based on the mined concept distributions. Finally, with the semantic\nsimilarity matrix as guiding information, a novel hashing loss with a modified\ncontrastive loss based regularization item is proposed to optimize the hashing\nnetwork. Extensive experiments on three benchmark datasets show that the\nproposed method outperforms the state-of-the-art baselines in the image\nretrieval task.",
    "descriptor": "",
    "authors": [
      "Rong-Cheng Tu",
      "Xian-Ling Mao",
      "Kevin Qinghong Lin",
      "Chengfei Cai",
      "Weize Qin",
      "Hongfa Wang",
      "Wei Wei",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.11475"
  },
  {
    "id": "arXiv:2209.11477",
    "title": "Weakly Supervised Two-Stage Training Scheme for Deep Video Fight  Detection Model",
    "abstract": "Fight detection in videos is an emerging deep learning application with\ntoday's prevalence of surveillance systems and streaming media. Previous work\nhas largely relied on action recognition techniques to tackle this problem. In\nthis paper, we propose a simple but effective method that solves the task from\na new perspective: we design the fight detection model as a composition of an\naction-aware feature extractor and an anomaly score generator. Also,\nconsidering that collecting frame-level labels for videos is too laborious, we\ndesign a weakly supervised two-stage training scheme, where we utilize\nmultiple-instance-learning loss calculated on video-level labels to train the\nscore generator, and adopt the self-training technique to further improve its\nperformance. Extensive experiments on a publicly available large-scale dataset,\nUBI-Fights, demonstrate the effectiveness of our method, and the performance on\nthe dataset exceeds several previous state-of-the-art approaches. Furthermore,\nwe collect a new dataset, VFD-2000, that specializes in video fight detection,\nwith a larger scale and more scenarios than existing datasets. The\nimplementation of our method and the proposed dataset will be publicly\navailable at https://github.com/Hepta-Col/VideoFightDetection.",
    "descriptor": "\nComments: Accepted by ICTAI 2022\n",
    "authors": [
      "Zhenting Qi",
      "Ruike Zhu",
      "Zheyu Fu",
      "Wenhao Chai",
      "Volodymyr Kindratenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11477"
  },
  {
    "id": "arXiv:2209.11478",
    "title": "Combining Motion Matching and Orientation Prediction to Animate Avatars  for Consumer-Grade VR Devices",
    "abstract": "The animation of user avatars plays a crucial role in conveying their pose,\ngestures, and relative distances to virtual objects or other users. Self-avatar\nanimation in immersive VR helps improve the user experience and provides a\nSense of Embodiment. However, consumer-grade VR devices typically include at\nmost three trackers, one at the Head Mounted Display (HMD), and two at the\nhandheld VR controllers. Since the problem of reconstruction the user pose from\nsuch sparse data is ill-defined, especially for the lower body, the approach\nadopted by most VR games consists of assuming the body orientation matches that\nof the HMD, and applying animation blending and time-warping from a reduced set\nof animations. Unfortunately, this approach produces noticeable mismatches\nbetween user and avatar movements. In this work we present a new approach to\nanimate user avatars that is suitable for current mainstream VR devices. First,\nwe use a neural network to estimate the user's body orientation based on the\ntracking information from the HMD and the hand controllers. Then we use this\norientation together with the velocity and rotation of the HMD to build a\nfeature vector that feeds a Motion Matching algorithm. We built a MoCap\ndatabase with animations of VR users wearing a HMD and used it to test our\napproach on both self-avatars and other users' avatars. Our results show that\nour system can provide a large variety of lower body animations while correctly\nmatching the user orientation, which in turn allows us to represent not only\nforward movements but also stepping in any direction.",
    "descriptor": "\nComments: Project Website: this https URL\n",
    "authors": [
      "Jose Luis Ponton",
      "Haoran Yun",
      "Carlos Andujar",
      "Nuria Pelechano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2209.11478"
  },
  {
    "id": "arXiv:2209.11481",
    "title": "Active Few-Shot Classification: a New Paradigm for Data-Scarce Learning  Settings",
    "abstract": "We consider a novel formulation of the problem of Active Few-Shot\nClassification (AFSC) where the objective is to classify a small, initially\nunlabeled, dataset given a very restrained labeling budget. This problem can be\nseen as a rival paradigm to classical Transductive Few-Shot Classification\n(TFSC), as both these approaches are applicable in similar conditions. We first\npropose a methodology that combines statistical inference, and an original\ntwo-tier active learning strategy that fits well into this framework. We then\nadapt several standard vision benchmarks from the field of TFSC. Our\nexperiments show the potential benefits of AFSC can be substantial, with gains\nin average weighted accuracy of up to 10% compared to state-of-the-art TFSC\nmethods for the same labeling budget. We believe this new paradigm could lead\nto new developments and standards in data-scarce learning settings.",
    "descriptor": "",
    "authors": [
      "Aymane Abdali",
      "Vincent Gripon",
      "Lucas Drumetz",
      "Bartosz Boguslawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11481"
  },
  {
    "id": "arXiv:2209.11482",
    "title": "AvatarGo: Plug and Play self-avatars for VR",
    "abstract": "The use of self-avatars in a VR application can enhance presence and\nembodiment which leads to a better user experience. In collaborative VR it also\nfacilitates non-verbal communication. Currently it is possible to track a few\nbody parts with cheap trackers and then apply IK methods to animate a\ncharacter. However, the correspondence between trackers and avatar joints is\ntypically fixed ad-hoc, which is enough to animate the avatar, but causes\nnoticeable mismatches between the user's body pose and the avatar. In this\npaper we present a fast and easy to set up system to compute exact offset\nvalues, unique for each user, which leads to improvements in avatar movement.\nOur user study shows that the Sense of Embodiment increased significantly when\nusing exact offsets as opposed to fixed ones. We also allowed the users to see\na semitransparent avatar overlaid with their real body to objectively evaluate\nthe quality of the avatar movement with our technique.",
    "descriptor": "\nComments: GitHub: this https URL\n",
    "authors": [
      "Jose Luis Ponton",
      "Eva Monclus",
      "Nuria Pelechano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2209.11482"
  },
  {
    "id": "arXiv:2209.11484",
    "title": "ET5: A Novel End-to-end Framework for Conversational Machine Reading  Comprehension",
    "abstract": "Conversational machine reading comprehension (CMRC) aims to assist computers\nto understand an natural language text and thereafter engage in a multi-turn\nconversation to answer questions related to the text. Existing methods\ntypically require three steps: (1) decision making based on entailment\nreasoning; (2) span extraction if required by the above decision; (3) question\nrephrasing based on the extracted span. However, for nearly all these methods,\nthe span extraction and question rephrasing steps cannot fully exploit the\nfine-grained entailment reasoning information in decision making step because\nof their relative independence, which will further enlarge the information gap\nbetween decision making and question phrasing. Thus, to tackle this problem, we\npropose a novel end-to-end framework for conversational machine reading\ncomprehension based on shared parameter mechanism, called entailment reasoning\nT5 (ET5). Despite the lightweight of our proposed framework, experimental\nresults show that the proposed ET5 achieves new state-of-the-art results on the\nShARC leaderboard with the BLEU-4 score of 55.2. Our model and code are\npublicly available at https://github.com/Yottaxx/ET5.",
    "descriptor": "\nComments: Accepted by COLING2022\n",
    "authors": [
      "Xiao Zhang",
      "Heyan Huang",
      "Zewen Chi",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11484"
  },
  {
    "id": "arXiv:2209.11485",
    "title": "Optimal Job Scheduling and Bandwidth Augmentation in Hybrid Data Center  Networks",
    "abstract": "Optimizing data transfers is critical for improving job performance in\ndata-parallel frameworks. In the hybrid data center with both wired and\nwireless links, reconfigurable wireless links can provide additional bandwidth\nto speed up job execution. However, it requires the scheduler and transceivers\nto make joint decisions under coupled constraints. In this work, we identify\nthat the joint job scheduling and bandwidth augmentation problem is a complex\nmixed integer nonlinear problem, which is not solvable by existing optimization\nmethods. To address this bottleneck, we transform it into an equivalent problem\nbased on the coupling of its heuristic bounds, the revised data transfer\nrepresentation and non-linear constraints decoupling and reformulation, such\nthat the optimal solution can be efficiently acquired by the Branch and Bound\nmethod. Based on the proposed method, the performance of job scheduling with\nand without bandwidth augmentation is studied. Experiments show that the\nperformance gain depends on multiple factors, especially the data size.\nCompared with existing solutions, our method can averagely reduce the job\ncompletion time by up to 10% under the setting of production scenario.",
    "descriptor": "\nComments: Accepted to appear in IEEE GLOBECOM 2022\n",
    "authors": [
      "Binquan Guo",
      "Zhou Zhang",
      "Ye Yan",
      "Hongyan Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.11485"
  },
  {
    "id": "arXiv:2209.11486",
    "title": "MetaPrompting: Learning to Learn Better Prompts",
    "abstract": "Prompting method is regarded as one of the crucial progress for few-shot\nnature language processing. Recent research on prompting moves from discrete\ntokens based ``hard prompts'' to continuous ``soft prompts'', which employ\nlearnable vectors as pseudo prompt tokens and achieve better performance.\nThough showing promising prospects, these soft-prompting methods are observed\nto rely heavily on good initialization to take effect. Unfortunately, obtaining\na perfect initialization for soft prompts requires understanding of inner\nlanguage models working and elaborate design, which is no easy task and has to\nrestart from scratch for each new task. To remedy this, we propose a\ngeneralized soft prompting method called MetaPrompting, which adopts the\nwell-recognized model-agnostic meta-learning algorithm to automatically find\nbetter prompt initialization that facilitates fast adaptation to new prompting\ntasks.Extensive experiments show MetaPrompting tackles soft prompt\ninitialization problem and brings significant improvement on four different\ndatasets (over 6 points improvement in accuracy for 1-shot setting), achieving\nnew state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Yutai Hou",
      "Hongyuan Dong",
      "Xinghao Wang",
      "Bohan Li",
      "Wanxiang Che"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11486"
  },
  {
    "id": "arXiv:2209.11488",
    "title": "GIDP: Learning a Good Initialization and Inducing Descriptor  Post-enhancing for Large-scale Place Recognition",
    "abstract": "Large-scale place recognition is a fundamental but challenging task, which\nplays an increasingly important role in autonomous driving and robotics.\nExisting methods have achieved acceptable good performance, however, most of\nthem are concentrating on designing elaborate global descriptor learning\nnetwork structures. The importance of feature generalization and descriptor\npost-enhancing has long been neglected. In this work, we propose a novel method\nnamed GIDP to learn a Good Initialization and Inducing Descriptor Poseenhancing\nfor Large-scale Place Recognition. In particular, an unsupervised momentum\ncontrast point cloud pretraining module and a reranking-based descriptor\npost-enhancing module are proposed respectively in GIDP. The former aims at\nlearning a good initialization for the point cloud encoding network before\ntraining the place recognition model, while the later aims at post-enhancing\nthe predicted global descriptor through reranking at inference time. Extensive\nexperiments on both indoor and outdoor datasets demonstrate that our method can\nachieve state-of-the-art performance using simple and general point cloud\nencoding backbones.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Zhaoxin Fan",
      "Zhenbo Song",
      "Hongyan Liu",
      "Jun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11488"
  },
  {
    "id": "arXiv:2209.11489",
    "title": "Social Robot Scenarios for Real-World Child and Family Care Settings  through Participatory Design",
    "abstract": "This paper discusses a 5-year PhD project, focused upon the implementation of\nsocial robots for general child and family care settings in the Netherlands.\nThe project is a collaboration with general Dutch family care organisations as\nwell as specialized child mental health care organisations. The project adapts\na bottom-up, participatory design approach, where end users are included in all\nstages of the project. End users consist of children, parents, and family care\nprofessionals, who all have different needs, regarding the social robot\nbehaviors as well as the participatory design methods. This paper provides\nsuggestions to deal with these differences in designing social robots for child\nmental support in real-world settings.",
    "descriptor": "",
    "authors": [
      "Anouk Neerincx"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11489"
  },
  {
    "id": "arXiv:2209.11492",
    "title": "Grouped Adaptive Loss Weighting for Person Search",
    "abstract": "Person search is an integrated task of multiple sub-tasks such as\nforeground/background classification, bounding box regression and person\nre-identification. Therefore, person search is a typical multi-task learning\nproblem, especially when solved in an end-to-end manner. Recently, some works\nenhance person search features by exploiting various auxiliary information,\ne.g. person joint keypoints, body part position, attributes, etc., which brings\nin more tasks and further complexifies a person search model. The inconsistent\nconvergence rate of each task could potentially harm the model optimization. A\nstraightforward solution is to manually assign different weights to different\ntasks, compensating for the diverse convergence rates. However, given the\nspecial case of person search, i.e. with a large number of tasks, it is\nimpractical to weight the tasks manually. To this end, we propose a Grouped\nAdaptive Loss Weighting (GALW) method which adjusts the weight of each task\nautomatically and dynamically. Specifically, we group tasks according to their\nconvergence rates. Tasks within the same group share the same learnable weight,\nwhich is dynamically assigned by considering the loss uncertainty. Experimental\nresults on two typical benchmarks, CUHK-SYSU and PRW, demonstrate the\neffectiveness of our method.",
    "descriptor": "\nComments: Accepted by ACM MM\n",
    "authors": [
      "Yanling Tian",
      "Di Chen",
      "Yunan Liu",
      "Shanshan Zhang",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11492"
  },
  {
    "id": "arXiv:2209.11493",
    "title": "Comparison of synthetic dataset generation methods for medical  intervention rooms using medical clothing detection as an example",
    "abstract": "The availability of real data from areas with high privacy requirements, such\nas the medical intervention space, is low and the acquisition legally complex.\nTherefore, this work presents a way to create a synthetic dataset for the\nmedical context, using medical clothing as an example. The goal is to close the\nreality gap between the synthetic and real data. For this purpose, methods of\n3D-scanned clothing and designed clothing are compared in a\nDomain-Randomization and Structured-Domain-Randomization scenario using an\nUnreal-Engine plugin or Unity. Additionally a Mixed-Reality dataset in front of\na greenscreen and a target domain dataset were used. Our experiments show, that\nStructured-Domain-Randomization of designed clothing together with\nMixed-Reality data provide a baseline achieving 72.0% mAP on a test dataset of\nthe clinical target domain. When additionally using 15% of available target\ndomain train data, the gap towards 100% (660 images) target domain train data\ncould be nearly closed 80.05% mAP (81.95% mAP). Finally we show that when\nadditionally using 100% target domain train data the accuracy could be\nincreased to 83.35% mAP.",
    "descriptor": "",
    "authors": [
      "Patrick Sch\u00fclein",
      "Hannah Teufel",
      "Ronja Vorpahl",
      "Indira Emter",
      "Yannick Bukschat",
      "Marcus Pfister",
      "Anke Siebert",
      "Nils Rathmann",
      "Steffen Diehl",
      "Marcus Vetter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11493"
  },
  {
    "id": "arXiv:2209.11497",
    "title": "Sequential Causal Effect Variational Autoencoder: Time Series Causal  Link Estimation under Hidden Confounding",
    "abstract": "Estimating causal effects from observational data in the presence of latent\nvariables sometimes leads to spurious relationships which can be misconceived\nas causal. This is an important issue in many fields such as finance and\nclimate science. We propose Sequential Causal Effect Variational Autoencoder\n(SCEVAE), a novel method for time series causality analysis under hidden\nconfounding. It is based on the CEVAE framework and recurrent neural networks.\nThe causal link's intensity of the confounded variables is calculated by using\ndirect causal criteria based on Pearl's do-calculus. We show the efficacy of\nSCEVAE by applying it to synthetic datasets with both linear and nonlinear\ncausal links. Furthermore, we apply our method to real aerosol-cloud-climate\nobservation data. We compare our approach to a time series deconfounding method\nwith and without substitute confounders on the synthetic data. We demonstrate\nthat our method performs better by comparing both methods to the ground truth.\nIn the case of real data, we use the expert knowledge of causal links and show\nhow the use of correct proxy variables aids data reconstruction.",
    "descriptor": "",
    "authors": [
      "Violeta Teodora Trifunov",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.11497"
  },
  {
    "id": "arXiv:2209.11500",
    "title": "Reactive Anticipatory Robot Skills with Memory",
    "abstract": "Optimal control in robotics has been increasingly popular in recent years and\nhas been applied in many applications involving complex dynamical systems.\nClosed-loop optimal control strategies include model predictive control (MPC)\nand time-varying linear controllers optimized through iLQR. However, such\nfeedback controllers rely on the information of the current state, limiting the\nrange of robotic applications where the robot needs to remember what it has\ndone before to act and plan accordingly. The recently proposed system level\nsynthesis (SLS) framework circumvents this limitation via a richer controller\nstructure with memory. In this work, we propose to optimally design reactive\nanticipatory robot skills with memory by extending SLS to tracking problems\ninvolving nonlinear systems and nonquadratic cost functions. We showcase our\nmethod with two scenarios exploiting task precisions and object affordances in\npick-and-place tasks in a simulated and a real environment with a 7-axis Franka\nEmika robot.",
    "descriptor": "",
    "authors": [
      "Hakan Girgin",
      "Julius Jankowski",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11500"
  },
  {
    "id": "arXiv:2209.11501",
    "title": "Outage Performance Analysis of HARQ-Aided Multi-RIS Systems",
    "abstract": "Reconfigurable intelligent surface (RIS) has recently attracted a spurt of\ninterest due to its innate advantages over Massive MIMO on power consumption.\nIn this paper, we study the outage performance of multi-RIS system with the\nhelp of hybrid automatic repeat request (HARQ) to improve the RIS system\nreliability, where the destination received channels are modeled by Rician\nfading and the phase shift setting only depends on the line-of-sight (LoS)\ncomponent. Both the exact and asymptotic outage probabilities under Type-I HARQ\nand HARQ with chase combining (HARQ-CC) schemes are derived. Particulary, the\ntractable asymptotic results empower us to derive meaningful insights for\nHARQ-aided multi-RIS system. On the one hand, we find that both the Type-I and\nthe HARQ-CC schemes can achieve full diversity that is equal to the maximal\nnumber of HARQ rounds. On the other hand, the closed-form expression of the\noptimal phase shift setting with respect to outage probability minimization is\nobtained. The optimal solution indicates that the reflecting link direction\nshould be consistent with direct link LoS component. Finally, the analytical\nresults are validated by Monte-Carlo simulations.",
    "descriptor": "",
    "authors": [
      "Qi Cao",
      "Huan Zhang",
      "Zheng Shi",
      "Hong Wang",
      "Yaru Fu",
      "Guanghua Yang",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11501"
  },
  {
    "id": "arXiv:2209.11504",
    "title": "Feedforward Control in the Presence of Input Nonlinearities: A  Learning-based Approach",
    "abstract": "Advanced feedforward control methods enable mechatronic systems to perform\nvarying motion tasks with extreme accuracy and throughput. The aim of this\npaper is to develop a data-driven feedforward controller that addresses input\nnonlinearities, which are common in typical applications such as semiconductor\nback-end equipment. The developed method consists of parametric inverse-model\nfeedforward that is optimized for tracking error reduction by exploiting ideas\nfrom iterative learning control. Results on a simulated set-up indicate\nimproved performance over existing identification methods for systems with\nnonlinearities at the input.",
    "descriptor": "\nComments: 6 pages, 8 figures, to be presented at Modeling Estimation and Control Conference 2022 in Jersey City, NJ, to be published in IFAC-PapersOnLine\n",
    "authors": [
      "Jilles van Hulst",
      "Maurice Poot",
      "Dragan Kosti\u0107",
      "Kai Wa Yan",
      "Jim Portegies",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11504"
  },
  {
    "id": "arXiv:2209.11505",
    "title": "The complexity of unsupervised learning of lexicographic preferences",
    "abstract": "This paper considers the task of learning users' preferences on a\ncombinatorial set of alternatives, as generally used by online configurators,\nfor example. In many settings, only a set of selected alternatives during past\ninteractions is available to the learner. Fargier et al. [2018] propose an\napproach to learn, in such a setting, a model of the users' preferences that\nranks previously chosen alternatives as high as possible; and an algorithm to\nlearn, in this setting, a particular model of preferences: lexicographic\npreferences trees (LP-trees). In this paper, we study complexity-theoretical\nproblems related to this approach. We give an upper bound on the sample\ncomplexity of learning an LP-tree, which is logarithmic in the number of\nattributes. We also prove that computing the LP tree that minimises the\nempirical risk can be done in polynomial time when restricted to the class of\nlinear LP-trees.",
    "descriptor": "",
    "authors": [
      "H\u00e9l\u00e8ne Fargier",
      "Pierre-Fran\u00e7ois Gimenez",
      "J\u00e9r\u00f4me Mengin",
      "Bao Ngoc Le Nguyen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11505"
  },
  {
    "id": "arXiv:2209.11515",
    "title": "Large Language Models are Few-shot Testers: Exploring LLM-based General  Bug Reproduction",
    "abstract": "Many automated test generation techniques have been developed to aid\ndevelopers with writing tests. To facilitate full automation, most existing\ntechniques aim to either increase coverage, or generate exploratory inputs.\nHowever, existing test generation techniques largely fall short of achieving\nmore semantic objectives, such as generating tests to reproduce a given bug\nreport. Reproducing bugs is nonetheless important, as our empirical study shows\nthat the number of tests added in open source repositories due to issues was\nabout 28% of the corresponding project test suite size. Meanwhile, due to the\ndifficulties of transforming the expected program semantics in bug reports into\ntest oracles, existing failure reproduction techniques tend to deal exclusively\nwith program crashes, a small subset of all bug reports. To automate test\ngeneration from general bug reports, we propose LIBRO, a framework that uses\nLarge Language Models (LLMs), which have been shown to be capable of performing\ncode-related tasks. Since LLMs themselves cannot execute the target buggy code,\nwe focus on post-processing steps that help us discern when LLMs are effective,\nand rank the produced tests according to their validity. Our evaluation of\nLIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate\nfailure reproducing test cases for 33% of all studied cases (251 out of 750),\nwhile suggesting a bug reproducing test in first place for 149 bugs. To\nmitigate data contamination, we also evaluate LIBRO against 31 bug reports\nsubmitted after the collection of the LLM training data terminated: LIBRO\nproduces bug reproducing tests for 32% of the studied bug reports. Overall, our\nresults show LIBRO has the potential to significantly enhance developer\nefficiency by automatically generating tests from bug reports.",
    "descriptor": "\nComments: 12 pages (including references)\n",
    "authors": [
      "Sungmin Kang",
      "Juyeon Yoon",
      "Shin Yoo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.11515"
  },
  {
    "id": "arXiv:2209.11518",
    "title": "Marine Video Kit: A New Marine Video Dataset for Content-based Analysis  and Retrieval",
    "abstract": "Effective analysis of unusual domain specific video collections represents an\nimportant practical problem, where state-of-the-art general purpose models\nstill face limitations. Hence, it is desirable to design benchmark datasets\nthat challenge novel powerful models for specific domains with additional\nconstraints. It is important to remember that domain specific data may be\nnoisier (e.g., endoscopic or underwater videos) and often require more\nexperienced users for effective search. In this paper, we focus on single-shot\nvideos taken from moving cameras in underwater environments which constitute a\nnontrivial challenge for research purposes. The first shard of a new Marine\nVideo Kit dataset is presented to serve for video retrieval and other computer\nvision challenges. In addition to basic meta-data statistics, we present\nseveral insights and reference graphs based on low-level features as well as\nsemantic annotations of selected keyframes. The analysis contains also\nexperiments showing limitations of respected general purpose models for\nretrieval.",
    "descriptor": "\nComments: 12 pages of content with 2 pages of reference\n",
    "authors": [
      "Quang-Trung Truong",
      "Tuan-Anh Vu",
      "Tan-Sang Ha",
      "Lokoc Jakub",
      "Yue Him Wong Tim",
      "Ajay Joneja",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11518"
  },
  {
    "id": "arXiv:2209.11519",
    "title": "Vector Quantized Semantic Communication System",
    "abstract": "Although analog semantic communication systems have received considerable\nattention in the literature, there is less work on digital semantic\ncommunication systems. In this paper, we develop a deep learning (DL)-enabled\nvector quantized (VQ) semantic communication system for image transmission,\nnamed VQ-DeepSC. Specifically, we propose a convolutional neural network\n(CNN)-based transceiver to extract multi-scale semantic features of images and\nintroduce multi-scale semantic embedding spaces to perform semantic feature\nquantization, rendering the data compatible with digital communication systems.\nFurthermore, we employ adversarial training to improve the quality of received\nimages by introducing a PatchGAN discriminator. Experimental results\ndemonstrate that the proposed VQ-DeepSC outperforms traditional image\ntransmission methods in terms of SSIM.",
    "descriptor": "",
    "authors": [
      "Qifan Fu",
      "Huiqiang Xie",
      "Zhijin Qin",
      "Gregory Slabaugh",
      "Xiaoming Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.11519"
  },
  {
    "id": "arXiv:2209.11523",
    "title": "WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels",
    "abstract": "Compared to 2D lanes, real 3D lane data is difficult to collect accurately.\nIn this paper, we propose a novel method for training 3D lanes with only 2D\nlane labels, called weakly supervised 3D lane detection WS-3D-Lane. By\nassumptions of constant lane width and equal height on adjacent lanes, we\nindirectly supervise 3D lane heights in the training. To overcome the problem\nof the dynamic change of the camera pitch during data collection, a camera\npitch self-calibration method is proposed. In anchor representation, we propose\na double-layer anchor with a improved non-maximum suppression (NMS) method,\nwhich enables the anchor-based method to predict two lane lines that are close.\nExperiments are conducted on the base of 3D-LaneNet under two supervision\nmethods. Under weakly supervised setting, our WS-3D-Lane outperforms previous\n3D-LaneNet: F-score rises to 92.3% on Apollo 3D synthetic dataset, and F1 rises\nto 74.5% on ONCE-3DLanes. Meanwhile, WS-3D-Lane in purely supervised setting\nmakes more increments and outperforms state-of-the-art. To the best of our\nknowledge, WS-3D-Lane is the first try of 3D lane detection under weakly\nsupervised setting.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Jianyong Ai",
      "Wenbo Ding",
      "Jiuhua Zhao",
      "Jiachen Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11523"
  },
  {
    "id": "arXiv:2209.11524",
    "title": "Control Barrier Functions in UGVs for Kinematic Obstacle Avoidance: A  Collision Cone Approach",
    "abstract": "In this paper, we propose a new class of Control Barrier Functions (CBFs) for\nUnmanned Ground Vehicles (UGVs) that help avoid collisions with kinematic\n(non-zero velocity) obstacles. While the current forms of CBFs have been\nsuccessful in guaranteeing safety/collision avoidance with static obstacles,\nextensions for the dynamic case have seen limited success. Moreover, with the\nUGV models like the unicycle or the bicycle, applications of existing CBFs have\nbeen conservative in terms of control, i.e., steering/thrust control has not\nbeen possible under certain scenarios. Drawing inspiration from the classical\nuse of collision cones for obstacle avoidance in trajectory planning, we\nintroduce its novel CBF formulation with theoretical guarantees on safety for\nboth the unicycle and bicycle models. The main idea is to ensure that the\nvelocity of the obstacle w.r.t. the vehicle is always pointing away from the\nvehicle. Accordingly, we construct a constraint that ensures that the velocity\nvector always avoids a cone of vectors pointing at the vehicle. The efficacy of\nthis new control methodology is experimentally verified on the Copernicus\nmobile robot. We further extend it to self-driving cars in the form of bicycle\nmodels and demonstrate collision avoidance under various scenarios in the CARLA\nsimulator.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Robotics and Automation (ICRA). 7 pages, 6 figures, For supplement video follow this https URL The first and second authors have contributed equally\n",
    "authors": [
      "Phani Thontepu",
      "Bhavya Giri Goswami",
      "Neelaksh Singh",
      "Shyamsundar P I",
      "Shyam Sundar M G",
      "Suresh Sundaram",
      "Vaibhav Katewa",
      "Shishir Kolathaya."
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.11524"
  },
  {
    "id": "arXiv:2209.11526",
    "title": "Statistical shape representations for temporal registration of plant  components in 3D",
    "abstract": "Plants are dynamic organisms. Understanding temporal variations in vegetation\nis an essential problem for all robots in the wild. However, associating\nrepeated 3D scans of plants across time is challenging. A key step in this\nprocess is re-identifying and tracking the same individual plant components\nover time. Previously, this has been achieved by comparing their global spatial\nor topological location. In this work, we demonstrate how using shape features\nimproves temporal organ matching. We present a landmark-free shape compression\nalgorithm, which allows for the extraction of 3D shape features of leaves,\ncharacterises leaf shape and curvature efficiently in few parameters, and makes\nthe association of individual leaves in feature space possible. The approach\ncombines 3D contour extraction and further compression using Principal\nComponent Analysis (PCA) to produce a shape space encoding, which is entirely\nlearned from data and retains information about edge contours and 3D curvature.\nOur evaluation on temporal scan sequences of tomato plants shows, that\nincorporating shape features improves temporal leaf-matching. A combination of\nshape, location, and rotation information proves most informative for\nrecognition of leaves over time and yields a true positive rate of 75%, a 15%\nimprovement on sate-of-the-art methods. This is essential for robotic crop\nmonitoring, which enables whole-of-lifecycle phenotyping.",
    "descriptor": "\nComments: 6 pages plus references, 7 figures, Submitted to ICRA 2023\n",
    "authors": [
      "Karoline Heiwolt",
      "Cengiz \u00d6ztireli",
      "Grzegorz Cielniak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11526"
  },
  {
    "id": "arXiv:2209.11527",
    "title": "An artificial neural network-based system for detecting machine failures  using tiny sound data: A case study",
    "abstract": "In an effort to advocate the research for a deep learning-based machine\nfailure detection system, we present a case study of our proposed system based\non a tiny sound dataset. Our case study investigates a variational autoencoder\n(VAE) for augmenting a small drill sound dataset from Valmet AB. A Valmet\ndataset contains 134 sounds that have been divided into two categories:\n\"Anomaly\" and \"Normal\" recorded from a drilling machine in Valmet AB, a company\nin Sundsvall, Sweden that supplies equipment and processes for the production\nof biofuels. Using deep learning models to detect failure drills on such a\nsmall sound dataset is typically unsuccessful. We employed a VAE to increase\nthe number of sounds in the tiny dataset by synthesizing new sounds from\noriginal sounds. The augmented dataset was created by combining these\nsynthesized sounds with the original sounds. We used a high-pass filter with a\npassband frequency of 1000 Hz and a low-pass filter with a passband frequency\nof 22\\kern 0.16667em000 Hz to pre-process sounds in the augmented dataset\nbefore transforming them to Mel spectrograms. The pre-trained 2D-CNN Alexnet\nwas then trained using these Mel spectrograms. When compared to using the\noriginal tiny sound dataset to train pre-trained Alexnet, using the augmented\nsound dataset enhanced the CNN model's classification results by 6.62\\%(94.12\\%\nwhen trained on the augmented dataset versus 87.5\\% when trained on the\noriginal dataset).",
    "descriptor": "\nComments: 8 pages, 9 figures, conference\n",
    "authors": [
      "Thanh Tran",
      "Sebastian Bader",
      "Jan Lundgren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.11527"
  },
  {
    "id": "arXiv:2209.11530",
    "title": "Solving Robot Assembly Tasks by Combining Interactive Teaching and  Self-Exploration",
    "abstract": "Many high precision (dis)assembly tasks are still being performed by humans,\nwhereas this is an ideal opportunity for automation. This paper provides a\nframework which enables a non-expert human operator to teach a robotic arm to\ndo complex precision tasks. The framework uses a variable Cartesian impedance\ncontroller to execute trajectories learned from kinesthetic human\ndemonstrations. Feedback can be given to interactively reshape or speed up the\noriginal demonstration. Board localization is done through a visual estimation\nof the task board position and refined through haptic feedback. Our framework\nis tested on the Robothon benchmark disassembly challenge, where the robot has\nto perform complex precision tasks, such as a key insertion. The results show\nhigh success rates for each of the manipulation subtasks, including cases when\nthe box is in novel poses. An ablation study is also performed to evaluate the\ncomponents of the framework.",
    "descriptor": "\nComments: Under review for ICRA 2023\n",
    "authors": [
      "Mariano Ramirez Montero",
      "Giovanni Franzese",
      "Jeroen Zwanepol",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11530"
  },
  {
    "id": "arXiv:2209.11533",
    "title": "A Unified Perspective on Natural Gradient Variational Inference with  Gaussian Mixture Models",
    "abstract": "Variational inference with Gaussian mixture models (GMMs) enables learning of\nhighly-tractable yet multi-modal approximations of intractable target\ndistributions. GMMs are particular relevant for problem settings with up to a\nfew hundred dimensions, for example in robotics, for modelling distributions\nover trajectories or joint distributions. This work focuses on two very\neffective methods for GMM-based variational inference that both employ\nindependent natural gradient updates for the individual components and the\ncategorical distribution of the weights. We show for the first time, that their\nderived updates are equivalent, although their practical implementations and\ntheoretical guarantees differ. We identify several design choices that\ndistinguish both approaches, namely with respect to sample selection, natural\ngradient estimation, stepsize adaptation, and whether trust regions are\nenforced or the number of components adapted. We perform extensive ablations on\nthese design choices and show that they strongly affect the efficiency of the\noptimization and the variability of the learned distribution. Based on our\ninsights, we propose a novel instantiation of our generalized framework, that\ncombines first-order natural gradient estimates with trust-regions and\ncomponent adaption, and significantly outperforms both previous methods in all\nour experiments.",
    "descriptor": "",
    "authors": [
      "Oleg Arenz",
      "Philipp Dahlinger",
      "Zihan Ye",
      "Michael Volpp",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11533"
  },
  {
    "id": "arXiv:2209.11534",
    "title": "An Interdisciplinary Perspective on Evaluation and Experimental Design  for Visual Text Analytics: Position Paper",
    "abstract": "Appropriate evaluation and experimental design are fundamental for empirical\nsciences, particularly in data-driven fields. Due to the successes in\ncomputational modeling of languages, for instance, research outcomes are having\nan increasingly immediate impact on end users. As the gap in adoption by end\nusers decreases, the need increases to ensure that tools and models developed\nby the research communities and practitioners are reliable, trustworthy, and\nsupportive of the users in their goals. In this position paper, we focus on the\nissues of evaluating visual text analytics approaches. We take an\ninterdisciplinary perspective from the visualization and natural language\nprocessing communities, as we argue that the design and validation of visual\ntext analytics include concerns beyond computational or visual/interactive\nmethods on their own. We identify four key groups of challenges for evaluating\nvisual text analytics approaches (data ambiguity, experimental design, user\ntrust, and \"big picture'' concerns) and provide suggestions for research\nopportunities from an interdisciplinary perspective.",
    "descriptor": "\nComments: To appear in Proceedings of the 2022 IEEE Workshop on Evaluation and Beyond - Methodological Approaches to Visualization (BELIV '22)\n",
    "authors": [
      "Kostiantyn Kucher",
      "Nicole Sultanum",
      "Angel Daza",
      "Vasiliki Simaki",
      "Maria Skeppstedt",
      "Barbara Plank",
      "Jean-Daniel Fekete",
      "Narges Mahyar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11534"
  },
  {
    "id": "arXiv:2209.11535",
    "title": "The path to 5G-Advanced and 6G Non-Terrestrial Network systems",
    "abstract": "Today, 5G networks are being worldwide rolled out, with significant benefits\nin our economy and society. However, 5G systems alone are not expected to be\nsufficient for the challenges that 2030 networks will experience, including,\ne.g., always-on networks, 1 Tbps peak data rate, <10 cm positioning, etc. Thus,\nthe definition of evolutions of the 5G systems and their (r)evolutions are\nalready being addressed by the scientific and industrial communities, targeting\n5G-Advanced (5G-A) and 6G. In this framework, Non-Terrestrial Networks (NTN)\nhave successfully been integrated in 3GPP Rel. 17 and it is expected that they\nwill play an even more pivotal role for 5G-A (up to Rel. 20) and 6G systems\n(beyond Rel. 20). In this paper, we explore the path that will lead to 5G-A and\n6G NTN communications, providing a clear perspective in terms of system\narchitecture, services, technologies, and standardisation roadmap.",
    "descriptor": "",
    "authors": [
      "Alessandro Guidotti",
      "Alessandro Vanelli-Coralli",
      "Vincenzo Schena",
      "Nicolas Chuberre",
      "Mohamed El Jaafari",
      "Jani Puttonen",
      "Stefano Cioni"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.11535"
  },
  {
    "id": "arXiv:2209.11545",
    "title": "Analysis on Blockchain Consensus Mechanism Based on Proof of Work and  Proof of Stake",
    "abstract": "In the white book of Bitcion, Satoshi Nakamoto described a bitcoin system\nthat can realize point-to-point online payment without a third-party\norganization. After supporting this magical application scenario and subverting\nthe traditional centralized system, the blockchain technology has attracted\nworldwide attention, triggered a research upsurge of blockchain consensus\nalgorithm, and produced a large number of innovative applications. Although\nvarious consensus algorithms continue to evolve with the iteration of\nblockchain products and applications, Proof of Work (POW) and Proof of Skake\n(POS) algorithms are still the core of consensus algorithms. This paper\ndiscusses two algorithms of POW and POS in blockchain consensus mechanism, and\nanalyzes the advantages and the existing problems of the two consensus\nmechanisms. Since consensus mechanism is the main focus of blockchain\ntechnology and has many influencing factors, this paper discusses the current\nproblems and some improved ideas, and selects some typical algorithms for a\nmore systematic introduction. In addition, some important issues related to\nsafety and performance are also discussed. This paper provides the researchers\na great reference on blockchain consensus mechanism.",
    "descriptor": "",
    "authors": [
      "Shi Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.11545"
  },
  {
    "id": "arXiv:2209.11549",
    "title": "MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust  Classifier",
    "abstract": "We offer a method for one-shot image synthesis that allows controlling\nmanipulations of a single image by inverting a quasi-robust classifier equipped\nwith strong regularizers. Our proposed method, entitled Magic, samples\nstructured gradients from a pre-trained quasi-robust classifier to better\npreserve the input semantics while preserving its classification accuracy,\nthereby guaranteeing credibility in the synthesis. Unlike current methods that\nuse complex primitives to supervise the process or use attention maps as a weak\nsupervisory signal, Magic aggregates gradients over the input, driven by a\nguide binary mask that enforces a strong, spatial prior. Magic implements a\nseries of manipulations with a single framework achieving shape and location\ncontrol, intense non-rigid shape deformations, and copy/move operations in the\npresence of repeating objects and gives users firm control over the synthesis\nby requiring simply specifying binary guide masks. Our study and findings are\nsupported by various qualitative comparisons with the state-of-the-art on the\nsame images sampled from ImageNet and quantitative analysis using machine\nperception along with a user survey of 100+ participants that endorse our\nsynthesis quality.",
    "descriptor": "\nComments: 12 pages, 9 figures, technical report\n",
    "authors": [
      "Mozhdeh Rouhsedaghat",
      "Masoud Monajatipoor",
      "Kai-Wei Chang",
      "C. -C. Jay Kuo",
      "Iacopo Masi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11549"
  },
  {
    "id": "arXiv:2209.11553",
    "title": "On Efficient Reinforcement Learning for Full-length Game of StarCraft II",
    "abstract": "StarCraft II (SC2) poses a grand challenge for reinforcement learning (RL),\nof which the main difficulties include huge state space, varying action space,\nand a long time horizon. In this work, we investigate a set of RL techniques\nfor the full-length game of StarCraft II. We investigate a hierarchical RL\napproach involving extracted macro-actions and a hierarchical architecture of\nneural networks. We investigate a curriculum transfer training procedure and\ntrain the agent on a single machine with 4 GPUs and 48 CPU threads. On a 64x64\nmap and using restrictive units, we achieve a win rate of 99% against the\nlevel-1 built-in AI. Through the curriculum transfer learning algorithm and a\nmixture of combat models, we achieve a 93% win rate against the most difficult\nnon-cheating level built-in AI (level-7). In this extended version of the\npaper, we improve our architecture to train the agent against the cheating\nlevel AIs and achieve the win rate against the level-8, level-9, and level-10\nAIs as 96%, 97%, and 94%, respectively. Our codes are at\nhttps://github.com/liuruoze/HierNet-SC2. To provide a baseline referring the\nAlphaStar for our work as well as the research and open-source community, we\nreproduce a scaled-down version of it, mini-AlphaStar (mAS). The latest version\nof mAS is 1.07, which can be trained on the raw action space which has 564\nactions. It is designed to run training on a single common machine, by making\nthe hyper-parameters adjustable. We then compare our work with mAS using the\nsame resources and show that our method is more effective. The codes of\nmini-AlphaStar are at https://github.com/liuruoze/mini-AlphaStar. We hope our\nstudy could shed some light on the future research of efficient reinforcement\nlearning on SC2 and other large-scale games.",
    "descriptor": "\nComments: 48 pages,21 figures\n",
    "authors": [
      "Ruo-Ze Liu",
      "Zhen-Jia Pang",
      "Zhou-Yu Meng",
      "Wenhai Wang",
      "Yang Yu",
      "Tong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11553"
  },
  {
    "id": "arXiv:2209.11554",
    "title": "mmWall: A Transflective Metamaterial Surface for mmWave Networks",
    "abstract": "Mobile operators are poised to leverage millimeter wave technology as 5G\nevolves, but despite efforts to bolster their reliability indoors and outdoors,\nmmWave links remain vulnerable to blockage by walls, people, and obstacles.\nFurther, there is significant interest in bringing outdoor mmWave coverage\nindoors, which for similar reasons remains challenging today. This paper\npresents the design, hardware implementation, and experimental evaluation of\nmmWall, the first electronically almost-360 degree steerable metamaterial\nsurface that operates above 24 GHz and both refracts or reflects incoming\nmmWave transmissions. Our metamaterial design consists of arrays of\nvaractor-split ring resonator unit cells, miniaturized for mmWave. Custom\ncontrol circuitry drives each resonator, overcoming coupling challenges that\narise at scale. Leveraging beam steering algorithms, we integrate mmWall into\nthe link layer discovery protocols of common mmWave networks. We have\nfabricated a 10 cm by 20 cm mmWall prototype consisting of a 28 by 76 unit cell\narray, and evaluate in indoor, outdoor-to-indoor, and multi-beam scenarios.\nIndoors, mmWall guarantees 91% of locations outage-free under 128-QAM mmWave\ndata rates and boosts SNR by up to 15 dB. Outdoors, mmWall reduces the\nprobability of complete link failure by a ratio of up to 40% under 0-80% path\nblockage and boosts SNR by up to 30 dB.",
    "descriptor": "\nComments: 18 pages, 18 figures, submitted to NSDI 2023\n",
    "authors": [
      "Kun Woo Cho",
      "Mohammad H. Mazaheri",
      "Jeremy Gummeson",
      "Omid Abari",
      "Kyle Jamieson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.11554"
  },
  {
    "id": "arXiv:2209.11555",
    "title": "Analysis of Fault Tolerant Multi-stage Switch Architecture for TSN",
    "abstract": "We conducted the feasibility analysis of utilizing a highly available\nmulti-stage architecture for TSN switches used for sending high priority,\nmission-critical traffic within a bounded latency instead of traditional\nsingle-stage architectures. To verify the TSN functionality, we implemented the\n'strict priority' feature. We evaluated the performance of both architectures\non multiple parameters such as fault tolerance, packet latency, throughput,\nreliability, path length effectiveness, and cost per unit. The fault tolerance\nanalysis demonstrated that the multi-stage architecture fairs better than the\nsingle-stage counterpart. The average latency and throughput performance of\nmulti-stage architectures, although low, can be considered comparable with\nsingle-stage counterparts. However, the multi-stage architecture fails to meet\nthe performance of single-stage architectures on parameters such as\nreliability, path length effectiveness, and cost-effectiveness. The improved\nfault tolerance comes at the cost of increased hardware resources, cost, and\ncomplexity. However, with the advent of cost-effective technologies in hardware\ndesign and efficient architecture designs, the multi-stage switching\narchitecture-based TSN switches can be made reasonably comparable to\nsingle-stage switching TSN switches. This work gives initial confidence that\nthe multi-stage architecture can be pursued further for safety-critical systems\nthat require determinism and reliability in the communication of critical\nmessages.",
    "descriptor": "",
    "authors": [
      "Adnan Ghaderi",
      "Rahul Nandkumar Gore"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.11555"
  },
  {
    "id": "arXiv:2209.11557",
    "title": "Applications of Machine Learning in Chemical and Biological Oceanography",
    "abstract": "Machine learning (ML) refers to computer algorithms that predict a meaningful\noutput or categorise complex systems based on a large amount of data. ML\napplied in a variety of areas, including natural science, engineering, space\nexploration, and even gaming development. This article focused on the use of\nmachine learning in the field of chemical and biological oceanography. In the\nprediction of global fixed nitrogen levels, partial carbon dioxide pressure,\nand other chemical properties, the application of ML is a promising tool.\nMachine learning is also utilised in the field of biological oceanography to\ndetect planktonic forms from various images (i.e., microscopy, FlowCAM and\nvideo recorder), spectrometers, and other signal processing techniques.\nMoreover, ML successfully classified the mammals using their acoustics,\ndetecting endangered mammalian and fish species in a specific environment. Most\nimportantly, using environmental data, the ML proved to be an effective method\nfor predicting hypoxic conditions and the harmful algal bloom events, an\nimportant measurement in terms of environmental monitoring. Furthermore,\nmachine learning was used to construct a number of databases for various\nspecies that will be useful to other researchers, and the creation of new\nalgorithms will help the marine research community better comprehend the\nchemistry and biology of the ocean.",
    "descriptor": "\nComments: 58 Pages, 5 Figures\n",
    "authors": [
      "Balamurugan Sadaiappan",
      "Preethiya Balakrishnan",
      "Vishal CR",
      "Neethu T Vijayan",
      "Mahendran Subramanian",
      "Mangesh U Gauns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.11557"
  },
  {
    "id": "arXiv:2209.11559",
    "title": "Query-based Hard-Image Retrieval for Object Detection at Test Time",
    "abstract": "There is a longstanding interest in capturing the error behaviour of object\ndetectors by finding images where their performance is likely to be\nunsatisfactory. In real-world applications such as autonomous driving, it is\nalso crucial to characterise potential failures beyond simple requirements of\ndetection performance. For example, a missed detection of a pedestrian close to\nan ego vehicle will generally require closer inspection than a missed detection\nof a car in the distance. The problem of predicting such potential failures at\ntest time has largely been overlooked in the literature and conventional\napproaches based on detection uncertainty fall short in that they are agnostic\nto such fine-grained characterisation of errors. In this work, we propose to\nreformulate the problem of finding \"hard\" images as a query-based hard image\nretrieval task, where queries are specific definitions of \"hardness\", and offer\na simple and intuitive method that can solve this task for a large family of\nqueries. Our method is entirely post-hoc, does not require ground-truth\nannotations, is independent of the choice of a detector, and relies on an\nefficient Monte Carlo estimation that uses a simple stochastic model in place\nof the ground-truth. We show experimentally that it can be applied successfully\nto a wide variety of queries for which it can reliably identify hard images for\na given detector without any labelled data. We provide results on ranking and\nclassification tasks using the widely used RetinaNet, Faster-RCNN, Mask-RCNN,\nand Cascade Mask-RCNN object detectors.",
    "descriptor": "",
    "authors": [
      "Edward Ayers",
      "Jonathan Sadeghi",
      "John Redford",
      "Romain Mueller",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11559"
  },
  {
    "id": "arXiv:2209.11570",
    "title": "A Unified Generative Framework based on Prompt Learning for Various  Information Extraction Tasks",
    "abstract": "Prompt learning is an effective paradigm that bridges gaps between the\npre-training tasks and the corresponding downstream applications. Approaches\nbased on this paradigm have achieved great transcendent results in various\napplications. However, it still needs to be answered how to design a unified\nframework based on the prompt learning paradigm for various information\nextraction tasks. In this paper, we propose a novel composable prompt-based\ngenerative framework, which could be applied to a wide range of tasks in the\nfield of Information Extraction. Specifically, we reformulate information\nextraction tasks into the form of filling slots in pre-designed type-specific\nprompts, which consist of one or multiple sub-prompts. A strategy of\nconstructing composable prompts is proposed to enhance the generalization\nability to extract events in data-scarce scenarios. Furthermore, to fit this\nframework, we transform Relation Extraction into the task of determining\nsemantic consistency in prompts. The experimental results demonstrate that our\napproach surpasses compared baselines on real-world datasets in data-abundant\nand data-scarce scenarios. Further analysis of the proposed framework is\npresented, as well as numerical experiments conducted to investigate impact\nfactors of performance on various tasks.",
    "descriptor": "",
    "authors": [
      "Zhigang Kan",
      "Linhui Feng",
      "Zhangyue Yin",
      "Linbo Qiao",
      "Xipeng Qiu",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.11570"
  },
  {
    "id": "arXiv:2209.11572",
    "title": "Multi-Modal Cross-Domain Alignment Network for Video Moment Retrieval",
    "abstract": "As an increasingly popular task in multimedia information retrieval, video\nmoment retrieval (VMR) aims to localize the target moment from an untrimmed\nvideo according to a given language query. Most previous methods depend heavily\non numerous manual annotations (i.e., moment boundaries), which are extremely\nexpensive to acquire in practice. In addition, due to the domain gap between\ndifferent datasets, directly applying these pre-trained models to an unseen\ndomain leads to a significant performance drop. In this paper, we focus on a\nnovel task: cross-domain VMR, where fully-annotated datasets are available in\none domain (``source domain''), but the domain of interest (``target domain'')\nonly contains unannotated datasets. As far as we know, we present the first\nstudy on cross-domain VMR. To address this new task, we propose a novel\nMulti-Modal Cross-Domain Alignment (MMCDA) network to transfer the annotation\nknowledge from the source domain to the target domain. However, due to the\ndomain discrepancy between the source and target domains and the semantic gap\nbetween videos and queries, directly applying trained models to the target\ndomain generally leads to a performance drop. To solve this problem, we develop\nthree novel modules: (i) a domain alignment module is designed to align the\nfeature distributions between different domains of each modality; (ii) a\ncross-modal alignment module aims to map both video and query features into a\njoint embedding space and to align the feature distributions between different\nmodalities in the target domain; (iii) a specific alignment module tries to\nobtain the fine-grained similarity between a specific frame and the given query\nfor optimal localization. By jointly training these three modules, our MMCDA\ncan learn domain-invariant and semantic-aligned cross-modal representations.",
    "descriptor": "",
    "authors": [
      "Xiang Fang",
      "Daizong Liu",
      "Pan Zhou",
      "YuChong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11572"
  },
  {
    "id": "arXiv:2209.11575",
    "title": "Robot Localization using Situational Graphs and Building Architectural  Plans",
    "abstract": "Robots in the construction industry can reduce costs through constant\nmonitoring of the work progress, using high precision data capturing. Accurate\ndata capturing requires precise localization of the mobile robot within the\nenvironment. In this paper we present our novel work on robot localization\nwhich extracts geometric, semantic as well as the topological information from\nthe architectural plans in the form of walls and rooms, and creates the\ntopological and metric-semantic layer of the Situational Graphs (S-Graphs)\nbefore navigating in the environment. When the robot navigates in the\nconstruction environment, it uses the robot odometry and the sensorial\nobservations in the form of planar walls extracted from the 3D lidar\nmeasurements, to estimate its pose relying on a particle filter method, by\nexploiting the previously built situational graph and its available geometric,\nsemantic and topological information. We validate our approach in both\nsimulated and real datasets captured on actual on-going construction sites\npresenting state-of-the-art results when comparing it against traditional\ngeometry based localization techniques.",
    "descriptor": "",
    "authors": [
      "Muhammad Shaheer",
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11575"
  },
  {
    "id": "arXiv:2209.11577",
    "title": "Towards Complete-View and High-Level Pose-based Gait Recognition",
    "abstract": "The model-based gait recognition methods usually adopt the pedestrian walking\npostures to identify human beings.\nHowever, existing methods did not explicitly resolve the large intra-class\nvariance of human pose due to camera views changing.\nIn this paper, we propose to generate multi-view pose sequences for each\nsingle-view pose sample by learning full-rank transformation matrices via\nlower-upper generative adversarial network (LUGAN).\nBy the prior of camera imaging, we derive that the spatial coordinates\nbetween cross-view poses satisfy a linear transformation of a full-rank matrix,\nthereby, this paper employs the adversarial training to learn transformation\nmatrices from the source pose and target views to obtain the target pose\nsequences.\nTo this end, we implement a generator composed of graph convolutional (GCN)\nlayers, fully connected (FC) layers and two-branch convolutional (CNN) layers:\nGCN layers and FC layers encode the source pose sequence and target view, then\nCNN branches learn a lower triangular matrix and an upper triangular matrix,\nrespectively, finally they are multiplied to formulate the full-rank\ntransformation matrix.\nFor the purpose of adversarial training, we further devise a condition\ndiscriminator that distinguishes whether the pose sequence is true or\ngenerated.\nTo enable the high-level correlation learning, we propose a plug-and-play\nmodule, named multi-scale hypergraph convolution (HGC), to replace the spatial\ngraph convolutional layer in baseline, which could simultaneously model the\njoint-level, part-level and body-level correlations.\nExtensive experiments on two large gait recognition datasets, i.e., CASIA-B\nand OUMVLP-Pose, demonstrate that our method outperforms the baseline model and\nexisting pose-based methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Honghu Pan",
      "Yongyong Chen",
      "Tingyang Xu",
      "Yunqi He",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11577"
  },
  {
    "id": "arXiv:2209.11578",
    "title": "Socio-economic and Technological Factors Influencing Financial Inclusion  among Indigenous Peoples in Bauchi State, Nigeria",
    "abstract": "The need to understand the factors that come to bear in the financial\ninclusion on the indigenous peoples in Nigeria necessitated the study. The need\nis pressing because scholars have established that the financial inclusion is\ncrucial to the socio-cultural and economic development of the indigenous\npeoples.",
    "descriptor": "\nComments: A Paper Presented at the International Conference on Information and Communication Technologies and Development, June 29 to July1, at the University of Washington in Seattle, USA\n",
    "authors": [
      "Abduljalal Hassan",
      "Samuel C. Avemaria Utulu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.11578"
  },
  {
    "id": "arXiv:2209.11579",
    "title": "A Probabilistic Model of Activity Recognition with Loose Clothing",
    "abstract": "Human activity recognition has become an attractive research area with the\ndevelopment of on-body wearable sensing technology. With comfortable\nelectronic-textiles, sensors can be embedded into clothing so that it is\npossible to record human movement outside the laboratory for long periods.\nHowever, a long-standing issue is how to deal with motion artefacts introduced\nby movement of clothing with respect to the body. Surprisingly, recent\nempirical findings suggest that cloth-attached sensor can actually achieve\nhigher accuracy of activity recognition than rigid-attached sensor,\nparticularly when predicting from short time-windows. In this work, a\nprobabilistic model is introduced in which this improved accuracy and\nresposiveness is explained by the increased statistical distance between\nmovements recorded via fabric sensing. The predictions of the model are\nverified in simulated and real human motion capture experiments, where it is\nevident that this counterintuitive effect is closely captured.",
    "descriptor": "",
    "authors": [
      "Tianchen Shen",
      "Irene Di Giulio",
      "Matthew Howard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11579"
  },
  {
    "id": "arXiv:2209.11582",
    "title": "Pose-Aided Video-based Person Re-Identification via Recurrent Graph  Convolutional Network",
    "abstract": "Existing methods for video-based person re-identification (ReID) mainly learn\nthe appearance feature of a given pedestrian via a feature extractor and a\nfeature aggregator.\nHowever, the appearance models would fail when different pedestrians have\nsimilar appearances.\nConsidering that different pedestrians have different walking postures and\nbody proportions, we propose to learn the discriminative pose feature beyond\nthe appearance feature for video retrieval.\nSpecifically, we implement a two-branch architecture to separately learn the\nappearance feature and pose feature, and then concatenate them together for\ninference.\nTo learn the pose feature, we first detect the pedestrian pose in each frame\nthrough an off-the-shelf pose detector, and construct a temporal graph using\nthe pose sequence.\nWe then exploit a recurrent graph convolutional network (RGCN) to learn the\nnode embeddings of the temporal pose graph, which devises a global information\npropagation mechanism to simultaneously achieve the neighborhood aggregation of\nintra-frame nodes and message passing among inter-frame graphs.\nFinally, we propose a dual-attention method consisting of node-attention and\ntime-attention to obtain the temporal graph representation from the node\nembeddings, where the self-attention mechanism is employed to learn the\nimportance of each node and each frame.\nWe verify the proposed method on three video-based ReID datasets, i.e., Mars,\nDukeMTMC and iLIDS-VID, whose experimental results demonstrate that the learned\npose feature can effectively improve the performance of existing appearance\nmodels.",
    "descriptor": "",
    "authors": [
      "Honghu Pan",
      "Qiao Liu",
      "Yongyong Chen",
      "Yunqi He",
      "Yuan Zheng",
      "Feng Zheng",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11582"
  },
  {
    "id": "arXiv:2209.11584",
    "title": "Multi-Granularity Graph Pooling for Video-based Person Re-Identification",
    "abstract": "The video-based person re-identification (ReID) aims to identify the given\npedestrian video sequence across multiple non-overlapping cameras.\nTo aggregate the temporal and spatial features of the video samples, the\ngraph neural networks (GNNs) are introduced.\nHowever, existing graph-based models, like STGCN, perform the\n\\textit{mean}/\\textit{max pooling} on node features to obtain the graph\nrepresentation, which neglect the graph topology and node importance.\nIn this paper, we propose the graph pooling network (GPNet) to learn the\nmulti-granularity graph representation for the video retrieval, where the\n\\textit{graph pooling layer} is implemented to downsample the graph.\nWe first construct a multi-granular graph, whose node features denote image\nembedding learned by backbone, and edges are established between the temporal\nand Euclidean neighborhood nodes.\nWe then implement multiple graph convolutional layers to perform the\nneighborhood aggregation on the graphs.\nTo downsample the graph, we propose a multi-head full attention graph pooling\n(MHFAPool) layer, which integrates the advantages of existing node clustering\nand node selection pooling methods.\nSpecifically, MHFAPool takes the main eigenvector of full attention matrix as\nthe aggregation coefficients to involve the global graph information in each\npooled nodes.\nExtensive experiments demonstrate that our GPNet achieves the competitive\nresults on four widely-used datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID\nand PRID-2011.",
    "descriptor": "",
    "authors": [
      "Honghu Pan",
      "Yongyong Chen",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11584"
  },
  {
    "id": "arXiv:2209.11585",
    "title": "Synthetic Voice Spoofing Detection Based On Online Hard Example Mining",
    "abstract": "The automatic speaker verification spoofing (ASVspoof) challenge series is\ncrucial for enhancing the spoofing consideration and the countermeasures\ngrowth. Although the recent ASVspoof 2019 validation results indicate the\nsignificant capability to identify most attacks, the model's recognition effect\nis still poor for some attacks. This paper presents the Online Hard Example\nMining (OHEM) algorithm for detecting unknown voice spoofing attacks. The OHEM\nis utilized to overcome the imbalance between simple and hard samples in the\ndataset. The presented system provides an equal error rate (EER) of 0.77% on\nthe ASVspoof 2019 Challenge logical access scenario's evaluation set.",
    "descriptor": "",
    "authors": [
      "Ruohua Zhou",
      "Chenlei Hu",
      "Qiuchen Yu",
      "Yuxuan Du"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.11585"
  },
  {
    "id": "arXiv:2209.11588",
    "title": "Learning Rigid Body Dynamics with Lagrangian Graph Neural Network",
    "abstract": "Lagrangian and Hamiltonian neural networks (LNN and HNN respectively) encode\nstrong inductive biases that allow them to outperform other models of physical\nsystems significantly. However, these models have, thus far, mostly been\nlimited to simple systems such as pendulums and springs or a single rigid body\nsuch as a gyroscope or a rigid rotor. Here, we present a Lagrangian graph\nneural network (LGNN) that can learn the dynamics of rigid bodies by exploiting\ntheir topology. We demonstrate the performance of LGNN by learning the dynamics\nof ropes, chains, and trusses with the bars modeled as rigid bodies. LGNN also\nexhibits generalizability -- LGNN trained on chains with a few segments\nexhibits generalizability to simulate a chain with large number of links and\narbitrary link length. We also show that the LGNN can simulate unseen hybrid\nsystems including bars and chains, on which they have not been trained on.\nSpecifically, we show that the LGNN can be used to model the dynamics of\ncomplex real-world structures such as the stability of tensegrity structures.\nFinally, we discuss the non-diagonal nature of the mass matrix and it's ability\nto generalize in complex systems.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ravinder Bhattoo",
      "Sayan Ranu",
      "N. M. Anoop Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11588"
  },
  {
    "id": "arXiv:2209.11591",
    "title": "involve-MI: Informative Planning with High-Dimensional Non-Parametric  Beliefs",
    "abstract": "One of the most complex tasks of decision making and planning is to gather\ninformation. This task becomes even more complex when the state is\nhigh-dimensional and its belief cannot be expressed with a parametric\ndistribution. Although the state is high-dimensional, in many problems only a\nsmall fraction of it might be involved in transitioning the state and\ngenerating observations. We exploit this fact to calculate an\ninformation-theoretic expected reward, mutual information (MI), over a much\nlower-dimensional subset of the state, to improve efficiency and without\nsacrificing accuracy. A similar approach was used in previous works, yet\nspecifically for Gaussian distributions, and we here extend it for general\ndistributions. Moreover, we apply the dimensionality reduction for cases in\nwhich the new states are augmented to the previous, yet again without\nsacrificing accuracy. We then continue by developing an estimator for the MI\nwhich works in a Sequential Monte Carlo (SMC) manner, and avoids the\nreconstruction of future belief's surfaces. Finally, we show how this work is\napplied to the informative planning optimization problem. This work is then\nevaluated in a simulation of an active SLAM problem, where the improvement in\nboth accuracy and timing is demonstrated.",
    "descriptor": "",
    "authors": [
      "Gilad Rotman",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11591"
  },
  {
    "id": "arXiv:2209.11595",
    "title": "Differentially private partitioned variational inference",
    "abstract": "Learning a privacy-preserving model from distributed sensitive data is an\nincreasingly important problem, often formulated in the federated learning\ncontext. Variational inference has recently been extended to the non-private\nfederated learning setting via the partitioned variational inference algorithm.\nFor privacy protection, the current gold standard is called differential\nprivacy. Differential privacy guarantees privacy in a strong, mathematically\nclearly defined sense.\nIn this paper, we present differentially private partitioned variational\ninference, the first general framework for learning a variational approximation\nto a Bayesian posterior distribution in the federated learning setting while\nminimising the number of communication rounds and providing differential\nprivacy guarantees for data subjects.\nWe propose three alternative implementations in the general framework, one\nbased on perturbing local optimisation done by individual parties, and two\nbased on perturbing global updates (one using a version of federated averaging,\none adding virtual parties to the protocol), and compare their properties both\ntheoretically and empirically. We show that perturbing the local optimisation\nworks well with simple and complex models as long as each party has enough\nlocal data. However, the privacy is always guaranteed independently by each\nparty. In contrast, perturbing the global updates works best with relatively\nsimple models. Given access to suitable secure primitives, such as secure\naggregation or secure shuffling, the performance can be improved by all parties\nguaranteeing privacy jointly.",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Mikko A. Heikkil\u00e4",
      "Matthew Ashman",
      "Siddharth Swaroop",
      "Richard E. Turner",
      "Antti Honkela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11595"
  },
  {
    "id": "arXiv:2209.11596",
    "title": "Quantification before Selection: Active Dynamics Preference for Robust  Reinforcement Learning",
    "abstract": "Training a robust policy is critical for policy deployment in real-world\nsystems or dealing with unknown dynamics mismatch in different dynamic systems.\nDomain Randomization~(DR) is a simple and elegant approach that trains a\nconservative policy to counter different dynamic systems without expert\nknowledge about the target system parameters. However, existing works reveal\nthat the policy trained through DR tends to be over-conservative and performs\npoorly in target domains. Our key insight is that dynamic systems with\ndifferent parameters provide different levels of difficulty for the policy, and\nthe difficulty of behaving well in a system is constantly changing due to the\nevolution of the policy. If we can actively sample the systems with proper\ndifficulty for the policy on the fly, it will stabilize the training process\nand prevent the policy from becoming over-conservative or over-optimistic. To\noperationalize this idea, we introduce Active Dynamics Preference~(ADP), which\nquantifies the informativeness and density of sampled system parameters. ADP\nactively selects system parameters with high informativeness and low density.\nWe validate our approach in four robotic locomotion tasks with various\ndiscrepancies between the training and testing environments. Extensive results\ndemonstrate that our approach has superior robustness for system inconsistency\ncompared to several baselines.",
    "descriptor": "",
    "authors": [
      "Kang Xu",
      "Yan Ma",
      "Wei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11596"
  },
  {
    "id": "arXiv:2209.11600",
    "title": "Machine Learning and Analytical Power Consumption Models for 5G Base  Stations",
    "abstract": "The energy consumption of the fifth generation(5G) of mobile networks is one\nof the major concerns of the telecom industry. However, there is not currently\nan accurate and tractable approach to evaluate 5G base stations (BSs) power\nconsumption. In this article, we propose a novel model for a realistic\ncharacterisation of the power consumption of 5G multi-carrier BSs, which builds\non a large data collection campaign. At first, we define a machine learning\narchitecture that allows modelling multiple 5G BS products. Then, we exploit\nthe knowledge gathered by this framework to derive a realistic and analytically\ntractable power consumption model, which can help driving both theoretical\nanalyses as well as feature standardisation, development and optimisation\nframeworks. Notably, we demonstrate that such model has high precision, and it\nis able of capturing the benefits of energy saving mechanisms. We believe this\nanalytical model represents a fundamental tool for understanding 5G BSs power\nconsumption, and accurately optimising the network energy efficiency.",
    "descriptor": "\nComments: Accepted by IEEE Communications Magazine\n",
    "authors": [
      "Nicola Piovesan",
      "David Lopez-Perez",
      "Antonio De Domenico",
      "Xinli Geng",
      "Harvey Bao",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11600"
  },
  {
    "id": "arXiv:2209.11603",
    "title": "Mixed Virtual Element approximation of linear acoustic wave equation",
    "abstract": "We design a Mixed Virtual Element Method for the approximated solution to the\nfirst-order form of the acoustic wave equation. In absence of external load,\nthe semi-discrete method exactly conserves the system energy. To integrate in\ntime the semi-discrete problem we consider a classical theta-method scheme. We\ncarry out the stability and convergence analysis in the energy norm for the\nsemi-discrete problem showing optimal rate of convergence with respect to the\nmesh size. We further study the property of energy conservation for the\nfully-discrete system. Finally, we present some verification tests as well as\nengineering application of the method.",
    "descriptor": "",
    "authors": [
      "Franco Dassi",
      "Alessio Fumagalli",
      "Ilario Mazzieri",
      "Giuseppe Vacca"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11603"
  },
  {
    "id": "arXiv:2209.11604",
    "title": "Neural Clamping: Joint Input Perturbation and Temperature Scaling for  Neural Network Calibration",
    "abstract": "Neural network calibration is an essential task in deep learning to ensure\nconsistency between the confidence of model prediction and the true correctness\nlikelihood. In this paper, we propose a new post-processing calibration method\ncalled Neural Clamping, which employs a simple joint input-output\ntransformation on a pre-trained classifier via a learnable universal input\nperturbation and an output temperature scaling parameter. Moreover, we provide\ntheoretical explanations on why Neural Clamping is provably better than\ntemperature scaling. Evaluated on CIFAR-100 and ImageNet image recognition\ndatasets and a variety of deep neural network models, our empirical results\nshow that Neural Clamping significantly outperforms state-of-the-art\npost-processing calibration methods.",
    "descriptor": "",
    "authors": [
      "Yung-Chen Tang",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11604"
  },
  {
    "id": "arXiv:2209.11607",
    "title": "I-SPLIT: Deep Network Interpretability for Split Computing",
    "abstract": "This work makes a substantial step in the field of split computing, i.e., how\nto split a deep neural network to host its early part on an embedded device and\nthe rest on a server. So far, potential split locations have been identified\nexploiting uniquely architectural aspects, i.e., based on the layer sizes.\nUnder this paradigm, the efficacy of the split in terms of accuracy can be\nevaluated only after having performed the split and retrained the entire\npipeline, making an exhaustive evaluation of all the plausible splitting points\nprohibitive in terms of time. Here we show that not only the architecture of\nthe layers does matter, but the importance of the neurons contained therein\ntoo. A neuron is important if its gradient with respect to the correct class\ndecision is high. It follows that a split should be applied right after a layer\nwith a high density of important neurons, in order to preserve the information\nflowing until then. Upon this idea, we propose Interpretable Split (I-SPLIT): a\nprocedure that identifies the most suitable splitting points by providing a\nreliable prediction on how well this split will perform in terms of\nclassification accuracy, beforehand of its effective implementation. As a\nfurther major contribution of I-SPLIT, we show that the best choice for the\nsplitting point on a multiclass categorization problem depends also on which\nspecific classes the network has to deal with. Exhaustive experiments have been\ncarried out on two networks, VGG16 and ResNet-50, and three datasets,\nTiny-Imagenet-200, notMNIST, and Chest X-Ray Pneumonia. The source code is\navailable at https://github.com/vips4/I-Split.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Federico Cunico",
      "Luigi Capogrosso",
      "Francesco Setti",
      "Damiano Carra",
      "Franco Fummi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11607"
  },
  {
    "id": "arXiv:2209.11615",
    "title": "Robust Domain Adaptation for Machine Reading Comprehension",
    "abstract": "Most domain adaptation methods for machine reading comprehension (MRC) use a\npre-trained question-answer (QA) construction model to generate pseudo QA pairs\nfor MRC transfer. Such a process will inevitably introduce mismatched pairs\n(i.e., noisy correspondence) due to i) the unavailable QA pairs in target\ndocuments, and ii) the domain shift during applying the QA construction model\nto the target domain. Undoubtedly, the noisy correspondence will degenerate the\nperformance of MRC, which however is neglected by existing works. To solve such\nan untouched problem, we propose to construct QA pairs by additionally using\nthe dialogue related to the documents, as well as a new domain adaptation\nmethod for MRC. Specifically, we propose Robust Domain Adaptation for Machine\nReading Comprehension (RMRC) method which consists of an answer extractor (AE),\na question selector (QS), and an MRC model. Specifically, RMRC filters out the\nirrelevant answers by estimating the correlation to the document via the AE,\nand extracts the questions by fusing the candidate questions in multiple rounds\nof dialogue chats via the QS. With the extracted QA pairs, MRC is fine-tuned\nand provides the feedback to optimize the QS through a novel reinforced\nself-training method. Thanks to the optimization of the QS, our method will\ngreatly alleviate the noisy correspondence problem caused by the domain shift.\nTo the best of our knowledge, this could be the first study to reveal the\ninfluence of noisy correspondence in domain adaptation MRC models and show a\nfeasible way to achieve robustness to mismatched pairs. Extensive experiments\non three datasets demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Liang Jiang",
      "Zhenyu Huang",
      "Jia Liu",
      "Zujie Wen",
      "Xi Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11615"
  },
  {
    "id": "arXiv:2209.11617",
    "title": "Linear Clustering Process on Networks",
    "abstract": "We propose a linear clustering process on a network consisting of two\nopposite forces: attraction and repulsion between adjacent nodes. Each node is\nmapped to a position on a one-dimensional line. The attraction and repulsion\nforces move the nodal position on the line, depending on how similar or\ndifferent the neighbourhoods of two adjacent nodes are. Based on each node\nposition, the number of clusters in a network, together with each node's\ncluster membership, is estimated. The performance of the proposed linear\nclustering process is benchmarked on synthetic networks against widely accepted\nclustering algorithms such as modularity, the Louvain method and the non-back\ntracking matrix. The proposed linear clustering process outperforms the most\npopular modularity-based methods, such as the Louvain method, while possessing\na comparable computational complexity.",
    "descriptor": "",
    "authors": [
      "Ivan Joki\u0107",
      "Piet Van Mieghem"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11617"
  },
  {
    "id": "arXiv:2209.11625",
    "title": "The SpeakIn Speaker Verification System for Far-Field Speaker  Verification Challenge 2022",
    "abstract": "This paper describes speaker verification (SV) systems submitted by the\nSpeakIn team to the Task 1 and Task 2 of the Far-Field Speaker Verification\nChallenge 2022 (FFSVC2022). SV tasks of the challenge focus on the problem of\nfully supervised far-field speaker verification (Task 1) and semi-supervised\nfar-field speaker verification (Task 2). In Task 1, we used the VoxCeleb and\nFFSVC2020 datasets as train datasets. And for Task 2, we only used the VoxCeleb\ndataset as train set. The ResNet-based and RepVGG-based architectures were\ndeveloped for this challenge. Global statistic pooling structure and MQMHA\npooling structure were used to aggregate the frame-level features across time\nto obtain utterance-level representation. We adopted AM-Softmax and AAM-Softmax\nto classify the resulting embeddings. We innovatively propose a staged transfer\nlearning method. In the pre-training stage we reserve the speaker weights, and\nthere are no positive samples to train them in this stage. Then we fine-tune\nthese weights with both positive and negative samples in the second stage.\nCompared with the traditional transfer learning strategy, this strategy can\nbetter improve the model performance. The Sub-Mean and AS-Norm backend methods\nwere used to solve the problem of domain mismatch. In the fusion stage, three\nmodels were fused in Task1 and two models were fused in Task2. On the FFSVC2022\nleaderboard, the EER of our submission is 3.0049% and the corresponding minDCF\nis 0.2938 in Task1. In Task2, EER and minDCF are 6.2060% and 0.5232\nrespectively. Our approach leads to excellent performance and ranks 1st in both\nchallenge tasks.",
    "descriptor": "\nComments: 5 pages. arXiv admin note: text overlap with arXiv:2209.10846\n",
    "authors": [
      "Yu Zheng",
      "Jinghan Peng",
      "Yihao Chen",
      "Yajun Zhang",
      "Jialong Wang",
      "Min Liu",
      "Minqiang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.11625"
  },
  {
    "id": "arXiv:2209.11628",
    "title": "A Neural Model for Regular Grammar Induction",
    "abstract": "Grammatical inference is a classical problem in computational learning theory\nand a topic of wider influence in natural language processing. We treat\ngrammars as a model of computation and propose a novel neural approach to\ninduction of regular grammars from positive and negative examples. Our model is\nfully explainable, its intermediate results are directly interpretable as\npartial parses, and it can be used to learn arbitrary regular grammars when\nprovided with sufficient data. Our method consistently attains high recall and\nprecision scores across a range of tests of varying complexity. We make the\ndetailed results and code readily available.",
    "descriptor": "\nComments: Accepted to the 21st IEEE International Conference on Machine Learning and Applications (ICMLA) 2022, 6 pages, 4 figures\n",
    "authors": [
      "Peter Belc\u00e1k",
      "David Hofer",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11628"
  },
  {
    "id": "arXiv:2209.11629",
    "title": "From Weakly Supervised Learning to Active Learning",
    "abstract": "Applied mathematics and machine computations have raised a lot of hope since\nthe recent success of supervised learning. Many practitioners in industries\nhave been trying to switch from their old paradigms to machine learning.\nInterestingly, those data scientists spend more time scrapping, annotating and\ncleaning data than fine-tuning models. This thesis is motivated by the\nfollowing question: can we derive a more generic framework than the one of\nsupervised learning in order to learn from clutter data?\nThis question is approached through the lens of weakly supervised learning,\nassuming that the bottleneck of data collection lies in annotation. We model\nweak supervision as giving, rather than a unique target, a set of target\ncandidates. We argue that one should look for an ``optimistic'' function that\nmatches most of the observations. This allows us to derive a principle to\ndisambiguate partial labels. We also discuss the advantage to incorporate\nunsupervised learning techniques into our framework, in particular manifold\nregularization approached through diffusion techniques, for which we derived a\nnew algorithm that scales better with input dimension then the baseline method.\nFinally, we switch from passive to active weakly supervised learning,\nintroducing the ``active labeling'' framework, in which a practitioner can\nquery weak information about chosen data. Among others, we leverage the fact\nthat one does not need full information to access stochastic gradients and\nperform stochastic gradient descent.",
    "descriptor": "\nComments: PhD Thesis, Ecole Normale Superieure, 2022\n",
    "authors": [
      "Vivien Cabannes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11629"
  },
  {
    "id": "arXiv:2209.11631",
    "title": "funcX: Federated Function as a Service for Science",
    "abstract": "funcX is a distributed function as a service (FaaS) platform that enables\nflexible, scalable, and high performance remote function execution. Unlike\ncentralized FaaS systems, funcX decouples the cloud-hosted management\nfunctionality from the edge-hosted execution functionality. funcX's endpoint\nsoftware can be deployed, by users or administrators, on arbitrary laptops,\nclouds, clusters, and supercomputers, in effect turning them into function\nserving systems. funcX's cloud-hosted service provides a single location for\nregistering, sharing, and managing both functions and endpoints. It allows for\ntransparent, secure, and reliable function execution across the federated\necosystem of endpoints--enabling users to route functions to endpoints based on\nspecific needs. funcX uses containers (e.g., Docker, Singularity, and Shifter)\nto provide common execution environments across endpoints. funcX implements\nvarious container management strategies to execute functions with high\nperformance and efficiency on diverse funcX endpoints. funcX also integrates\nwith an in-memory data store and Globus for managing data that may span\nendpoints. We motivate the need for funcX, present our prototype design and\nimplementation, and demonstrate, via experiments on two supercomputers, that\nfuncX can scale to more than 130 000 concurrent workers. We show that funcX's\ncontainer warming-aware routing algorithm can reduce the completion time for\n3000 functions by up to 61% compared to a randomized algorithm and the\nin-memory data store can speed up data transfers by up to 3x compared to a\nshared file system.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2005.04215\n",
    "authors": [
      "Zhuozhao Li",
      "Ryan Chard",
      "Yadu Babuji",
      "Ben Galewsky",
      "Tyler Skluzacek",
      "Kirill Nagaitsev",
      "Anna Woodard",
      "Ben Blaiszik",
      "Josh Bryan",
      "Daniel S. Katz",
      "Ian Foster",
      "Kyle Chard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.11631"
  },
  {
    "id": "arXiv:2209.11632",
    "title": "Facilitating Change Implementation for Continuous ML-Safety Assurance",
    "abstract": "We propose a method for deploying a safety-critical machine-learning\ncomponent into continuously evolving environments where an increased degree of\nautomation in the engineering process is desired. We associate semantic tags\nwith the safety case argumentation and turn each piece of evidence into a\nquantitative metric or a logic formula. With proper tool support, the impact\ncan be characterized by a query over the safety argumentation tree to highlight\nevidence turning invalid. The concept is exemplified using a vision-based\nemergency braking system of an autonomous guided vehicle for factory\nautomation.",
    "descriptor": "",
    "authors": [
      "Chih-Hong Cheng",
      "Nguyen Anh Vu Doan",
      "Balahari Balu",
      "Franziska Schwaiger",
      "Emmanouil Seferis",
      "Simon Burton",
      "Yassine Qamsane",
      "Ankit Shukla",
      "Yinchong Yang",
      "Zhiliang Wu",
      "Andreas Hapfelmeier",
      "Ingo Thon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.11632"
  },
  {
    "id": "arXiv:2209.11633",
    "title": "Formal Semantics of the CDL Language",
    "abstract": "We reverse-engineer a formal semantics of the Component Definition Language\n(CDL), which is part of the highly configurable, embedded operating system\neCos. This work provides the basis for an analysis and comparison of the two\nvariability-modeling languages Kconfig and CDL. The semantics given in this\ndocument are based on analyzing the CDL documentation, inspecting the source\ncode of the toolchain, as well as testing the tools on particular examples.",
    "descriptor": "\nComments: Technical Note, Department of Computer Science, University of Leipzig, Germany\n",
    "authors": [
      "Thorsten Berger",
      "Steven She"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.11633"
  },
  {
    "id": "arXiv:2209.11634",
    "title": "View-Invariant Skeleton-based Action Recognition via Global-Local  Contrastive Learning",
    "abstract": "Skeleton-based human action recognition has been drawing more interest\nrecently due to its low sensitivity to appearance changes and the accessibility\nof more skeleton data. However, even the 3D skeletons captured in practice are\nstill sensitive to the viewpoint and direction gave the occlusion of different\nhuman-body joints and the errors in human joint localization. Such view\nvariance of skeleton data may significantly affect the performance of action\nrecognition. To address this issue, we propose in this paper a new\nview-invariant representation learning approach, without any manual action\nlabeling, for skeleton-based human action recognition. Specifically, we\nleverage the multi-view skeleton data simultaneously taken for the same person\nin the network training, by maximizing the mutual information between the\nrepresentations extracted from different views, and then propose a global-local\ncontrastive loss to model the multi-scale co-occurrence relationships in both\nspatial and temporal domains. Extensive experimental results show that the\nproposed method is robust to the view difference of the input skeleton data and\nsignificantly boosts the performance of unsupervised skeleton-based human\naction methods, resulting in new state-of-the-art accuracies on two challenging\nmulti-view benchmarks of PKUMMD and NTU RGB+D.",
    "descriptor": "",
    "authors": [
      "Cunling Bian",
      "Wei Feng",
      "Fanbo Meng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11634"
  },
  {
    "id": "arXiv:2209.11647",
    "title": "Self-Sovereign Identity in a World of Authentication: Architecture and  Domain Usecases",
    "abstract": "Self-Sovereign Identity (SSI) is projected to become part of every person's\nlife in some form. The ability to verify and authenticate that an individual is\nthe actual person they are purported to be along with securing the personal\nattributes could have wide spread implications when engaging with third party\norganizations. Utilizing blockchains and other decentralized technologies, SSI\nis a growing area of research. The aspect of securing personal information\nwithin a decentralized structure has possible benefits to the public and\nprivate sectors. In this paper, we describe the SSI framework architecture as\nwell as possible use cases across domains like healthcare, finance, retail, and\ngovernment. The paper also contrasts SSI and its decentralized architecture\nwith the current widely adopted model of Public Key Infrastructure (PKI).",
    "descriptor": "",
    "authors": [
      "Morgan Reece",
      "Sudip Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.11647"
  },
  {
    "id": "arXiv:2209.11650",
    "title": "An Algebraic-Geometry Approach to Prime Factorization",
    "abstract": "New algorithms for prime factorization that outperform the existing ones or\ntake advantage of particular properties of the prime factors can have a\npractical impact on present implementations of cryptographic algorithms that\nrely on the complexity of factorization. Currently used keys are chosen on the\nbasis of the present algorithmic knowledge and, thus, can potentially be\nsubject to future breaches. For this reason, it is worth to investigate new\napproaches which have the potentiality of giving a computational advantage. The\nproblem has also relevance in quantum computation, as an efficient quantum\nalgorithm for prime factorization already exists. Thus, better classical\nasymptotic complexity can provide a better understanding of the advantages\noffered by quantum computers. In this paper, we reduce the factorization\nproblem to the search of points of parametrizable varieties, in particular\ncurves, over finite fields. The varieties are required to have an arbitrarily\nlarge number of intersection points with some hypersurface over the base field.\nFor a subexponential or poly- nomial factoring complexity, the number of\nparameters have to scale sublinearly in the space dimension n and the\ncomplexity of computing a point given the parameters has to be subexponential\nor polynomial, respectively. We outline a procedure for building these\nvarieties, which is illustrated with two constructions. In one case, we show\nthat there are varieties whose points can be evaluated efficiently given a\nnumber of parameters not greater than n/2. In the other case, the bound is\ndropped to n/3. Incidentally, the first construction resembles a kind of\nretro-causal model. Retro-causality is considered one possible explanation of\nquantum weirdness.",
    "descriptor": "",
    "authors": [
      "Alberto Montina",
      "Stefan Wolf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)",
      "Number Theory (math.NT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.11650"
  },
  {
    "id": "arXiv:2209.11651",
    "title": "Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and  Beyond",
    "abstract": "We develop a general deterministic distributed method for locally rounding\nfractional solutions of graph problems for which the analysis can be broken\ndown into analyzing pairs of vertices. Roughly speaking, the method can\ntransform fractional/probabilistic label assignments of the vertices into\nintegral/deterministic label assignments for the vertices, while approximately\npreserving a potential function that is a linear combination of functions, each\nof which depends on at most two vertices (subject to some conditions usually\nsatisfied in pairwise analyses). The method unifies and significantly\ngeneralizes prior work on deterministic local rounding techniques [Ghaffari,\nKuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17]\nto obtain polylogarithmic-time deterministic distributed solutions for\ncombinatorial graph problems. Our general rounding result enables us to locally\nand efficiently derandomize a range of distributed algorithms for local graph\nproblems, including maximal independent set (MIS), maximum-weight independent\nset approximation, and minimum-cost set cover approximation. As a highlight, we\nin particular obtain a deterministic $O(\\log^2\\Delta\\cdot\\log n)$-round\nalgorithm for computing an MIS in the LOCAL model and an almost as efficient\n$O(\\log^2\\Delta\\cdot\\log\\log\\Delta\\cdot\\log n)$-round deterministic MIS\nalgorithm in the CONGEST model. As a result, the best known deterministic\ndistributed time complexity of the four most widely studied distributed\nsymmetry breaking problems (MIS, maximal matching, $(\\Delta+1)$-vertex\ncoloring, and $(2\\Delta-1)$-edge coloring) is now $O(\\log^2\\Delta\\cdot\\log n)$.\nOur new MIS algorithm is also the first direct polylogarithmic-time\ndeterministic distributed MIS algorithm, which is not based on network\ndecomposition.",
    "descriptor": "",
    "authors": [
      "Salwa Faour",
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Fabian Kuhn",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11651"
  },
  {
    "id": "arXiv:2209.11659",
    "title": "Rational approximation preconditioners for multiphysics problems",
    "abstract": "We consider a class of mathematical models describing multiphysics phenomena\ninteracting through interfaces. On such interfaces, the traces of the fields\nlie (approximately) in the range of a weighted sum of two fractional\ndifferential operators. We use a rational function approximation to\nprecondition such operators. We first demonstrate the robustness of the\napproximation for ordinary functions given by weighted sums of fractional\nexponents. Additionally, we present more realistic examples utilizing the\nproposed preconditioning techniques in interface coupling between Darcy and\nStokes equations.",
    "descriptor": "",
    "authors": [
      "Ana Budisa",
      "Xiaozhe Hu",
      "Miroslav Kuchta",
      "Kent-Andre Mardal",
      "Ludmil Zikatanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11659"
  },
  {
    "id": "arXiv:2209.11664",
    "title": "A Constraint-Driven Approach to Line Flocking: The V Formation as an  Energy-Saving Strategy",
    "abstract": "The study of robotic flocking has received significant attention in the past\ntwenty years. In this article, we present a constraint-driven control algorithm\nthat minimizes the energy consumption of individual agents and yields an\nemergent V formation. As the formation emerges from the decentralized\ninteraction between agents, our approach is robust to the spontaneous addition\nor removal of agents to the system. First, we present an analytical model for\nthe trailing upwash behind a fixed-wing UAV, and we derive the optimal air\nspeed for trailing UAVs to maximize their travel endurance. Next, we prove that\nsimply flying at the optimal airspeed will never lead to emergent flocking\nbehavior, and we propose a new decentralized \"anseroid\" behavior that yields\nemergent V formations. We encode these behaviors in a constraint-driven control\nalgorithm that minimizes the locomotive power of each UAV. Finally, we prove\nthat UAVs initialized in an approximate V or echelon formation will converge\nunder our proposed control law, and we demonstrate this emergence occurs in\nreal-time in simulation and in physical experiments with a fleet of Crazyflie\nquadrotors.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Logan E. Beaver",
      "Christopher Kroninger",
      "Michael Dorothy",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.11664"
  },
  {
    "id": "arXiv:2209.11669",
    "title": "Improved Distributed Network Decomposition, Hitting Sets, and Spanners,  via Derandomization",
    "abstract": "This paper presents significantly improved deterministic algorithms for some\nof the key problems in the area of distributed graph algorithms, including\nnetwork decomposition, hitting sets, and spanners. As the main ingredient in\nthese results, we develop novel randomized distributed algorithms that we can\nanalyze using only pairwise independence, and we can thus derandomize\nefficiently. As our most prominent end-result, we obtain a deterministic\nconstruction for $O(\\log n)$-color $O(\\log n \\cdot \\log\\log\\log n)$-strong\ndiameter network decomposition in $\\tilde{O}(\\log^3 n)$ rounds. This is the\nfirst construction that achieves almost $\\log n$ in both parameters, and it\nimproves on a recent line of exciting progress on deterministic distributed\nnetwork decompositions [Rozho\\v{n}, Ghaffari STOC'20; Ghaffari, Grunau,\nRozho\\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\\v{n},\nGrunau FOCS'22].",
    "descriptor": "",
    "authors": [
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Bernhard Haeupler",
      "Saeed Ilchi",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11669"
  },
  {
    "id": "arXiv:2209.11672",
    "title": "MiCellAnnGELo: Annotate microscopy time series of complex cell surfaces  with 3D Virtual Reality",
    "abstract": "Summary: Advances in 3D live cell microscopy are enabling high-resolution\ncapture of previously unobserved processes. Unleashing the power of modern\nmachine learning methods to fully benefit from these technologies is, however,\nfrustrated by the difficulty of manually annotating 3D training data.\nMiCellAnnGELo virtual reality software offers an immersive environment for\nviewing and interacting with 4D microscopy data, including efficient tools for\nannotation. We present tools for labelling cell surfaces with a wide range of\napplications, including cell motility, endocytosis, and intracellular\nsignalling. Availability and implementation: MiCellAnnGELo employs the cross\nplatform (Mac/Unix/Windows) Unity game engine and is available under the MIT\nlicence at https://github.com/CellDynamics/MiCellAnnGELo.git, together with\nsample data. MiCellAnnGELo can be run in desktop mode on a 2D screen or in 3D\nusing a standard VR headset with compatible GPU.",
    "descriptor": "\nComments: For associated code and sample data, see this https URL\n",
    "authors": [
      "Adam Platt",
      "E. Josiah Lutton",
      "Till Bretschneider"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11672"
  },
  {
    "id": "arXiv:2209.11673",
    "title": "Image-to-Image Translation for Autonomous Driving from Coarsely-Aligned  Image Pairs",
    "abstract": "A self-driving car must be able to reliably handle adverse weather conditions\n(e.g., snowy) to operate safely. In this paper, we investigate the idea of\nturning sensor inputs (i.e., images) captured in an adverse condition into a\nbenign one (i.e., sunny), upon which the downstream tasks (e.g., semantic\nsegmentation) can attain high accuracy. Prior work primarily formulates this as\nan unpaired image-to-image translation problem due to the lack of paired images\ncaptured under the exact same camera poses and semantic layouts. While\nperfectly-aligned images are not available, one can easily obtain\ncoarsely-paired images. For instance, many people drive the same routes daily\nin both good and adverse weather; thus, images captured at close-by GPS\nlocations can form a pair. Though data from repeated traversals are unlikely to\ncapture the same foreground objects, we posit that they provide rich contextual\ninformation to supervise the image translation model. To this end, we propose a\nnovel training objective leveraging coarsely-aligned image pairs. We show that\nour coarsely-aligned training scheme leads to a better image translation\nquality and improved downstream tasks, such as semantic segmentation, monocular\ndepth estimation, and visual localization.",
    "descriptor": "\nComments: Submitted to the International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Youya Xia",
      "Josephine Monica",
      "Wei-Lun Chao",
      "Bharath Hariharan",
      "Kilian Q Weinberger",
      "Mark Campbell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11673"
  },
  {
    "id": "arXiv:2209.11675",
    "title": "An analysis of the Internet of Things in wireless sensor network  technologies",
    "abstract": "Information may be accessed from a distance thanks to computer networks.\nWireless or wired networks are also possible. Due to recent developments in\nwireless infrastructure, wireless sensor networks (WSNs) were developed.\nActivities or events occurring in the environment are monitored, recorded, and\nmanaged by WSN. Through a variety of routing techniques, data relaying is done\nin these systems. The fourth industrial revolution, or Industry 4.0, is defined\nas the integration of complex physical automation systems made up of machinery\nand devices connected by sensors and managed by software. This is done to boost\nthe efficiency and reliability of operations. Industry 4.0 is viewed as a\npossibility because of industrial IoT, the concept of leveraging IoT technology\nin manufacturing. delivering, in an industrial setting, a means of connecting\nengines, power grids, and sensors to the cloud. In this essay, we'll try to\ncomprehend how the Internet of Things (IoT) works in wireless sensor networks\nand how it might be used in various situations.",
    "descriptor": "\nComments: 8 pages, 13 figures, 3 tables, preprint\n",
    "authors": [
      "Harshit Poddar",
      "Vansh Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11675"
  },
  {
    "id": "arXiv:2209.11677",
    "title": "PNeRF: Probabilistic Neural Scene Representations for Uncertain 3D  Visual Mapping",
    "abstract": "Recently neural scene representations have provided very impressive results\nfor representing 3D scenes visually, however, their study and progress have\nmainly been limited to visualization of virtual models in computer graphics or\nscene reconstruction in computer vision without explicitly accounting for\nsensor and pose uncertainty. Using this novel scene representation in robotics\napplications, however, would require accounting for this uncertainty in the\nneural map. The aim of this paper is therefore to propose a novel method for\ntraining {\\em probabilistic neural scene representations} with uncertain\ntraining data that could enable the inclusion of these representations in\nrobotics applications. Acquiring images using cameras or depth sensors contains\ninherent uncertainty, and furthermore, the camera poses used for learning a 3D\nmodel are also imperfect. If these measurements are used for training without\naccounting for their uncertainty, then the resulting models are non-optimal,\nand the resulting scene representations are likely to contain artifacts such as\nblur and un-even geometry. In this work, the problem of uncertainty integration\nto the learning process is investigated by focusing on training with uncertain\ninformation in a probabilistic manner. The proposed method involves explicitly\naugmenting the training likelihood with an uncertainty term such that the\nlearnt probability distribution of the network is minimized with respect to the\ntraining uncertainty. It will be shown that this leads to more accurate image\nrendering quality, in addition to more precise and consistent geometry.\nValidation has been carried out on both synthetic and real datasets showing\nthat the proposed approach outperforms state-of-the-art methods. The results\nshow notably that the proposed method is capable of rendering novel\nhigh-quality views even when the training data is limited.",
    "descriptor": "\nComments: 7 Pages, 6 Figures, 5 Tables. Submitted to IEEE International Conference on Robotics and Automation 2023 (ICRA 2023)\n",
    "authors": [
      "Yassine Ahmine",
      "Arnab Dey",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11677"
  },
  {
    "id": "arXiv:2209.11679",
    "title": "Rethinking Missing Data: Aleatoric Uncertainty-Aware Recommendation",
    "abstract": "Historical interactions are the default choice for recommender model\ntraining, which typically exhibit high sparsity, i.e., most user-item pairs are\nunobserved missing data. A standard choice is treating the missing data as\nnegative training samples and estimating interaction likelihood between\nuser-item pairs along with the observed interactions. In this way, some\npotential interactions are inevitably mislabeled during training, which will\nhurt the model fidelity, hindering the model to recall the mislabeled items,\nespecially the long-tail ones. In this work, we investigate the mislabeling\nissue from a new perspective of aleatoric uncertainty, which describes the\ninherent randomness of missing data. The randomness pushes us to go beyond\nmerely the interaction likelihood and embrace aleatoric uncertainty modeling.\nTowards this end, we propose a new Aleatoric Uncertainty-aware Recommendation\n(AUR) framework that consists of a new uncertainty estimator along with a\nnormal recommender model. According to the theory of aleatoric uncertainty, we\nderive a new recommendation objective to learn the estimator. As the chance of\nmislabeling reflects the potential of a pair, AUR makes recommendations\naccording to the uncertainty, which is demonstrated to improve the\nrecommendation performance of less popular items without sacrificing the\noverall performance. We instantiate AUR on three representative recommender\nmodels: Matrix Factorization (MF), LightGCN, and VAE from mainstream model\narchitectures. Extensive results on two real-world datasets validate the\neffectiveness of AUR w.r.t. better recommendation results, especially on\nlong-tail items.",
    "descriptor": "",
    "authors": [
      "Chenxu Wang",
      "Fuli Feng",
      "Yang Zhang",
      "Qifan Wang",
      "Xunhan Hu",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11679"
  },
  {
    "id": "arXiv:2209.11680",
    "title": "An Overview of Violence Detection Techniques: Current Challenges and  Future Directions",
    "abstract": "The Big Video Data generated in today's smart cities has raised concerns from\nits purposeful usage perspective, where surveillance cameras, among many others\nare the most prominent resources to contribute to the huge volumes of data,\nmaking its automated analysis a difficult task in terms of computation and\npreciseness. Violence Detection (VD), broadly plunging under Action and\nActivity recognition domain, is used to analyze Big Video data for anomalous\nactions incurred due to humans. The VD literature is traditionally based on\nmanually engineered features, though advancements to deep learning based\nstandalone models are developed for real-time VD analysis. This paper focuses\non overview of deep sequence learning approaches along with localization\nstrategies of the detected violence. This overview also dives into the initial\nimage processing and machine learning-based VD literature and their possible\nadvantages such as efficiency against the current complex models.\nFurthermore,the datasets are discussed, to provide an analysis of the current\nmodels, explaining their pros and cons with future directions in VD domain\nderived from an in-depth analysis of the previous methods.",
    "descriptor": "\nComments: Artificial Intelligence Review\n",
    "authors": [
      "Nadia Mumtaz",
      "Naveed Ejaz",
      "Shabana Habib",
      "Syed Muhammad Mohsin",
      "Prayag Tiwari",
      "Shahab S. Band",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11680"
  },
  {
    "id": "arXiv:2209.11682",
    "title": "Meteorological Satellite Images Prediction Based on Deep Multi-scales  Extrapolation Fusion",
    "abstract": "Meteorological satellite imagery is critical for meteorologists. The data\nhave played an important role in monitoring and analyzing weather and climate\nchanges. However, satellite imagery is a kind of observation data and exists a\nsignificant time delay when transmitting the data back to Earth. It is\nimportant to make accurate predictions for meteorological satellite images,\nespecially the nowcasting prediction up to 2 hours ahead. In recent years,\nthere has been growing interest in the research of nowcasting prediction\napplications of weather radar images based on deep learning. Compared to the\nweather radar images prediction problem, the main challenge for meteorological\nsatellite images prediction is the large-scale observation areas and therefore\nthe large sizes of the observation products. Here we present a deep\nmulti-scales extrapolation fusion method, to address the challenge of the\nmeteorological satellite images nowcasting prediction. First, we downsample the\noriginal satellite images dataset with large size to several images datasets\nwith smaller resolutions, then we use a deep spatiotemporal sequences\nprediction method to generate the multi-scales prediction images with different\nresolutions separately. Second, we fuse the multi-scales prediction results to\nthe targeting prediction images with the original size by a conditional\ngenerative adversarial network. The experiments based on the FY-4A\nmeteorological satellite data show that the proposed method can generate\nrealistic prediction images that effectively capture the evolutions of the\nweather systems in detail. We believe that the general idea of this work can be\npotentially applied to other spatiotemporal sequence prediction tasks with a\nlarge size.",
    "descriptor": "",
    "authors": [
      "Fang Huang",
      "Wencong Cheng",
      "PanFeng Wang",
      "ZhiGang Wang",
      "HongHong He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.11682"
  },
  {
    "id": "arXiv:2209.11693",
    "title": "T3VIP: Transformation-based 3D Video Prediction",
    "abstract": "For autonomous skill acquisition, robots have to learn about the physical\nrules governing the 3D world dynamics from their own past experience to predict\nand reason about plausible future outcomes. To this end, we propose a\ntransformation-based 3D video prediction (T3VIP) approach that explicitly\nmodels the 3D motion by decomposing a scene into its object parts and\npredicting their corresponding rigid transformations. Our model is fully\nunsupervised, captures the stochastic nature of the real world, and the\nobservational cues in image and point cloud domains constitute its learning\nsignals. To fully leverage all the 2D and 3D observational signals, we equip\nour model with automatic hyperparameter optimization (HPO) to interpret the\nbest way of learning from them. To the best of our knowledge, our model is the\nfirst generative model that provides an RGB-D video prediction of the future\nfor a static camera. Our extensive evaluation with simulated and real-world\ndatasets demonstrates that our formulation leads to interpretable 3D models\nthat predict future depth videos while achieving on-par performance with 2D\nmodels on RGB video prediction. Moreover, we demonstrate that our model\noutperforms 2D baselines on visuomotor control. Videos, code, dataset, and\npre-trained models are available at this http URL",
    "descriptor": "\nComments: Accepted at the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Iman Nematollahi",
      "Erick Rosete-Beas",
      "Seyed Mahdi B. Azad",
      "Raghu Rajan",
      "Frank Hutter",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11693"
  },
  {
    "id": "arXiv:2209.11694",
    "title": "Rate-Distortion in Image Coding for Machines",
    "abstract": "In recent years, there has been a sharp increase in transmission of images to\nremote servers specifically for the purpose of computer vision. In many\napplications, such as surveillance, images are mostly transmitted for automated\nanalysis, and rarely seen by humans. Using traditional compression for this\nscenario has been shown to be inefficient in terms of bit-rate, likely due to\nthe focus on human based distortion metrics. Thus, it is important to create\nspecific image coding methods for joint use by humans and machines. One way to\ncreate the machine side of such a codec is to perform feature matching of some\nintermediate layer in a Deep Neural Network performing the machine task. In\nthis work, we explore the effects of the layer choice used in training a\nlearnable codec for humans and machines. We prove, using the data processing\ninequality, that matching features from deeper layers is preferable in the\nsense of rate-distortion. Next, we confirm our findings empirically by\nre-training an existing model for scalable human-machine coding. In our\nexperiments we show the trade-off between the human and machine sides of such a\nscalable model, and discuss the benefit of using deeper layers for training in\nthat regard.",
    "descriptor": "",
    "authors": [
      "Alon Harell",
      "Anderson De Andrade",
      "Ivan V. Bajic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.11694"
  },
  {
    "id": "arXiv:2209.11695",
    "title": "Dynamic camera alignment optimization problem based on Fractal  Decomposition based Algorithm",
    "abstract": "In this work, we tackle the Dynamic Optimization Problem (DOP) of IA in a\nreal-world application using a Dynamic Optimization Algorithm (DOA) called\nFractal Decomposition Algorithm (FDA), introduced by recently. We used FDA to\nperform IA on CCTV camera feed from a tunnel. As the camera viewpoint can\nchange by multiple reasons such as wind, maintenance, etc. the alignment is\nrequired to guarantee the correct functioning of video-based traffic security\nsystem.",
    "descriptor": "",
    "authors": [
      "Arcadi Llanza",
      "Nadiya Shvai",
      "Amir Nakib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.11695"
  },
  {
    "id": "arXiv:2209.11697",
    "title": "Edge-oriented Implicit Neural Representation with Channel Tuning",
    "abstract": "Implicit neural representation, which expresses an image as a continuous\nfunction rather than a discrete grid form, is widely used for image processing.\nDespite its outperforming results, there are still remaining limitations on\nrestoring clear shapes of a given signal such as the edges of an image. In this\npaper, we propose Gradient Magnitude Adjustment algorithm which calculates the\ngradient of an image for training the implicit representation. In addition, we\npropose Edge-oriented Representation Network (EoREN) that can reconstruct the\nimage with clear edges by fitting gradient information (Edge-oriented module).\nFurthermore, we add Channel-tuning module to adjust the distribution of given\nsignals so that it solves a chronic problem of fitting gradients. By separating\nbackpropagation paths of the two modules, EoREN can learn true color of the\nimage without hindering the role for gradients. We qualitatively show that our\nmodel can reconstruct complex signals and demonstrate general reconstruction\nability of our model with quantitative results.",
    "descriptor": "",
    "authors": [
      "Wonjoon Chang",
      "Dahee Kwon",
      "Bumjin Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11697"
  },
  {
    "id": "arXiv:2209.11703",
    "title": "Multivariate Wasserstein Functional Connectivity for Autism Screening",
    "abstract": "Most approaches to the estimation of brain functional connectivity from the\nfunctional magnetic resonance imaging (fMRI) data rely on computing some\nmeasure of statistical dependence, or more generally, a distance between\nunivariate representative time series of regions of interest (ROIs) consisting\nof multiple voxels. However, summarizing a ROI's multiple time series with its\nmean or the first principal component (1PC) may result to the loss of\ninformation as, for example, 1PC explains only a small fraction of variance of\nthe multivariate signal of the neuronal activity.\nWe propose to compare ROIs directly, without the use of representative time\nseries, defining a new measure of multivariate connectivity between ROIs, not\nnecessarily consisting of the same number of voxels, based on the Wasserstein\ndistance. We assess the proposed Wasserstein functional connectivity measure on\nthe autism screening task, demonstrating its superiority over commonly used\nunivariate and multivariate functional connectivity measures.",
    "descriptor": "",
    "authors": [
      "Oleg Kachan",
      "Alexander Bernstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11703"
  },
  {
    "id": "arXiv:2209.11704",
    "title": "UAV-miniUGV Hybrid System for Hidden Area Exploration and Manipulation",
    "abstract": "We propose a novel hybrid system (both hardware and software) of an Unmanned\nAerial Vehicle (UAV) carrying a miniature Unmanned Ground Vehicle (miniUGV) to\nperform a complex search and manipulation task. This system leverages\nheterogeneous robots to accomplish a task that cannot be done using a single\nrobot system. It enables the UAV to explore a hidden space with a narrow\nopening through which the miniUGV can easily enter and escape. The hidden space\nis assumed to be navigable for the miniUGV. The miniUGV uses Infrared (IR)\nsensors and a monocular camera to search for an object in the hidden space. The\nproposed system takes advantage of a wider field of view (fov) of the camera as\nwell as the stochastic nature of the object detection algorithms to guide the\nminiUGV in the hidden space to find the object. Upon finding the object the\nminiUGV grabs it using visual servoing and then returns back to its start point\nfrom where the UAV retracts it back and transports the object to a safe place.\nIn case there is no object found in the hidden space, UAV continues the aerial\nsearch. The tethered miniUGV gives the UAV an ability to act beyond its reach\nand perform a search and manipulation task which was not possible before for\nany of the robots individually. The system has a wide range of applications and\nwe have demonstrated its feasibility through repetitive experiments.",
    "descriptor": "",
    "authors": [
      "Durgakant Pushp",
      "Swapnil Kalhapure",
      "Kaushik Das",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11704"
  },
  {
    "id": "arXiv:2209.11708",
    "title": "Multilevel Robustness for 2D Vector Field Feature Tracking, Selection,  and Comparison",
    "abstract": "Critical point tracking is a core topic in scientific visualization for\nunderstanding the dynamic behavior of time-varying vector field data. The\ntopological notion of robustness has been introduced recently to quantify the\nstructural stability of critical points, that is, the robustness of a critical\npoint is the minimum amount of perturbation to the vector field necessary to\ncancel it. A theoretical basis has been established previously that relates\ncritical point tracking with the notion of robustness, in particular, critical\npoints could be tracked based on their closeness in stability, measured by\nrobustness, instead of just distance proximities within the domain. However, in\npractice, the computation of classic robustness may produce artifacts when a\ncritical point is close to the boundary of the domain; thus, we do not have a\ncomplete picture of the vector field behavior within its local neighborhood. To\nalleviate these issues, we introduce a multilevel robustness framework for the\nstudy of 2D time-varying vector fields. We compute the robustness of critical\npoints across varying neighborhoods to capture the multiscale nature of the\ndata and to mitigate the boundary effect suffered by the classic robustness\ncomputation. We demonstrate via experiments that such a new notion of\nrobustness can be combined seamlessly with existing feature tracking algorithms\nto improve the visual interpretability of vector fields in terms of feature\ntracking, selection, and comparison for large-scale scientific simulations. We\nobserve, for the first time, that the minimum multilevel robustness is highly\ncorrelated with physical quantities used by domain scientists in studying a\nreal-world tropical cyclone dataset. Such observation helps to increase the\nphysical interpretability of robustness.",
    "descriptor": "",
    "authors": [
      "Lin Yan",
      "Paul Aaron Ullrich",
      "Luke P. Van Roekel",
      "Bei Wang",
      "Hanqi Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11708"
  },
  {
    "id": "arXiv:2209.11711",
    "title": "Best Prompts for Text-to-Image Models and How to Find Them",
    "abstract": "Recent progress in generative models, especially in text-guided diffusion\nmodels, has enabled the production of aesthetically-pleasing imagery resembling\nthe works of professional human artists. However, one has to carefully compose\nthe textual description, called the prompt, and augment it with a set of\nclarifying keywords. Since aesthetics are challenging to evaluate\ncomputationally, human feedback is needed to determine the optimal prompt\nformulation and keyword combination. In this paper, we present a\nhuman-in-the-loop approach to learning the most useful combination of prompt\nkeywords using a genetic algorithm. We also show how such an approach can\nimprove the aesthetic appeal of images depicting the same descriptions.",
    "descriptor": "\nComments: 12 pages (4 main pages), 4 figures, 4 tables\n",
    "authors": [
      "Nikita Pavlichenko",
      "Dmitry Ustalov"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11711"
  },
  {
    "id": "arXiv:2209.11713",
    "title": "Robust adaptive MPC using control contraction metrics",
    "abstract": "We present a robust adaptive model predictive control (MPC) framework for\nnonlinear continuous-time systems with bounded parametric uncertainty and\nadditive disturbance. We utilize general control contraction metrics (CCMs) to\nparameterize a homothetic tube around a nominal prediction that contains all\nuncertain trajectories. Furthermore, we incorporate model adaptation using\nset-membership estimation. As a result, the proposed MPC formulation is\napplicable to a large class of nonlinear systems, reduces conservatism during\nonline operation, and guarantees robust constraint satisfaction and convergence\nto a neighborhood of the desired setpoint. One of the main technical\ncontributions is the derivation of corresponding tube dynamics based on CCMs\nthat account for the state and input dependent nature of the model mismatch.\nFurthermore, we online optimize over the nominal parameter, which enables\ngeneral set-membership updates for the parametric uncertainty in the MPC.\nBenefits of the proposed homothetic tube MPC and online adaptation are\ndemonstrated using a numerical example involving a planar quadrotor.",
    "descriptor": "",
    "authors": [
      "Andr\u00e1s Sasfi",
      "Melanie N. Zeilinger",
      "Johannes K\u00f6hler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.11713"
  },
  {
    "id": "arXiv:2209.11715",
    "title": "The \"Beatrix'' Resurrections: Robust Backdoor Detection via Gram  Matrices",
    "abstract": "Deep Neural Networks (DNNs) are susceptible to backdoor attacks during\ntraining. The model corrupted in this way functions normally, but when\ntriggered by certain patterns in the input, produces a predefined target label.\nExisting defenses usually rely on the assumption of the universal backdoor\nsetting in which poisoned samples share the same uniform trigger. However,\nrecent advanced backdoor attacks show that this assumption is no longer valid\nin dynamic backdoors where the triggers vary from input to input, thereby\ndefeating the existing defenses.\nIn this work, we propose a novel technique, Beatrix (backdoor detection via\nGram matrix). Beatrix utilizes Gram matrix to capture not only the feature\ncorrelations but also the appropriately high-order information of the\nrepresentations. By learning class-conditional statistics from activation\npatterns of normal samples, Beatrix can identify poisoned samples by capturing\nthe anomalies in activation patterns. To further improve the performance in\nidentifying target labels, Beatrix leverages kernel-based testing without\nmaking any prior assumptions on representation distribution. We demonstrate the\neffectiveness of our method through extensive evaluation and comparison with\nstate-of-the-art defensive techniques. The experimental results show that our\napproach achieves an F1 score of 91.1% in detecting dynamic backdoors, while\nthe state of the art can only reach 36.9%.",
    "descriptor": "\nComments: 19 pages, 23 figures. Code availability: this https URL\n",
    "authors": [
      "Wanlun Ma",
      "Derui Wang",
      "Ruoxi Sun",
      "Minhui Xue",
      "Sheng Wen",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11715"
  },
  {
    "id": "arXiv:2209.11717",
    "title": "Temporal Analysis on Topics Using Word2Vec",
    "abstract": "The present study proposes a novel method of trend detection and\nvisualization - more specifically, modeling the change in a topic over time.\nWhere current models used for the identification and visualization of trends\nonly convey the popularity of a singular word based on stochastic counting of\nusage, the approach in the present study illustrates the popularity and\ndirection that a topic is moving in. The direction in this case is a distinct\nsubtopic within the selected corpus. Such trends are generated by modeling the\nmovement of a topic by using k-means clustering and cosine similarity to group\nthe distances between clusters over time. In a convergent scenario, it can be\ninferred that the topics as a whole are meshing (tokens between topics,\nbecoming interchangeable). On the contrary, a divergent scenario would imply\nthat each topics' respective tokens would not be found in the same context (the\nwords are increasingly different to each other). The methodology was tested on\na group of articles from various media houses present in the 20 Newsgroups\ndataset.",
    "descriptor": "",
    "authors": [
      "Angad Sandhu",
      "Aneesh Edara",
      "Faizan Wajid",
      "Ashok Agrawala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11717"
  },
  {
    "id": "arXiv:2209.11727",
    "title": "Boost CTR Prediction for New Advertisements via Modeling Visual Content",
    "abstract": "Existing advertisements click-through rate (CTR) prediction models are mainly\ndependent on behavior ID features, which are learned based on the historical\nuser-ad interactions. Nevertheless, behavior ID features relying on historical\nuser behaviors are not feasible to describe new ads without previous\ninteractions with users. To overcome the limitations of behavior ID features in\nmodeling new ads, we exploit the visual content in ads to boost the performance\nof CTR prediction models. Specifically, we map each ad into a set of visual IDs\nbased on its visual content. These visual IDs are further used for generating\nthe visual embedding for enhancing CTR prediction models. We formulate the\nlearning of visual IDs into a supervised quantization problem. Due to a lack of\nclass labels for commercial images in advertisements, we exploit image textual\ndescriptions as the supervision to optimize the image extractor for generating\neffective visual IDs. Meanwhile, since the hard quantization is\nnon-differentiable, we soften the quantization operation to make it support the\nend-to-end network training. After mapping each image into visual IDs, we learn\nthe embedding for each visual ID based on the historical user-ad interactions\naccumulated in the past. Since the visual ID embedding depends only on the\nvisual content, it generalizes well to new ads. Meanwhile, the visual ID\nembedding complements the ad behavior ID embedding. Thus, it can considerably\nboost the performance of the CTR prediction models previously relying on\nbehavior ID features for both new ads and ads that have accumulated rich user\nbehaviors. After incorporating the visual ID embedding in the CTR prediction\nmodel of Baidu online advertising, the average CTR of ads improves by 1.46%,\nand the total charge increases by 1.10%.",
    "descriptor": "",
    "authors": [
      "Tan Yu",
      "Zhipeng Jin",
      "Jie Liu",
      "Yi Yang",
      "Hongliang Fei",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11727"
  },
  {
    "id": "arXiv:2209.11737",
    "title": "Semantic scene descriptions as an objective of human vision",
    "abstract": "Interpreting the meaning of a visual scene requires not only identification\nof its constituent objects, but also a rich semantic characterization of object\ninterrelations. Here, we study the neural mechanisms underlying visuo-semantic\ntransformations by applying modern computational techniques to a large-scale 7T\nfMRI dataset of human brain responses elicited by complex natural scenes. Using\nsemantic embeddings obtained by applying linguistic deep learning models to\nhuman-generated scene descriptions, we identify a widely distributed network of\nbrain regions that encode semantic scene descriptions. Importantly, these\nsemantic embeddings better explain activity in these regions than traditional\nobject category labels. In addition, they are effective predictors of activity\ndespite the fact that the participants did not actively engage in a semantic\ntask, suggesting that visuo-semantic transformations are a default mode of\nvision. In support of this view, we then show that highly accurate\nreconstructions of scene captions can be directly linearly decoded from\npatterns of brain activity. Finally, a recurrent convolutional neural network\ntrained on semantic embeddings further outperforms semantic embeddings in\npredicting brain activity, providing a mechanistic model of the brain's\nvisuo-semantic transformations. Together, these experimental and computational\nresults suggest that transforming visual input into rich semantic scene\ndescriptions may be a central objective of the visual system, and that focusing\nefforts on this new objective may lead to improved models of visual information\nprocessing in the human brain.",
    "descriptor": "",
    "authors": [
      "Adrien Doerig",
      "Tim C Kietzmann",
      "Emily Allen",
      "Yihan Wu",
      "Thomas Naselaris",
      "Kendrick Kay",
      "Ian Charest"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.11737"
  },
  {
    "id": "arXiv:2209.11739",
    "title": "Catoptric Light can be Dangerous: Effective Physical-World Attack by  Natural Phenomenon",
    "abstract": "Deep neural networks (DNNs) have achieved great success in many tasks.\nTherefore, it is crucial to evaluate the robustness of advanced DNNs. The\ntraditional methods use stickers as physical perturbations to fool the\nclassifiers, which is difficult to achieve stealthiness and there exists\nprinting loss. Some new types of physical attacks use light beam to perform\nattacks (e.g., laser, projector), whose optical patterns are artificial rather\nthan natural. In this work, we study a new type of physical attack, called\nadversarial catoptric light (AdvCL), in which adversarial perturbations are\ngenerated by common natural phenomena, catoptric light, to achieve stealthy and\nnaturalistic adversarial attacks against advanced DNNs in physical\nenvironments. Carefully designed experiments demonstrate the effectiveness of\nthe proposed method in simulated and real-world environments. The attack\nsuccess rate is 94.90% in a subset of ImageNet and 83.50% in the real-world\nenvironment. We also discuss some of AdvCL's transferability and defense\nstrategy against this attack.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.09652, arXiv:2209.02430\n",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11739"
  },
  {
    "id": "arXiv:2209.11740",
    "title": "On the Shift Invariance of Max Pooling Feature Maps in Convolutional  Neural Networks",
    "abstract": "In this paper, we aim to improve the mathematical interpretability of\nconvolutional neural networks for image classification. When trained on natural\nimage datasets, such networks tend to learn parameters in the first layer that\nclosely resemble oriented Gabor filters. By leveraging the properties of\ndiscrete Gabor-like convolutions, we prove that, under specific conditions,\nfeature maps computed by the subsequent max pooling operator tend to\napproximate the modulus of complex Gabor-like coefficients, and as such, are\nstable with respect to certain input shifts. We then compute a probabilistic\nmeasure of shift invariance for these layers. More precisely, we show that some\nfilters, depending on their frequency and orientation, are more likely than\nothers to produce stable image representations. We experimentally validate our\ntheory by considering a deterministic feature extractor based on the dual-tree\nwavelet packet transform, a particular case of discrete Gabor-like\ndecomposition. We demonstrate a strong correlation between shift invariance on\nthe one hand and similarity with complex modulus on the other hand.",
    "descriptor": "",
    "authors": [
      "Hubert Leterme",
      "K\u00e9vin Polisano",
      "Val\u00e9rie Perrier",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11740"
  },
  {
    "id": "arXiv:2209.11741",
    "title": "Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking  Neural Networks with Learnable Neuronal Dynamics",
    "abstract": "Event-based cameras have recently shown great potential for high-speed motion\nestimation owing to their ability to capture temporally rich information\nasynchronously. Spiking Neural Networks (SNNs), with their neuro-inspired\nevent-driven processing can efficiently handle such asynchronous data, while\nneuron models such as the leaky-integrate and fire (LIF) can keep track of the\nquintessential timing information contained in the inputs. SNNs achieve this by\nmaintaining a dynamic state in the neuron memory, retaining important\ninformation while forgetting redundant data over time. Thus, we posit that SNNs\nwould allow for better performance on sequential regression tasks compared to\nsimilarly sized Analog Neural Networks (ANNs). However, deep SNNs are difficult\nto train due to vanishing spikes at later layers. To that effect, we propose an\nadaptive fully-spiking framework with learnable neuronal dynamics to alleviate\nthe spike vanishing problem. We utilize surrogate gradient-based\nbackpropagation through time (BPTT) to train our deep SNNs from scratch. We\nvalidate our approach for the task of optical flow estimation on the\nMulti-Vehicle Stereo Event-Camera (MVSEC) dataset and the DSEC-Flow dataset.\nOur experiments on these datasets show an average reduction of 13% in average\nendpoint error (AEE) compared to state-of-the-art ANNs. We also explore several\ndown-scaled models and observe that our SNN models consistently outperform\nsimilarly sized ANNs offering 10%-16% lower AEE. These results demonstrate the\nimportance of SNNs for smaller models and their suitability at the edge. In\nterms of efficiency, our SNNs offer substantial savings in network parameters\n(48x) and computational energy (51x) while attaining ~10% lower EPE compared to\nthe state-of-the-art ANN implementations.",
    "descriptor": "",
    "authors": [
      "Adarsh Kumar Kosta",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11741"
  },
  {
    "id": "arXiv:2209.11745",
    "title": "Unified Algorithms for RL with Decision-Estimation Coefficients:  No-Regret, PAC, and Reward-Free Learning",
    "abstract": "Finding unified complexity measures and algorithms for sample-efficient\nlearning is a central topic of research in reinforcement learning (RL). The\nDecision-Estimation Coefficient (DEC) is recently proposed by Foster et al.\n(2021) as a necessary and sufficient complexity measure for sample-efficient\nno-regret RL. This paper makes progress towards a unified theory for RL with\nthe DEC framework. First, we propose two new DEC-type complexity measures:\nExplorative DEC (EDEC), and Reward-Free DEC (RFDEC). We show that they are\nnecessary and sufficient for sample-efficient PAC learning and reward-free\nlearning, thereby extending the original DEC which only captures no-regret\nlearning. Next, we design new unified sample-efficient algorithms for all three\nlearning goals. Our algorithms instantiate variants of the\nEstimation-To-Decisions (E2D) meta-algorithm with a strong and general model\nestimation subroutine. Even in the no-regret setting, our algorithm E2D-TA\nimproves upon the algorithms of Foster et al. (2021) which require either\nbounding a variant of the DEC which may be prohibitively large, or designing\nproblem-specific estimation subroutines. As applications, we recover existing\nand obtain new sample-efficient learning results for a wide range of tractable\nRL problems using essentially a single algorithm. Finally, as a connection, we\nre-analyze two existing optimistic model-based algorithms based on Posterior\nSampling or Maximum Likelihood Estimation, showing that they enjoy similar\nregret bounds as E2D-TA under similar structural conditions as the DEC.",
    "descriptor": "",
    "authors": [
      "Fan Chen",
      "Song Mei",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11745"
  },
  {
    "id": "arXiv:2209.11746",
    "title": "Evaluating Agent Interactions Through Episodic Knowledge Graphs",
    "abstract": "We present a new method based on episodic Knowledge Graphs (eKGs) for\nevaluating (multimodal) conversational agents in open domains. This graph is\ngenerated by interpreting raw signals during conversation and is able to\ncapture the accumulation of knowledge over time. We apply structural and\nsemantic analysis of the resulting graphs and translate the properties into\nqualitative measures. We compare these measures with existing automatic and\nmanual evaluation metrics commonly used for conversational agents. Our results\nshow that our Knowledge-Graph-based evaluation provides more qualitative\ninsights into interaction and the agent's behavior.",
    "descriptor": "",
    "authors": [
      "Selene B\u00e1ez Santamar\u00eda",
      "Piek Vossen",
      "Thomas Baier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11746"
  },
  {
    "id": "arXiv:2209.11748",
    "title": "GLSO: Grammar-guided Latent Space Optimization for Sample-efficient  Robot Design Automation",
    "abstract": "Robots have been used in all sorts of automation, and yet the design of\nrobots remains mainly a manual task. We seek to provide design tools to\nautomate the design of robots themselves. An important challenge in robot\ndesign automation is the large and complex design search space which grows\nexponentially with the number of components, making optimization difficult and\nsample inefficient. In this work, we present Grammar-guided Latent Space\nOptimization (GLSO), a framework that transforms design automation into a\nlow-dimensional continuous optimization problem by training a graph variational\nautoencoder (VAE) to learn a mapping between the graph-structured design space\nand a continuous latent space. This transformation allows optimization to be\nconducted in a continuous latent space, where sample efficiency can be\nsignificantly boosted by applying algorithms such as Bayesian Optimization.\nGLSO guides training of the VAE using graph grammar rules and robot world space\nfeatures, such that the learned latent space focus on valid robots and is\neasier for the optimization algorithm to explore. Importantly, the trained VAE\ncan be reused to search for designs specialized to multiple different tasks\nwithout retraining. We evaluate GLSO by designing robots for a set of\nlocomotion tasks in simulation, and demonstrate that our method outperforms\nrelated state-of-the-art robot design automation methods.",
    "descriptor": "",
    "authors": [
      "Jiaheng Hu",
      "Julian Whiman",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11748"
  },
  {
    "id": "arXiv:2209.11750",
    "title": "Lightweight Transformers for Human Activity Recognition on Mobile  Devices",
    "abstract": "Human Activity Recognition (HAR) on mobile devices has shown to be achievable\nwith lightweight neural models learned from data generated by the user's\ninertial measurement units (IMUs). Most approaches for instanced-based HAR have\nused Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTMs), or a\ncombination of the two to achieve state-of-the-art results with real-time\nperformances. Recently, the Transformers architecture in the language\nprocessing domain and then in the vision domain has pushed further the\nstate-of-the-art over classical architectures. However, such Transformers\narchitecture is heavyweight in computing resources, which is not well suited\nfor embedded applications of HAR that can be found in the pervasive computing\ndomain. In this study, we present Human Activity Recognition Transformer\n(HART), a lightweight, sensor-wise transformer architecture that has been\nspecifically adapted to the domain of the IMUs embedded on mobile devices. Our\nexperiments on HAR tasks with several publicly available datasets show that\nHART uses fewer FLoating-point Operations Per Second (FLOPS) and parameters\nwhile outperforming current state-of-the-art results. Furthermore, we present\nevaluations across various architectures on their performances in heterogeneous\nenvironments and show that our models can better generalize on different\nsensing devices or on-body positions.",
    "descriptor": "",
    "authors": [
      "Sannara EK",
      "Fran\u00e7ois Portet",
      "Philippe Lalanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11750"
  },
  {
    "id": "arXiv:2209.11755",
    "title": "Promptagator: Few-shot Dense Retrieval From 8 Examples",
    "abstract": "Much recent research on information retrieval has focused on how to transfer\nfrom one task (typically with abundant supervised data) to various other tasks\nwhere supervision is limited, with the implicit assumption that it is possible\nto generalize from one task to all the rest. However, this overlooks the fact\nthat there are many diverse and unique retrieval tasks, each targeting\ndifferent search intents, queries, and search domains. In this paper, we\nsuggest to work on Few-shot Dense Retrieval, a setting where each task comes\nwith a short description and a few examples. To amplify the power of a few\nexamples, we propose Prompt-base Query Generation for Retriever (Promptagator),\nwhich leverages large language models (LLM) as a few-shot query generator, and\ncreates task-specific retrievers based on the generated data. Powered by LLM's\ngeneralization ability, Promptagator makes it possible to create task-specific\nend-to-end retrievers solely based on a few examples {without} using Natural\nQuestions or MS MARCO to train %question generators or dual encoders.\nSurprisingly, LLM prompting with no more than 8 examples allows dual encoders\nto outperform heavily engineered models trained on MS MARCO like ColBERT v2 by\nmore than 1.2 nDCG on average on 11 retrieval sets. Further training\nstandard-size re-rankers using the same generated data yields another 5.0 point\nnDCG improvement. Our studies determine that query generation can be far more\neffective than previously observed, especially when a small amount of\ntask-specific knowledge is given.",
    "descriptor": "",
    "authors": [
      "Zhuyun Dai",
      "Vincent Y. Zhao",
      "Ji Ma",
      "Yi Luan",
      "Jianmo Ni",
      "Jing Lu",
      "Anton Bakalov",
      "Kelvin Guu",
      "Keith B. Hall",
      "Ming-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.11755"
  },
  {
    "id": "arXiv:2209.11757",
    "title": "Conditional GANs for Sonar Image Filtering with Applications to  Underwater Occupancy Mapping",
    "abstract": "Underwater robots typically rely on acoustic sensors like sonar to perceive\ntheir surroundings. However, these sensors are often inundated with multiple\nsources and types of noise, which makes using raw data for any meaningful\ninference with features, objects, or boundary returns very difficult. While\nseveral conventional methods of dealing with noise exist, their success rates\nare unsatisfactory. This paper presents a novel application of conditional\nGenerative Adversarial Networks (cGANs) to train a model to produce noise-free\nsonar images, outperforming several conventional filtering methods. Estimating\nfree space is crucial for autonomous robots performing active exploration and\nmapping. Thus, we apply our approach to the task of underwater occupancy\nmapping and show superior free and occupied space inference when compared to\nconventional methods.",
    "descriptor": "\nComments: 7 pages, 13 figures. This paper is under review\n",
    "authors": [
      "Tianxiang Lin",
      "Akshay Hinduja",
      "Mohamad Qadri",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11757"
  },
  {
    "id": "arXiv:2209.10797",
    "title": "DFX: A Low-latency Multi-FPGA Appliance for Accelerating  Transformer-based Text Generation",
    "abstract": "Transformer is a deep learning language model widely used for natural\nlanguage processing (NLP) services in datacenters. Among transformer models,\nGenerative Pre-trained Transformer (GPT) has achieved remarkable performance in\ntext generation, or natural language generation (NLG), which needs the\nprocessing of a large input context in the summarization stage, followed by the\ngeneration stage that produces a single word at a time. The conventional\nplatforms such as GPU are specialized for the parallel processing of large\ninputs in the summarization stage, but their performance significantly degrades\nin the generation stage due to its sequential characteristic. Therefore, an\nefficient hardware platform is required to address the high latency caused by\nthe sequential characteristic of text generation.\nIn this paper, we present DFX, a multi-FPGA acceleration appliance that\nexecutes GPT-2 model inference end-to-end with low latency and high throughput\nin both summarization and generation stages. DFX uses model parallelism and\noptimized dataflow that is model-and-hardware-aware for fast simultaneous\nworkload execution among devices. Its compute cores operate on custom\ninstructions and provide GPT-2 operations end-to-end. We implement the proposed\nhardware architecture on four Xilinx Alveo U280 FPGAs and utilize all of the\nchannels of the high bandwidth memory (HBM) and the maximum number of compute\nresources for high hardware efficiency. DFX achieves 5.58x speedup and 3.99x\nenergy efficiency over four NVIDIA V100 GPUs on the modern GPT-2 model. DFX is\nalso 8.21x more cost-effective than the GPU appliance, suggesting that it is a\npromising solution for text generation workloads in cloud datacenters.",
    "descriptor": "\nComments: Extension of HOTCHIPS 2022 and accepted in MICRO 2022\n",
    "authors": [
      "Seongmin Hong",
      "Seungjae Moon",
      "Junsoo Kim",
      "Sungjae Lee",
      "Minsub Kim",
      "Dongsoo Lee",
      "Joo-Young Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10797"
  },
  {
    "id": "arXiv:2209.11230",
    "title": "A Trio-Method for Retinal Vessel Segmentation using Image Processing",
    "abstract": "Inner Retinal neurons are a most essential part of the retina and they are\nsupplied with blood via retinal vessels. This paper primarily focuses on the\nsegmentation of retinal vessels using a triple preprocessing approach. DRIVE\ndatabase was taken into consideration and preprocessed by Gabor Filtering,\nGaussian Blur, and Edge Detection by Sobel and Pruning. Segmentation was driven\nout by 2 proposed U-Net architectures. Both the architectures were compared in\nterms of all the standard performance metrics. Preprocessing generated varied\ninteresting results which impacted the results shown by the UNet architectures\nfor segmentation. This real-time deployment can help in the efficient\npre-processing of images with better segmentation and detection.",
    "descriptor": "\nComments: Accepted at 26th UK Conference on Medical Image Understanding and Analysis (MIUA-2022) (Abstract short paper)\n",
    "authors": [
      "Mahendra Kumar Gourisaria",
      "Vinayak Singh",
      "Manoj Sahni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11230"
  },
  {
    "id": "arXiv:2209.11232",
    "title": "Hierarchical Graph Convolutional Network Built by Multiscale Atlases for  Brain Disorder Diagnosis Using Functional Connectivity",
    "abstract": "Functional connectivity network (FCN) data from functional magnetic resonance\nimaging (fMRI) is increasingly used for the diagnoses of brain disorders.\nHowever, state-of-the-art studies used to build the FCN using a single brain\nparcellation atlas at a certain spatial scale, which largely neglected\nfunctional interactions across different spatial scales in hierarchical\nmanners. In this study, we propose a novel framework to perform multiscale FCN\nanalysis for brain disorder diagnosis. We first use a set of well-defined\nmultiscale atlases to compute multiscale FCNs. Then, we utilize biologically\nmeaningful brain hierarchical relationships among the regions in multiscale\natlases to perform nodal pooling across multiple spatial scales, namely\n\"Atlas-guided Pooling\". Accordingly, we propose a Multiscale-Atlases-based\nHierarchical Graph Convolutional Network (MAHGCN), built on the stacked layers\nof graph convolution and the atlas-guided pooling, for a comprehensive\nextraction of diagnostic information from multiscale FCNs. Experiments on\nneuroimaging data from 1792 subjects demonstrate the effectiveness of our\nproposed method in the diagnoses of Alzheimer's disease (AD), the prodromal\nstage of AD (i.e., mild cognitive impairment [MCI]), as well as autism spectrum\ndisorder (ASD), with accuracy of 88.9%, 78.6%, and 72.7% respectively. All\nresults show significant advantages of our proposed method over other competing\nmethods. This study not only demonstrates the feasibility of brain disorder\ndiagnosis using resting-state fMRI empowered by deep learning, but also\nhighlights that the functional interactions in the multiscale brain hierarchy\nare worth being explored and integrated into deep learning network\narchitectures for better understanding the neuropathology of brain disorders.",
    "descriptor": "",
    "authors": [
      "Mianxin Liu",
      "Han Zhang",
      "Feng Shi",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.11232"
  },
  {
    "id": "arXiv:2209.11233",
    "title": "Assessing Robustness of EEG Representations under Data-shifts via Latent  Space and Uncertainty Analysis",
    "abstract": "The recent availability of large datasets in bio-medicine has inspired the\ndevelopment of representation learning methods for multiple healthcare\napplications. Despite advances in predictive performance, the clinical utility\nof such methods is limited when exposed to real-world data. Here we develop\nmodel diagnostic measures to detect potential pitfalls during deployment\nwithout assuming access to external data. Specifically, we focus on modeling\nrealistic data shifts in electrophysiological signals (EEGs) via data\ntransforms, and extend the conventional task-based evaluations with analyses of\na) model's latent space and b) predictive uncertainty, under these transforms.\nWe conduct experiments on multiple EEG feature encoders and two clinically\nrelevant downstream tasks using publicly available large-scale clinical EEGs.\nWithin this experimental setting, our results suggest that measures of latent\nspace integrity and model uncertainty under the proposed data shifts may help\nanticipate performance degradation during deployment.",
    "descriptor": "\nComments: Preprint under review\n",
    "authors": [
      "Neeraj Wagh",
      "Jionghao Wei",
      "Samarth Rawal",
      "Brent M. Berry",
      "Yogatheesan Varatharajah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11233"
  },
  {
    "id": "arXiv:2209.11259",
    "title": "Computational Discovery of Energy-Efficient Heat Treatment for  Microstructure Design using Deep Reinforcement Learning",
    "abstract": "Deep Reinforcement Learning (DRL) is employed to develop autonomously\noptimized and custom-designed heat-treatment processes that are both,\nmicrostructure-sensitive and energy efficient. Different from conventional\nsupervised machine learning, DRL does not rely on static neural network\ntraining from data alone, but a learning agent autonomously develops optimal\nsolutions, based on reward and penalty elements, with reduced or no\nsupervision. In our approach, a temperature-dependent Allen-Cahn model for\nphase transformation is used as the environment for the DRL agent, serving as\nthe model world in which it gains experience and takes autonomous decisions.\nThe agent of the DRL algorithm is controlling the temperature of the system, as\na model furnace for heat-treatment of alloys. Microstructure goals are defined\nfor the agent based on the desired microstructure of the phases. After\ntraining, the agent can generate temperature-time profiles for a variety of\ninitial microstructure states to reach the final desired microstructure state.\nThe agent's performance and the physical meaning of the heat-treatment profiles\ngenerated are investigated in detail. In particular, the agent is capable of\ncontrolling the temperature to reach the desired microstructure starting from a\nvariety of initial conditions. This capability of the agent in handling a\nvariety of conditions paves the way for using such an approach also for\nrecycling-oriented heat treatment process design where the initial composition\ncan vary from batch to batch, due to impurity intrusion, and also for the\ndesign of energy-efficient heat treatments. For testing this hypothesis, an\nagent without penalty on the total consumed energy is compared with one that\nconsiders energy costs. The energy cost penalty is imposed as an additional\ncriterion on the agent for finding the optimal temperature-time profile.",
    "descriptor": "",
    "authors": [
      "Jaber R. Mianroodi",
      "Nima H. Siboni",
      "Dierk Raabe"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11259"
  },
  {
    "id": "arXiv:2209.11282",
    "title": "Automated detection of Alzheimer disease using MRI images and deep  neural networks- A review",
    "abstract": "Early detection of Alzheimer disease is crucial for deploying interventions\nand slowing the disease progression. A lot of machine learning and deep\nlearning algorithms have been explored in the past decade with the aim of\nbuilding an automated detection for Alzheimer. Advancements in data\naugmentation techniques and advanced deep learning architectures have opened up\nnew frontiers in this field, and research is moving at a rapid speed. Hence,\nthe purpose of this survey is to provide an overview of recent research on deep\nlearning models for Alzheimer disease diagnosis. In addition to categorizing\nthe numerous data sources, neural network architectures, and commonly used\nassessment measures, we also classify implementation and reproducibility. Our\nobjective is to assist interested researchers in keeping up with the newest\ndevelopments and in reproducing earlier investigations as benchmarks. In\naddition, we also indicate future research directions for this topic.",
    "descriptor": "\nComments: 22 Pages, 5 Figures, 7 Tables\n",
    "authors": [
      "Narotam Singh",
      "Patteshwari.D",
      "Neha Soni",
      "Amita Kapoor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11282"
  },
  {
    "id": "arXiv:2209.11329",
    "title": "Iterative Qubits Management for Quantum Index Searching in a Hybrid  System",
    "abstract": "Recent advances in quantum computing systems attract tremendous attention.\nCommercial companies, such as IBM, Amazon, and IonQ, have started to provide\naccess to noisy intermediate-scale quantum computers. Researchers and\nentrepreneurs attempt to deploy their applications that aim to achieve a\nquantum speedup. Grover's algorithm and quantum phase estimation are the\nfoundations of many applications with the potential for such a speedup. While\nthese algorithms, in theory, obtain marvelous performance, deploying them on\nexisting quantum devices is a challenging task. For example, quantum phase\nestimation requires extra qubits and a large number of controlled operations,\nwhich are impractical due to low-qubit and noisy hardware. To fully utilize the\nlimited onboard qubits, we propose IQuCS, which aims at index searching and\ncounting in a quantum-classical hybrid system. IQuCS is based on Grover's\nalgorithm. From the problem size perspective, it analyzes results and tries to\nfilter out unlikely data points iteratively. A reduced data set is fed to the\nquantum computer in the next iteration. With a reduction in the problem size,\nIQuCS requires fewer qubits iteratively, which provides the potential for a\nshared computing environment. We implement IQuCS with Qiskit and conduct\nintensive experiments. The results demonstrate that it reduces qubits\nconsumption by up to 66.2%.",
    "descriptor": "",
    "authors": [
      "Wenrui Mu",
      "Ying Mao",
      "Long Cheng",
      "Qingle Wang",
      "Weiwen Jiang",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.11329"
  },
  {
    "id": "arXiv:2209.11339",
    "title": "Machine Space I: Weak exponentials and quantification over compact  spaces",
    "abstract": "Topology may be interpreted as the study of verifiability, where opens\ncorrespond to semi-decidable properties. In this paper we make a distinction\nbetween verifiable properties themselves and processes which carry out the\nverification procedure. The former are simply opens, while we call the latter\nmachines. Given a frame presentation $\\mathcal{O} X = \\langle G \\mid R\\rangle$\nwe construct a space of machines $\\Sigma^{\\Sigma^G}$ whose points are given by\nformal combinations of basic machines corresponding to generators in $G$. This\ncomes equipped with an `evaluation' map making it a weak exponential for\n$\\Sigma^X$.\nWhen it exists, the true exponential $\\Sigma^X$ occurs as a retract of\nmachine space. We argue this helps explain why some spaces are exponentiable\nand others not. We then use machine space to study compactness by giving a\npurely topological version of Escard\\'o's algorithm for universal\nquantification over compact spaces in finite time. Finally, we relate our study\nof machine space to domain theory and domain embeddings.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Peter F. Faul",
      "Graham Manuell"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.11339"
  },
  {
    "id": "arXiv:2209.11347",
    "title": "A second moment proof of the spread lemma",
    "abstract": "This note concerns a well-known result which we term the ``spread lemma,''\nwhich establishes the existence (with high probability) of a desired structure\nin a random set. The spread lemma was central to two recent celebrated results:\n(a) the improved bounds of Alweiss, Lovett, Wu, and Zhang (2019) on the\nErd\\H{o}s-Rado sunflower conjecture; and (b) the proof of the fractional\nKahn--Kalai conjecture by Frankston, Kahn, Narayanan and Park (2019). While the\nlemma was first proved (and later refined) by delicate counting arguments,\nalternative proofs have also been given, via Shannon's noiseless coding theorem\n(Rao, 2019), and also via manipulations of Shannon entropy bounds (Tao, 2020).\nIn this note we present a new proof of the spread lemma, that takes advantage\nof an explicit recasting of the proof in the language of Bayesian statistical\ninference. We show that from this viewpoint the proof proceeds in a\nstraightforward and principled probabilistic manner, leading to a truncated\nsecond moment calculation which concludes the proof. The proof can also be\nviewed as a demonstration of the ``planting trick'' introduced by Achlioptas\nand Coga-Oghlan (2008) in the study of random constraint satisfaction problems.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Elchanan Mossel",
      "Jonathan Niles-Weed",
      "Nike Sun",
      "Ilias Zadik"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.11347"
  },
  {
    "id": "arXiv:2209.11361",
    "title": "Quantum Entanglement with Self-stabilizing Token Ring for Fault-tolerant  Distributed Quantum Computing System",
    "abstract": "This paper shows how to construct quantum entanglement states of n qubits\nbased on a self-stabilizing token ring algorithm. The entangled states can be\napplied to the fields of the quantum network, quantum Internet, distributed\nquantum computing, and quantum cloud. To the best of our knowledge, this is the\nfirst attempt to construct quantum entanglement based on the self-stabilizing\nalgorithm. By the quantum circuit implementation based on the IBM Quantum\nExperience platform, it is demonstrated that the construction indeed can\nachieve specific n qubit entangled states, which in turn can be used to\ncirculate a token in a quantum network or quantum Internet for building a\ndistributed quantum computing system (DQCS). The built DQCS is fault-tolerant\nin the sense that it can tolerate transient faults such as occasional errors of\nentangled quantum states.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Jehn-Ruey Jiang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.11361"
  },
  {
    "id": "arXiv:2209.11371",
    "title": "Ensemble Kalman Methods: A Mean Field Perspective",
    "abstract": "This paper provides a unifying mean field based framework for the derivation\nand analysis of ensemble Kalman methods. Both state estimation and parameter\nestimation problems are considered, and formulations in both discrete and\ncontinuous time are employed. For state estimation problems both the control\nand filtering approaches are studied; analogously, for parameter estimation\n(inverse) problems the optimization and Bayesian perspectives are both studied.\nThe approach taken unifies a wide-ranging literature in the field, provides a\nframework for analysis of ensemble Kalman methods, and suggests open problems.",
    "descriptor": "",
    "authors": [
      "Edoardo Calvello",
      "Sebastian Reich",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11371"
  },
  {
    "id": "arXiv:2209.11418",
    "title": "Guaranteed Privacy of Distributed Nonconvex Optimization via  Mixed-Monotone Functional Perturbations",
    "abstract": "In this paper, we introduce a new notion of guaranteed privacy that requires\nthat the change of the range of the corresponding inclusion function to the\ntrue function is small. In particular, leveraging mixed-monotone inclusion\nfunctions, we propose a privacy-preserving mechanism for nonconvex distributed\noptimization, which is based on deterministic, but unknown, affine perturbation\nof the local objective functions, which is stronger than probabilistic\ndifferential privacy. The design requires a robust optimization method to\ncharacterize the best accuracy that can be achieved by an optimal perturbation.\nSubsequently, this is used to guide the refinement of a guaranteed-private\nperturbation mechanism that can achieve a quantifiable accuracy via a\ntheoretical upper bound that is shown to be independent of the chosen\noptimization algorithm.",
    "descriptor": "",
    "authors": [
      "Mohammad Khajenejad",
      "Sonia Martinez"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.11418"
  },
  {
    "id": "arXiv:2209.11431",
    "title": "Learning to screen Glaucoma like the ophthalmologists",
    "abstract": "GAMMA Challenge is organized to encourage the AI models to screen the\nglaucoma from a combination of 2D fundus image and 3D optical coherence\ntomography volume, like the ophthalmologists.",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11431"
  },
  {
    "id": "arXiv:2209.11433",
    "title": "The Kriston AI System for the VoxCeleb Speaker Recognition Challenge  2022",
    "abstract": "This technical report describes our system for track 1, 2 and 4 of the\nVoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22). By combining several\nResNet variants, our submission for track 1 attained a minDCF of 0:090 with EER\n1:401%. By further incorporating three fine-tuned pre-trained models, our\nsubmission for track 2 achieved a minDCF of 0:072 with EER 1:119%. For track 4,\nour system consisted of voice activity detection (VAD), speaker embedding\nextraction, agglomerative hierarchical clustering (AHC) followed by a\nre-clustering step based on a Bayesian hidden Markov model and overlapped\nspeech detection and handling. Our submission for track 4 achieved a\ndiarisation error rate (DER) of 4.86%. The submissions all ranked the 2nd\nplaces for the corresponding tracks.",
    "descriptor": "\nComments: System description of VoxSRC 2022: track 1, 2 and 4\n",
    "authors": [
      "Qutang Cai",
      "Guoqiang Hong",
      "Zhijian Ye",
      "Ximin Li",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.11433"
  },
  {
    "id": "arXiv:2209.11452",
    "title": "From String Detection to Orthogonal Vector Problem",
    "abstract": "Considering Grover's Search Algorithm (GSA) with the standard diffuser stage\napplied, we revisit the $3$-qubit unique String Detection Problem (SDP) and\nextend the algorithm to $4$-qubit SDP with multiple winners. We then\ninvestigate unstructured search problems with non-uniform distributions and\ndefine the Orthogonal Vector Problem (OVP) under quantum settings. Although no\nnumerically stable results is reached under the original GSA framework, we\nprovide intuition behind our implementation and further observations on OVP. We\nfurther perform a special case analysis under the modified GSA framework which\naims to stabilize the final measurement under arbitrary initial distribution.\nBased on the result of the analysis, we generalize the initial condition under\nwhich neither the original framework nor the modification works. Instead of\nutilizing GSA, we also propose a short-depth circuit that can calculate the\northogonal pair for a given vector represented as a binary string with constant\nruntime.",
    "descriptor": "",
    "authors": [
      "Yunhao Wang",
      "Tianyuan Zheng",
      "Lior Horesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.11452"
  },
  {
    "id": "arXiv:2209.11455",
    "title": "Modular Degradation Simulation and Restoration for Under-Display Camera",
    "abstract": "Under-display camera (UDC) provides an elegant solution for full-screen\nsmartphones. However, UDC captured images suffer from severe degradation since\nsensors lie under the display. Although this issue can be tackled by image\nrestoration networks, these networks require large-scale image pairs for\ntraining. To this end, we propose a modular network dubbed MPGNet trained using\nthe generative adversarial network (GAN) framework for simulating UDC imaging.\nSpecifically, we note that the UDC imaging degradation process contains\nbrightness attenuation, blurring, and noise corruption. Thus we model each\ndegradation with a characteristic-related modular network, and all modular\nnetworks are cascaded to form the generator. Together with a pixel-wise\ndiscriminator and supervised loss, we can train the generator to simulate the\nUDC imaging degradation process. Furthermore, we present a Transformer-style\nnetwork named DWFormer for UDC image restoration. For practical purposes, we\nuse depth-wise convolution instead of the multi-head self-attention to\naggregate local spatial information. Moreover, we propose a novel channel\nattention module to aggregate global information, which is critical for\nbrightness recovery. We conduct evaluations on the UDC benchmark, and our\nmethod surpasses the previous state-of-the-art models by 1.23 dB on the P-OLED\ntrack and 0.71 dB on the T-OLED track, respectively.",
    "descriptor": "",
    "authors": [
      "Yang Zhou",
      "Yuda Song",
      "Xin Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11455"
  },
  {
    "id": "arXiv:2209.11456",
    "title": "Segmentation-based Information Extraction and Amalgamation in Fundus  Images for Glaucoma Detection",
    "abstract": "Glaucoma is a severe blinding disease, for which automatic detection methods\nare urgently needed to alleviate the scarcity of ophthalmologists. Many works\nhave proposed to employ deep learning methods that involve the segmentation of\noptic disc and cup for glaucoma detection, in which the segmentation process is\noften considered merely as an upstream sub-task. The relationship between\nfundus images and segmentation masks in terms of joint decision-making in\nglaucoma assessment is rarely explored. We propose a novel segmentation-based\ninformation extraction and amalgamation method for the task of glaucoma\ndetection, which leverages the robustness of segmentation masks without\ndisregarding the rich information in the original fundus images. Experimental\nresults on both private and public datasets demonstrate that our proposed\nmethod outperforms all models that utilize solely either fundus images or\nmasks.",
    "descriptor": "",
    "authors": [
      "Yanni Wang",
      "Gang Yang",
      "Dayong Ding",
      "Jianchun Zao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11456"
  },
  {
    "id": "arXiv:2209.11495",
    "title": "Image Classification using Sequence of Pixels",
    "abstract": "This study compares sequential image classification methods based on\nrecurrent neural networks. We describe methods based on recurrent neural\nnetworks such as Long-Short-Term memory(LSTM), bidirectional Long-Short-Term\nmemory(BiLSTM) architectures, etc. We also review the state-of-the-art\nsequential image classification architectures. We mainly focus on LSTM, BiLSTM,\ntemporal convolution network, and independent recurrent neural network\narchitecture in the study. It is known that RNN lacks in learning long-term\ndependencies in the input sequence. We use a simple feature construction method\nusing orthogonal Ramanujan periodic transform on the input sequence.\nExperiments demonstrate that if these features are given to LSTM or BiLSTM\nnetworks, the performance increases drastically.\nOur focus in this study is to increase the training accuracy simultaneously\nreducing the training time for the LSTM and BiLSTM architecture, but not on\npushing the state-of-the-art results, so we use simple LSTM/BiLSTM\narchitecture. We compare sequential input with the constructed feature as input\nto single layer LSTM and BiLSTM network for MNIST and CIFAR datasets. We\nobserve that sequential input to the LSTM network with 128 hidden unit training\nfor five epochs results in training accuracy of 33% whereas constructed\nfeatures as input to the same LSTM network results in training accuracy of 90%\nwith 1/3 lesser time.",
    "descriptor": "",
    "authors": [
      "Gajraj Kuldeep"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11495"
  },
  {
    "id": "arXiv:2209.11499",
    "title": "The cavity method: from exact solutions to algorithms",
    "abstract": "The goal of this chapter is to review the main ideas that underlie the cavity\nmethod for disordered models defined on random graphs, as well as present some\nof its outcomes, focusing on the random constraint satisfaction problems for\nwhich it provided both a better understanding of the phase transitions they\nundergo, and suggestions for the development of algorithms to solve them.",
    "descriptor": "\nComments: To appear as a contribution to the edited volume \"Spin Glass Theory & Far Beyond - Replica Symmetry Breaking after 40 Years\", World Scientific\n",
    "authors": [
      "Alfredo Braunstein",
      "Guilhem Semerjian"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2209.11499"
  },
  {
    "id": "arXiv:2209.11514",
    "title": "Error Mitigation-Aided Optimization of Parameterized Quantum Circuits:  Convergence Analysis",
    "abstract": "Variational quantum algorithms (VQAs) offer the most promising path to\nobtaining quantum advantages via noisy intermediate-scale quantum (NISQ)\nprocessors. Such systems leverage classical optimization to tune the parameters\nof a parameterized quantum circuit (PQC). The goal is minimizing a cost\nfunction that depends on measurement outputs obtained from the PQC.\nOptimization is typically implemented via stochastic gradient descent (SGD). On\nNISQ computers, gate noise due to imperfections and decoherence affects the\nstochastic gradient estimates by introducing a bias. Quantum error mitigation\n(QEM) techniques can reduce the estimation bias without requiring any increase\nin the number of qubits, but they in turn cause an increase in the variance of\nthe gradient estimates. This work studies the impact of quantum gate noise on\nthe convergence of SGD for the variational eigensolver (VQE), a fundamental\ninstance of VQAs. The main goal is ascertaining conditions under which QEM can\nenhance the performance of SGD for VQEs. It is shown that quantum gate noise\ninduces a non-zero error-floor on the convergence error of SGD (evaluated with\nrespect to a reference noiseless PQC), which depends on the number of noisy\ngates, the strength of the noise, as well as the eigenspectrum of the\nobservable being measured and minimized. In contrast, with QEM, any arbitrarily\nsmall error can be obtained. Furthermore, for error levels attainable with or\nwithout QEM, QEM can reduce the number of required iterations, but only as long\nas the quantum noise level is sufficiently small, and a sufficiently large\nnumber of measurements is allowed at each SGD iteration. Numerical examples for\na max-cut problem corroborate the main theoretical findings.",
    "descriptor": "\nComments: Submitted for journal publication\n",
    "authors": [
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11514"
  },
  {
    "id": "arXiv:2209.11520",
    "title": "Power Management in Smart Residential Building with Deep Learning Model  for Occupancy Detection by Usage Pattern of Electric Appliances",
    "abstract": "With the growth of smart building applications, occupancy information in\nresidential buildings is becoming more and more significant. In the context of\nthe smart buildings' paradigm, this kind of information is required for a wide\nrange of purposes, including enhancing energy efficiency and occupant comfort.\nIn this study, occupancy detection in residential building is implemented using\ndeep learning based on technical information of electric appliances. To this\nend, a novel approach of occupancy detection for smart residential building\nsystem is proposed. The dataset of electric appliances, sensors, light, and\nHVAC, which is measured by smart metering system and is collected from 50\nhouseholds, is used for simulations. To classify the occupancy among datasets,\nthe support vector machine and autoencoder algorithm are used. Confusion matrix\nis utilized for accuracy, precision, recall, and F1 to demonstrate the\ncomparative performance of the proposed method in occupancy detection. The\nproposed algorithm achieves occupancy detection using technical information of\nelectric appliances by 95.7~98.4%. To validate occupancy detection data,\nprincipal component analysis and the t-distributed stochastic neighbor\nembedding (t-SNE) algorithm are employed. Power consumption with renewable\nenergy system is reduced to 11.1~13.1% in smart buildings by using occupancy\ndetection.",
    "descriptor": "\nComments: 11 pages, 7 figures, to be submitted to 7th International Conference on Renewable Energy and Conservation, ICREC 2022\n",
    "authors": [
      "Sangkeum Lee",
      "Sarvar Hussain Nengroo",
      "Hojun Jin",
      "Yoonmee Doh",
      "Chungho Lee",
      "Taewook Heo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11520"
  },
  {
    "id": "arXiv:2209.11522",
    "title": "Small coverage effect in epidemic network models shows that masks can  become more effective with less people wearing them",
    "abstract": "The effectiveness of non-pharmaceutical interventions to curb the spread of\nSARS-CoV-2 is determined by numerous contextual factors, including adherence.\nConventional wisdom holds that the effectiveness of protective behaviour such\nas wearing masks always increases with the number of people adopting it. Here\nwe show in a simulation study that this is not true in general. We employ a\nparsimonious network model based on the well-established empirical facts that\n(i) adherence to such interventions wanes over time and (ii) individuals tend\nto align their adoption strategies with their close social ties (homophily).\nWhen combining these assumptions, a broad dynamical regime emerges where the\nindividual-level infection risk reduction for those adopting protective\nbehaviour increases as the adherence to protective behavior decreases. For\ninstance, for a protective coverage of 10% we find the infection risk for\nadopting individuals can be reduced by close to 30% compared to situations\nwhere the coverage is 60%. Using estimates for the effectiveness of surgical\nmasks, we find that reductions in relative risk of masking versus non-masking\nindividuals range between 5% and 15%, i.e., vary by a factor of three. This\nsmall coverage effect originates from system-dynamical network properties that\nconspire to increase the chance that an outbreak will be over before the\npathogen is able to invade small but tightly connected groups of individuals\nthat protect themselves. Our results contradict the popular belief that masking\nbecomes ineffectual as more people drop their masks and might have far-reaching\nimplications for the protection of vulnerable population groups under resurgent\ninfection waves.",
    "descriptor": "",
    "authors": [
      "Peter Klimek",
      "Katharina Ledebur",
      "Stefan Thurner"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.11522"
  },
  {
    "id": "arXiv:2209.11531",
    "title": "Deep Learning-based Anonymization of Chest Radiographs: A  Utility-preserving Measure for Patient Privacy",
    "abstract": "Robust and reliable anonymization of chest radiographs constitutes an\nessential step before publishing large datasets of such for research purposes.\nThe conventional anonymization process is carried out by obscuring personal\ninformation in the images with black boxes and removing or replacing\nmeta-information. However, such simple measures retain biometric information in\nthe chest radiographs, allowing patients to be re-identified by a linkage\nattack. Therefore, we see an urgent need to obfuscate the biometric information\nappearing in the images. To the best of our knowledge, we propose the first\ndeep learning-based approach to targetedly anonymize chest radiographs while\nmaintaining data utility for diagnostic and machine learning purposes. Our\nmodel architecture is a composition of three independent neural networks that,\nwhen collectively used, allow for learning a deformation field that is able to\nimpede patient re-identification. The individual influence of each component is\ninvestigated with an ablation study. Quantitative results on the ChestX-ray14\ndataset show a reduction of patient re-identification from 81.8% to 58.6% in\nthe area under the receiver operating characteristic curve (AUC) with little\nimpact on the abnormality classification performance. This indicates the\nability to preserve underlying abnormality patterns while increasing patient\nprivacy. Furthermore, we compare the proposed deep learning-based anonymization\napproach with differentially private image pixelization, and demonstrate the\nsuperiority of our method towards resolving the privacy-utility trade-off for\nchest radiographs.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kai Packh\u00e4user",
      "Sebastian G\u00fcndel",
      "Florian Thamm",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11531"
  },
  {
    "id": "arXiv:2209.11537",
    "title": "Planar graph with twin-width seven",
    "abstract": "We construct a planar graph with twin-width equal to seven.",
    "descriptor": "",
    "authors": [
      "Daniel Kral",
      "Ander Lamaison"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.11537"
  },
  {
    "id": "arXiv:2209.11580",
    "title": "A new perspective on parameter study of optimization problems",
    "abstract": "We provide a new perspective on the study of parameterized optimization\nproblems. Our approach combines methods for post-optimal sensitivity analysis\nand ordinary differential equations to quantify the uncertainty in the\nminimizer due to uncertain parameters in the optimization problem. We\nillustrate the proposed approach with a simple analytic example and an inverse\nproblem governed by an advection diffusion equation.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Alen Alexanderian",
      "Joseph Hart",
      "Mason Stevens"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.11580"
  },
  {
    "id": "arXiv:2209.11606",
    "title": "An extension to VORO++ for multithreaded computation of Voronoi cells",
    "abstract": "VORO++ is a software library written in C++ for computing the Voronoi\ntessellation, a technique in computational geometry that is widely used for\nanalyzing systems of particles. VORO++ was released in 2009 and is based on\ncomputing the Voronoi cell for each particle individually. Here, we take\nadvantage of modern computer hardware, and extend the original serial version\nto allow for multithreaded computation of Voronoi cells via the OpenMP\napplication programming interface. We test the performance of the code, and\ndemonstrate that we can achieve parallel efficiencies greater than 95% in many\ncases. The multithreaded extension follows standard OpenMP programming\nparadigms, allowing it to be incorporated into other programs. We provide an\nexample of this using the VoroTop software library, performing a multithreaded\nVoronoi cell topology analysis of up to 102.4 million particles.",
    "descriptor": "",
    "authors": [
      "Jiayin Lu",
      "Emanuel A. Lazar",
      "Chris H. Rycroft"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Geometry (cs.CG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.11606"
  },
  {
    "id": "arXiv:2209.11614",
    "title": "Differentiable physics-enabled closure modeling for Burgers' turbulence",
    "abstract": "Data-driven turbulence modeling is experiencing a surge in interest following\nalgorithmic and hardware developments in the data sciences. We discuss an\napproach using the differentiable physics paradigm that combines known physics\nwith machine learning to develop closure models for Burgers' turbulence. We\nconsider the 1D Burgers system as a prototypical test problem for modeling the\nunresolved terms in advection-dominated turbulence problems. We train a series\nof models that incorporate varying degrees of physical assumptions on an a\nposteriori loss function to test the efficacy of models across a range of\nsystem parameters, including viscosity, time, and grid resolution. We find that\nconstraining models with inductive biases in the form of partial differential\nequations that contain known physics or existing closure approaches produces\nhighly data-efficient, accurate, and generalizable models, outperforming\nstate-of-the-art baselines. Addition of structure in the form of physics\ninformation also brings a level of interpretability to the models, potentially\noffering a stepping stone to the future of closure modeling.",
    "descriptor": "",
    "authors": [
      "Varun Shankar",
      "Vedant Puri",
      "Ramesh Balakrishnan",
      "Romit Maulik",
      "Venkatasubramanian Viswanathan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11614"
  },
  {
    "id": "arXiv:2209.11638",
    "title": "GSP-Based MAP Estimation of Graph Signals",
    "abstract": "In this paper, we consider the problem of recovering random graph signals\nfrom nonlinear measurements. We formulate the maximum a-posteriori probability\n(MAP) estimator, which results in a nonconvex optimization problem.\nConventional iterative methods for minimizing nonconvex problems are sensitive\nto the initialization, have high computational complexity, and do not utilize\nthe underlying graph structure behind the data. In this paper we propose two\nnew estimators that are both based on the Gauss-Newton method: 1) the\nelementwise graph-frequency-domain MAP (eGFD-MAP) estimator; and 2) the graph\nsignal processing MAP (GSP-MAP) estimator. At each iteration, these estimators\nare updated by the outputs of two graph filters, with the previous state\nestimator and the residual as the input graph signals. The eGFD-MAP estimator\nis an ad-hoc method that minimizes the MAP objective function in the graph\nfrequency domain and neglects mixed-derivatives of different graph frequencies\nin the Jacobian matrix as well as off-diagonal elements in the covariance\nmatrices. Consequently, it updates the elements of the graph signal\nindependently, which reduces the computational complexity compared to the\nconventional MAP estimator. The GSP-MAP estimator is based on optimizing the\ngraph filters at each iteration of the Gauss-Newton algorithm. We state\nconditions under which the eGFD-MAP and GSP- MAP estimators coincide with the\nMAP estimator, in the case of an observation model with orthogonal graph\nfrequencies. We evaluate the performance of the estimators for nonlinear graph\nsignal recovery tasks with synthetic data and with the real-world problem of\nstate estimation in power systems. These simulations show the advantages of the\nproposed estimators in terms of computational complexity, mean-squared-error,\nand robustness to the initialization of the iterative algorithms.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Guy Sagi",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11638"
  },
  {
    "id": "arXiv:2209.11661",
    "title": "Exact conservation laws for neural network integrators of dynamical  systems",
    "abstract": "The solution of time dependent differential equations with neural networks\nhas attracted a lot of attention recently. The central idea is to learn the\nlaws that govern the evolution of the solution from data, which might be\npolluted with random noise. However, in contrast to other machine learning\napplications, usually a lot is known about the system at hand. For example, for\nmany dynamical systems physical quantities such as energy or (angular) momentum\nare exactly conserved. Hence, the neural network has to learn these\nconservation laws from data and they will only be satisfied approximately due\nto finite training time and random noise. In this paper we present an\nalternative approach which uses Noether's Theorem to inherently incorporate\nconservation laws into the architecture of the neural network. We demonstrate\nthat this leads to better predictions for three model systems: the motion of a\nnon-relativistic particle in a three-dimensional Newtonian gravitational\npotential, the motion of a massive relativistic particle in the Schwarzschild\nmetric and a system of two interacting particles in four dimensions.",
    "descriptor": "\nComments: 21 pages, 16 figures; submitted to Journal of Computational Physics\n",
    "authors": [
      "Eike Hermann M\u00fcller"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.11661"
  },
  {
    "id": "arXiv:2209.11691",
    "title": "Multidimensional Interactive Fixed-Effects",
    "abstract": "This paper studies a linear and additively separable model for\nmultidimensional panel data of three or more dimensions with unobserved\ninteractive fixed effects. Two approaches are considered to account for these\nunobserved interactive fixed-effects when estimating coefficients on the\nobserved covariates. First, the model is embedded within the standard\ntwo-dimensional panel framework and restrictions are derived under which the\nfactor structure methods in Bai (2009) lead to consistent estimation of model\nparameters. The second approach considers group fixed-effects and kernel\nmethods that are more robust to the multidimensional nature of the problem.\nTheoretical results and simulations show the benefit of standard\ntwo-dimensional panel methods when the structure of the interactive\nfixed-effect term is known, but also highlight how the group fixed-effects and\nkernel methods perform well without knowledge of this structure. The methods\nare implemented to estimate the demand elasticity for beer under a handful of\nmodels for demand.",
    "descriptor": "",
    "authors": [
      "Hugo Freeman"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.11691"
  },
  {
    "id": "arXiv:2209.11729",
    "title": "Dual-Cycle: Self-Supervised Dual-View Fluorescence Microscopy Image  Reconstruction using CycleGAN",
    "abstract": "Three-dimensional fluorescence microscopy often suffers from anisotropy,\nwhere the resolution along the axial direction is lower than that within the\nlateral imaging plane. We address this issue by presenting Dual-Cycle, a new\nframework for joint deconvolution and fusion of dual-view fluorescence images.\nInspired by the recent Neuroclear method, Dual-Cycle is designed as a\ncycle-consistent generative network trained in a self-supervised fashion by\ncombining a dual-view generator and prior-guided degradation model. We validate\nDual-Cycle on both synthetic and real data showing its state-of-the-art\nperformance without any external training data.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Tomas Kerepecky",
      "Jiaming Liu",
      "Xue Wen Ng",
      "David W. Piston",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11729"
  },
  {
    "id": "arXiv:1702.03844",
    "title": "A Relaxed Ka\u010danov Iteration for the $p$-Poisson Problem",
    "abstract": "A Relaxed Ka\u010danov Iteration for the $p$-Poisson Problem",
    "descriptor": "",
    "authors": [
      "Lars Diening",
      "Massimo Fornasier",
      "Maximilian Wank"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1702.03844"
  },
  {
    "id": "arXiv:1907.05087",
    "title": "Optimal Space-Depth Trade-Off of CNOT Circuits in Quantum Logic  Synthesis",
    "abstract": "Comments: Complete details to the proofs",
    "descriptor": "\nComments: Complete details to the proofs\n",
    "authors": [
      "Jiaqing Jiang",
      "Xiaoming Sun",
      "Shang-Hua Teng",
      "Bujiao Wu",
      "Kewen Wu",
      "Jialin Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1907.05087"
  },
  {
    "id": "arXiv:1909.12582",
    "title": "Towards Coq-verified Esterel Semantics and Compiling",
    "abstract": "Towards Coq-verified Esterel Semantics and Compiling",
    "descriptor": "",
    "authors": [
      "G\u00e9rard Berry",
      "Lionel Rieg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1909.12582"
  },
  {
    "id": "arXiv:2001.01456",
    "title": "Facial Emotions Recognition using Convolutional Neural Net",
    "abstract": "Comments: 6 pages, 11 figures",
    "descriptor": "\nComments: 6 pages, 11 figures\n",
    "authors": [
      "Faisal Ghaffar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.01456"
  },
  {
    "id": "arXiv:2005.00611",
    "title": "Neural Lyapunov Control",
    "abstract": "Comments: NeurIPS 2019",
    "descriptor": "\nComments: NeurIPS 2019\n",
    "authors": [
      "Ya-Chien Chang",
      "Nima Roohi",
      "Sicun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00611"
  },
  {
    "id": "arXiv:2005.12794",
    "title": "Asymptotic links between signal processing, acoustic metamaterials and  biology",
    "abstract": "Asymptotic links between signal processing, acoustic metamaterials and  biology",
    "descriptor": "",
    "authors": [
      "Habib Ammari",
      "Bryn Davies"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2005.12794"
  },
  {
    "id": "arXiv:2006.14711",
    "title": "New Metrics for Learning Evaluation in Digital Education Platforms",
    "abstract": "Comments: 12 pages, 6 figures, 12 tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 12 tables\n",
    "authors": [
      "Gabriel Leit\u00e3o",
      "Juan Colonna",
      "Edwin Monteiro",
      "Elaine Oliveira",
      "Raimundo Barreto"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2006.14711"
  },
  {
    "id": "arXiv:2007.01118",
    "title": "Adapting $k$-means algorithms for outliers",
    "abstract": "Adapting $k$-means algorithms for outliers",
    "descriptor": "",
    "authors": [
      "Christoph Grunau",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.01118"
  },
  {
    "id": "arXiv:2008.08050",
    "title": "The MRS UAV System: Pushing the Frontiers of Reproducible Research,  Real-world Deployment, and Education with Autonomous Unmanned Aerial Vehicles",
    "abstract": "Comments: 28 pages, 20 figures, accepted to Journal of Intelligent & Robotic Systems (JINT), for the provided open-source software see this http URL, erratum for eq. 3, 15, 19, 24",
    "descriptor": "\nComments: 28 pages, 20 figures, accepted to Journal of Intelligent & Robotic Systems (JINT), for the provided open-source software see this http URL, erratum for eq. 3, 15, 19, 24\n",
    "authors": [
      "Tomas Baca",
      "Matej Petrlik",
      "Matous Vrba",
      "Vojtech Spurny",
      "Robert Penicka",
      "Daniel Hert",
      "Martin Saska"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.08050"
  },
  {
    "id": "arXiv:2010.04527",
    "title": "Constant-time connectivity tests",
    "abstract": "Constant-time connectivity tests",
    "descriptor": "",
    "authors": [
      "Philipp Klaus Krause"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2010.04527"
  },
  {
    "id": "arXiv:2010.12728",
    "title": "Differentiate Quality of Experience Scheduling for Deep Learning  Inferences with Docker Containers in the Cloud",
    "abstract": "Differentiate Quality of Experience Scheduling for Deep Learning  Inferences with Docker Containers in the Cloud",
    "descriptor": "",
    "authors": [
      "Ying Mao",
      "Weifeng Yan",
      "Yun Song",
      "Yue Zeng",
      "Ming Chen",
      "Long Cheng",
      "Qingzhi Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2010.12728"
  },
  {
    "id": "arXiv:2011.00029",
    "title": "Monitoring the edges of a graph using distances",
    "abstract": "Comments: 19 pages; 5 figures. A preliminary version appeared in the proceedings of CALDAM 2020",
    "descriptor": "\nComments: 19 pages; 5 figures. A preliminary version appeared in the proceedings of CALDAM 2020\n",
    "authors": [
      "Florent Foucaud",
      "Shih-Shun Kao",
      "Ralf Klasing",
      "Mirka Miller",
      "Joe Ryan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.00029"
  },
  {
    "id": "arXiv:2012.00565",
    "title": "The massless modular Hamiltonian",
    "abstract": "Comments: Changes w.r.t. v. 3: only this comment. Changes w.r.t. v. 2: the results on the massive modular hamiltonian of a ball contained a gap, and have been removed. 23 pages, 1 figure",
    "descriptor": "\nComments: Changes w.r.t. v. 3: only this comment. Changes w.r.t. v. 2: the results on the massive modular hamiltonian of a ball contained a gap, and have been removed. 23 pages, 1 figure\n",
    "authors": [
      "Roberto Longo",
      "Gerardo Morsella"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Information Theory (cs.IT)",
      "High Energy Physics - Theory (hep-th)",
      "Analysis of PDEs (math.AP)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2012.00565"
  },
  {
    "id": "arXiv:2102.09544",
    "title": "Combinatorial optimization and reasoning with graph neural networks",
    "abstract": "Combinatorial optimization and reasoning with graph neural networks",
    "descriptor": "",
    "authors": [
      "Quentin Cappart",
      "Didier Ch\u00e9telat",
      "Elias Khalil",
      "Andrea Lodi",
      "Christopher Morris",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09544"
  },
  {
    "id": "arXiv:2102.10256",
    "title": "Generalized Group Testing",
    "abstract": "Generalized Group Testing",
    "descriptor": "",
    "authors": [
      "Xiwei Cheng",
      "Sidharth Jaggi",
      "Qiaoqiao Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.10256"
  },
  {
    "id": "arXiv:2105.03216",
    "title": "Emergence in artificial life",
    "abstract": "Comments: 28 pages, 1 figure",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Carlos Gershenson"
    ],
    "subjectives": [
      "General Physics (physics.gen-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03216"
  },
  {
    "id": "arXiv:2105.12033",
    "title": "TNet: A Model-Constrained Tikhonov Network Approach for Inverse Problems",
    "abstract": "TNet: A Model-Constrained Tikhonov Network Approach for Inverse Problems",
    "descriptor": "",
    "authors": [
      "Hai V. Nguyen",
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.12033"
  },
  {
    "id": "arXiv:2105.12038",
    "title": "Unpaired Depth Super-Resolution in the Wild",
    "abstract": "Unpaired Depth Super-Resolution in the Wild",
    "descriptor": "",
    "authors": [
      "Aleksandr Safin",
      "Maxim Kan",
      "Nikita Drobyshev",
      "Oleg Voynov",
      "Alexey Artemov",
      "Alexander Filippov",
      "Denis Zorin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12038"
  },
  {
    "id": "arXiv:2106.08746",
    "title": "Real-time Adversarial Perturbations against Deep Reinforcement Learning  Policies: Attacks and Defenses",
    "abstract": "Comments: Will appear in the proceedings of ESORICS 2022; 13 pages, 6 figures, 6 tables",
    "descriptor": "\nComments: Will appear in the proceedings of ESORICS 2022; 13 pages, 6 figures, 6 tables\n",
    "authors": [
      "Buse G. A. Tekgul",
      "Shelly Wang",
      "Samuel Marchal",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08746"
  },
  {
    "id": "arXiv:2106.10022",
    "title": "Local AdaGrad-Type Algorithm for Stochastic Convex-Concave Optimization",
    "abstract": "Comments: 42 pages; Accepted to Machine Learning, 2022",
    "descriptor": "\nComments: 42 pages; Accepted to Machine Learning, 2022\n",
    "authors": [
      "Luofeng Liao",
      "Li Shen",
      "Jia Duan",
      "Mladen Kolar",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10022"
  },
  {
    "id": "arXiv:2106.12233",
    "title": "Testing of Autonomous Driving Systems: Where Are We and Where Should We  Go?",
    "abstract": "Testing of Autonomous Driving Systems: Where Are We and Where Should We  Go?",
    "descriptor": "",
    "authors": [
      "Guannan Lou",
      "Yao Deng",
      "Xi Zheng",
      "Mengshi Zhang",
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.12233"
  },
  {
    "id": "arXiv:2106.13543",
    "title": "A Variance-aware Multiobjective Louvain-like Method for Community  Detection in Multiplex Networks",
    "abstract": "A Variance-aware Multiobjective Louvain-like Method for Community  Detection in Multiplex Networks",
    "descriptor": "",
    "authors": [
      "Sara Venturini",
      "Andrea Cristofari",
      "Francesco Rinaldi",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13543"
  },
  {
    "id": "arXiv:2106.14075",
    "title": "Decentralized Composite Optimization in Stochastic Networks: A Dual  Averaging Approach with Linear Convergence",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Changxin Liu",
      "Zirui Zhou",
      "Jian Pei",
      "Yong Zhang",
      "Yang Shi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.14075"
  },
  {
    "id": "arXiv:2107.01873",
    "title": "Detecting Concept Drift With Neural Network Model Uncertainty",
    "abstract": "Detecting Concept Drift With Neural Network Model Uncertainty",
    "descriptor": "",
    "authors": [
      "Lucas Baier",
      "Tim Schl\u00f6r",
      "Jakob Sch\u00f6ffer",
      "Niklas K\u00fchl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01873"
  },
  {
    "id": "arXiv:2107.02299",
    "title": "LightFuse: Lightweight CNN based Dual-exposure Fusion",
    "abstract": "LightFuse: Lightweight CNN based Dual-exposure Fusion",
    "descriptor": "",
    "authors": [
      "Ziyi Liu",
      "Jie Yang",
      "Svetlana Yanushkevich",
      "Orly Yadid-Pecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02299"
  },
  {
    "id": "arXiv:2107.12871",
    "title": "Model Free Barrier Functions via Implicit Evading Maneuvers",
    "abstract": "Comments: This work has been submitted to the American Controls Conference",
    "descriptor": "\nComments: This work has been submitted to the American Controls Conference\n",
    "authors": [
      "Eric Squires",
      "Rohit Konda",
      "Samuel Coogan",
      "Magnus Egerstedt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.12871"
  },
  {
    "id": "arXiv:2107.13155",
    "title": "Improving Video Instance Segmentation via Temporal Pyramid Routing",
    "abstract": "Comments: T-PAMI-2022",
    "descriptor": "\nComments: T-PAMI-2022\n",
    "authors": [
      "Xiangtai Li",
      "Hao He",
      "Yibo Yang",
      "Henghui Ding",
      "Kuiyuan Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13155"
  },
  {
    "id": "arXiv:2108.05521",
    "title": "Measurement Integrity in Peer Prediction: A Peer Assessment Case Study",
    "abstract": "Comments: The code for our experiments is hosted in the following GitHub repository: this https URL Version 2 (uploaded on 9/22/22) introduces experiments with real peer grading data alongside significant changes to the framing of the paper and presentation of the results",
    "descriptor": "\nComments: The code for our experiments is hosted in the following GitHub repository: this https URL Version 2 (uploaded on 9/22/22) introduces experiments with real peer grading data alongside significant changes to the framing of the paper and presentation of the results\n",
    "authors": [
      "Noah Burrell",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2108.05521"
  },
  {
    "id": "arXiv:2108.10718",
    "title": "Convexity via Weak Distributive Laws",
    "abstract": "Comments: An extended abstract for this article is available at this https URL . This updated version takes into account the referees' comments and will appear in Logical Methods in Computer Science. arXiv admin note: substantial text overlap with arXiv:2012.14778",
    "descriptor": "\nComments: An extended abstract for this article is available at this https URL . This updated version takes into account the referees' comments and will appear in Logical Methods in Computer Science. arXiv admin note: substantial text overlap with arXiv:2012.14778\n",
    "authors": [
      "Filippo Bonchi",
      "Alessio Santamaria"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.10718"
  },
  {
    "id": "arXiv:2109.00452",
    "title": "Self-supervised Point Cloud Representation Learning via Separating Mixed  Shapes",
    "abstract": "Self-supervised Point Cloud Representation Learning via Separating Mixed  Shapes",
    "descriptor": "",
    "authors": [
      "Chao Sun",
      "Zhedong Zheng",
      "Xiaohan Wang",
      "Mingliang Xu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00452"
  },
  {
    "id": "arXiv:2109.12338",
    "title": "Distribution-sensitive Information Retention for Accurate Binary Neural  Network",
    "abstract": "Distribution-sensitive Information Retention for Accurate Binary Neural  Network",
    "descriptor": "",
    "authors": [
      "Haotong Qin",
      "Xiangguo Zhang",
      "Ruihao Gong",
      "Yifu Ding",
      "Yi Xu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12338"
  },
  {
    "id": "arXiv:2110.06553",
    "title": "Spatial-temporal Transformers for EEG Emotion Recognition",
    "abstract": "Spatial-temporal Transformers for EEG Emotion Recognition",
    "descriptor": "",
    "authors": [
      "Jiyao Liu",
      "Hao Wu",
      "Li Zhang",
      "Yanxi Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06553"
  },
  {
    "id": "arXiv:2111.02403",
    "title": "WORD: A large scale dataset, benchmark and clinical applicable study for  abdominal organ segmentation from CT image",
    "abstract": "Comments: Accepted to Medical Image Analysis, dataset at: this https URL",
    "descriptor": "\nComments: Accepted to Medical Image Analysis, dataset at: this https URL\n",
    "authors": [
      "Xiangde Luo",
      "Wenjun Liao",
      "Jianghong Xiao",
      "Jieneng Chen",
      "Tao Song",
      "Xiaofan Zhang",
      "Kang Li",
      "Dimitris N. Metaxas",
      "Guotai Wang",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02403"
  },
  {
    "id": "arXiv:2111.09986",
    "title": "Boost Distribution System Restoration with Emergency Communication  Vehicles Considering Cyber-Physical Interdependence",
    "abstract": "Boost Distribution System Restoration with Emergency Communication  Vehicles Considering Cyber-Physical Interdependence",
    "descriptor": "",
    "authors": [
      "Zhigang Ye",
      "Chen Chen",
      "Ruihuan Liu",
      "Kai Wu",
      "Zhaohong Bie",
      "Guannan Lou",
      "Wei Gu",
      "Yubo Yuan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09986"
  },
  {
    "id": "arXiv:2111.10934",
    "title": "Privacy-preserving Federated Adversarial Domain Adaption over Feature  Groups for Interpretability",
    "abstract": "Comments: Published in IEEE Transactions on Big Data",
    "descriptor": "\nComments: Published in IEEE Transactions on Big Data\n",
    "authors": [
      "Yan Kang",
      "Yang Liu",
      "Yuezhou Wu",
      "Guoqiang Ma",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10934"
  },
  {
    "id": "arXiv:2111.12600",
    "title": "Learning State Representations via Retracing in Reinforcement Learning",
    "abstract": "Learning State Representations via Retracing in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Changmin Yu",
      "Dong Li",
      "Jianye Hao",
      "Jun Wang",
      "Neil Burgess"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12600"
  },
  {
    "id": "arXiv:2112.01261",
    "title": "ViF-SD2E: A Robust Weakly-Supervised Method for Neural Decoding",
    "abstract": "Comments: 13 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 13 pages, 9 figures, 4 tables\n",
    "authors": [
      "Jingyi Feng",
      "Yong Luo",
      "Shuang Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01261"
  },
  {
    "id": "arXiv:2112.01465",
    "title": "Unifying information propagation models on networks and influence  maximization",
    "abstract": "Comments: 28 pages, 22 figures",
    "descriptor": "\nComments: 28 pages, 22 figures\n",
    "authors": [
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.01465"
  },
  {
    "id": "arXiv:2112.03740",
    "title": "Dilated convolution with learnable spacings",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Ismail Khalfaoui-Hassani",
      "Thomas Pellegrini",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03740"
  },
  {
    "id": "arXiv:2112.09542",
    "title": "A Formal Model for Polarization under Confirmation Bias in Social  Networks",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703\n",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Bernardo Amorim",
      "Sophia Knight",
      "Santiago Quintero",
      "Frank Valencia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.09542"
  },
  {
    "id": "arXiv:2112.10583",
    "title": "A singular Riemannian geometry approach to Deep Neural Networks II.  Reconstruction of 1-D equivalence classes",
    "abstract": "A singular Riemannian geometry approach to Deep Neural Networks II.  Reconstruction of 1-D equivalence classes",
    "descriptor": "",
    "authors": [
      "Alessandro Benfenati",
      "Alessio Marta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Metric Geometry (math.MG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.10583"
  },
  {
    "id": "arXiv:2112.14403",
    "title": "Balancing SRPT and FCFS via Starvation Mitigation",
    "abstract": "Comments: 1. Introduction is rewritten. 2. Add Theorem 1.4 and numerical study. 3. The proposed algorithm and the proof of Theorem 1.5 are simplified",
    "descriptor": "\nComments: 1. Introduction is rewritten. 2. Add Theorem 1.4 and numerical study. 3. The proposed algorithm and the proof of Theorem 1.5 are simplified\n",
    "authors": [
      "Tung-Wei Kuo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.14403"
  },
  {
    "id": "arXiv:2112.15383",
    "title": "Separation of Scales and a Thermodynamic Description of Feature Learning  in Some CNNs",
    "abstract": "Separation of Scales and a Thermodynamic Description of Feature Learning  in Some CNNs",
    "descriptor": "",
    "authors": [
      "Inbar Seroussi",
      "Gadi Naveh",
      "Zohar Ringel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.15383"
  },
  {
    "id": "arXiv:2201.01105",
    "title": "New RED-type TCP-AQM algorithms based on beta distribution drop  functions",
    "abstract": "New RED-type TCP-AQM algorithms based on beta distribution drop  functions",
    "descriptor": "",
    "authors": [
      "Angel Gim\u00e9nez",
      "Miguel A. Murcia",
      "Jos\u00e9 M. Amig\u00f3",
      "Oscar Mart\u00ednez-Bonastre",
      "Jos\u00e9 Valero"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.01105"
  },
  {
    "id": "arXiv:2201.09051",
    "title": "On the Robustness of Sparse Counterfactual Explanations to Adverse  Perturbations",
    "abstract": "On the Robustness of Sparse Counterfactual Explanations to Adverse  Perturbations",
    "descriptor": "",
    "authors": [
      "Marco Virgolin",
      "Saverio Fracaros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09051"
  },
  {
    "id": "arXiv:2201.09656",
    "title": "A singular Riemannian geometry approach to Deep Neural Networks I.  Theoretical foundations",
    "abstract": "A singular Riemannian geometry approach to Deep Neural Networks I.  Theoretical foundations",
    "descriptor": "",
    "authors": [
      "Alessandro Benfenati",
      "Alessio Marta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2201.09656"
  },
  {
    "id": "arXiv:2201.13418",
    "title": "GParareal: A time-parallel ODE solver using Gaussian process emulation",
    "abstract": "GParareal: A time-parallel ODE solver using Gaussian process emulation",
    "descriptor": "",
    "authors": [
      "Kamran Pentland",
      "Massimiliano Tamborrino",
      "T. J. Sullivan",
      "James Buchanan",
      "L. C. Appel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.13418"
  },
  {
    "id": "arXiv:2202.00389",
    "title": "Sense: Model Hardware Co-design for Accelerating Sparse CNN on Systolic  Array",
    "abstract": "Comments: 14 pages, 29 figures, 6 tables, IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS",
    "descriptor": "\nComments: 14 pages, 29 figures, 6 tables, IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS\n",
    "authors": [
      "Wenhao Sun",
      "Deng Liu",
      "Zhiwei Zou",
      "Wendi Sun",
      "Yi Kang",
      "Song Chen"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.00389"
  },
  {
    "id": "arXiv:2202.02472",
    "title": "Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor  Imagery Classification",
    "abstract": "Comments: 15 pages, 10 figures, 12 tables; This work has been accepted by the IEEE Transactions on Neural Networks and Learning Systems. Copyright will be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 15 pages, 10 figures, 12 tables; This work has been accepted by the IEEE Transactions on Neural Networks and Learning Systems. Copyright will be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02472"
  },
  {
    "id": "arXiv:2202.03176",
    "title": "Field-of-View IoU for Object Detection in 360\u00b0 Images",
    "abstract": "Field-of-View IoU for Object Detection in 360\u00b0 Images",
    "descriptor": "",
    "authors": [
      "Miao Cao",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03176"
  },
  {
    "id": "arXiv:2202.04537",
    "title": "Time complexity analysis of quantum difference methods for linear high  dimensional and multiscale partial differential equations",
    "abstract": "Comments: quantum difference methods",
    "descriptor": "\nComments: quantum difference methods\n",
    "authors": [
      "Shi Jin",
      "Nana Liu",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04537"
  },
  {
    "id": "arXiv:2202.04724",
    "title": "The Landscape of Distributed Complexities on Trees and Beyond",
    "abstract": "The Landscape of Distributed Complexities on Trees and Beyond",
    "descriptor": "",
    "authors": [
      "Christoph Grunau",
      "Vaclav Rozhon",
      "Sebastian Brandt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.04724"
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": "Comments: 21 pages, 7 figures",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05226"
  },
  {
    "id": "arXiv:2202.09282",
    "title": "FinNet: Solving Time-Independent Differential Equations with Finite  Difference Neural Network",
    "abstract": "FinNet: Solving Time-Independent Differential Equations with Finite  Difference Neural Network",
    "descriptor": "",
    "authors": [
      "Son N. T. Tu",
      "Thu Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09282"
  },
  {
    "id": "arXiv:2202.13670",
    "title": "FedDrive: Generalizing Federated Learning to Semantic Segmentation in  Autonomous Driving",
    "abstract": "FedDrive: Generalizing Federated Learning to Semantic Segmentation in  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Lidia Fantauzzo",
      "Eros Fani'",
      "Debora Caldarola",
      "Antonio Tavera",
      "Fabio Cermelli",
      "Marco Ciccone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13670"
  },
  {
    "id": "arXiv:2202.14005",
    "title": "Deep, Deep Learning with BART",
    "abstract": "Comments: Submitted to Magnetic Resonance in Medicine",
    "descriptor": "\nComments: Submitted to Magnetic Resonance in Medicine\n",
    "authors": [
      "Moritz Blumenthal",
      "Guanxiong Luo",
      "Martin Schilling",
      "H. Christian M. Holme",
      "Martin Uecker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.14005"
  },
  {
    "id": "arXiv:2203.01299",
    "title": "STEADY: Simultaneous State Estimation and Dynamics Learning from  Indirect Observations",
    "abstract": "Comments: Accepted for publication in the Proceedings of IROS 2022",
    "descriptor": "\nComments: Accepted for publication in the Proceedings of IROS 2022\n",
    "authors": [
      "Jiayi Wei",
      "Jarrett Holtz",
      "Isil Dillig",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01299"
  },
  {
    "id": "arXiv:2203.02331",
    "title": "F2DNet: Fast Focal Detection Network for Pedestrian Detection",
    "abstract": "Comments: Accepted at ICPR 2022",
    "descriptor": "\nComments: Accepted at ICPR 2022\n",
    "authors": [
      "Abdul Hannan Khan",
      "Mohsin Munir",
      "Ludger van Elst",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02331"
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": "Comments: Accepted at ICIP 2022",
    "descriptor": "\nComments: Accepted at ICIP 2022\n",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03677"
  },
  {
    "id": "arXiv:2203.03927",
    "title": "Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based  Approach",
    "abstract": "Comments: Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2023",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Yanbo Chen",
      "Zhengzhe Xu",
      "Zhuozhu Jian",
      "Gengpan Tang",
      "Yunong Yangli",
      "Anxing Xiao",
      "Xueqian Wang",
      "Bin Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03927"
  },
  {
    "id": "arXiv:2203.07530",
    "title": "TTCDist: Fast Distance Estimation From an Active Monocular Camera Using  Time-to-Contact",
    "abstract": "Comments: 18 pages, 24 figures, 1 table",
    "descriptor": "\nComments: 18 pages, 24 figures, 1 table\n",
    "authors": [
      "Levi Burner",
      "Nitin J. Sanket",
      "Cornelia Ferm\u00fcller",
      "Yiannis Aloimonos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07530"
  },
  {
    "id": "arXiv:2203.07657",
    "title": "Seamlessly Integrating Factual Information and Social Content with  Persuasive Dialogue",
    "abstract": "Comments: To appear in Proceedings of AACL-IJCNLP 2022; 16 pages, 4 figures, 7 tables",
    "descriptor": "\nComments: To appear in Proceedings of AACL-IJCNLP 2022; 16 pages, 4 figures, 7 tables\n",
    "authors": [
      "Maximillian Chen",
      "Weiyan Shi",
      "Feifan Yan",
      "Ryan Hou",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07657"
  },
  {
    "id": "arXiv:2203.07961",
    "title": "Variational inference of fractional Brownian motion with linear  computational complexity",
    "abstract": "Variational inference of fractional Brownian motion with linear  computational complexity",
    "descriptor": "",
    "authors": [
      "Hippolyte Verdier",
      "Fran\u00e7ois Laurent",
      "Alhassan Cass\u00e9",
      "Christian Vestergaard",
      "Jean-Baptiste Masson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.07961"
  },
  {
    "id": "arXiv:2203.09155",
    "title": "AdaSplats: Adaptive Splats from Semantic Point Cloud for Fast and  High-Fidelity LiDAR Simulation",
    "abstract": "Comments: 8 pages, 6 figures, 4 tables",
    "descriptor": "\nComments: 8 pages, 6 figures, 4 tables\n",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09155"
  },
  {
    "id": "arXiv:2203.09242",
    "title": "Depth-aware Neural Style Transfer using Instance Normalization",
    "abstract": "Comments: 8 pages, 8 figures, Computer Graphics & Visual Computing (CGVC) 2022",
    "descriptor": "\nComments: 8 pages, 8 figures, Computer Graphics & Visual Computing (CGVC) 2022\n",
    "authors": [
      "Eleftherios Ioannou",
      "Steve Maddock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09242"
  },
  {
    "id": "arXiv:2203.12459",
    "title": "Importance Sampling CAMs for Weakly-Supervised Segmentation with Highly  Accurate Contours",
    "abstract": "Comments: Additional experiments/results",
    "descriptor": "\nComments: Additional experiments/results\n",
    "authors": [
      "Arvi Jonnarth",
      "Michael Felsberg",
      "Yushan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.12459"
  },
  {
    "id": "arXiv:2203.13417",
    "title": "Amortized Projection Optimization for Sliced Wasserstein Generative  Models",
    "abstract": "Comments: Accepted to NeurIPS 2022, 22 pages, 6 figures, 8 tables",
    "descriptor": "\nComments: Accepted to NeurIPS 2022, 22 pages, 6 figures, 8 tables\n",
    "authors": [
      "Khai Nguyen",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13417"
  },
  {
    "id": "arXiv:2203.15149",
    "title": "CMGAN: Conformer-based Metric GAN for Speech Enhancement",
    "abstract": "Comments: 5 pages, 1 figure, 2 tables, published in INTERSPEECH 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, 2 tables, published in INTERSPEECH 2022\n",
    "authors": [
      "Ruizhe Cao",
      "Sherif Abdulatif",
      "Bin Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15149"
  },
  {
    "id": "arXiv:2203.15720",
    "title": "Transformer Inertial Poser: Real-time Human Motion Reconstruction from  Sparse IMUs with Simultaneous Terrain Generation",
    "abstract": "Comments: SIGGRAPH Asia 2022. Video: this https URL",
    "descriptor": "\nComments: SIGGRAPH Asia 2022. Video: this https URL\n",
    "authors": [
      "Yifeng Jiang",
      "Yuting Ye",
      "Deepak Gopinath",
      "Jungdam Won",
      "Alexander W. Winkler",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.15720"
  },
  {
    "id": "arXiv:2204.01188",
    "title": "Revisiting Sliced Wasserstein on Images: From Vectorization to  Convolution",
    "abstract": "Comments: Accepted to NeurIPS 2022, 29 pages, 9 figures, 11 tables",
    "descriptor": "\nComments: Accepted to NeurIPS 2022, 29 pages, 9 figures, 11 tables\n",
    "authors": [
      "Khai Nguyen",
      "Nhat Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.01188"
  },
  {
    "id": "arXiv:2204.02616",
    "title": "Mockingbird lattices",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Samuele Giraudo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.02616"
  },
  {
    "id": "arXiv:2204.04735",
    "title": "Reducing Model Jitter: Stable Re-training of Semantic Parsers in  Production Environments",
    "abstract": "Comments: SIGDIAL 2022 Best Paper",
    "descriptor": "\nComments: SIGDIAL 2022 Best Paper\n",
    "authors": [
      "Christopher Hidey",
      "Fei Liu",
      "Rahul Goel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04735"
  },
  {
    "id": "arXiv:2204.05874",
    "title": "Undirected $(1+\\varepsilon)$-Shortest Paths via Minor-Aggregates:  Near-Optimal Deterministic Parallel & Distributed Algorithms",
    "abstract": "Undirected $(1+\\varepsilon)$-Shortest Paths via Minor-Aggregates:  Near-Optimal Deterministic Parallel & Distributed Algorithms",
    "descriptor": "",
    "authors": [
      "V\u00e1clav Rozho\u0148",
      "Christoph Grunau",
      "Bernhard Haeupler",
      "Goran Zuzic",
      "Jason Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.05874"
  },
  {
    "id": "arXiv:2204.10191",
    "title": "Alexa as an Active Listener: How Backchanneling Can Elicit  Self-Disclosure and Promote User Experience",
    "abstract": "Comments: To appear in Proceedings of the ACM on Human-Computer Interaction (PACM HCI). The paper will be presented in CSCW 2022 (this https URL)",
    "descriptor": "\nComments: To appear in Proceedings of the ACM on Human-Computer Interaction (PACM HCI). The paper will be presented in CSCW 2022 (this https URL)\n",
    "authors": [
      "Eugene Cho",
      "Nasim Motalebi",
      "S. Shyam Sundar",
      "Saeed Abdullah"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.10191"
  },
  {
    "id": "arXiv:2204.10208",
    "title": "Message Flow Analysis with Complex Causal Links for Distributed ROS 2  Systems",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Christophe B\u00e9dard",
      "Pierre-Yves Lajoie",
      "Giovanni Beltrame",
      "Michel Dagenais"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.10208"
  },
  {
    "id": "arXiv:2204.14086",
    "title": "Deterministic Distributed Sparse and Ultra-Sparse Spanners and  Connectivity Certificates",
    "abstract": "Deterministic Distributed Sparse and Ultra-Sparse Spanners and  Connectivity Certificates",
    "descriptor": "",
    "authors": [
      "Marcel Bezdrighin",
      "Michael Elkin",
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Bernhard Haeupler",
      "Saeed Ilchi",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.14086"
  },
  {
    "id": "arXiv:2205.02648",
    "title": "Multi-Freq-LDPy: Multiple Frequency Estimation Under Local Differential  Privacy in Python",
    "abstract": "Comments: Paper published in the proceedings of ESORICS 2022",
    "descriptor": "\nComments: Paper published in the proceedings of ESORICS 2022\n",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Jean-Fran\u00e7ois Couchot",
      "S\u00e9bastien Gambs",
      "Catuscia Palamidessi",
      "Majid Zolfaghari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.02648"
  },
  {
    "id": "arXiv:2205.03519",
    "title": "Unsupervised Deep Unrolled Reconstruction Using Regularization by  Denoising",
    "abstract": "Unsupervised Deep Unrolled Reconstruction Using Regularization by  Denoising",
    "descriptor": "",
    "authors": [
      "Peizhou Huang",
      "Chaoyi Zhang",
      "Xiaoliang Zhang",
      "Xiaojuan Li",
      "Liang Dong",
      "Leslie Ying"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03519"
  },
  {
    "id": "arXiv:2205.06493",
    "title": "Regularization Theory of the Analytic Deep Prior Approach",
    "abstract": "Regularization Theory of the Analytic Deep Prior Approach",
    "descriptor": "",
    "authors": [
      "Clemens Arndt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06493"
  },
  {
    "id": "arXiv:2205.08012",
    "title": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction",
    "abstract": "Comments: AKBC 2022",
    "descriptor": "\nComments: AKBC 2022\n",
    "authors": [
      "Tara Safavi",
      "Doug Downey",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08012"
  },
  {
    "id": "arXiv:2205.11039",
    "title": "FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph  Reasoning",
    "abstract": "FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph  Reasoning",
    "descriptor": "",
    "authors": [
      "Xueyuan Lin",
      "Haihong E",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Li Ningyuan",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11039"
  },
  {
    "id": "arXiv:2205.12117",
    "title": "Phased Progressive Learning with Coupling-Regulation-Imbalance Loss for  Imbalanced Data Classification",
    "abstract": "Phased Progressive Learning with Coupling-Regulation-Imbalance Loss for  Imbalanced Data Classification",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Yi Cheng",
      "Fan Zhang",
      "Bingxuan Wu",
      "Pengfei Shao",
      "Peng Liu",
      "Shuwei Shen",
      "Peng Yao",
      "Ronald X.Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12117"
  },
  {
    "id": "arXiv:2205.14506",
    "title": "Introducing Non-Linear Activations into Quantum Generative Models",
    "abstract": "Introducing Non-Linear Activations into Quantum Generative Models",
    "descriptor": "",
    "authors": [
      "Kaitlin Gili",
      "Mykolas Sveistrys",
      "Chris Ballance"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14506"
  },
  {
    "id": "arXiv:2205.15278",
    "title": "EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware  Motion Model",
    "abstract": "Comments: Accepted by SIGGRAPH 2022 Conference Proceedings. For demo video and codes, see this https URL",
    "descriptor": "\nComments: Accepted by SIGGRAPH 2022 Conference Proceedings. For demo video and codes, see this https URL\n",
    "authors": [
      "Xinya Ji",
      "Hang Zhou",
      "Kaisiyuan Wang",
      "Qianyi Wu",
      "Wayne Wu",
      "Feng Xu",
      "Xun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15278"
  },
  {
    "id": "arXiv:2206.00517",
    "title": "One Positive Label is Sufficient: Single-Positive Multi-Label Learning  with Label Enhancement",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Ning Xu",
      "Congyu Qiao",
      "Jiaqi Lv",
      "Xin Geng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00517"
  },
  {
    "id": "arXiv:2206.01934",
    "title": "Stochastic Multiple Target Sampling Gradient Descent",
    "abstract": "Comments: 27 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 27 pages, 10 figures, 5 tables\n",
    "authors": [
      "Hoang Phan",
      "Ngoc Tran",
      "Trung Le",
      "Toan Tran",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01934"
  },
  {
    "id": "arXiv:2206.03572",
    "title": "Compressive Sensing with Wigner $D$-functions on Subsets of the Sphere",
    "abstract": "Compressive Sensing with Wigner $D$-functions on Subsets of the Sphere",
    "descriptor": "",
    "authors": [
      "Marc Andrew Valdez",
      "Alex J. Yuffa",
      "Michael B. Wakin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03572"
  },
  {
    "id": "arXiv:2206.03780",
    "title": "Attestation Mechanisms for Trusted Execution Environments Demystified",
    "abstract": "Comments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197. arXiv admin note: substantial text overlap with arXiv:2204.06790",
    "descriptor": "\nComments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197. arXiv admin note: substantial text overlap with arXiv:2204.06790\n",
    "authors": [
      "J\u00e4mes M\u00e9n\u00e9trey",
      "Christian G\u00f6ttel",
      "Anum Khurshid",
      "Marcelo Pasin",
      "Pascal Felber",
      "Valerio Schiavoni",
      "Shahid Raza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.03780"
  },
  {
    "id": "arXiv:2206.05434",
    "title": "Rewindable Quantum Computation and Its Equivalence to Cloning and  Adaptive Postselection",
    "abstract": "Comments: 29 pages, 3 figures, v2: Added Result 3 and improved Result 4",
    "descriptor": "\nComments: 29 pages, 3 figures, v2: Added Result 3 and improved Result 4\n",
    "authors": [
      "Ryo Hiromasa",
      "Akihiro Mizutani",
      "Yuki Takeuchi",
      "Seiichiro Tani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05434"
  },
  {
    "id": "arXiv:2206.05443",
    "title": "Islamic and capitalist economies: Comparison using econophysics models  of wealth exchange and redistribution",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Takeshi Kato"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05443"
  },
  {
    "id": "arXiv:2206.06973",
    "title": "Two-terminal source coding with common sum reconstruction",
    "abstract": "Comments: This paper was presented at the IEEE International Symposium on Information Theory (ISIT), Helsinki, Finland, June 2022",
    "descriptor": "\nComments: This paper was presented at the IEEE International Symposium on Information Theory (ISIT), Helsinki, Finland, June 2022\n",
    "authors": [
      "Tharindu Adikari",
      "Stark Draper"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06973"
  },
  {
    "id": "arXiv:2206.10589",
    "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for  Mobile Vision Applications",
    "abstract": "Comments: Accepted at ECCVW 2022 (CADL: Computational Aspects of Deep Learning)",
    "descriptor": "\nComments: Accepted at ECCVW 2022 (CADL: Computational Aspects of Deep Learning)\n",
    "authors": [
      "Muhammad Maaz",
      "Abdelrahman Shaker",
      "Hisham Cholakkal",
      "Salman Khan",
      "Syed Waqas Zamir",
      "Rao Muhammad Anwer",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10589"
  },
  {
    "id": "arXiv:2206.14330",
    "title": "Model-Based Approaches to Channel Charting",
    "abstract": "Comments: 28 pages, 13 figures, 6 tables",
    "descriptor": "\nComments: 28 pages, 13 figures, 6 tables\n",
    "authors": [
      "Amr Aly",
      "Ender Ayanoglu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.14330"
  },
  {
    "id": "arXiv:2207.01059",
    "title": "Identifying the Context Shift between Test Benchmarks and Production  Data",
    "abstract": "Identifying the Context Shift between Test Benchmarks and Production  Data",
    "descriptor": "",
    "authors": [
      "Matthew Groh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.01059"
  },
  {
    "id": "arXiv:2207.01773",
    "title": "Approximating Discontinuous Nash Equilibrial Values of Two-Player  General-Sum Differential Games",
    "abstract": "Comments: Submitted to ICRA 2023",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Lei Zhang",
      "Mukesh Ghimire",
      "Wenlong Zhang",
      "Zhe Xu",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.01773"
  },
  {
    "id": "arXiv:2207.01802",
    "title": "Backend Ensemble for Speaker Verification and Spoofing Countermeasure",
    "abstract": "Backend Ensemble for Speaker Verification and Spoofing Countermeasure",
    "descriptor": "",
    "authors": [
      "Li Zhang",
      "Yue Li",
      "Huan Zhao",
      "Qing Wang",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.01802"
  },
  {
    "id": "arXiv:2207.02535",
    "title": "Galois hulls of linear codes and new EAQECCs of arbitrary lengths",
    "abstract": "Comments: 32 pages, 8 tables",
    "descriptor": "\nComments: 32 pages, 8 tables\n",
    "authors": [
      "Yang Li",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.02535"
  },
  {
    "id": "arXiv:2207.03113",
    "title": "An Additive Instance-Wise Approach to Multi-class Model Interpretation",
    "abstract": "An Additive Instance-Wise Approach to Multi-class Model Interpretation",
    "descriptor": "",
    "authors": [
      "Vy Vo",
      "Van Nguyen",
      "Trung Le",
      "Quan Hung Tran",
      "Gholamreza Haffari",
      "Seyit Camtepe",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.03113"
  },
  {
    "id": "arXiv:2207.03603",
    "title": "Anthropomorphic Twisted String-Actuated Soft Robotic Gripper with  Tendon-Based Stiffening",
    "abstract": "Comments: 19 pages, 15 figures",
    "descriptor": "\nComments: 19 pages, 15 figures\n",
    "authors": [
      "David Bombara",
      "Revanth Konda",
      "Steven Swanbeck",
      "Jun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.03603"
  },
  {
    "id": "arXiv:2207.07941",
    "title": "MixTailor: Mixed Gradient Aggregation for Robust Learning Against  Tailored Attacks",
    "abstract": "Comments: To appear at the Transactions on Machine Learning Research (TMLR)",
    "descriptor": "\nComments: To appear at the Transactions on Machine Learning Research (TMLR)\n",
    "authors": [
      "Ali Ramezani-Kebrya",
      "Iman Tabrizian",
      "Fartash Faghri",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.07941"
  },
  {
    "id": "arXiv:2207.12248",
    "title": "Domain Adapting Deep Reinforcement Learning for Real-world Speech  Emotion Recognition",
    "abstract": "Domain Adapting Deep Reinforcement Learning for Real-world Speech  Emotion Recognition",
    "descriptor": "",
    "authors": [
      "Thejan Rajapakshe",
      "Rajib Rana",
      "Sara Khalifa",
      "Bjorn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.12248"
  },
  {
    "id": "arXiv:2207.12749",
    "title": "Thermodynamics of learning physical phenomena",
    "abstract": "Thermodynamics of learning physical phenomena",
    "descriptor": "",
    "authors": [
      "Elias Cueto",
      "Francisco Chinesta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2207.12749"
  },
  {
    "id": "arXiv:2208.00940",
    "title": "Maximal Extractable Value (MEV) Protection on a DAG",
    "abstract": "Maximal Extractable Value (MEV) Protection on a DAG",
    "descriptor": "",
    "authors": [
      "Dahlia Malkhi",
      "Pawel Szalachowski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.00940"
  },
  {
    "id": "arXiv:2208.03070",
    "title": "Activity Detection in Distributed MIMO: Distributed AMP via Likelihood  Ratio Fusion",
    "abstract": "Comments: 5 pages, 2 figures. This paper has been accepted for publication in IEEE Wireless Communications Letters. Code available at this https URL",
    "descriptor": "\nComments: 5 pages, 2 figures. This paper has been accepted for publication in IEEE Wireless Communications Letters. Code available at this https URL\n",
    "authors": [
      "Jianan Bai",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.03070"
  },
  {
    "id": "arXiv:2208.05083",
    "title": "Reducing Exploitability with Population Based Training",
    "abstract": "Comments: Presented at New Frontiers in Adversarial Machine Learning Workshop, ICML 2022",
    "descriptor": "\nComments: Presented at New Frontiers in Adversarial Machine Learning Workshop, ICML 2022\n",
    "authors": [
      "Pavel Czempin",
      "Adam Gleave"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.05083"
  },
  {
    "id": "arXiv:2208.05456",
    "title": "Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in  Extending Existing Social Computing Systems",
    "abstract": "Comments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW '22)",
    "descriptor": "\nComments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW '22)\n",
    "authors": [
      "Daniel A. Epstein",
      "Fannie Liu",
      "Andr\u00e9s Monroy-Hern\u00e1ndez",
      "Dennis Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.05456"
  },
  {
    "id": "arXiv:2208.08485",
    "title": "Complex-Value Spatio-temporal Graph Convolutional Neural Networks and  its Applications to Electric Power Systems AI",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tong Wu",
      "Anna Scaglione",
      "Daniel Arnold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08485"
  },
  {
    "id": "arXiv:2208.11949",
    "title": "Finite element methods for multicomponent convection-diffusion",
    "abstract": "Finite element methods for multicomponent convection-diffusion",
    "descriptor": "",
    "authors": [
      "Francis R. A. Aznaran",
      "Patrick E. Farrell",
      "Charles W. Monroe",
      "Alexander J. Van-Brunt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2208.11949"
  },
  {
    "id": "arXiv:2208.13085",
    "title": "Target Speaker Voice Activity Detection with Transformers and Its  Integration with End-to-End Neural Diarization",
    "abstract": "Target Speaker Voice Activity Detection with Transformers and Its  Integration with End-to-End Neural Diarization",
    "descriptor": "",
    "authors": [
      "Dongmei Wang",
      "Xiong Xiao",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Jian Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2208.13085"
  },
  {
    "id": "arXiv:2208.13389",
    "title": "Several classes of Galois self-orthogonal MDS codes",
    "abstract": "Comments: 18 pages, 9 tables",
    "descriptor": "\nComments: 18 pages, 9 tables\n",
    "authors": [
      "Yang Li",
      "Yunfei Su",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.13389"
  },
  {
    "id": "arXiv:2208.13653",
    "title": "Learning Binary and Sparse Permutation-Invariant Representations for  Fast and Memory Efficient Whole Slide Image Search",
    "abstract": "Learning Binary and Sparse Permutation-Invariant Representations for  Fast and Memory Efficient Whole Slide Image Search",
    "descriptor": "",
    "authors": [
      "Sobhan Hemati",
      "Shivam Kalra",
      "Morteza Babaie",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13653"
  },
  {
    "id": "arXiv:2208.14319",
    "title": "Representation Learning based and Interpretable Reactor System Diagnosis  Using Denoising Padded Autoencoder",
    "abstract": "Representation Learning based and Interpretable Reactor System Diagnosis  Using Denoising Padded Autoencoder",
    "descriptor": "",
    "authors": [
      "Chengyuan Li",
      "Zhifang Qiu",
      "Zhangrui Yan",
      "Meifu Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.14319"
  },
  {
    "id": "arXiv:2208.14698",
    "title": "Bayesian Optimization-based Combinatorial Assignment",
    "abstract": "Bayesian Optimization-based Combinatorial Assignment",
    "descriptor": "",
    "authors": [
      "Jakob Weissteiner",
      "Jakob Heiss",
      "Julien Siems",
      "Sven Seuken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.14698"
  },
  {
    "id": "arXiv:2209.00654",
    "title": "Distributional Drift Adaptation with Temporal Conditional Variational  Autoencoder for Multivariate Time Series Forecasting",
    "abstract": "Comments: 13 pages, 6 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: 13 pages, 6 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Hui He",
      "Qi Zhang",
      "Kun Yi",
      "Kaize Shi",
      "Zhendong Niu",
      "Longbin Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.00654"
  },
  {
    "id": "arXiv:2209.00771",
    "title": "Optimizing the Performative Risk under Weak Convexity Assumptions",
    "abstract": "Optimizing the Performative Risk under Weak Convexity Assumptions",
    "descriptor": "",
    "authors": [
      "Yulai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.00771"
  },
  {
    "id": "arXiv:2209.04161",
    "title": "ApproxTrain: Fast Simulation of Approximate Multipliers for DNN Training  and Inference",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Jing Gong",
      "Hassaan Saadat",
      "Hasindu Gamaarachchi",
      "Haris Javaid",
      "Xiaobo Sharon Hu",
      "Sri Parameswaran"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04161"
  },
  {
    "id": "arXiv:2209.04213",
    "title": "Autoencoder Based Iterative Modeling and Multivariate Time-Series  Subsequence Clustering Algorithm",
    "abstract": "Comments: 26 pages, 11 figures, for associated python code repositories see this https URL and this https URL; Minor spelling and grammar corrections, fixed wrong bibtex entry for SOStream, some improvements and corrections in formulas of section 4",
    "descriptor": "\nComments: 26 pages, 11 figures, for associated python code repositories see this https URL and this https URL; Minor spelling and grammar corrections, fixed wrong bibtex entry for SOStream, some improvements and corrections in formulas of section 4\n",
    "authors": [
      "Jonas K\u00f6hne",
      "Lars Henning",
      "Clemens G\u00fchmann"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04213"
  },
  {
    "id": "arXiv:2209.05307",
    "title": "Data-driven Parametric Insurance Framework Using Bayesian Neural  Networks",
    "abstract": "Data-driven Parametric Insurance Framework Using Bayesian Neural  Networks",
    "descriptor": "",
    "authors": [
      "Subeen Pang",
      "Chanyeol Choi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.05307"
  },
  {
    "id": "arXiv:2209.05557",
    "title": "Blurring Diffusion Models",
    "abstract": "Blurring Diffusion Models",
    "descriptor": "",
    "authors": [
      "Emiel Hoogeboom",
      "Tim Salimans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.05557"
  },
  {
    "id": "arXiv:2209.05559",
    "title": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "abstract": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "descriptor": "",
    "authors": [
      "Berend Jelmer Dirk Gort",
      "Xiao-Yang Liu",
      "Xinghang Sun",
      "Jiechao Gao",
      "Shuaiyu Chen",
      "Christina Dan Wang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.05559"
  },
  {
    "id": "arXiv:2209.05668",
    "title": "Class-Level Logit Perturbation",
    "abstract": "Class-Level Logit Perturbation",
    "descriptor": "",
    "authors": [
      "Mengyang Li",
      "Fengguang Su",
      "Ou Wu",
      "Ji Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.05668"
  },
  {
    "id": "arXiv:2209.06119",
    "title": "APTx: better activation function than MISH, SWISH, and ReLU's variants  used in deep learning",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Ravin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.06119"
  },
  {
    "id": "arXiv:2209.06430",
    "title": "CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language  Representation Alignment",
    "abstract": "CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language  Representation Alignment",
    "descriptor": "",
    "authors": [
      "Hongwei Xue",
      "Yuchong Sun",
      "Bei Liu",
      "Jianlong Fu",
      "Ruihua Song",
      "Houqiang Li",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06430"
  },
  {
    "id": "arXiv:2209.07063",
    "title": "GAGA: Deciphering Age-path of Generalized Self-paced Regularizer",
    "abstract": "Comments: 33 pages. Published as a conference paper at NeurIPS 2022",
    "descriptor": "\nComments: 33 pages. Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Xingyu Qu",
      "Diyang Li",
      "Xiaohan Zhao",
      "Bin Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07063"
  },
  {
    "id": "arXiv:2209.07224",
    "title": "Towards Interoperability of Open and Permissionless Blockchains: A  Cross-Chain Query Language",
    "abstract": "Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Felix H\u00e4rer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.07224"
  },
  {
    "id": "arXiv:2209.07285",
    "title": "Identifying research supporting the United Nations Sustainable  Development Goals",
    "abstract": "Comments: 11 pages, 3 figures, 5 tables, 18 references",
    "descriptor": "\nComments: 11 pages, 3 figures, 5 tables, 18 references\n",
    "authors": [
      "Yury Kashnitsky",
      "Guillaume Roberge",
      "Jingwen Mu",
      "Kevin Kang",
      "Weiwei Wang",
      "Maurice Vanderfeesten",
      "Maxim Rivest",
      "Lennart Ke\u00dfler",
      "Robert Jaworek",
      "Ma\u00e9va Vignes",
      "Bamini Jayabalasingham",
      "Finne Boonen",
      "Chris James",
      "Marius Doornenbal",
      "Isabelle Labrosse"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2209.07285"
  },
  {
    "id": "arXiv:2209.07637",
    "title": "Library transfer between distinct Laser-Induced Breakdown Spectroscopy  systems with shared standards",
    "abstract": "Comments: 32 pages, 22 figures",
    "descriptor": "\nComments: 32 pages, 22 figures\n",
    "authors": [
      "J. Vr\u00e1bel",
      "E. K\u00e9pe\u0161",
      "P. Ned\u011bln\u00edk",
      "J. Buday",
      "J. Cemp\u00edrek",
      "P. Po\u0159\u00edzka",
      "J. Kaiser"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07637"
  },
  {
    "id": "arXiv:2209.08722",
    "title": "Faster Randomized Interior Point Methods for Tall/Wide Linear Programs",
    "abstract": "Comments: Extended version of the NeurIPS 2020 submission. arXiv admin note: substantial text overlap with arXiv:2003.08072",
    "descriptor": "\nComments: Extended version of the NeurIPS 2020 submission. arXiv admin note: substantial text overlap with arXiv:2003.08072\n",
    "authors": [
      "Agniva Chowdhury",
      "Gregory Dexter",
      "Palma London",
      "Haim Avron",
      "Petros Drineas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.08722"
  },
  {
    "id": "arXiv:2209.08857",
    "title": "Deep Fusion of Multi-Object Densities Using Transformer",
    "abstract": "Comments: 5 pages, 4 figures. Python implementation is available at this https URL",
    "descriptor": "\nComments: 5 pages, 4 figures. Python implementation is available at this https URL\n",
    "authors": [
      "Lechi Li",
      "Chen Dai",
      "Yuxuan Xia",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08857"
  },
  {
    "id": "arXiv:2209.09449",
    "title": "Data-Centric AI Paradigm Based on Application-Driven Fine-grained  Dataset Design",
    "abstract": "Data-Centric AI Paradigm Based on Application-Driven Fine-grained  Dataset Design",
    "descriptor": "",
    "authors": [
      "Huan Hu",
      "Yajie Cui",
      "Zhaoxiang Liu",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09449"
  },
  {
    "id": "arXiv:2209.10178",
    "title": "Deep Learning based pipeline for anomaly detection and quality  enhancement in industrial binder jetting processes",
    "abstract": "Comments: Conference paper for: 17. Fachtagung \"Entwurf komplexer Automatisierungssysteme (EKA)\", Magdeburg/Germany, June 2022",
    "descriptor": "\nComments: Conference paper for: 17. Fachtagung \"Entwurf komplexer Automatisierungssysteme (EKA)\", Magdeburg/Germany, June 2022\n",
    "authors": [
      "Alexander Zeiser",
      "Bas van Stein",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10178"
  },
  {
    "id": "arXiv:2209.10292",
    "title": "Fast Few shot Self-attentive Semi-supervised Political Inclination  Prediction",
    "abstract": "Comments: Accepted to ICADL'22",
    "descriptor": "\nComments: Accepted to ICADL'22\n",
    "authors": [
      "Souvic Chakraborty",
      "Pawan Goyal",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10292"
  },
  {
    "id": "arXiv:2209.10642",
    "title": "Caught in the Crossfire: Fears of Chinese-American Scientists",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Yu Xie",
      "Xihong Lin",
      "Ju Li",
      "Qian He",
      "Junming Huang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2209.10642"
  },
  {
    "id": "arXiv:2209.10791",
    "title": "Homophone Reveals the Truth: A Reality Check for Speech2Vec",
    "abstract": "Comments: Corrected typos",
    "descriptor": "\nComments: Corrected typos\n",
    "authors": [
      "Guangyu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.10791"
  },
  {
    "id": "arXiv:2209.10807",
    "title": "SR-GCL: Session-Based Recommendation with Global Context Enhanced  Augmentation in Contrastive Learning",
    "abstract": "Comments: 11 pages. This paper has been accepted by DLG-AAAI'22",
    "descriptor": "\nComments: 11 pages. This paper has been accepted by DLG-AAAI'22\n",
    "authors": [
      "Eunkyu Oh",
      "Taehun Kim",
      "Minsoo Kim",
      "Yunhu Ji",
      "Sushil Khyalia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.10807"
  },
  {
    "id": "arXiv:2209.10892",
    "title": "Online Ridesharing with Meeting Points [Technical Report]",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Jiachuan Wang",
      "Peng Cheng",
      "Libin Zheng",
      "Lei Chen",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.10892"
  },
  {
    "id": "arXiv:2209.11047",
    "title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image  Translation",
    "abstract": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image  Translation",
    "descriptor": "",
    "authors": [
      "Junyoung Seo",
      "Gyuseong Lee",
      "Seokju Cho",
      "Jiyoung Lee",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11047"
  },
  {
    "id": "arXiv:2209.11112",
    "title": "CMGAN: Conformer-Based Metric-GAN for Monaural Speech Enhancement",
    "abstract": "Comments: 16 pages, 10 figures and 5 tables. arXiv admin note: text overlap with arXiv:2203.15149",
    "descriptor": "\nComments: 16 pages, 10 figures and 5 tables. arXiv admin note: text overlap with arXiv:2203.15149\n",
    "authors": [
      "Sherif Abdulatif",
      "Ruizhe Cao",
      "Bin Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.11112"
  },
  {
    "id": "arXiv:2209.11128",
    "title": "Learning Interpretable Latent Dialogue Actions With Less Supervision",
    "abstract": "Comments: 9 pages, accepted to AACL-IJCNLP 2022",
    "descriptor": "\nComments: 9 pages, accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Vojt\u011bch Hude\u010dek",
      "Ond\u0159ej Du\u0161ek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11128"
  },
  {
    "id": "arXiv:2209.11224",
    "title": "VToonify: Controllable High-Resolution Portrait Video Style Transfer",
    "abstract": "Comments: ACM Transactions on Graphics (SIGGRAPH Asia 2022). Code: this https URL Project page: this https URL",
    "descriptor": "\nComments: ACM Transactions on Graphics (SIGGRAPH Asia 2022). Code: this https URL Project page: this https URL\n",
    "authors": [
      "Shuai Yang",
      "Liming Jiang",
      "Ziwei Liu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11224"
  }
]
[
  {
    "id": "arXiv:2209.06822",
    "title": "Using Genetic Algorithms to Simulate Evolution",
    "abstract": "Evolution is the theory that plants and animals today have come from kinds\nthat have existed in the past. Scientists such as Charles Darwin and Alfred\nWallace dedicate their life to observe how species interact with their\nenvironment, grow, and change. We are able to predict future changes as well as\nsimulate the process using genetic algorithms. Genetic Algorithms give us the\nopportunity to present multiple variables and parameters to an environment and\nchange values to simulate different situations. By optimizing genetic\nalgorithms to hold entities in an environment, we are able to assign varying\ncharacteristics such as speed, size, and cloning probability, to the entities\nto simulate real natural selection and evolution in a shorter period of time.\nLearning about how species grow and evolve allows us to find ways to improve\ntechnology, help animals going extinct to survive, and figure* out how diseases\nspread and possible ways of making an environment uninhabitable for them. Using\ndata from an environment including genetic algorithms and parameters of speed,\nsize, and cloning percentage, the ability to test several changes in the\nenvironment and observe how the species interacts within it appears. After\ntesting different environments with a varied amount of food while keeping the\nnumber of starting population at 10 entities, it was found that an environment\nwith a scarce amount of food was not sustainable for small and slow entities.\nAll environments displayed an increase in speed, but the environments that were\nricher in food allowed for the entities to live for the entire duration of 50\ngenerations, as well as allowed the population to grow significantly.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Manasa Josyula"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.06822"
  },
  {
    "id": "arXiv:2209.06823",
    "title": "DEANet: Decomposition Enhancement and Adjustment Network for Low-Light  Image Enhancement",
    "abstract": "Images obtained under low-light conditions will seriously affect the quality\nof the images. Solving the problem of poor low-light image quality can\neffectively improve the visual quality of images and better improve the\nusability of computer vision. In addition, it has very important applications\nin many fields. This paper proposes a DEANet based on Retinex for low-light\nimage enhancement. It combines the frequency information and content\ninformation of the image into three sub-networks: decomposition network,\nenhancement network and adjustment network. These three sub-networks are\nrespectively used for decomposition, denoising, contrast enhancement and detail\npreservation, adjustment, and image generation. Our model has good robust\nresults for all low-light images. The model is trained on the public data set\nLOL, and the experimental results show that our method is better than the\nexisting state-of-the-art methods in terms of vision and quality.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Yonglong Jiang",
      "Liangliang Li",
      "Yuan Xue",
      "Hongbing Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06823"
  },
  {
    "id": "arXiv:2209.06824",
    "title": "An ensemble Multi-Agent System for non-linear classification",
    "abstract": "Self-Adaptive Multi-Agent Systems (AMAS) transform machine learning problems\ninto problems of local cooperation between agents. We present smapy, an\nensemble based AMAS implementation for mobility prediction, whose agents are\nprovided with machine learning models in addition to their cooperation rules.\nWith a detailed methodology, we show that it is possible to use linear models\nfor nonlinear classification on a benchmark transport mode detection dataset,\nif they are integrated in a cooperative multi-agent structure. The results\nobtained show a significant improvement of the performance of linear models in\nnon-linear contexts thanks to the multi-agent approach.",
    "descriptor": "",
    "authors": [
      "Thibault Fourez",
      "Nicolas Verstaevel",
      "Fr\u00e9d\u00e9ric Migeon",
      "Fr\u00e9d\u00e9ric Schettini",
      "Frederic Amblard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.06824"
  },
  {
    "id": "arXiv:2209.06825",
    "title": "An Exploration of Hands-free Text Selection for Virtual Reality  Head-Mounted Displays",
    "abstract": "Hand-based interaction, such as using a handheld controller or making hand\ngestures, has been widely adopted as the primary method for interacting with\nboth virtual reality (VR) and augmented reality (AR) head-mounted displays\n(HMDs). In contrast, hands-free interaction avoids the need for users' hands\nand although it can afford additional benefits, there has been limited research\nin exploring and evaluating hands-free techniques for these HMDs. As VR HMDs\nbecome ubiquitous, people will need to do text editing, which requires\nselecting text segments. Similar to hands-free interaction, text selection is\nunderexplored. This research focuses on both, text selection via hands-free\ninteraction. Our exploration involves a user study with 24 participants to\ninvestigate the performance, user experience, and workload of three hands-free\nselection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.\nResults indicate that Blink outperforms Dwell and Voice in completion time.\nUsers' subjective feedback also shows that Blink is the preferred technique for\ntext selection. This work is the first to explore hands-free interaction for\ntext selection in VR HMDs. Our results provide a solid platform for further\nresearch in this important area.",
    "descriptor": "\nComments: IEEE ISMAR'22 conference track; 8 pages. arXiv admin note: text overlap with arXiv:2209.06498\n",
    "authors": [
      "Xuanru Meng",
      "Wenge Xu",
      "Hai-Ning Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.06825"
  },
  {
    "id": "arXiv:2209.06826",
    "title": "Modifying Squint for Prediction with Expert Advice in a Changing  Environment",
    "abstract": "We provide a new method for online learning, specifically prediction with\nexpert advice, in a changing environment. In a non-changing environment the\nSquint algorithm has been designed to always function at least as well as other\nknown algorithms and in specific cases it functions much better. However, when\nusing a conventional black-box algorithm to make Squint suitable for a changing\nenvironment, it loses its beneficial properties. Hence, we provide a new\nalgorithm, Squint-CE, which is suitable for a changing environment and\npreserves the properties of Squint.",
    "descriptor": "",
    "authors": [
      "Thom Neuteboom",
      "Tim van Erven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06826"
  },
  {
    "id": "arXiv:2209.06827",
    "title": "Weakly Supervised Invariant Representation Learning Via Disentangling  Known and Unknown Nuisance Factors",
    "abstract": "Disentangled and invariant representations are two critical goals of\nrepresentation learning and many approaches have been proposed to achieve\neither one of them. However, those two goals are actually complementary to each\nother so that we propose a framework to accomplish both of them simultaneously.\nWe introduce a weakly supervised signal to learn disentangled representation\nwhich consists of three splits containing predictive, known nuisance and\nunknown nuisance information respectively. Furthermore, we incorporate\ncontrastive method to enforce representation invariance. Experiments shows that\nthe proposed method outperforms state-of-the-art (SOTA) methods on four\nstandard benchmarks and shows that the proposed method can have better\nadversarial defense ability comparing to other methods without adversarial\ntraining.",
    "descriptor": "",
    "authors": [
      "Jiageng Zhu",
      "Hanchen Xie",
      "Wael Abd-Almageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.06827"
  },
  {
    "id": "arXiv:2209.06828",
    "title": "A Temporal Anomaly Detection System for Vehicles utilizing Functional  Working Groups and Sensor Channels",
    "abstract": "A modern vehicle fitted with sensors, actuators, and Electronic Control Units\n(ECUs) can be divided into several operational subsystems called Functional\nWorking Groups (FWGs). Examples of these FWGs include the engine system,\ntransmission, fuel system, brakes, etc. Each FWG has associated sensor-channels\nthat gauge vehicular operating conditions. This data rich environment is\nconducive to the development of Predictive Maintenance (PdM) technologies.\nUndercutting various PdM technologies is the need for robust anomaly detection\nmodels that can identify events or observations which deviate significantly\nfrom the majority of the data and do not conform to a well defined notion of\nnormal vehicular operational behavior. In this paper, we introduce the Vehicle\nPerformance, Reliability, and Operations (VePRO) dataset and use it to create a\nmulti-phased approach to anomaly detection. Utilizing Temporal Convolution\nNetworks (TCN), our anomaly detection system can achieve 96% detection accuracy\nand accurately predicts 91% of true anomalies. The performance of our anomaly\ndetection system improves when sensor channels from multiple FWGs are utilized.",
    "descriptor": "",
    "authors": [
      "Subash Neupane",
      "Ivan A. Fernandez",
      "Wilson Patterson",
      "Sudip Mittal",
      "Shahram Rahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.06828"
  },
  {
    "id": "arXiv:2209.06850",
    "title": "CAT: Controllable Attribute Translation for Fair Facial Attribute  Classification",
    "abstract": "As the social impact of visual recognition has been under scrutiny, several\nprotected-attribute balanced datasets emerged to address dataset bias in\nimbalanced datasets. However, in facial attribute classification, dataset bias\nstems from both protected attribute level and facial attribute level, which\nmakes it challenging to construct a multi-attribute-level balanced real\ndataset. To bridge the gap, we propose an effective pipeline to generate\nhigh-quality and sufficient facial images with desired facial attributes and\nsupplement the original dataset to be a balanced dataset at both levels, which\ntheoretically satisfies several fairness criteria. The effectiveness of our\nmethod is verified on sex classification and facial attribute classification by\nyielding comparable task performance as the original dataset and further\nimproving fairness in a comprehensive fairness evaluation with a wide range of\nmetrics. Furthermore, our method outperforms both resampling and balanced\ndataset construction to address dataset bias, and debiasing models to address\ntask bias.",
    "descriptor": "",
    "authors": [
      "Jiazhi Li",
      "Wael Abd-Almageed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06850"
  },
  {
    "id": "arXiv:2209.06852",
    "title": "A Model Drift Detection and Adaptation Framework for 5G Core Networks",
    "abstract": "The advent of Fifth Generation (5G) and beyond 5G networks (5G+) has\nrevolutionized the way network operators consider the management and\norchestration of their networks. With an increased focus on intelligence and\nautomation through core network functions such as the NWDAF, service providers\nare tasked with integrating machine learning models and artificial intelligence\nsystems into their existing network operation practices. Due to the dynamic\nnature of next-generation networks and their supported use cases and\napplications, model drift is a serious concern, which can deteriorate the\nperformance of intelligent models deployed throughout the network. The work\npresented in this paper introduces a model drift detection and adaptation\nmodule for 5G core networks. Using a functional prototype of a 5G core network,\na drift in user behaviour is emulated, and the proposed framework is deployed\nand tested. The results of this work demonstrate the ability of the drift\ndetection module to accurately characterize a drifted concept as well as the\nability of the drift adaptation module to begin the necessary remediation\nefforts to restore system performance.",
    "descriptor": "\nComments: Accepted: IEEE MeditCom 2022\n",
    "authors": [
      "Dimitrios Michael Manias",
      "Ali Chouman",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06852"
  },
  {
    "id": "arXiv:2209.06855",
    "title": "Data Lifecycle Management in Evolving Input Distributions for  Learning-based Aerospace Applications",
    "abstract": "As input distributions evolve over a mission lifetime, maintaining\nperformance of learning-based models becomes challenging. This paper presents a\nframework to incrementally retrain a model by selecting a subset of test inputs\nto label, which allows the model to adapt to changing input distributions.\nAlgorithms within this framework are evaluated based on (1) model performance\nthroughout mission lifetime and (2) cumulative costs associated with labeling\nand model retraining. We provide an open-source benchmark of a satellite pose\nestimation model trained on images of a satellite in space and deployed in\nnovel scenarios (e.g., different backgrounds or misbehaving pixels), where\nalgorithms are evaluated on their ability to maintain high performance by\nretraining on a subset of inputs. We also propose a novel algorithm to select a\ndiverse subset of inputs for labeling, by characterizing the information gain\nfrom an input using Bayesian uncertainty quantification and choosing a subset\nthat maximizes collective information gain using concepts from batch active\nlearning. We show that our algorithm outperforms others on the benchmark, e.g.,\nachieves comparable performance to an algorithm that labels 100% of inputs,\nwhile only labeling 50% of inputs, resulting in low costs and high performance\nover the mission lifetime.",
    "descriptor": "",
    "authors": [
      "Somrita Banerjee",
      "Apoorva Sharma",
      "Edward Schmerling",
      "Max Spolaor",
      "Michael Nemerouf",
      "Marco Pavone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06855"
  },
  {
    "id": "arXiv:2209.06861",
    "title": "Landmark-free Statistical Shape Modeling via Neural Flow Deformations",
    "abstract": "Statistical shape modeling aims at capturing shape variations of an\nanatomical structure that occur within a given population. Shape models are\nemployed in many tasks, such as shape reconstruction and image segmentation,\nbut also shape generation and classification. Existing shape priors either\nrequire dense correspondence between training examples or lack robustness and\ntopological guarantees. We present FlowSSM, a novel shape modeling approach\nthat learns shape variability without requiring dense correspondence between\ntraining instances. It relies on a hierarchy of continuous deformation flows,\nwhich are parametrized by a neural network. Our model outperforms\nstate-of-the-art methods in providing an expressive and robust shape prior for\ndistal femur and liver. We show that the emerging latent representation is\ndiscriminative by separating healthy from pathological shapes. Ultimately, we\ndemonstrate its effectiveness on two shape reconstruction tasks from partial\ndata. Our source code is publicly available\n(https://github.com/davecasp/flowssm).",
    "descriptor": "\nComments: accepted for MICCAI 2022\n",
    "authors": [
      "David L\u00fcdke",
      "Tamaz Amiranashvili",
      "Felix Ambellan",
      "Ivan Ezhov",
      "Bjoern Menze",
      "Stefan Zachow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06861"
  },
  {
    "id": "arXiv:2209.06866",
    "title": "Robust Constrained Reinforcement Learning",
    "abstract": "Constrained reinforcement learning is to maximize the expected reward subject\nto constraints on utilities/costs. However, the training environment may not be\nthe same as the test one, due to, e.g., modeling error, adversarial attack,\nnon-stationarity, resulting in severe performance degradation and more\nimportantly constraint violation. We propose a framework of robust constrained\nreinforcement learning under model uncertainty, where the MDP is not fixed but\nlies in some uncertainty set, the goal is to guarantee that constraints on\nutilities/costs are satisfied for all MDPs in the uncertainty set, and to\nmaximize the worst-case reward performance over the uncertainty set. We design\na robust primal-dual approach, and further theoretically develop guarantee on\nits convergence, complexity and robust feasibility. We then investigate a\nconcrete example of $\\delta$-contamination uncertainty set, design an online\nand model-free algorithm and theoretically characterize its sample complexity.",
    "descriptor": "",
    "authors": [
      "Yue Wang",
      "Fei Miao",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06866"
  },
  {
    "id": "arXiv:2209.06869",
    "title": "On the State of the Art in Authorship Attribution and Authorship  Verification",
    "abstract": "Despite decades of research on authorship attribution (AA) and authorship\nverification (AV), inconsistent dataset splits/filtering and mismatched\nevaluation methods make it difficult to assess the state of the art. In this\npaper, we present a survey of the fields, resolve points of confusion,\nintroduce Valla that standardizes and benchmarks AA/AV datasets and metrics,\nprovide a large-scale empirical evaluation, and provide apples-to-apples\ncomparisons between existing methods. We evaluate eight promising methods on\nfifteen datasets (including distribution-shifted challenge sets) and introduce\na new large-scale dataset based on texts archived by Project Gutenberg.\nSurprisingly, we find that a traditional Ngram-based model performs best on 5\n(of 7) AA tasks, achieving an average macro-accuracy of $76.50\\%$ (compared to\n$66.71\\%$ for a BERT-based model). However, on the two AA datasets with the\ngreatest number of words per author, as well as on the AV datasets, BERT-based\nmodels perform best. While AV methods are easily applied to AA, they are seldom\nincluded as baselines in AA papers. We show that through the application of\nhard-negative mining, AV methods are competitive alternatives to AA methods.\nValla and all experiment code can be found here:\nhttps://github.com/JacobTyo/Valla",
    "descriptor": "",
    "authors": [
      "Jacob Tyo",
      "Bhuwan Dhingra",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06869"
  },
  {
    "id": "arXiv:2209.06877",
    "title": "PAPyA: Performance Analysis of Large RDF Graphs Processing Made Easy",
    "abstract": "Prescriptive Performance Analysis (PPA) has shown to be more useful than\ntraditional descriptive and diagnostic analyses for making sense of Big Data\n(BD) frameworks' performance. In practice, when processing large (RDF) graphs\non top of relational BD systems, several design decisions emerge and cannot be\ndecided automatically, e.g., the choice of the schema, the partitioning\ntechnique, and the storage formats. PPA, and in particular ranking functions,\nhelps enable actionable insights on performance data, leading practitioners to\nan easier choice of the best way to deploy BD frameworks, especially for graph\nprocessing. However, the amount of experimental work required to implement PPA\nis still huge. In this paper, we present PAPyA 1, a library for implementing\nPPA that allows (1) preparing RDF graphs data for a processing pipeline over\nrelational BD systems, (2) enables automatic ranking of the performance in a\nuser-defined solution space of experimental dimensions; (3) allows user-defined\nflexible extensions in terms of systems to test and ranking methods. We\nshowcase PAPyA on a set of experiments based on the SparkSQL framework. PAPyA\nsimplifies the performance analytics of BD systems for processing large (RDF)\ngraphs.We provide PAPyA as a public open-source library under an MIT license\nthat will be a catalyst for designing new research prescriptive analytical\ntechniques for BD applications.",
    "descriptor": "\nComments: Under Review in the Semantic Web Journal (SWJ). this https URL\n",
    "authors": [
      "Mohamed Ragab",
      "Adam Satria Adidarma",
      "Riccardo Tommasini"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.06877"
  },
  {
    "id": "arXiv:2209.06886",
    "title": "Vectorized Adjoint Sensitivity Method for Graph Convolutional Neural  Ordinary Differential Equations",
    "abstract": "This document, as the title stated, is meant to provide a vectorized\nimplementation of adjoint dynamics calculation for Graph Convolutional Neural\nOrdinary Differential Equations (GCDE). The adjoint sensitivity method is the\ngradient approximation method for neural ODEs that replaces the back\npropagation. When implemented on libraries such as PyTorch or Tensorflow, the\nadjoint can be calculated by autograd functions without the need for a\nhand-derived formula. In applications such as edge computing and in memristor\ncrossbars, however, autograds are not available, and therefore we need a\nvectorized derivation of adjoint dynamics to efficiently map the system on\nhardware. This document will go over the basics, then move on to derive the\nvectorized adjoint dynamics for GCDE.",
    "descriptor": "",
    "authors": [
      "Jack Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06886"
  },
  {
    "id": "arXiv:2209.06888",
    "title": "ADAMANT: A Pipeline for Adaptable Manipulation Tasks",
    "abstract": "This paper presents ADAMANT, a set of software modules that provides grasp\nplanning capabilities to an existing robot planning and control software\nframework. Our presented work allows a user to adapt a manipulation task to be\nused under widely different scenarios with minimal user input, thus reducing\nthe operator's cognitive load. The developed tools include (1) plugin-based\ncomponents that make it easy to extend default capabilities and to use\nthird-party grasp libraries, (2) An object-centric way to define task\nconstraints, (3) A user-friendly Rviz interface to use the grasp planner\nutilities, and (4) Interactive tools to use perception data to program a task.\nWe tested our framework on a wide variety of robot simulations.",
    "descriptor": "\nComments: Preprint. In review\n",
    "authors": [
      "Ana Huam\u00e1n Quispe",
      "Stephen Hart",
      "Seth Gee",
      "Robert R. Burridge"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06888"
  },
  {
    "id": "arXiv:2209.06889",
    "title": "Time Series Prediction for Food sustainability",
    "abstract": "With exponential growth in the human population, it is vital to conserve\nnatural resources without compromising on producing enough food to feed\neveryone. Doing so can improve people's livelihoods, health, and ecosystems for\nthe present and future generations. Sustainable development, a paradigm of the\nUnited Nations, is rooted in food, crop, livestock, forest, population, and\neven the emission of gases. By understanding the overall usage of natural\nresources in different countries in the past, it is possible to forecast the\ndemand in each country. The proposed solution consists of implementing a\nmachine learning system using a statistical regression model that can predict\nthe top k products that would endure a shortage in each country in a specific\nperiod in the future. The prediction performance in terms of absolute error and\nroot mean square error show promising results due to its low errors. This\nsolution could help organizations and manufacturers understand the productivity\nand sustainability needed to satisfy the global demand.",
    "descriptor": "",
    "authors": [
      "Fiona Victoria Stanley Jothiraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06889"
  },
  {
    "id": "arXiv:2209.06890",
    "title": "Transferring Implicit Knowledge of Non-Visual Object Properties Across  Heterogeneous Robot Morphologies",
    "abstract": "Humans leverage multiple sensor modalities when interacting with objects and\ndiscovering their intrinsic properties. Using the visual modality alone is\ninsufficient for deriving intuition behind object properties (e.g., which of\ntwo boxes is heavier), making it essential to consider non-visual modalities as\nwell, such as the tactile and auditory. Whereas robots may leverage various\nmodalities to obtain object property understanding via learned exploratory\ninteractions with objects (e.g., grasping, lifting, and shaking behaviors),\nchallenges remain: the implicit knowledge acquired by one robot via object\nexploration cannot be directly leveraged by another robot with different\nmorphology, because the sensor models, observed data distributions, and\ninteraction capabilities are different across these different robot\nconfigurations. To avoid the costly process of learning interactive object\nperception tasks from scratch, we propose a multi-stage projection framework\nfor each new robot for transferring implicit knowledge of object properties\nacross heterogeneous robot morphologies. We evaluate our approach on the\nobject-property recognition and object-identity recognition tasks, using a\ndataset containing two heterogeneous robots that perform 7,600 object\ninteractions. Results indicate that knowledge can be transferred across robots,\nsuch that a newly-deployed robot can bootstrap its recognition models without\nexhaustively exploring all objects. We also propose a data augmentation\ntechnique and show that this technique improves the generalization of models.\nWe release our code and datasets, here:\nhttps://github.com/gtatiya/Implicit-Knowledge-Transfer.",
    "descriptor": "\nComments: Under review for 2023 IEEE International Conference on Robotics and Automation (ICRA), May 29 - June 2, 2023 , ExCeL London, UK\n",
    "authors": [
      "Gyan Tatiya",
      "Jonathan Francis",
      "Jivko Sinapov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06890"
  },
  {
    "id": "arXiv:2209.06892",
    "title": "Interpolation-based immersed finite element and isogeometric analysis",
    "abstract": "We introduce a new paradigm for immersed finite element and isogeometric\nmethods based on interpolating function spaces from an unfitted background mesh\ninto Lagrange finite element spaces defined on a foreground mesh that captures\nthe domain geometry but is otherwise subject to minimal constraints on element\nquality or connectivity. This is a generalization of the concept of Lagrange\nextraction from the isogeometric analysis literature and also related to\ncertain variants of the finite cell and material point methods. Crucially, the\ninterpolation may be approximate without sacrificing high-order convergence\nrates, which distinguishes the present method from existing finite cell,\nCutFEM, and immersogeometric approaches. The interpolation paradigm also\npermits non-invasive reuse of existing finite element software for immersed\nanalysis. We analyze the properties of the interpolation-based immersed\nparadigm for a model problem and implement it on top of the open-source FEniCS\nfinite element software, to apply it to a variety of problems in fluid, solid,\nand structural mechanics where we demonstrate high-order accuracy and\napplicability to practical geometries like trimmed spline patches.",
    "descriptor": "",
    "authors": [
      "Jennifer E. Fromm",
      "Nils Wunsch",
      "Ru Xiang",
      "Han Zhao",
      "Kurt Maute",
      "John A. Evans",
      "David Kamensky"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06892"
  },
  {
    "id": "arXiv:2209.06896",
    "title": "Robust Safe Control for Uncertain Dynamic Models",
    "abstract": "Model mismatches prevail in real-world applications. Hence it is important to\ndesign robust safe control algorithms for systems with uncertain dynamic\nmodels. The major challenge is that uncertainty results in difficulty in\nfinding a feasible safe control in real-time. Existing methods usually simplify\nthe problem such as restricting uncertainty type, ignoring control limits, or\nforgoing feasibility guarantees. In this work, we overcome these issues by\nproposing a robust safe control framework for bounded state-dependent\nuncertainties. We first guarantee the feasibility of safe control for uncertain\ndynamics by learning a control-limits-aware, uncertainty-robust safety index.\nThen we show that robust safe control can be formulated as convex problems\n(Convex Semi-Infinite Programming or Second-Order Cone Programming) and propose\ncorresponding optimal solvers that can run in real-time. In addition, we\nanalyze when and how safety can be preserved under unmodeled uncertainties.\nExperiment results show that our method successfully finds robust safe control\nin real-time for different uncertainties and is much less conservative than a\nstrong baseline algorithm.",
    "descriptor": "",
    "authors": [
      "Tianhao Wei",
      "Shucheng Kang",
      "Weiye Zhao",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06896"
  },
  {
    "id": "arXiv:2209.06899",
    "title": "Out of One, Many: Using Language Models to Simulate Human Samples",
    "abstract": "We propose and explore the possibility that language models can be studied as\neffective proxies for specific human sub-populations in social science\nresearch. Practical and research applications of artificial intelligence tools\nhave sometimes been limited by problematic biases (such as racism or sexism),\nwhich are often treated as uniform properties of the models. We show that the\n\"algorithmic bias\" within one such tool -- the GPT-3 language model -- is\ninstead both fine-grained and demographically correlated, meaning that proper\nconditioning will cause it to accurately emulate response distributions from a\nwide variety of human subgroups. We term this property \"algorithmic fidelity\"\nand explore its extent in GPT-3. We create \"silicon samples\" by conditioning\nthe model on thousands of socio-demographic backstories from real human\nparticipants in multiple large surveys conducted in the United States. We then\ncompare the silicon and human samples to demonstrate that the information\ncontained in GPT-3 goes far beyond surface similarity. It is nuanced,\nmultifaceted, and reflects the complex interplay between ideas, attitudes, and\nsocio-cultural context that characterize human attitudes. We suggest that\nlanguage models with sufficient algorithmic fidelity thus constitute a novel\nand powerful tool to advance understanding of humans and society across a\nvariety of disciplines.",
    "descriptor": "",
    "authors": [
      "Lisa P. Argyle",
      "Ethan C. Busby",
      "Nancy Fulda",
      "Joshua Gubler",
      "Christopher Rytting",
      "David Wingate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06899"
  },
  {
    "id": "arXiv:2209.06904",
    "title": "Forecasting Evolution of Clusters in StarCraft II with Hebbian Learning",
    "abstract": "Tactics in StarCraft II are closely related to group behavior of the game\nagents. In other words, human players in the game often group spatially near\nagents into a team and control the team to defeat opponents. In this light,\nclustering the agents in StarCraft II has been studied for various purposes\nsuch as the efficient control of the agents in multi-agent reinforcement\nlearning and game analytic tools for the game users. However, these works do\nnot aim to learn and predict dynamics of the clusters, limiting the\napplications to currently observed game status. In this paper, we present a\nhybrid AI model that couples unsupervised and self-supervised learning to\nforecast evolution of the clusters in StarCraft II. We develop an unsupervised\nHebbian learning method in a set-to-cluster module to efficiently create a\nvariable number of the clusters, and it also features lower inference time\ncomplexity than conventional k-means clustering. For the prediction task, a\nlong short-term memory based prediction module is designed to recursively\nforecast state vectors generated by the set-to-cluster module. We observe the\nproposed model successfully predicts complex evolution of the clusters with\nregard to cluster centroids and their radii.",
    "descriptor": "\nComments: 7 pages, 9 figures, submitted to IEEE Transactions on Artificial Intelligence\n",
    "authors": [
      "Beomseok Kang",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06904"
  },
  {
    "id": "arXiv:2209.06905",
    "title": "Graph Neural Network Based Node Deployment for Throughput Enhancement",
    "abstract": "The recent rapid growth in mobile data traffic entails a pressing demand for\nimproving the throughput of the underlying wireless communication networks.\nNetwork node deployment has been considered as an effective approach for\nthroughput enhancement which, however, often leads to highly non-trivial\nnon-convex optimizations. Although convex approximation based solutions are\nconsidered in the literature, their approximation to the actual throughput may\nbe loose and sometimes lead to unsatisfactory performance. With this\nconsideration, in this paper, we propose a novel graph neural network (GNN)\nmethod for the network node deployment problem. Specifically, we fit a GNN to\nthe network throughput and use the gradients of this GNN to iteratively update\nthe locations of the network nodes. Besides, we show that an expressive GNN has\nthe capacity to approximate both the function value and the gradients of a\nmultivariate permutation-invariant function, as a theoretic support to the\nproposed method. To further improve the throughput, we also study a hybrid node\ndeployment method based on this approach. To train the desired GNN, we adopt a\npolicy gradient algorithm to create datasets containing good training samples.\nNumerical experiments show that the proposed methods produce competitive\nresults compared to the baselines.",
    "descriptor": "",
    "authors": [
      "Yifei Yang",
      "Dongmian Zou",
      "Xiaofan He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06905"
  },
  {
    "id": "arXiv:2209.06909",
    "title": "Multiway Powersort",
    "abstract": "Powersort (Munro & Wild, ESA2018) has recently replaced Timsort's suboptimal\nmerge policy in the CPython reference implementation of Python, as well as in\nPyPy and further libraries. We present a stable mergesort variant, Multiway\nPowersort, that exploits existing runs and finds nearly-optimal merging orders\nfor k-way merges with negligible overhead. As observed with Multiway Quicksort\n(Kushagra et al., ALENEX 2014; Aum\\\"uller & Dietzfelbinger, TALG 2016; Wild,\nPhD thesis 2016) and the inclusion of Dual-Pivot Quicksort in the Java runtime\nlibrary, memory transfers increasingly determine the cost of internal sorting.\nWe demonstrate that our 4-way Powersort implementation can achieve substantial\nspeedups over standard (2-way) Powersort and other stable sorting methods\nwithout compromising the optimally run-adaptive performance of Powersort.",
    "descriptor": "\nComments: 16 pages; accompanying source code at this https URL\n",
    "authors": [
      "William Cawley Gelling",
      "Markus E. Nebel",
      "Benjamin Smith",
      "Sebastian Wild"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.06909"
  },
  {
    "id": "arXiv:2209.06915",
    "title": "Predictive Closed-Loop Remote Control over Wireless Two-Way Split  Koopman Autoencoder",
    "abstract": "Real-time remote control over wireless is an important-yet-challenging\napplication in 5G and beyond due to its mission-critical nature under limited\ncommunication resources. Current solutions hinge on not only utilizing\nultra-reliable and low-latency communication (URLLC) links but also predicting\nfuture states, which may consume enormous communication resources and struggle\nwith a short prediction time horizon. To fill this void, in this article we\npropose a novel two-way Koopman autoencoder (AE) approach wherein: 1) a sensing\nKoopman AE learns to understand the temporal state dynamics and predicts\nmissing packets from a sensor to its remote controller; and 2) a controlling\nKoopman AE learns to understand the temporal action dynamics and predicts\nmissing packets from the controller to an actuator co-located with the sensor.\nSpecifically, each Koopman AE aims to learn the Koopman operator in the hidden\nlayers while the encoder of the AE aims to project the non-linear dynamics onto\na lifted subspace, which is reverted into the original non-linear dynamics by\nthe decoder of the AE. The Koopman operator describes the linearized temporal\ndynamics, enabling long-term future prediction and coping with missing packets\nand closed-form optimal control in the lifted subspace. Simulation results\ncorroborate that the proposed approach achieves a 38x lower mean squared\ncontrol error at 0 dBm signal-to-noise ratio (SNR) than the non-predictive\nbaseline.",
    "descriptor": "",
    "authors": [
      "Abanoub M.Girgis",
      "Hyowoon Seo",
      "Jihong Park",
      "Mehdi Bennis",
      "Jinho Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.06915"
  },
  {
    "id": "arXiv:2209.06916",
    "title": "Efficient multigrid reduction-in-time for method-of-lines  discretizations of linear advection",
    "abstract": "Parallel-in-time methods for partial differential equations (PDEs) have been\nthe subject of intense development over recent decades, particularly for\ndiffusion-dominated problems. It has been widely reported in the literature,\nhowever, that many of these methods perform quite poorly for\nadvection-dominated problems. Here we analyze the particular iterative\nparallel-in-time algorithm of multigrid reduction-in-time (MGRIT) for\ndiscretizations of constant-wave-speed linear advection problems. We focus on\ncommon method-of-lines discretizations that employ upwind finite differences in\nspace and Runge-Kutta methods in time. Using a convergence framework we\ndeveloped in previous work, we prove for a subclass of these discretizations\nthat, if using the standard approach of rediscretizing the fine-grid problem on\nthe coarse grid, robust MGRIT convergence with respect to CFL number and\ncoarsening factor is not possible. This poor convergence and non-robustness is\ncaused, at least in part, by an inadequate coarse-grid correction for smooth\nFourier modes known as characteristic components.We propose an alternative\ncoarse-grid that provides a better correction of these modes. This coarse-grid\noperator is related to previous work and uses a semi-Lagrangian discretization\ncombined with an implicitly treated truncation error correction. Theory and\nnumerical experiments show the coarse-grid operator yields fast MGRIT\nconvergence for many of the method-of-lines discretizations considered,\nincluding for both implicit and explicit discretizations of high order.",
    "descriptor": "",
    "authors": [
      "H. De Sterck",
      "R. D. Falgout",
      "O. A. Krzysik",
      "J. B. Schroder"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06916"
  },
  {
    "id": "arXiv:2209.06918",
    "title": "NanoFlowNet: Real-time Dense Optical Flow on a Nano Quadcopter",
    "abstract": "Nano quadcopters are small, agile, and cheap platforms that are well suited\nfor deployment in narrow, cluttered environments. Due to their limited payload,\nthese vehicles are highly constrained in processing power, rendering\nconventional vision-based methods for safe and autonomous navigation\nincompatible. Recent machine learning developments promise high-performance\nperception at low latency, while dedicated edge computing hardware has the\npotential to augment the processing capabilities of these limited devices. In\nthis work, we present NanoFlowNet, a lightweight convolutional neural network\nfor real-time dense optical flow estimation on edge computing hardware. We draw\ninspiration from recent advances in semantic segmentation for the design of\nthis network. Additionally, we guide the learning of optical flow using motion\nboundary ground truth data, which improves performance with no impact on\nlatency. Validation results on the MPI-Sintel dataset show the high performance\nof the proposed network given its constrained architecture. Additionally, we\nsuccessfully demonstrate the capabilities of NanoFlowNet by deploying it on the\nultra-low power GAP8 microprocessor and by applying it to vision-based obstacle\navoidance on board a Bitcraze Crazyflie, a 34 g nano quadcopter.",
    "descriptor": "\nComments: 8 pages, 9 figures, 4 tables\n",
    "authors": [
      "Rik J. Bouwmeester",
      "Federico Paredes-Vall\u00e9s",
      "Guido C. H. E. de Croon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06918"
  },
  {
    "id": "arXiv:2209.06922",
    "title": "Unprojected recycled block Krylov subspace methods for shifted systems",
    "abstract": "The use of block Krylov subspace methods for computing the solution to a\nsequence of shifted linear systems using subspace recycling was first proposed\nin [Soodhalter, SISC 2016], where a recycled shifted block GMRES algorithm\n(rsbGMRES) was proposed. Such methods use the equivalence of the shifted system\nto a Sylvester equation and exploit the shift invariance of the block Krylov\nsubspace generated from the Sylvester operator. This avoids the need for\ninitial residuals to span the same subspace and allows for a viable restarted\nKrylov subspace method with recycling for solving sequences of shifted systems.\nIn this paper we propose to develop these types of methods using unprojected\nKrylov subspaces. In doing so we show how one can overcome the difficulties\nassociated with developing methods based on projected Krylov subspaces such as\nrsbGMRES, while also allowing for practical methods to fit within a well known\nresidual projection framework. In addition, unprojected methods are known to be\nadvantageous when the projector is expensive to apply, making them of\nsignificant interest for High-Performance Computing applications. We develop an\nunprojected rsbFOM and unprojected rsbGMRES. We also develop a procedure for\nextracting shift dependent harmonic Ritz vectors over an augmented block Krylov\nsubspace for shifted systems yielding an approach for selecting a new recycling\nsubspace after each cycle of the algorithm. Numerical experiments demonstrate\nthe effectiveness of our methods.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Liam Burke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06922"
  },
  {
    "id": "arXiv:2209.06923",
    "title": "Prompt-based Conservation Learning for Multi-hop Question Answering",
    "abstract": "Multi-hop question answering (QA) requires reasoning over multiple documents\nto answer a complex question and provide interpretable supporting evidence.\nHowever, providing supporting evidence is not enough to demonstrate that a\nmodel has performed the desired reasoning to reach the correct answer. Most\nexisting multi-hop QA methods fail to answer a large fraction of sub-questions,\neven if their parent questions are answered correctly. In this paper, we\npropose the Prompt-based Conservation Learning (PCL) framework for multi-hop\nQA, which acquires new knowledge from multi-hop QA tasks while conserving old\nknowledge learned on single-hop QA tasks, mitigating forgetting. Specifically,\nwe first train a model on existing single-hop QA tasks, and then freeze this\nmodel and expand it by allocating additional sub-networks for the multi-hop QA\ntask. Moreover, to condition pre-trained language models to stimulate the kind\nof reasoning required for specific multi-hop questions, we learn soft prompts\nfor the novel sub-networks to perform type-specific reasoning. Experimental\nresults on the HotpotQA benchmark show that PCL is competitive for multi-hop QA\nand retains good performance on the corresponding single-hop sub-questions,\ndemonstrating the efficacy of PCL in mitigating knowledge loss by forgetting.",
    "descriptor": "\nComments: Accepted to COLING 2022\n",
    "authors": [
      "Zhenyun Deng",
      "Yonghua Zhu",
      "Yang Chen",
      "Qianqian Qi",
      "Michael Witbrock",
      "Patricia Riddle"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06923"
  },
  {
    "id": "arXiv:2209.06926",
    "title": "End-to-End Multi-View Structure-from-Motion with Hypercorrelation  Volumes",
    "abstract": "Image-based 3D reconstruction is one of the most important tasks in Computer\nVision with many solutions proposed over the last few decades. The objective is\nto extract metric information i.e. the geometry of scene objects directly from\nimages. These can then be used in a wide range of applications such as film,\ngames, virtual reality, etc. Recently, deep learning techniques have been\nproposed to tackle this problem. They rely on training on vast amounts of data\nto learn to associate features between images through deep convolutional neural\nnetworks and have been shown to outperform traditional procedural techniques.\nIn this paper, we improve on the state-of-the-art two-view\nstructure-from-motion(SfM) approach of [11] by incorporating 4D correlation\nvolume for more accurate feature matching and reconstruction. Furthermore, we\nextend it to the general multi-view case and evaluate it on the complex\nbenchmark dataset DTU [4]. Quantitative evaluations and comparisons with\nstate-of-the-art multi-view 3D reconstruction methods demonstrate its\nsuperiority in terms of the accuracy of reconstructions.",
    "descriptor": "\nComments: IEEE International Conference on Signal Processing, Sensors, and Intelligent Systems (SPSIS 2022)\n",
    "authors": [
      "Qiao Chen",
      "Charalambos Poullis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06926"
  },
  {
    "id": "arXiv:2209.06927",
    "title": "Optimization of Rocker-Bogie Mechanism using Heuristic Approaches",
    "abstract": "Optimal locomotion and efficient traversal of extraterrestrial rovers in\ndynamic terrains and environments is an important problem statement in the\nfield of planetary science and geophysical systems. Designing a superlative and\nefficient architecture for the suspension mechanism of planetary rovers is a\ncrucial step towards robust rovers. This paper focuses on the Rocker Bogie\nmechanism, a standard suspension methodology associated with foreign terrains.\nAfter scrutinizing the available previous literature and by leveraging various\noptimization and global minimization algorithms, this paper offers a novel\nstudy on mechanical design optimization of a rovers suspension mechanism. This\npaper presents extensive tests on Simulated Annealing, Genetic Algorithms,\nSwarm Intelligence techniques, Basin Hoping and Differential Evolution, while\nthoroughly assessing every related hyper parameter, to find utility driven\nsolutions. We also assess Dual Annealing and subsidiary algorithms for the\naforementioned task while maintaining an unbiased testing standpoint for\nethical research. Computational efficiency and overall fitness are considered\nkey valedictory parameters for assessing the related algorithms, emphasis is\nalso given to variable input seeds to find the most suitable utility driven\nstrategy. Simulated Annealing was obtained empirically to be the top performing\nheuristic strategy, with a fitness of 760, which was considerably superior to\nother algorithms and provided consistent performance across various input seeds\nand individual performance indicators.",
    "descriptor": "\nComments: 17 Pages, 18 Figures\n",
    "authors": [
      "Harsh Senjaliya",
      "Pranshav Gajjar",
      "Brijan Vaghasiya",
      "Pooja Shah",
      "Paresh Gujarati"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.06927"
  },
  {
    "id": "arXiv:2209.06928",
    "title": "Limit Cycles of AdaBoost",
    "abstract": "The iterative weight update for the AdaBoost machine learning algorithm may\nbe realized as a dynamical map on a probability simplex. When learning a\nlow-dimensional data set this algorithm has a tendency towards cycling\nbehavior, which is the topic of this paper. AdaBoost's cycling behavior lends\nitself to direct computational methods that are ineffective in the general,\nnon-cycling case of the algorithm. From these computational properties we give\na concrete correspondence between AdaBoost's cycling behavior and continued\nfractions dynamics. Then we explore the results of this correspondence to\nexpound on how the algorithm comes to be in this periodic state at all. What we\nintend for this work is to be a novel and self-contained explanation for the\ncycling dynamics of this machine learning algorithm.",
    "descriptor": "",
    "authors": [
      "Conor Snedeker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06928"
  },
  {
    "id": "arXiv:2209.06931",
    "title": "Robust Transferable Feature Extractors: Learning to Defend Pre-Trained  Networks Against White Box Adversaries",
    "abstract": "The widespread adoption of deep neural networks in computer vision\napplications has brought forth a significant interest in adversarial\nrobustness. Existing research has shown that maliciously perturbed inputs\nspecifically tailored for a given model (i.e., adversarial examples) can be\nsuccessfully transferred to another independently trained model to induce\nprediction errors. Moreover, this property of adversarial examples has been\nattributed to features derived from predictive patterns in the data\ndistribution. Thus, we are motivated to investigate the following question: Can\nadversarial defenses, like adversarial examples, be successfully transferred to\nother independently trained models? To this end, we propose a deep\nlearning-based pre-processing mechanism, which we refer to as a robust\ntransferable feature extractor (RTFE). After examining theoretical motivation\nand implications, we experimentally show that our method can provide\nadversarial robustness to multiple independently pre-trained classifiers that\nare otherwise ineffective against an adaptive white box adversary. Furthermore,\nwe show that RTFEs can even provide one-shot adversarial robustness to models\nindependently trained on different datasets.",
    "descriptor": "",
    "authors": [
      "Alexander Cann",
      "Ian Colbert",
      "Ihab Amer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06931"
  },
  {
    "id": "arXiv:2209.06932",
    "title": "Optimal Connectivity through Network Gradients for the Restricted  Boltzmann Machine",
    "abstract": "Leveraging sparse networks to connect successive layers in deep neural\nnetworks has recently been shown to provide benefits to large scale\nstate-of-the-art models. However, network connectivity also plays a significant\nrole on the learning curves of shallow networks, such as the classic Restricted\nBoltzmann Machines (RBM). A fundamental problem is efficiently finding\nconnectivity patterns that improve the learning curve. Recent principled\napproaches explicitly include network connections as parameters that must be\noptimized in the model, but often rely on continuous functions to represent\nconnections and on explicit penalization. This work presents a method to find\noptimal connectivity patterns for RBMs based on the idea of network gradients:\ncomputing the gradient of every possible connection, given a specific\nconnection pattern, and using the gradient to drive a continuous connection\nstrength parameter that in turn is used to determine the connection pattern.\nThus, learning RBM parameters and learning network connections is truly jointly\nperformed, albeit with different learning rates, and without changes to the\nobjective function. The method is applied to the MNIST data set showing that\nbetter RBM models are found for the benchmark tasks of sample generation and\ninput classification.",
    "descriptor": "",
    "authors": [
      "A. C. N. de Oliveira",
      "D. R. Figueiredo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06932"
  },
  {
    "id": "arXiv:2209.06936",
    "title": "Uncertainty-Aware Visual Perception for Safe Motion Planning",
    "abstract": "For safe operation, a robot must be able to avoid collisions in uncertain\nenvironments. Existing approaches for motion planning with uncertainties often\nmake conservative assumptions about Gaussianity and the obstacle geometry.\nWhile visual perception can deliver a more accurate representation of the\nenvironment, its use for safe motion planning is limited by the inherent\nmiscalibration of neural networks and the challenge of obtaining adequate\ndatasets. In order to address these imitations, we propose to employ ensembles\nof deep semantic segmentation networks trained with systematically augmented\ndatasets to ensure reliable probabilistic occupancy information. For avoiding\nconservatism during motion planning, we directly employ the probabilistic\nperception via a scenario-based path planning approach. A velocity scheduling\nscheme is applied to the path to ensure a safe motion despite tracking\ninaccuracies. We demonstrate the effectiveness of the systematic data\naugmentation in combination with deep ensembles and the proposed scenario-based\nplanning approach in comparisons to state-of-the-art methods and validate our\nframework in an experiment involving a human hand.",
    "descriptor": "",
    "authors": [
      "Ralf R\u00f6mer",
      "Armin Lederer",
      "Samuel Tesfazgi",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06936"
  },
  {
    "id": "arXiv:2209.06939",
    "title": "The Complexity Classes of Hamming Distance Recoverable Robust Problems",
    "abstract": "In the well-known complexity class NP, many combinatorial problems can be\nfound, whose optimization counterpart are important for many practical\nsettings. Those problems usually consider full knowledge about the input and\noptimize on this specific input. In a practical setting, however, uncertainty\nin the input data is a usual phenomenon, whereby this is normally not covered\nin optimization versions of NP problems. One concept to model the uncertainty\nin the input data, is \\textit{recoverable robustness}. In this setting, a\nsolution on the input is calculated, whereby a possible recovery to a good\nsolution should be guaranteed, whenever uncertainty manifests itself. That is,\na solution $\\texttt{s}_0$ for the base scenario $\\textsf{S}_0$ as well as a\nsolution \\texttt{s} for every possible scenario of scenario set \\textsf{S} has\nto be calculated. In other words, not only solution $\\texttt{s}_0$ for instance\n$\\textsf{S}_0$ is calculated but solutions \\texttt{s} for all scenarios from\n\\textsf{S} are prepared to correct possible errors through uncertainty. This\npaper introduces a specific concept of recoverable robust problems: Hamming\nDistance Recoverable Robust Problems. In this setting, solutions $\\texttt{s}_0$\nand \\texttt{s} have to be calculated, such that $\\texttt{s}_0$ and \\texttt{s}\nmay only differ in at most $\\kappa$ elements. That is, one can recover from a\nharmful scenario by choosing a different solution, which is not too far away\nfrom the first solution. This paper surveys the complexity of Hamming distance\nrecoverable robust version of optimization problems, typically found in NP for\ndifferent types of scenarios. The complexity is primarily situated in the lower\nlevels of the polynomial hierarchy. The main contribution of the paper is that\nrecoverable robust problems with compression-encoded scenarios and $m \\in\n\\mathbb{N}$ recoveries are $\\Sigma^P_{2m+1}$-complete.",
    "descriptor": "",
    "authors": [
      "Christoph Gr\u00fcne"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.06939"
  },
  {
    "id": "arXiv:2209.06940",
    "title": "TEAM: a parameter-free algorithm to teach collaborative robots motions  from user demonstrations",
    "abstract": "Collaborative robots (cobots) built to work alongside humans must be able to\nquickly learn new skills and adapt to new task configurations. Learning from\ndemonstration (LfD) enables cobots to learn and adapt motions to different use\nconditions. However, state-of-the-art LfD methods require manually tuning\nintrinsic parameters and have rarely been used in industrial contexts without\nexperts.\nIn this paper, the development and implementation of a LfD framework for\nindustrial applications with naive users is presented. We propose a\nparameter-free method based on probabilistic movement primitives, where all the\nparameters are pre-determined using Jensen-Shannon divergence and bayesian\noptimization; thus, users do not have to perform manual parameter tuning. This\nmethod learns motions from a small dataset of user demonstrations, and\ngeneralizes the motion to various scenarios and conditions.\nWe evaluate the method extensively in two field tests: one where the cobot\nworks on elevator door maintenance, and one where three Schindler workers teach\nthe cobot tasks useful for their workflow. Errors between the cobot\nend-effector and target positions range from $0$ to $1.48\\pm0.35$mm. For all\ntests, no task failures were reported. Questionnaires completed by the\nSchindler workers highlighted the method's ease of use, feeling of safety, and\nthe accuracy of the reproduced motion.\nOur code and recorded trajectories are made available online for\nreproduction.",
    "descriptor": "\nComments: 7 pages, 6 figures, submitted to ICRA 2023\n",
    "authors": [
      "Lorenzo Panchetti",
      "Jianhao Zheng",
      "Mohamed Bouri",
      "Malcolm Mielle"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06940"
  },
  {
    "id": "arXiv:2209.06941",
    "title": "Joint Debiased Representation and Image Clustering Learning with  Self-Supervision",
    "abstract": "Contrastive learning is among the most successful methods for visual\nrepresentation learning, and its performance can be further improved by jointly\nperforming clustering on the learned representations. However, existing methods\nfor joint clustering and contrastive learning do not perform well on\nlong-tailed data distributions, as majority classes overwhelm and distort the\nloss of minority classes, thus preventing meaningful representations to be\nlearned. Motivated by this, we develop a novel joint clustering and contrastive\nlearning framework by adapting the debiased contrastive loss to avoid\nunder-clustering minority classes of imbalanced datasets. We show that our\nproposed modified debiased contrastive loss and divergence clustering loss\nimproves the performance across multiple datasets and learning tasks. The\nsource code is available at\nhttps://anonymous.4open.science/r/SSL-debiased-clustering",
    "descriptor": "",
    "authors": [
      "Shunjie-Fabian Zheng",
      "JaeEun Nam",
      "Emilio Dorigatti",
      "Bernd Bischl",
      "Shekoofeh Azizi",
      "Mina Rezaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06941"
  },
  {
    "id": "arXiv:2209.06946",
    "title": "Robust Product Classification with Instance-Dependent Noise",
    "abstract": "Noisy labels in large E-commerce product data (i.e., product items are placed\ninto incorrect categories) are a critical issue for product categorization task\nbecause they are unavoidable, non-trivial to remove and degrade prediction\nperformance significantly. Training a product title classification model which\nis robust to noisy labels in the data is very important to make product\nclassification applications more practical. In this paper, we study the impact\nof instance-dependent noise to performance of product title classification by\ncomparing our data denoising algorithm and different noise-resistance training\nalgorithms which were designed to prevent a classifier model from over-fitting\nto noise. We develop a simple yet effective Deep Neural Network for product\ntitle classification to use as a base classifier. Along with recent methods of\nstimulating instance-dependent noise, we propose a novel noise stimulation\nalgorithm based on product title similarity. Our experiments cover multiple\ndatasets, various noise methods and different training solutions. Results\nuncover the limit of classification task when noise rate is not negligible and\ndata distribution is highly skewed.",
    "descriptor": "",
    "authors": [
      "Huy Nguyen",
      "Devashish Khatwani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06946"
  },
  {
    "id": "arXiv:2209.06947",
    "title": "Use case-focused metrics to evaluate machine learning for diseases  involving parasite loads",
    "abstract": "Communal hill-climbing, via comparison of algorithm performances, can greatly\naccelerate ML research. However, it requires task-relevant metrics. For\ndiseases involving parasite loads, e.g., malaria and neglected tropical\ndiseases (NTDs) such as schistosomiasis, the metrics currently reported in ML\npapers (e.g., AUC, F1 score) are ill-suited to the clinical task. As a result,\nthe hill-climbing system is not enabling progress towards solutions that\naddress these dire illnesses. Drawing on examples from malaria and NTDs, this\npaper highlights two gaps in current ML practice and proposes methods for\nimprovement: (i) We describe aspects of ML development, and performance metrics\nin particular, that need to be firmly grounded in the clinical use case, and we\noffer methods for acquiring this domain knowledge. (ii) We describe in detail\nperformance metrics to guide development of ML models for diseases involving\nparasite loads. We highlight the importance of a patient-level perspective,\ninterpatient variability, false positive rates, limit of detection, and\ndifferent types of error. We also discuss problems with ROC curves and AUC as\ncommonly used in this context.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Charles B. Delahunt",
      "Noni Gachuhi",
      "Matthew P. Horning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06947"
  },
  {
    "id": "arXiv:2209.06952",
    "title": "Landmark Tracking in Liver US images Using Cascade Convolutional Neural  Networks with Long Short-Term Memory",
    "abstract": "This study proposed a deep learning-based tracking method for ultrasound (US)\nimage-guided radiation therapy. The proposed cascade deep learning model is\ncomposed of an attention network, a mask region-based convolutional neural\nnetwork (mask R-CNN), and a long short-term memory (LSTM) network. The\nattention network learns a mapping from a US image to a suspected area of\nlandmark motion in order to reduce the search region. The mask R-CNN then\nproduces multiple region-of-interest (ROI) proposals in the reduced region and\nidentifies the proposed landmark via three network heads: bounding box\nregression, proposal classification, and landmark segmentation. The LSTM\nnetwork models the temporal relationship among the successive image frames for\nbounding box regression and proposal classification. To consolidate the final\nproposal, a selection method is designed according to the similarities between\nsequential frames. The proposed method was tested on the liver US tracking\ndatasets used in the Medical Image Computing and Computer Assisted\nInterventions (MICCAI) 2015 challenges, where the landmarks were annotated by\nthree experienced observers to obtain their mean positions. Five-fold\ncross-validation on the 24 given US sequences with ground truths shows that the\nmean tracking error for all landmarks is 0.65+/-0.56 mm, and the errors of all\nlandmarks are within 2 mm. We further tested the proposed model on 69 landmarks\nfrom the testing dataset that has a similar image pattern to the training\npattern, resulting in a mean tracking error of 0.94+/-0.83 mm. Our experimental\nresults have demonstrated the feasibility and accuracy of our proposed method\nin tracking liver anatomic landmarks using US images, providing a potential\nsolution for real-time liver tracking for active motion management during\nradiation therapy.",
    "descriptor": "",
    "authors": [
      "Yupei Zhang",
      "Xianjin Dai",
      "Zhen Tian",
      "Yang Lei",
      "Jacob F. Wynne",
      "Pretesh Patel",
      "Yue Chen",
      "Tian Liu",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.06952"
  },
  {
    "id": "arXiv:2209.06953",
    "title": "On the interplay of adversarial robustness and architecture components:  patches, convolution and attention",
    "abstract": "In recent years novel architecture components for image classification have\nbeen developed, starting with attention and patches used in transformers. While\nprior works have analyzed the influence of some aspects of architecture\ncomponents on the robustness to adversarial attacks, in particular for vision\ntransformers, the understanding of the main factors is still limited. We\ncompare several (non)-robust classifiers with different architectures and study\ntheir properties, including the effect of adversarial training on the\ninterpretability of the learnt features and robustness to unseen threat models.\nAn ablation from ResNet to ConvNeXt reveals key architectural changes leading\nto almost $10\\%$ higher $\\ell_\\infty$-robustness.",
    "descriptor": "\nComments: Presented at the \"New Frontiers in Adversarial Machine Learning\" Workshop at ICML 2022\n",
    "authors": [
      "Francesco Croce",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06953"
  },
  {
    "id": "arXiv:2209.06954",
    "title": "Finetuning Pretrained Vision-Language Models with Correlation  Information Bottleneck for Robust Visual Question Answering",
    "abstract": "Benefiting from large-scale Pretrained Vision-Language Models (VL-PMs), the\nperformance of Visual Question Answering (VQA) has started to approach human\noracle performance. However, finetuning large-scale VL-PMs with limited data\nfor VQA usually faces overfitting and poor generalization issues, leading to a\nlack of robustness. In this paper, we aim to improve the robustness of VQA\nsystems (ie, the ability of the systems to defend against input variations and\nhuman-adversarial attacks) from the perspective of Information Bottleneck when\nfinetuning VL-PMs for VQA. Generally, internal representations obtained by\nVL-PMs inevitably contain irrelevant and redundant information for the\ndownstream VQA task, resulting in statistically spurious correlations and\ninsensitivity to input variations. To encourage representations to converge to\na minimal sufficient statistic in vision-language learning, we propose the\nCorrelation Information Bottleneck (CIB) principle, which seeks a tradeoff\nbetween representation compression and redundancy by minimizing the mutual\ninformation (MI) between the inputs and internal representations while\nmaximizing the MI between the outputs and the representations. Meanwhile, CIB\nmeasures the internal correlations among visual and linguistic inputs and\nrepresentations by a symmetrized joint MI estimation. Extensive experiments on\nfive VQA benchmarks of input robustness and two VQA benchmarks of\nhuman-adversarial robustness demonstrate the effectiveness and superiority of\nthe proposed CIB in improving the robustness of VQA systems.",
    "descriptor": "\nComments: 20 pages, 4 figures, 13 tables\n",
    "authors": [
      "Jingjing Jiang",
      "Ziyi Liu",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06954"
  },
  {
    "id": "arXiv:2209.06955",
    "title": "Adversarial Correctness and Privacy for Probabilistic Data Structures",
    "abstract": "We study the security of Probabilistic Data Structures (PDS) for handling\nApproximate Membership Queries (AMQ); prominent examples of AMQ-PDS are Bloom\nand Cuckoo filters. AMQ-PDS are increasingly being deployed in environments\nwhere adversaries can gain benefit from carefully selecting inputs, for example\nto increase the false positive rate of an AMQ-PDS. They are also being used in\nsettings where the inputs are sensitive and should remain private in the face\nof adversaries who can access an AMQ-PDS through an API or who can learn its\ninternal state by compromising the system running the AMQ-PDS.\nWe develop simulation-based security definitions that speak to correctness\nand privacy of AMQ-PDS. Our definitions are general and apply to a broad range\nof adversarial settings. We use our definitions to analyse the behaviour of\nboth Bloom filters and insertion-only Cuckoo filters. We show that these\nAMQ-PDS can be provably protected through replacement or composition of hash\nfunctions with keyed pseudorandom functions in their construction. We also\nexamine the practical impact on storage size and computation of providing\nsecure instances of Bloom and insertion-only Cuckoo filters.",
    "descriptor": "\nComments: The full version of the paper accepted at ACM CCS '22. The latest version is available at this https URL\n",
    "authors": [
      "Mia Fili\u0107",
      "Kenneth G. Paterson",
      "Anupama Unnikrishnan",
      "Fernando Virdia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.06955"
  },
  {
    "id": "arXiv:2209.06956",
    "title": "Design and Analysis of Polar Codes Based on Piecewise Gaussian  Approximation",
    "abstract": "In this article, we propose the construction of polar codes based on\npiecewise Gaussian approximation (PGA) techniques. The PGA is first optimized\nand then compared to the Gaussian approximation (GA) construction method,\nshowing performance gains for medium blocks and high precision for long blocks,\nin scenarios with successive cancellation (SC) decoding and additive white\ngaussian noise (AWGN) channel. Based on the PGA, we develop two approximations\nbased on multi-segmented polynomials that are easy to implement. We present the\nApproximate PGA (APGA) that is optimized for medium blocks and provides a\nperformance improvement without increasing complexity. Furthermore, we develop\nthe simplified PGA (SPGA) as an alternative to the GA, which is optimized for\nlong blocks and achieves high construction accuracy. Simulation results show\nthat the APGA and SPGA construction methods outperform existing GA and\ncompeting approaches for medium and long block codes with notable performance\nimprovement.",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "R. M. Oliveira",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.06956"
  },
  {
    "id": "arXiv:2209.06957",
    "title": "Reduced models with nonlinear approximations of latent dynamics for  model premixed flame problems",
    "abstract": "Efficiently reducing models of chemically reacting flows is often challenging\nbecause their characteristic features such as sharp gradients in the flow\nfields and couplings over various time and length scales lead to dynamics that\nevolve in high-dimensional spaces. In this work, we show that online adaptive\nreduced models that construct nonlinear approximations by adapting\nlow-dimensional subspaces over time can predict well latent dynamics with\nproperties similar to those found in chemically reacting flows. The adaptation\nof the subspaces is driven by the online adaptive empirical interpolation\nmethod, which takes sparse residual evaluations of the full model to compute\nlow-rank basis updates of the subspaces. Numerical experiments with a premixed\nflame model problem show that reduced models based on online adaptive empirical\ninterpolation accurately predict flame dynamics far outside of the training\nregime and in regimes where traditional static reduced models, which keep\nreduced spaces fixed over time and so provide only linear approximations of\nlatent dynamics, fail to make meaningful predictions.",
    "descriptor": "",
    "authors": [
      "Wayne Isaac Tan Uy",
      "Christopher R. Wentland",
      "Cheng Huang",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06957"
  },
  {
    "id": "arXiv:2209.06964",
    "title": "Bipedal Robot Walking Control Using Human Whole-Body Dynamic  Telelocomotion",
    "abstract": "For humanoids to be deployed in demanding situations, such as search and\nrescue, highly intelligent decision making and proficient sensorimotor skill is\nexpected. A promising solution is to leverage human prowess by interconnecting\nrobot and human via teleoperation. Towards creating seamless operation, this\npaper presents a dynamic telelocomotion framework that synchronizes the gait of\na human pilot with the walking of a bipedal robot. First, we introduce a method\nto generate a virtual human walking model from the stepping behavior of a human\npilot which serves as a reference for the robot to walk. Second, the dynamics\nof the walking reference and robot walking are synchronized by applying forces\nto the human pilot and the robot to achieve dynamic similarity between the two\nsystems. This enables the human pilot to continuously perceive and cancel any\nasynchrony between the walking reference and robot. A consistent step placement\nstrategy for the robot is derived to maintain dynamic similarity through step\ntransitions. Using our human-machine-interface, we demonstrate that the human\npilot can achieve stable and synchronous teleoperation of a simulated robot\nthrough stepping-in-place, walking, and disturbance rejection experiments. This\nwork provides a fundamental step towards transferring human intelligence and\nreflexes to humanoid robots.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Guillermo Colin",
      "Youngwoo Sim",
      "Joao Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06964"
  },
  {
    "id": "arXiv:2209.06967",
    "title": "A novel illumination condition varied image dataset-Food Vision Dataset  (FVD) for fair and reliable consumer acceptability predictions from food",
    "abstract": "Recent advances in artificial intelligence promote a wide range of computer\nvision applications in many different domains. Digital cameras, acting as human\neyes, can perceive fundamental object properties, such as shapes and colors,\nand can be further used for conducting high-level tasks, such as image\nclassification, and object detections. Human perceptions have been widely\nrecognized as the ground truth for training and evaluating computer vision\nmodels. However, in some cases, humans can be deceived by what they have seen.\nWell-functioned human vision relies on stable external lighting while unnatural\nillumination would influence human perception of essential characteristics of\ngoods. To evaluate the illumination effects on human and computer perceptions,\nthe group presents a novel dataset, the Food Vision Dataset (FVD), to create an\nevaluation benchmark to quantify illumination effects, and to push forward\ndevelopments of illumination estimation methods for fair and reliable consumer\nacceptability prediction from food appearances. FVD consists of 675 images\ncaptured under 3 different power and 5 different temperature settings every\nalternate day for five such days.",
    "descriptor": "\nComments: 8 pages, 4 figures, 1 table\n",
    "authors": [
      "Swarna Sethu",
      "Dongyi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06967"
  },
  {
    "id": "arXiv:2209.06968",
    "title": "Stochastic strategies for patrolling a terrain with a synchronized  multi-robot system",
    "abstract": "A group of cooperative aerial robots can be deployed to efficiently patrol a\nterrain, in which each robot flies around an assigned area and shares\ninformation with the neighbors periodically in order to protect or supervise\nit. To ensure robustness, previous works on these synchronized systems propose\nsending a robot to the neighboring area in case it detects a failure. In order\nto deal with unpredictability and to improve on the efficiency in the\ndeterministic patrolling scheme, this paper proposes random strategies to cover\nthe areas distributed among the agents. First, a theoretical study of the\nstochastic process is addressed in this paper for two metrics: the \\emph{idle\ntime}, the expected time between two consecutive observations of any point of\nthe terrain and the \\emph{isolation time}, the expected time that a robot is\nwithout communication with any other robot. After that, the random strategies\nare experimentally compared with the deterministic strategy adding another\nmetric: the \\emph{broadcast time}, the expected time elapsed from the moment a\nrobot emits a message until it is received by all the other robots of the team.\nThe simulations show that theoretical results are in good agreement with the\nsimulations and the random strategies outperform the behavior obtained with the\ndeterministic protocol proposed in the literature.",
    "descriptor": "",
    "authors": [
      "Luis E. Caraballo",
      "Jos\u00e9 M. D\u00edaz-B\u00e1\u00f1ez",
      "Ruy Fabila-Monroy",
      "Carlos Hidalgo-Toscan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2209.06968"
  },
  {
    "id": "arXiv:2209.06970",
    "title": "Generative Visual Prompt: Unifying Distributional Control of Pre-Trained  Generative Models",
    "abstract": "Generative models (e.g., GANs and diffusion models) learn the underlying data\ndistribution in an unsupervised manner. However, many applications of interest\nrequire sampling from a specific region of the generative model's output space\nor evenly over a range of characteristics. To allow efficient sampling in these\nscenarios, we propose Generative Visual Prompt (PromptGen), a framework for\ndistributional control over pre-trained generative models by incorporating\nknowledge of arbitrary off-the-shelf models. PromptGen defines control as an\nenergy-based model (EBM) and samples images in a feed-forward manner by\napproximating the EBM with invertible neural networks, avoiding optimization at\ninference. We demonstrate how PromptGen can control several generative models\n(e.g., StyleGAN2, StyleNeRF, diffusion autoencoder, and NVAE) using various\noff-the-shelf models: (1) with the CLIP model, PromptGen can sample images\nguided by text, (2) with image classifiers, PromptGen can de-bias generative\nmodels across a set of attributes, and (3) with inverse graphics models,\nPromptGen can sample images of the same identity in different poses. (4)\nFinally, PromptGen reveals that the CLIP model shows \"reporting bias\" when used\nas control, and PromptGen can further de-bias this controlled distribution in\nan iterative manner. Our code is available at\nhttps://github.com/ChenWu98/Generative-Visual-Prompt.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Chen Henry Wu",
      "Saman Motamed",
      "Shaunak Srivastava",
      "Fernando De la Torre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06970"
  },
  {
    "id": "arXiv:2209.06971",
    "title": "PointACL:Adversarial Contrastive Learning for Robust Point Clouds  Representation under Adversarial Attack",
    "abstract": "Despite recent success of self-supervised based contrastive learning model\nfor 3D point clouds representation, the adversarial robustness of such\npre-trained models raised concerns. Adversarial contrastive learning (ACL) is\nconsidered an effective way to improve the robustness of pre-trained models. In\ncontrastive learning, the projector is considered an effective component for\nremoving unnecessary feature information during contrastive pretraining and\nmost ACL works also use contrastive loss with projected feature representations\nto generate adversarial examples in pretraining, while \"unprojected \" feature\nrepresentations are used in generating adversarial inputs during\ninference.Because of the distribution gap between projected and \"unprojected\"\nfeatures, their models are constrained of obtaining robust feature\nrepresentations for downstream tasks. We introduce a new method to generate\nhigh-quality 3D adversarial examples for adversarial training by utilizing\nvirtual adversarial loss with \"unprojected\" feature representations in\ncontrastive learning framework. We present our robust aware loss function to\ntrain self-supervised contrastive learning framework adversarially.\nFurthermore, we find selecting high difference points with the Difference of\nNormal (DoN) operator as additional input for adversarial self-supervised\ncontrastive learning can significantly improve the adversarial robustness of\nthe pre-trained model. We validate our method, PointACL on downstream tasks,\nincluding 3D classification and 3D segmentation with multiple datasets. It\nobtains comparable robust accuracy over state-of-the-art contrastive\nadversarial learning methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.00179 by other authors\n",
    "authors": [
      "Junxuan Huang",
      "Yatong An",
      "Lu cheng",
      "Bai Chen",
      "Junsong Yuan",
      "Chunming Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.06971"
  },
  {
    "id": "arXiv:2209.06977",
    "title": "SQL and NoSQL Databases Software architectures performance analysis and  assessments -- A Systematic Literature review",
    "abstract": "Context: The efficient processing of Big Data is a challenging task for SQL\nand NoSQL Databases, where competent software architecture plays a vital role.\nThe SQL Databases are designed for structuring data and supporting vertical\nscalability. In contrast, horizontal scalability is backed by NoSQL Databases\nand can process sizeable unstructured Data efficiently. One can choose the\nright paradigm according to the organisation's needs; however, making the\ncorrect choice can often be challenging. The SQL and NoSQL Databases follow\ndifferent architectures. Also, the mixed model is followed by each category of\nNoSQL Databases. Hence, data movement becomes difficult for cloud consumers\nacross multiple cloud service providers (CSPs). In addition, each cloud\nplatform IaaS, PaaS, SaaS, and DBaaS also monitors various paradigms.\nObjective: This systematic literature review (SLR) aims to study the related\narticles associated with SQL and NoSQL Database software architectures and\ntackle data portability and Interoperability among various cloud platforms.\nState of the art presented many performance comparison studies of SQL and NoSQL\nDatabases by observing scaling, performance, availability, consistency and\nsharding characteristics. According to the research studies, NoSQL Database\ndesigned structures can be the right choice for big data analytics, while SQL\nDatabases are suitable for OLTP Databases. The researcher proposes numerous\napproaches associated with data movement in the cloud. Platform-based APIs are\ndeveloped, which makes users' data movement difficult. Therefore, data\nportability and Interoperability issues are noticed during data movement across\nmultiple CSPs. To minimize developer efforts and Interoperability, Unified APIs\nare demanded to make data movement relatively more accessible among various\ncloud platforms.",
    "descriptor": "\nComments: 57 pages systematic literature review, already submitted to Big Data Research; More importantly, we can not add method, result and conclusion section in the abstract here due to characters limitations. Please check pdf file\n",
    "authors": [
      "Wisal Khan",
      "Teerath Kumar",
      "Zhang Cheng",
      "Kislay Raj",
      "Arunabha M Roy",
      "Bin Luo"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.06977"
  },
  {
    "id": "arXiv:2209.06979",
    "title": "Efficient Quantized Sparse Matrix Operations on Tensor Cores",
    "abstract": "The exponentially growing model size drives the continued success of deep\nlearning, but it brings prohibitive computation and memory cost. From the\nalgorithm perspective, model sparsification and quantization have been studied\nto alleviate the problem. From the architecture perspective, hardware vendors\nprovide Tensor cores for acceleration. However, it is very challenging to gain\npractical speedups from sparse, low-precision matrix operations on Tensor\ncores, because of the strict requirements for data layout and lack of support\nfor efficiently manipulating the low-precision integers. We propose Magicube, a\nhigh-performance sparse-matrix library for low-precision integers on Tensor\ncores. Magicube supports SpMM and SDDMM, two major sparse operations in deep\nlearning with mixed precision. Experimental results on an NVIDIA A100 GPU show\nthat Magicube achieves on average 1.44x (up to 2.37x) speedup over the\nvendor-optimized library for sparse kernels, and 1.43x speedup over the\nstate-of-the-art with a comparable accuracy for end-to-end sparse Transformer\ninference.",
    "descriptor": "\nComments: Accepted by 2022 International Conference for High Performance Computing, Networking, Storage and Analysis (SC'22), Best Paper Finalist\n",
    "authors": [
      "Shigang Li",
      "Kazuki Osawa",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06979"
  },
  {
    "id": "arXiv:2209.06987",
    "title": "Non-Parallel Voice Conversion for ASR Augmentation",
    "abstract": "Automatic speech recognition (ASR) needs to be robust to speaker differences.\nVoice Conversion (VC) modifies speaker characteristics of input speech. This is\nan attractive feature for ASR data augmentation. In this paper, we demonstrate\nthat voice conversion can be used as a data augmentation technique to improve\nASR performance, even on LibriSpeech, which contains 2,456 speakers. For ASR\naugmentation, it is necessary that the VC model be robust to a wide range of\ninput speech. This motivates the use of a non-autoregressive, non-parallel VC\nmodel, and the use of a pretrained ASR encoder within the VC model. This work\nsuggests that despite including many speakers, speaker diversity may remain a\nlimitation to ASR quality. Finally, interrogation of our VC performance has\nprovided useful metrics for objective evaluation of VC quality.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Gary Wang",
      "Andrew Rosenberg",
      "Bhuvana Ramabhadran",
      "Fadi Biadsy",
      "Yinghui Huang",
      "Jesse Emond",
      "Pedro Moreno Mengibar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.06987"
  },
  {
    "id": "arXiv:2209.06993",
    "title": "Learning from Future: A Novel Self-Training Framework for Semantic  Segmentation",
    "abstract": "Self-training has shown great potential in semi-supervised learning. Its core\nidea is to use the model learned on labeled data to generate pseudo-labels for\nunlabeled samples, and in turn teach itself. To obtain valid supervision,\nactive attempts typically employ a momentum teacher for pseudo-label prediction\nyet observe the confirmation bias issue, where the incorrect predictions may\nprovide wrong supervision signals and get accumulated in the training process.\nThe primary cause of such a drawback is that the prevailing self-training\nframework acts as guiding the current state with previous knowledge, because\nthe teacher is updated with the past student only. To alleviate this problem,\nwe propose a novel self-training strategy, which allows the model to learn from\nthe future. Concretely, at each training step, we first virtually optimize the\nstudent (i.e., caching the gradients without applying them to the model\nweights), then update the teacher with the virtual future student, and finally\nask the teacher to produce pseudo-labels for the current student as the\nguidance. In this way, we manage to improve the quality of pseudo-labels and\nthus boost the performance. We also develop two variants of our\nfuture-self-training (FST) framework through peeping at the future both deeply\n(FST-D) and widely (FST-W). Taking the tasks of unsupervised domain adaptive\nsemantic segmentation and semi-supervised semantic segmentation as the\ninstances, we experimentally demonstrate the effectiveness and superiority of\nour approach under a wide range of settings. Code will be made publicly\navailable.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Ye Du",
      "Yujun Shen",
      "Haochen Wang",
      "Jingjing Fei",
      "Wei Li",
      "Liwei Wu",
      "Rui Zhao",
      "Zehua Fu",
      "Qingjie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06993"
  },
  {
    "id": "arXiv:2209.06994",
    "title": "PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on  Transformer",
    "abstract": "Lane detection is one of the fundamental modules in self-driving. In this\npaper we employ a transformer-only method for lane detection, thus it could\nbenefit from the blooming development of fully vision transformer and achieves\nthe state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks,\nby fine-tuning the weight fully pre-trained on large datasets. More\nimportantly, this paper proposes a novel and general framework called\nPriorLane, which is used to enhance the segmentation performance of the fully\nvision transformer by introducing the low-cost local prior knowledge. PriorLane\nutilizes an encoder-only transformer to fuse the feature extracted by a\npre-trained segmentation model with prior knowledge embeddings. Note that a\nKnowledge Embedding Alignment (KEA) module is adapted to enhance the fusion\nperformance by aligning the knowledge embedding. Extensive experiments on our\nZjlab dataset show that Prior-Lane outperforms SOTA lane detection methods by a\n2.82% mIoU, and the code will be released at: https://github.\ncom/vincentqqb/PriorLane.",
    "descriptor": "",
    "authors": [
      "Qibo Qiu",
      "Haiming Gao",
      "Wei Hua",
      "Gang Huang",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06994"
  },
  {
    "id": "arXiv:2209.06995",
    "title": "Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A  Prompt-Based Uncertainty Propagation Approach",
    "abstract": "We propose PATRON, a new method that uses prompt-based uncertainty estimation\nfor data selection for pre-trained language model fine-tuning under cold-start\nscenarios, i.e., no initial labeled data are available. In PATRON, we design\n(1) a prompt-based uncertainty propagation approach to estimate the importance\nof data points and (2) a partition-then-rewrite (PTR) strategy to promote\nsample diversity when querying for annotations. Experiments on six text\nclassification datasets show that PATRON outperforms the strongest cold-start\ndata selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON\nachieves 91.0% and 92.1% of the fully supervised performance based on vanilla\nfine-tuning and prompt-based learning respectively. Our implementation of\nPATRON is available at \\url{https://github.com/yueyu1030/Patron}.",
    "descriptor": "",
    "authors": [
      "Yue Yu",
      "Rongzhi Zhang",
      "Ran Xu",
      "Jieyu Zhang",
      "Jiaming Shen",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06995"
  },
  {
    "id": "arXiv:2209.06997",
    "title": "M^4I: Multi-modal Models Membership Inference",
    "abstract": "With the development of machine learning techniques, the attention of\nresearch has been moved from single-modal learning to multi-modal learning, as\nreal-world data exist in the form of different modalities. However, multi-modal\nmodels often carry more information than single-modal models and they are\nusually applied in sensitive scenarios, such as medical report generation or\ndisease identification. Compared with the existing membership inference against\nmachine learning classifiers, we focus on the problem that the input and output\nof the multi-modal models are in different modalities, such as image\ncaptioning. This work studies the privacy leakage of multi-modal models through\nthe lens of membership inference attack, a process of determining whether a\ndata record involves in the model training process or not. To achieve this, we\npropose Multi-modal Models Membership Inference (M^4I) with two attack methods\nto infer the membership status, named metric-based (MB) M^4I and feature-based\n(FB) M^4I, respectively. More specifically, MB M^4I adopts similarity metrics\nwhile attacking to infer target data membership. FB M^4I uses a pre-trained\nshadow multi-modal feature extractor to achieve the purpose of data inference\nattack by comparing the similarities from extracted input and output features.\nExtensive experimental results show that both attack methods can achieve strong\nperformances. Respectively, 72.5% and 94.83% of attack success rates on average\ncan be obtained under unrestricted scenarios. Moreover, we evaluate multiple\ndefense mechanisms against our attacks. The source code of M^4I attacks is\npublicly available at\nhttps://github.com/MultimodalMI/Multimodal-membership-inference.git.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Pingyi Hu",
      "Zihan Wang",
      "Ruoxi Sun",
      "Hu Wang",
      "Minhui Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.06997"
  },
  {
    "id": "arXiv:2209.06999",
    "title": "Data Science Approach to predict the winning Fantasy Cricket Team Dream  11 Fantasy Sports",
    "abstract": "The evolution of digital technology and the increasing popularity of sports\ninspired the innovators to take the experience of users with a proclivity\ntowards sports to a whole new different level, by introducing Fantasy Sports\nPlatforms FSPs. The application of Data Science and Analytics is Ubiquitous in\nthe Modern World. Data Science and Analytics open doors to gain a deeper\nunderstanding and help in the decision making process. We firmly believed that\nwe could adopt Data Science to predict the winning fantasy cricket team on the\nFSP, Dream 11. We built a predictive model that predicts the performance of\nplayers in a prospective game. We used a combination of Greedy and Knapsack\nAlgorithms to prescribe the combination of 11 players to create a fantasy\ncricket team that has the most significant statistical odds of finishing as the\nstrongest team thereby giving us a higher chance of winning the pot of bets on\nthe Dream 11 FSP. We used PyCaret Python Library to help us understand and\nadopt the best Regressor Algorithm for our problem statement to make precise\npredictions. Further, we used Plotly Python Library to give us visual insights\ninto the team, and players performances by accounting for the statistical, and\nsubjective factors of a prospective game. The interactive plots help us to\nbolster the recommendations of our predictive model. You either win big, win\nsmall, or lose your bet based on the performance of the players selected for\nyour fantasy team in the prospective game, and our model increases the\nprobability of you winning big.",
    "descriptor": "",
    "authors": [
      "Sachin Kumar S",
      "Prithvi HV",
      "C Nandini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06999"
  },
  {
    "id": "arXiv:2209.07000",
    "title": "VIPHY: Probing \"Visible\" Physical Commonsense Knowledge",
    "abstract": "In recent years, vision-language models (VLMs) have shown remarkable\nperformance on visual reasoning tasks (e.g. attributes, location). While such\ntasks measure the requisite knowledge to ground and reason over a given visual\ninstance, they do not, however, measure the ability of VLMs to retain and\ngeneralize such knowledge. In this work, we evaluate their ability to acquire\n\"visible\" physical knowledge -- the information that is easily accessible from\nimages of static scenes, particularly across the dimensions of object color,\nsize and space. We build an automatic pipeline to derive a comprehensive\nknowledge resource for calibrating and probing these models. Our results\nindicate a severe gap between model and human performance across all three\ntasks. Furthermore, our caption pretrained baseline (CapBERT) significantly\noutperforms VLMs on both size and spatial tasks -- highlighting that despite\nsufficient access to ground language with visual modality, they struggle to\nretain such knowledge. The dataset and code are available at\nhttps://github.com/Axe--/ViPhy .",
    "descriptor": "\nComments: In Progress (under review)\n",
    "authors": [
      "Shikhar Singh",
      "Ehsan Qasemi",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07000"
  },
  {
    "id": "arXiv:2209.07001",
    "title": "Pose Attention-Guided Profile-to-Frontal Face Recognition",
    "abstract": "In recent years, face recognition systems have achieved exceptional success\ndue to promising advances in deep learning architectures. However, they still\nfail to achieve expected accuracy when matching profile images against a\ngallery of frontal images. Current approaches either perform pose normalization\n(i.e., frontalization) or disentangle pose information for face recognition. We\ninstead propose a new approach to utilize pose as an auxiliary information via\nan attention mechanism. In this paper, we hypothesize that pose attended\ninformation using an attention mechanism can guide contextual and distinctive\nfeature extraction from profile faces, which further benefits a better\nrepresentation learning in an embedded domain. To achieve this, first, we\ndesign a unified coupled profile-to-frontal face recognition network. It learns\nthe mapping from faces to a compact embedding subspace via a class-specific\ncontrastive loss. Second, we develop a novel pose attention block (PAB) to\nspecially guide the pose-agnostic feature extraction from profile faces. To be\nmore specific, PAB is designed to explicitly help the network to focus on\nimportant features along both channel and spatial dimension while learning\ndiscriminative yet pose invariant features in an embedding subspace. To\nvalidate the effectiveness of our proposed method, we conduct experiments on\nboth controlled and in the wild benchmarks including Multi-PIE, CFP, IJBC, and\nshow superiority over the state of the arts.",
    "descriptor": "\nComments: 10 pages, 5 figures, Accepted at IJCB, 2022\n",
    "authors": [
      "Moktari Mostofa",
      "Mohammad Saeed Ebrahimi Saadabadi",
      "Sahar Rahimi Malakshan",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07001"
  },
  {
    "id": "arXiv:2209.07003",
    "title": "Vision-aided UAV Navigation and Dynamic Obstacle Avoidance using  Gradient-based B-spline Trajectory Optimization",
    "abstract": "Navigating dynamic environments requires the robot to generate collision-free\ntrajectories and actively avoid moving obstacles. Most previous works designed\npath planning algorithms based on one single map representation, such as the\ngeometric, occupancy, or ESDF map. Although they have shown success in static\nenvironments, due to the limitation of map representation, those methods cannot\nreliably handle static and dynamic obstacles simultaneously. To address the\nproblem, this paper proposes a gradient-based B-spline trajectory optimization\nalgorithm utilizing the robot's onboard vision. The depth vision enables the\nrobot to track and represent dynamic objects geometrically based on the voxel\nmap. The proposed optimization first adopts the circle-based guide-point\nalgorithm to approximate the costs and gradients for avoiding static obstacles.\nThen, with the vision-detected moving objects, our receding-horizon distance\nfield is simultaneously used to prevent dynamic collisions. Finally, the\niterative re-guide strategy is applied to generate the collision-free\ntrajectory. The simulation and physical experiments prove that our method can\nrun in real-time to navigate dynamic environments safely.",
    "descriptor": "",
    "authors": [
      "Zhefan Xu",
      "Yumeng Xiu",
      "Xiaoyang Zhan",
      "Baihan Chen",
      "Kenji Shimada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07003"
  },
  {
    "id": "arXiv:2209.07005",
    "title": "Self-Supervised Texture Image Anomaly Detection By Fusing Normalizing  Flow and Dictionary Learning",
    "abstract": "A common study area in anomaly identification is industrial images anomaly\ndetection based on texture background. The interference of texture images and\nthe minuteness of texture anomalies are the main reasons why many existing\nmodels fail to detect anomalies. We propose a strategy for anomaly detection\nthat combines dictionary learning and normalizing flow based on the\naforementioned questions. The two-stage anomaly detection approach already in\nuse is enhanced by our method. In order to improve baseline method, this\nresearch add normalizing flow in representation learning and combines deep\nlearning and dictionary learning. Improved algorithms have exceeded 95$\\%$\ndetection accuracy on all MVTec AD texture type data after experimental\nvalidation. It shows strong robustness. The baseline method's detection\naccuracy for the Carpet data was 67.9%. The article was upgraded, raising the\ndetection accuracy to 99.7%.",
    "descriptor": "",
    "authors": [
      "Yaohua Guo",
      "Lijuan Song",
      "Zirui Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07005"
  },
  {
    "id": "arXiv:2209.07006",
    "title": "Time- vs. frequency- domain inverse elastic scattering: Theory and  experiment",
    "abstract": "This study formally adapts the time-domain linear sampling method (TLSM) for\nultrasonic imaging of stationary and evolving fractures in safety-critical\ncomponents. The TLSM indicator is then applied to the laboratory test data of\n[22, 18] and the obtained reconstructions are compared to their\nfrequency-domain counterparts. The results highlight the unique capability of\nthe time-domain imaging functional for high-fidelity tracking of evolving\ndamage, and its relative robustness to sparse and reduced aperture data at\nmoderate noise levels. A comparative analysis of the TLSM images against the\nmultifrequency LSM maps of [22] further reveals that thanks to the\nfull-waveform inversion in time and space, the TLSM generates images of\nremarkably higher quality with the same dataset.",
    "descriptor": "",
    "authors": [
      "Xiaoli Liu",
      "Jian Song",
      "Fatemeh Pourahmadian",
      "Houssem Haddar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07006"
  },
  {
    "id": "arXiv:2209.07007",
    "title": "Gromov-Wasserstein Autoencoders",
    "abstract": "Learning concise data representations without supervisory signals is a\nfundamental challenge in machine learning. A prominent approach to this goal is\nlikelihood-based models such as variational autoencoders (VAE) to learn latent\nrepresentations based on a meta-prior, which is a general premise assumed\nbeneficial for downstream tasks (e.g., disentanglement). However, such\napproaches often deviate from the original likelihood architecture to apply the\nintroduced meta-prior, causing undesirable changes in their training. In this\npaper, we propose a novel representation learning method, Gromov-Wasserstein\nAutoencoders (GWAE), which directly matches the latent and data distributions.\nInstead of a likelihood-based objective, GWAE models have a trainable prior\noptimized by minimizing the Gromov-Wasserstein (GW) metric. The GW metric\nmeasures the distance structure-oriented discrepancy between distributions\nsupported on incomparable spaces, e.g., with different dimensionalities. By\nrestricting the family of the trainable prior, we can introduce meta-priors to\ncontrol latent representations for downstream tasks. The empirical comparison\nwith the existing VAE-based methods shows that GWAE models can learn\nrepresentations based on meta-priors by changing the prior family without\nfurther modifying the GW objective.",
    "descriptor": "\nComments: 34 pages, 11 figures\n",
    "authors": [
      "Nao Nakagawa",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07007"
  },
  {
    "id": "arXiv:2209.07016",
    "title": "Algorithms and Lower Bounds for Replacement Paths under Multiple Edge  Failures",
    "abstract": "This paper considers a natural fault-tolerant shortest paths problem: for\nsome constant integer $f$, given a directed weighted graph with no negative\ncycles and two fixed vertices $s$ and $t$, compute (either explicitly or\nimplicitly) for every tuple of $f$ edges, the distance from $s$ to $t$ if these\nedges fail. We call this problem $f$-Fault Replacement Paths ($f$FRP).\nWe first present an $\\tilde{O}(n^3)$ time algorithm for $2$FRP in $n$-vertex\ndirected graphs with arbitrary edge weights and no negative cycles. As $2$FRP\nis a generalization of the well-studied Replacement Paths problem (RP) that\nasks for the distances between $s$ and $t$ for any single edge failure, $2$FRP\nis at least as hard as RP. Since RP in graphs with arbitrary weights is\nequivalent in a fine-grained sense to All-Pairs Shortest Paths (APSP)\n[Vassilevska Williams and Williams FOCS'10, J.~ACM'18], $2$FRP is at least as\nhard as APSP, and thus a substantially subcubic time algorithm in the number of\nvertices for $2$FRP would be a breakthrough. Therefore, our algorithm in\n$\\tilde{O}(n^3)$ time is conditionally nearly optimal. Our algorithm implies an\n$\\tilde{O}(n^{f+1})$ time algorithm for the $f$FRP problem, giving the first\nimprovement over the straightforward $O(n^{f+2})$ time algorithm.\nThen we focus on the restriction of $2$FRP to graphs with small integer\nweights bounded by $M$ in absolute values. Using fast rectangular matrix\nmultiplication, we obtain a randomized algorithm that runs in\n$\\tilde{O}(M^{2/3}n^{2.9153})$ time. This implies an improvement over our\n$\\tilde{O}(n^{f+1})$ time arbitrary weight algorithm for all $f>1$. We also\npresent a data structure variant of the algorithm that can trade off\npre-processing and query time. In addition to the algebraic algorithms, we also\ngive an $n^{8/3-o(1)}$ conditional lower bound for combinatorial $2$FRP\nalgorithms in directed unweighted graphs.",
    "descriptor": "\nComments: To appear in FOCS 2022; Abstract shortened to fit arXiv requirements\n",
    "authors": [
      "Virginia Vassilevska Williams",
      "Eyob Woldeghebriel",
      "Yinzhan Xu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07016"
  },
  {
    "id": "arXiv:2209.07018",
    "title": "FRANS: Automatic Feature Extraction for Time Series Forecasting",
    "abstract": "Feature extraction methods help in dimensionality reduction and capture\nrelevant information. In time series forecasting (TSF), features can be used as\nauxiliary information to achieve better accuracy. Traditionally, features used\nin TSF are handcrafted, which requires domain knowledge and significant\ndata-engineering work. In this research, we first introduce a notion of static\nand dynamic features, which then enables us to develop our autonomous Feature\nRetrieving Autoregressive Network for Static features (FRANS) that does not\nrequire domain knowledge. The method is based on a CNN classifier that is\ntrained to create for each series a collective and unique class representation\neither from parts of the series or, if class labels are available, from a set\nof series of the same class. It allows to discriminate series with similar\nbehaviour but from different classes and makes the features extracted from the\nclassifier to be maximally discriminatory. We explore the interpretability of\nour features, and evaluate the prediction capabilities of the method within the\nforecasting meta-learning environment FFORMA. Our results show that our\nfeatures lead to improvement in accuracy in most situations. Once trained our\napproach creates features orders of magnitude faster than statistical methods.",
    "descriptor": "",
    "authors": [
      "Alexey Chernikov",
      "Chang Wei Tan",
      "Pablo Montero-Manso",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07018"
  },
  {
    "id": "arXiv:2209.07023",
    "title": "MR4MR: Mixed Reality for Melody Reincarnation",
    "abstract": "There is a long history of an effort made to explore musical elements with\nthe entities and spaces around us, such as musique concr\\`ete and ambient\nmusic. In the context of computer music and digital art, interactive\nexperiences that concentrate on the surrounding objects and physical spaces\nhave also been designed. In recent years, with the development and\npopularization of devices, an increasing number of works have been designed in\nExtended Reality to create such musical experiences. In this paper, we describe\nMR4MR, a sound installation work that allows users to experience melodies\nproduced from interactions with their surrounding space in the context of Mixed\nReality (MR). Using HoloLens, an MR head-mounted display, users can bump\nvirtual objects that emit sound against real objects in their surroundings.\nThen, by continuously creating a melody following the sound made by the object\nand re-generating randomly and gradually changing melody using music generation\nmachine learning models, users can feel their ambient melody \"reincarnating\".",
    "descriptor": "\nComments: Accepted paper at the 3rd Conference on AI Music Creativity (September 2022)\n",
    "authors": [
      "Atsuya Kobayashi",
      "Ryogo Ishino",
      "Ryuku Nobusue",
      "Takumi Inoue",
      "Keisuke Okazaki",
      "Shoma Sawa",
      "Nao Tokui"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07023"
  },
  {
    "id": "arXiv:2209.07024",
    "title": "Almost Ramanujan Expanders from Arbitrary Expanders via Operator  Amplification",
    "abstract": "We give an efficient algorithm that transforms any bounded degree expander\ngraph into another that achieves almost optimal (namely, near-quadratic, $d\n\\leq 1/\\lambda^{2+o(1)}$) trade-off between (any desired) spectral expansion\n$\\lambda$ and degree $d$. Furthermore, the algorithm is local: every vertex can\ncompute its new neighbors as a subset of its original neighborhood of radius\n$O(\\log(1/\\lambda))$. The optimal quadratic trade-off is known as the Ramanujan\nbound, so our construction gives almost Ramanujan expanders from arbitrary\nexpanders.\nThe locality of the transformation preserves structural properties of the\noriginal graph, and thus has many consequences. Applied to Cayley graphs, our\ntransformation shows that any expanding finite group has almost Ramanujan\nexpanding generators. Similarly, one can obtain almost optimal explicit\nconstructions of quantum expanders, dimension expanders, monotone expanders,\netc., from existing (suboptimal) constructions of such objects. Another\nconsequence is a \"derandomized\" random walk on the original (suboptimal)\nexpander with almost optimal convergence rate. Our transformation also applies\nwhen the degree is not bounded or the expansion is not constant.\nWe obtain our results by a generalization of Ta-Shma's technique in his\nbreakthrough paper [STOC 2017], used to obtain explicit almost optimal binary\ncodes. Specifically, our spectral amplification extends Ta-Shma's analysis of\nbias amplification from scalars to matrices of arbitrary dimension in a very\nnatural way. Curiously, while Ta-Shma's explicit bias amplification\nderandomizes a well-known probabilistic argument (underlying the\nGilbert--Varshamov bound), there seems to be no known probabilistic (or other\nexistential) way of achieving our explicit (\"high-dimensional\") spectral\namplification.",
    "descriptor": "\nComments: 48 pages\n",
    "authors": [
      "Fernando Granha Jeronimo",
      "Tushant Mittal",
      "Sourya Roy",
      "Avi Wigderson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.07024"
  },
  {
    "id": "arXiv:2209.07025",
    "title": "Dynamic X-Ray Vision in Mixed Reality",
    "abstract": "X-ray vision, a technique that allows users to see through walls and other\nobstacles, is a popular technique for Augmented Reality (AR) and Mixed Reality\n(MR). In this paper, we demonstrate a dynamic X-ray vision window that is\nrendered in real-time based on the user's current position and changes with\nmovement in the physical environment. Moreover, the location and transparency\nof the window are also dynamically rendered based on the user's eye gaze. We\nbuild this X-ray vision window for a current state-of-the-art MR Head-Mounted\nDevice (HMD) -- HoloLens 2 by integrating several different features: scene\nunderstanding, eye tracking, and clipping primitive.",
    "descriptor": "",
    "authors": [
      "Hung-Jui Guo",
      "Jonathan Z. Bakdash",
      "Laura R. Marusich",
      "Balakrishnan Prabhakaran"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.07025"
  },
  {
    "id": "arXiv:2209.07026",
    "title": "Can We Solve 3D Vision Tasks Starting from A 2D Vision Transformer?",
    "abstract": "Vision Transformers (ViTs) have proven to be effective, in solving 2D image\nunderstanding tasks by training over large-scale image datasets; and meanwhile\nas a somehow separate track, in modeling the 3D visual world too such as voxels\nor point clouds. However, with the growing hope that transformers can become\nthe \"universal\" modeling tool for heterogeneous data, ViTs for 2D and 3D tasks\nhave so far adopted vastly different architecture designs that are hardly\ntransferable. That invites an (over-)ambitious question: can we close the gap\nbetween the 2D and 3D ViT architectures? As a piloting study, this paper\ndemonstrates the appealing promise to understand the 3D visual world, using a\nstandard 2D ViT architecture, with only minimal customization at the input and\noutput levels without redesigning the pipeline. To build a 3D ViT from its 2D\nsibling, we \"inflate\" the patch embedding and token sequence, accompanied with\nnew positional encoding mechanisms designed to match the 3D data geometry. The\nresultant \"minimalist\" 3D ViT, named Simple3D-Former, performs surprisingly\nrobustly on popular 3D tasks such as object classification, point cloud\nsegmentation and indoor scene detection, compared to highly customized\n3D-specific designs. It can hence act as a strong baseline for new 3D ViTs.\nMoreover, we note that pursing a unified 2D-3D ViT design has practical\nrelevance besides just scientific curiosity. Specifically, we demonstrate that\nSimple3D-Former naturally enables to exploit the wealth of pre-trained weights\nfrom large-scale realistic 2D images (e.g., ImageNet), which can be plugged in\nto enhancing the 3D task performance \"for free\".",
    "descriptor": "",
    "authors": [
      "Yi Wang",
      "Zhiwen Fan",
      "Tianlong Chen",
      "Hehe Fan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07026"
  },
  {
    "id": "arXiv:2209.07027",
    "title": "Generalized Representations Learning for Time Series Classification",
    "abstract": "Time series classification is an important problem in real world. Due to its\nnon-stationary property that the distribution changes over time, it remains\nchallenging to build models for generalization to unseen distributions. In this\npaper, we propose to view the time series classification problem from the\ndistribution perspective. We argue that the temporal complexity attributes to\nthe unknown latent distributions within. To this end, we propose DIVERSIFY to\nlearn generalized representations for time series classification. DIVERSIFY\ntakes an iterative process: it first obtains the worst-case distribution\nscenario via adversarial training, then matches the distributions of the\nobtained sub-domains. We also present some theoretical insights. We conduct\nexperiments on gesture recognition, speech commands recognition, wearable\nstress and affect detection, and sensor-based human activity recognition with a\ntotal of seven datasets in different settings. Results demonstrate that\nDIVERSIFY significantly outperforms other baselines and effectively\ncharacterizes the latent distributions by qualitative and quantitative\nanalysis.",
    "descriptor": "\nComments: Technical report; 18 pages\n",
    "authors": [
      "Wang Lu",
      "Jindong Wang",
      "Xinwei Sun",
      "Yiqiang Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07027"
  },
  {
    "id": "arXiv:2209.07031",
    "title": "A semantic hierarchical graph neural network for text classification",
    "abstract": "The key to the text classification task is language representation and\nimportant information extraction, and there are many related studies. In recent\nyears, the research on graph neural network (GNN) in text classification has\ngradually emerged and shown its advantages, but the existing models mainly\nfocus on directly inputting words as graph nodes into the GNN models ignoring\nthe different levels of semantic structure information in the samples. To\naddress the issue, we propose a new hierarchical graph neural network (HieGNN)\nwhich extracts corresponding information from word-level, sentence-level and\ndocument-level respectively. Experimental results on several benchmark datasets\nachieve better or similar results compared to several baseline methods, which\ndemonstrate that our model is able to obtain more useful information for\nclassification from samples.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Shuai Hua",
      "Xinxin Li",
      "Yunpeng Jing",
      "Qunfeng Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07031"
  },
  {
    "id": "arXiv:2209.07034",
    "title": "A Temporal Densely Connected Recurrent Network for Event-based Human  Pose Estimation",
    "abstract": "Event camera is an emerging bio-inspired vision sensors that report per-pixel\nbrightness changes asynchronously. It holds noticeable advantage of high\ndynamic range, high speed response, and low power budget that enable it to best\ncapture local motions in uncontrolled environments. This motivates us to unlock\nthe potential of event cameras for human pose estimation, as the human pose\nestimation with event cameras is rarely explored. Due to the novel paradigm\nshift from conventional frame-based cameras, however, event signals in a time\ninterval contain very limited information, as event cameras can only capture\nthe moving body parts and ignores those static body parts, resulting in some\nparts to be incomplete or even disappeared in the time interval. This paper\nproposes a novel densely connected recurrent architecture to address the\nproblem of incomplete information. By this recurrent architecture, we can\nexplicitly model not only the sequential but also non-sequential geometric\nconsistency across time steps to accumulate information from previous frames to\nrecover the entire human bodies, achieving a stable and accurate human pose\nestimation from event data. Moreover, to better evaluate our model, we collect\na large scale multimodal event-based dataset that comes with human pose\nannotations, which is by far the most challenging one to the best of our\nknowledge. The experimental results on two public datasets and our own dataset\ndemonstrate the effectiveness and strength of our approach. Code can be\navailable online for facilitating the future research.",
    "descriptor": "",
    "authors": [
      "Zhanpeng Shao",
      "Wen Zhou",
      "Wuzhen Wang",
      "Jianyu Yang",
      "Youfu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07034"
  },
  {
    "id": "arXiv:2209.07035",
    "title": "Online Combinatorial Auctions for Resource Allocation with Supply Costs  and Capacity Limits",
    "abstract": "We study a general online combinatorial auction problem in algorithmic\nmechanism design. A provider allocates multiple types of capacity-limited\nresources to customers that arrive in a sequential and arbitrary manner. Each\ncustomer has a private valuation function on bundles of resources that she can\npurchase (e.g., a combination of different resources such as CPU and RAM in\ncloud computing). The provider charges payment from customers who purchase a\nbundle of resources and incurs an increasing supply cost with respect to the\ntotality of resources allocated. The goal is to maximize the social welfare,\nnamely, the total valuation of customers for their purchased bundles, minus the\ntotal supply cost of the provider for all the resources that have been\nallocated. We adopt the competitive analysis framework and provide posted-price\nmechanisms with optimal competitive ratios. Our pricing mechanism is optimal in\nthe sense that no other online algorithms can achieve a better competitive\nratio. We validate the theoretic results via empirical studies of online\nresource allocation in cloud computing. Our numerical results demonstrate that\nthe proposed pricing mechanism is competitive and robust against system\nuncertainties and outperforms existing benchmarks.",
    "descriptor": "\nComments: 51 pages, 11 figures\n",
    "authors": [
      "Xiaoqi Tan",
      "Alberto Leon-Garcia",
      "Yuan Wu",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.07035"
  },
  {
    "id": "arXiv:2209.07036",
    "title": "Langevin Autoencoders for Learning Deep Latent Variable Models",
    "abstract": "Markov chain Monte Carlo (MCMC), such as Langevin dynamics, is valid for\napproximating intractable distributions. However, its usage is limited in the\ncontext of deep latent variable models owing to costly datapoint-wise sampling\niterations and slow convergence. This paper proposes the amortized Langevin\ndynamics (ALD), wherein datapoint-wise MCMC iterations are entirely replaced\nwith updates of an encoder that maps observations into latent variables. This\namortization enables efficient posterior sampling without datapoint-wise\niterations. Despite its efficiency, we prove that ALD is valid as an MCMC\nalgorithm, whose Markov chain has the target posterior as a stationary\ndistribution under mild assumptions. Based on the ALD, we also present a new\ndeep latent variable model named the Langevin autoencoder (LAE). Interestingly,\nthe LAE can be implemented by slightly modifying the traditional autoencoder.\nUsing multiple synthetic datasets, we first validate that ALD can properly\nobtain samples from target posteriors. We also evaluate the LAE on the image\ngeneration task, and show that our LAE can outperform existing methods based on\nvariational inference, such as the variational autoencoder, and other\nMCMC-based methods in terms of the test likelihood.",
    "descriptor": "\nComments: accepted at Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Shohei Taniguchi",
      "Yusuke Iwasawa",
      "Wataru Kumagai",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07036"
  },
  {
    "id": "arXiv:2209.07037",
    "title": "On error-based step size control for discontinuous Galerkin methods for  compressible fluid dynamics",
    "abstract": "We study temporal step size control of explicit Runge-Kutta methods for\ncompressible computational fluid dynamics (CFD), including the Navier-Stokes\nequations and hyperbolic systems of conservation laws such as the Euler\nequations. We demonstrate that error-based approaches are convenient in a wide\nrange of applications and compare them to more classical step size control\nbased on a Courant-Friedrichs-Lewy (CFL) number. Our numerical examples show\nthat error-based step size control is easy to use, robust, and efficient, e.g.,\nfor (initial) transient periods, complex geometries, nonlinear shock capturing\napproaches, and schemes that use nonlinear entropy projections. We demonstrate\nthese properties for problems ranging from well-understood academic test cases\nto industrially relevant large-scale computations with two disjoint code bases,\nthe open source Julia packages Trixi.jl with OrdinaryDiffEq.jl and the\nC/Fortran code SSDC based on PETSc.",
    "descriptor": "",
    "authors": [
      "Hendrik Ranocha",
      "Andrew R. Winters",
      "Hugo Guillermo Castro",
      "Lisandro Dalcin",
      "Michael Schlottke-Lakemper",
      "Gregor J. Gassner",
      "Matteo Parsani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07037"
  },
  {
    "id": "arXiv:2209.07039",
    "title": "Sparsity Inducing Representations for Policy Decompositions",
    "abstract": "Policy Decomposition (PoDec) is a framework that lessens the curse of\ndimensionality when deriving policies to optimal control problems. For a given\nsystem representation, i.e. the state variables and control inputs describing a\nsystem, PoDec generates strategies to decompose the joint optimization of\npolicies for all control inputs. Thereby, policies for different inputs are\nderived in a decoupled or cascaded fashion and as functions of some subsets of\nthe state variables, leading to reduction in computation. However, the choice\nof system representation is crucial as it dictates the suboptimality of the\nresulting policies. We present a heuristic method to find a representation more\namenable to decomposition. Our approach is based on the observation that every\ndecomposition enforces a sparsity pattern in the resulting policies at the cost\nof optimality and a representation that already leads to a sparse optimal\npolicy is likely to produce decompositions with lower suboptimalities. As the\noptimal policy is not known we construct a system representation that\nsparsifies its LQR approximation. For a simplified biped, a 4 degree-of-freedom\nmanipulator, and a quadcopter, we discover decompositions that offer 10%\nreduction in trajectory costs over those identified by vanilla PoDec. Moreover,\nthe decomposition policies produce trajectories with substantially lower costs\ncompared to policies obtained from state-of-the-art reinforcement learning\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Ashwin Khadke",
      "Hartmut Geyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07039"
  },
  {
    "id": "arXiv:2209.07040",
    "title": "Learning-Based Adaptive Control for Stochastic Linear Systems with Input  Constraints",
    "abstract": "We propose a certainty-equivalence scheme for adaptive control of scalar\nlinear systems subject to additive, i.i.d. Gaussian disturbances and bounded\ncontrol input constraints, without requiring prior knowledge of the bounds of\nthe system parameters, nor the control direction. Assuming that the system is\nat-worst marginally stable, mean square boundedness of the closed-loop system\nstates is proven. Lastly, numerical examples are presented to illustrate our\nresults.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Seth Siriya",
      "Jingge Zhu",
      "Dragan Ne\u0161i\u0107",
      "Ye Pu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07040"
  },
  {
    "id": "arXiv:2209.07042",
    "title": "Efficient Perception, Planning, and Control Algorithms for Vision-Based  Automated Vehicles",
    "abstract": "Owing to resource limitations, efficient computation systems have long been a\ncritical demand for those designing autonomous vehicles. Additionally, sensor\ncost and size restrict the development of self-driving cars. This paper\npresents an efficient framework for the operation of vision-based automatic\nvehicles; a front-facing camera and a few inexpensive radars are the required\nsensors for driving environment perception. The proposed algorithm comprises a\nmulti-task UNet (MTUNet) network for extracting image features and constrained\niterative linear quadratic regulator (CILQR) modules for rapid lateral and\nlongitudinal motion planning. The MTUNet is designed to simultaneously solve\nlane line segmentation, ego vehicle heading angle regression, road type\nclassification, and traffic object detection tasks at an approximate speed of\n40 FPS when an RGB image of size 228 x 228 is fed into it. The CILQR algorithms\nthen take processed MTUNet outputs and radar data as their input to produce\ndriving commands for lateral and longitudinal vehicle automation guidance; both\noptimal control problems can be solved within 1 ms. The proposed CILQR\ncontrollers are shown to be more efficient than the sequential quadratic\nprogramming (SQP) methods and can collaborate with the MTUNet to drive a car\nautonomously in unseen simulation environments for lane-keeping and\ncar-following maneuvers. Our experiments demonstrate that the proposed\nautonomous driving system is applicable to modern automobiles.",
    "descriptor": "\nComments: 7 figures, 11 pages including references\n",
    "authors": [
      "Der-Hau Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07042"
  },
  {
    "id": "arXiv:2209.07043",
    "title": "Towards self-attention based navigation in the real world",
    "abstract": "Vision-based navigation requires processing complex information to make\ntask-orientated decisions. Applications include autonomous robots, self-driving\ncars, and assistive vision for humans. One of the key elements in the process\nis the extraction and selection of relevant features in pixel space upon which\nto base action choices, for which Machine Learning techniques are well suited.\nHowever, Deep Reinforcement Learning agents trained in simulation often exhibit\nunsatisfactory results when deployed in the real-world due to perceptual\ndifferences known as the $\\textit{reality gap}$. An approach that is yet to be\nexplored to bridge this gap is self-attention. In this paper we (1) perform a\nsystematic exploration of the hyperparameter space for self-attention based\nnavigation of 3D environments and qualitatively appraise behaviour observed\nfrom different hyperparameter sets, including their ability to generalise; (2)\npresent strategies to improve the agents' generalisation abilities and\nnavigation behaviour; and (3) show how models trained in simulation are capable\nof processing real world images meaningfully in real time. To our knowledge,\nthis is the first demonstration of a self-attention based agent successfully\ntrained in navigating a 3D action space, using less than 4000 parameters.",
    "descriptor": "\nComments: Submitted to The 2022 Australian Conference on Robotics and Automation (ACRA 2022)\n",
    "authors": [
      "Jaime Ruiz-Serra",
      "Jack White",
      "Stephen Petrie",
      "Tatiana Kameneva",
      "Chris McCarthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07043"
  },
  {
    "id": "arXiv:2209.07044",
    "title": "Fair Inference for Discrete Latent Variable Models",
    "abstract": "It is now well understood that machine learning models, trained on data\nwithout due care, often exhibit unfair and discriminatory behavior against\ncertain populations. Traditional algorithmic fairness research has mainly\nfocused on supervised learning tasks, particularly classification. While\nfairness in unsupervised learning has received some attention, the literature\nhas primarily addressed fair representation learning of continuous embeddings.\nIn this paper, we conversely focus on unsupervised learning using probabilistic\ngraphical models with discrete latent variables. We develop a fair stochastic\nvariational inference technique for the discrete latent variables, which is\naccomplished by including a fairness penalty on the variational distribution\nthat aims to respect the principles of intersectionality, a critical lens on\nfairness from the legal, social science, and humanities literature, and then\noptimizing the variational parameters under this penalty. We first show the\nutility of our method in improving equity and fairness for clustering using\nna\\\"ive Bayes and Gaussian mixture models on benchmark datasets. To demonstrate\nthe generality of our approach and its potential for real-world impact, we then\ndevelop a special-purpose graphical model for criminal justice risk\nassessments, and use our fairness approach to prevent the inferences from\nencoding unfair societal biases.",
    "descriptor": "",
    "authors": [
      "Rashidul Islam",
      "Shimei Pan",
      "James R. Foulds"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07044"
  },
  {
    "id": "arXiv:2209.07046",
    "title": "Exploring Visual Interpretability for Contrastive Language-Image  Pre-training",
    "abstract": "Contrastive Language-Image pre-training (CLIP) learns rich representations\nvia readily available supervisions of natural language. It could improve\ngeneral performance on downstream vision tasks, including but not limited to\nzero-shot, long tail, segmentation, retrieval, caption and video. However, to\nthe best of our knowledge, the visual interpretability of CLIP has not been\nstudied yet. To provide visual explanations of its predictions, we propose the\nImage-Text Similarity Map (ITSM). Based on it, we surprisingly find that CLIP\nprefers the background regions than the foregrounds, and presenting erroneous\nvisualization against human understanding. Experimentally, we find the devil is\nin the pooling part, where inappropriate pooling methods lead to a phenomenon\ncalled semantic shift. To correct and boost the visualization results, we\npropose the Masked Max Pooling, with attention map from the self-supervised\nimage encoder. Meanwhile, interpretability task and recognition task require\ndifferent representations. To address the problem, we propose the dual\nprojections to cater this requirement. We integrate above methods as\nInterpretable Contrastive Language-Image pre-training (ICLIP). And experiments\nsuggest ICLIP greatly improves the interpretability. For example, the\nnontrivial improvements are $32.85\\%$ and $49.10\\%$, respectively, on VOC 2012\ndataset.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Yi Li",
      "Hualiang Wang",
      "Yiqun Duan",
      "Hang Xu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07046"
  },
  {
    "id": "arXiv:2209.07047",
    "title": "iFlipper: Label Flipping for Individual Fairness",
    "abstract": "As machine learning becomes prevalent, mitigating any unfairness present in\nthe training data becomes critical. Among the various notions of fairness, this\npaper focuses on the well-known individual fairness, which states that similar\nindividuals should be treated similarly. While individual fairness can be\nimproved when training a model (in-processing), we contend that fixing the data\nbefore model training (pre-processing) is a more fundamental solution. In\nparticular, we show that label flipping is an effective pre-processing\ntechnique for improving individual fairness. Our system iFlipper solves the\noptimization problem of minimally flipping labels given a limit to the\nindividual fairness violations, where a violation occurs when two similar\nexamples in the training data have different labels. We first prove that the\nproblem is NP-hard. We then propose an approximate linear programming algorithm\nand provide theoretical guarantees on how close its result is to the optimal\nsolution in terms of the number of label flips. We also propose techniques for\nmaking the linear programming solution more optimal without exceeding the\nviolations limit. Experiments on real datasets show that iFlipper significantly\noutperforms other pre-processing baselines in terms of individual fairness and\naccuracy on unseen test sets. In addition, iFlipper can be combined with\nin-processing techniques for even better results.",
    "descriptor": "\nComments: 20 pages, 19 figures, 8 tables\n",
    "authors": [
      "Hantian Zhang",
      "Ki Hyun Tae",
      "Jaeyoung Park",
      "Xu Chu",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07047"
  },
  {
    "id": "arXiv:2209.07048",
    "title": "AutoUpdate: Automatically Recommend Code Updates for Android Apps",
    "abstract": "Android developers frequently update source code to improve the performance,\nsecurity, or maintainability of Android apps. Such Android code updating\nactivities are intuitively repetitive, manual, and time-consuming. In this\npaper, we propose AutoUpdate, a Transformer-based automated code update\nrecommendation approach for Android Apps, which takes advantage of code\nabstraction (Abs) and Byte-Pair Encoding (BPE) techniques to represent source\ncode. Since this is the first work to automatically update code in Android\napps, we collect a history of 209,346 updated method pairs from 3,195\nreal-world Android applications available on Google Play stores that span 14\nyears (2008-2022). Through an extensive experiment on our curated datasets, the\nresults show that AutoUpdate(1) achieves a perfect prediction of 25% based on\nthe realistic time-wise evaluation scenario, which outperforms the two baseline\napproaches; (2) gains benefits at least 17% of improvement by using both Abs\nand BPE; (3) is able to recommend code updates for various purposes (e.g.,\nfixing bugs, adding new feature, refactoring methods). On the other hand, the\nmodels (4) could produce optimistically high accuracy due to the unrealistic\nevaluation scenario (i.e., random splits), suggesting that researchers should\nconsider time-wise evaluation scenarios in the future; (5) are less accurate\nfor a larger size of methods with a larger number of changed tokens, providing\na research opportunity for future work. Our findings demonstrate the\nsignificant advancement of NMT-based code update recommendation approaches for\nAndroid apps.",
    "descriptor": "\nComments: Under review at a SE journal\n",
    "authors": [
      "Yue Liu",
      "Chakkrit Tantithamthavorn",
      "Yonghui Liu",
      "Patanamon Thongtanunam",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07048"
  },
  {
    "id": "arXiv:2209.07053",
    "title": "Accuracy of the Uzbek stop words detection: a case study on \"School  corpus\"",
    "abstract": "Stop words are very important for information retrieval and text analysis\ninvestigation tasks of natural language processing. Current work presents a\nmethod to evaluate the quality of a list of stop words aimed at automatically\ncreating techniques. Although the method proposed in this paper was tested on\nan automatically-generated list of stop words for the Uzbek language, it can\nbe, with some modifications, applied to similar languages either from the same\nfamily or the ones that have an agglutinative nature. Since the Uzbek language\nbelongs to the family of agglutinative languages, it can be explained that the\nautomatic detection of stop words in the language is a more complex process\nthan in inflected languages. Moreover, we integrated our previous work on stop\nwords detection in the example of the \"School corpus\" by investigating how to\nautomatically analyse the detection of stop words in Uzbek texts. This work is\ndevoted to answering whether there is a good way of evaluating available stop\nwords for Uzbek texts, or whether it is possible to determine what part of the\nUzbek sentence contains the majority of the stop words by studying the\nnumerical characteristics of the probability of unique words. The results show\nacceptable accuracy of the stop words lists.",
    "descriptor": "\nComments: In proceedings of The International Conference and Workshop on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP), June 7-8, 2022, Koper, Slovenia\n",
    "authors": [
      "Khabibulla Madatov",
      "Shukurla Bekchanov",
      "Jernej Vi\u010di\u010d"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07053"
  },
  {
    "id": "arXiv:2209.07055",
    "title": "Valid Utility Games with Information Sharing Constraints",
    "abstract": "The use of game theoretic methods for control in multiagent systems has been\nan important topic in recent research. Valid utility games in particular have\nbeen used to model real-world problems; such games have the convenient property\nthat the value of any decision set which is a Nash equilibrium of the game is\nguaranteed to be within 1/2 of the value of the optimal decision set. However,\nan implicit assumption in this guarantee is that each agent is aware of the\ndecisions of all other agents. In this work, we first describe how this\nguarantee degrades as agents are only aware of a subset of the decisions of\nother agents. We then show that this loss can be mitigated by restriction to a\nrelevant subclass of games.",
    "descriptor": "",
    "authors": [
      "David Grimsman",
      "Philip N. Brown",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07055"
  },
  {
    "id": "arXiv:2209.07057",
    "title": "MIPI 2022 Challenge on RGB+ToF Depth Completion: Dataset and Report",
    "abstract": "Developing and integrating advanced image sensors with novel algorithms in\ncamera systems is prevalent with the increasing demand for computational\nphotography and imaging on mobile platforms. However, the lack of high-quality\ndata for research and the rare opportunity for in-depth exchange of views from\nindustry and academia constrain the development of mobile intelligent\nphotography and imaging (MIPI). To bridge the gap, we introduce the first MIPI\nchallenge including five tracks focusing on novel image sensors and imaging\nalgorithms. In this paper, RGB+ToF Depth Completion, one of the five tracks,\nworking on the fusion of RGB sensor and ToF sensor (with spot illumination) is\nintroduced. The participants were provided with a new dataset called\nTetrasRGBD, which contains 18k pairs of high-quality synthetic RGB+Depth\ntraining data and 2.3k pairs of testing data from mixed sources. All the data\nare collected in an indoor scenario. We require that the running time of all\nmethods should be real-time on desktop GPUs. The final results are evaluated\nusing objective metrics and Mean Opinion Score (MOS) subjectively. A detailed\ndescription of all models developed in this challenge is provided in this\npaper. More details of this challenge and the link to the dataset can be found\nat https://github.com/mipi-challenge/MIPI2022.",
    "descriptor": "\nComments: ECCV 2022 Mobile Intelligent Photography and Imaging (MIPI) Workshop--RGB+ToF Depth Completion Challenge Report. MIPI workshop website: this http URL\n",
    "authors": [
      "Wenxiu Sun",
      "Qingpeng Zhu",
      "Chongyi Li",
      "Ruicheng Feng",
      "Shangchen Zhou",
      "Jun Jiang",
      "Qingyu Yang",
      "Chen Change Loy",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07057"
  },
  {
    "id": "arXiv:2209.07061",
    "title": "PROB-SLAM: Real-time Visual SLAM Based on Probabilistic Graph  Optimization",
    "abstract": "Traditional SLAM algorithms are typically based on artificial features, which\nlack high-level information. By introducing semantic information, SLAM can own\nhigher stability and robustness rather than purely hand-crafted features.\nHowever, the high uncertainty of semantic detection networks prohibits the\npractical functionality of high-level information. To solve the uncertainty\nproperty introduced by semantics, this paper proposed a novel probability map\nbased on the Gaussian distribution assumption. This map transforms the semantic\nbinary object detection into probability results, which help establish a\nprobabilistic data association between artificial features and semantic info.\nThrough our algorithm, the higher confidence will be given higher weights in\neach update step while the edge of the detection area will be endowed with\nlower confidence. Then the uncertainty is undermined and has less effect on\nnonlinear optimization. The experiments are carried out in the TUM RGBD\ndataset, results show that our system improves ORB-SLAM2 by about 15% in indoor\nenvironments' errors. We have demonstrated that the method can be successfully\napplied to environments containing dynamic objects.",
    "descriptor": "",
    "authors": [
      "Xianwei Meng",
      "Bonian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07061"
  },
  {
    "id": "arXiv:2209.07063",
    "title": "GAGA: Deciphering Age-path of Generalized Self-paced Regularizer",
    "abstract": "Nowadays self-paced learning (SPL) is an important machine learning paradigm\nthat mimics the cognitive process of humans and animals. The SPL regime\ninvolves a self-paced regularizer and a gradually increasing age parameter,\nwhich plays a key role in SPL but where to optimally terminate this process is\nstill non-trivial to determine. A natural idea is to compute the solution path\nw.r.t. age parameter (i.e., age-path). However, current age-path algorithms are\neither limited to the simplest regularizer, or lack solid theoretical\nunderstanding as well as computational efficiency. To address this challenge,\nwe propose a novel \\underline{G}eneralized \\underline{Ag}e-path\n\\underline{A}lgorithm (GAGA) for SPL with various self-paced regularizers based\non ordinary differential equations (ODEs) and sets control, which can learn the\nentire solution spectrum w.r.t. a range of age parameters. To the best of our\nknowledge, GAGA is the first exact path-following algorithm tackling the\nage-path for general self-paced regularizer. Finally the algorithmic steps of\nclassic SVM and Lasso are described in detail. We demonstrate the performance\nof GAGA on real-world datasets, and find considerable speedup between our\nalgorithm and competing baselines.",
    "descriptor": "\nComments: 33 pages. Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Xingyu Qu",
      "Diyang Li",
      "Xiaohan Zhao",
      "Bin Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07063"
  },
  {
    "id": "arXiv:2209.07064",
    "title": "SecSkyline: Fast Privacy-Preserving Skyline Queries over Encrypted Cloud  Databases",
    "abstract": "The well-known benefits of cloud computing have spurred the popularity of\ndatabase service outsourcing, where one can resort to the cloud to conveniently\nstore and query databases. Coming with such popular trend is the threat to data\nprivacy, as the cloud gains access to the databases and queries which may\ncontain sensitive information, like medical or financial data. A large body of\nwork has been presented for querying encrypted databases, which has been mostly\nfocused on secure keyword search. In this paper, we instead focus on the\nsupport for secure skyline query processing over encrypted outsourced\ndatabases, where little work has been done. Skyline query is an advanced kind\nof database query which is important for multi-criteria decision-making systems\nand applications. We propose SecSkyline, a new system framework building on\nlightweight cryptography for fast privacy-preserving skyline queries.\nSecSkyline ambitiously provides strong protection for not only the content\nconfidentiality of the outsourced database, the query, and the result, but also\nfor data patterns that may incur indirect data leakages, such as dominance\nrelationships among data points and search access patterns. Extensive\nexperiments demonstrate that SecSkyline is substantially superior to the\nstate-of-the-art in query latency, with up to 813$\\times$ improvement.",
    "descriptor": "\nComments: under review by a journal\n",
    "authors": [
      "Yifeng Zheng",
      "Weibo Wang",
      "Songlei Wang",
      "Xiaohua Jia",
      "Hejiao Huang",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.07064"
  },
  {
    "id": "arXiv:2209.07065",
    "title": "CommunityLM: Probing Partisan Worldviews from Language Models",
    "abstract": "As political attitudes have diverged ideologically in the United States,\npolitical speech has diverged lingusitically. The ever-widening polarization\nbetween the US political parties is accelerated by an erosion of mutual\nunderstanding between them. We aim to make these communities more\ncomprehensible to each other with a framework that probes community-specific\nresponses to the same survey questions using community language models\nCommunityLM. In our framework we identify committed partisan members for each\ncommunity on Twitter and fine-tune LMs on the tweets authored by them. We then\nassess the worldviews of the two groups using prompt-based probing of their\ncorresponding LMs, with prompts that elicit opinions about public figures and\ngroups surveyed by the American National Election Studies (ANES) 2020\nExploratory Testing Survey. We compare the responses generated by the LMs to\nthe ANES survey results, and find a level of alignment that greatly exceeds\nseveral baseline methods. Our work aims to show that we can use community LMs\nto query the worldview of any group of people given a sufficiently large sample\nof their social media discussions or media diet.",
    "descriptor": "\nComments: Paper accepted by COLING 2022\n",
    "authors": [
      "Hang Jiang",
      "Doug Beeferman",
      "Brandon Roy",
      "Deb Roy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07065"
  },
  {
    "id": "arXiv:2209.07066",
    "title": "A Lattice-Based Embedding Method for Reversible Audio Watermarking",
    "abstract": "Reversible audio watermarking (RAW) is a promising technique in various\napplications. To simultaneously meet the demand of achieving high\nimperceptibility and robustness, this paper proposes a novel RAW scheme based\non lattices. The scheme is referred to as Meet-in-the-Middle Embedding (MME),\nin which the lattice quantization errors are properly scaled and added back to\nthe quantized host signals. Simulations show that MME excels in a wide range of\nmetrics including signal-to-watermark ratio (SWR), objective difference grade\n(ODG), and bit error rate (BER).",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Junren Qin",
      "Shanxiang Lyu",
      "Jiarui Deng",
      "Xingyuan Liang",
      "Shijun Xiang",
      "Hao Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.07066"
  },
  {
    "id": "arXiv:2209.07067",
    "title": "Efficient learning of nonlinear prediction models with time-series  privileged information",
    "abstract": "In domains where sample sizes are limited, efficient learning algorithms are\ncritical. Learning using privileged information (LuPI) offers increased sample\nefficiency by allowing prediction models access to types of information at\ntraining time which is unavailable when the models are used. In recent work, it\nwas shown that for prediction in linear-Gaussian dynamical systems, a LuPI\nlearner with access to intermediate time series data is never worse and often\nbetter in expectation than any unbiased classical learner. We provide new\ninsights into this analysis and generalize it to nonlinear prediction tasks in\nlatent dynamical systems, extending theoretical guarantees to the case where\nthe map connecting latent variables and observations is known up to a linear\ntransform. In addition, we propose algorithms based on random features and\nrepresentation learning for the case when this map is unknown. A suite of\nempirical results confirm theoretical findings and show the potential of using\nprivileged time-series information in nonlinear prediction.",
    "descriptor": "",
    "authors": [
      "Bastian Jung",
      "Fredrik D Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07067"
  },
  {
    "id": "arXiv:2209.07068",
    "title": "uChecker: Masked Pretrained Language Models as Unsupervised Chinese  Spelling Checkers",
    "abstract": "The task of Chinese Spelling Check (CSC) is aiming to detect and correct\nspelling errors that can be found in the text. While manually annotating a\nhigh-quality dataset is expensive and time-consuming, thus the scale of the\ntraining dataset is usually very small (e.g., SIGHAN15 only contains 2339\nsamples for training), therefore supervised-learning based models usually\nsuffer the data sparsity limitation and over-fitting issue, especially in the\nera of big language models. In this paper, we are dedicated to investigating\nthe \\textbf{unsupervised} paradigm to address the CSC problem and we propose a\nframework named \\textbf{uChecker} to conduct unsupervised spelling error\ndetection and correction. Masked pretrained language models such as BERT are\nintroduced as the backbone model considering their powerful language diagnosis\ncapability. Benefiting from the various and flexible MASKing operations, we\npropose a Confusionset-guided masking strategy to fine-train the masked\nlanguage model to further improve the performance of unsupervised detection and\ncorrection. Experimental results on standard datasets demonstrate the\neffectiveness of our proposed model uChecker in terms of character-level and\nsentence-level Accuracy, Precision, Recall, and F1-Measure on tasks of spelling\nerror detection and correction respectively.",
    "descriptor": "\nComments: COLING2022,11 pages\n",
    "authors": [
      "Piji Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07068"
  },
  {
    "id": "arXiv:2209.07069",
    "title": "Active Self-Training for Weakly Supervised 3D Scene Semantic  Segmentation",
    "abstract": "Since the preparation of labeled data for training semantic segmentation\nnetworks of point clouds is a time-consuming process, weakly supervised\napproaches have been introduced to learn from only a small fraction of data.\nThese methods are typically based on learning with contrastive losses while\nautomatically deriving per-point pseudo-labels from a sparse set of\nuser-annotated labels. In this paper, our key observation is that the selection\nof what samples to annotate is as important as how these samples are used for\ntraining. Thus, we introduce a method for weakly supervised segmentation of 3D\nscenes that combines self-training with active learning. The active learning\nselects points for annotation that likely result in performance improvements to\nthe trained model, while the self-training makes efficient use of the\nuser-provided labels for learning the model. We demonstrate that our approach\nleads to an effective method that provides improvements in scene segmentation\nover previous works and baselines, while requiring only a small number of user\nannotations.",
    "descriptor": "",
    "authors": [
      "Gengxin Liu",
      "Oliver van Kaick",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07069"
  },
  {
    "id": "arXiv:2209.07070",
    "title": "Fixed-Point Centrality for Networks",
    "abstract": "This paper proposes a family of network centralities called fixed-point\ncentralities. This centrality family is defined via the fixed point of\npermutation equivariant mappings related to the underlying network. Such a\ncentrality notion is immediately extended to define fixed-point centralities\nfor infinite graphs characterized by graphons. Variation bounds of such\ncentralities with respect to the variations of the underlying graphs and\ngraphons under mild assumptions are established. Fixed-point centralities\nconnect with a variety of different models on networks including graph neural\nnetworks, static and dynamic games on networks, and Markov decision processes.",
    "descriptor": "\nComments: 8 pages, Accepted for presentation at IEEE Conference on Decision and Control\n",
    "authors": [
      "Shuang Gao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07070"
  },
  {
    "id": "arXiv:2209.07074",
    "title": "On the Reuse Bias in Off-Policy Reinforcement Learning",
    "abstract": "Importance sampling (IS) is a popular technique in off-policy evaluation,\nwhich re-weights the return of trajectories in the replay buffer to boost\nsample efficiency. However, training with IS can be unstable and previous\nattempts to address this issue mainly focus on analyzing the variance of IS. In\nthis paper, we reveal that the instability is also related to a new notion of\nReuse Bias of IS -- the bias in off-policy evaluation caused by the reuse of\nthe replay buffer for evaluation and optimization. We theoretically show that\nthe off-policy evaluation and optimization of the current policy with the data\nfrom the replay buffer result in an overestimation of the objective, which may\ncause an erroneous gradient update and degenerate the performance. We further\nprovide a high-probability upper bound of the Reuse Bias, and show that\ncontrolling one term of the upper bound can control the Reuse Bias by\nintroducing the concept of stability for off-policy algorithms. Based on these\nanalyses, we finally present a novel Bias-Regularized Importance Sampling\n(BIRIS) framework along with practical algorithms, which can alleviate the\nnegative impact of the Reuse Bias. Experimental results show that our\nBIRIS-based methods can significantly improve the sample efficiency on a series\nof continuous control tasks in MuJoCo.",
    "descriptor": "",
    "authors": [
      "Chengyang Ying",
      "Zhongkai Hao",
      "Xinning Zhou",
      "Hang Su",
      "Dong Yan",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07074"
  },
  {
    "id": "arXiv:2209.07075",
    "title": "Bi-level Physics-Informed Neural Networks for PDE Constrained  Optimization using Broyden's Hypergradients",
    "abstract": "Deep learning based approaches like Physics-informed neural networks (PINNs)\nand DeepONets have shown promise on solving PDE constrained optimization\n(PDECO) problems. However, existing methods are insufficient to handle those\nPDE constraints that have a complicated or nonlinear dependency on optimization\ntargets. In this paper, we present a novel bi-level optimization framework to\nresolve the challenge by decoupling the optimization of the targets and\nconstraints. For the inner loop optimization, we adopt PINNs to solve the PDE\nconstraints only. For the outer loop, we design a novel method by using\nBroyden's method based on the Implicit Function Theorem (IFT), which is\nefficient and accurate for approximating hypergradients. We further present\ntheoretical explanations and error analysis of the hypergradients computation.\nExtensive experiments on multiple large-scale and nonlinear PDE constrained\noptimization problems demonstrate that our method achieves state-of-the-art\nresults compared with strong baselines.",
    "descriptor": "",
    "authors": [
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Jian Song",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07075"
  },
  {
    "id": "arXiv:2209.07076",
    "title": "Responsible AI Implementation: A Human-centered Framework for  Accelerating the Innovation Process",
    "abstract": "There is still a significant gap between expectations and the successful\nadoption of AI to innovate and improve businesses. Due to the emergence of deep\nlearning, AI adoption is more complex as it often incorporates big data and the\ninternet of things, affecting data privacy. Existing frameworks have identified\nthe need to focus on human-centered design, combining technical and\nbusiness/organizational perspectives. However, trust remains a critical issue\nthat needs to be designed from the beginning. The proposed framework expands\nfrom the human-centered design approach, emphasizing and maintaining the trust\nthat underpins the process. This paper proposes a theoretical framework for\nresponsible artificial intelligence (AI) implementation. The proposed framework\nemphasizes a synergistic business technology approach for the agile co-creation\nprocess. The aim is to streamline the adoption process of AI to innovate and\nimprove business by involving all stakeholders throughout the project so that\nthe AI technology is designed, developed, and deployed in conjunction with\npeople and not in isolation. The framework presents a fresh viewpoint on\nresponsible AI implementation based on analytical literature review, conceptual\nframework design, and practitioners' mediating expertise. The framework\nemphasizes establishing and maintaining trust throughout the human-centered\ndesign and agile development of AI. This human-centered approach is aligned\nwith and enabled by the privacy by design principle. The creators of the\ntechnology and the end-users are working together to tailor the AI solution\nspecifically for the business requirements and human characteristics. An\nillustrative case study on adopting AI for assisting planning in a hospital\nwill demonstrate that the proposed framework applies to real-life applications.",
    "descriptor": "\nComments: 18 pages, 7 Figures\n",
    "authors": [
      "Dian Tjondronegoro",
      "Elizabeth Yuwono",
      "Brent Richards",
      "Damian Green",
      "Siiri Hatakka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.07076"
  },
  {
    "id": "arXiv:2209.07080",
    "title": "Layerwise Bregman Representation Learning with Applications to Knowledge  Distillation",
    "abstract": "In this work, we propose a novel approach for layerwise representation\nlearning of a trained neural network. In particular, we form a Bregman\ndivergence based on the layer's transfer function and construct an extension of\nthe original Bregman PCA formulation by incorporating a mean vector and\nnormalizing the principal directions with respect to the geometry of the local\nconvex function around the mean. This generalization allows exporting the\nlearned representation as a fixed layer with a non-linearity. As an application\nto knowledge distillation, we cast the learning problem for the student network\nas predicting the compression coefficients of the teacher's representations,\nwhich are passed as the input to the imported layer. Our empirical findings\nindicate that our approach is substantially more effective for transferring\ninformation between networks than typical teacher-student training using the\nteacher's penultimate layer representations and soft labels.",
    "descriptor": "",
    "authors": [
      "Ehsan Amid",
      "Rohan Anil",
      "Christopher Fifty",
      "Manfred K. Warmuth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07080"
  },
  {
    "id": "arXiv:2209.07081",
    "title": "DEQGAN: Learning the Loss Function for PINNs with Generative Adversarial  Networks",
    "abstract": "Solutions to differential equations are of significant scientific and\nengineering relevance. Physics-Informed Neural Networks (PINNs) have emerged as\na promising method for solving differential equations, but they lack a\ntheoretical justification for the use of any particular loss function. This\nwork presents Differential Equation GAN (DEQGAN), a novel method for solving\ndifferential equations using generative adversarial networks to \"learn the loss\nfunction\" for optimizing the neural network. Presenting results on a suite of\ntwelve ordinary and partial differential equations, including the nonlinear\nBurgers', Allen-Cahn, Hamilton, and modified Einstein's gravity equations, we\nshow that DEQGAN can obtain multiple orders of magnitude lower mean squared\nerrors than PINNs that use $L_2$, $L_1$, and Huber loss functions. We also show\nthat DEQGAN achieves solution accuracies that are competitive with popular\nnumerical methods. Finally, we present two methods to improve the robustness of\nDEQGAN to different hyperparameter settings.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.11133\n",
    "authors": [
      "Blake Bullwinkel",
      "Dylan Randle",
      "Pavlos Protopapas",
      "David Sondak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07081"
  },
  {
    "id": "arXiv:2209.07084",
    "title": "Knowledge Graph Completion with Pre-trained Multimodal Transformer and  Twins Negative Sampling",
    "abstract": "Knowledge graphs (KGs) that modelings the world knowledge as structural\ntriples are inevitably incomplete. Such problems still exist for multimodal\nknowledge graphs (MMKGs). Thus, knowledge graph completion (KGC) is of great\nimportance to predict the missing triples in the existing KGs. As for the\nexisting KGC methods, embedding-based methods rely on manual design to leverage\nmultimodal information while finetune-based approaches are not superior to\nembedding-based methods in link prediction. To address these problems, we\npropose a VisualBERT-enhanced Knowledge Graph Completion model (VBKGC for\nshort). VBKGC could capture deeply fused multimodal information for entities\nand integrate them into the KGC model. Besides, we achieve the co-design of the\nKGC model and negative sampling by designing a new negative sampling strategy\ncalled twins negative sampling. Twins negative sampling is suitable for\nmultimodal scenarios and could align different embeddings for entities. We\nconduct extensive experiments to show the outstanding performance of VBKGC on\nthe link prediction task and make further exploration of VBKGC.",
    "descriptor": "\nComments: Accepted by KDD 2022 Undergraduate Consortium\n",
    "authors": [
      "Yichi Zhang",
      "Wen Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07084"
  },
  {
    "id": "arXiv:2209.07088",
    "title": "Self-distilled Feature Aggregation for Self-supervised Monocular Depth  Estimation",
    "abstract": "Self-supervised monocular depth estimation has received much attention\nrecently in computer vision. Most of the existing works in literature aggregate\nmulti-scale features for depth prediction via either straightforward\nconcatenation or element-wise addition, however, such feature aggregation\noperations generally neglect the contextual consistency between multi-scale\nfeatures. Addressing this problem, we propose the Self-Distilled Feature\nAggregation (SDFA) module for simultaneously aggregating a pair of low-scale\nand high-scale features and maintaining their contextual consistency. The SDFA\nemploys three branches to learn three feature offset maps respectively: one\noffset map for refining the input low-scale feature and the other two for\nrefining the input high-scale feature under a designed self-distillation\nmanner. Then, we propose an SDFA-based network for self-supervised monocular\ndepth estimation, and design a self-distilled training strategy to train the\nproposed network with the SDFA module. Experimental results on the KITTI\ndataset demonstrate that the proposed method outperforms the comparative\nstate-of-the-art methods in most cases. The code is available at\nhttps://github.com/ZM-Zhou/SDFA-Net_pytorch.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Zhengming Zhou",
      "Qiulei Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07088"
  },
  {
    "id": "arXiv:2209.07089",
    "title": "Constrained Update Projection Approach to Safe Policy Optimization",
    "abstract": "Safe reinforcement learning (RL) studies problems where an intelligent agent\nhas to not only maximize reward but also avoid exploring unsafe areas. In this\nstudy, we propose CUP, a novel policy optimization method based on Constrained\nUpdate Projection framework that enjoys rigorous safety guarantee. Central to\nour CUP development is the newly proposed surrogate functions along with the\nperformance bound. Compared to previous safe RL methods, CUP enjoys the\nbenefits of 1) CUP generalizes the surrogate functions to generalized advantage\nestimator (GAE), leading to strong empirical performance. 2) CUP unifies\nperformance bounds, providing a better understanding and interpretability for\nsome existing algorithms; 3) CUP provides a non-convex implementation via only\nfirst-order optimizers, which does not require any strong approximation on the\nconvexity of the objectives. To validate our CUP method, we compared CUP\nagainst a comprehensive list of safe RL baselines on a wide range of tasks.\nExperiments show the effectiveness of CUP both in terms of reward and safety\nconstraint satisfaction. We have opened the source code of CUP at\nhttps://github.com/RL-boxes/Safe-RL/tree/ main/CUP.",
    "descriptor": "\nComments: Accepted by NeurIPS2022. arXiv admin note: substantial text overlap with arXiv:2202.07565; text overlap with arXiv:2002.06506 by other authors\n",
    "authors": [
      "Long Yang",
      "Jiaming Ji",
      "Juntao Dai",
      "Linrui Zhang",
      "Binbin Zhou",
      "Pengfei Li",
      "Yaodong Yang",
      "Gang Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07089"
  },
  {
    "id": "arXiv:2209.07090",
    "title": "Characterizing Attributed Tree Translations in Terms of Macro Tree  Transducers",
    "abstract": "It is well known that attributed tree transducers can be equipped with\n\"regular look-around\" in order to obtain a more robust class of translations.\nWe present two characterizations of this class in terms of macro tree\ntransducers (MTTs): the first one is a static restriction on the rules of the\nMTTs, where the MTTs need to be equipped with regular look-around. The second\ncharacterization is a dynamic one, where the MTTs only need regular look-ahead.",
    "descriptor": "",
    "authors": [
      "Kenji Hashimoto",
      "Sebastian Maneth"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2209.07090"
  },
  {
    "id": "arXiv:2209.07096",
    "title": "Multi-Objective Policy Gradients with Topological Constraints",
    "abstract": "Multi-objective optimization models that encode ordered sequential\nconstraints provide a solution to model various challenging problems including\nencoding preferences, modeling a curriculum, and enforcing measures of safety.\nA recently developed theory of topological Markov decision processes (TMDPs)\ncaptures this range of problems for the case of discrete states and actions. In\nthis work, we extend TMDPs towards continuous spaces and unknown transition\ndynamics by formulating, proving, and implementing the policy gradient theorem\nfor TMDPs. This theoretical result enables the creation of TMDP learning\nalgorithms that use function approximators, and can generalize existing deep\nreinforcement learning (DRL) approaches. Specifically, we present a new\nalgorithm for a policy gradient in TMDPs by a simple extension of the proximal\npolicy optimization (PPO) algorithm. We demonstrate this on a real-world\nmultiple-objective navigation problem with an arbitrary ordering of objectives\nboth in simulation and on a real robot.",
    "descriptor": "",
    "authors": [
      "Kyle Hollins Wray",
      "Stas Tiomkin",
      "Mykel J. Kochenderfer",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07096"
  },
  {
    "id": "arXiv:2209.07098",
    "title": "Multi-Modal Masked Autoencoders for Medical Vision-and-Language  Pre-Training",
    "abstract": "Medical vision-and-language pre-training provides a feasible solution to\nextract effective vision-and-language representations from medical images and\ntexts. However, few studies have been dedicated to this field to facilitate\nmedical vision-and-language understanding. In this paper, we propose a\nself-supervised learning paradigm with multi-modal masked autoencoders\n(M$^3$AE), which learn cross-modal domain knowledge by reconstructing missing\npixels and tokens from randomly masked images and texts. There are three key\ndesigns to make this simple approach work. First, considering the different\ninformation densities of vision and language, we adopt different masking ratios\nfor the input image and text, where a considerably larger masking ratio is used\nfor images. Second, we use visual and textual features from different layers to\nperform the reconstruction to deal with different levels of abstraction in\nvisual and language. Third, we develop different designs for vision and\nlanguage decoders (i.e., a Transformer for vision and a multi-layer perceptron\nfor language). To perform a comprehensive evaluation and facilitate further\nresearch, we construct a medical vision-and-language benchmark including three\ntasks. Experimental results demonstrate the effectiveness of our approach,\nwhere state-of-the-art results are achieved on all downstream tasks. Besides,\nwe conduct further analysis to better verify the effectiveness of different\ncomponents of our approach and various settings of pre-training. The source\ncode is available at~\\url{https://github.com/zhjohnchan/M3AE}.",
    "descriptor": "\nComments: Natural Language Processing. 11 pages, 3 figures\n",
    "authors": [
      "Zhihong Chen",
      "Yuhao Du",
      "Jinpeng Hu",
      "Yang Liu",
      "Guanbin Li",
      "Xiang Wan",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07098"
  },
  {
    "id": "arXiv:2209.07100",
    "title": "Concurrent Size",
    "abstract": "The size of a data structure (i.e., the number of elements in it) is a widely\nused property of a data set. However, for concurrent programs, obtaining a\ncorrect size efficiently is non-trivial. In fact, the literature does not offer\na mechanism to obtain a correct (linearizable) size of a concurrent data set\nwithout resorting to inefficient solutions, such as taking a full snapshot of\nthe data structure to count the elements, or acquiring one global lock in all\nupdate and size operations. This paper presents a methodology for adding a\nconcurrent linearizable size operation to sets and dictionaries with a\nrelatively low performance overhead. Theoretically, the proposed size operation\nis wait-free with asymptotic complexity linear in the number of threads\n(independently of data-structure size). Practically, we evaluated the\nperformance overhead by adding size to various concurrent data structures in\nJava$-$a skip list, a hash table and a tree. The proposed linearizable size\noperation executes faster by orders of magnitude compared to the existing\noption of taking a snapshot, while incurring a throughput loss of $1\\%-20\\%$ on\nthe original data structure's operations.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Gal Sela",
      "Erez Petrank"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07100"
  },
  {
    "id": "arXiv:2209.07105",
    "title": "Bridging Implicit and Explicit Geometric Transformations for  Single-Image View Synthesis",
    "abstract": "Creating novel views from a single image has achieved tremendous strides with\nadvanced autoregressive models. Although recent methods generate high-quality\nnovel views, synthesizing with only one explicit or implicit 3D geometry has a\ntrade-off between two objectives that we call the ``seesaw'' problem: 1)\npreserving reprojected contents and 2) completing realistic out-of-view\nregions. Also, autoregressive models require a considerable computational cost.\nIn this paper, we propose a single-image view synthesis framework for\nmitigating the seesaw problem. The proposed model is an efficient\nnon-autoregressive model with implicit and explicit renderers. Motivated by\ncharacteristics that explicit methods well preserve reprojected pixels and\nimplicit methods complete realistic out-of-view region, we introduce a loss\nfunction to complement two renderers. Our loss function promotes that explicit\nfeatures improve the reprojected area of implicit features and implicit\nfeatures improve the out-of-view area of explicit features. With the proposed\narchitecture and loss function, we can alleviate the seesaw problem,\noutperforming autoregressive-based state-of-the-art methods and generating an\nimage $\\approx$100 times faster. We validate the efficiency and effectiveness\nof our method with experiments on RealEstate10K and ACID datasets.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Byeongjun Park",
      "Hyojun Go",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07105"
  },
  {
    "id": "arXiv:2209.07108",
    "title": "Asymptotically preserving particle methods for strongly  magnetizedplasmas in a torus",
    "abstract": "We propose and analyze a class of particle methods for the Vlasov equation\nwith a strong external magnetic field in a torus configuration. In this regime,\nthe time step can be subject to stability constraints related to the smallness\nof Larmor radius. To avoid this limitation, our approach is based on\nhigher-order semi-implicit numerical schemes already validated on dissipative\nsystems [3] and for magnetic fields pointing in a fixed direction [9, 10, 12].\nIt hinges on asymptotic insights gained in [11] at the continuous level. Thus,\nwhen the magnitude of the external magnetic field is large, this scheme\nprovides a consistent approximation of the guiding-center system taking into\naccount curvature and variation of the magnetic field. Finally, we carry out a\ntheoretical proof of consistency and perform several numerical experiments that\nestablish a solid validation of the method and its underlying concepts.",
    "descriptor": "",
    "authors": [
      "Francis Filbet",
      "Luis Miguel Miguel Rodrigues"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07108"
  },
  {
    "id": "arXiv:2209.07115",
    "title": "LAVOLUTION: Measurement of Non-target Structural Displacement Calibrated  by Structured Light",
    "abstract": "Displacement is an important measurement for the assessment of structural\nconditions, but its field measurement is often hindered by difficulties\nassociated with sensor installation and measurement accuracy. To overcome the\ndisadvantages of conventional displacement measurement, computer vision\n(CV)-based methods have been implemented due to their remote sensing\ncapabilities and accuracy. This paper presents a strategy for non-target\nstructural displacement measurement that makes use of CV to avoid the need to\ninstall a target on the structure while calibrating the displacement using\nstructured light. The proposed system called as LAVOLUTION calculates the\nrelative position of the camera with regard to the structure using four equally\nspaced beams of structured light and obtains a scale factor to convert pixel\nmovement into structural displacement. A jig for the four beams of structured\nlight is designed and a corresponding alignment process is proposed. A method\nfor calculating the scale factor using the designed jig for tunable\nstructured-light is proposed and validated via numerical simulations and\nlab-scale experiments. To confirm the feasibility of the proposed displacement\nmeasurement process, experiments on a shaking table and a full-scale bridge are\nconducted and the accuracy of the proposed method is compared with that of a\nreference laser doppler vibrometer.",
    "descriptor": "\nComments: 27 pages, 12 figures, 3 tables\n",
    "authors": [
      "Jongbin Won",
      "Minhyuk Song",
      "Gunhee Kim",
      "Jong-Woong Park",
      "Haemin Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07115"
  },
  {
    "id": "arXiv:2209.07116",
    "title": "Decentralized Learning with Separable Data: Generalization and Fast  Algorithms",
    "abstract": "Decentralized learning offers privacy and communication efficiency when data\nare naturally distributed among agents communicating over an underlying graph.\nMotivated by overparameterized learning settings, in which models are trained\nto zero training loss, we study algorithmic and generalization properties of\ndecentralized learning with gradient descent on separable data. Specifically,\nfor decentralized gradient descent (DGD) and a variety of loss functions that\nasymptote to zero at infinity (including exponential and logistic losses), we\nderive novel finite-time generalization bounds. This complements a long line of\nrecent work that studies the generalization performance and the implicit bias\nof gradient descent over separable data, but has thus far been limited to\ncentralized learning scenarios. Notably, our generalization bounds match in\norder their centralized counterparts. Critical behind this, and of independent\ninterest, is establishing novel bounds on the training loss and the\nrate-of-consensus of DGD for a class of self-bounded losses. Finally, on the\nalgorithmic front, we design improved gradient-based routines for decentralized\nlearning with separable data and empirically demonstrate orders-of-magnitude of\nspeed-up in terms of both training and generalization performance.",
    "descriptor": "",
    "authors": [
      "Hossein Taheri",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.07116"
  },
  {
    "id": "arXiv:2209.07118",
    "title": "Align, Reason and Learn: Enhancing Medical Vision-and-Language  Pre-training with Knowledge",
    "abstract": "Medical vision-and-language pre-training (Med-VLP) has received considerable\nattention owing to its applicability to extracting generic vision-and-language\nrepresentations from medical images and texts. Most existing methods mainly\ncontain three elements: uni-modal encoders (i.e., a vision encoder and a\nlanguage encoder), a multi-modal fusion module, and pretext tasks, with few\nstudies considering the importance of medical domain expert knowledge and\nexplicitly exploiting such knowledge to facilitate Med-VLP. Although there\nexist knowledge-enhanced vision-and-language pre-training (VLP) methods in the\ngeneral domain, most require off-the-shelf toolkits (e.g., object detectors and\nscene graph parsers), which are unavailable in the medical domain. In this\npaper, we propose a systematic and effective approach to enhance Med-VLP by\nstructured medical knowledge from three perspectives. First, considering\nknowledge can be regarded as the intermediate medium between vision and\nlanguage, we align the representations of the vision encoder and the language\nencoder through knowledge. Second, we inject knowledge into the multi-modal\nfusion model to enable the model to perform reasoning using knowledge as the\nsupplementation of the input image and text. Third, we guide the model to put\nemphasis on the most critical information in images and texts by designing\nknowledge-induced pretext tasks. To perform a comprehensive evaluation and\nfacilitate further research, we construct a medical vision-and-language\nbenchmark including three tasks. Experimental results illustrate the\neffectiveness of our approach, where state-of-the-art performance is achieved\non all downstream tasks. Further analyses explore the effects of different\ncomponents of our approach and various settings of pre-training.",
    "descriptor": "\nComments: Natural Language Processing. 10 pages, 3 figures\n",
    "authors": [
      "Zhihong Chen",
      "Guanbin Li",
      "Xiang Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07118"
  },
  {
    "id": "arXiv:2209.07121",
    "title": "4DenoiseNet: Adverse Weather Denoising from Adjacent Point Clouds",
    "abstract": "Reliable point cloud data is essential for perception tasks \\textit{e.g.} in\nrobotics and autonomous driving applications. Adverse weather causes a specific\ntype of noise to light detection and ranging (LiDAR) sensor data, which\ndegrades the quality of the point clouds significantly. To address this issue,\nthis letter presents a novel point cloud adverse weather denoising deep\nlearning algorithm (4DenoiseNet). Our algorithm takes advantage of the time\ndimension unlike deep learning adverse weather denoising methods in the\nliterature. It performs about 10\\% better in terms of intersection over union\nmetric compared to the previous work and is more computationally efficient.\nThese results are achieved on our novel SnowyKITTI dataset, which has over\n40000 adverse weather annotated point clouds. Moreover, strong qualitative\nresults on the Canadian Adverse Driving Conditions dataset indicate good\ngeneralizability to domain shifts and to different sensor intrinsics.",
    "descriptor": "",
    "authors": [
      "Alvari Sepp\u00e4nen",
      "Risto Ojala",
      "Kari Tammi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07121"
  },
  {
    "id": "arXiv:2209.07124",
    "title": "How Much Does It Cost to Train a Machine Learning Model over Distributed  Data Sources?",
    "abstract": "Federated learning (FL) is one of the most appealing alternatives to the\nstandard centralized learning paradigm, allowing heterogeneous set of devices\nto train a machine learning model without sharing their raw data. However, FL\nrequires a central server to coordinate the learning process, thus introducing\npotential scalability and security issues. In the literature, server-less FL\napproaches like gossip federated learning (GFL) and blockchain-enabled\nfederated learning (BFL) have been proposed to mitigate these issues. In this\nwork, we propose a complete overview of these three techniques proposing a\ncomparison according to an integral set of performance indicators, including\nmodel accuracy, time complexity, communication overhead, convergence time and\nenergy consumption. An extensive simulation campaign permits to draw a\nquantitative analysis. In particular, GFL is able to save the 18% of training\ntime, the 68% of energy and the 51% of data to be shared with respect to the\nCFL solution, but it is not able to reach the level of accuracy of CFL. On the\nother hand, BFL represents a viable solution for implementing decentralized\nlearning with a higher level of security, at the cost of an extra energy usage\nand data sharing. Finally, we identify open issues on the two decentralized\nfederated learning implementations and provide insights on potential extensions\nand possible research directions on this new research field.",
    "descriptor": "",
    "authors": [
      "Elia Guerra",
      "Francesc Wilhelmi",
      "Marco Miozzo",
      "Paolo Dini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07124"
  },
  {
    "id": "arXiv:2209.07125",
    "title": "BadRes: Reveal the Backdoors through Residual Connection",
    "abstract": "Generally, residual connections are indispensable network components in\nbuilding CNNs and Transformers for various downstream tasks in CV and VL, which\nencourages skip shortcuts between network blocks. However, the layer-by-layer\nloopback residual connections may also hurt the model's robustness by allowing\nunsuspecting input. In this paper, we proposed a simple yet strong backdoor\nattack method - BadRes, where the residual connections play as a turnstile to\nbe deterministic on clean inputs while unpredictable on poisoned ones. We have\nperformed empirical evaluations on four datasets with ViT and BEiT models, and\nthe BadRes achieves 97% attack success rate while receiving zero performance\ndegradation on clean data. Moreover, we analyze BadRes with state-of-the-art\ndefense methods and reveal the fundamental weakness lying in residual\nconnections.",
    "descriptor": "\nComments: 16pages, 9 figures\n",
    "authors": [
      "Mingrui He",
      "Tianyu Chen",
      "Haoyi Zhou",
      "Shanghang Zhang",
      "Jianxin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.07125"
  },
  {
    "id": "arXiv:2209.07126",
    "title": "Forgetting to Remember: A Scalable Incremental Learning Framework for  Cross-Task Blind Image Quality Assessment",
    "abstract": "Recent years have witnessed the great success of blind image quality\nassessment (BIQA) in various task-specific scenarios, which present invariable\ndistortion types and evaluation criteria. However, due to the rigid structure\nand learning framework, they cannot apply to the cross-task BIQA scenario,\nwhere the distortion types and evaluation criteria keep changing in practical\napplications. This paper proposes a scalable incremental learning framework\n(SILF) that could sequentially conduct BIQA across multiple evaluation tasks\nwith limited memory capacity. More specifically, we develop a dynamic parameter\nisolation strategy to sequentially update the task-specific parameter subsets,\nwhich are non-overlapped with each other. Each parameter subset is temporarily\nsettled to Remember one evaluation preference toward its corresponding task,\nand the previously settled parameter subsets can be adaptively reused in the\nfollowing BIQA to achieve better performance based on the task relevance. To\nsuppress the unrestrained expansion of memory capacity in sequential tasks\nlearning, we develop a scalable memory unit by gradually and selectively\npruning unimportant neurons from previously settled parameter subsets, which\nenable us to Forget part of previous experiences and free the limited memory\ncapacity for adapting to the emerging new tasks. Extensive experiments on\neleven IQA datasets demonstrate that our proposed method significantly\noutperforms the other state-of-the-art methods in cross-task BIQA.",
    "descriptor": "",
    "authors": [
      "Rui Ma",
      "Qingbo Wu",
      "King N. Ngan",
      "Hongliang Li",
      "Fanman Meng",
      "Linfeng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.07126"
  },
  {
    "id": "arXiv:2209.07131",
    "title": "Technical Report: The effect of Input Parameters on Falsification of  Cyber-Physical Systems",
    "abstract": "The aim of this technical report is to investigate the effect of input\nparameters on the falsification of cyber-physical systems (CPSs).",
    "descriptor": "",
    "authors": [
      "Zahra Ramezani",
      "Knut \u00c5kesson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07131"
  },
  {
    "id": "arXiv:2209.07133",
    "title": "COOL-MC: A Comprehensive Tool for Reinforcement Learning and Model  Checking",
    "abstract": "This paper presents COOL-MC, a tool that integrates state-of-the-art\nreinforcement learning (RL) and model checking. Specifically, the tool builds\nupon the OpenAI gym and the probabilistic model checker Storm. COOL-MC provides\nthe following features: (1) a simulator to train RL policies in the OpenAI gym\nfor Markov decision processes (MDPs) that are defined as input for Storm, (2) a\nnew model builder for Storm, which uses callback functions to verify (neural\nnetwork) RL policies, (3) formal abstractions that relate models and policies\nspecified in OpenAI gym or Storm, and (4) algorithms to obtain bounds on the\nperformance of so-called permissive policies. We describe the components and\narchitecture of COOL-MC and demonstrate its features on multiple benchmark\nenvironments.",
    "descriptor": "",
    "authors": [
      "Dennis Gross",
      "Nils Jansen",
      "Sebastian Junges",
      "Guillermo A. Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.07133"
  },
  {
    "id": "arXiv:2209.07136",
    "title": "Locally recoverable codes from towers of function fields",
    "abstract": "In this work we construct sequences of locally recoverable AG codes arising\nfrom a tower of function fields and give bound for the parameters of the\nobtained codes. In a particular case of a tower over $\\mathbb{F}_{q^2}$ for any\nodd $q$, defined by Garcia and Stichtenoth in [GS2007], we show that the bound\nis sharp for the first code in the sequence, and we include a detailed analysis\nfor the following codes in the sequence based on the distribution of rational\nplaces that split completely in the considered function field extension.",
    "descriptor": "",
    "authors": [
      "M. Chara",
      "F. Galluccio",
      "E. Mart\u00ednez-Moro"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2209.07136"
  },
  {
    "id": "arXiv:2209.07138",
    "title": "Self-Healing Secure Blockchain Framework in Microgrids",
    "abstract": "Blockchain has recently been depicted as a secure protocol for information\nexchange in cyber-physical microgrids. However, it is still found vulnerable\nagainst consensus-manipulation attacks. These stealth attacks are often\ndifficult to detect as they use kernel-level access to mask their actions. In\nthis paper, we firstly build a trusted and secured peer-to-peer network\nmechanism for physical DC microgrids' validation of transactions over\nDistributed Ledger. Secondly, we leverage from a physics-informed approach for\ndetecting malware-infected nodes and then recovering from these stealth attacks\nusing a self-healing recovery scheme augmented into the microgrid Blockchain\nnetwork. This scheme allows compromised nodes to adapt to a reconstructed\ntrustworthy signal in a multi-hop manner using corresponding measurements from\nthe reliable nodes in the network. This supplements the capabilities of\nBlockchain enabling it to detect and mitigate consensus manipulation attempts.",
    "descriptor": "\nComments: IEEE Transactions Submission\n",
    "authors": [
      "Suman Rath",
      "Lam Duc Nguyen",
      "Subham Sahoo",
      "Petar Popovski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07138"
  },
  {
    "id": "arXiv:2209.07139",
    "title": "The Impact of Edge Displacement Vaserstein Distance on UD Parsing  Performance",
    "abstract": "We contribute to the discussion on parsing performance in NLP by introducing\na measurement that evaluates the differences between the distributions of edge\ndisplacement (the directed distance of edges) seen in training and test data.\nWe hypothesize that this measurement will be related to differences observed in\nparsing performance across treebanks. We motivate this by building upon\nprevious work and then attempt to falsify this hypothesis by using a number of\nstatistical methods. We establish that there is a statistical correlation\nbetween this measurement and parsing performance even when controlling for\npotential covariants. We then use this to establish a sampling technique that\ngives us an adversarial and complementary split. This gives an idea of the\nlower and upper bounds of parsing systems for a given treebank in lieu of\nfreshly sampled data. In a broader sense, the methodology presented here can\nact as a reference for future correlation-based exploratory work in NLP.",
    "descriptor": "\nComments: This is the final peer-reviewed manuscript accepted for publication in Computational Linguistics. The journal version with the final editorial and typesetting changes is available open-access at this https URL\n",
    "authors": [
      "Mark Anderson",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07139"
  },
  {
    "id": "arXiv:2209.07140",
    "title": "Beat Transformer: Demixed Beat and Downbeat Tracking with Dilated  Self-Attention",
    "abstract": "We propose Beat Transformer, a novel Transformer encoder architecture for\njoint beat and downbeat tracking. Different from previous models that track\nbeats solely based on the spectrogram of an audio mixture, our model deals with\ndemixed spectrograms with multiple instrument channels. This is inspired by the\nfact that humans perceive metrical structures from richer musical contexts,\nsuch as chord progression and instrumentation. To this end, we develop a\nTransformer model with both time-wise attention and instrument-wise attention\nto capture deep-buried metrical cues. Moreover, our model adopts a novel\ndilated self-attention mechanism, which achieves powerful hierarchical\nmodelling with only linear complexity. Experiments demonstrate a significant\nimprovement in demixed beat tracking over the non-demixed version. Also, Beat\nTransformer achieves up to 4% point improvement in downbeat tracking accuracy\nover the TCN architectures. We further discover an interpretable attention\npattern that mirrors our understanding of hierarchical metrical structures.",
    "descriptor": "\nComments: Accepted by ISMIR 2022\n",
    "authors": [
      "Jingwei Zhao",
      "Gus Xia",
      "Ye Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.07140"
  },
  {
    "id": "arXiv:2209.07143",
    "title": "HARP: Autoregressive Latent Video Prediction with High-Fidelity Image  Generator",
    "abstract": "Video prediction is an important yet challenging problem; burdened with the\ntasks of generating future frames and learning environment dynamics. Recently,\nautoregressive latent video models have proved to be a powerful video\nprediction tool, by separating the video prediction into two sub-problems:\npre-training an image generator model, followed by learning an autoregressive\nprediction model in the latent space of the image generator. However,\nsuccessfully generating high-fidelity and high-resolution videos has yet to be\nseen. In this work, we investigate how to train an autoregressive latent video\nprediction model capable of predicting high-fidelity future frames with minimal\nmodification to existing models, and produce high-resolution (256x256) videos.\nSpecifically, we scale up prior models by employing a high-fidelity image\ngenerator (VQ-GAN) with a causal transformer model, and introduce additional\ntechniques of top-k sampling and data augmentation to further improve video\nprediction quality. Despite the simplicity, the proposed method achieves\ncompetitive performance to state-of-the-art approaches on standard video\nprediction benchmarks with fewer parameters, and enables high-resolution video\nprediction on complex and large-scale datasets. Videos are available at\nhttps://sites.google.com/view/harp-videos/home.",
    "descriptor": "\nComments: Extended draft of the paper accepted to ICIP 2022 conference\n",
    "authors": [
      "Younggyo Seo",
      "Kimin Lee",
      "Fangchen Liu",
      "Stephen James",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07143"
  },
  {
    "id": "arXiv:2209.07144",
    "title": "Domain Adversarial Training on Conditional Variational Auto-Encoder for  Controllable Music Generation",
    "abstract": "The variational auto-encoder has become a leading framework for symbolic\nmusic generation, and a popular research direction is to study how to\neffectively control the generation process. A straightforward way is to control\na model using different conditions during inference. However, in music\npractice, conditions are usually sequential (rather than simple categorical\nlabels), involving rich information that overlaps with the learned\nrepresentation. Consequently, the decoder gets confused about whether to\n\"listen to\" the latent representation or the condition, and sometimes just\nignores the condition. To solve this problem, we leverage domain adversarial\ntraining to disentangle the representation from condition cues for better\ncontrol. Specifically, we propose a condition corruption objective that uses\nthe representation to denoise a corrupted condition. Minimized by a\ndiscriminator and maximized by the VAE encoder, this objective adversarially\ninduces a condition-invariant representation. In this paper, we focus on the\ntask of melody harmonization to illustrate our idea, while our methodology can\nbe generalized to other controllable generative tasks. Demos and experiments\nshow that our methodology facilitates not only condition-invariant\nrepresentation learning but also higher-quality controllability compared to\nbaselines.",
    "descriptor": "\nComments: Accepted by ISMIR 2022\n",
    "authors": [
      "Jingwei Zhao",
      "Gus Xia",
      "Ye Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.07144"
  },
  {
    "id": "arXiv:2209.07147",
    "title": "One-Shot Transfer of Affordance Regions? AffCorrs!",
    "abstract": "In this work, we tackle one-shot visual search of object parts. Given a\nsingle reference image of an object with annotated affordance regions, we\nsegment semantically corresponding parts within a target scene. We propose\nAffCorrs, an unsupervised model that combines the properties of pre-trained\nDINO-ViT's image descriptors and cyclic correspondences. We use AffCorrs to\nfind corresponding affordances both for intra- and inter-class one-shot part\nsegmentation. This task is more difficult than supervised alternatives, but\nenables future work such as learning affordances via imitation and assisted\nteleoperation.",
    "descriptor": "\nComments: Published in Conference on Robot Learning, 2022 For code and dataset, refer to this https URL\n",
    "authors": [
      "Denis Hadjivelichkov",
      "Sicelukwanda Zwane",
      "Marc Deisenroth",
      "Lourdes Agapito",
      "Dimitrios Kanoulas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07147"
  },
  {
    "id": "arXiv:2209.07148",
    "title": "Semi-Counterfactual Risk Minimization Via Neural Networks",
    "abstract": "Counterfactual risk minimization is a framework for offline policy\noptimization with logged data which consists of context, action, propensity\nscore, and reward for each sample point. In this work, we build on this\nframework and propose a learning method for settings where the rewards for some\nsamples are not observed, and so the logged data consists of a subset of\nsamples with unknown rewards and a subset of samples with known rewards. This\nsetting arises in many application domains, including advertising and\nhealthcare. While reward feedback is missing for some samples, it is possible\nto leverage the unknown-reward samples in order to minimize the risk, and we\nrefer to this setting as semi-counterfactual risk minimization. To approach\nthis kind of learning problem, we derive new upper bounds on the true risk\nunder the inverse propensity score estimator. We then build upon these bounds\nto propose a regularized counterfactual risk minimization method, where the\nregularization term is based on the logged unknown-rewards dataset only; hence\nit is reward-independent. We also propose another algorithm based on generating\npseudo-rewards for the logged unknown-rewards dataset. Experimental results\nwith neural networks and benchmark datasets indicate that these algorithms can\nleverage the logged unknown-rewards dataset besides the logged known-reward\ndataset.",
    "descriptor": "\nComments: Accepted in EWRL 2022\n",
    "authors": [
      "Gholamali Aminian",
      "Roberto Vega",
      "Omar Rivasplata",
      "Laura Toni",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.07148"
  },
  {
    "id": "arXiv:2209.07157",
    "title": "On the detrimental effect of invariances in the likelihood for  variational inference",
    "abstract": "Variational Bayesian posterior inference often requires simplifying\napproximations such as mean-field parametrisation to ensure tractability.\nHowever, prior work has associated the variational mean-field approximation for\nBayesian neural networks with underfitting in the case of small datasets or\nlarge model sizes. In this work, we show that invariances in the likelihood\nfunction of over-parametrised models contribute to this phenomenon because\nthese invariances complicate the structure of the posterior by introducing\ndiscrete and/or continuous modes which cannot be well approximated by Gaussian\nmean-field distributions. In particular, we show that the mean-field\napproximation has an additional gap in the evidence lower bound compared to a\npurpose-built posterior that takes into account the known invariances.\nImportantly, this invariance gap is not constant; it vanishes as the\napproximation reverts to the prior. We proceed by first considering translation\ninvariances in a linear model with a single data point in detail. We show that,\nwhile the true posterior can be constructed from a mean-field parametrisation,\nthis is achieved only if the objective function takes into account the\ninvariance gap. Then, we transfer our analysis of the linear model to neural\nnetworks. Our analysis provides a framework for future work to explore\nsolutions to the invariance problem.",
    "descriptor": "",
    "authors": [
      "Richard Kurle",
      "Ralf Herbrich",
      "Tim Januschowski",
      "Yuyang Wang",
      "Jan Gasthaus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07157"
  },
  {
    "id": "arXiv:2209.07163",
    "title": "Morphology-Aware Interactive Keypoint Estimation",
    "abstract": "Diagnosis based on medical images, such as X-ray images, often involves\nmanual annotation of anatomical keypoints. However, this process involves\nsignificant human efforts and can thus be a bottleneck in the diagnostic\nprocess. To fully automate this procedure, deep-learning-based methods have\nbeen widely proposed and have achieved high performance in detecting keypoints\nin medical images. However, these methods still have clinical limitations:\naccuracy cannot be guaranteed for all cases, and it is necessary for doctors to\ndouble-check all predictions of models. In response, we propose a novel deep\nneural network that, given an X-ray image, automatically detects and refines\nthe anatomical keypoints through a user-interactive system in which doctors can\nfix mispredicted keypoints with fewer clicks than needed during manual\nrevision. Using our own collected data and the publicly available AASCE\ndataset, we demonstrate the effectiveness of the proposed method in reducing\nthe annotation costs via extensive quantitative and qualitative results. A demo\nvideo of our approach is available on our project webpage.",
    "descriptor": "\nComments: MICCAI 2022. The first two authors contributed equally. The last two authors are the co-corresponding authors\n",
    "authors": [
      "Jinhee Kim",
      "Taesung Kim",
      "Taewoo Kim",
      "Jaegul Choo",
      "Dong-Wook Kim",
      "Byungduk Ahn",
      "In-Seok Song",
      "Yoon-Ji Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07163"
  },
  {
    "id": "arXiv:2209.07164",
    "title": "Challenges and Opportunities of Machine Learning for Monitoring and  Operational Data Analytics in Quantitative Codesign of Supercomputers",
    "abstract": "This work examines the challenges and opportunities of Machine Learning (ML)\nfor Monitoring and Operational Data Analytics (MODA) in the context of\nQuantitative Codesign of Supercomputers (QCS). MODA is employed to gain\ninsights into the behavior of current High Performance Computing (HPC) systems\nto improve system efficiency, performance, and reliability (e.g. through\noptimizing cooling infrastructure, job scheduling, and application parameter\ntuning). In this work, we take the position that QCS in general, and MODA in\nparticular, require close exchange with the ML community to realize the full\npotential of data-driven analysis for the benefit of existing and future HPC\nsystems. This exchange will facilitate identifying the appropriate ML methods\nto gain insights into current HPC systems and to go beyond expert-based\nknowledge and rules of thumb.",
    "descriptor": "",
    "authors": [
      "Thomas Jakobsche",
      "Nicolas Lachiche",
      "Florina M. Ciorba"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.07164"
  },
  {
    "id": "arXiv:2209.07171",
    "title": "Learning to Exploit Elastic Actuators for Quadruped Locomotion",
    "abstract": "Spring-based actuators in legged locomotion provide energy-efficiency and\nimproved performance, but increase the difficulty of controller design. Whereas\nprevious works have focused on extensive modeling and simulation to find\noptimal controllers for such systems, we propose to learn model-free\ncontrollers directly on the real robot. In our approach, gaits are first\nsynthesized by central pattern generators (CPGs), whose parameters are\noptimized to quickly obtain an open-loop controller that achieves efficient\nlocomotion. Then, to make that controller more robust and further improve the\nperformance, we use reinforcement learning to close the loop, to learn\ncorrective actions on top of the CPGs. We evaluate the proposed approach in\nDLR's elastic quadruped bert. Our results in learning trotting and pronking\ngaits show that exploitation of the spring actuator dynamics emerges naturally\nfrom optimizing for dynamic motions, yielding high-performing locomotion\ndespite being model-free. The whole process takes no more than 1.5 hours on the\nreal robot and results in natural-looking gaits.",
    "descriptor": "",
    "authors": [
      "Antonin Raffin",
      "Daniel Seidel",
      "Jens Kober",
      "Alin Albu-Sch\u00e4ffer",
      "Jo\u00e3o Silv\u00e9rio",
      "Freek Stulp"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07171"
  },
  {
    "id": "arXiv:2209.07172",
    "title": "Two case studies on implementing best practices for Software Process  Improvement",
    "abstract": "Software Process Improvement requires significant effort related not only to\nthe identification of relevant issues and providing an adequate response to\nthem but also to the implementation and adoption of the changes. Best practices\nprovide recommendations to software teams on how to address the identified\nobjectives in practice, based on aggregated experience and knowledge. In the\npaper, we present the GEANT experience and observations from the process of\nadopting the best practices and present the setting we have been using.",
    "descriptor": "",
    "authors": [
      "Bartosz Walter",
      "Branko Marovic",
      "Ivan Garnizov",
      "Marcin Wolski",
      "Andrijana Todosijevic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07172"
  },
  {
    "id": "arXiv:2209.07175",
    "title": "Literature Review of various Fuzzy Rule based Systems",
    "abstract": "Fuzzy rule based systems (FRBSs) is a rule-based system which uses linguistic\nfuzzy variables as antecedents and consequent to represent the human\nunderstandable knowledge. They have been applied to various applications and\nareas throughout the literature. However, FRBSs suffers from many drawbacks\nsuch as uncertainty representation, high number of rules, interpretability\nloss, high computational time for learning etc. To overcome these issues with\nFRBSs, there exists many extentions of FRBSs. In this paper, we present an\noverview and literature review for various types and prominent areas of fuzzy\nsystems (FRBSs) namely genetic fuzzy system (GFS), Hierarchical fuzzy system\n(HFS), neuro fuzzy system (NFS), evolving fuzzy system (eFS), FRBSs for big\ndata, FRBSs for imbalanced data, interpretability in FRBSs and FRBSs which uses\ncluster centroids as fuzzy rule, during the years 2010-2021. GFS uses\ngenetic/evolutionary approaches to improve the learning ability of FRBSs, HFS\nsolve the curse of dimensionality for FRBSs, NFS improves approximation ability\nof FRBSs using neural networks and dynamic systems for streaming data is\nconsidered in eFS. FRBSs are seen as good solutions for big data and imbalanced\ndata, in the recent years the interpretability in FRBSs has gained popularity\ndue to high dimensional and big data and rules are initialized with cluster\ncentroids to limit the number of rules in FRBSs. This paper also highlights\nimportant contributions, publication statistics and current trends in the\nfield. The paper also addresses several open research areas which need further\nattention from the FRBSs research community.",
    "descriptor": "\nComments: 46 pages, not peer-reviewed\n",
    "authors": [
      "Ayush K. Varshney",
      "Vicen\u00e7 Torra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07175"
  },
  {
    "id": "arXiv:2209.07190",
    "title": "Adaptive Fairness Improvement Based on Causality Analysis",
    "abstract": "Given a discriminating neural network, the problem of fairness improvement is\nto systematically reduce discrimination without significantly scarifies its\nperformance (i.e., accuracy). Multiple categories of fairness improving methods\nhave been proposed for neural networks, including pre-processing, in-processing\nand post-processing. Our empirical study however shows that these methods are\nnot always effective (e.g., they may improve fairness by paying the price of\nhuge accuracy drop) or even not helpful (e.g., they may even worsen both\nfairness and accuracy). In this work, we propose an approach which adaptively\nchooses the fairness improving method based on causality analysis. That is, we\nchoose the method based on how the neurons and attributes responsible for\nunfairness are distributed among the input attributes and the hidden neurons.\nOur experimental evaluation shows that our approach is effective (i.e., always\nidentify the best fairness improving method) and efficient (i.e., with an\naverage time overhead of 5 minutes).",
    "descriptor": "\nComments: 12 pages, 8 figures, published in ESEC/FSE 2022\n",
    "authors": [
      "Mengdi Zhang",
      "Jun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07190"
  },
  {
    "id": "arXiv:2209.07199",
    "title": "Landmark Management in the Application of Radar SLAM",
    "abstract": "This paper focuses on efficient landmark management in radar based\nsimultaneous localization and mapping (SLAM). Landmark management is necessary\nin order to maintain a consistent map of the estimated landmarks relative to\nthe estimate of the platform's pose. This task is particularly important when\nfaced with multiple detections from the same landmark and/or dynamic\nenvironments where the location of a landmark can change. A further challenge\nwith radar data is the presence of false detections. Accordingly, we propose a\nsimple yet efficient rule based solution for radar SLAM landmark management.\nAssuming a low-dynamic environment, there are several steps in our solution:\nnew landmarks need to be detected and included, false landmarks need to be\nidentified and removed, and the consistency of the landmarks registered in the\nmap needs to be maintained. To illustrate our solution, we run an extended\nKalman filter SLAM algorithm in an environment containing both stationary and\ntemporally stationary landmarks. Our simulation results demonstrate that the\nproposed solution is capable of reliably managing landmarks even when faced\nwith false detections and multiple detections from the same landmark.",
    "descriptor": "\nComments: 8 pages, 5 figures, 2 tables, submitted to 2022 APSIPA Annual Summit & Conference\n",
    "authors": [
      "Shuai Sun",
      "Beth Jelfs",
      "Kamran Ghorbani",
      "Glenn Matthews",
      "Christopher Gilliam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.07199"
  },
  {
    "id": "arXiv:2209.07202",
    "title": "Dizzy: Large-Scale Crawling and Analysis of Onion Services",
    "abstract": "With nearly 2.5m users, onion services have become the prominent part of the\ndarkweb. Over the last five years alone, the number of onion domains has\nincreased 20x, reaching more than 700k unique domains in January 2022. As onion\nservices host various types of illicit content, they have become a valuable\nresource for darkweb research and an integral part of e-crime investigation and\nthreat intelligence. However, this content is largely un-indexed by today's\nsearch engines and researchers have to rely on outdated or manually-collected\ndatasets that are limited in scale, scope, or both.\nTo tackle this problem, we built Dizzy: An open-source crawling and analysis\nsystem for onion services. Dizzy implements novel techniques to explore,\nupdate, check, and classify hidden services at scale, without overwhelming the\nTor network. We deployed Dizzy in April 2021 and used it to analyze more than\n63.3m crawled onion webpages, focusing on domain operations, web content,\ncryptocurrency usage, and web graph. Our main findings show that onion services\nare unreliable due to their high churn rate, have a relatively small number of\nreachable domains that are often similar and illicit, enjoy a growing\nunderground cryptocurrency economy, and have a topologically different graph\nstructure than the regular web.",
    "descriptor": "",
    "authors": [
      "Isuranga Perera",
      "Yazan Boshmaf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07202"
  },
  {
    "id": "arXiv:2209.07204",
    "title": "Ein Beitrag zur durchg\u00e4ngigen, formalen Verhaltensspezifikation  automatisierter Stra\u00dfenfahrzeuge",
    "abstract": "Assuring safety of automated vehicles (SAE Level 3+) requires specifying and\nvalidating the behavior of such a vehicle in its operational environment. In\norder to argue and support assumptions that are made during the behavior\nspecification within scenarios, a traceable documentation of design decisions\nis required. With the introduction of the \\textit{semantic norm behavior\nanalysis} a method is proposed, which contributes to a traceable mapping of\nconcerns towards the behavior of an automated vehicle in its operational\nenvironment to a formal rule system of semantic concepts for considered\nscenarios. In this work, a semantic norm behavior analysis is conducted in two\nselected example scenarios. Thereby, an example of the formalization of\nbehavioral rules from an excerpt of the German traffic code is given.\n--\nDie Absicherung automatisierter Stra{\\ss}enfahrzeuge (SAE Level 3+) setzt die\nSpezifikation und \\\"Uberpr\\\"ufung des Verhaltens eines Fahrzeugs in seiner\nBetriebsumgebung voraus. Um Annahmen, welche bei der Verhaltensspezifikation\ninnerhalb von Szenarien getroffen werden, begr\\\"unden und belegen zu k\\\"onnen,\nist eine durchg\\\"angige Dokumentation dieser Entwurfsentscheidungen\nerforderlich. Mit der Einf\\\"uhrung der \\textit{semantischen\nNormverhaltensanalyse} wird eine Methode vorgeschlagen, mithilfe derer\nAnspr\\\"uche an das Verhalten eines automatisierten Fahrzeugs in seiner\nBetriebsumgebung durchg\\\"angig auf ein formales Regelsystem aus semantischen\nKonzepten f\\\"ur ausgew\\\"ahlte Szenarien abgebildet werden k\\\"onnen. Eine\nsemantische Normverhaltensanalyse wird in dieser Arbeit in zwei ausgew\\\"ahlten\nSzenarien durchgef\\\"uhrt. Hierf\\\"ur werden Verhaltensregeln aus einem Auszug\nder Stra{\\ss}enverkehrsordnung exemplarisch formalisiert.",
    "descriptor": "\nComments: 25 pages, 8 figures, in German\n",
    "authors": [
      "Nayel Fabian Salem",
      "Veronica Haber",
      "Matthias Rauschenbach",
      "Marcus Nolte",
      "Jan Reich",
      "Torben Stolte",
      "Robert Graubohm",
      "Markus Maurer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07204"
  },
  {
    "id": "arXiv:2209.07206",
    "title": "Encrypted distributed state estimation via affine averaging",
    "abstract": "Distributed state estimation arises in many applications such as position\nestimation in robot swarms, clock synchronization for processor networks, and\ndata fusion. One characteristic is that agents only have access to noisy\nmeasurements of deviations between their own and neighboring states. Still,\nestimations of their actual state can be obtained in a fully distributed manner\nusing algorithms such as affine averaging. However, running this algorithm,\nrequires that the agents exchange their current state estimations, which can be\na privacy issue (since they eventually reveal the actual states). To counteract\nthis threat, we propose an encrypted version of the affine averaging algorithm\nin this paper. More precisely, we use homomorphic encryption to realize an\nencrypted implementation, where only one ``leader'' agent has access to its\nstate estimation in plaintext. One main challenge (which often arises for\nrecursive encrypted computations) is to prevent overflow w.r.t.~the bounded\nmessage space of the cryptosystem. We solve this problem by periodically\nresetting the agents' states with the help of the leader. We study the\nresulting system dynamics with respect to different reset strategies and\nsupport our findings with extensive numerical simulations.",
    "descriptor": "",
    "authors": [
      "N. Schl\u00fcter",
      "P. Binfet",
      "J. Kim",
      "M. Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07206"
  },
  {
    "id": "arXiv:2209.07211",
    "title": "On the acceptance by code reviewers of candidate security patches  suggested by Automated Program Repair tools",
    "abstract": "\\textbf{Background:} Testing and validation of the semantic correctness of\npatches provided by tools for Automated Program Repairs (APR) has received a\nlot of attention. Yet, the eventual acceptance or rejection of suggested\npatches for real world projects by humans patch reviewers has received a\nlimited attention.\\\\ \\textbf{Objective:} To address this issue, we plan to\ninvestigate whether (possibly incorrect) security patches suggested by APR\ntools are recognized by human reviewers. We also want to investigate whether\nknowing that a patch was produced by an allegedly specialized tool does change\nthe decision of human reviewers. \\\\ \\textbf{Method:} In the first phase, using\na balanced design, we propose to human reviewers a combination of patches\nproposed by APR tools for different vulnerabilities and ask reviewers to adopt\nor reject the proposed patches. In the second phase, we tell participants that\nsome of the proposed patches were generated by security specialized tools (even\nif the tool was actually a `normal' APR tool) and measure whether the human\nreviewers would change their decision to adopt or reject a patch.\\\\\n\\textbf{Limitations:} The experiment will be conducted in an academic setting,\nand to maintain power, it will focus on a limited sample of popular APR tools\nand popular vulnerability types.",
    "descriptor": "",
    "authors": [
      "Aurora Papotti",
      "Ranindya Paramitha",
      "Fabio Massacci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07211"
  },
  {
    "id": "arXiv:2209.07214",
    "title": "Are Deep Learning-Generated Social Media Profiles Indistinguishable from  Real Profiles?",
    "abstract": "In recent years, deep learning methods have become increasingly capable of\ngenerating near photorealistic pictures and humanlike text up to the point that\nhumans can no longer recognize what is real and what is AI-generated.\nConcerningly, there is evidence that some of these methods have already been\nadopted to produce fake social media profiles and content. We hypothesize that\nthese advances have made detecting generated fake social media content in the\nfeed extremely difficult, if not impossible, for the average user of social\nmedia. This paper presents the results of an experiment where 375 participants\nattempted to label real and generated profiles and posts in a simulated social\nmedia feed. The results support our hypothesis and suggest that even\nfully-generated fake profiles with posts written by an advanced text generator\nare difficult for humans to identify.",
    "descriptor": "\nComments: This paper has been accepted for the upcoming 56th Hawaii International Conference on System Sciences (HICSS-56)\n",
    "authors": [
      "Sippo Rossi",
      "Youngjin Kwon",
      "Odd Harald Auglend",
      "Raghava Rao Mukkamala",
      "Matti Rossi",
      "Jason Thatcher"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07214"
  },
  {
    "id": "arXiv:2209.07215",
    "title": "ProAPT: Projection of APT Threats with Deep Reinforcement Learning",
    "abstract": "The highest level in the Endsley situation awareness model is called\nprojection when the status of elements in the environment in the near future is\npredicted. In cybersecurity situation awareness, the projection for an Advanced\nPersistent Threat (APT) requires predicting the next step of the APT. The\nthreats are constantly changing and becoming more complex. As supervised and\nunsupervised learning methods require APT datasets for projecting the next step\nof APTs, they are unable to identify unknown APT threats. In reinforcement\nlearning methods, the agent interacts with the environment, and so it might\nproject the next step of known and unknown APTs. So far, reinforcement learning\nhas not been used to project the next step for APTs. In reinforcement learning,\nthe agent uses the previous states and actions to approximate the best action\nof the current state. When the number of states and actions is abundant, the\nagent employs a neural network which is called deep learning to approximate the\nbest action of each state. In this paper, we present a deep reinforcement\nlearning system to project the next step of APTs. As there exists some relation\nbetween attack steps, we employ the Long- Short-Term Memory (LSTM) method to\napproximate the best action of each state. In our proposed system, based on the\ncurrent situation, we project the next steps of APT threats.",
    "descriptor": "",
    "authors": [
      "Motahareh Dehghan",
      "Babak Sadeghiyan",
      "Erfan Khosravian",
      "Alireza Sedighi Moghaddam",
      "Farshid Nooshi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07215"
  },
  {
    "id": "arXiv:2209.07216",
    "title": "TempoWiC: An Evaluation Benchmark for Detecting Meaning Shift in Social  Media",
    "abstract": "Language evolves over time, and word meaning changes accordingly. This is\nespecially true in social media, since its dynamic nature leads to faster\nsemantic shifts, making it challenging for NLP models to deal with new content\nand trends. However, the number of datasets and models that specifically\naddress the dynamic nature of these social platforms is scarce. To bridge this\ngap, we present TempoWiC, a new benchmark especially aimed at accelerating\nresearch in social media-based meaning shift. Our results show that TempoWiC is\na challenging benchmark, even for recently-released language models specialized\nin social media.",
    "descriptor": "\nComments: Accepted to COLING 2022. Used to create the TempoWiC Shared Task for EvoNLP\n",
    "authors": [
      "Daniel Loureiro",
      "Aminette D'Souza",
      "Areej Nasser Muhajab",
      "Isabella A. White",
      "Gabriel Wong",
      "Luis Espinosa Anke",
      "Leonardo Neves",
      "Francesco Barbieri",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07216"
  },
  {
    "id": "arXiv:2209.07219",
    "title": "Training Neural Networks in Single vs Double Precision",
    "abstract": "The commitment to single-precision floating-point arithmetic is widespread in\nthe deep learning community. To evaluate whether this commitment is justified,\nthe influence of computing precision (single and double precision) on the\noptimization performance of the Conjugate Gradient (CG) method (a second-order\noptimization algorithm) and RMSprop (a first-order algorithm) has been\ninvestigated. Tests of neural networks with one to five fully connected hidden\nlayers and moderate or strong nonlinearity with up to 4 million network\nparameters have been optimized for Mean Square Error (MSE). The training tasks\nhave been set up so that their MSE minimum was known to be zero. Computing\nexperiments have disclosed that single-precision can keep up (with superlinear\nconvergence) with double-precision as long as line search finds an improvement.\nFirst-order methods such as RMSprop do not benefit from double precision.\nHowever, for moderately nonlinear tasks, CG is clearly superior. For strongly\nnonlinear tasks, both algorithm classes find only solutions fairly poor in\nterms of mean square error as related to the output variance. CG with double\nfloating-point precision is superior whenever the solutions have the potential\nto be useful for the application goal.",
    "descriptor": "",
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Siegfried Handschuh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07219"
  },
  {
    "id": "arXiv:2209.07220",
    "title": "Face Shape-Guided Deep Feature Alignment for Face Recognition Robust to  Face Misalignment",
    "abstract": "For the past decades, face recognition (FR) has been actively studied in\ncomputer vision and pattern recognition society. Recently, due to the advances\nin deep learning, the FR technology shows high performance for most of the\nbenchmark datasets. However, when the FR algorithm is applied to a real-world\nscenario, the performance has been known to be still unsatisfactory. This is\nmainly attributed to the mismatch between training and testing sets. Among such\nmismatches, face misalignment between training and testing faces is one of the\nfactors that hinder successful FR. To address this limitation, we propose a\nface shape-guided deep feature alignment framework for FR robust to the face\nmisalignment. Based on a face shape prior (e.g., face keypoints), we train the\nproposed deep network by introducing alignment processes, i.e., pixel and\nfeature alignments, between well-aligned and misaligned face images. Through\nthe pixel alignment process that decodes the aggregated feature extracted from\na face image and face shape prior, we add the auxiliary task to reconstruct the\nwell-aligned face image. Since the aggregated features are linked to the face\nfeature extraction network as a guide via the feature alignment process, we\ntrain the robust face feature to the face misalignment. Even if the face shape\nestimation is required in the training stage, the additional face alignment\nprocess, which is usually incorporated in the conventional FR pipeline, is not\nnecessarily needed in the testing phase. Through the comparative experiments,\nwe validate the effectiveness of the proposed method for the face misalignment\nwith the FR datasets.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Hyung-Il Kim",
      "Kimin Yun",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07220"
  },
  {
    "id": "arXiv:2209.07221",
    "title": "Number of Attention Heads vs Number of Transformer-Encoders in Computer  Vision",
    "abstract": "Determining an appropriate number of attention heads on one hand and the\nnumber of transformer-encoders, on the other hand, is an important choice for\nComputer Vision (CV) tasks using the Transformer architecture. Computing\nexperiments confirmed the expectation that the total number of parameters has\nto satisfy the condition of overdetermination (i.e., number of constraints\nsignificantly exceeding the number of parameters). Then, good generalization\nperformance can be expected. This sets the boundaries within which the number\nof heads and the number of transformers can be chosen. If the role of context\nin images to be classified can be assumed to be small, it is favorable to use\nmultiple transformers with a low number of heads (such as one or two). In\nclassifying objects whose class may heavily depend on the context within the\nimage (i.e., the meaning of a patch being dependent on other patches), the\nnumber of heads is equally important as that of transformers.",
    "descriptor": "",
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Siegfried Handschuh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07221"
  },
  {
    "id": "arXiv:2209.07223",
    "title": "Conceptual Modeling of the Whole-Part Relationship",
    "abstract": "Conceptual models rely on structural information to describe relationships\namong UML classes; among these, the whole-part (WP) relationship plays a\nfundamental role. This paper explores and analyzes the WP semantics at large\nwith a focus on its software engineering use. The WP relationship has often\nbeen treated as a first-class modeling construct in object-oriented analysis, a\nsubject of keen interest and it is considered important for UML modeling. From\nthe scientific and philosophical aspects, a theory of parts forming a whole is\na complex issue, loaded with controversies that are widely discussed. This\npaper aims to offer a semantic assembly model that is useful to describe WP\nrelationships in conceptual modeling. We contribute to the WP research by\nconducting an ontological analysis using UML samples that exemplify the WP\nconstruct. The method of investigation is based on a model called a thinging\nmachine (TM) to explore the WP semantics through applying TM to numerous\nexisting UML models. The TM model uses the so-called thimacs (things/machines)\nto form building blocks for describing the domain at a three levels of\ndescription: static, events, and behavioral models. This approach contrasts the\nUML method, which is infected by a multiplicity problem concerning the\nintegrated view of structure and behavior and how to associate diagrams with\none another. This investigation s results point to a promising contribution to\nthe understanding of the notion of WP relationship in UML.",
    "descriptor": "\nComments: 12 pages, 36 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07223"
  },
  {
    "id": "arXiv:2209.07224",
    "title": "Towards Interoperability of Open and Permissionless Blockchains: A  Cross-Chain Query Language",
    "abstract": "The rise of open and permissionless blockchains has introduced novel\nplatforms for applications based on distributed data storage. At the\napplication and business levels, long-established query languages such as SQL\nprovide interoperability that can be complemented by blockchain-based data\nstorage today, enabling permissionless and verifiable data storage along with\ndecentralized execution across tens of thousands of nodes. However, when\naccessing one or more blockchains, interoperability is not provided today,\nposing challenges such as inhomogeneous data access in addition to different\nfeatures and trade-offs, e.g. in data and distribution, scalability, and\nsecurity. Towards interoperability in data access among the increasing number\nof blockchain platforms, this paper introduces a cross-chain query language for\ndata access across blockchains. Similar to SQL, the language abstracts from\nimplementation based on a data model compatible with the largest open and\npermissionless blockchains (OPB) today. The language, data model, and\nprocessing architecture are demonstrated and evaluated with an implemented\nprototype, aiming to contribute to the discussion on blockchain\ninteroperability among OPB.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Felix H\u00e4rer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.07224"
  },
  {
    "id": "arXiv:2209.07225",
    "title": "MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via  Mixing Recurrent Soft Decision Trees",
    "abstract": "Multi-agent reinforcement learning (MARL) recently has achieved tremendous\nsuccess in a wide range of fields. However, with a black-box neural network\narchitecture, existing MARL methods make decisions in an opaque fashion that\nhinders humans from understanding the learned knowledge and how input\nobservations influence decisions. Our solution is MIXing Recurrent soft\ndecision Trees (MIXRTs), a novel interpretable architecture that can represent\nexplicit decision processes via the root-to-leaf path of decision trees. We\nintroduce a novel recurrent structure in soft decision trees to address partial\nobservability, and estimate joint action values via linearly mixing outputs of\nrecurrent trees based on local observations only. Theoretical analysis shows\nthat MIXRTs guarantees the structural constraint with additivity and\nmonotonicity in factorization. We evaluate MIXRTs on a range of challenging\nStarCraft II tasks. Experimental results show that our interpretable learning\nframework obtains competitive performance compared to widely investigated\nbaselines, and delivers more straightforward explanations and domain knowledge\nof the decision processes.",
    "descriptor": "",
    "authors": [
      "Zichuan Liu",
      "Yuanyang Zhu",
      "Zhi Wang",
      "Chunlin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.07225"
  },
  {
    "id": "arXiv:2209.07228",
    "title": "Joint Trajectory and Resource Optimization of MEC-Assisted UAVs in  Sub-THz Networks: A Resources-based Multi-Agent Proximal Policy Optimization  DRL with Attention Mechanism",
    "abstract": "THz band communication technology will be used in the 6G networks to enable\nhigh-speed and high-capacity data service demands. However, THz-communication\nlosses arise owing to limitations, i.e., molecular absorption, rain\nattenuation, and coverage range. Furthermore, to maintain steady\nTHz-communications and overcome coverage distances in rural and suburban\nregions, the required number of BSs is very high. Consequently, a new\ncommunication platform that enables aerial communication services is required.\nFurthermore, the airborne platform supports LoS communications rather than NLoS\ncommunications, which helps overcome these losses. Therefore, in this work, we\ninvestigate the deployment and resource optimization for MEC-enabled UAVs,\nwhich can provide THz-based communications in remote regions. To this end, we\nformulate an optimization problem to minimize the sum of the energy consumption\nof both MEC-UAV and MUs and the delay incurred by MUs under the given task\ninformation. The formulated problem is a MINLP problem, which is NP-hard. We\ndecompose the main problem into two subproblems to address the formulated\nproblem. We solve the first subproblem with a standard optimization solver,\ni.e., CVXPY, due to its convex nature. To solve the second subproblem, we\ndesign a RMAPPO DRL algorithm with an attention mechanism. The considered\nattention mechanism is utilized for encoding a diverse number of observations.\nThis is designed by the network coordinator to provide a differentiated fit\nreward to each agent in the network. The simulation results show that the\nproposed algorithm outperforms the benchmark and yields a network utility which\nis $2.22\\%$, $15.55\\%$, and $17.77\\%$ more than the benchmarks.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Yu Min Park",
      "Sheikh Salman Hassan",
      "Yan Kyaw Tun",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.07228"
  },
  {
    "id": "arXiv:2209.07233",
    "title": "Towards Spatial Multiplexing in Wireless Networks within Computing  Packages",
    "abstract": "Wireless Networks-on-Chip (WNoCs) are regarded as a disruptive alternative to\nconventional interconnection networks at the chip scale, yet limited by the\nrelatively low aggregate bandwidth of such wireless networks. Hence, any method\nto increase the amount of concurrent channels in this scenario is of high\nvalue. In this direction, and since WNoC implies close integration of multiple\nantennas on a chip anyway, in this paper we present a feasibility study of\ncompact monopole antenna arrays in a flip-chip environment at millimeter-wave\nand sub-terahertz frequencies. By means of a full-wave solver, we evaluate the\nfeasibility to create, at will, concentrations of field in different spots of\nthe chip. This way, we set the steps towards spatial multiplexing that enables\nconcurrent multicast communications and also increases the aggregate bandwidth\nof the wireless network. Our results at 60 GHz show two clearly separable\nparallel channels that radiate simultaneously from two opposite corners of the\nchip, achieving a Signal-to-Interference Ratio (SIR) of around 40 dB, which\nproves that the channels are independent of each other even in such an enclosed\nenvironment. Further, we see potential to expand our approach to three or more\nconcurrent channels, and to frequencies beyond 100 GHz.",
    "descriptor": "",
    "authors": [
      "F\u00e1tima Rodr\u00edguez-Gal\u00e1n",
      "Elana Pereira de Santana",
      "Peter Haring Bol\u00edvar",
      "Sergi Abadal",
      "Eduard Alarc\u00f3n"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2209.07233"
  },
  {
    "id": "arXiv:2209.07235",
    "title": "Sound and Complete Verification of Polynomial Networks",
    "abstract": "Polynomial Networks (PNs) have demonstrated promising performance on face and\nimage recognition recently. However, robustness of PNs is unclear and thus\nobtaining certificates becomes imperative for enabling their adoption in\nreal-world applications. Existing verification algorithms on ReLU neural\nnetworks (NNs) based on branch and bound (BaB) techniques cannot be trivially\napplied to PN verification. In this work, we devise a new bounding method,\nequipped with BaB for global convergence guarantees, called VPN. One key\ninsight is that we obtain much tighter bounds than the interval bound\npropagation baseline. This enables sound and complete PN verification with\nempirical validation on MNIST, CIFAR10 and STL10 datasets. We believe our\nmethod has its own interest to NN verification.",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Elias Abad Rocamora",
      "Mehmet Fatih Sahin",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.07235"
  },
  {
    "id": "arXiv:2209.07237",
    "title": "Robust Implementation of Foreground Extraction and Vessel Segmentation  for X-ray Coronary Angiography Image Sequence",
    "abstract": "The extraction of contrast-filled vessels from X-ray coronary\nangiography(XCA) image sequence has important clinical significance for\nintuitively diagnosis and therapy. In this study, XCA image sequence O is\nregarded as a three-dimensional tensor input, vessel layer H is a sparse\ntensor, and background layer B is a low-rank tensor. Using tensor nuclear\nnorm(TNN) minimization, a novel method for vessel layer extraction based on\ntensor robust principal component analysis(TRPCA) is proposed. Furthermore,\nconsidering the irregular movement of vessels and the dynamic interference of\nsurrounding irrelevant tissues, the total variation(TV) regularized\nspatial-temporal constraint is introduced to separate the dynamic background E.\nSubsequently, for the vessel images with uneven contrast distribution, a\ntwo-stage region growth(TSRG) method is utilized for vessel enhancement and\nsegmentation. A global threshold segmentation is used as the pre-processing to\nobtain the main branch, and the Radon-Like features(RLF) filter is used to\nenhance and connect broken minor segments, the final vessel mask is constructed\nby combining the two intermediate results. We evaluated the visibility of\nTV-TRPCA algorithm for foreground extraction and the accuracy of TSRG algorithm\nfor vessel segmentation on real clinical XCA image sequences and third-party\ndatabase. Both qualitative and quantitative results verify the superiority of\nthe proposed methods over the existing state-of-the-art approaches.",
    "descriptor": "\nComments: 18pages, 8figures, Under review for Medical Image Analysis\n",
    "authors": [
      "Zeyu Fu",
      "Zhuang Fu",
      "Chenzhuo Lv",
      "Jun Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07237"
  },
  {
    "id": "arXiv:2209.07238",
    "title": "Generalization Properties of NAS under Activation and Skip Connection  Search",
    "abstract": "Neural Architecture Search (NAS) has fostered the automatic discovery of\nneural architectures, which achieve state-of-the-art accuracy in image\nrecognition. Despite the progress achieved with NAS, so far there is little\nattention to theoretical guarantees on NAS. In this work, we study the\ngeneralization properties of NAS under a unifying framework enabling (deep)\nlayer skip connection search and activation function search. To this end, we\nderive the lower (and upper) bounds of the minimum eigenvalue of Neural Tangent\nKernel under the (in)finite width regime from a search space including mixed\nactivation functions, fully connected, and residual neural networks. Our\nanalysis is non-trivial due to the coupling of various architectures and\nactivation functions under the unifying framework. Then, we leverage the\neigenvalue bounds to establish generalization error bounds of NAS in the\nstochastic gradient descent training. Importantly, we theoretically and\nexperimentally show how the derived results can guide NAS to select the\ntop-performing architectures, even in the case without training, leading to a\ntraining-free algorithm based on our theory. Accordingly, our numerical\nvalidation shed light on the design of computationally efficient methods for\nNAS.",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07238"
  },
  {
    "id": "arXiv:2209.07239",
    "title": "UBARv2: Towards Mitigating Exposure Bias in Task-Oriented Dialogs",
    "abstract": "This paper studies the exposure bias problem in task-oriented dialog systems,\nwhere the model's generated content over multiple turns drives the dialog\ncontext away from the ground-truth distribution at training time, introducing\nerror propagation and damaging the robustness of the TOD system. To bridge the\ngap between training and inference for multi-turn task-oriented dialogs, we\npropose session-level sampling which explicitly exposes the model to sampled\ngenerated content of dialog context during training. Additionally, we employ a\ndropout-based consistency regularization with the masking strategy R-Mask to\nfurther improve the robustness and performance of the model. The proposed\nUBARv2 achieves state-of-the-art performance on the standardized evaluation\nbenchmark MultiWOZ and extensive experiments show the effectiveness of the\nproposed methods.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Yunyi Yang",
      "Hong Ding",
      "Qingyi Liu",
      "Xiaojun Quan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07239"
  },
  {
    "id": "arXiv:2209.07240",
    "title": "Neural Stochastic Control",
    "abstract": "Control problems are always challenging since they arise from the real-world\nsystems where stochasticity and randomness are of ubiquitous presence. This\nnaturally and urgently calls for developing efficient neural control policies\nfor stabilizing not only the deterministic equations but the stochastic systems\nas well. Here, in order to meet this paramount call, we propose two types of\ncontrollers, viz., the exponential stabilizer (ES) based on the stochastic\nLyapunov theory and the asymptotic stabilizer (AS) based on the stochastic\nasymptotic stability theory. The ES can render the controlled systems\nexponentially convergent but it requires a long computational time; conversely,\nthe AS makes the training much faster but it can only assure the asymptotic\n(not the exponential) attractiveness of the control targets. These two\nstochastic controllers thus are complementary in applications. We also\ninvestigate rigorously the linear controller and the proposed neural stochastic\ncontrollers in both convergence time and energy cost and numerically compare\nthem in these two indexes. More significantly, we use several representative\nphysical systems to illustrate the usefulness of the proposed controllers in\nstabilization of dynamical systems.",
    "descriptor": "\nComments: 9 pages, 9 figures, NeurIPS 2022\n",
    "authors": [
      "Jingdong Zhang",
      "Qunxi Zhu",
      "Wei Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2209.07240"
  },
  {
    "id": "arXiv:2209.07243",
    "title": "Inequalities for entropies and dimensions",
    "abstract": "We show that linear inequalities for entropies have a natural geometric\ninterpretation in terms of Hausdorff and packing dimensions, using the\npoint-to-set principle and known results about inequalities for complexities,\nentropies and the sizes of subgroups.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Alexander Shen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2209.07243"
  },
  {
    "id": "arXiv:2209.07244",
    "title": "Linear Transformations for Cross-lingual Sentiment Analysis",
    "abstract": "This paper deals with cross-lingual sentiment analysis in Czech, English and\nFrench languages. We perform zero-shot cross-lingual classification using five\nlinear transformations combined with LSTM and CNN based classifiers. We compare\nthe performance of the individual transformations, and in addition, we confront\nthe transformation-based approach with existing state-of-the-art BERT-like\nmodels. We show that the pre-trained embeddings from the target domain are\ncrucial to improving the cross-lingual classification results, unlike in the\nmonolingual classification, where the effect is not so distinctive.",
    "descriptor": "\nComments: Accepted to TSD 2022\n",
    "authors": [
      "Pavel P\u0159ib\u00e1\u0148",
      "Jakub \u0160m\u00edd",
      "Adam Mi\u0161tera",
      "Pavel Kr\u00e1l"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07244"
  },
  {
    "id": "arXiv:2209.07245",
    "title": "Efficient first-order predictor-corrector multiple objective  optimization for fair misinformation detection",
    "abstract": "Multiple-objective optimization (MOO) aims to simultaneously optimize\nmultiple conflicting objectives and has found important applications in machine\nlearning, such as minimizing classification loss and discrepancy in treating\ndifferent populations for fairness. At optimality, further optimizing one\nobjective will necessarily harm at least another objective, and decision-makers\nneed to comprehensively explore multiple optima (called Pareto front) to\npinpoint one final solution. We address the efficiency of finding the Pareto\nfront. First, finding the front from scratch using stochastic multi-gradient\ndescent (SMGD) is expensive with large neural networks and datasets. We propose\nto explore the Pareto front as a manifold from a few initial optima, based on a\npredictor-corrector method. Second, for each exploration step, the predictor\nsolves a large-scale linear system that scales quadratically in the number of\nmodel parameters and requires one backpropagation to evaluate a second-order\nHessian-vector product per iteration of the solver. We propose a Gauss-Newton\napproximation that only scales linearly, and that requires only first-order\ninner-product per iteration. This also allows for a choice between the MINRES\nand conjugate gradient methods when approximately solving the linear system.\nThe innovations make predictor-corrector possible for large networks.\nExperiments on multi-objective (fairness and accuracy) misinformation detection\ntasks show that 1) the predictor-corrector method can find Pareto fronts better\nthan or similar to SMGD with less time; and 2) the proposed first-order method\ndoes not harm the quality of the Pareto front identified by the second-order\nmethod, while further reduce running time.",
    "descriptor": "",
    "authors": [
      "Eric Enouen",
      "Katja Mathesius",
      "Sean Wang",
      "Arielle Carr",
      "Sihong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07245"
  },
  {
    "id": "arXiv:2209.07246",
    "title": "On-line Identification of Photovoltaic Arrays' Dynamic Model Parameters",
    "abstract": "This paper deals with the problem of on-line identification of the parameters\nof a realistic dynamical model of a photovoltaic array connected to a power\nsystem through a power converter. It has been shown in the literature that,\nwhen interacting with switching devices, this model is able to better account\nfor the PV array operation, as compared to the classical five parameter static\nmodel of the array. While there are many results of identification of the\nparameters of the latter model, to the best of our knowledge, no one has\nprovided a solution for the aforementioned more complex dynamic model since it\nconcerns the parameter estimation of a nonlinear, underexcited system with\nunmeasurable state variables. Achieving such objective is the main contribution\nof the paper. We propose a new parameterisation of the dynamic model, which,\ncombined with the powerful identification technique of dynamic regressor\nextension and mixing, ensures a fast and accurate online estimation of the\nunknown parameters. Realistic numerical examples via computer simulations are\npresented to assess the performance of the proposed approach -- even being able\nto track the parameter variations when the system changes operating point.",
    "descriptor": "",
    "authors": [
      "Alexey Bobtsov",
      "Fernando Mancilla-David",
      "Stanislav Aranovskiy",
      "Romeo Ortega"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07246"
  },
  {
    "id": "arXiv:2209.07250",
    "title": "Answering Count Questions with Structured Answers from Text",
    "abstract": "In this work we address the challenging case of answering count queries in\nweb search, such as ``number of songs by John Lennon''. Prior methods merely\nanswer these with a single, and sometimes puzzling number or return a ranked\nlist of text snippets with different numbers. This paper proposes a methodology\nfor answering count queries with inference, contextualization and explanatory\nevidence. Unlike previous systems, our method infers final answers from\nmultiple observations, supports semantic qualifiers for the counts, and\nprovides evidence by enumerating representative instances. Experiments with a\nwide variety of queries, including existing benchmark show the benefits of our\nmethod, and the influence of specific parameter settings. Our code, data and an\ninteractive system demonstration are publicly available at\nhttps://github.com/ghoshs/CoQEx and https://nlcounqer.mpi-inf.mpg.de/.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.05039\n",
    "authors": [
      "Shrestha Ghosh",
      "Simon Razniewski",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.07250"
  },
  {
    "id": "arXiv:2209.07252",
    "title": "2.5D Mapping, Pathfinding and Path Following For Navigation Of A  Differential Drive Robot In Uneven Terrain",
    "abstract": "Safe navigation in uneven terrains is an important problem in robotic\nresearch. In this paper we propose a 2.5D navigation system which consists of\nelevation map building, path planning and local path following with obstacle\navoidance. For local path following we use Model Predictive Path Integral\n(MPPI) control method. We propose novel cost-functions for MPPI in order to\nadapt it to elevation maps and motion through unevenness. We evaluate our\nsystem on multiple synthetic tests and in a simulated environment with\ndifferent types of obstacles and rough surfaces.",
    "descriptor": "\nComments: This is a preprint of the paper accepted to IFAC SYROCO'21/22. It contains 6 pages, 4 figures and 2 tables. The supplementary video available at this https URL\n",
    "authors": [
      "Stepan Dergachev",
      "Kirill Muravyev",
      "Konstantin Yakovlev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07252"
  },
  {
    "id": "arXiv:2209.07258",
    "title": "Graph-to-Text Generation with Dynamic Structure Pruning",
    "abstract": "Most graph-to-text works are built on the encoder-decoder framework with\ncross-attention mechanism. Recent studies have shown that explicitly modeling\nthe input graph structure can significantly improve the performance. However,\nthe vanilla structural encoder cannot capture all specialized information in a\nsingle forward pass for all decoding steps, resulting in inaccurate semantic\nrepresentations. Meanwhile, the input graph is flatted as an unordered sequence\nin the cross attention, ignoring the original graph structure. As a result, the\nobtained input graph context vector in the decoder may be flawed. To address\nthese issues, we propose a Structure-Aware Cross-Attention (SACA) mechanism to\nre-encode the input graph representation conditioning on the newly generated\ncontext at each decoding step in a structure aware manner. We further adapt\nSACA and introduce its variant Dynamic Graph Pruning (DGP) mechanism to\ndynamically drop irrelevant nodes in the decoding process. We achieve new\nstate-of-the-art results on two graph-to-text datasets, LDC2020T02 and\nENT-DESC, with only minor increase on computational cost.",
    "descriptor": "\nComments: accepted by COLING2022 Oral\n",
    "authors": [
      "Liang Li",
      "Ruiying Geng",
      "Bowen Li",
      "Can Ma",
      "Yinliang Yue",
      "Binhua Li",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07258"
  },
  {
    "id": "arXiv:2209.07263",
    "title": "Robustness in deep learning: The good (width), the bad (depth), and the  ugly (initialization)",
    "abstract": "We study the average robustness notion in deep neural networks in (selected)\nwide and narrow, deep and shallow, as well as lazy and non-lazy training\nsettings. We prove that in the under-parameterized setting, width has a\nnegative effect while it improves robustness in the over-parameterized setting.\nThe effect of depth closely depends on the initialization and the training\nmode. In particular, when initialized with LeCun initialization, depth helps\nrobustness with lazy training regime. In contrast, when initialized with Neural\nTangent Kernel (NTK) and He-initialization, depth hurts the robustness.\nMoreover, under non-lazy training regime, we demonstrate how the width of a\ntwo-layer ReLU network benefits robustness. Our theoretical developments\nimprove the results by Huang et al. [2021], Wu et al. [2021] and are consistent\nwith Bubeck and Sellke [2021], Bubeck et al. [2021].",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07263"
  },
  {
    "id": "arXiv:2209.07266",
    "title": "The power of random information for numerical approximation and  integration",
    "abstract": "This thesis investigates the quality of randomly collected data by employing\na framework built on information-based complexity, a field related to the\nnumerical analysis of abstract problems. The quality or power of gathered\ninformation is measured by its radius which is the uniform error obtainable by\nthe best possible algorithm using it. The main aim is to present progress\ntowards understanding the power of random information for approximation and\nintegration problems.",
    "descriptor": "\nComments: Phd thesis, University of Passau (2022), 165 pages. Based on arXiv:1907.06435, arXiv:2009.11275, arXiv:2010.04522, arXiv:2109.14504\n",
    "authors": [
      "Mathias Sonnleitner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2209.07266"
  },
  {
    "id": "arXiv:2209.07267",
    "title": "Compressed Particle-Based Federated Bayesian Learning and Unlearning",
    "abstract": "Conventional frequentist FL schemes are known to yield overconfident\ndecisions. Bayesian FL addresses this issue by allowing agents to process and\nexchange uncertainty information encoded in distributions over the model\nparameters. However, this comes at the cost of a larger per-iteration\ncommunication overhead. This letter investigates whether Bayesian FL can still\nprovide advantages in terms of calibration when constraining communication\nbandwidth. We present compressed particle-based Bayesian FL protocols for FL\nand federated \"unlearning\" that apply quantization and sparsification across\nmultiple particles. The experimental results confirm that the benefits of\nBayesian FL are robust to bandwidth constraints.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Jinu Gong",
      "Osvaldo Simeone",
      "Joonhyuk Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.07267"
  },
  {
    "id": "arXiv:2209.07268",
    "title": "AssembleRL: Learning to Assemble Furniture from Their Point Clouds",
    "abstract": "The rise of simulation environments has enabled learning-based approaches for\nassembly planning, which is otherwise a labor-intensive and daunting task.\nAssembling furniture is especially interesting since furniture are intricate\nand pose challenges for learning-based approaches. Surprisingly, humans can\nsolve furniture assembly mostly given a 2D snapshot of the assembled product.\nAlthough recent years have witnessed promising learning-based approaches for\nfurniture assembly, they assume the availability of correct connection labels\nfor each assembly step, which are expensive to obtain in practice. In this\npaper, we alleviate this assumption and aim to solve furniture assembly with as\nlittle human expertise and supervision as possible. To be specific, we assume\nthe availability of the assembled point cloud, and comparing the point cloud of\nthe current assembly and the point cloud of the target product, obtain a novel\nreward signal based on two measures: Incorrectness and incompleteness. We show\nthat our novel reward signal can train a deep network to successfully assemble\ndifferent types of furniture. Code and networks available here:\nhttps://github.com/METU-KALFA/AssembleRL",
    "descriptor": "\nComments: 6 pages, 6 figures, iros2022\n",
    "authors": [
      "\u00d6zg\u00fcr Aslan",
      "Burak Bolat",
      "Batuhan Bal",
      "Tu\u011fba T\u00fcmer",
      "Erol \u015eahin",
      "Sinan Kalkan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07268"
  },
  {
    "id": "arXiv:2209.07271",
    "title": "Revisiting Crowd Counting: State-of-the-art, Trends, and Future  Perspectives",
    "abstract": "Crowd counting is an effective tool for situational awareness in public\nplaces. Automated crowd counting using images and videos is an interesting yet\nchallenging problem that has gained significant attention in computer vision.\nOver the past few years, various deep learning methods have been developed to\nachieve state-of-the-art performance. The methods evolved over time vary in\nmany aspects such as model architecture, input pipeline, learning paradigm,\ncomputational complexity, and accuracy gains etc. In this paper, we present a\nsystematic and comprehensive review of the most significant contributions in\nthe area of crowd counting. Although few surveys exist on the topic, our survey\nis most up-to date and different in several aspects. First, it provides a more\nmeaningful categorization of the most significant contributions by model\narchitectures, learning methods (i.e., loss functions), and evaluation methods\n(i.e., evaluation metrics). We chose prominent and distinct works and excluded\nsimilar works. We also sort the well-known crowd counting models by their\nperformance over benchmark datasets. We believe that this survey can be a good\nresource for novice researchers to understand the progressive developments and\ncontributions over time and the current state-of-the-art.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Muhammad Asif Khan",
      "Hamid Menouar",
      "Ridha Hamila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07271"
  },
  {
    "id": "arXiv:2209.07272",
    "title": "Socially Enhanced Situation Awareness from Microblogs using Artificial  Intelligence: A Survey",
    "abstract": "The rise of social media platforms provides an unbounded, infinitely rich\nsource of aggregate knowledge of the world around us, both historic and\nreal-time, from a human perspective. The greatest challenge we face is how to\nprocess and understand this raw and unstructured data, go beyond individual\nobservations and see the \"big picture\"--the domain of Situation Awareness. We\nprovide an extensive survey of Artificial Intelligence research, focusing on\nmicroblog social media data with applications to Situation Awareness, that\ngives the seminal work and state-of-the-art approaches across six thematic\nareas: Crime, Disasters, Finance, Physical Environment, Politics, and Health\nand Population. We provide a novel, unified methodological perspective,\nidentify key results and challenges, and present ongoing research directions.",
    "descriptor": "\nComments: Accepted to ACM Computing Surveys (CSUR) 2022\n",
    "authors": [
      "Rabindra Lamsal",
      "Aaron Harwood",
      "Maria Rodriguez Read"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07272"
  },
  {
    "id": "arXiv:2209.07274",
    "title": "Introducing Grid WAR: Rethinking WAR for Starting Pitchers",
    "abstract": "Traditional methods of computing WAR (wins above replacement) for pitchers\nare based on an invalid mathematical foundation. Consequently, these metrics,\nwhich produce reasonable values for many pitchers, can be substantially\ninaccurate for some. Specifically, FanGraphs and Baseball Reference compute a\npitcher's WAR as a function of his performance averaged over the entire season.\nThis is wrong because WAR must be a convex function of the number of runs\nallowed by the pitcher in a game. Hence we propose a new way to compute WAR for\nstarting pitchers: Grid WAR (GWAR). The idea is to compute a starter's GWAR for\neach of his individual games, and define a starter's seasonal GWAR as the sum\nof the GWAR of each of his games. We show that GWAR is indeed a convex function\nin the number of runs allowed during a game. As such, GWAR accounts for a\nfundamental baseball principle that not all runs allowed have the same impact\nin determining the outcome of a game: for instance, the difference in GWAR\nbetween allowing 1 run in a game instead of 0 is much greater than the\ndifference in GWAR between allowing 6 runs in a game instead of 5. Moreover,\nJensen's inequality implies that, by ignoring the convexity of WAR, current\nimplementations of WAR undervalue certain pitchers, particularly those who\nallow few runs (specifically, 0 or 1 run) in many games. It also unfairly\npenalizes pitchers who are credited with a large number of runs in a short\nouting. These flaws are corrected by GWAR.",
    "descriptor": "",
    "authors": [
      "Ryan S. Brill",
      "Abraham J. Wyner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.07274"
  },
  {
    "id": "arXiv:2209.07278",
    "title": "\u00daFAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for  Coreference Resolution",
    "abstract": "We describe the winning submission to the CRAC 2022 Shared Task on\nMultilingual Coreference Resolution. Our system first solves mention detection\nand then coreference linking on the retrieved spans with an\nantecedent-maximization approach, and both tasks are fine-tuned jointly with\nshared Transformer weights. We report results of fine-tuning a wide range of\npretrained models. The center of this contribution are fine-tuned multilingual\nmodels. We found one large multilingual model with sufficiently large encoder\nto increase performance on all datasets across the board, with the benefit not\nlimited only to the underrepresented languages or groups of typologically\nrelative languages. The source code is available at\nhttps://github.com/ufal/crac2022-corpipe.",
    "descriptor": "\nComments: Accepted to CRAC 2022 (Fifth Workshop on Computational Models of Reference, Anaphora and Coreference)\n",
    "authors": [
      "Milan Straka",
      "Jana Strakov\u00e1"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07278"
  },
  {
    "id": "arXiv:2209.07282",
    "title": "MDE for Machine Learning-Enabled Software Systems: A Case Study and  Comparison of MontiAnna & ML-Quadrat",
    "abstract": "In this paper, we propose to adopt the MDE paradigm for the development of\nMachine Learning (ML)-enabled software systems with a focus on the Internet of\nThings (IoT) domain. We illustrate how two state-of-the-art open-source\nmodeling tools, namely MontiAnna and ML-Quadrat can be used for this purpose as\ndemonstrated through a case study. The case study illustrates using ML, in\nparticular deep Artificial Neural Networks (ANNs), for automated image\nrecognition of handwritten digits using the MNIST reference dataset, and\nintegrating the machine learning components into an IoT system. Subsequently,\nwe conduct a functional comparison of the two frameworks, setting out an\nanalysis base to include a broad range of design considerations, such as the\nproblem domain, methods for the ML integration into larger systems, and\nsupported ML methods, as well as topics of recent intense interest to the ML\ncommunity, such as AutoML and MLOps. Accordingly, this paper is focused on\nelucidating the potential of the MDE approach in the ML domain. This supports\nthe ML engineer in developing the (ML/software) model rather than implementing\nthe code, and additionally enforces reusability and modularity of the design\nthrough enabling the out-of-the-box integration of ML functionality as a\ncomponent of the IoT or cyber-physical systems.",
    "descriptor": "\nComments: ACM / IEEE 25th International Conference on Model Driven Engineering Languages and Systems (MODELS 2022) Companion - MDE Intelligence Workshop\n",
    "authors": [
      "J\u00f6rg Christian Kirchhof",
      "Evgeny Kusmenko",
      "Jonas Ritz",
      "Bernhard Rumpe",
      "Armin Moin",
      "Atta Badii",
      "Stephan G\u00fcnnemann",
      "Moharram Challenger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07282"
  },
  {
    "id": "arXiv:2209.07285",
    "title": "Identifying research supporting the United Nations Sustainable  Development Goals",
    "abstract": "The United Nations (UN) Sustainable Development Goals (SDGs) challenge the\nglobal community to build a world where no one is left behind. Recognizing that\nresearch plays a fundamental part in supporting these goals, attempts have been\nmade to classify research publications according to their relevance in\nsupporting each of the UN's SDGs. In this paper, we outline the methodology\nthat we followed when mapping research articles to SDGs and which is adopted by\nTimes Higher Education in their Social Impact rankings. We also discuss various\naspects in which the methodology can be improved and generalized to other types\nof content apart from research articles. The results presented in this paper\nare the outcome of the SDG Research Mapping Initiative that was established as\na partnership between the University of Southern Denmark, the Aurora European\nUniversities Alliance (represented by Vrije Universiteit Amsterdam), the\nUniversity of Auckland, and Elsevier to bring together broad expertise and\nshare best practices on identifying research contributions to UN's Sustainable\nDevelopment Goals.",
    "descriptor": "\nComments: 11 pages, 3 figures, 5 tables, 18 references\n",
    "authors": [
      "Yury Kashnitsky",
      "Guillaume Roberge",
      "Jingwen Mu",
      "Kevin Kang",
      "Weiwei Wang",
      "Maurice Vanderfeesten",
      "Maxim Rivest",
      "Lennart Ke\u00dfler",
      "Robert Jaworek",
      "Ma\u00e9va Vignes",
      "Bamini Jayabalasingham",
      "Finne Boonen",
      "Chris James",
      "Marius Doornenbal",
      "Isabelle Labrosse"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2209.07285"
  },
  {
    "id": "arXiv:2209.07288",
    "title": "Exploiting Reward Shifting in Value-Based Deep RL",
    "abstract": "In this work, we study the simple yet universally applicable case of reward\nshaping in value-based Deep Reinforcement Learning (DRL). We show that reward\nshifting in the form of the linear transformation is equivalent to changing the\ninitialization of the $Q$-function in function approximation. Based on such an\nequivalence, we bring the key insight that a positive reward shifting leads to\nconservative exploitation, while a negative reward shifting leads to\ncuriosity-driven exploration. Accordingly, conservative exploitation improves\noffline RL value estimation, and optimistic value estimation improves\nexploration for online RL. We validate our insight on a range of RL tasks and\nshow its improvement over baselines: (1) In offline RL, the conservative\nexploitation leads to improved performance based on off-the-shelf algorithms;\n(2) In online continuous control, multiple value functions with different\nshifting constants can be used to tackle the exploration-exploitation dilemma\nfor better sample efficiency; (3) In discrete control tasks, a negative reward\nshifting yields an improvement over the curiosity-based exploration method.",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Lei Han",
      "Rui Yang",
      "Xiaoteng Ma",
      "Jian Guo",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07288"
  },
  {
    "id": "arXiv:2209.07297",
    "title": "Un referentiel spatial pour la gestion de la voirie dans son  environnement",
    "abstract": "The densification of urban basements into distribution networks leads to\ninterventions involving different actors. These interventions generally impact\nthe roadway, that is to say the entire road infrastructure, both structurally\n(vertical component) and superficially (horizontal component). In addition to\nthe financial costs, each intervention can weaken the structure and disturb the\nvarious users. Our work aims at optimizing interventions by improving the\ncoordinated management of data related to the road and its environment in a\nspatial reference frame. For that, we aim at a modeling adapted to the\nmanagement of the infrastructure integrating the roadway and its constituent\nelements with the materials and their thicknesses. Our approach is organized in\nfour axes: 1/ A description of the roadway's constituent elements, to propose a\ncoherent vision to the actors. 2/ A study of the existing data for the\nmanagement of the infrastructure, in order to identify the knowledge and the\nneeds. 3/ A GIS modeling of the infrastructure to help communities to produce\ntheir data. 4/ An analysis of spatial interactions between roads and networks,\nto open discussions on construction choices. This article retraces all the work\ncarried out for the four axes and proposes to open the debate on the design of\na spatial reference system for roads adapted to their management.",
    "descriptor": "\nComments: in French language\n",
    "authors": [
      "A. Pavard",
      "A. Dony",
      "P. Bordin"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.07297"
  },
  {
    "id": "arXiv:2209.07299",
    "title": "Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge  Graph Completion",
    "abstract": "Knowledge Graph Completion (KGC) has been recently extended to multiple\nknowledge graph (KG) structures, initiating new research directions, e.g.\nstatic KGC, temporal KGC and few-shot KGC. Previous works often design KGC\nmodels closely coupled with specific graph structures, which inevitably results\nin two drawbacks: 1) structure-specific KGC models are mutually incompatible;\n2) existing KGC methods are not adaptable to emerging KGs. In this paper, we\npropose KG-S2S, a Seq2Seq generative framework that could tackle different\nverbalizable graph structures by unifying the representation of KG facts into\n\"flat\" text, regardless of their original form. To remedy the KG structure\ninformation loss from the \"flat\" text, we further improve the input\nrepresentations of entities and relations, and the inference algorithm in\nKG-S2S. Experiments on five benchmarks show that KG-S2S outperforms many\ncompetitive baselines, setting new state-of-the-art performance. Finally, we\nanalyze KG-S2S's ability on the different relations and the Non-entity\nGenerations.",
    "descriptor": "\nComments: COLING 2022 Main Conference\n",
    "authors": [
      "Chen Chen",
      "Yufei Wang",
      "Bing Li",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07299"
  },
  {
    "id": "arXiv:2209.07302",
    "title": "MVNet: Memory Assistance and Vocal Reinforcement Network for Speech  Enhancement",
    "abstract": "Speech enhancement improves speech quality and promotes the performance of\nvarious downstream tasks. However, most current speech enhancement work was\nmainly devoted to improving the performance of downstream automatic speech\nrecognition (ASR), only a relatively small amount of work focused on the\nautomatic speaker verification (ASV) task. In this work, we propose a MVNet\nconsisted of a memory assistance module which improves the performance of\ndownstream ASR and a vocal reinforcement module which boosts the performance of\nASV. In addition, we design a new loss function to improve speaker vocal\nsimilarity. Experimental results on the Libri2mix dataset show that our method\noutperforms baseline methods in several metrics, including speech quality,\nintelligibility, and speaker vocal similarity et al.",
    "descriptor": "\nComments: ICONIP 2022\n",
    "authors": [
      "Jianrong Wang",
      "Xiaomin Li",
      "Xuewei Li",
      "Mei Yu",
      "Qiang Fang",
      "Li Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.07302"
  },
  {
    "id": "arXiv:2209.07303",
    "title": "Differentially Private Estimation of Hawkes Process",
    "abstract": "Point process models are of great importance in real world applications. In\ncertain critical applications, estimation of point process models involves\nlarge amounts of sensitive personal data from users. Privacy concerns naturally\narise which have not been addressed in the existing literature. To bridge this\nglaring gap, we propose the first general differentially private estimation\nprocedure for point process models. Specifically, we take the Hawkes process as\nan example, and introduce a rigorous definition of differential privacy for\nevent stream data based on a discretized representation of the Hawkes process.\nWe then propose two differentially private optimization algorithms, which can\nefficiently estimate Hawkes process models with the desired privacy and utility\nguarantees under two different settings. Experiments are provided to back up\nour theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Tianyi Liu",
      "Tuo Zhao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07303"
  },
  {
    "id": "arXiv:2209.07304",
    "title": "Bi-SIS Epidemics on Graphs -- Quantitative Analysis of Coexistence  Equilibria",
    "abstract": "We consider a system in which two viruses of the\nSusceptible-Infected-Susceptible (SIS) type compete over general, overlaid\ngraphs. While such systems have been the focus of many recent works, they have\nmostly been studied in the sense of convergence analysis, with no existing\nresults quantifying the non-trivial coexistence equilibria (CE) - that is, when\nboth competing viruses maintain long term presence over the network. In this\npaper, we prove monotonicity of the CE with respect to effective infection\nrates of the two viruses, and provide the first quantitative analysis of such\nequilibria in the form of upper bounds involving spectral radii of the\nunderlying graphs, as well as positive equilibria of related single-virus\nsystems. Our results provide deeper insight into how the long term infection\nprobabilities are affected by system parameters, which we further highlight via\nnumerical results.",
    "descriptor": "\nComments: To appear in IEEE CDC 2022\n",
    "authors": [
      "Vishwaraj Doshi",
      "Jie Hu",
      "Do Young Eun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07304"
  },
  {
    "id": "arXiv:2209.07312",
    "title": "Multicalibrated Regression for Downstream Fairness",
    "abstract": "We show how to take a regression function $\\hat{f}$ that is appropriately\n``multicalibrated'' and efficiently post-process it into an approximately error\nminimizing classifier satisfying a large variety of fairness constraints. The\npost-processing requires no labeled data, and only a modest amount of unlabeled\ndata and computation. The computational and sample complexity requirements of\ncomputing $\\hat f$ are comparable to the requirements for solving a single fair\nlearning task optimally, but it can in fact be used to solve many different\ndownstream fairness-constrained learning problems efficiently. Our\npost-processing method easily handles intersecting groups, generalizing prior\nwork on post-processing regression functions to satisfy fairness constraints\nthat only applied to disjoint groups. Our work extends recent work showing that\nmulticalibrated regression functions are ``omnipredictors'' (i.e. can be\npost-processed to optimally solve unconstrained ERM problems) to constrained\noptimization.",
    "descriptor": "",
    "authors": [
      "Ira Globus-Harris",
      "Varun Gupta",
      "Christopher Jung",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Aaron Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07312"
  },
  {
    "id": "arXiv:2209.07320",
    "title": "Physically recurrent neural networks for path-dependent heterogeneous  materials: embedding constitutive models in a data-driven surrogate",
    "abstract": "Driven by the need to accelerate numerical simulations, the use of machine\nlearning techniques is rapidly growing in the field of computational solid\nmechanics. Their application is especially advantageous in concurrent\nmultiscale finite element analysis (FE$^2$) due to the exceedingly high\ncomputational costs often associated with it and the high number of similar\nmicromechanical analyses involved. To tackle the issue, using surrogate models\nto approximate the microscopic behavior and accelerate the simulations is a\npromising and increasingly popular strategy. However, several challenges\nrelated to their data-driven nature compromise the reliability of surrogate\nmodels in material modeling. The alternative explored in this work is to\nreintroduce some of the physics-based knowledge of classical constitutive\nmodeling into a neural network by employing the actual material models used in\nthe full-order micromodel to introduce non-linearity. Thus, path-dependency\narises naturally since every material model in the layer keeps track of its own\ninternal variables. For the numerical examples, a composite Representative\nVolume Element with elastic fibers and elasto-plastic matrix material is used\nas the microscopic model. The network is tested in a series of challenging\nscenarios and its performance is compared to that of a state-of-the-art\nRecurrent Neural Network (RNN). A remarkable outcome of the novel framework is\nthe ability to naturally predict unloading/reloading behavior without ever\nseeing it during training, a stark contrast with popular but data-hungry models\nsuch as RNNs. Finally, the proposed network is applied to FE$^2$ examples to\nassess its robustness for application in nonlinear finite element analysis.",
    "descriptor": "\nComments: 30 pages, 24 figures\n",
    "authors": [
      "M. A. Maia",
      "I. B. C. M. Rocha",
      "P. Kerfriden",
      "F. P. van der Meer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.07320"
  },
  {
    "id": "arXiv:2209.07322",
    "title": "Intuitive Robot Programming by Capturing Human Manufacturing Skills: A  Framework for the Process of Glass Adhesive Application",
    "abstract": "There is a great demand for the robotization of manufacturing processes\nfea-turing monotonous labor. Some manufacturing tasks requiring specific skills\n(welding, painting, etc.) suffer from a lack of workers. Robots have been used\nin these tasks, but their flexibility is limited since they are still difficult\nto program/re-program by non-experts, making them inaccessible to most\ncompanies. Robot offline programming (OLP) is reliable. However, generat-ed\npaths directly from CAD/CAM do not include relevant parameters repre-senting\nhuman skills such as robot end-effector orientations and velocities. This paper\npresents an intuitive robot programming system to capture human manufacturing\nskills and transform them into robot programs. Demonstra-tions from human\nskilled workers are recorded using a magnetic tracking system attached to the\nworker tools. Collected data include the orientations and velocity of the\nworking paths. Positional data are extracted from CAD/CAM since its error when\ncaptured by the magnetic tracker, is signifi-cant. Paths poses are transformed\nin Cartesian space and validated in a simu-lation environment. Robot programs\nare generated and transferred to the real robot. Experiments on the process of\nglass adhesive application demonstrat-ed the intuitiveness to use and\neffectiveness of the proposed framework in capturing human skills and\ntransferring them to the robot.",
    "descriptor": "",
    "authors": [
      "Mihail Babcinschi",
      "Francisco Cruz",
      "Nicole Duarte",
      "Silvia Santos",
      "Samuel Alves",
      "Pedro Neto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07322"
  },
  {
    "id": "arXiv:2209.07324",
    "title": "Stability Guarantees for Continuous RL Control",
    "abstract": "Lack of stability guarantees strongly limits the use of reinforcement\nlearning (RL) in safety critical robotic applications. Here we propose a\ncontrol system architecture for continuous RL control and derive corresponding\nstability theorems via contraction analysis, yielding constraints on the\nnetwork weights to ensure stability. The control architecture can be\nimplemented in general RL algorithms and improve their stability, robustness,\nand sample efficiency. We demonstrate the importance and benefits of such\nguarantees for RL on two standard examples, PPO learning of a 2D problem and\nHIRO learning of maze tasks.",
    "descriptor": "",
    "authors": [
      "Bing Song",
      "Jean-Jacques Slotine",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07324"
  },
  {
    "id": "arXiv:2209.07326",
    "title": "A Continual Development Methodology for Large-scale Multitask Dynamic ML  Systems",
    "abstract": "The traditional Machine Learning (ML) methodology requires to fragment the\ndevelopment and experimental process into disconnected iterations whose\nfeedback is used to guide design or tuning choices. This methodology has\nmultiple efficiency and scalability disadvantages, such as leading to spend\nsignificant resources into the creation of multiple trial models that do not\ncontribute to the final solution.The presented work is based on the intuition\nthat defining ML models as modular and extensible artefacts allows to introduce\na novel ML development methodology enabling the integration of multiple design\nand evaluation iterations into the continuous enrichment of a single unbounded\nintelligent system. We define a novel method for the generation of dynamic\nmultitask ML models as a sequence of extensions and generalizations. We first\nanalyze the capabilities of the proposed method by using the standard ML\nempirical evaluation methodology. Finally, we propose a novel continuous\ndevelopment methodology that allows to dynamically extend a pre-existing\nmultitask large-scale ML system while analyzing the properties of the proposed\nmethod extensions. This results in the generation of an ML model capable of\njointly solving 124 image classification tasks achieving state of the art\nquality with improved size and compute cost.",
    "descriptor": "",
    "authors": [
      "Andrea Gesmundo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07326"
  },
  {
    "id": "arXiv:2209.07330",
    "title": "Semiparametric Best Arm Identification with Contextual Information",
    "abstract": "We study best-arm identification with a fixed budget and contextual\n(covariate) information in stochastic multi-armed bandit problems. In each\nround, after observing contextual information, we choose a treatment arm using\npast observations and current context. Our goal is to identify the best\ntreatment arm, a treatment arm with the maximal expected reward marginalized\nover the contextual distribution, with a minimal probability of\nmisidentification. First, we derive semiparametric lower bounds for this\nproblem, where we regard the gaps between the expected rewards of the best and\nsuboptimal treatment arms as parameters of interest, and all other parameters,\nsuch as the expected rewards conditioned on contexts, as the nuisance\nparameters. We then develop the \"Contextual RS-AIPW strategy,\" which consists\nof the random sampling (RS) rule tracking a target allocation ratio and the\nrecommendation rule using the augmented inverse probability weighting (AIPW)\nestimator. Our proposed Contextual RS-AIPW strategy is optimal because the\nupper bound for the probability of misidentification matches the semiparametric\nlower bound when the budget goes to infinity, and the gaps converge to zero.",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Masaaki Imaizumi",
      "Takuya Ishihara",
      "Toru Kitagawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07330"
  },
  {
    "id": "arXiv:2209.07332",
    "title": "A Temporal Graphlet Kernel for Classifying Dissemination in Evolving  Networks",
    "abstract": "We introduce the \\emph{temporal graphlet kernel} for classifying\ndissemination processes in labeled temporal graphs. Such dissemination\nprocesses can be spreading (fake) news, infectious diseases, or computer\nviruses in dynamic networks. The networks are modeled as labeled temporal\ngraphs, in which the edges exist at specific points in time, and node labels\nchange over time. The classification problem asks to discriminate dissemination\nprocesses of different origins or parameters, e.g., infectious diseases with\ndifferent infection probabilities. Our new kernel represents labeled temporal\ngraphs in the feature space of temporal graphlets, i.e., small subgraphs\ndistinguished by their structure, time-dependent node labels, and chronological\norder of edges. We introduce variants of our kernel based on classes of\ngraphlets that are efficiently countable. For the case of temporal wedges, we\npropose a highly efficient approximative kernel with low error in expectation.\nWe show that our kernels are faster to compute and provide better accuracy than\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Lutz Oettershagen",
      "Nils M. Kriege",
      "Claude Jordan",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07332"
  },
  {
    "id": "arXiv:2209.07333",
    "title": "Public Reaction to Scientific Research via Twitter Sentiment Prediction",
    "abstract": "Social media users share their ideas, thoughts, and emotions with other\nusers. However, it is not clear how online users would respond to new research\noutcomes. This study aims to predict the nature of the emotions expressed by\nTwitter users toward scientific publications. Additionally, we investigate what\nfeatures of the research articles help in such prediction. Identifying the\nsentiments of research articles on social media will help scientists gauge a\nnew societal impact of their research articles.",
    "descriptor": "\nComments: Journal of Data and Information Sciences\n",
    "authors": [
      "Murtuza Shahzad",
      "Hamed Alhoori"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07333"
  },
  {
    "id": "arXiv:2209.07334",
    "title": "What is a good doge? Analyzing the patrician social network of the  Republic of Venice",
    "abstract": "The Venetian republic was one of the most successful trans-modern states,\nsurviving for a millennium through innovation, commercial cunning, exploitation\nof colonies and legal stability. Part of the success might be due to its\ngovernment structure, a republic ruled by a doge chosen among a relatively\nlimited set of Venetian patrician families. In this paper we analyze the\nstructure of the social network they formed through marriage, and how\ngovernment was monopolized by a relatively small set of families, the one that\nbecame patrician first.",
    "descriptor": "",
    "authors": [
      "J. J. Merelo-Guerv\u00f3s"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07334"
  },
  {
    "id": "arXiv:2209.07341",
    "title": "CLIPping Privacy: Identity Inference Attacks on Multi-Modal Machine  Learning Models",
    "abstract": "As deep learning is now used in many real-world applications, research has\nfocused increasingly on the privacy of deep learning models and how to prevent\nattackers from obtaining sensitive information about the training data.\nHowever, image-text models like CLIP have not yet been looked at in the context\nof privacy attacks. While membership inference attacks aim to tell whether a\nspecific data point was used for training, we introduce a new type of privacy\nattack, named identity inference attack (IDIA), designed for multi-modal\nimage-text models like CLIP. Using IDIAs, an attacker can reveal whether a\nparticular person, was part of the training data by querying the model in a\nblack-box fashion with different images of the same person. Letting the model\nchoose from a wide variety of possible text labels, the attacker can probe the\nmodel whether it recognizes the person and, therefore, was used for training.\nThrough several experiments on CLIP, we show that the attacker can identify\nindividuals used for training with very high accuracy and that the model learns\nto connect the names with the depicted people. Our experiments show that a\nmulti-modal image-text model indeed leaks sensitive information about its\ntraining data and, therefore, should be handled with care.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Dominik Hintersdorf",
      "Lukas Struppek",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07341"
  },
  {
    "id": "arXiv:2209.07342",
    "title": "Sampling for network function learning",
    "abstract": "Given a valued graph, where both the nodes and the edges of the graph are\nassociated with one or several values, any network function for a given node\nmust be defined in terms of that node and its connected nodes in the graph.\nGenerally, applying the same definition to the whole graph or any given\nsubgraph of it would result in systematically different network functions. In\nthis paper we consider the feasibility of graph sampling approach to network\nfunction learning, as well as the corresponding learning methods based on the\nsample graphs. This can be useful either when the edges are unknown to start\nwith or the graph is too large (or dynamic) to be processed entirely.",
    "descriptor": "",
    "authors": [
      "Li-Chun Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07342"
  },
  {
    "id": "arXiv:2209.07348",
    "title": "Coupled Evolutionary Behavioral and Disease Dynamics under Reinfection  Risk",
    "abstract": "We study the interplay between epidemic dynamics and human decision making\nfor epidemics that involve reinfection risk; in particular, the\nsusceptible-infected-susceptible (SIS) and the\nsusceptible-infected-recovered-infected (SIRI) epidemic models. In the proposed\ngame-theoretic setting, individuals choose whether to adopt protection or not\nbased on the trade-off between the cost of adopting protection and the risk of\ninfection; the latter depends on the current prevalence of the epidemic and the\nfraction of individuals who adopt protection in the entire population. We\ndefine the coupled epidemic-behavioral dynamics by modeling the evolution of\nindividual protection adoption behavior according to the replicator dynamics.\nFor the SIS epidemic, we fully characterize the equilibria and their stability\nproperties. We further analyze the coupled dynamics under timescale separation\nwhen individual behavior evolves faster than the epidemic, and characterize the\nequilibria of the resulting discontinuous hybrid dynamical system for both SIS\nand SIRI models. Numerical results illustrate how the coupled dynamics exhibits\noscillatory behavior and convergence to sliding mode solutions under suitable\nparameter regimes.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.10276\n",
    "authors": [
      "Abhisek Satapathi",
      "Narendra Kumar Dhar",
      "Ashish R. Hota",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07348"
  },
  {
    "id": "arXiv:2209.07350",
    "title": "Overhead-Free Blockage Detection and Precoding Through Physics-Based  Graph Neural Networks: LIDAR Data Meets Ray Tracing",
    "abstract": "In this letter, we address blockage detection and precoder design for\nmultiple-input multiple-output (MIMO) links, without communication overhead\nrequired. Blockage detection is achieved by classifying light detection and\nranging (LIDAR) data through a physics-based graph neural network (GNN). For\nprecoder design, a preliminary channel estimate is obtained by running ray\ntracing on a 3D surface obtained from LIDAR data. This estimate is successively\nrefined and the precoder is designed accordingly. Numerical simulations show\nthat blockage detection is successful with 95% accuracy. Our digital precoding\nachieves 90% of the capacity and analog precoding outperforms previous works\nexploiting LIDAR for precoder design.",
    "descriptor": "\nComments: Submitted to IEEE for publication\n",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.07350"
  },
  {
    "id": "arXiv:2209.07351",
    "title": "Rethinking Round-trip Translation for Automatic Machine Translation  Evaluation",
    "abstract": "A parallel corpus is generally required to automatically evaluate the\ntranslation quality using the metrics, such as BLEU, METEOR and BERTScore.\nWhile the reference-based evaluation paradigm is widely used in many machine\ntranslation tasks, it is difficult to be applied to translation with\nlow-resource languages, as those languages suffer from a deficiency of corpora.\nRound-trip translation provides an encouraging way to alleviate the urgent\nrequirement of the parallel corpus, although it was unfortunately not observed\nto correlate with forwarding translation in the era of statistical machine\ntranslation. In this paper, we firstly observe that forward translation quality\nconsistently correlates to corresponding round-trip translation quality in the\nscope of neural machine translation. Then, we carefully analyse and unveil the\nreason for the contradictory results on statistical machine translation\nsystems. Secondly, we propose a simple yet effective regression method to\npredict the performance of forward translation scores based on round-trip\ntranslation scores for various language pairs, including those between very\nlow-resource languages. We conduct extensive experiments to show the\neffectiveness and robustness of the predictive models on 1,000+ language pairs.\nFinally, we test our method on challenging settings, such as predicting scores:\ni) for unseen language pairs in training and ii) on real-world WMT shared tasks\nbut in new domains. The extensive experiments demonstrate the robustness and\nutility of our approach. We believe our work will inspire works on very\nlow-resource multilingual machine translation.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Terry Yue Zhuo",
      "Qiongkai Xu",
      "Xuanli He",
      "Trevor Cohn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07351"
  },
  {
    "id": "arXiv:2209.07353",
    "title": "Measuring Geographic Performance Disparities of Offensive Language  Classifiers",
    "abstract": "Text classifiers are applied at scale in the form of one-size-fits-all\nsolutions. Nevertheless, many studies show that classifiers are biased\nregarding different languages and dialects. When measuring and discovering\nthese biases, some gaps present themselves and should be addressed. First,\n``Does language, dialect, and topical content vary across geographical\nregions?'' and secondly ``If there are differences across the regions, do they\nimpact model performance?''. We introduce a novel dataset called GeoOLID with\nmore than 14 thousand examples across 15 geographically and demographically\ndiverse cities to address these questions. We perform a comprehensive analysis\nof geographical-related content and their impact on performance disparities of\noffensive language detection models. Overall, we find that current models do\nnot generalize across locations. Likewise, we show that while offensive\nlanguage models produce false positives on African American English, model\nperformance is not correlated with each city's minority population proportions.\nWarning: This paper contains offensive language.",
    "descriptor": "\nComments: Accepted by 29th International Conference on Computational Linguistics (COLING 2022)\n",
    "authors": [
      "Brandon Lwowski",
      "Paul Rad",
      "Anthony Rios"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07353"
  },
  {
    "id": "arXiv:2209.07364",
    "title": "Continuous MDP Homomorphisms and Homomorphic Policy Gradient",
    "abstract": "Abstraction has been widely studied as a way to improve the efficiency and\ngeneralization of reinforcement learning algorithms. In this paper, we study\nabstraction in the continuous-control setting. We extend the definition of MDP\nhomomorphisms to encompass continuous actions in continuous state spaces. We\nderive a policy gradient theorem on the abstract MDP, which allows us to\nleverage approximate symmetries of the environment for policy optimization.\nBased on this theorem, we propose an actor-critic algorithm that is able to\nlearn the policy and the MDP homomorphism map simultaneously, using the lax\nbisimulation metric. We demonstrate the effectiveness of our method on\nbenchmark tasks in the DeepMind Control Suite. Our method's ability to utilize\nMDP homomorphisms for representation learning leads to improved performance\nwhen learning from pixel observations.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Sahand Rezaei-Shoshtari",
      "Rosie Zhao",
      "Prakash Panangaden",
      "David Meger",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07364"
  },
  {
    "id": "arXiv:2209.07365",
    "title": "Do Cloud Developers Prefer CLIs or Web Consoles? CLIs Mostly, Though It  Varies by Task",
    "abstract": "Despite the increased importance of Cloud tooling, and many large-scale\nstudies of Cloud users, research has yet to answer what tool modalities (e.g.\nCLI or web console) developers prefer. In formulating our studies, we quickly\nfound that preference varies heavily based on the programming task at hand. To\naddress this gap, we conducted a two-part research study that quantifies\nmodality preference as a function of programming task. Part one surveys how\npreference for three tool modalities (CLI, IDE, web console) varies across\nthree classes of task (CRUD, debugging, monitoring). The survey shows, among 60\nrespondents, developers most prefer the CLI modality, especially for CRUD\ntasks. Monitoring tasks are the exception for which developers prefer the web\nconsole. Part two observes how four participants complete a task using the\nkubectl CLI and the OpenShift web console. All four participants prefer using\nthe CLI to accomplish the task.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Cora Coleman",
      "William G. Griswold",
      "Nick Mitchell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.07365"
  },
  {
    "id": "arXiv:2209.07366",
    "title": "3DMM-RF: Convolutional Radiance Fields for 3D Face Modeling",
    "abstract": "Facial 3D Morphable Models are a main computer vision subject with countless\napplications and have been highly optimized in the last two decades. The\ntremendous improvements of deep generative networks have created various\npossibilities for improving such models and have attracted wide interest.\nMoreover, the recent advances in neural radiance fields, are revolutionising\nnovel-view synthesis of known scenes. In this work, we present a facial 3D\nMorphable Model, which exploits both of the above, and can accurately model a\nsubject's identity, pose and expression and render it in arbitrary\nillumination. This is achieved by utilizing a powerful deep style-based\ngenerator to overcome two main weaknesses of neural radiance fields, their\nrigidity and rendering speed. We introduce a style-based generative network\nthat synthesizes in one pass all and only the required rendering samples of a\nneural radiance field. We create a vast labelled synthetic dataset of facial\nrenders, and train the network on these data, so that it can accurately model\nand generalize on facial identity, pose and appearance. Finally, we show that\nthis model can accurately be fit to \"in-the-wild\" facial images of arbitrary\npose and illumination, extract the facial characteristics, and be used to\nre-render the face in controllable conditions.",
    "descriptor": "",
    "authors": [
      "Stathis Galanakis",
      "Baris Gecer",
      "Alexandros Lattas",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07366"
  },
  {
    "id": "arXiv:2209.07367",
    "title": "Deep Reinforcement Learning for Task Offloading in UAV-Aided Smart Farm  Networks",
    "abstract": "The fifth and sixth generations of wireless communication networks are\nenabling tools such as internet of things devices, unmanned aerial vehicles\n(UAVs), and artificial intelligence, to improve the agricultural landscape\nusing a network of devices to automatically monitor farmlands. Surveying a\nlarge area requires performing a lot of image classification tasks within a\nspecific period of time in order to prevent damage to the farm in case of an\nincident, such as fire or flood. UAVs have limited energy and computing power,\nand may not be able to perform all of the intense image classification tasks\nlocally and within an appropriate amount of time. Hence, it is assumed that the\nUAVs are able to partially offload their workload to nearby multi-access edge\ncomputing devices. The UAVs need a decision-making algorithm that will decide\nwhere the tasks will be performed, while also considering the time constraints\nand energy level of the other UAVs in the network. In this paper, we introduce\na Deep Q-Learning (DQL) approach to solve this multi-objective problem. The\nproposed method is compared with Q-Learning and three heuristic baselines, and\nthe simulation results show that our proposed DQL-based method achieves\ncomparable results when it comes to the UAVs' remaining battery levels and\npercentage of deadline violations. In addition, our method is able to reach\nconvergence 13 times faster than Q-Learning.",
    "descriptor": "\nComments: Accepted Paper\n",
    "authors": [
      "Anne Catherine Nguyen",
      "Turgay Pamuklu",
      "Aisha Syed",
      "W. Sean Kennedy",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07367"
  },
  {
    "id": "arXiv:2209.07368",
    "title": "Causal Coupled Mechanisms: A Control Method with Cooperation and  Competition for Complex System",
    "abstract": "Complex systems are ubiquitous in the real world and tend to have complicated\nand poorly understood dynamics. For their control issues, the challenge is to\nguarantee accuracy, robustness, and generalization in such bloated and troubled\nenvironments. Fortunately, a complex system can be divided into multiple\nmodular structures that human cognition appears to exploit. Inspired by this\ncognition, a novel control method, Causal Coupled Mechanisms (CCMs), is\nproposed that explores the cooperation in division and competition in\ncombination. Our method employs the theory of hierarchical reinforcement\nlearning (HRL), in which 1) the high-level policy with competitive awareness\ndivides the whole complex system into multiple functional mechanisms, and 2)\nthe low-level policy finishes the control task of each mechanism. Specifically\nfor cooperation, a cascade control module helps the series operation of CCMs,\nand a forward coupled reasoning module is used to recover the coupling\ninformation lost in the division process. On both synthetic systems and a\nreal-world biological regulatory system, the CCM method achieves robust and\nstate-of-the-art control results even with unpredictable random noise.\nMoreover, generalization results show that reusing prepared specialized CCMs\nhelps to perform well in environments with different confounders and dynamics.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Xuehui Yu",
      "Jingchi Jiang",
      "Xinmiao Yu",
      "Yi Guan",
      "Xue Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07368"
  },
  {
    "id": "arXiv:2209.07369",
    "title": "Adversarially Robust Learning: A Generic Minimax Optimal Learner and  Characterization",
    "abstract": "We present a minimax optimal learner for the problem of learning predictors\nrobust to adversarial examples at test-time. Interestingly, we find that this\nrequires new algorithmic ideas and approaches to adversarially robust learning.\nIn particular, we show, in a strong negative sense, the suboptimality of the\nrobust learner proposed by Montasser, Hanneke, and Srebro (2019) and a broader\nfamily of learners we identify as local learners. Our results are enabled by\nadopting a global perspective, specifically, through a key technical\ncontribution: the global one-inclusion graph, which may be of independent\ninterest, that generalizes the classical one-inclusion graph due to Haussler,\nLittlestone, and Warmuth (1994). Finally, as a byproduct, we identify a\ndimension characterizing qualitatively and quantitatively what classes of\npredictors $\\mathcal{H}$ are robustly learnable. This resolves an open problem\ndue to Montasser et al. (2019), and closes a (potentially) infinite gap between\nthe established upper and lower bounds on the sample complexity of\nadversarially robust learning.",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Omar Montasser",
      "Steve Hanneke",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07369"
  },
  {
    "id": "arXiv:2209.07375",
    "title": "Wealth Dynamics Over Generations: Analysis and Interventions",
    "abstract": "We present a stylized model with feedback loops for the evolution of a\npopulation's wealth over generations. Individuals have both talent and wealth:\ntalent is a random variable distributed identically for everyone, but wealth is\na random variable that is dependent on the population one is born into.\nIndividuals then apply to a downstream agent, which we treat as a university\nthroughout the paper (but could also represent an employer) who makes a\ndecision about whether to admit them or not. The university does not directly\nobserve talent or wealth, but rather a signal (representing e.g. a standardized\ntest) that is a convex combination of both. The university knows the\ndistributions from which an individual's type and wealth are drawn, and makes\nits decisions based on the posterior distribution of the applicant's\ncharacteristics conditional on their population and signal. Each population's\nwealth distribution at the next round then depends on the fraction of that\npopulation that was admitted by the university at the previous round.\nWe study wealth dynamics in this model, and give conditions under which the\ndynamics have a single attracting fixed point (which implies population wealth\ninequality is transitory), and conditions under which it can have multiple\nattracting fixed points (which implies that population wealth inequality can be\npersistent). In the case in which there are multiple attracting fixed points,\nwe study interventions aimed at eliminating or mitigating inequality, including\nincreasing the capacity of the university to admit more people, aligning the\nsignal generated by individuals with the preferences of the university, and\nmaking direct monetary transfers to the less wealthy population.",
    "descriptor": "",
    "authors": [
      "Krishna Acharya",
      "Eshwar Ram Arunachaleswaran",
      "Sampath Kannan",
      "Aaron Roth",
      "Juba Ziani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.07375"
  },
  {
    "id": "arXiv:2209.07376",
    "title": "Understanding Deep Neural Function Approximation in Reinforcement  Learning via $\u03b5$-Greedy Exploration",
    "abstract": "This paper provides a theoretical study of deep neural function approximation\nin reinforcement learning (RL) with the $\\epsilon$-greedy exploration under the\nonline setting. This problem setting is motivated by the successful deep\nQ-networks (DQN) framework that falls in this regime. In this work, we provide\nan initial attempt on theoretical understanding deep RL from the perspective of\nfunction class and neural networks architectures (e.g., width and depth) beyond\nthe \"linear\" regime. To be specific, we focus on the value based algorithm with\nthe $\\epsilon$-greedy exploration via deep (and two-layer) neural networks\nendowed by Besov (and Barron) function spaces, respectively, which aims at\napproximating an $\\alpha$-smooth Q-function in a $d$-dimensional feature space.\nWe prove that, with $T$ episodes, scaling the width $m =\n\\widetilde{\\mathcal{O}}(T^{\\frac{d}{2\\alpha + d}})$ and the depth\n$L=\\mathcal{O}(\\log T)$ of the neural network for deep RL is sufficient for\nlearning with sublinear regret in Besov spaces. Moreover, for a two layer\nneural network endowed by the Barron space, scaling the width\n$\\Omega(\\sqrt{T})$ is sufficient. To achieve this, the key issue in our\nanalysis is how to estimate the temporal difference error under deep neural\nfunction approximation as the $\\epsilon$-greedy exploration is not enough to\nensure \"optimism\". Our analysis reformulates the temporal difference error in\nan $L^2(\\mathrm{d}\\mu)$-integrable space over a certain averaged measure $\\mu$,\nand transforms it to a generalization problem under the non-iid setting. This\nmight have its own interest in RL theory for better understanding\n$\\epsilon$-greedy exploration in deep RL.",
    "descriptor": "\nComments: Accepted by NeruIPS22\n",
    "authors": [
      "Fanghui Liu",
      "Luca Viano",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07376"
  },
  {
    "id": "arXiv:2209.07382",
    "title": "IoT-Aerial Base Station Task Offloading with Risk-Sensitive  Reinforcement Learning for Smart Agriculture",
    "abstract": "Aerial base stations (ABSs) allow smart farms to offload processing\nresponsibility of complex tasks from internet of things (IoT) devices to ABSs.\nIoT devices have limited energy and computing resources, thus it is required to\nprovide an advanced solution for a system that requires the support of ABSs.\nThis paper introduces a novel multi-actor-based risk-sensitive reinforcement\nlearning approach for ABS task scheduling for smart agriculture. The problem is\ndefined as task offloading with a strict condition on completing the IoT tasks\nbefore their deadlines. Moreover, the algorithm must also consider the limited\nenergy capacity of the ABSs. The results show that our proposed approach\noutperforms several heuristics and the classic Q-Learning approach.\nFurthermore, we provide a mixed integer linear programming solution to\ndetermine a lower bound on the performance, and clarify the gap between our\nrisk-sensitive solution and the optimal solution, as well. The comparison\nproves our extensive simulation results demonstrate that our method is a\npromising approach for providing a guaranteed task processing services for the\nIoT tasks in a smart farm, while increasing the hovering time of the ABSs in\nthis farm.",
    "descriptor": "\nComments: Accepted Paper\n",
    "authors": [
      "Turgay Pamuklu",
      "Anne Catherine Nguyen",
      "Aisha Syed",
      "W. Sean Kennedy",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07382"
  },
  {
    "id": "arXiv:2209.07383",
    "title": "Visual Recognition with Deep Nearest Centroids",
    "abstract": "We devise deep nearest centroids (DNC), a conceptually elegant yet\nsurprisingly effective network for large-scale visual recognition, by\nrevisiting Nearest Centroids, one of the most classic and simple classifiers.\nCurrent deep models learn the classifier in a fully parametric manner, ignoring\nthe latent data structure and lacking simplicity and explainability. DNC\ninstead conducts nonparametric, case-based reasoning; it utilizes sub-centroids\nof training samples to describe class distributions and clearly explains the\nclassification as the proximity of test data and the class sub-centroids in the\nfeature space. Due to the distance-based nature, the network output\ndimensionality is flexible, and all the learnable parameters are only for data\nembedding. That means all the knowledge learnt for ImageNet classification can\nbe completely transferred for pixel recognition learning, under the\n\"pre-training and fine-tuning\" paradigm. Apart from its nested simplicity and\nintuitive decision-making mechanism, DNC can even possess ad-hoc explainability\nwhen the sub-centroids are selected as actual training images that humans can\nview and inspect. Compared with parametric counterparts, DNC performs better on\nimage classification (CIFAR-10, ImageNet) and greatly boots pixel recognition\n(ADE20K, Cityscapes), with improved transparency and fewer learnable\nparameters, using various network architectures (ResNet, Swin) and segmentation\nmodels (FCN, DeepLabV3, Swin). We feel this work brings fundamental insights\ninto related fields.",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Wenguan Wang",
      "Cheng Han",
      "Tianfei Zhou",
      "Dongfang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07383"
  },
  {
    "id": "arXiv:2209.07384",
    "title": "Self-Supervised Attention Networks and Uncertainty Loss Weighting for  Multi-Task Emotion Recognition on Vocal Bursts",
    "abstract": "Vocal bursts play an important role in communicating affect, making them\nvaluable for improving speech emotion recognition. Here, we present our\napproach for classifying vocal bursts and predicting their emotional\nsignificance in the ACII Affective Vocal Burst Workshop & Challenge 2022\n(A-VB). We use a large self-supervised audio model as shared feature extractor\nand compare multiple architectures built on classifier chains and attention\nnetworks, combined with uncertainty loss weighting strategies. Our approach\nsurpasses the challenge baseline by a wide margin on all four tasks.",
    "descriptor": "\nComments: 4 pages, 1 figure, submitted to The 2022 ACII Affective Vocal Burst Workshop & Challenge (A-VB)\n",
    "authors": [
      "Vincent Karas",
      "Andreas Triantafyllopoulos",
      "Meishu Song",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.07384"
  },
  {
    "id": "arXiv:2209.07385",
    "title": "Resilient Communication Scheme for Distributed Decision of  InterconnectingNetworks of Microgrids",
    "abstract": "Networking of microgrids can provide the operational flexibility needed for\nthe increasing number of DERs deployed at the distribution level and supporting\nend-use demand when there is loss of the bulk power system. But, networked\nmicrogrids are vulnerable to cyber-physical attacks and faults due to the\ncomplex interconnections. As such, it is necessary to design resilient control\nsystems to support the operations of networked microgrids in responses to\ncyber-physical attacks and faults. This paper introduces a resilient\ncommunication scheme for interconnecting multiple microgrids to support\ncritical demand, in which the interconnection decision can be made\ndistributedly by each microgrid controller even in the presence of cyberattacks\nto some communication links or microgrid controllers. This scheme blends a\nrandomized peer-to-peer communication network for exchanging information among\ncontrollers and resilient consensus algorithms for achieving reliable\ninterconnection agreement. The network of 6 microgrids divided from a modified\n123-node test distribution feeder is used to demonstrate the effectiveness of\nthe proposed resilient communication scheme.",
    "descriptor": "",
    "authors": [
      "Thanh Long Vu",
      "Sayak Mukherjee",
      "Veronica Adetola"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07385"
  },
  {
    "id": "arXiv:2209.07386",
    "title": "Pricing Optimal Outcomes in Coupled and Non-Convex Markets: Theory and  Applications to Electricity Markets",
    "abstract": "Classical results in general equilibrium theory assume divisible goods and\nconvex preferences of market participants. In many real-world markets,\nparticipants have non-convex preferences and the allocation problem needs to\nconsider complex constraints. Electricity markets are a prime example. In such\nmarkets, Walrasian prices are impossible, and heuristic pricing rules based on\nthe dual of the relaxed allocation problem are used in practice. However, these\nrules have been criticized for high side-payments and inadequate congestion\nsignals. We show that existing pricing heuristics optimize specific design\ngoals that can be conflicting. The trade-offs can be substantial, and we\nestablish that the design of pricing rules is fundamentally a multi-objective\noptimization problem addressing different incentives. In addition to\ntraditional multi-objective optimization techniques using weighing of\nindividual objectives, we introduce a novel parameter-free pricing rule that\nminimizes incentives for market participants to deviate locally. Our findings\nshow how the new pricing rule capitalizes on the upsides of existing pricing\nrules under scrutiny today. It leads to prices that incur low make-whole\npayments while providing adequate congestion signals and low lost opportunity\ncosts. Our suggested pricing rule does not require weighing of objectives, it\nis computationally scalable, and balances trade-offs in a principled manner,\naddressing an important policy issue in electricity markets.",
    "descriptor": "\nComments: 41 pages, 2 figures\n",
    "authors": [
      "Mete \u015eeref Ahunbay",
      "Martin Bichler",
      "Johannes Kn\u00f6rr"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.07386"
  },
  {
    "id": "arXiv:2209.07392",
    "title": "On the programming effort required to generate Behavior Trees and Finite  State Machines for robotic applications",
    "abstract": "In this paper we provide a practical demonstration of how the modularity in a\nBehavior Tree (BT) decreases the effort in programming a robot task when\ncompared to a Finite State Machine (FSM). In recent years the way to represent\na task plan to control an autonomous agent has been shifting from the standard\nFSM towards BTs. Many works in the literature have highlighted and proven the\nbenefits of such design compared to standard approaches, especially in terms of\nmodularity, reactivity and human readability. However, these works have often\nfailed in providing a tangible comparison in the implementation of those\npolicies and the programming effort required to modify them. This is a relevant\naspect in many robotic applications, where the design choice is dictated both\nby the robustness of the policy and by the time required to program it. In this\nwork, we compare backward chained BTs with a fault-tolerant design of FSMs by\nevaluating the cost to modify them. We validate the analysis with a set of\nexperiments in a simulation environment where a mobile manipulator solves an\nitem fetching task.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Matteo Iovino",
      "Julian F\u00f6rster",
      "Pietro Falco",
      "Jen Jen Chung",
      "Roland Siegwart",
      "Christian Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07392"
  },
  {
    "id": "arXiv:2209.07393",
    "title": "Online Marker-free Extrinsic Camera Calibration using Person Keypoint  Detections",
    "abstract": "Calibration of multi-camera systems, i.e. determining the relative poses\nbetween the cameras, is a prerequisite for many tasks in computer vision and\nrobotics. Camera calibration is typically achieved using offline methods that\nuse checkerboard calibration targets. These methods, however, often are\ncumbersome and lengthy, considering that a new calibration is required each\ntime any camera pose changes. In this work, we propose a novel, marker-free\nonline method for the extrinsic calibration of multiple smart edge sensors,\nrelying solely on 2D human keypoint detections that are computed locally on the\nsensor boards from RGB camera images. Our method assumes the intrinsic camera\nparameters to be known and requires priming with a rough initial estimate of\nthe camera poses. The person keypoint detections from multiple views are\nreceived at a central backend where they are synchronized, filtered, and\nassigned to person hypotheses. We use these person hypotheses to repeatedly\nsolve optimization problems in the form of factor graphs. Given suitable\nobservations of one or multiple persons traversing the scene, the estimated\ncamera poses converge towards a coherent extrinsic calibration within a few\nminutes. We evaluate our approach in real-world settings and show that the\ncalibration with our method achieves lower reprojection errors compared to a\nreference calibration generated by an offline method using a traditional\ncalibration target.",
    "descriptor": "\nComments: DAGM German Conference on Pattern Recognition (GCPR), Konstanz, September 2022\n",
    "authors": [
      "Bastian P\u00e4tzold",
      "Simon Bultmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07393"
  },
  {
    "id": "arXiv:2209.07394",
    "title": "ESAVE: Estimating Server and Virtual Machine Energy",
    "abstract": "Sustainable software engineering has received a lot of attention in recent\ntimes, as we witness an ever-growing slice of energy use, for example, at data\ncenters, as software systems utilize the underlying infrastructure.\nCharacterizing servers for their energy use accurately without being intrusive,\nis therefore important to make sustainable software deployment choices. In this\npaper, we introduce ESAVE which is a machine learning-based approach that\nleverages a small set of hardware attributes to characterize a server or\nvirtual machine's energy usage across different levels of utilization. This is\nbased upon an extensive exploration of multiple ML approaches, with a focus on\na minimal set of required attributes, while showcasing good accuracy. Early\nvalidations show that ESAVE has only around 12% average prediction error,\ndespite being non-intrusive.",
    "descriptor": "\nComments: 3 pages. To be published in the proceedings of 37th IEEE/ACM International Conference on Automated Software Engineering: Late Breaking Results Track (ASE '22), October 10-14, 2022, Michigan, USA\n",
    "authors": [
      "Priyavanshi Pathania",
      "Rohit Mehra",
      "Vibhu Saujanya Sharma",
      "Vikrant Kaulgud",
      "Sanjay Podder",
      "Adam P. Burden"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.07394"
  },
  {
    "id": "arXiv:2209.07397",
    "title": "Decision making in cancer: Causal questions require causal answers",
    "abstract": "Treatment decisions in cancer care are guided by treatment effect estimates\nfrom randomized controlled trials (RCTs). RCTs estimate the average effect of\none treatment versus another in a certain population. However, treatments may\nnot be equally effective for every patient in a population. Knowing the\neffectiveness of treatments tailored to specific patient and tumor\ncharacteristics would enable individualized treatment decisions. Getting\ntailored treatment effects by averaging outcomes in different patient subgroups\nin RCTs requires an unfeasible number of patients to have sufficient\nstatistical power in all relevant subgroups for all possible treatments.\nThe American Joint Committee on Cancer (AJCC) recommends that researchers\ndevelop outcome prediction models (OPMs) in an effort to individualize\ntreatment decisions. OPMs sometimes called risk models or prognosis models, use\npatient and tumor characteristics to predict a patient outcome such as overall\nsurvival. The assumption is that the predictions are useful for treatment\ndecisions using rules such as \"prescribe chemotherapy only if the OPM predicts\nthe patient has a high risk of recurrence\". Recognizing the importance of\nreliable predictions, the AJCC published a checklist for OPMs to ensure\ndependable OPM prediction accuracy in the patient population for which the OPM\nwas designed. However, accurate outcome predictions do not imply that these\npredictions yield good treatment decisions. In this perspective, we show that\nOPM rely on a fixed treatment policy which implies that OPM that were found to\naccurately predict outcomes in validation studies can still lead to patient\nharm when used to inform treatment decisions. We then give guidance on how to\ndevelop models that are useful for individualized treatment decisions and how\nto evaluate whether a model has value for decision-making.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Wouter A.C. van Amsterdam",
      "Pim A. de Jong",
      "Joost J.C. Verhoeff",
      "Tim Leiner",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07397"
  },
  {
    "id": "arXiv:2209.07399",
    "title": "A Light Recipe to Train Robust Vision Transformers",
    "abstract": "In this paper, we ask whether Vision Transformers (ViTs) can serve as an\nunderlying architecture for improving the adversarial robustness of machine\nlearning models against evasion attacks. While earlier works have focused on\nimproving Convolutional Neural Networks, we show that also ViTs are highly\nsuitable for adversarial training to achieve competitive performance. We\nachieve this objective using a custom adversarial training recipe, discovered\nusing rigorous ablation studies on a subset of the ImageNet dataset. The\ncanonical training recipe for ViTs recommends strong data augmentation, in part\nto compensate for the lack of vision inductive bias of attention modules, when\ncompared to convolutions. We show that this recipe achieves suboptimal\nperformance when used for adversarial training. In contrast, we find that\nomitting all heavy data augmentation, and adding some additional bag-of-tricks\n($\\varepsilon$-warmup and larger weight decay), significantly boosts the\nperformance of robust ViTs. We show that our recipe generalizes to different\nclasses of ViT architectures and large-scale models on full ImageNet-1k.\nAdditionally, investigating the reasons for the robustness of our models, we\nshow that it is easier to generate strong attacks during training when using\nour recipe and that this leads to better robustness at test time. Finally, we\nfurther study one consequence of adversarial training by proposing a way to\nquantify the semantic nature of adversarial perturbations and highlight its\ncorrelation with the robustness of the model. Overall, we recommend that the\ncommunity should avoid translating the canonical training recipes in ViTs to\nrobust training and rethink common training choices in the context of\nadversarial training.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Edoardo Debenedetti",
      "Vikash Sehwag",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07399"
  },
  {
    "id": "arXiv:2209.07400",
    "title": "Private Synthetic Data for Multitask Learning and Marginal Queries",
    "abstract": "We provide a differentially private algorithm for producing synthetic data\nsimultaneously useful for multiple tasks: marginal queries and multitask\nmachine learning (ML). A key innovation in our algorithm is the ability to\ndirectly handle numerical features, in contrast to a number of related prior\napproaches which require numerical features to be first converted into {high\ncardinality} categorical features via {a binning strategy}. Higher binning\ngranularity is required for better accuracy, but this negatively impacts\nscalability. Eliminating the need for binning allows us to produce synthetic\ndata preserving large numbers of statistical queries such as marginals on\nnumerical features, and class conditional linear threshold queries. Preserving\nthe latter means that the fraction of points of each class label above a\nparticular half-space is roughly the same in both the real and synthetic data.\nThis is the property that is needed to train a linear classifier in a multitask\nsetting. Our algorithm also allows us to produce high quality synthetic data\nfor mixed marginal queries, that combine both categorical and numerical\nfeatures. Our method consistently runs 2-5x faster than the best comparable\ntechniques, and provides significant accuracy improvements in both marginal\nqueries and linear prediction tasks for mixed-type datasets.",
    "descriptor": "\nComments: The short version of this paper appears in the proceedings of NeurIPS-22\n",
    "authors": [
      "Giuseppe Vietri",
      "Cedric Archambeau",
      "Sergul Aydore",
      "William Brown",
      "Michael Kearns",
      "Aaron Roth",
      "Ankit Siva",
      "Shuai Tang",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07400"
  },
  {
    "id": "arXiv:2209.07403",
    "title": "Private Stochastic Optimization in the Presence of Outliers: Optimal  Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses",
    "abstract": "We study differentially private (DP) stochastic optimization (SO) with data\ncontaining outliers and loss functions that are not Lipschitz continuous. To\ndate, the vast majority of work on DP SO assumes that the loss is Lipschitz\n(i.e. stochastic gradients are uniformly bounded), and their error bounds scale\nwith the Lipschitz parameter of the loss. While this assumption is convenient,\nit is often unrealistic: in many practical problems where privacy is required,\ndata may contain outliers or be unbounded, causing some stochastic gradients to\nhave large norm. In such cases, the Lipschitz parameter may be prohibitively\nlarge, leading to vacuous excess risk bounds. Thus, building on a recent line\nof work [WXDX20, KLZ22], we make the weaker assumption that stochastic\ngradients have bounded $k$-th moments for some $k \\geq 2$. Compared with works\non DP Lipschitz SO, our excess risk scales with the $k$-th moment bound instead\nof the Lipschitz parameter of the loss, allowing for significantly faster rates\nin the presence of outliers. For convex and strongly convex loss functions, we\nprovide the first asymptotically optimal excess risk bounds (up to a\nlogarithmic factor). Moreover, in contrast to the prior works [WXDX20, KLZ22],\nour bounds do not require the loss function to be differentiable/smooth. We\nalso devise an accelerated algorithm that runs in linear time and yields\nimproved (compared to prior works) and nearly optimal excess risk for smooth\nlosses. Additionally, our work is the first to address non-convex non-Lipschitz\nloss functions satisfying the Proximal-PL inequality; this covers some classes\nof neural nets, among other practical models. Our Proximal-PL algorithm has\nnearly optimal excess risk that almost matches the strongly convex lower bound.\nLastly, we provide shuffle DP variations of our algorithms, which do not\nrequire a trusted curator (e.g. for distributed learning).",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07403"
  },
  {
    "id": "arXiv:2209.07404",
    "title": "Self-Organizing Map Neural Network Algorithm for the Determination of  Fracture Location in Solid-State Process joined Dissimilar Alloys",
    "abstract": "The subject area known as computational neuroscience involves the\ninvestigation of brain function using mathematical techniques and theories. In\norder to comprehend how the brain processes information, it can also include\nvarious methods from signal processing, computer science, and physics. In the\npresent work, for the first time a neurobiological based unsupervised machine\nlearning algorithm i.e., Self-Organizing Map Neural Network is implemented for\ndetermining the fracture location in dissimilar friction stir welded\nAA5754-C11000 alloys. Too Shoulder Diameter (mm), Tool Rotational Speed (RPM),\nand Tool Traverse Speed (mm/min) are input parameters while the Fracture\nlocation i.e. whether the specimen fracture at Thermo-Mechanically Affected\nZone (TMAZ) of copper or it fractures at TMAZ of Aluminium. The results showed\nthat the implemented algorithm is able to predict the fracture location with\n96.92% accuracy.",
    "descriptor": "",
    "authors": [
      "Akshansh Mishra",
      "Anish Dasgupta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07404"
  },
  {
    "id": "arXiv:2209.07407",
    "title": "Chemotaxis of sea urchin sperm cells through deep reinforcement learning",
    "abstract": "By imitating biological microswimmers, microrobots can be designed to\naccomplish targeted delivery of cargos and biomedical manipulations at\nmicroscale. However, it is still a great challenge to enable microrobots to\nmaneuver in a complex environment. Machine learning algorithms offer a tool to\nboost mobility and flexibility of a synthetic microswimmer, hence could help us\ndesign truly smart microrobots. In this work, we investigate how a model of sea\nurchin sperm cell can self-learn chemotactic motion in a chemoattractant\nconcentration field. We employ an artificial neural network to act as a\ndecision-making agent and facilitate the sperm cell to discover efficient\nmaneuver strategies through a deep reinforcement learning (DRL) algorithm. Our\nresults show that chemotactic behaviours, very similar to the realistic ones,\ncan be achieved by the DRL utilizing only limited environmental information. In\nmost cases, the DRL algorithm discovers more efficient strategies than the\nhuman-devised one. Furthermore, the DRL can even utilize an external\ndisturbance to facilitate the chemotactic motion if the extra flow information\nis also taken into account by the artificial neural network. Our results\nprovide insights to the chemotactic process of sea urchin sperm cells and also\nprepare guidance for the intelligent maneuver of microrobots.",
    "descriptor": "",
    "authors": [
      "Chaojie Mo",
      "Xin Bian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2209.07407"
  },
  {
    "id": "arXiv:2209.07410",
    "title": "Arithmetic circuit tensor networks, multivariable function  representation, and high-dimensional integration",
    "abstract": "Many computational problems can be formulated in terms of high-dimensional\nfunctions. Simple representations of such functions and resulting computations\nwith them typically suffer from the \"curse of dimensionality\", an exponential\ncost dependence on dimension. Tensor networks provide a way to represent\ncertain classes of high-dimensional functions with polynomial memory. This\nresults in computations where the exponential cost is ameliorated or in some\ncases, removed, if the tensor network representation can be obtained. Here, we\nintroduce a direct mapping from the arithmetic circuit of a function to\narithmetic circuit tensor networks, avoiding the need to perform any\noptimization or functional fit. We demonstrate the power of the circuit\nconstruction in examples of multivariable integration on the unit hypercube in\nup to 50 dimensions, where the complexity of integration can be understood from\nthe circuit structure. We find very favorable cost scaling compared to\nquasi-Monte-Carlo integration for these cases, and further give an example\nwhere efficient quasi-Monte-Carlo cannot be theoretically performed without\nknowledge of the underlying tensor network circuit structure.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Ruojing Peng",
      "Johnnie Gray",
      "Garnet Kin-Lic Chan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07410"
  },
  {
    "id": "arXiv:2209.07413",
    "title": "Evolving Zero Cost Proxies For Neural Architecture Scoring",
    "abstract": "Neural Architecture Search (NAS) has significantly improved productivity in\nthe design and deployment of neural networks (NN). As NAS typically evaluates\nmultiple models by training them partially or completely, the improved\nproductivity comes at the cost of significant carbon footprint. To alleviate\nthis expensive training routine, zero-shot/cost proxies analyze an NN at\ninitialization to generate a score, which correlates highly with its true\naccuracy. Zero-cost proxies are currently designed by experts conducting\nmultiple cycles of empirical testing on possible algorithms, data-sets, and\nneural architecture design spaces. This lowers productivity and is an\nunsustainable approach towards zero-cost proxy design as deep learning\nuse-cases diversify in nature. Additionally, existing zero-cost proxies fail to\ngeneralize across neural architecture design spaces. In this paper, we propose\na genetic programming framework to automate the discovery of zero-cost proxies\nfor neural architecture scoring. Our methodology efficiently discovers an\ninterpretable and generalizable zero-cost proxy that gives state of the art\nscore-accuracy correlation on all data-sets and search spaces of NASBench-201\nand Network Design Spaces (NDS). We believe that this research indicates a\npromising direction towards automatically discovering zero-cost proxies that\ncan work across network architecture design spaces, data-sets, and tasks.",
    "descriptor": "",
    "authors": [
      "Yash Akhauri",
      "J. Pablo Munoz",
      "Nilesh Jain",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07413"
  },
  {
    "id": "arXiv:2209.07417",
    "title": "Examining Large Pre-Trained Language Models for Machine Translation:  What You Don't Know About It",
    "abstract": "Pre-trained language models (PLMs) often take advantage of the monolingual\nand multilingual dataset that is freely available online to acquire general or\nmixed domain knowledge before deployment into specific tasks. Extra-large PLMs\n(xLPLMs) are proposed very recently to claim supreme performances over\nsmaller-sized PLMs such as in machine translation (MT) tasks. These xLPLMs\ninclude Meta-AI's wmt21-dense-24-wide-en-X and NLLB. \\textit{In this work, we\nexamine if xLPLMs are absolutely superior to smaller-sized PLMs in fine-tuning\ntoward domain-specific MTs.} We use two different in-domain data of different\nsizes: commercial automotive in-house data and \\textbf{clinical} shared task\ndata from the ClinSpEn2022 challenge at WMT2022. We choose popular Marian\nHelsinki as smaller sized PLM and two massive-sized Mega-Transformers from\nMeta-AI as xLPLMs.\nOur experimental investigation shows that 1) on smaller sized in-domain\ncommercial automotive data, xLPLM wmt21-dense-24-wide-en-X indeed shows much\nbetter evaluation scores using S\\textsc{acre}BLEU and hLEPOR metrics than\nsmaller-sized Marian, even though its score increase rate is lower than Marian\nafter fine-tuning; 2) on relatively larger-size well prepared clinical data\nfine-tuning, the xLPLM NLLB \\textbf{tends to lose} its advantage over\nsmaller-sized Marian on two sub-tasks (clinical terms and ontology concepts)\nusing ClinSpEn offered metrics METEOR, COMET, and ROUGE-L, and totally lost to\nMarian on Task-1 (clinical cases) on all metrics including S\\textsc{acre}BLEU\nand BLEU; 3) \\textbf{metrics do not always agree} with each other on the same\ntasks using the same model outputs.",
    "descriptor": "\nComments: System paper submitted to WMT2022: BiomedicalMT Track (ClinSpEn2022)\n",
    "authors": [
      "Lifeng Han",
      "Gleb Erofeev",
      "Irina Sorokina",
      "Serge Gladkoff",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07417"
  },
  {
    "id": "arXiv:2209.07419",
    "title": "FFPA-Net: Efficient Feature Fusion with Projection Awareness for 3D  Object Detection",
    "abstract": "Promising complementarity exists between the texture features of color images\nand the geometric information of LiDAR point clouds. However, there still\npresent many challenges for efficient and robust feature fusion in the field of\n3D object detection. In this paper, first, unstructured 3D point clouds are\nfilled in the 2D plane and 3D point cloud features are extracted faster using\nprojection-aware convolution layers. Further, the corresponding indexes between\ndifferent sensor signals are established in advance in the data preprocessing,\nwhich enables faster cross-modal feature fusion. To address LiDAR points and\nimage pixels misalignment problems, two new plug-and-play fusion modules,\nLiCamFuse and BiLiCamFuse, are proposed. In LiCamFuse, soft query weights with\nperceiving the Euclidean distance of bimodal features are proposed. In\nBiLiCamFuse, the fusion module with dual attention is proposed to deeply\ncorrelate the geometric and textural features of the scene. The quantitative\nresults on the KITTI dataset demonstrate that the proposed method achieves\nbetter feature-level fusion. In addition, the proposed network shows a shorter\nrunning time compared to existing methods.",
    "descriptor": "\nComments: 7 pages, 4 figures; under review\n",
    "authors": [
      "Chaokang Jiang",
      "Guangming Wang",
      "Jinxing Wu",
      "Yanzi Miao",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07419"
  },
  {
    "id": "arXiv:2209.07420",
    "title": "Scalable Task-Driven Robotic Swarm Control via Collision Avoidance and  Learning Mean-Field Control",
    "abstract": "In recent years, reinforcement learning and its multi-agent analogue have\nachieved great success in solving various complex control problems. However,\nmulti-agent reinforcement learning remains challenging both in its theoretical\nanalysis and empirical design of algorithms, especially for large swarms of\nembodied robotic agents where a definitive toolchain remains part of active\nresearch. We use emerging state-of-the-art mean-field control techniques in\norder to convert many-agent swarm control into more classical single-agent\ncontrol of distributions. This allows profiting from advances in single-agent\nreinforcement learning at the cost of assuming weak interaction between agents.\nAs a result, the mean-field model is violated by the nature of real systems\nwith embodied, physically colliding agents. Here, we combine collision\navoidance and learning of mean-field control into a unified framework for\ntractably designing intelligent robotic swarm behavior. On the theoretical\nside, we provide novel approximation guarantees for both general mean-field\ncontrol in continuous spaces and with collision avoidance. On the practical\nside, we show that our approach outperforms multi-agent reinforcement learning\nand allows for decentralized open-loop application while avoiding collisions,\nboth in simulation and real UAV swarms. Overall, we propose a framework for the\ndesign of swarm behavior that is both mathematically well-founded and\npractically useful, enabling the solution of otherwise intractable swarm\nproblems.",
    "descriptor": "",
    "authors": [
      "Kai Cui",
      "Mengguang Li",
      "Christian Fabian",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07420"
  },
  {
    "id": "arXiv:2209.07421",
    "title": "Heart Attack Classification System using Neural Network Trained with  Particle Swarm Optimization",
    "abstract": "The prior detection of a heart attack could lead to the saving of one's life.\nPutting specific criteria into a system that provides an early warning of an\nimminent at-tack will be advantageous to a better prevention plan for an\nupcoming heart attack. Some studies have been conducted for this purpose, but\nyet the goal has not been reached to prevent a patient from getting such a\ndisease. In this paper, Neural Network trained with Particle Swarm Optimization\n(PSONN) is used to analyze the input criteria and enhance heart attack\nanticipation. A real and novel dataset that has been recorded on the disease is\nused. After preprocessing the data, the features are fed into the system. As a\nresult, the outcomes from PSONN have been evaluated against those from other\nalgorithms. Decision Tree, Random Forest, Neural network trained with\nBackpropagation (BPNN), and Naive Bayes were among those employed. Then the\nresults of 100%, 99.2424%, 99.2323%, 81.3131%, and 66.4141% are produced\nconcerning the mentioned algorithms, which show that PSONN has recorded the\nhighest accuracy rate among all other tested algorithms.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Askandar H. Amin",
      "Botan K. Ahmed",
      "Bestan B. Maaroof",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07421"
  },
  {
    "id": "arXiv:2209.07424",
    "title": "CMSBERT-CLR: Context-driven Modality Shifting BERT with Contrastive  Learning for linguistic, visual, acoustic Representations",
    "abstract": "Multimodal sentiment analysis has become an increasingly popular research\narea as the demand for multimodal online content is growing. For multimodal\nsentiment analysis, words can have different meanings depending on the\nlinguistic context and non-verbal information, so it is crucial to understand\nthe meaning of the words accordingly. In addition, the word meanings should be\ninterpreted within the whole utterance context that includes nonverbal\ninformation. In this paper, we present a Context-driven Modality Shifting BERT\nwith Contrastive Learning for linguistic, visual, acoustic Representations\n(CMSBERT-CLR), which incorporates the whole context's non-verbal and verbal\ninformation and aligns modalities more effectively through contrastive\nlearning. First, we introduce a Context-driven Modality Shifting (CMS) to\nincorporate the non-verbal and verbal information within the whole context of\nthe sentence utterance. Then, for improving the alignment of different\nmodalities within a common embedding space, we apply contrastive learning.\nFurthermore, we use an exponential moving average parameter and label smoothing\nas optimization strategies, which can make the convergence of the network more\nstable and increase the flexibility of the alignment. In our experiments, we\ndemonstrate that our approach achieves state-of-the-art results.",
    "descriptor": "\nComments: Accepted by IJCNN 2022\n",
    "authors": [
      "Junghun Kim",
      "Jihie Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.07424"
  },
  {
    "id": "arXiv:2209.07427",
    "title": "A case for DOT: Theoretical Foundations for Objects With Pattern  Matching and GADT-style Reasoning",
    "abstract": "Many programming languages in the OO tradition now support pattern matching\nin some form. Historical examples include Scala and Ceylon, with the more\nrecent additions of Java, Kotlin, TypeScript, and Flow. But pattern matching on\ngeneric class hierarchies currently results in puzzling type errors in most of\nthese languages. Yet this combination of features occurs naturally in many\nscenarios, such as when manipulating typed ASTs. To support it properly,\ncompilers needs to implement a form of subtyping reconstruction: the ability to\nreconstruct subtyping information uncovered at runtime during pattern matching.\nWe introduce cDOT, a new calculus in the family of Dependent Object Types (DOT)\nintended to serve as a formal foundation for subtyping reconstruction. Being\ndescended from pDOT, itself a formal foundation for Scala, cDOT can be used to\nencode advanced object-oriented features such as generic inheritance, type\nconstructor variance, F-bounded polymorphism, and first-class recursive\nmodules. We demonstrate that subtyping reconstruction subsumes GADTs by\nencoding $\\lambda_{2,G\\mu}$, a classical constraint-based GADT calculus, into\ncDOT.",
    "descriptor": "\nComments: 46 pages, 11 figures. For the associated mechanized proof of soundness, see this https URL\n",
    "authors": [
      "Aleksander Boruch-Gruszecki",
      "Rados\u0142aw Wa\u015bko",
      "Yichen Xu",
      "Lionel Parreaux"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.07427"
  },
  {
    "id": "arXiv:2209.07428",
    "title": "Astromorphic Self-Repair of Neuromorphic Hardware Systems",
    "abstract": "While neuromorphic computing architectures based on Spiking Neural Networks\n(SNNs) are increasingly gaining interest as a pathway toward bio-plausible\nmachine learning, attention is still focused on computational units like the\nneuron and synapse. Shifting from this neuro-synaptic perspective, this paper\nattempts to explore the self-repair role of glial cells, in particular,\nastrocytes. The work investigates stronger correlations with astrocyte\ncomputational neuroscience models to develop macro-models with a higher degree\nof bio-fidelity that accurately captures the dynamic behavior of the\nself-repair process. Hardware-software co-design analysis reveals that\nbio-morphic astrocytic regulation has the potential to self-repair hardware\nrealistic faults in neuromorphic hardware systems with significantly better\naccuracy and repair convergence for unsupervised learning tasks on the MNIST\nand F-MNIST datasets.",
    "descriptor": "",
    "authors": [
      "Zhuangyu Han",
      "Nafiul Islam",
      "Abhronil Sengupta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07428"
  },
  {
    "id": "arXiv:2209.07430",
    "title": "Machine Reading, Fast and Slow: When Do Models \"Understand\" Language?",
    "abstract": "Two of the most fundamental challenges in Natural Language Understanding\n(NLU) at present are: (a) how to establish whether deep learning-based models\nscore highly on NLU benchmarks for the 'right' reasons; and (b) to understand\nwhat those reasons would even be. We investigate the behavior of reading\ncomprehension models with respect to two linguistic 'skills': coreference\nresolution and comparison. We propose a definition for the reasoning steps\nexpected from a system that would be 'reading slowly', and compare that with\nthe behavior of five models of the BERT family of various sizes, observed\nthrough saliency scores and counterfactual explanations. We find that for\ncomparison (but not coreference) the systems based on larger encoders are more\nlikely to rely on the 'right' information, but even they struggle with\ngeneralization, suggesting that they still learn specific lexical patterns\nrather than the general principles of comparison.",
    "descriptor": "\nComments: Accepted COLING 2022\n",
    "authors": [
      "Sagnik Ray Choudhury",
      "Anna Rogers",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07430"
  },
  {
    "id": "arXiv:2209.07435",
    "title": "Hourly operation of a regulated lake via Model Predictive Control",
    "abstract": "The optimal operation of regulated lakes is a challenging task involving\nconflicting objectives, ranging from controlling lake levels to avoid floods\nand low levels to water supply downstream. The traditional approach to\noperation policy design is based on an offline optimization, where a feedback\ncontrol rule mapping lake storage into daily release decisions is identified\nover a set of observational data. In this paper, we propose a receding-horizon\npolicy for a more frequent, online regulation of the lake level, and we discuss\nits tuning as compared to benchmark approaches. As side contributions, we\nprovide a daily alternative based on the same rationale, and we show that this\nis still valid under some assumptions on the water inflow. Numerical\nsimulations are used to show the effectiveness of the proposed approach. We\ndemonstrate the approach on the regulated lake Como, Italy.",
    "descriptor": "\nComments: 6 pages, 5 figures, IFAC 2nd-CMWRS 2022, Milan\n",
    "authors": [
      "Raffaele G. Cestari",
      "Andrea Castelletti",
      "Simone Formentin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07435"
  },
  {
    "id": "arXiv:2209.07437",
    "title": "Mean-Field Approximation of Cooperative Constrained Multi-Agent  Reinforcement Learning (CMARL)",
    "abstract": "Mean-Field Control (MFC) has recently been proven to be a scalable tool to\napproximately solve large-scale multi-agent reinforcement learning (MARL)\nproblems. However, these studies are typically limited to unconstrained\ncumulative reward maximization framework. In this paper, we show that one can\nuse the MFC approach to approximate the MARL problem even in the presence of\nconstraints. Specifically, we prove that, an $N$-agent constrained MARL\nproblem, with state, and action spaces of each individual agents being of sizes\n$|\\mathcal{X}|$, and $|\\mathcal{U}|$ respectively, can be approximated by an\nassociated constrained MFC problem with an error, $e\\triangleq\n\\mathcal{O}\\left([\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}]/\\sqrt{N}\\right)$.\nIn a special case where the reward, cost, and state transition functions are\nindependent of the action distribution of the population, we prove that the\nerror can be improved to $e=\\mathcal{O}(\\sqrt{|\\mathcal{X}|}/\\sqrt{N})$. Also,\nwe provide a Natural Policy Gradient based algorithm and prove that it can\nsolve the constrained MARL problem within an error of $\\mathcal{O}(e)$ with a\nsample complexity of $\\mathcal{O}(e^{-6})$.",
    "descriptor": "",
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal",
      "Satish V. Ukkusuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.07437"
  },
  {
    "id": "arXiv:2209.07439",
    "title": "Coeffects for Sharing and Mutation",
    "abstract": "In type-and-coeffect systems, contexts are enriched by coeffects modeling how\nthey are actually used, typically through annotations on single variables.\nCoeffects are computed bottom-up, combining, for each term, the coeffects of\nits subterms, through a fixed set of algebraic operators. We show that this\nprincipled approach can be adopted to track sharing in the imperative paradigm,\nthat is, links among variables possibly introduced by the execution. This\nprovides a significant example of non-structural coeffects, which cannot be\ncomputed by-variable, since the way a given variable is used can affect the\ncoeffects of other variables. To illustrate the effectiveness of the approach,\nwe enhance the type system tracking sharing to model a sophisticated set of\nfeatures related to uniqueness and immutability. Thanks to the coeffect-based\napproach, we can express such features in a simple way and prove related\nproperties with standard techniques.",
    "descriptor": "",
    "authors": [
      "Riccardo Bianchini",
      "Francesco Dagnino",
      "Paola Giannini",
      "Elena Zucca",
      "Marco Servetto"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.07439"
  },
  {
    "id": "arXiv:2209.07440",
    "title": "Envy-freeness in 3D Hedonic Games",
    "abstract": "We study the problem of partitioning a set of agents into coalitions based on\nthe agents' additively separable preferences, which can also be viewed as a\nhedonic game. We apply three successively weaker solution concepts, namely\nenvy-freeness, weakly justified envy-freeness, and justified envy-freeness.\nIn a model in which coalitions may have any size, trivial solutions exist for\nthese concepts, which provides a strong motivation for placing restrictions on\ncoalition size. In this paper, we require feasible coalitions to have size\nthree. We study the existence of partitions that are envy-free, weakly\njustified envy-free, and justified envy-free, and the computational complexity\nof finding such partitions, if they exist.\nWe present a comprehensive complexity classification, in terms of the\nrestrictions placed on the agents' preferences. From this, we identify a\ngeneral trend that for the three successively weaker solution concepts,\nexistence and polynomial-time solvability hold under successively weaker\nrestrictions.",
    "descriptor": "\nComments: 78 pages, 6 figures\n",
    "authors": [
      "\u00c1gnes Cseh",
      "Michael McKay",
      "David Manlove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07440"
  },
  {
    "id": "arXiv:2209.07442",
    "title": "Automatic Error Analysis for Document-level Information Extraction",
    "abstract": "Document-level information extraction (IE) tasks have recently begun to be\nrevisited in earnest using the end-to-end neural network techniques that have\nbeen successful on their sentence-level IE counterparts. Evaluation of the\napproaches, however, has been limited in a number of dimensions. In particular,\nthe precision/recall/F1 scores typically reported provide few insights on the\nrange of errors the models make. We build on the work of Kummerfeld and Klein\n(2013) to propose a transformation-based framework for automating error\nanalysis in document-level event and (N-ary) relation extraction. We employ our\nframework to compare two state-of-the-art document-level template-filling\napproaches on datasets from three domains; and then, to gauge progress in IE\nsince its inception 30 years ago, vs. four systems from the MUC-4 (1992)\nevaluation.",
    "descriptor": "\nComments: Accepted to ACL 2022 Main Conference. First three authors contributed equally to this work\n",
    "authors": [
      "Aliva Das",
      "Xinya Du",
      "Barry Wang",
      "Kejian Shi",
      "Jiayuan Gu",
      "Thomas Porter",
      "Claire Cardie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07442"
  },
  {
    "id": "arXiv:2209.07446",
    "title": "Efficiency Ordering of Stochastic Gradient Descent",
    "abstract": "We consider the stochastic gradient descent (SGD) algorithm driven by a\ngeneral stochastic sequence, including i.i.d noise and random walk on an\narbitrary graph, among others; and analyze it in the asymptotic sense.\nSpecifically, we employ the notion of `efficiency ordering', a well-analyzed\ntool for comparing the performance of Markov Chain Monte Carlo (MCMC) samplers,\nfor SGD algorithms in the form of Loewner ordering of covariance matrices\nassociated with the scaled iterate errors in the long term. Using this\nordering, we show that input sequences that are more efficient for MCMC\nsampling also lead to smaller covariance of the errors for SGD algorithms in\nthe limit. This also suggests that an arbitrarily weighted MSE of SGD iterates\nin the limit becomes smaller when driven by more efficient chains. Our finding\nis of particular interest in applications such as decentralized optimization\nand swarm learning, where SGD is implemented in a random walk fashion on the\nunderlying communication graph for cost issues and/or data privacy. We\ndemonstrate how certain non-Markovian processes, for which typical mixing-time\nbased non-asymptotic bounds are intractable, can outperform their Markovian\ncounterparts in the sense of efficiency ordering for SGD. We show the utility\nof our method by applying it to gradient descent with shuffling and mini-batch\ngradient descent, reaffirming key results from existing literature under a\nunified framework. Empirically, we also observe efficiency ordering for\nvariants of SGD such as accelerated SGD and Adam, open up the possibility of\nextending our notion of efficiency ordering to a broader family of stochastic\noptimization algorithms.",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Jie Hu",
      "Vishwaraj Doshi",
      "Do Young Eun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07446"
  },
  {
    "id": "arXiv:2209.07448",
    "title": "Proving Hypersafety Compositionally",
    "abstract": "Hypersafety properties of arity $n$ are program properties that relate $n$\ntraces of a program (or, more generally, traces of $n$ programs). Classic\nexamples include determinism, idempotence, and associativity. A number of\nrelational program logics have been introduced to target this class of\nproperties. Their aim is to construct simpler proofs by capitalizing on\nstructural similarities between the $n$ related programs. We propose an\nunexplored, complementary proof principle that establishes hyper-triples (i.e.\nhypersafety judgments) as a unifying compositional building block for proofs,\nand we use it to develop a Logic for Hyper-triple Composition (LHC), which\nsupports forms of proof compositionality that were not achievable in previous\nlogics. We prove LHC sound and apply it to a number of challenging examples.",
    "descriptor": "\nComments: 44 pages. Extended version of the OOPSLA'22 paper with the same title. Includes full proofs and case studies in appendix\n",
    "authors": [
      "Emanuele D'Osualdo",
      "Azadeh Farzan",
      "Derek Dreyer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.07448"
  },
  {
    "id": "arXiv:2209.07449",
    "title": "Extended Intelligence",
    "abstract": "We argue that intelligence, construed as the disposition to perform tasks\nsuccessfully, is a property of systems composed of agents and their contexts.\nThis is the thesis of extended intelligence. We argue that the performance of\nan agent will generally not be preserved if its context is allowed to vary.\nHence, this disposition is not possessed by an agent alone, but is rather\npossessed by the system consisting of an agent and its context, which we dub an\nagent-in-context. An agent's context may include an environment, other agents,\ncultural artifacts (like language, technology), or all of these, as is\ntypically the case for humans and artificial intelligence systems, as well as\nmany non-human animals. In virtue of the thesis of extended intelligence, we\ncontend that intelligence is context-bound, task-particular and incommensurable\namong agents. Our thesis carries strong implications for how intelligence is\nanalyzed in the context of both psychology and artificial intelligence.",
    "descriptor": "",
    "authors": [
      "David L Barack",
      "Andrew Jaegle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.07449"
  },
  {
    "id": "arXiv:2209.07454",
    "title": "A Unifying Framework for Online Optimization with Long-Term Constraints",
    "abstract": "We study online learning problems in which a decision maker has to take a\nsequence of decisions subject to $m$ long-term constraints. The goal of the\ndecision maker is to maximize their total reward, while at the same time\nachieving small cumulative constraints violation across the $T$ rounds. We\npresent the first best-of-both-world type algorithm for this general class of\nproblems, with no-regret guarantees both in the case in which rewards and\nconstraints are selected according to an unknown stochastic model, and in the\ncase in which they are selected at each round by an adversary. Our algorithm is\nthe first to provide guarantees in the adversarial setting with respect to the\noptimal fixed strategy that satisfies the long-term constraints. In particular,\nit guarantees a $\\rho/(1+\\rho)$ fraction of the optimal reward and sublinear\nregret, where $\\rho$ is a feasibility parameter related to the existence of\nstrictly feasible solutions. Our framework employs traditional regret\nminimizers as black-box components. Therefore, by instantiating it with an\nappropriate choice of regret minimizers it can handle the full-feedback as well\nas the bandit-feedback setting. Moreover, it allows the decision maker to\nseamlessly handle scenarios with non-convex rewards and constraints. We show\nhow our framework can be applied in the context of budget-management mechanisms\nfor repeated auctions in order to guarantee long-term constraints that are not\npacking (e.g., ROI constraints).",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Andrea Celli",
      "Alberto Marchesi",
      "Giulia Romano",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07454"
  },
  {
    "id": "arXiv:2209.07459",
    "title": "A Robotic Visual Grasping Design: Rethinking Convolution Neural Network  with High-Resolutions",
    "abstract": "High-resolution representations are important for vision-based robotic\ngrasping problems. Existing works generally encode the input images into\nlow-resolution representations via sub-networks and then recover\nhigh-resolution representations. This will lose spatial information, and errors\nintroduced by the decoder will be more serious when multiple types of objects\nare considered or objects are far away from the camera. To address these\nissues, we revisit the design paradigm of CNN for robotic perception tasks. We\ndemonstrate that using parallel branches as opposed to serial stacked\nconvolutional layers will be a more powerful design for robotic visual grasping\ntasks. In particular, guidelines of neural network design are provided for\nrobotic perception tasks, e.g., high-resolution representation and lightweight\ndesign, which respond to the challenges in different manipulation scenarios. We\nthen develop a novel grasping visual architecture referred to as HRG-Net, a\nparallel-branch structure that always maintains a high-resolution\nrepresentation and repeatedly exchanges information across resolutions.\nExtensive experiments validate that these two designs can effectively enhance\nthe accuracy of visual-based grasping and accelerate network training. We show\na series of comparative experiments in real physical environments at Youtube:\nhttps://youtu.be/Jhlsp-xzHFY.",
    "descriptor": "",
    "authors": [
      "Zhangli Zhou",
      "Shaochen Wang",
      "Ziyang Chen",
      "Mingyu Cai",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07459"
  },
  {
    "id": "arXiv:2209.07463",
    "title": "Omnipredictors for Constrained Optimization",
    "abstract": "The notion of omnipredictors (Gopalan, Kalai, Reingold, Sharan and Wieder\nITCS 2021), suggested a new paradigm for loss minimization. Rather than\nlearning a predictor based on a known loss function, omnipredictors can easily\nbe post-processed to minimize any one of a rich family of loss functions\ncompared with the loss of a class $C$. It has been shown that such\nomnipredictors exist and are implied (for all convex and Lipschitz loss\nfunctions) by the notion of multicalibration from the algorithmic fairness\nliterature. Nevertheless, it is often the case that the action selected must\nobey some additional constraints (such as capacity or parity constraints). In\nitself, the original notion of omnipredictors does not apply in this\nwell-motivated and heavily studied the context of constrained loss\nminimization.\nIn this paper, we introduce omnipredictors for constrained optimization and\nstudy their complexity and implications. The notion that we introduce allows\nthe learner to be unaware of the loss function that will be later assigned as\nwell as the constraints that will be later imposed, as long as the\nsubpopulations that are used to define these constraints are known.\nThe paper shows how to obtain omnipredictors for constrained optimization\nproblems, relying on appropriate variants of multicalibration. For some\ninteresting constraints and general loss functions and for general constraints\nand some interesting loss functions, we show how omnipredictors are implied by\na variant of multicalibration that is similar in complexity to standard\nmulticalibration. We demonstrate that in the general case, standard\nmulticalibration is insufficient and show that omnipredictors are implied by\nmulticalibration with respect to a class containing all the level sets of\nhypotheses in $C$. We also investigate the implications when the constraints\nare group fairness notions.",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Lunjia Hu",
      "Inbal Livni-Navon",
      "Omer Reingold",
      "Chutong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.07463"
  },
  {
    "id": "arXiv:2209.07474",
    "title": "On the Surprising Effectiveness of Transformers in Low-Labeled Video  Recognition",
    "abstract": "Recently vision transformers have been shown to be competitive with\nconvolution-based methods (CNNs) broadly across multiple vision tasks. The less\nrestrictive inductive bias of transformers endows greater representational\ncapacity in comparison with CNNs. However, in the image classification setting\nthis flexibility comes with a trade-off with respect to sample efficiency,\nwhere transformers require ImageNet-scale training. This notion has carried\nover to video where transformers have not yet been explored for video\nclassification in the low-labeled or semi-supervised settings. Our work\nempirically explores the low data regime for video classification and discovers\nthat, surprisingly, transformers perform extremely well in the low-labeled\nvideo setting compared to CNNs. We specifically evaluate video vision\ntransformers across two contrasting video datasets (Kinetics-400 and\nSomethingSomething-V2) and perform thorough analysis and ablation studies to\nexplain this observation using the predominant features of video transformer\narchitectures. We even show that using just the labeled data, transformers\nsignificantly outperform complex semi-supervised CNN methods that leverage\nlarge-scale unlabeled data as well. Our experiments inform our recommendation\nthat semi-supervised learning video work should consider the use of video\ntransformers in the future.",
    "descriptor": "",
    "authors": [
      "Farrukh Rahman",
      "\u00d6mer Mubarek",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07474"
  },
  {
    "id": "arXiv:2209.07475",
    "title": "Neural Networks Reduction via Lumping",
    "abstract": "The increasing size of recently proposed Neural Networks makes it hard to\nimplement them on embedded devices, where memory, battery and computational\npower are a non-trivial bottleneck. For this reason during the last years\nnetwork compression literature has been thriving and a large number of\nsolutions has been been published to reduce both the number of operations and\nthe parameters involved with the models. Unfortunately, most of these reducing\ntechniques are actually heuristic methods and usually require at least one\nre-training step to recover the accuracy. The need of procedures for model\nreduction is well-known also in the fields of Verification and Performances\nEvaluation, where large efforts have been devoted to the definition of\nquotients that preserve the observable underlying behaviour. In this paper we\ntry to bridge the gap between the most popular and very effective network\nreduction strategies and formal notions, such as lumpability, introduced for\nverification and evaluation of Markov Chains. Elaborating on lumpability we\npropose a pruning approach that reduces the number of neurons in a network\nwithout using any data or fine-tuning, while completely preserving the exact\nbehaviour. Relaxing the constraints on the exact definition of the quotienting\nmethod we can give a formal explanation of some of the most common reduction\ntechniques.",
    "descriptor": "",
    "authors": [
      "Dalila Ressi",
      "Riccardo Romanello",
      "Sabina Rossi",
      "Carla Piazza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07475"
  },
  {
    "id": "arXiv:2209.07478",
    "title": "Control Barrier Function Contracts for Vehicular Mission Planning Under  Signal Temporal Logic Specifications",
    "abstract": "We present a compositional control synthesis method based on assume-guarantee\ncontracts with application to correct-by-construction design of vehicular\nmission plans. In our approach, a mission-level specification expressed in a\nfragment of signal temporal logic (STL) is decomposed into predicates defined\non non-overlapping time intervals. The STL predicates are then mapped to an\naggregation of contracts associated with continuously differentiable\ntime-varying control barrier functions. The barrier functions are used to\nconstrain the lower-level control synthesis problem, which is solved via\nquadratic programming. Our approach can avoid the conservatism of previous\nmethods for task-driven control based on under-approximations. We illustrate\nits effectiveness on a case study motivated by vehicular mission planning under\nsafety constraints as well as constraints imposed by traffic regulations under\nvehicle-to-vehicle and vehicle-to-infrastructure communication.",
    "descriptor": "\nComments: Extended version of paper accepted to appear at the 61st IEEE Conference on Decision and Control (CDC), 2022\n",
    "authors": [
      "Muhammad Waqas",
      "Nikhil Vijay Naik",
      "Petros Ioannou",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07478"
  },
  {
    "id": "arXiv:2209.07479",
    "title": "Gollum: A Gold Standard for Large Scale Multi Source Knowledge Graph  Matching",
    "abstract": "The number of Knowledge Graphs (KGs) generated with automatic and manual\napproaches is constantly growing. For an integrated view and usage, an\nalignment between these KGs is necessary on the schema as well as instance\nlevel. While there are approaches that try to tackle this multi source\nknowledge graph matching problem, large gold standards are missing to evaluate\ntheir effectiveness and scalability. We close this gap by presenting Gollum --\na gold standard for large-scale multi source knowledge graph matching with over\n275,000 correspondences between 4,149 different KGs. They originate from\nknowledge graphs derived by applying the DBpedia extraction framework to a\nlarge wiki farm. Three variations of the gold standard are made available: (1)\na version with all correspondences for evaluating unsupervised matching\napproaches, and two versions for evaluating supervised matching: (2) one where\neach KG is contained both in the train and test set, and (3) one where each KG\nis exclusively contained in the train or the test set.",
    "descriptor": "\nComments: accepted at AKBC 2022\n",
    "authors": [
      "Sven Hertling",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07479"
  },
  {
    "id": "arXiv:2209.07481",
    "title": "Rho-Tau Bregman Information and the Geometry of Annealing Paths",
    "abstract": "Markov Chain Monte Carlo methods for sampling from complex distributions and\nestimating normalization constants often simulate samples from a sequence of\nintermediate distributions along an annealing path, which bridges between a\ntractable initial distribution and a target density of interest. Prior work has\nconstructed annealing paths using quasi-arithmetic means, and interpreted the\nresulting intermediate densities as minimizing an expected divergence to the\nendpoints. We provide a comprehensive analysis of this 'centroid' property\nusing Bregman divergences under a monotonic embedding of the density function,\nthereby associating common divergences such as Amari's and Renyi's\n${\\alpha}$-divergences, ${(\\alpha,\\beta)}$-divergences, and the Jensen-Shannon\ndivergence with intermediate densities along an annealing path. Our analysis\nhighlights the interplay between parametric families, quasi-arithmetic means,\nand divergence functions using the rho-tau Bregman divergence framework of\nZhang 2004;2013.",
    "descriptor": "\nComments: 26 pages + appendix\n",
    "authors": [
      "Rob Brekelmans",
      "Frank Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.07481"
  },
  {
    "id": "arXiv:2209.07482",
    "title": "Euler scheme for approximation of solution of nonlinear ODEs under  inexact information",
    "abstract": "We investigate error of the Euler scheme in the case when the right-hand side\nfunction of the underlying ODE satisfies nonstandard assumptions such as local\none-side Lipschitz condition and local H\\\"older continuity. Moreover, we assume\ntwo cases in regards to information availability: exact and noisy with respect\nto the right-hand side function. Optimality analysis of the Euler scheme is\nalso provided. Lastly, we present the results of some numerical experiments.",
    "descriptor": "\nComments: 18 pages, 9 pages\n",
    "authors": [
      "Natalia Czy\u017cewska",
      "Pawe\u0142 M. Morkisz",
      "Pawe\u0142 Przyby\u0142owicz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07482"
  },
  {
    "id": "arXiv:2209.07484",
    "title": "Hydra Attention: Efficient Attention with Many Heads",
    "abstract": "While transformers have begun to dominate many tasks in vision, applying them\nto large images is still computationally difficult. A large reason for this is\nthat self-attention scales quadratically with the number of tokens, which in\nturn, scales quadratically with the image size. On larger images (e.g., 1080p),\nover 60% of the total computation in the network is spent solely on creating\nand applying attention matrices. We take a step toward solving this issue by\nintroducing Hydra Attention, an extremely efficient attention operation for\nVision Transformers (ViTs). Paradoxically, this efficiency comes from taking\nmulti-head attention to its extreme: by using as many attention heads as there\nare features, Hydra Attention is computationally linear in both tokens and\nfeatures with no hidden constants, making it significantly faster than standard\nself-attention in an off-the-shelf ViT-B/16 by a factor of the token count.\nMoreover, Hydra Attention retains high accuracy on ImageNet and, in some cases,\nactually improves it.",
    "descriptor": "\nComments: Accepted CADL 2022 (ECCV Workshop)\n",
    "authors": [
      "Daniel Bolya",
      "Cheng-Yang Fu",
      "Xiaoliang Dai",
      "Peizhao Zhang",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07484"
  },
  {
    "id": "arXiv:2209.07490",
    "title": "Semi-Symbolic Inference for Efficient Streaming Probabilistic  Programming",
    "abstract": "Efficient inference is often possible in a streaming context using\nRao-Blackwellized particle filters (RBPFs), which exactly solve inference\nproblems when possible and fall back on sampling approximations when necessary.\nWhile RBPFs can be implemented by hand to provide efficient inference, the goal\nof streaming probabilistic programming is to automatically generate such\nefficient inference implementations given input probabilistic programs.\nIn this work, we propose semi-symbolic inference, a technique for executing\nprobabilistic programs using a runtime inference system that automatically\nimplements Rao-Blackwellized particle filtering. To perform exact and\napproximate inference together, the semi-symbolic inference system manipulates\nsymbolic distributions to perform exact inference when possible and falls back\non approximate sampling when necessary. This approach enables the system to\nimplement the same RBPF a developer would write by hand. To ensure this, we\nidentify closed families of distributions -- such as linear-Gaussian and finite\ndiscrete models -- on which the inference system guarantees exact inference. We\nhave implemented the runtime inference system in the ProbZelus streaming\nprobabilistic programming language. Despite an average $1.6\\times$ slowdown\ncompared to the state of the art on existing benchmarks, our evaluation shows\nthat speedups of $3\\times$-$87\\times$ are obtainable on a new set of\nchallenging benchmarks we have designed to exploit closed families.",
    "descriptor": "",
    "authors": [
      "Eric Atkinson",
      "Charles Yuan",
      "Guillaume Baudart",
      "Louis Mandel",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.07490"
  },
  {
    "id": "arXiv:2209.07491",
    "title": "Defending Root DNS Servers Against DDoS Using Layered Defenses",
    "abstract": "Distributed Denial-of-Service (DDoS) attacks exhaust resources, leaving a\nserver unavailable to legitimate clients. The Domain Name System (DNS) is a\nfrequent target of DDoS attacks. Since DNS is a critical infrastructure\nservice, protecting it from DoS is imperative. Many prior approaches have\nfocused on specific filters or anti-spoofing techniques to protect generic\nservices. DNS root nameservers are more challenging to protect, since they use\nfixed IP addresses, serve very diverse clients and requests, receive\npredominantly UDP traffic that can be spoofed, and must guarantee high quality\nof service. In this paper we propose a layered DDoS defense for DNS root\nnameservers. Our defense uses a library of defensive filters, which can be\noptimized for different attack types, with different levels of selectivity. We\nfurther propose a method that automatically and continuously evaluates and\nselects the best combination of filters throughout the attack. We show that\nthis layered defense approach provides exceptional protection against all\nattack types using traces of ten real attacks from a DNS root nameserver. Our\nautomated system can select the best defense within seconds and quickly reduces\ntraffic to the server within a manageable range, while keeping collateral\ndamage lower than 2%. We can handle millions of filtering rules without\nnoticeable operational overhead.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "A S M Rizvi",
      "Jelena Mirkovic",
      "John Heidemann",
      "Wesley Hardaker",
      "Robert Story"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.07491"
  },
  {
    "id": "arXiv:2209.07493",
    "title": "Decentralized Infrastructure for (Neuro)science",
    "abstract": "The most pressing problems in science are neither empirical nor theoretical,\nbut infrastructural. Scientific practice is defined by coproductive, mutually\nreinforcing infrastructural deficits and incentive systems that everywhere\nconstrain and contort our art of curiosity in service of profit and prestige.\nOur infrastructural problems are not unique to science, but reflective of the\nbroader logic of digital enclosure where platformatized control of information\nproduction and extraction fuels some of the largest corporations in the world.\nI have taken lessons learned from decades of intertwined digital cultures\nwithin and beyond academia like wikis, pirates, and librarians in order to\ndraft a path towards more liberatory infrastructures for both science and\nsociety. Based on a system of peer-to-peer linked data, I sketch interoperable\nsystems for shared data, tools, and knowledge that map onto three domains of\nplatform capture: storage, computation and communication. The challenge of\ninfrastructure is not solely technical, but also social and cultural, and so I\nattempt to ground a practical development blueprint in an ethics for organizing\nand maintaining it. I intend this draft as a rallying call for organization, to\nbe revised with the input of collaborators and through the challenges posed by\nits implementation. I argue that a more liberatory future for science is\nneither utopian nor impractical -- the truly impractical choice is to continue\nto organize science as prestige fiefdoms resting on a pyramid scheme of\nunderpaid labor, playing out the clock as every part of our work is swallowed\nwhole by circling information conglomerates. It was arguably scientists looking\nfor a better way to communicate that created something as radical as the\ninternet in the first place, and I believe we can do it again.",
    "descriptor": "\nComments: Original Web Document: this https URL\n",
    "authors": [
      "Jonny L. Saunders"
    ],
    "subjectives": [
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2209.07493"
  },
  {
    "id": "arXiv:2209.07494",
    "title": "Hierarchical Attention Network for Explainable Depression Detection on  Twitter Aided by Metaphor Concept Mappings",
    "abstract": "Automatic depression detection on Twitter can help individuals privately and\nconveniently understand their mental health status in the early stages before\nseeing mental health professionals. Most existing black-box-like deep learning\nmethods for depression detection largely focused on improving classification\nperformance. However, explaining model decisions is imperative in health\nresearch because decision-making can often be high-stakes and life-and-death.\nReliable automatic diagnosis of mental health problems including depression\nshould be supported by credible explanations justifying models' predictions. In\nthis work, we propose a novel explainable model for depression detection on\nTwitter. It comprises a novel encoder combining hierarchical attention\nmechanisms and feed-forward neural networks. To support psycholinguistic\nstudies, our model leverages metaphorical concept mappings as input. Thus, it\nnot only detects depressed individuals, but also identifies features of such\nusers' tweets and associated metaphor concept mappings.",
    "descriptor": "",
    "authors": [
      "Sooji Han",
      "Rui Mao",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07494"
  },
  {
    "id": "arXiv:2209.07496",
    "title": "Unsupervised Opinion Summarization Using Approximate Geodesics",
    "abstract": "Opinion summarization is the task of creating summaries capturing popular\nopinions from user reviews. In this paper, we introduce Geodesic Summarizer\n(GeoSumm), a novel system to perform unsupervised extractive opinion\nsummarization. GeoSumm involves an encoder-decoder based representation\nlearning model, that generates representations of text as a distribution over\nlatent semantic units. GeoSumm generates these representations by performing\ndictionary learning over pre-trained text representations at multiple decoder\nlayers. We then use these representations to quantify the relevance of review\nsentences using a novel approximate geodesic distance based scoring mechanism.\nWe use the relevance scores to identify popular opinions in order to compose\ngeneral and aspect-specific summaries. Our proposed model, GeoSumm, achieves\nstate-of-the-art performance on three opinion summarization datasets. We\nperform additional experiments to analyze the functioning of our model and\nshowcase the generalization ability of {\\X} across different domains.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Nicholas Monath",
      "Avinava Dubey",
      "Amr Ahmed",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07496"
  },
  {
    "id": "arXiv:2209.07497",
    "title": "On Power Set Axiom",
    "abstract": "Usual math sets have special types: countable, compact, open, occasionally\nBorel, rarely projective, etc. Generic sets dependent on Power Set axiom appear\nmostly in esoteric areas, ST logic, etc. Dropping that Axiom may greatly\nsimplify the foundations of mainstream math. Meanwhile dependence on it of a\ntheorem is worth noting, as dependence on Choice often is.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Leonid A. Levin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.07497"
  },
  {
    "id": "arXiv:2209.07498",
    "title": "Detecting Synthetic Speech Manipulation in Real Audio Recordings",
    "abstract": "Recent advances in artificial speech and audio technologies have improved the\nabilities of deep-fake operators to falsify media and spread malicious\nmisinformation. Anyone with limited coding skills can use freely available\nspeech synthesis tools to create convincing simulations of influential\nspeakers' voices with the malicious intent to distort the original message.\nWith the latest technology, malicious operators do not have to generate an\nentire audio clip; instead, they can insert a partial manipulation or a segment\nof synthetic speech into a genuine audio recording to change the entire context\nand meaning of the original message. Detecting these insertions is especially\nchallenging because partially manipulated audio can more easily avoid synthetic\nspeech detectors than entirely fake messages can. This paper describes a\npotential partial synthetic speech detection system based on the x-ResNet\narchitecture with a probabilistic linear discriminant analysis (PLDA) backend\nand interleaved aware score processing. Experimental results suggest that the\nPLDA backend results in a 25% average error reduction among partially\nsynthesized datasets over a non-PLDA baseline.",
    "descriptor": "\nComments: Submitted to IEEE International Workshop on Information Forensics and Security (WIFS)\n",
    "authors": [
      "Md Hafizur Rahman",
      "Martin Graciarena",
      "Diego Castan",
      "Chris Cobo-Kroenke",
      "Mitchell McLaren",
      "Aaron Lawson"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.07498"
  },
  {
    "id": "arXiv:2209.07499",
    "title": "DiP-GNN: Discriminative Pre-Training of Graph Neural Networks",
    "abstract": "Graph neural network (GNN) pre-training methods have been proposed to enhance\nthe power of GNNs. Specifically, a GNN is first pre-trained on a large-scale\nunlabeled graph and then fine-tuned on a separate small labeled graph for\ndownstream applications, such as node classification. One popular pre-training\nmethod is to mask out a proportion of the edges, and a GNN is trained to\nrecover them. However, such a generative method suffers from graph mismatch.\nThat is, the masked graph inputted to the GNN deviates from the original graph.\nTo alleviate this issue, we propose DiP-GNN (Discriminative Pre-training of\nGraph Neural Networks). Specifically, we train a generator to recover\nidentities of the masked edges, and simultaneously, we train a discriminator to\ndistinguish the generated edges from the original graph's edges. In our\nframework, the graph seen by the discriminator better matches the original\ngraph because the generator can recover a proportion of the masked edges.\nExtensive experiments on large-scale homogeneous and heterogeneous graphs\ndemonstrate the effectiveness of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Haoming Jiang",
      "Qingyu Yin",
      "Xianfeng Tang",
      "Bing Yin",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07499"
  },
  {
    "id": "arXiv:2209.07503",
    "title": "Robust Locomotion on Legged Robots through Planning on Motion Primitive  Graphs",
    "abstract": "The functional demands of robotic systems often require completing various\ntasks or behaviors under the effect of disturbances or uncertain environments.\nOf increasing interest is the autonomy for dynamic robots, such as multirotors,\nmotor vehicles, and legged platforms. Here, disturbances and environmental\nconditions can have significant impact on the successful performance of the\nindividual dynamic behaviors, referred to as \"motion primitives\". Despite this,\nrobustness can be achieved by switching to and transitioning through suitable\nmotion primitives. This paper contributes such a method by presenting an\nabstraction of the motion primitive dynamics and a corresponding \"motion\nprimitive transfer function\". From this, a mixed discrete and continuous\n\"motion primitive graph\" is constructed, and an algorithm capable of online\nsearch of this graph is detailed. The result is a framework capable of\nrealizing holistic robustness on dynamic systems. This is experimentally\ndemonstrated for a set of motion primitives on a quadrupedal robot, subject to\nvarious environmental and intentional disturbances.",
    "descriptor": "",
    "authors": [
      "Wyatt Ubellacker",
      "Aaron Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07503"
  },
  {
    "id": "arXiv:2209.07504",
    "title": "Computing mixed Schatten norm of completely positive maps",
    "abstract": "Computing $p \\rightarrow q$ norm for matrices is a classical problem in\ncomputational mathematics and power iteration is a well-known method for\ncomputing $p \\rightarrow q $ norm for a matrix with nonnegative entries. Here\nwe define an equivalent iteration method for computing $ S_p \\rightarrow S_q $\nnorm for completely positive maps where $S_p$ is the Schatten $p$ norm. We\ngeneralize almost all of the definitions, properties, lemmas, etc. in the\nmatrix setting to completely positive maps and prove an important theorem in\nthis setting.",
    "descriptor": "",
    "authors": [
      "Mohammad ShahverdiKondori",
      "Sio On Chan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07504"
  },
  {
    "id": "arXiv:2209.07507",
    "title": "Bidirectional Learning for Offline Infinite-width Model-based  Optimization",
    "abstract": "In offline model-based optimization, we strive to maximize a black-box\nobjective function by only leveraging a static dataset of designs and their\nscores. This problem setting arises in numerous fields including the design of\nmaterials, robots, DNA sequences, and proteins. Recent approaches train a deep\nneural network (DNN) on the static dataset to act as a proxy function, and then\nperform gradient ascent on the existing designs to obtain potentially\nhigh-scoring designs. This methodology frequently suffers from the\nout-of-distribution problem where the proxy function often returns poor\ndesigns. To mitigate this problem, we propose BiDirectional learning for\noffline Infinite-width model-based optimization} (BDI). BDI consists of two\nmappings: the forward mapping leverages the static dataset to predict the\nscores of the high-scoring designs, and the backward mapping leverages the\nhigh-scoring designs to predict the scores of the static dataset. The backward\nmapping, neglected in previous work, can distill more information from the\nstatic dataset into the high-scoring designs, which effectively mitigates the\nout-of-distribution problem. For a finite-width DNN model, the loss function of\nthe backward mapping is intractable and only has an approximate form, which\nleads to a significant deterioration of the design quality. We thus adopt an\ninfinite-width DNN model, and propose to employ the corresponding neural\ntangent kernel to yield a closed-form loss for more accurate design updates.\nExperiments on {various} tasks verify the effectiveness of BDI. The code is\navailable at https://github.com/GGchen1997/BDI.",
    "descriptor": "\nComments: Accepted by NeurIPS2022; AI4Science; Drug discovery; Offline model-based optimization; Neural tangent kernel; Bi-level optimization\n",
    "authors": [
      "Chen",
      "Yingxue Zhang",
      "Jie Fu",
      "Mark Coates"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.07507"
  },
  {
    "id": "arXiv:2209.07509",
    "title": "Random initialisations performing above chance and how to find them",
    "abstract": "Neural networks trained with stochastic gradient descent (SGD) starting from\ndifferent random initialisations typically find functionally very similar\nsolutions, raising the question of whether there are meaningful differences\nbetween different SGD solutions. Entezari et al. recently conjectured that\ndespite different initialisations, the solutions found by SGD lie in the same\nloss valley after taking into account the permutation invariance of neural\nnetworks. Concretely, they hypothesise that any two solutions found by SGD can\nbe permuted such that the linear interpolation between their parameters forms a\npath without significant increases in loss. Here, we use a simple but powerful\nalgorithm to find such permutations that allows us to obtain direct empirical\nevidence that the hypothesis is true in fully connected networks. Strikingly,\nwe find that two networks already live in the same loss valley at the time of\ninitialisation and averaging their random, but suitably permuted initialisation\nperforms significantly above chance. In contrast, for convolutional\narchitectures, our evidence suggests that the hypothesis does not hold.\nEspecially in a large learning rate regime, SGD seems to discover diverse\nmodes.",
    "descriptor": "",
    "authors": [
      "Frederik Benzing",
      "Simon Schug",
      "Robert Meier",
      "Johannes von Oswald",
      "Yassir Akram",
      "Nicolas Zucchet",
      "Laurence Aitchison",
      "Angelika Steger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07509"
  },
  {
    "id": "arXiv:2209.07511",
    "title": "Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language  Models",
    "abstract": "Pre-trained vision-language models (e.g., CLIP) have shown promising\nzero-shot generalization in many downstream tasks with properly designed text\nprompts. Instead of relying on hand-engineered prompts, recent works learn\nprompts using the training data from downstream tasks. While effective,\ntraining on domain-specific data reduces a model's generalization capability to\nunseen new domains. In this work, we propose test-time prompt tuning (TPT), a\nmethod that can learn adaptive prompts on the fly with a single test sample.\nFor image classification, TPT optimizes the prompt by minimizing the entropy\nwith confidence selection so that the model has consistent predictions across\ndifferent augmented views of each test sample. In evaluating generalization to\nnatural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP\nby 3.6% on average, surpassing previous prompt tuning approaches that require\nadditional task-specific training data. In evaluating cross-dataset\ngeneralization with unseen categories, TPT performs on par with the\nstate-of-the-art approaches that use additional training data. Project page:\nhttps://azshue.github.io/TPT.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Manli Shu",
      "Weili Nie",
      "De-An Huang",
      "Zhiding Yu",
      "Tom Goldstein",
      "Anima Anandkumar",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07511"
  },
  {
    "id": "arXiv:2209.07515",
    "title": "Medical Image Segmentation using LeViT-UNet++: A Case Study on GI Tract  Data",
    "abstract": "Gastro-Intestinal Tract cancer is considered a fatal malignant condition of\nthe organs in the GI tract. Due to its fatality, there is an urgent need for\nmedical image segmentation techniques to segment organs to reduce the treatment\ntime and enhance the treatment. Traditional segmentation techniques rely upon\nhandcrafted features and are computationally expensive and inefficient. Vision\nTransformers have gained immense popularity in many image classification and\nsegmentation tasks. To address this problem from a transformers' perspective,\nwe introduced a hybrid CNN-transformer architecture to segment the different\norgans from an image. The proposed solution is robust, scalable, and\ncomputationally efficient, with a Dice and Jaccard coefficient of 0.79 and\n0.72, respectively. The proposed solution also depicts the essence of deep\nlearning-based automation to improve the effectiveness of the treatment",
    "descriptor": "\nComments: Paper accepted at the 26th International Computer Science and Engineering Conference (ICSEC)\n",
    "authors": [
      "Praneeth Nemani",
      "Satyanarayana Vollala"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.07515"
  },
  {
    "id": "arXiv:2209.07517",
    "title": "Spectral Total-Variation Processing of Shapes -- Theory and Applications",
    "abstract": "In this work we present a comprehensive analysis of total variation (TV) on\nnon Euclidean domains and its eigenfunctions. We specifically address\nparameterized surfaces, a natural representation of the shapes used in 3D\ngraphics. Our work sheds new light on the celebrated Beltrami and Anisotropic\nTV flows, and explains experimental findings from recent years on shape\nspectral TV [Fumero et al. 2020] and adaptive anisotropic spectral TV [Biton\nand Gilboa 2022]. A new notion of convexity on manifolds is derived, by\ncharacterizing structures that are stable throughout the TV flow, performed on\nmanifolds. We further propose a time efficient nonlinear and non Euclidean\nspectral framework for shape processing that is based on zero homogeneous\nflows, and propose three different such methods. Each method satisfies distinct\ncharacteristics, demonstrated through smoothing, enhancing and exaggerating\nfilters.",
    "descriptor": "\nComments: 14, pages, 15 figures\n",
    "authors": [
      "Jonathan Brokman",
      "Martin Burger",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2209.07517"
  },
  {
    "id": "arXiv:2209.07518",
    "title": "Distribution Aware Metrics for Conditional Natural Language Generation",
    "abstract": "Traditional automated metrics for evaluating conditional natural language\ngeneration use pairwise comparisons between a single generated text and the\nbest-matching gold-standard ground truth text. When multiple ground truths are\navailable, scores are aggregated using an average or max operation across\nreferences. While this approach works well when diversity in the ground truth\ndata (i.e. dispersion of the distribution of conditional texts) can be ascribed\nto noise, such as in automated speech recognition, it does not allow for robust\nevaluation in the case where diversity in the ground truths represents signal\nfor the model. In this work we argue that existing metrics are not appropriate\nfor domains such as visual description or summarization where ground truths are\nsemantically diverse, and where the diversity in those captions captures useful\nadditional information about the context. We propose a novel paradigm for\nmulti-candidate evaluation of conditional language generation models, and a new\nfamily of metrics that compare the distributions of reference and\nmodel-generated caption sets using small sample sets of each. We demonstrate\nthe utility of our approach with a case study in visual description: where we\nshow that existing models optimize for single-description quality over\ndiversity, and gain some insights into how sampling methods and temperature\nimpact description quality and diversity.",
    "descriptor": "",
    "authors": [
      "David M Chan",
      "Yiming Ni",
      "Austin Myers",
      "Sudheendra Vijayanarasimhan",
      "David A Ross",
      "John Canny"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07518"
  },
  {
    "id": "arXiv:2209.07520",
    "title": "On (Random-order) Online Contention Resolution Schemes for the Matching  Polytope of (Bipartite) Graphs",
    "abstract": "We present new results for online contention resolution schemes for the\nmatching polytope of graphs, in the random-order (RCRS) and adversarial (OCRS)\narrival models. Our results include improved selectability guarantees (i.e.,\nlower bounds), as well as new impossibility results (i.e., upper bounds). By\nwell-known reductions to the prophet (secretary) matching problem, a\n$c$-selectable OCRS (RCRS) implies a $c$-competitive algorithm for adversarial\n(random order) edge arrivals. Similar reductions are also known for the\nquery-commit matching problem. For the adversarial arrival model, we present a\nnew analysis of the OCRS of Ezra et al.~(EC, 2020). We show that this scheme is\n$0.344$-selectable for general graphs and $0.349$-selectable for bipartite\ngraphs, improving on the previous $0.337$ selectability result for this\nalgorithm. We also show that the selectability of this scheme cannot be greater\nthan $0.361$ for general graphs and $0.382$ for bipartite graphs. We further\nshow that no OCRS can achieve a selectability greater than $0.4$ for general\ngraphs, and $0.433$ for bipartite graphs.\nFor random-order arrivals, we present two attenuation-based schemes which use\nnew attenuation functions. Our first RCRS is $0.474$-selectable for general\ngraphs, and our second is $0.476$-selectable for bipartite graphs. These\nresults improve upon the recent $0.45$ (and $0.456$) selectability results for\ngeneral graphs (respectively, bipartite graphs) due to Pollner et al.~(EC,\n2022). On general graphs, our 0.474-selectable RCRS provides the best known\npositive result even for offline contention resolution, and also for the\ncorrelation gap. We conclude by proving a fundamental upper bound of 0.5 on the\nselectability of RCRS, using bipartite graphs.",
    "descriptor": "",
    "authors": [
      "Calum MacRury",
      "Will Ma",
      "Nathaniel Grammel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.07520"
  },
  {
    "id": "arXiv:2209.07521",
    "title": "On-Device Domain Generalization",
    "abstract": "We present a systematic study of domain generalization (DG) for tiny neural\nnetworks, a problem that is critical to on-device machine learning applications\nbut has been overlooked in the literature where research has been focused on\nlarge models only. Tiny neural networks have much fewer parameters and lower\ncomplexity, and thus should not be trained the same way as their large\ncounterparts for DG applications. We find that knowledge distillation is a\nstrong candidate for solving the problem: it outperforms state-of-the-art DG\nmethods that were developed using large models with a large margin. Moreover,\nwe observe that the teacher-student performance gap on test data with domain\nshift is bigger than that on in-distribution data. To improve DG for tiny\nneural networks without increasing the deployment cost, we propose a simple\nidea called out-of-distribution knowledge distillation (OKD), which aims to\nteach the student how the teacher handles (synthetic) out-of-distribution data\nand is proved to be a promising framework for solving the problem. We also\ncontribute a scalable method of creating DG datasets, called DOmain Shift in\nCOntext (DOSCO), which can be applied to broad data at scale without much human\neffort. Code and models are released at\n\\url{https://github.com/KaiyangZhou/on-device-dg}.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Kaiyang Zhou",
      "Yuanhan Zhang",
      "Yuhang Zang",
      "Jingkang Yang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07521"
  },
  {
    "id": "arXiv:2209.07522",
    "title": "Test-Time Training with Masked Autoencoders",
    "abstract": "Test-time training adapts to a new test distribution on the fly by optimizing\na model for each test input using self-supervision. In this paper, we use\nmasked autoencoders for this one-sample learning problem. Empirically, our\nsimple method improves generalization on many visual benchmarks for\ndistribution shifts. Theoretically, we characterize this improvement in terms\nof the bias-variance trade-off.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yossi Gandelsman",
      "Yu Sun",
      "Xinlei Chen",
      "Alexei A. Efros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07522"
  },
  {
    "id": "arXiv:2209.07524",
    "title": "$\\tilde{O}(n+\\mathrm{poly}(k))$-time Algorithm for Bounded Tree Edit  Distance",
    "abstract": "Computing the edit distance of two strings is one of the most basic problems\nin computer science and combinatorial optimization. Tree edit distance is a\nnatural generalization of edit distance in which the task is to compute a\nmeasure of dissimilarity between two (unweighted) rooted trees with node\nlabels. Perhaps the most notable recent application of tree edit distance is in\nNoSQL big databases, such as MongoDB, where each row of the database is a JSON\ndocument represented as a labeled rooted tree, and finding dissimilarity\nbetween two rows is a basic operation. Until recently, the fastest algorithm\nfor tree edit distance ran in cubic time (Demaine, Mozes, Rossman, Weimann;\nTALG'10); however, Mao (FOCS'21) broke the cubic barrier for the tree edit\ndistance problem using fast matrix multiplication.\nGiven a parameter $k$ as an upper bound on the distance, an $O(n+k^2)$-time\nalgorithm for edit distance has been known since the 1980s due to the works of\nMyers (Algorithmica'86) and Landau and Vishkin (JCSS'88). The existence of an\n$\\tilde{O}(n+\\mathrm{poly}(k))$-time algorithm for tree edit distance has been\nposed as an open question, e.g., by Akmal and Jin (ICALP'21), who gave a\nstate-of-the-art $\\tilde{O}(nk^2)$-time algorithm. In this paper, we answer\nthis question positively.",
    "descriptor": "\nComments: Full version of a paper accepted to FOCS 2022\n",
    "authors": [
      "Debarati Das",
      "Jacob Gilbert",
      "MohammadTaghi Hajiaghayi",
      "Tomasz Kociumaka",
      "Barna Saha",
      "Hamed Saleh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07524"
  },
  {
    "id": "arXiv:2209.07526",
    "title": "OmniVL:One Foundation Model for Image-Language and Video-Language Tasks",
    "abstract": "This paper presents OmniVL, a new foundation model to support both\nimage-language and video-language tasks using one universal architecture. It\nadopts a unified transformer-based visual encoder for both image and video\ninputs, and thus can perform joint image-language and video-language\npretraining. We demonstrate, for the first time, such a paradigm benefits both\nimage and video tasks, as opposed to the conventional one-directional transfer\n(e.g., use image-language to help video-language). To this end, we propose a\ndecoupled joint pretraining of image-language and video-language to effectively\ndecompose the vision-language modeling into spatial and temporal dimensions and\nobtain performance boost on both image and video tasks. Moreover, we introduce\na novel unified vision-language contrastive (UniVLC) loss to leverage\nimage-text, video-text, image-label (e.g., image classification), video-label\n(e.g., video action recognition) data together, so that both supervised and\nnoisily supervised pretraining data are utilized as much as possible. Without\nincurring extra task-specific adaptors, OmniVL can simultaneously support\nvisual only tasks (e.g., image classification, video action recognition),\ncross-modal alignment tasks (e.g., image/video-text retrieval), and multi-modal\nunderstanding and generation tasks (e.g., image/video question answering,\ncaptioning). We evaluate OmniVL on a wide range of downstream tasks and achieve\nstate-of-the-art or competitive results with similar model size and data scale.",
    "descriptor": "\nComments: To appear at NeurIPs 2022\n",
    "authors": [
      "Junke Wang",
      "Dongdong Chen",
      "Zuxuan Wu",
      "Chong Luo",
      "Luowei Zhou",
      "Yucheng Zhao",
      "Yujia Xie",
      "Ce Liu",
      "Yu-Gang Jiang",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07526"
  },
  {
    "id": "arXiv:2206.08300",
    "title": "Stake-governed tug-of-war and the biased infinity Laplacian",
    "abstract": "We introduce a two-person zero-sum game that we call stake-governed\ntug-of-war. The game develops the classic tug-of-war random-turn game\nfrom~\\cite{PSSW09}. In tug-of-war, two players compete by moving a counter\nalong adjacent edges of a graph, each winning the right to move at a given turn\naccording to the outcome of the flip of a fair coin; a payment is made from one\nplayer to the other when the counter reaches a boundary set on which the\nterminal payment value is specified. The player Mina who makes the payment\nseeks to minimize its mean; her opponent Maxine seeks to maximize it. The\ngame's value is the infinity harmonic extension of the payment boundary data.\nIn the stake-governed version, both players first receive a limited budget. At\nthe start of each turn, each stakes an amount drawn from her present budget,\nand the right to move at the turn is won randomly by a player with probability\nequal to the ratio of her stake and the combined stake just offered. For\ncertain graphs, we present the solution of a leisurely version of the game, in\nwhich, after stakes are bid at a turn, the upcoming move is cancelled with\nprobability $1 - \\epsilon \\in (0,1)$. With the parameter $\\epsilon$ small\nenough, and for finite trees whose leaves are the boundary set and whose\npayment function is the indicator on a given leaf, we determine the value of\nthe game and the set of Nash equilibria. When the ratio of the initial fortunes\nof Maxine and Mina is $\\lambda$, Maxine wins each turn with a probability\n$\\tfrac{\\lambda}{1+\\lambda}$ under optimal play, and game value is a biased\ninfinity harmonic function $h(\\lambda,v)$; each player stakes a shared\nnon-random proportion of her present fortune, a formula for which we give in\nterms of the spatial gradient and $\\lambda$-derivative of $h(\\lambda,v)$. We\nalso show with some examples how the solution can differ when $\\epsilon$ is\none.",
    "descriptor": "\nComments: 64 pages with four figures\n",
    "authors": [
      "Alan Hammond",
      "G\u00e1bor Pete"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.08300"
  },
  {
    "id": "arXiv:2209.06843",
    "title": "Robust field-level inference with dark matter halos",
    "abstract": "We train graph neural networks on halo catalogues from Gadget N-body\nsimulations to perform field-level likelihood-free inference of cosmological\nparameters. The catalogues contain $\\lesssim$5,000 halos with masses $\\gtrsim\n10^{10}~h^{-1}M_\\odot$ in a periodic volume of $(25~h^{-1}{\\rm Mpc})^3$; every\nhalo in the catalogue is characterized by several properties such as position,\nmass, velocity, concentration, and maximum circular velocity. Our models, built\nto be permutationally, translationally, and rotationally invariant, do not\nimpose a minimum scale on which to extract information and are able to infer\nthe values of $\\Omega_{\\rm m}$ and $\\sigma_8$ with a mean relative error of\n$\\sim6\\%$, when using positions plus velocities and positions plus masses,\nrespectively. More importantly, we find that our models are very robust: they\ncan infer the value of $\\Omega_{\\rm m}$ and $\\sigma_8$ when tested using halo\ncatalogues from thousands of N-body simulations run with five different N-body\ncodes: Abacus, CUBEP$^3$M, Enzo, PKDGrav3, and Ramses. Surprisingly, the model\ntrained to infer $\\Omega_{\\rm m}$ also works when tested on thousands of\nstate-of-the-art CAMELS hydrodynamic simulations run with four different codes\nand subgrid physics implementations. Using halo properties such as\nconcentration and maximum circular velocity allow our models to extract more\ninformation, at the expense of breaking the robustness of the models. This may\nhappen because the different N-body codes are not converged on the relevant\nscales corresponding to these parameters.",
    "descriptor": "\nComments: 25 pages, 11 figures, summary video: this https URL\n",
    "authors": [
      "Helen Shao",
      "Francisco Villaescusa-Navarro",
      "Pablo Villanueva-Domingo",
      "Romain Teyssier",
      "Lehman H. Garrison",
      "Marco Gatti",
      "Derek Inman",
      "Yueying Ni",
      "Ulrich P. Steinwandel",
      "Mihir Kulkarni",
      "Eli Visbal",
      "Greg L. Bryan",
      "Daniel Angles-Alcazar",
      "Tiago Castro",
      "Elena Hernandez-Martinez",
      "Klaus Dolag"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06843"
  },
  {
    "id": "arXiv:2209.06848",
    "title": "Urban precipitation downscaling using deep learning: a smart city  application over Austin, Texas, USA",
    "abstract": "Urban downscaling is a link to transfer the knowledge from coarser climate\ninformation to city scale assessments. These high-resolution assessments need\nmultiyear climatology of past data and future projections, which are complex\nand computationally expensive to generate using traditional numerical weather\nprediction models. The city of Austin, Texas, USA has seen tremendous growth in\nthe past decade. Systematic planning for the future requires the availability\nof fine resolution city-scale datasets. In this study, we demonstrate a novel\napproach generating a general purpose operator using deep learning to perform\nurban downscaling. The algorithm employs an iterative super-resolution\nconvolutional neural network (Iterative SRCNN) over the city of Austin, Texas,\nUSA. We show the development of a high-resolution gridded precipitation product\n(300 m) from a coarse (10 km) satellite-based product (JAXA GsMAP). High\nresolution gridded datasets of precipitation offer insights into the spatial\ndistribution of heavy to low precipitation events in the past. The algorithm\nshows improvement in the mean peak-signal-to-noise-ratio and mutual information\nto generate high resolution gridded product of size 300 m X 300 m relative to\nthe cubic interpolation baseline. Our results have implications for developing\nhigh-resolution gridded-precipitation urban datasets and the future planning of\nsmart cities for other cities and other climatic variables.",
    "descriptor": "",
    "authors": [
      "Manmeet Singh",
      "Nachiketa Acharya",
      "Sajad Jamshidi",
      "Junfeng Jiao",
      "Zong-Liang Yang",
      "Marc Coudert",
      "Zach Baumer",
      "Dev Niyogi"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06848"
  },
  {
    "id": "arXiv:2209.06853",
    "title": "Asymptotic Statistical Analysis of $f$-divergence GAN",
    "abstract": "Generative Adversarial Networks (GANs) have achieved great success in data\ngeneration. However, its statistical properties are not fully understood. In\nthis paper, we consider the statistical behavior of the general $f$-divergence\nformulation of GAN, which includes the Kullback--Leibler divergence that is\nclosely related to the maximum likelihood principle. We show that for\nparametric generative models that are correctly specified, all $f$-divergence\nGANs with the same discriminator classes are asymptotically equivalent under\nsuitable regularity conditions. Moreover, with an appropriately chosen local\ndiscriminator, they become equivalent to the maximum likelihood estimate\nasymptotically. For generative models that are misspecified, GANs with\ndifferent $f$-divergences {converge to different estimators}, and thus cannot\nbe directly compared. However, it is shown that for some commonly used\n$f$-divergences, the original $f$-GAN is not optimal in that one can achieve a\nsmaller asymptotic variance when the discriminator training in the original\n$f$-GAN formulation is replaced by logistic regression. The resulting\nestimation method is referred to as Adversarial Gradient Estimation (AGE).\nEmpirical studies are provided to support the theory and to demonstrate the\nadvantage of AGE over the original $f$-GANs under model misspecification.",
    "descriptor": "",
    "authors": [
      "Xinwei Shen",
      "Kani Chen",
      "Tong Zhang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06853"
  },
  {
    "id": "arXiv:2209.06860",
    "title": "Reconstruction of Three-dimensional Scroll Wave Chaos in Opaque and  Transparent Excitable Media using Deep Neural Networks",
    "abstract": "Scroll wave chaos is thought to underlie life-threatening ventricular\nfibrillation. However, currently there is no direct way to measure action\npotential wave patterns transmurally throughout the thick ventricular heart\nmuscle. Consequently, direct observation of three-dimensional electrical scroll\nwave chaos remains elusive. Here, we study whether it is possible to\nreconstruct simulated three-dimensional scroll wave chaos inside a bulk-shaped\nexcitable medium from two-dimensional observations of the wave dynamics on the\nbulk's surface using deep learning. We trained encoding-decoding convolutional\nneural networks to predict three-dimensional scroll wave chaos inside opaque\nand transparent as well as isotropic and anisotropic excitable media from\ntwo-dimensional projections or observations of the wave dynamics on the\nsurface. We tested whether observations from one or two opposing surfaces would\nbe sufficient, whether incorporating measurements of the surface deformation\nimproves the reconstruction, and tested the feasibility of predicting the\nbulk's thickness. We demonstrate that it is possible to fully reconstruct\nthree-dimensional scroll wave chaos in transparent excitable media with\nanisotropy and to obtain partial reconstructions in opaque excitable media when\nanalyzing two opposing layers of the bulk. We found that anisotropy provides\ncrucial information for neural networks to decode depth, which facilitates the\nreconstructions. In the future, deep neural networks could be used to visualize\ntransmural action potential wave patterns during ventricular fibrillation from\nepi- or endocardial recordings.",
    "descriptor": "",
    "authors": [
      "Jan Lebert",
      "Meenakshi Mittal",
      "Jan Christoph"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.06860"
  },
  {
    "id": "arXiv:2209.06862",
    "title": "Deep learning in a bilateral brain with hemispheric specialization",
    "abstract": "The brains of all bilaterally symmetric animals on Earth are are divided into\nleft and right hemispheres. The anatomy and functionality of the hemispheres\nhave a large degree of overlap, but they specialize to possess different\nattributes. The left hemisphere is believed to specialize in specificity and\nroutine, the right in generalities and novelty. In this study, we propose an\nartificial neural network that imitates that bilateral architecture using two\nconvolutional neural networks with different training objectives and test it on\nan image classification task. The bilateral architecture outperforms\narchitectures of similar representational capacity that don't exploit\ndifferential specialization. It demonstrates the efficacy of bilateralism and\nconstitutes a new principle that could be incorporated into other computational\nneuroscientific models and used as an inductive bias when designing new ML\nsystems. An analysis of the model can help us to understand the human brain.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Chandramouli Rajagopalan",
      "David Rawlinson",
      "Elkhonon Goldberg",
      "Gideon Kowadlo"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.06862"
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": "In this paper, we lay out a novel model of neuroplasticity in the form of a\nhorizontal-vertical integration model of neural processing. We believe a new\napproach to neural modeling will benefit the 3rd wave of AI. The horizontal\nplane consists of an adaptive network of neurons connected by transmission\nlinks which generates spatio-temporal spike patterns. This fits with standard\ncomputational neuroscience approaches. Additionally for each individual neuron\nthere is a vertical part consisting of internal adaptive parameters steering\nthe external membrane-expressed parameters which are involved in neural\ntransmission. Each neuron has a vertical modular system of parameters\ncorresponding to (a) external parameters at the membrane layer, divided into\ncompartments (spines, boutons) (b) internal parameters in the submembrane zone\nand the cytoplasm with its protein signaling network and (c) core parameters in\nthe nucleus for genetic and epigenetic information. In such models, each node\n(=neuron) in the horizontal network has its own internal memory. Neural\ntransmission and information storage are systematically separated, an important\nconceptual advance over synaptic weight models. We discuss the membrane-based\n(external) filtering and selection of outside signals for processing vs. signal\nloss by fast fluctuations and the neuron-internal computing strategies from\nintracellular protein signaling to the nucleus as the core system. We want to\nshow that the individual neuron has an important role in the computation of\nsignals and that many assumptions derived from the synaptic weight adjustment\nhypothesis of memory may not hold in a real brain. Not every transmission event\nleaves a trace and the neuron is a self-programming device, rather than\npassively determined by current input. Ultimately we strive to build a flexible\nmemory system that processes facts and events automatically.",
    "descriptor": "",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2209.06865"
  },
  {
    "id": "arXiv:2209.06901",
    "title": "Simulation of Atlantic Hurricane Tracks and Features: A Deep Learning  Approach",
    "abstract": "The objective of this paper is to employ machine learning (ML) and deep\nlearning (DL) techniques to obtain from input data (storm features) available\nin or derived from the HURDAT2 database models capable of simulating important\nhurricane properties such as landfall location and wind speed that are\nconsistent with historical records. In pursuit of this objective, a trajectory\nmodel providing the storm center in terms of longitude and latitude, and\nintensity models providing the central pressure and maximum 1-$min$ wind speed\nat 10 $m$ elevation were created. The trajectory and intensity models are\ncoupled and must be advanced together, six hours at a time, as the features\nthat serve as inputs to the models at any given step depend on predictions at\nthe previous time steps. Once a synthetic storm database is generated,\nproperties of interest, such as the frequencies of large wind speeds may be\nextracted from any part of the simulation domain. The coupling of the\ntrajectory and intensity models obviates the need for an intensity decay inland\nof the coastline. Prediction results are compared to historical data, and the\nefficacy of the storm simulation models is demonstrated for three examples: New\nOrleans, Miami and Cape Hatteras.",
    "descriptor": "",
    "authors": [
      "Rikhi Bose",
      "Adam L. Pintar",
      "Emil Simiu"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06901"
  },
  {
    "id": "arXiv:2209.06906",
    "title": "Nonlinear dynamic analysis of asymmetric bistable energy harvesters",
    "abstract": "Nonlinear vibration energy harvesting systems can potentially increase the\npower collected from the kinetic energy available in their operating\nenvironment since they usually can recover energy in broadband frequencies\ncompared to their linear counterpart. However, these systems have a high degree\nof complexity, sensitivity to slight variations of the parameters and the\ninitial conditions, and may present multiple solutions. For these reasons, it\nis rare for the designer to have a deep understanding of the dynamic behavior\nof this type of nonlinear oscillator. This situation is even more peculiar when\ngeometric imperfections from the system's manufacturing process are present, as\nthey can significantly influence the energy recovery process. Intending to fill\nthis lack of understanding about general aspects of the nonlinear dynamics of\nthis kind of system, the present paper presents a broad numerical investigation\nof local and global characteristics of the underlying dynamical systems using\nbifurcation diagrams and basins of attraction. Bifurcation analysis is\nperformed by exploring the broad spectrum of a harmonic signal, going from low\nto high amplitude and frequency of excitation. Basins of attraction analysis\nbased on 0-1 test for chaos is proposed as an efficient statistical technique\nto identify chaotic and periodic solutions. Different levels of asymmetry are\ninvestigated, and a particular situation is defined and analyzed when a value\nof the sloping angle where the system is attached compensates for the asymmetry\nof the quadratic term. The result shows the different solutions defined by\nexcitation forces and initial conditions, indicating the best scenario for\nincreasing the power output. The adverse effects of the asymmetries are\npresented. However, we also demonstrated that it is possible to around this\nbehavior using the sloping angle to compensate for the asymmetric influence",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Pedro Norenberg",
      "Roberto Luo",
      "Vinicius Goncaalves Lopes",
      "Jo\u00e3o Victor L. L. Peterson",
      "Americo Cunha Jr"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Chaotic Dynamics (nlin.CD)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.06906"
  },
  {
    "id": "arXiv:2209.06910",
    "title": "Modelling of physical systems with a Hopf bifurcation using mechanistic  models and machine learning",
    "abstract": "We propose a new hybrid modelling approach that combines a mechanistic model\nwith a machine-learnt model to predict the limit cycle oscillations of physical\nsystems with a Hopf bifurcation. The mechanistic model is an ordinary\ndifferential equation normal-form model capturing the bifurcation structure of\nthe system. A data-driven mapping from this model to the experimental\nobservations is then identified based on experimental data using machine\nlearning techniques. The proposed method is first demonstrated numerically on a\nVan der Pol oscillator and a three-degree-of-freedom aeroelastic model. It is\nthen applied to model the behaviour of a physical aeroelastic structure\nexhibiting limit cycle oscillations during wind tunnel tests. The method is\nshown to be general, data-efficient and to offer good accuracy without any\nprior knowledge about the system other than its bifurcation structure.",
    "descriptor": "",
    "authors": [
      "K.H. Lee",
      "D.A.W. Barton",
      "L.Renson"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2209.06910"
  },
  {
    "id": "arXiv:2209.06913",
    "title": "ESSumm: Extractive Speech Summarization from Untranscribed Meeting",
    "abstract": "In this paper, we propose a novel architecture for direct extractive\nspeech-to-speech summarization, ESSumm, which is an unsupervised model without\ndependence on intermediate transcribed text. Different from previous methods\nwith text presentation, we are aimed at generating a summary directly from\nspeech without transcription. First, a set of smaller speech segments are\nextracted based on speech signal's acoustic features. For each candidate speech\nsegment, a distance-based summarization confidence score is designed for latent\nspeech representation measure. Specifically, we leverage the off-the-shelf\nself-supervised convolutional neural network to extract the deep speech\nfeatures from raw audio. Our approach automatically predicts the optimal\nsequence of speech segments that capture the key information with a target\nsummary length. Extensive results on two well-known meeting datasets (AMI and\nICSI corpora) show the effectiveness of our direct speech-based method to\nimprove the summarization quality with untranscribed data. We also observe that\nour unsupervised speech-based method even performs on par with recent\ntranscript-based summarization approaches, where extra speech recognition is\nrequired.",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Jun Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.06913"
  },
  {
    "id": "arXiv:2209.06930",
    "title": "How Much Structure Is Needed for Huge Quantum Speedups?",
    "abstract": "I survey, for a general scientific audience, three decades of research into\nwhich sorts of problems admit exponential speedups via quantum computers --\nfrom the classics (like the algorithms of Simon and Shor), to the breakthrough\nof Yamakawa and Zhandry from April 2022. I discuss both the quantum circuit\nmodel, which is what we ultimately care about in practice but where our\nknowledge is radically incomplete, and the so-called oracle or black-box or\nquery complexity model, where we've managed to achieve a much more thorough\nunderstanding that then informs our conjectures about the circuit model. I\ndiscuss the strengths and weaknesses of switching attention to sampling tasks,\nas was done in the recent quantum supremacy experiments. I make some skeptical\nremarks about widely-repeated claims of exponential quantum speedups for\npractical machine learning and optimization problems. Through many examples, I\ntry to convey the \"law of conservation of weirdness,\" according to which every\nproblem admitting an exponential quantum speedup must have some unusual\nproperty to allow the amplitude to be concentrated on the unknown right\nanswer(s).",
    "descriptor": "\nComments: 16 pages, 6 figures. Edited transcript of a rapporteur talk delivered at the 28th Solvay Physics Conference in Brussels on May 21, 2022\n",
    "authors": [
      "Scott Aaronson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2209.06930"
  },
  {
    "id": "arXiv:2209.06948",
    "title": "An Automated Process for 2D and 3D Finite Element Overclosure and Gap  Adjustment using Radial Basis Function Networks",
    "abstract": "In biomechanics, geometries representing complicated organic structures are\nconsistently segmented from sparse volumetric data or morphed from template\ngeometries resulting in initial overclosure between adjacent geometries. In\nFEA, these overclosures result in numerical instability and inaccuracy as part\nof contact analysis. Several techniques exist to fix overclosures, but most\nsuffer from several drawbacks. This work introduces a novel automated algorithm\nin an iterative process to remove overclosure and create a desired minimum gap\nfor 2D and 3D finite element models. The RBF Network algorithm was introduced\nby its four major steps to remove the initial overclosure. Additionally, the\nalgorithm was validated using two test cases against conventional nodal\nadjustment. The first case compared the ability of each algorithm to remove\ndiffering levels of overclosure between two deformable muscles and the effects\non mesh quality. The second case used a non-deformable femur and deformable\ndistal femoral cartilage geometry with initial overclosure to test both\nalgorithms and observe the effects on the resulting contact FEA. The RBF\nNetwork in the first case study was successfully able to remove all\noverclosures. In the second case, the nodal adjustment method failed to create\na usable FEA model, while the RBF Network had no such issue. This work proposed\nan algorithm to remove initial overclosures prior to FEA that has improved\nperformance over conventional nodal adjustment, especially in complicated\nsituations and those involving 3D elements. The work can be included in\nexisting FEA modeling workflows to improve FEA results in situations involving\nsparse volumetric segmentation and mesh morphing. This algorithm has been\nimplemented in MATLAB, and the source code is publicly available to download at\nthe following GitHub repository: https://github.com/thor-andreassen/femors",
    "descriptor": "\nComments: 13 Pages, 3 Figures, 2 Tables\n",
    "authors": [
      "Thor E. Andreassen",
      "Donald R. Hume",
      "Landon D. Hamilton",
      "Sean E. Higinbotham",
      "Kevin B. Shelburne"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.06948"
  },
  {
    "id": "arXiv:2209.06950",
    "title": "Lossy Image Compression with Conditional Diffusion Models",
    "abstract": "Diffusion models are a new class of generative models that mark a milestone\nin high-quality image generation while relying on solid probabilistic\nprinciples. This makes them promising candidate models for neural image\ncompression. This paper outlines an end-to-end optimized framework based on a\nconditional diffusion model for image compression. Besides latent variables\ninherent to the diffusion process, the model introduces an additional\nper-instance \"content\" latent variable to condition the denoising process. Upon\ndecoding, the diffusion process conditionally generates/reconstructs an image\nusing ancestral sampling. Our experiments show that this approach outperforms\none of the best-performing conventional image codecs (BPG) and one neural codec\non two compression benchmarks, where we focus on rate-perception tradeoffs.\nQualitatively, our approach shows fewer decompression artifacts than the\nclassical approach.",
    "descriptor": "\nComments: Accepted at the ECCV 2022 Workshop on Uncertainty Quantification for Computer Vision\n",
    "authors": [
      "Ruihan Yang",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06950"
  },
  {
    "id": "arXiv:2209.06975",
    "title": "Wasserstein $K$-means for clustering probability distributions",
    "abstract": "Clustering is an important exploratory data analysis technique to group\nobjects based on their similarity. The widely used $K$-means clustering method\nrelies on some notion of distance to partition data into a fewer number of\ngroups. In the Euclidean space, centroid-based and distance-based formulations\nof the $K$-means are equivalent. In modern machine learning applications, data\noften arise as probability distributions and a natural generalization to handle\nmeasure-valued data is to use the optimal transport metric. Due to non-negative\nAlexandrov curvature of the Wasserstein space, barycenters suffer from\nregularity and non-robustness issues. The peculiar behaviors of Wasserstein\nbarycenters may make the centroid-based formulation fail to represent the\nwithin-cluster data points, while the more direct distance-based $K$-means\napproach and its semidefinite program (SDP) relaxation are capable of\nrecovering the true cluster labels. In the special case of clustering Gaussian\ndistributions, we show that the SDP relaxed Wasserstein $K$-means can achieve\nexact recovery given the clusters are well-separated under the $2$-Wasserstein\nmetric. Our simulation and real data examples also demonstrate that\ndistance-based $K$-means can achieve better classification performance over the\nstandard centroid-based $K$-means for clustering probability distributions and\nimages.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Yubo Zhuang",
      "Xiaohui Chen",
      "Yun Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06975"
  },
  {
    "id": "arXiv:2209.06983",
    "title": "Double Doubly Robust Thompson Sampling for Generalized Linear Contextual  Bandits",
    "abstract": "We propose a novel contextual bandit algorithm for generalized linear rewards\nwith an $\\tilde{O}(\\sqrt{\\kappa^{-1} \\phi T})$ regret over $T$ rounds where\n$\\phi$ is the minimum eigenvalue of the covariance of contexts and $\\kappa$ is\na lower bound of the variance of rewards. In several practical cases where\n$\\phi=O(d)$, our result is the first regret bound for generalized linear model\n(GLM) bandits with the order $\\sqrt{d}$ without relying on the approach of Auer\n[2002]. We achieve this bound using a novel estimator called double\ndoubly-robust (DDR) estimator, a subclass of doubly-robust (DR) estimator but\nwith a tighter error bound. The approach of Auer [2002] achieves independence\nby discarding the observed rewards, whereas our algorithm achieves independence\nconsidering all contexts using our DDR estimator. We also provide an\n$O(\\kappa^{-1} \\phi \\log (NT) \\log T)$ regret bound for $N$ arms under a\nprobabilistic margin condition. Regret bounds under the margin condition are\ngiven by Bastani and Bayati [2020] and Bastani et al. [2021] under the setting\nthat contexts are common to all arms but coefficients are arm-specific. When\ncontexts are different for all arms but coefficients are common, ours is the\nfirst regret bound under the margin condition for linear models or GLMs. We\nconduct empirical studies using synthetic data and real examples, demonstrating\nthe effectiveness of our algorithm.",
    "descriptor": "\nComments: 33 pages including Appendix\n",
    "authors": [
      "Wonyoung Kim",
      "Kyungbok Lee",
      "Myunghee Cho Paik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06983"
  },
  {
    "id": "arXiv:2209.06998",
    "title": "Stochastic Tree Ensembles for Estimating Heterogeneous Effects",
    "abstract": "Determining subgroups that respond especially well (or poorly) to specific\ninterventions (medical or policy) requires new supervised learning methods\ntailored specifically for causal inference. Bayesian Causal Forest (BCF) is a\nrecent method that has been documented to perform well on data generating\nprocesses with strong confounding of the sort that is plausible in many\napplications. This paper develops a novel algorithm for fitting the BCF model,\nwhich is more efficient than the previously available Gibbs sampler. The new\nalgorithm can be used to initialize independent chains of the existing Gibbs\nsampler leading to better posterior exploration and coverage of the associated\ninterval estimates in simulation studies. The new algorithm is compared to\nrelated approaches via simulation studies as well as an empirical analysis.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Nikolay Krantsevich",
      "Jingyu He",
      "P. Richard Hahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06998"
  },
  {
    "id": "arXiv:2209.07004",
    "title": "Emergence of polarization in a sigmoidal bounded-confidence model of  opinion dynamics",
    "abstract": "We propose a nonlinear bounded-confidence model (BCM) of continuous-time\nopinion dynamics on networks with both {persuadable} individuals and zealots.\nThe model is parameterized by a scalar $\\gamma$, which controls the steepness\nof a smooth influence function that encodes the relative weights that nodes\nplace on the opinions of other nodes. When $\\gamma = 0$, this influence\nfunction exactly recovers Taylor's averaging model; when $\\gamma \\rightarrow\n\\infty$, the influence function converges to that of a modified\nHegselmann--Krause (HK) BCM. Unlike the classical HK model, {however,} {our\nsigmoidal bounded-confidence model (SBCM)} is smooth for any finite $\\gamma$.\nWe show that the {set} of steady states of our {SBCM} is qualitatively similar\nto that of the Taylor model when $\\gamma$ is small and that the {set} of steady\nstates approaches a subset of the {set} of steady states of a modified HK model\nas $\\gamma \\rightarrow \\infty$. For several special graph topologies, we give\nanalytical descriptions of important features of the space of steady states. A\nnotable result is a closed-form relationship between the stability of a\npolarized state and the graph topology in a simple model of {echo chambers in\nsocial networks}. Because the influence function of our BCM is smooth, we are\nable to study it with linear stability analysis, which is difficult to employ\nwith the usual discontinuous influence functions in BCMs.",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Heather Z. Brooks",
      "Philip S. Chodrow",
      "Mason Porter"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07004"
  },
  {
    "id": "arXiv:2209.07011",
    "title": "Feature Selection integrated Deep Learning for Ultrahigh Dimensional and  Highly Correlated Feature Space",
    "abstract": "In recent years, deep learning has been a topic of interest in almost all\ndisciplines due to its impressive empirical success in analyzing complex data\nsets, such as imaging, genetics, climate, and medical data. While most of the\ndevelopments are treated as black-box machines, there is an increasing interest\nin interpretable, reliable, and robust deep learning models applicable to a\nbroad class of applications. Feature-selected deep learning is proven to be\npromising in this regard. However, the recent developments do not address the\nsituations of ultra-high dimensional and highly correlated feature selection in\naddition to the high noise level. In this article, we propose a novel screening\nand cleaning strategy with the aid of deep learning for the cluster-level\ndiscovery of highly correlated predictors with a controlled error rate. A\nthorough empirical evaluation over a wide range of simulated scenarios\ndemonstrates the effectiveness of the proposed method by achieving high power\nwhile having a minimal number of false discoveries. Furthermore, we implemented\nthe algorithm in the riboflavin (vitamin $B_2$) production dataset in the\ncontext of understanding the possible genetic association with riboflavin\nproduction. The gain of the proposed methodology is illustrated by achieving\nlower prediction error compared to other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Arkaprabha Ganguli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07011"
  },
  {
    "id": "arXiv:2209.07015",
    "title": "Upper bounds on the Natarajan dimensions of some function classes",
    "abstract": "The Natarajan dimension is a fundamental tool for characterizing multi-class\nPAC learnability, generalizing the Vapnik-Chervonenkis (VC) dimension from\nbinary to multi-class classification problems. This note establishes upper\nbounds on Natarajan dimensions for certain function classes, including (i)\nmulti-class decision tree and random forests, and (ii) multi-class neural\nnetworks with binary, linear and ReLU activations. These results may be\nrelevant for describing the performance of certain multi-class learning\nalgorithms.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Ying Jin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07015"
  },
  {
    "id": "arXiv:2209.07028",
    "title": "Estimating large causal polytree skeletons from small samples",
    "abstract": "We consider the problem of estimating the skeleton of a large causal polytree\nfrom a relatively small i.i.d. sample. This is motivated by the problem of\ndetermining causal structure when the number of variables is very large\ncompared to the sample size, such as in gene regulatory networks. We give an\nalgorithm that recovers the tree with high accuracy in such settings. The\nalgorithm works under essentially no distributional or modeling assumptions\nother than some mild non-degeneracy conditions.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Sourav Chatterjee",
      "Mathukumalli Vidyasagar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07028"
  },
  {
    "id": "arXiv:2209.07030",
    "title": "Model-Guided Multi-Contrast Deep Unfolding Network for MRI  Super-resolution Reconstruction",
    "abstract": "Magnetic resonance imaging (MRI) with high resolution (HR) provides more\ndetailed information for accurate diagnosis and quantitative image analysis.\nDespite the significant advances, most existing super-resolution (SR)\nreconstruction network for medical images has two flaws: 1) All of them are\ndesigned in a black-box principle, thus lacking sufficient interpretability and\nfurther limiting their practical applications. Interpretable neural network\nmodels are of significant interest since they enhance the trustworthiness\nrequired in clinical practice when dealing with medical images. 2) most\nexisting SR reconstruction approaches only use a single contrast or use a\nsimple multi-contrast fusion mechanism, neglecting the complex relationships\nbetween different contrasts that are critical for SR improvement. To deal with\nthese issues, in this paper, a novel Model-Guided interpretable Deep Unfolding\nNetwork (MGDUN) for medical image SR reconstruction is proposed. The\nModel-Guided image SR reconstruction approach solves manually designed\nobjective functions to reconstruct HR MRI. We show how to unfold an iterative\nMGDUN algorithm into a novel model-guided deep unfolding network by taking the\nMRI observation matrix and explicit multi-contrast relationship matrix into\naccount during the end-to-end optimization. Extensive experiments on the\nmulti-contrast IXI dataset and BraTs 2019 dataset demonstrate the superiority\nof our proposed model.",
    "descriptor": "\nComments: Accepted to ACMMM 2022, 9 pages\n",
    "authors": [
      "Gang Yang",
      "Li Zhang",
      "Man Zhou",
      "Aiping Liu",
      "Xun Chen",
      "Zhiwei Xiong",
      "Feng Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07030"
  },
  {
    "id": "arXiv:2209.07052",
    "title": "MIPI 2022 Challenge on Under-Display Camera Image Restoration: Methods  and Results",
    "abstract": "Developing and integrating advanced image sensors with novel algorithms in\ncamera systems are prevalent with the increasing demand for computational\nphotography and imaging on mobile platforms. However, the lack of high-quality\ndata for research and the rare opportunity for in-depth exchange of views from\nindustry and academia constrain the development of mobile intelligent\nphotography and imaging (MIPI). To bridge the gap, we introduce the first MIPI\nchallenge including five tracks focusing on novel image sensors and imaging\nalgorithms. In this paper, we summarize and review the Under-Display Camera\n(UDC) Image Restoration track on MIPI 2022. In total, 167 participants were\nsuccessfully registered, and 19 teams submitted results in the final testing\nphase. The developed solutions in this challenge achieved state-of-the-art\nperformance on Under-Display Camera Image Restoration. A detailed description\nof all models developed in this challenge is provided in this paper. More\ndetails of this challenge and the link to the dataset can be found at\nhttps://github.com/mipi-challenge/MIPI2022.",
    "descriptor": "\nComments: ECCV 2022 Mobile Intelligent Photography and Imaging (MIPI) Workshop--Under-display Camera Image Restoration Challenge Report. MIPI workshop website: this http URL\n",
    "authors": [
      "Ruicheng Feng",
      "Chongyi Li",
      "Shangchen Zhou",
      "Wenxiu Sun",
      "Qingpeng Zhu",
      "Jun Jiang",
      "Qingyu Yang",
      "Chen Change Loy",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07052"
  },
  {
    "id": "arXiv:2209.07060",
    "title": "MIPI 2022 Challenge on Quad-Bayer Re-mosaic: Dataset and Report",
    "abstract": "Developing and integrating advanced image sensors with novel algorithms in\ncamera systems are prevalent with the increasing demand for computational\nphotography and imaging on mobile platforms. However, the lack of high-quality\ndata for research and the rare opportunity for in-depth exchange of views from\nindustry and academia constrain the development of mobile intelligent\nphotography and imaging (MIPI). To bridge the gap, we introduce the first MIPI\nchallenge, including five tracks focusing on novel image sensors and imaging\nalgorithms. In this paper, Quad Joint Remosaic and Denoise, one of the five\ntracks, working on the interpolation of Quad CFA to Bayer at full resolution,\nis introduced. The participants were provided a new dataset, including 70\n(training) and 15 (validation) scenes of high-quality Quad and Bayer pairs. In\naddition, for each scene, Quad of different noise levels was provided at 0dB,\n24dB, and 42dB. All the data were captured using a Quad sensor in both outdoor\nand indoor conditions. The final results are evaluated using objective metrics,\nincluding PSNR, SSIM, LPIPS, and KLD. A detailed description of all models\ndeveloped in this challenge is provided in this paper. More details of this\nchallenge and the link to the dataset can be found at\nhttps://github.com/mipi-challenge/MIPI2022.",
    "descriptor": "\nComments: ECCV 2022 Mobile Intelligent Photography and Imaging (MIPI) Workshop--Quad-Bayer Re-mosaic Challenge Report. MIPI workshop website: this http URL\n",
    "authors": [
      "Qingyu Yang",
      "Guang Yang",
      "Jun Jiang",
      "Chongyi Li",
      "Ruicheng Feng",
      "Shangchen Zhou",
      "Wenxiu Sun",
      "Qingpeng Zhu",
      "Chen Change Loy",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07060"
  },
  {
    "id": "arXiv:2209.07086",
    "title": "Earthquake Phase Association with Graph Neural Networks",
    "abstract": "Seismic phase association connects earthquake arrival time measurements to\ntheir causative sources. Effective association must determine the number of\ndiscrete events, their location and origin times, and it must differentiate\nreal arrivals from measurement artifacts. The advent of deep learning pickers,\nwhich provide high rates of picks from closely overlapping small magnitude\nearthquakes, motivates revisiting the phase association problem and approaching\nit using the methods of deep learning. We have developed a Graph Neural Network\nassociator that simultaneously predicts both source space-time localization,\nand discrete source-arrival association likelihoods. The method is applicable\nto arbitrary geometry, time-varying seismic networks of hundreds of stations,\nand is robust to high rates of sources and input picks with variable noise and\nquality. Our Graph Earthquake Neural Interpretation Engine (GENIE) uses one\ngraph to represent the station set and another to represent the spatial source\nregion. GENIE learns relationships from data in this combined representation\nthat enable it to determine robust source and source-arrival associations. We\ntrain on synthetic data, and test our method on real data from the Northern\nCalifornia (NC) seismic network using input generated by the PhaseNet deep\nlearning phase picker. We successfully re-detect ~96% of all events M>1\nreported by the USGS during 500 random days between 2000$\\unicode{x2013}$2022.\nOver a 100-day continuous interval of processing in 2017$\\unicode{x2013}$2018,\nwe detect ~4.2x the number of events reported by the USGS. Our new events have\nsmall magnitude estimates below the magnitude of completeness of the USGS\ncatalog, and are located close to the active faults and quarries in the region.\nOur results demonstrate that GENIE can effectively solve the association\nproblem under complex seismic monitoring conditions.",
    "descriptor": "",
    "authors": [
      "Ian W. McBrearty",
      "Gregory C. Beroza"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07086"
  },
  {
    "id": "arXiv:2209.07101",
    "title": "Order of uniform approximation by polynomial interpolation in the  complex plane and beyond",
    "abstract": "For Lagrange polynomial interpolation on open arcs $X=\\gamma$ in $\\CC$, it is\nwell-known that the Lebesgue constant for the family of Chebyshev points\n${\\bf{x}}_n:=\\{x_{n,j}\\}^{n}_{j=0}$ on $[-1,1]\\subset \\RR$ has growth order of\n$O(log(n))$. The same growth order was shown in \\cite{ZZ} for the Lebesgue\nconstant of the family ${\\bf {z^{**}_n}}:=\\{z_{n,j}^{**}\\}^{n}_{j=0}$ of some\nproperly adjusted Fej\\'er points on a rectifiable smooth open arc\n$\\gamma\\subset \\CC$. On the other hand, in our recent work \\cite{CZ2021}, it\nwas observed that if the smooth open arc $\\gamma$ is replaced by an $L$-shape\narc $\\gamma_0 \\subset \\CC$ consisting of two line segments, numerical\nexperiments suggest that the Marcinkiewicz-Zygmund inequalities are no longer\nvalid for the family of Fej\\'er points ${\\bf\nz}_n^{*}:=\\{z_{n,j}^{*}\\}^{n}_{j=0}$ on $\\gamma$, and that the rate of growth\nfor the corresponding Lebesgue constant $L_{{\\bf {z}}^{*}_n}$ is as fast as\n$c\\,log^2(n)$ for some constant $c>0$.\nThe main objective of the present paper is 3-fold: firstly, it will be shown\nthat for the special case of the $L$-shape arc $\\gamma_0$ consisting of two\nline segments of the same length that meet at the angle of $\\pi/2$, the growth\nrate of the Lebesgue constant $L_{{\\bf {z}}_n^{*}}$ is at least as fast as\n$O(Log^2(n))$, with $\\lim\\sup \\frac{L_{{\\bf {z}}_n^{*}}}{log^2(n)} = \\infty$;\nsecondly, the corresponding (modified) Marcinkiewicz-Zygmund inequalities fail\nto hold; and thirdly, a proper adjustment ${\\bf\nz}_n^{**}:=\\{z_{n,j}^{**}\\}^{n}_{j=0}$ of the Fej\\'er points on $\\gamma$ will\nbe described to assure the growth rate of $L_{{\\bf z}_n^{**}}$ to be exactly\n$O(Log^2(n))$.",
    "descriptor": "\nComments: Submit to Indagationes Mathematicae, Prof. Jaap Korevaar 100-th birthday special issue, 32 pages, no figures, keywords:Lebesgue constants; Marcinkiewicz-Zygmund inequalities;\n",
    "authors": [
      "Charles K. Chui",
      "Lefan Zhong"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Complex Variables (math.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07101"
  },
  {
    "id": "arXiv:2209.07111",
    "title": "$\u03c1$-GNF : A Novel Sensitivity Analysis Approach Under Unobserved  Confounders",
    "abstract": "We propose a new sensitivity analysis model that combines copulas and\nnormalizing flows for causal inference under unobserved confounding. We refer\nto the new model as $\\rho$-GNF ($\\rho$-Graphical Normalizing Flow), where\n$\\rho{\\in}[-1,+1]$ is a bounded sensitivity parameter representing the backdoor\nnon-causal association due to unobserved confounding modeled using the most\nwell studied and widely popular Gaussian copula. Specifically, $\\rho$-GNF\nenables us to estimate and analyse the frontdoor causal effect or average\ncausal effect (ACE) as a function of $\\rho$. We call this the $\\rho_{curve}$.\nThe $\\rho_{curve}$ enables us to specify the confounding strength required to\nnullify the ACE. We call this the $\\rho_{value}$. Further, the $\\rho_{curve}$\nalso enables us to provide bounds for the ACE given an interval of $\\rho$\nvalues. We illustrate the benefits of $\\rho$-GNF with experiments on simulated\nand real-world data in terms of our empirical ACE bounds being narrower than\nother popular ACE bounds.",
    "descriptor": "\nComments: 10 main pages (+4 reference pages, +6 appendix), 8 Figures, Under review\n",
    "authors": [
      "Sourabh Balgi",
      "Jose M. Pe\u00f1a",
      "Adel Daoud"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07111"
  },
  {
    "id": "arXiv:2209.07151",
    "title": "Feedback Loops in Opinion Dynamics of Agent-Based Models with  Multiplicative Noise",
    "abstract": "We introduce an agent-based model for co-evolving opinion and social\ndynamics, under the influence of multiplicative noise. In this model, every\nagent is characterized by a position in a social space and a continuous opinion\nstate variable. Agents' movements are governed by positions and opinions of\nother agents and similarly, the opinion dynamics is influenced by agents'\nspatial proximity and their opinion similarity. Using numerical simulations and\nformal analysis, we study this feedback loop between opinion dynamics and\nmobility of agents in a social space. We investigate the behavior of this ABM\nin different regimes and explore the influence of various factors on appearance\nof emerging phenomena such as group formation and opinion consensus. We study\nthe empirical distribution and in the limit of infinite number of agents we\nderive a corresponding reduced model given by a partial differential equation\n(PDE). Finally, using numerical examples we show that a resulting PDE model is\na good approximation of the original ABM.",
    "descriptor": "",
    "authors": [
      "Natasa Djurdjevac Conrad",
      "Jonas K\u00f6ppl",
      "Ana Djurdjevac"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07151"
  },
  {
    "id": "arXiv:2209.07154",
    "title": "Risk-aware linear bandits with convex loss",
    "abstract": "In decision-making problems such as the multi-armed bandit, an agent learns\nsequentially by optimizing a certain feedback. While the mean reward criterion\nhas been extensively studied, other measures that reflect an aversion to\nadverse outcomes, such as mean-variance or conditional value-at-risk (CVaR),\ncan be of interest for critical applications (healthcare, agriculture).\nAlgorithms have been proposed for such risk-aware measures under bandit\nfeedback without contextual information. In this work, we study contextual\nbandits where such risk measures can be elicited as linear functions of the\ncontexts through the minimization of a convex loss. A typical example that fits\nwithin this framework is the expectile measure, which is obtained as the\nsolution of an asymmetric least-square problem. Using the method of mixtures\nfor supermartingales, we derive confidence sequences for the estimation of such\nrisk measures. We then propose an optimistic UCB algorithm to learn optimal\nrisk-aware actions, with regret guarantees similar to those of generalized\nlinear bandits. This approach requires solving a convex problem at each round\nof the algorithm, which we can relax by allowing only approximated solution\nobtained by online gradient descent, at the cost of slightly higher regret. We\nconclude by evaluating the resulting algorithms on numerical experiments.",
    "descriptor": "",
    "authors": [
      "Patrick Saux",
      "Odalric-Ambrym Maillard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07154"
  },
  {
    "id": "arXiv:2209.07162",
    "title": "Brain Imaging Generation with Latent Diffusion Models",
    "abstract": "Deep neural networks have brought remarkable breakthroughs in medical image\nanalysis. However, due to their data-hungry nature, the modest dataset sizes in\nmedical imaging projects might be hindering their full potential. Generating\nsynthetic data provides a promising alternative, allowing to complement\ntraining datasets and conducting medical image research at a larger scale.\nDiffusion models recently have caught the attention of the computer vision\ncommunity by producing photorealistic synthetic images. In this study, we\nexplore using Latent Diffusion Models to generate synthetic images from\nhigh-resolution 3D brain images. We used T1w MRI images from the UK Biobank\ndataset (N=31,740) to train our models to learn about the probabilistic\ndistribution of brain images, conditioned on covariables, such as age, sex, and\nbrain structure volumes. We found that our models created realistic data, and\nwe could use the conditioning variables to control the data generation\neffectively. Besides that, we created a synthetic dataset with 100,000 brain\nimages and made it openly available to the scientific community.",
    "descriptor": "\nComments: 10 pages, 3 figures, Accepted in the Deep Generative Models workshop @ MICCAI 2022\n",
    "authors": [
      "Walter H. L. Pinaya",
      "Petru-Daniel Tudosiu",
      "Jessica Dafflon",
      "Pedro F da Costa",
      "Virginia Fernandez",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.07162"
  },
  {
    "id": "arXiv:2209.07180",
    "title": "Open Challenges in Synthetic Speech Detection",
    "abstract": "In this paper the current status and open challenges of synthetic speech\ndetection are addressed. The work comprises an initial analysis of available\nopen datasets and of existing detection methods, a description of the\nrequirements for new research datasets compliant with regulations and better\nrepresenting real-case scenarios, and a discussion of the desired\ncharacteristics of future trustworthy detection methods in terms of both\nfunctional and non-functional requirements. Compared to other works, based on\nspecific detection solutions or presenting single dataset of synthetic\nspeeches, our paper is meant to orient future state-of-the-art research in the\ndomain, to quickly lessen the current gap between synthesis and detection\napproaches.",
    "descriptor": "\nComments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China\n",
    "authors": [
      "Luca Cuccovillo",
      "Christoforos Papastergiopoulos",
      "Anastasios Vafeiadis",
      "Artem Yaroshchuk",
      "Patrick Aichroth",
      "Konstantinos Votis",
      "Dimitrios Tzovaras"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.07180"
  },
  {
    "id": "arXiv:2209.07193",
    "title": "NU-net: An Unpretentious Nested U-net for Breast Tumor Segmentation",
    "abstract": "Breast tumor segmentation is one of the key steps that helps us characterize\nand localize tumor regions. However, variable tumor morphology, blurred\nboundary, and similar intensity distributions bring challenges for accurate\nsegmentation of breast tumors. Recently, many U-net variants have been proposed\nand widely used for breast tumors segmentation. However, these architectures\nsuffer from two limitations: (1) Ignoring the characterize ability of the\nbenchmark networks, and (2) Introducing extra complex operations increases the\ndifficulty of understanding and reproducing the network. To alleviate these\nchallenges, this paper proposes a simple yet powerful nested U-net (NU-net) for\naccurate segmentation of breast tumors. The key idea is to utilize U-Nets with\ndifferent depths and shared weights to achieve robust characterization of\nbreast tumors. NU-net mainly has the following advantages: (1) Improving\nnetwork adaptability and robustness to breast tumors with different scales, (2)\nThis method is easy to reproduce and execute, and (3) The extra operations\nincrease network parameters without significantly increasing computational\ncost. Extensive experimental results with twelve state-of-the-art segmentation\nmethods on three public breast ultrasound datasets demonstrate that NU-net has\nmore competitive segmentation performance on breast tumors. Furthermore, the\nrobustness of NU-net is further illustrated on the segmentation of renal\nultrasound images. The source code is publicly available on\nhttps://github.com/CGPzy/NU-net.",
    "descriptor": "",
    "authors": [
      "Gong-Ping Chen",
      "Lei Li",
      "Yu Dai",
      "Jian-Xun Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07193"
  },
  {
    "id": "arXiv:2209.07196",
    "title": "Environment Classification via Blind Roomprints Estimation",
    "abstract": "In this paper we present a novel approach for environment classification for\nspeech recordings, which does not require the selection of decaying\nreverberation tails. It is based on a multi-band RT60 analysis of blind channel\nestimates and achieves an accuracy of up to 93.6% on test recordings derived\nfrom the ACE corpus.",
    "descriptor": "\nComments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China\n",
    "authors": [
      "Malte Baum",
      "Luca Cuccovillo",
      "Artem Yaroshchuk",
      "Patrick Aichroth"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.07196"
  },
  {
    "id": "arXiv:2209.07226",
    "title": "Solving nonlinear Klein-Gordon equations on unbounded domains via the  Finite Element Method",
    "abstract": "A large class of scalar-tensor theories of gravity exhibit a screening\nmechanism that dynamically suppresses fifth forces in the Solar system and\nlocal laboratory experiments. Technically, at the scalar field equation level,\nthis usually translates into nonlinearities which strongly limit the scope of\nanalytical approaches. This article presents $femtoscope$ $-$ a Python\nnumerical tool based on the Finite Element Method (FEM) and Newton method for\nsolving Klein-Gordon-like equations that arise in particular in the symmetron\nor chameleon models. Regarding the latter, the scalar field behavior is\ngenerally only known infinitely far away from the its sources. We thus\ninvestigate existing and new FEM-based techniques for dealing with asymptotic\nboundary conditions on finite-memory computers, whose convergence are assessed.\nFinally, $femtoscope$ is showcased with a study of the chameleon fifth force in\nEarth orbit.",
    "descriptor": "",
    "authors": [
      "Hugo L\u00e9vy",
      "Jo\u00ebl Berg\u00e9",
      "Jean-Philippe Uzan"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.07226"
  },
  {
    "id": "arXiv:2209.07230",
    "title": "Distributed Sparse Linear Regression with Sublinear Communication",
    "abstract": "We study the problem of high-dimensional sparse linear regression in a\ndistributed setting under both computational and communication constraints.\nSpecifically, we consider a star topology network whereby several machines are\nconnected to a fusion center, with whom they can exchange relatively short\nmessages. Each machine holds noisy samples from a linear regression model with\nthe same unknown sparse $d$-dimensional vector of regression coefficients\n$\\theta$. The goal of the fusion center is to estimate the vector $\\theta$ and\nits support using few computations and limited communication at each machine.\nIn this work, we consider distributed algorithms based on Orthogonal Matching\nPursuit (OMP) and theoretically study their ability to exactly recover the\nsupport of $\\theta$. We prove that under certain conditions, even at low\nsignal-to-noise-ratios where individual machines are unable to detect the\nsupport of $\\theta$, distributed-OMP methods correctly recover it with total\ncommunication sublinear in $d$. In addition, we present simulations that\nillustrate the performance of distributed OMP-based algorithms and show that\nthey perform similarly to more sophisticated and computationally intensive\nmethods, and in some cases even outperform them.",
    "descriptor": "\nComments: 45 pages, 3 figures\n",
    "authors": [
      "Chen Amiraz",
      "Robert Krauthgamer",
      "Boaz Nadler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07230"
  },
  {
    "id": "arXiv:2209.07232",
    "title": "A Spatiotemporal Model for Precise and Efficient Fully-automatic 3D  Motion Correction in OCT",
    "abstract": "Optical coherence tomography (OCT) is a micrometer-scale, volumetric imaging\nmodality that has become a clinical standard in ophthalmology. OCT instruments\nimage by raster-scanning a focused light spot across the retina, acquiring\nsequential cross-sectional images to generate volumetric data. Patient eye\nmotion during the acquisition poses unique challenges: Non-rigid, discontinuous\ndistortions can occur, leading to gaps in data and distorted topographic\nmeasurements. We present a new distortion model and a corresponding\nfully-automatic, reference-free optimization strategy for computational motion\ncorrection in orthogonally raster-scanned, retinal OCT volumes. Using a novel,\ndomain-specific spatiotemporal parametrization of forward-warping\ndisplacements, eye motion can be corrected continuously for the first time.\nParameter estimation with temporal regularization improves robustness and\naccuracy over previous spatial approaches. We correct each A-scan individually\nin 3D in a single mapping, including repeated acquisitions used in OCT\nangiography protocols. Specialized 3D forward image warping reduces median\nruntime to < 9 s, fast enough for clinical use. We present a quantitative\nevaluation on 18 subjects with ocular pathology and demonstrate accurate\ncorrection during microsaccades. Transverse correction is limited only by\nocular tremor, whereas submicron repeatability is achieved axially (0.51 um\nmedian of medians), representing a dramatic improvement over previous work.\nThis allows assessing longitudinal changes in focal retinal pathologies as a\nmarker of disease progression or treatment response, and promises to enable\nmultiple new capabilities such as supersampled/super-resolution volume\nreconstruction and analysis of pathological eye motion occuring in neurological\ndiseases.",
    "descriptor": "\nComments: Presented at MICCAI 2022 (main conference). The arXiv version provides full quality figures. 9 pages content (5 figures) + 2 pages references + 2 pages supplementary material (2 figures)\n",
    "authors": [
      "Stefan Ploner",
      "Siyu Chen",
      "Jungeun Won",
      "Lennart Husvogt",
      "Katharina Breininger",
      "Julia Schottenhamml",
      "James Fujimoto",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07232"
  },
  {
    "id": "arXiv:2209.07236",
    "title": "The Controllability and Structural Controllability of Laplacian Dynamics",
    "abstract": "In this paper, classic controllability and structural controllability under\ntwo protocols are investigated. For classic controllability, the multiplicity\nof eigenvalue zero of general Laplacian matrix $L^*$ is shown to be determined\nby the sum of the numbers of zero circles, identical nodes and opposite pairs,\nwhile it is always simple for the Laplacian $L$ with diagonal entries in\nabsolute form. For a fixed structurally balanced topology, the controllable\nsubspace is proved to be invariant even if the antagonistic weights are\nselected differently under the corresponding protocol with $L$. For a graph\nexpanded from a star graph rooted from a single leader, the dimension of\ncontrollable subspace is two under the protocol associated with $L^*$. In\naddition, the system is structurally controllable under both protocols if and\nonly if the topology without unaccessible nodes is connected. As a reinforcing\ncase of structural controllability, strong structural controllability requires\nthe system to be controllable for any choice of weights. The connection between\nfather nodes and child nodes affects strong structural controllability because\nit determines the linear relationship of the control information from father\nnodes. This discovery is a major factor in establishing the sufficient\nconditions on strong structural controllability for multi-agent systems under\nboth protocols, rather than for complex networks, about latter results are\nalready abundant.",
    "descriptor": "",
    "authors": [
      "Jijun Qu",
      "Zhijian Ji",
      "Yungang Liu",
      "Chong Lin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.07236"
  },
  {
    "id": "arXiv:2209.07259",
    "title": "Design of a Strong-Arm Dynamic-Latch based comparator with high speed,  low power and low offset for SAR-ADC",
    "abstract": "Comparators are utilised by Nyquist-rate and oversampling analog to digital\nconverters (ADCs) to accomplish quantization and perhaps sampling. Thus,\ncomparators have a substantial effect on the speed and accuracy of ADCs. This\nstudy provides a revised design for a dynamic-latch-based comparator that\nachieves the lowest latency, maximum area-efficient realisation, reduced power\ndissipation, and low offset. The proposed circuit has been designed and\nsimulated using GDPK 45 nm standard CMOS-Process to operate on 100 MHz clock,\nat 1.2V supply voltage. Design and simulation have been carried out using\nCADENCE Virtuoso EDA tool. Compared to the original design, the PDP was easily\nreduced by approximately by 6% with offset voltage reduced by 8 mV without\nspeed trade-off.",
    "descriptor": "\nComments: 5 pages, 5 figures, Under review in ICICM 2022\n",
    "authors": [
      "Sounak Dutta"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07259"
  },
  {
    "id": "arXiv:2209.07277",
    "title": "Blind and Channel-agnostic Equalization Using Adversarial Networks",
    "abstract": "Due to the rapid development of autonomous driving, the Internet of Things\nand streaming services, modern communication systems have to cope with varying\nchannel conditions and a steadily rising number of users and devices. This, and\nthe still rising bandwidth demands, can only be met by intelligent network\nautomation, which requires highly flexible and blind transceiver algorithms. To\ntackle those challenges, we propose a novel adaptive equalization scheme, which\nexploits the prosperous advances in deep learning by training an equalizer with\nan adversarial network. The learning is only based on the statistics of the\ntransmit signal, so it is blind regarding the actual transmit symbols and\nagnostic to the channel model. The proposed approach is independent of the\nequalizer topology and enables the application of powerful neural network based\nequalizers. In this work, we prove this concept in simulations of different --\nboth linear and nonlinear -- transmission channels and demonstrate the\ncapability of the proposed blind learning scheme to approach the performance of\nnon-blind equalizers. Furthermore, we provide a theoretical perspective and\nhighlight the challenges of the approach.",
    "descriptor": "\nComments: Accepted and to be presented at the IEEE GLOBECOM 2022 conference\n",
    "authors": [
      "Vincent Lauinger",
      "Manuel Hoffmann",
      "Jonas Ney",
      "Norbert Wehn",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07277"
  },
  {
    "id": "arXiv:2209.07279",
    "title": "Quantum Talagrand, KKL and Friedgut's theorems and the learnability of  quantum Boolean functions",
    "abstract": "We extend three related results from the analysis of influences of Boolean\nfunctions to the quantum setting, namely the KKL Theorem, Friedgut's Junta\nTheorem and Talagrand's variance inequality for geometric influences. Our\nresults are derived by a joint use of recently studied hypercontractivity and\ngradient estimates. These generic tools also allow us to derive generalizations\nof these results in a general von Neumann algebraic setting beyond the case of\nthe quantum hypercube, including examples in infinite dimensions relevant to\nquantum information theory such as continuous variables quantum systems.\nFinally, we comment on the implications of our results as regards to\nnoncommutative extensions of isoperimetric type inequalities and the\nlearnability of quantum observables.",
    "descriptor": "\nComments: 38 pages. Comments welcome\n",
    "authors": [
      "Cambyse Rouz\u00e9",
      "Melchior Wirth",
      "Haonan Zhang"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07279"
  },
  {
    "id": "arXiv:2209.07300",
    "title": "Multi-Task Mixture Density Graph Neural Networks for Predicting Cu-based  Single-Atom Alloy Catalysts for CO2 Reduction Reaction",
    "abstract": "Graph neural networks (GNNs) have drawn more and more attention from material\nscientists and demonstrated a high capacity to establish connections between\nthe structure and properties. However, with only unrelaxed structures provided\nas input, few GNN models can predict the thermodynamic properties of relaxed\nconfigurations with an acceptable level of error. In this work, we develop a\nmulti-task (MT) architecture based on DimeNet++ and mixture density networks to\nimprove the performance of such task. Taking CO adsorption on Cu-based\nsingle-atom alloy catalysts as an illustration, we show that our method can\nreliably estimate CO adsorption energy with a mean absolute error of 0.087 eV\nfrom the initial CO adsorption structures without costly first-principles\ncalculations. Further, compared to other state-of-the-art GNN methods, our\nmodel exhibits improved generalization ability when predicting catalytic\nperformance of out-of-domain configurations, built with either unseen substrate\nsurfaces or doping species. We show that the proposed MT GNN strategy can\nfacilitate catalyst discovery.",
    "descriptor": "\nComments: 22 pages, 3 figures, 2 tables\n",
    "authors": [
      "Chen Liang",
      "Bowen Wang",
      "Shaogang Hao",
      "Guangyong Chen",
      "Pheng-Ann Heng",
      "Xiaolong Zou"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07300"
  },
  {
    "id": "arXiv:2209.07306",
    "title": "Statistical Modeling of Data Breach Risks: Time to Identification and  and Notification",
    "abstract": "It is very challenging to predict the cost of a cyber incident owing to the\ncomplex nature of cyber risk. However, it is inevitable for insurance companies\nwho offer cyber insurance policies. The time to identifying an incident and the\ntime to noticing the affected individuals are two important components in\ndetermining the cost of a cyber incident. In this work, we initialize the study\non those two metrics via statistical modeling approaches. Particularly, we\npropose a novel approach to imputing the missing data, and further develop a\ndependence model to capture the complex pattern exhibited by those two metrics.\nThe empirical study shows that the proposed approach has a satisfactory\npredictive performance and is superior to other commonly used models.",
    "descriptor": "",
    "authors": [
      "Maochao Xu",
      "Quynh Nhu Nguyen"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.07306"
  },
  {
    "id": "arXiv:2209.07313",
    "title": "HarDNet-DFUS: An Enhanced Harmonically-Connected Network for Diabetic  Foot Ulcer Image Segmentation and Colonoscopy Polyp Segmentation",
    "abstract": "We present a neural network architecture for medical image segmentation of\ndiabetic foot ulcers and colonoscopy polyps. Diabetic foot ulcers are caused by\nneuropathic and vascular complications of diabetes mellitus. In order to\nprovide a proper diagnosis and treatment, wound care professionals need to\nextract accurate morphological features from the foot wounds. Using\ncomputer-aided systems is a promising approach to extract related morphological\nfeatures and segment the lesions. We propose a convolution neural network\ncalled HarDNet-DFUS by enhancing the backbone and replacing the decoder of\nHarDNet-MSEG, which was SOTA for colonoscopy polyp segmentation in 2021. For\nthe MICCAI 2022 Diabetic Foot Ulcer Segmentation Challenge (DFUC2022), we train\nHarDNet-DFUS using the DFUC2022 dataset and increase its robustness by means of\nfive-fold cross validation, Test Time Augmentation, etc. In the validation\nphase of DFUC2022, HarDNet-DFUS achieved 0.7063 mean dice and was ranked third\namong all participants. In the final testing phase of DFUC2022, it achieved\n0.7287 mean dice and was the first place winner. HarDNet-DFUS also deliver\nexcellent performance for the colonoscopy polyp segmentation task. It achieves\n0.924 mean Dice on the famous Kvasir dataset, an improvement of 1.2\\% over the\noriginal HarDNet-MSEG. The codes are available on\nhttps://github.com/kytimmylai/DFUC2022 (for Diabetic Foot Ulcers Segmentation)\nand https://github.com/YuWenLo/HarDNet-DFUS (for Colonoscopy Polyp\nSegmentation).",
    "descriptor": "",
    "authors": [
      "Ting-Yu Liao",
      "Ching-Hui Yang",
      "Yu-Wen Lo",
      "Kuan-Ying Lai",
      "Po-Huai Shen",
      "Youn-Long Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07313"
  },
  {
    "id": "arXiv:2209.07331",
    "title": "Complex hypergraphs",
    "abstract": "Providing an abstract representation of natural and human complex structures\nis a challenging problem. Accounting for the system heterogenous components\nwhile allowing for analytical tractability is a difficult balance. Here I\nintroduce complex hypergraphs (chygraphs), bringing together concepts from\nhypergraphs, multi-layer networks and simplicial complexes. To illustrate the\napplicability of this combinatorial structure I calculate the components size\nstatistics and identify the transition to a giant component. To this end I\nintroduce a vectorization technique that tackles the multi-level nature of\nchygraphs. I conclude that chygraphs are a unifying representation of complex\nsystems allowing for analytical insight.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Alexei Vazquez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07331"
  },
  {
    "id": "arXiv:2209.07370",
    "title": "A Geometric Perspective on Variational Autoencoders",
    "abstract": "This paper introduces a new interpretation of the Variational Autoencoder\nframework by taking a fully geometric point of view. We argue that vanilla VAE\nmodels unveil naturally a Riemannian structure in their latent space and that\ntaking into consideration those geometrical aspects can lead to better\ninterpolations and an improved generation procedure. This new proposed sampling\nmethod consists in sampling from the uniform distribution deriving\nintrinsically from the learned Riemannian latent space and we show that using\nthis scheme can make a vanilla VAE competitive and even better than more\nadvanced versions on several benchmark datasets. Since generative models are\nknown to be sensitive to the number of training samples we also stress the\nmethod's robustness in the low data regime.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Cl\u00e9ment Chadebec",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07370"
  },
  {
    "id": "arXiv:2209.07373",
    "title": "Complex systems science and urban science: towards applications to  sustainability trade-offs in territorial systems",
    "abstract": "Urban systems are at the core of current sustainability concerns, and their\nstudy from a complexity perspective has a long history in several disciplines.\nWe survey this literature and discuss future research directions relevant to\nsustainable planning, in particular the construction of integrative approaches.\nWe finally illustrate this research program with the coupling of urban\nsimulation models to explore trade-offs between sustainable development goals\nin systems of cities.",
    "descriptor": "\nComments: Journ{\\'e}es Scientifiques de Rochebrune 2022\n",
    "authors": [
      "Juste Raimbault",
      "Denise Pumain"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07373"
  },
  {
    "id": "arXiv:2209.07396",
    "title": "Towards Healing the Blindness of Score Matching",
    "abstract": "Score-based divergences have been widely used in machine learning and\nstatistics applications. Despite their empirical success, a blindness problem\nhas been observed when using these for multi-modal distributions. In this work,\nwe discuss the blindness problem and propose a new family of divergences that\ncan mitigate the blindness problem. We illustrate our proposed divergence in\nthe context of density estimation and report improved performance compared to\ntraditional approaches.",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Oscar Key",
      "Peter Hayes",
      "David Barber",
      "Brooks Paige",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07396"
  },
  {
    "id": "arXiv:2209.07405",
    "title": "Widely Used and Fast De Novo Drug Design by a Protein Sequence-Based  Reinforcement Learning Model",
    "abstract": "De novo molecular design has facilitated the exploration of large chemical\nspace to accelerate drug discovery. Structure-based de novo method can overcome\nthe data scarcity of active ligands by incorporating drug-target interaction\ninto deep generative architectures. However, these strategies are bottlenecked\nby the small fraction of experimentally determined protein or complex\nstructures. In addition, the cost of molecular generation is computationally\nexpensive due to 3D representations of both molecule and protein. Here, we\ndemonstrate a widely used and fast protein sequence-based reinforcement\nlearning (RL) model for drug discovery. In the generative model, one of the\nreward components, a binding affinity predictor, is based on 1D protein\nsequence and molecular SMILES. As a proof of concept, the RL model was utilized\nto design molecules for four targets. The generated compounds showed\nbioactivities by the validation of both QSAR and molecular docking with\nexperimental 3D binding pockets. We also found that the performance of\ngenerated molecules depends on the selection of data source training for the\nbinding predictor. Furthermore, drug design for a kinase without any\nexperimental structure, CDK20, was studied by our model. With only 1D protein\nsequence as input, the generated novel compounds showed favorable binding\naffinity based on the AlphaFold predicted structure.",
    "descriptor": "",
    "authors": [
      "Yaqin Li",
      "Lingli Li",
      "Yongjin Xu",
      "Yi Yu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07405"
  },
  {
    "id": "arXiv:2209.07406",
    "title": "Towards Coupling Full-disk and Active Region-based Flare Prediction for  Operational Space Weather Forecasting",
    "abstract": "Solar flare prediction is a central problem in space weather forecasting and\nhas captivated the attention of a wide spectrum of researchers due to recent\nadvances in both remote sensing as well as machine learning and deep learning\napproaches. The experimental findings based on both machine and deep learning\nmodels reveal significant performance improvements for task specific datasets.\nAlong with building models, the practice of deploying such models to production\nenvironments under operational settings is a more complex and often\ntime-consuming process which is often not addressed directly in research\nsettings. We present a set of new heuristic approaches to train and deploy an\noperational solar flare prediction system for $\\geq$M1.0-class flares with two\nprediction modes: full-disk and active region-based. In full-disk mode,\npredictions are performed on full-disk line-of-sight magnetograms using deep\nlearning models whereas in active region-based models, predictions are issued\nfor each active region individually using multivariate time series data\ninstances. The outputs from individual active region forecasts and full-disk\npredictors are combined to a final full-disk prediction result with a\nmeta-model. We utilized an equal weighted average ensemble of two base\nlearners' flare probabilities as our baseline meta learner and improved the\ncapabilities of our two base learners by training a logistic regression model.\nThe major findings of this study are: (i) We successfully coupled two\nheterogeneous flare prediction models trained with different datasets and model\narchitecture to predict a full-disk flare probability for next 24 hours, (ii)\nOur proposed ensembling model, i.e., logistic regression, improves on the\npredictive performance of two base learners and the baseline meta learner\nmeasured in terms of two widely used metrics True Skill Statistic (TSS) and\nHeidke Skill core (HSS), and (iii) Our result analysis suggests that the\nlogistic regression-based ensemble (Meta-FP) improves on the full-disk model\n(base learner) by $\\sim9\\%$ in terms TSS and $\\sim10\\%$ in terms of HSS.\nSimilarly, it improves on the AR-based model (base learner) by $\\sim17\\%$ and\n$\\sim20\\%$ in terms of TSS and HSS respectively. Finally, when compared to the\nbaseline meta model, it improves on TSS by $\\sim10\\%$ and HSS by $\\sim15\\%$.",
    "descriptor": "",
    "authors": [
      "Chetraj Pandey",
      "Anli Ji",
      "Rafal A. Angryk",
      "Manolis K. Georgoulis",
      "Berkay Aydin"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07406"
  },
  {
    "id": "arXiv:2209.07414",
    "title": "Trustworthy modelling of atmospheric formaldehyde powered by deep  learning",
    "abstract": "Formaldehyde (HCHO) is one one of the most important trace gas in the\natmosphere, as it is a pollutant causing respiratory and other diseases. It is\nalso a precursor of tropospheric ozone which damages crops and deteriorates\nhuman health. Study of HCHO chemistry and long-term monitoring using satellite\ndata is important from the perspective of human health, food security and air\npollution. Dynamic atmospheric chemistry models struggle to simulate\natmospheric formaldehyde and often overestimate by up to two times relative to\nsatellite observations and reanalysis. Spatial distribution of modelled HCHO\nalso fail to match satellite observations. Here, we present deep learning\napproach using a simple super-resolution based convolutional neural network\ntowards simulating fast and reliable atmospheric HCHO. Our approach is an\nindirect method of HCHO estimation without the need to chemical equations. We\nfind that deep learning outperforms dynamical model simulations which involves\ncomplicated atmospheric chemistry representation. Causality establishing the\nnonlinear relationships of different variables to target formaldehyde is\nestablished in our approach by using a variety of precursors from meteorology\nand chemical reanalysis to target OMI AURA satellite based HCHO predictions. We\nchoose South Asia for testing our implementation as it doesnt have in situ\nmeasurements of formaldehyde and there is a need for improved quality data over\nthe region. Moreover, there are spatial and temporal data gaps in the satellite\nproduct which can be removed by trustworthy modelling of atmospheric\nformaldehyde. This study is a novel attempt using computer vision for\ntrustworthy modelling of formaldehyde from remote sensing can lead to cascading\nsocietal benefits.",
    "descriptor": "",
    "authors": [
      "Mriganka Sekhar Biswas",
      "Manmeet Singh"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07414"
  },
  {
    "id": "arXiv:2209.07423",
    "title": "Can Pre-trained Models Really Learn Better Molecular Representations for  AI-aided Drug Discovery?",
    "abstract": "Self-supervised pre-training is gaining increasingly more popularity in\nAI-aided drug discovery, leading to more and more pre-trained models with the\npromise that they can extract better feature representations for molecules.\nYet, the quality of learned representations have not been fully explored. In\nthis work, inspired by the two phenomena of Activity Cliffs (ACs) and Scaffold\nHopping (SH) in traditional Quantitative Structure-Activity Relationship (QSAR)\nanalysis, we propose a method named Representation-Property Relationship\nAnalysis (RePRA) to evaluate the quality of the representations extracted by\nthe pre-trained model and visualize the relationship between the\nrepresentations and properties. The concepts of ACs and SH are generalized from\nthe structure-activity context to the representation-property context, and the\nunderlying principles of RePRA are analyzed theoretically. Two scores are\ndesigned to measure the generalized ACs and SH detected by RePRA, and therefore\nthe quality of representations can be evaluated. In experiments,\nrepresentations of molecules from 10 target tasks generated by 7 pre-trained\nmodels are analyzed. The results indicate that the state-of-the-art pre-trained\nmodels can overcome some shortcomings of canonical Extended-Connectivity\nFingerPrints (ECFP), while the correlation between the basis of the\nrepresentation space and specific molecular substructures are not explicit.\nThus, some representations could be even worse than the canonical fingerprints.\nOur method enables researchers to evaluate the quality of molecular\nrepresentations generated by their proposed self-supervised pre-trained models.\nAnd our findings can guide the community to develop better pre-training\ntechniques to regularize the occurrence of ACs and SH.",
    "descriptor": "",
    "authors": [
      "Ziqiao Zhang",
      "Yatao Bian",
      "Ailin Xie",
      "Pengju Han",
      "Long-Kai Huang",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07423"
  },
  {
    "id": "arXiv:2209.07436",
    "title": "Statistical monitoring of models based on artificial intelligence",
    "abstract": "The rapid advancement of models based on artificial intelligence demands\ninnovative monitoring techniques which can operate in real time with low\ncomputational costs. In machine learning, especially if we consider neural\nnetwork (NN) learning algorithms, and in particular deep-learning\narchitectures, the models are often trained in a supervised manner.\nConsequently, the learned relationship between the input and the output must\nremain valid during the model's deployment. If this stationarity assumption\nholds, we can conclude that the NN generates accurate predictions. Otherwise,\nthe retraining or rebuilding of the model is required. We propose to consider\nthe latent feature representation of the data (called \"embedding\") generated by\nthe NN for determining the time point when the data stream starts being\nnonstationary. To be precise, we monitor embeddings by applying multivariate\ncontrol charts based on the calculation of the data depth and normalized ranks.\nThe performance of the introduced method is evaluated using various NNs with\ndifferent underlying data formats.",
    "descriptor": "",
    "authors": [
      "Anna Malinovskaya",
      "Pavlo Mozharovskyi",
      "Philipp Otto"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07436"
  },
  {
    "id": "arXiv:2209.07451",
    "title": "On the Trail of Lost Pennies",
    "abstract": "We introduce a two-person non-zero-sum random-turn game that is a variant of\nthe stake-governed games introduced recently in [HP2022]. We call the new game\nthe Trail of Lost Pennies. At time zero, a counter is placed at a given integer\nlocation: $X_0 = k \\in \\mathbb{Z}$, say. At the $i$-th turn (for $i \\in\n\\mathbb{N}_+$), Maxine and Mina place non-negative stakes, $a_i$ and $b_i$, for\nwhich each pays from her own savings. Maxine is declared to be the turn victor\nwith probability $\\tfrac{a_i}{a_i+b_i}$; otherwise, Mina is. If Maxine wins the\nturn, she will move the counter one place to the right, so that $X_i = X_{i-1}\n+1$; if Mina does so, the counter will move one place to the left, so that $X_i\n= X_{i-1} -1$. If $\\liminf X_i = \\infty$, then Maxine wins the game; if\n$\\limsup X_i = -\\infty$, then Mina does. (A special rule is needed to treat the\nremaining, indeterminate, case.) When Maxine wins, she receives a terminal\npayment of $m_\\infty$, while Mina receives $n_\\infty$. If Mina wins, these\nrespective receipts are $m_{-\\infty}$ and $n_{-\\infty}$. The four terminal\npayment values are supposed to be real numbers that satisfy $m_\\infty >\nm_{-\\infty}$ and $n_\\infty < n_{-\\infty}$, where these bounds accord with the\nnotion that Maxine wins when the counter ends far to the right, and that Mina\ndoes so when it reaches far to the left. Each player is motivated to offer\nstakes at each turn of the game, in order to secure the higher terminal payment\nthat will arise from her victory; but since these stake amounts accumulate to\nact as a cost depleting the profit arising from victory, each player must also\nseek to control these expenses. In this article, we study the Trail of Lost\nPennies, formulating strategies for the two players and defining and analysing\nNash equilibria in the game.",
    "descriptor": "\nComments: 74 pages with five figures\n",
    "authors": [
      "Alan Hammond"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2209.07451"
  },
  {
    "id": "arXiv:2209.07455",
    "title": "A Genetic Quantum Annealing Algorithm",
    "abstract": "A genetic algorithm (GA) is a search-based optimization technique based on\nthe principles of Genetics and Natural Selection. We present an algorithm which\nenhances the classical GA with input from quantum annealers. As in a classical\nGA, the algorithm works by breeding a population of possible solutions based on\ntheir fitness. However, the population of individuals is defined by the\ncontinuous couplings on the quantum annealer, which then give rise via quantum\nannealing to the set of corresponding phenotypes that represent attempted\nsolutions. This introduces a form of directed mutation into the algorithm that\ncan enhance its performance in various ways. Two crucial enhancements come from\nthe continuous couplings having strengths that are inherited from the fitness\nof the parents (so-called nepotism) and from the annealer couplings allowing\nthe entire population to be influenced by the fittest individuals (so-called\nquantum-polyandry). We find our algorithm to be significantly more powerful on\nseveral simple problems than a classical GA.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Steven Abel",
      "Luca A. Nutricati",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2209.07455"
  },
  {
    "id": "arXiv:2209.07492",
    "title": "MRI-MECH: Mechanics-informed MRI to estimate esophageal health",
    "abstract": "Dynamic magnetic resonance imaging (MRI) is a popular medical imaging\ntechnique to generate image sequences of the flow of a contrast material inside\ntissues and organs. However, its application to imaging bolus movement through\nthe esophagus has only been demonstrated in few feasibility studies and is\nrelatively unexplored. In this work, we present a computational framework\ncalled mechanics-informed MRI (MRI-MECH) that enhances that capability thereby\nincreasing the applicability of dynamic MRI for diagnosing esophageal\ndisorders. Pineapple juice was used as the swallowed contrast material for the\ndynamic MRI and the MRI image sequence was used as input to the MRI-MECH. The\nMRI-MECH modeled the esophagus as a flexible one-dimensional tube and the\nelastic tube walls followed a linear tube law. Flow through the esophagus was\nthen governed by one-dimensional mass and momentum conservation equations.\nThese equations were solved using a physics-informed neural network (PINN). The\nPINN minimized the difference between the measurements from the MRI and model\npredictions ensuring that the physics of the fluid flow problem was always\nfollowed. MRI-MECH calculated the fluid velocity and pressure during esophageal\ntransit and estimated the mechanical health of the esophagus by calculating\nwall stiffness and active relaxation. Additionally, MRI-MECH predicted missing\ninformation about the lower esophageal sphincter during the emptying process,\ndemonstrating its applicability to scenarios with missing data or poor image\nresolution. In addition to potentially improving clinical decisions based on\nquantitative estimates of the mechanical health of the esophagus, MRI-MECH can\nalso be enhanced for application to other medical imaging modalities to enhance\ntheir functionality as well.",
    "descriptor": "\nComments: 21 pages, 15 figures\n",
    "authors": [
      "Sourav Halder",
      "Ethan M. Johnson",
      "Jun Yamasaki",
      "Peter J. Kahrilas",
      "Michael Markl",
      "John E. Pandolfino",
      "Neelesh A. Patankar"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.07492"
  },
  {
    "id": "arXiv:2209.07505",
    "title": "Temporal, structural, and functional heterogeneities extend criticality  and antifragility in random Boolean networks",
    "abstract": "Most models of complex systems have been homogeneous, i.e., all elements have\nthe same properties (spatial, temporal, structural, functional). However, most\nnatural systems are heterogeneous: few elements are more relevant, larger,\nstronger, or faster than others. In homogeneous systems, criticality -- a\nbalance between change and stability, order and chaos -- is usually found for a\nvery narrow region in the parameter space, close to a phase transition. Using\nrandom Boolean networks -- a general model of discrete dynamical systems -- we\nshow that heterogeneity -- in time, structure, and function -- can broaden\nadditively the parameter region where criticality is found. Moreover, parameter\nregions where antifragility is found are also increased with heterogeneity.\nHowever, maximum antifragility is found for particular parameters in\nhomogeneous networks. Our work suggests that the \"optimal\" balance between\nhomogeneity and heterogeneity is non-trivial, context-dependent, and in some\ncases, dynamic.",
    "descriptor": "",
    "authors": [
      "Amahury Jafet L\u00f3pez-D\u00edaz",
      "Fernanda S\u00e1nchez-Puig",
      "Carlos Gershenson"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.07505"
  },
  {
    "id": "arXiv:2209.07519",
    "title": "Multi-Modal Beam Prediction Challenge 2022: Towards Generalization",
    "abstract": "Beam management is a challenging task for millimeter wave (mmWave) and\nsub-terahertz communication systems, especially in scenarios with highly-mobile\nusers. Leveraging external sensing modalities such as vision, LiDAR, radar,\nposition, or a combination of them, to address this beam management challenge\nhas recently attracted increasing interest from both academia and industry.\nThis is mainly motivated by the dependency of the beam direction decision on\nthe user location and the geometry of the surrounding environment --\ninformation that can be acquired from the sensory data. To realize the promised\nbeam management gains, such as the significant reduction in beam alignment\noverhead, in practice, however, these solutions need to account for important\naspects. For example, these multi-modal sensing aided beam selection approaches\nshould be able to generalize their learning to unseen scenarios and should be\nable to operate in realistic dense deployments.\nThe \"Multi-Modal Beam Prediction Challenge 2022: Towards Generalization\"\ncompetition is offered to provide a platform for investigating these critical\nquestions. In order to facilitate the generalizability study, the competition\noffers a large-scale multi-modal dataset with co-existing communication and\nsensing data collected across multiple real-world locations and different times\nof the day. In this paper, along with the detailed descriptions of the problem\nstatement and the development dataset, we provide a baseline solution that\nutilizes the user position data to predict the optimal beam indices. The\nobjective of this challenge is to go beyond a simple feasibility study and\nenable necessary research in this direction, paving the way towards\ngeneralizable multi-modal sensing-aided beam management for real-world future\ncommunication systems.",
    "descriptor": "\nComments: The dataset is available on the ML competition page: this https URL\n",
    "authors": [
      "Gouranga Charan",
      "Umut Demirhan",
      "Jo\u00e3o Morais",
      "Arash Behboodi",
      "Hamed Pezeshki",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.07519"
  },
  {
    "id": "arXiv:1811.11660",
    "title": "A short and elegant proof of a theorem of J.-E. Pin",
    "abstract": "Comments: 11 pages, major update with new proof",
    "descriptor": "\nComments: 11 pages, major update with new proof\n",
    "authors": [
      "Michiel de Bondt"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1811.11660"
  },
  {
    "id": "arXiv:1905.05285",
    "title": "Nearest Neighbor and Kernel Survival Analysis: Nonasymptotic Error  Bounds and Strong Consistency Rates",
    "abstract": "Comments: International Conference on Machine Learning (ICML 2019); this draft includes minor corrections",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML 2019); this draft includes minor corrections\n",
    "authors": [
      "George H. Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.05285"
  },
  {
    "id": "arXiv:1908.06955",
    "title": "Dynamic Graph Message Passing Networks",
    "abstract": "Comments: CVPR 2020 Oral",
    "descriptor": "\nComments: CVPR 2020 Oral\n",
    "authors": [
      "Li Zhang",
      "Dan Xu",
      "Anurag Arnab",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.06955"
  },
  {
    "id": "arXiv:2004.09640",
    "title": "Mechanism Design for Online Resource Allocation: A Unified Approach",
    "abstract": "Comments: 52 pages, 5 figures",
    "descriptor": "\nComments: 52 pages, 5 figures\n",
    "authors": [
      "Xiaoqi Tan",
      "Bo Sun",
      "Alberto Leon-Garcia",
      "Yuan Wu",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.09640"
  },
  {
    "id": "arXiv:2005.12900",
    "title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning  with a Generative Model",
    "abstract": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning  with a Generative Model",
    "descriptor": "",
    "authors": [
      "Gen Li",
      "Yuting Wei",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.12900"
  },
  {
    "id": "arXiv:2006.10641",
    "title": "Shannon meets Myerson: Information Extraction from a Strategic Sender",
    "abstract": "Comments: Submitted to Games and Economic Behaviour",
    "descriptor": "\nComments: Submitted to Games and Economic Behaviour\n",
    "authors": [
      "Anuj S. Vora",
      "Ankur A. Kulkarni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.10641"
  },
  {
    "id": "arXiv:2008.07369",
    "title": "Continuous Patrolling Games",
    "abstract": "Continuous Patrolling Games",
    "descriptor": "",
    "authors": [
      "Steve Alpern",
      "Thuy Bui",
      "Thomas Lidbetter",
      "Katerina Papadaki"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.07369"
  },
  {
    "id": "arXiv:2008.11702",
    "title": "Delving into Inter-Image Invariance for Unsupervised Visual  Representations",
    "abstract": "Comments: International Journal of Computer Vision (IJCV), 2022",
    "descriptor": "\nComments: International Journal of Computer Vision (IJCV), 2022\n",
    "authors": [
      "Jiahao Xie",
      "Xiaohang Zhan",
      "Ziwei Liu",
      "Yew Soon Ong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11702"
  },
  {
    "id": "arXiv:2010.14928",
    "title": "Particle gradient descent model for point process generation",
    "abstract": "Particle gradient descent model for point process generation",
    "descriptor": "",
    "authors": [
      "Antoine Brochard",
      "Bart\u0142omiej B\u0142aszczyszyn",
      "St\u00e9phane Mallat",
      "Sixin Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2010.14928"
  },
  {
    "id": "arXiv:2010.15833",
    "title": "The realizability of discs with ribbons on a M\u00f6bius strip",
    "abstract": "Comments: in Russian",
    "descriptor": "\nComments: in Russian\n",
    "authors": [
      "Arthur Bikeev Igorevich"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2010.15833"
  },
  {
    "id": "arXiv:2011.08559",
    "title": "Normalized Weighting Schemes for Image Interpolation Algorithms",
    "abstract": "Comments: 6 pages, 14 figures, 2 Tables",
    "descriptor": "\nComments: 6 pages, 14 figures, 2 Tables\n",
    "authors": [
      "Olivier Rukundo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08559"
  },
  {
    "id": "arXiv:2011.10737",
    "title": "Neural-iLQR: A Learning-Aided Shooting Method for Trajectory  Optimization",
    "abstract": "Comments: 7 pages, 7 figures",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Zilong Cheng",
      "Yulin Li",
      "Kai Chen",
      "Jun Ma",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.10737"
  },
  {
    "id": "arXiv:2101.05592",
    "title": "Dynamic network analysis of a target defense differential game with  limited observations",
    "abstract": "Comments: accepted in IEEE Transactions on Control of Network Systems",
    "descriptor": "\nComments: accepted in IEEE Transactions on Control of Network Systems\n",
    "authors": [
      "Sharad Kumar Singh",
      "Puduru Viswanadha Reddy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.05592"
  },
  {
    "id": "arXiv:2101.05768",
    "title": "How to Attack and Defend NextG Radio Access Network Slicing with  Reinforcement Learning",
    "abstract": "How to Attack and Defend NextG Radio Access Network Slicing with  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Yi Shi",
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "M. Cenk Gursoy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.05768"
  },
  {
    "id": "arXiv:2101.10203",
    "title": "ISP Distillation",
    "abstract": "ISP Distillation",
    "descriptor": "",
    "authors": [
      "Eli Schwartz",
      "Alex Bronstein",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.10203"
  },
  {
    "id": "arXiv:2101.12198",
    "title": "A Spectral Approach to Polytope Diameter",
    "abstract": "Comments: Refined the statement + proof of Theorem 1.1, comparison with related work. Fixed some minor mistakes, added references",
    "descriptor": "\nComments: Refined the statement + proof of Theorem 1.1, comparison with related work. Fixed some minor mistakes, added references\n",
    "authors": [
      "Hariharan Narayanan",
      "Rikhav Shah",
      "Nikhil Srivastava"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.12198"
  },
  {
    "id": "arXiv:2102.12586",
    "title": "A Stochastic Optimization Framework for Fair Risk Minimization",
    "abstract": "A Stochastic Optimization Framework for Fair Risk Minimization",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Sina Baharlouei",
      "Rakesh Pavan",
      "Meisam Razaviyayn",
      "Ahmad Beirami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.12586"
  },
  {
    "id": "arXiv:2103.06459",
    "title": "Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings",
    "abstract": "Comments: Accepted by COLING 2022",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Linlin Liu",
      "Thien Hai Nguyen",
      "Shafiq Joty",
      "Lidong Bing",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.06459"
  },
  {
    "id": "arXiv:2104.07456",
    "title": "Effect of Post-processing on Contextualized Word Representations",
    "abstract": "Comments: COLING 2022",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Hassan Sajjad",
      "Firoj Alam",
      "Fahim Dalvi",
      "Nadir Durrani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07456"
  },
  {
    "id": "arXiv:2104.07737",
    "title": "A Random Persistence Diagram Generator",
    "abstract": "Comments: 17 pages, 6 figures and 3 tables",
    "descriptor": "\nComments: 17 pages, 6 figures and 3 tables\n",
    "authors": [
      "Theodore Papamarkou",
      "Farzana Nasrin",
      "Austin Lawson",
      "Na Gong",
      "Orlando Rios",
      "Vasileios Maroulas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2104.07737"
  },
  {
    "id": "arXiv:2104.08664",
    "title": "Characterizing Idioms: Conventionality and Contingency",
    "abstract": "Characterizing Idioms: Conventionality and Contingency",
    "descriptor": "",
    "authors": [
      "Michaela Socolof",
      "Jackie Chi Kit Cheung",
      "Michael Wagner",
      "Timothy J. O'Donnell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08664"
  },
  {
    "id": "arXiv:2104.14686",
    "title": "String Diagram Rewrite Theory II: Rewriting with Symmetric Monoidal  Structure",
    "abstract": "String Diagram Rewrite Theory II: Rewriting with Symmetric Monoidal  Structure",
    "descriptor": "",
    "authors": [
      "Filippo Bonchi",
      "Fabio Gadducci",
      "Aleks Kissinger",
      "Pawel Sobocinski",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14686"
  },
  {
    "id": "arXiv:2104.14759",
    "title": "Non-Deterministic Functions as Non-Deterministic Processes (Extended  Version)",
    "abstract": "Comments: Extended version of an FSCD 2021 paper. 56 pages plus appendices with full proofs",
    "descriptor": "\nComments: Extended version of an FSCD 2021 paper. 56 pages plus appendices with full proofs\n",
    "authors": [
      "Joseph W. N. Paulus",
      "Daniele Nantes-Sobrinho",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14759"
  },
  {
    "id": "arXiv:2105.11895",
    "title": "The Component Diagnosability of General Networks",
    "abstract": "Comments: 21 pages, 11 figures",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Hongbin Zhuang",
      "Wenzhong Guo",
      "Xiaoyan Li",
      "Ximeng Liu",
      "Cheng-Kuan Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.11895"
  },
  {
    "id": "arXiv:2106.01555",
    "title": "Comparing Acoustic-based Approaches for Alzheimer's Disease Detection",
    "abstract": "Comments: Accepted to INTERSPEECH 2021; update includes corrections to last two rows of Table 2 and corresponding text edits",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021; update includes corrections to last two rows of Table 2 and corresponding text edits\n",
    "authors": [
      "Aparna Balagopalan",
      "Jekaterina Novikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01555"
  },
  {
    "id": "arXiv:2106.14706",
    "title": "Motion Projection Consistency Based 3D Human Pose Estimation with  Virtual Bones from Monocular Videos",
    "abstract": "Comments: 10 pages, 7 figures. Accepted by TCDS 2022",
    "descriptor": "\nComments: 10 pages, 7 figures. Accepted by TCDS 2022\n",
    "authors": [
      "Guangming Wang",
      "Honghao Zeng",
      "Ziliang Wang",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14706"
  },
  {
    "id": "arXiv:2108.13461",
    "title": "Time Series Prediction using Deep Learning Methods in Healthcare",
    "abstract": "Time Series Prediction using Deep Learning Methods in Healthcare",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Morid",
      "Olivia R. Liu Sheng",
      "Joseph Dunbar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13461"
  },
  {
    "id": "arXiv:2109.04898",
    "title": "LibFewShot: A Comprehensive Library for Few-shot Learning",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Wenbin Li",
      "Ziyi",
      "Wang",
      "Xuesong Yang",
      "Chuanqi Dong",
      "Pinzhuo Tian",
      "Tiexin Qin",
      "Jing Huo",
      "Yinghuan Shi",
      "Lei Wang",
      "Yang Gao",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04898"
  },
  {
    "id": "arXiv:2109.07206",
    "title": "Signaling Design for Cooperative Resource Allocation and its Impact to  Reliability",
    "abstract": "Signaling Design for Cooperative Resource Allocation and its Impact to  Reliability",
    "descriptor": "",
    "authors": [
      "Rasmus Liborius Bruun",
      "C. Santiago Morej\u00f3n Garc\u00eda",
      "Troels B. S\u00f8rensen",
      "Nuno K. Pratas",
      "Tatiana Kozlova Madsen",
      "Preben Mogensen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.07206"
  },
  {
    "id": "arXiv:2109.07429",
    "title": "Towards a Game-Theoretic Security Analysis of Off-Chain Protocols",
    "abstract": "Comments: This submission is the extended version of our CSF 2023 paper \"Towards a Game-Theoretic Security Analysis of Off-Chain Protocols\"",
    "descriptor": "\nComments: This submission is the extended version of our CSF 2023 paper \"Towards a Game-Theoretic Security Analysis of Off-Chain Protocols\"\n",
    "authors": [
      "Sophie Rain",
      "Georgia Avarikioti",
      "Laura Kov\u00e1cs",
      "Matteo Maffei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.07429"
  },
  {
    "id": "arXiv:2109.09824",
    "title": "Well Googled is Half Done: Multimodal Forecasting of New Fashion Product  Sales with Image-based Google Trends",
    "abstract": "Comments: Paper submitted at Wiley Journal of Forecasting",
    "descriptor": "\nComments: Paper submitted at Wiley Journal of Forecasting\n",
    "authors": [
      "Geri Skenderi",
      "Christian Joppi",
      "Matteo Denitto",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09824"
  },
  {
    "id": "arXiv:2109.10474",
    "title": "Rapid detection and recognition of whole brain activity in a freely  behaving Caenorhabditis elegans",
    "abstract": "Rapid detection and recognition of whole brain activity in a freely  behaving Caenorhabditis elegans",
    "descriptor": "",
    "authors": [
      "Yuxiang Wu",
      "Shang Wu",
      "Xin Wang",
      "Chengtian Lang",
      "Quanshi Zhang",
      "Quan Wen",
      "Tianqi Xu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10474"
  },
  {
    "id": "arXiv:2109.13595",
    "title": "The Fragility of Optimized Bandit Algorithms",
    "abstract": "The Fragility of Optimized Bandit Algorithms",
    "descriptor": "",
    "authors": [
      "Lin Fan",
      "Peter W. Glynn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.13595"
  },
  {
    "id": "arXiv:2110.00481",
    "title": "Personalized Rehabilitation Robotics based on Online Learning Control",
    "abstract": "Personalized Rehabilitation Robotics based on Online Learning Control",
    "descriptor": "",
    "authors": [
      "Samuel Tesfazgi",
      "Armin Lederer",
      "Johannes F. Kunz",
      "Alejandro J. Ord\u00f3\u00f1ez-Conejo",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00481"
  },
  {
    "id": "arXiv:2110.05076",
    "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
    "abstract": "Comments: 21 pages with 10 appendix section Our paper has been accepted in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 21 pages with 10 appendix section Our paper has been accepted in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Mingcheng Hou",
      "Issei Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05076"
  },
  {
    "id": "arXiv:2110.05531",
    "title": "Study of Drug Assimilation in Human System using Physics Informed Neural  Networks",
    "abstract": "Comments: Incomplete research work with insufficient data and lot of errors in results and languauge",
    "descriptor": "\nComments: Incomplete research work with insufficient data and lot of errors in results and languauge\n",
    "authors": [
      "Kanupriya Goswami",
      "Arpana Sharma",
      "Madhu Pruthi",
      "Richa Gupta"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05531"
  },
  {
    "id": "arXiv:2110.06357",
    "title": "Tangent Space and Dimension Estimation with the Wasserstein Distance",
    "abstract": "Comments: Main theorems rewritten. Introduction is written more compactly",
    "descriptor": "\nComments: Main theorems rewritten. Introduction is written more compactly\n",
    "authors": [
      "Uzu Lim",
      "Harald Oberhauser",
      "Vidit Nanda"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06357"
  },
  {
    "id": "arXiv:2111.02135",
    "title": "Efficient 3D Deep LiDAR Odometry",
    "abstract": "Comments: 17 pages, 13 figures. Accepted by PAMI 2022. arXiv admin note: substantial text overlap with arXiv:2012.00972",
    "descriptor": "\nComments: 17 pages, 13 figures. Accepted by PAMI 2022. arXiv admin note: substantial text overlap with arXiv:2012.00972\n",
    "authors": [
      "Guangming Wang",
      "Xinrui Wu",
      "Shuyang Jiang",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02135"
  },
  {
    "id": "arXiv:2111.04484",
    "title": "On Bi-infinite and Conjugate Post Correspondence Problems",
    "abstract": "On Bi-infinite and Conjugate Post Correspondence Problems",
    "descriptor": "",
    "authors": [
      "Olivier Finkel",
      "Vesa Halava",
      "Tero Harju",
      "Esa Sahla"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.04484"
  },
  {
    "id": "arXiv:2111.06382",
    "title": "The ZERO Regrets Algorithm: Optimizing over Pure Nash Equilibria via  Integer Programming",
    "abstract": "The ZERO Regrets Algorithm: Optimizing over Pure Nash Equilibria via  Integer Programming",
    "descriptor": "",
    "authors": [
      "Gabriele Dragotto",
      "Rosario Scatamacchia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.06382"
  },
  {
    "id": "arXiv:2111.06711",
    "title": "An Axiomatic Approach to Formalized Responsibility Ascription",
    "abstract": "An Axiomatic Approach to Formalized Responsibility Ascription",
    "descriptor": "",
    "authors": [
      "Sarah Hiller",
      "Jonas Israel",
      "Jobst Heitzig"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.06711"
  },
  {
    "id": "arXiv:2112.03258",
    "title": "DoodleFormer: Creative Sketch Drawing with Transformers",
    "abstract": "Comments: Accepted to ECCV-2022. Project webpage: this https URL",
    "descriptor": "\nComments: Accepted to ECCV-2022. Project webpage: this https URL\n",
    "authors": [
      "Ankan Kumar Bhunia",
      "Salman Khan",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer",
      "Fahad Shahbaz Khan",
      "Jorma Laaksonen",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03258"
  },
  {
    "id": "arXiv:2112.03492",
    "title": "Decision-based Black-box Attack Against Vision Transformers via  Patch-wise Adversarial Removal",
    "abstract": "Decision-based Black-box Attack Against Vision Transformers via  Patch-wise Adversarial Removal",
    "descriptor": "",
    "authors": [
      "Yucheng Shi",
      "Yahong Han",
      "Yu-an Tan",
      "Xiaohui Kuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.03492"
  },
  {
    "id": "arXiv:2112.11699",
    "title": "Few-Shot Object Detection: A Comprehensive Survey",
    "abstract": "Comments: 27 pages, 13 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: 27 pages, 13 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Mona K\u00f6hler",
      "Markus Eisenbach",
      "Horst-Michael Gross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11699"
  },
  {
    "id": "arXiv:2112.12596",
    "title": "The need for a more human-centered approach to designing and validating  transparent AI in medical image analysis -- Guidelines and Evidence from a  Systematic Review",
    "abstract": "The need for a more human-centered approach to designing and validating  transparent AI in medical image analysis -- Guidelines and Evidence from a  Systematic Review",
    "descriptor": "",
    "authors": [
      "Haomin Chen",
      "Catalina Gomez",
      "Chien-Ming Huang",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.12596"
  },
  {
    "id": "arXiv:2201.00875",
    "title": "Transport type metrics on the space of probability measures involving  singular base measures",
    "abstract": "Transport type metrics on the space of probability measures involving  singular base measures",
    "descriptor": "",
    "authors": [
      "Luca Nenna",
      "Brendan Pass"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.00875"
  },
  {
    "id": "arXiv:2201.02006",
    "title": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "abstract": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "descriptor": "",
    "authors": [
      "Philip James Purnell"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.02006"
  },
  {
    "id": "arXiv:2201.02495",
    "title": "Sign Language Video Retrieval with Free-Form Textual Queries",
    "abstract": "Comments: In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
    "descriptor": "\nComments: In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Amanda Duarte",
      "Samuel Albanie",
      "Xavier Gir\u00f3-i-Nieto",
      "G\u00fcl Varol"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.02495"
  },
  {
    "id": "arXiv:2201.03101",
    "title": "ImageSubject: A Large-scale Dataset for Subject Detection",
    "abstract": "ImageSubject: A Large-scale Dataset for Subject Detection",
    "descriptor": "",
    "authors": [
      "Xin Miao",
      "Jiayi Liu",
      "Huayan Wang",
      "Jun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.03101"
  },
  {
    "id": "arXiv:2201.07601",
    "title": "BiConMP: A Nonlinear Model Predictive Control Framework for Whole Body  Motion Planning",
    "abstract": "BiConMP: A Nonlinear Model Predictive Control Framework for Whole Body  Motion Planning",
    "descriptor": "",
    "authors": [
      "Avadesh Meduri",
      "Paarth Shah",
      "Julian Viereck",
      "Majid Khadiv",
      "Ioannis Havoutis",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.07601"
  },
  {
    "id": "arXiv:2201.08227",
    "title": "Learning Multi-agent Options for Tabular Reinforcement Learning using  Factor Graphs",
    "abstract": "Learning Multi-agent Options for Tabular Reinforcement Learning using  Factor Graphs",
    "descriptor": "",
    "authors": [
      "Jiayu Chen",
      "Jingdi Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08227"
  },
  {
    "id": "arXiv:2201.11036",
    "title": "Fast Server Learning Rate Tuning for Coded Federated Dropout",
    "abstract": "Comments: 6 pages plus references and appendix, 6 figures. Accepted and presented at FL-IJCAI22 (this https URL)",
    "descriptor": "\nComments: 6 pages plus references and appendix, 6 figures. Accepted and presented at FL-IJCAI22 (this https URL)\n",
    "authors": [
      "Giacomo Verardo",
      "Daniel Barreira",
      "Marco Chiesa",
      "Dejan Kostic",
      "Gerald Q. Maguire Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11036"
  },
  {
    "id": "arXiv:2201.11367",
    "title": "Pan More Gold from the Sand: Refining Open-domain Dialogue Training with  Noisy Self-Retrieval Generation",
    "abstract": "Comments: Accepted in COLING 2022",
    "descriptor": "\nComments: Accepted in COLING 2022\n",
    "authors": [
      "Yihe Wang",
      "Yitong Li",
      "Yasheng Wang",
      "Fei Mi",
      "Pingyi Zhou",
      "Xin Wang",
      "Jin Liu",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11367"
  },
  {
    "id": "arXiv:2202.01724",
    "title": "Seeded Database Matching Under Noisy Column Repetitions",
    "abstract": "Seeded Database Matching Under Noisy Column Repetitions",
    "descriptor": "",
    "authors": [
      "Serhat Bakirtas",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01724"
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02142"
  },
  {
    "id": "arXiv:2202.02281",
    "title": "\"I'm Just Overwhelmed\": Investigating Physical Therapy Accessibility and  Technology Interventions for People with Disabilities and/or Chronic  Conditions",
    "abstract": "Comments: 22 pages, 2 tables",
    "descriptor": "\nComments: 22 pages, 2 tables\n",
    "authors": [
      "Momona Yamagami",
      "Kelly Mack",
      "Jennifer Mankoff",
      "Katherine M. Steele"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02281"
  },
  {
    "id": "arXiv:2202.03264",
    "title": "Experimental Investigation of Variational Mode Decomposition and Deep  Learning for Short-Term Multi-horizon Residential Electric Load Forecasting",
    "abstract": "Experimental Investigation of Variational Mode Decomposition and Deep  Learning for Short-Term Multi-horizon Residential Electric Load Forecasting",
    "descriptor": "",
    "authors": [
      "Mohamed Aymane Ahajjam",
      "Daniel Bonilla Licea",
      "Mounir Ghogho",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03264"
  },
  {
    "id": "arXiv:2202.06949",
    "title": "Consensus Division in an Arbitrary Ratio",
    "abstract": "Comments: correct the contribution of reference [SW85]; fix typos; update figures",
    "descriptor": "\nComments: correct the contribution of reference [SW85]; fix typos; update figures\n",
    "authors": [
      "Paul W. Goldberg",
      "Jiawei Li"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06949"
  },
  {
    "id": "arXiv:2202.07559",
    "title": "Unsupervised Learning of Group Invariant and Equivariant Representations",
    "abstract": "Unsupervised Learning of Group Invariant and Equivariant Representations",
    "descriptor": "",
    "authors": [
      "Robin Winter",
      "Marco Bertolini",
      "Tuan Le",
      "Frank No\u00e9",
      "Djork-Arn\u00e9 Clevert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07559"
  },
  {
    "id": "arXiv:2202.10062",
    "title": "USCORE: An Effective Approach to Fully Unsupervised Evaluation Metrics  for Machine Translation",
    "abstract": "Comments: Several Revisions, includes github link",
    "descriptor": "\nComments: Several Revisions, includes github link\n",
    "authors": [
      "Jonas Belouadi",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.10062"
  },
  {
    "id": "arXiv:2202.11006",
    "title": "Robust Real-time LiDAR-inertial Initialization",
    "abstract": "Robust Real-time LiDAR-inertial Initialization",
    "descriptor": "",
    "authors": [
      "Fangcheng Zhu",
      "Yunfan Ren",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11006"
  },
  {
    "id": "arXiv:2202.11627",
    "title": "Dyck paths with catastrophes modulo the positions of a given pattern",
    "abstract": "Comments: 25 pages, 14 figures, 1 table",
    "descriptor": "\nComments: 25 pages, 14 figures, 1 table\n",
    "authors": [
      "Jean-Luc Baril",
      "Sergey Kirgizov",
      "Armen Petrossian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.11627"
  },
  {
    "id": "arXiv:2202.12183",
    "title": "Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning  with Provable Convergence",
    "abstract": "Comments: 32 pages, 12 figures",
    "descriptor": "\nComments: 32 pages, 12 figures\n",
    "authors": [
      "Zi-Hao Qiu",
      "Quanqi Hu",
      "Yongjian Zhong",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12183"
  },
  {
    "id": "arXiv:2202.12883",
    "title": "Human Detection of Political Deepfakes across Transcripts, Audio, and  Video",
    "abstract": "Human Detection of Political Deepfakes across Transcripts, Audio, and  Video",
    "descriptor": "",
    "authors": [
      "Matthew Groh",
      "Aruna Sankaranarayanan",
      "Andrew Lippman",
      "Rosalind Picard"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12883"
  },
  {
    "id": "arXiv:2202.13377",
    "title": "Meta-RangeSeg: LiDAR Sequence Semantic Segmentation Using Multiple  Feature Aggregation",
    "abstract": "Comments: Accepted by RA-L with IROS 2022",
    "descriptor": "\nComments: Accepted by RA-L with IROS 2022\n",
    "authors": [
      "Song Wang",
      "Jianke Zhu",
      "Ruixiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.13377"
  },
  {
    "id": "arXiv:2203.00567",
    "title": "Descriptellation: Deep Learned Constellation Descriptors",
    "abstract": "Descriptellation: Deep Learned Constellation Descriptors",
    "descriptor": "",
    "authors": [
      "Chunwei Xing",
      "Xinyu Sun",
      "Andrei Cramariuc",
      "Samuel Gull",
      "Jen Jen Chung",
      "Cesar Cadena",
      "Roland Siegwart",
      "Florian Tschopp"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00567"
  },
  {
    "id": "arXiv:2203.01104",
    "title": "Parameter-Efficient Mixture-of-Experts Architecture for Pre-trained  Language Models",
    "abstract": "Comments: 11 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 2 figures, 2 tables\n",
    "authors": [
      "Ze-Feng Gao",
      "Peiyu Liu",
      "Wayne Xin Zhao",
      "Zhong-Yi Lu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.01104"
  },
  {
    "id": "arXiv:2203.02202",
    "title": "Carbon Footprint of Selecting and Training Deep Learning Models for  Medical Image Analysis",
    "abstract": "Comments: Accepted to be presented as an Oral Presentation at 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2022. 13 pages. 5 figures",
    "descriptor": "\nComments: Accepted to be presented as an Oral Presentation at 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2022. 13 pages. 5 figures\n",
    "authors": [
      "Raghavendra Selvan",
      "Nikhil Bhagwat",
      "Lasse F. Wolff Anthony",
      "Benjamin Kanding",
      "Erik B. Dam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02202"
  },
  {
    "id": "arXiv:2203.02399",
    "title": "Benchmarking Counterfactual Algorithms for XAI: From White Box to Black  Box",
    "abstract": "Benchmarking Counterfactual Algorithms for XAI: From White Box to Black  Box",
    "descriptor": "",
    "authors": [
      "Catarina Moreira",
      "Yu-Liang Chou",
      "Chihcheng Hsieh",
      "Chun Ouyang",
      "Joaquim Jorge",
      "Jo\u00e3o Madeiras Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.02399"
  },
  {
    "id": "arXiv:2203.04446",
    "title": "Self-Supervised Domain Calibration and Uncertainty Estimation for Place  Recognition",
    "abstract": "Self-Supervised Domain Calibration and Uncertainty Estimation for Place  Recognition",
    "descriptor": "",
    "authors": [
      "Pierre-Yves Lajoie",
      "Giovanni Beltrame"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04446"
  },
  {
    "id": "arXiv:2203.05250",
    "title": "On the computational properties of basic mathematical notions",
    "abstract": "Comments: 44 pages, to appear in the Journal of Logic and Computation",
    "descriptor": "\nComments: 44 pages, to appear in the Journal of Logic and Computation\n",
    "authors": [
      "Dag Normann",
      "Sam Sanders"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.05250"
  },
  {
    "id": "arXiv:2203.07094",
    "title": "DialMed: A Dataset for Dialogue-based Medication Recommendation",
    "abstract": "Comments: Accepted as a long paper at COLING 2022",
    "descriptor": "\nComments: Accepted as a long paper at COLING 2022\n",
    "authors": [
      "Zhenfeng He",
      "Yuqiang Han",
      "Zhenqiu Ouyang",
      "Wei Gao",
      "Hongxu Chen",
      "Guandong Xu",
      "Jian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07094"
  },
  {
    "id": "arXiv:2203.07341",
    "title": "Defending From Physically-Realizable Adversarial Attacks Through  Internal Over-Activation Analysis",
    "abstract": "Defending From Physically-Realizable Adversarial Attacks Through  Internal Over-Activation Analysis",
    "descriptor": "",
    "authors": [
      "Giulio Rossolini",
      "Federico Nesti",
      "Fabio Brau",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07341"
  },
  {
    "id": "arXiv:2203.09337",
    "title": "CoBRA: A Composable Benchmark for Robotics Applications",
    "abstract": "CoBRA: A Composable Benchmark for Robotics Applications",
    "descriptor": "",
    "authors": [
      "Matthias Mayer",
      "Jonathan K\u00fclz",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09337"
  },
  {
    "id": "arXiv:2203.09441",
    "title": "Learning of Structurally Unambiguous Probabilistic Grammars",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2011.07472",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.07472\n",
    "authors": [
      "Dana Fisman",
      "Dolav Nitay",
      "Michal Ziv-Ukelson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09441"
  },
  {
    "id": "arXiv:2203.09812",
    "title": "Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared  Control on the Hannes Prosthesis",
    "abstract": "Comments: Accepted to IROS 2022",
    "descriptor": "\nComments: Accepted to IROS 2022\n",
    "authors": [
      "Federico Vasile",
      "Elisa Maiettini",
      "Giulia Pasquale",
      "Astrid Florio",
      "Nicol\u00f2 Boccardo",
      "Lorenzo Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09812"
  },
  {
    "id": "arXiv:2203.10316",
    "title": "Learning to Reason Deductively: Math Word Problem Solving as Complex  Relation Extraction",
    "abstract": "Comments: 12 pages, 7 figures, ACL-2022, additional experiments for math23k and large-LM",
    "descriptor": "\nComments: 12 pages, 7 figures, ACL-2022, additional experiments for math23k and large-LM\n",
    "authors": [
      "Zhanming Jie",
      "Jierui Li",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10316"
  },
  {
    "id": "arXiv:2203.10925",
    "title": "Learning Occlusion-Aware Coarse-to-Fine Depth Map for Self-supervised  Monocular Depth Estimation",
    "abstract": "Comments: Accepted at ACM Multimedia 2022",
    "descriptor": "\nComments: Accepted at ACM Multimedia 2022\n",
    "authors": [
      "Zhengming Zhou",
      "Qiulei Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10925"
  },
  {
    "id": "arXiv:2203.11076",
    "title": "Collaborative Learning for Cyberattack Detection in Blockchain Networks",
    "abstract": "Collaborative Learning for Cyberattack Detection in Blockchain Networks",
    "descriptor": "",
    "authors": [
      "Tran Viet Khoa",
      "Do Hai Son",
      "Dinh Thai Hoang",
      "Nguyen Linh Trung",
      "Tran Thi Thuy Quynh",
      "Diep N. Nguyen",
      "Nguyen Viet Ha",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11076"
  },
  {
    "id": "arXiv:2203.11675",
    "title": "Subset Sum in $O(n^{11}\\log(n))$",
    "abstract": "Subset Sum in $O(n^{11}\\log(n))$",
    "descriptor": "",
    "authors": [
      "Rion Tolchin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.11675"
  },
  {
    "id": "arXiv:2203.13176",
    "title": "Emergence of hierarchical reference systems in multi-agent communication",
    "abstract": "Emergence of hierarchical reference systems in multi-agent communication",
    "descriptor": "",
    "authors": [
      "Xenia Ohmer",
      "Marko Duda",
      "Elia Bruni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13176"
  },
  {
    "id": "arXiv:2203.15835",
    "title": "ACR Loss: Adaptive Coordinate-based Regression Loss for Face Alignment",
    "abstract": "Comments: Accepted in International Conference on Pattern Recognition (ICPR) 2022",
    "descriptor": "\nComments: Accepted in International Conference on Pattern Recognition (ICPR) 2022\n",
    "authors": [
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15835"
  },
  {
    "id": "arXiv:2204.00611",
    "title": "Learning the conditional law: signatures and conditional GANs in  filtering and prediction of diffusion processes",
    "abstract": "Comments: Accepted CDC-2022",
    "descriptor": "\nComments: Accepted CDC-2022\n",
    "authors": [
      "Fabian Germ",
      "Marc Sabate-Vidales"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.00611"
  },
  {
    "id": "arXiv:2204.00772",
    "title": "Improved Approximation Algorithm for Graph Burning on Trees",
    "abstract": "Comments: We found an issue in the proof. We will submit after rectifying the proof",
    "descriptor": "\nComments: We found an issue in the proof. We will submit after rectifying the proof\n",
    "authors": [
      "Rahul Kumar Gautam",
      "Anjeneya Swami Kare",
      "Durga Bhavani S"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.00772"
  },
  {
    "id": "arXiv:2204.01119",
    "title": "Fitting an immersed submanifold to data via Sussmann's orbit theorem",
    "abstract": "Comments: 8 pages; extended version of the paper to appear in Proc. 2022 IEEE Conference on Decision and Control",
    "descriptor": "\nComments: 8 pages; extended version of the paper to appear in Proc. 2022 IEEE Conference on Decision and Control\n",
    "authors": [
      "Joshua Hanson",
      "Maxim Raginsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.01119"
  },
  {
    "id": "arXiv:2204.02075",
    "title": "Complex-Valued Autoencoders for Object Discovery",
    "abstract": "Complex-Valued Autoencoders for Object Discovery",
    "descriptor": "",
    "authors": [
      "Sindy L\u00f6we",
      "Phillip Lippe",
      "Maja Rudolph",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02075"
  },
  {
    "id": "arXiv:2204.02844",
    "title": "Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware  Adversarial Training",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yuanhao Cai",
      "Xiaowan Hu",
      "Haoqian Wang",
      "Yulun Zhang",
      "Hanspeter Pfister",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02844"
  },
  {
    "id": "arXiv:2204.03276",
    "title": "PALBERT: Teaching ALBERT to Ponder",
    "abstract": "PALBERT: Teaching ALBERT to Ponder",
    "descriptor": "",
    "authors": [
      "Nikita Balagansky",
      "Daniil Gavrilov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03276"
  },
  {
    "id": "arXiv:2204.06207",
    "title": "Safe Stochastic Model Predictive Control",
    "abstract": "Comments: This work has been accepted to the IEEE 2022 Conference on Decision and Control",
    "descriptor": "\nComments: This work has been accepted to the IEEE 2022 Conference on Decision and Control\n",
    "authors": [
      "Tim Br\u00fcdigam",
      "Robert Jacumet",
      "Dirk Wollherr",
      "Marion Leibold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.06207"
  },
  {
    "id": "arXiv:2204.06471",
    "title": "Hybrid Neural Network Augmented Physics-based Models for Nonlinear  Filtering",
    "abstract": "Hybrid Neural Network Augmented Physics-based Models for Nonlinear  Filtering",
    "descriptor": "",
    "authors": [
      "Tales Imbiriba",
      "Ahmet Demirkaya",
      "Jind\u0159ich Dun\u00edk",
      "Ond\u0159ej Straka",
      "Deniz Erdo\u011fmu\u015f",
      "Pau Closas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.06471"
  },
  {
    "id": "arXiv:2204.07874",
    "title": "Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a  Pedestrian Automatic Emergency Brake System",
    "abstract": "Comments: Under revision",
    "descriptor": "\nComments: Under revision\n",
    "authors": [
      "Markus Borg",
      "Jens Henriksson",
      "Kasper Socha",
      "Olof Lennartsson",
      "Elias Sonnsj\u00f6 L\u00f6negren",
      "Thanh Bui",
      "Piotr Tomaszewski",
      "Sankar Raman Sathyamoorthy",
      "Sebastian Brink",
      "Mahshid Helali Moghadam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07874"
  },
  {
    "id": "arXiv:2204.10766",
    "title": "From Books to Knowledge Graphs",
    "abstract": "From Books to Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Natallia Kokash",
      "Matteo Romanello",
      "Ernest Suyver",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.10766"
  },
  {
    "id": "arXiv:2204.11776",
    "title": "Blind Equalization and Channel Estimation in Coherent Optical  Communications Using Variational Autoencoders",
    "abstract": "Comments: Published (Open Access) in IEEE Journal on Selected Areas in Communications, Sep 2022",
    "descriptor": "\nComments: Published (Open Access) in IEEE Journal on Selected Areas in Communications, Sep 2022\n",
    "authors": [
      "Vincent Lauinger",
      "Fred Buchali",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11776"
  },
  {
    "id": "arXiv:2204.12079",
    "title": "Exact Wirelength of Embedding 3-Ary n-Cubes into certain Cylinders and  Trees",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Rajeshwari S",
      "M Rajesh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.12079"
  },
  {
    "id": "arXiv:2205.00793",
    "title": "Ultra-Reliable Low-Latency Millimeter-Wave Communications with Sliding  Window Network Coding",
    "abstract": "Ultra-Reliable Low-Latency Millimeter-Wave Communications with Sliding  Window Network Coding",
    "descriptor": "",
    "authors": [
      "Eurico Dias",
      "Duarte Raposo",
      "Homa Esfahanizadeh",
      "Alejandro Cohen",
      "T\u00e2nia Ferreira",
      "Miguel Lu\u00eds",
      "Susana Sargento",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.00793"
  },
  {
    "id": "arXiv:2205.00885",
    "title": "Hierarchical Decompositions of Stochastic Pursuit-Evasion Games",
    "abstract": "Hierarchical Decompositions of Stochastic Pursuit-Evasion Games",
    "descriptor": "",
    "authors": [
      "Yue Guan",
      "Mohammad Afshari",
      "Qifan Zhang",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.00885"
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "Comments: 31 pages, 6 figures, fixed incorrect citation",
    "descriptor": "\nComments: 31 pages, 6 figures, fixed incorrect citation\n",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01663"
  },
  {
    "id": "arXiv:2205.03400",
    "title": "Defying Gravity: The Complexity of the Hanano Puzzle",
    "abstract": "Defying Gravity: The Complexity of the Hanano Puzzle",
    "descriptor": "",
    "authors": [
      "Michael C. Chavrimootoo"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.03400"
  },
  {
    "id": "arXiv:2205.05800",
    "title": "Stochastic first-order methods for average-reward Markov decision  processes",
    "abstract": "Stochastic first-order methods for average-reward Markov decision  processes",
    "descriptor": "",
    "authors": [
      "Tianjiao Li",
      "Feiyang Wu",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05800"
  },
  {
    "id": "arXiv:2205.05826",
    "title": "Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling",
    "abstract": "Comments: MICRO2022 version",
    "descriptor": "\nComments: MICRO2022 version\n",
    "authors": [
      "Yannan Nellie Wu",
      "Po-An Tsai",
      "Angshuman Parashar",
      "Vivienne Sze",
      "Joel S. Emer"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.05826"
  },
  {
    "id": "arXiv:2205.05963",
    "title": "Economical Precise Manipulation and Auto Eye-Hand Coordination with  Binocular Visual Reinforcement Learning",
    "abstract": "Comments: 12 pages, 16 figures",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Yiwen Chen",
      "Sheng Guo",
      "Zedong Zhang",
      "Lei Zhou",
      "Xian Yao Ng",
      "Marcelo H. Ang Jr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05963"
  },
  {
    "id": "arXiv:2205.09872",
    "title": "Content-Context Factorized Representations for Automated Speech  Recognition",
    "abstract": "Comments: Presented at Interspeech 2022 (On-Site Oral Presentation)",
    "descriptor": "\nComments: Presented at Interspeech 2022 (On-Site Oral Presentation)\n",
    "authors": [
      "David M. Chan",
      "Shalini Ghosh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.09872"
  },
  {
    "id": "arXiv:2205.10255",
    "title": "Tower: Data Structures in Quantum Superposition",
    "abstract": "Comments: 30 pages, 22 figures. [v2] add discussion of concurrent work in Sec 1.4 and add acknowledgements section. [v3] camera-ready version, incorporates revisions following conference review",
    "descriptor": "\nComments: 30 pages, 22 figures. [v2] add discussion of concurrent work in Sec 1.4 and add acknowledgements section. [v3] camera-ready version, incorporates revisions following conference review\n",
    "authors": [
      "Charles Yuan",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.10255"
  },
  {
    "id": "arXiv:2205.11495",
    "title": "Flexible Diffusion Modeling of Long Videos",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "William Harvey",
      "Saeid Naderiparizi",
      "Vaden Masrani",
      "Christian Weilbach",
      "Frank Wood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11495"
  },
  {
    "id": "arXiv:2205.12365",
    "title": "Low-rank Optimal Transport: Approximation, Statistics and Debiasing",
    "abstract": "Low-rank Optimal Transport: Approximation, Statistics and Debiasing",
    "descriptor": "",
    "authors": [
      "Meyer Scetbon",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12365"
  },
  {
    "id": "arXiv:2205.12381",
    "title": "First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual  Information Maximization",
    "abstract": "Comments: Accepted to Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: Accepted to Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Siddharth Reddy",
      "Sergey Levine",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.12381"
  },
  {
    "id": "arXiv:2205.14612",
    "title": "Do Residual Neural Networks discretize Neural Ordinary Differential  Equations?",
    "abstract": "Comments: Accepted at NeurIPS 2022 24 pages",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 24 pages\n",
    "authors": [
      "Michael E. Sander",
      "Pierre Ablin",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14612"
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15117"
  },
  {
    "id": "arXiv:2205.15544",
    "title": "Refining Low-Resource Unsupervised Translation by Language  Disentanglement of Multilingual Model",
    "abstract": "Comments: Published in NeurIPS 2022",
    "descriptor": "\nComments: Published in NeurIPS 2022\n",
    "authors": [
      "Xuan-Phi Nguyen",
      "Shafiq Joty",
      "Wu Kui",
      "Ai Ti Aw"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15544"
  },
  {
    "id": "arXiv:2205.15827",
    "title": "Robust Anytime Learning of Markov Decision Processes",
    "abstract": "Robust Anytime Learning of Markov Decision Processes",
    "descriptor": "",
    "authors": [
      "Marnix Suilen",
      "Thiago D. Sim\u00e3o",
      "David Parker",
      "Nils Jansen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15827"
  },
  {
    "id": "arXiv:2206.01382",
    "title": "Falconn++: A Locality-sensitive Filtering Approach for Approximate  Nearest Neighbor Search",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Ninh Pham",
      "Tao Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01382"
  },
  {
    "id": "arXiv:2206.01653",
    "title": "Metrics reloaded: Pitfalls and recommendations for image analysis  validation",
    "abstract": "Comments: Shared first authors: Lena Maier-Hein, Annika Reinke",
    "descriptor": "\nComments: Shared first authors: Lena Maier-Hein, Annika Reinke\n",
    "authors": [
      "Lena Maier-Hein",
      "Annika Reinke",
      "Patrick Godau",
      "Minu D. Tizabi",
      "Evangelia Christodoulou",
      "Ben Glocker",
      "Fabian Isensee",
      "Jens Kleesiek",
      "Michal Kozubek",
      "Mauricio Reyes",
      "Michael A. Riegler",
      "Manuel Wiesenfarth",
      "Michael Baumgartner",
      "Matthias Eisenmann",
      "Doreen Heckmann-N\u00f6tzel",
      "A. Emre Kavur",
      "Tim R\u00e4dsch",
      "Laura Acion",
      "Michela Antonelli",
      "Tal Arbel",
      "Spyridon Bakas",
      "Peter Bankhead",
      "Arriel Benis",
      "M. Jorge Cardoso",
      "Veronika Cheplygina",
      "Beth Cimini",
      "Gary S. Collins",
      "Keyvan Farahani",
      "Luciana Ferrer",
      "Adrian Galdran",
      "Bram van Ginneken",
      "Robert Haase",
      "Daniel A. Hashimoto",
      "Michael M. Hoffman",
      "Merel Huisman",
      "Pierre Jannin",
      "Charles E. Kahn",
      "Dagmar Kainmueller",
      "Bernhard Kainz",
      "Alexandros Karargyris",
      "Alan Karthikesalingam",
      "Hannes Kenngott",
      "Florian Kofler",
      "Annette Kopp-Schneider",
      "Anna Kreshuk",
      "Tahsin Kurc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01653"
  },
  {
    "id": "arXiv:2206.01843",
    "title": "Visual Clues: Bridging Vision and Language Foundations for Image  Paragraph Captioning",
    "abstract": "Visual Clues: Bridging Vision and Language Foundations for Image  Paragraph Captioning",
    "descriptor": "",
    "authors": [
      "Yujia Xie",
      "Luowei Zhou",
      "Xiyang Dai",
      "Lu Yuan",
      "Nguyen Bach",
      "Ce Liu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01843"
  },
  {
    "id": "arXiv:2206.02008",
    "title": "Hidden Degrees of Freedom in Implicit Vortex Filaments",
    "abstract": "Comments: The supplementary video is available at this https URL",
    "descriptor": "\nComments: The supplementary video is available at this https URL\n",
    "authors": [
      "Sadashige Ishida",
      "Chris Wojtan",
      "Albert Chern"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.02008"
  },
  {
    "id": "arXiv:2206.05238",
    "title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus  Creation, Annotation Reliability, and Prediction",
    "abstract": "Comments: Computational Linguistics Journal in Issue No 1, March 2023; 71 pages, 13 figures, 19 tables",
    "descriptor": "\nComments: Computational Linguistics Journal in Issue No 1, March 2023; 71 pages, 13 figures, 19 tables\n",
    "authors": [
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05238"
  },
  {
    "id": "arXiv:2206.06295",
    "title": "Markov Chain Score Ascent: A Unifying Framework of Variational Inference  with Markovian Gradients",
    "abstract": "Comments: To be presented at NeurIPS 2022",
    "descriptor": "\nComments: To be presented at NeurIPS 2022\n",
    "authors": [
      "Kyurae Kim",
      "Jisu Oh",
      "Jacob R. Gardner",
      "Adji Bousso Dieng",
      "Hongseok Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06295"
  },
  {
    "id": "arXiv:2206.06658",
    "title": "A novel MDPSO-SVR hybrid model for feature selection in electricity  consumption forecasting",
    "abstract": "A novel MDPSO-SVR hybrid model for feature selection in electricity  consumption forecasting",
    "descriptor": "",
    "authors": [
      "Yukun Bao",
      "Liang Shen",
      "Xiaoyuan Zhang",
      "Yanmei Huang",
      "Changrui Deng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06658"
  },
  {
    "id": "arXiv:2206.09868",
    "title": "Understanding Robust Learning through the Lens of Representation  Similarities",
    "abstract": "Comments: 35 pages, 29 figures; Accepted to Neurips 2022",
    "descriptor": "\nComments: 35 pages, 29 figures; Accepted to Neurips 2022\n",
    "authors": [
      "Christian Cianfarani",
      "Arjun Nitin Bhagoji",
      "Vikash Sehwag",
      "Ben Y. Zhao",
      "Prateek Mittal",
      "Haitao Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09868"
  },
  {
    "id": "arXiv:2206.10843",
    "title": "Learning Debiased Classifier with Biased Committee",
    "abstract": "Comments: ICML workshop on Spurious correlations, Invariance, and Stability (SCIS), Baltimore MD, 2022 Conference on Neural Information Processing Systems (NeurIPS), New Orleans, 2022",
    "descriptor": "\nComments: ICML workshop on Spurious correlations, Invariance, and Stability (SCIS), Baltimore MD, 2022 Conference on Neural Information Processing Systems (NeurIPS), New Orleans, 2022\n",
    "authors": [
      "Nayeong Kim",
      "Sehyun Hwang",
      "Sungsoo Ahn",
      "Jaesik Park",
      "Suha Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10843"
  },
  {
    "id": "arXiv:2206.15407",
    "title": "Shifts 2.0: Extending The Dataset of Real Distributional Shifts",
    "abstract": "Shifts 2.0: Extending The Dataset of Real Distributional Shifts",
    "descriptor": "",
    "authors": [
      "Andrey Malinin",
      "Andreas Athanasopoulos",
      "Muhamed Barakovic",
      "Meritxell Bach Cuadra",
      "Mark J. F. Gales",
      "Cristina Granziera",
      "Mara Graziani",
      "Nikolay Kartashev",
      "Konstantinos Kyriakopoulos",
      "Po-Jui Lu",
      "Nataliia Molchanova",
      "Antonis Nikitakis",
      "Vatsal Raina",
      "Francesco La Rosa",
      "Eli Sivena",
      "Vasileios Tsarsitalidis",
      "Efi Tsompopoulou",
      "Elena Volf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15407"
  },
  {
    "id": "arXiv:2207.00669",
    "title": "Differentiable Collision Detection for a Set of Convex Primitives",
    "abstract": "Differentiable Collision Detection for a Set of Convex Primitives",
    "descriptor": "",
    "authors": [
      "Kevin Tracy",
      "Taylor A. Howell",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.00669"
  },
  {
    "id": "arXiv:2207.01062",
    "title": "Distributed Online System Identification for LTI Systems Using Reverse  Experience Replay",
    "abstract": "Distributed Online System Identification for LTI Systems Using Reverse  Experience Replay",
    "descriptor": "",
    "authors": [
      "Ting-Jui Chang",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01062"
  },
  {
    "id": "arXiv:2207.03677",
    "title": "SuperTickets: Drawing Task-Agnostic Lottery Tickets from Supernets via  Jointly Architecture Searching and Parameter Pruning",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Haoran You",
      "Baopu Li",
      "Zhanyi Sun",
      "Xu Ouyang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03677"
  },
  {
    "id": "arXiv:2207.04726",
    "title": "On the Convergence of the Backward Reachable Sets of Robust Controlled  Invariant Sets For Discrete-time Linear Systems",
    "abstract": "Comments: 9 pages, accepted by CDC 2022",
    "descriptor": "\nComments: 9 pages, accepted by CDC 2022\n",
    "authors": [
      "Zexiang Liu",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04726"
  },
  {
    "id": "arXiv:2207.04814",
    "title": "High-Order Coupled Fully-Connected Tensor Network Decomposition for  Hyperspectral Image Super-Resolution",
    "abstract": "High-Order Coupled Fully-Connected Tensor Network Decomposition for  Hyperspectral Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Diyi Jin",
      "Jianjun Liu",
      "Jinlong Yang",
      "Zebin Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04814"
  },
  {
    "id": "arXiv:2207.05188",
    "title": "Knowledge Graph Induction enabling Recommending and Trend Analysis: A  Corporate Research Community Use Case",
    "abstract": "Comments: Accepted at ISWC 2022",
    "descriptor": "\nComments: Accepted at ISWC 2022\n",
    "authors": [
      "Nandana Mihindukulasooriya",
      "Mike Sava",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Irene Yachbes",
      "Aditya Gidh",
      "Jillian Duckwitz",
      "Kovit Nisar",
      "Michael Santos",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.05188"
  },
  {
    "id": "arXiv:2207.06529",
    "title": "Estimating Classification Confidence Using Kernel Densities",
    "abstract": "Estimating Classification Confidence Using Kernel Densities",
    "descriptor": "",
    "authors": [
      "Peter Salamon",
      "David Salamon",
      "V. Adrian Cantu",
      "Michelle An",
      "Tyler Perry",
      "Robert A. Edwards",
      "Anca M. Segall"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06529"
  },
  {
    "id": "arXiv:2207.07499",
    "title": "Formalising Szemer\u00e9di's Regularity Lemma and Roth's Theorem on  Arithmetic Progressions in Isabelle/HOL",
    "abstract": "Formalising Szemer\u00e9di's Regularity Lemma and Roth's Theorem on  Arithmetic Progressions in Isabelle/HOL",
    "descriptor": "",
    "authors": [
      "Chelsea Edmonds",
      "Angeliki Koutsoukou-Argyraki",
      "Lawrence C. Paulson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.07499"
  },
  {
    "id": "arXiv:2207.07543",
    "title": "Pick your Neighbor: Local Gauss-Southwell Rule for Fast Asynchronous  Decentralized Optimization",
    "abstract": "Comments: Revised writing, added references",
    "descriptor": "\nComments: Revised writing, added references\n",
    "authors": [
      "Marina Costantini",
      "Nikolaos Liakopoulos",
      "Panayotis Mertikopoulos",
      "Thrasyvoulos Spyropoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07543"
  },
  {
    "id": "arXiv:2207.08739",
    "title": "Rethinking Data Augmentation for Robust Visual Question Answering",
    "abstract": "Comments: Accepted to ECCV 2022; Codes: this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022; Codes: this https URL\n",
    "authors": [
      "Long Chen",
      "Yuhang Zheng",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.08739"
  },
  {
    "id": "arXiv:2207.09455",
    "title": "To update or not to update? Neurons at equilibrium in deep models",
    "abstract": "To update or not to update? Neurons at equilibrium in deep models",
    "descriptor": "",
    "authors": [
      "Andrea Bragagnolo",
      "Enzo Tartaglione",
      "Marco Grangetto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09455"
  },
  {
    "id": "arXiv:2207.12214",
    "title": "Laplacian-based Cluster-Contractive t-SNE for High Dimensional Data  Visualization",
    "abstract": "Laplacian-based Cluster-Contractive t-SNE for High Dimensional Data  Visualization",
    "descriptor": "",
    "authors": [
      "Yan Sun",
      "Yi Han",
      "Jicong Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.12214"
  },
  {
    "id": "arXiv:2207.12232",
    "title": "A Resilient Navigation and Path Planning System for High-speed  Autonomous Race Car",
    "abstract": "A Resilient Navigation and Path Planning System for High-speed  Autonomous Race Car",
    "descriptor": "",
    "authors": [
      "Daegyu Lee",
      "Chanyoung Jung",
      "Andrea Finazzi",
      "Hyunki Seong",
      "D.Hyunchul Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.12232"
  },
  {
    "id": "arXiv:2207.14741",
    "title": "End-to-end View Synthesis via NeRF Attention",
    "abstract": "Comments: Fixed reference formatting issues",
    "descriptor": "\nComments: Fixed reference formatting issues\n",
    "authors": [
      "Zelin Zhao",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.14741"
  },
  {
    "id": "arXiv:2208.00394",
    "title": "STrajNet: Multi-modal Hierarchical Transformer for Occupancy Flow Field  Prediction in Autonomous Driving",
    "abstract": "STrajNet: Multi-modal Hierarchical Transformer for Occupancy Flow Field  Prediction in Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Haochen Liu",
      "Zhiyu Huang",
      "Chen Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.00394"
  },
  {
    "id": "arXiv:2208.00638",
    "title": "Composable Text Controls in Latent Space with ODEs",
    "abstract": "Comments: 27 Pages, Code: this https URL",
    "descriptor": "\nComments: 27 Pages, Code: this https URL\n",
    "authors": [
      "Guangyi Liu",
      "Zeyu Feng",
      "Yuan Gao",
      "Zichao Yang",
      "Xiaodan Liang",
      "Junwei Bao",
      "Xiaodong He",
      "Shuguang Cui",
      "Zhen Li",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.00638"
  },
  {
    "id": "arXiv:2208.02870",
    "title": "Improved post-hoc probability calibration for out-of-domain MRI  segmentation",
    "abstract": "Comments: Accepted for UNSURE workshop at MICCAI 2022",
    "descriptor": "\nComments: Accepted for UNSURE workshop at MICCAI 2022\n",
    "authors": [
      "Cheng Ouyang",
      "Shuo Wang",
      "Chen Chen",
      "Zeju Li",
      "Wenjia Bai",
      "Bernhard Kainz",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.02870"
  },
  {
    "id": "arXiv:2208.03873",
    "title": "CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal  Relationships between Chest X-Rays",
    "abstract": "Comments: Accepted at MICCAI 2022",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Gaurang Karwande",
      "Amarachi Mbakawe",
      "Joy T. Wu",
      "Leo A. Celi",
      "Mehdi Moradi",
      "Ismini Lourentzou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03873"
  },
  {
    "id": "arXiv:2208.04534",
    "title": "An Embarrassingly Easy but Strong Baseline for Nested Named Entity  Recognition",
    "abstract": "Comments: Updates for analysis part. The performance gain is from recalling more nested entities",
    "descriptor": "\nComments: Updates for analysis part. The performance gain is from recalling more nested entities\n",
    "authors": [
      "Hang Yan",
      "Yu Sun",
      "Xiaonan Li",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.04534"
  },
  {
    "id": "arXiv:2208.05444",
    "title": "Active Learning Exploration of Transition Metal Complexes to Discover  Method-Insensitive and Synthetically Accessible Chromophores",
    "abstract": "Active Learning Exploration of Transition Metal Complexes to Discover  Method-Insensitive and Synthetically Accessible Chromophores",
    "descriptor": "",
    "authors": [
      "Chenru Duan",
      "Aditya Nandy",
      "Gianmarco Terrones",
      "David W. Kastner",
      "Heather J. Kulik"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2208.05444"
  },
  {
    "id": "arXiv:2208.07313",
    "title": "Task Oriented Video Coding: A Survey",
    "abstract": "Task Oriented Video Coding: A Survey",
    "descriptor": "",
    "authors": [
      "Daniel Wood"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07313"
  },
  {
    "id": "arXiv:2208.08307",
    "title": "SC-Explorer: Incremental 3D Scene Completion for Safe and Efficient  Exploration Mapping and Planning",
    "abstract": "Comments: 18 pages, 14 figures. Code will be released at this https URL",
    "descriptor": "\nComments: 18 pages, 14 figures. Code will be released at this https URL\n",
    "authors": [
      "Lukas Schmid",
      "Mansoor Nasir Cheema",
      "Victor Reijgwart",
      "Roland Siegwart",
      "Federico Tombari",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08307"
  },
  {
    "id": "arXiv:2208.08408",
    "title": "Summarizing Patients Problems from Hospital Progress Notes Using  Pre-trained Sequence-to-Sequence Models",
    "abstract": "Comments: Paper is accepted to COLING 2022",
    "descriptor": "\nComments: Paper is accepted to COLING 2022\n",
    "authors": [
      "Yanjun Gao",
      "Dmitriy Dligach",
      "Timothy Miller",
      "Dongfang Xu",
      "Matthew M. Churpek",
      "Majid Afshar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08408"
  },
  {
    "id": "arXiv:2208.09298",
    "title": "Applying Back Propagation Algorithm and Analytic Hierarchy Process to  Environment Assessment",
    "abstract": "Applying Back Propagation Algorithm and Analytic Hierarchy Process to  Environment Assessment",
    "descriptor": "",
    "authors": [
      "Chunyu Sui",
      "Xinrui Li",
      "Yinghang Song",
      "Chen Wu",
      "Ziyang Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09298"
  },
  {
    "id": "arXiv:2208.09828",
    "title": "I Know What You Do Not Know: Knowledge Graph Embedding via  Co-distillation Learning",
    "abstract": "Comments: Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)",
    "descriptor": "\nComments: Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)\n",
    "authors": [
      "Yang Liu",
      "Zequn Sun",
      "Guangyao Li",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09828"
  },
  {
    "id": "arXiv:2208.10165",
    "title": "Exploring Task-oriented Communication in Multi-agent System: A Deep  Reinforcement Learning Approach",
    "abstract": "Comments: This is just a first draft",
    "descriptor": "\nComments: This is just a first draft\n",
    "authors": [
      "Guojun He"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.10165"
  },
  {
    "id": "arXiv:2208.10226",
    "title": "From Easy to Hard: A Dual Curriculum Learning Framework for  Context-Aware Document Ranking",
    "abstract": "Comments: CIKM 2022 Camera Ready",
    "descriptor": "\nComments: CIKM 2022 Camera Ready\n",
    "authors": [
      "Yutao Zhu",
      "Jian-Yun Nie",
      "Yixuan Su",
      "Haonan Chen",
      "Xinyu Zhang",
      "Zhicheng Dou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10226"
  },
  {
    "id": "arXiv:2208.10844",
    "title": "CLOWER: A Pre-trained Language Model with Contrastive Learning over Word  and Character Representations",
    "abstract": "Comments: Accepted in COLING 2022",
    "descriptor": "\nComments: Accepted in COLING 2022\n",
    "authors": [
      "Borun Chen",
      "Hongyin Tang",
      "Jiahao Bu",
      "Kai Zhang",
      "Jingang Wang",
      "Qifan Wang",
      "Hai-Tao Zheng",
      "Wei Wu",
      "Liqian Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10844"
  },
  {
    "id": "arXiv:2208.10848",
    "title": "How to train your solver part II: Verification of boundary conditions  for smoothed particle hydrodynamics",
    "abstract": "How to train your solver part II: Verification of boundary conditions  for smoothed particle hydrodynamics",
    "descriptor": "",
    "authors": [
      "Pawan Negi",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10848"
  },
  {
    "id": "arXiv:2208.11508",
    "title": "PSSAT: A Perturbed Semantic Structure Awareness Transferring Method for  Perturbation-Robust Slot Filling",
    "abstract": "Comments: Accepted by COLING 2022",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Guanting Dong",
      "Daichi Guo",
      "Liwen Wang",
      "Xuefeng Li",
      "Zechen Wang",
      "Chen Zeng",
      "Keqing He",
      "Jinzheng Zhao",
      "Hao Lei",
      "Xinyue Cui",
      "Yi Huang",
      "Junlan Feng",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.11508"
  },
  {
    "id": "arXiv:2208.11646",
    "title": "Of Human Criteria and Automatic Metrics: A Benchmark of the Evaluation  of Story Generation",
    "abstract": "Comments: 43 pages, 38 figures. Proceedings of the 29th International Conference on Computational Linguistics (COLING 2022)",
    "descriptor": "\nComments: 43 pages, 38 figures. Proceedings of the 29th International Conference on Computational Linguistics (COLING 2022)\n",
    "authors": [
      "Cyril Chhun",
      "Pierre Colombo",
      "Chlo\u00e9 Clavel",
      "Fabian M. Suchanek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.11646"
  },
  {
    "id": "arXiv:2208.11908",
    "title": "Adaptive Perception Transformer for Temporal Action Localization",
    "abstract": "Adaptive Perception Transformer for Temporal Action Localization",
    "descriptor": "",
    "authors": [
      "Yizheng Ouyang",
      "Tianjin Zhang",
      "Weibo Gu",
      "Hongfa Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11908"
  },
  {
    "id": "arXiv:2208.13295",
    "title": "Adapting the LodView RDF Browser for Navigation over the Multilingual  Linguistic Linked Open Data Cloud",
    "abstract": "Adapting the LodView RDF Browser for Navigation over the Multilingual  Linguistic Linked Open Data Cloud",
    "descriptor": "",
    "authors": [
      "Alexander Kirillovich",
      "Konstantin Nikolaev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.13295"
  },
  {
    "id": "arXiv:2209.00148",
    "title": "A Note on the Games-Chan Algorithm",
    "abstract": "Comments: Exposition and main theorem improved, typos corrected. Application to finding multiplicity of x-1 in any $q$-ary polynomial added",
    "descriptor": "\nComments: Exposition and main theorem improved, typos corrected. Application to finding multiplicity of x-1 in any $q$-ary polynomial added\n",
    "authors": [
      "Graham H. Norton"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2209.00148"
  },
  {
    "id": "arXiv:2209.02836",
    "title": "Studying Bias in GANs through the Lens of Race",
    "abstract": "Comments: ECCV 2022. Project Page: this https URL",
    "descriptor": "\nComments: ECCV 2022. Project Page: this https URL\n",
    "authors": [
      "Vongani H. Maluleke",
      "Neerja Thakkar",
      "Tim Brooks",
      "Ethan Weber",
      "Trevor Darrell",
      "Alexei A. Efros",
      "Angjoo Kanazawa",
      "Devin Guillory"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.02836"
  },
  {
    "id": "arXiv:2209.02854",
    "title": "Video Restoration with a Deep Plug-and-Play Prior",
    "abstract": "Comments: 10 pages + 4 pages supplementary; code at github.com/amonod/pnp-video",
    "descriptor": "\nComments: 10 pages + 4 pages supplementary; code at github.com/amonod/pnp-video\n",
    "authors": [
      "Antoine Monod",
      "Julie Delon",
      "Matias Tassano",
      "Andr\u00e9s Almansa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.02854"
  },
  {
    "id": "arXiv:2209.03316",
    "title": "On the Complementarity between Pre-Training and Random-Initialization  for Resource-Rich Machine Translation",
    "abstract": "Comments: COLING 2022",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Changtong Zan",
      "Liang Ding",
      "Li Shen",
      "Yu Cao",
      "Weifeng Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.03316"
  },
  {
    "id": "arXiv:2209.04067",
    "title": "RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk",
    "abstract": "RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk",
    "descriptor": "",
    "authors": [
      "Jia Lin Hau",
      "Marek Petrik",
      "Mohammad Ghavamzadeh",
      "Reazul Russel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04067"
  },
  {
    "id": "arXiv:2209.04963",
    "title": "Responsible AI Pattern Catalogue: A Multivocal Literature Review",
    "abstract": "Responsible AI Pattern Catalogue: A Multivocal Literature Review",
    "descriptor": "",
    "authors": [
      "Qinghua Lu",
      "Liming Zhu",
      "Xiwei Xu",
      "Jon Whittle",
      "Didar Zowghi",
      "Aurelie Jacquet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.04963"
  },
  {
    "id": "arXiv:2209.05408",
    "title": "Deterministic Sequencing of Exploration and Exploitation for  Reinforcement Learning",
    "abstract": "Deterministic Sequencing of Exploration and Exploitation for  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Piyush Gupta",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.05408"
  },
  {
    "id": "arXiv:2209.05479",
    "title": "Leveraging Language Foundation Models for Human Mobility Forecasting",
    "abstract": "Comments: Accepted at ACM SIGSPATIAL 2022",
    "descriptor": "\nComments: Accepted at ACM SIGSPATIAL 2022\n",
    "authors": [
      "Hao Xue",
      "Bhanu Prakash Voutharoja",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.05479"
  },
  {
    "id": "arXiv:2209.05732",
    "title": "R\u00e9nyi Divergence Deep Mutual Learning",
    "abstract": "R\u00e9nyi Divergence Deep Mutual Learning",
    "descriptor": "",
    "authors": [
      "Weipeng Huang",
      "Junjie Tao",
      "Changbo Deng",
      "Ming Fan",
      "Wenqiang Wan",
      "Qi Xiong",
      "Guangyuan Piao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.05732"
  },
  {
    "id": "arXiv:2209.06111",
    "title": "D-Lite: Navigation-Oriented Compression of 3D Scene Graphs under  Communication Constraints",
    "abstract": "Comments: 11 pages, 4 figures; submitted to ICRA 2023; fixed descriptions and appendix",
    "descriptor": "\nComments: 11 pages, 4 figures; submitted to ICRA 2023; fixed descriptions and appendix\n",
    "authors": [
      "Yun Chang",
      "Luca Ballotta",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.06111"
  },
  {
    "id": "arXiv:2209.06251",
    "title": "Data-Driven Gain Scheduling Control of Linear Parameter-Varying Systems  using Quadratic Matrix Inequalities",
    "abstract": "Comments: 13 pages, 1 figure",
    "descriptor": "\nComments: 13 pages, 1 figure\n",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06251"
  },
  {
    "id": "arXiv:2209.06351",
    "title": "DevNet: Self-supervised Monocular Depth Learning via Density Volume  Construction",
    "abstract": "Comments: Accepted by European Conference on Computer Vision 2022 (ECCV2022)",
    "descriptor": "\nComments: Accepted by European Conference on Computer Vision 2022 (ECCV2022)\n",
    "authors": [
      "Kaichen Zhou",
      "Lanqing Hong",
      "Changhao Chen",
      "Hang Xu",
      "Chaoqiang Ye",
      "Qingyong Hu",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06351"
  },
  {
    "id": "arXiv:2209.06434",
    "title": "ConvNext Based Neural Network for Anti-Spoofing",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qiaowei Ma",
      "Jinghui Zhong",
      "Yitao Yang",
      "Weiheng Liu",
      "Ying Gao",
      "Wing W.Y. Ng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.06434"
  },
  {
    "id": "arXiv:2209.06505",
    "title": "BERT-based Ensemble Approaches for Hate Speech Detection",
    "abstract": "BERT-based Ensemble Approaches for Hate Speech Detection",
    "descriptor": "",
    "authors": [
      "Khouloud Mnassri",
      "Praboda Rajapaksha",
      "Reza Farahbakhsh",
      "Noel Crespi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06505"
  },
  {
    "id": "arXiv:2209.06515",
    "title": "Learning to Evaluate Performance of Multi-modal Semantic Localization",
    "abstract": "Comments: 19 pages, 11 figures",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Zhiqiang Yuan",
      "Wenkai Zhang",
      "Chongyang Li",
      "Zhaoying Pan",
      "Yongqiang Mao",
      "Jialiang Chen",
      "Shouke Li",
      "Hongqi Wang",
      "Xian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.06515"
  },
  {
    "id": "arXiv:2209.06517",
    "title": "How to Find Strong Summary Coherence Measures? A Toolbox and a  Comparative Study for Summary Coherence Measure Evaluation",
    "abstract": "Comments: Accepted at COLING2022. Edited to correct differences to COLING version caused by arxiv package versions",
    "descriptor": "\nComments: Accepted at COLING2022. Edited to correct differences to COLING version caused by arxiv package versions\n",
    "authors": [
      "Julius Steen",
      "Katja Markert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06517"
  },
  {
    "id": "arXiv:2209.06560",
    "title": "Graph Contrastive Learning with Personalized Augmentation",
    "abstract": "Graph Contrastive Learning with Personalized Augmentation",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Qiaoyu Tan",
      "Xiao Huang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06560"
  },
  {
    "id": "arXiv:2209.06626",
    "title": "NAAP-440 Dataset and Baseline for Neural Architecture Accuracy  Prediction",
    "abstract": "NAAP-440 Dataset and Baseline for Neural Architecture Accuracy  Prediction",
    "descriptor": "",
    "authors": [
      "Tal Hakim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.06626"
  },
  {
    "id": "arXiv:2209.06701",
    "title": "Natural Language Inference Prompts for Zero-shot Emotion Classification  in Text across Corpora",
    "abstract": "Comments: Accepted to COLING 2022",
    "descriptor": "\nComments: Accepted to COLING 2022\n",
    "authors": [
      "Flor Miriam Plaza-del-Arco",
      "Mar\u00eda-Teresa Mart\u00edn-Valdivia",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06701"
  },
  {
    "id": "arXiv:2209.06779",
    "title": "Efficient Planar Pose Estimation via UWB Measurements",
    "abstract": "Comments: We change the organization of the paper, add one author, and correct several typos",
    "descriptor": "\nComments: We change the organization of the paper, add one author, and correct several typos\n",
    "authors": [
      "Haodong Jiang",
      "Wentao Wang",
      "Yuan Shen",
      "Xinghan Li",
      "Xiaoqiang Ren",
      "Biqiang Mu",
      "Junfeng Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06779"
  }
]
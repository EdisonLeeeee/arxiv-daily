[
  {
    "id": "arXiv:2105.13381",
    "title": "Recent advances and clinical applications of deep learning in medical  image analysis",
    "abstract": "Deep learning has become the mainstream technology in computer vision, and it\nhas received extensive research interest in developing new medical image\nprocessing algorithms to support disease detection and diagnosis. As compared\nto conventional machine learning technologies, the major advantage of deep\nlearning is that models can automatically identify and recognize representative\nfeatures through the hierarchal model architecture, while avoiding the\nlaborious development of hand-crafted features. In this paper, we reviewed and\nsummarized more than 200 recently published papers to provide a comprehensive\noverview of applying deep learning methods in various medical image analysis\ntasks. Especially, we emphasize the latest progress and contributions of\nstate-of-the-art unsupervised and semi-supervised deep learning in medical\nimages, which are summarized based on different application scenarios,\nincluding lesion classification, segmentation, detection, and image\nregistration. Additionally, we also discussed the major technical challenges\nand suggested the possible solutions in future research efforts.",
    "descriptor": "",
    "authors": [
      "Xuxin Chen",
      "Ximin Wang",
      "Ke Zhang",
      "Roy Zhang",
      "Kar-Ming Fung",
      "Theresa C. Thai",
      "Kathleen Moore",
      "Robert S. Mannel",
      "Hong Liu",
      "Bin Zheng",
      "Yuchen Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13381"
  },
  {
    "id": "arXiv:2105.13383",
    "title": "An Online Learning Approach to Optimizing Time-Varying Costs of AoI",
    "abstract": "We consider systems that require timely monitoring of sources over a\ncommunication network, where the cost of delayed information is unknown,\ntime-varying and possibly adversarial. For the single source monitoring\nproblem, we design algorithms that achieve sublinear regret compared to the\nbest fixed policy in hindsight. For the multiple source scheduling problem, we\ndesign a new online learning algorithm called\nFollow-the-Perturbed-Whittle-Leader and show that it has low regret compared to\nthe best fixed scheduling policy in hindsight, while remaining computationally\nfeasible. The algorithm and its regret analysis are novel and of independent\ninterest to the study of online restless multi-armed bandit problems. We\nfurther design algorithms that achieve sublinear regret compared to the best\ndynamic policy when the environment is slowly varying. Finally, we apply our\nalgorithms to a mobility tracking problem. We consider non-stationary and\nadversarial mobility models and illustrate the performance benefit of using our\nonline learning algorithms compared to an oblivious scheduling policy.",
    "descriptor": "\nComments: Accepted to ACM Mobihoc '21\n",
    "authors": [
      "Vishrant Tripathi",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13383"
  },
  {
    "id": "arXiv:2105.13385",
    "title": "Online Learning Meets Machine Translation Evaluation: Finding the Best  Systems with the Least Human Effort",
    "abstract": "In Machine Translation, assessing the quality of a large amount of automatic\ntranslations can be challenging. Automatic metrics are not reliable when it\ncomes to high performing systems. In addition, resorting to human evaluators\ncan be expensive, especially when evaluating multiple systems. To overcome the\nlatter challenge, we propose a novel application of online learning that, given\nan ensemble of Machine Translation systems, dynamically converges to the best\nsystems, by taking advantage of the human feedback available. Our experiments\non WMT'19 datasets show that our online approach quickly converges to the top-3\nranked systems for the language pairs considered, despite the lack of human\nfeedback for many translations.",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 Main Conference (long paper)\n",
    "authors": [
      "V\u00e2nia Mendon\u00e7a",
      "Ricardo Rei",
      "Luisa Coheur",
      "Alberto Sardinha",
      "Ana L\u00facia Santos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13385"
  },
  {
    "id": "arXiv:2105.13389",
    "title": "GPS-Based Geolocation of Consumer IP Addresses",
    "abstract": "This paper uses two commercial datasets of IP addresses from smartphones,\ngeolocated through the Global Positioning System (GPS), to characterize the\ngeography of IP address subnets from mobile and broadband ISPs. Datasets that\nge olocate IP addresses based on GPS offer superlative accuracy and precision\nfor IP geolocation and thus provide an unprecedented opportunity to understand\nboth the accuracy of existing geolocation databases as well as other properties\nof IP addresses, such as mobility and churn. We focus our analysis on large\ncities in the United States.\nAfter evaluating the accuracy of existing geolocation databases, we analyze\nthe circumstances under which IP geolocation databases may be more or less\naccurate. We find that geolocation databases are more accurate on fixed-line\nthan mobile networks, that IP addresses on university networks can be more\naccurately located than those from consumer or business networks, and that\noften the paid versions of these databases are not significantly more accurate\nthan the free versions. We then characterize how quickly subnets associated\nwith fixed-line networks change geographic locations, and how long residential\nbroadband ISP subscribers retain individual IP addresses. We find, generally,\nthat most IP address assignments are stable over two months, although stability\ndoes vary across ISPs. Finally, we evaluate the suitability of existing IP\ngeolocation databases for understanding Internet access and performance in\nhuman populations within specific geographies and demographics. Although the\nmedian accuracy of IP geolocation is better than 3 km in some contexts, we\nconclude that relying on IP geolocation databases to understand Internet access\nin densely populated regions such as cities is premature.",
    "descriptor": "",
    "authors": [
      "James Saxon",
      "Nick Feamster"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13389"
  },
  {
    "id": "arXiv:2105.13392",
    "title": "Cross-Referencing Self-Training Network for Sound Event Detection in  Audio Mixtures",
    "abstract": "Sound event detection is an important facet of audio tagging that aims to\nidentify sounds of interest and define both the sound category and time\nboundaries for each sound event in a continuous recording. With advances in\ndeep neural networks, there has been tremendous improvement in the performance\nof sound event detection systems, although at the expense of costly data\ncollection and labeling efforts. In fact, current state-of-the-art methods\nemploy supervised training methods that leverage large amounts of data samples\nand corresponding labels in order to facilitate identification of sound\ncategory and time stamps of events. As an alternative, the current study\nproposes a semi-supervised method for generating pseudo-labels from\nunsupervised data using a student-teacher scheme that balances self-training\nand cross-training. Additionally, this paper explores post-processing which\nextracts sound intervals from network prediction, for further improvement in\nsound event detection performance. The proposed approach is evaluated on sound\nevent detection task for the DCASE2020 challenge. The results of these methods\non both \"validation\" and \"public evaluation\" sets of DESED database show\nsignificant improvement compared to the state-of-the art systems in\nsemi-supervised learning.",
    "descriptor": "",
    "authors": [
      "Sangwook Park",
      "David K. Han",
      "Mounya Elhilali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13392"
  },
  {
    "id": "arXiv:2105.13393",
    "title": "Classification and Uncertainty Quantification of Corrupted Data using  Semi-Supervised Autoencoders",
    "abstract": "Parametric and non-parametric classifiers often have to deal with real-world\ndata, where corruptions like noise, occlusions, and blur are unavoidable -\nposing significant challenges. We present a probabilistic approach to classify\nstrongly corrupted data and quantify uncertainty, despite the model only having\nbeen trained with uncorrupted data. A semi-supervised autoencoder trained on\nuncorrupted data is the underlying architecture. We use the decoding part as a\ngenerative model for realistic data and extend it by convolutions, masking, and\nadditive Gaussian noise to describe imperfections. This constitutes a\nstatistical inference task in terms of the optimal latent space activations of\nthe underlying uncorrupted datum. We solve this problem approximately with\nMetric Gaussian Variational Inference (MGVI). The supervision of the\nautoencoder's latent space allows us to classify corrupted data directly under\nuncertainty with the statistically inferred latent space activations.\nFurthermore, we demonstrate that the model uncertainty strongly depends on\nwhether the classification is correct or wrong, setting a basis for a\nstatistical \"lie detector\" of the classification. Independent of that, we show\nthat the generative model can optimally restore the uncorrupted datum by\ndecoding the inferred latent space activations.",
    "descriptor": "",
    "authors": [
      "Philipp Joppich",
      "Sebastian Dorn",
      "Oliver De Candido",
      "Wolfgang Utschick",
      "Jakob Knollm\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13393"
  },
  {
    "id": "arXiv:2105.13395",
    "title": "Measuring OpenSHMEM Communication Routines with SKaMPI-OpenSHMEM User's  manual",
    "abstract": "This document presents the OpenSHMEM extension for the Special Karlsruhe MPI\nbenchmark and the measurement algorithms used to measure the routines.",
    "descriptor": "\nComments: This paper is a technical report that comes with our benchmarking software. It implements distributed algorithms for the measurement of distributed operations\n",
    "authors": [
      "Camille Coti",
      "Allen D Malony"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13395"
  },
  {
    "id": "arXiv:2105.13396",
    "title": "Comparing Models for Extracting the Backbone of Bipartite Projections",
    "abstract": "Projections of bipartite or two-mode networks capture co-occurrences, and are\nused in diverse fields (e.g., ecology, economics, bibliometrics, politics) to\nrepresent unipartite networks that would otherwise be difficult or impossible\nto measure directly. A key challenge in analyzing such networks is determining\nwhether an observed number of co-occurrences is significant. Several models now\nexist for doing so and thus for extracting the backbone of bipartite\nprojections, but they have not been directly compared to each other. In this\npaper, we compare five such models -- fixed fill model (FFM) fixed row model\n(FRM), fixed column model (FCM), fixed degree sequence model (FDSM), and\nstochastic degree sequence model (SDSM) -- in terms of accuracy, speed,\nstatistical power, similarity, and community detection. We find that the\ncomputationally-fast SDSM offers a statistically conservative but close\napproximation of the computationally-impractical FDSM under a wide range of\nconditions, and that it correctly recovers a known community structure even\nwhen the signal is weak. Therefore, although each backbone model may have\nparticular applications, we recommend SDSM for extracting the backbone of most\nbipartite projections.",
    "descriptor": "",
    "authors": [
      "Zachary P. Neal",
      "Rachel Domagalski",
      "Bruce Sahan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13396"
  },
  {
    "id": "arXiv:2105.13398",
    "title": "Tactical Reframing of Online Disinformation Campaigns Against The  Istanbul Convention",
    "abstract": "In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights\ntreaty that addresses violence against women, citing issues with the\nconvention's implicit recognition of sexual and gender minorities. In this\nwork, we trace disinformation campaigns related to the Istanbul Convention and\nits associated Turkish law that circulate on divorced men's rights Facebook\ngroups. We find that these groups adjusted the narrative and focus of the\ncampaigns to appeal to a larger audience, which we refer to as \"tactical\nreframing.\" Initially, the men organized in a grass-roots manner to campaign\nagainst the Turkish law that was passed to codify the convention, focusing on\none-sided custody of children and indefinite alimony. Later, they reframed\ntheir campaign and began attacking the Istanbul Convention, highlighting its\nacknowledgment of homosexuality. This case study highlights how disinformation\ncampaigns can be used to weaponize homophobia in order to limit the rights of\nwomen. To the best of our knowledge, this is the first case study that analyzes\na narrative reframing in the context of a disinformation campaign on social\nmedia.",
    "descriptor": "\nComments: Accepted to Data For the Welbeing of Most Vulnerable (DWMV) Workshop colocated with ICWSM 2021\n",
    "authors": [
      "Tu\u011frulcan Elmas",
      "Rebekah Overdorf",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.13398"
  },
  {
    "id": "arXiv:2105.13399",
    "title": "Times Series Forecasting for Urban Building Energy Consumption Based on  Graph Convolutional Network",
    "abstract": "The world is increasingly urbanizing and the building industry accounts for\nmore than 40% of energy consumption in the United States. To improve urban\nsustainability, many cities adopt ambitious energy-saving strategies through\nretrofitting existing buildings and constructing new communities. In this\nsituation, an accurate urban building energy model (UBEM) is the foundation to\nsupport the design of energy-efficient communities. However, current UBEM are\nlimited in their abilities to capture the inter-building interdependency due to\ntheir dynamic and non-linear characteristics. Those models either ignored or\noversimplified these building interdependencies, which can substantially affect\nthe accuracy of urban energy modeling. To fill the research gap, this study\nproposes a novel data-driven UBEM synthesizing the solar-based building\ninterdependency and spatial-temporal graph convolutional network (ST-GCN)\nalgorithm. Especially, we took a university campus located in downtown Atlanta\nas an example to predict the hourly energy consumption. Furthermore, we tested\nthe feasibility of the proposed model by comparing the performance of the\nST-GCN model with other common time-series machine learning models. The results\nindicate that the ST-GCN model overall outperforms all others. In addition, the\nphysical knowledge embedded in the model is well interpreted. After discussion,\nit is found that data-driven models integrated engineering or physical\nknowledge can significantly improve the urban building energy simulation.",
    "descriptor": "\nComments: 22 pages, 10 figures, submitted to applied energy\n",
    "authors": [
      "Yuqing Hu",
      "Xiaoyuan Cheng",
      "Suhang Wang",
      "Jianli Chen",
      "Tianxiang Zhao",
      "Enyan Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13399"
  },
  {
    "id": "arXiv:2105.13403",
    "title": "Approximate evolution operators for the Active Flux method",
    "abstract": "This work focuses on the numerical solution of hyperbolic conservations laws\n(possibly endowed with a source term) using the Active Flux method. This method\nis an extension of the finite volume method. Instead of solving a Riemann\nProblem, the Active Flux method uses actively evolved point values along the\ncell boundary in order to compute the numerical flux. Early applications of the\nmethod were linear equations with an available exact solution operator, and\nActive Flux was shown to be structure preserving in such cases. For nonlinear\nPDEs or balance laws, exact evolution operators generally are unavailable.\nHere, strategies are shown how sufficiently accurate approximate evolution\noperators can be designed which allow to make Active Flux structure preserving\n/ well-balanced for nonlinear problems.",
    "descriptor": "",
    "authors": [
      "Wasilij Barsukow"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13403"
  },
  {
    "id": "arXiv:2105.13404",
    "title": "How to Integrate Security Compliance Requirements with Agile Software  Engineering at Scale?",
    "abstract": "Integrating security into agile software development is an open issue for\nresearch and practice. Especially in strongly regulated industries, complexity\nincreases not only when scaling agile practices but also when aiming for\ncompliance with security standards. To achieve security compliance in a\nlarge-scale agile context, we developed S2C-SAFe: An extension of the Scaled\nAgile Framework that is compliant to the security standard IEC~62443-4-1 for\nsecure product development.\nIn this paper, we present the framework and its evaluation by agile and\nsecurity experts within Siemens' large-scale project ecosystem. We discuss\nbenefits and limitations as well as challenges from a practitioners'\nperspective. Our results indicate that \\ssafe contributes to successfully\nintegrating security compliance with lean and agile development in regulated\nenvironments. We also hope to raise awareness for the importance and challenges\nof integrating security in the scope of Continuous Software Engineering.",
    "descriptor": "\nComments: Authors' Copy\n",
    "authors": [
      "Fabiola Moy\u00f3n",
      "Daniel M\u00e9ndez Fern\u00e1ndez",
      "Kristian Beckers",
      "Sebastian Klepper"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13404"
  },
  {
    "id": "arXiv:2105.13409",
    "title": "R-SARL: Crowd-aware Navigation Based Deep Reinforcement Learning for  Nonholonomic Robot in Complex Environments",
    "abstract": "Robot navigation in a safe way for complex and crowded situations is studied\nin this work. When facing complex environments with both static and dynamic\nobstacles, in existing works unicycle nonholonomic robots are prone to two\nextreme behaviors, one is to fall into dead ends formed by obstacles, and the\nother is to not complete the navigation task in time due to excessive collision\navoidance.As a result, we propose the R-SARL framework, which is based on a\ndeep reinforcement learning algorithm and where we augment the reward function\nto avoid collisions. In particular, we estimate unsafe interactions between the\nrobot and obstacles in a look-ahead distance and penalize accordingly, so that\nthe robot can avoid collisions in advance and reach its destination\nsafely.Furthermore, we penalize frequent excessive detours to reduce the\ntimeout and thus improve the efficiency of navigation.We test our method in\nvarious challenging and complex crowd navigation tasks. The results show that\nour method improves navigation performance and outperforms state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Yanying Zhou",
      "Shijie Li",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13409"
  },
  {
    "id": "arXiv:2105.13411",
    "title": "Model Repair Revamped: On the Automated Synthesis of Markov Chains",
    "abstract": "This paper outlines two approaches|based on counterexample-guided abstraction\nrefinement (CEGAR) and counterexample-guided inductive synthesis (CEGIS),\nrespectively to the automated synthesis of finite-state probabilistic models\nand programs. Our CEGAR approach iteratively partitions the design space\nstarting from an abstraction of this space and refines this by a light-weight\nanalysis of verification results. The CEGIS technique exploits critical\nsubsystems as counterexamples to prune all programs behaving incorrectly on\nthat input. We show the applicability of these synthesis techniques to\nsketching of probabilistic programs, controller synthesis of POMDPs, and\nsoftware product lines.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Milan Ceska",
      "Christian Dehnert",
      "Nils Jansen",
      "Sebastian Junges",
      "Joost-Pieter Katoen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.13411"
  },
  {
    "id": "arXiv:2105.13413",
    "title": "Using Process Models to understand Security Standards",
    "abstract": "Many industrial software development processes today have to comply with\nsecurity standards such as the IEC~62443-4-1. These standards, written in\nnatural language, are ambiguous and complex to understand. This is especially\ntrue for non-security experts. Security practitioners thus invest much effort\ninto comprehending standards and, later, into introducing them to development\nteams. However, our experience in the industry shows that development\npractitioners might very well also read such standards, but nevertheless end up\ninviting experts for interpretation (or confirmation). Such a scenario is not\nin tune with current trends and needs of increasing velocity in continuous\nsoftware engineering.\nIn this paper, we propose a tool-supported approach to make security\nstandards more precise and easier to understand for both non-security as well\nas security experts by applying process models. This approach emerges from a\nlarge industrial company and encompasses so far the IEC62443-4-1 standard. We\nfurther present a case study with 16 industry practitioners showing how the\napproach improves communication between development and security compliance\npractitioners.",
    "descriptor": "\nComments: Authors Copy\n",
    "authors": [
      "Fabiola Moy\u00f3n",
      "Daniel M\u00e9ndez",
      "Kristian Beckers",
      "Sebastian Klepper"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13413"
  },
  {
    "id": "arXiv:2105.13418",
    "title": "On Privacy and Confidentiality of Communications in Organizational  Graphs",
    "abstract": "Machine learned models trained on organizational communication data, such as\nemails in an enterprise, carry unique risks of breaching confidentiality, even\nif the model is intended only for internal use. This work shows how\nconfidentiality is distinct from privacy in an enterprise context, and aims to\nformulate an approach to preserving confidentiality while leveraging principles\nfrom differential privacy. The goal is to perform machine learning tasks, such\nas learning a language model or performing topic analysis, using interpersonal\ncommunications in the organization, while not learning about confidential\ninformation shared in the organization. Works that apply differential privacy\ntechniques to natural language processing tasks usually assume independently\ndistributed data, and overlook potential correlation among the records.\nIgnoring this correlation results in a fictional promise of privacy. Naively\nextending differential privacy techniques to focus on group privacy instead of\nrecord-level privacy is a straightforward approach to mitigate this issue. This\napproach, although providing a more realistic privacy-guarantee, is\nover-cautious and severely impacts model utility. We show this gap between\nthese two extreme measures of privacy over two language tasks, and introduce a\nmiddle-ground solution. We propose a model that captures the correlation in the\nsocial network graph, and incorporates this correlation in the privacy\ncalculations through Pufferfish privacy principles.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Masoumeh Shafieinejad",
      "Huseyin Inan",
      "Marcello Hasegawa",
      "Robert Sim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13418"
  },
  {
    "id": "arXiv:2105.13423",
    "title": "Observability Conditions and Sensing Quality for Unicycle Systems with  Constant External Forcing",
    "abstract": "In certain systems which are subject to significant constant external forcing\nsuch as an airplane in wind or an underwater glider in ocean currents, the\nability to detect the forcing depends on both the measurements available and\nwhether appropriate control is being applied. Using analytical nonlinear\nobservability techniques, we define the necessary characteristics required of a\nmeasurement function for systems with unicycle dynamics subject to constant\nforcing to be observable. We further consider the necessary associated motion\ncharacteristics required of this class of systems to enable the desired sensing\ncapabilities. We then apply these results in combination with the empirical\nGramian to quantify relative observability, optimal sensor selection, and\nsensing quality for different motion primitive modes for a Dubins path.",
    "descriptor": "\nComments: Submitted to IEEE 2021 Conference on Decision and Control/Control Systems Letters (CDC/L-CSS) 6 pages, 4 figures\n",
    "authors": [
      "Natalie Brace",
      "Kristi A. Morgansen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13423"
  },
  {
    "id": "arXiv:2105.13424",
    "title": "Sinan: Data-Driven, QoS-Aware Cluster Management for Microservices",
    "abstract": "Cloud applications are increasingly shifting from large monolithic services,\nto large numbers of loosely-coupled, specialized microservices. Despite their\nadvantages in terms of facilitating development, deployment, modularity, and\nisolation, microservices complicate resource management, as dependencies\nbetween them introduce backpressure effects and cascading QoS violations.\nWe present Sinan, a data-driven cluster manager for interactive cloud\nmicroservices that is online and QoS-aware. Sinan leverages a set of scalable\nand validated machine learning models to determine the performance impact of\ndependencies between microservices, and allocate appropriate resources per tier\nin a way that preserves the end-to-end tail latency target. We evaluate Sinan\nboth on dedicated local clusters and large-scale deployments on Google Compute\nEngine (GCE) across representative end-to-end applications built with\nmicroservices, such as social networks and hotel reservation sites. We show\nthat Sinan always meets QoS, while also maintaining cluster utilization high,\nin contrast to prior work which leads to unpredictable performance or\nsacrifices resource efficiency. Furthermore, the techniques in Sinan are\nexplainable, meaning that cloud operators can yield insights from the ML models\non how to better deploy and design their applications to reduce unpredictable\nperformance.",
    "descriptor": "",
    "authors": [
      "Yanqi Zhang",
      "Weizhe Hua",
      "Zhuangzhuang Zhou",
      "Edward Suh",
      "Christina Delimitrou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13424"
  },
  {
    "id": "arXiv:2105.13426",
    "title": "GuideMe: A Mobile Application based on Global Positioning System and  Object Recognition Towards a Smart Tourist Guide",
    "abstract": "Finding information about tourist places to visit is a challenging problem\nthat people face while visiting different countries. This problem is\naccentuated when people are coming from different countries, speak different\nlanguages, and are from all segments of society. In this context, visitors and\npilgrims face important problems to find the appropriate doaas when visiting\nholy places. In this paper, we propose a mobile application that helps the user\nfind the appropriate doaas for a given holy place in an easy and intuitive\nmanner. Three different options are developed to achieve this goal: 1) manual\nsearch, 2) GPS location to identify the holy places and therefore their\ncorresponding doaas, and 3) deep learning (DL) based method to determine the\nholy place by analyzing an image taken by the visitor. Experiments show good\nperformance of the proposed mobile application in providing the appropriate\ndoaas for visited holy places.",
    "descriptor": "",
    "authors": [
      "Wadii Boulila",
      "Anmar Abuhamdah",
      "Maha Driss",
      "Slim Kammoun",
      "Jawad Ahmad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13426"
  },
  {
    "id": "arXiv:2105.13428",
    "title": "Interacto: A Modern User Interaction Processing Model",
    "abstract": "Since most software systems provide their users with interactive features,\nbuilding user interfaces (UI) is one of the core software engineering tasks. It\nconsists in designing, implementing and testing ever more sophisticated and\nversatile ways for users to interact with software systems, and safely\nconnecting these interactions with commands querying or modifying their state.\nHowever, most UI frameworks still rely on a low level model, the bare bone UI\nevent processing model. This model was suitable for the rather simple UIs of\nthe early 80s (menus, buttons, keyboards, mouse clicks), but now exhibits major\nsoftware engineering flaws for modern, highly interactive UIs. These flaws\ninclude lack of separation of concerns, weak modularity and thus low\nreusability of code for advanced interactions, as well as low testability. To\nmitigate these flaws, we propose Interacto as a high level user interaction\nprocessing model. By reifying the concept of user interaction, Interacto makes\nit easy to design, implement and test modular and reusable advanced user\ninteractions, and to connect them to commands with built-in undo/redo support.\nTo demonstrate its applicability and generality, we briefly present two open\nsource implementations of Interacto for Java/JavaFX and TypeScript/Angular. We\nevaluate Interacto interest (1) on a real world case study, where it has been\nused since 2013, and with (2) a controlled experiment with 44 master students,\ncomparing it with traditionnal UI frameworks.",
    "descriptor": "",
    "authors": [
      "Arnaud Blouin",
      "Jean-Marc J\u00e9z\u00e9quel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.13428"
  },
  {
    "id": "arXiv:2105.13430",
    "title": "Explainable Multi-class Classification of the CAMH COVID-19 Mental  Health Data",
    "abstract": "Application of Machine Learning algorithms to the medical domain is an\nemerging trend that helps to advance medical knowledge. At the same time, there\nis a significant a lack of explainable studies that promote informed,\ntransparent, and interpretable use of Machine Learning algorithms. In this\npaper, we present explainable multi-class classification of the Covid-19 mental\nhealth data. In Machine Learning study, we aim to find the potential factors to\ninfluence a personal mental health during the Covid-19 pandemic. We found that\nRandom Forest (RF) and Gradient Boosting (GB) have scored the highest accuracy\nof 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF\nand 61.8% for GB. We then compare a Post-hoc system (Local Interpretable\nModel-Agnostic Explanations, or LIME) and an Ante-hoc system (Gini Importance)\nin their ability to explain the obtained Machine Learning results. To the best\nof these authors knowledge, our study is the first explainable Machine Learning\nstudy of the mental health data collected during Covid-19 pandemics.",
    "descriptor": "\nComments: 22 pages, including Appendixes; 7 tables and 5 figures in the main text\n",
    "authors": [
      "YuanZheng Hu",
      "Marina Sokolova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.13430"
  },
  {
    "id": "arXiv:2105.13431",
    "title": "Exploitation vs Caution: Risk-sensitive Policies for Offline Learning",
    "abstract": "Offline model learning for planning is a branch of machine learning that\ntrains agents to perform actions in an unknown environment using a fixed batch\nof previously collected experiences. The limited size of the data set hinders\nthe estimate of the Value function of the relative Markov Decision Process\n(MDP), bounding the performance of the obtained policy in the real world. In\nthis context, recent works showed that planning with a discount factor lower\nthan the one used during the evaluation phase yields more performing policies.\nHowever, the optimal discount factor is finally chosen by cross-validation. Our\naim is to show that looking for a sub-optimal solution of a Bayesian MDP might\nlead to better performances with respect to the current baselines that work in\nthe offline setting. Hence, we propose Exploitation vs Caution (EvC), an\nalgorithm that automatically selects the policy that solves a Risk-sensitive\nBayesian MDP in a set of policies obtained by solving several MDPs\ncharacterized by different discount factors and transition dynamics. On one\nhand, the Bayesian formalism elegantly includes model uncertainty and on\nanother hand the introduction of a risk-sensitive utility function guarantees\nrobustness. We evaluated the proposed approach in different discrete simple\nenvironments offering a fair variety of MDP classes. We also compared the\nobtained results with state-of-the-art offline learning for planning baselines\nsuch as MOPO and MOReL. In the tested scenarios EvC is more robust than the\nsaid approaches suggesting that sub-optimally solving an Offline Risk-sensitive\nBayesian MDP (ORBMDP) could define a sound framework for planning under model\nuncertainty.",
    "descriptor": "\nComments: Preprint, under review\n",
    "authors": [
      "Giorgio Angelotti",
      "Nicolas Drougard",
      "Caroline Ponzoni Carvalho Chanel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13431"
  },
  {
    "id": "arXiv:2105.13434",
    "title": "FuSeConv: Fully Separable Convolutions for Fast Inference on Systolic  Arrays",
    "abstract": "Both efficient neural networks and hardware accelerators are being explored\nto speed up DNN inference on edge devices. For example, MobileNet uses\ndepthwise separable convolution to achieve much lower latency, while systolic\narrays provide much higher performance per watt. Interestingly however, the\ncombination of these two ideas is inefficient: The computational patterns of\ndepth-wise separable convolution are not systolic and lack data reuse to\nsaturate the systolic array's constrained dataflow. In this paper, we propose\nFuSeConv (Fully-Separable Convolution) as a drop-in replacement for depth-wise\nseparable convolution. FuSeConv generalizes the decomposition of convolutions\nfully to separable 1D convolutions along spatial and depth dimensions. The\nresultant computation is systolic and efficiently utilizes the systolic array\nwith a slightly modified dataflow. With FuSeConv, we achieve a significant\nspeed-up of 3x-7x with the MobileNet family of networks on a systolic array of\nsize 64x64, with comparable accuracy on the ImageNet dataset. The high speed-up\nmotivates exploration of hardware-aware Neural Operator Search (NOS) in\ncomplement to ongoing efforts on Neural Architecture Search (NAS).",
    "descriptor": "\nComments: To appear in the Proceedings of the Design, Automation & Test in Europe (DATE), 2021\n",
    "authors": [
      "Surya Selvam",
      "Vinod Ganesan",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13434"
  },
  {
    "id": "arXiv:2105.13435",
    "title": "Intrusion Detection using Machine Learning Techniques: An Experimental  Comparison",
    "abstract": "Due to an exponential increase in the number of cyber-attacks, the need for\nimproved Intrusion Detection Systems (IDS) is apparent than ever. In this\nregard, Machine Learning (ML) techniques are playing a pivotal role in the\nearly classification of the attacks in case of intrusion detection within the\nsystem. However, due to a large number of algorithms available, the selection\nof the right method is a challenging task. To resolve this issue, this paper\nanalyses some of the current state-of-the-art intrusion detection methods and\ndiscusses their pros and cons. Further, a review of different ML methods is\ncarried out with four methods showing to be the most suitable one for\nclassifying attacks. Several algorithms are selected and investigated to\nevaluate the performance of IDS. These IDS classifies binary and multiclass\nattacks in terms of detecting whether or not the traffic has been considered as\nbenign or an attack. The experimental results demonstrate that binary\nclassification has greater consistency in their accuracy results which ranged\nfrom 0.9938 to 0.9977, while multiclass ranges from 0.9294 to 0.9983. However,\nit has been also observed that multiclass provides the best results with the\nalgorithm k-Nearest neighbor giving an accuracy score of 0.9983 while the\nbinary classification highest score is 0.9977 from Random Forest. The\nexperimental results demonstrate that multiclass classification produces better\nperformance in terms of intrusion detection by specifically differentiating\nbetween the attacks and allowing a more targeted response to an attack.",
    "descriptor": "",
    "authors": [
      "Kathryn-Ann Tait",
      "Jan Sher Khan",
      "Fehaid Alqahtani",
      "Awais Aziz Shah",
      "Fadia Ali Khan",
      "Mujeeb Ur Rehman",
      "Wadii Boulila",
      "Jawad Ahmad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13435"
  },
  {
    "id": "arXiv:2105.13442",
    "title": "Hopper: Modeling and Detecting Lateral Movement (Extended Report)",
    "abstract": "In successful enterprise attacks, adversaries often need to gain access to\nadditional machines beyond their initial point of compromise, a set of internal\nmovements known as lateral movement. We present Hopper, a system for detecting\nlateral movement based on commonly available enterprise logs. Hopper constructs\na graph of login activity among internal machines and then identifies\nsuspicious sequences of loginsthat correspond to lateral movement. To\nunderstand the larger context of each login, Hopper employs an inference\nalgorithm to identify the broader path(s) of movement that each login belongs\nto and the causal user responsible for performing a path's logins. Hopper then\nleverages this path inference algorithm, in conjunction with a set of detection\nrules and a new anomaly scoring algorithm, to surface the login paths most\nlikely to reflect lateral movement. On a 15-month enterprise dataset consisting\nof over 780 million internal logins, Hop-per achieves a 94.5% detection rate\nacross over 300 realistic attack scenarios, including one red team attack,\nwhile generating an average of <9 alerts per day. In contrast, to detect the\nsame number of attacks, prior state-of-the-art systems would need to generate\nnearly 8x as many false positives.",
    "descriptor": "\nComments: Usenix Security Symposium 2021\n",
    "authors": [
      "Grant Ho",
      "Mayank Dhiman",
      "Devdatta Akhawe",
      "Vern Paxson",
      "Stefan Savage",
      "Geoffrey M. Voelker",
      "David Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13442"
  },
  {
    "id": "arXiv:2105.13448",
    "title": "Open-world Machine Learning: Applications, Challenges, and Opportunities",
    "abstract": "Traditional machine learning especially supervised learning follows the\nassumptions of closed-world learning i.e., for each testing class a training\nclass is available. However, such machine learning models fail to identify the\nclasses which were not available during training time. These classes can be\nreferred to as unseen classes. Whereas, open-world machine learning deals with\narbitrary inputs (data with unseen classes) to machine learning systems.\nMoreover, traditional machine learning is static learning which is not\nappropriate for an active environment where the perspective and sources, and/or\nvolume of data are changing rapidly. In this paper, first, we present an\noverview of open-world learning with importance to the real-world context.\nNext, different dimensions of open-world learning are explored and discussed.\nThe area of open-world learning gained the attention of the research community\nin the last decade only. We have searched through different online digital\nlibraries and scrutinized the work done in the last decade. This paper presents\na systematic review of various techniques for open-world machine learning. It\nalso presents the research gaps, challenges, and future directions in\nopen-world learning. This paper will help researchers to understand the\ncomprehensive developments of open-world learning and the likelihoods to extend\nthe research in suitable areas. It will also help to select applicable\nmethodologies and datasets to explore this further.",
    "descriptor": "",
    "authors": [
      "Jitendra Parmar",
      "Satyendra Singh Chouhan",
      "Santosh Singh Rathore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13448"
  },
  {
    "id": "arXiv:2105.13449",
    "title": "Relational Gating for \"What If\" Reasoning",
    "abstract": "This paper addresses the challenge of learning to do procedural reasoning\nover text to answer \"What if...\" questions. We propose a novel relational\ngating network that learns to filter the key entities and relationships and\nlearns contextual and cross representations of both procedure and question for\nfinding the answer. Our relational gating network contains an entity gating\nmodule, relation gating module, and contextual interaction module. These\nmodules help in solving the \"What if...\" reasoning problem. We show that\nmodeling pairwise relationships helps to capture higher-order relations and\nfind the line of reasoning for causes and effects in the procedural\ndescriptions. Our proposed approach achieves the state-of-the-art results on\nthe WIQA dataset.",
    "descriptor": "\nComments: Accepted by IJCAI 2021\n",
    "authors": [
      "Chen Zheng",
      "Parisa Kordjamshidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13449"
  },
  {
    "id": "arXiv:2105.13454",
    "title": "Computational modeling of the nonlinear stochastic dynamics of  horizontal drillstrings",
    "abstract": "This work intends to analyze the nonlinear stochastic dynamics of\ndrillstrings in horizontal configuration. For this purpose, it considers a beam\ntheory, with effects of rotatory inertia and shear deformation, which is\ncapable of reproducing the large displacements that the beam undergoes. The\nfriction and shock effects, due to beam/borehole wall transversal impacts, as\nwell as the force and torque induced by bit-rock interaction, are also\nconsidered in the model. Uncertainties of bit-rock interaction model are taken\ninto account using a parametric probabilistic approach. Numerical simulations\nhave shown that the mechanical system of interest has a very rich nonlinear\nstochastic dynamics, which generate phenomena such as bit-bounce, stick-slip,\nand transverse impacts. A study aiming to maximize the drilling process\nefficiency, varying drillstring velocities of translation and rotation is\npresented. Also, the work presents the definition and solution of two\noptimizations problems, one deterministic and one robust, where the objective\nis to maximize drillstring rate of penetration into the soil respecting its\nstructural limits.",
    "descriptor": "",
    "authors": [
      "Americo Cunha Jr",
      "Christian Soize",
      "Rubens Sampaio"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Mathematical Physics (math-ph)",
      "Classical Physics (physics.class-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13454"
  },
  {
    "id": "arXiv:2105.13456",
    "title": "Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced  Collective Inference",
    "abstract": "Compared to the general news domain, information extraction (IE) from\nbiomedical text requires much broader domain knowledge. However, many previous\nIE methods do not utilize any external knowledge during inference. Due to the\nexponential growth of biomedical publications, models that do not go beyond\ntheir fixed set of parameters will likely fall behind. Inspired by how humans\nlook up relevant information to comprehend a scientific text, we present a\nnovel framework that utilizes external knowledge for joint entity and relation\nextraction named KECI (Knowledge-Enhanced Collective Inference). Given an input\ntext, KECI first constructs an initial span graph representing its initial\nunderstanding of the text. It then uses an entity linker to form a knowledge\ngraph containing relevant background knowledge for the the entity mentions in\nthe text. To make the final predictions, KECI fuses the initial span graph and\nthe knowledge graph into a more refined graph using an attention mechanism.\nKECI takes a collective approach to link mention spans to entities by\nintegrating global relational information into local representations using\ngraph convolutional networks. Our experimental results show that the framework\nis highly effective, achieving new state-of-the-art results in two different\nbenchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse\ndrug event extraction). For example, KECI achieves absolute improvements of\n4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity\nand relation extraction tasks.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Tuan Lai",
      "Heng Ji",
      "ChengXiang Zhai",
      "Quan Hung Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13456"
  },
  {
    "id": "arXiv:2105.13458",
    "title": "A comparison between central- and self-dispatch storage management  principles in island systems",
    "abstract": "This paper presents a comparative evaluation of central and self-dispatch\nmanagement concepts for battery energy storage (BES) facilities in island power\nsystems with a high renewable energy source (RES) penetration. BES facilities\ndeployed to support the integration of additional wind capacity can be either\ncentrally dispatched by the island System Operator or they can be\nself-dispatched within a Virtual Power Plant entity comprising renewables and\nstorage, called a Hybrid Power Station (HPS). To explore the anticipated\nbenefits of each BES management paradigm, annual simulations are performed for\nan example island system, employing a three-layer mixed integer linear\nprogramming (MILP) method to simulate the unit commitment and economic dispatch\nprocesses. The levelized cost of energy (LCOE) of combined BES and renewables\ninvestments is calculated and the achieved RES penetration levels and island\nsystem generation cost are evaluated, allowing the identification of Pareto\noptimal storage configurations, leading to lowest LCOE for a given RES\npenetration target. Overall, the centrally dispatched BES systems prove to be\nsubstantially more cost-effective, compared to the self-dispatched alternative,\nfor achieving similar RES penetration levels.",
    "descriptor": "",
    "authors": [
      "Georgios N. Psarros",
      "Pantelis A. Dratsas",
      "Stavros A. Papathanassiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13458"
  },
  {
    "id": "arXiv:2105.13459",
    "title": "Enhancing the performance of a bistable energy harvesting device via the  cross-entropy method",
    "abstract": "This work deals with the solution of a non-convex optimization problem to\nenhance the performance of an energy harvesting device, which involves a\nnonlinear objective function and a discontinuous constraint. This optimization\nproblem, which seeks to find a suitable configuration of parameters that\nmaximize the electrical power recovered by a bistable energy harvesting system,\nis formulated in terms of the dynamical system response and a binary classifier\nobtained from 0 to 1 test for chaos. A stochastic solution strategy that\ncombines penalization and the cross-entropy method is proposed and numerically\ntested. Computational experiments are conducted to address the performance of\nthe proposed optimization approach by comparison with a reference solution,\nobtained via an exhaustive search in a refined numerical mesh. The obtained\nresults illustrate the effectiveness and robustness of the cross-entropy\noptimization strategy (even in the presence of noise or in moderately higher\ndimensions), showing that the proposed framework may be a very useful and\npowerful tool to solve optimization problems involving nonlinear energy\nharvesting dynamical systems.",
    "descriptor": "",
    "authors": [
      "Americo Cunha Jr"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13459"
  },
  {
    "id": "arXiv:2105.13461",
    "title": "Learning Model-Based Vehicle-Relocation Decisions for Real-Time  Ride-Sharing: Hybridizing Learning and Optimization",
    "abstract": "Large-scale ride-sharing systems combine real-time dispatching and routing\noptimization over a rolling time horizon with a model predictive control(MPC)\ncomponent that relocates idle vehicles to anticipate the demand. The MPC\noptimization operates over a longer time horizon to compensate for the inherent\nmyopic nature of the real-time dispatching. These longer time horizons are\nbeneficial for the quality of the decisions but increase computational\ncomplexity. To address this computational challenge, this paper proposes a\nhybrid approach that combines machine learning and optimization. The\nmachine-learning component learns the optimal solution to the MPC optimization\non the aggregated level to overcome the sparsity and high-dimensionality of the\nMPC solutions. The optimization component transforms the machine-learning\npredictions back to the original granularity via a tractable transportation\nmodel. As a consequence, the original NP-hard MPC problem is reduced to a\npolynomial time prediction and optimization. Experimental results show that the\nhybrid approach achieves 27% further reduction in rider waiting time than the\nMPC optimization, thanks to its ability to model a longer time horizon within\nthe computational limits.",
    "descriptor": "",
    "authors": [
      "Enpeng Yuan",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13461"
  },
  {
    "id": "arXiv:2105.13462",
    "title": "The Sobolev Regularization Effect of Stochastic Gradient Descent",
    "abstract": "The multiplicative structure of parameters and input data in the first layer\nof neural networks is explored to build connection between the landscape of the\nloss function with respect to parameters and the landscape of the model\nfunction with respect to input data. By this connection, it is shown that flat\nminima regularize the gradient of the model function, which explains the good\ngeneralization performance of flat minima. Then, we go beyond the flatness and\nconsider high-order moments of the gradient noise, and show that Stochastic\nGradient Dascent (SGD) tends to impose constraints on these moments by a linear\nstability analysis of SGD around global minima. Together with the\nmultiplicative structure, we identify the Sobolev regularization effect of SGD,\ni.e. SGD regularizes the Sobolev seminorms of the model function with respect\nto the input data. Finally, bounds for generalization error and adversarial\nrobustness are provided for solutions found by SGD under assumptions of the\ndata distribution.",
    "descriptor": "",
    "authors": [
      "Chao Ma",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13462"
  },
  {
    "id": "arXiv:2105.13464",
    "title": "Training With Data Dependent Dynamic Learning Rates",
    "abstract": "Recently many first and second order variants of SGD have been proposed to\nfacilitate training of Deep Neural Networks (DNNs). A common limitation of\nthese works stem from the fact that they use the same learning rate across all\ninstances present in the dataset. This setting is widely adopted under the\nassumption that loss functions for each instance are similar in nature, and\nhence, a common learning rate can be used. In this work, we relax this\nassumption and propose an optimization framework which accounts for difference\nin loss function characteristics across instances. More specifically, our\noptimizer learns a dynamic learning rate for each instance present in the\ndataset. Learning a dynamic learning rate for each instance allows our\noptimization framework to focus on different modes of training data during\noptimization. When applied to an image classification task, across different\nCNN architectures, learning dynamic learning rates leads to consistent gains\nover standard optimizers. When applied to a dataset containing corrupt\ninstances, our framework reduces the learning rates on noisy instances, and\nimproves over the state-of-the-art. Finally, we show that our optimization\nframework can be used for personalization of a machine learning model towards a\nknown targeted data distribution.",
    "descriptor": "",
    "authors": [
      "Shreyas Saxena",
      "Nidhi Vyas",
      "Dennis DeCoste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13464"
  },
  {
    "id": "arXiv:2105.13465",
    "title": "Verb Sense Clustering using Contextualized Word Representations for  Semantic Frame Induction",
    "abstract": "Contextualized word representations have proven useful for various natural\nlanguage processing tasks. However, it remains unclear to what extent these\nrepresentations can cover hand-coded semantic information such as semantic\nframes, which specify the semantic role of the arguments associated with a\npredicate. In this paper, we focus on verbs that evoke different frames\ndepending on the context, and we investigate how well contextualized word\nrepresentations can recognize the difference of frames that the same verb\nevokes. We also explore which types of representation are suitable for semantic\nframe induction. In our experiments, we compare seven different contextualized\nword representations for two English frame-semantic resources, FrameNet and\nPropBank. We demonstrate that several contextualized word representations,\nespecially BERT and its variants, are considerably informative for semantic\nframe induction. Furthermore, we examine the extent to which the contextualized\nrepresentation of a verb can estimate the number of frames that the verb can\nevoke.",
    "descriptor": "\nComments: ACL-IJCNLP 2021 Findings\n",
    "authors": [
      "Kosuke Yamada",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13465"
  },
  {
    "id": "arXiv:2105.13466",
    "title": "Semantic Frame Induction using Masked Word Embeddings and Two-Step  Clustering",
    "abstract": "Recent studies on semantic frame induction show that relatively high\nperformance has been achieved by using clustering-based methods with\ncontextualized word embeddings. However, there are two potential drawbacks to\nthese methods: one is that they focus too much on the superficial information\nof the frame-evoking verb and the other is that they tend to divide the\ninstances of the same verb into too many different frame clusters. To overcome\nthese drawbacks, we propose a semantic frame induction method using masked word\nembeddings and two-step clustering. Through experiments on the English FrameNet\ndata, we demonstrate that using the masked word embeddings is effective for\navoiding too much reliance on the surface information of frame-evoking verbs\nand that two-step clustering can improve the number of resulting frame clusters\nfor the instances of the same verb.",
    "descriptor": "\nComments: ACL-IJCNLP 2021\n",
    "authors": [
      "Kosuke Yamada",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13466"
  },
  {
    "id": "arXiv:2105.13468",
    "title": "Hailstorm : A Statically-Typed, Purely Functional Language for IoT  Applications",
    "abstract": "With the growing ubiquity of Internet of Things(IoT), more complex logic is\nbeing programmed on resource-constrained IoT devices, almost exclusively using\nthe C programming language. While C provides low-level control over memory, it\nlacks a number of high-level programming abstractions such as higher-order\nfunctions, polymorphism, strong static typing, memory safety, and automatic\nmemory management.\nWe present Hailstorm, a statically-typed, purely functional programming\nlanguage that attempts to address the above problem. It is a high-level\nprogramming language with a strict typing discipline. It supports features like\nhigher-order functions, tail-recursion, and automatic memory management, to\nprogram IoT devices in a declarative manner. Applications running on these\ndevices tend to be heavily dominated by I/O. Hailstorm tracks side effects\nlikeI/O in its type system using resource types. This choice allowed us to\nexplore the design of a purely functional standalone language, in an area where\nit is more common to embed a functional core in an imperative shell. The\nlanguage borrows the combinators of arrowized FRP, but has discrete-time\nsemantics. The design of the full set of combinators is work in progress,\ndriven by examples. So far, we have evaluated Hailstorm by writing standard\nexamples from the literature (earthquake detection, a railway crossing system\nand various other clocked systems), and also running examples on the GRiSP\nembedded systems board, through generation of Erlang.",
    "descriptor": "",
    "authors": [
      "Abhiroop Sarkar",
      "Mary Sheeran"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13468"
  },
  {
    "id": "arXiv:2105.13471",
    "title": "Inspecting the concept knowledge graph encoded by modern language models",
    "abstract": "The field of natural language understanding has experienced exponential\nprogress in the last few years, with impressive results in several tasks. This\nsuccess has motivated researchers to study the underlying knowledge encoded by\nthese models. Despite this, attempts to understand their semantic capabilities\nhave not been successful, often leading to non-conclusive, or contradictory\nconclusions among different works. Via a probing classifier, we extract the\nunderlying knowledge graph of nine of the most influential language models of\nthe last years, including word embeddings, text generators, and context\nencoders. This probe is based on concept relatedness, grounded on WordNet. Our\nresults reveal that all the models encode this knowledge, but suffer from\nseveral inaccuracies. Furthermore, we show that the different architectures and\ntraining strategies lead to different model biases. We conduct a systematic\nevaluation to discover specific factors that explain why some concepts are\nchallenging. We hope our insights will motivate the development of models that\ncapture concepts more precisely.",
    "descriptor": "",
    "authors": [
      "Carlos Aspillaga",
      "Marcelo Mendoza",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13471"
  },
  {
    "id": "arXiv:2105.13478",
    "title": "Measuring the Performance and Network Utilization of Popular Video  Conferencing Applications",
    "abstract": "Video conferencing applications (VCAs) have become a critical Internet\napplication, even more so during the COVID-19 pandemic, as users worldwide now\nrely on them for work, school, and telehealth. It is thus increasingly\nimportant to understand the resource requirements of different VCAs and how\nthey perform under different network conditions, including: how much speed\n(upstream and downstream throughput) a VCA needs to support high quality of\nexperience; how VCAs perform under temporary reductions in available capacity;\nhow they compete with themselves, with each other, and with other applications;\nand how usage modality (e.g., number of participants) affects utilization. We\nstudy three modern VCAs: Zoom, Google Meet, and Microsoft Teams. Answers to\nthese questions differ substantially depending on VCA. First, the average\nutilization on an unconstrained link varies between 0.8 Mbps and 1.9 Mbps.\nGiven temporary reduction of capacity, some VCAs can take as long as 50 seconds\nto recover to steady state. Differences in proprietary congestion control\nalgorithms also result in unfair bandwidth allocations: in constrained\nbandwidth settings, one Zoom video conference can consume more than 75% of the\navailable bandwidth when competing with another VCA (e.g., Meet, Teams). For\nsome VCAs, client utilization can decrease as the number of participants\nincreases, due to the reduced video resolution of each participant's video\nstream given a larger number of participants. Finally, one participant's\nviewing mode (e.g., pinning a speaker) can affect the upstream utilization of\nother participants.",
    "descriptor": "",
    "authors": [
      "Kyle MacMillan",
      "Tarun Mangla",
      "James Saxon",
      "Nick Feamster"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13478"
  },
  {
    "id": "arXiv:2105.13479",
    "title": "Leveraging Linguistic Coordination in Reranking N-Best Candidates For  End-to-End Response Selection Using BERT",
    "abstract": "Retrieval-based dialogue systems select the best response from many\ncandidates. Although many state-of-the-art models have shown promising\nperformance in dialogue response selection tasks, there is still quite a gap\nbetween R@1 and R@10 performance. To address this, we propose to leverage\nlinguistic coordination (a phenomenon that individuals tend to develop similar\nlinguistic behaviors in conversation) to rerank the N-best candidates produced\nby BERT, a state-of-the-art pre-trained language model. Our results show an\nimprovement in R@1 compared to BERT baselines, demonstrating the utility of\nrepairing machine-generated outputs by leveraging a linguistic theory.",
    "descriptor": "\nComments: The 34th International FLAIRS Conference Proceedings, May 2021\n",
    "authors": [
      "Mingzhi Yu",
      "Diane Litman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13479"
  },
  {
    "id": "arXiv:2105.13480",
    "title": "Efficient distributed algorithms for Convolutional Neural Networks",
    "abstract": "Several efficient distributed algorithms have been developed for\nmatrix-matrix multiplication: the 3D algorithm, the 2D SUMMA algorithm, and the\n2.5D algorithm. Each of these algorithms was independently conceived and they\ntrade-off memory needed per node and the inter-node data communication volume.\nThe convolutional neural network (CNN) computation may be viewed as a\ngeneralization of matrix-multiplication combined with neighborhood stencil\ncomputations. We develop communication-efficient distributed-memory algorithms\nfor CNNs that are analogous to the 2D/2.5D/3D algorithms for matrix-matrix\nmultiplication.",
    "descriptor": "\nComments: Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21), July 6--8, 2021, Virtual Event, USA\n",
    "authors": [
      "Rui Li",
      "Yufan Xu",
      "Aravind Sukumaran-Rajam",
      "Atanas Rountev",
      "P Sadayappan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13480"
  },
  {
    "id": "arXiv:2105.13482",
    "title": "FastRIFE: Optimization of Real-Time Intermediate Flow Estimation for  Video Frame Interpolation",
    "abstract": "The problem of video inter-frame interpolation is an essential task in the\nfield of image processing. Correctly increasing the number of frames in the\nrecording while maintaining smooth movement allows to improve the quality of\nplayed video sequence, enables more effective compression and creating a\nslow-motion recording. This paper proposes the FastRIFE algorithm, which is\nsome speed improvement of the RIFE (Real-Time Intermediate Flow Estimation)\nmodel. The novel method was examined and compared with other recently published\nalgorithms. All source codes are available at\nhttps://gitlab.com/malwinq/interpolation-of-images-for-slow-motion-videos",
    "descriptor": "\nComments: WSCG 2021 29. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision\n",
    "authors": [
      "Malwina Kubas",
      "Grzegorz Sarwas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13482"
  },
  {
    "id": "arXiv:2105.13484",
    "title": "High-Order Multirate Explicit Time-Stepping Schemes for the  Baroclinic-Barotropic Split Dynamics in Primitive Equations",
    "abstract": "In order to treat the multiple time scales of ocean dynamics in an efficient\nmanner, the baroclinic-barotropic splitting technique has been widely used for\nsolving the primitive equations for ocean modeling. In this paper, we propose\nsecond and third-order multirate explicit time-stepping schemes for such split\nsystems based on the strong stability-preserving Runge-Kutta (SSPRK) framework.\nOur method allows for a large time step to be used for advancing the\nthree-dimensional (slow) baroclinic mode and a small time step for the\ntwo-dimensional (fast) barotropic mode, so that each of the two mode solves\nonly need satisfy their respective CFL condition to maintain numerical\nstability. It is well known that the SSPRK method achieves high-order temporal\naccuracy by utilizing a convex combination of forward-Euler steps. At each time\nstep of our method, the baroclinic velocity is first computed by using the\nSSPRK scheme to advance the baroclinic-barotropic system with the large time\nstep, then the barotropic velocity is specially corrected by using the same\nSSPRK scheme with the small time step to advance the barotropic subsystem with\na barotropic forcing interpolated based on values from the preceding baroclinic\nsolves. Finally, the fluid thickness and the sea surface height perturbation is\nupdated by coupling the predicted baroclinic and barotropic velocities.\nTemporal truncation error analyses are also carried out for the proposed\nschemes. Two benchmark tests drawn from the -MPAS-Ocean\" platform are used to\nnumerically demonstrate the accuracy and parallel performance of the proposed\nschemes.",
    "descriptor": "",
    "authors": [
      "Rihui Lan",
      "Lili Ju",
      "Zhu Wang",
      "Max Gunzburger",
      "Philip Jones"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13484"
  },
  {
    "id": "arXiv:2105.13487",
    "title": "Multidimensional Byzantine Agreement in a Synchronous Setting",
    "abstract": "In this paper we will present the Multidimensional Byzantine Agreement (MBA)\nProtocol, a leaderless Byzantine agreement protocol defined for complete and\nsynchronous networks that allows a network of nodes to reach consensus on a\nvector of relevant information regarding a set of observed events.\nThe consensus process is carried out in parallel on each component, and the\noutput is a vector whose components are either values with wide agreement in\nthe network (even if no individual node agrees on every value) or a special\nvalue $\\bot$ that signals irreconcilable disagreement. The MBA Protocol is\nprobabilistic and its execution halts with probability 1, and the number of\nsteps necessary to halt follows a Bernoulli-like distribution.\nThe design combines a Multidimensional Graded Consensus and a\nMultidimensional Binary Byzantine Agreement, the generalization to the\nmultidimensional case of two protocols by Micali and Feldman.\nWe prove the correctness and security of the protocol assuming a synchronous\nnetwork where less than a third of the nodes are malicious.",
    "descriptor": "\nComments: 15 pages, 0 figures\n",
    "authors": [
      "Andrea Flamini",
      "Riccardo Longo",
      "Alessio Meneghetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13487"
  },
  {
    "id": "arXiv:2105.13489",
    "title": "Early Experiences Migrating CUDA codes to oneAPI",
    "abstract": "The heterogeneous computing paradigm represents a real programming challenge\ndue to the proliferation of devices with different hardware characteristics.\nRecently Intel introduced oneAPI, a new programming environment that allows\ncode developed in DPC++ to be run on different devices such as CPUs, GPUs,\nFPGAs, among others. This paper presents our first experiences in porting two\nCUDA applications to DPC++ using the oneAPI dpct tool. From the experimental\nwork, it was possible to verify that dpct does not achieve 100% of the\nmigration task; however, it performs most of the work, reporting the programmer\nof possible pending adaptations. Additionally, it was possible to verify the\nfunctional portability of the DPC++ code obtained, having successfully executed\nit on different CPU and GPU architectures.",
    "descriptor": "\nComments: Accepted for publication in 9th Conference on Cloud Computing Conference, Big Data & Emerging Topics (JCC-BD&ET 2021, this https URL)\n",
    "authors": [
      "Manuel Costanzo",
      "Enzo Rucci",
      "Carlos Garc\u00eda Sanchez",
      "Marcelo Naiouf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13489"
  },
  {
    "id": "arXiv:2105.13490",
    "title": "Integrating and validating urban simulation models",
    "abstract": "Urban systems are intrinsically complex, involving different dimensions and\nscales, and consequently various approaches and scientific disciplines. In that\ncontext, urban simulation models have been coined as essential for the\nconstruction of evidence-based and integrated urban sciences. This review and\nposition paper synthesises previous work focused on coupling and integrating\nurban models on the one hand, and exploring and validating such simulation\nmodels on the other hand. These research directions are complementary basis for\na research program towards the development of integrated urban theories, with\nsome application perspectives to sustainable territorial planning.",
    "descriptor": "\nComments: 12 pages, French Regional Conference on Complex Systems 2021\n",
    "authors": [
      "Juste Raimbault"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13490"
  },
  {
    "id": "arXiv:2105.13491",
    "title": "Resilient and Adaptive Framework for Large Scale Android Malware  Fingerprinting using Deep Learning and NLP Techniques",
    "abstract": "Android malware detection is a significat problem that affects billions of\nusers using millions of Android applications (apps) in existing markets. This\npaper proposes PetaDroid, a framework for accurate Android malware detection\nand family clustering on top of static analyses. PetaDroid automatically adapts\nto Android malware and benign changes over time with resilience to common\nbinary obfuscation techniques. The framework employs novel techniques\nelaborated on top of natural language processing (NLP) and machine learning\ntechniques to achieve accurate, adaptive, and resilient Android malware\ndetection and family clustering. PetaDroid identifies malware using an ensemble\nof convolutional neural network (CNN) on proposed Inst2Vec features. The\nframework clusters the detected malware samples into malware family groups\nutilizing sample feature digests generated using deep neural auto-encoder. For\nchange adaptation, PetaDroid leverages the detection confidence probability\nduring deployment to automatically collect extension datasets and periodically\nuse them to build new malware detection models. Besides, PetaDroid uses\ncode-fragment randomization during the training to enhance the resiliency to\ncommon obfuscation techniques. We extensively evaluated PetaDroid on multiple\nreference datasets. PetaDroid achieved a high detection rate (98-99% f1-score)\nunder different evaluation settings with high homogeneity in the produced\nclusters (96%). We conducted a thorough quantitative comparison with\nstate-of-the-art solutions MaMaDroid, DroidAPIMiner, MalDozer, in which\nPetaDroid outperforms them under all the evaluation settings.",
    "descriptor": "",
    "authors": [
      "ElMouatez Billah Karbab",
      "Mourad Debbabi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13491"
  },
  {
    "id": "arXiv:2105.13493",
    "title": "Efficient and Accurate Gradients for Neural SDEs",
    "abstract": "Neural SDEs combine many of the best qualities of both RNNs and SDEs, and as\nsuch are a natural choice for modelling many types of temporal dynamics. They\noffer memory efficiency, high-capacity function approximation, and strong\npriors on model space. Neural SDEs may be trained as VAEs or as GANs; in either\ncase it is necessary to backpropagate through the SDE solve. In particular this\nmay be done by constructing a backwards-in-time SDE whose solution is the\ndesired parameter gradients. However, this has previously suffered from severe\nspeed and accuracy issues, due to high computational complexity, numerical\nerrors in the SDE solve, and the cost of reconstructing Brownian motion. Here,\nwe make several technical innovations to overcome these issues. First, we\nintroduce the reversible Heun method: a new SDE solver that is algebraically\nreversible -- which reduces numerical gradient errors to almost zero, improving\nseveral test metrics by substantial margins over state-of-the-art. Moreover it\nrequires half as many function evaluations as comparable solvers, giving up to\na $1.98\\times$ speedup. Next, we introduce the Brownian interval. This is a new\nand computationally efficient way of exactly sampling and reconstructing\nBrownian motion; this is in contrast to previous reconstruction techniques that\nare both approximate and relatively slow. This gives up to a $10.6\\times$ speed\nimprovement over previous techniques. After that, when specifically training\nNeural SDEs as GANs (Kidger et al. 2021), we demonstrate how SDE-GANs may be\ntrained through careful weight clipping and choice of activation function. This\nreduces computational cost (giving up to a $1.87\\times$ speedup), and removes\nthe truncation errors of the double adjoint required for gradient penalty,\nsubstantially improving several test metrics. Altogether these techniques offer\nsubstantial improvements over the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Patrick Kidger",
      "James Foster",
      "Xuechen Li",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13493"
  },
  {
    "id": "arXiv:2105.13495",
    "title": "Learning Dynamic Graph Representation of Brain Connectome with  Spatio-Temporal Attention",
    "abstract": "Functional connectivity (FC) between regions of the brain can be assessed by\nthe degree of temporal correlation measured with functional neuroimaging\nmodalities. Based on the fact that these connectivities build a network,\ngraph-based approaches for analyzing the brain connectome have provided\ninsights into the functions of the human brain. The development of graph neural\nnetworks (GNNs) capable of learning representation from graph structured data\nhas led to increased interest in learning the graph representation of the brain\nconnectome. Although recent attempts to apply GNN to the FC network have shown\npromising results, there is still a common limitation that they usually do not\nincorporate the dynamic characteristics of the FC network which fluctuates over\ntime. In addition, a few studies that have attempted to use dynamic FC as an\ninput for the GNN reported a reduction in performance compared to static FC\nmethods, and did not provide temporal explainability. Here, we propose STAGIN,\na method for learning dynamic graph representation of the brain connectome with\nspatio-temporal attention. Specifically, a temporal sequence of brain graphs is\ninput to the STAGIN to obtain the dynamic graph representation, while novel\nREADOUT functions and the Transformer encoder provide spatial and temporal\nexplainability with attention, respectively. Experiments on the HCP-Rest and\nthe HCP-Task datasets demonstrate exceptional performance of our proposed\nmethod. Analysis of the spatio-temporal attention also provide concurrent\ninterpretation with the neuroscientific knowledge, which further validates our\nmethod. Code is available at https://github.com/egyptdj/stagin",
    "descriptor": "",
    "authors": [
      "Byung-Hoon Kim",
      "Jong Chul Ye",
      "Jae-Jin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2105.13495"
  },
  {
    "id": "arXiv:2105.13496",
    "title": "Diagnosing Transformers in Task-Oriented Semantic Parsing",
    "abstract": "Modern task-oriented semantic parsing approaches typically use seq2seq\ntransformers to map textual utterances to semantic frames comprised of intents\nand slots. While these models are empirically strong, their specific strengths\nand weaknesses have largely remained unexplored. In this work, we study BART\nand XLM-R, two state-of-the-art parsers, across both monolingual and\nmultilingual settings. Our experiments yield several key results:\ntransformer-based parsers struggle not only with disambiguating intents/slots,\nbut surprisingly also with producing syntactically-valid frames. Though\npre-training imbues transformers with syntactic inductive biases, we find the\nambiguity of copying utterance spans into frames often leads to tree\ninvalidity, indicating span extraction is a major bottleneck for current\nparsers. However, as a silver lining, we show transformer-based parsers give\nsufficient indicators for whether a frame is likely to be correct or incorrect,\nmaking them easier to deploy in production settings.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021\n",
    "authors": [
      "Shrey Desai",
      "Ahmed Aly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13496"
  },
  {
    "id": "arXiv:2105.13497",
    "title": "Branching Dueling Q-Network Based Online Scheduling of a Microgrid With  Distributed Energy Storage Systems",
    "abstract": "This letter investigates a Branching Dueling Q-Network (BDQ) based online\noperation strategy for a microgrid with distributed battery energy storage\nsystems (BESSs) operating under uncertainties. The developed deep reinforcement\nlearning (DRL) based microgrid online optimization strategy can achieve a\nlinear increase in the number of neural network outputs with the number of\ndistributed BESSs, which overcomes the curse of dimensionality caused by the\ncharge and discharge decisions of multiple BESSs. Numerical simulations\nvalidate the effectiveness of the proposed method.",
    "descriptor": "\nComments: Submitted to IEEE Journal and under review, 4 pages, 3 figures\n",
    "authors": [
      "Hang Shuai",
      "Fangxing",
      "Hector Pulgar-Painemal",
      "Yaosuo Xue"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13497"
  },
  {
    "id": "arXiv:2105.13500",
    "title": "An Analysis of Amazon Echo's Network Behavior",
    "abstract": "With over 20 million units sold since 2015, Amazon Echo, the Alexa-enabled\nsmart speaker developed by Amazon, is probably one of the most widely deployed\nInternet of Things consumer devices. Despite the very large installed base,\nsurprisingly little is known about the device's network behavior. We modify a\nfirst generation Echo device, decrypt its communication with Amazon cloud, and\nanalyze the device pairing, Alexa Voice Service, and drop-in calling protocols.\nWe also describe our methodology and the experimental setup. We find a minor\nshortcoming in the device pairing protocol and learn that drop-in calls are\nend-to-end encrypted and based on modern open standards. Overall, we find the\nEcho to be a well-designed device from the network communication perspective.",
    "descriptor": "",
    "authors": [
      "Jan Janak",
      "Teresa Tseng",
      "Aliza Isaacs",
      "Henning Schulzrinne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13500"
  },
  {
    "id": "arXiv:2105.13502",
    "title": "Unsupervised Domain Adaption of Object Detectors: A Survey",
    "abstract": "Recent advances in deep learning have led to the development of accurate and\nefficient models for various computer vision applications such as object\nclassification, semantic segmentation, and object detection. However, learning\nhighly accurate models relies on the availability of datasets with a large\nnumber of annotated images. Due to this, model performance drops drastically\nwhen evaluated on label-scarce datasets having visually distinct images. This\nissue is commonly referred to as covariate shift or dataset bias. Domain\nadaptation attempts to address this problem by leveraging domain shift\ncharacteristics from labeled data in a related domain when learning a\nclassifier for label-scarce target dataset. There are a plethora of works to\nadapt object classification and semantic segmentation models to label-scarce\ntarget dataset through unsupervised domain adaptation. Considering that object\ndetection is a fundamental task in computer vision, many recent works have\nrecently focused on addressing the domain adaptation issue for object detection\nas well. In this paper, we provide a brief introduction to the domain\nadaptation problem for object detection and present an overview of various\nmethods proposed to date for addressing this problem. Furthermore, we highlight\nstrategies proposed for this problem and the associated shortcomings.\nSubsequently, we identify multiple aspects of the unsupervised domain adaptive\ndetection problem that are most promising for future research in the area. We\nbelieve that this survey shall be valuable to the pattern recognition experts\nworking in the fields of computer vision, biometrics, medical imaging, and\nautonomous navigation by introducing them to the problem, getting them familiar\nwith the current status of the progress, and providing them with promising\ndirection for future research.",
    "descriptor": "",
    "authors": [
      "Poojan Oza",
      "Vishwanath A. Sindagi",
      "Vibashan VS",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13502"
  },
  {
    "id": "arXiv:2105.13503",
    "title": "Wireless for Control: Over-the-Air Controller",
    "abstract": "In closed-loop wireless control systems, the state-of-the-art approach\nprescribes that a controller receives by wireless communications the individual\nsensor measurements, and then sends the computed control signal to the\nactuators. We propose an over-the-air controller scheme where all sensors\nattached to the plant simultaneously transmit scaled sensing signals directly\nto the actuator; then the feedback control signal is computed partially over\nthe air and partially by a scaling operation at the actuator. Such over-the-air\ncontroller essentially adopts the over-the-air computation concept to compute\nthe control signal for closed-loop wireless control systems. In contrast to the\nstate-of-the-art sensor-to-controller and controller-to-actuator communication\napproach, the over-the-air controller exploits the superposition properties of\nmultiple-access wireless channels to complete the communication and computation\nof a large number of sensing signals in a single communication resource unit.\nTherefore, the proposed scheme can obtain significant benefits in terms of low\nactuation delay and low wireless resource utilization by a simple network\narchitecture that does not require a dedicated controller. Numerical results\nshow that our proposed over-the-air controller achieves a huge widening of the\nstability region in terms of sampling time and delay, and a significant\nreduction of the computation error of the control signal.",
    "descriptor": "",
    "authors": [
      "Pangun Park",
      "Piergiuseppe Di Marco",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13503"
  },
  {
    "id": "arXiv:2105.13506",
    "title": "Airflow-Inertial Odometry for Resilient State Estimation on Multirotors",
    "abstract": "We present a dead reckoning strategy for increased resilience to position\nestimation failures on multirotors, using only data from a low-cost IMU and\nnovel, bio-inspired airflow sensors. The goal is challenging, since low-cost\nIMUs are subject to large noise and drift, while 3D airflow sensing is made\ndifficult by the interference caused by the propellers and by the wind. Our\napproach relies on a deep-learning strategy to interpret the measurements of\nthe bio-inspired sensors, a map of the wind speed to compensate for\nposition-dependent wind, and a filter to fuse the information and generate a\npose and velocity estimate. Our results show that the approach reduces the\ndrift with respect to IMU-only dead reckoning by up to an order of magnitude\nover 30 seconds after a position sensor failure in non-windy environments, and\nit can compensate for the challenging effects of turbulent, and spatially\nvarying wind.",
    "descriptor": "\nComments: Accepted to the 2021 International Conference on Robotics and Automation (ICRA 2021). Contains minor updates in Fig. 2 and Section IV.b, VII.E, VII.F\n",
    "authors": [
      "Andrea Tagliabue",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13506"
  },
  {
    "id": "arXiv:2105.13509",
    "title": "Learning to Stylize Novel Views",
    "abstract": "We tackle a 3D scene stylization problem - generating stylized images of a\nscene from arbitrary novel views given a set of images of the same scene and a\nreference image of the desired style as inputs. Direct solution of combining\nnovel view synthesis and stylization approaches lead to results that are blurry\nor not consistent across different views. We propose a point cloud-based method\nfor consistent 3D scene stylization. First, we construct the point cloud by\nback-projecting the image features to the 3D space. Second, we develop point\ncloud aggregation modules to gather the style information of the 3D scene, and\nthen modulate the features in the point cloud with a linear transformation\nmatrix. Finally, we project the transformed features to 2D space to obtain the\nnovel views. Experimental results on two diverse datasets of real-world scenes\nvalidate that our method generates consistent stylized novel view synthesis\nresults against other alternative approaches.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Hsin-Ping Huang",
      "Hung-Yu Tseng",
      "Saurabh Saini",
      "Maneesh Singh",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13509"
  },
  {
    "id": "arXiv:2105.13510",
    "title": "A Note on Optimal Fees for Constant Function Market Makers",
    "abstract": "We suggest a framework to determine optimal trading fees for constant\nfunction market makers (CFMMs) in order to maximize liquidity provider returns.\nIn a setting of multiple competing liquidity pools, we show that no race to the\nbottom occurs, but instead pure Nash equilibria of optimal fees exist. We\ntheoretically prove the existence of these equilibria for pools using the\nconstant product trade function used in popular CFMMs like Uniswap. We also\nnumerically compute the equilibria for a number of examples and discuss the\neffects the equilibrium fees have on capital allocation among pools. Finally,\nwe use our framework to compute optimal fees for real world pools using past\ntrade data.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Robin Fritsch",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.13510"
  },
  {
    "id": "arXiv:2105.13512",
    "title": "Lower Bounds on the Low-Distortion Embedding Dimension of Submanifolds  of $\\mathbb{R}^n$",
    "abstract": "Let $\\mathcal{M}$ be a smooth submanifold of $\\mathbb{R}^n$ equipped with the\nEuclidean (chordal) metric. This note considers the smallest dimension $m$ for\nwhich there exists a bi-Lipschitz function $f: \\mathcal{M} \\mapsto\n\\mathbb{R}^m$ with bi-Lipschitz constants close to one. The main result bounds\nthe embedding dimension $m$ below in terms of the bi-Lipschitz constants of $f$\nand the reach, volume, diameter, and dimension of $\\mathcal{M}$. This new lower\nbound is applied to show that prior upper bounds by Eftekhari and Wakin\n(arXiv:1306.4748) on the minimal low-distortion embedding dimension of such\nmanifolds using random matrices achieve near-optimal dependence on both reach\nand volume. This supports random linear maps as being nearly as efficient as\nthe best possible nonlinear maps at reducing the ambient dimension for manifold\ndata. In the process of proving our main result, we also prove similar results\nconcerning the impossibility of achieving better nonlinear measurement maps\nwith the Restricted Isometry Property (RIP) in compressive sensing\napplications.",
    "descriptor": "",
    "authors": [
      "Mark Iwen",
      "Arman Tavakoli",
      "Benjamin Schmidt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13512"
  },
  {
    "id": "arXiv:2105.13514",
    "title": "Stochastic Intervention for Causal Inference via Reinforcement Learning",
    "abstract": "Causal inference methods are widely applied in various decision-making\ndomains such as precision medicine, optimal policy and economics. Central to\ncausal inference is the treatment effect estimation of intervention strategies,\nsuch as changes in drug dosing and increases in financial aid. Existing methods\nare mostly restricted to the deterministic treatment and compare outcomes under\ndifferent treatments. However, they are unable to address the substantial\nrecent interest of treatment effect estimation under stochastic treatment,\ne.g., \"how all units health status change if they adopt 50\\% dose reduction\".\nIn other words, they lack the capability of providing fine-grained treatment\neffect estimation to support sound decision-making. In our study, we advance\nthe causal inference research by proposing a new effective framework to\nestimate the treatment effect on stochastic intervention. Particularly, we\ndevelop a stochastic intervention effect estimator (SIE) based on nonparametric\ninfluence function, with the theoretical guarantees of robustness and fast\nconvergence rates. Additionally, we construct a customised reinforcement\nlearning algorithm based on the random search solver which can effectively find\nthe optimal policy to produce the greatest expected outcomes for the\ndecision-making process. Finally, we conduct an empirical study to justify that\nour framework can achieve significant performance in comparison with\nstate-of-the-art baselines.",
    "descriptor": "\nComments: Under review for Neurocomputiong. arXiv admin note: substantial text overlap with arXiv:2105.12898\n",
    "authors": [
      "Tri Dung Duong",
      "Qian Li",
      "Guandong Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13514"
  },
  {
    "id": "arXiv:2105.13515",
    "title": "Vaccine Credential Technology Principles",
    "abstract": "The historically rapid development of effective COVID-19 vaccines has\npolicymakers facing evergreen public health questions regarding vaccination\nrecords and verification. Governments and institutions around the world are\nalready taking action on digital vaccine certificates, including guidance and\nrecommendations from the European Commission, the WHO, and the Biden\nAdministration. These could be encouraging efforts: an effective system for\nvaccine certificates could potentially be part of a safe return to work,\ntravel, and daily life, and a secure technological implementation could improve\non existing systems to prioritize privacy, streamline access, and build for\nnecessary interoperability across countries and contexts. However, vaccine\ncredentials are not without potential harms, and, particularly given major\ninequities in vaccine access and rollout, there are valid concerns that they\nmay be used in ineffective or exclusionary ways that exacerbate inequality,\nallow for discrimination, violate privacy, and assume consent. While the\npresent moment calls for urgency, we must also acknowledge that choices made in\nthe vaccine credentialing rollout for COVID-19 are likely to have long-term\nimplications, and must be made with care. In this paper, we outline potential\nimplementation and ethical concerns that may arise from tech-enabled vaccine\ncredentialing programs now and in the future, and discuss the technological\ntradeoffs implicated in these concerns. We suggest a set of principles that, if\nadopted, may mitigate these concerns, forestall preventable harms, and point\nthe way forward; the paper is structured as a deep dive into each of these\nprinciples.",
    "descriptor": "",
    "authors": [
      "Divya Siddarth",
      "Vi Hart",
      "Bethan Cantrell",
      "Kristina Yasuda",
      "Josh Mandel",
      "Karen Easterbrook"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.13515"
  },
  {
    "id": "arXiv:2105.13524",
    "title": "Improving Generalization in Meta-RL with Imaginary Tasks from Latent  Dynamics Mixture",
    "abstract": "The generalization ability of most meta-reinforcement learning (meta-RL)\nmethods is largely limited to test tasks that are sampled from the same\ndistribution used to sample training tasks. To overcome the limitation, we\npropose Latent Dynamics Mixture (LDM) that trains a reinforcement learning\nagent with imaginary tasks generated from mixtures of learned latent dynamics.\nBy training a policy on mixture tasks along with original training tasks, LDM\nallows the agent to prepare for unseen test tasks during training and prevents\nthe agent from overfitting the training tasks. LDM significantly outperforms\nstandard meta-RL methods in test returns on the gridworld navigation and MuJoCo\ntasks where we strictly separate the training task distribution and the test\ntask distribution.",
    "descriptor": "",
    "authors": [
      "Suyoung Lee",
      "Sae-Young Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13524"
  },
  {
    "id": "arXiv:2105.13527",
    "title": "Feedback Linearization for Quadrotors with a Learned Acceleration Error  Model",
    "abstract": "This paper enhances the feedback linearization controller for multirotors\nwith a learned acceleration error model and a thrust input delay mitigation\nmodel. Feedback linearization controllers are theoretically appealing but their\nperformance suffers on real systems, where the true system does not match the\nknown system model. We take a step in reducing these robustness issues by\nlearning an acceleration error model, applying this model in the position\ncontroller, and further propagating it forward to the attitude controller. We\nshow how this approach improves performance over the standard feedback\nlinearization controller in the presence of unmodeled dynamics and repeatable\nexternal disturbances in both simulation and hardware experiments. We also show\nthat our thrust control input delay model improves the step response on\nhardware systems.",
    "descriptor": "\nComments: Accepted at ICRA 2021\n",
    "authors": [
      "Alexander Spitzer",
      "Nathan Michael"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13527"
  },
  {
    "id": "arXiv:2105.13530",
    "title": "A BIC based Mixture Model Defense against Data Poisoning Attacks on  Classifiers",
    "abstract": "Data Poisoning (DP) is an effective attack that causes trained classifiers to\nmisclassify their inputs.DP attacks significantly degrade a classifier's\naccuracy by covertly injecting attack samples into the training set. Broadly\napplicable to different classifier structures, without strong assumptions about\nthe attacker, we herein propose a novel Bayesian Information Criterion\n(BIC)-based mixture model defense against DP attacks that: 1) applies a mixture\nmodel both to well-fit potentially multi-modal class distributions and to\ncapture adversarial samples within a small subset of mixture components; 2)\njointly identifies poisoned components and samples by minimizing the BIC cost\nover all classes, with the identified poisoned data removed prior to classifier\ntraining. Our experimental results, for various classifier structures,\ndemonstrate the effectiveness and universality of our defense under strong DP\nattacks, as well as the superiority over other works.",
    "descriptor": "",
    "authors": [
      "Xi Li",
      "David J. Miller",
      "Zhen Xiang",
      "George Kesidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13530"
  },
  {
    "id": "arXiv:2105.13531",
    "title": "Empirical Study of Multi-Task Hourglass Model for Semantic Segmentation  Task",
    "abstract": "The semantic segmentation (SS) task aims to create a dense classification by\nlabeling at the pixel level each object present on images. Convolutional neural\nnetwork (CNN) approaches have been widely used, and exhibited the best results\nin this task. However, the loss of spatial precision on the results is a main\ndrawback that has not been solved. In this work, we propose to use a multi-task\napproach by complementing the semantic segmentation task with edge detection,\nsemantic contour, and distance transform tasks. We propose that by sharing a\ncommon latent space, the complementary tasks can produce more robust\nrepresentations that can enhance the semantic labels. We explore the influence\nof contour-based tasks on latent space, as well as their impact on the final\nresults of SS. We demonstrate the effectiveness of learning in a multi-task\nsetting for hourglass models in the Cityscapes, CamVid, and Freiburg Forest\ndatasets by improving the state-of-the-art without any refinement\npost-processing.",
    "descriptor": "\nComments: To appear in IEEE Access. Code available at this https URL\n",
    "authors": [
      "Darwin Saire",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13531"
  },
  {
    "id": "arXiv:2105.13533",
    "title": "Inertial Sensor Data To Image Encoding For Human Action Recognition",
    "abstract": "Convolutional Neural Networks (CNNs) are successful deep learning models in\nthe field of computer vision. To get the maximum advantage of CNN model for\nHuman Action Recognition (HAR) using inertial sensor data, in this paper, we\nuse 4 types of spatial domain methods for transforming inertial sensor data to\nactivity images, which are then utilized in a novel fusion framework. These\nfour types of activity images are Signal Images (SI), Gramian Angular Field\n(GAF) Images, Markov Transition Field (MTF) Images and Recurrence Plot (RP)\nImages. Furthermore, for creating a multimodal fusion framework and to exploit\nactivity image, we made each type of activity images multimodal by convolving\nwith two spatial domain filters : Prewitt filter and High-boost filter.\nResnet-18, a CNN model, is used to learn deep features from multi-modalities.\nLearned features are extracted from the last pooling layer of each ReNet and\nthen fused by canonical correlation based fusion (CCF) for improving the\naccuracy of human action recognition. These highly informative features are\nserved as input to a multiclass Support Vector Machine (SVM). Experimental\nresults on three publicly available inertial datasets show the superiority of\nthe proposed method over the current state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Zeeshan Ahmad",
      "Naimul Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.13533"
  },
  {
    "id": "arXiv:2105.13534",
    "title": "Essential System Services in Grids Dominated by Renewable Energy",
    "abstract": "As the proportion of variable inverter-based renewable energy generation in\nelectricity systems increases from a minority to the majority of total supply,\nthe complexity and cost of providing ancillary system services increases in\nparallel. Australia is experiencing this shift now - from having the third most\ncarbon-intensive electricity sector in the world in 2010, to now having\npenetrations of variable renewable energy (VRE) regularly reaching 100 percent\nin some regions, with world-leading uptake of distributed energy resources\n(DER). This paper presents pioneering work exploring new technical, economic\nand regulatory frameworks for the provision of Essential System Services (ESS),\nalso known as ancillary services, in power systems dominated by variable\ninverter-based renewable energy resources. We explore the recent application of\nthe concept of demand curves and nomograms to the procurement of ESS, and\nemerging design principles for frameworks in facilitating the evolution from\ndefault provision of system services by synchronous generation, to\nco-optimisation of services through unit commitment, to independent provision\nof services through inverter based resources. The paper also analyses the\nrecent technical and financial success of the world's largest battery, the\nHornsdale Power Reserve in South Australia, and its ability to inform how\nfuture electricity market frameworks may incentivize and accommodate new\ntechnological capability, both first and Nth of a kind systems. Finally, the\npaper reviews emerging energy system technological capability, including the\nprovision of synthetic inertia and RoCoF control, grid-forming inverters, and\nadvanced DER aggregation in providing ESS and system restart capability for\nsecure, resilient and island-able grids.",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Niraj Lal",
      "Toby Price",
      "Leon Kwek",
      "Christopher Wilson",
      "Farhad Billimoria",
      "Trent Morrow",
      "Matt Garbutt",
      "Dean Sharafi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13534"
  },
  {
    "id": "arXiv:2105.13538",
    "title": "Two-level overlapping Schwarz methods based on local generalized  eigenproblems for Hermitian variational problems",
    "abstract": "The research of two-level overlapping Schwarz (TL-OS) method based on\nconstrained energy minimizing coarse space is still in its infancy, and there\nexist some defects, e.g. mainly for Poisson-like problems and too heavy\ncomputational cost of coarse space construction. In this paper, by introducing\nappropriate assumptions, we propose more concise coarse basis functions for\ngeneral Hermitian positive and definite discrete systems, and establish the\ncorresponding TL-OS preconditioned algorithmic and theoretical frameworks.\nFurthermore, to enhance the practicability of the algorithm, we design two\neconomical TL-OS preconditioners and prove that the condition number is robust\nwith respect to the model and mesh parameters. As the first application of the\nframeworks, we prove that the assumptions hold for the linear finite element\ndiscretization of Poisson problem with high contrast and oscillatory\ncoefficient. In particular, we also prove that the condition number of the\neconomically preconditioned system is independent of the jump range under a\ncertain jump distribution. Experimental results show that the first kind of\neconomical preconditioner is more efficient and stable than the existed one.\nSecondly, we construct TL-OS and the economical TL-OS preconditioners for the\nplane wave least squares discrete system of Helmholtz equation by using the\nframeworks. The numerical results for homogeneous and non-homogeneous cases\nillustrate that the PCG method based on the proposed preconditioners have good\nstability in terms of the angular frequency, mesh parameters and the number of\nfreedoms in each element.",
    "descriptor": "",
    "authors": [
      "Qing Lu",
      "Junxian Wang",
      "Shi Shu",
      "Jie Peng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13538"
  },
  {
    "id": "arXiv:2105.13553",
    "title": "Autonomous Optimization of Fluid Systems at Varying Length Scales",
    "abstract": "Autonomous optimization is a process by which hardware conditions are\ndiscovered that generate an optimized experimental product without the guidance\nof a domain expert. We design an autonomous optimization framework to discover\nthe experimental conditions within fluid systems that generate discrete and\nuniform droplet patterns. Generating discrete and uniform droplets requires\nhigh-precision control over the experimental conditions of a fluid system.\nFluid stream instabilities, such as Rayleigh-Plateau instability and capillary\ninstability, drive the separation of a flow into individual droplets. However,\nbecause this phenomenon leverages an instability, by nature the hardware must\nbe precisely tuned to achieve uniform, repeatable droplets. Typically this\nrequires a domain expert in the loop and constant re-tuning depending on the\nhardware configuration and liquid precursor selection. Herein, we propose a\ncomputer vision-driven Bayesian optimization framework to discover the precise\nhardware conditions that generate uniform, reproducible droplets with the\ndesired features, leveraging flow instability without a domain expert in the\nloop. This framework is validated on two fluid systems, at the micrometer and\nmillimeter length scales, using microfluidic and inkjet systems, respectively,\nindicating the application breadth of this approach.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Alexander E. Siemenn",
      "Evyatar Shaulsky",
      "Matthew Beveridge",
      "Tonio Buonassisi",
      "Sara M. Hashmi",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2105.13553"
  },
  {
    "id": "arXiv:2105.13556",
    "title": "Blending Advertising with Organic Content in E-Commerce: A Virtual Bids  Optimization Approach",
    "abstract": "In e-commerce platforms, sponsored and non-sponsored content are jointly\ndisplayed to users and both may interactively influence their engagement\nbehavior. The former content helps advertisers achieve their marketing goals\nand provides a stream of ad revenue to the platform. The latter content\ncontributes to users' engagement with the platform, which is key to its\nlong-term health. A burning issue for e-commerce platform design is how to\nblend advertising with content in a way that respects these interactions and\nbalances these multiple business objectives. This paper describes a system\ndeveloped for this purpose in the context of blending personalized sponsored\ncontent with non-sponsored content on the product detail pages of JD.COM, an\ne-commerce company. This system has three key features: (1) Optimization of\nmultiple competing business objectives through a new virtual bids approach and\nthe expressiveness of the latent, implicit valuation of the platform for the\nmultiple objectives via these virtual bids. (2) Modeling of users' click\nbehavior as a function of their characteristics, the individual characteristics\nof each sponsored content and the influence exerted by other sponsored and\nnon-sponsored content displayed alongside through a deep learning approach; (3)\nConsideration of externalities in the allocation of ads, thereby making it\ndirectly compatible with a Vickrey-Clarke-Groves (VCG) auction scheme for the\ncomputation of payments in the presence of these externalities. The system is\ncurrently deployed and serving all traffic through JD.COM's mobile application.\nExperiments demonstrating the performance and advantages of the system are\npresented.",
    "descriptor": "",
    "authors": [
      "Carlos Carrion",
      "Zenan Wang",
      "Harikesh Nair",
      "Xianghong Luo",
      "Yulin Lei",
      "Xiliang Lin",
      "Wenlong Chen",
      "Qiyu Hu",
      "Changping Peng",
      "Yongjun Bao",
      "Weipeng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2105.13556"
  },
  {
    "id": "arXiv:2105.13557",
    "title": "Self-supervised Detransformation Autoencoder for Representation Learning  in Open Set Recognition",
    "abstract": "The objective of Open set recognition (OSR) is to learn a classifier that can\nreject the unknown samples while classifying the known classes accurately. In\nthis paper, we propose a self-supervision method, Detransformation Autoencoder\n(DTAE), for the OSR problem. This proposed method engages in learning\nrepresentations that are invariant to the transformations of the input data.\nExperiments on several standard image datasets indicate that the pre-training\nprocess significantly improves the model performance in the OSR tasks.\nMeanwhile, our proposed self-supervision method achieves significant gains in\ndetecting the unknown class and classifying the known classes. Moreover, our\nanalysis indicates that DTAE can yield representations that contain more target\nclass information and less transformation information than RotNet.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.15117\n",
    "authors": [
      "Jingyun Jia",
      "Philip K. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13557"
  },
  {
    "id": "arXiv:2105.13559",
    "title": "One-shot Learning with Absolute Generalization",
    "abstract": "One-shot learning is proposed to make a pretrained classifier workable on a\nnew dataset based on one labeled samples from each pattern. However, few of\nresearchers consider whether the dataset itself supports one-shot learning. In\nthis paper, we propose a set of definitions to explain what kind of datasets\ncan support one-shot learning and propose the concept \"absolute\ngeneralization\". Based on these definitions, we proposed a method to build an\nabsolutely generalizable classifier. The proposed method concatenates two\nsamples as a new single sample, and converts a classification problem to an\nidentity identification problem or a similarity metric problem. Experiments\ndemonstrate that the proposed method is superior to baseline on one-shot\nlearning datasets and artificial datasets.",
    "descriptor": "\nComments: 8 pages, 41 figures\n",
    "authors": [
      "Hao Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13559"
  },
  {
    "id": "arXiv:2105.13562",
    "title": "ILDC for CJPE: Indian Legal Documents Corpus for Court  JudgmentPrediction and Explanation",
    "abstract": "An automated system that could assist a judge in predicting the outcome of a\ncase would help expedite the judicial process. For such a system to be\npractically useful, predictions by the system should be explainable. To promote\nresearch in developing such a system, we introduce ILDC (Indian Legal Documents\nCorpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated\nwith original court decisions. A portion of the corpus (a separate test set) is\nannotated with gold standard explanations by legal experts. Based on ILDC, we\npropose the task of Court Judgment Prediction and Explanation (CJPE). The task\nrequires an automated system to predict an explainable outcome of a case. We\nexperiment with a battery of baseline models for case predictions and propose a\nhierarchical occlusion based model for explainability. Our best prediction\nmodel has an accuracy of 78% versus 94% for human legal experts, pointing\ntowards the complexity of the prediction task. The analysis of explanations by\nthe proposed algorithm reveals a significant difference in the point of view of\nthe algorithm and legal experts for explaining the judgments, pointing towards\nscope for future research.",
    "descriptor": "\nComments: Accepted at ACL 2021, 17 Pages (9 Pages main paper, 4 pages references, 4 pages appendix)\n",
    "authors": [
      "Vijit Malik",
      "Rishabh Sanjay",
      "Shubham Kumar Nigam",
      "Kripa Ghosh",
      "Shouvik Kumar Guha",
      "Arnab Bhattacharya",
      "Ashutosh Modi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13562"
  },
  {
    "id": "arXiv:2105.13563",
    "title": "Towards the statistical construction of hybrid development methods",
    "abstract": "Hardly any software development process is used as prescribed by authors or\nstandards. Regardless of company size or industry sector, a majority of project\nteams and companies use hybrid development methods (short: hybrid methods) that\ncombine different development methods and practices. Even though such hybrid\nmethods are highly individualized, a common understanding of how to\nsystematically construct synergetic practices is missing. In this article, we\nmake a first step towards a statistical construction procedure for hybrid\nmethods. Grounded in 1467 data points from a large-scale practitioner survey,\nwe study the question: What are hybrid methods made of and how can they be\nsystematically constructed? Our findings show that only eight methods and few\npractices build the core of modern software development. Using an 85% agreement\nlevel in the participants' selections, we provide examples illustrating how\nhybrid methods can be characterized by the practices they are made of.\nFurthermore, using this characterization, we develop an initial construction\nprocedure, which allows for defining a method frame and enriching it\nincrementally to devise a hybrid method using ranked sets of practice.",
    "descriptor": "\nComments: Journal paper, 16 pages 9 figures, 5 tables. arXiv admin note: substantial text overlap with arXiv:2101.08016\n",
    "authors": [
      "Paolo Tell",
      "Jil Kl\u00fcnder",
      "Steffen K\u00fcpper",
      "David Raffo",
      "Stephen MacDonell",
      "J\u00fcrgen M\u00fcnch",
      "Dietmar Pfahl",
      "Oliver Linssen",
      "Marco Kuhrmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13563"
  },
  {
    "id": "arXiv:2105.13569",
    "title": "Lagrangian Data Assimilation and Uncertainty Quantification for Sea Ice  Floes with an Efficient Physics-Constrained Superfloe Parameterization",
    "abstract": "The discrete element method (DEM) is providing a new modeling approach for\ndescribing sea ice dynamics. It exploits particle-based methods to characterize\nthe physical quantities of each sea ice floe along its trajectory under\nLagrangian coordinates. One major challenge in applying the DEM models is the\nheavy computational cost when the number of the floes becomes large. In this\npaper, an efficient Lagrangian parameterization algorithm is developed, which\naims at reducing the computational cost of simulating the DEM models while\npreserving the key features of the sea ice. The new parameterization takes\nadvantage of a small number of artificial ice floes, named the superfloes, to\neffectively approximate a considerable number of the floes, where the\nparameterization scheme satisfies several important physics constraints. The\nphysics constraints guarantee the superfloe parameterized system will have\nsimilar short-term dynamical behavior as the full system. These constraints\nalso allow the superfloe parameterized system to accurately quantify the\nlong-range uncertainty, especially the non-Gaussian statistical features, of\nthe full system. In addition, the superfloe parameterization facilitates a\nsystematic noise inflation strategy that significantly advances an ensemble\nbased data assimilation algorithm for recovering the unobserved ocean field\nunderneath the sea ice. Such a new noise inflation method avoids ad hoc tunings\nas in many traditional algorithms and is computationally extremely efficient.\nNumerical experiments based on an idealized DEM model with multiscale features\nillustrate the success of the superfloe parameterization in quantifying the\nuncertainty and assimilating both the sea ice and the associated ocean field.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Nan Chen",
      "Quanling Deng",
      "Samuel N. Stechmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.13569"
  },
  {
    "id": "arXiv:2105.13573",
    "title": "Investigating Code-Mixed Modern Standard Arabic-Egyptian to English  Machine Translation",
    "abstract": "Recent progress in neural machine translation (NMT) has made it possible to\ntranslate successfully between monolingual language pairs where large parallel\ndata exist, with pre-trained models improving performance even further.\nAlthough there exists work on translating in code-mixed settings (where one of\nthe pairs includes text from two or more languages), it is still unclear what\nrecent success in NMT and language modeling exactly means for translating\ncode-mixed text. We investigate one such context, namely MT from code-mixed\nModern Standard Arabic and Egyptian Arabic (MSAEA) into English. We develop\nmodels under different conditions, employing both (i) standard end-to-end\nsequence-to-sequence (S2S) Transformers trained from scratch and (ii)\npre-trained S2S language models (LMs). We are able to acquire reasonable\nperformance using only MSA-EN parallel data with S2S models trained from\nscratch. We also find LMs fine-tuned on data from various Arabic dialects to\nhelp the MSAEA-EN task. Our work is in the context of the Shared Task on\nMachine Translation in Code-Switching. Our best model achieves $\\bf25.72$ BLEU,\nplacing us first on the official shared task evaluation for MSAEA-EN.",
    "descriptor": "\nComments: CALCS2021, colocated with NAACL-2021\n",
    "authors": [
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13573"
  },
  {
    "id": "arXiv:2105.13574",
    "title": "Parallel Programming Applied Research Projects for Teaching Parallel  Programming to Beginner Students",
    "abstract": "In this paper, we discuss the educational value of a few mid-size and one\nlarge applied research projects at the Computer Science Department of Okanagan\nCollege (OC) and at the Universities of Paris East Creteil (LACL) and Orleans\n(LIFO) in France. We found, that some freshmen students are very active and\neager to be involved in applied research projects starting from the second\nsemester. They are actively participating in programming competitions and want\nto be involved in applied research projects to compete with sophomore and older\nstudents. Our observation is based on five NSERC Engage College and Applied\nResearch and Development (ARD) grants, and several small applied projects.\nStudent involvement in applied research is a key motivation and success factor\nin our activities, but we are also involved in transferring some results of\napplied research, namely programming techniques, into the parallel programming\ncourses for beginners at the senior- and first-year MSc levels. We illustrate\nthis feedback process with programming notions for beginners, practical tools\nto acquire them and the overall success/failure of students as experienced for\nmore than 10 years in our French University courses.",
    "descriptor": "",
    "authors": [
      "Youry Khmelevsky",
      "Gaetan J.D.R. Hains"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13574"
  },
  {
    "id": "arXiv:2105.13575",
    "title": "2nd Place Solution for IJCAI-PRICAI 2020 3D AI Challenge: 3D Object  Reconstruction from A Single Image",
    "abstract": "In this paper, we present our solution for the {\\it IJCAI--PRICAI--20 3D AI\nChallenge: 3D Object Reconstruction from A Single Image}. We develop a variant\nof AtlasNet that consumes single 2D images and generates 3D point clouds\nthrough 2D to 3D mapping. To push the performance to the limit and present\nguidance on crucial implementation choices, we conduct extensive experiments to\nanalyze the influence of decoder design and different settings on the\nnormalization, projection, and sampling methods. Our method achieves 2nd place\nin the final track with a score of $70.88$, a chamfer distance of $36.87$, and\na mean f-score of $59.18$. The source code of our method will be available at\nhttps://github.com/em-data/Enhanced_AtlasNet_3DReconstruction.",
    "descriptor": "\nComments: 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Yichen Cao",
      "Yufei Wei",
      "Shichao Liu",
      "Lin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13575"
  },
  {
    "id": "arXiv:2105.13578",
    "title": "Hierarchical Transformer Encoders for Vietnamese Spelling Correction",
    "abstract": "In this paper, we propose a Hierarchical Transformer model for Vietnamese\nspelling correction problem. The model consists of multiple Transformer\nencoders and utilizes both character-level and word-level to detect errors and\nmake corrections. In addition, to facilitate future work in Vietnamese spelling\ncorrection tasks, we propose a realistic dataset collected from real-life texts\nfor the problem. We compare our method with other methods and publicly\navailable systems. The proposed method outperforms all of the contemporary\nmethods in terms of recall, precision, and f1-score. A demo version is publicly\navailable.",
    "descriptor": "\nComments: Accepted by The 34th International Conference on Industrial, Engineering & Other Applications of Applied Intelligent Systems(IEA/AIE 2021)\n",
    "authors": [
      "Hieu Tran",
      "Cuong V. Dinh",
      "Long Phan",
      "Son T. Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13578"
  },
  {
    "id": "arXiv:2105.13580",
    "title": "MODISSA: a multipurpose platform for the prototypical realization of  vehicle-related applications using optical sensors",
    "abstract": "We present the current state of development of the sensor-equipped car\nMODISSA, with which Fraunhofer IOSB realizes a configurable experimental\nplatform for hardware evaluation and software development in the context of\nmobile mapping and vehicle-related safety and protection. MODISSA is based on a\nvan that has successively been equipped with a variety of optical sensors over\nthe past few years, and contains hardware for complete raw data acquisition,\ngeoreferencing, real-time data analysis, and immediate visualization on in-car\ndisplays. We demonstrate the capabilities of MODISSA by giving a deeper insight\ninto experiments with its specific configuration in the scope of three\ndifferent applications. Other research groups can benefit from these\nexperiences when setting up their own mobile sensor system, especially\nregarding the selection of hardware and software, the knowledge of possible\nsources of error, and the handling of the acquired sensor data.",
    "descriptor": "\nComments: Authors' version of an article accepted for publication in Applied Optics, 9 May 2021\n",
    "authors": [
      "Bj\u00f6rn Borgmann",
      "Volker Schatz",
      "Marcus Hammer",
      "Marcus Hebel",
      "Michael Arens",
      "Uwe Stilla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13580"
  },
  {
    "id": "arXiv:2105.13583",
    "title": "A Modular First Formalisation of Combinatorial Design Theory",
    "abstract": "Combinatorial design theory studies set systems with certain balance and\nsymmetry properties and has applications to computer science and elsewhere.\nThis paper presents a modular approach to formalising designs for the first\ntime using Isabelle and assesses the usability of a locale-centric approach to\nformalisations of mathematical structures. We demonstrate how locales can be\nused to specify numerous types of designs and their hierarchy. The resulting\nlibrary, which is concise and adaptable, includes formal definitions and proofs\nfor many key properties, operations, and theorems on the construction and\nexistence of designs.",
    "descriptor": "\nComments: This paper has been accepted to CICM 2021. The full formalisation will be made available on the Isabelle AFP prior to the conference, and is alternatively available here: this https URL\n",
    "authors": [
      "Chelsea Edmonds",
      "Lawrence Paulson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.13583"
  },
  {
    "id": "arXiv:2105.13585",
    "title": "Fragmentation; a Tool for Finding Information, Encryption and Data Flow  in Systems",
    "abstract": "We introduce a new information-theoretic measure, fragmentation (F) which can\nbe used to determine how fragmented predictive information is in a system. The\nconcept can be extended to generate fragmentation matrices that can illustrate\ninformation flows through digital brains, in the form of directed graphs.\nFragmentation and fragmentation matrices can provide new insights into digital\nbrains structure and function, in other words, how causal digital networks\n\"think\" and process information. In addition to describing F we demonstrate how\nit can be used to examine how complex processing arises in neural networks,\nincluding differences in lifetime processing and incidents of incidental\nencryption.",
    "descriptor": "",
    "authors": [
      "Douglas Kirkpatrick",
      "Victoria Cao",
      "Clifford Bohm"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.13585"
  },
  {
    "id": "arXiv:2105.13591",
    "title": "Spatial-Temporal Dual Graph Neural Networks for Travel Time Estimation",
    "abstract": "Travel time estimation is a basic but important part in intelligent\ntransportation systems, especially widely applied in online map services to\nhelp travel navigation and route planning. Most previous works commonly model\nthe road segments or intersections separately and obtain their spatial-temporal\ncharacteristics for travel time estimation. However, due to the continuous\nalternation of the road segments and intersections, the dynamic features of\nthem are supposed to be coupled and interactive. Therefore, modeling one of\nthem limits further improvement in accuracy of estimating travel time. To\naddress the above problems, we propose a novel graph-based deep learning\nframework for travel time estimation, namely Spatial-Temporal Dual Graph Neural\nNetworks (STDGNN). Specifically, we first establish the spatial-temporal dual\ngraph architecture to capture the complex correlations of both intersections\nand road segments. The adjacency relations of intersections and that of road\nsegments are respectively characterized by node-wise graph and edge-wise graph.\nIn order to capture the joint spatial-temporal dynamics of the intersections\nand road segments, we adopt the spatial-temporal learning layer that\nincorporates the multi-scale spatial-temporal graph convolution networks and\ndual graph interaction networks. Followed by the spatial-temporal learning\nlayer, we also employ the multi-task learning layer to estimate the travel time\nof a given whole route and each road segment simultaneously. We conduct\nextensive experiments to evaluate our proposed model on two real-world\ntrajectory datasets, and the experimental results show that STDGNN\nsignificantly outperforms several state-of-art baselines.",
    "descriptor": "",
    "authors": [
      "Guangyin Jin",
      "Huan Yan",
      "Fuxian Li",
      "Jincai Huang",
      "Yong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13591"
  },
  {
    "id": "arXiv:2105.13592",
    "title": "Chhoyhopper: A Moving Target Defense with IPv6",
    "abstract": "Services on the public Internet are frequently scanned, then subject to\nbrute-force and denial-of-service attacks. We would like to run such services\nstealthily, available to friends but hidden from adversaries. In this work, we\npropose a moving target defense named \"Chhoyhopper\" that utilizes the vast IPv6\naddress space to conceal publicly available services. The client and server to\nhop to different IPv6 addresses in a pattern based on a shared, pre-distributed\nsecret and the time-of-day. By hopping over a /64 prefix, services cannot be\nfound by active scanners, and passively observed information is useless after\ntwo minutes. We demonstrate our system with SSH, and show that it can be\nextended to other applications.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "ASM Rizvi",
      "John Heidemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13592"
  },
  {
    "id": "arXiv:2105.13593",
    "title": "Semi-supervised Anatomical Landmark Detection via Shape-regulated  Self-training",
    "abstract": "Well-annotated medical images are costly and sometimes even impossible to\nacquire, hindering landmark detection accuracy to some extent. Semi-supervised\nlearning alleviates the reliance on large-scale annotated data by exploiting\nthe unlabeled data to understand the population structure of anatomical\nlandmarks. The global shape constraint is the inherent property of anatomical\nlandmarks that provides valuable guidance for more consistent pseudo labelling\nof the unlabeled data, which is ignored in the previously semi-supervised\nmethods. In this paper, we propose a model-agnostic shape-regulated\nself-training framework for semi-supervised landmark detection by fully\nconsidering the global shape constraint. Specifically, to ensure pseudo labels\nare reliable and consistent, a PCA-based shape model adjusts pseudo labels and\neliminate abnormal ones. A novel Region Attention loss to make the network\nautomatically focus on the structure consistent regions around pseudo labels.\nExtensive experiments show that our approach outperforms other semi-supervised\nmethods and achieves notable improvement on three medical image datasets.\nMoreover, our framework is flexible and can be used as a plug-and-play module\nintegrated into most supervised methods to improve performance further.",
    "descriptor": "",
    "authors": [
      "Runnan Chen",
      "Yuexin Ma",
      "Lingjie Liu",
      "Nenglun Chen",
      "Zhiming Cui",
      "Guodong Wei",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13593"
  },
  {
    "id": "arXiv:2105.13595",
    "title": "On Stricter Reachable Repetitiveness Measures*",
    "abstract": "The size $b$ of the smallest bidirectional macro scheme, which is arguably\nthe most general copy-paste scheme to generate a given sequence, is considered\nto be the strictest reachable measure of repetitiveness. It is strictly\nlower-bounded by measures like $\\gamma$ and $\\delta$, which are known or\nbelieved to be unreachable and to capture the entropy of repetitiveness. In\nthis paper we study another sequence generation mechanism, namely compositions\nof a morphism. We show that these form another plausible mechanism to\ncharacterize repetitive sequences and define NU-systems, which combine such a\nmechanism with macro schemes. We show that the size $\\nu \\leq b$ of the\nsmallest NU-system is reachable and can be $o(\\delta)$ for some string\nfamilies, thereby implying that the limit of compressibility of repetitive\nsequences can be even smaller than previously thought. We also derive several\nother results characterizing $\\nu$.",
    "descriptor": "\nComments: Funded in part by Basal Funds FB0001, Fondecyt Grant 1-200038, and a Conicyt Doctoral Scholarship, ANID, Chile\n",
    "authors": [
      "Gonzalo Navarro",
      "Cristian Urbina"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.13595"
  },
  {
    "id": "arXiv:2105.13598",
    "title": "End-to-End Deep Fault Tolerant Control",
    "abstract": "Ideally, accurate sensor measurements are needed to achieve a good\nperformance in the closed-loop control of mechatronic systems. As a\nconsequence, sensor faults will prevent the system from working correctly,\nunless a fault-tolerant control (FTC) architecture is adopted. As model-based\nFTC algorithms for nonlinear systems are often challenging to design, this\npaper focuses on a new method for FTC in the presence of sensor faults, based\non deep learning. The considered approach replaces the phases of fault\ndetection and isolation and controller design with a single recurrent neural\nnetwork, which has the value of past sensor measurements in a given time window\nas input, and the current values of the control variables as output. This\nend-to-end deep FTC method is applied to a mechatronic system composed of a\nspherical inverted pendulum, whose configuration is changed via reaction\nwheels, in turn actuated by electric motors. The simulation and experimental\nresults show that the proposed method can handle abrupt faults occurring in\nlink position/velocity sensors. The provided supplementary material includes a\nvideo of real-world experiments and the software source code.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Daulet Baimukashev",
      "Bexultan Rakhim",
      "Matteo Rubagotti",
      "Huseyin Atakan Varol"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13598"
  },
  {
    "id": "arXiv:2105.13599",
    "title": "Short-Term Stock Price-Trend Prediction Using Meta-Learning",
    "abstract": "Although conventional machine learning algorithms have been widely adopted\nfor stock-price predictions in recent years, the massive volume of specific\nlabeled data required are not always available. In contrast, meta-learning\ntechnology uses relatively small amounts of training data, called fast\nlearners. Such methods are beneficial under conditions of limited data\navailability, which often obtain for trend prediction based on time-series data\nlimited by sparse information. In this study, we consider short-term stock\nprice prediction using a meta-learning framework with several convolutional\nneural networks, including the temporal convolution network, fully\nconvolutional network, and residual neural network. We propose a sliding time\nhorizon to label stocks according to their predicted price trends, referred to\nas called dynamic k-average labeling, using prediction labels including \"rise\nplus\", \"rise\", \"fall\", and \"fall plus\". The effectiveness of the proposed\nmeta-learning framework was evaluated by application to the S&P500. The\nexperimental results show that the inclusion of the proposed meta-learning\nframework significantly improved both regular and balanced prediction accuracy\nand profitability.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Shin-Hung Chang",
      "Cheng-Wen Hsu",
      "Hsing-Ying Li",
      "Wei-Sheng Zeng",
      "Jan-Ming Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13599"
  },
  {
    "id": "arXiv:2105.13600",
    "title": "Placement Optimization and Power Control in Intelligent Reflecting  Surface Aided Multiuser System",
    "abstract": "Intelligent reflecting surface (IRS) is a new and revolutionary technology\ncapable of reconfiguring the wireless propagation environment by controlling\nits massive low-cost passive reflecting elements. Different from prior works\nthat focus on optimizing IRS reflection coefficients or single-IRS placement,\nwe aim to maximize the minimum throughput of a single-cell multiuser system\naided by multiple IRSs, by joint multi-IRS placement and power control at the\naccess point (AP), which is a mixed-integer non-convex problem with drastically\nincreased complexity with the number of IRSs/users. To tackle this challenge, a\nring-based IRS placement scheme is proposed along with a power control policy\nthat equalizes the users' non-outage probability. An efficient searching\nalgorithm is further proposed to obtain a close-to-optimal solution for\narbitrary number of IRSs/rings. Numerical results validate our analysis and\nshow that our proposed scheme significantly outperforms the benchmark schemes\nwithout IRS and/or with other power control policies. Moreover, it is shown\nthat the IRSs are preferably deployed near AP for coverage range extension,\nwhile with more IRSs, they tend to spread out over the cell to cover more and\nget closer to target users.",
    "descriptor": "\nComments: 2-col, 7 pages. This paper focuses on the multi-IRS placement optimization and downlink AP power control for achieving max-min throughput in a single-cell multi-user system. A ring-based IRS placement scheme is proposed which utilizes the near-AP/near-user deployment modes. Closed-form power control policy is devised to equalize the users' non-outage probability\n",
    "authors": [
      "Bifeng Ling",
      "Jiangbin Lyu",
      "Liqun Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13600"
  },
  {
    "id": "arXiv:2105.13601",
    "title": "The Trusted Edge",
    "abstract": "Edge computing promises to reshape the centralized nature of today's\ncloud-based applications by bringing computing resources, at least in part,\ncloser to the user. Reasons include the increasing need for real-time\n(short-delay, reliably-connected) computing and resource-demanding artificial\nintelligence (AI) algorithms that overstrain mobile devices' batteries or\ncompute power but are too bandwidth-demanding to be offloaded to a distant\ncloud. However, companies may need to run their protected business logic on\n(untrusted) third-party edge devices, which can lead to serious issues due to\nweaker security measures than in cloud environments. This article makes the\ncase for trusted edge computing (TEC), which focuses on developing concepts and\nmethods for protecting application providers' business logic (and thus their\nintellectual property) specifically tailored to open edge infrastructures. This\narticle further discusses open challenges in TEC to be addressed in the future.\nOtherwise, edge computing risks being a non-starter for most businesses due to\nthe inadequate and neglected protection of intellectual property.",
    "descriptor": "",
    "authors": [
      "Christian Meurisch"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13601"
  },
  {
    "id": "arXiv:2105.13602",
    "title": "ResearchGate and Google Scholar: How much do they differ in  publications, citations and different metrics and why?",
    "abstract": "ResearchGate has emerged as a popular professional network for scientists and\nresearchers in a very short span of time. Similar to Google Scholar, the\nResearchGate indexing uses an automatic crawling algorithm that extracts\nbibliographic data, citations and other information about scholarly articles\nfrom various sources. However, it has been observed that the two platforms\noften show different publication and citation data for the same institutions,\njournals and authors. This paper, therefore, attempts to analyse and measure\nthe differences in publication counts, citations and different metrics of the\ntwo platforms for a large data set of highly cited authors. The results\nindicate that there are significantly high differences in publication counts\nand citations for the same authors in the two platforms, with Google Scholar\nhaving higher counts for a vast majority of the cases. The different metrics\ncomputed by the two platforms also differ in their values, showing different\ndegrees of correlations. The coverage policy, indexing errors, author\nattribution mechanism and strategy to deal with predatory publishing are found\nto be the main probable reasons for the differences in the two platforms.",
    "descriptor": "",
    "authors": [
      "Vivek Kumar Singh",
      "Satya Swarup Srichandan",
      "Hiran H. Lathabai"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.13602"
  },
  {
    "id": "arXiv:2105.13603",
    "title": "High Performance and Scalable NAT System on Commodity Platforms",
    "abstract": "Quick network address translation (NAT) is proposed to improve the network\nperformance of the NAT system on the commodity server by three ways. First, the\nquick NAT search algorithm is designed to use the Hash search instead of the\nsequential search to reduce latency when looking up the NAT rule table. Second,\nto leverage the power of the multi-core central processing unit (CPU) and the\nmulti-queue network interface card, Quick NAT enables multiple CPU cores to\nprocess in parallel. The localized connection tracking table and the\ncompare-and-swap based lock-free NAT Hash tables are designed to eliminate the\nlock overhead. Third, Quick NAT uses the polling and zero-copy delivery to\nreduce the cost of interrupt and packet copies. The evaluation results show\nthat Quick NAT obtains high scalability and line-rate throughput on the\ncommodity server.",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Junfeng Li",
      "Dan Li",
      "Yukai Huang",
      "Yang Cheng",
      "Ruilin Ling"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13603"
  },
  {
    "id": "arXiv:2105.13604",
    "title": "Automated Generation of Robotic Planning Domains from Observations",
    "abstract": "Automated planning enables robots to find plans to achieve complex,\nlong-horizon tasks, given a planning domain. This planning domain consists of a\nlist of actions, with their associated preconditions and effects, and is\nusually manually defined by a human expert, which is very time-consuming or\neven infeasible. In this paper, we introduce a novel method for generating this\ndomain automatically from human demonstrations. First, we automatically segment\nand recognize the different observed actions from human demonstrations. From\nthese demonstrations, the relevant preconditions and effects are obtained, and\nthe associated planning operators are generated. Finally, a sequence of actions\nthat satisfies a user-defined goal can be planned using a symbolic planner. The\ngenerated plan is executed in a simulated environment by the TIAGo robot. We\ntested our method on a dataset of 12 demonstrations collected from three\ndifferent participants. The results show that our method is able to generate\nexecutable plans from using one single demonstration with a 92% success rate,\nand 100% when the information from all demonstrations are included, even for\npreviously unknown stacking goals.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Maximilian Diehl",
      "Chris Paxton",
      "Karinne Ramirez-Amaro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13604"
  },
  {
    "id": "arXiv:2105.13607",
    "title": "Alleviating the Knowledge-Language Inconsistency: A Study for Deep  Commonsense Knowledge",
    "abstract": "Knowledge facts are typically represented by relational triples, while we\nobserve that some commonsense facts are represented by the triples whose forms\nare inconsistent with the expression of language. This inconsistency puts\nforward a challenge for pre-trained language models to deal with these\ncommonsense knowledge facts. In this paper, we term such knowledge as deep\ncommonsense knowledge and conduct extensive exploratory experiments on it. We\nshow that deep commonsense knowledge occupies a significant part of commonsense\nknowledge while conventional methods fail to capture it effectively. We further\npropose a novel method to mine the deep commonsense knowledge distributed in\nsentences, alleviating the reliance of conventional methods on the triple\nrepresentation form of knowledge. Experiments demonstrate that the proposal\nsignificantly improves the performance in mining deep commonsense knowledge.",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Lei Li",
      "Yunfang Wu",
      "Qi Su",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13607"
  },
  {
    "id": "arXiv:2105.13608",
    "title": "Not Far Away, Not So Close: Sample Efficient Nearest Neighbour Data  Augmentation via MiniMax",
    "abstract": "Data augmentation in Natural Language Processing (NLP) often yields examples\nthat are less human-interpretable. Recently, leveraging kNN such that augmented\nexamples are retrieved from large repositories of unlabelled sentences has made\na step toward interpretable augmentation. Inspired by this paradigm, we\nintroduce MiniMax-kNN, a sample efficient data augmentation strategy. We\nexploit a semi-supervised approach based on knowledge distillation to train a\nmodel on augmented data. In contrast to existing kNN augmentation techniques\nthat blindly incorporate all samples, our method dynamically selects a subset\nof augmented samples with respect to the maximum KL-divergence of the training\nloss. This step aims to extract the most efficient samples to ensure our\naugmented data covers regions in the input space with maximum loss value. These\nmaximum loss regions are shrunk in our minimization step using augmented\nsamples. We evaluated our technique on several text classification tasks and\ndemonstrated that MiniMax-kNN consistently outperforms strong baselines. Our\nresults show that MiniMax-kNN requires fewer augmented examples and less\ncomputation to achieve superior performance over the state-of-the-art kNN-based\naugmentation techniques.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Ehsan Kamalloo",
      "Mehdi Rezagholizadeh",
      "Peyman Passban",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13608"
  },
  {
    "id": "arXiv:2105.13609",
    "title": "A nearly Blackwell-optimal policy gradient method",
    "abstract": "For continuing environments, reinforcement learning methods commonly maximize\na discounted reward criterion with discount factor close to 1 in order to\napproximate the steady-state reward (the gain). However, such a criterion only\nconsiders the long-run performance, ignoring the transient behaviour. In this\nwork, we develop a policy gradient method that optimizes the gain, then the\nbias (which indicates the transient performance and is important to capably\nselect from policies with equal gain). We derive expressions that enable\nsampling for the gradient of the bias, and its preconditioning Fisher matrix.\nWe further propose an algorithm that solves the corresponding bi-level\noptimization using a logarithmic barrier. Experimental results provide insights\ninto the fundamental mechanisms of our proposal.",
    "descriptor": "\nComments: 26 pages (9-page main content)\n",
    "authors": [
      "Vektor Dewanto",
      "Marcus Gallagher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13609"
  },
  {
    "id": "arXiv:2105.13617",
    "title": "FReTAL: Generalizing Deepfake Detection using Knowledge Distillation and  Representation Learning",
    "abstract": "As GAN-based video and image manipulation technologies become more\nsophisticated and easily accessible, there is an urgent need for effective\ndeepfake detection technologies. Moreover, various deepfake generation\ntechniques have emerged over the past few years. While many deepfake detection\nmethods have been proposed, their performance suffers from new types of\ndeepfake methods on which they are not sufficiently trained. To detect new\ntypes of deepfakes, the model should learn from additional data without losing\nits prior knowledge about deepfakes (catastrophic forgetting), especially when\nnew deepfakes are significantly different. In this work, we employ the\nRepresentation Learning (ReL) and Knowledge Distillation (KD) paradigms to\nintroduce a transfer learning-based Feature Representation Transfer Adaptation\nLearning (FReTAL) method. We use FReTAL to perform domain adaptation tasks on\nnew deepfake datasets while minimizing catastrophic forgetting. Our student\nmodel can quickly adapt to new types of deepfake by distilling knowledge from a\npre-trained teacher model and applying transfer learning without using source\ndomain data during domain adaptation. Through experiments on FaceForensics++\ndatasets, we demonstrate that FReTAL outperforms all baselines on the domain\nadaptation task with up to 86.97% accuracy on low-quality deepfakes.",
    "descriptor": "\nComments: 12 pages, 2 figures, 5 tables, accepted for publication at the Workshop on Media Forensics 2021\n",
    "authors": [
      "Minha Kim",
      "Shahroz Tariq",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13617"
  },
  {
    "id": "arXiv:2105.13618",
    "title": "Optimal Model Placement and Online Model Splitting for Device-Edge  Co-Inference",
    "abstract": "Device-edge co-inference opens up new possibilities for resource-constrained\nwireless devices (WDs) to execute deep neural network (DNN)-based applications\nwith heavy computation workloads. In particular, the WD executes the first few\nlayers of the DNN and sends the intermediate features to the edge server that\nprocesses the remaining layers of the DNN. By adapting the model splitting\ndecision, there exists a tradeoff between local computation cost and\ncommunication overhead. In practice, the DNN model is re-trained and updated\nperiodically at the edge server. Once the DNN parameters are regenerated, part\nof the updated model must be placed at the WD to facilitate on-device\ninference. In this paper, we study the joint optimization of the model\nplacement and online model splitting decisions to minimize the energy-and-time\ncost of device-edge co-inference in presence of wireless channel fading. The\nproblem is challenging because the model placement and model splitting\ndecisions are strongly coupled, while involving two different time scales. We\nfirst tackle online model splitting by formulating an optimal stopping problem,\nwhere the finite horizon of the problem is determined by the model placement\ndecision. In addition to deriving the optimal model splitting rule based on\nbackward induction, we further investigate a simple one-stage look-ahead rule,\nfor which we are able to obtain analytical expressions of the model splitting\ndecision. The analysis is useful for us to efficiently optimize the model\nplacement decision in a larger time scale. In particular, we obtain a\nclosed-form model placement solution for the fully-connected multilayer\nperceptron with equal neurons. Simulation results validate the superior\nperformance of the joint optimal model placement and splitting with various DNN\nstructures.",
    "descriptor": "\nComments: This paper has been submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Jia Yan",
      "Suzhi Bi",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13618"
  },
  {
    "id": "arXiv:2105.13619",
    "title": "CRT-Net: A Generalized and Scalable Framework for the Computer-Aided  Diagnosis of Electrocardiogram Signals",
    "abstract": "Electrocardiogram (ECG) signals play critical roles in the clinical screening\nand diagnosis of many types of cardiovascular diseases. Despite deep neural\nnetworks that have been greatly facilitated computer-aided diagnosis (CAD) in\nmany clinical tasks, the variability and complexity of ECG in the clinic still\npose significant challenges in both diagnostic performance and clinical\napplications. In this paper, we develop a robust and scalable framework for the\nclinical recognition of ECG. Considering the fact that hospitals generally\nrecord ECG signals in the form of graphic waves of 2-D images, we first extract\nthe graphic waves of 12-lead images into numerical 1-D ECG signals by a\nproposed bi-directional connectivity method. Subsequently, a novel deep neural\nnetwork, namely CRT-Net, is designed for the fine-grained and comprehensive\nrepresentation and recognition of 1-D ECG signals. The CRT-Net can well explore\nwaveform features, morphological characteristics and time domain features of\nECG by embedding convolution neural network(CNN), recurrent neural\nnetwork(RNN), and transformer module in a scalable deep model, which is\nespecially suitable in clinical scenarios with different lengths of ECG signals\ncaptured from different devices. The proposed framework is first evaluated on\ntwo widely investigated public repositories, demonstrating the superior\nperformance of ECG recognition in comparison with state-of-the-art. Moreover,\nwe validate the effectiveness of our proposed bi-directional connectivity and\nCRT-Net on clinical ECG images collected from the local hospital, including 258\npatients with chronic kidney disease (CKD), 351 patients with Type-2 Diabetes\n(T2DM), and around 300 patients in the control group. In the experiments, our\nmethods can achieve excellent performance in the recognition of these two types\nof disease.",
    "descriptor": "",
    "authors": [
      "Jingyi Liu",
      "Zhongyu Li",
      "Xiayue Fan",
      "Jintao Yan",
      "Bolin Li",
      "Xuemeng Hu",
      "Qing Xia",
      "Yue Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13619"
  },
  {
    "id": "arXiv:2105.13623",
    "title": "Enhanced Doubly Robust Learning for Debiasing Post-click Conversion Rate  Estimation",
    "abstract": "Post-click conversion, as a strong signal indicating the user preference, is\nsalutary for building recommender systems. However, accurately estimating the\npost-click conversion rate (CVR) is challenging due to the selection bias,\ni.e., the observed clicked events usually happen on users' preferred items.\nCurrently, most existing methods utilize counterfactual learning to debias\nrecommender systems. Among them, the doubly robust (DR) estimator has achieved\ncompetitive performance by combining the error imputation based (EIB) estimator\nand the inverse propensity score (IPS) estimator in a doubly robust way.\nHowever, inaccurate error imputation may result in its higher variance than the\nIPS estimator. Worse still, existing methods typically use simple\nmodel-agnostic methods to estimate the imputation error, which are not\nsufficient to approximate the dynamically changing model-correlated target\n(i.e., the gradient direction of the prediction model). To solve these\nproblems, we first derive the bias and variance of the DR estimator. Based on\nit, a more robust doubly robust (MRDR) estimator has been proposed to further\nreduce its variance while retaining its double robustness. Moreover, we propose\na novel double learning approach for the MRDR estimator, which can convert the\nerror imputation into the general CVR estimation. Besides, we empirically\nverify that the proposed learning scheme can further eliminate the high\nvariance problem of the imputation learning. To evaluate its effectiveness,\nextensive experiments are conducted on a semi-synthetic dataset and two\nreal-world datasets. The results demonstrate the superiority of the proposed\napproach over the state-of-the-art methods. The code is available at\nhttps://github.com/guosyjlu/MRDR-DL.",
    "descriptor": "\nComments: 10 pages, 3 figures, accepted by SIGIR 2021\n",
    "authors": [
      "Siyuan Guo",
      "Lixin Zou",
      "Yiding Liu",
      "Wenwen Ye",
      "Suqi Cheng",
      "Shuaiqiang Wang",
      "Hechang Chen",
      "Dawei Yin",
      "Yi Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.13623"
  },
  {
    "id": "arXiv:2105.13626",
    "title": "ByT5: Towards a token-free future with pre-trained byte-to-byte models",
    "abstract": "Most widely-used pre-trained language models operate on sequences of tokens\ncorresponding to word or subword units. Encoding text as a sequence of tokens\nrequires a tokenizer, which is typically created as an independent artifact\nfrom the model. Token-free models that instead operate directly on raw text\n(bytes or characters) have many benefits: they can process text in any language\nout of the box, they are more robust to noise, and they minimize technical debt\nby removing complex and error-prone text preprocessing pipelines. Since byte or\ncharacter sequences are longer than token sequences, past work on token-free\nmodels has often introduced new model architectures designed to amortize the\ncost of operating directly on raw text. In this paper, we show that a standard\nTransformer architecture can be used with minimal modifications to process byte\nsequences. We carefully characterize the trade-offs in terms of parameter\ncount, training FLOPs, and inference speed, and show that byte-level models are\ncompetitive with their token-level counterparts. We also demonstrate that\nbyte-level models are significantly more robust to noise and perform better on\ntasks that are sensitive to spelling and pronunciation. As part of our\ncontribution, we release a new set of pre-trained byte-level Transformer models\nbased on the T5 architecture, as well as all code and data used in our\nexperiments.",
    "descriptor": "",
    "authors": [
      "Linting Xue",
      "Aditya Barua",
      "Noah Constant",
      "Rami Al-Rfou",
      "Sharan Narang",
      "Mihir Kale",
      "Adam Roberts",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13626"
  },
  {
    "id": "arXiv:2105.13630",
    "title": "THINK: A Novel Conversation Model for Generating Grammatically Correct  and Coherent Responses",
    "abstract": "Many existing conversation models that are based on the encoder-decoder\nframework have focused on ways to make the encoder more complicated to enrich\nthe context vectors so as to increase the diversity and informativeness of\ngenerated responses. However, these approaches face two problems. First, the\ndecoder is too simple to effectively utilize the previously generated\ninformation and tends to generate duplicated and self-contradicting responses.\nSecond, the complex encoder tends to generate diverse but incoherent responses\nbecause the complex context vectors may deviate from the original semantics of\ncontext. In this work, we proposed a conversation model named \"THINK\" (Teamwork\ngeneration Hover around Impressive Noticeable Keywords) to make the decoder\nmore complicated and avoid generating duplicated and self-contradicting\nresponses. The model simplifies the context vectors and increases the coherence\nof generated responses in a reasonable way. For this model, we propose Teamwork\ngeneration framework and Semantics Extractor. Compared with other baselines,\nboth automatic and human evaluation showed the advantages of our model.",
    "descriptor": "",
    "authors": [
      "Bin Sun",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Jiamou Liu",
      "Kan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13630"
  },
  {
    "id": "arXiv:2105.13634",
    "title": "Saudi Parents' Security and Privacy Concerns about their Children's  Smart Device Applications",
    "abstract": "In this paper, we investigate Saudi parents' security and privacy concerns\nregarding their children's smart device applications (apps). To this end, we\nconducted a survey and analysed 119 responses. Our results show that Saudi\nparents expressed a high level of concern regarding their children's security\nand privacy when using smart device apps. However, they expressed higher\nconcerns about apps' content than privacy issues such as apps' requests to\naccess sensitive data. Furthermore, parents' concerns are not in line with most\nof the children's installed apps, which contain apps inappropriate for their\nage, require parental guidance, and request access to sensitive data such as\nlocation. We also compare Saudi parents' practices and concerns with those\nreported by Western (mainly from the UK) and Chinese parents in previous\nreports. We find interesting patterns and establish new relationships.\nFurthermore, Saudi and Western parents show higher levels of privacy concerns\nthan Chinese parents. The low level of privacy concerns expressed by Chinese\nparents even after being informed about possible privacy implications could be\nrelated cultural or political reasons. Finally, we tested 14 security and\nprivacy practices and concerns against high vs. low socioeconomic classes\n(parents' education, technical background, and income) to find whether there\nare significant differences between high and low classes. Out of 42 tests (14\nproperties x 3 classes) we find significant differences between high and low\nclasses in 7 tests only. While this is a positive trend overall, it is\nimportant to work on bridging these gaps. The results of this paper provide key\nfindings to identify areas of improvements and recommendations, especially for\nSaudis, which can be used by parents, developers, researchers, regulators, and\npolicy makers.",
    "descriptor": "",
    "authors": [
      "Eman Alashwali",
      "Fatimah Alashwali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.13634"
  },
  {
    "id": "arXiv:2105.13635",
    "title": "Noised Consistency Training for Text Summarization",
    "abstract": "Neural abstractive summarization methods often require large quantities of\nlabeled training data. However, labeling large amounts of summarization data is\noften prohibitive due to time, financial, and expertise constraints, which has\nlimited the usefulness of summarization systems to practical applications. In\nthis paper, we argue that this limitation can be overcome by a semi-supervised\napproach: consistency training which is to leverage large amounts of unlabeled\ndata to improve the performance of supervised learning over a small corpus. The\nconsistency regularization semi-supervised learning can regularize model\npredictions to be invariant to small noise applied to input articles. By adding\nnoised unlabeled corpus to help regularize consistency training, this framework\nobtains comparative performance without using the full dataset. In particular,\nwe have verified that leveraging large amounts of unlabeled data decently\nimproves the performance of supervised learning over an insufficient labeled\ndataset.",
    "descriptor": "",
    "authors": [
      "Junnan Liu",
      "Qianren Mao",
      "Bang Liu",
      "Hao Peng",
      "Hongdong Zhu",
      "Jianxin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13635"
  },
  {
    "id": "arXiv:2105.13636",
    "title": "The Power of Log-Sum-Exp: Sequential Density Ratio Matrix Estimation for  Speed-Accuracy Optimization",
    "abstract": "We propose a model for multiclass classification of time series to make a\nprediction as early and as accurate as possible. The matrix sequential\nprobability ratio test (MSPRT) is known to be asymptotically optimal for this\nsetting, but contains a critical assumption that hinders broad real-world\napplications; the MSPRT requires the underlying probability density. To address\nthis problem, we propose to solve density ratio matrix estimation (DRME), a\nnovel type of density ratio estimation that consists of estimating matrices of\nmultiple density ratios with constraints and thus is more challenging than the\nconventional density ratio estimation. We propose a log-sum-exp-type loss\nfunction (LSEL) for solving DRME and prove the following: (i) the LSEL provides\nthe true density ratio matrix as the sample size of the training set increases\n(consistency); (ii) it assigns larger gradients to harder classes (hard class\nweighting effect); and (iii) it provides discriminative scores even on\nclass-imbalanced datasets (guess-aversion). Our overall architecture for early\nclassification, MSPRT-TANDEM, statistically significantly outperforms baseline\nmodels on four datasets including action recognition, especially in the early\nstage of sequential observations. Our code and datasets are publicly available\nat: https://github.com/TaikiMiyagawa/MSPRT-TANDEM.",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Akinori F. Ebihara",
      "Taiki Miyagawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13636"
  },
  {
    "id": "arXiv:2105.13637",
    "title": "Curse of Dimensionality in Unconstrained Private Convex ERM",
    "abstract": "We consider the lower bounds of differentially private empirical risk\nminimization for general convex functions in this paper. For convex generalized\nlinear models (GLMs), the well-known tight bound of DP-ERM in the constrained\ncase is $\\tilde{\\Theta}(\\frac{\\sqrt{p}}{\\epsilon n})$, while recently,\n\\cite{sstt21} find the tight bound of DP-ERM in the unconstrained case is\n$\\tilde{\\Theta}(\\frac{\\sqrt{\\text{rank}}}{\\epsilon n})$ where $p$ is the\ndimension, $n$ is the sample size and $\\text{rank}$ is the rank of the feature\nmatrix of the GLM objective function. As $\\text{rank}\\leq \\min\\{n,p\\}$, a\nnatural and important question arises that whether we can evade the curse of\ndimensionality for over-parameterized models where $n\\ll p$, for more general\nconvex functions beyond GLM. We answer this question negatively by giving the\nfirst and tight lower bound of unconstrained private ERM for the general convex\nfunction, matching the current upper bound\n$\\tilde{O}(\\frac{\\sqrt{p}}{n\\epsilon})$ for unconstrained private ERM. We also\ngive an $\\Omega(\\frac{p}{n\\epsilon})$ lower bound for unconstrained pure-DP ERM\nwhich recovers the result in the constrained case.",
    "descriptor": "",
    "authors": [
      "Daogao Liu",
      "Zhou Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13637"
  },
  {
    "id": "arXiv:2105.13639",
    "title": "On-site Online Feature Selection for Classification of Switchgear  Actuations",
    "abstract": "As connected sensors continue to evolve, interest in low-voltage monitoring\nsolutions is increasing. This also applies in the area of switchgear\nmonitoring, where the detection of switch actions, their differentiation and\naging are of fundamental interest. In particular, the universal applicability\nfor various types of construction plays a major role. Methods in which\ndesign-specific features are learned in an offline training are therefore less\nsuitable for assessing the condition of switchgears. A new computational\nefficient method for intelligent online feature selection is presented, which\ncan be used to train a model for the addressed use cases on-site. Process- and\ndesign-specific features can be learned locally (e.g. on a sensor system)\nwithout the need of prior offline training. The proposed method is evaluated on\nfour datasets of switchgear measurements, which were recorded using\nmicroelectromechanical system (MEMS) based sensors (acoustic and vibration).\nFurthermore, we show that the features selected by our method can be used to\ntrack changes in switching processes due to aging effects.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Christina Nicolaou",
      "Ahmad Mansour",
      "Kristof Van Laerhoven"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13639"
  },
  {
    "id": "arXiv:2105.13645",
    "title": "Learning to Select Cuts for Efficient Mixed-Integer Programming",
    "abstract": "Cutting plane methods play a significant role in modern solvers for tackling\nmixed-integer programming (MIP) problems. Proper selection of cuts would remove\ninfeasible solutions in the early stage, thus largely reducing the\ncomputational burden without hurting the solution accuracy. However, the major\ncut selection approaches heavily rely on heuristics, which strongly depend on\nthe specific problem at hand and thus limit their generalization capability. In\nthis paper, we propose a data-driven and generalizable cut selection approach,\nnamed Cut Ranking, in the settings of multiple instance learning. To measure\nthe quality of the candidate cuts, a scoring function, which takes the\ninstance-specific cut features as inputs, is trained and applied in cut ranking\nand selection. In order to evaluate our method, we conduct extensive\nexperiments on both synthetic datasets and real-world datasets. Compared with\ncommonly used heuristics for cut selection, the learning-based policy has shown\nto be more effective, and is capable of generalizing over multiple problems\nwith different properties. Cut Ranking has been deployed in an industrial\nsolver for large-scale MIPs. In the online A/B testing of the product planning\nproblems with more than $10^7$ variables and constraints daily, Cut Ranking has\nachieved the average speedup ratio of 12.42% over the production solver without\nany accuracy loss of solution.",
    "descriptor": "\nComments: 30 pages,3 figures\n",
    "authors": [
      "Zeren Huang",
      "Kerong Wang",
      "Furui Liu",
      "Hui-ling Zhen",
      "Weinan Zhang",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Yong Yu",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13645"
  },
  {
    "id": "arXiv:2105.13648",
    "title": "Cross-Lingual Abstractive Summarization with Limited Parallel Resources",
    "abstract": "Parallel cross-lingual summarization data is scarce, requiring models to\nbetter use the limited available cross-lingual resources. Existing methods to\ndo so often adopt sequence-to-sequence networks with multi-task frameworks.\nSuch approaches apply multiple decoders, each of which is utilized for a\nspecific task. However, these independent decoders share no parameters, hence\nfail to capture the relationships between the discrete phrases of summaries in\ndifferent languages, breaking the connections in order to transfer the\nknowledge of the high-resource languages to low-resource languages. To bridge\nthese connections, we propose a novel Multi-Task framework for Cross-Lingual\nAbstractive Summarization (MCLAS) in a low-resource setting. Employing one\nunified decoder to generate the sequential concatenation of monolingual and\ncross-lingual summaries, MCLAS makes the monolingual summarization task a\nprerequisite of the CLS task. In this way, the shared decoder learns\ninteractions involving alignments and summary patterns across languages, which\nencourages attaining knowledge transfer. Experiments on two CLS datasets\ndemonstrate that our model significantly outperforms three baseline models in\nboth low-resource and full-dataset scenarios. Moreover, in-depth analysis on\nthe generated summaries and attention heads verifies that interactions are\nlearned well using MCLAS, which benefits the CLS task under limited parallel\nresources.",
    "descriptor": "\nComments: Accepted by ACL2021\n",
    "authors": [
      "Yu Bai",
      "Yang Gao",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13648"
  },
  {
    "id": "arXiv:2105.13649",
    "title": "Pruning and Slicing Neural Networks using Formal Verification",
    "abstract": "Deep neural networks (DNNs) play an increasingly important role in various\ncomputer systems. In order to create these networks, engineers typically\nspecify a desired topology, and then use an automated training algorithm to\nselect the network's weights. While training algorithms have been studied\nextensively and are well understood, the selection of topology remains a form\nof art, and can often result in networks that are unnecessarily large - and\nconsequently are incompatible with end devices that have limited memory,\nbattery or computational power. Here, we propose to address this challenge by\nharnessing recent advances in DNN verification. We present a framework and a\nmethodology for discovering redundancies in DNNs - i.e., for finding neurons\nthat are not needed, and can be removed in order to reduce the size of the DNN.\nBy using sound verification techniques, we can formally guarantee that our\nsimplified network is equivalent to the original, either completely, or up to a\nprescribed tolerance. Further, we show how to combine our technique with\nslicing, which results in a family of very small DNNs, which are together\nequivalent to the original. Our approach can produce DNNs that are\nsignificantly smaller than the original, rendering them suitable for deployment\non additional kinds of systems, and even more amenable to subsequent formal\nverification. We provide a proof-of-concept implementation of our approach, and\nuse it to evaluate our techniques on several real-world DNNs.",
    "descriptor": "",
    "authors": [
      "Ori Lahav",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13649"
  },
  {
    "id": "arXiv:2105.13650",
    "title": "Data Augmentation for Text Generation Without Any Augmented Data",
    "abstract": "Data augmentation is an effective way to improve the performance of many\nneural text generation models. However, current data augmentation methods need\nto define or choose proper data mapping functions that map the original samples\ninto the augmented samples. In this work, we derive an objective to formulate\nthe problem of data augmentation on text generation tasks without any use of\naugmented data constructed by specific mapping functions. Our proposed\nobjective can be efficiently optimized and applied to popular loss functions on\ntext generation tasks with a convergence rate guarantee. Experiments on five\ndatasets of two text generation tasks show that our approach can approximate or\neven surpass popular data augmentation methods.",
    "descriptor": "\nComments: Accepted into the main conference of ACL 2021\n",
    "authors": [
      "Wei Bi",
      "Huayang Li",
      "Jiacheng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13650"
  },
  {
    "id": "arXiv:2105.13655",
    "title": "Learning to Schedule",
    "abstract": "This paper proposes a learning and scheduling algorithm to minimize the\nexpected cumulative holding cost incurred by jobs, where statistical parameters\ndefining their individual holding costs are unknown a priori. In each time\nslot, the server can process a job while receiving the realized random holding\ncosts of the jobs remaining in the system. Our algorithm is a learning-based\nvariant of the $c\\mu$ rule for scheduling: it starts with a preemption period\nof fixed length which serves as a learning phase, and after accumulating enough\ndata about individual jobs, it switches to nonpreemptive scheduling mode. The\nalgorithm is designed to handle instances with large or small gaps in jobs'\nparameters and achieves near-optimal performance guarantees. The performance of\nour algorithm is captured by its regret, where the benchmark is the minimum\npossible cost attained when the statistical parameters of jobs are fully known.\nWe prove upper bounds on the regret of our algorithm, and we derive a regret\nlower bound that is almost matching the proposed upper bounds. Our numerical\nresults demonstrate the effectiveness of our algorithm and show that our\ntheoretical regret analysis is nearly tight.",
    "descriptor": "",
    "authors": [
      "Dabeen Lee",
      "Milan Vojnovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13655"
  },
  {
    "id": "arXiv:2105.13659",
    "title": "Deception Detection in Videos using the Facial Action Coding System",
    "abstract": "Facts are important in decision making in every situation, which is why it is\nimportant to catch deceptive information before they are accepted as facts.\nDeception detection in videos has gained traction in recent times for its\nvarious real-life application. In our approach, we extract facial action units\nusing the facial action coding system which we use as parameters for training a\ndeep learning model. We specifically use long short-term memory (LSTM) which we\ntrained using the real-life trial dataset and it provided one of the best\nfacial only approaches to deception detection. We also tested cross-dataset\nvalidation using the Real-life trial dataset, the Silesian Deception Dataset,\nand the Bag-of-lies Deception Dataset which has not yet been attempted by\nanyone else for a deception detection system. We tested and compared all\ndatasets amongst each other individually and collectively using the same deep\nlearning training model. The results show that adding different datasets for\ntraining worsen the accuracy of the model. One of the primary reasons is that\nthe nature of these datasets vastly differs from one another.",
    "descriptor": "",
    "authors": [
      "Hammad Ud Din Ahmed",
      "Usama Ijaz Bajwa",
      "Fan Zhang",
      "Muhammad Waqas Anwar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13659"
  },
  {
    "id": "arXiv:2105.13662",
    "title": "Inside ASCENT: Exploring a Deep Commonsense Knowledge Base and its Usage  in Question Answering",
    "abstract": "ASCENT is a fully automated methodology for extracting and consolidating\ncommonsense assertions from web contents (Nguyen et al., WWW 2021). It advances\ntraditional triple-based commonsense knowledge representation by capturing\nsemantic facets like locations and purposes, and composite concepts, i.e.,\nsubgroups and related aspects of subjects. In this demo, we present a web\nportal that allows users to understand its construction process, explore its\ncontent, and observe its impact in the use case of question answering. The demo\nwebsite and an introductory video are both available online.",
    "descriptor": "\nComments: Demo website: this https URL; introductory video: this https URL\n",
    "authors": [
      "Tuan-Phong Nguyen",
      "Simon Razniewski",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13662"
  },
  {
    "id": "arXiv:2105.13665",
    "title": "Domain-Adaptive Pretraining Methods for Dialogue Understanding",
    "abstract": "Language models like BERT and SpanBERT pretrained on open-domain data have\nobtained impressive gains on various NLP tasks. In this paper, we probe the\neffectiveness of domain-adaptive pretraining objectives on downstream tasks. In\nparticular, three objectives, including a novel objective focusing on modeling\npredicate-argument relations, are evaluated on two challenging dialogue\nunderstanding tasks. Experimental results demonstrate that domain-adaptive\npretraining with proper objectives can significantly improve the performance of\na strong baseline on these tasks, achieving the new state-of-the-art\nperformances.",
    "descriptor": "\nComments: 6 pages, to appear in ACL2021\n",
    "authors": [
      "Han Wu",
      "Kun Xu",
      "Linfeng Song",
      "Lifeng Jin",
      "Haisong Zhang",
      "Linqi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13665"
  },
  {
    "id": "arXiv:2105.13669",
    "title": "Measuring global properties of neural generative model outputs via  generating mathematical objects",
    "abstract": "We train deep generative models on datasets of reflexive polytopes. This\nenables us to compare how well the models have picked up on various global\nproperties of generated samples. Our datasets are complete in the sense that\nevery single example, up to changes of coordinate, is included in the dataset.\nUsing this property we also perform tests checking to what extent the models\nare merely memorizing the data. We also train models on the same dataset\nrepresented in two different ways, enabling us to measure which form is easiest\nto learn from. We use these experiments to show that deep generative models can\nlearn to generate geometric objects with non-trivial global properties, and\nthat the models learn some underlying properties of the objects rather than\nsimply memorizing the data.",
    "descriptor": "",
    "authors": [
      "Bernt Ivar Utst\u00f8l N\u00f8dland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13669"
  },
  {
    "id": "arXiv:2105.13670",
    "title": "Transferable Deep Reinforcement Learning Framework for Autonomous  Vehicles with Joint Radar-Data Communications",
    "abstract": "Autonomous Vehicles (AVs) are required to operate safely and efficiently in\ndynamic environments. For this, the AVs equipped with Joint\nRadar-Communications (JRC) functions can enhance the driving safety by\nutilizing both radar detection and data communication functions. However,\noptimizing the performance of the AV system with two different functions under\nuncertainty and dynamic of surrounding environments is very challenging. In\nthis work, we first propose an intelligent optimization framework based on the\nMarkov Decision Process (MDP) to help the AV make optimal decisions in\nselecting JRC operation functions under the dynamic and uncertainty of the\nsurrounding environment. We then develop an effective learning algorithm\nleveraging recent advances of deep reinforcement learning techniques to find\nthe optimal policy for the AV without requiring any prior information about\nsurrounding environment. Furthermore, to make our proposed framework more\nscalable, we develop a Transfer Learning (TL) mechanism that enables the AV to\nleverage valuable experiences for accelerating the training process when it\nmoves to a new environment. Extensive simulations show that the proposed\ntransferable deep reinforcement learning framework reduces the obstacle miss\ndetection probability by the AV up to 67% compared to other conventional deep\nreinforcement learning approaches.",
    "descriptor": "",
    "authors": [
      "Nguyen Quang Hieu",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Ping Wang",
      "Dong In Kim",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13670"
  },
  {
    "id": "arXiv:2105.13677",
    "title": "ResT: An Efficient Transformer for Visual Recognition",
    "abstract": "This paper presents an efficient multi-scale vision Transformer, called ResT,\nthat capably served as a general-purpose backbone for image recognition. Unlike\nexisting Transformer methods, which employ standard Transformer blocks to\ntackle raw images with a fixed resolution, our ResT have several advantages:\n(1) A memory-efficient multi-head self-attention is built, which compresses the\nmemory by a simple depth-wise convolution, and projects the interaction across\nthe attention-heads dimension while keeping the diversity ability of\nmulti-heads; (2) Position encoding is constructed as spatial attention, which\nis more flexible and can tackle with input images of arbitrary size without\ninterpolation or fine-tune; (3) Instead of the straightforward tokenization at\nthe beginning of each stage, we design the patch embedding as a stack of\noverlapping convolution operation with stride on the 2D-reshaped token map. We\ncomprehensively validate ResT on image classification and downstream tasks.\nExperimental results show that the proposed ResT can outperform the recently\nstate-of-the-art backbones by a large margin, demonstrating the potential of\nResT as strong backbones. The code and models will be made publicly available\nat https://github.com/wofmanaf/ResT.",
    "descriptor": "\nComments: ResT is an efficient multi-scale vision Transformer that can tackle input images with arbitrary size. arXiv admin note: text overlap with arXiv:2103.14030 by other authors\n",
    "authors": [
      "Qinglong Zhang",
      "Yubin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13677"
  },
  {
    "id": "arXiv:2105.13680",
    "title": "Focus on Local: Detecting Lane Marker from Bottom Up via Key Point",
    "abstract": "Mainstream lane marker detection methods are implemented by predicting the\noverall structure and deriving parametric curves through post-processing.\nComplex lane line shapes require high-dimensional output of CNNs to model\nglobal structures, which further increases the demand for model capacity and\ntraining data. In contrast, the locality of a lane marker has finite geometric\nvariations and spatial coverage. We propose a novel lane marker detection\nsolution, FOLOLane, that focuses on modeling local patterns and achieving\nprediction of global structures in a bottom-up manner. Specifically, the CNN\nmodels lowcomplexity local patterns with two separate heads, the first one\npredicts the existence of key points, and the second refines the location of\nkey points in the local range and correlates key points of the same lane line.\nThe locality of the task is consistent with the limited FOV of the feature in\nCNN, which in turn leads to more stable training and better generalization. In\naddition, an efficiency-oriented decoding algorithm was proposed as well as a\ngreedy one, which achieving 36% runtime gains at the cost of negligible\nperformance degradation. Both of the two decoders integrated local information\ninto the global geometry of lane markers. In the absence of a complex network\narchitecture design, the proposed method greatly outperforms all existing\nmethods on public datasets while achieving the best state-of-the-art results\nand real-time processing simultaneously.",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Zhan Qu",
      "Huan Jin",
      "Yang Zhou",
      "Zhen Yang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13680"
  },
  {
    "id": "arXiv:2105.13683",
    "title": "Fast zone-based algorithms for reachability in pushdown timed automata",
    "abstract": "Given the versatility of timed automata a huge body of work has evolved that\nconsiders extensions of timed automata. One extension that has received a lot\nof interest is timed automata with a, possibly unbounded, stack, also called\nthe pushdown timed automata (PDTA) model. While different algorithms have been\ngiven for reachability in different variants of this model, most of these\nresults are purely theoretical and do not give rise to efficient\nimplementations. One main reason for this is that none of these algorithms (and\nthe implementations that exist) use the so-called zone-based abstraction, but\nrely either on the region-abstraction or other approaches, which are\nsignificantly harder to implement.\nIn this paper, we show that a naive extension using simulations of the zone\nbased reachability algorithm for the control state reachability problem of\ntimed automata is not sound in the presence of a stack. To understand this\nbetter we give an inductive rule based view of the zone reachability algorithm\nfor timed automata. This alternate view allows us to analyze and adapt the\nrules to also work for pushdown timed automata. We obtain the first zone-based\nalgorithm for PDTA which is terminating, sound and complete. We implement our\nalgorithm in the tool TChecker and perform experiments to show its efficacy,\nthus leading the way for more practical approaches to the verification of\npushdown timed systems.",
    "descriptor": "\nComments: Long version of conference paper accepted at CAV'2021\n",
    "authors": [
      "S. Akshay",
      "Paul Gastin",
      "Karthik R Prakash"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.13683"
  },
  {
    "id": "arXiv:2105.13688",
    "title": "Learning Uncertainty For Safety-Oriented Semantic Segmentation In  Autonomous Driving",
    "abstract": "In this paper, we show how uncertainty estimation can be leveraged to enable\nsafety critical image segmentation in autonomous driving, by triggering a\nfallback behavior if a target accuracy cannot be guaranteed. We introduce a new\nuncertainty measure based on disagreeing predictions as measured by a\ndissimilarity function. We propose to estimate this dissimilarity by training a\ndeep neural architecture in parallel to the task-specific network. It allows\nthis observer to be dedicated to the uncertainty estimation, and let the\ntask-specific network make predictions. We propose to use self-supervision to\ntrain the observer, which implies that our method does not require additional\ntraining data. We show experimentally that our proposed approach is much less\ncomputationally intensive at inference time than competing methods (e.g.\nMCDropout), while delivering better results on safety-oriented evaluation\nmetrics on the CamVid dataset, especially in the case of glare artifacts.",
    "descriptor": "",
    "authors": [
      "Victor Besnier",
      "David Picard",
      "Alexandre Briot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13688"
  },
  {
    "id": "arXiv:2105.13695",
    "title": "AutoSampling: Search for Effective Data Sampling Schedules",
    "abstract": "Data sampling acts as a pivotal role in training deep learning models.\nHowever, an effective sampling schedule is difficult to learn due to the\ninherently high dimension of parameters in learning the sampling schedule. In\nthis paper, we propose an AutoSampling method to automatically learn sampling\nschedules for model training, which consists of the multi-exploitation step\naiming for optimal local sampling schedules and the exploration step for the\nideal sampling distribution. More specifically, we achieve sampling schedule\nsearch with shortened exploitation cycle to provide enough supervision. In\naddition, we periodically estimate the sampling distribution from the learned\nsampling schedules and perturb it to search in the distribution space. The\ncombination of two searches allows us to learn a robust sampling schedule. We\napply our AutoSampling method to a variety of image classification tasks\nillustrating the effectiveness of the proposed method.",
    "descriptor": "\nComments: Automl for sampling firstly without any assumpation\n",
    "authors": [
      "Ming Sun",
      "Haoxuan Dou",
      "Baopu Li",
      "Lei Cui",
      "Junjie Yan",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13695"
  },
  {
    "id": "arXiv:2105.13697",
    "title": "AdvParams: An Active DNN Intellectual Property Protection Technique via  Adversarial Perturbation Based Parameter Encryption",
    "abstract": "A well-trained DNN model can be regarded as an intellectual property (IP) of\nthe model owner. To date, many DNN IP protection methods have been proposed,\nbut most of them are watermarking based verification methods where model owners\ncan only verify their ownership passively after the copyright of DNN models has\nbeen infringed. In this paper, we propose an effective framework to actively\nprotect the DNN IP from infringement. Specifically, we encrypt the DNN model's\nparameters by perturbing them with well-crafted adversarial perturbations. With\nthe encrypted parameters, the accuracy of the DNN model drops significantly,\nwhich can prevent malicious infringers from using the model. After the\nencryption, the positions of encrypted parameters and the values of the added\nadversarial perturbations form a secret key. Authorized user can use the secret\nkey to decrypt the model. Compared with the watermarking methods which only\npassively verify the ownership after the infringement occurs, the proposed\nmethod can prevent infringement in advance. Moreover, compared with most of the\nexisting active DNN IP protection methods, the proposed method does not require\nadditional training process of the model, which introduces low computational\noverhead. Experimental results show that, after the encryption, the test\naccuracy of the model drops by 80.65%, 81.16%, and 87.91% on Fashion-MNIST,\nCIFAR-10, and GTSRB, respectively. Moreover, the proposed method only needs to\nencrypt an extremely low number of parameters, and the proportion of the\nencrypted parameters of all the model's parameters is as low as 0.000205%. The\nexperimental results also indicate that, the proposed method is robust against\nmodel fine-tuning attack and model pruning attack. Moreover, for the adaptive\nattack where attackers know the detailed steps of the proposed method, the\nproposed method is also demonstrated to be robust.",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Zhiyu Wu",
      "Jian Wang",
      "Yushu Zhang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13697"
  },
  {
    "id": "arXiv:2105.13698",
    "title": "Network Activities Recognition and Analysis Based on Supervised Machine  Learning Classification Methods Using J48 and Na\u00efve Bayes Algorithm",
    "abstract": "Network activities recognition has always been a significant component of\nintrusion detection. However, with the increasing network traffic flow and\ncomplexity of network behavior, it is becoming more and more difficult to\nidentify the specific behavior quickly and accurately by user network\nmonitoring software. It also requires the system security staff to pay close\nattention to the latest intrusion monitoring technology and methods. All of\nthese greatly increase the difficulty and complexity of intrusion detection\ntasks. The application of machine learning methods based on supervised\nclassification technology would help to liberate the network security staff\nfrom the heavy and boring tasks. A finetuned model would accurately recognize\nuser behavior, which could provide persistent monitoring with a relative high\naccuracy and good adaptability. Finally, the results of network activities\nrecognition by J48 and Na\\\"ive Bayes algorithms are introduced and evaluated.",
    "descriptor": "",
    "authors": [
      "Fan Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13698"
  },
  {
    "id": "arXiv:2105.13699",
    "title": "Accelerating JavaScript Static Analysis via Dynamic Shortcuts (Extended  Version)",
    "abstract": "JavaScript has become one of the most widely used programming languages for\nweb development, server-side programming, and even micro-controllers for IoT.\nHowever, its extremely functional and dynamic features degrade the performance\nand precision of static analysis. Moreover, the variety of built-in functions\nand host environments requires excessive manual modeling of their behaviors. To\nalleviate these problems, researchers have proposed various ways to leverage\ndynamic analysis during JavaScript static analysis. However, they do not fully\nutilize the high performance of dynamic analysis and often sacrifice the\nsoundness of static analysis.\nIn this paper, we present dynamic shortcuts, a new technique to flexibly\nswitch between abstract and concrete execution during JavaScript static\nanalysis in a sound way. It can significantly improve the analysis performance\nand precision by using highly-optimized commercial JavaScript engines and\nlessen the modeling efforts for opaque code. We actualize the technique via\n$\\text{SAFE}_\\textsf{DS}$, an extended combination of $\\text{SAFE}$ and\nJalangi, a static analyzer and a dynamic analyzer, respectively. We evaluated\n$\\text{SAFE}_\\textsf{DS}$ using 269 official tests of Lodash 4 library. Our\nexperiment shows that $\\text{SAFE}_\\textsf{DS}$ is 7.81x faster than the\nbaseline static analyzer, and it improves the precision to reduce failed\nassertions by 12.31% on average for 22 opaque functions.",
    "descriptor": "\nComments: 16 pages, 11 figures, 1 table, In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21)\n",
    "authors": [
      "Joonyoung Park",
      "Jihyeok Park",
      "Dongjun Youn",
      "Sukyoung Ryu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13699"
  },
  {
    "id": "arXiv:2105.13700",
    "title": "Fair and Adventurous Enumeration of Quantifier Instantiations",
    "abstract": "SMT solvers generally tackle quantifiers by instantiating their variables\nwith tuples of terms from the ground part of the formula. Recent enumerative\napproaches for quantifier instantiation consider tuples of terms in some\nheuristic order. This paper studies different strategies to order such tuples\nand their impact on performance. We decouple the ordering problem into two\nparts. First is the order of the sequence of terms to consider for each\nquantified variable, and second is the order of the instantiation tuples\nthemselves. While the most and least preferred tuples, i.e. those with all\nvariables assigned to the most or least preferred terms, are clear, the\ncombinations in between allow flexibility in an implementation. We look at\nprincipled strategies of complete enumeration, where some strategies are more\nfair, meaning they treat all the variables the same but some strategies may be\nmore adventurous, meaning that they may venture further down the preference\nlist. We further describe new techniques for discarding irrelevant\ninstantiations which are crucial for the performance of these strategies in\npractice. These strategies are implemented in the SMT solver cvc5, where they\ncontribute to the diversification of the solver's configuration space, as shown\nby our experimental results.",
    "descriptor": "",
    "authors": [
      "Mikol\u00e1\u0161 Janota",
      "Haniel Barbosa",
      "Pascal Fontaine",
      "Andrew Reynolds"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13700"
  },
  {
    "id": "arXiv:2105.13703",
    "title": "SPFA: SFA on Multiple Persistent Faults",
    "abstract": "For classical fault analysis, a transient fault is required to be injected\nduring runtime, e.g., only at a specific round. Instead, Persistent Fault\nAnalysis (PFA) introduces a powerful class of fault attacks that allows for a\nfault to be present throughout the whole execution. One limitation of original\nPFA as introduced by Zhang et al. at CHES'18 is that the faulty values need to\nbe known to the adversary. While this was addressed at a follow-up work at\nCHES'20, the solution is only applicable to a single faulty value. Instead, we\nuse the potency of Statistical Fault Analysis (SFA) in the persistent fault\nsetting, presenting Statistical Persistent Fault Analysis (SPFA) as a more\ngeneral approach of PFA. As a result, any or even a multitude of unknown faults\nthat cause an exploitable bias in the targeted round can be used to recover the\ncipher's secret key. Indeed, the undesired faults in the other rounds that\noccur due the persistent nature of the attack converge to a uniform\ndistribution as required by SFA. We verify the effectiveness of our attack\nagainst LED and AES.",
    "descriptor": "",
    "authors": [
      "Susanne Engels",
      "Falk Schellenberg",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13703"
  },
  {
    "id": "arXiv:2105.13704",
    "title": "Natural Language Processing 4 All (NLP4All): A New Online Platform for  Teaching and Learning NLP Concepts",
    "abstract": "Natural Language Processing offers new insights into language data across\nalmost all disciplines and domains, and allows us to corroborate and/or\nchallenge existing knowledge. The primary hurdles to widening participation in\nand use of these new research tools are, first, a lack of coding skills in\nstudents across K-16, and in the population at large, and second, a lack of\nknowledge of how NLP-methods can be used to answer questions of disciplinary\ninterest outside of linguistics and/or computer science. To broaden\nparticipation in NLP and improve NLP-literacy, we introduced a new tool\nweb-based tool called Natural Language Processing 4 All (NLP4All). The intended\npurpose of NLP4All is to help teachers facilitate learning with and about NLP,\nby providing easy-to-use interfaces to NLP-methods, data, and analyses, making\nit possible for non- and novice-programmers to learn NLP concepts\ninteractively.",
    "descriptor": "\nComments: Accepted to the 5th Workshop on Teaching NLP at NAACL-HLT 2021\n",
    "authors": [
      "Rebekah Baglini",
      "Arthur Hjorth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13704"
  },
  {
    "id": "arXiv:2105.13710",
    "title": "OTTers: One-turn Topic Transitions for Open-Domain Dialogue",
    "abstract": "Mixed initiative in open-domain dialogue requires a system to pro-actively\nintroduce new topics. The one-turn topic transition task explores how a system\nconnects two topics in a cooperative and coherent manner. The goal of the task\nis to generate a \"bridging\" utterance connecting the new topic to the topic of\nthe previous conversation turn. We are especially interested in commonsense\nexplanations of how a new topic relates to what has been mentioned before. We\nfirst collect a new dataset of human one-turn topic transitions, which we call\nOTTers. We then explore different strategies used by humans when asked to\ncomplete such a task, and notice that the use of a bridging utterance to\nconnect the two topics is the approach used the most. We finally show how\nexisting state-of-the-art text generation models can be adapted to this task\nand examine the performance of these baselines on different splits of the\nOTTers data.",
    "descriptor": "",
    "authors": [
      "Karin Sevegnani",
      "David M. Howcroft",
      "Ioannis Konstas",
      "Verena Rieser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13710"
  },
  {
    "id": "arXiv:2105.13717",
    "title": "Coverage Analysis of Cellular-Connected UAV Communications with 3GPP  Antenna and Channel Models",
    "abstract": "For reliable and efficient communications of aerial platforms, such as\nunmanned aerial vehicles (UAVs), the cellular network is envisioned to provide\nconnectivity for the aerial and ground user equipment (GUE) simultaneously,\nwhich brings challenges to the existing pattern of the base station (BS)\ntailored for ground-level services. Thus, we focus on the coverage probability\nanalysis to investigate the coexistence of aerial and terrestrial users, by\nemploying realistic antenna and channel models reported in the 3rd Generation\nPartnership Project (3GPP). The homogeneous Poisson point process (PPP) is used\nto describe the BS distribution, and the BS antenna is adjustable in the\ndown-tilted angle and the number of the antenna array. Meantime,\nomnidirectional antennas are used for cellular users. We first derive the\napproximation of coverage probability and then conduct numerous simulations to\nevaluate the impacts of antenna numbers, down-tilted angles, carrier\nfrequencies, and user heights. One of the essential findings indicates that the\ncoverage probabilities of high-altitude users become less sensitive to the\ndown-tilted angle. Moreover, we found that the aerial user equipment (AUE) in a\ncertain range of heights can achieve the same or better coverage probability\nthan that of GUE, which provides an insight into the effective deployment of\ncellular-connected aerial communications.",
    "descriptor": "",
    "authors": [
      "Zhuangzhuang Cui",
      "Ke Guan",
      "\u0130smail G\u00fcven\u00e7",
      "Claude Oestges",
      "Zhangdui Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.13717"
  },
  {
    "id": "arXiv:2105.13718",
    "title": "Voice Activity Detection for Ultrasound-based Silent Speech Interfaces  using Convolutional Neural Networks",
    "abstract": "Voice Activity Detection (VAD) is not easy task when the input audio signal\nis noisy, and it is even more complicated when the input is not even an audio\nrecording. This is the case with Silent Speech Interfaces (SSI) where we record\nthe movement of the articulatory organs during speech, and we aim to\nreconstruct the speech signal from this recording. Our SSI system synthesizes\nspeech from ultrasonic videos of the tongue movement, and the quality of the\nresulting speech signals are evaluated by metrics such as the mean squared\nerror loss function of the underlying neural network and the Mel-Cepstral\nDistortion (MCD) of the reconstructed speech compared to the original. Here, we\nfirst demonstrate that the amount of silence in the training data can have an\ninfluence both on the MCD evaluation metric and on the performance of the\nneural network model. Then, we train a convolutional neural network classifier\nto separate silent and speech-containing ultrasound tongue images, using a\nconventional VAD algorithm to create the training labels from the corresponding\nspeech signal. In the experiments our ultrasound-based speech/silence separator\nachieved a classification accuracy of about 85\\% and an AUC score around 86\\%.",
    "descriptor": "\nComments: 12 pages, 7 tables, 4 figures\n",
    "authors": [
      "Amin Honarmandi Shandiz",
      "L\u00e1szl\u00f3 T\u00f3th"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13718"
  },
  {
    "id": "arXiv:2105.13719",
    "title": "On the condition number of the shifted real Ginibre ensemble",
    "abstract": "We derive an accurate lower tail estimate on the lowest singular value\n$\\sigma_1(X-z)$ of a real Gaussian (Ginibre) random matrix $X$ shifted by a\ncomplex parameter $z$. Such shift effectively changes the upper tail behaviour\nof the condition number $\\kappa(X-z)$ from the slower\n$\\mathbf{P}(\\kappa(X-z)\\ge t)\\lesssim 1/t$ decay typical for real Ginibre\nmatrices to the faster $1/t^2$ decay seen for complex Ginibre matrices as long\nas $z$ is away from the real axis. This sharpens and resolves a recent\nconjecture in [arXiv:2005.08930] on the regularizing effect of the real Ginibre\nensemble with a genuinely complex shift. As a consequence we obtain an improved\nupper bound on the eigenvalue condition numbers (known also as the eigenvector\noverlaps) for real Ginibre matrices. The main technical tool is a rigorous\nsupersymmetric analysis from our earlier work [arXiv:1908.01653].",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Giorgio Cipolloni",
      "L\u00e1szl\u00f3 Erd\u0151s",
      "Dominik Schr\u00f6der"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13719"
  },
  {
    "id": "arXiv:2105.13723",
    "title": "A New Algorithm for the LQR Problem with Partially Unknown Dynamics",
    "abstract": "We consider an LQR optimal control problem with partially unknown dynamics.\nWe propose a new model-based online algorithm to obtain an approximation of the\ndynamics $and$ the control at the same time during a single simulation.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to a conference proceeedings\n",
    "authors": [
      "Agnese Pacifico",
      "Andrea Pesare",
      "Maurizio Falcone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13723"
  },
  {
    "id": "arXiv:2105.13725",
    "title": "Promoting the Acquisition of Hardware Reverse Engineering Skills",
    "abstract": "This full research paper focuses on skill acquisition in Hardware Reverse\nEngineering (HRE) - an important field of cyber security. HRE is a prevalent\ntechnique routinely employed by security engineers (i) to detect malicious\nhardware manipulations, (ii) to conduct VLSI failure analysis, (iii) to\nidentify IP infringements, and (iv) to perform competitive analyses. Even\nthough the scientific community and industry have a high demand for HRE\nexperts, there is a lack of educational courses. We developed a\nuniversity-level HRE course based on general cognitive psychological research\non skill acquisition, as research on the acquisition of HRE skills is lacking\nthus far. To investigate how novices acquire HRE skills in our course, we\nconducted two studies with students on different levels of prior knowledge. Our\nresults show that cognitive factors (e.g., working memory), and prior\nexperiences (e.g., in symmetric cryptography) influence the acquisition of HRE\nskills. We conclude by discussing implications for future HRE courses and by\noutlining ideas for future research that would lead to a more comprehensive\nunderstanding of skill acquisition in this important field of cyber security.",
    "descriptor": "",
    "authors": [
      "Carina Wiesen",
      "Steffen Becker",
      "Nils Albartus Christof Paar",
      "Nikol Rummel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.13725"
  },
  {
    "id": "arXiv:2105.13728",
    "title": "An Explanatory Query-Based Framework for Exploring Academic Expertise",
    "abstract": "The success of research institutions heavily relies upon identifying the\nright researchers \"for the job\": researchers may need to identify appropriate\ncollaborators, often from across disciplines; students may need to identify\nsuitable supervisors for projects of their interest; administrators may need to\nmatch funding opportunities with relevant researchers, and so on. Usually,\nfinding potential collaborators in institutions is a time-consuming manual\nsearch task prone to bias. In this paper, we propose a novel query-based\nframework for searching, scoring, and exploring research expertise\nautomatically, based upon processing abstracts of academic publications. Given\nuser queries in natural language, our framework finds researchers with relevant\nexpertise, making use of domain-specific knowledge bases and word embeddings.\nIt also generates explanations for its recommendations. We evaluate our\nframework with an institutional repository of papers from a leading university,\nusing, as baselines, artificial neural networks and transformer-based models\nfor a multilabel classification task to identify authors of publication\nabstracts. We also assess the cross-domain effectiveness of our framework with\na (separate) research funding repository for the same institution. We show that\nour simple method is effective in identifying matches, while satisfying\ndesirable properties and being efficient.",
    "descriptor": "",
    "authors": [
      "Oana Cocarascu",
      "Andrew McLean Paul French",
      "Francesca Toni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13728"
  },
  {
    "id": "arXiv:2105.13729",
    "title": "Matchings and Copeland's Method",
    "abstract": "Given a graph $G = (V,E)$ where every vertex has weak preferences over its\nneighbors, we consider the problem of computing an optimal matching as per\nagent preferences. The classical notion of optimality in this setting is\nstability. However stable matchings, and more generally, popular matchings need\nnot exist when $G$ is non-bipartite. Unlike popular matchings, Copeland winners\nalways exist in any voting instance -- we study the complexity of computing a\nmatching that is a Copeland winner and show there is no polynomial-time\nalgorithm for this problem unless $\\mathsf{P} = \\mathsf{NP}$.\nWe introduce a relaxation of both popular matchings and Copeland winners\ncalled semi-Copeland winners. These are matchings with Copeland score at least\n$\\mu/2$, where $\\mu$ is the total number of matchings in $G$; the maximum\npossible Copeland score is $(\\mu-1/2)$. We show a fully polynomial-time\nrandomized approximation scheme to compute a matching with Copeland score at\nleast $\\mu/2\\cdot(1-\\varepsilon)$ for any $\\varepsilon > 0$.",
    "descriptor": "",
    "authors": [
      "Telikepalli Kavitha",
      "Rohit Vaish"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.13729"
  },
  {
    "id": "arXiv:2105.13731",
    "title": "DeepTag: A General Framework for Fiducial Marker Design and Detection",
    "abstract": "A fiducial marker system usually consists of markers, a detection algorithm,\nand a coding system. The appearance of markers and the detection robustness are\ngenerally limited by the existing detection algorithms, which are hand-crafted\nwith traditional low-level image processing techniques. Furthermore, a\nsophisticatedly designed coding system is required to overcome the shortcomings\nof both markers and detection algorithms. To improve the flexibility and\nrobustness in various applications, we propose a general deep learning based\nframework, DeepTag, for fiducial marker design and detection. DeepTag not only\nsupports detection of a wide variety of existing marker families, but also\nmakes it possible to design new marker families with customized local patterns.\nMoreover, we propose an effective procedure to synthesize training data on the\nfly without manual annotations. Thus, DeepTag can easily adapt to existing and\nnewly-designed marker families. To validate DeepTag and existing methods,\nbeside existing datasets, we further collect a new large and challenging\ndataset where markers are placed in different view distances and angles.\nExperiments show that DeepTag well supports different marker families and\ngreatly outperforms the existing methods in terms of both detection robustness\nand pose accuracy. Both code and dataset are available at\n\\url{https://herohuyongtao.github.io/research/publications/deep-tag/}.",
    "descriptor": "\nComments: preprint in submission\n",
    "authors": [
      "Zhuming Zhang",
      "Yongtao Hu",
      "Guoxing Yu",
      "Jingwen Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13731"
  },
  {
    "id": "arXiv:2105.13732",
    "title": "SoK: Achieving State Machine Replication in Blockchains based on  Repeated Consensus",
    "abstract": "This paper revisits the ubiquitous problem of achieving state machine\nreplication in blockchains based on repeated consensus, like Tendermint. To\nachieve state machine replication in blockchains built on top of consensus, one\nneeds to guarantee fairness of user transactions. A huge body of work has been\ncarried out on the relation between state machine replication and consensus in\nthe past years, in a variety of system models and with respect to varied\nproblem specifications. We systematize this work by proposing novel and\nrigorous abstractions for state machine replication and repeated consensus in a\nsystem model that accounts for realistic blockchains in which blocks may\ncontain several transactions issued by one or more users, and where validity\nand order of transactions within a block is determined by an external\napplication-dependent function that can capture various approaches for\norder-fairness in the literature. Based on these abstractions, we propose a\nreduction from state machine replication to repeated consensus, such that user\nfairness is achieved using the consensus module as a black box. This approach\nallows to achieve fairness as an add-on on top of preexisting consensus modules\nin blockchains based on repeated consensus.",
    "descriptor": "\nComments: 10 pages, 2 figures, 5 algorithms\n",
    "authors": [
      "Silvia Bonomi",
      "Antonella Del Pozzo",
      "\u00c1lvaro Garc\u00eda-P\u00e9rez",
      "Sara Tucci-Piergiovanni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13732"
  },
  {
    "id": "arXiv:2105.13733",
    "title": "FAST CAT: Collaborative Data Entry and Curation for Semantic  Interoperability in Digital Humanities",
    "abstract": "Descriptive and empirical sciences, such as History, are the sciences that\ncollect, observe and describe phenomena in order to explain them and draw\ninterpretative conclusions about influences, driving forces and impacts under\ngiven circumstances. Spreadsheet software and relational database management\nsystems are still the dominant tools for quantitative analysis and overall data\nmanagement in these these sciences, allowing researchers to directly analyse\nthe gathered data and perform scholarly interpretation. However, this current\npractice has a set of limitations, including the high dependency of the\ncollected data on the initial research hypothesis, usually useless for other\nresearch, the lack of representation of the details from which the registered\nrelations are inferred, and the difficulty to revisit the original data sources\nfor verification, corrections or improvements. To cope with these problems, in\nthis paper we present FAST CAT, a collaborative system for assistive data entry\nand curation in Digital Humanities and similar forms of empirical research. We\ndescribe the related challenges, the overall methodology we follow for\nsupporting semantic interoperability, and discuss the use of FAST CAT in the\ncontext of a European (ERC) project of Maritime History, called SeaLiT, which\nexamines economic, social and demographic impacts of the introduction of\nsteamboats in the Mediterranean area between the 1850s and the 1920s.",
    "descriptor": "\nComments: This is a preprint of an article accepted for publication at the ACM Journal on Computing and Cultural Heritage (JOCCH)\n",
    "authors": [
      "Pavlos Fafalios",
      "Kostas Petrakis",
      "Georgios Samaritakis",
      "Korina Doerr",
      "Athina Kritsotaki",
      "Yannis Tzitzikas",
      "Martin Doerr"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.13733"
  },
  {
    "id": "arXiv:2105.13744",
    "title": "Grammar Index By Induced Suffix Sorting",
    "abstract": "Pattern matching is the most central task for text indices. Most recent\nindices leverage compression techniques to make pattern matching feasible for\nmassive but highly-compressible datasets. Within this kind of indices, we\npropose a new compressed text index built upon a grammar compression based on\ninduced suffix sorting [Nunes et al., DCC'18]. We show that this grammar\nexhibits a locality sensitive parsing property, which allows us to specify,\ngiven a pattern $P$, certain substrings of $P$, called cores, that are\nsimilarly parsed in the text grammar whenever these occurrences are extensible\nto occurrences of $P$. Supported by the cores, given a pattern of length $m$,\nwe can locate all its $occ$ occurrences in a text $T$ of length $n$ within $O(m\n\\lg |\\mathcal{S}| + occ_C \\lg|\\mathcal{S}| \\lg n + occ)$ time, where\n$\\mathcal{S}$ is the set of all characters and non-terminals, $occ$ is the\nnumber of occurrences, and $occ_C$ is the number of occurrences of a chosen\ncore $C$ of $P$ in the right hand side of all production rules of the grammar\nof $T$. Our grammar index requires $O(g)$ words of space and can be built in\n$O(n)$ time using $O(g)$ working space, where $g$ is the sum of the right hand\nsides of all production rules. We underline the strength of our grammar index\nwith an exhaustive practical evaluation that gives evidence that our proposed\nsolution excels at locating long patterns in highly-repetitive texts.",
    "descriptor": "\nComments: Our implementation is available at this https URL\n",
    "authors": [
      "Tooru Akagi",
      "Dominik K\u00f6ppl",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Hideo Bannai",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.13744"
  },
  {
    "id": "arXiv:2105.13745",
    "title": "Robust Regularization with Adversarial Labelling of Perturbed Samples",
    "abstract": "Recent researches have suggested that the predictive accuracy of neural\nnetwork may contend with its adversarial robustness. This presents challenges\nin designing effective regularization schemes that also provide strong\nadversarial robustness. Revisiting Vicinal Risk Minimization (VRM) as a\nunifying regularization principle, we propose Adversarial Labelling of\nPerturbed Samples (ALPS) as a regularization scheme that aims at improving the\ngeneralization ability and adversarial robustness of the trained model. ALPS\ntrains neural networks with synthetic samples formed by perturbing each\nauthentic input sample towards another one along with an adversarially assigned\nlabel. The ALPS regularization objective is formulated as a min-max problem, in\nwhich the outer problem is minimizing an upper-bound of the VRM loss, and the\ninner problem is L$_1$-ball constrained adversarial labelling on perturbed\nsample. The analytic solution to the induced inner maximization problem is\nelegantly derived, which enables computational efficiency. Experiments on the\nSVHN, CIFAR-10, CIFAR-100 and Tiny-ImageNet datasets show that the ALPS has a\nstate-of-the-art regularization performance while also serving as an effective\nadversarial training scheme.",
    "descriptor": "\nComments: Accepted to IJCAI2021\n",
    "authors": [
      "Xiaohui Guo",
      "Richong Zhang",
      "Yaowei Zheng",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13745"
  },
  {
    "id": "arXiv:2105.13748",
    "title": "Application of a Generalized Secant Method to Nonlinear Equations with  Complex Roots",
    "abstract": "The secant method is a very effective numerical procedure used for solving\nnonlinear equations of the form $f(x)=0$. In a recent work [A. Sidi,\nGeneralization of the secant method for nonlinear equations. {\\em Appl. Math.\nE-Notes}, 8:115--123, 2008] we presented a generalization of the secant method\nthat uses only one evaluation of $f(x)$ per iteration, and we provided a local\nconvergence theory for it that concerns real roots. For each integer $k$, this\nmethod generates a sequence $\\{x_n\\}$ of approximations to a real root of\n$f(x)$, where, for $n\\geq k$, $x_{n+1}=x_n-f(x_n)/p'_{n,k}(x_n)$, $p_{n,k}(x)$\nbeing the polynomial of degree $k$ that interpolates $f(x)$ at\n$x_n,x_{n-1},\\ldots,x_{n-k}$, the order $s_k$ of this method satisfying\n$1<s_k<2$. Clearly, when $k=1$, this method reduces to the secant method with\n$s_1=(1+\\sqrt{5})/2$. In addition, $s_1<s_2<s_3<\\cdots,$ such that and\n$\\lim_{k\\to\\infty}s_k=2$. In this note, we study the application of this method\nto simple complex roots of a real or complex function $f(z)$. We show that the\nlocal convergence theory developed for real roots can be extended almost as is\nto complex roots, provided suitable assumptions and justifications are made. We\nillustrate the theory with two numerical examples.",
    "descriptor": "\nComments: 10 pages, 2 tables. arXiv admin note: text overlap with arXiv:2012.04248\n",
    "authors": [
      "Avram Sidi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13748"
  },
  {
    "id": "arXiv:2105.13753",
    "title": "New Image Captioning Encoder via Semantic Visual Feature Matching for  Heavy Rain Images",
    "abstract": "Image captioning generates text that describes scenes from input images. It\nhas been developed for high quality images taken in clear weather. However, in\nbad weather conditions, such as heavy rain, snow, and dense fog, the poor\nvisibility owing to rain streaks, rain accumulation, and snowflakes causes a\nserious degradation of image quality. This hinders the extraction of useful\nvisual features and results in deteriorated image captioning performance. To\naddress practical issues, this study introduces a new encoder for captioning\nheavy rain images. The central idea is to transform output features extracted\nfrom heavy rain input images into semantic visual features associated with\nwords and sentence context. To achieve this, a target encoder is initially\ntrained in an encoder-decoder framework to associate visual features with\nsemantic words. Subsequently, the objects in a heavy rain image are rendered\nvisible by using an initial reconstruction subnetwork (IRS) based on a heavy\nrain model. The IRS is then combined with another semantic visual feature\nmatching subnetwork (SVFMS) to match the output features of the IRS with the\nsemantic visual features of the pretrained target encoder. The proposed encoder\nis based on the joint learning of the IRS and SVFMS. It is is trained in an\nend-to-end manner, and then connected to the pretrained decoder for image\ncaptioning. It is experimentally demonstrated that the proposed encoder can\ngenerate semantic visual features associated with words even from heavy rain\nimages, thereby increasing the accuracy of the generated captions.",
    "descriptor": "",
    "authors": [
      "Chang-Hwan Son",
      "Pung-Hwi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13753"
  },
  {
    "id": "arXiv:2105.13754",
    "title": "Embedded Vision for Self-Driving on Forest Roads",
    "abstract": "Forest roads in Romania are unique natural wildlife sites used for recreation\nby countless tourists. In order to protect and maintain these roads, we propose\nRovisLab AMTU (Autonomous Mobile Test Unit), which is a robotic system designed\nto autonomously navigate off-road terrain and inspect if any deforestation or\ndamage occurred along tracked route. AMTU's core component is its embedded\nvision module, optimized for real-time environment perception. For achieving a\nhigh computation speed, we use a learning system to train a multi-task Deep\nNeural Network (DNN) for scene and instance segmentation of objects, while the\nkeypoints required for simultaneous localization and mapping are calculated\nusing a handcrafted FAST feature detector and the Lucas-Kanade tracking\nalgorithm. Both the DNN and the handcrafted backbone are run in parallel on the\nGPU of an NVIDIA AGX Xavier board. We show experimental results on the test\ntrack of our research facility.",
    "descriptor": "",
    "authors": [
      "Sorin Grigorescu",
      "Mihai Zaha",
      "Bogdan Trasnea",
      "Cosmin Ginerica"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13754"
  },
  {
    "id": "arXiv:2105.13755",
    "title": "The Generation of Security Scoring Systems Leveraging Human Expert  Opinion",
    "abstract": "While the existence of many security elements can be measured (e.g.,\nvulnerabilities, security controls, or privacy controls), it is challenging to\nmeasure their relative security impact. In the physical world we can often\nmeasure the impact of individual elements to a system. However, in cyber\nsecurity we often lack ground truth (i.e., the ability to directly measure\nsignificance). In this work we propose to solve this by leveraging human expert\nopinion to provide ground truth. Experts are iteratively asked to compare pairs\nof security elements to determine their relative significance. On the back end\nour knowledge encoding tool performs a form of binary insertion sort on a set\nof security elements using each expert as an oracle for the element\ncomparisons. The tool not only sorts the elements (note that equality may be\npermitted), but it also records the strength or degree of each relationship.\nThe output is a directed acyclic `constraint' graph that provides a total\nordering among the sets of equivalent elements. Multiple constraint graphs are\nthen unified together to form a single graph that is used to generate a scoring\nor prioritization system. For our empirical study, we apply this\ndomain-agnostic measurement approach to generate scoring/prioritization systems\nin the areas of vulnerability scoring, privacy control prioritization, and\ncyber security control evaluation.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Peter Mell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13755"
  },
  {
    "id": "arXiv:2105.13756",
    "title": "The Unpatchable Silicon: A Full Break of the Bitstream Encryption of  Xilinx 7-Series FPGAs",
    "abstract": "The security of FPGAs is a crucial topic, as any vulnerability within the\nhardware can have severe consequences, if they are used in a secure design.\nSince FPGA designs are encoded in a bitstream, securing the bitstream is of the\nutmost importance. Adversaries have many motivations to recover and manipulate\nthe bitstream, including design cloning, IP theft, manipulation of the design,\nor design subversions e.g., through hardware Trojans. Given that FPGAs are\noften part of cyber-physical systems e.g., in aviation, medical, or industrial\ndevices, this can even lead to physical harm. Consequently, vendors have\nintroduced bitstream encryption, offering authenticity and confidentiality.\nEven though attacks against bitstream encryption have been proposed in the\npast, e.g., side-channel analysis and probing, these attacks require\nsophisticated equipment and considerable technical expertise. In this paper, we\nintroduce novel low-cost attacks against the Xilinx 7-Series (and Virtex-6)\nbitstream encryption, resulting in the total loss of authenticity and\nconfidentiality. We exploit a design flaw which piecewise leaks the decrypted\nbitstream. In the attack, the FPGA is used as a decryption oracle, while only\naccess to a configuration interface is needed. The attack does not require any\nsophisticated tools and, depending on the target system, can potentially be\nlaunched remotely. In addition to the attacks, we discuss several\ncountermeasures.",
    "descriptor": "",
    "authors": [
      "Maik Ender",
      "Amir Moradi",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13756"
  },
  {
    "id": "arXiv:2105.13762",
    "title": "Inferring community characteristics in labelled networks",
    "abstract": "Labelled networks form a very common and important class of data, naturally\nappearing in numerous applications in science and engineering. A typical\ninference goal is to determine how the vertex labels(or {\\em features}) affect\nthe network's graph structure. A standard approach has been to partition the\nnetwork into blocks grouped by distinct values of the feature of interest. A\nblock-based random graph model -- typically a variant of the stochastic block\nmodel -- is then used to test for evidence of asymmetric behaviour within these\nfeature-based communities. Nevertheless, the resulting communities often do not\nproduce a natural partition of the graph. In this work, we introduce a new\ngenerative model, the feature-first block model (FFBM), which is more effective\nat describing vertex-labelled undirected graphs and also facilitates the use of\nricher queries on labelled networks. We develop a Bayesian framework for\ninference with this model, and we present a method to efficiently sample from\nthe posterior distribution of the FFBM parameters. The FFBM's structure is kept\ndeliberately simple to retain easy interpretability of the parameter values. We\napply the proposed methods to a variety of network data to extract the most\nimportant features along which the vertices are partitioned. The main\nadvantages of the proposed approach are that the whole feature-space is used\nautomatically, and features can be rank-ordered implicitly according to impact.\nAny features that do not significantly impact the high-level structure can be\ndiscarded to reduce the problem dimension. In cases where the vertex features\navailable do not readily explain the community structure in the resulting\nnetwork, the approach detects this and is protected against over-fitting.\nResults on several real-world datasets illustrate the performance of the\nproposed methods.",
    "descriptor": "",
    "authors": [
      "Ioannis Kontoyiannis",
      "Lawrence Tray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13762"
  },
  {
    "id": "arXiv:2105.13765",
    "title": "Exploiting Transductive Property of Graph Convolutional Neural Networks  with Less Labeling Effort",
    "abstract": "Recently, machine learning approaches on Graph data have become very popular.\nIt was observed that significant results were obtained by including implicit or\nexplicit logical connections between data samples that make up the data to the\nmodel. In this context, the developing GCN model has made significant\nexperimental contributions with Convolution filters applied to graph data. This\nmodel follows Transductive and Semi-Supervised Learning approach. Due to its\ntransductive property, all of the data samples, which is partially labeled, are\ngiven as input to the model. Labeling, which is a cost, is very important.\nWithin the scope of this study, the following research question is tried to be\nanswered: If at least how many samples are labeled, the optimum model success\nis achieved? In addition, some experimental contributions have been made on the\naccuracy of the model, whichever sampling approach is used with fixed labeling\neffort. According to the experiments, the success of the model can be increased\nby using the local centrality metric.",
    "descriptor": "",
    "authors": [
      "Yasir Kilic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13765"
  },
  {
    "id": "arXiv:2105.13769",
    "title": "ARMORY: Fully Automated and Exhaustive Fault Simulation on ARM-M  Binaries",
    "abstract": "Embedded systems are ubiquitous. However, physical access of users and\nlikewise attackers makes them often threatened by fault attacks: a single fault\nduring the computation of a cryptographic primitive can lead to a total loss of\nsystem security. This can have serious consequences, e.g., in safetycritical\nsystems, including bodily harm and catastrophic technical failures. However,\ncountermeasures often focus on isolated fault models and high layers of\nabstraction. This leads to a dangerous sense of security, because exploitable\nfaults that are only visible at machine code level might not be covered by\ncountermeasures. In this work we present ARMORY, a fully automated open source\nframework for exhaustive fault simulation on binaries of the ubiquitous ARM-M\nclass. It allows engineers and analysts to efficiently scan a binary for\npotential weaknesses against arbitrary combinations of multi-variate fault\ninjections under a large variety of fault models. Using ARMORY, we demonstrate\nthe power of fully automated fault analysis and the dangerous implications of\napplying countermeasures without knowledge of physical addresses and offsets.\nWe exemplarily analyze two case studies, which are highly relevant for\npractice: a DFA on AES (cryptographic) and a secure bootloader\n(non-cryptographic). Our results show that indeed numerous exploitable faults\nfound by ARMORY which occur in the actual implementations are easily missed in\nmanual inspection. Crucially, most faults are only visible when taking machine\ncode information, i.e., addresses and offsets, into account. Surprisingly, we\nshow that a countermeasure that protects against one type of fault can actually\nlargely increase the vulnerability to other fault models. Our work demonstrates\nthe need for countermeasures that, at least in their evaluation, are not\nrestricted to isolated fault models and consider low-level information [...].",
    "descriptor": "",
    "authors": [
      "Max Hoffmann",
      "Falk Schellenberg",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13769"
  },
  {
    "id": "arXiv:2105.13771",
    "title": "Chromatic and spatial analysis of one-pixel attacks against an image  classifier",
    "abstract": "One-pixel attack is a curious way of deceiving neural network classifier by\nchanging only one pixel in the input image. The full potential and boundaries\nof this attack method are not yet fully understood. In this research, the\nsuccessful and unsuccessful attacks are studied in more detail to illustrate\nthe working mechanisms of a one-pixel attack. The data comes from our earlier\nstudies where we applied the attack against medical imaging. We used a real\nbreast cancer tissue dataset and a real classifier as the attack target. This\nresearch presents ways to analyze chromatic and spatial distributions of\none-pixel attacks. In addition, we present one-pixel attack confidence maps to\nillustrate the behavior of the target classifier. We show that the more\neffective attacks change the color of the pixel more, and that the successful\nattacks are situated at the center of the images. This kind of analysis is not\nonly useful for understanding the behavior of the attack but also the qualities\nof the classifying neural network.",
    "descriptor": "",
    "authors": [
      "Janne Alatalo",
      "Joni Korpihalkola",
      "Tuomo Sipola",
      "Tero Kokkonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13771"
  },
  {
    "id": "arXiv:2105.13774",
    "title": "Mapping urban socioeconomic inequalities in developing countries through  Facebook advertising data",
    "abstract": "Ending poverty in all its forms everywhere is the number one Sustainable\nDevelopment Goal of the UN 2030 Agenda. To monitor the progress towards such an\nambitious target, reliable, up-to-date and fine-grained measurements of\nsocioeconomic indicators are necessary. When it comes to socioeconomic\ndevelopment, novel digital traces can provide a complementary data source to\novercome the limits of traditional data collection methods, which are often not\nregularly updated and lack adequate spatial resolution. In this study, we\ncollect publicly available and anonymous advertising audience estimates from\nFacebook to predict socioeconomic conditions of urban residents, at a fine\nspatial granularity, in four large urban areas: Atlanta (USA), Bogot\\'a\n(Colombia), Santiago (Chile), and Casablanca (Morocco). We find that behavioral\nattributes inferred from the Facebook marketing platform can accurately map the\nsocioeconomic status of residential areas within cities, and that predictive\nperformance is comparable in both high and low-resource settings. We also show\nthat training a model on attributes of adult Facebook users, aged more than 25,\nleads to a more accurate mapping of socioeconomic conditions in all cities. Our\nwork provides additional evidence of the value of social advertising media data\nto measure human development.",
    "descriptor": "",
    "authors": [
      "Serena Giurgola",
      "Simone Piaggesi",
      "M\u00e1rton Karsai",
      "Yelena Mejova",
      "Andr\u00e9 Panisson",
      "Michele Tizzoni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.13774"
  },
  {
    "id": "arXiv:2105.13775",
    "title": "Incremental Learning of Probabilistic Movement Primitives (ProMPs) for  Human-Robot Cooperation",
    "abstract": "For a successful deployment of physical Human-Robot Cooperation (pHRC),\nhumans need to be able to teach robots new motor skills quickly. Probabilistic\nmovement primitives (ProMPs) are a promising method to encode a robot's motor\nskills learned from human demonstrations in pHRC settings. However, most\nalgorithms to learn ProMPs from human demonstrations operate in batch mode,\nwhich is not ideal in pHRC. In this paper we propose a new learning algorithm\nto learn ProMPs incrementally in pHRC settings. Our algorithm incorporates new\ndemonstrations sequentially as they arrive, allowing humans to observe the\nrobot's learning progress and incrementally shape the robot's motor skill. A\nbuilt in forgetting factor allows for corrective demonstrations resulting from\nthe human's learning curve or changes in task constraints. We compare the\nperformance of our algorithm to existing batch ProMP algorithms on reference\ndata generated from a pick-and-place task at our lab. Furthermore, we show in a\nproof of concept study on a Franka Emika Panda how the forgetting factor allows\nus to adopt changes in the task. The incremental learning algorithm presented\nin this paper has the potential to lead to a more intuitive learning progress\nand to establish a successful cooperation between human and robot faster than\ntraining in batch mode.",
    "descriptor": "\nComments: This work has been submitted to IROS 2021\n",
    "authors": [
      "Daniel Sch\u00e4le",
      "Martin F. Stoelen",
      "Erik Kyrkjeb\u00f8"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13775"
  },
  {
    "id": "arXiv:2105.13777",
    "title": "Linear Complexity of Binary Interleaved Sequences of Period 4n",
    "abstract": "Binary periodic sequences with good autocorrelation property have many\napplications in many aspects of communication. In past decades many series of\nsuch binary sequences have been constructed. In the application of\ncryptography, such binary sequences are required to have larger linear\ncomplexity. Tang and Ding \\cite{X. Tang} presented a method to construct a\nseries of binary sequences with period 4$n$ having optimal autocorrelation.\nSuch sequences are interleaved by two arbitrary binary sequences with period\n$n\\equiv 3\\pmod 4$ and ideal autocorrelation. In this paper we present a\ngeneral formula on the linear complexity of such interleaved sequences.\nParticularly, we show that the linear complexity of such sequences with period\n4$n$ is not bigger than $2n+2$. Interleaving by several types of known binary\nsequences with ideal autocorrelation ($m$-sequences, Legendre, twin-prime and\nHall's sequences), we present many series of such sequences having the maximum\nvalue $2n+2$ of linear complexity which gives an answer of a problem raised by\nN. Li and X. Tang \\cite{N. Li}. Finally, in the conclusion section we show that\nit can be seen easily that the 2-adic complexity of all such interleaved\nsequences reaches the maximum value $\\log_{2}(2^{4n}-1)$.",
    "descriptor": "",
    "authors": [
      "Qiuyue Liu",
      "Shiyuan Qiang",
      "Minghui Yang",
      "Keqin Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13777"
  },
  {
    "id": "arXiv:2105.13778",
    "title": "\"Why Would I Trust Your Numbers?\" On the Explainability of Expected  Values in Soccer",
    "abstract": "In recent years, many different approaches have been proposed to quantify the\nperformances of soccer players. Since player performances are challenging to\nquantify directly due to the low-scoring nature of soccer, most approaches\nestimate the expected impact of the players' on-the-ball actions on the\nscoreline. While effective, these approaches are yet to be widely embraced by\nsoccer practitioners. The soccer analytics community has primarily focused on\nimproving the accuracy of the models, while the explainability of the produced\nmetrics is often much more important to practitioners.\nTo help bridge the gap between scientists and practitioners, we introduce an\nexplainable Generalized Additive Model that estimates the expected value for\nshots. Unlike existing models, our model leverages features corresponding to\nwidespread soccer concepts. To this end, we represent the locations of shots by\nfuzzily assigning the shots to designated zones on the pitch that practitioners\nare familiar with. Our experimental evaluation shows that our model is as\naccurate as existing models, while being easier to explain to soccer\npractitioners.",
    "descriptor": "\nComments: Paper accepted for presentation at the AI for Sports Analytics workshop at IJCAI 2021\n",
    "authors": [
      "Jan Van Haaren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13778"
  },
  {
    "id": "arXiv:2105.13782",
    "title": "How to Split: the Effect of Word Segmentation on Gender Bias in Speech  Translation",
    "abstract": "Having recognized gender bias as a major issue affecting current translation\ntechnologies, researchers have primarily attempted to mitigate it by working on\nthe data front. However, whether algorithmic aspects concur to exacerbate\nunwanted outputs remains so far under-investigated. In this work, we bring the\nanalysis on gender bias in automatic translation onto a seemingly neutral yet\ncritical component: word segmentation. Can segmenting methods influence the\nability to translate gender? Do certain segmentation approaches penalize the\nrepresentation of feminine linguistic markings? We address these questions by\ncomparing 5 existing segmentation strategies on the target side of speech\ntranslation systems. Our results on two language pairs (English-Italian/French)\nshow that state-of-the-art sub-word splitting (BPE) comes at the cost of higher\ngender bias. In light of this finding, we propose a combined approach that\npreserves BPE overall translation quality, while leveraging the higher ability\nof character-based segmentation to properly translate gender.",
    "descriptor": "\nComments: Accepted in Findings of ACL 2021\n",
    "authors": [
      "Marco Gaido",
      "Beatrice Savoldi",
      "Luisa Bentivogli",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13782"
  },
  {
    "id": "arXiv:2105.13783",
    "title": "Quantile Encoder: Tackling High Cardinality Categorical Features in  Regression Problems",
    "abstract": "Regression problems have been widely studied in machinelearning literature\nresulting in a plethora of regression models and performance measures. However,\nthere are few techniques specially dedicated to solve the problem of how to\nincorporate categorical features to regression problems. Usually, categorical\nfeature encoders are general enough to cover both classification and regression\nproblems. This lack of specificity results in underperforming regression\nmodels. In this paper,we provide an in-depth analysis of how to tackle high\ncardinality categor-ical features with the quantile. Our proposal outperforms\nstate-of-the-encoders, including the traditional statistical mean target\nencoder, when considering the Mean Absolute Error, especially in the presence\nof long-tailed or skewed distributions. Besides, to deal with possible\noverfitting when there are categories with small support, our encoder benefits\nfrom additive smoothing. Finally, we describe how to expand the encoded values\nby creating a set of features with different quantiles. This expanded encoder\nprovides a more informative output about the categorical feature in question,\nfurther boosting the performance of the regression model.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Carlos Mougan",
      "David Masip",
      "Jordi Nin",
      "Oriol Pujol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13783"
  },
  {
    "id": "arXiv:2105.13787",
    "title": "Do not explain without context: addressing the blind spot of model  explanations",
    "abstract": "The increasing number of regulations and expectations of predictive machine\nlearning models, such as so called right to explanation, has led to a large\nnumber of methods promising greater interpretability. High demand has led to a\nwidespread adoption of XAI techniques like Shapley values, Partial Dependence\nprofiles or permutational variable importance. However, we still do not know\nenough about their properties and how they manifest in the context in which\nexplanations are created by analysts, reviewed by auditors, and interpreted by\nvarious stakeholders. This paper highlights a blind spot which, although\ncritical, is often overlooked when monitoring and auditing machine learning\nmodels: the effect of the reference data on the explanation calculation. We\ndiscuss that many model explanations depend directly or indirectly on the\nchoice of the referenced data distribution. We showcase examples where small\nchanges in the distribution lead to drastic changes in the explanations, such\nas a change in trend or, alarmingly, a conclusion. Consequently, we postulate\nthat obtaining robust and useful explanations always requires supporting them\nwith a broader context.",
    "descriptor": "",
    "authors": [
      "Katarzyna Wo\u017anica",
      "Katarzyna P\u0119kala",
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "El\u017cbieta Sienkiewicz",
      "Przemys\u0142aw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13787"
  },
  {
    "id": "arXiv:2105.13789",
    "title": "Using Convolutional Neural Networks for Relative Pose Estimation of a  Non-Cooperative Spacecraft with Thermal Infrared Imagery",
    "abstract": "Recent interest in on-orbit servicing and Active Debris Removal (ADR)\nmissions have driven the need for technologies to enable non-cooperative\nrendezvous manoeuvres. Such manoeuvres put heavy burden on the perception\ncapabilities of a chaser spacecraft. This paper demonstrates Convolutional\nNeural Networks (CNNs) capable of providing an initial coarse pose estimation\nof a target from a passive thermal infrared camera feed. Thermal cameras offer\na promising alternative to visible cameras, which struggle in low light\nconditions and are susceptible to overexposure. Often, thermal information on\nthe target is not available a priori; this paper therefore proposes using\nvisible images to train networks. The robustness of the models is demonstrated\non two different targets, first on synthetic data, and then in a laboratory\nenvironment for a realistic scenario that might be faced during an ADR mission.\nGiven that there is much concern over the use of CNN in critical applications\ndue to their black box nature, we use innovative techniques to explain what is\nimportant to our network and fault conditions.",
    "descriptor": "\nComments: 14 pages; 11 figures; European Space Agency Guidance, Navigation and Control Conference 2021\n",
    "authors": [
      "Maxwell Hogan",
      "Duarte Rondao",
      "Nabil Aouf",
      "Olivier Dubois-Matra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13789"
  },
  {
    "id": "arXiv:2105.13790",
    "title": "Optimality of Cross-validation in Scattered Data Approximation",
    "abstract": "Choosing models from a hypothesis space is a frequent task in approximation\ntheory and inverse problems. Cross-validation is a classical tool in the\nlearner's repertoire to compare the goodness of fit for different\nreconstruction models. Much work has been dedicated to computing this quantity\nin a fast manner but tackling its theoretical properties occurs to be\ndifficult. So far, most optimality results are stated in an asymptotic fashion.\nIn this paper we propose a concentration inequality on the difference of\ncross-validation score and the risk functional with respect to the squared\nerror. This gives a pre-asymptotic bound which holds with high probability. For\nthe assumptions we rely on bounds on the uniform error of the model which allow\nfor a broadly applicable framework.\nWe support our claims by applying this machinery to Shepard's model, where we\nare able to determine precise constants of the concentration inequality.\nNumerical experiments in combination with fast algorithms indicate the\napplicability of our results.",
    "descriptor": "",
    "authors": [
      "Felix Bartel",
      "Ralf Hielscher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13790"
  },
  {
    "id": "arXiv:2105.13791",
    "title": "The three-step workflow: a pragmatic approach to allocating academic  hospitals' affiliations for bibliometric purposes",
    "abstract": "This paper presents a method for classifying the varying degrees of\ninterdependency between academic hospitals and universities in the context of\nthe Leiden Ranking. A key question for ranking universities is whether or not\nto allocate the publication output of affiliated hospitals to universities.\nHospital nomenclatures vary worldwide to denote some form of collaboration with\na university: academic hospitals, teaching hospitals, university hospitals, and\nacademic medical centres do not correspond to universally standard definitions.\nThus, rather than seeking a normative definition of academic hospitals, we are\nproposing a workflow that aligns the university-hospital relationship with one\nof three general models: full integration of the hospital and the medical\nfaculty into a single organization; health science centres in which hospitals\nand medical faculty remain separate entities albeit within the same governance\nstructure; and structures in which universities and hospitals are separate\nentities which collaborate with one another. This classification system\nprovides a standard by which we can allocate publications which note\naffiliations with academic hospitals. Our three-step workflow effectively\ntranslates the three above-mentioned models into two types of instrumental\nrelationships for the assignation of publications: \"associate\" and \"component\".\nWhen a hospital and a medical faculty are fully integrated or when a hospital\nis part of a health science centre, the relationship is classified as\ncomponent. When a hospital follows the model of collaboration and support, the\nrelationship is classified as associate. The compilation of data following\nthese standards allows for a more uniform comparison between worldwide\neducational and research systems.",
    "descriptor": "\nComments: 19 pages, 4 figures, 1 table\n",
    "authors": [
      "Andrea Reyes Elizondo",
      "Clara Calero-Medina",
      "Martijn S. Visser"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.13791"
  },
  {
    "id": "arXiv:2105.13792",
    "title": "Early Exiting with Ensemble Internal Classifiers",
    "abstract": "As a simple technique to accelerate inference of large-scale pre-trained\nmodels, early exiting has gained much attention in the NLP community. It allows\nsamples to exit early at internal classifiers without passing through the\nentire model. Most existing work usually trains the internal classifiers\nindependently and employs an exiting strategy to decide whether or not to exit\nbased on the confidence of the current internal classifier. However, none of\nthese works takes full advantage of the fact that the internal classifiers are\ntrained to solve the same task therefore can be used to construct an ensemble.\nIn this paper, we show that a novel objective function for the training of the\nensemble internal classifiers can be naturally induced from the perspective of\nensemble learning and information theory. The proposed training objective\nconsists of two terms: one for accuracy and the other for the diversity of the\ninternal classifiers. In contrast, the objective used in prior work is exactly\nthe accuracy term of our training objective therefore only optimizes the\naccuracy but not diversity. Further, we propose a simple voting-based strategy\nthat considers predictions of all the past internal classifiers to infer the\ncorrect label and decide whether to exit. Experimental results on various NLP\ntasks show that our proposed objective function and voting-based strategy can\nachieve better accuracy-speed trade-offs.",
    "descriptor": "",
    "authors": [
      "Tianxiang Sun",
      "Yunhua Zhou",
      "Xiangyang Liu",
      "Xinyu Zhang",
      "Hao Jiang",
      "Zhao Cao",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13792"
  },
  {
    "id": "arXiv:2105.13794",
    "title": "The Wits Intelligent Teaching System: Detecting Student Engagement  During Lectures Using Convolutional Neural Networks",
    "abstract": "To perform contingent teaching and be responsive to students' needs during\nclass, lecturers must be able to quickly assess the state of their audience.\nWhile effective teachers are able to gauge easily the affective state of the\nstudents, as class sizes grow this becomes increasingly difficult and less\nprecise. The Wits Intelligent Teaching System (WITS) aims to assist lecturers\nwith real-time feedback regarding student affect. The focus is primarily on\nrecognising engagement or lack thereof. Student engagement is labelled based on\nbehaviour and postures that are common to classroom settings. These proxies are\nthen used in an observational checklist to construct a dataset of engagement\nupon which a CNN based on AlexNet is successfully trained and which\nsignificantly outperforms a Support Vector Machine approach. The deep learning\napproach provides satisfactory results on a challenging, real-world dataset\nwith significant occlusion, lighting and resolution constraints.",
    "descriptor": "",
    "authors": [
      "Richard Klein",
      "Turgay Celik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13794"
  },
  {
    "id": "arXiv:2105.13795",
    "title": "SLGCN: Structure Learning Graph Convolutional Networks for Graphs under  Heterophily",
    "abstract": "The performances of GNNs for representation learning on the graph-structured\ndata are generally limited to the issue that existing GNNs rely on one\nassumption, i.e., the original graph structure is reliable. However, since\nreal-world graphs is inevitably noisy or incomplete, this assumption is often\nunrealistic. In this paper, we propose a structure learning graph convolutional\nnetworks (SLGCNs) to alleviate the issue from two aspects, and the proposed\napproach is applied to node classification. Specifically, the first is node\nfeatures, we design a efficient-spectral-clustering with anchors (ESC-ANCH)\napproach to efficiently aggregate feature representationsfrom all similar\nnodes, no matter how far away they are. The second is edges, our approach\ngenerates a re-connected adjacency matrix according to the similarities between\nnodes and optimized for the downstream prediction task so as to make up for the\nshortcomings of original adjacency matrix, considering that the original\nadjacency matrix usually provides misleading information for aggregation step\nof GCN in the graphs with low level of homophily. Both the re-connected\nadjacency matrix and original adjacency matrix are applied to SLGCNs to\naggregate feature representations from nearby nodes. Thus, SLGCNs can be\napplied to graphs with various levels of homophily. Experimental results on a\nwide range of benchmark datasets illustrate that the proposed SLGCNs outperform\nthe stat-of-the-art GNN counterparts.",
    "descriptor": "",
    "authors": [
      "Mengying Jiang",
      "Guizhong Liu",
      "Yuanchao Su",
      "Xinliang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13795"
  },
  {
    "id": "arXiv:2105.13797",
    "title": "An unsupervised machine-learning checkpoint-restart algorithm using  Gaussian mixtures for particle-in-cell simulations",
    "abstract": "We propose an unsupervised machine-learning checkpoint-restart (CR) lossy\nalgorithm for particle-in-cell (PIC) algorithms using Gaussian mixtures (GM).\nThe algorithm features a particle compression stage and a particle\nreconstruction stage, where a continuum particle distribution function is\nconstructed and resampled, respectively. To guarantee fidelity of the CR\nprocess, we ensure the exact preservation of charge, momentum, and energy for\nboth compression and reconstruction stages, everywhere on the mesh. We also\nensure the preservation of Gauss' law after particle reconstruction. As a\nresult, the GM CR algorithm is shown to provide a clean, conservative restart\ncapability while potentially affording orders of magnitude savings in\ninput/output requirements. We demonstrate the algorithm using a recently\ndeveloped exactly energy- and charge-conserving PIC algorithm on physical\nproblems of interest, with compression factors $\\gtrsim75$ with no appreciable\nimpact on the quality of the restarted dynamics.",
    "descriptor": "\nComments: Extended abstract for Supercheck21. arXiv admin note: substantial text overlap with arXiv:2007.12273\n",
    "authors": [
      "Guangye Chen",
      "Luis Chac\u00f3n",
      "Truong B. Nguyen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13797"
  },
  {
    "id": "arXiv:2105.13799",
    "title": "Inaccuracy matters: accounting for solution accuracy in event-triggered  nonlinear model predictive control",
    "abstract": "We consider the effect of using approximate system predictions in\nevent-triggered control schemes. Such approximations may result from using\nnumerical transcription methods for solving continuous-time optimal control\nproblems. Mesh refinement can guarantee upper bounds on the error in the\ndifferential equations which model the system dynamics. With the accuracy\nguarantees of a mesh refinement scheme, we show that the proposed\nevent-triggering scheme -- which compares the measured system with approximate\nstate predictions -- can be used with a guaranteed strictly positive\ninter-update time. We show that if we have knowledge of the employed\ntranscription scheme or the approximation errors, then we can obtain better\nonline estimates of inter-update times. We additionally detail a method of\ntightening constraints on the approximate system trajectory used in the\nnonlinear programming problem to guarantee constraint satisfaction of the\ncontinuous-time system. This is the first work to incorporate prediction\naccuracy in triggering metrics. Using the solution accuracy we can guarantee\nreliable lower bounds for inter-update times and perform solution dependent\nconstraint tightening.",
    "descriptor": "\nComments: 14 pages, 11 figures, Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Omar J. Faqir",
      "Eric C. Kerrigan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13799"
  },
  {
    "id": "arXiv:2105.13802",
    "title": "DIVE: End-to-end Speech Diarization via Iterative Speaker Embedding",
    "abstract": "We introduce DIVE, an end-to-end speaker diarization algorithm. Our neural\nalgorithm presents the diarization task as an iterative process: it repeatedly\nbuilds a representation for each speaker before predicting the voice activity\nof each speaker conditioned on the extracted representations. This strategy\nintrinsically resolves the speaker ordering ambiguity without requiring the\nclassical permutation invariant training loss. In contrast with prior work, our\nmodel does not rely on pretrained speaker representations and optimizes all\nparameters of the system with a multi-speaker voice activity loss. Importantly,\nour loss explicitly excludes unreliable speaker turn boundaries from training,\nwhich is adapted to the standard collar-based Diarization Error Rate (DER)\nevaluation. Overall, these contributions yield a system redefining the\nstate-of-the-art on the standard CALLHOME benchmark, with 6.7% DER compared to\n7.8% for the best alternative.",
    "descriptor": "",
    "authors": [
      "Neil Zeghidour",
      "Olivier Teboul",
      "David Grangier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13802"
  },
  {
    "id": "arXiv:2105.13806",
    "title": "DRL: Deep Reinforcement Learning for Intelligent Robot Control --  Concept, Literature, and Future",
    "abstract": "Combination of machine learning (for generating machine intelligence),\ncomputer vision (for better environment perception), and robotic systems (for\ncontrolled environment interaction) motivates this work toward proposing a\nvision-based learning framework for intelligent robot control as the ultimate\ngoal (vision-based learning robot). This work specifically introduces deep\nreinforcement learning as the the learning framework, a General-purpose\nframework for AI (AGI) meaning application-independent and\nplatform-independent. In terms of robot control, this framework is proposing\nspecifically a high-level control architecture independent of the low-level\ncontrol, meaning these two required level of control can be developed\nseparately from each other. In this aspect, the high-level control creates the\nrequired intelligence for the control of the platform using the recorded\nlow-level controlling data from that same platform generated by a trainer. The\nrecorded low-level controlling data is simply indicating the successful and\nfailed experiences or sequences of experiments conducted by a trainer using the\nsame robotic platform. The sequences of the recorded data are composed of\nobservation data (input sensor), generated reward (feedback value) and action\ndata (output controller). For experimental platform and experiments, vision\nsensors are used for perception of the environment, different kinematic\ncontrollers create the required motion commands based on the platform\napplication, deep learning approaches generate the required intelligence, and\nfinally reinforcement learning techniques incrementally improve the generated\nintelligence until the mission is accomplished by the robot.",
    "descriptor": "",
    "authors": [
      "Aras Dargazany"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13806"
  },
  {
    "id": "arXiv:2105.13807",
    "title": "Gym-$\u03bc$RTS: Toward Affordable Full Game Real-time Strategy Games  Research with Deep Reinforcement Learning",
    "abstract": "In recent years, researchers have achieved great success in applying Deep\nReinforcement Learning (DRL) algorithms to Real-time Strategy (RTS) games,\ncreating strong autonomous agents that could defeat professional players in\nStarCraft~II. However, existing approaches to tackle full games have high\ncomputational costs, usually requiring the use of thousands of GPUs and CPUs\nfor weeks. This paper has two main contributions to address this issue: 1) We\nintroduce Gym-$\\mu$RTS (pronounced \"gym-micro-RTS\") as a fast-to-run RL\nenvironment for full-game RTS research and 2) we present a collection of\ntechniques to scale DRL to play full-game $\\mu$RTS as well as ablation studies\nto demonstrate their empirical importance. Our best-trained bot can defeat\nevery $\\mu$RTS bot we tested from the past $\\mu$RTS competitions when working\nin a single-map setting, resulting in a state-of-the-art DRL agent while only\ntaking about 60 hours of training using a single machine (one GPU, three vCPU,\n16GB RAM).",
    "descriptor": "\nComments: Accepted to IEEE Conference of Games (COG) 2021\n",
    "authors": [
      "Shengyi Huang",
      "Santiago Onta\u00f1\u00f3n",
      "Chris Bamford",
      "Lukasz Grela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13807"
  },
  {
    "id": "arXiv:2105.13808",
    "title": "The Herbarium 2021 Half-Earth Challenge Dataset",
    "abstract": "Herbarium sheets present a unique view of the world's botanical history,\nevolution, and diversity. This makes them an all-important data source for\nbotanical research. With the increased digitisation of herbaria worldwide and\nthe advances in the fine-grained classification domain that can facilitate\nautomatic identification of herbarium specimens, there are a lot of\nopportunities for supporting research in this field. However, existing datasets\nare either too small, or not diverse enough, in terms of represented taxa,\ngeographic distribution or host institutions. Furthermore, aggregating multiple\ndatasets is difficult as taxa exist under a multitude of different names and\nthe taxonomy requires alignment to a common reference. We present the Herbarium\nHalf-Earth dataset, the largest and most diverse dataset of herbarium specimens\nto date for automatic taxon recognition.",
    "descriptor": "\nComments: FGVC8 Workshop at CVPR 2021\n",
    "authors": [
      "Riccardo de Lutio",
      "Damon Little",
      "Barbara Ambrose",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13808"
  },
  {
    "id": "arXiv:2105.13809",
    "title": "Distribution Matching for Machine Teaching",
    "abstract": "Machine teaching is an inverse problem of machine learning that aims at\nsteering the student learner towards its target hypothesis, in which the\nteacher has already known the student's learning parameters. Previous studies\non machine teaching focused on balancing the teaching risk and cost to find\nthose best teaching examples deriving the student model. This optimization\nsolver is in general ineffective when the student learner does not disclose any\ncue of the learning parameters. To supervise such a teaching scenario, this\npaper presents a distribution matching-based machine teaching strategy.\nSpecifically, this strategy backwardly and iteratively performs the halving\noperation on the teaching cost to find a desired teaching set. Technically, our\nstrategy can be expressed as a cost-controlled optimization process that finds\nthe optimal teaching examples without further exploring in the parameter\ndistribution of the student learner. Then, given any a limited teaching cost,\nthe training examples will be closed-form. Theoretical analysis and experiment\nresults demonstrate this strategy.",
    "descriptor": "\nComments: Black-box Machine Teaching\n",
    "authors": [
      "Xiaofeng Cao",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13809"
  },
  {
    "id": "arXiv:2105.13810",
    "title": "A Survey on Anomaly Detection for Technical Systems using LSTM Networks",
    "abstract": "Anomalies represent deviations from the intended system operation and can\nlead to decreased efficiency as well as partial or complete system failure. As\nthe causes of anomalies are often unknown due to complex system dynamics,\nefficient anomaly detection is necessary. Conventional detection approaches\nrely on statistical and time-invariant methods that fail to address the complex\nand dynamic nature of anomalies. With advances in artificial intelligence and\nincreasing importance for anomaly detection and prevention in various domains,\nartificial neural network approaches enable the detection of more complex\nanomaly types while considering temporal and contextual characteristics. In\nthis article, a survey on state-of-the-art anomaly detection using deep neural\nand especially long short-term memory networks is conducted. The investigated\napproaches are evaluated based on the application scenario, data and anomaly\ntypes as well as further metrics. To highlight the potential of upcoming\nanomaly detection techniques, graph-based and transfer learning approaches are\nalso included in the survey, enabling the analysis of heterogeneous data as\nwell as compensating for its shortage and improving the handling of dynamic\nprocesses.",
    "descriptor": "\nComments: 14 pages, 6 figures, 4 tables. Accepted for publication by Computers in Industry\n",
    "authors": [
      "Benjamin Lindemann",
      "Benjamin Maschler",
      "Nada Sahlab",
      "Michael Weyrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13810"
  },
  {
    "id": "arXiv:2105.13812",
    "title": "A proxemics game between festival visitors and an industrial robot",
    "abstract": "With increased applications of collaborative robots (cobots) in industrial\nworkplaces, behavioural effects of human-cobot interactions need to be further\ninvestigated. This is of particular importance as nonverbal behaviours of\ncollaboration partners in human-robot teams significantly influence the\nexperience of the human interaction partners and the success of the\ncollaborative task. During the Ars Electronica 2020 Festival for Art,\nTechnology and Society (Linz, Austria), we invited visitors to exploratively\ninteract with an industrial robot, exhibiting restricted interaction\ncapabilities: extending and retracting its arm, depending on the movements of\nthe volunteer. The movements of the arm were pre-programmed and telecontrolled\nfor safety reasons (which was not obvious to the participants). We recorded\nvideo data of these interactions and investigated general nonverbal behaviours\nof the humans interacting with the robot, as well as nonverbal behaviours of\npeople in the audience. Our results showed that people were more interested in\nexploring the robot's action and perception capabilities than just reproducing\nthe interaction game as introduced by the instructors. We also found that the\nmajority of participants interacting with the robot approached it up to a\ndistance which would be perceived as threatening or intimidating, if it were a\nhuman interaction partner. Regarding bystanders, we found examples where people\nmade movements as if trying out variants of the current participant's\nbehaviour.",
    "descriptor": "\nComments: 5 pager, 2 pictures, HRI21 Workshop on \"Exploring Applications for Autonomous Non-Verbal Human-Robot Interactions\" March 8 2021\n",
    "authors": [
      "Brigitte Krenn",
      "Stephanie Gross",
      "Bernhard Dieber",
      "Horst Pichler",
      "Kathrin Meyer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13812"
  },
  {
    "id": "arXiv:2105.13813",
    "title": "Grey-box models for wave loading prediction",
    "abstract": "The quantification of wave loading on offshore structures and components is a\ncrucial element in the assessment of their useful remaining life. In many\napplications the well-known Morison's equation is employed to estimate the\nforcing from waves with assumed particle velocities and accelerations. This\npaper develops a grey-box modelling approach to improve the predictions of the\nforce on structural members. A grey-box model intends to exploit the enhanced\npredictive capabilities of data-based modelling whilst retaining physical\ninsight into the behaviour of the system; in the context of the work carried\nout here, this can be considered as physics-informed machine learning. There\nare a number of possible approaches to establish a grey-box model. This paper\ndemonstrates two means of combining physics (white box) and data-based (black\nbox) components; one where the model is a simple summation of the two\ncomponents, the second where the white-box prediction is fed into the black box\nas an additional input. Here Morison's equation is used as the physics-based\ncomponent in combination with a data-based Gaussian process NARX - a dynamic\nvariant of the more well-known Gaussian process regression. Two key challenges\nwith employing the GP-NARX formulation that are addressed here are the\nselection of appropriate lag terms and the proper treatment of uncertainty\npropagation within the dynamic GP. The best performing grey-box model, the\nresidual modelling GP-NARX, was able to achieve a 29.13\\% and 5.48\\% relative\nreduction in NMSE over Morison's Equation and a black-box GP-NARX respectively,\nalongside significant benefits in extrapolative capabilities of the model, in\ncircumstances of low dataset coverage.",
    "descriptor": "",
    "authors": [
      "Daniel J Pitchforth",
      "Timothy J Rogers",
      "Ulf T Tygesen",
      "Elizabeth J Cross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2105.13813"
  },
  {
    "id": "arXiv:2105.13816",
    "title": "High accuracy analysis of adaptive multiresolution-based lattice  Boltzmann schemes via the equivalent equations",
    "abstract": "Multiresolution provides a fundamental tool based on the wavelet theory to\nbuild adaptive numerical schemes for Partial Differential Equations and\ntime-adaptive meshes, allowing for error control. We have introduced this\nstrategy before to construct adaptive lattice Boltzmann methods with this\ninteresting feature.Furthermore, these schemes allow for an effective memory\ncompression of the solution when spatially localized phenomena -- such as\nshocks or fronts -- are involved, to rely on the original scheme without any\nmanipulation at the finest level of grid and to reach a high level of accuracy\non the solution.Nevertheless, the peculiar way of modeling the desired physical\nphenomena in the lattice Boltzmann schemes calls, besides the possibility of\ncontrolling the error introduced by the mesh adaptation, for a deeper and more\nprecise understanding of how mesh adaptation alters the physics approximated by\nthe numerical strategy. In this contribution, this issue is studied by\nperforming the equivalent equations analysis of the adaptive method after\nwriting the scheme under an adapted formalism. It provides an essential tool to\nmaster the perturbations introduced by the adaptive numerical strategy, which\ncan thus be devised to preserve the desired features of the reference scheme at\na high order of accuracy. The theoretical considerations are corroborated by\nnumerical experiments in both the 1D and 2D context, showing the relevance of\nthe analysis. In particular, we show that our numerical method outperforms\ntraditional approaches, whether or not the solution of the reference scheme\nconverges to the solution of the target equation.Furthermore, we discuss the\ninfluence of various collision strategies for non-linear problems, showing that\nthey have only a marginal impact on the quality of the solution, thus further\nassessing the proposed strategy.",
    "descriptor": "",
    "authors": [
      "Thomas Bellotti",
      "Lo\u00efc Gouarin",
      "Benjamin Graille",
      "Marc Massot"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13816"
  },
  {
    "id": "arXiv:2105.13817",
    "title": "Achieving Fairness with a Simple Ridge Penalty",
    "abstract": "Estimating a fair linear regression model subject to a user-defined level of\nfairness can be achieved by solving a non-convex quadratic programming\noptimisation problem with quadratic constraints. In this work we propose an\nalternative, more flexible approach to this task that enforces a user-defined\nlevel of fairness by means of a ridge penalty. Our proposal addresses three\nlimitations of the former approach: it produces regression coefficient\nestimates that are more intuitive to interpret; it is mathematically simpler,\nwith a solution that is partly in closed form; and it is easier to extend\nbeyond linear regression. We evaluate both approaches empirically on five\ndifferent data sets, and we find that our proposal provides better goodness of\nfit and better predictive accuracy while being equally effective at achieving\nthe desired fairness level. In addition we highlight a source of bias in the\noriginal experimental evaluation of the non-convex quadratic approach, and we\ndiscuss how our proposal can be extended to a wide range of models.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Marco Scutari",
      "Manuel Proissl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.13817"
  },
  {
    "id": "arXiv:2105.13818",
    "title": "Language Models Use Monotonicity to Assess NPI Licensing",
    "abstract": "We investigate the semantic knowledge of language models (LMs), focusing on\n(1) whether these LMs create categories of linguistic environments based on\ntheir semantic monotonicity properties, and (2) whether these categories play a\nsimilar role in LMs as in human language understanding, using negative polarity\nitem licensing as a case study. We introduce a series of experiments consisting\nof probing with diagnostic classifiers (DCs), linguistic acceptability tasks,\nas well as a novel DC ranking method that tightly connects the probing results\nto the inner workings of the LM. By applying our experimental pipeline to LMs\ntrained on various filtered corpora, we are able to gain stronger insights into\nthe semantic generalizations that are acquired by these models.",
    "descriptor": "\nComments: Published in ACL Findings 2021\n",
    "authors": [
      "Jaap Jumelet",
      "Milica Deni\u0107",
      "Jakub Szymanik",
      "Dieuwke Hupkes",
      "Shane Steinert-Threlkeld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13818"
  },
  {
    "id": "arXiv:2105.13824",
    "title": "SEVerity: Code Injection Attacks against Encrypted Virtual Machines",
    "abstract": "Modern enterprises increasingly take advantage of cloud infrastructures. Yet,\noutsourcing code and data into the cloud requires enterprises to trust cloud\nproviders not to meddle with their data. To reduce the level of trust towards\ncloud providers, AMD has introduced Secure Encrypted Virtualization (SEV). By\nencrypting Virtual Machines (VMs), SEV aims to ensure data confidentiality,\ndespite a compromised or curious Hypervisor. The SEV Encrypted State (SEV-ES)\nextension additionally protects the VM's register state from unauthorized\naccess. Yet, both extensions do not provide integrity of the VM's memory, which\nhas already been abused to leak the protected data or to alter the VM's\ncontrol-flow. In this paper, we introduce the SEVerity attack; a missing puzzle\npiece in the series of attacks against the AMD SEV family. Specifically, we\nabuse the system's lack of memory integrity protection to inject and execute\narbitrary code within SEV-ES-protected VMs. Contrary to previous code execution\nattacks against the AMD SEV family, SEVerity neither relies on a specific CPU\nversion nor on any code gadgets inside the VM. Instead, SEVerity abuses the\nfact that SEV-ES prohibits direct memory access into the encrypted memory.\nSpecifically, SEVerity injects arbitrary code into the encrypted VM through I/O\nchannels and uses the Hypervisor to locate and trigger the execution of the\nencrypted payload. This allows us to sidestep the protection mechanisms of\nSEV-ES. Overall, our results demonstrate a success rate of 100% and hence\nhighlight that memory integrity protection is an obligation when encrypting\nVMs. Consequently, our work presents the final stroke in a series of attacks\nagainst AMD SEV and SEV-ES and renders the present implementation as incapable\nof protecting against a curious, vulnerable, or malicious Hypervisor.",
    "descriptor": "",
    "authors": [
      "Mathias Morbitzer",
      "Sergej Proskurin",
      "Martin Radev",
      "Marko Dorfhuber",
      "Erick Quintanar Salas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13824"
  },
  {
    "id": "arXiv:2105.13825",
    "title": "Improving Facial Attribute Recognition by Group and Graph Learning",
    "abstract": "Exploiting the relationships between attributes is a key challenge for\nimproving multiple facial attribute recognition. In this work, we are concerned\nwith two types of correlations that are spatial and non-spatial relationships.\nFor the spatial correlation, we aggregate attributes with spatial similarity\ninto a part-based group and then introduce a Group Attention Learning to\ngenerate the group attention and the part-based group feature. On the other\nhand, to discover the non-spatial relationship, we model a group-based Graph\nCorrelation Learning to explore affinities of predefined part-based groups. We\nutilize such affinity information to control the communication between all\ngroups and then refine the learned group features. Overall, we propose a\nunified network called Multi-scale Group and Graph Network. It incorporates\nthese two newly proposed learning strategies and produces coarse-to-fine\ngraph-based group features for improving facial attribute recognition.\nComprehensive experiments demonstrate that our approach outperforms the\nstate-of-the-art methods.",
    "descriptor": "\nComments: ICME2021(Oral)\n",
    "authors": [
      "Zhenghao Chen",
      "Shuhang Gu",
      "Feng Zhu",
      "Jing Xu",
      "Rui Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13825"
  },
  {
    "id": "arXiv:2105.13826",
    "title": "4-Adic Complexity of Interleaved Quaternary Sequences",
    "abstract": "Tang and Ding \\cite{X. Tang} present a series of quaternary sequences $w(a,\nb)$ interleaved by two binary sequences $a$ and $b$ with ideal autocorrelation\nand show that such interleaved quaternary sequences have optimal\nautocorrelation. In this paper we consider the 4-adic complexity $FC_{w}(4)$ of\nsuch quaternary sequence $w=w(a, b)$. We present a general formula on\n$FC_{w}(4)$, $w=w(a, b)$. As a direct consequence, we get a general lower bound\n$FC_{w}(4)\\geq\\log_{4}(4^{n}-1)$ where $2n$ is the period of the sequence $w$.\nBy taking $a$ and $b$ to be several types of known binary sequences with ideal\nautocorrelation ($m$-sequences, twin-prime, Legendre, Hall sequences and their\ncomplement, shift or sample sequences), we compute the exact values of\n$FC_{w}(4)$, $w=w(a, b)$. The results show that in most cases $FC_{w}(4)$\nreaches or nearly reaches the maximum value $\\log_{4}(4^{2n}-1)$.",
    "descriptor": "",
    "authors": [
      "Shiyuan Qiang",
      "Xiaoyan Jing",
      "Minghui Yang",
      "Keqin Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13826"
  },
  {
    "id": "arXiv:2105.13827",
    "title": "Extended Cyclic Codes Sandwiched Between Reed-Muller Codes",
    "abstract": "The famous Barnes-Wall lattices can be obtained by applying Construction D to\na chain of Reed-Muller codes. By applying Construction ${{D}}^{{(cyc)}}$ to a\nchain of extended cyclic codes sandwiched between Reed-Muller codes, Hu and\nNebe (J. London Math. Soc. (2) 101 (2020) 1068-1089) constructed new series of\nuniversally strongly perfect lattices sandwiched between Barnes-Wall lattices.\nIn this paper, we explicitly determine the minimum weight codewords of those\ncodes for some special cases.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Changjiang Ji",
      "Yan Xu",
      "Sihuang Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13827"
  },
  {
    "id": "arXiv:2105.13835",
    "title": "Kernel-based methods for Solving Time-Dependent Advection-Diffusion  Equations on Manifolds",
    "abstract": "In this paper, we extend the class of kernel methods, the so-called diffusion\nmaps (DM) and ghost point diffusion maps (GPDM), to solve the time-dependent\nadvection-diffusion PDE on unknown smooth manifolds without and with\nboundaries. The core idea is to directly approximate the spatial components of\nthe differential operator on the manifold with a local integral operator and\ncombine it with the standard implicit time difference scheme. When the manifold\nhas a boundary, a simplified version of the GPDM approach is used to overcome\nthe bias of the integral approximation near the boundary. The Monte-Carlo\ndiscretization of the integral operator over the point cloud data gives rise to\na mesh-free formulation that is natural for randomly distributed points, even\nwhen the manifold is embedded in high-dimensional ambient space. Here, we\nestablish the convergence of the proposed solver on appropriate topologies,\ndepending on the distribution of point cloud data and boundary type. We provide\nnumerical results to validate the convergence results on various examples that\ninvolve simple geometry and an unknown manifold. Additionally, we also found\npositive results in solving the one-dimensional viscous Burger's equation where\nGPDM is adopted with a pseudo-spectral Galerkin framework to approximate\nnonlinear advection term.",
    "descriptor": "",
    "authors": [
      "Qile Yan",
      "Shixiao Willing Jiang",
      "John Harlim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13835"
  },
  {
    "id": "arXiv:2105.13837",
    "title": "Adapting Behaviors via Reactive Synthesis",
    "abstract": "In the \\emph{Adapter Design Pattern}, a programmer implements a \\emph{Target}\ninterface by constructing an \\emph{Adapter} that accesses an existing\n\\emph{Adaptee} code. In this work, we present a reactive synthesis\ninterpretation to the adapter design pattern, wherein an algorithm takes an\n\\emph{Adaptee} and a \\emph{Target} transducers, and the aim is to synthesize an\n\\emph{Adapter} transducer that, when composed with the {\\em Adaptee}, generates\na behavior that is equivalent to the behavior of the {\\em Target}. One use of\nsuch an algorithm is to synthesize controllers that achieve similar goals on\ndifferent hardware platforms. While this problem can be solved with existing\nsynthesis algorithms, current state-of-the-art tools fail to scale. To cope\nwith the computational complexity of the problem, we introduce a special form\nof specification format, called {\\em Separated GR($k$)}, which can be solved\nwith a scalable synthesis algorithm but still allows for a large set of\nrealistic specifications. We solve the realizability and the synthesis problems\nfor Separated GR($k$), and show how to exploit the separated nature of our\nspecification to construct better algorithms, in terms of time complexity, than\nknown algorithms for GR($k$) synthesis. We then describe a tool, called\nSGR($k$), that we have implemented based on the above approach and show, by\nexperimental evaluation, how our tool outperforms current state-of-the-art\ntools on various benchmarks and test-cases.",
    "descriptor": "",
    "authors": [
      "Gal Amram",
      "Suguman Bansal",
      "Dror Fried",
      "Lucas M. Tabajara",
      "Moshe Y. Vardi",
      "Gera Weiss"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.13837"
  },
  {
    "id": "arXiv:2105.13838",
    "title": "It's your turn! -- A collaborative human-robot pick-and-place scenario  in a virtual industrial setting",
    "abstract": "In human-robot collaborative interaction scenarios, nonverbal communication\nplays an important role. Both, signals sent by a human collaborator need to be\nidentified and interpreted by the robotic system, and the signals sent by the\nrobot need to be identified and interpreted by the human. In this paper, we\nfocus on the latter. We implemented on an industrial robot in a VR environment\nnonverbal behavior signalling the user that it is now their turn to proceed\nwith a pick-and-place task. The signals were presented in four different test\nconditions: no signal, robot arm gesture, light signal, combination of robot\narm gesture and light signal. Test conditions were presented to the\nparticipants in two rounds. The qualitative analysis was conducted with focus\non (i) potential signals in human behaviour indicating why some participants\nimmediately took over from the robot whereas others needed more time to\nexplore, (ii) human reactions after the nonverbal signal of the robot, and\n(iii) whether participants showed different behaviours in the different test\nconditions. We could not identify potential signals why some participants were\nimmediately successful and others not. There was a bandwidth of behaviors after\nthe robot stopped working, e.g. participants rearranged the objects, looked at\nthe robot or the object, or gestured the robot to proceed. We found evidence\nthat robot deictic gestures were helpful for the human to correctly interpret\nwhat to do next. Moreover, there was a strong tendency that humans interpreted\nthe light signal projected on the robot's gripper as a request to give the\nobject in focus to the robot. Whereas a robot's pointing gesture at the object\nwas a strong trigger for the humans to look at the object.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables, HRI21 Workshop on \"Exploring Applications for Autonomous Non-Verbal Human-Robot Interactions\" March 8 2021\n",
    "authors": [
      "Brigitte Krenn",
      "Tim Reinboth",
      "Stephanie Gross",
      "Christine Busch",
      "Martina Mara",
      "Kathrin Meyer",
      "Michael Heiml",
      "Thomas Layer-Wagner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13838"
  },
  {
    "id": "arXiv:2105.13840",
    "title": "Gobra: Modular Specification and Verification of Go Programs (extended  version)",
    "abstract": "Go is an increasingly-popular systems programming language targeting,\nespecially, concurrent and distributed systems. Go differentiates itself from\nother imperative languages by offering structural subtyping and lightweight\nconcurrency through goroutines with message-passing communication. This\ncombination of features poses interesting challenges for static verification,\nmost prominently the combination of a mutable heap and advanced concurrency\nprimitives.\nWe present Gobra, a modular, deductive program verifier for Go that proves\nmemory safety, crash safety, data-race freedom, and user-provided\nspecifications. Gobra is based on separation logic and supports a large subset\nof Go. Its implementation translates an annotated Go program into the Viper\nintermediate verification language and uses an existing SMT-based verification\nbackend to compute and discharge proof obligations.",
    "descriptor": "",
    "authors": [
      "Felix A. Wolf",
      "Linard Arquint",
      "Martin Clochard",
      "Wytse Oortwijn",
      "Jo\u00e3o C. Pereira",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.13840"
  },
  {
    "id": "arXiv:2105.13841",
    "title": "A General Taylor Framework for Unifying and Revisiting Attribution  Methods",
    "abstract": "Attribution methods provide an insight into the decision-making process of\nmachine learning models, especially deep neural networks, by assigning\ncontribution scores to each individual feature. However, the attribution\nproblem has not been well-defined, which lacks a unified guideline to the\ncontribution assignment process. Furthermore, existing attribution methods\noften built upon various empirical intuitions and heuristics. There still lacks\na general theoretical framework that not only can offer a good description of\nthe attribution problem, but also can be applied to unifying and revisiting\nexisting attribution methods. To bridge the gap, in this paper, we propose a\nTaylor attribution framework, which models the attribution problem as how to\ndecide individual payoffs in a coalition. Then, we reformulate fourteen\nmainstream attribution methods into the Taylor framework and analyze these\nattribution methods in terms of rationale, fidelity, and limitation in the\nframework. Moreover, we establish three principles for a good attribution in\nthe Taylor attribution framework, i.e., low approximation error, correct Taylor\ncontribution assignment, and unbiased baseline selection. Finally, we\nempirically validate the Taylor reformulations and reveal a positive\ncorrelation between the attribution performance and the number of principles\nfollowed by the attribution method via benchmarking on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Huiqi Deng",
      "Na Zou",
      "Mengnan Du",
      "Weifu Chen",
      "Guocan Feng",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13841"
  },
  {
    "id": "arXiv:2105.13843",
    "title": "Explainable Enterprise Credit Rating via Deep Feature Crossing Network",
    "abstract": "Due to the powerful learning ability on high-rank and non-linear features,\ndeep neural networks (DNNs) are being applied to data mining and machine\nlearning in various fields, and exhibit higher discrimination performance than\nconventional methods. However, the applications based on DNNs are rare in\nenterprise credit rating tasks because most of DNNs employ the \"end-to-end\"\nlearning paradigm, which outputs the high-rank representations of objects and\npredictive results without any explanations. Thus, users in the financial\nindustry cannot understand how these high-rank representations are generated,\nwhat do they mean and what relations exist with the raw inputs. Then users\ncannot determine whether the predictions provided by DNNs are reliable, and not\ntrust the predictions providing by such \"black box\" models. Therefore, in this\npaper, we propose a novel network to explicitly model the enterprise credit\nrating problem using DNNs and attention mechanisms. The proposed model realizes\nexplainable enterprise credit ratings. Experimental results obtained on\nreal-world enterprise datasets verify that the proposed approach achieves\nhigher performance than conventional methods, and provides insights into\nindividual rating results and the reliability of model training.",
    "descriptor": "",
    "authors": [
      "Weiyu Guo",
      "Zhijiang Yang",
      "Shu Wu",
      "Fu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.13843"
  },
  {
    "id": "arXiv:2105.13845",
    "title": "Multi-Tier Adaptive Memory Programming and Cluster- and Job-based  Relocation for Distributed On-demand Crowdshipping",
    "abstract": "With rapid e-commerce growth, on-demand urban delivery is having a high time\nespecially for food, grocery, and retail, often requiring delivery in a very\nshort amount of time after an order is placed. This imposes significant\nfinancial and operational challenges for traditional vehicle-based delivery\nmethods. Crowdshipping, which employs ordinary people with a low pay rate and\nlimited time availability, has emerged as an attractive alternative. This paper\nproposes a multi-tier adaptive memory programming (M-TAMP) to tackle on-demand\nassignment of requests to crowdsourcees with spatially distributed request\norigins and destination and crowdsourcee starting points. M-TAMP starts with\nmultiple initial solutions constructed based on different plausible\ncontemplations in assigning requests to crowdsourcees, and organizes solution\nsearch through waves, phases, and steps, imitating both ocean waves and human\nmemory functioning while seeking the best solution. The assignment is further\nenforced by proactively relocating idle crowdsourcees, for which a\ncomputationally efficient cluster- and job-based strategy is devised. Numerical\nexperiments demonstrate the superiority of MTAMP over a number of existing\nmethods, and that relocation can greatly improve the efficiency of\ncrowdsourcee-request assignment.",
    "descriptor": "\nComments: 46 pages, 9 figures, 4 algorithms\n",
    "authors": [
      "Tanvir Ahamed",
      "Bo Zou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13845"
  },
  {
    "id": "arXiv:2105.13854",
    "title": "Neonatal seizure detection from raw multi-channel EEG using a fully  convolutional architecture",
    "abstract": "A deep learning classifier for detecting seizures in neonates is proposed.\nThis architecture is designed to detect seizure events from raw\nelectroencephalogram (EEG) signals as opposed to the state-of-the-art hand\nengineered feature-based representation employed in traditional machine\nlearning based solutions. The seizure detection system utilises only\nconvolutional layers in order to process the multichannel time domain signal\nand is designed to exploit the large amount of weakly labelled data in the\ntraining stage. The system performance is assessed on a large database of\ncontinuous EEG recordings of 834h in duration; this is further validated on a\nheld-out publicly available dataset and compared with two baseline SVM based\nsystems.\nThe developed system achieves a 56% relative improvement with respect to a\nfeature-based state-of-the art baseline, reaching an AUC of 98.5%; this also\ncompares favourably both in terms of performance and run-time. The effect of\nvarying architectural parameters is thoroughly studied. The performance\nimprovement is achieved through novel architecture design which allows more\nefficient usage of available training data and end-to-end optimisation from the\nfront-end feature extraction to the back-end classification. The proposed\narchitecture opens new avenues for the application of deep learning to neonatal\nEEG, where the performance becomes a function of the amount of training data\nwith less dependency on the availability of precise clinical labels.",
    "descriptor": "",
    "authors": [
      "Alison O'Shea",
      "Gordon Lightbody",
      "Geraldine Boylan",
      "Andriy Temko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13854"
  },
  {
    "id": "arXiv:2105.13855",
    "title": "A Sum-of-Ratios Multi-Dimensional-Knapsack Decomposition for DNN  Resource Scheduling",
    "abstract": "In recent years, to sustain the resource-intensive computational needs for\ntraining deep neural networks (DNNs), it is widely accepted that exploiting the\nparallelism in large-scale computing clusters is critical for the efficient\ndeployments of DNN training jobs. However, existing resource schedulers for\ntraditional computing clusters are not well suited for DNN training, which\nresults in unsatisfactory job completion time performance. The limitations of\nthese resource scheduling schemes motivate us to propose a new computing\ncluster resource scheduling framework that is able to leverage the special\nlayered structure of DNN jobs and significantly improve their job completion\ntimes. Our contributions in this paper are three-fold: i) We develop a new\nresource scheduling analytical model by considering DNN's layered structure,\nwhich enables us to analytically formulate the resource scheduling optimization\nproblem for DNN training in computing clusters; ii) Based on the proposed\nperformance analytical model, we then develop an efficient resource scheduling\nalgorithm based on the widely adopted parameter-server architecture using a\nsum-of-ratios multi-dimensional-knapsack decomposition (SMD) method to offer\nstrong performance guarantee; iii) We conduct extensive numerical experiments\nto demonstrate the effectiveness of the proposed schedule algorithm and its\nsuperior performance over the state of the art.",
    "descriptor": "",
    "authors": [
      "Menglu Yu",
      "Chuan Wu",
      "Bo Ji",
      "Jia Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13855"
  },
  {
    "id": "arXiv:2105.13856",
    "title": "Lightweight Cross-Lingual Sentence Representation Learning",
    "abstract": "Large-scale models for learning fixed-dimensional cross-lingual sentence\nrepresentations like Large-scale models for learning fixed-dimensional\ncross-lingual sentence representations like LASER (Artetxe and Schwenk, 2019b)\nlead to significant improvement in performance on downstream tasks. However,\nfurther increases and modifications based on such large-scale models are\nusually impractical due to memory limitations. In this work, we introduce a\nlightweight dual-transformer architecture with just 2 layers for generating\nmemory-efficient cross-lingual sentence representations. We explore different\ntraining tasks and observe that current cross-lingual training tasks leave a\nlot to be desired for this shallow architecture. To ameliorate this, we propose\na novel cross-lingual language model, which combines the existing single-word\nmasked language model with the newly proposed cross-lingual token-level\nreconstruction task. We further augment the training task by the introduction\nof two computationally-lite sentence-level contrastive learning tasks to\nenhance the alignment of cross-lingual sentence representation space, which\ncompensates for the learning bottleneck of the lightweight transformer for\ngenerative tasks. Our comparisons with competing models on cross-lingual\nsentence retrieval and multilingual document classification confirm the\neffectiveness of the newly proposed training tasks for a shallow model.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Zhuoyuan Mao",
      "Prakhar Gupta",
      "Chenhui Chu",
      "Martin Jaggi",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13856"
  },
  {
    "id": "arXiv:2105.13857",
    "title": "Learning Approximate and Exact Numeral Systems via Reinforcement  Learning",
    "abstract": "Recent work (Xu et al., 2020) has suggested that numeral systems in different\nlanguages are shaped by a functional need for efficient communication in an\ninformation-theoretic sense. Here we take a learning-theoretic approach and\nshow how efficient communication emerges via reinforcement learning. In our\nframework, two artificial agents play a Lewis signaling game where the goal is\nto convey a numeral concept. The agents gradually learn to communicate using\nreinforcement learning and the resulting numeral systems are shown to be\nefficient in the information-theoretic framework of Regier et al. (2015);\nGibson et al. (2017). They are also shown to be similar to human numeral\nsystems of same type. Our results thus provide a mechanistic explanation via\nreinforcement learning of the recent results in Xu et al. (2020) and can\npotentially be generalized to other semantic domains.",
    "descriptor": "\nComments: CogSci 2021\n",
    "authors": [
      "Emil Carlsson",
      "Devdatt Dubhashi",
      "Fredrik D. Johansson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13857"
  },
  {
    "id": "arXiv:2105.13859",
    "title": "GAN for time series prediction, data assimilation and uncertainty  quantification",
    "abstract": "We propose a new method in which a generative adversarial network (GAN) is\nused to quantify the uncertainty of forward simulations in the presence of\nobserved data. Previously, a method has been developed which enables GANs to\nmake time series predictions and data assimilation by training a GAN with\nunconditional simulations of a high-fidelity numerical model. After training,\nthe GAN can be used to predict the evolution of the spatial distribution of the\nsimulation states and observed data is assimilated. In this paper, we describe\nthe process required in order to quantify uncertainty, during which no\nadditional simulations of the high-fidelity numerical model are required. These\nmethods take advantage of the adjoint-like capabilities of generative models\nand the ability to simulate forwards and backwards in time. Set within a\nreduced-order model framework for efficiency, we apply these methods to a\ncompartmental model in epidemiology to predict the spread of COVID-19 in an\nidealised town. The results show that the proposed method can efficiently\nquantify uncertainty in the presence of measurements using only unconditional\nsimulations of the high-fidelity numerical model.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.07729\n",
    "authors": [
      "Vinicius L. S. Silva",
      "Claire E. Heaney",
      "Christopher C. Pain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13859"
  },
  {
    "id": "arXiv:2105.13864",
    "title": "SalientSleepNet: Multimodal Salient Wave Detection Network for Sleep  Staging",
    "abstract": "Sleep staging is fundamental for sleep assessment and disease diagnosis.\nAlthough previous attempts to classify sleep stages have achieved high\nclassification performance, several challenges remain open: 1) How to\neffectively extract salient waves in multimodal sleep data; 2) How to capture\nthe multi-scale transition rules among sleep stages; 3) How to adaptively seize\nthe key role of specific modality for sleep staging. To address these\nchallenges, we propose SalientSleepNet, a multimodal salient wave detection\nnetwork for sleep staging. Specifically, SalientSleepNet is a temporal fully\nconvolutional network based on the $\\rm U^2$-Net architecture that is\noriginally proposed for salient object detection in computer vision. It is\nmainly composed of two independent $\\rm U^2$-like streams to extract the\nsalient features from multimodal data, respectively. Meanwhile, the multi-scale\nextraction module is designed to capture multi-scale transition rules among\nsleep stages. Besides, the multimodal attention module is proposed to\nadaptively capture valuable information from multimodal data for the specific\nsleep stage. Experiments on the two datasets demonstrate that SalientSleepNet\noutperforms the state-of-the-art baselines. It is worth noting that this model\nhas the least amount of parameters compared with the existing deep neural\nnetwork models.",
    "descriptor": "\nComments: Accepted by IJCAI 2021. The SOLE copyright holder is IJCAI (International Joint Conferences on Artificial Intelligence), all rights reserved\n",
    "authors": [
      "Ziyu Jia",
      "Youfang Lin",
      "Jing Wang",
      "Xuehui Wang",
      "Peiyi Xie",
      "Yingbin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.13864"
  },
  {
    "id": "arXiv:2105.13865",
    "title": "Recursive Contour Saliency Blending Network for Accurate Salient Object  Detection",
    "abstract": "Contour information plays a vital role in salient object detection. However,\nexcessive false positives remain in predictions from existing contour-based\nmodels due to insufficient contour-saliency fusion. In this work, we designed a\nnetwork for better edge quality in salient object detection. We proposed a\ncontour-saliency blending module to exchange information between contour and\nsaliency. We adopted recursive CNN to increase contour-saliency fusion while\nkeeping the total trainable parameters the same. Furthermore, we designed a\nstage-wise feature extraction module to help the model pick up the most helpful\nfeatures from previous intermediate saliency predictions. Besides, we proposed\ntwo new loss functions, namely Dual Confinement Loss and Confidence Loss, for\nour model to generate better boundary predictions. Evaluation results on five\ncommon benchmark datasets reveal that our model achieves competitive\nstate-of-the-art performance. Last but not least, our model is lightweight and\nfast, with only 27.9 million parameters and real-time inferencing at 31 FPS.",
    "descriptor": "",
    "authors": [
      "Yi Ke Yun",
      "Chun Wei Tan",
      "Takahiro Tsubono"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13865"
  },
  {
    "id": "arXiv:2105.13866",
    "title": "Kotless: a Serverless Framework for Kotlin",
    "abstract": "Recent trends in Web development demonstrate an increased interest in\nserverless applications, i.e. applications that utilize computational resources\nprovided by cloud services on demand instead of requiring traditional server\nmanagement. This approach enables better resource management while being\nscalable, reliable, and cost-effective. However, it comes with a number of\norganizational and technical difficulties which stem from the interaction\nbetween the application and the cloud infrastructure, for example, having to\nset up a recurring task of reuploading updated files. In this paper, we present\nKotless - a Kotlin Serverless Framework. Kotless is a cloud-agnostic toolkit\nthat solves these problems by interweaving the deployed application into the\ncloud infrastructure and automatically generating the necessary deployment\ncode. This relieves developers from having to spend their time integrating and\nmanaging their applications instead of developing them. Kotless has proven its\ncapabilities and has been used to develop several serverless applications\nalready in production. Its source code is available at\nhttps://github.com/JetBrains/kotless, a tool demo can be found at\nhttps://www.youtube.com/watch?v=IMSakPNl3TY",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Vladislav Tankov",
      "Yaroslav Golubev",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13866"
  },
  {
    "id": "arXiv:2105.13868",
    "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval",
    "abstract": "Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 main conference (Long Paper)\n",
    "authors": [
      "Shuhuai Ren",
      "Junyang Lin",
      "Guangxiang Zhao",
      "Rui Men",
      "An Yang",
      "Jingren Zhou",
      "Xu Sun",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13868"
  },
  {
    "id": "arXiv:2105.13870",
    "title": "Regret-Minimizing Bayesian Persuasion",
    "abstract": "We study a Bayesian persuasion setting with binary actions (adopt and reject)\nfor Receiver. We examine the following question - how well can Sender perform,\nin terms of persuading Receiver to adopt, when ignorant of Receiver's utility?\nWe take a robust (adversarial) approach to study this problem; that is, our\ngoal is to design signaling schemes for Sender that perform well for all\npossible Receiver's utilities. We measure performance of signaling schemes via\nthe notion of (additive) regret: the difference between Sender's hypothetically\noptimal utility had she known Receiver's utility function and her actual\nutility induced by the given scheme.\nOn the negative side, we show that if Sender has no knowledge at all about\nReceiver's utility, then Sender has no signaling scheme that performs robustly\nwell. On the positive side, we show that if Sender only knows Receiver's\nordinal preferences of the states of nature - i.e., Receiver's utility upon\nadoption is monotonic as a function of the state - then Sender can guarantee a\nsurprisingly low regret even when the number of states tends to infinity. In\nfact, we exactly pin down the minimum regret value that Sender can guarantee in\nthis case, which turns out to be at most 1/e. We further show that such\npositive results are not possible under the alternative performance measure of\na multiplicative approximation ratio by proving that no constant ratio can be\nguaranteed even for monotonic Receiver's utility; this may serve to demonstrate\nthe merits of regret as a robust performance measure that is not too\npessimistic. Finally, we analyze an intermediate setting in between the\nno-knowledge and the ordinal-knowledge settings.",
    "descriptor": "",
    "authors": [
      "Yakov Babichenko",
      "Inbal Talgam-Cohen",
      "Haifeng Xu",
      "Konstantin Zabarnyi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.13870"
  },
  {
    "id": "arXiv:2105.13878",
    "title": "Accelerating BERT Inference for Sequence Labeling via Early-Exit",
    "abstract": "Both performance and efficiency are crucial factors for sequence labeling\ntasks in many real-world scenarios. Although the pre-trained models (PTMs) have\nsignificantly improved the performance of various sequence labeling tasks,\ntheir computational cost is expensive. To alleviate this problem, we extend the\nrecent successful early-exit mechanism to accelerate the inference of PTMs for\nsequence labeling tasks. However, existing early-exit mechanisms are\nspecifically designed for sequence-level tasks, rather than sequence labeling.\nIn this paper, we first propose a simple extension of sentence-level early-exit\nfor sequence labeling tasks. To further reduce the computational cost, we also\npropose a token-level early-exit mechanism that allows partial tokens to exit\nearly at different layers. Considering the local dependency inherent in\nsequence labeling, we employed a window-based criterion to decide for a token\nwhether or not to exit. The token-level early-exit brings the gap between\ntraining and inference, so we introduce an extra self-sampling fine-tuning\nstage to alleviate it. The extensive experiments on three popular sequence\nlabeling tasks show that our approach can save up to 66%-75% inference cost\nwith minimal performance degradation. Compared with competitive compressed\nmodels such as DistilBERT, our approach can achieve better performance under\nthe same speed-up ratios of 2X, 3X, and 4X.",
    "descriptor": "\nComments: Accepted to the ACL 2021\n",
    "authors": [
      "Xiaonan Li",
      "Yunfan Shao",
      "Tianxiang Sun",
      "Hang Yan",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13878"
  },
  {
    "id": "arXiv:2105.13880",
    "title": "Knowledge Inheritance for Pre-trained Language Models",
    "abstract": "Recent explorations of large-scale pre-trained language models (PLMs) such as\nGPT-3 have revealed the power of PLMs with huge amounts of parameters, setting\noff a wave of training ever-larger PLMs. However, training a large-scale PLM\nrequires tremendous amounts of computational resources, which is time-consuming\nand expensive. In addition, existing large-scale PLMs are mainly trained from\nscratch individually, ignoring the availability of many existing well-trained\nPLMs. To this end, we explore the question that how can previously trained PLMs\nbenefit training larger PLMs in future. Specifically, we introduce a novel\npre-training framework named \"knowledge inheritance\" (KI), which combines both\nself-learning and teacher-guided learning to efficiently train larger PLMs.\nSufficient experimental results demonstrate the feasibility of our KI\nframework. We also conduct empirical analyses to explore the effects of teacher\nPLMs' pre-training settings, including model architecture, pre-training data,\netc. Finally, we show that KI can well support lifelong learning and knowledge\ntransfer.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Yujia Qin",
      "Yankai Lin",
      "Jing Yi",
      "Jiajie Zhang",
      "Xu Han",
      "Zhengyan Zhang",
      "Yusheng Su",
      "Zhiyuan Liu",
      "Peng Li",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13880"
  },
  {
    "id": "arXiv:2105.13881",
    "title": "CausCF: Causal Collaborative Filtering for RecommendationEffect  Estimation",
    "abstract": "To improve user experience and profits of corporations, modern industrial\nrecommender systems usually aim to select the items that are most likely to be\ninteracted with (e.g., clicks and purchases). However, they overlook the fact\nthat users may purchase the items even without recommendations. To select these\neffective items, it is essential to estimate the causal effect of\nrecommendations. The real effective items are the ones which can contribute to\npurchase probability uplift. Nevertheless, it is difficult to obtain the real\ncausal effect since we can only recommend or not recommend an item to a user at\none time. Furthermore, previous works usually rely on the randomized controlled\ntrial~(RCT) experiment to evaluate their performance. However, it is usually\nnot practicable in the recommendation scenario due to its unavailable time\nconsuming. To tackle these problems, in this paper, we propose a causal\ncollaborative filtering~(CausCF) method inspired by the widely adopted\ncollaborative filtering~(CF) technique. It is based on the idea that similar\nusers not only have a similar taste on items, but also have similar treatment\neffect under recommendations. CausCF extends the classical matrix factorization\nto the tensor factorization with three dimensions -- user, item, and treatment.\nFurthermore, we also employs regression discontinuity design (RDD) to evaluate\nthe precision of the estimated causal effects from different models. With the\ntestable assumptions, RDD analysis can provide an unbiased causal conclusion\nwithout RCT experiments. Through dedicated experiments on both the public\ndatasets and the industrial application, we demonstrate the effectiveness of\nour proposed CausCF on the causal effect estimation and ranking performance\nimprovement.",
    "descriptor": "",
    "authors": [
      "Xu Xie",
      "Zhaoyang Liu",
      "Shiwen Wu",
      "Fei Sun",
      "Cihang Liu",
      "Jiawei Chen",
      "Jinyang Gao",
      "Bin Cui",
      "Bolin Ding"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.13881"
  },
  {
    "id": "arXiv:2105.13889",
    "title": "Equilibrium and non-Equilibrium regimes in the learning of Restricted  Boltzmann Machines",
    "abstract": "Training Restricted Boltzmann Machines (RBMs) has been challenging for a long\ntime due to the difficulty of computing precisely the log-likelihood gradient.\nOver the past decades, many works have proposed more or less successful\ntraining recipes but without studying the crucial quantity of the problem: the\nmixing time i.e. the number of Monte Carlo iterations needed to sample new\nconfigurations from a model. In this work, we show that this mixing time plays\na crucial role in the dynamics and stability of the trained model, and that\nRBMs operate in two well-defined regimes, namely equilibrium and\nout-of-equilibrium, depending on the interplay between this mixing time of the\nmodel and the number of steps, $k$, used to approximate the gradient. We\nfurther show empirically that this mixing time increases with the learning,\nwhich often implies a transition from one regime to another as soon as $k$\nbecomes smaller than this time. In particular, we show that using the popular\n$k$ (persistent) contrastive divergence approaches, with $k$ small, the\ndynamics of the learned model are extremely slow and often dominated by strong\nout-of-equilibrium effects. On the contrary, RBMs trained in equilibrium\ndisplay faster dynamics, and a smooth convergence to dataset-like\nconfigurations during the sampling. Finally we discuss how to exploit in\npractice both regimes depending on the task one aims to fulfill: (i) short $k$s\ncan be used to generate convincing samples in short times, (ii) large $k$ (or\nincreasingly large) must be used to learn the correct equilibrium distribution\nof the RBM.",
    "descriptor": "\nComments: 12 page, 3 figures. submitted to Neurips 2021\n",
    "authors": [
      "Aur\u00e9lien Decelle",
      "Cyril Furtlehner",
      "Beatriz Seoane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2105.13889"
  },
  {
    "id": "arXiv:2105.13890",
    "title": "Towards Efficient Full 8-bit Integer DNN Online Training on  Resource-limited Devices without Batch Normalization",
    "abstract": "Huge computational costs brought by convolution and batch normalization (BN)\nhave caused great challenges for the online training and corresponding\napplications of deep neural networks (DNNs), especially in resource-limited\ndevices. Existing works only focus on the convolution or BN acceleration and no\nsolution can alleviate both problems with satisfactory performance. Online\ntraining has gradually become a trend in resource-limited devices like mobile\nphones while there is still no complete technical scheme with acceptable model\nperformance, processing speed, and computational cost. In this research, an\nefficient online-training quantization framework termed EOQ is proposed by\ncombining Fixup initialization and a novel quantization scheme for DNN model\ncompression and acceleration. Based on the proposed framework, we have\nsuccessfully realized full 8-bit integer network training and removed BN in\nlarge-scale DNNs. Especially, weight updates are quantized to 8-bit integers\nfor the first time. Theoretical analyses of EOQ utilizing Fixup initialization\nfor removing BN have been further given using a novel Block Dynamical Isometry\ntheory with weaker assumptions. Benefiting from rational quantization\nstrategies and the absence of BN, the full 8-bit networks based on EOQ can\nachieve state-of-the-art accuracy and immense advantages in computational cost\nand processing speed. What is more, the design of deep learning chips can be\nprofoundly simplified for the absence of unfriendly square root operations in\nBN. Beyond this, EOQ has been evidenced to be more advantageous in small-batch\nonline training with fewer batch samples. In summary, the EOQ framework is\nspecially designed for reducing the high cost of convolution and BN in network\ntraining, demonstrating a broad application prospect of online training in\nresource-limited devices.",
    "descriptor": "",
    "authors": [
      "Yukuan Yang",
      "Xiaowei Chi",
      "Lei Deng",
      "Tianyi Yan",
      "Feng Gao",
      "Guoqi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13890"
  },
  {
    "id": "arXiv:2105.13892",
    "title": "Training Classifiers that are Universally Robust to All Label Noise  Levels",
    "abstract": "For classification tasks, deep neural networks are prone to overfitting in\nthe presence of label noise. Although existing methods are able to alleviate\nthis problem at low noise levels, they encounter significant performance\nreduction at high noise levels, or even at medium noise levels when the label\nnoise is asymmetric. To train classifiers that are universally robust to all\nnoise levels, and that are not sensitive to any variation in the noise model,\nwe propose a distillation-based framework that incorporates a new subcategory\nof Positive-Unlabeled learning. In particular, we shall assume that a small\nsubset of any given noisy dataset is known to have correct labels, which we\ntreat as \"positive\", while the remaining noisy subset is treated as\n\"unlabeled\". Our framework consists of the following two components: (1) We\nshall generate, via iterative updates, an augmented clean subset with\nadditional reliable \"positive\" samples filtered from \"unlabeled\" samples; (2)\nWe shall train a teacher model on this larger augmented clean set. With the\nguidance of the teacher model, we then train a student model on the whole\ndataset. Experiments were conducted on the CIFAR-10 dataset with synthetic\nlabel noise at multiple noise levels for both symmetric and asymmetric noise.\nThe results show that our framework generally outperforms at medium to high\nnoise levels. We also evaluated our framework on Clothing1M, a real-world noisy\ndataset, and we achieved 2.94% improvement in accuracy over existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: IJCNN 2021 paper, 8 pages, 3 figures. Code available: this https URL\n",
    "authors": [
      "Jingyi Xu",
      "Tony Q. S. Quek",
      "Kai Fong Ernest Chong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13892"
  },
  {
    "id": "arXiv:2105.13894",
    "title": "Performance Evaluation of Snapshot Methods to Warm the Serverless Cold  Start",
    "abstract": "The serverless computing model strengthens the cloud computing tendency to\nabstract resource management. Serverless platforms are responsible for\ndeploying and scaling the developer's applications. Serverless also\nincorporated the pay-as-you-go billing model, which only considers the time\nspent processing client requests. Such a decision created a natural incentive\nfor improving the platform's efficient resource usage. This search for\nefficiency can lead to the cold start problem, which represents a delay to\nexecute serverless applications. Among the solutions proposed to deal with the\ncold start, those based on the snapshot method stand out. Despite the rich\nexploration of the technique, there is a lack of research that evaluates the\nsolution's trade-offs. In this direction, this work compares two solutions to\nmitigate the cold start: Prebaking and SEUSS. We analyzed the solution's\nperformance with functions of different levels of complexity: NoOp, a function\nthat renders Markdown to HTML, and a function that loads 41 MB of dependencies.\nPreliminary results indicated that Prebaking showed a 33% and 25% superior\nperformance to startup the NoOp and Markdown functions, respectively. Further\nanalysis also revealed that Prebaking's warmup mechanism reduced the Markdown\nfirst request processing time by 69%.",
    "descriptor": "\nComments: in Portuguese\n",
    "authors": [
      "Paulo Silva",
      "Thiago Emmanuel Pereira"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.13894"
  },
  {
    "id": "arXiv:2105.13901",
    "title": "Video-rate multispectral imaging in laparoscopic surgery: First-in-human  application",
    "abstract": "Multispectral and hyperspectral imaging (MSI/HSI) can provide clinically\nrelevant information on morphological and functional tissue properties.\nApplication in the operating room (OR), however, has so far been limited by\ncomplex hardware setups and slow acquisition times. To overcome these\nlimitations, we propose a novel imaging system for video-rate spectral imaging\nin the clinical workflow. The system integrates a small snapshot multispectral\ncamera with a standard laparoscope and a clinically commonly used light source,\nenabling the recording of multispectral images with a spectral dimension of 16\nat a frame rate of 25 Hz. An ongoing in patient study shows that multispectral\nrecordings from this system can help detect perfusion changes in partial\nnephrectomy surgery, thus opening the doors to a wide range of clinical\napplications.",
    "descriptor": "",
    "authors": [
      "Leonardo Ayala",
      "Sebastian Wirkert",
      "Anant Vemuri",
      "Tim Adler",
      "Silvia Seidlitz",
      "Sebastian Pirmann",
      "Christina Engels",
      "Dogu Teber",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13901"
  },
  {
    "id": "arXiv:2105.13902",
    "title": "Demotivate adversarial defense in remote sensing",
    "abstract": "Convolutional neural networks are currently the state-of-the-art algorithms\nfor many remote sensing applications such as semantic segmentation or object\ndetection. However, these algorithms are extremely sensitive to over-fitting,\ndomain change and adversarial examples specifically designed to fool them.\nWhile adversarial attacks are not a threat in most remote sensing applications,\none could wonder if strengthening networks to adversarial attacks could also\nincrease their resilience to over-fitting and their ability to deal with the\ninherent variety of worldwide data. In this work, we study both adversarial\nretraining and adversarial regularization as adversarial defenses to this\npurpose. However, we show through several experiments on public remote sensing\ndatasets that adversarial robustness seems uncorrelated to geographic and\nover-fitting robustness.",
    "descriptor": "\nComments: 4 pages, 1 figure, 2 tables. Conference IGARSS 2021\n",
    "authors": [
      "Adrien Chan-Hon-Tong",
      "Gaston Lenczner",
      "Aurelien Plyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13902"
  },
  {
    "id": "arXiv:2105.13904",
    "title": "An In-Memory Analog Computing Co-Processor for Energy-Efficient CNN  Inference on Mobile Devices",
    "abstract": "In this paper, we develop an in-memory analog computing (IMAC) architecture\nrealizing both synaptic behavior and activation functions within non-volatile\nmemory arrays. Spin-orbit torque magnetoresistive random-access memory\n(SOT-MRAM) devices are leveraged to realize sigmoidal neurons as well as\nbinarized synapses. First, it is shown the proposed IMAC architecture can be\nutilized to realize a multilayer perceptron (MLP) classifier achieving orders\nof magnitude performance improvement compared to previous mixed-signal and\ndigital implementations. Next, a heterogeneous mixed-signal and mixed-precision\nCPU-IMAC architecture is proposed for convolutional neural networks (CNNs)\ninference on mobile processors, in which IMAC is designed as a co-processor to\nrealize fully-connected (FC) layers whereas convolution layers are executed in\nCPU. Architecture-level analytical models are developed to evaluate the\nperformance and energy consumption of the CPU-IMAC architecture. Simulation\nresults exhibit 6.5% and 10% energy savings for CPU-IMAC based realizations of\nLeNet and VGG CNN models, for MNIST and CIFAR-10 pattern recognition tasks,\nrespectively.",
    "descriptor": "\nComments: 6 pages, 8 figures. arXiv admin note: text overlap with arXiv:2012.02695, arXiv:2006.01238\n",
    "authors": [
      "Mohammed Elbtity",
      "Abhishek Singh",
      "Brendan Reidy",
      "Xiaochen Guo",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13904"
  },
  {
    "id": "arXiv:2105.13905",
    "title": "Learning Structures for Deep Neural Networks",
    "abstract": "In this paper, we focus on the unsupervised setting for structure learning of\ndeep neural networks and propose to adopt the efficient coding principle,\nrooted in information theory and developed in computational neuroscience, to\nguide the procedure of structure learning without label information. This\nprinciple suggests that a good network structure should maximize the mutual\ninformation between inputs and outputs, or equivalently maximize the entropy of\noutputs under mild assumptions. We further establish connections between this\nprinciple and the theory of Bayesian optimal classification, and empirically\nverify that larger entropy of the outputs of a deep neural network indeed\ncorresponds to a better classification accuracy. Then as an implementation of\nthe principle, we show that sparse coding can effectively maximize the entropy\nof the output signals, and accordingly design an algorithm based on global\ngroup sparse coding to automatically learn the inter-layer connection and\ndetermine the depth of a neural network. Our experiments on a public image\nclassification dataset demonstrate that using the structure learned from\nscratch by our proposed algorithm, one can achieve a classification accuracy\ncomparable to the best expert-designed structure (i.e., convolutional neural\nnetworks (CNN)). In addition, our proposed algorithm successfully discovers the\nlocal connectivity (corresponding to local receptive fields in CNN) and\ninvariance structure (corresponding to pulling in CNN), as well as achieves a\ngood tradeoff between marginal performance gain and network depth.",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Fei Pan",
      "Chunting Zhou",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13905"
  },
  {
    "id": "arXiv:2105.13906",
    "title": "Training of SSD(Single Shot Detector) for Facial Detection using Nvidia  Jetson Nano",
    "abstract": "In this project, we have used the computer vision algorithm SSD (Single Shot\ndetector) computer vision algorithm and trained this algorithm from the dataset\nwhich consists of 139 Pictures. Images were labeled using Intel CVAT (Computer\nVision Annotation Tool)\nWe trained this model for facial detection. We have deployed our trained\nmodel and software in the Nvidia Jetson Nano Developer kit. Model code is\nwritten in Pytorch's deep learning framework. The programming language used is\nPython.",
    "descriptor": "\nComments: 7 Pages, 7 figures\n",
    "authors": [
      "Saif Ur Rehman",
      "Muhammad Rashid Razzaq",
      "Muhammad Hadi Hussian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13906"
  },
  {
    "id": "arXiv:2105.13907",
    "title": "Towards a Very Large Scale Traffic Simulator for Multi-Agent  Reinforcement Learning Testbeds",
    "abstract": "Smart traffic control and management become an emerging application for Deep\nReinforcement Learning (DRL) to solve traffic congestion problems in urban\nnetworks. Different traffic control and management policies can be tested on\nthe traffic simulation. Current DRL-based studies are mainly supported by the\nmicroscopic simulation software (e.g., SUMO), while it is not suitable for\ncity-wide control due to the computational burden and gridlock effect. To the\nbest of our knowledge, there is a lack of studies on the large-scale traffic\nsimulator for DRL testbeds, which could further hinder the development of DRL.\nIn view of this, we propose a meso-macro traffic simulator for very large-scale\nDRL scenarios. The proposed simulator integrates mesoscopic and macroscopic\ntraffic simulation models to improve efficiency and eliminate gridlocks. The\nmesoscopic link model simulates flow dynamics on roads, and the macroscopic\nBathtub model depicts vehicle movement in regions. Moreover, both types of\nmodels can be hybridized to accommodate various DRL tasks. This creates portals\nfor mixed transportation applications under different contexts. The result\nshows that the developed simulator only takes 46 seconds to finish a 24-hour\nsimulation in a very large city with 2.2 million vehicles, which is much faster\nthan SUMO. Additionally, we develop a graphic interface for users to visualize\nthe simulation results in a web explorer. In the future, the developed\nmeso-macro traffic simulator could serve as a new environment for very\nlarge-scale DRL problems.",
    "descriptor": "\nComments: IJCAI 2021 Reinforcement Learning for Intelligent Transportation Systems (RL4ITS) Workshop\n",
    "authors": [
      "Zijian Hu",
      "Chengxiang Zhuge",
      "Wei Ma"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.13907"
  },
  {
    "id": "arXiv:2105.13910",
    "title": "A Holistic Approach to Enhanced Security and Privacy in Digital Health  Passports",
    "abstract": "As governments around the world decide to deploy digital health passports as\na tool to curb the spread of Covid-19, it becomes increasingly importation to\nconsider how these can be constructed with privacy by design. In this paper we\ndiscuss the privacy and security issues of common approaches to constructing\ndigital health passports. We then show how to construct, and deploy, secure and\nprivate digital health passports, in a simple and efficient manner. We do so by\nusing a protocol for distributed password-based token issuance, secret sharing\nand leveraging modern smart phones' secure hardware. Our solution only requires\na constant amount of asymmetric cryptographic operations and a single round of\ncommunication between the user and the party verifying the user's digital\nhealth passport, and only two rounds between the user and the server issuing\nthe digital health passport.",
    "descriptor": "",
    "authors": [
      "Tore Kasper Frederiksen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13910"
  },
  {
    "id": "arXiv:2105.13921",
    "title": "TensorFlow ManOpt: a library for optimization on Riemannian manifolds",
    "abstract": "The adoption of neural networks and deep learning in non-Euclidean domains\nhas been hindered until recently by the lack of scalable and efficient learning\nframeworks. Existing toolboxes in this space were mainly motivated by research\nand education use cases, whereas practical aspects, such as deploying and\nmaintaining machine learning models, were often overlooked.\nWe attempt to bridge this gap by proposing TensorFlow ManOpt, a Python\nlibrary for optimization on Riemannian manifolds in TensorFlow. The library is\ndesigned with the aim for a seamless integration with the TensorFlow ecosystem,\ntargeting not only research, but also streamlining production machine learning\npipelines.",
    "descriptor": "\nComments: The library code is available at this https URL\n",
    "authors": [
      "Oleg Smirnov"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13921"
  },
  {
    "id": "arXiv:2105.13926",
    "title": "Geometric Deep Learning and Equivariant Neural Networks",
    "abstract": "We survey the mathematical foundations of geometric deep learning, focusing\non group equivariant and gauge equivariant neural networks. We develop gauge\nequivariant convolutional neural networks on arbitrary manifolds $\\mathcal{M}$\nusing principal bundles with structure group $K$ and equivariant maps between\nsections of associated vector bundles. We also discuss group equivariant neural\nnetworks for homogeneous spaces $\\mathcal{M}=G/K$, which are instead\nequivariant with respect to the global symmetry $G$ on $\\mathcal{M}$. Group\nequivariant layers can be interpreted as intertwiners between induced\nrepresentations of $G$, and we show their relation to gauge equivariant\nconvolutional layers. We analyze several applications of this formalism,\nincluding semantic segmentation and object detection networks. We also discuss\nthe case of spherical networks in great detail, corresponding to the case\n$\\mathcal{M}=S^2=\\mathrm{SO}(3)/\\mathrm{SO}(2)$. Here we emphasize the use of\nFourier analysis involving Wigner matrices, spherical harmonics and\nClebsch-Gordan coefficients for $G=\\mathrm{SO}(3)$, illustrating the power of\nrepresentation theory for deep learning.",
    "descriptor": "\nComments: 57 pages\n",
    "authors": [
      "Jan E. Gerken",
      "Jimmy Aronsson",
      "Oscar Carlsson",
      "Hampus Linander",
      "Fredrik Ohlsson",
      "Christoffer Petersson",
      "Daniel Persson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2105.13926"
  },
  {
    "id": "arXiv:2105.13929",
    "title": "Quantifying Information Leakage from Gradients",
    "abstract": "Sharing deep neural networks' gradients instead of training data could\nfacilitate data privacy in collaborative learning. In practice however,\ngradients can disclose both private latent attributes and original data.\nMathematical metrics are needed to quantify both original and latent\ninformation leakages from gradients computed over the training data. In this\nwork, we first use an adaptation of the empirical $\\mathcal{V}$-information to\npresent an information-theoretic justification for the attack success rates in\na layer-wise manner. We then move towards a deeper understanding of gradient\nleakages and propose more general and efficient metrics, using sensitivity and\nsubspace distance to quantify the gradient changes w.r.t. original and latent\ninformation, respectively. Our empirical results, on six datasets and four\nmodels, reveal that gradients of the first layers contain the highest amount of\noriginal information, while the classifier/fully-connected layers placed after\nthe feature extractor contain the highest latent information. Further, we show\nhow training hyperparameters such as gradient aggregation can decrease\ninformation leakages. Our characterization provides a new understanding on\ngradient-based information leakages using the gradients' sensitivity w.r.t.\nchanges in private information, and portends possible defenses such as\nlayer-based protection or strong aggregation.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Fan Mo",
      "Anastasia Borovykh",
      "Mohammad Malekzadeh",
      "Hamed Haddadi",
      "Soteris Demetriou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13929"
  },
  {
    "id": "arXiv:2105.13931",
    "title": "Capacity of Backscatter Communication under Arbitrary Fading Dependence",
    "abstract": "We analyze the impact of arbitrary dependence between the forward and\nbackward links in backscatter communication systems. Specifically, we quantify\nthe effect of positive and negative dependence between these fading links on\nchannel capacity, using Copula theory. The benefits of this approach are\nhighlighted over the classical framework of linear dependence based on\nPearson's correlation coefficient, which is also analyzed. Results show that\nfor a fixed transmit power budget, capacity grows with positive dependence as\nwell as with fading severity in the low signal-to-noise ratio (SNR) regime.\nConversely, fading dependence becomes immaterial in the high SNR regime.",
    "descriptor": "",
    "authors": [
      "F. Rostami Ghadi",
      "F. J. Martin-Vega",
      "F. J. Lopez-Martinez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13931"
  },
  {
    "id": "arXiv:2105.13935",
    "title": "Finite-Horizon LQR Control of Quadrotors on $SE_2(3)$",
    "abstract": "This paper considers optimal control of a quadrotor unmanned aerial vehicles\n(UAV) using the discrete-time, finite-horizon, linear quadratic regulator\n(LQR). The state of a quadrotor UAV is represented as an element of the matrix\nLie group of double direct isometries, $SE_2(3)$. The nonlinear system is\nlinearized using a left-invariant error about a reference trajectory, leading\nto an optimal gain sequence that can be calculated offline. The reference\ntrajectory is calculated using the differentially flat properties of the\nquadrotor. Monte-Carlo simulations demonstrate robustness of the proposed\ncontrol scheme to parametric uncertainty, state-estimation error, and initial\nerror. Additionally, when compared to an LQR controller that uses a\nconventional error definition, the proposed controller demonstrates better\nperformance when initial errors are large.",
    "descriptor": "\nComments: Published in IEEE Robotics and Automation Letters and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Mitchell R. Cohen",
      "Khairi Abdulrahim",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13935"
  },
  {
    "id": "arXiv:2105.13937",
    "title": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient  adaptive algorithms for neural networks",
    "abstract": "We present a new class of adaptive stochastic optimization algorithms, which\novercomes many of the known shortcomings of popular adaptive optimizers that\nare currently used for the fine tuning of artificial neural networks (ANNs).\nIts underpinning theory relies on advances of Euler's polygonal approximations\nfor stochastic differential equations (SDEs) with monotone coefficients. As a\nresult, it inherits the stability properties of tamed algorithms, while it\naddresses other known issues, e.g. vanishing gradients in ANNs. In particular,\nwe provide an nonasymptotic analysis and full theoretical guarantees for the\nconvergence properties of an algorithm of this novel class, which we named\nTH$\\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments\nare presented with different types of ANNs, which show the superior performance\nof TheoPouLa over many popular adaptive optimization algorithms.",
    "descriptor": "",
    "authors": [
      "Dong-Young Lim",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13937"
  },
  {
    "id": "arXiv:2105.13939",
    "title": "Efficient Online-Bandit Strategies for Minimax Learning Problems",
    "abstract": "Several learning problems involve solving min-max problems, e.g., empirical\ndistributional robust learning or learning with non-standard aggregated losses.\nMore specifically, these problems are convex-linear problems where the\nminimization is carried out over the model parameters $w\\in\\mathcal{W}$ and the\nmaximization over the empirical distribution $p\\in\\mathcal{K}$ of the training\nset indexes, where $\\mathcal{K}$ is the simplex or a subset of it. To design\nefficient methods, we let an online learning algorithm play against a\n(combinatorial) bandit algorithm. We argue that the efficiency of such\napproaches critically depends on the structure of $\\mathcal{K}$ and propose two\nproperties of $\\mathcal{K}$ that facilitate designing efficient algorithms. We\nfocus on a specific family of sets $\\mathcal{S}_{n,k}$ encompassing various\nlearning applications and provide high-probability convergence guarantees to\nthe minimax values.",
    "descriptor": "",
    "authors": [
      "Christophe Roux",
      "Elias Wirth",
      "Sebastian Pokutta",
      "Thomas Kerdreux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13939"
  },
  {
    "id": "arXiv:2105.13940",
    "title": "Differentiable Artificial Reverberation",
    "abstract": "We propose differentiable artificial reverberation (DAR), a family of\nartificial reverberation (AR) models implemented in a deep learning framework.\nCombined with the modern deep neural networks (DNNs), the differentiable\nstructure of DAR allows training loss gradients to be back-propagated in an\nend-to-end manner. Most of the AR models bottleneck training speed when\nimplemented \"as is\" in the time domain and executed with a parallel processor\nlike GPU due to their infinite impulse response (IIR) filter components. We\ntackle this by further developing a recently proposed acceleration technique,\nwhich borrows the frequency-sampling method (FSM). With the proposed DAR\nmodels, we aim to solve an artificial reverberation parameter (ARP) estimation\ntask in a unified approach. We design an ARP estimation network applicable to\nboth analysis-synthesis (RIR-to-ARP) and blind estimation\n(reverberant-speech-to-ARP) tasks. And using different DAR models only requires\nslightly a different decoder configuration. This way, the proposed DAR\nframework overcomes the previous methods' limitations of task-dependency and\nAR-model-dependency.",
    "descriptor": "\nComments: Manuscript in progress\n",
    "authors": [
      "Sungho Lee",
      "Hyeong-Seok Choi",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13940"
  },
  {
    "id": "arXiv:2105.13941",
    "title": "Reflections on Termination of Linear Loops",
    "abstract": "This paper shows how techniques for linear dynamical systems can be used to\nreason about the behavior of general loops. We present two main results. First,\nwe show that every loop that can be expressed as a transition formula in linear\ninteger arithmetic has a best model as a deterministic affine transition\nsystem. Second, we show that for any linear dynamical system $f$ with integer\neigenvalues and any integer arithmetic formula $G$, there is a linear integer\narithmetic formula that holds exactly for the states of $f$ for which $G$ is\neventually invariant. Combining the two, we develop a monotone conditional\ntermination analysis for general loops.",
    "descriptor": "",
    "authors": [
      "Shaowei Zhu",
      "Zachary Kincaid"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.13941"
  },
  {
    "id": "arXiv:2105.13942",
    "title": "Towards Deterministic Diverse Subset Sampling",
    "abstract": "Determinantal point processes (DPPs) are well known models for diverse subset\nselection problems, including recommendation tasks, document summarization and\nimage search. In this paper, we discuss a greedy deterministic adaptation of\nk-DPP. Deterministic algorithms are interesting for many applications, as they\nprovide interpretability to the user by having no failure probability and\nalways returning the same results. First, the ability of the method to yield\nlow-rank approximations of kernel matrices is evaluated by comparing the\naccuracy of the Nystr\\\"om approximation on multiple datasets. Afterwards, we\ndemonstrate the usefulness of the model on an image search task.",
    "descriptor": "",
    "authors": [
      "Joachim Schreurs",
      "Micha\u00ebl Fanuel",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13942"
  },
  {
    "id": "arXiv:2105.13947",
    "title": "Changing the World by Changing the Data",
    "abstract": "NLP community is currently investing a lot more research and resources into\ndevelopment of deep learning models than training data. While we have made a\nlot of progress, it is now clear that our models learn all kinds of spurious\npatterns, social biases, and annotation artifacts. Algorithmic solutions have\nso far had limited success. An alternative that is being actively discussed is\nmore careful design of datasets so as to deliver specific signals. This\nposition paper maps out the arguments for and against data curation, and argues\nthat fundamentally the point is moot: curation already is and will be\nhappening, and it is changing the world. The question is only how much thought\nwe want to invest into that process.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Anna Rogers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13947"
  },
  {
    "id": "arXiv:2105.13949",
    "title": "Latent Space Exploration Using Generative Kernel PCA",
    "abstract": "Kernel PCA is a powerful feature extractor which recently has seen a\nreformulation in the context of Restricted Kernel Machines (RKMs). These RKMs\nallow for a representation of kernel PCA in terms of hidden and visible units\nsimilar to Restricted Boltzmann Machines. This connection has led to insights\non how to use kernel PCA in a generative procedure, called generative kernel\nPCA. In this paper, the use of generative kernel PCA for exploring latent\nspaces of datasets is investigated. New points can be generated by gradually\nmoving in the latent space, which allows for an interpretation of the\ncomponents. Firstly, examples of this feature space exploration on three\ndatasets are shown with one of them leading to an interpretable representation\nof ECG signals. Afterwards, the use of the tool in combination with novelty\ndetection is shown, where the latent space around novel patterns in the data is\nexplored. This helps in the interpretation of why certain points are considered\nas novel.",
    "descriptor": "",
    "authors": [
      "David Winant",
      "Joachim Schreurs",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13949"
  },
  {
    "id": "arXiv:2105.13950",
    "title": "Reset control systems: the zero-crossing resetting law",
    "abstract": "A novel representation of reset control systems with a zero-crossing\nresetting law, in the framework of hybrid inclusions, is postulated. The\nproblems of well-posedness and stability of the resulting hybrid dynamical\nsystem are investigated, with a strong motivation in how non-deterministic\nbehavior is accomplished in control practice. Several stability conditions,\nbased on the eigenstructure of matrices related with periods of the reset\ninterval sequences, and on Lyapunov function-based conditions, are developed.",
    "descriptor": "\nComments: 29 pages, 11 figures\n",
    "authors": [
      "Alfonso Ba\u00f1os",
      "Antonio Barreiro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13950"
  },
  {
    "id": "arXiv:2105.13957",
    "title": "Darknet Data Mining -- A Canadian Cyber-crime Perspective",
    "abstract": "Exploring the darknet can be a daunting task; this paper explores the\napplication of data mining the darknet within a Canadian cybercrime\nperspective. Measuring activity through marketplace analysis and vendor\nattribution has proven difficult in the past. Observing different aspects of\nthe darknet and implementing methods of monitoring and collecting data in the\nhopes of connecting contributions to the darknet marketplaces to and from\nCanada. The significant findings include a small Canadian presence, measured\nthe product categories, and attribution of one cross-marketplace vendor through\ndata visualization. The results were made possible through a multi-stage\nprocessing pipeline, including data crawling, scraping, and parsing. The\nprimary future works include enhancing the pipeline to include other media,\nsuch as web forums, chatrooms, and emails. Applying machine learning models\nlike natural language processing or sentiment analysis could prove beneficial\nduring investigations.",
    "descriptor": "\nComments: 13 pages, 19 figures, Honours Bachelors Capstone Project. for associated code, see this https URL\n",
    "authors": [
      "Edward Crowder",
      "Jay Lansiquot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13957"
  },
  {
    "id": "arXiv:2105.13959",
    "title": "Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for  Multiple Toxic Span Extraction from Online Comments",
    "abstract": "Social network platforms are generally used to share positive, constructive,\nand insightful content. However, in recent times, people often get exposed to\nobjectionable content like threat, identity attacks, hate speech, insults,\nobscene texts, offensive remarks or bullying. Existing work on toxic speech\ndetection focuses on binary classification or on differentiating toxic speech\namong a small set of categories. This paper describes the system proposed by\nteam Cisco for SemEval-2021 Task 5: Toxic Spans Detection, the first shared\ntask focusing on detecting the spans in the text that attribute to its\ntoxicity, in English language. We approach this problem primarily in two ways:\na sequence tagging approach and a dependency parsing approach. In our sequence\ntagging approach we tag each token in a sentence under a particular tagging\nscheme. Our best performing architecture in this approach also proved to be our\nbest performing architecture overall with an F1 score of 0.6922, thereby\nplacing us 7th on the final evaluation phase leaderboard. We also explore a\ndependency parsing approach where we extract spans from the input sentence\nunder the supervision of target span boundaries and rank our spans using a\nbiaffine model. Finally, we also provide a detailed analysis of our results and\nmodel performance in our paper.",
    "descriptor": "\nComments: 9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021\n",
    "authors": [
      "Sreyan Ghosh",
      "Sonal Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13959"
  },
  {
    "id": "arXiv:2105.13961",
    "title": "A Study about the Knowledge and Use of Requirements Engineering  Standards in Industry",
    "abstract": "Context: The use of standards is considered a vital part of any engineering\ndiscipline. So one could expect that standards play an important role in\nRequirements Engineering (RE) as well. However, little is known about the\nactual knowledge and use of RE-related standards in industry.\nObjective: In this article, we investigate to which extent standards and\nrelated artifacts such as templates or guidelines are known and used by RE\npractitioners.\nMethod: To this end, we have conducted an questionnaire-based online survey.\nWe could analyze the replies from 90 RE practitioners using a combination of\nclosed and open-text questions.\nResults: Our results indicate that the knowledge and use of standards and\nrelated artifacts in RE is less widespread than one might expect from an\nengineering perspective. For example, about 45\\% of the respondents working as\nrequirements engineers or business analysts do not know at least one of the two\ncore standard in RE. Participants in our study mostly use standards by personal\ndecision rather than being imposed by their respective company, customer, or\nregulator. Beyond insufficient knowledge, we also found cultural and\norganizational factors impeding the widespread adoption of standards in RE.\nConclusions: Overall, our results provide empirically informed insights into\nthe actual use of standards and related artifacts in RE practice and -\nindirectly - about the value that the current standards create for RE\npractitioners.",
    "descriptor": "\nComments: Preprint accepted for publication at IEEE Transactions on Software Engineering\n",
    "authors": [
      "Xavier Franch",
      "Martin Glinz",
      "Daniel Mendez",
      "Norbert Seyff"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13961"
  },
  {
    "id": "arXiv:2105.13962",
    "title": "NViSII: A Scriptable Tool for Photorealistic Image Generation",
    "abstract": "We present a Python-based renderer built on NVIDIA's OptiX ray tracing engine\nand the OptiX AI denoiser, designed to generate high-quality synthetic images\nfor research in computer vision and deep learning. Our tool enables the\ndescription and manipulation of complex dynamic 3D scenes containing object\nmeshes, materials, textures, lighting, volumetric data (e.g., smoke), and\nbackgrounds. Metadata, such as 2D/3D bounding boxes, segmentation masks, depth\nmaps, normal maps, material properties, and optical flow vectors, can also be\ngenerated. In this work, we discuss design goals, architecture, and\nperformance. We demonstrate the use of data generated by path tracing for\ntraining an object detector and pose estimator, showing improved performance in\nsim-to-real transfer in situations that are difficult for traditional\nraster-based renderers. We offer this tool as an easy-to-use, performant,\nhigh-quality renderer for advancing research in synthetic data generation and\ndeep learning.",
    "descriptor": "\nComments: SDG Workshop at ICLR 2021. Project page is at this https URL\n",
    "authors": [
      "Nathan Morrical",
      "Jonathan Tremblay",
      "Yunzhi Lin",
      "Stephen Tyree",
      "Stan Birchfield",
      "Valerio Pascucci",
      "Ingo Wald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13962"
  },
  {
    "id": "arXiv:2105.13964",
    "title": "A Review of Network Evolution Towards a Smart Connected World",
    "abstract": "With the rapid innovations in technology, wireless internet-connected devices\nare more ubiquitous than ever and can be found in virtually every aspect of\nboth our personal and professional lives. In this paper, we propose a\ncomprehensive literature review that focuses on various network components that\ncreate connectivity among different devices, specifically Wireless Sensor\nNetworks (WSNs), Radio-Frequency Identification (RFID) tags, Internet of Things\n(IoT) devices, and how these devices helped usher in the 4th Industrial\nRevolution, or Industry 4.0. This paper focuses on the protocols, architecture,\nuses, security concerns, and solutions used in these network technologies, as\nwell as their differences and similarities.",
    "descriptor": "\nComments: This material is based upon work supported by the National Science Foundation under Grant No. (CNS-1801593). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation\n",
    "authors": [
      "Olivia Haring",
      "Sylvia Worlali Azumah",
      "Nelly Elsayed"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13964"
  },
  {
    "id": "arXiv:2105.13965",
    "title": "Revitalizing Optimization for 3D Human Pose and Shape Estimation: A  Sparse Constrained Formulation",
    "abstract": "We propose a novel sparse constrained formulation and from it derive a\nreal-time optimization method for 3D human pose and shape estimation. Our\noptimization method is orders of magnitude faster (avg. 4 ms convergence) than\nexisting optimization methods, while being mathematically equivalent to their\ndense unconstrained formulation. We achieve this by exploiting the underlying\nsparsity and constraints of our formulation to efficiently compute the\nGauss-Newton direction. We show that this computation scales linearly with the\nnumber of joints of a complex 3D human model, in contrast to prior work where\nit scales cubically due to their dense unconstrained formulation. Based on our\noptimization method, we present a real-time motion capture framework that\nestimates 3D human poses and shapes from a single image at over 30 FPS. In\nbenchmarks against state-of-the-art methods on multiple public datasets, our\nframe-work outperforms other optimization methods and achieves competitive\naccuracy against regression methods.",
    "descriptor": "\nComments: 20 pages, including appendix\n",
    "authors": [
      "Taosha Fan",
      "Kalyan Vasudev Alwala",
      "Donglai Xiang",
      "Weipeng Xu",
      "Todd Murphey",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13965"
  },
  {
    "id": "arXiv:2105.13967",
    "title": "Bridge Data Center AI Systems with Edge Computing for Actionable  Information Retrieval",
    "abstract": "Extremely high data rates at modern synchrotron and X-ray free-electron\nlasers (XFELs) light source beamlines motivate the use of machine learning\nmethods for data reduction, feature detection, and other purposes. Regardless\nof the application, the basic concept is the same: data collected in early\nstages of an experiment, data from past similar experiments, and/or data\nsimulated for the upcoming experiment are used to train machine learning models\nthat, in effect, learn specific characteristics of those data; these models are\nthen used to process subsequent data more efficiently than would\ngeneral-purpose models that lack knowledge of the specific dataset or data\nclass. Thus, a key challenge is to be able to train models with sufficient\nrapidity that they can be deployed and used within useful timescales. We\ndescribe here how specialized data center AI systems can be used for this\npurpose.",
    "descriptor": "",
    "authors": [
      "Zhengchun Liu",
      "Ahsan Ali",
      "Peter Kenesei",
      "Antonino Miceli",
      "Hemant Sharma",
      "Nicholas Schwarz",
      "Dennis Trujillo",
      "Hyunseung Yoo",
      "Ryan Coffee",
      "Ryan Herbst",
      "Jana Thayer",
      "Chun Hong Yoon",
      "Ian Foster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13967"
  },
  {
    "id": "arXiv:2105.13970",
    "title": "Pull Request Decision Explained: An Empirical Overview",
    "abstract": "Context: Pull-based development model is widely used in open source, leading\nthe trends in distributed software development. One aspect which has garnered\nsignificant attention is studies on pull request decision - identifying factors\nfor explanation. Objective: This study builds on a decade long research on pull\nrequest decision to explain it. We empirically investigate how factors\ninfluence pull request decision and scenarios that change the influence of\nfactors. Method: We identify factors influencing pull request decision on\nGitHub through a systematic literature review and infer it by mining archival\ndata. We collect a total of 3,347,937 pull requests with 95 features from\n11,230 diverse projects on GitHub. Using this data, we explore the relations of\nthe factors to each other and build mixed-effect logistic regression models to\nempirically explain pull request decision. Results: Our study shows that a\nsmall number of factors explain pull request decision with the integrator same\nor different from the submitter as the most important factor. We also noted\nthat some factors are important only in special cases e.g., the percentage of\nfailed builds is important for pull request decision when continuous\nintegration is used.",
    "descriptor": "",
    "authors": [
      "Xunhui Zhang",
      "Yue Yu",
      "Georgios Gousios",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13970"
  },
  {
    "id": "arXiv:2105.13971",
    "title": "Artificial life: sustainable self-replicating systems",
    "abstract": "Nature has found one method of organizing living matter, but maybe there are\nalso other options -- not yet discovered -- on how to create life. To study the\nlife as it could be is the objective of an interdisciplinary field called\nArtificial Life (commonly abbreviated as ALife). The word \"artificial\" refers\nto the fact that humans are involved in the creation process. The results might\nbe completely unlike natural forms of life, not only because of their chemical\ncomposition, but even some computer programs exhibiting life-like behaviours\ninterest ALife researchers.",
    "descriptor": "\nComments: Short review chapter, to be included in EPS Grand Challenges 2050 book\n",
    "authors": [
      "Carlos Gershenson",
      "Jitka Cejkova"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13971"
  },
  {
    "id": "arXiv:2105.13975",
    "title": "Relation Matters in Sampling: A Scalable Multi-Relational Graph Neural  Network for Drug-Drug Interaction Prediction",
    "abstract": "Sampling is an established technique to scale graph neural networks to large\ngraphs. Current approaches however assume the graphs to be homogeneous in terms\nof relations and ignore relation types, critically important in biomedical\ngraphs. Multi-relational graphs contain various types of relations that usually\ncome with variable frequency and have different importance for the problem at\nhand. We propose an approach to modeling the importance of relation types for\nneighborhood sampling in graph neural networks and show that we can learn the\nright balance: relation-type probabilities that reflect both frequency and\nimportance. Our experiments on drug-drug interaction prediction show that\nstate-of-the-art graph neural networks profit from relation-dependent sampling\nin terms of both accuracy and efficiency.",
    "descriptor": "",
    "authors": [
      "Arthur Feeney",
      "Rishabh Gupta",
      "Veronika Thost",
      "Rico Angell",
      "Gayathri Chandu",
      "Yash Adhikari",
      "Tengfei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13975"
  },
  {
    "id": "arXiv:2105.13977",
    "title": "Perturbation Theory for the Information Bottleneck",
    "abstract": "Extracting relevant information from data is crucial for all forms of\nlearning. The information bottleneck (IB) method formalizes this, offering a\nmathematically precise and conceptually appealing framework for understanding\nlearning phenomena. However the nonlinearity of the IB problem makes it\ncomputationally expensive and analytically intractable in general. Here we\nderive a perturbation theory for the IB method and report the first complete\ncharacterization of the learning onset, the limit of maximum relevant\ninformation per bit extracted from data. We test our results on synthetic\nprobability distributions, finding good agreement with the exact numerical\nsolution near the onset of learning. We explore the difference and subtleties\nin our derivation and previous attempts at deriving a perturbation theory for\nthe learning onset and attribute the discrepancy to a flawed assumption. Our\nwork also provides a fresh perspective on the intimate relationship between the\nIB method and the strong data processing inequality.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Vudtiwat Ngampruetikorn",
      "David J. Schwab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.13977"
  },
  {
    "id": "arXiv:2105.13978",
    "title": "What Is Considered Complete for Visual Recognition?",
    "abstract": "This is an opinion paper. We hope to deliver a key message that current\nvisual recognition systems are far from complete, i.e., recognizing everything\nthat human can recognize, yet it is very unlikely that the gap can be bridged\nby continuously increasing human annotations. Based on the observation, we\nadvocate for a new type of pre-training task named learning-by-compression. The\ncomputational models (e.g., a deep network) are optimized to represent the\nvisual data using compact features, and the features preserve the ability to\nrecover the original data. Semantic annotations, when available, play the role\nof weak supervision. An important yet challenging issue is the evaluation of\nimage recovery, where we suggest some design principles and future research\ndirections. We hope our proposal can inspire the community to pursue the\ncompression-recovery tradeoff rather than the accuracy-complexity tradeoff.",
    "descriptor": "\nComments: 13 pages, 5 figures, 1 table\n",
    "authors": [
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Longhui Wei",
      "Jianlong Chang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13978"
  },
  {
    "id": "arXiv:2105.13979",
    "title": "EDEN: Deep Feature Distribution Pooling for Saimaa Ringed Seals Pattern  Matching",
    "abstract": "In this paper, pelage pattern matching is considered to solve the individual\nre-identification of the Saimaa ringed seals. Animal re-identification together\nwith the access to large amount of image material through camera traps and\ncrowd-sourcing provide novel possibilities for animal monitoring and\nconservation. We propose a novel feature pooling approach that allow\naggregating the local pattern features to get a fixed size embedding vector\nthat incorporate global features by taking into account the spatial\ndistribution of features. This is obtained by eigen decomposition of\ncovariances computed for probability mass functions representing feature maps.\nEmbedding vectors can then be used to find the best match in the database of\nknown individuals allowing animal re-identification. The results show that the\nproposed pooling method outperforms the existing methods on the challenging\nSaimaa ringed seal image data.",
    "descriptor": "\nComments: 10 pages, 4 figures,submitted to 2nd International Conference on Cyber-Physical Systems & Control (CPS&C'2021)\n",
    "authors": [
      "Ilja Chelak",
      "Ekaterina Nepovinnykh",
      "Tuomas Eerola",
      "Heikki Kalviainen",
      "Igor Belykh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13979"
  },
  {
    "id": "arXiv:2105.13980",
    "title": "Deterministic 3-Coloring of Trees in the Sublinear MPC model",
    "abstract": "We present deterministic $O(\\log^2 \\log n)$ time sublinear Massively Parallel\nComputation (MPC) algorithms for 3-coloring, maximal independent set and\nmaximal matching in trees with $n$ nodes. In accordance with the sublinear MPC\nregime, our algorithms run on machines that have memory as little as\n$O(n^\\delta)$ for any arbitrary constant $0<\\delta<1$. Furthermore, our\nalgorithms use only $O(n)$ global memory. Our main result is the 3-coloring\nalgorithm, which contrasts the probabilistic 4-coloring algorithm of Ghaffari,\nGrunau and Jin [DISC'20]. The maximal independent set and maximal matching\nalgorithms follow in $O(1)$ time after obtaining the coloring. The key\ningredient of our 3-coloring algorithm is an $O(\\log^2 \\log n)$ time MPC\nimplementation of a variant of the rake-and-compress tree decomposition used by\nChang and Pettie [FOCS'17], which is closely related to the $H$-partition by\nBarenboim and Elkin [PODC'08]. When restricting to trees of constant maximum\ndegree, we bring the runtime down to $O(\\log \\log n)$.",
    "descriptor": "",
    "authors": [
      "Rustam Latypov",
      "Jara Uitto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.13980"
  },
  {
    "id": "arXiv:2105.13984",
    "title": "Confident in the Crowd: Bayesian Inference to Improve Data Labelling in  Crowdsourcing",
    "abstract": "With the increased interest in machine learning and big data problems, the\nneed for large amounts of labelled data has also grown. However, it is often\ninfeasible to get experts to label all of this data, which leads many\npractitioners to crowdsourcing solutions. In this paper, we present new\ntechniques to improve the quality of the labels while attempting to reduce the\ncost. The naive approach to assigning labels is to adopt a majority vote\nmethod, however, in the context of data labelling, this is not always ideal as\ndata labellers are not equally reliable. One might, instead, give higher\npriority to certain labellers through some kind of weighted vote based on past\nperformance. This paper investigates the use of more sophisticated methods,\nsuch as Bayesian inference, to measure the performance of the labellers as well\nas the confidence of each label. The methods we propose follow an iterative\nimprovement algorithm which attempts to use the least amount of workers\nnecessary to achieve the desired confidence in the inferred label. This paper\nexplores simulated binary classification problems with simulated workers and\nquestions to test the proposed methods. Our methods outperform the standard\nvoting methods in both cost and accuracy while maintaining higher reliability\nwhen there is disagreement within the crowd.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Pierce Burke",
      "Richard Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.13984"
  },
  {
    "id": "arXiv:2105.13985",
    "title": "LDPC Codes with Soft Interference Cancellation for Uncoordinated  Unsourced Multiple Access",
    "abstract": "This article presents a novel enhancement to the random spreading based\ncoding scheme developed by Pradhan et al.\\ for the unsourced multiple access\nchannel. The original coding scheme features a polar outer code in conjunction\nwith a successive cancellation list decoder (SCLD) and a hard-input soft-output\nMMSE estimator. In contrast, the proposed scheme employs a soft-input\nsoft-output MMSE estimator for multi-user detection. This is accomplished by\nreplacing the SCLD based polar code with an LDPC code amenable to belief\npropagation decoding. This novel framework is leveraged to successfully pass\npertinent soft information between the MMSE estimator and the outer code. LDPC\ncodes are carefully designed using density evolution techniques to match the\niterative process. This enhanced architecture exhibits significant performance\nimprovements and represents the state-of-the-art over a wide range of system\nparameters.",
    "descriptor": "",
    "authors": [
      "Asit Kumar Pradhan",
      "Vamsi K. Amalladinne",
      "Krishna R. Narayanan",
      "Jean-Francois Chamberland"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13985"
  },
  {
    "id": "arXiv:2105.13986",
    "title": "Improving Generalization in Mountain Car Through the Partitioned  Parameterized Policy Approach via Quasi-Stochastic Gradient Descent",
    "abstract": "The reinforcement learning problem of finding a control policy that minimizes\nthe minimum time objective for the Mountain Car environment is considered.\nParticularly, a class of parameterized nonlinear feedback policies is optimized\nover to reach the top of the highest mountain peak in minimum time. The\noptimization is carried out using quasi-Stochastic Gradient Descent (qSGD)\nmethods. In attempting to find the optimal minimum time policy, a new\nparameterized policy approach is considered that seeks to learn an optimal\npolicy parameter for different regions of the state space, rather than rely on\na single macroscopic policy parameter for the entire state space. This\npartitioned parameterized policy approach is shown to outperform the uniform\nparameterized policy approach and lead to greater generalization than prior\nmethods, where the Mountain Car became trapped in circular trajectories in the\nstate space.",
    "descriptor": "",
    "authors": [
      "Caleb M. Bowyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13986"
  },
  {
    "id": "arXiv:2105.13988",
    "title": "An Explainable Probabilistic Classifier for Categorical Data Inspired to  Quantum Physics",
    "abstract": "This paper presents Sparse Tensor Classifier (STC), a supervised\nclassification algorithm for categorical data inspired by the notion of\nsuperposition of states in quantum physics. By regarding an observation as a\nsuperposition of features, we introduce the concept of wave-particle duality in\nmachine learning and propose a generalized framework that unifies the classical\nand the quantum probability. We show that STC possesses a wide range of\ndesirable properties not available in most other machine learning methods but\nit is at the same time exceptionally easy to comprehend and use. Empirical\nevaluation of STC on structured data and text classification demonstrates that\nour methodology achieves state-of-the-art performances compared to both\nstandard classifiers and deep learning, at the additional benefit of requiring\nminimal data pre-processing and hyper-parameter tuning. Moreover, STC provides\na native explanation of its predictions both for single instances and for each\ntarget label globally.",
    "descriptor": "",
    "authors": [
      "Emanuele Guidotti",
      "Alfio Ferrara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13988"
  },
  {
    "id": "arXiv:2105.13994",
    "title": "Linguistic Structures as Weak Supervision for Visual Scene Graph  Generation",
    "abstract": "Prior work in scene graph generation requires categorical supervision at the\nlevel of triplets - subjects and objects, and predicates that relate them,\neither with or without bounding box information. However, scene graph\ngeneration is a holistic task: thus holistic, contextual supervision should\nintuitively improve performance. In this work, we explore how linguistic\nstructures in captions can benefit scene graph generation. Our method captures\nthe information provided in captions about relations between individual\ntriplets, and context for subjects and objects (e.g. visual properties are\nmentioned). Captions are a weaker type of supervision than triplets since the\nalignment between the exhaustive list of human-annotated subjects and objects\nin triplets, and the nouns in captions, is weak. However, given the large and\ndiverse sources of multimodal data on the web (e.g. blog posts with images and\ncaptions), linguistic supervision is more scalable than crowdsourced triplets.\nWe show extensive experimental comparisons against prior methods which leverage\ninstance- and image-level supervision, and ablate our method to show the impact\nof leveraging phrasal and sequential context, and techniques to improve\nlocalization of subjects and objects.",
    "descriptor": "\nComments: To appear in CVPR 2021\n",
    "authors": [
      "Keren Ye",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13994"
  },
  {
    "id": "arXiv:2105.13995",
    "title": "SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular  Data in Scientific Documents (SEM-TAB-FACTS)",
    "abstract": "Understanding tables is an important and relevant task that involves\nunderstanding table structure as well as being able to compare and contrast\ninformation within cells. In this paper, we address this challenge by\npresenting a new dataset and tasks that addresses this goal in a shared task in\nSemEval 2020 Task 9: Fact Verification and Evidence Finding for Tabular Data in\nScientific Documents (SEM-TAB-FACTS). Our dataset contains 981\nmanually-generated tables and an auto-generated dataset of 1980 tables\nproviding over 180K statement and over 16M evidence annotations. SEM-TAB-FACTS\nfeatured two sub-tasks. In sub-task A, the goal was to determine if a statement\nis supported, refuted or unknown in relation to a table. In sub-task B, the\nfocus was on identifying the specific cells of a table that provide evidence\nfor the statement. 69 teams signed up to participate in the task with 19\nsuccessful submissions to subtask A and 12 successful submissions to subtask B.\nWe present our results and main findings from the competition.",
    "descriptor": "\nComments: To Appear in SemEval 2021\n",
    "authors": [
      "Nancy X. R. Wang",
      "Diwakar Mahajan",
      "Marina Danilevsk. Sara Rosenthal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13995"
  },
  {
    "id": "arXiv:2105.14002",
    "title": "What if This Modified That? Syntactic Interventions via Counterfactual  Embeddings",
    "abstract": "Neural language models exhibit impressive performance on a variety of tasks,\nbut their internal reasoning may be difficult to understand. Prior art aims to\nuncover meaningful properties within model representations via probes, but it\nis unclear how faithfully such probes portray information that the models\nactually use. To overcome such limitations, we propose a technique, inspired by\ncausal analysis, for generating counterfactual embeddings within models. In\nexperiments testing our technique, we produce evidence that suggests some\nBERT-based models use a tree-distance-like representation of syntax in\ndownstream prediction tasks.",
    "descriptor": "",
    "authors": [
      "Mycal Tucker",
      "Peng Qian",
      "Roger Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14002"
  },
  {
    "id": "arXiv:2105.14004",
    "title": "Distributed adaptive stabilization",
    "abstract": "In this paper we consider distributed adaptive stabilization for uncertain\nmultivariable linear systems with a time-varying diagonal matrix gain. We show\nthat uncertain multivariable linear systems are stabilizable by diagonal matrix\nhigh gains if the system matrix is an H-matrix with positive diagonal entries.\nBased on matrix measure and stability theory for diagonally dominant systems,\nwe consider two classes of uncertain linear systems, and derive a threshold\ncondition to ensure their exponential stability by a monotonically increasing\ndiagonal gain matrix. When each individual gain function in the matrix gain is\nupdated by state-dependent functions using only local state information, the\nboundedness and convergence of both system states and adaptive matrix gains are\nguaranteed. We apply the adaptive distributed stabilization approach to\nadaptive synchronization control for large-scale complex networks consisting of\nnonlinear node dynamics and time-varying coupling weights. A unified framework\nfor adaptive synchronization is proposed that includes several general design\napproaches for adaptive coupling weights to guarantee network synchronization.",
    "descriptor": "\nComments: 16 Pages and 7 figures\n",
    "authors": [
      "Zhiyong Sun",
      "Anders Rantzer",
      "Zhongkui Li",
      "Anders Robertsson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2105.14004"
  },
  {
    "id": "arXiv:2105.14005",
    "title": "Online Hate: Behavioural Dynamics and Relationship with Misinformation",
    "abstract": "Online debates are often characterised by extreme polarisation and heated\ndiscussions among users. The presence of hate speech online is becoming\nincreasingly problematic, making necessary the development of appropriate\ncountermeasures. In this work, we perform hate speech detection on a corpus of\nmore than one million comments on YouTube videos through a machine learning\nmodel fine-tuned on a large set of hand-annotated data. Our analysis shows that\nthere is no evidence of the presence of \"serial haters\", intended as active\nusers posting exclusively hateful comments. Moreover, coherently with the echo\nchamber hypothesis, we find that users skewed towards one of the two categories\nof video channels (questionable, reliable) are more prone to use inappropriate,\nviolent, or hateful language within their opponents community. Interestingly,\nusers loyal to reliable sources use on average a more toxic language than their\ncounterpart. Finally, we find that the overall toxicity of the discussion\nincreases with its length, measured both in terms of number of comments and\ntime. Our results show that, coherently with Godwin's law, online debates tend\nto degenerate towards increasingly toxic exchanges of views.",
    "descriptor": "",
    "authors": [
      "Matteo Cinelli",
      "Andra\u017e Pelicon",
      "Igor Mozeti\u010d",
      "Walter Quattrociocchi",
      "Petra Kralj Novak",
      "Fabiana Zollo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14005"
  },
  {
    "id": "arXiv:2105.14009",
    "title": "Iris Liveness Detection using a Cascade of Dedicated Deep Learning  Networks",
    "abstract": "Iris pattern recognition has significantly improved the biometric\nauthentication field due to its high stability and uniqueness. Such physical\ncharacteristics have played an essential role in security and other related\nareas. However, presentation attacks, also known as spoofing techniques, can\nbypass biometric authentication systems using artefacts such as printed images,\nartificial eyes, textured contact lenses, etc. Many liveness detection methods\nthat improve the security of these systems have been proposed. The first\nInternational Iris Liveness Detection competition, where the effectiveness of\nliveness detection methods is evaluated, was first launched in 2013, and its\nlatest iteration was held in 2020. This paper proposes a serial architecture\nbased on a MobileNetV2 modification, trained from scratch to classify bona fide\niris images versus presentation attack images. The bona fide class consists of\nlive iris images, whereas the attack presentation instrument classes are\ncomprised of cadaver, printed, and contact lenses images, for a total of four\nscenarios. All the images were pre-processed and weighted per class to present\na fair evaluation. This proposal won the LivDet-Iris 2020 competition using\ntwo-class scenarios. Additionally, we present new three-class and four-class\nscenarios that further improve the competition results. This approach is\nprimarily focused in detecting the bona fide class over improving the detection\nof presentation attack instruments. For the two, three, and four classes\nscenarios, an Equal Error Rate (EER) of 4.04\\%, 0.33\\%, and 4,53\\% was obtained\nrespectively. Overall, the best serial model proposed, using three scenarios,\nreached an ERR of 0.33\\% with an Attack Presentation Classification Error Rate\n(APCER) of 0.0100 and a Bona Fide Classification Error Rate (BPCER) of 0.000.\nThis work outperforms the LivDet-Iris 2020 competition results.",
    "descriptor": "",
    "authors": [
      "Juan Tapia",
      "Sebastian Gonzalez",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14009"
  },
  {
    "id": "arXiv:2105.14013",
    "title": "Feature extraction and evaluation for BioMedical Question Answering",
    "abstract": "In this paper, we present our work on the BioASQ pipeline. The goal is to\nanswer four types of questions: summary, yes/no, factoids, and list. Our goal\nis to empirically evaluate different modules involved: the feature extractor\nand the sentence selection block. We used our pipeline to test the\neffectiveness of each module for all kinds of question types and perform error\nanalysis. We defined metrics that are useful for future research related to the\nBioASQ pipeline critical to improve the performance of the training pipeline.",
    "descriptor": "\nComments: An exploratory analysis for BioMedical Question Answering\n",
    "authors": [
      "Ankit Shah",
      "Srishti Singh",
      "Shih-Yen Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14013"
  },
  {
    "id": "arXiv:2105.14016",
    "title": "Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs  with a Generative Model",
    "abstract": "The curse of dimensionality is a widely known issue in reinforcement learning\n(RL). In the tabular setting where the state space $\\mathcal{S}$ and the action\nspace $\\mathcal{A}$ are both finite, to obtain a nearly optimal policy with\nsampling access to a generative model, the minimax optimal sample complexity\nscales linearly with $|\\mathcal{S}|\\times|\\mathcal{A}|$, which can be\nprohibitively large when $\\mathcal{S}$ or $\\mathcal{A}$ is large. This paper\nconsiders a Markov decision process (MDP) that admits a set of state-action\nfeatures, which can linearly express (or approximate) its probability\ntransition kernel. We show that a model-based approach (resp.$~$Q-learning)\nprovably learns an $\\varepsilon$-optimal policy (resp.$~$Q-function) with high\nprobability as soon as the sample size exceeds the order of\n$\\frac{K}{(1-\\gamma)^{3}\\varepsilon^{2}}$\n(resp.$~$$\\frac{K}{(1-\\gamma)^{4}\\varepsilon^{2}}$), up to some logarithmic\nfactor. Here $K$ is the feature dimension and $\\gamma\\in(0,1)$ is the discount\nfactor of the MDP. Both sample complexity bounds are provably tight, and our\nresult for the model-based approach matches the minimax lower bound. Our\nresults show that for arbitrarily large-scale MDP, both the model-based\napproach and Q-learning are sample-efficient when $K$ is relatively small, and\nhence the title of this paper.",
    "descriptor": "",
    "authors": [
      "Bingyan Wang",
      "Yuling Yan",
      "Jianqing Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14016"
  },
  {
    "id": "arXiv:2105.14021",
    "title": "Boosting Monocular Depth Estimation Models to High-Resolution via  Content-Adaptive Multi-Resolution Merging",
    "abstract": "Neural networks have shown great abilities in estimating depth from a single\nimage. However, the inferred depth maps are well below one-megapixel resolution\nand often lack fine-grained details, which limits their practicality. Our\nmethod builds on our analysis on how the input resolution and the scene\nstructure affects depth estimation performance. We demonstrate that there is a\ntrade-off between a consistent scene structure and the high-frequency details,\nand merge low- and high-resolution estimations to take advantage of this\nduality using a simple depth merging network. We present a double estimation\nmethod that improves the whole-image depth estimation and a patch selection\nmethod that adds local details to the final result. We demonstrate that by\nmerging estimations at different resolutions with changing context, we can\ngenerate multi-megapixel depth maps with a high level of detail using a\npre-trained model.",
    "descriptor": "\nComments: For more details visit this http URL\n",
    "authors": [
      "S. Mahdi H. Miangoleh",
      "Sebastian Dille",
      "Long Mai",
      "Sylvain Paris",
      "Ya\u011f\u0131z Aksoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14021"
  },
  {
    "id": "arXiv:2105.13355",
    "title": "Besov regularity of non-linear parabolic PDEs on non-convex polyhedral  domains",
    "abstract": "This paper is concerned with the regularity of solutions to parabolic\nevolution equations. We consider semilinear problems on non-convex domains.\nSpecial attention is paid to the smoothness in the specific scale\n$B^r_{\\tau,\\tau}$, $\\frac{1}{\\tau}=\\frac rd+ \\frac 1p$ of Besov spaces. The\nregularity in these spaces determines the approximation order that can be\nachieved by adaptive and other nonlinear approximation schemes. We show that\nfor all cases under consideration the Besov regularity is high enough to\njustify the use of adaptive algorithms. Our proofs are based on Schauder's\nfixed point theorem.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.12796; text overlap with arXiv:1811.09428\n",
    "authors": [
      "Stephan Dahlke",
      "Cornelia Schneider"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13355"
  },
  {
    "id": "arXiv:2105.13387",
    "title": "Type III solar radio burst detection and classification: A deep learning  approach",
    "abstract": "Solar Radio Bursts (SRBs) are generally observed in dynamic spectra and have\nfive major spectral classes, labelled Type I to Type V depending on their shape\nand extent in frequency and time. Due to their complex characterisation, a\nchallenge in solar radio physics is the automatic detection and classification\nof such radio bursts. Classification of SRBs has become fundamental in recent\nyears due to large data rates generated by advanced radio telescopes such as\nthe LOw-Frequency ARray, (LOFAR). Current state-of-the-art algorithms implement\nthe Hough or Radon transform as a means of detecting predefined parametric\nshapes in images. These algorithms achieve up to 84% accuracy, depending on the\nType of radio burst being classified. Other techniques include procedures that\nrely on Constant-FalseAlarm-Rate detection, which is essentially detection of\nradio bursts using a de-noising and adaptive threshold in dynamic spectra. It\nworks well for a variety of different Types of radio bursts and achieves an\naccuracy of up to 70%. In this research, we are introducing a methodology named\nYou Only Look Once v2 (YOLOv2) for solar radio burst classification. By using\nType III simulation methods we can train the algorithm to classify real Type\nIII solar radio bursts in real-time at an accu",
    "descriptor": "\nComments: 6 pages, 6 figures, Irish Signals & Systems Conference 2021 (pre-print)\n",
    "authors": [
      "Jeremiah Scully",
      "Ronan Flynn",
      "Eoin Carley",
      "Peter Gallagher",
      "Mark Daly"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13387"
  },
  {
    "id": "arXiv:2105.13420",
    "title": "Model Selection for Production System via Automated Online Experiments",
    "abstract": "A challenge that machine learning practitioners in the industry face is the\ntask of selecting the best model to deploy in production. As a model is often\nan intermediate component of a production system, online controlled experiments\nsuch as A/B tests yield the most reliable estimation of the effectiveness of\nthe whole system, but can only compare two or a few models due to budget\nconstraints. We propose an automated online experimentation mechanism that can\nefficiently perform model selection from a large pool of models with a small\nnumber of online experiments. We derive the probability distribution of the\nmetric of interest that contains the model uncertainty from our Bayesian\nsurrogate model trained using historical logs. Our method efficiently\nidentifies the best model by sequentially selecting and deploying a list of\nmodels from the candidate set that balance exploration-exploitation. Using\nsimulations based on real data, we demonstrate the effectiveness of our method\non two different tasks.",
    "descriptor": "\nComments: NeurIPS 2020\n",
    "authors": [
      "Zhenwen Dai",
      "Praveen Chandar",
      "Ghazal Fazelnia",
      "Ben Carterette",
      "Mounia Lalmas-Roelleke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13420"
  },
  {
    "id": "arXiv:2105.13429",
    "title": "Flow based features and validation metric for machine learning  reconstruction of PIV data",
    "abstract": "Reconstruction of flow field from real sparse data by a physics-oriented\napproach is a current challenge for fluid scientists in the AI community. The\nproblem includes feature recognition and implementation of AI algorithms that\nlink data to a physical feature space in order to produce reconstructed data.\nThe present article applies machine learning approach to study contribution of\ndifferent flow-based features with practical fluid mechanics applications for\nreconstruction of the missing data of turbomachinery PIV measurements. Support\nvector regression (SVR) and multi-layer perceptron (MLP) are selected as two\nrobust regressors capable of modelling non-linear fluid flow phenomena. The\nproposed flow-based features are optimally scaled and filtered to extract the\nbest configuration. In addition to conventional data-based validation of the\nregressors, a metric is proposed that reflects mass conservation law as an\nimportant requirement for a physical flow reproduction. For a velocity field\nincluding 25% of clustered missing data, the reconstruction accuracy achieved\nby SVR in terms of R2-score is as high as 0.993 for the in-plane velocity\nvectors in comparison with that obtained by MLP which is up to 0.981. In terms\nof mass conservation metric, the SVR model by R2-score up to 0.96 is\nconsiderably more accurate than the MLP estimator. For extremely sparse data\nwith a gappiness of 75%, vector and contour plots from SVR and MLP were\nconsistent with those of the original field.",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Ghasem Akbari",
      "Nader Montazerin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13429"
  },
  {
    "id": "arXiv:2105.13440",
    "title": "Non-negative matrix factorization algorithms greatly improve topic model  fits",
    "abstract": "We report on the potential for using algorithms for non-negative matrix\nfactorization (NMF) to improve parameter estimation in topic models. While\nseveral papers have studied connections between NMF and topic models, none have\nsuggested leveraging these connections to develop new algorithms for fitting\ntopic models. Importantly, NMF avoids the \"sum-to-one\" constraints on the topic\nmodel parameters, resulting in an optimization problem with simpler structure\nand more efficient computations. Building on recent advances in optimization\nalgorithms for NMF, we show that first solving the NMF problem then recovering\nthe topic model fit can produce remarkably better fits, and in less time, than\nstandard algorithms for topic models. While we focus primarily on maximum\nlikelihood estimation, we show that this approach also has the potential to\nimprove variational inference for topic models. Our methods are implemented in\nthe R package fastTopics.",
    "descriptor": "\nComments: Submitted to Advances in Neural Information Processing Systems 2021\n",
    "authors": [
      "Peter Carbonetto",
      "Abhishek Sarkar",
      "Zihao Wang",
      "Matthew Stephens"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.13440"
  },
  {
    "id": "arXiv:2105.13473",
    "title": "Consistency capacity of reservoir computers",
    "abstract": "We study the propagation and distribution of information-carrying signals\ninjected in dynamical systems serving as a reservoir computers. A multivariate\ncorrelation analysis in tailored replica tests reveals consistency spectra and\ncapacities of a reservoir. These measures provide a high-dimensional portrait\nof the nonlinear functional dependence on the inputs. For multiple inputs a\nhierarchy of capacity measures characterizes the interference of signals from\neach source. For each input the time-resolved capacity forms a nonlinear fading\nmemory profile. We illustrate the methodology with various types of echo state\nnetworks.",
    "descriptor": "",
    "authors": [
      "Thomas J\u00fcngling",
      "Thomas Lymburn",
      "Michael Small"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.13473"
  },
  {
    "id": "arXiv:2105.13485",
    "title": "Avancee-1 Mission and SaDoD Method: LiDAR-based stimulated atomic  disintegration of space debris (SaDoD) using Optical Neural Networks",
    "abstract": "The surface degradation of satellites in Low Earth Orbit (LEO) is affected by\nAtomic Oxygen (AO) and varies depending on the spacecraft orbital parameters.\nAtomic oxygen initiates several chemical and physical reactions with materials\nand produces erosion and self-disintegration of the debris at high energy. This\npaper discusses Avancee-1 Mission, LiDAR-based space debris removal using\nOptical Neural Networks (ONN) to optimize debris detection and mission\naccuracy. The SaDoD Method is a Stimulated Atomic Disintegration of Orbital\nDebris, which in this case has been achieved using LiDAR technology and Optical\nNeural Networks. We propose Optical Neural Network algorithms with a high\nability of image detection and classification. The results show that orbital\ndebris has a higher chance of disintegration when the laser beam is coming from\nGeostationary Orbit (GEO) satellites and in the presence of high solar\nactivities. This paper proposes a LiDAR-based space debris removal method\ndepending on the variation of atomic oxygen erosion with orbital parameters and\nsolar energy levels. The results obtained show that orbital debris undergoes\nthe most intense degradation at low altitudes and higher temperatures. The\nsatellites in GEO use Optical Neural Network algorithms for object detection\nbefore sending the laser beams to achieve self-disintegration. The SaDoD Method\ncan be implemented with other techniques, but especially for the Avancee-1\nMission, the SaDoD was implemented with LiDAR technologies and Optical Neural\nNetwork algorithms.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Manuel Ntumba",
      "Saurabh Gore"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13485"
  },
  {
    "id": "arXiv:2105.13504",
    "title": "Lattice partition recovery with dyadic CART",
    "abstract": "We study piece-wise constant signals corrupted by additive Gaussian noise\nover a $d$-dimensional lattice. Data of this form naturally arise in a host of\napplications, and the tasks of signal detection or testing, de-noising and\nestimation have been studied extensively in the statistical and signal\nprocessing literature. In this paper we consider instead the problem of\npartition recovery, i.e.~of estimating the partition of the lattice induced by\nthe constancy regions of the unknown signal, using the\ncomputationally-efficient dyadic classification and regression tree (DCART)\nmethodology proposed by \\citep{donoho1997cart}. We prove that, under\nappropriate regularity conditions on the shape of the partition elements, a\nDCART-based procedure consistently estimates the underlying partition at a rate\nof order $\\sigma^2 k^* \\log (N)/\\kappa^2$, where $k^*$ is the minimal number of\nrectangular sub-graphs obtained using recursive dyadic partitions supporting\nthe signal partition, $\\sigma^2$ is the noise variance, $\\kappa$ is the minimal\nmagnitude of the signal difference among contiguous elements of the partition\nand $N$ is the size of the lattice. Furthermore, under stronger assumptions,\nour method attains a sharper estimation error of order\n$\\sigma^2\\log(N)/\\kappa^2$, independent of $ k^*$, which we show to be minimax\nrate optimal. Our theoretical guarantees further extend to the partition\nestimator based on the optimal regression tree estimator (ORT) of\n\\cite{chatterjee2019adaptive} and to the one obtained through an NP-hard\nexhaustive search method. We corroborate our theoretical findings and the\neffectiveness of DCART for partition recovery in simulations.",
    "descriptor": "",
    "authors": [
      "Oscar Hernan Madrid Padilla",
      "Yi Yu",
      "Alessandro Rinaldo"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13504"
  },
  {
    "id": "arXiv:2105.13508",
    "title": "Reduced Complexity Neural Network Equalizers for Two-dimensional  Magnetic Recording",
    "abstract": "Recent studies show promising performance gains achieved by non-linear\nequalization using neural networks (NNs) over traditional linear equalization\nin two-dimensional magnetic recording (TDMR) channels. But the examined neural\nnetwork architectures entail much higher implementation complexities compared\nwith the linear equalizer, which precludes practical implementation. For\nexample, among the low complexity reported architectures, the multilayer\nperceptron (MLP) requires about 6.6 times increase in complexity over the\nlinear equalizer. This paper investigates candidate reduced complexity neural\nnetwork architectures for equalization over TDMR. We test the performance on\nreadback signals measured over an actual hard disk drive with TDMR technology.\nFour variants of a reduced complexity MLP (RC-MLP) architecture are proposed. A\nproposed variant achieves the best balance between performance and complexity.\nThis architecture consists of finite-impulse response filters, a non-linear\nactivation, and a hidden delay line. The complexity of the architecture is only\n1.59 times the linear equalizer's complexity, while achieving most of the\nperformance gains of the MLP.",
    "descriptor": "",
    "authors": [
      "Ahmed Aboutaleb",
      "Nitin Nangare"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13508"
  },
  {
    "id": "arXiv:2105.13518",
    "title": "18.8 Gbps real-time quantum random number generator with a photonic  integrated chip",
    "abstract": "Quantum random number generators (QRNGs) can produce true random numbers.\nYet, the two most important QRNG parameters highly desired for practical\napplications, i.e., speed and size, have to be compromised during\nimplementations. Here, we present the fastest and miniaturized QRNG with a\nrecord real-time output rate as high as 18.8 Gbps by combining a photonic\nintegrated chip and the technology of optimized randomness extraction. We\nassemble the photonic integrated circuit designed for vacuum state QRNG\nimplementation, InGaAs homodyne detector and high-bandwidth transimpedance\namplifier into a single chip using hybrid packaging, which exhibits the\nexcellent characteristics of integration and high-frequency response. With a\nsample rate of 2.5 GSa/s in a 10-bit analog-to-digital converter and subsequent\nparalleled postprocessing in a field programmable gate array, the QRNG outputs\nultrafast random bitstreams via a fiber optic transceiver, whose real-time\nspeed is validated in a personal computer.",
    "descriptor": "\nComments: 5 pages, 4 figures. Accepted for publication in Applied Physics Letters\n",
    "authors": [
      "Bing Bai",
      "Jianyao Huang",
      "Guan-Ru Qiao",
      "You-Qi Nie",
      "Weijie Tang",
      "Tao Chu",
      "Jun Zhang",
      "Jian-Wei Pan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2105.13518"
  },
  {
    "id": "arXiv:2105.13536",
    "title": "ECG Heart-beat Classification Using Multimodal Image Fusion",
    "abstract": "In this paper, we present a novel Image Fusion Model (IFM) for ECG heart-beat\nclassification to overcome the weaknesses of existing machine learning\ntechniques that rely either on manual feature extraction or direct utilization\nof 1D raw ECG signal. At the input of IFM, we first convert the heart beats of\nECG into three different images using Gramian Angular Field (GAF), Recurrence\nPlot (RP) and Markov Transition Field (MTF) and then fuse these images to\ncreate a single imaging modality. We use AlexNet for feature extraction and\nclassification and thus employ end to end deep learning. We perform experiments\non PhysioNet MIT-BIH dataset for five different arrhythmias in accordance with\nthe AAMI EC57 standard and on PTB diagnostics dataset for myocardial infarction\n(MI) classification. We achieved an state of an art results in terms of\nprediction accuracy, precision and recall.",
    "descriptor": "",
    "authors": [
      "Zeeshan Ahmad",
      "Anika Tabassum",
      "Naimul Khan",
      "Ling Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13536"
  },
  {
    "id": "arXiv:2105.13570",
    "title": "Detecting the hosts of bacteriophages using GCN-based semi-supervised  learning",
    "abstract": "Motivation: Bacteriophages (aka phages) are viruses that infect bacteria and\narchaea. Thus, they play important regulatory roles in natural and\nhost-associated ecosystems. As the most abundant and diverse biological\nentities in the biosphere, phages have received increased attention in their\nresearch and applications. In particular, identifying their hosts provides key\nknowledge for their usages as antibiotics. High-throughput sequencing and its\napplication to the microbiome have offered new opportunities for phage host\ndetection. However, there are two main challenges for computational host\nprediction. First, the known phage-host relationships are very limited compared\nto sequenced phages. Second, although the sequence similarity between phages\nand bacteria has been used as a major feature for host prediction, the\nalignment is either missing or ambiguous for accurate host prediction. Thus,\nthere is still a need to improve the accuracy of host prediction. Results: In\nthis work, we present a semi-supervised learning model, named HostG, to conduct\nhost prediction for novel phages. We construct a knowledge graph by utilizing\nboth phage-phage protein similarity and phage-host DNA sequence similarity.\nThen graph convolutional network (GCN) is adopted to exploit phages with or\nwithout known hosts in training to enhance the learning ability. During the GCN\ntraining, we minimize the expected calibrated error (ECE) to ensure the\nconfidence of the predictions. We tested HostG on both simulated and real\nsequencing data and the results demonstrated that it competes favorably against\nthe state-of-the-art pipelines.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Jiayu Shang",
      "Yanni Sun"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13570"
  },
  {
    "id": "arXiv:2105.13615",
    "title": "A lower bound for essential covers of the cube",
    "abstract": "Essential covers were introduced by Linial and Radhakrishnan as a model that\ncaptures two complementary properties: (1) all variables must be included and\n(2) no element is redundant. In their seminal paper, they proved that every\nessential cover of the $n$-dimensional hypercube must be of size at least\n$\\Omega(n^{0.5})$. Later on, this notion found several applications in\ncomplexity theory. We improve the lower bound to $\\Omega(n^{0.52})$, and\ndescribe two applications.",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Gal Yehuda",
      "Amir Yehudayoff"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.13615"
  },
  {
    "id": "arXiv:2105.13675",
    "title": "Audio-visual scene classification: analysis of DCASE 2021 Challenge  submissions",
    "abstract": "This paper presents the details of the Audio-Visual Scene Classification task\nin the DCASE 2021 Challenge (Task 1 Subtask B). The task is concerned with\nclassification using audio and video modalities, using a dataset of\nsynchronized recordings. Here we describe the datasets and baseline systems.\nAfter the challenge submission deadline, challenge results and analysis of the\nsubmissions will be added.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Toni Heittola",
      "Annamaria Mesaros",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.13675"
  },
  {
    "id": "arXiv:2105.13678",
    "title": "An efficient hybrid hash based privacy amplification algorithm for  quantum key distribution",
    "abstract": "Privacy amplification (PA) is an essential part in a quantum key distribution\n(QKD) system, distilling a highly secure key from a partially secure string by\npublic negotiation between two parties. The optimization objectives of privacy\namplification for QKD are large block size, high throughput and low cost. For\nthe global optimization of these objectives, a novel privacy amplification\nalgorithm is proposed in this paper by combining multilinear-modular-hashing\nand modular arithmetic hashing. This paper proves the security of this hybrid\nhashing PA algorithm within the framework of both information theory and\ncomposition security theory. A scheme based on this algorithm is implemented\nand evaluated on a CPU platform. The results on a typical CV-QKD system\nindicate that the throughput of this scheme (261Mbps@2.6*10^8 input block size)\nis twice higher than the best existing scheme (140Mbps@1*10^8 input block\nsize). Moreover, This scheme is implemented on a mobile CPU platform instead of\na desktop CPU or a server CPU, which means that this algorithm has a better\nperformance with a much lower cost and power consumption.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Yan Bingze",
      "Li Qiong",
      "Mao Haokun",
      "Chen Nan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13678"
  },
  {
    "id": "arXiv:2105.13727",
    "title": "Slow Momentum with Fast Reversion: A Trading Strategy Using Deep  Learning and Changepoint Detection",
    "abstract": "Momentum strategies are an important part of alternative investments and are\nat the heart of commodity trading advisors (CTAs). These strategies have\nhowever been found to have difficulties adjusting to rapid changes in market\nconditions, such as during the 2020 market crash. In particular, immediately\nafter momentum turning points, where a trend reverses from an uptrend\n(downtrend) to a downtrend (uptrend), time-series momentum (TSMOM) strategies\nare prone to making bad bets. To improve the response to regime change, we\nintroduce a novel approach, where we insert an online change-point detection\n(CPD) module into a Deep Momentum Network (DMN) [1904.04912] pipeline, which\nuses an LSTM deep-learning architecture to simultaneously learn both trend\nestimation and position sizing. Furthermore, our model is able to optimise the\nway in which it balances 1) a slow momentum strategy which exploits persisting\ntrends, but does not overreact to localised price moves, and 2) a fast\nmean-reversion strategy regime by quickly flipping its position, then swapping\nit back again to exploit localised price moves. Our CPD module outputs a\nchangepoint location and severity score, allowing our model to learn to respond\nto varying degrees of disequilibrium, or smaller and more localised\nchangepoints, in a data driven manner. Using a portfolio of 50, liquid,\ncontinuous futures contracts over the period 1990-2020, the addition of the CPD\nmodule leads to an improvement in Sharpe ratio of $33\\%$. Even more notably,\nthis module is especially beneficial in periods of significant nonstationarity,\nand in particular, over the most recent years tested (2015-2020) the\nperformance boost is approximately $400\\%$. This is especially interesting as\ntraditional momentum strategies have been underperforming in this period.",
    "descriptor": "",
    "authors": [
      "Kieran Wood",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.13727"
  },
  {
    "id": "arXiv:2105.13738",
    "title": "Fork-join and redundancy systems with heavy-tailed job sizes",
    "abstract": "We investigate the tail asymptotics of the response time distribution for the\ncancel-on-start (c.o.s.) and cancel-on-completion (c.o.c.) variants of\nredundancy-$d$ scheduling and the fork-join model with heavy-tailed job sizes.\nWe present bounds, which only differ in the pre-factor, for the tail\nprobability of the response time in the case of the first-come first-served\n(FCFS) discipline. For the c.o.s. variant we restrict ourselves to\nredundancy-$d$ scheduling, which is a special case of the fork-join model. In\nparticular, for regularly varying job sizes with tail index $-\\nu$ the tail\nindex of the response time for the c.o.s. variant of redundancy-$d$ equals\n$-\\min\\{d_{\\mathrm{cap}}(\\nu-1),\\nu\\}$, where $d_{\\mathrm{cap}} =\n\\min\\{d,N-k\\}$, $N$ is the number of servers and $k$ is the integer part of the\nload. This result indicates that for $d_{\\mathrm{cap}} < \\frac{\\nu}{\\nu-1}$ the\nwaiting time component is dominant, whereas for $d_{\\mathrm{cap}} >\n\\frac{\\nu}{\\nu-1}$ the job size component is dominant. Thus, having $d = \\lceil\n\\min\\{\\frac{\\nu}{\\nu-1},N-k\\} \\rceil$ replicas is sufficient to achieve the\noptimal asymptotic tail behavior of the response time. For the c.o.c. variant\nof the fork-join($n_{\\mathrm{F}},n_{\\mathrm{J}}$) model the tail index of the\nresponse time, under some assumptions on the load, equals $1-\\nu$ and\n$1-(n_{\\mathrm{F}}+1-n_{\\mathrm{J}})\\nu$, for identical and i.i.d. replicas,\nrespectively; here the waiting time component is always dominant.",
    "descriptor": "",
    "authors": [
      "Youri Raaijmakers",
      "Sem Borst",
      "Onno Boxma"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.13738"
  },
  {
    "id": "arXiv:2105.13743",
    "title": "Control Architecture of the Double-Cross-Correlation Processor for  Sampling-Rate-Offset Estimation in Acoustic Sensor Networks",
    "abstract": "Distributed hardware of acoustic sensor networks bears inconsistency of local\nsampling frequencies, which is detrimental to signal processing. Fundamentally,\nsampling rate offset (SRO) nonlinearly relates the discrete-time signals\nacquired by different sensor nodes. As such, retrieval of SRO from the\navailable signals requires nonlinear estimation, like double-cross-correlation\nprocessing (DXCP), and frequently results in biased estimation. SRO\ncompensation by asynchronous sampling rate conversion (ASRC) on the signals\nthen leaves an unacceptable residual. As a remedy to this problem, multi-stage\nprocedures have been devised to diminish the SRO residual with multiple\niterations of SRO estimation and ASRC over the entire signal. This paper\nconverts the mechanism of offline multi-stage processing into a continuous\nfeedback-control loop comprising a controlled ASRC unit followed by an online\nimplementation of DXCP-based SRO estimation. To support the design of an\noptimum internal model control unit for this closed-loop system, the paper\ndeploys an analytical dynamical model of the proposed online DXCP. The\nresulting control architecture then merely applies a single treatment of each\nsignal frame, while efficiently diminishing SRO bias with time. Evaluations\nwith both speech and Gaussian input demonstrate that the high accuracy of\nmulti-stage processing is maintained at the low complexity of single-stage\n(open-loop) processing.",
    "descriptor": "",
    "authors": [
      "Aleksej Chinaev",
      "Sven Wienand",
      "Gerald Enzner"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13743"
  },
  {
    "id": "arXiv:2105.13746",
    "title": "SafeAMC: Adversarial training for robust modulation recognition models",
    "abstract": "In communication systems, there are many tasks, like modulation recognition,\nwhich rely on Deep Neural Networks (DNNs) models. However, these models have\nbeen shown to be susceptible to adversarial perturbations, namely imperceptible\nadditive noise crafted to induce misclassification. This raises questions about\nthe security but also the general trust in model predictions. We propose to use\nadversarial training, which consists of fine-tuning the model with adversarial\nperturbations, to increase the robustness of automatic modulation recognition\n(AMC) models. We show that current state-of-the-art models benefit from\nadversarial training, which mitigates the robustness issues for some families\nof modulations. We use adversarial perturbations to visualize the features\nlearned, and we found that in robust models the signal symbols are shifted\ntowards the nearest classes in constellation space, like maximum likelihood\nmethods. This confirms that robust models not only are more secure, but also\nmore interpretable, building their decisions on signal statistics that are\nrelevant to modulation recognition.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.14977\n",
    "authors": [
      "Javier Maroto",
      "G\u00e9r\u00f4me Bovet",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13746"
  },
  {
    "id": "arXiv:2105.13793",
    "title": "A systematic review of transfer learning based approaches for diabetic  retinopathy detection",
    "abstract": "Cases of diabetes and related diabetic retinopathy (DR) have been increasing\nat an alarming rate in modern times. Early detection of DR is an important\nproblem since it may cause permanent blindness in the late stages. In the last\ntwo decades, many different approaches have been applied in DR detection.\nReviewing academic literature shows that deep neural networks (DNNs) have\nbecome the most preferred approach for DR detection. Among these DNN\napproaches, Convolutional Neural Network (CNN) models are the most used ones in\nthe field of medical image classification. Designing a new CNN architecture is\na tedious and time-consuming approach. Additionally, training an enormous\nnumber of parameters is also a difficult task. Due to this reason, instead of\ntraining CNNs from scratch, using pre-trained models has been suggested in\nrecent years as transfer learning approach. Accordingly, the present study as a\nreview focuses on DNN and Transfer Learning based applications of DR detection\nconsidering 38 publications between 2015 and 2020. The published papers are\nsummarized using 9 figures and 10 tables, giving information about 22\npre-trained CNN models, 12 DR data sets and standard performance metrics.",
    "descriptor": "\nComments: 25 pages 9 figures 10 tables\n",
    "authors": [
      "Burcu Oltu",
      "B\u00fc\u015fra K\u00fcbra Karaca",
      "Hamit Erdem",
      "Atilla \u00d6zg\u00fcr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13793"
  },
  {
    "id": "arXiv:2105.13831",
    "title": "Implicit Regularization in Matrix Sensing via Mirror Descent",
    "abstract": "We study discrete-time mirror descent applied to the unregularized empirical\nrisk in matrix sensing. In both the general case of rectangular matrices and\nthe particular case of positive semidefinite matrices, a simple potential-based\nanalysis in terms of the Bregman divergence allows us to establish convergence\nof mirror descent -- with different choices of the mirror maps -- to a matrix\nthat, among all global minimizers of the empirical risk, minimizes a quantity\nexplicitly related to the nuclear norm, the Frobenius norm, and the von Neumann\nentropy. In both cases, this characterization implies that mirror descent, a\nfirst-order algorithm minimizing the unregularized empirical risk, recovers\nlow-rank matrices under the same set of assumptions that are sufficient to\nguarantee recovery for nuclear-norm minimization. When the sensing matrices are\nsymmetric and commute, we show that gradient descent with full-rank factorized\nparametrization is a first-order approximation to mirror descent, in which case\nwe obtain an explicit characterization of the implicit bias of gradient flow as\na by-product.",
    "descriptor": "",
    "authors": [
      "Fan Wu",
      "Patrick Rebeschini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13831"
  },
  {
    "id": "arXiv:2105.13850",
    "title": "pRSL: Interpretable Multi-label Stacking by Learning Probabilistic Rules",
    "abstract": "A key task in multi-label classification is modeling the structure between\nthe involved classes. Modeling this structure by probabilistic and\ninterpretable means enables application in a broad variety of tasks such as\nzero-shot learning or learning from incomplete data. In this paper, we present\nthe probabilistic rule stacking learner (pRSL) which uses probabilistic\npropositional logic rules and belief propagation to combine the predictions of\nseveral underlying classifiers. We derive algorithms for exact and approximate\ninference and learning, and show that pRSL reaches state-of-the-art performance\non various benchmark datasets.\nIn the process, we introduce a novel multicategorical generalization of the\nnoisy-or gate. Additionally, we report simulation results on the quality of\nloopy belief propagation algorithms for approximate inference in bipartite\nnoisy-or networks.",
    "descriptor": "",
    "authors": [
      "Kirchhof Michael",
      "Schmid Lena",
      "Reining Christopher",
      "ten Hompel Michael",
      "Pauly Markus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.13850"
  },
  {
    "id": "arXiv:2105.13863",
    "title": "On plain algebraic curves passing through $n$-independent nodes",
    "abstract": "Let a set of nodes $\\mathcal X$ in the plain be $n$-independent, i.e., each\nnode has a fundamental polynomial of degree $n.$ Assume that $\\#\\mathcal\nX=d(n,k)+3= (n+1)+n+\\cdots+(n-k+5)+3$ and $4 \\le k\\le n-1.$ In this paper we\nprove that there are at most seven linearly independent curves of degree less\nthan or equal to $k$ that pass through all the nodes of $\\mathcal X.$ We\nprovide a characterization of the case when there are exactly seven such\ncurves. Namely, we prove that then the set $\\mathcal X$ has a very special\nconstruction: all its nodes but three belong to a (maximal) curve of degree\n$k-3.$ Let us mention that in a series of such results this is the third one.\nIn the end, an important application to the bivariate polynomial interpolation\nis provided, which is essential also for the study of the Gasca-Maeztu\nconjecture.",
    "descriptor": "\nComments: 24 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874\n",
    "authors": [
      "Hakop Hakopian",
      "Harutyun Kloyan",
      "Davit Voskanyan"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13863"
  },
  {
    "id": "arXiv:2105.13871",
    "title": "DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion",
    "abstract": "Singing voice conversion (SVC) is one promising technique which can enrich\nthe way of human-computer interaction by endowing a computer the ability to\nproduce high-fidelity and expressive singing voice. In this paper, we propose\nDiffSVC, an SVC system based on denoising diffusion probabilistic model.\nDiffSVC uses phonetic posteriorgrams (PPGs) as content features. A denoising\nmodule is trained in DiffSVC, which takes destroyed mel spectrogram produced by\nthe diffusion/forward process and its corresponding step information as input\nto predict the added Gaussian noise. We use PPGs, fundamental frequency\nfeatures and loudness features as auxiliary input to assist the denoising\nprocess. Experiments show that DiffSVC can achieve superior conversion\nperformance in terms of naturalness and voice similarity to current\nstate-of-the-art SVC approaches.",
    "descriptor": "\nComments: Preprint. 8 pages, 2 figures and 1 table\n",
    "authors": [
      "Songxiang Liu",
      "Yuewen Cao",
      "Dan Su",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.13871"
  },
  {
    "id": "arXiv:2105.13898",
    "title": "Volatility Modeling of Stocks from Selected Sectors of the Indian  Economy Using GARCH",
    "abstract": "Volatility clustering is an important characteristic that has a significant\neffect on the behavior of stock markets. However, designing robust models for\naccurate prediction of future volatilities of stock prices is a very\nchallenging research problem. We present several volatility models based on\ngeneralized autoregressive conditional heteroscedasticity (GARCH) framework for\nmodeling the volatility of ten stocks listed in the national stock exchange\n(NSE) of India. The stocks are selected from the auto sector and the banking\nsector of the Indian economy, and they have a significant impact on the\nsectoral index of their respective sectors in the NSE. The historical stock\nprice records from Jan 1, 2010, to Apr 30, 2021, are scraped from the Yahoo\nFinance website using the DataReader API of the Pandas module in the Python\nprogramming language. The GARCH modules are built and fine-tuned on the\ntraining data and then tested on the out-of-sample data to evaluate the\nperformance of the models. The analysis of the results shows that asymmetric\nGARCH models yield more accurate forecasts on the future volatility of stocks.",
    "descriptor": "\nComments: This paper is the accepted version of our paper in the IEEE Asian Conference on Innovation Technology (IEEE ASIANCON'2021) which will be organized in Pune, INDIA during August 28 - 29, 2021. The paper consists of 8 pages and it contains 13 figures and 22 tables\n",
    "authors": [
      "Jaydip Sen",
      "Sidra Mehtab",
      "Abhishek Dutta"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.13898"
  },
  {
    "id": "arXiv:2105.13913",
    "title": "Simple steps are all you need: Frank-Wolfe and generalized  self-concordant functions",
    "abstract": "Generalized self-concordance is a key property present in the objective\nfunction of many important learning problems. We establish the convergence rate\nof a simple Frank-Wolfe variant that uses the open-loop step size strategy\n$\\gamma_t = 2/(t+2)$, obtaining a $\\mathcal{O}(1/t)$ convergence rate for this\nclass of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the\niteration count. This avoids the use of second-order information or the need to\nestimate local smoothness parameters of previous work. We also show improved\nconvergence rates for various common cases, e.g., when the feasible region\nunder consideration is uniformly convex or polyhedral.",
    "descriptor": "",
    "authors": [
      "Alejandro Carderera",
      "Mathieu Besan\u00e7on",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13913"
  },
  {
    "id": "arXiv:2105.13922",
    "title": "Discretization Drift in Two-Player Games",
    "abstract": "Gradient-based methods for two-player games produce rich dynamics that can\nsolve challenging problems, yet can be difficult to stabilize and understand.\nPart of this complexity originates from the discrete update steps given by\nsimultaneous or alternating gradient descent, which causes each player to drift\naway from the continuous gradient flow -- a phenomenon we call discretization\ndrift. Using backward error analysis, we derive modified continuous dynamical\nsystems that closely follow the discrete dynamics. These modified dynamics\nprovide an insight into the notorious challenges associated with zero-sum\ngames, including Generative Adversarial Networks. In particular, we identify\ndistinct components of the discretization drift that can alter performance and\nin some cases destabilize the game. Finally, quantifying discretization drift\nallows us to identify regularizers that explicitly cancel harmful forms of\ndrift or strengthen beneficial forms of drift, and thus improve performance of\nGAN training.",
    "descriptor": "",
    "authors": [
      "Mihaela Rosca",
      "Yan Wu",
      "Benoit Dherin",
      "David G. T. Barrett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13922"
  },
  {
    "id": "arXiv:2105.13928",
    "title": "DMInet: An Accurate and Highly Flexible Deep Learning Framework for Drug  Discovery with Membrane Selectivity",
    "abstract": "Drug membrane interaction is a very significant bioprocess to consider in\ndrug discovery. Here, we propose a novel deep learning framework coined DMInet\nto study drug-membrane interactions that leverages large-scale Martini\ncoarse-grained molecular simulations of permeation of drug-like molecules\nacross six different lipid membranes. The network of DMInet receives three\ninputs, viz, the drug-like molecule, membrane type and spatial distance across\nmembrane thickness, and predicts the potential of mean force with structural\nresolution across the lipid membrane and membrane selectivity. Inheriting from\ncoarse-grained Martini representation of organic molecules and combined with\ndeep learning, DMInet has the potential for more accelerated high throughput\nscreening in drug discovery across a much larger chemical space than that can\nbe explored by physics-based simulations alone. Moreover, DMInet is highly\nflexible in its nature and holds the possibilities for other properties\nprediction without significant change of the architecture. Last but not least,\nthe architecture of DMInet is general and can be applied to other membrane\nproblems involving permeation and selection.",
    "descriptor": "",
    "authors": [
      "Guang Chen"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13928"
  },
  {
    "id": "arXiv:2105.13945",
    "title": "Quantum Optimisation of Complex Systems with a Quantum Annealer",
    "abstract": "We perform an in-depth comparison of quantum annealing with several classical\noptimisation techniques, namely thermal annealing, Nelder-Mead, and gradient\ndescent. We begin with a direct study of the 2D Ising model on a quantum\nannealer, and compare its properties directly with those of the thermal 2D\nIsing model. These properties include an Ising-like phase transition that can\nbe induced by either a change in 'quantum-ness' of the theory, or by a scaling\nthe Ising couplings up or down. This behaviour is in accord with what is\nexpected from the physical understanding of the quantum system. We then go on\nto demonstrate the efficacy of the quantum annealer at minimising several\nincreasingly hard two dimensional potentials. For all the potentials we find\nthe general behaviour that Nelder-Mead and gradient descent methods are very\nsusceptible to becoming trapped in false minima, while the thermal anneal\nmethod is somewhat better at discovering the true minimum. However, and despite\ncurrent limitations on its size, the quantum annealer performs a minimisation\nvery markedly better than any of these classical techniques. A quantum anneal\ncan be designed so that the system almost never gets trapped in a false\nminimum, and rapidly and successfully minimises the potentials.",
    "descriptor": "\nComments: 24 pages, 19 figures\n",
    "authors": [
      "Steve Abel",
      "Andrew Blance",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13945"
  },
  {
    "id": "arXiv:2105.13954",
    "title": "A Gradient Method for Multilevel Optimization",
    "abstract": "Although application examples of multilevel optimization have already been\ndiscussed since the '90s, the development of solution methods was almost\nlimited to bilevel cases due to the difficulty of the problem. In recent years,\nin machine learning, Franceschi et al. have proposed a method for solving\nbilevel optimization problems by replacing their lower-level problems with the\n$T$ steepest descent update equations with some prechosen iteration number $T$.\nIn this paper, we have developed a gradient-based algorithm for multilevel\noptimization with $n$ levels based on their idea and proved that our\nreformulation with $n T$ variables asymptotically converges to the original\nmultilevel problem. As far as we know, this is one of the first algorithms with\nsome theoretical guarantee for multilevel optimization. Numerical experiments\nshow that a trilevel hyperparameter learning model considering data poisoning\nproduces more stable prediction results than an existing bilevel hyperparameter\nlearning model in noisy data settings.",
    "descriptor": "",
    "authors": [
      "Ryo Sato",
      "Mirai Tanaka",
      "Akiko Takeda"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13954"
  },
  {
    "id": "arXiv:2105.13987",
    "title": "ScalingNet: extracting features from raw EEG data for emotion  recognition",
    "abstract": "Convolutional Neural Networks(CNNs) has achieved remarkable performance\nbreakthrough in a variety of tasks. Recently, CNNs based methods that are fed\nwith hand-extracted EEG features gradually produce a powerful performance on\nthe EEG data based emotion recognition task. In this paper, we propose a novel\nconvolutional layer allowing to adaptively extract effective data-driven\nspectrogram-like features from raw EEG signals, which we reference as scaling\nlayer. Further, it leverages convolutional kernels scaled from one data-driven\npattern to exposed a frequency-like dimension to address the shortcomings of\nprior methods requiring hand-extracted features or their approximations. The\nproposed neural network architecture based on the scaling layer, references as\nScalingNet, has achieved the state-of-the-art result across the established\nDEAP benchmark dataset.",
    "descriptor": "",
    "authors": [
      "Jingzhao Hu",
      "Chen Wang",
      "Qiaomei Jia",
      "Qirong Bu",
      "Jun Feng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13987"
  },
  {
    "id": "arXiv:2105.13993",
    "title": "PTNet: A High-Resolution Infant MRI Synthesizer Based on Transformer",
    "abstract": "Magnetic resonance imaging (MRI) noninvasively provides critical information\nabout how human brain structures develop across stages of life. Developmental\nscientists are particularly interested in the first few years of\nneurodevelopment. Despite the success of MRI collection and analysis for\nadults, it is a challenge for researchers to collect high-quality multimodal\nMRIs from developing infants mainly because of their irregular sleep pattern,\nlimited attention, inability to follow instructions to stay still, and a lack\nof analysis approaches. These challenges often lead to a significant reduction\nof usable data. To address this issue, researchers have explored various\nsolutions to replace corrupted scans through synthesizing realistic MRIs. Among\nthem, the convolution neural network (CNN) based generative adversarial network\nhas demonstrated promising results and achieves state-of-the-art performance.\nHowever, adversarial training is unstable and may need careful tuning of\nregularization terms to stabilize the training. In this study, we introduced a\nnovel MRI synthesis framework - Pyramid Transformer Net (PTNet). PTNet consists\nof transformer layers, skip-connections, and multi-scale pyramid\nrepresentation. Compared with the most widely used CNN-based conditional GAN\nmodels (namely pix2pix and pix2pixHD), our model PTNet shows superior\nperformance in terms of synthesis accuracy and model size. Notably, PTNet does\nnot require any type of adversarial training and can be easily trained using\nthe simple mean squared error loss.",
    "descriptor": "\nComments: arXiv Preprint\n",
    "authors": [
      "Xuzhe Zhang",
      "Xinzi He",
      "Jia Guo",
      "Nabil Ettehadi",
      "Natalie Aw",
      "David Semanek",
      "Jonathan Posner",
      "Andrew Laine",
      "Yun Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13993"
  },
  {
    "id": "arXiv:2105.13997",
    "title": "On Hamilton-Jacobi PDEs and image denoising models with certain  non-additive noise",
    "abstract": "We consider image denoising problems formulated as variational problems. It\nis known that Hamilton-Jacobi PDEs govern the solution of such optimization\nproblems when the noise model is additive. In this work, we address certain\nnon-additive noise models and show that they are also related to\nHamilton-Jacobi PDEs. These findings allow us to establish new connections\nbetween additive and non-additive noise imaging models. With these connections,\nsome non-convex models for non-additive noise can be solved by applying convex\noptimization algorithms to the equivalent convex models for additive noise.\nSeveral numerical results are provided for denoising problems with Poisson\nnoise or multiplicative noise.",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00f4me Darbon",
      "Tingwei Meng",
      "Elena Resmerita"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13997"
  },
  {
    "id": "arXiv:1504.00233",
    "title": "Quantum Information Processing with Finite Resources -- Mathematical  Foundations",
    "abstract": "Comments: 135 pages, partly based on arXiv:1203.2142; v3: published version; v4: typos removed, previous Lemma 3.3 removed; v5: typos removed, new proof for stronger triangle inequality of purified distance",
    "descriptor": "\nComments: 135 pages, partly based on arXiv:1203.2142; v3: published version; v4: typos removed, previous Lemma 3.3 removed; v5: typos removed, new proof for stronger triangle inequality of purified distance\n",
    "authors": [
      "Marco Tomamichel"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/1504.00233"
  },
  {
    "id": "arXiv:1709.09899",
    "title": "A method to segment maps from different modalities using free space  layout -- MAORIS : MAp Of RIpples Segmentation",
    "abstract": "Comments: 7 pages, 11 figures",
    "descriptor": "\nComments: 7 pages, 11 figures\n",
    "authors": [
      "Malcolm Mielle",
      "Martin Magnusson",
      "Achim J. Lilienthal"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1709.09899"
  },
  {
    "id": "arXiv:1805.03727",
    "title": "ARES: Adaptive, Reconfigurable, Erasure coded, atomic Storage",
    "abstract": "ARES: Adaptive, Reconfigurable, Erasure coded, atomic Storage",
    "descriptor": "",
    "authors": [
      "Nicolas Nicolaou",
      "Viveck Cadambe",
      "N. Prakash",
      "Andria Trigeorgi",
      "Kishori M. Konwar",
      "Nancy Lynch",
      "Muriel Medard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1805.03727"
  },
  {
    "id": "arXiv:1807.07177",
    "title": "A $\u03c6$-Competitive Algorithm for Scheduling Packets with Deadlines",
    "abstract": "Comments: Another major revision of the paper, with focus on presentation. Also included hard examples for some simpler variants of the algorithm",
    "descriptor": "\nComments: Another major revision of the paper, with focus on presentation. Also included hard examples for some simpler variants of the algorithm\n",
    "authors": [
      "Pavel Vesel\u00fd",
      "Marek Chrobak",
      "\u0141ukasz Je\u017c",
      "Ji\u0159\u00ed Sgall"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1807.07177"
  },
  {
    "id": "arXiv:1810.13431",
    "title": "Targeted stochastic gradient Markov chain Monte Carlo for hidden Markov  models with rare latent states",
    "abstract": "Targeted stochastic gradient Markov chain Monte Carlo for hidden Markov  models with rare latent states",
    "descriptor": "",
    "authors": [
      "Rihui Ou",
      "Deborshee Sen",
      "Alexander L Young",
      "David B Dunson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1810.13431"
  },
  {
    "id": "arXiv:1811.06273",
    "title": "On Infinite Prefix Normal Words",
    "abstract": "Comments: 22 pages, 5 figures, 1 Table, accepted in Theoret. Comp. Sc.. This is the journal version of the paper with the same title at accepted at SOFSEM 2019 (45th International Conference on Current Trends in Theory and Practice of Computer Science, Nov\\'y Smokovec, Slovakia, January 27-30, 2019)",
    "descriptor": "\nComments: 22 pages, 5 figures, 1 Table, accepted in Theoret. Comp. Sc.. This is the journal version of the paper with the same title at accepted at SOFSEM 2019 (45th International Conference on Current Trends in Theory and Practice of Computer Science, Nov\\'y Smokovec, Slovakia, January 27-30, 2019)\n",
    "authors": [
      "Ferdinando Cicalese",
      "Zsuzsanna Lipt\u00e1k",
      "Massimiliano Rossi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1811.06273"
  },
  {
    "id": "arXiv:1811.11629",
    "title": "Class of scalable parallel and vectorizable pseudorandom number  generators based on non-cryptographic RSA exponentiation ciphers",
    "abstract": "Comments: 10 pages, 1 figure. arXiv admin note: text overlap with arXiv:1411.2484",
    "descriptor": "\nComments: 10 pages, 1 figure. arXiv admin note: text overlap with arXiv:1411.2484\n",
    "authors": [
      "Jetanat Datephanyawat",
      "Paul D. Beale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1811.11629"
  },
  {
    "id": "arXiv:1901.08974",
    "title": "On the cross-validation bias due to unsupervised pre-processing",
    "abstract": "Comments: 31 pages, 6 figures, 1 table. New sections: (4.2.) Experiments on a real dataset; (6.) Potential impact on model selection; (7.1.) Upper bounds based on stability arguments. Updated Fig. 1. with larger sample sizes",
    "descriptor": "\nComments: 31 pages, 6 figures, 1 table. New sections: (4.2.) Experiments on a real dataset; (6.) Potential impact on model selection; (7.1.) Upper bounds based on stability arguments. Updated Fig. 1. with larger sample sizes\n",
    "authors": [
      "Amit Moscovich",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.08974"
  },
  {
    "id": "arXiv:1903.12394",
    "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating  Knowledge into Learning Systems",
    "abstract": "Comments: Accepted at IEEE Transactions on Knowledge and Data Engineering: this https URL",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Knowledge and Data Engineering: this https URL\n",
    "authors": [
      "Laura von Rueden",
      "Sebastian Mayer",
      "Katharina Beckh",
      "Bogdan Georgiev",
      "Sven Giesselbach",
      "Raoul Heese",
      "Birgit Kirsch",
      "Julius Pfrommer",
      "Annika Pick",
      "Rajkumar Ramamurthy",
      "Michal Walczak",
      "Jochen Garcke",
      "Christian Bauckhage",
      "Jannis Schuecker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.12394"
  },
  {
    "id": "arXiv:1904.12834",
    "title": "Incorporating prior financial domain knowledge into neural networks for  implied volatility surface prediction",
    "abstract": "Comments: 8 pages, SIGKDD 2021",
    "descriptor": "\nComments: 8 pages, SIGKDD 2021\n",
    "authors": [
      "Yu Zheng",
      "Yongxin Yang",
      "Bowei Chen"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1904.12834"
  },
  {
    "id": "arXiv:1905.11377",
    "title": "FlightGoggles: A Modular Framework for Photorealistic Camera,  Exteroceptive Sensor, and Dynamics Simulation",
    "abstract": "Comments: Initial version appeared at IROS 2019. Supplementary material can be found at this https URL Revision includes description of new FlightGoggles features, such as a photogrammetric model of the MIT Stata Center, new rendering settings, and a Python API",
    "descriptor": "\nComments: Initial version appeared at IROS 2019. Supplementary material can be found at this https URL Revision includes description of new FlightGoggles features, such as a photogrammetric model of the MIT Stata Center, new rendering settings, and a Python API\n",
    "authors": [
      "Winter Guerra",
      "Ezra Tal",
      "Varun Murali",
      "Gilhyun Ryou",
      "Sertac Karaman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1905.11377"
  },
  {
    "id": "arXiv:1906.04608",
    "title": "A Unifying Framework for Information Processing in Stochastically Driven  Dynamical Systems",
    "abstract": "Comments: 23 pages, 9 figures",
    "descriptor": "\nComments: 23 pages, 9 figures\n",
    "authors": [
      "Tomoyuki Kubota",
      "Hirokazu Takahashi",
      "Kohei Nakajima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.04608"
  },
  {
    "id": "arXiv:1907.12075",
    "title": "Data-driven computation of invariant sets of discrete time-invariant  black-box systems",
    "abstract": "Comments: A shorter version with the title \"Scenario-based set invariance verification for black-box nonlinear systems\" is published in the IEEE Control Systems Letters (L-CSS)",
    "descriptor": "\nComments: A shorter version with the title \"Scenario-based set invariance verification for black-box nonlinear systems\" is published in the IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Zheming Wang",
      "Rapha\u00ebl M. Jungers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/1907.12075"
  },
  {
    "id": "arXiv:1909.03889",
    "title": "Recovery of Future Data via Convolution Nuclear Norm Minimization",
    "abstract": "Recovery of Future Data via Convolution Nuclear Norm Minimization",
    "descriptor": "",
    "authors": [
      "Guangcan Liu",
      "Wayne Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.03889"
  },
  {
    "id": "arXiv:1909.10519",
    "title": "Quantum Inflation: A General Approach to Quantum Causal Compatibility",
    "abstract": "Comments: V3 updated to match published version",
    "descriptor": "\nComments: V3 updated to match published version\n",
    "authors": [
      "Elie Wolfe",
      "Alejandro Pozas-Kerstjens",
      "Matan Grinberg",
      "Denis Rosset",
      "Antonio Ac\u00edn",
      "Miguel Navascues"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1909.10519"
  },
  {
    "id": "arXiv:1910.00370",
    "title": "Sub-Architecture Ensemble Pruning in Neural Architecture Search",
    "abstract": "Comments: Accepted by TNNLS. This work was done when the first author was a visiting research scholar at Texas A&M University",
    "descriptor": "\nComments: Accepted by TNNLS. This work was done when the first author was a visiting research scholar at Texas A&M University\n",
    "authors": [
      "Yijun Bian",
      "Qingquan Song",
      "Mengnan Du",
      "Jun Yao",
      "Huanhuan Chen",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.00370"
  },
  {
    "id": "arXiv:1911.10139",
    "title": "HILUCSI: Simple, Robust, and Fast Multilevel ILU for Large-Scale  Saddle-Point Problems from PDEs",
    "abstract": "Comments: Submitted to Numerical Linear Algebra with Applications (NLAA)",
    "descriptor": "\nComments: Submitted to Numerical Linear Algebra with Applications (NLAA)\n",
    "authors": [
      "Qiao Chen",
      "Aditi Ghai",
      "Xiangmin Jiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/1911.10139"
  },
  {
    "id": "arXiv:1912.13200",
    "title": "AdderNet: Do We Really Need Multiplications in Deep Learning?",
    "abstract": "AdderNet: Do We Really Need Multiplications in Deep Learning?",
    "descriptor": "",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Chunjing Xu",
      "Boxin Shi",
      "Chao Xu",
      "Qi Tian",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.13200"
  },
  {
    "id": "arXiv:2001.03108",
    "title": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian  Noises: Explicit Bounds and Feedback Coding Design",
    "abstract": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian  Noises: Explicit Bounds and Feedback Coding Design",
    "descriptor": "",
    "authors": [
      "Song Fang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2001.03108"
  },
  {
    "id": "arXiv:2001.05137",
    "title": "Driver Safety Development Real Time Driver Drowsiness Detection System  Based on Convolutional Neural Network",
    "abstract": "Comments: Hashemi, M., Mirrashid, A. & Beheshti Shirazi, A. Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network. SN COMPUT. SCI. 1, 289 (2020). this https URL",
    "descriptor": "\nComments: Hashemi, M., Mirrashid, A. & Beheshti Shirazi, A. Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network. SN COMPUT. SCI. 1, 289 (2020). this https URL\n",
    "authors": [
      "Maryam Hashemi",
      "Alireza Mirrashid",
      "Aliasghar Beheshti Shirazi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.05137"
  },
  {
    "id": "arXiv:2001.11103",
    "title": "Simulation of electron-proton scattering events by a Feature-Augmented  and Transformed Generative Adversarial Network (FAT-GAN)",
    "abstract": "Comments: 7 pages, 5 figures, expanded author list, paper accepted in IJCAI21",
    "descriptor": "\nComments: 7 pages, 5 figures, expanded author list, paper accepted in IJCAI21\n",
    "authors": [
      "Yasir Alanazi",
      "N. Sato",
      "Tianbo Liu",
      "W. Melnitchouk",
      "Pawel Ambrozewicz",
      "Florian Hauenstein",
      "Michelle P. Kuchera",
      "Evan Pritchard",
      "Michael Robertson",
      "Ryan Strauss",
      "Luisa Velasco",
      "Yaohang Li"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.11103"
  },
  {
    "id": "arXiv:2002.00253",
    "title": "Bandits with Knapsacks beyond the Worst-Case",
    "abstract": "Comments: The initial version, titled \"Advances in Bandits with Knapsacks\", was published on arxiv.org in Jan'20. The present version improves both upper and lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it simplifies the algorithm and analysis in the main result, and fixes several issues in the lower bounds",
    "descriptor": "\nComments: The initial version, titled \"Advances in Bandits with Knapsacks\", was published on arxiv.org in Jan'20. The present version improves both upper and lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it simplifies the algorithm and analysis in the main result, and fixes several issues in the lower bounds\n",
    "authors": [
      "Karthik Abinav Sankararaman",
      "Aleksandrs Slivkins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00253"
  },
  {
    "id": "arXiv:2002.05138",
    "title": "Regret Bounds for Discounted MDPs",
    "abstract": "Regret Bounds for Discounted MDPs",
    "descriptor": "",
    "authors": [
      "Shuang Liu",
      "Hao Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.05138"
  },
  {
    "id": "arXiv:2002.06757",
    "title": "Relational Message Passing for Knowledge Graph Completion",
    "abstract": "Relational Message Passing for Knowledge Graph Completion",
    "descriptor": "",
    "authors": [
      "Hongwei Wang",
      "Hongyu Ren",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.06757"
  },
  {
    "id": "arXiv:2002.07555",
    "title": "Convergence analysis of multi-level spectral deferred corrections",
    "abstract": "Comments: 42 pages, 4 figures",
    "descriptor": "\nComments: 42 pages, 4 figures\n",
    "authors": [
      "Gitte Kremling",
      "Robert Speck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.07555"
  },
  {
    "id": "arXiv:2002.07671",
    "title": "Can visualization alleviate dichotomous thinking? Effects of visual  representations on the cliff effect",
    "abstract": "Can visualization alleviate dichotomous thinking? Effects of visual  representations on the cliff effect",
    "descriptor": "",
    "authors": [
      "Jouni Helske",
      "Satu Helske",
      "Matthew Cooper",
      "Anders Ynnerman",
      "Lonni Besan\u00e7on"
    ],
    "subjectives": [
      "Other Statistics (stat.OT)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2002.07671"
  },
  {
    "id": "arXiv:2002.08087",
    "title": "LAMBERT: Layout-Aware (Language) Modeling for information extraction",
    "abstract": "Comments: accepted to ICDAR 2021",
    "descriptor": "\nComments: accepted to ICDAR 2021\n",
    "authors": [
      "\u0141ukasz Garncarek",
      "Rafa\u0142 Powalski",
      "Tomasz Stanis\u0142awek",
      "Bartosz Topolski",
      "Piotr Halama",
      "Micha\u0142 Turski",
      "Filip Grali\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2002.08087"
  },
  {
    "id": "arXiv:2003.04604",
    "title": "Hilbert's Tenth Problem in Coq (Extended Version)",
    "abstract": "Comments: submitted to LMCS",
    "descriptor": "\nComments: submitted to LMCS\n",
    "authors": [
      "Dominique Larchey-Wendling",
      "Yannick Forster"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2003.04604"
  },
  {
    "id": "arXiv:2004.00869",
    "title": "An Upgrading Algorithm with Optimal Power Law",
    "abstract": "An Upgrading Algorithm with Optimal Power Law",
    "descriptor": "",
    "authors": [
      "Or Ordentlich",
      "Ido Tal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.00869"
  },
  {
    "id": "arXiv:2004.01668",
    "title": "Relative Error Streaming Quantiles",
    "abstract": "Comments: Full version of the paper to appear in PODS 2021. 46 pages, 2 figures",
    "descriptor": "\nComments: Full version of the paper to appear in PODS 2021. 46 pages, 2 figures\n",
    "authors": [
      "Graham Cormode",
      "Zohar Karnin",
      "Edo Liberty",
      "Justin Thaler",
      "Pavel Vesel\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.01668"
  },
  {
    "id": "arXiv:2004.02491",
    "title": "A quasi-Monte Carlo data compression algorithm for machine learning",
    "abstract": "A quasi-Monte Carlo data compression algorithm for machine learning",
    "descriptor": "",
    "authors": [
      "Josef Dick",
      "Michael Feischl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.02491"
  },
  {
    "id": "arXiv:2004.04858",
    "title": "Pattern Discovery in Colored Strings",
    "abstract": "Comments: 22 pages, 5 figures, 2 tables, published in ACM Journal of Experimental Algorithmics. This is the journal version of the paper with the same title at SEA 2020 (18th Symposium on Experimental Algorithms, Catania, Italy, June 16-18, 2020)",
    "descriptor": "\nComments: 22 pages, 5 figures, 2 tables, published in ACM Journal of Experimental Algorithmics. This is the journal version of the paper with the same title at SEA 2020 (18th Symposium on Experimental Algorithms, Catania, Italy, June 16-18, 2020)\n",
    "authors": [
      "Zsuzsanna Lipt\u00e1k",
      "Simon J. Puglisi",
      "Massimiliano Rossi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.04858"
  },
  {
    "id": "arXiv:2004.07411",
    "title": "Leaderless Consensus of a Hierarchical Cyber-Physical System",
    "abstract": "Leaderless Consensus of a Hierarchical Cyber-Physical System",
    "descriptor": "",
    "authors": [
      "Xiao Chen",
      "Yanjun Li",
      "Arman Goudarzi",
      "Ji Xiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.07411"
  },
  {
    "id": "arXiv:2004.08794",
    "title": "Robust Frequency-Based Structure Extraction",
    "abstract": "Comments: for test implementation check: this https URL",
    "descriptor": "\nComments: for test implementation check: this https URL\n",
    "authors": [
      "Tomasz Piotr Kucner",
      "Matteo Luperto",
      "Stephanie Lowry",
      "Martin Magnusson",
      "Achim J. Lilienthal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2004.08794"
  },
  {
    "id": "arXiv:2004.14786",
    "title": "Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting  BERT",
    "abstract": "Comments: ACL2020",
    "descriptor": "\nComments: ACL2020\n",
    "authors": [
      "Zhiyong Wu",
      "Yun Chen",
      "Ben Kao",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.14786"
  },
  {
    "id": "arXiv:2006.04338",
    "title": "A Decentralized Policy Gradient Approach to Multi-task Reinforcement  Learning",
    "abstract": "A Decentralized Policy Gradient Approach to Multi-task Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Sihan Zeng",
      "Aqeel Anwar",
      "Thinh Doan",
      "Arijit Raychowdhury",
      "Justin Romberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.04338"
  },
  {
    "id": "arXiv:2006.05509",
    "title": "Can artificial intelligence (AI) be used to accurately detect  tuberculosis (TB) from chest X-rays? An evaluation of five AI products for TB  screening and triaging in a high TB burden setting",
    "abstract": "Comments: 43 pages, 3 Tables 3 Figures",
    "descriptor": "\nComments: 43 pages, 3 Tables 3 Figures\n",
    "authors": [
      "Zhi Zhen Qin",
      "Shahriar Ahmed",
      "Mohammad Shahnewaz Sarker",
      "Kishor Paul",
      "Ahammad Shafiq Sikder Adel",
      "Tasneem Naheyan",
      "Rachael Barrett",
      "Sayera Banu",
      "Jacob Creswell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2006.05509"
  },
  {
    "id": "arXiv:2006.16340",
    "title": "A Nonmonotone Matrix-Free Algorithm for Nonlinear Equality-Constrained  Least-Squares Problems",
    "abstract": "A Nonmonotone Matrix-Free Algorithm for Nonlinear Equality-Constrained  Least-Squares Problems",
    "descriptor": "",
    "authors": [
      "E. Bergou",
      "Y. Diouane",
      "V. Kungurtsev",
      "C. W. Royer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.16340"
  },
  {
    "id": "arXiv:2006.16409",
    "title": "A Bayesian regularization-backpropagation neural network model for  peeling computations",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Saipraneeth Gouravaraju",
      "Jyotindra Narayan",
      "Roger A. Sauer",
      "Sachin Singh Gautam"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.16409"
  },
  {
    "id": "arXiv:2006.16779",
    "title": "PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning",
    "abstract": "Comments: Findings of ACL 2021. First four authors contributed equally to this work",
    "descriptor": "\nComments: Findings of ACL 2021. First four authors contributed equally to this work\n",
    "authors": [
      "Siqi Bao",
      "Huang He",
      "Fan Wang",
      "Hua Wu",
      "Haifeng Wang",
      "Wenquan Wu",
      "Zhen Guo",
      "Zhibin Liu",
      "Xinchao Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.16779"
  },
  {
    "id": "arXiv:2007.09647",
    "title": "Adversarial Immunization for Certifiable Robustness on Graphs",
    "abstract": "Comments: Accepted by the WSDM 2021; Code: this https URL",
    "descriptor": "\nComments: Accepted by the WSDM 2021; Code: this https URL\n",
    "authors": [
      "Shuchang Tao",
      "Huawei Shen",
      "Qi Cao",
      "Liang Hou",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.09647"
  },
  {
    "id": "arXiv:2009.09218",
    "title": "Misinformation and its stakeholders in Europe: a web-based analysis",
    "abstract": "Misinformation and its stakeholders in Europe: a web-based analysis",
    "descriptor": "",
    "authors": [
      "Emmanouil Koulas",
      "Marios Anthopoulos",
      "Sotiria Grammenou",
      "Christos Kaimakamis",
      "Konstantinos Kousaris",
      "Fotini-Rafailia Panavou",
      "Orestis Piskioulis",
      "Syed Iftikhar H. Shah",
      "Vasilios Peristeras"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.09218"
  },
  {
    "id": "arXiv:2010.00974",
    "title": "Computation of invariant sets via immersion for discrete-time nonlinear  systems",
    "abstract": "Comments: The assumption of asymptotic stability is relaxed",
    "descriptor": "\nComments: The assumption of asymptotic stability is relaxed\n",
    "authors": [
      "Zheming Wang",
      "Rapha\u00ebl M. Jungers",
      "Chong-Jin Ong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.00974"
  },
  {
    "id": "arXiv:2010.01684",
    "title": "Large System Analysis of Box-Relaxation in Correlated Massive MIMO  Channels Under Imperfect CSI",
    "abstract": "Large System Analysis of Box-Relaxation in Correlated Massive MIMO  Channels Under Imperfect CSI",
    "descriptor": "",
    "authors": [
      "Ayed M. Alrashdi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.01684"
  },
  {
    "id": "arXiv:2010.02065",
    "title": "Detecting Misclassification Errors in Neural Networks with a Gaussian  Process Model",
    "abstract": "Comments: 32 pages, 3 figures, 15 tables",
    "descriptor": "\nComments: 32 pages, 3 figures, 15 tables\n",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.02065"
  },
  {
    "id": "arXiv:2010.06081",
    "title": "Oort: Efficient Federated Learning via Guided Participant Selection",
    "abstract": "Oort: Efficient Federated Learning via Guided Participant Selection",
    "descriptor": "",
    "authors": [
      "Fan Lai",
      "Xiangfeng Zhu",
      "Harsha V. Madhyastha",
      "Mosharaf Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.06081"
  },
  {
    "id": "arXiv:2010.06144",
    "title": "Multi-layer Residual Sparsifying Transform (MARS) Model for Low-dose CT  Image Reconstruction",
    "abstract": "Comments: 28 pages, 12 figures, accepted by Medical Physics. arXiv admin note: text overlap with arXiv:2005.03825",
    "descriptor": "\nComments: 28 pages, 12 figures, accepted by Medical Physics. arXiv admin note: text overlap with arXiv:2005.03825\n",
    "authors": [
      "Xikai Yang",
      "Yong Long",
      "Saiprasad Ravishankar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.06144"
  },
  {
    "id": "arXiv:2010.09843",
    "title": "What breach? Measuring online awareness of security incidents by  studying real-world browsing behavior",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Sruti Bhagavatula",
      "Lujo Bauer",
      "Apu Kapadia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2010.09843"
  },
  {
    "id": "arXiv:2010.11687",
    "title": "PlenoptiCam v1.0: A light-field imaging framework",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Christopher Hahne",
      "Amar Aggoun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.11687"
  },
  {
    "id": "arXiv:2010.12902",
    "title": "A one-dimensional morphoelastic model for burn injuries: sensitivity  analysis and a feasibility study",
    "abstract": "A one-dimensional morphoelastic model for burn injuries: sensitivity  analysis and a feasibility study",
    "descriptor": "",
    "authors": [
      "Ginger Egberts",
      "Fred Vermolen",
      "Paul van Zuijlen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2010.12902"
  },
  {
    "id": "arXiv:2011.02850",
    "title": "Applying a Legendre collocation method based on domain decomposition to  calculate underwater sound propagation in a horizontally stratified  environment",
    "abstract": "Comments: 29pages, 7 figures",
    "descriptor": "\nComments: 29pages, 7 figures\n",
    "authors": [
      "Houwang Tu",
      "Yongxian Wang",
      "Qiang Lan",
      "Wei Liu",
      "Wenbin Xiao",
      "Shuqing Ma"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Spectral Theory (math.SP)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.02850"
  },
  {
    "id": "arXiv:2011.04923",
    "title": "Expressiveness of Neural Networks Having Width Equal or Below the Input  Dimension",
    "abstract": "Expressiveness of Neural Networks Having Width Equal or Below the Input  Dimension",
    "descriptor": "",
    "authors": [
      "Hans-Peter Beise",
      "Steve Dias Da Cruz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.04923"
  },
  {
    "id": "arXiv:2011.08013",
    "title": "A General Numerical Method to Model Anisotropy in Discretized Bond-Based  Peridynamics",
    "abstract": "Comments: 56 pages",
    "descriptor": "\nComments: 56 pages\n",
    "authors": [
      "Naveen Prakash"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.08013"
  },
  {
    "id": "arXiv:2011.08712",
    "title": "A Simple Framework to Quantify Different Types of Uncertainty in Deep  Neural Networks for Image Classification",
    "abstract": "A Simple Framework to Quantify Different Types of Uncertainty in Deep  Neural Networks for Image Classification",
    "descriptor": "",
    "authors": [
      "Aria Khoshsirat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.08712"
  },
  {
    "id": "arXiv:2011.11307",
    "title": "Restricted Boltzmann Machine, recent advances and mean-field theory",
    "abstract": "Comments: 44 pages, 13 figures. Accepted for CPB",
    "descriptor": "\nComments: 44 pages, 13 figures. Accepted for CPB\n",
    "authors": [
      "Aur\u00e9lien Decelle",
      "Cyril Furtlehner"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.11307"
  },
  {
    "id": "arXiv:2011.14582",
    "title": "Polar-Cap Codebook Design for MISO Rician Fading Channels with Limited  Feedback",
    "abstract": "Comments: 5 pages, 4 figures, and published in IEEE Wireless Communications Letters",
    "descriptor": "\nComments: 5 pages, 4 figures, and published in IEEE Wireless Communications Letters\n",
    "authors": [
      "Sung Hyuck Hong",
      "Sucheol Kim",
      "Junil Choi",
      "Wan Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.14582"
  },
  {
    "id": "arXiv:2012.00113",
    "title": "The FEDHC Bayesian network learning algorithm",
    "abstract": "The FEDHC Bayesian network learning algorithm",
    "descriptor": "",
    "authors": [
      "Michail Tsagris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00113"
  },
  {
    "id": "arXiv:2012.00364",
    "title": "Pre-Trained Image Processing Transformer",
    "abstract": "Comments: To be appeared in CVPR 2021",
    "descriptor": "\nComments: To be appeared in CVPR 2021\n",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Tianyu Guo",
      "Chang Xu",
      "Yiping Deng",
      "Zhenhua Liu",
      "Siwei Ma",
      "Chunjing Xu",
      "Chao Xu",
      "Wen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00364"
  },
  {
    "id": "arXiv:2012.02356",
    "title": "WeaQA: Weak Supervision via Captions for Visual Question Answering",
    "abstract": "Comments: Accepted in Findings of ACL 2021",
    "descriptor": "\nComments: Accepted in Findings of ACL 2021\n",
    "authors": [
      "Pratyay Banerjee",
      "Tejas Gokhale",
      "Yezhou Yang",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.02356"
  },
  {
    "id": "arXiv:2012.02486",
    "title": "Unsupervised Adversarially-Robust Representation Learning on Graphs",
    "abstract": "Unsupervised Adversarially-Robust Representation Learning on Graphs",
    "descriptor": "",
    "authors": [
      "Jiarong Xu",
      "Yang Yang",
      "Junru Chen",
      "Chunping Wang",
      "Xin Jiang",
      "Jiangang Lu",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.02486"
  },
  {
    "id": "arXiv:2012.03149",
    "title": "Adaptive Weighted Discriminator for Training Generative Adversarial  Networks",
    "abstract": "Comments: 16 pages total, 7 figures, 6 tables and 2 algorithms",
    "descriptor": "\nComments: 16 pages total, 7 figures, 6 tables and 2 algorithms\n",
    "authors": [
      "Vasily Zadorozhnyy",
      "Qiang Cheng",
      "Qiang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03149"
  },
  {
    "id": "arXiv:2012.06774",
    "title": "A network analysis on cloud gaming: Stadia, GeForce Now and PSNow",
    "abstract": "A network analysis on cloud gaming: Stadia, GeForce Now and PSNow",
    "descriptor": "",
    "authors": [
      "Andrea Di Domenico",
      "Gianluca Perna",
      "Martino Trevisan",
      "Luca Vassio",
      "Danilo Giordano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.06774"
  },
  {
    "id": "arXiv:2012.07044",
    "title": "Monitoring multimode processes: a modified PCA algorithm with continual  learning ability",
    "abstract": "Comments: This paper has been accepted by Journal of Process Control",
    "descriptor": "\nComments: This paper has been accepted by Journal of Process Control\n",
    "authors": [
      "Jingxin Zhang",
      "Donghua Zhou",
      "Maoyin Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07044"
  },
  {
    "id": "arXiv:2012.07085",
    "title": "Pseudospectral roaming contour integral methods for convection-diffusion  equations",
    "abstract": "Pseudospectral roaming contour integral methods for convection-diffusion  equations",
    "descriptor": "",
    "authors": [
      "Nicola Guglielmi",
      "Maria L\u00f3pez-Fern\u00e1ndez",
      "Mattia Manucci"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.07085"
  },
  {
    "id": "arXiv:2012.09501",
    "title": "A Hierarchical Feature Constraint to Camouflage Medical Adversarial  Attacks",
    "abstract": "A Hierarchical Feature Constraint to Camouflage Medical Adversarial  Attacks",
    "descriptor": "",
    "authors": [
      "Qingsong Yao",
      "Zecheng He",
      "Yi Lin",
      "Kai Ma",
      "Yefeng Zheng",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09501"
  },
  {
    "id": "arXiv:2012.13806",
    "title": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "abstract": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "descriptor": "",
    "authors": [
      "Danilo Pianini",
      "Roberto Casadei",
      "Mirko Viroli",
      "Stefano Mariani",
      "Franco Zambonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.13806"
  },
  {
    "id": "arXiv:2012.15519",
    "title": "Linear-Quadratic regulators for internal boundary control of lane-free  automated vehicle traffic",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2008.10255",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2008.10255\n",
    "authors": [
      "Milad Malekzadeh",
      "Ioannis Papamichail",
      "Markos Papageorgiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.15519"
  },
  {
    "id": "arXiv:2101.00300",
    "title": "When Is Generalizable Reinforcement Learning Tractable?",
    "abstract": "Comments: v2 extends results to function approximation setting",
    "descriptor": "\nComments: v2 extends results to function approximation setting\n",
    "authors": [
      "Dhruv Malik",
      "Yuanzhi Li",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.00300"
  },
  {
    "id": "arXiv:2101.00926",
    "title": "CLeaR: An Adaptive Continual Learning Framework for Regression Tasks",
    "abstract": "Comments: Submitted to the journal: AI Perspectives",
    "descriptor": "\nComments: Submitted to the journal: AI Perspectives\n",
    "authors": [
      "Yujiang He",
      "Bernhard Sick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00926"
  },
  {
    "id": "arXiv:2101.02373",
    "title": "Architectural Patterns for the Design of Federated Learning Systems",
    "abstract": "Comments: Submitted to Elsevier's Journal of Systems and Software, Special issue on Software Architecture and Artificial Intelligence",
    "descriptor": "\nComments: Submitted to Elsevier's Journal of Systems and Software, Special issue on Software Architecture and Artificial Intelligence\n",
    "authors": [
      "Sin Kit Lo",
      "Qinghua Lu",
      "Liming Zhu",
      "Hye-young Paik",
      "Xiwei Xu",
      "Chen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.02373"
  },
  {
    "id": "arXiv:2101.02808",
    "title": "Average-Reward Off-Policy Policy Evaluation with Function Approximation",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Shangtong Zhang",
      "Yi Wan",
      "Richard S. Sutton",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.02808"
  },
  {
    "id": "arXiv:2101.06482",
    "title": "A Renormalization Group Approach to Connect Discrete- and  Continuous-Time Descriptions of Gaussian Processes",
    "abstract": "Comments: 5 pages, 2 figures; 14 pages - Supplemental Material",
    "descriptor": "\nComments: 5 pages, 2 figures; 14 pages - Supplemental Material\n",
    "authors": [
      "Federica Ferretti",
      "Victor Chard\u00e8s",
      "Thierry Mora",
      "Aleksandra M Walczak",
      "Irene Giardina"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06482"
  },
  {
    "id": "arXiv:2101.06645",
    "title": "The Complexity of Bicriteria Tree-Depth",
    "abstract": "The Complexity of Bicriteria Tree-Depth",
    "descriptor": "",
    "authors": [
      "Piotr Borowiecki",
      "Dariusz Dereniowski",
      "Dorota Osula"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2101.06645"
  },
  {
    "id": "arXiv:2101.06846",
    "title": "Efficient and Accurate Multi-Body Simulation with Stiff Viscoelastic  Contacts",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Bilal Hammoud",
      "Luca Olivieri",
      "Ludovic Righetti",
      "Justin Carpentier",
      "Andrea Del Prete"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.06846"
  },
  {
    "id": "arXiv:2101.08862",
    "title": "Breaking the Deadly Triad with a Target Network",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Shangtong Zhang",
      "Hengshuai Yao",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08862"
  },
  {
    "id": "arXiv:2101.11738",
    "title": "Probabilistic Error Analysis For Sequential Summation of Real Floating  Point Numbers",
    "abstract": "Comments: Advised by Professor Ilse C.F. Ipsen",
    "descriptor": "\nComments: Advised by Professor Ilse C.F. Ipsen\n",
    "authors": [
      "Johnathan Rhyne"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.11738"
  },
  {
    "id": "arXiv:2101.12571",
    "title": "A mass, momentum, and energy conservative dynamical low-rank scheme for  the Vlasov equation",
    "abstract": "A mass, momentum, and energy conservative dynamical low-rank scheme for  the Vlasov equation",
    "descriptor": "",
    "authors": [
      "Lukas Einkemmer",
      "Ilon Joseph"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.12571"
  },
  {
    "id": "arXiv:2102.01887",
    "title": "Llama: A Heterogeneous & Serverless Framework for Auto-Tuning Video  Analytics Pipelines",
    "abstract": "Llama: A Heterogeneous & Serverless Framework for Auto-Tuning Video  Analytics Pipelines",
    "descriptor": "",
    "authors": [
      "Francisco Romero",
      "Mark Zhao",
      "Neeraja J. Yadwadkar",
      "Christos Kozyrakis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.01887"
  },
  {
    "id": "arXiv:2102.04560",
    "title": "Core Imaging Library -- Part I: a versatile Python framework for  tomographic imaging",
    "abstract": "Comments: 22 pages, 11 figures",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Jakob S. J\u00f8rgensen",
      "Evelina Ametova",
      "Genoveva Burca",
      "Gemma Fardell",
      "Evangelos Papoutsellis",
      "Edoardo Pasca",
      "Kris Thielemans",
      "Martin Turner",
      "Ryan Warr",
      "William R. B. Lionheart",
      "Philip J. Withers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2102.04560"
  },
  {
    "id": "arXiv:2102.05379",
    "title": "Argmax Flows and Multinomial Diffusion: Learning Categorical  Distributions",
    "abstract": "Argmax Flows and Multinomial Diffusion: Learning Categorical  Distributions",
    "descriptor": "",
    "authors": [
      "Emiel Hoogeboom",
      "Didrik Nielsen",
      "Priyank Jaini",
      "Patrick Forr\u00e9",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05379"
  },
  {
    "id": "arXiv:2102.06126",
    "title": "Core Imaging Library -- Part II: Multichannel reconstruction for dynamic  and spectral tomography",
    "abstract": "Core Imaging Library -- Part II: Multichannel reconstruction for dynamic  and spectral tomography",
    "descriptor": "",
    "authors": [
      "Evangelos Papoutsellis",
      "Evelina Ametova",
      "Claire Delplancke",
      "Gemma Fardell",
      "Jakob S. J\u00f8rgensen",
      "Edoardo Pasca",
      "Martin Turner",
      "Ryan Warr",
      "William R. B. Lionheart",
      "Philip J. Withers"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Mathematical Software (cs.MS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.06126"
  },
  {
    "id": "arXiv:2102.06589",
    "title": "PAC-BUS: Meta-Learning Bounds via PAC-Bayes and Uniform Stability",
    "abstract": "PAC-BUS: Meta-Learning Bounds via PAC-Bayes and Uniform Stability",
    "descriptor": "",
    "authors": [
      "Alec Farid",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06589"
  },
  {
    "id": "arXiv:2102.08607",
    "title": "On the Convergence and Sample Efficiency of Variance-Reduced Policy  Gradient Method",
    "abstract": "On the Convergence and Sample Efficiency of Variance-Reduced Policy  Gradient Method",
    "descriptor": "",
    "authors": [
      "Junyu Zhang",
      "Chengzhuo Ni",
      "Zheng Yu",
      "Csaba Szepesvari",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08607"
  },
  {
    "id": "arXiv:2102.12718",
    "title": "A Simulation-based End-to-End Learning Framework for Evidential  Occupancy Grid Mapping",
    "abstract": "Comments: Accepted to be published as part of the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-15, 2021",
    "descriptor": "\nComments: Accepted to be published as part of the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-15, 2021\n",
    "authors": [
      "Raphael van Kempen",
      "Bastian Lampe",
      "Timo Woopen",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.12718"
  },
  {
    "id": "arXiv:2103.00800",
    "title": "Query Rewriting via Cycle-Consistent Translation for E-Commerce Search",
    "abstract": "Comments: 12 pages, 9 figures; accepted by ICDE2021",
    "descriptor": "\nComments: 12 pages, 9 figures; accepted by ICDE2021\n",
    "authors": [
      "Yiming Qiu",
      "Kang Zhang",
      "Han Zhang",
      "Songlin Wang",
      "Sulong Xu",
      "Yun Xiao",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00800"
  },
  {
    "id": "arXiv:2103.00868",
    "title": "Panoramic Panoptic Segmentation: Towards Complete Surrounding  Understanding via Unsupervised Contrastive Learning",
    "abstract": "Comments: 7 pages, 4 figures, 2 tables. Accepted to 2021 IEEE Intelligent Vehicles Symposium (IV2021). The project is at this https URL",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables. Accepted to 2021 IEEE Intelligent Vehicles Symposium (IV2021). The project is at this https URL\n",
    "authors": [
      "Alexander Jaus",
      "Kailun Yang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.00868"
  },
  {
    "id": "arXiv:2103.00879",
    "title": "DR-TANet: Dynamic Receptive Temporal Attention Network for Street Scene  Change Detection",
    "abstract": "Comments: 8 pages, 9 figures, 6 tables. Accepted to IEEE Intelligent Vehicles Symposium 2021 (IV2021). Code is available at this https URL",
    "descriptor": "\nComments: 8 pages, 9 figures, 6 tables. Accepted to IEEE Intelligent Vehicles Symposium 2021 (IV2021). Code is available at this https URL\n",
    "authors": [
      "Shuo Chen",
      "Kailun Yang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.00879"
  },
  {
    "id": "arXiv:2103.01019",
    "title": "Why IP-based Subject Access Requests Are Denied?",
    "abstract": "Why IP-based Subject Access Requests Are Denied?",
    "descriptor": "",
    "authors": [
      "Supriya Adhatarao",
      "C\u00e9dric Lauradoux",
      "Cristiana Santos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.01019"
  },
  {
    "id": "arXiv:2103.03977",
    "title": "Sparse LiDAR and Stereo Fusion (SLS-Fusion) for Depth Estimationand 3D  Object Detection",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Nguyen Anh Minh Mai",
      "Pierre Duthon",
      "Louahdi Khoudour",
      "Alain Crouzil",
      "Sergio A. Velastin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03977"
  },
  {
    "id": "arXiv:2103.05196",
    "title": "A Learning-Based Computational Impact Time Guidance",
    "abstract": "A Learning-Based Computational Impact Time Guidance",
    "descriptor": "",
    "authors": [
      "Zichao Liu",
      "Jiang Wang",
      "Shaoming He",
      "Hyo-Sang Shin",
      "Antonios Tsourdos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.05196"
  },
  {
    "id": "arXiv:2103.05844",
    "title": "BIKED: A Dataset and Machine Learning Benchmarks for Data-Driven Bicycle  Design",
    "abstract": "BIKED: A Dataset and Machine Learning Benchmarks for Data-Driven Bicycle  Design",
    "descriptor": "",
    "authors": [
      "Lyle Regenwetter",
      "Brent Curry",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05844"
  },
  {
    "id": "arXiv:2103.07492",
    "title": "Continual Learning for Recurrent Neural Networks: an Empirical  Evaluation",
    "abstract": "Comments: In submission",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Andrea Cossu",
      "Antonio Carta",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07492"
  },
  {
    "id": "arXiv:2103.09357",
    "title": "A new framework for the stability analysis of perturbed saddle-point  problems and applications",
    "abstract": "A new framework for the stability analysis of perturbed saddle-point  problems and applications",
    "descriptor": "",
    "authors": [
      "Qingguo Hong",
      "Johannes Kraus",
      "Maria Lymbery",
      "Fadi Philo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.09357"
  },
  {
    "id": "arXiv:2103.10134",
    "title": "Recent Advances in Data-Driven Wireless Communication Using Gaussian  Prcesses: A Comprehensive Survey",
    "abstract": "Recent Advances in Data-Driven Wireless Communication Using Gaussian  Prcesses: A Comprehensive Survey",
    "descriptor": "",
    "authors": [
      "Kai Chen",
      "Qinglei Kong",
      "Yijue Dai",
      "Yue Xu",
      "Feng Yin",
      "Lexi Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.10134"
  },
  {
    "id": "arXiv:2103.11736",
    "title": "Automatic Pulmonary Artery-Vein Separation in CT Images using Twin-Pipe  Network and Topology Reconstruction",
    "abstract": "Automatic Pulmonary Artery-Vein Separation in CT Images using Twin-Pipe  Network and Topology Reconstruction",
    "descriptor": "",
    "authors": [
      "Lin Pan",
      "Yaoyong Zheng",
      "Liqin Huang",
      "Liuqing Chen",
      "Zhen Zhang",
      "Rongda Fu",
      "Bin Zheng",
      "Shaohua Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11736"
  },
  {
    "id": "arXiv:2103.11843",
    "title": "Implementation of Artificial Neural Networks for the Nepta-Uranian  Interplanetary (NUIP) Mission",
    "abstract": "Comments: 20 pages, 13 figures, 6 tables",
    "descriptor": "\nComments: 20 pages, 13 figures, 6 tables\n",
    "authors": [
      "Saurabh Gore",
      "Manuel Ntumba"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11843"
  },
  {
    "id": "arXiv:2103.12513",
    "title": "On gray-box modeling for virtual flow metering",
    "abstract": "Comments: 38 pages, 28 figures",
    "descriptor": "\nComments: 38 pages, 28 figures\n",
    "authors": [
      "Mathilde Hotvedt",
      "Bjarne Grimstad",
      "Dag Ljungquist",
      "Lars Imsland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.12513"
  },
  {
    "id": "arXiv:2104.00428",
    "title": "Storchastic: A Framework for General Stochastic Automatic  Differentiation",
    "abstract": "Comments: 28 pages, 1 figure",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Emile van Krieken",
      "Jakub M. Tomczak",
      "Annette ten Teije"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00428"
  },
  {
    "id": "arXiv:2104.01747",
    "title": "Fast Design Space Exploration of Nonlinear Systems: Part I",
    "abstract": "Comments: 14 pages, 26 figures. arXiv admin note: text overlap with arXiv:2010.09842",
    "descriptor": "\nComments: 14 pages, 26 figures. arXiv admin note: text overlap with arXiv:2010.09842\n",
    "authors": [
      "Sanjai Narain",
      "Emily Mak",
      "Dana Chee",
      "Brendan Englot",
      "Kishore Pochiraju",
      "Niraj K. Jha",
      "Karthik Narayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.01747"
  },
  {
    "id": "arXiv:2104.04630",
    "title": "WLV-RIT at SemEval-2021 Task 5: A Neural Transformer Framework for  Detecting Toxic Spans",
    "abstract": "Comments: Accepted to SemEval-2021",
    "descriptor": "\nComments: Accepted to SemEval-2021\n",
    "authors": [
      "Tharindu Ranasinghe",
      "Diptanu Sarkar",
      "Marcos Zampieri",
      "Alexander Ororbia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04630"
  },
  {
    "id": "arXiv:2104.04672",
    "title": "Deep Learning Identifies Neuroimaging Signatures of Alzheimer's Disease  Using Structural and Synthesized Functional MRI Data",
    "abstract": "Comments: Published in IEEE ISBI 2021. Available at this https URL",
    "descriptor": "\nComments: Published in IEEE ISBI 2021. Available at this https URL\n",
    "authors": [
      "Nanyan Zhu",
      "Chen Liu",
      "Xinyang Feng",
      "Dipika Sikka",
      "Sabrina Gjerswold-Selleck",
      "Scott A. Small",
      "Jia Guo"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04672"
  },
  {
    "id": "arXiv:2104.06378",
    "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question  Answering",
    "abstract": "Comments: NAACL 2021. Code & data available at this https URL",
    "descriptor": "\nComments: NAACL 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Hongyu Ren",
      "Antoine Bosselut",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06378"
  },
  {
    "id": "arXiv:2104.06521",
    "title": "TAAC: Temporally Abstract Actor-Critic for Continuous Control",
    "abstract": "TAAC: Temporally Abstract Actor-Critic for Continuous Control",
    "descriptor": "",
    "authors": [
      "Haonan Yu",
      "Wei Xu",
      "Haichao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.06521"
  },
  {
    "id": "arXiv:2104.07060",
    "title": "Membership-Mappings for Data Representation Learning",
    "abstract": "Membership-Mappings for Data Representation Learning",
    "descriptor": "",
    "authors": [
      "Mohit Kumar",
      "Bernhard A. Moser",
      "Lukas Fischer",
      "Bernhard Freudenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2104.07060"
  },
  {
    "id": "arXiv:2104.07204",
    "title": "Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese  Pre-trained Language Models",
    "abstract": "Comments: Accepted at NAACL 2021, 16 pages, this https URL",
    "descriptor": "\nComments: Accepted at NAACL 2021, 16 pages, this https URL\n",
    "authors": [
      "Yuxuan Lai",
      "Yijia Liu",
      "Yansong Feng",
      "Songfang Huang",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07204"
  },
  {
    "id": "arXiv:2104.08623",
    "title": "Learning Fuzzy Clustering for SPECT/CT Segmentation via Convolutional  Neural Networks",
    "abstract": "Comments: This manuscript has been published by Medical Physics (2021)",
    "descriptor": "\nComments: This manuscript has been published by Medical Physics (2021)\n",
    "authors": [
      "Junyu Chen",
      "Ye Li",
      "Licia P. Luna",
      "Hyun Woo Chung",
      "Steven P. Rowe",
      "Yong Du",
      "Lilja B. Solnes",
      "Eric C. Frey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08623"
  },
  {
    "id": "arXiv:2104.09125",
    "title": "SAPE: Spatially-Adaptive Progressive Encoding for Neural Optimization",
    "abstract": "SAPE: Spatially-Adaptive Progressive Encoding for Neural Optimization",
    "descriptor": "",
    "authors": [
      "Amir Hertz",
      "Or Perel",
      "Raja Giryes",
      "Olga Sorkine-Hornung",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2104.09125"
  },
  {
    "id": "arXiv:2104.09835",
    "title": "WiFiMod: Transformer-based Indoor Human Mobility Modeling using Passive  Sensing",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Amee Trivedi",
      "Kate Silverstein",
      "Emma Strubell",
      "Mohit Iyyer",
      "Prashant Shenoy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.09835"
  },
  {
    "id": "arXiv:2104.10027",
    "title": "HTN Planning Domain for Deployment of Cloud Applications",
    "abstract": "Comments: Published in the proceedings of the 10th International Planning Competition: Planner and Domain Abstracts - Hierarchical Task Network (HTN) Planning Track",
    "descriptor": "\nComments: Published in the proceedings of the 10th International Planning Competition: Planner and Domain Abstracts - Hierarchical Task Network (HTN) Planning Track\n",
    "authors": [
      "Ilche Georgievski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10027"
  },
  {
    "id": "arXiv:2104.10402",
    "title": "PTHash: Revisiting FCH Minimal Perfect Hashing",
    "abstract": "Comments: Accepted to SIGIR 2021",
    "descriptor": "\nComments: Accepted to SIGIR 2021\n",
    "authors": [
      "Giulio Ermanno Pibiri",
      "Roberto Trani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.10402"
  },
  {
    "id": "arXiv:2104.12470",
    "title": "Easy and Efficient Transformer : Scalable Inference Solution For large  NLP mode",
    "abstract": "Easy and Efficient Transformer : Scalable Inference Solution For large  NLP mode",
    "descriptor": "",
    "authors": [
      "Gongzheng li",
      "Yadong Xi",
      "Jingzhen Ding",
      "Duan Wang",
      "Bai Liu",
      "Changjie Fan",
      "Xiaoxi Mao",
      "Zeng Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12470"
  },
  {
    "id": "arXiv:2104.12815",
    "title": "Provenance-based Data Skipping (TechReport)",
    "abstract": "Comments: 20 pages, 14 figures",
    "descriptor": "\nComments: 20 pages, 14 figures\n",
    "authors": [
      "Xing Niu",
      "Ziyu Liu",
      "Pengyuan Li",
      "Boris Glavic"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2104.12815"
  },
  {
    "id": "arXiv:2104.14787",
    "title": "A User-Guided Bayesian Framework for Ensemble Feature Selection in Life  Science Applications (UBayFS)",
    "abstract": "A User-Guided Bayesian Framework for Ensemble Feature Selection in Life  Science Applications (UBayFS)",
    "descriptor": "",
    "authors": [
      "Anna Jenul",
      "Stefan Schrunner",
      "J\u00fcrgen Pilz",
      "Oliver Tomic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2104.14787"
  },
  {
    "id": "arXiv:2105.00065",
    "title": "Quantum Foundations of Classical Reversible Computing",
    "abstract": "Comments: 73 pages, 16 figures, accepted by Entropy",
    "descriptor": "\nComments: 73 pages, 16 figures, accepted by Entropy\n",
    "authors": [
      "Michael P. Frank",
      "Karpur Shukla"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.00065"
  },
  {
    "id": "arXiv:2105.02977",
    "title": "Building a Distributed Computing System for LDMX: Challenges of creating  and operating a lightweight e-infrastructure for small-to-medium size  accelerator experiments",
    "abstract": "Comments: 10 pages, 4 figures, Submitted to 25th International Conference on Computing in High-Energy and Nuclear Physics (vCHEP 2021)",
    "descriptor": "\nComments: 10 pages, 4 figures, Submitted to 25th International Conference on Computing in High-Energy and Nuclear Physics (vCHEP 2021)\n",
    "authors": [
      "Lene Kristian Bryngemark",
      "David Cameron",
      "Valentina Dutta",
      "Thomas Eichlersmith",
      "Balazs Konya",
      "Omar Moreno",
      "Geoffrey Mullier",
      "Florido Paganelli",
      "Ruth P\u00f6ttgen",
      "Fuzzy Rogers",
      "Andrii Salnikov",
      "Paul Weakliem"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.02977"
  },
  {
    "id": "arXiv:2105.03505",
    "title": "Unsupervised Cross-Domain Prerequisite Chain Learning using Variational  Graph Autoencoders",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Irene Li",
      "Vanessa Yan",
      "Tianxiao Li",
      "Rihao Qu",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03505"
  },
  {
    "id": "arXiv:2105.03933",
    "title": "Joint Learning of Deep Retrieval Model and Product Quantization based  Embedding Index",
    "abstract": "Comments: 4 pages, 4 figures; accepted by SIGIR2021",
    "descriptor": "\nComments: 4 pages, 4 figures; accepted by SIGIR2021\n",
    "authors": [
      "Han Zhang",
      "Hongwei Shen",
      "Yiming Qiu",
      "Yunjiang Jiang",
      "Songlin Wang",
      "Sulong Xu",
      "Yun Xiao",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03933"
  },
  {
    "id": "arXiv:2105.04132",
    "title": "An Attention-Fused Network for Semantic Segmentation of  Very-High-Resolution Remote Sensing Imagery",
    "abstract": "Comments: 35 pages. Published by ISPRS Journal of Photogrammetry and Remote Sensing",
    "descriptor": "\nComments: 35 pages. Published by ISPRS Journal of Photogrammetry and Remote Sensing\n",
    "authors": [
      "Xuan Yang",
      "Shanshan Li",
      "Zhengchao Chen",
      "Jocelyn Chanussot",
      "Xiuping Jia",
      "Bing Zhang",
      "Baipeng Li",
      "Pan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04132"
  },
  {
    "id": "arXiv:2105.05381",
    "title": "Accuracy-Privacy Trade-off in Deep Ensembles",
    "abstract": "Accuracy-Privacy Trade-off in Deep Ensembles",
    "descriptor": "",
    "authors": [
      "Shahbaz Rezaei",
      "Zubair Shafiq",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.05381"
  },
  {
    "id": "arXiv:2105.06162",
    "title": "Variable Coded Batch Matrix Multiplication",
    "abstract": "Comments: 8 pages, 3 figures, submitted to IEEE Global Communications Conference (GLOBECOM) 2021",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to IEEE Global Communications Conference (GLOBECOM) 2021\n",
    "authors": [
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06162"
  },
  {
    "id": "arXiv:2105.06201",
    "title": "Strategic Successive Refinement Coding for Bayesian Persuasion with Two  Decoders",
    "abstract": "Strategic Successive Refinement Coding for Bayesian Persuasion with Two  Decoders",
    "descriptor": "",
    "authors": [
      "Rony Bou Rouphael",
      "Mael Le Treust"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06201"
  },
  {
    "id": "arXiv:2105.06322",
    "title": "Hedging Against Sore Loser Attacks in Cross-Chain Transactions",
    "abstract": "Comments: To apper in PODC 2021",
    "descriptor": "\nComments: To apper in PODC 2021\n",
    "authors": [
      "Yingjie Xue",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.06322"
  },
  {
    "id": "arXiv:2105.07270",
    "title": "Annotation Uncertainty in the Context of Grammatical Change",
    "abstract": "Annotation Uncertainty in the Context of Grammatical Change",
    "descriptor": "",
    "authors": [
      "Marie-Luis Merten",
      "Marcel Wever",
      "Michaela Geierhos",
      "Doris Tophinke",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07270"
  },
  {
    "id": "arXiv:2105.07618",
    "title": "Dissipation of Oscillation Energy and Distribution of Damping Power in a  Multimachine Power System: A Small-signal Analysis",
    "abstract": "Dissipation of Oscillation Energy and Distribution of Damping Power in a  Multimachine Power System: A Small-signal Analysis",
    "descriptor": "",
    "authors": [
      "Kaustav Chatterjee",
      "Nilanjan Ray Chaudhuri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.07618"
  },
  {
    "id": "arXiv:2105.07731",
    "title": "Connectivity of 1d random geometric graphs",
    "abstract": "Comments: 27 pages, 11 figures",
    "descriptor": "\nComments: 27 pages, 11 figures\n",
    "authors": [
      "Alexander P. Kartun-Giles",
      "Kostas Koufos",
      "Nicolas Privault"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.07731"
  },
  {
    "id": "arXiv:2105.08316",
    "title": "CoMAE: A Multi-factor Hierarchical Framework for Empathetic Response  Generation",
    "abstract": "Comments: Accepted to Findings of ACL 2021 (Long Paper)",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021 (Long Paper)\n",
    "authors": [
      "Chujie Zheng",
      "Yong Liu",
      "Wei Chen",
      "Yongcai Leng",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.08316"
  },
  {
    "id": "arXiv:2105.08902",
    "title": "LNGate: Powering IoT with Next Generation Lightning Micro-payments using  Threshold Cryptography",
    "abstract": "Comments: Author's version. To appear at 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks (WiSec 2021). arXiv admin note: text overlap with arXiv:2012.10576",
    "descriptor": "\nComments: Author's version. To appear at 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks (WiSec 2021). arXiv admin note: text overlap with arXiv:2012.10576\n",
    "authors": [
      "Ahmet Kurt",
      "Suat Mercan",
      "Omer Shlomovits",
      "Enes Erdin",
      "Kemal Akkaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.08902"
  },
  {
    "id": "arXiv:2105.09226",
    "title": "Detection of Emotions in Hindi-English Code Mixed Text Data",
    "abstract": "Detection of Emotions in Hindi-English Code Mixed Text Data",
    "descriptor": "",
    "authors": [
      "Divyansh Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09226"
  },
  {
    "id": "arXiv:2105.09938",
    "title": "Measuring Coding Challenge Competence With APPS",
    "abstract": "Comments: Code and the APPS dataset is available at this https URL",
    "descriptor": "\nComments: Code and the APPS dataset is available at this https URL\n",
    "authors": [
      "Dan Hendrycks",
      "Steven Basart",
      "Saurav Kadavath",
      "Mantas Mazeika",
      "Akul Arora",
      "Ethan Guo",
      "Collin Burns",
      "Samir Puranik",
      "Horace He",
      "Dawn Song",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09938"
  },
  {
    "id": "arXiv:2105.10568",
    "title": "High Throughput Soybean Pod-Counting with In-Field Robotic Data  Collection and Machine-Vision Based Data Analysis",
    "abstract": "High Throughput Soybean Pod-Counting with In-Field Robotic Data  Collection and Machine-Vision Based Data Analysis",
    "descriptor": "",
    "authors": [
      "Michael McGuire",
      "Chinmay Soman",
      "Brian Diers",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10568"
  },
  {
    "id": "arXiv:2105.10585",
    "title": "Properties of the After Kernel",
    "abstract": "Properties of the After Kernel",
    "descriptor": "",
    "authors": [
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.10585"
  },
  {
    "id": "arXiv:2105.10680",
    "title": "Cybercosm: New Foundations for a Converged Science Data Ecosystem",
    "abstract": "Comments: Updated Grant No.'s. Added link to FAQ",
    "descriptor": "\nComments: Updated Grant No.'s. Added link to FAQ\n",
    "authors": [
      "Mark Asch",
      "Fran\u00e7ois Bodin",
      "Micah Beck",
      "Terry Moore",
      "Michela Taufer",
      "Jean-Pierre Vilotte"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.10680"
  },
  {
    "id": "arXiv:2105.10682",
    "title": "Feasible Actor-Critic: Constrained Reinforcement Learning for Ensuring  Statewise Safety",
    "abstract": "Comments: There are some confusions in Theorem 2 in section 4. We will resubmit it until this problem is fixed",
    "descriptor": "\nComments: There are some confusions in Theorem 2 in section 4. We will resubmit it until this problem is fixed\n",
    "authors": [
      "Haitong Ma",
      "Yang Guan",
      "Shegnbo Eben Li",
      "Xiangteng Zhang",
      "Sifa Zheng",
      "Jianyu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10682"
  },
  {
    "id": "arXiv:2105.10867",
    "title": "EXoN: EXplainable encoder Network",
    "abstract": "EXoN: EXplainable encoder Network",
    "descriptor": "",
    "authors": [
      "SeungHwan An",
      "Hosik Choi",
      "Jong-June Jeon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10867"
  },
  {
    "id": "arXiv:2105.11071",
    "title": "Alternating Fixpoint Operator for Hybrid MKNF Knowledge Bases as an  Approximator of AFT",
    "abstract": "Alternating Fixpoint Operator for Hybrid MKNF Knowledge Bases as an  Approximator of AFT",
    "descriptor": "",
    "authors": [
      "Fangfang Liu",
      "Jia-huai You"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11071"
  },
  {
    "id": "arXiv:2105.11187",
    "title": "Pulmonary embolism identification in computerized tomography pulmonary  angiography scans with deep learning technologies in COVID-19 patients",
    "abstract": "Comments: 16 pages, 6 figures, 1 table, Submitted to the European Radiology journal of Springer",
    "descriptor": "\nComments: 16 pages, 6 figures, 1 table, Submitted to the European Radiology journal of Springer\n",
    "authors": [
      "Chairi Kiourt",
      "Georgios Feretzakis",
      "Konstantinos Dalamarinis",
      "Dimitris Kalles",
      "Georgios Pantos",
      "Ioannis Papadopoulos",
      "Spyros Kouris",
      "George Ioannakis",
      "Evangelos Loupelis",
      "Petros Antonopoulos",
      "Aikaterini Sakagianni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11187"
  },
  {
    "id": "arXiv:2105.11439",
    "title": "2nd-order Updates with 1st-order Complexity",
    "abstract": "Comments: 12 pages, 3 figures, conference preprint",
    "descriptor": "\nComments: 12 pages, 3 figures, conference preprint\n",
    "authors": [
      "Michael F. Zimmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.11439"
  },
  {
    "id": "arXiv:2105.11479",
    "title": "A Flawed Dataset for Symbolic Equation Verification",
    "abstract": "A Flawed Dataset for Symbolic Equation Verification",
    "descriptor": "",
    "authors": [
      "Ernest Davis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.11479"
  },
  {
    "id": "arXiv:2105.11752",
    "title": "Argument Undermining: Counter-Argument Generation by Attacking Weak  Premises",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Milad Alshomary",
      "Shahbaz Syed",
      "Martin Potthast",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11752"
  },
  {
    "id": "arXiv:2105.11876",
    "title": "Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior  Implicit Recommendation",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Xiao Luo",
      "Daqing Wu",
      "Chong Chen",
      "Jinwen Ma",
      "Minghua Deng",
      "Chen Shen",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.11876"
  },
  {
    "id": "arXiv:2105.12107",
    "title": "Self-Organized Variational Autoencoders (Self-VAE) for Learned Image  Compression",
    "abstract": "Comments: Accepted for publication in IEEE International Conference on Image Processing (ICIP) 2021",
    "descriptor": "\nComments: Accepted for publication in IEEE International Conference on Image Processing (ICIP) 2021\n",
    "authors": [
      "M. Ak\u0131n Y\u0131lmaz",
      "Onur Kele\u015f",
      "Hilal G\u00fcven",
      "A. Murat Tekalp",
      "Junaid Malik",
      "Serkan K\u0131ranyaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12107"
  },
  {
    "id": "arXiv:2105.12186",
    "title": "Self-Guided Instance-Aware Network for Depth Completion and Enhancement",
    "abstract": "Comments: Accepted by ICRA 2021",
    "descriptor": "\nComments: Accepted by ICRA 2021\n",
    "authors": [
      "Zhongzhen Luo",
      "Fengjia Zhang",
      "Guoyi Fu",
      "Jiajie Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.12186"
  },
  {
    "id": "arXiv:2105.12392",
    "title": "Unsupervised Pronoun Resolution via Masked Noun-Phrase Prediction",
    "abstract": "Comments: Accepted to ACL2021",
    "descriptor": "\nComments: Accepted to ACL2021\n",
    "authors": [
      "Ming Shen",
      "Pratyay Banerjee",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.12392"
  },
  {
    "id": "arXiv:2105.12544",
    "title": "Language Model as an Annotator: Exploring DialoGPT for Dialogue  Summarization",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Xiachong Feng",
      "Xiaocheng Feng",
      "Libo Qin",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.12544"
  },
  {
    "id": "arXiv:2105.12620",
    "title": "Lessons Learned and Improvements when Building Screen-Space Samplers  with Blue-Noise Error Distribution",
    "abstract": "Comments: 2 pages, 1 figure",
    "descriptor": "\nComments: 2 pages, 1 figure\n",
    "authors": [
      "Laurent Belcour",
      "Eric Heitz"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.12620"
  },
  {
    "id": "arXiv:2105.12623",
    "title": "New instances for maximum weight independent set from a vehicle routing  application",
    "abstract": "Comments: 5 pages, 1 table",
    "descriptor": "\nComments: 5 pages, 1 table\n",
    "authors": [
      "Yuanyuan Dong",
      "Andrew V. Goldberg",
      "Alexander Noe",
      "Nikos Parotsidis",
      "Mauricio G. C. Resende",
      "Quico Spaen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.12623"
  },
  {
    "id": "arXiv:2105.12802",
    "title": "Direct Detection Under Tukey Signalling",
    "abstract": "Comments: Submitted to J. Lightwave Techn. on May 26th, 2021",
    "descriptor": "\nComments: Submitted to J. Lightwave Techn. on May 26th, 2021\n",
    "authors": [
      "Amir Tasbihi",
      "Frank R. Kschischang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.12802"
  },
  {
    "id": "arXiv:2105.12825",
    "title": "Trade the Event: Corporate Events Detection for News-Based Event-Driven  Trading",
    "abstract": "Comments: Accepted to publish in Findings of ACL 2021",
    "descriptor": "\nComments: Accepted to publish in Findings of ACL 2021\n",
    "authors": [
      "Zhihan Zhou",
      "Liqian Ma",
      "Han Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Finance (q-fin.CP)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.12825"
  },
  {
    "id": "arXiv:2105.12833",
    "title": "Simulated Data Generation Through Algorithmic Force Coefficient  Estimation for AI-Based Robotic Projectile Launch Modeling",
    "abstract": "Comments: ACIRS 2021; First two authors contributed equally, order arbitrarily assigned",
    "descriptor": "\nComments: ACIRS 2021; First two authors contributed equally, order arbitrarily assigned\n",
    "authors": [
      "Sajiv Shah",
      "Ayaan Haque",
      "Fei Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.12833"
  },
  {
    "id": "arXiv:2105.12894",
    "title": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown  System Dynamics",
    "abstract": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown  System Dynamics",
    "descriptor": "",
    "authors": [
      "Chaofan Huang",
      "Simin Ma",
      "Shihao Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.12894"
  },
  {
    "id": "arXiv:2105.12988",
    "title": "Normative versus strategic accounts of acknowledgment data: the case of  the top-five journals of economics",
    "abstract": "Comments: 43 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 43 pages, 5 figures, 5 tables\n",
    "authors": [
      "Alberto Baccini",
      "Eugenio Petrovich"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.12988"
  },
  {
    "id": "arXiv:2105.13074",
    "title": "Path-based knowledge reasoning with textual semantic information for  medical knowledge graph completion",
    "abstract": "Path-based knowledge reasoning with textual semantic information for  medical knowledge graph completion",
    "descriptor": "",
    "authors": [
      "Yinyu Lan",
      "Shizhu He",
      "Xiangrong Zeng",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13074"
  },
  {
    "id": "arXiv:2105.13134",
    "title": "Coupled-Cluster Theory Revisited",
    "abstract": "Coupled-Cluster Theory Revisited",
    "descriptor": "",
    "authors": [
      "Mih\u00e1ly Andr\u00e1s Csirik",
      "Andre Laestadius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13134"
  },
  {
    "id": "arXiv:2105.13204",
    "title": "Pose2Drone: A Skeleton-Pose-based Framework for Human-Drone Interaction",
    "abstract": "Pose2Drone: A Skeleton-Pose-based Framework for Human-Drone Interaction",
    "descriptor": "",
    "authors": [
      "Zdravko Marinov",
      "Stanka Vasileva",
      "Qing Wang",
      "Constantin Seibold",
      "Jiaming Zhang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13204"
  },
  {
    "id": "arXiv:2105.13336",
    "title": "TENSILE: A Tensor granularity dynamic GPU memory scheduler method  towards multiple dynamic workloads system",
    "abstract": "TENSILE: A Tensor granularity dynamic GPU memory scheduler method  towards multiple dynamic workloads system",
    "descriptor": "",
    "authors": [
      "Kaixin Zhang",
      "Hongzhi Wang",
      "Tongxin Li",
      "Han Hu",
      "Jiye Qiu",
      "Songling Zou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.13336"
  }
]
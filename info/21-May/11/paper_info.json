[
  {
    "id": "arXiv:2105.03432",
    "title": "Generalising Multilingual Concept-to-Text NLG with Language Agnostic  Delexicalisation",
    "abstract": "Concept-to-text Natural Language Generation is the task of expressing an\ninput meaning representation in natural language. Previous approaches in this\ntask have been able to generalise to rare or unseen instances by relying on a\ndelexicalisation of the input. However, this often requires that the input\nappears verbatim in the output text. This poses challenges in multilingual\nsettings, where the task expands to generate the output text in multiple\nlanguages given the same input. In this paper, we explore the application of\nmultilingual models in concept-to-text and propose Language Agnostic\nDelexicalisation, a novel delexicalisation method that uses multilingual\npretrained embeddings, and employs a character-level post-editing model to\ninflect words in their correct form during relexicalisation. Our experiments\nacross five datasets and five languages show that multilingual models\noutperform monolingual models in concept-to-text and that our framework\noutperforms previous approaches, especially for low resource languages.",
    "descriptor": "\nComments: To be published in the proceedings of ACL-IJCNLP 2021\n",
    "authors": [
      "Giulio Zhou",
      "Gerasimos Lampouras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03432"
  },
  {
    "id": "arXiv:2105.03452",
    "title": "New Numerical Interface Scheme for the Kurganov-Tadmor second-order  Method",
    "abstract": "In this paper, we develop a numerical scheme to handle interfaces across\ncomputational domains in multi-block schemes for the approximation of systems\nof conservation laws. We are interested in transmitting shock discontinuities\nwithout lowering the overall precision of the method. We want to accomplish\nthis without using information from interior points of adjacent grids, that is,\nsharing only information from boundary points of those grids. To achieve this,\nwe choose to work with the second-order Kurganov-Tadmor (KT) method at interior\npoints, relaxing it to first order at interfaces. This allows us to keep\nsecond-order overall accuracy (in the relevant norm) and at the same time\npreserve the TVD property of the original scheme. After developing the method\nwe performed several standard one and two-dimensional tests. Among them, we\nused the one-dimensional advection and Burgers equations to verify the\nsecond-order convergence of the method. We also tested the two-dimensional\nEuler equations with an implosion and a Gresho vortex\\cite{liska2003}. In\nparticular, in the two-dimensional implosion test we can see that regardless of\nthe orientation of shocks with respect to the interface, they travel across\nthem without appreciable deformation both in amplitude and front direction.",
    "descriptor": "",
    "authors": [
      "Pablo Montes",
      "Oscar Reula"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03452"
  },
  {
    "id": "arXiv:2105.03456",
    "title": "CASTing a Net: Supporting Teachers with Search Technology",
    "abstract": "Past and current research has typically focused on ensuring that search\ntechnology for the classroom serves children. In this paper, we argue for the\nneed to broaden the research focus to include teachers and how search\ntechnology can aid them. In particular, we share how furnishing a\nbehind-the-scenes portal for teachers can empower them by providing a window\ninto the spelling, writing, and concept connection skills of their students.",
    "descriptor": "\nComments: KidRec '21: 5th International and Interdisciplinary Perspectives on Children & Recommender and Information Retrieval Systems (KidRec) Search and Recommendation Technology through the Lens of a Teacher- Co-located with ACM IDC 2021\n",
    "authors": [
      "Garrett Allen",
      "Katherine Landau Wright",
      "Jerry Alan Fails",
      "Casey Kennington",
      "Maria Soledad Pera"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03456"
  },
  {
    "id": "arXiv:2105.03458",
    "title": "Duplex Sequence-to-Sequence Learning for Reversible Machine Translation",
    "abstract": "Sequence-to-sequence (seq2seq) problems such as machine translation are\nbidirectional, which naturally derive a pair of directional tasks and two\ndirectional learning signals. However, typical seq2seq neural networks are {\\em\nsimplex} that only model one unidirectional task, which cannot fully exploit\nthe potential of bidirectional learning signals from parallel data. To address\nthis issue, we propose a {\\em duplex} seq2seq neural network, REDER (Reversible\nDuplex Transformer), and apply it to machine translation. The architecture of\nREDER has two ends, each of which specializes in a language so as to read and\nyield sequences in that language. As a result, REDER can simultaneously learn\nfrom the bidirectional signals, and enables {\\em reversible machine\ntranslation} by simply flipping the input and output ends, Experiments on\nwidely-used machine translation benchmarks verify that REDER achieves the first\nsuccess of reversible machine translation, which helps obtain considerable\ngains over several strong baselines.",
    "descriptor": "\nComments: Under review, 10 pages\n",
    "authors": [
      "Zaixiang Zheng",
      "Hao Zhou",
      "Shujian Huang",
      "Jiajun Chen",
      "Jingjing Xu",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03458"
  },
  {
    "id": "arXiv:2105.03461",
    "title": "Impact of DER Communication Delay in AGC: Cyber-Physical Dynamic  Simulation",
    "abstract": "Distributed energy resource (DER) frequency regulations are promising\ntechnologies for future grid operation. Unlike conventional generators, DERs\nmight require open communication networks to exchange signals with control\ncenters, possibly through DER aggregators; therefore, the impacts of the\ncommunication variations on the system stability need to be investigated. This\npaper develops a cyber-physical dynamic simulation model based on the\nHierarchical Engine for Large-Scale Co-Simulation (HELICS) to evaluate the\nimpact of the communication variations, such as delays in DER frequency\nregulations. The feasible delay range can be obtained under different parameter\nsettings. The results show that the risk of instability generally increases\nwith the communication delay.",
    "descriptor": "",
    "authors": [
      "Wenbo Wang",
      "Xin Fang",
      "Anthony Florita"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03461"
  },
  {
    "id": "arXiv:2105.03462",
    "title": "Necessary and Sufficient Girth Conditions for Tanner Graphs of  Quasi-Cyclic LDPC Codes",
    "abstract": "This paper revisits the connection between the girth of a protograph-based\nLDPC code given by a parity-check matrix and the properties of powers of the\nproduct between the matrix and its transpose in order to obtain the necessary\nand sufficient conditions for a code to have given girth between 6 and 12, and\nto show how these conditions can be incorporated into simple algorithms to\nconstruct codes of that girth. To this end, we highlight the role that certain\nsubmatrices that appear in these products have in the construction of codes of\ndesired girth. In particular, we show that imposing girth conditions on a\nparity-check matrix is equivalent to imposing conditions on a square submatrix\nobtained from it and we show how this equivalence is particularly strong for a\nprotograph based parity-check matrix of variable node degree 2, where the\ncycles in its Tanner graph correspond one-to-one to the cycles in the Tanner\ngraph of a square submatrix obtained by adding the permutation matrices (or\nproducts of these) in the composition of the parity-check matrix. We end the\npaper with exemplary constructions of codes with various girths and computer\nsimulations. Although, we mostly assume the case of fully connected protographs\nof variable node degree 2 and 3, the results can be used for any parity-check\nmatrix/protograph-based Tanner graph.",
    "descriptor": "\nComments: Submitted to the 2021 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Roxana Smarandache",
      "David G. M. Mitchell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03462"
  },
  {
    "id": "arXiv:2105.03463",
    "title": "Conditional a posteriori error bounds for high order DG time stepping  approximations of semilinear heat models with blow-up",
    "abstract": "This work is concerned with the development of an adaptive numerical method\nfor semilinear heat flow models featuring a general (possibly) nonlinear\nreaction term that may cause the solution to blow up in finite time. The fully\ndiscrete scheme consists of a high order discontinuous Galerkin (dG) time\nstepping method and a conforming finite element discretisation (cG) in space.\nThe proposed adaptive procedure is based on rigorously devised conditional a\nposteriori error bounds in the $L^{\\infty}(L^{\\infty})$ norm. Numerical\nexperiments complement the theoretical results.",
    "descriptor": "",
    "authors": [
      "Stephen Metcalfe",
      "Thomas P. Wihler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03463"
  },
  {
    "id": "arXiv:2105.03464",
    "title": "Estimating Parkinsonism Severity in Natural Gait Videos of Older Adults  with Dementia",
    "abstract": "Drug-induced parkinsonism affects many older adults with dementia, often\ncausing gait disturbances. New advances in vision-based human pose-estimation\nhave opened possibilities for frequent and unobtrusive analysis of gait in\nresidential settings. This work proposes novel spatial-temporal graph\nconvolutional network (ST-GCN) architectures and training procedures to predict\nclinical scores of parkinsonism in gait from video of individuals with\ndementia. We propose a two-stage training approach consisting of a\nself-supervised pretraining stage that encourages the ST-GCN model to learn\nabout gait patterns before predicting clinical scores in the finetuning stage.\nThe proposed ST-GCN models are evaluated on joint trajectories extracted from\nvideo and are compared against traditional (ordinal, linear, random forest)\nregression models and temporal convolutional network baselines. Three 2D human\npose-estimation libraries (OpenPose, Detectron, AlphaPose) and the Microsoft\nKinect (2D and 3D) are used to extract joint trajectories of 4787 natural\nwalking bouts from 53 older adults with dementia. A subset of 399 walks from 14\nparticipants is annotated with scores of parkinsonism severity on the gait\ncriteria of the Unified Parkinson's Disease Rating Scale (UPDRS) and the\nSimpson-Angus Scale (SAS). Our results demonstrate that ST-GCN models operating\non 3D joint trajectories extracted from the Kinect consistently outperform all\nother models and feature sets. Prediction of parkinsonism scores in natural\nwalking bouts of unseen participants remains a challenging task, with the best\nmodels achieving macro-averaged F1-scores of 0.53 +/- 0.03 and 0.40 +/- 0.02\nfor UPDRS-gait and SAS-gait, respectively. Pre-trained model and demo code for\nthis work is available:\nhttps://github.com/TaatiTeam/stgcn_parkinsonism_prediction.",
    "descriptor": "",
    "authors": [
      "Andrea Sabo",
      "Sina Mehdizadeh",
      "Andrea Iaboni",
      "Babak Taati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03464"
  },
  {
    "id": "arXiv:2105.03480",
    "title": "A semigroup method for high dimensional elliptic PDEs and eigenvalue  problems based on neural networks",
    "abstract": "In this paper, we propose a semigroup method for solving high-dimensional\nelliptic partial differential equations (PDEs) and the associated eigenvalue\nproblems based on neural networks. For the PDE problems, we reformulate the\noriginal equations as variational problems with the help of semigroup operators\nand then solve the variational problems with neural network (NN)\nparameterization. The main advantages are that no mixed second-order derivative\ncomputation is needed during the stochastic gradient descent training and that\nthe boundary conditions are taken into account automatically by the semigroup\noperator. For eigenvalue problems, a primal-dual method is proposed, resolving\nthe constraint with a scalar dual variable. Numerical results are provided to\ndemonstrate the performance of the proposed methods.",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Haoya Li",
      "Lexing Ying"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03480"
  },
  {
    "id": "arXiv:2105.03482",
    "title": "Measuring and Increasing Context Usage in Context-Aware Machine  Translation",
    "abstract": "Recent work in neural machine translation has demonstrated both the necessity\nand feasibility of using inter-sentential context -- context from sentences\nother than those currently being translated. However, while many current\nmethods present model architectures that theoretically can use this extra\ncontext, it is often not clear how much they do actually utilize it at\ntranslation time. In this paper, we introduce a new metric, conditional\ncross-mutual information, to quantify the usage of context by these models.\nUsing this metric, we measure how much document-level machine translation\nsystems use particular varieties of context. We find that target context is\nreferenced more than source context, and that conditioning on a longer context\nhas a diminishing effect on results. We then introduce a new, simple training\nmethod, context-aware word dropout, to increase the usage of context by\ncontext-aware models. Experiments show that our method increases context usage\nand that this reflects on the translation quality according to metrics such as\nBLEU and COMET, as well as performance on anaphoric pronoun resolution and\nlexical cohesion contrastive datasets.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Patrick Fernandes",
      "Kayo Yin",
      "Graham Neubig",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03482"
  },
  {
    "id": "arXiv:2105.03484",
    "title": "Empirical Evaluation of Pre-trained Transformers for Human-Level NLP:  The Role of Sample Size and Dimensionality",
    "abstract": "In human-level NLP tasks, such as predicting mental health, personality, or\ndemographics, the number of observations is often smaller than the standard\n768+ hidden state sizes of each layer within modern transformer-based language\nmodels, limiting the ability to effectively leverage transformers. Here, we\nprovide a systematic study on the role of dimension reduction methods\n(principal components analysis, factorization techniques, or multi-layer\nauto-encoders) as well as the dimensionality of embedding vectors and sample\nsizes as a function of predictive performance. We first find that fine-tuning\nlarge models with a limited amount of data pose a significant difficulty which\ncan be overcome with a pre-trained dimension reduction regime. RoBERTa\nconsistently achieves top performance in human-level tasks, with PCA giving\nbenefit over other reduction methods in better handling users that write longer\ntexts. Finally, we observe that a majority of the tasks achieve results\ncomparable to the best performance with just $\\frac{1}{12}$ of the embedding\ndimensions.",
    "descriptor": "\nComments: 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT)\n",
    "authors": [
      "Adithya V Ganesan",
      "Matthew Matero",
      "Aravind Reddy Ravula",
      "Huy Vu",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03484"
  },
  {
    "id": "arXiv:2105.03489",
    "title": "Reinforcement Learning and Control of a Lower Extremity Exoskeleton for  Squat Assistance",
    "abstract": "A significant challenge for the control of a robotic lower extremity\nrehabilitation exoskeleton is to ensure stability and robustness during\nprogrammed tasks or motions, which is crucial for the safety of the\nmobility-impaired user. Due to various levels of the user's disability, the\nhuman-exoskeleton interaction forces and external perturbations are\nunpredictable and could vary substantially and cause conventional motion\ncontrollers to behave unreliably or the robot to fall down. In this work, we\npropose a new, reinforcement learning-based, motion controller for a lower\nextremity rehabilitation exoskeleton, aiming to perform collaborative squatting\nexercises with efficiency, stability, and strong robustness. Unlike most\nexisting rehabilitation exoskeletons, our exoskeleton has ankle actuation on\nboth sagittal and front planes and is equipped with multiple foot force sensors\nto estimate center of pressure (CoP), an important indicator of system balance.\nThis proposed motion controller takes advantage of the CoP information by\nincorporating it in the state input of the control policy network and adding it\nto the reward during the learning to maintain a well balanced system state\nduring motions. In addition, we use dynamics randomization and adversary force\nperturbations including large human interaction forces during the training to\nfurther improve control robustness. To evaluate the effectiveness of the\nlearning controller, we conduct numerical experiments with different settings\nto demonstrate its remarkable ability on controlling the exoskeleton to\nrepetitively perform well balanced and robust squatting motions under strong\nperturbations and realistic human interaction forces.",
    "descriptor": "",
    "authors": [
      "S. Luo",
      "G. Androwis",
      "S. Adamovich",
      "H. Su",
      "X. Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03489"
  },
  {
    "id": "arXiv:2105.03491",
    "title": "Uniform Convergence, Adversarial Spheres and a Simple Remedy",
    "abstract": "Previous work has cast doubt on the general framework of uniform convergence\nand its ability to explain generalization in neural networks. By considering a\nspecific dataset, it was observed that a neural network completely\nmisclassifies a projection of the training data (adversarial set), rendering\nany existing generalization bound based on uniform convergence vacuous. We\nprovide an extensive theoretical investigation of the previously studied data\nsetting through the lens of infinitely-wide models. We prove that the Neural\nTangent Kernel (NTK) also suffers from the same phenomenon and we uncover its\norigin. We highlight the important role of the output bias and show\ntheoretically as well as empirically how a sensible choice completely mitigates\nthe problem. We identify sharp phase transitions in the accuracy on the\nadversarial set and study its dependency on the training sample size. As a\nresult, we are able to characterize critical sample sizes beyond which the\neffect disappears. Moreover, we study decompositions of a neural network into a\nclean and noisy part by considering its canonical decomposition into its\ndifferent eigenfunctions and show empirically that for too small bias the\nadversarial phenomenon still persists.",
    "descriptor": "",
    "authors": [
      "Gregor Bachmann",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03491"
  },
  {
    "id": "arXiv:2105.03492",
    "title": "Human-Aided Saliency Maps Improve Generalization of Deep Learning",
    "abstract": "Deep learning has driven remarkable accuracy increases in many computer\nvision problems. One ongoing challenge is how to achieve the greatest accuracy\nin cases where training data is limited. A second ongoing challenge is that\ntrained models are sometimes fragile in the sense that the accuracy achieved\ndoes not generalize well, even to new data that is subjectively similar to the\ntraining set. We address these challenges in a novel way, with the first-ever\n(to our knowledge) exploration of encoding human judgement about salient\nregions of images into the training data. We compare the accuracy and\ngeneralization of a state-of-the-art deep learning algorithm for a difficult\nproblem in biometric presentation attack detection when trained on (a) original\nimages with typical data augmentations, and (b) the same original images\ntransformed to encode human judgement about salient image regions. The latter\napproach results in models that achieve higher accuracy and better\ngeneralization, decreasing the error of the LivDet-Iris 2020 winner from 29.78%\nto 16.37%, and achieving impressive generalization in a\nleave-one-attack-type-out evaluation scenario. This work opens a new area of\nstudy for how to embed human intelligence into training strategies for deep\nlearning to achieve high accuracy and generalization in cases of limited\ntraining data.",
    "descriptor": "",
    "authors": [
      "Aidan Boyd",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03492"
  },
  {
    "id": "arXiv:2105.03494",
    "title": "The iWildCam 2021 Competition Dataset",
    "abstract": "Camera traps enable the automatic collection of large quantities of image\ndata. Ecologists use camera traps to monitor animal populations all over the\nworld. In order to estimate the abundance of a species from camera trap data,\necologists need to know not just which species were seen, but also how many\nindividuals of each species were seen. Object detection techniques can be used\nto find the number of individuals in each image. However, since camera traps\ncollect images in motion-triggered bursts, simply adding up the number of\ndetections over all frames is likely to lead to an incorrect estimate.\nOvercoming these obstacles may require incorporating spatio-temporal reasoning\nor individual re-identification in addition to traditional species detection\nand classification.\nWe have prepared a challenge where the training data and test data are from\ndifferent cameras spread across the globe. The set of species seen in each\ncamera overlap, but are not identical. The challenge is to classify species and\ncount individual animals across sequences in the test cameras.",
    "descriptor": "\nComments: FGVC8 Workshop at CVPR 2021. arXiv admin note: substantial text overlap with arXiv:2004.10340\n",
    "authors": [
      "Sara Beery",
      "Arushi Agarwal",
      "Elijah Cole",
      "Vighnesh Birodkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03494"
  },
  {
    "id": "arXiv:2105.03495",
    "title": "Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction  from Language Models",
    "abstract": "Coherent discourse is distinguished from a mere collection of utterances by\nthe satisfaction of a diverse set of constraints, for example choice of\nexpression, logical relation between denoted events, and implicit compatibility\nwith world-knowledge. Do neural language models encode such constraints? We\ndesign an extendable set of test suites addressing different aspects of\ndiscourse and dialogue coherence. Unlike most previous coherence evaluation\nstudies, we address specific linguistic devices beyond sentence order\nperturbations, allowing for a more fine-grained analysis of what constitutes\ncoherence and what neural models trained on a language modelling objective do\nencode. Extending the targeted evaluation paradigm for neural language models\n(Marvin and Linzen, 2018) to phenomena beyond syntax, we show that this\nparadigm is equally suited to evaluate linguistic qualities that contribute to\nthe notion of coherence.",
    "descriptor": "\nComments: Accepted as long paper at NAACL 2021\n",
    "authors": [
      "Anne Beyer",
      "Sharid Lo\u00e1iciga",
      "David Schlangen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03495"
  },
  {
    "id": "arXiv:2105.03500",
    "title": "A Convergent Finite Difference Method for Optimal Transport on the  Sphere",
    "abstract": "We introduce a convergent finite difference method for solving the optimal\ntransportation problem on the sphere. The method applies to both the\ntraditional squared geodesic cost (arising in mesh generation) and a\nlogarithmic cost (arising in the reflector antenna design problem). At each\npoint on the sphere, we replace the surface PDE with a Generated Jacobian\nequation posed on the local tangent plane using geodesic normal coordinates.\nThe discretization is inspired by recent monotone methods for the\nMonge-Amp\\`ere equation, but requires significant adaptations in order to\ncorrectly handle the mix of gradient and Hessian terms appearing inside the\nnonlinear determinant operator, as well as the singular logarithmic cost\nfunction. Numerical results demonstrate the success of this method on a wide\nrange of challenging problems involving both the squared geodesic and the\nlogarithmic cost functions.",
    "descriptor": "\nComments: 34 pages, 21 figures\n",
    "authors": [
      "Brittany Froese Hamfeldt",
      "Axel G. R. Turnquist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03500"
  },
  {
    "id": "arXiv:2105.03502",
    "title": "Conversational Code Analysis: The Future of Secure Coding",
    "abstract": "The area of software development and secure coding can benefit significantly\nfrom advancements in virtual assistants. Research has shown that many coders\nneglect security in favor of meeting deadlines. This shortcoming leaves systems\nvulnerable to attackers. While a plethora of tools are available for\nprogrammers to scan their code for vulnerabilities, finding the right tool can\nbe challenging. It is therefore imperative to adopt measures to get programmers\nto utilize code analysis tools that will help them produce more secure code.\nThis chapter looks at the limitations of existing approaches to secure coding\nand proposes a methodology that allows programmers to scan and fix\nvulnerabilities in program code by communicating with virtual assistants on\ntheir smart devices. With the ubiquitous move towards virtual assistants, it is\nimportant to design systems that are more reliant on voice than on standard\npoint-and-click and keyboard-driven approaches. Consequently, we propose\nMyCodeAnalyzer, a Google Assistant app and code analysis framework, which was\ndesigned to interactively scan program code for vulnerabilities and flaws using\nvoice commands during development. We describe the proposed methodology,\nimplement a prototype, test it on a vulnerable project and present our results.",
    "descriptor": "",
    "authors": [
      "Fitzroy D. Nembhard",
      "Marco M. Carvalho"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03502"
  },
  {
    "id": "arXiv:2105.03503",
    "title": "The Consolation of Network Coding and Partial Protection Techniques to  Optical Transport Networks in Data, Data, Data Era",
    "abstract": "The age of acceleration is taking place, driven by the revolutionary digital\ntransformation creating basically a digital version of our physical world and\nthe currency in that digital space is data. Massive amount of data has been\ngenerated ranging from wearable devices monitoring our physical health every\nsingle millisecond to autonomous vehicles generating roughly 5Tb hourly to even\nastronomical activities producing an order of Exabytes on daily basis and then\nultra-broadband Internet comes into play, moving such data to the cloud.\nInternet traffic therefore has been experiencing explosive growth and in this\ncontext, optical transport networks forming the backbone of the Internet are\npushed for transformation in system capacity. While the intuitive solution of\ndeploying multiple fibers can address the pressing demand for increased\ncapacity, doing so does not bring improvement in economic of scales in terms of\ncost, power consumption and spectral efficiency. This necessitates for a\ndifferent approach so that the fiber capacity could be utilized in a more\nefficient manner. In this paper, we focus on innovative techniques, that is,\nnetwork coding and partial protection, to reduce the effective traffic load in\norder to achieve greater capacity efficiency for optical transport networks.\nSpecifically, the application of network coding is examined by upgrading the\nfunctionalities of intermediate nodes with processing (i.e., encoding and\ndecoding) capabilities. Besides, partial protection relying on the premise of\nproviding just enough bandwidth in case of failure events is investigated for\nsaving the redundant protection capacity. What is more interesting arises when\ncombining both network coding and partial protection and we present insights on\nhow to derive compounding gains in such unique prospect.",
    "descriptor": "\nComments: 5 pages, 5 figures, 2 tables, submitted to a conference\n",
    "authors": [
      "Dao Thanh Hai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03503"
  },
  {
    "id": "arXiv:2105.03505",
    "title": "Unsupervised Cross-Domain Prerequisite Chain Learning using Variational  Graph Autoencoders",
    "abstract": "Learning prerequisite chains is an essential task for efficiently acquiring\nknowledge in both known and unknown domains. For example, one may be an expert\nin the natural language processing (NLP) domain but want to determine the best\norder to learn new concepts in an unfamiliar Computer Vision domain (CV). Both\ndomains share some common concepts, such as machine learning basics and deep\nlearning models. In this paper, we propose unsupervised cross-domain concept\nprerequisite chain learning using an optimized variational graph autoencoder.\nOur model learns to transfer concept prerequisite relations from an\ninformation-rich domain (source domain) to an information-poor domain (target\ndomain), substantially surpassing other baseline models. Also, we expand an\nexisting dataset by introducing two new domains: CV and Bioinformatics (BIO).\nThe annotated data and resources, as well as the code, will be made publicly\navailable.",
    "descriptor": "\nComments: Short paper Accepted by ACL 2021\n",
    "authors": [
      "Irene Li",
      "Vanessa Yan",
      "Tianxiao Li",
      "Rihao Qu",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03505"
  },
  {
    "id": "arXiv:2105.03509",
    "title": "Wyner wiretap-like encoding scheme for cyber-physical systems",
    "abstract": "In this study, the authors consider the problem of exchanging secrete\nmessages in cyber-physical systems (CPSs) without resorting to cryptographic\nsolutions. In particular, they consider a CPS where the networked controller\nwants to send a secrete message to the plant. They show that such a problem can\nbe solved by exploiting a Wyner wiretap-like encoding scheme taking advantage\nof the closed-loop operations typical of feedback control systems.\nSpecifically, by resorting to the control concept of one-step reachable sets,\nthey first show that a wiretap-like encoding scheme exists whenever there is an\nasymmetry in the plant model knowledge available to control system (the\ndefender) and to the eavesdropper. The effectiveness of the proposed scheme is\nconfirmed by means of a numerical example. Finally, they conclude the study by\npresenting open design challenges that can be addressed by the research\ncommunity to improve, in different directions, the secrete message exchange\nproblem in CPSs",
    "descriptor": "",
    "authors": [
      "Walter Lucia",
      "Amr Youssef"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03509"
  },
  {
    "id": "arXiv:2105.03517",
    "title": "Applicability of overlay non-delay tolerant position-based protocols in  highways and urban environments for vanet",
    "abstract": "Vehicular Ad hoc Network (VANET) is a new sort of wireless ad-hoc network.\nVehicle-to-Vehicle (V2V) communication is one of the main communication\nparadigms that provide a level of safety and convenience to drivers and\npassengers on the road. In such an environment, routing data packets is\nchallenging due to frequent changes of network topology because of the highly\ndynamic nature of vehicles. Thus, routing in VANETs requires efficient\nprotocols that guarantee message transmission among vehicles. Numerous routing\nprotocols and algorithms have been proposed or enhanced to solve the\naforementioned problems. Many position-based routing protocols have been\ndeveloped for routing messages that have been identified to be appropriate for\nVANETs. This work explores the performances of selected unicast non-delay\ntolerant overlay position-based routing protocols. The evaluation has been\nconducted in highway and urban environments in two different scenarios. The\nevaluation metrics that are used are Packet Delivery Ratio (PDR), Void Problem\nOccurrence (VPO), and Average Hop Count (AHC).",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Mahmoud Ali Al Shugran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03517"
  },
  {
    "id": "arXiv:2105.03519",
    "title": "Understanding by Understanding Not: Modeling Negation in Language Models",
    "abstract": "Negation is a core construction in natural language. Despite being very\nsuccessful on many tasks, state-of-the-art pre-trained language models often\nhandle negation incorrectly. To improve language models in this regard, we\npropose to augment the language modeling objective with an unlikelihood\nobjective that is based on negated generic sentences from a raw text corpus. By\ntraining BERT with the resulting combined objective we reduce the mean top~1\nerror rate to 4% on the negated LAMA dataset. We also see some improvements on\nthe negated NLI benchmarks.",
    "descriptor": "",
    "authors": [
      "Arian Hosseini",
      "Siva Reddy",
      "Dzmitry Bahdanau",
      "R Devon Hjelm",
      "Alessandro Sordoni",
      "Aaron Courville"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03519"
  },
  {
    "id": "arXiv:2105.03521",
    "title": "Stochastic Properties of EIP-1559 Basefees",
    "abstract": "EIP-1559 is a new proposed pricing mechanism for the Ethereum protocol\ndeveloped to bring stability to fluctuating gas prices. To properly understand\nthis as a stochastic process, it is necessary to develop the mathematical\nfoundations to understand under what conditions the base fee gas price outcomes\nbehave as a stationary process, and when it does not. Understanding these\nmathematical fundamentals is critical to properly engineering a stable system.",
    "descriptor": "",
    "authors": [
      "Ian C. Moore",
      "Jagdeep Sidhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03521"
  },
  {
    "id": "arXiv:2105.03522",
    "title": "On Abstract Machine Semantics for Proto-Quipper-M",
    "abstract": "Quipper is a domain-specific programming language for the description of\nquantum circuits. Because it is implemented as an embedded language in Haskell,\nQuipper is a very practical functional language. However, for the same reason,\nit lacks a formal semantics and it is limited by Haskell's type system. In\nparticular, because Haskell lacks linear types, it is easy to write Quipper\nprograms that violate the non-cloning property of quantum states. In order to\nformalize relevant fragments of Quipper in a type-safe way, the Proto-Quipper\nfamily of research languages has been introduced over the last years. In this\npaper we first review Proto-Quipper-M, an instance of the Proto-Quipper family\nbased on a categorical model for quantum circuits, which features a linear type\nsystem that guarantees that the non-cloning property holds at compile time. We\nthen derive a tentative small-step operational semantics from the big-step\nsemantics of Proto-Quipper-M and we prove that the two are equivalent. After\nproving subject reduction and progress results for the tentative semantics, we\nbuild upon it to obtain a truly small-step semantics in the style of an\nabstract machine, which we eventually prove to be equivalent to the original\nsemantics.",
    "descriptor": "\nComments: 72 pages (34 without appendix), 5 figures\n",
    "authors": [
      "Andrea Colledan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03522"
  },
  {
    "id": "arXiv:2105.03523",
    "title": "Test Suites as a Source of Training Data for Static Analysis Alert  Classifiers",
    "abstract": "Flaw-finding static analysis tools typically generate large volumes of code\nflaw alerts including many false positives. To save on human effort to triage\nthese alerts, a significant body of work attempts to use machine learning to\nclassify and prioritize alerts. Identifying a useful set of training data,\nhowever, remains a fundamental challenge in developing such classifiers in many\ncontexts. We propose using static analysis test suites (i.e., repositories of\n\"benchmark\" programs that are purpose-built to test coverage and precision of\nstatic analysis tools) as a novel source of training data. In a case study, we\ngenerated a large quantity of alerts by executing various static analyzers on\nthe Juliet C/C++ test suite, and we automatically derived ground truth labels\nfor these alerts by referencing the Juliet test suite metadata. Finally, we\nused this data to train classifiers to predict whether an alert is a false\npositive. Our classifiers obtained high precision (90.2%) and recall (88.2%)\nfor a large number of code flaw types on a hold-out test set. This preliminary\nresult suggests that pre-training classifiers on test suite data could help to\njumpstart static analysis alert classification in data-limited contexts.",
    "descriptor": "\nComments: 9 pages, 3 figures, 6 tables, to be published in proceedings of Conference on Automation of Software Test (AST 2021)\n",
    "authors": [
      "Lori Flynn",
      "William Snavely",
      "Zachary Kurtz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03523"
  },
  {
    "id": "arXiv:2105.03531",
    "title": "On the Complexity of Verification of Time-Sensitive Distributed Systems:  Technical Report",
    "abstract": "Time-Sensitive Distributed Systems (TSDS), such as applications using\nautonomous drones, achieve goals under possible environment interference (e.g.,\nwinds). Goals are often specified using explicit time constraints, and,\nmoreover, goals must be satisfied by the system perpetually. For example,\ndrones carrying out the surveillance of some area must always have recent\npictures, i.e., at most M time units old, of some strategic locations. This\npaper proposes a Multiset Rewriting language with explicit time for specifying\nand analyzing TSDSes. We introduce new properties, such as realizability (there\nexists a good trace), survivability (where, in addition, all admissible traces\nare good), recoverability (all compliant traces do not reach\npoints-of-no-return), and reliability (system can always continue functioning\nusing a good trace). A good trace is an infinite trace in which goals are\nperpetually satisfied. We propose a class of systems called Progressing Timed\nSystems (PTS), where intuitively only a finite number of actions can be carried\nout in a bounded time period. We prove that for this class of systems the\nproblems of realizability, recoverability, reliability, and survivability are\nPSPACE-complete. Furthermore, if we impose a bound on time (as in bounded\nmodel-checking), we show that for PTS, realizability becomes NP-complete, while\nsurvivability and reliability problems are in the $\\Delta_2^p$ class of the\npolynomial hierarchy.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1606.07886\n",
    "authors": [
      "Max Kanovich",
      "Tajana Ban Kirigin",
      "Vivek Nigam",
      "Andre Scedrov",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.03531"
  },
  {
    "id": "arXiv:2105.03533",
    "title": "Video Class Agnostic Segmentation with Contrastive Learningfor  Autonomous Driving",
    "abstract": "Semantic segmentation in autonomous driving predominantly focuses on learning\nfrom large-scale data with a closed set of known classes without considering\nunknown objects. Motivated by safety reasons, we address the video class\nagnostic segmentation task, which considers unknown objects outside the closed\nset of known classes in our training data. We propose a novel auxiliary\ncontrastive loss to learn the segmentation of known classes and unknown\nobjects. Unlike previous work in contrastive learning that samples the anchor,\npositive and negative examples on an image level, our contrastive learning\nmethod leverages pixel-wise semantic and temporal guidance. We conduct\nexperiments on Cityscapes-VPS by withholding four classes from training and\nshow an improvement gain for both known and unknown objects segmentation with\nthe auxiliary contrastive loss. We further release a large-scale synthetic\ndataset for different autonomous driving scenarios that includes distinct and\nrare unknown objects. We conduct experiments on the full synthetic dataset and\na reduced small-scale version, and show how contrastive learning is more\neffective in small scale datasets. Our proposed models, dataset, and code will\nbe released at https://github.com/MSiam/video_class_agnostic_segmentation.",
    "descriptor": "",
    "authors": [
      "Mennatullah Siam",
      "Alex Kendall",
      "Martin Jagersand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03533"
  },
  {
    "id": "arXiv:2105.03534",
    "title": "SimJEB: Simulated Jet Engine Bracket Dataset",
    "abstract": "Recent advancements in geometric deep learning have enabled a new class of\nengineering surrogate models; however, few existing shape datasets are\nwell-suited to evaluate them. This paper introduces the Simulated Jet Engine\nBracket Dataset (SimJEB): a new, public collection of crowdsourced mechanical\nbrackets and high-fidelity structural simulations designed specifically for\nsurrogate modeling. SimJEB models are more complex, diverse, and realistic than\nthe synthetically generated datasets commonly used in parametric surrogate\nmodel evaluation. In contrast to existing engineering shape collections,\nSimJEB's models are all designed for the same engineering function and thus\nhave consistent structural loads and support conditions. The models in SimJEB\nwere collected from the original submissions to the GrabCAD Jet Engine Bracket\nChallenge: an open engineering design competition with over 700 hand-designed\nCAD entries from 320 designers representing 56 countries. Each model has been\ncleaned, categorized, meshed, and simulated with finite element analysis\naccording to the original competition specifications. The result is a\ncollection of diverse, high-quality and application-focused designs for\nadvancing geometric deep learning and engineering surrogate models.",
    "descriptor": "",
    "authors": [
      "Eamon Whalen",
      "Azariah Beyene",
      "Caitlin Mueller"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03534"
  },
  {
    "id": "arXiv:2105.03536",
    "title": "Pareto-Optimal Quantized ResNet Is Mostly 4-bit",
    "abstract": "Quantization has become a popular technique to compress neural networks and\nreduce compute cost, but most prior work focuses on studying quantization\nwithout changing the network size. Many real-world applications of neural\nnetworks have compute cost and memory budgets, which can be traded off with\nmodel quality by changing the number of parameters. In this work, we use ResNet\nas a case study to systematically investigate the effects of quantization on\ninference compute cost-quality tradeoff curves. Our results suggest that for\neach bfloat16 ResNet model, there are quantized models with lower cost and\nhigher accuracy; in other words, the bfloat16 compute cost-quality tradeoff\ncurve is Pareto-dominated by the 4-bit and 8-bit curves, with models primarily\nquantized to 4-bit yielding the best Pareto curve. Furthermore, we achieve\nstate-of-the-art results on ImageNet for 4-bit ResNet-50 with\nquantization-aware training, obtaining a top-1 eval accuracy of 77.09%. We\ndemonstrate the regularizing effect of quantization by measuring the\ngeneralization gap. The quantization method we used is optimized for\npracticality: It requires little tuning and is designed with hardware\ncapabilities in mind. Our work motivates further research into optimal numeric\nformats for quantization, as well as the development of machine learning\naccelerators supporting these formats. As part of this work, we contribute a\nquantization library written in JAX, which is open-sourced at\nhttps://github.com/google-research/google-research/tree/master/aqt.",
    "descriptor": "\nComments: 8 pages. Accepted at the Efficient Deep Learning for Computer Vision Workshop at CVPR 2021\n",
    "authors": [
      "AmirAli Abdolrashidi",
      "Lisa Wang",
      "Shivani Agrawal",
      "Jonathan Malmaud",
      "Oleg Rybakov",
      "Chas Leichner",
      "Lukasz Lew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03536"
  },
  {
    "id": "arXiv:2105.03540",
    "title": "An Intelligent Model for Solving Manpower Scheduling Problems",
    "abstract": "The manpower scheduling problem is a critical research field in the resource\nmanagement area. Based on the existing studies on scheduling problem solutions,\nthis paper transforms the manpower scheduling problem into a combinational\noptimization problem under multi-constraint conditions from a new perspective.\nIt also uses logical paradigms to build a mathematical model for problem\nsolution and an improved multi-dimensional evolution algorithm for solving the\nmodel. Moreover, the constraints discussed in this paper basically cover all\nthe requirements of human resource coordination in modern society and are\nsupported by our experiment results. In the discussion part, we compare our\nmodel with other heuristic algorithms or linear programming methods and prove\nthat the model proposed in this paper makes a 25.7% increase in efficiency and\na 17% increase in accuracy at most. In addition, to the numerical solution of\nthe manpower scheduling problem, this paper also studies the algorithm for\nscheduling task list generation and the method of displaying scheduling\nresults. As a result, we not only provide various modifications for the basic\nalgorithm to solve different condition problems but also propose a new\nalgorithm that increases at least 28.91% in time efficiency by comparing with\ndifferent baseline models.",
    "descriptor": "\nComments: none\n",
    "authors": [
      "Lingyu Zhang",
      "Tianyu Liu",
      "Yunhai Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03540"
  },
  {
    "id": "arXiv:2105.03541",
    "title": "Apply Artificial Neural Network to Solving Manpower Scheduling Problem",
    "abstract": "The manpower scheduling problem is a kind of critical combinational\noptimization problem. Researching solutions to scheduling problems can improve\nthe efficiency of companies, hospitals, and other work units. This paper\nproposes a new model combined with deep learning to solve the multi-shift\nmanpower scheduling problem based on the existing research. This model first\nsolves the objective function's optimized value according to the current\nconstraints to find the plan of employee arrangement initially. It will then\nuse the scheduling table generation algorithm to obtain the scheduling result\nin a short time. Moreover, the most prominent feature we propose is that we\nwill use the neural network training method based on the time series to solve\nlong-term and long-period scheduling tasks and obtain manpower arrangement. The\nselection criteria of the neural network and the training process are also\ndescribed in this paper. We demonstrate that our model can make a precise\nforecast based on the improvement of neural networks. This paper also discusses\nthe challenges in the neural network training process and obtains enlightening\nresults after getting the arrangement plan. Our research shows that neural\nnetworks and deep learning strategies have the potential to solve similar\nproblems effectively.",
    "descriptor": "\nComments: none\n",
    "authors": [
      "Tianyu Liu",
      "Lingyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03541"
  },
  {
    "id": "arXiv:2105.03545",
    "title": "The Pony Express Communication Problem",
    "abstract": "We introduce a new problem which we call the Pony Express problem. n robots\nwith differing speeds are situated over some domain. A message is placed at\nsome commonly known point. Robots can acquire the message either by visiting\nits initial position, or by encountering another robot that has already\nacquired it. The robots must collaborate to deliver the message to a given\ndestination. The objective is to deliver the message in minimum time. In this\npaper we study the Pony Express problem on the line where n robots are\narbitrarily deployed along a finite segment. The robots have different speeds\nand can move in both directions. We are interested in both offline centralized\nand online distributed algorithms. In the online case, we assume the robots\nhave limited knowledge of the initial configuration. In particular, the robots\ndo not know the initial positions and speeds of the other robots nor even their\nown position and speed. They do, however, know the direction on the line in\nwhich to find the message and have the ability to compare speeds when they\nmeet.\nFirst, we study the Pony Express problem where the message is initially\nplaced at one endpoint of a segment and must be delivered to the other\nendpoint. We provide an O(n log n) running time offline algorithm as well as an\noptimal online algorithm. Then we study the Half-Broadcast problem where the\nmessage is at the center and must be delivered to either one of the endpoints\nof the segment [-1,1]. We provide an offline algorithm running in O(n^2 log n)\ntime and we provide an online algorithm that attains a competitive ratio of 3/2\nwhich we show is the best possible. Finally, we study the Broadcast problem\nwhere the message is at the center and must be delivered to both endpoints of\nthe segment [-1,1]. Here we give an FPTAS in the offline case and an online\nalgorithm that attains a competitive ratio of 9/5, which we show is tight.",
    "descriptor": "\nComments: 14 pages, 3 figures to be published in IWOCA 2021\n",
    "authors": [
      "Jared Coleman",
      "Evangelos Kranakis",
      "Danny Krizanc",
      "Oscar Morales Ponce"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.03545"
  },
  {
    "id": "arXiv:2105.03546",
    "title": "Scalable, Decentralized Multi-Agent Reinforcement Learning Methods  Inspired by Stigmergy and Ant Colonies",
    "abstract": "Bolstering multi-agent learning algorithms to tackle complex coordination and\ncontrol tasks has been a long-standing challenge of on-going research. Numerous\nmethods have been proposed to help reduce the effects of non-stationarity and\nunscalability. In this work, we investigate a novel approach to decentralized\nmulti-agent learning and planning that attempts to address these two\nchallenges. In particular, this method is inspired by the cohesion,\ncoordination, and behavior of ant colonies. As a result, these algorithms are\ndesigned to be naturally scalable to systems with numerous agents. While no\noptimality is guaranteed, the method is intended to work well in practice and\nscale better in efficacy with the number of agents present than others. The\napproach combines single-agent RL and an ant-colony-inspired decentralized,\nstigmergic algorithm for multi-agent path planning and environment\nmodification. Specifically, we apply this algorithm in a setting where agents\nmust navigate to a goal location, learning to push rectangular boxes into holes\nto yield new traversable pathways. It is shown that while the approach yields\npromising success in this particular environment, it may not be as easily\ngeneralized to others. The algorithm designed is notably scalable to numerous\nagents but is limited in its performance due to its relatively simplistic,\nrule-based approach. Furthermore, the composability of RL-trained policies is\ncalled into question, where, while policies are successful in their training\nenvironments, applying trained policies to a larger-scale, multi-agent\nframework results in unpredictable behavior.",
    "descriptor": "\nComments: 50 pages, 40 figures\n",
    "authors": [
      "Austin Anhkhoi Nguyen"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03546"
  },
  {
    "id": "arXiv:2105.03552",
    "title": "Solving social dilemmas by reasoning about expectations",
    "abstract": "It has been argued that one role of social constructs, such as institutions,\ntrust and norms, is to coordinate the expectations of autonomous entities in\norder to resolve collective action situations (such as collective risk\ndilemmas) through the coordination of behaviour. While much work has addressed\nthe formal representation of these social constructs, in this paper we focus\nspecifically on the formal representation of, and associated reasoning with,\nthe expectations themselves. In particular, we investigate how explicit\nreasoning about expectations can be used to encode both traditional game theory\nsolution concepts and social mechanisms for the social dilemma situation. We\nuse the Collective Action Simulation Platform (CASP) to model a collective risk\ndilemma based on a flood plain scenario and show how using expectations in the\nreasoning mechanisms of the agents making decisions supports the choice of\ncooperative behaviour.",
    "descriptor": "",
    "authors": [
      "Abira Sengupta",
      "Stephen Cranefield",
      "Jeremy Pitt"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.03552"
  },
  {
    "id": "arXiv:2105.03559",
    "title": "Applications of Auction and Mechanism Design in Edge Computing: A Survey",
    "abstract": "Edge computing as a promising technology provides lower latency, more\nefficient transmission, and faster speed of data processing since the edge\nservers are closer to the user devices. Each edge server with limited resources\ncan offload latency-sensitive and computation-intensive tasks from nearby user\ndevices. However, edge computing faces challenges such as resource allocation,\nenergy consumption, security and privacy issues, etc. Auction mechanisms can\nwell characterize bidirectional interactions between edge servers and user\ndevices under the above constraints in edge computing. As demonstrated by the\nexisting works, auction and mechanism design approaches are outstanding on\nachieving optimal allocation strategy while guaranteeing mutual satisfaction\namong edge servers and user devices, especially for scenarios with scarce\nresources. In this paper, we introduce a comprehensive survey of recent\nresearches that apply auction approaches in edge computing. Firstly, a brief\noverview of edge computing including three common edge computing paradigms,\ni.e., cloudlet, fog computing and mobile edge computing, is presented. Then, we\nintroduce fundamentals and backgrounds of auction schemes commonly used in edge\ncomputing systems. After then, a comprehensive survey of applications of\nauction-based approaches applied for edge computing is provided, which is\ncategorized by different auction approaches. Finally, several open challenges\nand promising research directions are discussed.",
    "descriptor": "",
    "authors": [
      "Houming Qiu",
      "Kun Zhu",
      "Nguyen Cong Luong",
      "Changyan Yi",
      "Dusit Niyato",
      "Dong In Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.03559"
  },
  {
    "id": "arXiv:2105.03560",
    "title": "Error analysis of an unfitted HDG method for a class of non-linear  elliptic problems",
    "abstract": "We study Hibridizable Discontinuous Galerkin (HDG) discretizations for a\nclass of non-linear interior elliptic boundary value problems posed in curved\ndomains where both the source term and the diffusion coefficient are\nnon-linear. We consider the cases where the non-linear diffusion coefficient\ndepends on the solution and on the gradient of the solution. To sidestep the\nneed for curved elements, the discrete solution is computed on a polygonal\nsubdomain that is not assumed to interpolate the true boundary, giving rise to\nan unfitted computational mesh. We show that, under mild assumptions on the\nsource term and the computational domain, the discrete systems are well posed.\nFurthermore, we provide a priori error estimates showing that the discrete\nsolution will have optimal order of convergence as long as the distance between\nthe curved boundary and the computational boundary remains of the same order of\nmagnitude as the mesh parameter.",
    "descriptor": "",
    "authors": [
      "Nestor S\u00e1nchez",
      "Tonatiuh S\u00e1nchez-Vizuet",
      "Manuel E. Solano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03560"
  },
  {
    "id": "arXiv:2105.03564",
    "title": "$E^2Coop$: Energy Efficient and Cooperative Obstacle Detection and  Avoidance for UAV Swarms",
    "abstract": "Energy efficiency is of critical importance to trajectory planning for UAV\nswarms in obstacle avoidance. In this paper, we present $E^2Coop$, a new scheme\ndesigned to avoid collisions for UAV swarms by tightly coupling Artificial\nPotential Field (APF) with Particle Swarm Planning (PSO) based trajectory\nplanning. In $E^2Coop$, swarm members perform trajectory planning cooperatively\nto avoid collisions in an energy-efficient manner. $E^2Coop$ exploits the\nadvantages of the active contour model in image processing for trajectory\nplanning. Each swarm member plans its trajectories on the contours of the\nenvironment field to save energy and avoid collisions to obstacles. Swarm\nmembers that fall within the safeguard distance of each other plan their\ntrajectories on different contours to avoid collisions with each other.\nSimulation results demonstrate that $E^2Coop$ can save energy up to 51\\%\ncompared with two state-of-the-art schemes.",
    "descriptor": "\nComments: The 31st International Conference on Automated Planning and Scheduling 2021\n",
    "authors": [
      "Shuangyao Huang",
      "Haibo Zhang",
      "Zhiyi Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03564"
  },
  {
    "id": "arXiv:2105.03567",
    "title": "Multimodal and Contrastive Learning for Click Fraud Detection",
    "abstract": "Advertising click fraud detection plays one of the vital roles in current\nE-commerce websites as advertising is an essential component of its business\nmodel. It aims at, given a set of corresponding features, e.g., demographic\ninformation of users and statistical features of clicks, predicting whether a\nclick is fraudulent or not in the community. Recent efforts attempted to\nincorporate attributed behavior sequence and heterogeneous network for\nextracting complex features of users and achieved significant effects on click\nfraud detection. In this paper, we propose a Multimodal and Contrastive\nlearning network for Click Fraud detection (MCCF). Specifically, motivated by\nthe observations on differences of demographic information, behavior sequences\nand media relationship between fraudsters and genuine users on E-commerce\nplatform, MCCF jointly utilizes wide and deep features, behavior sequence and\nheterogeneous network to distill click representations. Moreover, these three\nmodules are integrated by contrastive learning and collaboratively contribute\nto the final predictions. With the real-world datasets containing 2.54 million\nclicks on Alibaba platform, we investigate the effectiveness of MCCF. The\nexperimental results show that the proposed approach is able to improve AUC by\n7.2% and F1-score by 15.6%, compared with the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to DeMal@WWW 2021\n",
    "authors": [
      "Weibin Li",
      "Qiwei Zhong",
      "Qingyang Zhao",
      "Hongchun Zhang",
      "Xiaonan Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03567"
  },
  {
    "id": "arXiv:2105.03569",
    "title": "Improving Robustness for Pose Estimation via Stable Heatmap Regression",
    "abstract": "Deep learning methods have achieved excellent performance in pose estimation,\nbut the lack of robustness causes the keypoints to change drastically between\nsimilar images. In view of this problem, a stable heatmap regression method is\nproposed to alleviate network vulnerability to small perturbations. We utilize\nthe correlation between different rows and columns in a heatmap to alleviate\nthe multi-peaks problem, and design a highly differentiated heatmap regression\nto make a keypoint discriminative from surrounding points. A maximum stability\ntraining loss is used to simplify the optimization difficulty when minimizing\nthe prediction gap of two similar images. The proposed method achieves a\nsignificant advance in robustness over state-of-the-art approaches on two\nbenchmark datasets and maintains high performance.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Yumeng Zhang",
      "Li Chen",
      "Yufeng Liu",
      "Xiaoyan Guo",
      "Wen Zheng",
      "Junhai Yong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03569"
  },
  {
    "id": "arXiv:2105.03570",
    "title": "Domain-Specific Suppression for Adaptive Object Detection",
    "abstract": "Domain adaptation methods face performance degradation in object detection,\nas the complexity of tasks require more about the transferability of the model.\nWe propose a new perspective on how CNN models gain the transferability,\nviewing the weights of a model as a series of motion patterns. The directions\nof weights, and the gradients, can be divided into domain-specific and\ndomain-invariant parts, and the goal of domain adaptation is to concentrate on\nthe domain-invariant direction while eliminating the disturbance from\ndomain-specific one. Current UDA object detection methods view the two\ndirections as a whole while optimizing, which will cause domain-invariant\ndirection mismatch even if the output features are perfectly aligned. In this\npaper, we propose the domain-specific suppression, an exemplary and\ngeneralizable constraint to the original convolution gradients in\nbackpropagation to detach the two parts of directions and suppress the\ndomain-specific one. We further validate our theoretical analysis and methods\non several domain adaptive object detection tasks, including weather, camera\nconfiguration, and synthetic to real-world adaptation. Our experiment results\nshow significant advance over the state-of-the-art methods in the UDA object\ndetection field, performing a promotion of $10.2\\sim12.2\\%$ mAP on all these\ndomain adaptation scenarios.",
    "descriptor": "\nComments: Accepted in CVPR 2021\n",
    "authors": [
      "Yu Wang",
      "Rui Zhang",
      "Shuo Zhang",
      "Miao Li",
      "YangYang Xia",
      "XiShan Zhang",
      "ShaoLi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03570"
  },
  {
    "id": "arXiv:2105.03571",
    "title": "Comprehensive Study: How the Context Information of Different  Granularity Affects Dialogue State Tracking?",
    "abstract": "Dialogue state tracking (DST) plays a key role in task-oriented dialogue\nsystems to monitor the user's goal. In general, there are two strategies to\ntrack a dialogue state: predicting it from scratch and updating it from\nprevious state. The scratch-based strategy obtains each slot value by inquiring\nall the dialogue history, and the previous-based strategy relies on the current\nturn dialogue to update the previous dialogue state. However, it is hard for\nthe scratch-based strategy to correctly track short-dependency dialogue state\nbecause of noise; meanwhile, the previous-based strategy is not very useful for\nlong-dependency dialogue state tracking. Obviously, it plays different roles\nfor the context information of different granularity to track different kinds\nof dialogue states. Thus, in this paper, we will study and discuss how the\ncontext information of different granularity affects dialogue state tracking.\nFirst, we explore how greatly different granularities affect dialogue state\ntracking. Then, we further discuss how to combine multiple granularities for\ndialogue state tracking. Finally, we apply the findings about context\ngranularity to few-shot learning scenario. Besides, we have publicly released\nall codes\\footnote{\\url{https://anonymous}}.",
    "descriptor": "\nComments: Accepted as long paper at main conference of ACL 2021\n",
    "authors": [
      "Puhai Yang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03571"
  },
  {
    "id": "arXiv:2105.03572",
    "title": "Blockchain Systems, Technologies and Applications: A Methodology  Perspective",
    "abstract": "In the past decade, blockchain has shown a promising vision greatly to build\nthe trust without any powerful third party in a secure, decentralized and\nsalable manner. However, due to the wide application and future development\nfrom cryptocurrency to Internet of Things, blockchain is an extremely complex\nsystem enabling integration with mathematics, finance, computer science,\ncommunication and network engineering, etc. As a result, it is a challenge for\nengineer, expert and researcher to fully understand the blockchain process in a\nsystematic view from top to down. First, this article introduces how blockchain\nworks, the research activity and challenge, and illustrates the roadmap\ninvolving the classic methodology with typical blockchain use cases and topics.\nSecond, in blockchain system, how to adopt stochastic process, game theory,\noptimization, machine learning and cryptography to study blockchain running\nprocess and design blockchain protocol/algorithm are discussed in details.\nMoreover, the advantage and limitation using these methods are also summarized\nas the guide of future work to further considered. Finally, some remaining\nproblems from technical, commercial and political views are discussed as the\nopen issues. The main findings of this article will provide an overview in a\nmethodology perspective to study theoretical model for blockchain fundamentals\nunderstanding, design network service for blockchain-based mechanisms and\nalgorithms, as well as apply blockchain for Internet of Things, etc.",
    "descriptor": "",
    "authors": [
      "Bin Cao",
      "Zixin Wang",
      "Long Zhang",
      "Daquan Feng",
      "Mugen Peng",
      "Lei Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03572"
  },
  {
    "id": "arXiv:2105.03573",
    "title": "Survey of Parallel A* in Rust",
    "abstract": "A* is one of the most popular Best First Search (BFS) techniques for graphs.\nIt combines the cost-based search of Breadth First Search with a computed\nheuristic for each node to attempt to locate the goal path faster than\ntraditional Breadth First Search or Depth First Search techniques. However, A*\nis a sequential algorithm. The standard implementation only runs in one thread.\nThere are a few attempts to get A* to leverage multiple threads. Centralized\n(SPA*) and Decentralized (DPA*, HDA*) methods are the most standard attempts,\nwith the most unique and modern method being massively-parallel A* (MPA* or\nGA*). We will attempt an implementation of each in Rust to determine if there\nis a performance boost, and which one has the best performance.",
    "descriptor": "",
    "authors": [
      "Brett Fazio",
      "Ellie Kozlowski",
      "Dylan Ochoa",
      "Blake Robertson",
      "Idel Martinez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.03573"
  },
  {
    "id": "arXiv:2105.03577",
    "title": "Joint Beamforming and Reconfigurable Intelligent Surface Design for  Two-Way Relay Networks",
    "abstract": "In this paper, we consider a reconfigurable intelligent surface\n(RIS)-assisted two-way relay network, in which two users exchange information\nthrough the base station (BS) with the help of an RIS. By jointly designing the\nphase shifts at the RIS and beamforming matrix at the BS, our objective is to\nmaximize the minimum signal-to-noise ratio (SNR) of the two users, under the\ntransmit power constraint at the BS. We first consider the single-antenna BS\ncase, and propose two algorithms to design the RIS phase shifts and the BS\npower amplification parameter, namely the SNR-upper-bound-maximization (SUM)\nmethod, and genetic-SNR-maximization (GSM) method. When there are multiple\nantennas at the BS, the optimization problem can be approximately addressed by\nsuccessively solving two decoupled subproblems, one to optimize the RIS phase\nshifts, the other to optimize the BS beamforming matrix. The first subproblem\ncan be solved by using SUM or GSM method, while the second subproblem can be\nsolved by using optimized beamforming or maximum-ratio-beamforming method. The\nproposed algorithms have been verified through numerical results with\ncomputational complexity analysis.",
    "descriptor": "",
    "authors": [
      "Jun Wang",
      "Ying-Chang Liang",
      "Jingon Joung",
      "Xiaojun Yuan",
      "Xinguo Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03577"
  },
  {
    "id": "arXiv:2105.03578",
    "title": "Learning to Predict Repeatability of Interest Points",
    "abstract": "Many robotics applications require interest points that are highly repeatable\nunder varying viewpoints and lighting conditions. However, this requirement is\nvery challenging as the environment changes continuously and indefinitely,\nleading to appearance changes of interest points with respect to time. This\npaper proposes to predict the repeatability of an interest point as a function\nof time, which can tell us the lifespan of the interest point considering daily\nor seasonal variation. The repeatability predictor (RP) is formulated as a\nregressor trained on repeated interest points from multiple viewpoints over a\nlong period of time. Through comprehensive experiments, we demonstrate that our\nRP can estimate when a new interest point is repeated, and also highlight an\ninsightful analysis about this problem. For further comparison, we apply our RP\nto the map summarization under visual localization framework, which builds a\ncompact representation of the full context map given the query time. The\nexperimental result shows a careful selection of potentially repeatable\ninterest points predicted by our RP can significantly mitigate the degeneration\nof localization accuracy from map summarization.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Anh-Dzung Doan",
      "Daniyar Turmukhambetov",
      "Yasir Latif",
      "Tat-Jun Chin",
      "Soohyun Bae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03578"
  },
  {
    "id": "arXiv:2105.03579",
    "title": "Unsupervised Remote Sensing Super-Resolution via Migration Image Prior",
    "abstract": "Recently, satellites with high temporal resolution have fostered wide\nattention in various practical applications. Due to limitations of bandwidth\nand hardware cost, however, the spatial resolution of such satellites is\nconsiderably low, largely limiting their potentials in scenarios that require\nspatially explicit information. To improve image resolution, numerous\napproaches based on training low-high resolution pairs have been proposed to\naddress the super-resolution (SR) task. Despite their success, however,\nlow/high spatial resolution pairs are usually difficult to obtain in satellites\nwith a high temporal resolution, making such approaches in SR impractical to\nuse. In this paper, we proposed a new unsupervised learning framework, called\n\"MIP\", which achieves SR tasks without low/high resolution image pairs. First,\nrandom noise maps are fed into a designed generative adversarial network (GAN)\nfor reconstruction. Then, the proposed method converts the reference image to\nlatent space as the migration image prior. Finally, we update the input noise\nvia an implicit method, and further transfer the texture and structured\ninformation from the reference image. Extensive experimental results on the\nDraper dataset show that MIP achieves significant improvements over\nstate-of-the-art methods both quantitatively and qualitatively. The proposed\nMIP is open-sourced at this http URL",
    "descriptor": "\nComments: 6 pages, 4 figures. IEEE International Conference on Multimedia and Expo (ICME) 2021\n",
    "authors": [
      "Jiaming Wang",
      "Zhenfeng Shao",
      "Tao Liu",
      "Xiao Huang",
      "Ruiqian Zhang",
      "Yu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.03579"
  },
  {
    "id": "arXiv:2105.03581",
    "title": "Distortion-Based Outer-Bounds for Channels with Rate-Limited Feedback",
    "abstract": "We present a new technique to obtain outer-bounds on the capacity region of\nnetworks with ultra low-rate feedback. We establish a connection between the\nachievable rates in the forward channel and the minimum distortion that can be\nattained over the feedback channel.",
    "descriptor": "\nComments: To be presented at IEEE International Symposium on Information Theory (ISIT) 2021\n",
    "authors": [
      "Alireza Vahid"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03581"
  },
  {
    "id": "arXiv:2105.03582",
    "title": "Sign-Agnostic CONet: Learning Implicit Surface Reconstructions by  Sign-Agnostic Optimization of Convolutional Occupancy Networks",
    "abstract": "Surface reconstruction from point clouds is a fundamental problem in the\ncomputer vision and graphics community. Recent state-of-the-arts solve this\nproblem by individually optimizing each local implicit field during inference.\nWithout considering the geometric relationships between local fields, they\ntypically require accurate normals to avoid the sign conflict problem in\noverlapping regions of local fields, which severely limits their applicability\nto raw scans where surface normals could be unavailable. Although SAL breaks\nthis limitation via sign-agnostic learning, it is still unexplored that how to\nextend this pipeline to local shape modeling. To this end, we propose to learn\nimplicit surface reconstruction by sign-agnostic optimization of convolutional\noccupancy networks, to simultaneously achieve advanced scalability, generality,\nand applicability in a unified framework. In the paper, we also show this goal\ncan be effectively achieved by a simple yet effective design, which optimizes\nthe occupancy fields that are conditioned on convolutional features from an\nhourglass network architecture with an unsigned binary cross-entropy loss.\nExtensive experimental comparison with previous state-of-the-arts on both\nobject-level and scene-level datasets demonstrate the superior accuracy of our\napproach for surface reconstruction from un-orientated point clouds.",
    "descriptor": "\nComments: 18 pages; 14 figures; 5 tables\n",
    "authors": [
      "Jiapeng Tang",
      "Jiabao Lei",
      "Dan Xu",
      "Feiying Ma",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03582"
  },
  {
    "id": "arXiv:2105.03588",
    "title": "Facial Emotion Recognition: State of the Art Performance on FER2013",
    "abstract": "Facial emotion recognition (FER) is significant for human-computer\ninteraction such as clinical practice and behavioral description. Accurate and\nrobust FER by computer models remains challenging due to the heterogeneity of\nhuman faces and variations in images such as different facial pose and\nlighting. Among all techniques for FER, deep learning models, especially\nConvolutional Neural Networks (CNNs) have shown great potential due to their\npowerful automatic feature extraction and computational efficiency. In this\nwork, we achieve the highest single-network classification accuracy on the\nFER2013 dataset. We adopt the VGGNet architecture, rigorously fine-tune its\nhyperparameters, and experiment with various optimization methods. To our best\nknowledge, our model achieves state-of-the-art single-network accuracy of 73.28\n% on FER2013 without using extra training data.",
    "descriptor": "\nComments: 9 pages, 5 figures, 2 tables\n",
    "authors": [
      "Yousif Khaireddin",
      "Zhuofa Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03588"
  },
  {
    "id": "arXiv:2105.03589",
    "title": "Relay Assisted Underlay Cognitive Radio Networks with Multiple Users",
    "abstract": "In this letter, we consider an underlay cognitive radio network assisted by\ndual-hop decode-and-forward (DF) relaying. For a general multi-user network, we\nadopt a max-min fairness relay selection scheme and analyse the outage\nprobability when the channels are subject to independent and non-identical\nNakagami-m fading. The relay network operates within the constraint imposed on\nthe peak interference power tolerable by the primary receiver. We then analyse\nthe asymptotic outage probability performance and illustrate the existence of\ni) the full-diversity order when the interference level at the primary user\nincreases proportionally with the relay transmit power; and ii) an outage floor\nwhen the transmit powers of the relays are restricted by the primary receiver.\nWe also analyse the outage probability with imperfect channel state information\n(CSI) and the average throughput over Rayleigh fading channels. Illustrative\nanalytical results are accurately validated by numerical simulations.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Lanwei Zhang",
      "Rajitha Senanayake",
      "Saman Atapattu",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.03589"
  },
  {
    "id": "arXiv:2105.03591",
    "title": "Loss Tolerant Federated Learning",
    "abstract": "Federated learning has attracted attention in recent years for\ncollaboratively training data on distributed devices with privacy-preservation.\nThe limited network capacity of mobile and IoT devices has been seen as one of\nthe major challenges for cross-device federated learning. Recent solutions have\nbeen focusing on threshold-based client selection schemes to guarantee the\ncommunication efficiency. However, we find this approach can cause biased\nclient selection and results in deteriorated performance. Moreover, we find\nthat the challenge of network limit may be overstated in some cases and the\npacket loss is not always harmful. In this paper, we explore the loss tolerant\nfederated learning (LT-FL) in terms of aggregation, fairness, and\npersonalization. We use ThrowRightAway (TRA) to accelerate the data uploading\nfor low-bandwidth-devices by intentionally ignoring some packet losses. The\nresults suggest that, with proper integration, TRA and other algorithms can\ntogether guarantee the personalization and fairness performance in the face of\npacket loss below a certain fraction (10%-30%).",
    "descriptor": "",
    "authors": [
      "Pengyuan Zhou",
      "Pei Fang",
      "Pan Hui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03591"
  },
  {
    "id": "arXiv:2105.03592",
    "title": "De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks",
    "abstract": "Machine learning techniques have been widely applied to various applications.\nHowever, they are potentially vulnerable to data poisoning attacks, where\nsophisticated attackers can disrupt the learning procedure by injecting a\nfraction of malicious samples into the training dataset. Existing defense\ntechniques against poisoning attacks are largely attack-specific: they are\ndesigned for one specific type of attacks but do not work for other types,\nmainly due to the distinct principles they follow. Yet few general defense\nstrategies have been developed. In this paper, we propose De-Pois, an\nattack-agnostic defense against poisoning attacks. The key idea of De-Pois is\nto train a mimic model the purpose of which is to imitate the behavior of the\ntarget model trained by clean samples. We take advantage of Generative\nAdversarial Networks (GANs) to facilitate informative training data\naugmentation as well as the mimic model construction. By comparing the\nprediction differences between the mimic model and the target model, De-Pois is\nthus able to distinguish the poisoned samples from clean ones, without explicit\nknowledge of any ML algorithms or types of poisoning attacks. We implement four\ntypes of poisoning attacks and evaluate De-Pois with five typical defense\nmethods on different realistic datasets. The results demonstrate that De-Pois\nis effective and efficient for detecting poisoned data against all the four\ntypes of poisoning attacks, with both the accuracy and F1-score over 0.9 on\naverage.",
    "descriptor": "\nComments: To be published in IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Jian Chen",
      "Xuxin Zhang",
      "Rui Zhang",
      "Chen Wang",
      "Ling Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03592"
  },
  {
    "id": "arXiv:2105.03594",
    "title": "Learning stochastic decision trees",
    "abstract": "We give a quasipolynomial-time algorithm for learning stochastic decision\ntrees that is optimally resilient to adversarial noise. Given an\n$\\eta$-corrupted set of uniform random samples labeled by a size-$s$ stochastic\ndecision tree, our algorithm runs in time\n$n^{O(\\log(s/\\varepsilon)/\\varepsilon^2)}$ and returns a hypothesis with error\nwithin an additive $2\\eta + \\varepsilon$ of the Bayes optimal. An additive\n$2\\eta$ is the information-theoretic minimum.\nPreviously no non-trivial algorithm with a guarantee of $O(\\eta) +\n\\varepsilon$ was known, even for weaker noise models. Our algorithm is\nfurthermore proper, returning a hypothesis that is itself a decision tree;\npreviously no such algorithm was known even in the noiseless setting.",
    "descriptor": "\nComments: To appear in ICALP 2021\n",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03594"
  },
  {
    "id": "arXiv:2105.03595",
    "title": "HiTyper: A Hybrid Static Type Inference Framework with Neural Prediction",
    "abstract": "Type inference for dynamic programming languages is an important yet\nchallenging task. By leveraging the natural language information of existing\nhuman annotations, deep neural networks outperform other traditional techniques\nand become the state-of-the-art (SOTA) in this task. However, they are facing\nsome new challenges, such as fixed type set, type drift, type correctness, and\ncomposite type prediction. To mitigate the challenges, in this paper, we\npropose a hybrid type inference framework named HiTyper, which integrates\nstatic inference into deep learning (DL) models for more accurate type\nprediction. Specifically, HiTyper creates a new syntax graph for each program,\ncalled type graph, illustrating the type flow among all variables in the\nprogram. Based on the type graph, HiTyper statically infers the types of the\nvariables with appropriate static constraints. HiTyper then adopts a SOTA DL\nmodel to predict the types of other variables that cannot be inferred\nstatically, during which process a type correction algorithm is employed to\nvalidate and correct the types recommended by the DL model. Extensive\nexperiments show that HiTyper outperforms the SOTA DL approach by 12.7% in\nterms of top-1 F1-score. Moreover, HiTyper filters out 50.6% of incorrect\ncandidate types recommended by the SOTA DL model, indicating that HiTyper could\nimprove the correctness of predicted types. Case studies also demonstrate the\ncapability of HiTyper in alleviating the fixed type set issue, and in handling\ntype drift and complicated types such as composite data types.",
    "descriptor": "",
    "authors": [
      "Yun Peng",
      "Zongjie Li",
      "Cuiyun Gao",
      "Bowei Gao",
      "David Lo",
      "Michael Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.03595"
  },
  {
    "id": "arXiv:2105.03596",
    "title": "Dynamic-OFA: Runtime DNN Architecture Switching for Performance Scaling  on Heterogeneous Embedded Platforms",
    "abstract": "Mobile and embedded platforms are increasingly required to efficiently\nexecute computationally demanding DNNs across heterogeneous processing\nelements. At runtime, the available hardware resources to DNNs can vary\nconsiderably due to other concurrently running applications. The performance\nrequirements of the applications could also change under different scenarios.\nTo achieve the desired performance, dynamic DNNs have been proposed in which\nthe number of channels/layers can be scaled in real time to meet different\nrequirements under varying resource constraints. However, the training process\nof such dynamic DNNs can be costly, since platform-aware models of different\ndeployment scenarios must be retrained to become dynamic. This paper proposes\nDynamic-OFA, a novel dynamic DNN approach for state-of-the-art platform-aware\nNAS models (i.e. Once-for-all network (OFA)). Dynamic-OFA pre-samples a family\nof sub-networks from a static OFA backbone model, and contains a runtime\nmanager to choose different sub-networks under different runtime environments.\nAs such, Dynamic-OFA does not need the traditional dynamic DNN training\npipeline. Compared to the state-of-the-art, our experimental results using\nImageNet on a Jetson Xavier NX show that the approach is up to 3.5x (CPU), 2.4x\n(GPU) faster for similar ImageNet Top-1 accuracy, or 3.8% (CPU), 5.1% (GPU)\nhigher accuracy at similar latency.",
    "descriptor": "\nComments: Accepted at CVPR ECV Workshop 2021\n",
    "authors": [
      "Wei Lou",
      "Lei Xun",
      "Amin Sabet",
      "Jia Bi",
      "Jonathon Hare",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03596"
  },
  {
    "id": "arXiv:2105.03598",
    "title": "Pure Exploration Bandit Problem with General Reward Functions Depending  on Full Distributions",
    "abstract": "In this paper, we study the pure exploration bandit model on general\ndistribution functions, which means that the reward function of each arm\ndepends on the whole distribution, not only its mean. We adapt the racing\nframework and LUCB framework to solve this problem, and design algorithms for\nestimating the value of the reward functions with different types of\ndistributions. Then we show that our estimation methods have correctness\nguarantee with proper parameters, and obtain sample complexity upper bounds for\nthem. Finally, we discuss about some important applications and their\ncorresponding solutions under our learning framework.",
    "descriptor": "",
    "authors": [
      "Siwei Wang",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03598"
  },
  {
    "id": "arXiv:2105.03599",
    "title": "Improving Document Representations by Generating Pseudo Query Embeddings  for Dense Retrieval",
    "abstract": "Recently, the retrieval models based on dense representations have been\ngradually applied in the first stage of the document retrieval tasks, showing\nbetter performance than traditional sparse vector space models. To obtain high\nefficiency, the basic structure of these models is Bi-encoder in most cases.\nHowever, this simple structure may cause serious information loss during the\nencoding of documents since the queries are agnostic. To address this problem,\nwe design a method to mimic the queries on each of the documents by an\niterative clustering process and represent the documents by multiple pseudo\nqueries (i.e., the cluster centroids). To boost the retrieval process using\napproximate nearest neighbor search library, we also optimize the matching\nfunction with a two-step score calculation procedure. Experimental results on\nseveral popular ranking and QA datasets show that our model can achieve\nstate-of-the-art results.",
    "descriptor": "\nComments: 11 pages, 2 figures, Accepted by ACL 2021\n",
    "authors": [
      "Hongyin Tang",
      "Xingwu Sun",
      "Beihong Jin",
      "Jingang Wang",
      "Fuzheng Zhang",
      "Wei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03599"
  },
  {
    "id": "arXiv:2105.03600",
    "title": "Incremental Training and Group Convolution Pruning for Runtime DNN  Performance Scaling on Heterogeneous Embedded Platforms",
    "abstract": "Inference for Deep Neural Networks is increasingly being executed locally on\nmobile and embedded platforms due to its advantages in latency, privacy and\nconnectivity. Since modern System on Chips typically execute a combination of\ndifferent and dynamic workloads concurrently, it is challenging to consistently\nmeet inference time/energy budget at runtime because of the local computing\nresources available to the DNNs vary considerably. To address this challenge, a\nvariety of dynamic DNNs were proposed. However, these works have significant\nmemory overhead, limited runtime recoverable compression rate and narrow\ndynamic ranges of performance scaling. In this paper, we present a dynamic DNN\nusing incremental training and group convolution pruning. The channels of the\nDNN convolution layer are divided into groups, which are then trained\nincrementally. At runtime, following groups can be pruned for inference\ntime/energy reduction or added back for accuracy recovery without model\nretraining. In addition, we combine task mapping and Dynamic Voltage Frequency\nScaling (DVFS) with our dynamic DNN to deliver finer trade-off between accuracy\nand time/power/energy over a wider dynamic range. We illustrate the approach by\nmodifying AlexNet for the CIFAR10 image dataset and evaluate our work on two\nheterogeneous hardware platforms: Odroid XU3 (ARM big.LITTLE CPUs) and Nvidia\nJetson Nano (CPU and GPU). Compared to the existing works, our approach can\nprovide up to 2.36x (energy) and 2.73x (time) wider dynamic range with a 2.4x\nsmaller memory footprint at the same compression rate. It achieved 10.6x\n(energy) and 41.6x (time) wider dynamic range by combining with task mapping\nand DVFS.",
    "descriptor": "\nComments: Accepted at ACM/IEEE Workshop on Machine Learning for CAD (MLCAD) 2019\n",
    "authors": [
      "Lei Xun",
      "Long Tran-Thanh",
      "Bashir M Al-Hashimi",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03600"
  },
  {
    "id": "arXiv:2105.03603",
    "title": "Learning to Detect an Odd Restless Markov Arm with a Trembling Hand",
    "abstract": "This paper studies the problem of finding an anomalous arm in a multi-armed\nbandit when (a) each arm is a finite-state Markov process, and (b) the arms are\nrestless. Here, anomaly means that the transition probability matrix (TPM) of\none of the arms (the odd arm) is different from the common TPM of each of the\nnon-odd arms. The TPMs are unknown to a decision entity that wishes to find the\nindex of the odd arm as quickly as possible, subject to an upper bound on the\nerror probability. We derive a problem instance specific asymptotic lower bound\non the expected time required to find the odd arm index, where the asymptotics\nis as the error probability vanishes. Further, we devise a policy based on the\nprinciple of certainty equivalence, and demonstrate that under a continuous\nselection assumption and a certain regularity assumption on the TPMs, the\npolicy achieves the lower bound arbitrarily closely. Thus, while the lower\nbound is shown for all problem instances, the upper bound is shown only for\nthose problem instances satisfying the regularity assumption. Our achievability\nanalysis is based on resolving the identifiability problem in the context of a\ncertain countable-state controlled Markov process.",
    "descriptor": "\nComments: A shorter version of this manuscript has been accepted for presentation at the 2021 IEEE International Symposium on Information Theory. This manuscript contains the proofs of all the main results\n",
    "authors": [
      "P. N. Karthik",
      "Rajesh Sundaresan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03603"
  },
  {
    "id": "arXiv:2105.03606",
    "title": "On Multi-Channel Huffman Codes for Asymmetric-Alphabet Channels",
    "abstract": "Zero-error single-channel source coding has been studied extensively over the\npast decades. Its natural multi-channel generalization is however not well\ninvestigated. While the special case with multiple symmetric-alphabet channels\nwas studied a decade ago, codes in such setting have no advantage over\nsingle-channel codes in data compression, making them worthless in most\napplications. With essentially no development since the last decade, in this\npaper, we break the stalemate by showing that it is possible to beat\nsingle-channel source codes in terms of compression assuming\nasymmetric-alphabet channels. We present the multi-channel analog of several\nclassical results in single-channel source coding, such as that a multi-channel\nHuffman code is an optimal tree-decodable code. We also show some evidences\nthat finding an efficient construction of multi-channel Huffman codes may be\nhard. Nevertheless, we propose a suboptimal code construction whose redundancy\nis guaranteed to be no larger than that of an optimal single-channel source\ncode.",
    "descriptor": "\nComments: full version of the ISIT 2021 paper\n",
    "authors": [
      "Hoover H. F. Yin",
      "Xishi Wang",
      "Ka Hei Ng",
      "Russell W. F. Lai",
      "Lucien K. L. Ng",
      "Jack P. K. Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03606"
  },
  {
    "id": "arXiv:2105.03608",
    "title": "Optimising Resource Management for Embedded Machine Learning",
    "abstract": "Machine learning inference is increasingly being executed locally on mobile\nand embedded platforms, due to the clear advantages in latency, privacy and\nconnectivity. In this paper, we present approaches for online resource\nmanagement in heterogeneous multi-core systems and show how they can be applied\nto optimise the performance of machine learning workloads. Performance can be\ndefined using platform-dependent (e.g. speed, energy) and platform-independent\n(accuracy, confidence) metrics. In particular, we show how a Deep Neural\nNetwork (DNN) can be dynamically scalable to trade-off these various\nperformance metrics. Achieving consistent performance when executing on\ndifferent platforms is necessary yet challenging, due to the different\nresources provided and their capability, and their time-varying availability\nwhen executing alongside other workloads. Managing the interface between\navailable hardware resources (often numerous and heterogeneous in nature),\nsoftware requirements, and user experience is increasingly complex.",
    "descriptor": "\nComments: Accepted at DATE 2020\n",
    "authors": [
      "Lei Xun",
      "Long Tran-Thanh",
      "Bashir M Al-Hashimi",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03608"
  },
  {
    "id": "arXiv:2105.03611",
    "title": "360NorVic: 360-Degree Video Classification from Mobile Encrypted Video  Traffic",
    "abstract": "Streaming 360{\\deg} video demands high bandwidth and low latency, and poses\nsignificant challenges to Internet Service Providers (ISPs) and Mobile Network\nOperators (MNOs). The identification of 360{\\deg} video traffic can therefore\nbenefits fixed and mobile carriers to optimize their network and provide better\nQuality of Experience (QoE) to the user. However, end-to-end encryption of\nnetwork traffic has obstructed identifying those 360{\\deg} videos from regular\nvideos. As a solution this paper presents 360NorVic, a near-realtime and\noffline Machine Learning (ML) classification engine to distinguish 360{\\deg}\nvideos from regular videos when streamed from mobile devices. We collect packet\nand flow level data for over 800 video traces from YouTube & Facebook\naccounting for 200 unique videos under varying streaming conditions. Our\nresults show that for near-realtime and offline classification at packet level,\naverage accuracy exceeds 95%, and that for flow level, 360NorVic achieves more\nthan 92% average accuracy. Finally, we pilot our solution in the commercial\nnetwork of a large MNO showing the feasibility and effectiveness of 360NorVic\nin production settings.",
    "descriptor": "\nComments: 7 pages, 15 figures, accepted in Workshop on Network and OperatingSystem Support for Digital Audio and Video (NOSSDAV 21)\n",
    "authors": [
      "Chamara Kattadige",
      "Aravindh Raman",
      "Kanchana Thilakarathna",
      "Andra Lutu",
      "Diego Perino"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.03611"
  },
  {
    "id": "arXiv:2105.03616",
    "title": "Interpretable Mixture Density Estimation by use of Differentiable  Tree-module",
    "abstract": "In order to develop reliable services using machine learning, it is important\nto understand the uncertainty of the model outputs. Often the probability\ndistribution that the prediction target follows has a complex shape, and a\nmixture distribution is assumed as a distribution that uncertainty follows.\nSince the output of mixture density estimation is complicated, its\ninterpretability becomes important when considering its use in real services.\nIn this paper, we propose a method for mixture density estimation that utilizes\nan interpretable tree structure. Further, a fast inference procedure based on\ntime-invariant information cache achieves both high speed and interpretability.",
    "descriptor": "",
    "authors": [
      "Ryuichi Kanoh",
      "Tomu Yanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03616"
  },
  {
    "id": "arXiv:2105.03619",
    "title": "Quantum Synchronizable Codes on Sextic Cyclotomy",
    "abstract": "Quantum synchronizable codes are kinds of quantum error-correcting codes that\ncan not only correct the effects of quantum noise on qubits but also the\nmisalignment in block synchronization. In this paper, the quantum\nsynchronizable codes constructed are CSS quantum error-correcting codes whose\nsynchronization capabilities reach the upper bound. And we use cyclic codes\ngained by sextic cyclotomic classes to construct two classes of quantum\nsynchronizable codes. Moreover, the quantum synchronizable codes are posses\ngood error-correcting capability towards bit error and phase error, since the\ncyclic codes we used are optimal or almost optimal.",
    "descriptor": "\nComments: Quantum Synchronizable, Sextic cyclotomy, Cyclic code\n",
    "authors": [
      "Tao Wang",
      "Tongjiang Yan",
      "Xueting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03619"
  },
  {
    "id": "arXiv:2105.03620",
    "title": "ABCNet v2: Adaptive Bezier-Curve Network for Real-time End-to-end Text  Spotting",
    "abstract": "End-to-end text-spotting, which aims to integrate detection and recognition\nin a unified framework, has attracted increasing attention due to its\nsimplicity of the two complimentary tasks. It remains an open problem\nespecially when processing arbitrarily-shaped text instances. Previous methods\ncan be roughly categorized into two groups: character-based and\nsegmentation-based, which often require character-level annotations and/or\ncomplex post-processing due to the unstructured output. Here, we tackle\nend-to-end text spotting by presenting Adaptive Bezier Curve Network v2 (ABCNet\nv2). Our main contributions are four-fold: 1) For the first time, we adaptively\nfit arbitrarily-shaped text by a parameterized Bezier curve, which, compared\nwith segmentation-based methods, can not only provide structured output but\nalso controllable representation. 2) We design a novel BezierAlign layer for\nextracting accurate convolution features of a text instance of arbitrary\nshapes, significantly improving the precision of recognition over previous\nmethods. 3) Different from previous methods, which often suffer from complex\npost-processing and sensitive hyper-parameters, our ABCNet v2 maintains a\nsimple pipeline with the only post-processing non-maximum suppression (NMS). 4)\nAs the performance of text recognition closely depends on feature alignment,\nABCNet v2 further adopts a simple yet effective coordinate convolution to\nencode the position of the convolutional filters, which leads to a considerable\nimprovement with negligible computation overhead. Comprehensive experiments\nconducted on various bilingual (English and Chinese) benchmark datasets\ndemonstrate that ABCNet v2 can achieve state-of-the-art performance while\nmaintaining very high efficiency.",
    "descriptor": "\nComments: 16 pages. Code is at: this https URL arXiv admin note: text overlap with arXiv:2002.10200\n",
    "authors": [
      "Yuliang Liu",
      "Chunhua Shen",
      "Lianwen Jin",
      "Tong He",
      "Peng Chen",
      "Chongyu Liu",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03620"
  },
  {
    "id": "arXiv:2105.03626",
    "title": "SuMo: A Mutation Testing Strategy for Solidity Smart Contracts",
    "abstract": "Smart Contracts are software programs that are deployed and executed within a\nblockchain infrastructure. Due to their immutable nature, directly resulting\nfrom the specific characteristics of the deploying infrastructure, smart\ncontracts must be thoroughly tested before their release. Testing is one of the\nmain activities that can help to improve the reliability of a smart contract,\nso as to possibly prevent considerable loss of valuable assets. It is therefore\nimportant to provide the testers with tools that permit them to assess the\nactivity they performed. Mutation testing is a powerful approach for assessing\nthe fault-detection capability of a test suite. In this paper, we propose SuMo,\na novel mutation testing tool for Ethereum Smart Contracts. SuMo implements a\nset of 44 mutation operators that were designed starting from the latest\nSolidity documentation, and from well-known mutation testing tools. These allow\nto simulate a wide variety of faults that can be made by smart contract\ndevelopers. The set of operators was designed to limit the generation of\nstillborn mutants, which slow down the mutation testing process and limit the\nusability of the tool. We report a first evaluation of SuMo on open-source\nprojects for which test suites were available. The results we got are\nencouraging, and they suggest that SuMo can effectively help developers to\ndeliver more reliable smart contracts.",
    "descriptor": "",
    "authors": [
      "Morena Barboni",
      "Andrea Morichetta",
      "Andrea Polini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.03626"
  },
  {
    "id": "arXiv:2105.03627",
    "title": "Improving Cross-Lingual Reading Comprehension with Self-Training",
    "abstract": "Substantial improvements have been made in machine reading comprehension,\nwhere the machine answers questions based on a given context. Current\nstate-of-the-art models even surpass human performance on several benchmarks.\nHowever, their abilities in the cross-lingual scenario are still to be\nexplored. Previous works have revealed the abilities of pre-trained\nmultilingual models for zero-shot cross-lingual reading comprehension. In this\npaper, we further utilized unlabeled data to improve the performance. The model\nis first supervised-trained on source language corpus, and then self-trained\nwith unlabeled target language data. The experiment results showed improvements\nfor all languages, and we also analyzed how self-training benefits\ncross-lingual reading comprehension in qualitative aspects.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Wei-Cheng Huang",
      "Chien-yu Huang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03627"
  },
  {
    "id": "arXiv:2105.03630",
    "title": "A Phase Theory of MIMO LTI Systems",
    "abstract": "In this paper, we introduce a definition of phase response for a class of\nmulti-input multi-output (MIMO) linear time-invariant (LTI) systems whose\nfrequency responses are (semi-)sectorial at all frequencies. The newly defined\nphase concept subsumes the well-known notions of positive real systems and\nnegative imaginary systems. We formulate a small phase theorem for feedback\nstability, which complements the celebrated small gain theorem. The small phase\ntheorem lays the foundation of a phase theory of MIMO systems. We also discuss\ntime-domain interpretations of phase-bounded systems via both energy signal\nanalysis and power signal analysis. In addition, a sectored real lemma is\nderived for the computation of MIMO phases, which serves as a natural\ncounterpart of the bounded real lemma.",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Dan Wang",
      "Sei Zhen Khong",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03630"
  },
  {
    "id": "arXiv:2105.03631",
    "title": "Coded Alternating Least Squares for Straggler Mitigation in Distributed  Recommendations",
    "abstract": "Matrix factorization is an important representation learning algorithm, e.g.,\nrecommender systems, where a large matrix can be factorized into the product of\ntwo low dimensional matrices termed as latent representations. This paper\ninvestigates the problem of matrix factorization in distributed computing\nsystems with stragglers, those compute nodes that are slow to return\ncomputation results. A computation procedure, called coded Alternative Least\nSquare (ALS), is proposed for mitigating the effect of stragglers in such\nsystems. The coded ALS algorithm iteratively computes two low dimensional\nlatent matrices by solving various linear equations, with the Entangled\nPolynomial Code (EPC) as a building block. We theoretically characterize the\nmaximum number of stragglers that the algorithm can tolerate (or the recovery\nthreshold) in relation to the redundancy of coding (or the code rate). In\naddition, we theoretically show the computation complexity for the coded ALS\nalgorithm and conduct numerical experiments to validate our design.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Siyuan Wang",
      "Qifa Yan",
      "Jingjing Zhang",
      "Jianping Wang",
      "Linqi Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03631"
  },
  {
    "id": "arXiv:2105.03632",
    "title": "CASIA-Face-Africa: A Large-scale African Face Image Database",
    "abstract": "Face recognition is a popular and well-studied area with wide applications in\nour society. However, racial bias had been proven to be inherent in most State\nOf The Art (SOTA) face recognition systems. Many investigative studies on face\nrecognition algorithms have reported higher false positive rates of African\nsubjects cohorts than the other cohorts. Lack of large-scale African face image\ndatabases in public domain is one of the main restrictions in studying the\nracial bias problem of face recognition. To this end, we collect a face image\ndatabase namely CASIA-Face-Africa which contains 38,546 images of 1,183 African\nsubjects. Multi-spectral cameras are utilized to capture the face images under\nvarious illumination settings. Demographic attributes and facial expressions of\nthe subjects are also carefully recorded. For landmark detection, each face\nimage in the database is manually labeled with 68 facial keypoints. A group of\nevaluation protocols are constructed according to different applications,\ntasks, partitions and scenarios. The performances of SOTA face recognition\nalgorithms without re-training are reported as baselines. The proposed database\nalong with its face landmark annotations, evaluation protocols and preliminary\nresults form a good benchmark to study the essential aspects of face biometrics\nfor African subjects, especially face image preprocessing, face feature\nanalysis and matching, facial expression recognition, sex/age estimation,\nethnic classification, face image generation, etc. The database can be\ndownloaded from our this http URL",
    "descriptor": "\nComments: This paper has been accepted for publication in the journal IEEE TIFS\n",
    "authors": [
      "Jawad Muhammad",
      "Yunlong Wang",
      "Caiyong Wang",
      "Kunbo Zhang",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03632"
  },
  {
    "id": "arXiv:2105.03636",
    "title": "RISe of Flight: RIS-Empowered UAV Communications for Robust and Reliable  Air-to-Ground Networks",
    "abstract": "Next generation mobile networks need to expand towards uncharted territories\nin order to enable the digital transformation of society. In this context,\naerial devices such as unmanned aerial vehicles (UAVs) are expected to address\nthis gap in hard-to-reach locations. However, limited battery-life is an\nobstacle for the successful spread of such solutions. Reconfigurable\nintelligent surfaces (RISs) represent a promising solution addressing this\nchallenge since on-board passive and lightweight controllable devices can\nefficiently reflect the signal propagation from the ground BSs towards specific\ntarget areas. In this paper, we focus on air-to-ground networks where UAVs\nequipped with RIS can fly over selected areas to provide connectivity. In\nparticular, we study how to optimally compensate flight effects and propose\nRiFe as well as its practical implementation Fair-RiFe that automatically\nconfigure RIS parameters accounting for undesired UAV oscillations due to\nadverse atmospheric conditions. Our results show that both algorithms provide\nrobustness and reliability while outperforming state-of-the-art solutions in\nthe multiple conditions studied.",
    "descriptor": "\nComments: Submitted for journal publication\n",
    "authors": [
      "Placido Mursia",
      "Francesco Devoti",
      "Vincenzo Sciancalepore",
      "Xavier Costa-P\u00e9rez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03636"
  },
  {
    "id": "arXiv:2105.03638",
    "title": "Fast Neighborhood Rendezvous",
    "abstract": "In the rendezvous problem, two computing entities (called \\emph{agents})\nlocated at different vertices in a graph have to meet at the same vertex. In\nthis paper, we consider the synchronous \\emph{neighborhood rendezvous problem},\nwhere the agents are initially located at two adjacent vertices. While this\nproblem can be trivially solved in $O(\\Delta)$ rounds ($\\Delta$ is the maximum\ndegree of the graph), it is highly challenging to reveal whether that problem\ncan be solved in $o(\\Delta)$ rounds, even assuming the rich computational\ncapability of agents. The only known result is that the time complexity of\n$O(\\sqrt{n})$ rounds is achievable if the graph is complete and agents are\nprobabilistic, asymmetric, and can use whiteboards placed at vertices. Our main\ncontribution is to clarify the situation (with respect to computational models\nand graph classes) admitting such a sublinear-time rendezvous algorithm. More\nprecisely, we present two algorithms achieving fast rendezvous additionally\nassuming bounded minimum degree, unique vertex identifier, accessibility to\nneighborhood IDs, and randomization. The first algorithm runs within\n$\\tilde{O}(\\sqrt{n\\Delta/\\delta} + n/\\delta)$ rounds for graphs of the minimum\ndegree larger than $\\sqrt{n}$, where $n$ is the number of vertices in the\ngraph, and $\\delta$ is the minimum degree of the graph. The second algorithm\nassumes that the largest vertex ID is $O(n)$, and achieves $\\tilde{O}\\left(\n\\frac{n}{\\sqrt{\\delta}} \\right)$-round time complexity without using\nwhiteboards. These algorithms attain $o(\\Delta)$-round complexity in the case\nof $\\delta = {\\omega}(\\sqrt{n} \\log n)$ and $\\delta = \\omega(n^{2/3} \\log^{4/3}\nn)$ respectively.",
    "descriptor": "",
    "authors": [
      "Ryota Eguchi",
      "Naoki Kitamura",
      "Taisuke Izumi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.03638"
  },
  {
    "id": "arXiv:2105.03640",
    "title": "On Guaranteed Optimal Robust Explanations for NLP Models",
    "abstract": "We build on abduction-based explanations for ma-chine learning and develop a\nmethod for computing local explanations for neural network models in natural\nlanguage processing (NLP). Our explanations comprise a subset of the words of\nthe in-put text that satisfies two key features: optimality w.r.t. a\nuser-defined cost function, such as the length of explanation, and robustness,\nin that they ensure prediction invariance for any bounded perturbation in the\nembedding space of the left out words. We present two solution algorithms,\nrespectively based on implicit hitting sets and maximum universal subsets,\nintroducing a number of algorithmic improvements to speed up convergence of\nhard instances. We show how our method can be con-figured with different\nperturbation sets in the em-bedded space and used to detect bias in predictions\nby enforcing include/exclude constraints on biased terms, as well as to enhance\nexisting heuristic-based NLP explanation frameworks such as Anchors. We\nevaluate our framework on three widely used sentiment analysis tasks and texts\nof up to100words from SST, Twitter and IMDB datasets,demonstrating the\neffectiveness of the derived explanations.",
    "descriptor": "\nComments: 12 pages (7+5 Appendix). Accepted as long-paper at IJCAI 2021\n",
    "authors": [
      "Emanuele La Malfa",
      "Agnieszka Zbrzezny",
      "Rhiannon Michelmore",
      "Nicola Paoletti",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03640"
  },
  {
    "id": "arXiv:2105.03641",
    "title": "Neural Text Generation with Part-of-Speech Guided Softmax",
    "abstract": "Neural text generation models are likely to suffer from the low-diversity\nproblem. Various decoding strategies and training-based methods have been\nproposed to promote diversity only by exploiting contextual features, but\nrarely do they consider incorporating syntactic structure clues. In this work,\nwe propose using linguistic annotation, i.e., part-of-speech (POS), to guide\nthe text generation. In detail, we introduce POS Guided Softmax (POSG-Softmax)\nto explicitly model two posterior probabilities: (i) next-POS, and (ii)\nnext-token from the vocabulary of the target POS. A POS guided sampling\nstrategy is further proposed to address the low-diversity problem by enriching\nthe diversity of POS. Extensive experiments and human evaluations demonstrate\nthat, compared with existing state-of-the-art methods, our proposed methods can\ngenerate more diverse text while maintaining comparable quality.",
    "descriptor": "\nComments: Main text: 8 pages, 2 figures, 8 tables. Supplementary Information: 2 pages, 7 tables\n",
    "authors": [
      "Zhixian Yang",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03641"
  },
  {
    "id": "arXiv:2105.03642",
    "title": "MIMO Terahertz Quantum Key Distribution",
    "abstract": "We propose a multiple-input multiple-output (MIMO) quantum key distribution\n(QKD) scheme for improving the secret key rates and increasing the maximum\ntransmission distance for terahertz (THz) frequency range applications\noperating at room temperature. We propose a transmit beamforming and receive\ncombining scheme that converts the rank-$r$ MIMO channel between Alice and Bob\ninto $r$ parallel lossy quantum channels whose transmittances depend on the\nnon-zero singular values of the MIMO channel. The MIMO transmission scheme\nprovides a multiplexing gain of $r$, along with a beamforming and array gain\nequal to the product of the number of transmit and receive antennas. This\nimproves the secret key rate and extends the maximum transmission distance. Our\nsimulation results show that multiple antennas are necessary to overcome the\nhigh free-space path loss at THz frequencies. Positive key rates are achievable\nin the $10-30$ THz frequency range that can be used for both indoor and outdoor\nQKD applications for beyond fifth generation ultra-secure wireless\ncommunications systems.",
    "descriptor": "\nComments: Submitted to IEEE Communications Letters\n",
    "authors": [
      "Neel Kanth Kundu",
      "Soumya P. Dash",
      "Matthew R. McKay",
      "Ranjan K. Mallik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03642"
  },
  {
    "id": "arXiv:2105.03647",
    "title": "A Novel Triplet Sampling Method for Multi-Label Remote Sensing Image  Search and Retrieval",
    "abstract": "Learning the similarity between remote sensing (RS) images forms the\nfoundation for content based RS image retrieval (CBIR). Recently, deep metric\nlearning approaches that map the semantic similarity of images into an\nembedding space have been found very popular in RS. A common approach for\nlearning the metric space relies on the selection of triplets of similar\n(positive) and dissimilar (negative) images to a reference image called as an\nanchor. Choosing triplets is a difficult task particularly for multi-label RS\nCBIR, where each training image is annotated by multiple class labels. To\naddress this problem, in this paper we propose a novel triplet sampling method\nin the framework of deep neural networks (DNNs) defined for multi-label RS CBIR\nproblems. The proposed method selects a small set of the most representative\nand informative triplets based on two main steps. In the first step, a set of\nanchors that are diverse to each other in the embedding space is selected from\nthe current mini-batch using an iterative algorithm. In the second step,\ndifferent sets of positive and negative images are chosen for each anchor by\nevaluating relevancy, hardness, and diversity of the images among each other\nbased on a novel ranking strategy. Experimental results obtained on two\nmulti-label benchmark achieves show that the selection of the most informative\nand representative triplets in the context of DNNs results in: i) reducing the\ncomputational complexity of the training phase of the DNNs without any\nsignificant loss on the performance; and ii) an increase in learning speed\nsince informative triplets allow fast convergence. The code of the proposed\nmethod is publicly available at\nhttps://git.tu-berlin.de/rsim/image-retrieval-from-triplets.",
    "descriptor": "\nComments: The paper is under review. Our code is available online at this https URL\n",
    "authors": [
      "Tristan Kreuziger",
      "Mahdyar Ravanbakhsh",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.03647"
  },
  {
    "id": "arXiv:2105.03649",
    "title": "In-Hardware Learning of Multilayer Spiking Neural Networks on a  Neuromorphic Processor",
    "abstract": "Although widely used in machine learning, backpropagation cannot directly be\napplied to SNN training and is not feasible on a neuromorphic processor that\nemulates biological neuron and synapses. This work presents a spike-based\nbackpropagation algorithm with biological plausible local update rules and\nadapts it to fit the constraint in a neuromorphic hardware. The algorithm is\nimplemented on Intel Loihi chip enabling low power in-hardware supervised\nonline learning of multilayered SNNs for mobile applications. We test this\nimplementation on MNIST, Fashion-MNIST, CIFAR-10 and MSTAR datasets with\npromising performance and energy-efficiency, and demonstrate a possibility of\nincremental online learning with the implementation.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted for Design Automation Conference (DAC) 2021\n",
    "authors": [
      "Amar Shrestha",
      "Haowen Fang",
      "Daniel Patrick Rider",
      "Zaidao Mei",
      "Qinru Qiu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.03649"
  },
  {
    "id": "arXiv:2105.03650",
    "title": "How To Train Your Program",
    "abstract": "We present a Bayesian approach to machine learning with probabilistic\nprograms. In our approach, training on available data is implemented as\ninference on a hierarchical model. The posterior distribution of model\nparameters is then used to \\textit{stochastically condition} a complementary\nmodel, such that inference on new data yields the same posterior distribution\nof latent parameters corresponding to the new data as inference on a\nhierachical model on the combination of both previously available and new data,\nat a lower computation cost. We frame the approach as a design pattern of\nprobabilistic programming referred to herein as `stump and fungus', and\nillustrate realization of the pattern on a didactic case study.",
    "descriptor": "\nComments: submitted to PROBPROG11\n",
    "authors": [
      "David Tolpin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03650"
  },
  {
    "id": "arXiv:2105.03654",
    "title": "Improving Named Entity Recognition by External Context Retrieving and  Cooperative Learning",
    "abstract": "Recent advances in Named Entity Recognition (NER) show that document-level\ncontexts can significantly improve model performance. In many application\nscenarios, however, such contexts are not available. In this paper, we propose\nto find external contexts of a sentence by retrieving and selecting a set of\nsemantically relevant texts through a search engine, with the original sentence\nas the query. We find empirically that the contextual representations computed\non the retrieval-based input view, constructed through the concatenation of a\nsentence and its external contexts, can achieve significantly improved\nperformance compared to the original input view based only on the sentence.\nFurthermore, we can improve the model performance of both input views by\nCooperative Learning, a training method that encourages the two input views to\nproduce similar contextual representations or output label distributions.\nExperiments show that our approach can achieve new state-of-the-art performance\non 8 NER data sets across 5 domains.",
    "descriptor": "\nComments: Accepted to ACL 2021, submission version, 12 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03654"
  },
  {
    "id": "arXiv:2105.03655",
    "title": "FlingBot: The Unreasonable Effectiveness of Dynamic Manipulation for  Cloth Unfolding",
    "abstract": "High-velocity dynamic actions (e.g., fling or throw) play a crucial role in\nour every-day interaction with deformable objects by improving our efficiency\nand effectively expanding our physical reach range. Yet, most prior works have\ntackled cloth manipulation using exclusively single-arm quasi-static actions,\nwhich requires a large number of interactions for challenging initial cloth\nconfigurations and strictly limits the maximum cloth size by the robot's reach\nrange. In this work, we demonstrate the effectiveness of dynamic flinging\nactions for cloth unfolding. We propose a self-supervised learning framework,\nFlingBot, that learns how to unfold a piece of fabric from arbitrary initial\nconfigurations using a pick, stretch, and fling primitive for a dual-arm setup\nfrom visual observations. The final system achieves over 80\\% coverage within 3\nactions on novel cloths, can unfold cloths larger than the system's reach\nrange, and generalizes to T-shirts despite being trained on only rectangular\ncloths. We also finetuned FlingBot on a real-world dual-arm robot platform,\nwhere it increased the cloth coverage 3.6 times more than the quasi-static\nbaseline did. The simplicity of FlingBot combined with its superior performance\nover quasi-static baselines demonstrates the effectiveness of dynamic actions\nfor deformable object manipulation. The project video is available at\n$\\href{https://youtu.be/T4tDy5y_6ZM}{here}$.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Huy Ha",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03655"
  },
  {
    "id": "arXiv:2105.03659",
    "title": "Logic-Driven Context Extension and Data Augmentation for Logical  Reasoning of Text",
    "abstract": "Logical reasoning of text requires understanding critical logical information\nin the text and performing inference over them. Large-scale pre-trained models\nfor logical reasoning mainly focus on word-level semantics of text while\nstruggling to capture symbolic logic. In this paper, we propose to understand\nlogical symbols and expressions in the text to arrive at the answer. Based on\nsuch logical information, we not only put forward a context extension framework\nbut also propose a data augmentation algorithm. The former extends the context\nto cover implicit logical expressions following logical equivalence laws. The\nlatter augments literally similar but logically different instances to better\ncapture logical information, especially logical negative and conditional\nrelationships. We conduct experiments on ReClor dataset. The results show that\nour method achieves the state-of-the-art performance, and both logic-driven\ncontext extension framework and data augmentation algorithm can help improve\nthe accuracy. And our multi-model ensemble system is the first to surpass human\nperformance on both EASY set and HARD set of ReClor.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Siyuan Wang",
      "Wanjun Zhong",
      "Duyu Tang",
      "Zhongyu Wei",
      "Zhihao Fan",
      "Daxin Jiang",
      "Ming Zhou",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03659"
  },
  {
    "id": "arXiv:2105.03663",
    "title": "On Linear Interpolation in the Latent Space of Deep Generative Models",
    "abstract": "The underlying geometrical structure of the latent space in deep generative\nmodels is in most cases not Euclidean, which may lead to biases when comparing\ninterpolation capabilities of two models. Smoothness and plausibility of linear\ninterpolations in latent space are associated with the quality of the\nunderlying generative model. In this paper, we show that not all such\ninterpolations are comparable as they can deviate arbitrarily from the shortest\ninterpolation curve given by the geodesic. This deviation is revealed by\ncomputing curve lengths with the pull-back metric of the generative model,\nfinding shorter curves than the straight line between endpoints, and measuring\na non-zero relative length improvement on this straight line. This leads to a\nstrategy to compare linear interpolations across two generative models. We also\nshow the effect and importance of choosing an appropriate output space for\ncomputing shorter curves. For this computation we derive an extension of the\npull-back metric.",
    "descriptor": "\nComments: For BibTex and Poster: this https URL\n",
    "authors": [
      "Mike Yan Michelis",
      "Quentin Becker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03663"
  },
  {
    "id": "arXiv:2105.03664",
    "title": "D2S: Document-to-Slide Generation Via Query-Based Text Summarization",
    "abstract": "Presentations are critical for communication in all areas of our lives, yet\nthe creation of slide decks is often tedious and time-consuming. There has been\nlimited research aiming to automate the document-to-slides generation process\nand all face a critical challenge: no publicly available dataset for training\nand benchmarking. In this work, we first contribute a new dataset, SciDuet,\nconsisting of pairs of papers and their corresponding slides decks from recent\nyears' NLP and ML conferences (e.g., ACL). Secondly, we present D2S, a novel\nsystem that tackles the document-to-slides task with a two-step approach: 1)\nUse slide titles to retrieve relevant and engaging text, figures, and tables;\n2) Summarize the retrieved context into bullet points with long-form question\nanswering. Our evaluation suggests that long-form QA outperforms\nstate-of-the-art summarization baselines on both automated ROUGE metrics and\nqualitative human evaluation.",
    "descriptor": "\nComments: accepted at NAACL 2021\n",
    "authors": [
      "Edward Sun",
      "Yufang Hou",
      "Dakuo Wang",
      "Yunfeng Zhang",
      "Nancy X.R. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03664"
  },
  {
    "id": "arXiv:2105.03669",
    "title": "Chameleon: A Semi-AutoML framework targeting quick and scalable  development and deployment of production-ready ML systems for SMEs",
    "abstract": "Developing, scaling, and deploying modern Machine Learning solutions remains\nchallenging for small- and middle-sized enterprises (SMEs). This is due to a\nhigh entry barrier of building and maintaining a dedicated IT team as well as\nthe difficulties of real-world data (RWD) compared to standard benchmark data.\nTo address this challenge, we discuss the implementation and concepts of\nChameleon, a semi-AutoML framework. The goal of Chameleon is fast and scalable\ndevelopment and deployment of production-ready machine learning systems into\nthe workflow of SMEs. We first discuss the RWD challenges faced by SMEs. After,\nwe outline the central part of the framework which is a model and loss-function\nzoo with RWD-relevant defaults. Subsequently, we present how one can use a\ntemplatable framework in order to automate the experiment iteration cycle, as\nwell as close the gap between development and deployment. Finally, we touch on\nour testing framework component allowing us to investigate common model failure\nmodes and support best practices of model deployment governance.",
    "descriptor": "",
    "authors": [
      "Johannes Otterbach",
      "Thomas Wollmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03669"
  },
  {
    "id": "arXiv:2105.03671",
    "title": "The Tags Are Alright: Robust Large-Scale RFID Clone Detection Through  Federated Data-Augmented Radio Fingerprinting",
    "abstract": "Millions of RFID tags are pervasively used all around the globe to\ninexpensively identify a wide variety of everyday-use objects. One of the key\nissues of RFID is that tags cannot use energy-hungry cryptography. For this\nreason, radio fingerprinting (RFP) is a compelling approach that leverages the\nunique imperfections in the tag's wireless circuitry to achieve large-scale\nRFID clone detection. Recent work, however, has unveiled that time-varying\nchannel conditions can significantly decrease the accuracy of the RFP process.\nWe propose the first large-scale investigation into RFP of RFID tags with\ndynamic channel conditions. Specifically, we perform a massive data collection\ncampaign on a testbed composed by 200 off-the-shelf identical RFID tags and a\nsoftware-defined radio (SDR) tag reader. We collect data with different\ntag-reader distances in an over-the-air configuration. To emulate implanted\nRFID tags, we also collect data with two different kinds of porcine meat\ninserted between the tag and the reader. We use this rich dataset to train and\ntest several convolutional neural network (CNN)--based classifiers in a variety\nof channel conditions. Our investigation reveals that training and testing on\ndifferent channel conditions drastically degrades the classifier's accuracy.\nFor this reason, we propose a novel training framework based on federated\nmachine learning (FML) and data augmentation (DAG) to boost the accuracy.\nExtensive experimental results indicate that (i) our FML approach improves\naccuracy by up to 48%; (ii) our DA approach improves the FML performance by up\nto 31%. To the best of our knowledge, this is the first paper experimentally\ndemonstrating the efficacy of FML and DA on a large device population. We are\nsharing with the research community our fully-labeled 200-GB RFID waveform\ndataset, the entirety of our code and trained models.",
    "descriptor": "",
    "authors": [
      "Mauro Piva",
      "Gaia Maselli",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03671"
  },
  {
    "id": "arXiv:2105.03677",
    "title": "Active Terahertz Imaging Dataset for Concealed Object Detection",
    "abstract": "Concealed object detection in Terahertz imaging is an urgent need for public\nsecurity and counter-terrorism. In this paper, we provide a public dataset for\nevaluating multi-object detection algorithms in active Terahertz imaging\nresolution 5 mm by 5 mm. To the best of our knowledge, this is the first public\nTerahertz imaging dataset prepared to evaluate object detection algorithms.\nObject detection on this dataset is much more difficult than on those standard\npublic object detection datasets due to its inferior imaging quality. Facing\nthe problem of imbalanced samples in object detection and hard training\nsamples, we evaluate four popular detectors: YOLOv3, YOLOv4, FRCN-OHEM, and\nRetinaNet on this dataset. Experimental results indicate that the RetinaNet\nachieves the highest mAP. In addition, we demonstrate that hiding objects in\ndifferent parts of the human body affect detection accuracy. The dataset is\navailable at https://github.com/LingLIx/THz_Dataset.",
    "descriptor": "",
    "authors": [
      "Dong Liang",
      "Fei Xue",
      "Ling Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03677"
  },
  {
    "id": "arXiv:2105.03680",
    "title": "A Crossover That Matches Diverse Parents Together in Evolutionary  Algorithms",
    "abstract": "Crossover and mutation are the two main operators that lead to new solutions\nin evolutionary approaches. In this article, a new method of performing the\ncrossover phase is presented. The problem of choice is evolutionary decision\ntree construction. The method aims at finding such individuals that together\ncomplement each other. Hence we say that they are diversely specialized. We\npropose the way of calculating the so-called complementary fitness. In several\nempirical experiments, we evaluate the efficacy of the method proposed in four\nvariants and compare it to a fitness-rank-based approach. One variant emerges\nclearly as the best approach, whereas the remaining ones are below the\nbaseline.",
    "descriptor": "\nComments: Accepted to GECCO 2021\n",
    "authors": [
      "Maciej \u015awiechowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03680"
  },
  {
    "id": "arXiv:2105.03681",
    "title": "A Simple yet Universal Strategy for Online Convex Optimization",
    "abstract": "Recently, several universal methods have been proposed for online convex\noptimization, and attain minimax rates for multiple types of convex functions\nsimultaneously. However, they need to design and optimize one surrogate loss\nfor each type of functions, which makes it difficult to exploit the structure\nof the problem and utilize the vast amount of existing algorithms. In this\npaper, we propose a simple strategy for universal online convex optimization,\nwhich avoids these limitations. The key idea is to construct a set of experts\nto process the original online functions, and deploy a meta-algorithm over the\n\\emph{linearized} losses to aggregate predictions from experts. Specifically,\nwe choose Adapt-ML-Prod to track the best expert, because it has a second-order\nbound and can be used to leverage strong convexity and exponential concavity.\nIn this way, we can plug in off-the-shelf online solvers as black-box experts\nto deliver problem-dependent regret bounds. Furthermore, our strategy inherits\nthe theoretical guarantee of any expert designed for strongly convex functions\nand exponentially concave functions, up to a double logarithmic factor. For\ngeneral convex functions, it maintains the minimax optimality and also achieves\na small-loss bound.",
    "descriptor": "",
    "authors": [
      "Lijun Zhang",
      "Guanghui Wang",
      "Jinfeng Yi",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.03681"
  },
  {
    "id": "arXiv:2105.03682",
    "title": "Enhancing ensemble learning and transfer learning in multimodal data  analysis by adaptive dimensionality reduction",
    "abstract": "Modern data analytics take advantage of ensemble learning and transfer\nlearning approaches to tackle some of the most relevant issues in data\nanalysis, such as lack of labeled data to use to train the analysis models,\nsparsity of the information, and unbalanced distributions of the records.\nNonetheless, when applied to multimodal datasets (i.e., datasets acquired by\nmeans of multiple sensing techniques or strategies), the state-of-theart\nmethods for ensemble learning and transfer learning might show some\nlimitations. In fact, in multimodal data analysis, not all observations would\nshow the same level of reliability or information quality, nor an homogeneous\ndistribution of errors and uncertainties. This condition might undermine the\nclassic assumptions ensemble learning and transfer learning methods rely on. In\nthis work, we propose an adaptive approach for dimensionality reduction to\novercome this issue. By means of a graph theory-based approach, the most\nrelevant features across variable size subsets of the considered datasets are\nidentified. This information is then used to set-up ensemble learning and\ntransfer learning architectures. We test our approach on multimodal datasets\nacquired in diverse research fields (remote sensing, brain-computer interfaces,\nphotovoltaic energy). Experimental results show the validity and the robustness\nof our approach, able to outperform state-of-the-art techniques.",
    "descriptor": "\nComments: 18 pages, 10 figures, submitted to Pattern Recognition\n",
    "authors": [
      "Andrea Marinoni",
      "Saloua Chlaily",
      "Eduard Khachatrian",
      "Torbj\u00f8rn Eltoft",
      "Sivasakthy Selvakumaran",
      "Mark Girolami",
      "Christian Jutten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03682"
  },
  {
    "id": "arXiv:2105.03686",
    "title": "Long Short-Term Temporal Meta-learning in Online Recommendation",
    "abstract": "An effective online recommendation system should jointly capture user\nlong-term and short-term preferences in both user internal and external\nbehaviors. However, it is challenging to conduct fast adaptations to variable\nnew topics while making full use of all information in large-scale systems, due\nto the online efficiency limitation and complexity of real-world systems. To\naddress this, we propose a novel Long Short-Term Temporal Meta-learning\nframework (LSTTM) for online recommendation, which captures user preferences\nfrom a global long-term graph and an internal short-term graph. To improve\nonline learning for short-term interests, we propose a temporal MAML method\nwith asynchronous online updating for fast adaptation, which regards\nrecommendations at different time periods as different tasks. In experiments,\nLSTTM achieves significant improvements on both offline and online evaluations.\nLSTTM has also been deployed on a widely-used online system, affecting millions\nof users. The idea of temporal MAML can be easily transferred to other models\nand temporal tasks.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Ruobing Xie",
      "Yalong Wang",
      "Rui Wang",
      "Yuanfu Lu",
      "Yuanhang Zou",
      "Feng Xia",
      "Leyu Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03686"
  },
  {
    "id": "arXiv:2105.03687",
    "title": "Covariance Matrix Adaptation Evolution Strategy Assisted by Principal  Component Analysis",
    "abstract": "Over the past decades, more and more methods gain a giant development due to\nthe development of technology. Evolutionary Algorithms are widely used as a\nheuristic method. However, the budget of computation increases exponentially\nwhen the dimensions increase. In this paper, we will use the dimensionality\nreduction method Principal component analysis (PCA) to reduce the dimension\nduring the iteration of Covariance Matrix Adaptation Evolution Strategy\n(CMA-ES), which is a good Evolutionary Algorithm that is presented as the\nnumeric type and useful for different kinds of problems. We assess the\nperformance of our new methods in terms of convergence rate on multi-modal\nproblems from the Black-Box Optimization Benchmarking (BBOB) problem set and we\nalso use the framework COmparing Continuous Optimizers (COCO) to see how the\nnew method going and compare it to the other algorithms.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Yangjie Mei"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.03687"
  },
  {
    "id": "arXiv:2105.03688",
    "title": "HamNet: Conformation-Guided Molecular Representation with Hamiltonian  Neural Networks",
    "abstract": "Well-designed molecular representations (fingerprints) are vital to combine\nmedical chemistry and deep learning. Whereas incorporating 3D geometry of\nmolecules (i.e. conformations) in their representations seems beneficial,\ncurrent 3D algorithms are still in infancy. In this paper, we propose a novel\nmolecular representation algorithm which preserves 3D conformations of\nmolecules with a Molecular Hamiltonian Network (HamNet). In HamNet, implicit\npositions and momentums of atoms in a molecule interact in the Hamiltonian\nEngine following the discretized Hamiltonian equations. These implicit\ncoordinations are supervised with real conformations with translation- &\nrotation-invariant losses, and further used as inputs to the Fingerprint\nGenerator, a message-passing neural network. Experiments show that the\nHamiltonian Engine can well preserve molecular conformations, and that the\nfingerprints generated by HamNet achieve state-of-the-art performances on\nMoleculeNet, a standard molecular machine learning benchmark.",
    "descriptor": "\nComments: in ICLR-2021 (poster)\n",
    "authors": [
      "Ziyao Li",
      "Shuwen Yang",
      "Guojie Song",
      "Lingsheng Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03688"
  },
  {
    "id": "arXiv:2105.03689",
    "title": "Self-Supervised Adversarial Example Detection by Disentangled  Representation",
    "abstract": "Deep learning models are known to be vulnerable to adversarial examples that\nare elaborately designed for malicious purposes and are imperceptible to the\nhuman perceptual system. Autoencoder, when trained solely over benign examples,\nhas been widely used for (self-supervised) adversarial detection based on the\nassumption that adversarial examples yield larger reconstruction error.\nHowever, because lacking adversarial examples in its training and the too\nstrong generalization ability of autoencoder, this assumption does not always\nhold true in practice. To alleviate this problem, we explore to detect\nadversarial examples by disentangled representations of images under the\nautoencoder structure. By disentangling input images as class features and\nsemantic features, we train an autoencoder, assisted by a discriminator\nnetwork, over both correctly paired class/semantic features and incorrectly\npaired class/semantic features to reconstruct benign and counterexamples. This\nmimics the behavior of adversarial examples and can reduce the unnecessary\ngeneralization ability of autoencoder. Compared with the state-of-the-art\nself-supervised detection methods, our method exhibits better performance in\nvarious measurements (i.e., AUC, FPR, TPR) over different datasets (MNIST,\nFashion-MNIST and CIFAR-10), different adversarial attack methods (FGSM, BIM,\nPGD, DeepFool, and CW) and different victim models (8-layer CNN and 16-layer\nVGG). We compare our method with the state-of-the-art self-supervised detection\nmethods under different adversarial attacks and different victim models (30\nattack settings), and it exhibits better performance in various measurements\n(AUC, FPR, TPR) for most attacks settings. Ideally, AUC is $1$ and our method\nachieves $0.99+$ on CIFAR-10 for all attacks. Notably, different from other\nAutoencoder-based detectors, our method can provide resistance to the adaptive\nadversary.",
    "descriptor": "",
    "authors": [
      "Zhaoxi Zhang",
      "Leo Yu Zhang",
      "Xufei Zheng",
      "Shengshan Hu",
      "Jinyu Tian",
      "Jiantao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03689"
  },
  {
    "id": "arXiv:2105.03692",
    "title": "Provable Guarantees against Data Poisoning Using Self-Expansion and  Compatibility",
    "abstract": "A recent line of work has shown that deep networks are highly susceptible to\nbackdoor data poisoning attacks. Specifically, by injecting a small amount of\nmalicious data into the training distribution, an adversary gains the ability\nto control the model's behavior during inference. In this work, we propose an\niterative training procedure for removing poisoned data from the training set.\nOur approach consists of two steps. We first train an ensemble of weak learners\nto automatically discover distinct subpopulations in the training set. We then\nleverage a boosting framework to recover the clean data. Empirically, our\nmethod successfully defends against several state-of-the-art backdoor attacks,\nincluding both clean and dirty label attacks. We also present results from an\nindependent third-party evaluation including a recent \\textit{adaptive}\npoisoning adversary. The results indicate our approach is competitive with\nexisting defenses against backdoor attacks on deep neural networks, and\nsignificantly outperforms the state-of-the-art in several scenarios.",
    "descriptor": "",
    "authors": [
      "Charles Jin",
      "Melinda Sun",
      "Martin Rinard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03692"
  },
  {
    "id": "arXiv:2105.03693",
    "title": "On the discrepancy of set systems definable in sparse graph classes",
    "abstract": "Discrepancy is a natural measure for the inherent complexity of set systems\nwith many applications in mathematics and computer science. The discrepancy of\na set system $(U,\\mathscr S)$ is the minimum over all mappings $\\chi\\colon\nU\\rightarrow\\{-1,1\\}$ of $\\max_{S\\in\\mathscr S}\\bigl|\\sum_{v\\in\nS}\\chi(v)\\bigr|$. We study the discrepancy of set systems that are first-order\ndefinable in sparse graph classes. We prove that all the set systems definable\nin a monotone class $\\mathscr C$ have bounded discrepancy if and only if\n$\\mathscr C$ has bounded expansion, and that they have hereditary discrepancy\nat most $|U|^{c}$ (for some~$c<1/2$) if and only if $\\mathscr C$ is nowhere\ndense. However, if $\\mathscr C$ is somewhere dense, then for every positive\ninteger $d$ there is a set system of $d$-tuples definable in $\\mathscr C$ with\ndiscrepancy $\\Omega(|U|^{1/2})$.\nFrom the algorithmic point of view, we prove that if $\\mathscr C$ is a class\nof graphs with bounded expansion and $\\phi(\\bar x;\\bar y)$ is a first-order\nformula, then for each input graph $G\\in\\mathscr C$, a mapping\n$\\chi:V(G)^{|\\bar x|}\\rightarrow\\{-1,1\\}$ witnessing the boundedness of the\ndiscrepancy of the set-system defined by~$\\phi$ can be computed in $\\mathcal\nO(|G|^{|\\bar x|})$ time. We also deduce that for such set-systems, when $|\\bar\nx|=1$, $\\varepsilon$-nets of size $\\mathcal{O}(1/\\varepsilon)$ can be computed\nin time $\\mathcal{O}(|G|\\,\\log |G|)$ and $\\varepsilon$-approximations of size\n$\\mathcal{O}(1/\\varepsilon)$ can be computed in polynomial time.",
    "descriptor": "",
    "authors": [
      "Mario Grobler",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03693"
  },
  {
    "id": "arXiv:2105.03695",
    "title": "LPVcore: MATLAB Toolbox for LPV Modelling, Identification and Control",
    "abstract": "This paper describes the LPVcore software package for MATLAB developed to\nmodel, simulate, estimate and control systems via linear parameter-varying\n(LPV) input-output (IO), state-space (SS) and linear fractional (LFR)\nrepresentations. In the LPVcore toolbox, basis affine parameter-varying matrix\nfunctions are implemented to enable users to represent LPV systems in a global\nsetting, i.e., for time-varying scheduling trajectories. This is a key\ndifference compared to other software suites that use a grid or only LFR-based\nrepresentations. The paper contains an overview of functions in the toolbox to\nsimulate and identify IO, SS and LFR representations. Based on various\nprediction-error minimization methods, a comprehensive example is given on the\nidentification of a DC motor with an unbalanced disc, demonstrating the\ncapabilities of the toolbox. The software and examples are available on\nwww.lpvcore.net.",
    "descriptor": "",
    "authors": [
      "P. den Boef",
      "P. B. Cox",
      "R. T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03695"
  },
  {
    "id": "arXiv:2105.03701",
    "title": "Business Entity Matching with Siamese Graph Convolutional Networks",
    "abstract": "Data integration has been studied extensively for decades and approached from\ndifferent angles. However, this domain still remains largely rule-driven and\nlacks universal automation. Recent developments in machine learning and in\nparticular deep learning have opened the way to more general and efficient\nsolutions to data-integration tasks. In this paper, we demonstrate an approach\nthat allows modeling and integrating entities by leveraging their relations and\ncontextual information. This is achieved by combining siamese and graph neural\nnetworks to effectively propagate information between connected entities and\nsupport high scalability. We evaluated our approach on the task of integrating\ndata about business entities, demonstrating that it outperforms both\ntraditional rule-based systems and other deep learning approaches.",
    "descriptor": "",
    "authors": [
      "Evgeny Krivosheev",
      "Mattia Atzeni",
      "Katsiaryna Mirylenka",
      "Paolo Scotton",
      "Christoph Miksovic",
      "Anton Zorin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03701"
  },
  {
    "id": "arXiv:2105.03702",
    "title": "On a conjecture on APN permutations",
    "abstract": "The single trivariate representation proposed in [C. Beierle, C. Carlet, G.\nLeander, L. Perrin, A Further Study of Quadratic APN Permutations in Dimension\nNine, arXiv:2104.08008] of the two sporadic quadratic APN permutations in\ndimension 9 found by Beierle and Leander \\cite{Beierle} is further\ninvestigated. In particular, using tools from algebraic geometry over finite\nfields, we prove that such a family does not contain any other APN permutation\nfor larger dimensions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Daniele Bartoli",
      "Marco Timpanella"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.03702"
  },
  {
    "id": "arXiv:2105.03703",
    "title": "Tensor Programs IIb: Architectural Universality of Neural Tangent Kernel  Training Dynamics",
    "abstract": "Yang (2020a) recently showed that the Neural Tangent Kernel (NTK) at\ninitialization has an infinite-width limit for a large class of architectures\nincluding modern staples such as ResNet and Transformers. However, their\nanalysis does not apply to training. Here, we show the same neural networks (in\nthe so-called NTK parametrization) during training follow a kernel gradient\ndescent dynamics in function space, where the kernel is the infinite-width NTK.\nThis completes the proof of the *architectural universality* of NTK behavior.\nTo achieve this result, we apply the Tensor Programs technique: Write the\nentire SGD dynamics inside a Tensor Program and analyze it via the Master\nTheorem. To facilitate this proof, we develop a graphical notation for Tensor\nPrograms.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Greg Yang",
      "Etai Littwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.03703"
  },
  {
    "id": "arXiv:2105.03705",
    "title": "Understanding Neural Networks with Logarithm Determinant Entropy  Estimator",
    "abstract": "Understanding the informative behaviour of deep neural networks is challenged\nby misused estimators and the complexity of network structure, which leads to\ninconsistent observations and diversified interpretation. Here we propose the\nLogDet estimator -- a reliable matrix-based entropy estimator that approximates\nShannon differential entropy. We construct informative measurements based on\nLogDet estimator, verify our method with comparable experiments and utilize it\nto analyse neural network behaviour. Our results demonstrate the LogDet\nestimator overcomes the drawbacks that emerge from highly diverse and\ndegenerated distribution thus is reliable to estimate entropy in neural\nnetworks. The Network analysis results also find a functional distinction\nbetween shallow and deeper layers, which can help understand the compression\nphenomenon in the Information bottleneck theory of neural networks.",
    "descriptor": "\nComments: 15pages,22 figures\n",
    "authors": [
      "Zhanghao Zhouyin",
      "Ding Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03705"
  },
  {
    "id": "arXiv:2105.03708",
    "title": "All Together Now: Teachers as Research Partners in the Design of Search  Technology for the Classroom",
    "abstract": "In the classroom environment, search tools are the means for students to\naccess Web resources. The perspectives of students, researchers, and industry\npractitioners lead the ongoing research debate in this area. In this article,\nwe argue in favor of incorporating a new voice into this debate: teachers. We\nshowcase the value of involving teachers in all aspects related to the design\nof search tools for the classroom; from the beginning till the end. Driven by\nour research experience designing, developing, and evaluating new tools to\nsupport children's information discovery in the classroom, we share insights on\nthe role of the experts-in-the-loop, i.e., teachers who provide the connection\nbetween search tools and students. And yes, in our case, always involving a\nteacher as a research partner.",
    "descriptor": "\nComments: In KidRec '21: 5th International and Interdisciplinary Perspectives on Children & Recommender and Information Retrieval Systems (KidRec) Search and Recommendation Technology through the Lens of a Teacher- Co-located with ACM IDC 2021; June 26, 2021; Online Event\n",
    "authors": [
      "Emiliana Murgia",
      "Monica Landoni",
      "Theo Huibers",
      "Maria Soledad Pera"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.03708"
  },
  {
    "id": "arXiv:2105.03710",
    "title": "Falling Through the Gaps: Neural Architectures as Models of  Morphological Rule Learning",
    "abstract": "Recent advances in neural architectures have revived the problem of\nmorphological rule learning. We evaluate the Transformer as a model of\nmorphological rule learning and compare it with Recurrent Neural Networks (RNN)\non English, German, and Russian. We bring to the fore a hitherto overlooked\nproblem, the morphological gaps, where the expected inflection of a word is\nmissing. For example, 63 Russian verbs lack a first-person-singular present\nform such that one cannot comfortably say \"*o\\v{s}\\v{c}u\\v{s}\\v{c}u\" (\"I\nfeel\"). Even English has gaps, such as the past participle of \"stride\": the\nfunction of morphological inflection can be partial. Both neural architectures\nproduce inflections that ought to be missing. Analyses reveal that Transformers\nrecapitulate the statistical distribution of inflections in the training data,\nsimilar to RNNs. Models' success on English and German is driven by the fact\nthat rules in these languages can be identified with the majority forms, which\nis not universal.",
    "descriptor": "",
    "authors": [
      "Deniz Beser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03710"
  },
  {
    "id": "arXiv:2105.03714",
    "title": "Protecting Individual Interests across Clusters: Spectral Clustering  with Guarantees",
    "abstract": "Studies related to fairness in machine learning have recently gained traction\ndue to its ever-expanding role in high-stakes decision making. For example, it\nmay be desirable to ensure that all clusters discovered by an algorithm have\nhigh gender diversity. Previously, these problems have been studied under a\nsetting where sensitive attributes, with respect to which fairness conditions\nimpose diversity across clusters, are assumed to be observable; hence,\nprotected groups are readily available. Most often, this may not be true, and\ndiversity or individual interests can manifest as an intrinsic or latent\nfeature of a social network. For example, depending on latent sensitive\nattributes, individuals interact with each other and represent each other's\ninterests, resulting in a network, which we refer to as a representation graph.\nMotivated by this, we propose an individual fairness criterion for clustering a\ngraph $\\mathcal{G}$ that requires each cluster to contain an adequate number of\nmembers connected to the individual under a representation graph $\\mathcal{R}$.\nWe devise a spectral clustering algorithm to find fair clusters under a given\nrepresentation graph. We further propose a variant of the stochastic block\nmodel and establish our algorithm's weak consistency under this model. Finally,\nwe present experimental results to corroborate our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Shubham Gupta",
      "Ambedkar Dukkipati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03714"
  },
  {
    "id": "arXiv:2105.03716",
    "title": "Continuous representations of intents for dialogue systems",
    "abstract": "Intent modelling has become an important part of modern dialogue systems.\nWith the rapid expansion of practical dialogue systems and virtual assistants,\nsuch as Amazon Alexa, Apple Siri, and Google Assistant, the interest has only\nincreased. However, up until recently the focus has been on detecting a fixed,\ndiscrete, number of seen intents. Recent years have seen some work done on\nunseen intent detection in the context of zero-shot learning. This paper\ncontinues the prior work by proposing a novel model where intents are\ncontinuous points placed in a specialist Intent Space that yields several\nadvantages. First, the continuous representation enables to investigate\nrelationships between the seen intents. Second, it allows any unseen intent to\nbe reliably represented given limited quantities of data. Finally, this paper\nwill show how the proposed model can be augmented with unseen intents without\nretraining any of the seen ones. Experiments show that the model can reliably\nadd unseen intents with a high accuracy while retaining a high performance on\nthe seen intents.",
    "descriptor": "",
    "authors": [
      "Sindre Andr\u00e9 Jacobsen",
      "Anton Ragni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.03716"
  },
  {
    "id": "arXiv:2105.03721",
    "title": "Team Orienteering Coverage Planning with Uncertain Reward",
    "abstract": "Many municipalities and large organizations have fleets of vehicles that need\nto be coordinated for tasks such as garbage collection or infrastructure\ninspection. Motivated by this need, this paper focuses on the common subproblem\nin which a team of vehicles needs to plan coordinated routes to patrol an area\nover iterations while minimizing temporally and spatially dependent costs. In\nparticular, at a specific location (e.g., a vertex on a graph), we assume the\ncost grows linearly in expectation with an unknown rate, and the cost is reset\nto zero whenever any vehicle visits the vertex (representing the robot\nservicing the vertex). We formulate this problem in graph terminology and call\nit Team Orienteering Coverage Planning with Uncertain Reward (TOCPUR). We\npropose to solve TOCPUR by simultaneously estimating the accumulated cost at\nevery vertex on the graph and solving a novel variant of the Team Orienteering\nProblem (TOP) iteratively, which we call the Team Orienteering Coverage Problem\n(TOCP). We provide the first mixed integer programming formulation for the\nTOCP, as a significant adaptation of the original TOP. We introduce a new\nbenchmark consisting of hundreds of randomly generated graphs for comparing\ndifferent methods. We show the proposed solution outperforms both the exact TOP\nsolution and a greedy algorithm. In addition, we provide a demo of our method\non a team of three physical robots in a real-world environment.",
    "descriptor": "",
    "authors": [
      "Bo Liu",
      "Xuesu Xiao",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03721"
  },
  {
    "id": "arXiv:2105.03725",
    "title": "DAMOV: A New Methodology and Benchmark Suite for Evaluating Data  Movement Bottlenecks",
    "abstract": "Data movement between the CPU and main memory is a first-order obstacle\nagainst improving performance, scalability, and energy efficiency in modern\nsystems. Computer systems employ a range of techniques to reduce overheads tied\nto data movement, spanning from traditional mechanisms (e.g., deep multi-level\ncache hierarchies, aggressive hardware prefetchers) to emerging techniques such\nas Near-Data Processing (NDP), where some computation is moved close to memory.\nOur goal is to methodically identify potential sources of data movement over a\nbroad set of applications and to comprehensively compare traditional\ncompute-centric data movement mitigation techniques to more memory-centric\ntechniques, thereby developing a rigorous understanding of the best techniques\nto mitigate each source of data movement.\nWith this goal in mind, we perform the first large-scale characterization of\na wide variety of applications, across a wide range of application domains, to\nidentify fundamental program properties that lead to data movement to/from main\nmemory. We develop the first systematic methodology to classify applications\nbased on the sources contributing to data movement bottlenecks. From our\nlarge-scale characterization of 77K functions across 345 applications, we\nselect 144 functions to form the first open-source benchmark suite (DAMOV) for\nmain memory data movement studies. We select a diverse range of functions that\n(1) represent different types of data movement bottlenecks, and (2) come from a\nwide range of application domains. Using NDP as a case study, we identify new\ninsights about the different data movement bottlenecks and use these insights\nto determine the most suitable data movement mitigation mechanism for a\nparticular application. We open-source DAMOV and the complete source code for\nour new characterization methodology at https://github.com/CMU-SAFARI/DAMOV.",
    "descriptor": "\nComments: This paper is accepted to SIGMETRICS 2021 and will be presented at the conference in June 2021. Our open source software will be released after the presentation at SIGMETRICS 2021\n",
    "authors": [
      "Geraldo F. Oliveira",
      "Juan G\u00f3mez-Luna",
      "Lois Orosa",
      "Saugata Ghose",
      "Nandita Vijaykumar",
      "Ivan Fernandez",
      "Mohammad Sadrosadati",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03725"
  },
  {
    "id": "arXiv:2105.03726",
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": "Although machine learning (ML) is widely used in practice, little is known\nabout practitioners' actual understanding of potential security challenges. In\nthis work, we close this substantial gap in the literature and contribute a\nqualitative study focusing on developers' mental models of the ML pipeline and\npotentially vulnerable components. Studying mental models has helped in other\nsecurity fields to discover root causes or improve risk communication. Our\nstudy reveals four characteristic ranges in mental models of industrial\npractitioners. The first range concerns the intertwined relationship of\nadversarial machine learning (AML) and classical security. The second range\ndescribes structural and functional components. The third range expresses\nindividual variations of mental models, which are neither explained by the\napplication nor by the educational background of the corresponding subjects.\nThe fourth range corresponds to the varying levels of technical depth, which\nare however not determined by our subjects' level of knowledge. Our\ncharacteristic ranges have implications for the integration of AML into\ncorporate workflows, security enhancing tools for practitioners, and creating\nappropriate regulatory frameworks for AML.",
    "descriptor": "\nComments: 19 pages, 8 figures, under submission\n",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Katharina Krombholz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03726"
  },
  {
    "id": "arXiv:2105.03731",
    "title": "Time integrators for dispersive equations in the long wave regime",
    "abstract": "We introduce a novel class of time integrators for dispersive equations which\nallow us to reproduce the dynamics of the solution from the classical $\n\\varepsilon = 1$ up to long wave limit regime $ \\varepsilon \\ll 1 $ on the\nnatural time scale of the PDE $t= \\mathcal{O}(\\frac{1}{\\varepsilon})$. Most\nnotably our new schemes converge with rates at order $\\tau \\varepsilon$ over\nlong times $t= \\frac{1}{\\varepsilon}$.",
    "descriptor": "",
    "authors": [
      "Mar\u00eda Cabrera Calvo",
      "Fr\u00e9d\u00e9ric Rousset",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03731"
  },
  {
    "id": "arXiv:2105.03732",
    "title": "Uniformly accurate splitting schemes for the Benjamin-Bona-Mahony  equation with dispersive parameter",
    "abstract": "We propose a new class of uniformly accurate splitting methods for the\nBenjamin-Bona-Mahony equation which converge uniformly in the dispersive\nparameter $\\varepsilon$. The proposed splitting schemes are furthermore\nasymptotic convergent and preserve the KdV limit. We carry out a rigorous\nconvergence analysis of the splitting schemes exploiting the smoothing\nproperties in the system. This will allow us to establish improved error bounds\nwith gain either in regularity (for non smooth solutions) or in the dispersive\nparameter $\\varepsilon$. The latter will be interesting in regimes of a small\ndispersive parameter. We will in particular show that in the classical BBM case\n$P(\\partial_x) = \\partial_x$ our Lie splitting does not require any spatial\nregularity, i.e, first order time convergence holds in $H^{r}$ for solutions in\n$H^{r}$ without any loss of derivative. This estimate holds uniformly in\n$\\varepsilon$. In regularizing regimes $\\varepsilon=\\mathcal{O}(1) $ we even\ngain a derivative with our time discretisation at the cost of loosing in terms\nof $\\frac{1}{\\varepsilon}$. Numerical experiments underline our theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Mar\u00eda Cabrera Calvo",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03732"
  },
  {
    "id": "arXiv:2105.03733",
    "title": "Generative Actor-Critic: An Off-policy Algorithm Using the Push-forward  Model",
    "abstract": "Model-free deep reinforcement learning has achieved great success in many\ndomains, such as video games, recommendation systems and robotic control tasks.\nIn continuous control tasks, widely used policies with Gaussian distributions\nresults in ineffective exploration of environments and limited performance of\nalgorithms in many cases. In this paper, we propose a density-free off-policy\nalgorithm, Generative Actor-Critic(GAC), using the push-forward model to\nincrease the expressiveness of policies, which also includes an entropy-like\ntechnique, MMD-entropy regularizer, to balance the exploration and\nexploitation. Additionnally, we devise an adaptive mechanism to automatically\nscale this regularizer, which further improves the stability and robustness of\nGAC. The experiment results show that push-forward policies possess desirable\nfeatures, such as multi-modality, which can improve the efficiency of\nexploration and asymptotic performance of algorithms obviously.",
    "descriptor": "",
    "authors": [
      "Peng Lingwei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03733"
  },
  {
    "id": "arXiv:2105.03736",
    "title": "PIM-DRAM:Accelerating Machine Learning Workloads using Processing in  Memory based on DRAM Technology",
    "abstract": "Deep Neural Networks (DNNs) have gained significant interest in the recent\npast for plethora of applications such as image and video analytics, language\ntranslation, and medical diagnosis. High memory bandwidth is required to keep\nup with the needs of data-intensive DNN applications when implemented on a\nvon-Neumann hardware architecture as majority of the data resides in the main\nmemory. Therefore, processing in memory can provide a promising solution for\nthe memory wall bottleneck for ML workloads. In this work, we propose a\nDRAM-based processing-in-memory (PIM) multiplication primitive coupled with\nintra-bank accumulation to accelerate matrix vector operations in ML workloads.\nMoreover, we propose a processing-in-memory DRAM bank architecture, data\nmapping and dataflow based on the proposed primitive. System evaluations\nperformed on networks like AlexNet, VGG16 and ResNet18 show that the proposed\narchitecture, mapping, and data flow can provide up to 23x and 6.5x benefits\nover a GPU and an ideal conventional (non-PIM) baseline architecture with\ninfinite compute bandwidth, respectively.",
    "descriptor": "",
    "authors": [
      "Sourjya Roy",
      "Mustafa Ali",
      "Anand Raghunathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.03736"
  },
  {
    "id": "arXiv:2105.03743",
    "title": "Certified Robustness to Text Adversarial Attacks by Randomized [MASK]",
    "abstract": "Recently, few certified defense methods have been developed to provably\nguarantee the robustness of a text classifier to adversarial synonym\nsubstitutions. However, all existing certified defense methods assume that the\ndefenders are informed of how the adversaries generate synonyms, which is not a\nrealistic scenario. In this paper, we propose a certifiably robust defense\nmethod by randomly masking a certain proportion of the words in an input text,\nin which the above unrealistic assumption is no longer necessary. The proposed\nmethod can defend against not only word substitution-based attacks, but also\ncharacter-level perturbations. We can certify the classifications of over 50%\ntexts to be robust to any perturbation of 5 words on AGNEWS, and 2 words on\nSST2 dataset. The experimental results show that our randomized smoothing\nmethod significantly outperforms recently proposed defense methods across\nmultiple datasets.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2021, Long Paper\n",
    "authors": [
      "Jiehang Zeng",
      "Xiaoqing Zheng",
      "Jianhan Xu",
      "Linyang Li",
      "Liping Yuan",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03743"
  },
  {
    "id": "arXiv:2105.03746",
    "title": "Contrastive Conditional Transport for Representation Learning",
    "abstract": "Contrastive learning (CL) has achieved remarkable success in learning data\nrepresentations without label supervision. However, the conventional CL loss is\nsensitive to how many negative samples are included and how they are selected.\nThis paper proposes contrastive conditional transport (CCT) that defines its CL\nloss over dependent sample-query pairs, which in practice is realized by\ndrawing a random query, randomly selecting positive and negative samples, and\ncontrastively reweighting these samples according to their distances to the\nquery, exerting a greater force to both pull more distant positive samples\ntowards the query and push closer negative samples away from the query.\nTheoretical analysis shows that this unique contrastive reweighting scheme\nhelps in the representation space to both align the positive samples with the\nquery and reduce the mutual information between the negative sample and query.\nExtensive large-scale experiments on standard vision tasks show that CCT not\nonly consistently outperforms existing methods on benchmark datasets in\ncontrastive representation learning but also provides interpretable contrastive\nweights and latent representations. PyTorch code will be provided.",
    "descriptor": "",
    "authors": [
      "Huangjie Zheng",
      "Xu Chen",
      "Jiangchao Yao",
      "Hongxia Yang",
      "Chunyuan Li",
      "Ya Zhang",
      "Hao Zhang",
      "Ivor Tsang",
      "Jingren Zhou",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03746"
  },
  {
    "id": "arXiv:2105.03748",
    "title": "Simulating User Satisfaction for the Evaluation of Task-oriented  Dialogue Systems",
    "abstract": "Evaluation is crucial in the development process of task-oriented dialogue\nsystems. As an evaluation method, user simulation allows us to tackle issues\nsuch as scalability and cost-efficiency, making it a viable choice for\nlarge-scale automatic evaluation. To help build a human-like user simulator\nthat can measure the quality of a dialogue, we propose the following task:\nsimulating user satisfaction for the evaluation of task-oriented dialogue\nsystems. The purpose of the task is to increase the evaluation power of user\nsimulations and to make the simulation more human-like. To overcome a lack of\nannotated data, we propose a user satisfaction annotation dataset, USS, that\nincludes 6,800 dialogues sampled from multiple domains, spanning real-world\ne-commerce dialogues, task-oriented dialogues constructed through Wizard-of-Oz\nexperiments, and movie recommendation dialogues. All user utterances in those\ndialogues, as well as the dialogues themselves, have been labeled based on a\n5-level satisfaction scale. We also share three baseline methods for user\nsatisfaction prediction and action prediction tasks. Experiments conducted on\nthe USS dataset suggest that distributed representations outperform\nfeature-based methods. A model based on hierarchical GRUs achieves the best\nperformance in in-domain user satisfaction prediction, while a BERT-based model\nhas better cross-domain generalization ability.",
    "descriptor": "\nComments: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21), 2021\n",
    "authors": [
      "Weiwei Sun",
      "Shuo Zhang",
      "Krisztian Balog",
      "Zhaochun Ren",
      "Pengjie Ren",
      "Zhumin Chen",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03748"
  },
  {
    "id": "arXiv:2105.03753",
    "title": "Parameterized Complexity of Feature Selection for Categorical Data  Clustering",
    "abstract": "We develop new algorithmic methods with provable guarantees for feature\nselection in regard to categorical data clustering. While feature selection is\none of the most common approaches to reduce dimensionality in practice, most of\nthe known feature selection methods are heuristics. We study the following\nmathematical model. We assume that there are some inadvertent (or undesirable)\nfeatures of the input data that unnecessarily increase the cost of clustering.\nConsequently, we want to select a subset of the original features from the data\nsuch that there is a small-cost clustering on the selected features. More\nprecisely, for given integers $\\ell$ (the number of irrelevant features) and\n$k$ (the number of clusters), budget $B$, and a set of $n$ categorical data\npoints (represented by $m$-dimensional vectors whose elements belong to a\nfinite set of values $\\Sigma$), we want to select $m-\\ell$ relevant features\nsuch that the cost of any optimal $k$-clustering on these features does not\nexceed $B$. Here the cost of a cluster is the sum of Hamming distances\n($\\ell_0$-distances) between the selected features of the elements of the\ncluster and its center. The clustering cost is the total sum of the costs of\nthe clusters. We use the framework of parameterized complexity to identify how\nthe complexity of the problem depends on parameters $k$, $B$, and $|\\Sigma|$.\nOur main result is an algorithm that solves the Feature Selection problem in\ntime $f(k,B,|\\Sigma|)\\cdot m^{g(k,|\\Sigma|)}\\cdot n^2$ for some functions $f$\nand $g$. In other words, the problem is fixed-parameter tractable parameterized\nby $B$ when $|\\Sigma|$ and $k$ are constants. Our algorithm is based on a\nsolution to a more general problem, Constrained Clustering with Outliers. We\nalso complement our algorithmic findings with complexity lower bounds.",
    "descriptor": "\nComments: 25 pages, full version\n",
    "authors": [
      "Sayan Bandyapadhyay",
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.03753"
  },
  {
    "id": "arXiv:2105.03756",
    "title": "RAIL: A modular framework for Reinforcement-learning-based Adversarial  Imitation Learning",
    "abstract": "While Adversarial Imitation Learning (AIL) algorithms have recently led to\nstate-of-the-art results on various imitation learning benchmarks, it is\nunclear as to what impact various design decisions have on performance. To this\nend, we present here an organizing, modular framework called\nReinforcement-learning-based Adversarial Imitation Learning (RAIL) that\nencompasses and generalizes a popular subclass of existing AIL approaches.\nUsing the view espoused by RAIL, we create two new IfO (Imitation from\nObservation) algorithms, which we term SAIfO: SAC-based Adversarial Imitation\nfrom Observation and SILEM (Skeletal Feature Compensation for Imitation\nLearning with Embodiment Mismatch). We go into greater depth about SILEM in a\nseparate technical report. In this paper, we focus on SAIfO, evaluating it on a\nsuite of locomotion tasks from OpenAI Gym, and showing that it outperforms\ncontemporaneous RAIL algorithms that perform IfO.",
    "descriptor": "",
    "authors": [
      "Eddy Hudson",
      "Garrett Warnell",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03756"
  },
  {
    "id": "arXiv:2105.03759",
    "title": "Multi-layered planar firefighting",
    "abstract": "Consider a model of fire spreading through a graph; initially some vertices\nare burning, and at every given time-step fire spreads from burning vertices to\ntheir neighbours. The firefighter problem is a solitaire game in which a player\nis allowed, at every time-step, to protect some non-burning vertices (by\neffectively deleting them) in order to contain the fire growth. How many\nvertices per turn, on average, must be protected in order to stop the fire from\nspreading infinitely?\nHere we consider the problem on $\\mathbb{Z}^2\\times [h]$ for both nearest\nneighbour adjacency and strong adjacency. We determine the critical protection\nrates for these graphs to be $1.5h$ and $3h$, respectively. This establishes\nthe fact that using an optimal two-dimensional strategy for all layers in\nparallel is asymptotically optimal.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Arye Deutch",
      "Ohad Noy Feldheim",
      "Rani Hod"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.03759"
  },
  {
    "id": "arXiv:2105.03760",
    "title": "PCA Event-Based Otical Flow for Visual Odometry",
    "abstract": "With the advent of neuromorphic vision sensors such as event-based cameras, a\nparadigm shift is required for most computer vision algorithms. Among these\nalgorithms, optical flow estimation is a prime candidate for this process\nconsidering that it is linked to a neuromorphic vision approach. Usage of\noptical flow is widespread in robotics applications due to its richness and\naccuracy. We present a Principal Component Analysis (PCA) approach to the\nproblem of event-based optical flow estimation. In this approach, we examine\ndifferent regularization methods which efficiently enhance the estimation of\nthe optical flow. We show that the best variant of our proposed method,\ndedicated to the real-time context of visual odometry, is about two times\nfaster compared to state-of-the-art implementations while significantly\nimproves optical flow accuracy.",
    "descriptor": "\nComments: 9 pages, 8 figures, not published yet\n",
    "authors": [
      "Mahmoud Z. Khairallah",
      "Fabien Bonardi",
      "David Roussel",
      "Samia Bouchafa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03760"
  },
  {
    "id": "arXiv:2105.03761",
    "title": "e-ViL: A Dataset and Benchmark for Natural Language Explanations in  Vision-Language Tasks",
    "abstract": "Recently, an increasing number of works have introduced models capable of\ngenerating natural language explanations (NLEs) for their predictions on\nvision-language (VL) tasks. Such models are appealing because they can provide\nhuman-friendly and comprehensive explanations. However, there is still a lack\nof unified evaluation approaches for the explanations generated by these\nmodels. Moreover, there are currently only few datasets of NLEs for VL tasks.\nIn this work, we introduce e-ViL, a benchmark for explainable vision-language\ntasks that establishes a unified evaluation framework and provides the first\ncomprehensive comparison of existing approaches that generate NLEs for VL\ntasks. e-ViL spans four models and three datasets. Both automatic metrics and\nhuman evaluation are used to assess model-generated explanations. We also\nintroduce e-SNLI-VE, the largest existing VL dataset with NLEs (over 430k\ninstances). Finally, we propose a new model that combines UNITER, which learns\njoint embeddings of images and text, and GPT-2, a pre-trained language model\nthat is well-suited for text generation. It surpasses the previous\nstate-of-the-art by a large margin across all datasets.",
    "descriptor": "",
    "authors": [
      "Maxime Kayser",
      "Oana-Maria Camburu",
      "Leonard Salewski",
      "Cornelius Emde",
      "Virginie Do",
      "Zeynep Akata",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03761"
  },
  {
    "id": "arXiv:2105.03767",
    "title": "Aerospace Sliding Mode Control Toolbox: Relative Degree Approach with  Resource Prospector Lander and Launch Vehicle Case Studies",
    "abstract": "Conventional Sliding mode control and observation techniques are widely used\nin aerospace applications, including aircrafts, UAVs, launch vehicles, missile\ninterceptors, and hypersonic missiles. This work is dedicated to creating a\nMATLAB-based sliding mode controller design and simulation software toolbox\nthat aims to support aerospace vehicle applications. An architecture of the\naerospace sliding mode control toolbox (SMC Aero) using the relative degree\napproach is proposed. The SMC Aero libraries include 1st order sliding mode\ncontrol (1-SMC), second order sliding mode control (2-SMC), higher order\nsliding mode (HOSM) control (either fixed gain or adaptive), as well as higher\norder sliding mode differentiators. The efficacy of the SMC Aero toolbox is\nconfirmed in two case studies: controlling and simulating resource prospector\nlander (RPL) soft landing on the Moon and launch vehicle (LV) attitude control\nin ascent mode.",
    "descriptor": "",
    "authors": [
      "S. Kode",
      "Y. Shtessel",
      "A. Levant",
      "J. Rakoczy",
      "M. Hannan",
      "J. Orr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03767"
  },
  {
    "id": "arXiv:2105.03773",
    "title": "Separations for Estimating Large Frequency Moments on Data Streams",
    "abstract": "We study the classical problem of moment estimation of an underlying vector\nwhose $n$ coordinates are implicitly defined through a series of updates in a\ndata stream. We show that if the updates to the vector arrive in the\nrandom-order insertion-only model, then there exist space efficient algorithms\nwith improved dependencies on the approximation parameter $\\varepsilon$. In\nparticular, for any real $p > 2$, we first obtain an algorithm for $F_p$ moment\nestimation using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^{4/p}}\\cdot\nn^{1-2/p}\\right)$ bits of memory. Our techniques also give algorithms for $F_p$\nmoment estimation with $p>2$ on arbitrary order insertion-only and turnstile\nstreams, using $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^{4/p}}\\cdot\nn^{1-2/p}\\right)$ bits of space and two passes, which is the first optimal\nmulti-pass $F_p$ estimation algorithm up to $\\log n$ factors. Finally, we give\nan improved lower bound of $\\Omega\\left(\\frac{1}{\\varepsilon^2}\\cdot\nn^{1-2/p}\\right)$ for one-pass insertion-only streams. Our results separate the\ncomplexity of this problem both between random and non-random orders, as well\nas one-pass and multi-pass streams.",
    "descriptor": "",
    "authors": [
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03773"
  },
  {
    "id": "arXiv:2105.03775",
    "title": "NLP-IIS@UT at SemEval-2021 Task 4: Machine Reading Comprehension using  the Long Document Transformer",
    "abstract": "This paper presents a technical report of our submission to the 4th task of\nSemEval-2021, titled: Reading Comprehension of Abstract Meaning. In this task,\nwe want to predict the correct answer based on a question given a context.\nUsually, contexts are very lengthy and require a large receptive field from the\nmodel. Thus, common contextualized language models like BERT miss fine\nrepresentation and performance due to the limited capacity of the input tokens.\nTo tackle this problem, we used the Longformer model to better process the\nsequences. Furthermore, we utilized the method proposed in the Longformer\nbenchmark on Wikihop dataset which improved the accuracy on our task data from\n23.01% and 22.95% achieved by the baselines for subtask 1 and 2, respectively,\nto 70.30% and 64.38%.",
    "descriptor": "\nComments: 6 pages, 1 figure. Accepted in SemEval2021\n",
    "authors": [
      "Hossein Basafa",
      "Sajad Movahedi",
      "Ali Ebrahimi",
      "Azadeh Shakery",
      "Heshaam Faili"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03775"
  },
  {
    "id": "arXiv:2105.03778",
    "title": "An Exhaustive Study of Using Commercial LTE Network for UAV  Communication in Rural Areas",
    "abstract": "Unmanned aerial vehicles (UAVs) have been increasingly used in a wide area of\nmilitary and civilian applications such as data collection and monitoring. A\nreliable network for command and control, communication, and data transfer is\ncrucial, not only for mission purposes but also for safety concerns. The\nalready deployed cellular networks are appropriate candidates for UAV\ncommunication given the solid security and wide coverage of these networks.\nHowever, the reliability of such networks needs a comprehensive investigation.\nIn this paper, we use the long-term evolution (LTE) network as the\ninfrastructure for drone communication and data transfer, in a rural area. We\nstudy the communication characteristics of an LTE-connected drone during\nlow-altitude flights, for different altitudes and UAV speeds. We show that, in\nsuch areas, the higher elevation benefits from a better signal quality and\nexperiences a fewer number of handover processes. Higher speed flights also\nslightly degrade the communication performance.",
    "descriptor": "",
    "authors": [
      "Mohammed Gharib",
      "Shashidhar Nandadapu",
      "Fatemeh Afghah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03778"
  },
  {
    "id": "arXiv:2105.03781",
    "title": "MetaKernel: Learning Variational Random Features with Limited Labels",
    "abstract": "Few-shot learning deals with the fundamental and challenging problem of\nlearning from a few annotated samples, while being able to generalize well on\nnew tasks. The crux of few-shot learning is to extract prior knowledge from\nrelated tasks to enable fast adaptation to a new task with a limited amount of\ndata. In this paper, we propose meta-learning kernels with random Fourier\nfeatures for few-shot learning, we call MetaKernel. Specifically, we propose\nlearning variational random features in a data-driven manner to obtain\ntask-specific kernels by leveraging the shared knowledge provided by related\ntasks in a meta-learning setting. We treat the random feature basis as the\nlatent variable, which is estimated by variational inference. The shared\nknowledge from related tasks is incorporated into a context inference of the\nposterior, which we achieve via a long-short term memory module. To establish\nmore expressive kernels, we deploy conditional normalizing flows based on\ncoupling layers to achieve a richer posterior distribution over random Fourier\nbases. The resultant kernels are more informative and discriminative, which\nfurther improves the few-shot learning. To evaluate our method, we conduct\nextensive experiments on both few-shot image classification and regression\ntasks. A thorough ablation study demonstrates that the effectiveness of each\nintroduced component in our method. The benchmark results on fourteen datasets\ndemonstrate MetaKernel consistently delivers at least comparable and often\nbetter performance than state-of-the-art alternatives.",
    "descriptor": "\nComments: 19 pages,7 figures. arXiv admin note: substantial text overlap with arXiv:2006.06707\n",
    "authors": [
      "Yingjun Du",
      "Haoliang Sun",
      "Xiantong Zhen",
      "Jun Xu",
      "Yilong Yin",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03781"
  },
  {
    "id": "arXiv:2105.03782",
    "title": "Construction of Sparse Suffix Trees and LCE Indexes in Optimal Time and  Space",
    "abstract": "The notions of synchronizing and partitioning sets are recently introduced\nvariants of locally consistent parsings with great potential in\nproblem-solving. In this paper we propose a deterministic algorithm that\nconstructs for a given readonly string of length $n$ over the alphabet\n$\\{0,1,\\ldots,n^{\\mathcal{O}(1)}\\}$ a version of $\\tau$-partitioning set with\nsize $\\mathcal{O}(b)$ and $\\tau = \\frac{n}{b}$ using $\\mathcal{O}(b)$ space and\n$\\mathcal{O}(\\frac{1}{\\epsilon}n)$ time provided $b \\ge n^\\epsilon$, for\n$\\epsilon > 0$. As a corollary, for $b \\ge n^\\epsilon$ and constant $\\epsilon >\n0$, we obtain linear construction algorithms with $\\mathcal{O}(b)$ space on top\nof the string for two major small-space indexes: a sparse suffix tree, which is\na compacted trie built on $b$ chosen suffixes of the string, and a longest\ncommon extension (LCE) index, which occupies $\\mathcal{O}(b)$ space and allows\nus to compute the longest common prefix for any pair of substrings in\n$\\mathcal{O}(n/b)$ time. For both, the $\\mathcal{O}(b)$ construction storage is\nasymptotically optimal since the tree itself takes $\\mathcal{O}(b)$ space and\nany LCE index with $\\mathcal{O}(n/b)$ query time must occupy at least\n$\\mathcal{O}(b)$ space by a known trade-off (at least for $b \\ge \\Omega(n /\n\\log n)$). In case of arbitrary $b \\ge \\Omega(\\log^2 n)$, we present\nconstruction algorithms for the partitioning set, sparse suffix tree, and LCE\nindex with $\\mathcal{O}(n\\log_b n)$ running time and $\\mathcal{O}(b)$ space,\nthus also improving the state of the art.",
    "descriptor": "\nComments: 26 pages, 2 figures\n",
    "authors": [
      "Dmitry Kosolobov",
      "Nikita Sivukhin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03782"
  },
  {
    "id": "arXiv:2105.03788",
    "title": "Dynamic Game Theoretic Neural Optimizer",
    "abstract": "The connection between training deep neural networks (DNNs) and optimal\ncontrol theory (OCT) has attracted considerable attention as a principled tool\nof algorithmic design. Despite few attempts being made, they have been limited\nto architectures where the layer propagation resembles a Markovian dynamical\nsystem. This casts doubts on their flexibility to modern networks that heavily\nrely on non-Markovian dependencies between layers (e.g. skip connections in\nresidual networks). In this work, we propose a novel dynamic game perspective\nby viewing each layer as a player in a dynamic game characterized by the DNN\nitself. Through this lens, different classes of optimizers can be seen as\nmatching different types of Nash equilibria, depending on the implicit\ninformation structure of each (p)layer. The resulting method, called Dynamic\nGame Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired\noptimizers to richer network class; it also motivates a new training principle\nby solving a multi-player cooperative game. DGNOpt shows convergence\nimprovements over existing methods on image classification datasets with\nresidual networks. Our work marries strengths from both OCT and game theory,\npaving ways to new algorithmic opportunities from robust optimal control and\nbandit-based optimization.",
    "descriptor": "\nComments: Accepted in International Conference on Machine Learning (ICML) 2021 as Oral\n",
    "authors": [
      "Guan-Horng Liu",
      "Tianrong Chen",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.03788"
  },
  {
    "id": "arXiv:2105.03789",
    "title": "Kudu: An Efficient and Scalable Distributed Graph Pattern Mining Engine",
    "abstract": "This paper proposes Kudu, a general distributed execution engine with a\nwell-defined abstraction that can be integrated with various existing\nsingle-machine graph pattern mining (GPM) systems. With this approach, the\nprogramming interfaces and codes based on existing GPM systems do not change\nand Kudu can transparently enable the distributed execution. The key novelty is\nextendable embedding which can express pattern enumeration algorithm and enable\nfine-grained task scheduling. To enable efficient scheduling, we propose a\nnovel BFS-DFS hybrid exploration method that generates sufficient concurrent\ntasks without incurring high memory consumption. The computation and\ncommunication of Kudu can be further optimized with several effective\ntechniques. We implemented two scalable distributed GPM systems by porting\nAutomine and GraphPi on Kudu. Our evaluation shows that Kudu-based systems\nsignificantly outperform state-of-the-art graph partition-based GPM systems by\nup to three orders of magnitude, achieve similar or even better performance\ncompared with the fastest graph replication-based systems, and scale to large\ndatasets with graph partitioning.",
    "descriptor": "",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.03789"
  },
  {
    "id": "arXiv:2105.03790",
    "title": "Distribution Matching for Heterogeneous Multi-Task Learning: a  Large-scale Face Study",
    "abstract": "Multi-Task Learning has emerged as a methodology in which multiple tasks are\njointly learned by a shared learning algorithm, such as a DNN. MTL is based on\nthe assumption that the tasks under consideration are related; therefore it\nexploits shared knowledge for improving performance on each individual task.\nTasks are generally considered to be homogeneous, i.e., to refer to the same\ntype of problem. Moreover, MTL is usually based on ground truth annotations\nwith full, or partial overlap across tasks. In this work, we deal with\nheterogeneous MTL, simultaneously addressing detection, classification &\nregression problems. We explore task-relatedness as a means for co-training, in\na weakly-supervised way, tasks that contain little, or even non-overlapping\nannotations. Task-relatedness is introduced in MTL, either explicitly through\nprior expert knowledge, or through data-driven studies. We propose a novel\ndistribution matching approach, in which knowledge exchange is enabled between\ntasks, via matching of their predictions' distributions. Based on this\napproach, we build FaceBehaviorNet, the first framework for large-scale face\nanalysis, by jointly learning all facial behavior tasks. We develop case\nstudies for: i) continuous affect estimation, action unit detection, basic\nemotion recognition; ii) attribute detection, face identification.\nWe illustrate that co-training via task relatedness alleviates negative\ntransfer. Since FaceBehaviorNet learns features that encapsulate all aspects of\nfacial behavior, we conduct zero-/few-shot learning to perform tasks beyond the\nones that it has been trained for, such as compound emotion recognition. By\nconducting a very large experimental study, utilizing 10 databases, we\nillustrate that our approach outperforms, by large margins, the\nstate-of-the-art in all tasks and in all databases, even in these which have\nnot been used in its training.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.15792, arXiv:1910.11111\n",
    "authors": [
      "Dimitrios Kollias",
      "Viktoriia Sharmanska",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03790"
  },
  {
    "id": "arXiv:2105.03791",
    "title": "Enhancing Transformers with Gradient Boosted Decision Trees for NLI  Fine-Tuning",
    "abstract": "Transfer learning has become the dominant paradigm for many natural language\nprocessing tasks. In addition to models being pretrained on large datasets,\nthey can be further trained on intermediate (supervised) tasks that are similar\nto the target task. For small Natural Language Inference (NLI) datasets,\nlanguage modelling is typically followed by pretraining on a large (labelled)\nNLI dataset before fine-tuning with each NLI subtask. In this work, we explore\nGradient Boosted Decision Trees (GBDTs) as an alternative to the commonly used\nMulti-Layer Perceptron (MLP) classification head. GBDTs have desirable\nproperties such as good performance on dense, numerical features and are\neffective where the ratio of the number of samples w.r.t the number of features\nis low. We then introduce FreeGBDT, a method of fitting a GBDT head on the\nfeatures computed during fine-tuning to increase performance without additional\ncomputation by the neural network. We demonstrate the effectiveness of our\nmethod on several NLI datasets using a strong baseline model (RoBERTa-large\nwith MNLI pretraining). The FreeGBDT shows a consistent improvement over the\nMLP classification head.",
    "descriptor": "\nComments: To appear as long paper in Findings of ACL 2021\n",
    "authors": [
      "Benjamin Minixhofer",
      "Milan Gritta",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03791"
  },
  {
    "id": "arXiv:2105.03793",
    "title": "Stability and Generalization of Stochastic Gradient Methods for Minimax  Problems",
    "abstract": "Many machine learning problems can be formulated as minimax problems such as\nGenerative Adversarial Networks (GANs), AUC maximization and robust estimation,\nto mention but a few. A substantial amount of studies are devoted to studying\nthe convergence behavior of their stochastic gradient-type algorithms. In\ncontrast, there is relatively little work on their generalization, i.e., how\nthe learning models built from training examples would behave on test examples.\nIn this paper, we provide a comprehensive generalization analysis of stochastic\ngradient methods for minimax problems under both convex-concave and\nnonconvex-nonconcave cases through the lens of algorithmic stability. We\nestablish a quantitative connection between stability and several\ngeneralization measures both in expectation and with high probability. For the\nconvex-concave setting, our stability analysis shows that stochastic gradient\ndescent ascent attains optimal generalization bounds for both smooth and\nnonsmooth minimax problems. We also establish generalization bounds for both\nweakly-convex-weakly-concave and gradient-dominated problems.",
    "descriptor": "\nComments: To appear in ICML 2021\n",
    "authors": [
      "Yunwen Lei",
      "Zhenhuan Yang",
      "Tianbao Yang",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03793"
  },
  {
    "id": "arXiv:2105.03797",
    "title": "AnomalyHop: An SSL-based Image Anomaly Localization Method",
    "abstract": "An image anomaly localization method based on the successive subspace\nlearning (SSL) framework, called AnomalyHop, is proposed in this work.\nAnomalyHop consists of three modules: 1) feature extraction via successive\nsubspace learning (SSL), 2) normality feature distributions modeling via\nGaussian models, and 3) anomaly map generation and fusion. Comparing with\nstate-of-the-art image anomaly localization methods based on deep neural\nnetworks (DNNs), AnomalyHop is mathematically transparent, easy to train, and\nfast in its inference speed. Besides, its area under the ROC curve (ROC-AUC)\nperformance on the MVTec AD dataset is 95.9%, which is among the best of\nseveral benchmarking methods. Our codes are publicly available at Github.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Kaitai Zhang",
      "Bin Wang",
      "Wei Wang",
      "Fahad Sohrab",
      "Moncef Gabbouj",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03797"
  },
  {
    "id": "arXiv:2105.03799",
    "title": "Human Gait State Prediction Using Cellular Automata and Classification  Using ELM",
    "abstract": "In this research article, we have reported periodic cellular automata rules\nfor different gait state prediction and classification of the gait data using\nextreme machine Leaning (ELM). This research is the first attempt to use\ncellular automaton to understand the complexity of bipedal walk. Due to\nnonlinearity, varying configurations throughout the gait cycle and the passive\njoint located at the unilateral foot-ground contact in bipedal walk resulting\nvariation of dynamic descriptions and control laws from phase to phase for\nhuman gait is making difficult to predict the bipedal walk states. We have\ndesigned the cellular automata rules which will predict the next gait state of\nbipedal steps based on the previous two neighbour states. We have designed\ncellular automata rules for normal walk. The state prediction will help to\ncorrectly design the bipedal walk. The normal walk depends on next two states\nand has total 8 states. We have considered the current and previous states to\npredict next state. So we have formulated 16 rules using cellular automata, 8\nrules for each leg. The priority order maintained using the fact that if right\nleg in swing phase then left leg will be in stance phase. To validate the model\nwe have classified the gait Data using ELM [1] and achieved accuracy 60%. We\nhave explored the trajectories and compares with another gait trajectories.\nFinally we have presented the error analysis for different joints.",
    "descriptor": "\nComments: Machine Intelligence and Signal Analysis conference. Published in book Advances in Intelligent Systems and Computing, vol 748. Springer, Singapore. arXiv admin note: substantial text overlap with arXiv:1710.06548\n",
    "authors": [
      "Vijay Bhaskar Semwal",
      "Neha Gaud",
      "G.C.Nandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03799"
  },
  {
    "id": "arXiv:2105.03800",
    "title": "Fine-Grained $\u03b5$-Margin Closed-Form Stabilization of Parametric  Hawkes Processes",
    "abstract": "Hawkes Processes have undergone increasing popularity as default tools for\nmodeling self- and mutually exciting interactions of discrete events in\ncontinuous-time event streams. A Maximum Likelihood Estimation (MLE)\nunconstrained optimization procedure over parametrically assumed forms of the\ntriggering kernels of the corresponding intensity function are a widespread\ncost-effective modeling strategy, particularly suitable for data with few\nand/or short sequences. However, the MLE optimization lacks guarantees, except\nfor strong assumptions on the parameters of the triggering kernels, and may\nlead to instability of the resulting parameters .In the present work, we show\nhow a simple stabilization procedure improves the performance of the MLE\noptimization without these overly restrictive assumptions.This stabilized\nversion of the MLE is shown to outperform traditional methods over sequences of\nseveral different lengths.",
    "descriptor": "\nComments: Presented as a RobustML workshop paper at ICLR 2021\n",
    "authors": [
      "Rafael Lima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03800"
  },
  {
    "id": "arXiv:2105.03801",
    "title": "Long-Span Dependencies in Transformer-based Summarization Systems",
    "abstract": "Transformer-based models have achieved state-of-the-art results in a wide\nrange of natural language processing (NLP) tasks including document\nsummarization. Typically these systems are trained by fine-tuning a large\npre-trained model to the target task. One issue with these transformer-based\nmodels is that they do not scale well in terms of memory and compute\nrequirements as the input length grows. Thus, for long document summarization,\nit can be challenging to train or fine-tune these models. In this work, we\nexploit large pre-trained transformer-based models and address long-span\ndependencies in abstractive summarization using two methods: local\nself-attention; and explicit content selection. These approaches are compared\non a range of network configurations. Experiments are carried out on standard\nlong-span summarization tasks, including Spotify Podcast, arXiv, and PubMed\ndatasets. We demonstrate that by combining these methods, we can achieve\nstate-of-the-art results on all three tasks in the ROUGE scores. Moreover,\nwithout a large-scale GPU card, our approach can achieve comparable or better\nresults than existing approaches.",
    "descriptor": "\nComments: ACL 2021 (accepted version)\n",
    "authors": [
      "Potsawee Manakul",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03801"
  },
  {
    "id": "arXiv:2105.03804",
    "title": "Slash or burn: Power line and vegetation classification for wildfire  prevention",
    "abstract": "Electric utilities are struggling to manage increasing wildfire risk in a\nhotter and drier climate. Utility transmission and distribution lines regularly\nignite destructive fires when they make contact with surrounding vegetation.\nTrimming vegetation to maintain the separation from utility assets is as\ncritical to safety as it is difficult. Each utility has tens of thousands of\nlinear miles to manage, poor knowledge of where those assets are located, and\nno way to prioritize trimming. Feature-enhanced convolutional neural networks\n(CNNs) have proven effective in this problem space. Histograms of oriented\ngradients (HOG) and Hough transforms are used to increase the salience of the\nlinear structures like power lines and poles. Data is frequently taken from\ndrone or satellite footage, but Google Street View offers an even more scalable\nand lower cost solution. This paper uses $1,320$ images scraped from Street\nView, transfer learning on popular CNNs, and feature engineering to place\nimages in one of three classes: (1) no utility systems, (2) utility systems\nwith no overgrown vegetation, or (3) utility systems with overgrown vegetation.\nThe CNN output thus yields a prioritized vegetation management system and\ncreates a geotagged map of utility assets as a byproduct. Test set accuracy\nwith reached $80.15\\%$ using VGG11 with a trained first layer and classifier,\nand a model ensemble correctly classified $88.88\\%$ of images with risky\nvegetation overgrowth.",
    "descriptor": "",
    "authors": [
      "Austin Park",
      "Farzaneh Rajabi",
      "Ross Weber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03804"
  },
  {
    "id": "arXiv:2105.03807",
    "title": "Estimation of 3D Human Pose Using Prior Knowledge",
    "abstract": "Estimating three-dimensional human poses from the positions of\ntwo-dimensional joints has shown promising results.However, using\ntwo-dimensional joint coordinates as input loses more information than\nimage-based approaches and results in ambiguity.In order to overcome this\nproblem, we combine bone length and camera parameters with two-dimensional\njoint coordinates for input.This combination is more discriminative than the\ntwo-dimensional joint coordinates in that it can improve the accuracy of the\nmodel's prediction depth and alleviate the ambiguity that comes from projecting\nthree-dimensional coordinates into two-dimensional space. Furthermore, we\nintroduce direction constraints which can better measure the difference between\nthe ground truth and the output of the proposed model. The experimental results\non the H36M show that the method performed better than other state-of-the-art\nthree-dimensional human pose estimation approaches.",
    "descriptor": "\nComments: letter\n",
    "authors": [
      "Shu Chen",
      "Lei Zhang",
      "Beiji Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03807"
  },
  {
    "id": "arXiv:2105.03811",
    "title": "Click-Through Rate Prediction Using Graph Neural Networks and Online  Learning",
    "abstract": "Recommendation systems have been extensively studied by many literature in\nthe past and are ubiquitous in online advertisement, shopping\nindustry/e-commerce, query suggestions in search engines, and friend\nrecommendation in social networks. Moreover,\nrestaurant/music/product/movie/news/app recommendations are only a few of the\napplications of a recommender system. A small percent improvement on the CTR\nprediction accuracy has been mentioned to add millions of dollars of revenue to\nthe advertisement industry. Click-Through-Rate (CTR) prediction is a special\nversion of recommender system in which the goal is predicting whether or not a\nuser is going to click on a recommended item. A content-based recommendation\napproach takes into account the past history of the user's behavior, i.e. the\nrecommended products and the users reaction to them. So, a personalized model\nthat recommends the right item to the right user at the right time is the key\nto building such a model. On the other hand, the so-called collaborative\nfiltering approach incorporates the click history of the users who are very\nsimilar to a particular user, thereby helping the recommender to come up with a\nmore confident prediction for that particular user by leveraging the wider\nknowledge of users who share their taste in a connected network of users. In\nthis project, we are interested in building a CTR predictor using Graph Neural\nNetworks complemented by an online learning algorithm that models such dynamic\ninteractions. By framing the problem as a binary classification task, we have\nevaluated this system both on the offline models (GNN, Deep Factorization\nMachines) with test-AUC of 0.7417 and on the online learning model with\ntest-AUC of 0.7585 using a sub-sampled version of Criteo public dataset\nconsisting of 10,000 data points.",
    "descriptor": "",
    "authors": [
      "Farzaneh Rajabi",
      "Jack Siyuan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03811"
  },
  {
    "id": "arXiv:2105.03812",
    "title": "Analysis and Mitigations of Reverse Engineering Attacks on Local Feature  Descriptors",
    "abstract": "As autonomous driving and augmented reality evolve, a practical concern is\ndata privacy. In particular, these applications rely on localization based on\nuser images. The widely adopted technology uses local feature descriptors,\nwhich are derived from the images and it was long thought that they could not\nbe reverted back. However, recent work has demonstrated that under certain\nconditions reverse engineering attacks are possible and allow an adversary to\nreconstruct RGB images. This poses a potential risk to user privacy. We take\nthis a step further and model potential adversaries using a privacy threat\nmodel. Subsequently, we show under controlled conditions a reverse engineering\nattack on sparse feature maps and analyze the vulnerability of popular\ndescriptors including FREAK, SIFT and SOSNet. Finally, we evaluate potential\nmitigation techniques that select a subset of descriptors to carefully balance\nprivacy reconstruction risk while preserving image matching accuracy; our\nresults show that similar accuracy can be obtained when revealing less\ninformation.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Deeksha Dangwal",
      "Vincent T. Lee",
      "Hyo Jin Kim",
      "Tianwei Shen",
      "Meghan Cowan",
      "Rajvi Shah",
      "Caroline Trippel",
      "Brandon Reagen",
      "Timothy Sherwood",
      "Vasileios Balntas",
      "Armin Alaghi",
      "Eddy Ilg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03812"
  },
  {
    "id": "arXiv:2105.03813",
    "title": "Adaptive and Risk-Aware Target Tracking with Heterogeneous Robot Teams",
    "abstract": "We consider a scenario where a team of robots with heterogeneous sensors must\ntrack a set of hostile targets which induce sensory failures on the robots. In\nparticular, the likelihood of failures depends on the proximity between the\ntargets and the robots. We propose a control framework that implicitly\naddresses the competing objectives of performance maximization and sensor\npreservation (which impacts the future performance of the team). Our framework\nconsists of a predictive component -- which accounts for the risk of being\ndetected by the target, and a reactive component -- which maximizes the\nperformance of the team regardless of the failures that have already occurred.\nBased on a measure of the abundance of sensors in the team, our framework can\ngenerate aggressive and risk-averse robot configurations to track the targets.\nCrucially, the heterogeneous sensing capabilities of the robots are explicitly\nconsidered in each step, allowing for a more expressive risk-performance\ntrade-off. Simulated experiments with induced sensor failures demonstrate the\nefficacy of the proposed approach.",
    "descriptor": "\nComments: Submitted to the International Conference on Intelligent Robots and Systems 2021. 9 pages\n",
    "authors": [
      "Siddharth Mayya",
      "Ragesh K. Ramachandran",
      "Lifeng Zhou",
      "Gaurav S. Sukhatme",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03813"
  },
  {
    "id": "arXiv:2105.03814",
    "title": "Benchmarking a New Paradigm: An Experimental Analysis of a Real  Processing-in-Memory Architecture",
    "abstract": "Many modern workloads, such as neural networks, databases, and graph\nprocessing, are fundamentally memory-bound. For such workloads, the data\nmovement between main memory and CPU cores imposes a significant overhead in\nterms of both latency and energy. A major reason is that this communication\nhappens through a narrow bus with high latency and limited bandwidth, and the\nlow data reuse in memory-bound workloads is insufficient to amortize the cost\nof main memory access. Fundamentally addressing this data movement bottleneck\nrequires a paradigm where the memory system assumes an active role in computing\nby integrating processing capabilities. This paradigm is known as\nprocessing-in-memory (PIM).\nRecent research explores different forms of PIM architectures, motivated by\nthe emergence of new 3D-stacked memory technologies that integrate memory with\na logic layer where processing elements can be easily placed. Past works\nevaluate these architectures in simulation or, at best, with simplified\nhardware prototypes. In contrast, the UPMEM company has designed and\nmanufactured the first publicly-available real-world PIM architecture.\nThis paper provides the first comprehensive analysis of the first\npublicly-available real-world PIM architecture. We make two key contributions.\nFirst, we conduct an experimental characterization of the UPMEM-based PIM\nsystem using microbenchmarks to assess various architecture limits such as\ncompute throughput and memory bandwidth, yielding new insights. Second, we\npresent PrIM, a benchmark suite of 16 workloads from different application\ndomains (e.g., linear algebra, databases, graph processing, neural networks,\nbioinformatics).",
    "descriptor": "\nComments: This paper is accepted to SIGMETRICS 2021 and will be presented at the conference in June 2021. Our open source software will be released after the presentation at SIGMETRICS 2021\n",
    "authors": [
      "Juan G\u00f3mez-Luna",
      "Izzat El Hajj",
      "Ivan Fernandez",
      "Christina Giannoula",
      "Geraldo F. Oliveira",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03814"
  },
  {
    "id": "arXiv:2105.03815",
    "title": "Knowledge-based Review Generation by Coherence Enhanced Text Planning",
    "abstract": "As a natural language generation task, it is challenging to generate\ninformative and coherent review text. In order to enhance the informativeness\nof the generated text, existing solutions typically learn to copy entities or\ntriples from knowledge graphs (KGs). However, they lack overall consideration\nto select and arrange the incorporated knowledge, which tends to cause text\nincoherence.\nTo address the above issue, we focus on improving entity-centric coherence of\nthe generated reviews by leveraging the semantic structure of KGs. In this\npaper, we propose a novel Coherence Enhanced Text Planning model (CETP) based\non knowledge graphs (KGs) to improve both global and local coherence for review\ngeneration. The proposed model learns a two-level text plan for generating a\ndocument: (1) the document plan is modeled as a sequence of sentence plans in\norder, and (2) the sentence plan is modeled as an entity-based subgraph from\nKG. Local coherence can be naturally enforced by KG subgraphs through\nintra-sentence correlations between entities. For global coherence, we design a\nhierarchical self-attentive architecture with both subgraph- and node-level\nattention to enhance the correlations between subgraphs. To our knowledge, we\nare the first to utilize a KG-based text planning model to enhance text\ncoherence for review generation. Extensive experiments on three datasets\nconfirm the effectiveness of our model on improving the content coherence of\ngenerated texts.",
    "descriptor": "\nComments: Accepted by SIGIR 2021 (Long Paper)\n",
    "authors": [
      "Junyi Li",
      "Wayne Xin Zhao",
      "Zhicheng Wei",
      "Nicholas Jing Yuan",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03815"
  },
  {
    "id": "arXiv:2105.03817",
    "title": "TrTr: Visual Tracking with Transformer",
    "abstract": "Template-based discriminative trackers are currently the dominant tracking\nmethods due to their robustness and accuracy, and the Siamese-network-based\nmethods that depend on cross-correlation operation between features extracted\nfrom template and search images show the state-of-the-art tracking performance.\nHowever, general cross-correlation operation can only obtain relationship\nbetween local patches in two feature maps. In this paper, we propose a novel\ntracker network based on a powerful attention mechanism called Transformer\nencoder-decoder architecture to gain global and rich contextual\ninterdependencies. In this new architecture, features of the template image is\nprocessed by a self-attention module in the encoder part to learn strong\ncontext information, which is then sent to the decoder part to compute\ncross-attention with the search image features processed by another\nself-attention module. In addition, we design the classification and regression\nheads using the output of Transformer to localize target based on\nshape-agnostic anchor. We extensively evaluate our tracker TrTr, on VOT2018,\nVOT2019, OTB-100, UAV, NfS, TrackingNet, and LaSOT benchmarks and our method\nperforms favorably against state-of-the-art algorithms. Training code and\npretrained models are available at https://github.com/tongtybj/TrTr.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Moju Zhao",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03817"
  },
  {
    "id": "arXiv:2105.03818",
    "title": "Heterogeneous Risk Minimization",
    "abstract": "Machine learning algorithms with empirical risk minimization usually suffer\nfrom poor generalization performance due to the greedy exploitation of\ncorrelations among the training data, which are not stable under distributional\nshifts. Recently, some invariant learning methods for out-of-distribution (OOD)\ngeneralization have been proposed by leveraging multiple training environments\nto find invariant relationships. However, modern datasets are frequently\nassembled by merging data from multiple sources without explicit source labels.\nThe resultant unobserved heterogeneity renders many invariant learning methods\ninapplicable. In this paper, we propose Heterogeneous Risk Minimization (HRM)\nframework to achieve joint learning of latent heterogeneity among the data and\ninvariant relationship, which leads to stable prediction despite distributional\nshifts. We theoretically characterize the roles of the environment labels in\ninvariant learning and justify our newly proposed HRM framework. Extensive\nexperimental results validate the effectiveness of our HRM framework.",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. (ICML2021)\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyuan Hu",
      "Peng Cui",
      "Bo Li",
      "Zheyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03818"
  },
  {
    "id": "arXiv:2105.03819",
    "title": "Evaluating Deep Neural Network Ensembles by Majority Voting cum  Meta-Learning scheme",
    "abstract": "Deep Neural Networks (DNNs) are prone to overfitting and hence have high\nvariance. Overfitted networks do not perform well for a new data instance. So\ninstead of using a single DNN as classifier we propose an ensemble of seven\nindependent DNN learners by varying only the input to these DNNs keeping their\narchitecture and intrinsic properties same. To induce variety in the training\ninput, for each of the seven DNNs, one-seventh of the data is deleted and\nreplenished by bootstrap sampling from the remaining samples. We have proposed\na novel technique for combining the prediction of the DNN learners in the\nensemble. Our method is called pre-filtering by majority voting coupled with\nstacked meta-learner which performs a two-step confi-dence check for the\npredictions before assigning the final class labels. All the algorithms in this\npaper have been tested on five benchmark datasets name-ly, Human Activity\nRecognition (HAR), Gas sensor array drift, Isolet, Spam-base and Internet\nadvertisements. Our ensemble approach achieves higher accuracy than a single\nDNN and the average individual accuracies of DNNs in the ensemble, as well as\nthe baseline approaches of plurality voting and meta-learning.",
    "descriptor": "\nComments: Included in Proceedings of 3rd ICSCSP 2020\n",
    "authors": [
      "Anmol Jain",
      "Aishwary Kumar",
      "Seba Susan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03819"
  },
  {
    "id": "arXiv:2105.03821",
    "title": "Exploiting Path Information for Anchor Based Graph Neural Network",
    "abstract": "Learning node representation that incorporating information from graph\nstructure benefits wide range of tasks on graph. Majority of existing graph\nneural networks (GNNs) have limited power in capturing position information for\na given node. The idea of positioning nodes with selected anchors has been\nexploit, yet mainly rely on explicit labeling of distance information. Here we\npropose Graph Inference Representation (GIR), an anchor based GNN encoding path\ninformation related to anchors for each node. Abilities to get position-aware\nembedding are theoretically and experimentally investigated on GIRs and its\ncore variants. Further, the complementary characteristic of GIRs and typical\nGNNs embeddings are demonstrated. We show that GIRs get outperformed results on\nposition-aware scenario, and could improve GNNs results by fuse GIRs embedding.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Yuheng Lu",
      "ChuXiong Sun",
      "Jie Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03821"
  },
  {
    "id": "arXiv:2105.03822",
    "title": "RBNN: Memory-Efficient Reconfigurable Deep Binary Neural Network with IP  Protection for Internet of Things",
    "abstract": "Though deep neural network models exhibit outstanding performance for various\napplications, their large model size and extensive floating-point operations\nrender deployment on mobile computing platforms a major challenge, and, in\nparticular, on Internet of Things devices. One appealing solution is model\nquantization that reduces the model size and uses integer operations commonly\nsupported by microcontrollers . To this end, a 1-bit quantized DNN model or\ndeep binary neural network maximizes the memory efficiency, where each\nparameter in a BNN model has only 1-bit. In this paper, we propose a\nreconfigurable BNN (RBNN) to further amplify the memory efficiency for\nresource-constrained IoT devices. Generally, the RBNN can be reconfigured on\ndemand to achieve any one of M (M>1) distinct tasks with the same parameter\nset, thus only a single task determines the memory requirements. In other\nwords, the memory utilization is improved by times M. Our extensive experiments\ncorroborate that up to seven commonly used tasks can co-exist (the value of M\ncan be larger). These tasks with a varying number of classes have no or\nnegligible accuracy drop-off on three binarized popular DNN architectures\nincluding VGG, ResNet, and ReActNet. The tasks span across different domains,\ne.g., computer vision and audio domains validated herein, with the prerequisite\nthat the model architecture can serve those cross-domain tasks. To protect the\nintellectual property of an RBNN model, the reconfiguration can be controlled\nby both a user key and a device-unique root key generated by the intrinsic\nhardware fingerprint. By doing so, an RBNN model can only be used per paid user\nper authorized device, thus benefiting both the user and the model provider.",
    "descriptor": "",
    "authors": [
      "Huming Qiu",
      "Hua Ma",
      "Zhi Zhang",
      "Yifeng Zheng",
      "Anmin Fu",
      "Pan Zhou",
      "Yansong Gao",
      "Derek Abbott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03822"
  },
  {
    "id": "arXiv:2105.03824",
    "title": "FNet: Mixing Tokens with Fourier Transforms",
    "abstract": "We show that Transformer encoder architectures can be massively sped up, with\nlimited accuracy costs, by replacing the self-attention sublayers with simple\nlinear transformations that \"mix\" input tokens. These linear transformations,\nalong with simple nonlinearities in feed-forward layers, are sufficient to\nmodel semantic relationships in several text classification tasks. Perhaps most\nsurprisingly, we find that replacing the self-attention sublayer in a\nTransformer encoder with a standard, unparameterized Fourier Transform achieves\n92% of the accuracy of BERT on the GLUE benchmark, but pre-trains and runs up\nto seven times faster on GPUs and twice as fast on TPUs. The resulting model,\nwhich we name FNet, scales very efficiently to long inputs, matching the\naccuracy of the most accurate \"efficient\" Transformers on the Long Range Arena\nbenchmark, but training and running faster across all sequence lengths on GPUs\nand relatively shorter sequence lengths on TPUs. Finally, FNet has a light\nmemory footprint and is particularly efficient at smaller model sizes: for a\nfixed speed and accuracy budget, small FNet models outperform Transformer\ncounterparts.",
    "descriptor": "",
    "authors": [
      "James Lee-Thorp",
      "Joshua Ainslie",
      "Ilya Eckstein",
      "Santiago Ontanon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03824"
  },
  {
    "id": "arXiv:2105.03826",
    "title": "A Hybrid Model for Combining Neural Image Caption and k-Nearest Neighbor  Approach for Image Captioning",
    "abstract": "A hybrid model is proposed that integrates two popular image captioning\nmethods to generate a text-based summary describing the contents of the image.\nThe two image captioning models are the Neural Image Caption (NIC) and the\nk-nearest neighbor approach. These are trained individually on the training\nset. We extract a set of five features, from the validation set, for evaluating\nthe results of the two models that in turn is used to train a logistic\nregression classifier. The BLEU-4 scores of the two models are compared for\ngenerating the binary-value ground truth for the logistic regression\nclassifier. For the test set, the input images are first passed separately\nthrough the two models to generate the individual captions. The\nfive-dimensional feature set extracted from the two models is passed to the\nlogistic regression classifier to take a decision regarding the final caption\ngenerated which is the best of two captions generated by the models. Our\nimplementation of the k-nearest neighbor model achieves a BLEU-4 score of 15.95\nand the NIC model achieves a BLEU-4 score of 16.01, on the benchmark Flickr8k\ndataset. The proposed hybrid model is able to achieve a BLEU-4 score of 18.20\nproving the validity of our approach.",
    "descriptor": "\nComments: Included in Proceedings of 3rd ICSCSP 2020\n",
    "authors": [
      "Kartik Arora",
      "Ajul Raj",
      "Arun Goel",
      "Seba Susan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03826"
  },
  {
    "id": "arXiv:2105.03827",
    "title": "Good Practices and A Strong Baseline for Traffic Anomaly Detection",
    "abstract": "The detection of traffic anomalies is a critical component of the intelligent\ncity transportation management system. Previous works have proposed a variety\nof notable insights and taken a step forward in this field, however, dealing\nwith the complex traffic environment remains a challenge. Moreover, the lack of\nhigh-quality data and the complexity of the traffic scene, motivate us to study\nthis problem from a hand-crafted perspective. In this paper, we propose a\nstraightforward and efficient framework that includes pre-processing, a dynamic\ntrack module, and post-processing. With video stabilization, background\nmodeling, and vehicle detection, the pro-processing phase aims to generate\ncandidate anomalies. The dynamic tracking module seeks and locates the start\ntime of anomalies by utilizing vehicle motion patterns and spatiotemporal\nstatus. Finally, we use post-processing to fine-tune the temporal boundary of\nanomalies. Not surprisingly, our proposed framework was ranked $1^{st}$ in the\nNVIDIA AI CITY 2021 leaderboard for traffic anomaly detection. The code is\navailable at: https://github.com/Endeavour10020/AICity2021-Anomaly-Detection .",
    "descriptor": "\nComments: We rank $1^{st}$ in the CVPR 2021 NVIDIA AI CITY Challenge for Traffic Anomaly detection\n",
    "authors": [
      "Yuxiang Zhao",
      "Wenhao Wu",
      "Yue He",
      "Yingying Li",
      "Xiao Tan",
      "Shifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03827"
  },
  {
    "id": "arXiv:2105.03828",
    "title": "Impacts of Privately Owned Electric Vehicles on Distribution System  Resilience: A Multi-agent Optimization Approach",
    "abstract": "We investigate the effects of private electric vehicles (EVs) on the\nresilience of distribution systems after disruptions. We propose a framework of\nnetwork-based multi-agent optimization problems with equilibrium constraints\n(N-MOPEC) to consider the decentralized decision making of stakeholders in\ntransportation and energy systems. To solve the high-dimensional non-convex\nproblem, we develop an efficient computational algorithm based on exact convex\nreformulation. Numerical studies are conducted to illustrate the effectiveness\nof our modeling and computational approach and to draw policy insights. The\nproposed modeling and computational strategies could provide a solid foundation\nfor the future study of power system resilience with private EVs in coupled\ntransportation and power networks.",
    "descriptor": "",
    "authors": [
      "Sina Baghali",
      "Zhaomiao Guo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03828"
  },
  {
    "id": "arXiv:2105.03830",
    "title": "Beyond Monocular Deraining: Parallel Stereo Deraining Network Via  Semantic Prior",
    "abstract": "Rain is a common natural phenomenon. Taking images in the rain however often\nresults in degraded quality of images, thus compromises the performance of many\ncomputer vision systems. Most existing de-rain algorithms use only one single\ninput image and aim to recover a clean image. Few work has exploited stereo\nimages. Moreover, even for single image based monocular deraining, many current\nmethods fail to complete the task satisfactorily because they mostly rely on\nper pixel loss functions and ignore semantic information. In this paper, we\npresent a Paired Rain Removal Network (PRRNet), which exploits both stereo\nimages and semantic information. Specifically, we develop a Semantic-Aware\nDeraining Module (SADM) which solves both tasks of semantic segmentation and\nderaining of scenes, and a Semantic-Fusion Network (SFNet) and a View-Fusion\nNetwork (VFNet) which fuse semantic information and multi-view information\nrespectively. In addition, we also introduce an Enhanced Paired Rain Removal\nNetwork (EPRRNet) which exploits semantic prior to remove rain streaks from\nstereo images. We first use a coarse deraining network to reduce the rain\nstreaks on the input images, and then adopt a pre-trained semantic segmentation\nnetwork to extract semantic features from the coarse derained image. Finally, a\nparallel stereo deraining network fuses semantic and multi-view information to\nrestore finer results. We also propose new stereo based rainy datasets for\nbenchmarking. Experiments on both monocular and the newly proposed stereo rainy\ndatasets demonstrate that the proposed method achieves the state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Kaihao Zhang",
      "Wenhan Luo",
      "Yanjiang Yu",
      "Wenqi Ren",
      "Fang Zhao",
      "Changsheng Li",
      "Lin Ma",
      "Wei Liu",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03830"
  },
  {
    "id": "arXiv:2105.03831",
    "title": "Super Solutions of the Model RB",
    "abstract": "The concept of super solution is a special type of generalized solutions with\ncertain degree of robustness and stability. In this paper we consider the\n$(1,1)$-super solutions of the model RB. Using the first moment method, we\nestablish a \"threshold\" such that as the constraint density crosses this value,\nthe expected number of $(1,1)$-super solutions goes from $0$ to infinity.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Guangyan Zhou",
      "Wei Xu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03831"
  },
  {
    "id": "arXiv:2105.03832",
    "title": "Dataset and Performance Comparison of Deep Learning Architectures for  Plum Detection and Robotic Harvesting",
    "abstract": "Many automated operations in agriculture, such as weeding and plant counting,\nrequire robust and accurate object detectors. Robotic fruit harvesting is one\nof these, and is an important technology to address the increasing labour\nshortages and uncertainty suffered by tree crop growers. An eye-in-hand sensing\nsetup is commonly used in harvesting systems and provides benefits to sensing\naccuracy and flexibility. However, as the hand and camera move from viewing the\nentire trellis to picking a specific fruit, large changes in lighting, colour,\nobscuration and exposure occur. Object detection algorithms used in harvesting\nshould be robust to these challenges, but few datasets for assessing this\ncurrently exist. In this work, two new datasets are gathered during day and\nnight operation of an actual robotic plum harvesting system. A range of current\ngeneration deep learning object detectors are benchmarked against these.\nAdditionally, two methods for fusing depth and image information are tested for\ntheir impact on detector performance. Significant differences between day and\nnight accuracy of different detectors is found, transfer learning is identified\nas essential in all cases, and depth information fusion is assessed as only\nmarginally effective. The dataset and benchmark models are made available\nonline.",
    "descriptor": "\nComments: 20 pages, 8 figures, 2 tables. Associated dataset at this http URL\n",
    "authors": [
      "Jasper Brown",
      "Salah Sukkarieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03832"
  },
  {
    "id": "arXiv:2105.03833",
    "title": "Euclidean Distance-Optimal Post-Processing of Grid-Based Paths",
    "abstract": "Paths planned over grids can often be suboptimal in an Euclidean space and\ncontain a large number of unnecessary turns. Consequently, researchers have\nlooked into post-processing techniques to improve the paths after they are\nplanned. In this paper, we propose a novel post-processing technique, called\nHomotopic Visibility Graph Planning (HVG) which differentiates itself from\nexisting post-processing methods in that it is guaranteed to shorten the path\nsuch that it is at least as short as the provably shortest path that lies\nwithin the same topological class as the initially computed path. We propose\nthe algorithm, provide proofs and compare it experimentally against other\npost-processing methods and any-angle planning algorithms.",
    "descriptor": "",
    "authors": [
      "Guru Koushik Senthil Kumar",
      "Sandip Aine",
      "Maxim Likhachev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03833"
  },
  {
    "id": "arXiv:2105.03834",
    "title": "Learning Image Attacks toward Vision Guided Autonomous Vehicles",
    "abstract": "While adversarial neural networks have been shown successful for static image\nattacks, very few approaches have been developed for attacking online image\nstreams while taking into account the underlying physical dynamics of\nautonomous vehicles, their mission, and environment. This paper presents an\nonline adversarial machine learning framework that can effectively misguide\nautonomous vehicles' missions. In the existing image attack methods devised\ntoward autonomous vehicles, optimization steps are repeated for every image\nframe. This framework removes the need for fully converged optimization at\nevery frame to realize image attacks in real-time. Using reinforcement\nlearning, a generative neural network is trained over a set of image frames to\nobtain an attack policy that is more robust to dynamic and uncertain\nenvironments. A state estimator is introduced for processing image streams to\nreduce the attack policy's sensitivity to physical variables such as unknown\nposition and velocity. A simulation study is provided to validate the results.",
    "descriptor": "",
    "authors": [
      "Hyung-Jin Yoon",
      "Hamid Jafarnejad Sani",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03834"
  },
  {
    "id": "arXiv:2105.03835",
    "title": "Segmenting Hybrid Trajectories using Latent ODEs",
    "abstract": "Smooth dynamics interrupted by discontinuities are known as hybrid systems\nand arise commonly in nature. Latent ODEs allow for powerful representation of\nirregularly sampled time series but are not designed to capture trajectories\narising from hybrid systems. Here, we propose the Latent Segmented ODE\n(LatSegODE), which uses Latent ODEs to perform reconstruction and changepoint\ndetection within hybrid trajectories featuring jump discontinuities and\nswitching dynamical modes. Where it is possible to train a Latent ODE on the\nsmooth dynamical flows between discontinuities, we apply the pruned exact\nlinear time (PELT) algorithm to detect changepoints where latent dynamics\nrestart, thereby maximizing the joint probability of a piece-wise continuous\nlatent dynamical representation. We propose usage of the marginal likelihood as\na score function for PELT, circumventing the need for model complexity-based\npenalization. The LatSegODE outperforms baselines in reconstructive and\nsegmentation tasks including synthetic data sets of sine waves, Lotka Volterra\ndynamics, and UCI Character Trajectories.",
    "descriptor": "",
    "authors": [
      "Ruian Shi",
      "Quaid Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03835"
  },
  {
    "id": "arXiv:2105.03838",
    "title": "HyperHyperNetworks for the Design of Antenna Arrays",
    "abstract": "We present deep learning methods for the design of arrays and single\ninstances of small antennas. Each design instance is conditioned on a target\nradiation pattern and is required to conform to specific spatial dimensions and\nto include, as part of its metallic structure, a set of predetermined\nlocations. The solution, in the case of a single antenna, is based on a\ncomposite neural network that combines a simulation network, a hypernetwork,\nand a refinement network. In the design of the antenna array, we add an\nadditional design level and employ a hypernetwork within a hypernetwork. The\nlearning objective is based on measuring the similarity of the obtained\nradiation pattern to the desired one. Our experiments demonstrate that our\napproach is able to design novel antennas and antenna arrays that are compliant\nwith the design requirements, considerably better than the baseline methods. We\ncompare the solutions obtained by our method to existing designs and\ndemonstrate a high level of overlap. When designing the antenna array of a\ncellular phone, the obtained solution displays improved properties over the\nexisting one.",
    "descriptor": "",
    "authors": [
      "Shahar Lutati",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.03838"
  },
  {
    "id": "arXiv:2105.03839",
    "title": "News Kaleidoscope: Visual Investigation of Coverage Diversity in News  Event Reporting",
    "abstract": "We develop a visual analytics system, NewsKaleidoscope, to investigate the\nhow news reporting of events varies. NewsKaleidoscope combines several backend\ntext language processing techniques with a coordinated visualization interface\ntailored for visualization non-expert users. To robustly evaluate\nNewsKaleidoscope, we conduct a trio of user studies. (1) A usability study with\nnews novices assesses the overall system and the specific insights promoted for\njournalism-agnostic users. (2) A follow-up study with news experts assesses the\ninsights promoted for journalism-savvy users. (3) Based on identified system\nlimitations in these two studies, we amend NewsKaleidoscope design and conduct\na third study to validate these improvements. Results indicate that, for both\nnews novice and experts, NewsKaleidoscope supports an effective, task-driven\nworkflow for analyzing the diversity of news coverage about events, though\njournalism expertise has a significant influence on the user insights and\ntakeaways. Our insights while developing and evaluating NewsKaleidoscope can\naid future interface designs that combine visualization with natural language\nprocessing to analyze coverage diversity in news event reporting.",
    "descriptor": "",
    "authors": [
      "Aditi Mishra",
      "Shashank Ginjpalli",
      "Chris Bryan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.03839"
  },
  {
    "id": "arXiv:2105.03841",
    "title": "The Temporal Dictionary Ensemble (TDE) Classifier for Time Series  Classification",
    "abstract": "Using bag of words representations of time series is a popular approach to\ntime series classification. These algorithms involve approximating and\ndiscretising windows over a series to form words, then forming a count of words\nover a given dictionary. Classifiers are constructed on the resulting\nhistograms of word counts. A 2017 evaluation of a range of time series\nclassifiers found the bag of symbolic-fourier approximation symbols (BOSS)\nensemble the best of the dictionary based classifiers. It forms one of the\ncomponents of hierarchical vote collective of transformation-based ensembles\n(HIVE-COTE), which represents the current state of the art. Since then, several\nnew dictionary based algorithms have been proposed that are more accurate or\nmore scalable (or both) than BOSS. We propose a further extension of these\ndictionary based classifiers that combines the best elements of the others\ncombined with a novel approach to constructing ensemble members based on an\nadaptive Gaussian process model of the parameter space. We demonstrate that the\ntemporal dictionary ensemble (TDE) is more accurate than other dictionary based\napproaches. Furthermore, unlike the other classifiers, if we replace BOSS in\nHIVE-COTE with TDE, HIVE-COTE is significantly more accurate. We also show this\nnew version of HIVE-COTE is significantly more accurate than the current best\ndeep learning approach, a recently proposed hybrid tree ensemble and a recently\nintroduced competitive classifier making use of highly randomised convolutional\nkernels. This advance represents a new state of the art for time series\nclassification.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.12008\n",
    "authors": [
      "Matthew Middlehurst",
      "James Large",
      "Gavin Cawley",
      "Anthony Bagnall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03841"
  },
  {
    "id": "arXiv:2105.03842",
    "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic  Speech Recognition",
    "abstract": "Error correction techniques have been used to refine the output sentences\nfrom automatic speech recognition (ASR) models and achieve a lower word error\nrate (WER) than original ASR outputs. Previous works usually use a\nsequence-to-sequence model to correct an ASR output sentence autoregressively,\nwhich causes large latency and cannot be deployed in online ASR services. A\nstraightforward solution to reduce latency, inspired by non-autoregressive\n(NAR) neural machine translation, is to use an NAR sequence generation model\nfor ASR error correction, which, however, comes at the cost of significantly\nincreased ASR error rate. In this paper, observing distinctive error patterns\nand correction operations (i.e., insertion, deletion, and substitution) in ASR,\nwe propose FastCorrect, a novel NAR error correction model based on edit\nalignment. In training, FastCorrect aligns each source token from an ASR output\nsentence to the target tokens from the corresponding ground-truth sentence\nbased on the edit distance between the source and target sentences, and\nextracts the number of target tokens corresponding to each source token during\nedition/correction, which is then used to train a length predictor and to\nadjust the source tokens to match the length of the target sentence for\nparallel generation. In inference, the token number predicted by the length\npredictor is used to adjust the source tokens for target sequence generation.\nExperiments on the public AISHELL-1 dataset and an internal industrial-scale\nASR dataset show the effectiveness of FastCorrect for ASR error correction: 1)\nit speeds up the inference by 6-9 times and maintains the accuracy (8-14% WER\nreduction) compared with the autoregressive correction model; and 2) it\noutperforms the accuracy of popular NAR models adopted in neural machine\ntranslation by a large margin.",
    "descriptor": "",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Linchen Zhu",
      "Jin Xu",
      "Renqian Luo",
      "Linquan Liu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Ed Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.03842"
  },
  {
    "id": "arXiv:2105.03844",
    "title": "Reinforcement Learning with Expert Trajectory For Quantitative Trading",
    "abstract": "In recent years, quantitative investment methods combined with artificial\nintelligence have attracted more and more attention from investors and\nresearchers. Existing related methods based on the supervised learning are not\nvery suitable for learning problems with long-term goals and delayed rewards in\nreal futures trading. In this paper, therefore, we model the price prediction\nproblem as a Markov decision process (MDP), and optimize it by reinforcement\nlearning with expert trajectory. In the proposed method, we employ more than\n100 short-term alpha factors instead of price, volume and several technical\nfactors in used existing methods to describe the states of MDP. Furthermore,\nunlike DQN (deep Q-learning) and BC (behavior cloning) in related methods, we\nintroduce expert experience in training stage, and consider both the\nexpert-environment interaction and the agent-environment interaction to design\nthe temporal difference error so that the agents are more adaptable for\ninevitable noise in financial data. Experimental results evaluated on share\nprice index futures in China, including IF (CSI 300) and IC (CSI 500), show\nthat the advantages of the proposed method compared with three typical\ntechnical analysis and two deep leaning based methods.",
    "descriptor": "",
    "authors": [
      "Sihang Chen",
      "Weiqi Luo",
      "Chao Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.03844"
  },
  {
    "id": "arXiv:2105.03851",
    "title": "Employing Agent Beliefs during Fault Diagnosis for IEC 61499 Industrial  Cyber-Physical Systems",
    "abstract": "We have come to rely on industrial-scale cyber-physical systems more and more\nto manage tasks and machinery in safety-critical situations. Efficient,\nreliable fault identification and management has become a critical factor in\nthe design of these increasingly sophisticated and complex devices. Teams of\nco-operating software agents are one way to coordinate the flow of diagnostic\ninformation gathered during fault-finding. By wielding domain knowledge of the\nsoftware architecture used to construct the system, agents build and refine\ntheir beliefs about the location and root cause of faults. This paper examines\nhow agents constructed within the GORITE Multi-Agent Framework create and\nrefine their beliefs. We demonstrate three different belief structures\nimplemented within our Fault Diagnostic Engine, showing how each supports a\ndistinct aspect of the agent's reasoning. Using domain knowledge of the IEC\n61499 Function Block architecture, agents are able to examine and rigorously\nevaluate both individual components and entire subsystems.",
    "descriptor": "\nComments: Conference paper, 6 pages, 6 figures\n",
    "authors": [
      "Barry Dowdeswell",
      "Roopak Sinha",
      "Dennis Jarvis",
      "Jacqueline Jarvis",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.03851"
  },
  {
    "id": "arXiv:2105.03852",
    "title": "Towards Dynamic Feature Selection with Attention to Assist Banking  Customers in Establishing a New Business",
    "abstract": "Establishing a new business may involve Knowledge acquisition in various\nareas, from personal to business and marketing sources. This task is\nchallenging as it requires examining various data islands to uncover hidden\npatterns and unknown correlations such as purchasing behavior, consumer buying\nsignals, and demographic and socioeconomic attributes of different locations.\nThis paper introduces a novel framework for extracting and identifying\nimportant features from banking and non-banking data sources to address this\nchallenge. We present an attention-based supervised feature selection approach\nto select important and relevant features which contribute most to the\ncustomer's query regarding establishing a new business. We report on the\nexperiment conducted on an openly available dataset created from Kaggle and the\nUCI machine learning repositories.",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Edrisi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03852"
  },
  {
    "id": "arXiv:2105.03855",
    "title": "GMOTE: Gaussian based minority oversampling technique for imbalanced  classification adapting tail probability of outliers",
    "abstract": "Classification of imbalanced data is one of the common problems in the recent\nfield of data mining. Imbalanced data substantially affects the performance of\nstandard classification models. Data-level approaches mainly use the\noversampling methods to solve the problem, such as synthetic minority\noversampling Technique (SMOTE). However, since the methods such as SMOTE\ngenerate instances by linear interpolation, synthetic data space may look like\na polygonal. Also, the oversampling methods generate outliers of the minority\nclass. In this paper, we proposed Gaussian based minority oversampling\ntechnique (GMOTE) with a statistical perspective for imbalanced datasets. To\navoid linear interpolation and to consider outliers, this proposed method\ngenerates instances by the Gaussian Mixture Model. Motivated by\nclustering-based multivariate Gaussian outlier score (CMGOS), we propose to\nadapt tail probability of instances through the Mahalanobis distance to\nconsider local outliers. The experiment was carried out on a representative set\nof benchmark datasets. The performance of the GMOTE is compared with other\nmethods such as SMOTE. When the GMOTE is combined with classification and\nregression tree (CART) or support vector machine (SVM), it shows better\naccuracy and F1-Score. Experimental results demonstrate the robust performance.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Seung Jee Yang",
      "Kyung Joon Cha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03855"
  },
  {
    "id": "arXiv:2105.03856",
    "title": "The D-plus Discriminant and Complexity of Root Clustering",
    "abstract": "Let $p(x)$ be an integer polynomial with $m\\ge 2$ distinct roots\n$\\alpha_1,\\ldots,\\alpha_m$ whose multiplicities are\n$\\boldsymbol{\\mu}=(\\mu_1,\\ldots,\\mu_m)$. We define the D-plus discriminant of\n$p(x)$ to be $D^+(p):= \\prod_{1\\le i<j\\le m}(\\alpha_i-\\alpha_j)^{\\mu_i+\\mu_j}$.\nUnlike the classical discriminant, $D^+(p)$ never vanishes. We first prove a\nconjecture that $D^+(p)$ is a $\\boldsymbol{\\mu}$-symmetric function of its\nroots $\\alpha_1,\\ldots,\\alpha_m$. Our main result gives an explicit formula for\n$D^+(p)$, as a rational function of its coefficients. A basic tool used by our\nproof is the \"symbolic Poisson resultant\". The D-plus discriminant first arose\nin the complexity analysis of a root clustering algorithm from Becker et al.\n(ISSAC 2016). The bit-complexity of this algorithm is proportional to a\nquantity $\\log(|D^+(p)|^{-1})$. As an application of our main result, we give\nan explicit upper bound on this quantity in terms of the degree of $p$ and its\nleading coefficient.",
    "descriptor": "",
    "authors": [
      "Jing Yang",
      "Chee K. Yap"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.03856"
  },
  {
    "id": "arXiv:2105.03857",
    "title": "Seismic Fault Segmentation via 3D-CNN Training by a Few 2D Slices Labels",
    "abstract": "Detection faults in seismic data is a crucial step for seismic structural\ninterpretation, reservoir characterization and well placement, and it is full\nof challenges. Some recent works regard fault detection as an image\nsegmentation task. The task of image segmentation requires a large amount of\ndata labels, especially 3D seismic data, which has a complex structure and a\nlot of noise. Therefore, its annotation requires expert experience and a huge\nworkload, wrong labeling and missing labeling will affect the segmentation\nperformance of the model. In this study, we present a new binary cross-entropy\nand smooth L1 loss ({\\lambda}-BCE and {\\lambda}-smooth L1) to effectively train\n3D-CNN by sampling some 2D slices from 3D seismic data, so that the model can\nlearn the segmentation of 3D seismic data from a few 2D slices. In order to\nfully extract information from limited and low-dimensional data and suppress\nseismic noise, we propose an attention module that can be used for active\nsupervision training (Active Attention Module, AAM) and embedded in the network\nto participate in the differentiation and optimization of the model. During\ntraining, the attention heatmap target is generated by the original binary\nlabel, and letting it supervise the attention module using the {\\lambda}-smooth\nL1 loss. Qualitative experiments show that our method can extract 3D seismic\nfeatures from a few 2D slices labels on real data, to segment a complete fault\nvolume. Through visualization, the segmentation effect achieves\nstate-of-the-art. Quantitative experiments on synthetic data prove the\neffectiveness of our training method and attention module. Experiments show\nthat using our method, labeling one 2D slice every 30 frames at least (3.3% of\nthe original label), the model can achieve a segmentation performance similar\nto that of a 3D label.",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "YiMin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Xiao Li",
      "Yingjie Xi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03857"
  },
  {
    "id": "arXiv:2105.03858",
    "title": "Location-Based Timing Advance Estimation for 5G Integrated LEO Satellite  Communications",
    "abstract": "Integrated satellite-terrestrial communications networks aim to exploit both\nthe satellite and the ground mobile communications, thus providing genuine\nubiquitous coverage. For 5G integrated low earth orbit (LEO) satellite\ncommunication systems, the timing advance (TA) is required to be estimated in\nthe initial random access procedure in order to facilitate the uplink frame\nalignment among different users. However, due to the inherent characteristics\nof LEO satellite communication systems, e.g., wide beam coverage and long\npropagation delays, the existing 5G terrestrial uplink TA scheme is not\napplicable in the satellite networks. In this paper, we investigate\nlocation-based TA estimation for 5G integrated LEO satellite communication\nsystems. We obtain the time difference of arrival (TDOA) and frequency\ndifference of arrival (FDOA) measurements in the downlink timing and frequency\nsynchronization phase, which are made from the satellite at different time\ninstants. We propose to take these measurements for either UE geolocation or\nephemeris estimation, thus calculating the TA value. The estimation is then\nformulated as a quadratic optimization problem whose globally optimal solution\ncan be obtained by a quadratic penalty algorithm. To reduce the computational\ncomplexity, we further propose an alternative approximation method based on\niteratively performing a linearization procedure on the quadratic equality\nconstraints. Numerical results show that the proposed methods can approach the\nconstrained Cramer-Rao lower bound (CRLB) of the TA estimation and thus assure\nuplink frame alignment for different users.",
    "descriptor": "",
    "authors": [
      "Wenjin Wang",
      "Tingting Chen",
      "Rui Ding",
      "Gonzalo Seco-Granados",
      "Li You",
      "Xiqi Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03858"
  },
  {
    "id": "arXiv:2105.03859",
    "title": "RRCD: Redirecci\u00f3n de Registros Basada en Compresi\u00f3n de Datos para  Tolerar FallosPermanentes en una GPU",
    "abstract": "The ever-increasing parallelism demand of General-Purpose Graphics Processing\nUnit (GPGPU) applications pushes toward larger and more energy-hungry register\nfiles in successive GPU generations. Reducing the supply voltage beyond its\nsafe limit is an effective way to improve the energy efficiency of register\nfiles. However, at these operating voltages, the reliability of the circuit is\ncompromised. This work aims to tolerate permanent faults from process\nvariations in large GPU register files operating below the safe supply voltage\nlimit. To do so, this paper proposes a microarchitectural patching technique,\nDC-Patch, exploiting the inherent data redundancy of applications to compress\nregisters at run-time with neither compiler assistance nor instruction set\nmodifications. Instead of disabling an entire faulty register file entry,\nDC-Patch leverages the reliable cells within a faulty entry to store compressed\nregister values. Experimental results show that, with more than a third of\nfaulty register entries, DC-Patch ensures a reliable operation of the register\nfile and reduces the energy consumption by 47% with respect to a conventional\nregister file working at nominal supply voltage. The energy savings are 21%\ncompared to a voltage noise smoothing scheme operating at the safe supply\nvoltage limit. These benefits are obtained with less than 2 and 6% impact on\nthe system performance and area, respectively.",
    "descriptor": "\nComments: 10 page, in Spanish, 6 Figures, to be submitted to Jornadas SARTECO 2021\n",
    "authors": [
      "Yamilka Toca-D\u00edaz",
      "Alejandro Valero",
      "Rub\u00e9n Gran-Tejero",
      "Dar\u00edo Su\u00e1rez-Gracia"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.03859"
  },
  {
    "id": "arXiv:2105.03864",
    "title": "Quick NAT: High performance NAT system on commodity platforms",
    "abstract": "NAT gateway is an important network system in today's IPv4 network when\ntranslating a private IPv4 address to a public address. However, traditional\nNAT system based on Linux Netfilter cannot achieve high network throughput to\nmeet modern requirements such as data centers. To address this challenge, we\nimprove the network performance of NAT system by three ways. First, we leverage\nDPDK to enable polling and zero-copy delivery, so as to reduce the cost of\ninterrupt and packet copies. Second, we enable multiple CPU cores to process in\nparallel and use lock-free hash table to minimize the contention between CPU\ncores. Third, we use hash search instead of sequential search when looking up\nthe NAT rule table. Evaluation shows that our Quick NAT system significantly\nimproves the performance of NAT on commodity platforms.",
    "descriptor": "",
    "authors": [
      "Junfeng Li",
      "Dan Li",
      "Yukai Huang",
      "Yang Cheng",
      "Ruilin Ling"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.03864"
  },
  {
    "id": "arXiv:2105.03867",
    "title": "Improving Cost Learning for JPEG Steganography by Exploiting JPEG Domain  Knowledge",
    "abstract": "Although significant progress in automatic learning of steganographic cost\nhas been achieved recently, existing methods designed for spatial images are\nnot well applicable to JPEG images which are more common media in daily life.\nThe difficulties of migration mostly lie in the unique and complicated JPEG\ncharacteristics caused by 8x8 DCT mode structure. To address the issue, in this\npaper we extend an existing automatic cost learning scheme to JPEG, where the\nproposed scheme called JEC-RL (JPEG Embedding Cost with Reinforcement Learning)\nis explicitly designed to tailor the JPEG DCT structure. It works with the\nembedding action sampling mechanism under reinforcement learning, where a\npolicy network learns the optimal embedding policies via maximizing the rewards\nprovided by an environment network. The policy network is constructed following\na domain-transition design paradigm, where three modules including pixel-level\ntexture complexity evaluation, DCT feature extraction, and mode-wise\nrearrangement, are proposed. These modules operate in serial, gradually\nextracting useful features from a decompressed JPEG image and converting them\ninto embedding policies for DCT elements, while considering JPEG\ncharacteristics including inter-block and intra-block correlations\nsimultaneously. The environment network is designed in a gradient-oriented way\nto provide stable reward values by using a wide architecture equipped with a\nfixed preprocessing layer with 8x8 DCT basis filters. Extensive experiments and\nablation studies demonstrate that the proposed method can achieve good security\nperformance for JPEG images against both advanced feature based and modern CNN\nbased steganalyzers.",
    "descriptor": "",
    "authors": [
      "Weixuan Tang",
      "Bin Li",
      "Mauro Barni",
      "Jin Li",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03867"
  },
  {
    "id": "arXiv:2105.03868",
    "title": "Non-Recursive Graph Convolutional Networks",
    "abstract": "Graph Convolutional Networks (GCNs) are powerful models for node\nrepresentation learning tasks. However, the node representation in existing GCN\nmodels is usually generated by performing recursive neighborhood aggregation\nacross multiple graph convolutional layers with certain sampling methods, which\nmay lead to redundant feature mixing, needless information loss, and extensive\ncomputations. Therefore, in this paper, we propose a novel architecture named\nNon-Recursive Graph Convolutional Network (NRGCN) to improve both the training\nefficiency and the learning performance of GCNs in the context of node\nclassification. Specifically, NRGCN proposes to represent different hops of\nneighbors for each node based on inner-layer aggregation and layer-independent\nsampling. In this way, each node can be directly represented by concatenating\nthe information extracted independently from each hop of its neighbors thereby\navoiding the recursive neighborhood expansion across layers. Moreover, the\nlayer-independent sampling and aggregation can be precomputed before the model\ntraining, thus the training process can be accelerated considerably. Extensive\nexperiments on benchmark datasets verify that our NRGCN outperforms the\nstate-of-the-art GCN models, in terms of the node classification performance\nand reliability.",
    "descriptor": "\nComments: 5 pages, 2 figures. Accepted to ICASSP 2021\n",
    "authors": [
      "Hao Chen",
      "Zengde Deng",
      "Yue Xu",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03868"
  },
  {
    "id": "arXiv:2105.03869",
    "title": "Trajectory Prediction for Autonomous Driving with Topometric Map",
    "abstract": "State-of-the-art autonomous driving systems rely on high definition (HD) maps\nfor localization and navigation. However, building and maintaining HD maps is\ntime-consuming and expensive. Furthermore, the HD maps assume structured\nenvironment such as the existence of major road and lanes, which are not\npresent in rural areas. In this work, we propose an end-to-end transformer\nnetworks based approach for map-less autonomous driving. The proposed model\ntakes raw LiDAR data and noisy topometric map as input and produces precise\nlocal trajectory for navigation. We demonstrate the effectiveness of our method\nin real-world driving data, including both urban and rural areas. The\nexperimental results show that the proposed method outperforms state-of-the-art\nmultimodal methods and is robust to the perturbations of the topometric map.\nThe code of the proposed method is publicly available at\n\\url{https://github.com/Jiaolong/trajectory-prediction}.",
    "descriptor": "",
    "authors": [
      "Jiaolong Xu",
      "Liang Xiao",
      "Dawei Zhao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03869"
  },
  {
    "id": "arXiv:2105.03874",
    "title": "Sparse power methods for large-scale higher-order PageRank problems",
    "abstract": "A commonly used technique for the higher-order PageRank problem is the power\nmethod that is computationally intractable for large-scale problems. The\ntruncated power method proposed recently provides us with another idea to solve\nthis problem, however, its accuracy and efficiency can be poor in practical\ncomputations. In this work, we revisit the higher-order PageRank problem and\nconsider how to solve it efficiently. The contribution of this work is as\nfollows. First, we accelerate the truncated power method for high-order\nPageRank. In the improved version, it is neither to form and store the vectors\narising from the dangling states, nor to store an auxiliary matrix. Second, we\npropose a truncated power method with partial updating to further release the\noverhead, in which one only needs to update some important columns of the\napproximation in each iteration. On the other hand, the truncated power method\nsolves a modified high-order PageRank model for convenience, which is not\nmathematically equivalent to the original one. Thus, the third contribution of\nthis work is to propose a sparse power method with partial updating for the\noriginal higher-order PageRank problem. The convergence of all the proposed\nmethods are discussed. Numerical experiments on large and sparse real-world and\nsynthetic data sets are performed. The numerical results show the superiority\nof our new algorithms over some state-of-the-art ones for large and sparse\nhigher-order PageRank problems.",
    "descriptor": "",
    "authors": [
      "Jun Huang",
      "Gang Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03874"
  },
  {
    "id": "arXiv:2105.03875",
    "title": "Bounding Information Leakage in Machine Learning",
    "abstract": "Machine Learning services are being deployed in a large range of applications\nthat make it easy for an adversary, using the algorithm and/or the model, to\ngain access to sensitive data. This paper investigates fundamental bounds on\ninformation leakage. First, we identify and bound the success rate of the\nworst-case membership inference attack, connecting it to the generalization\nerror of the target model. Second, we study the question of how much sensitive\ninformation is stored by the algorithm about the training set and we derive\nbounds on the mutual information between the sensitive attributes and model\nparameters. Although our contributions are mostly of theoretical nature, the\nbounds and involved concepts are of practical relevance. Inspired by our\ntheoretical analysis, we study linear regression and DNN models to illustrate\nhow these bounds can be used to assess the privacy guarantees of ML models.",
    "descriptor": "",
    "authors": [
      "Ganesh Del Grosso",
      "Georg Pichler",
      "Catuscia Palamidessi",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03875"
  },
  {
    "id": "arXiv:2105.03876",
    "title": "Selective Probabilistic Classifier Based on Hypothesis Testing",
    "abstract": "In this paper, we propose a simple yet effective method to deal with the\nviolation of the Closed-World Assumption for a classifier. Previous works tend\nto apply a threshold either on the classification scores or the loss function\nto reject the inputs that violate the assumption. However, these methods cannot\nachieve the low False Positive Ratio (FPR) required in safety applications. The\nproposed method is a rejection option based on hypothesis testing with\nprobabilistic networks. With probabilistic networks, it is possible to estimate\nthe distribution of outcomes instead of a single output. By utilizing Z-test\nover the mean and standard deviation for each class, the proposed method can\nestimate the statistical significance of the network certainty and reject\nuncertain outputs. The proposed method was experimented on with different\nconfigurations of the COCO and CIFAR datasets. The performance of the proposed\nmethod is compared with the Softmax Response, which is a known top-performing\nmethod. It is shown that the proposed method can achieve a broader range of\noperation and cover a lower FPR than the alternative.",
    "descriptor": "\nComments: Accepted in EUVIP 2021 conference\n",
    "authors": [
      "Saeed Bakhshi Germi",
      "Esa Rahtu",
      "Heikki Huttunen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03876"
  },
  {
    "id": "arXiv:2105.03877",
    "title": "Non-iterative Optimization Algorithm for Active Distribution Grids  Considering Uncertainty of Feeder Parameters",
    "abstract": "To cope with fast-fluctuating distributed energy resources (DERs) and\nuncontrolled loads, this paper formulates a time-varying optimization problem\nfor distribution grids with DERs and develops a novel non-iterative algorithm\nto track the optimal solutions. Different from existing methods, the proposed\napproach does not require iterations during the sampling interval. It only\nneeds to perform a single one-step calculation at each interval to obtain the\nevolution of the optimal trajectory, which demonstrates fast calculation and\nonline-tracking capability with an asymptotically vanishing error.\nSpecifically, the designed approach contains two terms: a prediction term\ntracking the change in the optimal solution based on the time-varying nature of\nsystem power, and a correction term pushing the solution toward the optimum\nbased on Newton's method. Moreover, the proposed algorithm can be applied in\nthe absence of an accurate network model by leveraging voltage measurements to\nidentify the true voltage sensitivity parameters. Simulations for an\nillustrative distribution network are provided to validate the approach.",
    "descriptor": "\nComments: 9 pages, 10 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "J. Wu",
      "M. Liu",
      "W. Lu",
      "K. Xie",
      "M. Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03877"
  },
  {
    "id": "arXiv:2105.03879",
    "title": "Directional Convergence Analysis under Spherically Symmetric  Distribution",
    "abstract": "We consider the fundamental problem of learning linear predictors (i.e.,\nseparable datasets with zero margin) using neural networks with gradient flow\nor gradient descent. Under the assumption of spherically symmetric data\ndistribution, we show directional convergence guarantees with exact convergence\nrate for two-layer non-linear networks with only two hidden nodes, and (deep)\nlinear networks. Moreover, our discovery is built on dynamic from the\ninitialization without both initial loss and perfect classification constraint\nin contrast to previous works. We also point out and study the challenges in\nfurther strengthening and generalizing our results.",
    "descriptor": "",
    "authors": [
      "Dachao Lin",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03879"
  },
  {
    "id": "arXiv:2105.03883",
    "title": "Perturbative expansion of the fundamental equation of online user  dynamics for describing changes in eigenfrequencies",
    "abstract": "The oscillation model has been proposed as a theoretical framework for\ndescribing user dynamics in online social networks. This model can model the\nuser dynamics generated by a particular network structure and allow its causal\nrelationships to be explicitly described. In this paper, by applying\nperturbation theory to the fundamental equation of the oscillation model, we\nconfirm that we can explicitly trace, at least in principle, the changes in\nuser dynamics associated with changes in the network structure. Specifically,\nwe formulate perturbative expansions up to infinite order, by drawing on\ninferences from regularities found in perturbative expansions; the accuracy of\nperturbative expansions of finite order is evaluated by numerical experiments.",
    "descriptor": "\nComments: 16 pages, 16 figures, submitted to IEEE Access\n",
    "authors": [
      "Naoki Hirakura",
      "Masaki Aida"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03883"
  },
  {
    "id": "arXiv:2105.03887",
    "title": "Lawformer: A Pre-trained Language Model for Chinese Legal Long Documents",
    "abstract": "Legal artificial intelligence (LegalAI) aims to benefit legal systems with\nthe technology of artificial intelligence, especially natural language\nprocessing (NLP). Recently, inspired by the success of pre-trained language\nmodels (PLMs) in the generic domain, many LegalAI researchers devote their\neffort to apply PLMs to legal tasks. However, utilizing PLMs to address legal\ntasks is still challenging, as the legal documents usually consist of thousands\nof tokens, which is far longer than the length that mainstream PLMs can\nprocess. In this paper, we release the Longformer-based pre-trained language\nmodel, named as Lawformer, for Chinese legal long documents understanding. We\nevaluate Lawformer on a variety of LegalAI tasks, including judgment\nprediction, similar case retrieval, legal reading comprehension, and legal\nquestion answering. The experimental results demonstrate that our model can\nachieve promising improvement on tasks with long documents as inputs.",
    "descriptor": "",
    "authors": [
      "Chaojun Xiao",
      "Xueyu Hu",
      "Zhiyuan Liu",
      "Cunchao Tu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03887"
  },
  {
    "id": "arXiv:2105.03889",
    "title": "Conformer: Local Features Coupling Global Representations for Visual  Recognition",
    "abstract": "Within Convolutional Neural Network (CNN), the convolution operations are\ngood at extracting local features but experience difficulty to capture global\nrepresentations. Within visual transformer, the cascaded self-attention modules\ncan capture long-distance feature dependencies but unfortunately deteriorate\nlocal feature details. In this paper, we propose a hybrid network structure,\ntermed Conformer, to take advantage of convolutional operations and\nself-attention mechanisms for enhanced representation learning. Conformer roots\nin the Feature Coupling Unit (FCU), which fuses local features and global\nrepresentations under different resolutions in an interactive fashion.\nConformer adopts a concurrent structure so that local features and global\nrepresentations are retained to the maximum extent. Experiments show that\nConformer, under the comparable parameter complexity, outperforms the visual\ntransformer (DeiT-B) by 2.3% on ImageNet. On MSCOCO, it outperforms ResNet-101\nby 3.7% and 3.6% mAPs for object detection and instance segmentation,\nrespectively, demonstrating the great potential to be a general backbone\nnetwork. Code is available at https://github.com/pengzhiliang/Conformer.",
    "descriptor": "\nComments: submitted to iccv2021\n",
    "authors": [
      "Zhiliang Peng",
      "Wei Huang",
      "Shanzhi Gu",
      "Lingxi Xie",
      "Yaowei Wang",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03889"
  },
  {
    "id": "arXiv:2105.03891",
    "title": "Interaction Detection Between Vehicles and Vulnerable Road Users: A Deep  Generative Approach with Attention",
    "abstract": "Intersections where vehicles are permitted to turn and interact with\nvulnerable road users (VRUs) like pedestrians and cyclists are among some of\nthe most challenging locations for automated and accurate recognition of road\nusers' behavior. In this paper, we propose a deep conditional generative model\nfor interaction detection at such locations. It aims to automatically analyze\nmassive video data about the continuity of road users' behavior. This task is\nessential for many intelligent transportation systems such as traffic safety\ncontrol and self-driving cars that depend on the understanding of road users'\nlocomotion. A Conditional Variational Auto-Encoder based model with Gaussian\nlatent variables is trained to encode road users' behavior and perform\nprobabilistic and diverse predictions of interactions. The model takes as input\nthe information of road users' type, position and motion automatically\nextracted by a deep learning object detector and optical flow from videos, and\ngenerates frame-wise probabilities that represent the dynamics of interactions\nbetween a turning vehicle and any VRUs involved. The model's efficacy was\nvalidated by testing on real--world datasets acquired from two different\nintersections. It achieved an F1-score above 0.96 at a right--turn intersection\nin Germany and 0.89 at a left--turn intersection in Japan, both with very busy\ntraffic flows.",
    "descriptor": "",
    "authors": [
      "Hao Cheng",
      "Li Feng",
      "Hailong Liu",
      "Takatsugu Hirayama",
      "Hiroshi Murase",
      "Monika Sester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03891"
  },
  {
    "id": "arXiv:2105.03897",
    "title": "Binarized Weight Error Networks With a Transition Regularization Term",
    "abstract": "This paper proposes a novel binarized weight network (BT) for a\nresource-efficient neural structure. The proposed model estimates a binary\nrepresentation of weights by taking into account the approximation error with\nan additional term. This model increases representation capacity and stability,\nparticularly for shallow networks, while the computation load is theoretically\nreduced. In addition, a novel regularization term is introduced that is\nsuitable for all threshold-based binary precision networks. This term penalizes\nthe trainable parameters that are far from the thresholds at which binary\ntransitions occur. This step promotes a swift modification for binary-precision\nresponses at train time. The experimental results are carried out for two sets\nof tasks: visual classification and visual inverse problems. Benchmarks for\nCifar10, SVHN, Fashion, ImageNet2012, Set5, Set14, Urban and BSD100 datasets\nshow that our method outperforms all counterparts with binary precision.",
    "descriptor": "\nComments: Submitted to ICIP 2021\n",
    "authors": [
      "Savas Ozkan",
      "Gozde Bozdagi Akar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03897"
  },
  {
    "id": "arXiv:2105.03901",
    "title": "Feedback Gains for Gaussian Massive Multiple-Access Channels",
    "abstract": "Feedback is shown to increase the sum-rate capacity of K-user Gaussian\nmultiple-access channels by at most a factor of approximately 1.54, improving\nThomas' doubling bound (1987). The new bound is the best possible in the sense\nthat it can be approached as closely as desired for a massive number of users.\nMoreover, feedback provides unbounded power gain in K for a fixed transmit\npower per user.",
    "descriptor": "\nComments: Submitted to the 2021 IEEE Information Theory Workshop\n",
    "authors": [
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03901"
  },
  {
    "id": "arXiv:2105.03902",
    "title": "Learning Gradient Fields for Molecular Conformation Generation",
    "abstract": "We study a fundamental problem in computational chemistry known as molecular\nconformation generation, trying to predict stable 3D structures from 2D\nmolecular graphs. Existing machine learning approaches usually first predict\ndistances between atoms and then generate a 3D structure satisfying the\ndistances, where noise in predicted distances may induce extra errors during 3D\ncoordinate generation. Inspired by the traditional force field methods for\nmolecular dynamics simulation, in this paper, we propose a novel approach\ncalled ConfGF by directly estimating the gradient fields of the log density of\natomic coordinates. The estimated gradient fields allow directly generating\nstable conformations via Langevin dynamics. However, the problem is very\nchallenging as the gradient fields are roto-translation equivariant. We notice\nthat estimating the gradient fields of atomic coordinates can be translated to\nestimating the gradient fields of interatomic distances, and hence develop a\nnovel algorithm based on recent score-based generative models to effectively\nestimate these gradients. Experimental results across multiple tasks show that\nConfGF outperforms previous state-of-the-art baselines by a significant margin.",
    "descriptor": "\nComments: ICML 2021, Long talk\n",
    "authors": [
      "Chence Shi",
      "Shitong Luo",
      "Minkai Xu",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2105.03902"
  },
  {
    "id": "arXiv:2105.03906",
    "title": "TextAdaIN: Fine-Grained AdaIN for Robust Text Recognition",
    "abstract": "Leveraging the characteristics of convolutional layers, image classifiers are\nextremely effective. However, recent works have exposed that in many cases they\nimmoderately rely on global image statistics that are easy to manipulate while\npreserving image semantics. In text recognition, we reveal that it is rather\nthe local image statistics which the networks overly depend on. Motivated by\nthis, we suggest an approach to regulate the reliance on local statistics that\nimproves overall text recognition performance.\nOur method, termed TextAdaIN, creates local distortions in the feature map\nwhich prevent the network from overfitting to the local statistics. It does so\nby deliberately mismatching fine-grained feature statistics between samples in\na mini-batch. Despite TextAdaIN's simplicity, extensive experiments show its\neffectiveness compared to other, more complicated methods. TextAdaIN achieves\nstate-of-the-art results on standard handwritten text recognition benchmarks.\nAdditionally, it generalizes to multiple architectures and to the domain of\nscene text recognition. Furthermore, we demonstrate that integrating TextAdaIN\nimproves robustness towards image corruptions.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Oren Nuriel",
      "Sharon Fogel",
      "Ron Litman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03906"
  },
  {
    "id": "arXiv:2105.03907",
    "title": "Generative Mechanisms: The mechanisms that implement codes",
    "abstract": "The purpose of this paper is to abstractly describe the notion of a\ngenerative mechanism that implements a code and to provide a number of examples\nincluding the DNA-RNA machinery that implements the genetic code, Chomsky's\nPrinciples & Parameters model of a child acquiring a specific grammar given\n`chunks' of linguistic experience (which play the role of the received code),\nand embryonic development where positional information in the developing embryo\nplays the role of the received code. A generative mechanism is distinguished\nfrom a selectionist mechanism that has heretofore played an important role in\nbiological modeling (e.g., Darwinian evolution and the immune system).",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1410.4501\n",
    "authors": [
      "David Ellerman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03907"
  },
  {
    "id": "arXiv:2105.03909",
    "title": "Diagnosable-by-Design Model-Driven Development for IEC 61499 Industrial  Cyber-Physical Systems",
    "abstract": "Integrating the design and creation of fault identification and diagnostic\ncapabilities into Model-Driven Development methodologies is one approach to\nenhancing the resilience of Industrial Cyber-Physical Systems. We present a\nFault Diagnostic Engine designed to recognise and diagnose faults in IEC 61499\nFunction Block Applications. Using diagnostic agents that interact directly\nwith the target application, we demonstrate fault monitoring and analysis\ntechniques and as well as failure scenario intervention. By designing and\nbuilding fault diagnostic resources during early phases of Model-Driven\nDevelopment, both iterative testing and long-term fault management capabilities\ncan be created. While applying and refining appropriate model artifacts, we\ndemonstrate that the concurrent development of function blocks alongside fault\nmanagement capabilities is both feasible and worthwhile.",
    "descriptor": "\nComments: Conference paper, 6 pages, 7 figures, 1 table\n",
    "authors": [
      "Barry Dowdeswell",
      "Roopak Sinha",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.03909"
  },
  {
    "id": "arXiv:2105.03917",
    "title": "Combining Time-Dependent Force Perturbations in Robot-Assisted Surgery  Training",
    "abstract": "Teleoperated robot-assisted minimally-invasive surgery (RAMIS) offers many\nadvantages over open surgery. However, there are still no guidelines for\ntraining skills in RAMIS. Motor learning theories have the potential to improve\nthe design of RAMIS training but they are based on simple movements that do not\nresemble the complex movements required in surgery. To fill this gap, we\ndesigned an experiment to investigate the effect of time-dependent force\nperturbations on the learning of a pattern-cutting surgical task. Thirty\nparticipants took part in the experiment: (1) a control group that trained\nwithout perturbations, and (2) a 1Hz group that trained with 1Hz periodic force\nperturbations that pushed each participant's hand inwards and outwards in the\nradial direction. We monitored their learning using four objective metrics and\nfound that participants in the 1Hz group learned how to overcome the\nperturbations and improved their performances during training without impairing\ntheir performances after the perturbations were removed. Our results present an\nimportant step toward understanding the effect of adding perturbations to RAMIS\ntraining protocols and improving RAMIS training for the benefit of surgeons and\npatients.",
    "descriptor": "",
    "authors": [
      "Yarden Sharon",
      "Daniel Naftalovich",
      "Lidor Bahar",
      "Yael Refaely",
      "Ilana Nisky"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.03917"
  },
  {
    "id": "arXiv:2105.03918",
    "title": "Opening the Blackbox: Accelerating Neural Differential Equations by  Regularizing Internal Solver Heuristics",
    "abstract": "Democratization of machine learning requires architectures that automatically\nadapt to new problems. Neural Differential Equations (NDEs) have emerged as a\npopular modeling framework by removing the need for ML practitioners to choose\nthe number of layers in a recurrent model. While we can control the\ncomputational cost by choosing the number of layers in standard architectures,\nin NDEs the number of neural network evaluations for a forward pass can depend\non the number of steps of the adaptive ODE solver. But, can we force the NDE to\nlearn the version with the least steps while not increasing the training cost?\nCurrent strategies to overcome slow prediction require high order automatic\ndifferentiation, leading to significantly higher training time. We describe a\nnovel regularization method that uses the internal cost heuristics of adaptive\ndifferential equation solvers combined with discrete adjoint sensitivities to\nguide the training process towards learning NDEs that are easier to solve. This\napproach opens up the blackbox numerical analysis behind the differential\nequation solver's algorithm and directly uses its local error estimates and\nstiffness heuristics as cheap and accurate cost estimates. We incorporate our\nmethod without any change in the underlying NDE framework and show that our\nmethod extends beyond Ordinary Differential Equations to accommodate Neural\nStochastic Differential Equations. We demonstrate how our approach can halve\nthe prediction time and, unlike other methods which can increase the training\ntime by an order of magnitude, we demonstrate similar reduction in training\ntimes. Together this showcases how the knowledge embedded within\nstate-of-the-art equation solvers can be used to enhance machine learning.",
    "descriptor": "\nComments: Proceedings of the 38 th International Conference on Machine Learning, 2021\n",
    "authors": [
      "Avik Pal",
      "Yingbo Ma",
      "Viral Shah",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03918"
  },
  {
    "id": "arXiv:2105.03923",
    "title": "CASA-B: A Unified Framework of Model-Free Reinforcement Learning",
    "abstract": "Building on the breakthrough of reinforcement learning, this paper introduces\na unified framework of model-free reinforcement learning, CASA-B, Critic AS an\nActor with Bandits Vote Algorithm. CASA-B is an actor-critic framework that\nestimates state-value, state-action-value and policy. An expectation-correct\nDoubly Robust Trace is introduced to learn state-value and state-action-value,\nwhose convergence properties are guaranteed. We prove that CASA-B integrates a\nconsistent path for the policy evaluation and the policy improvement. The\npolicy evaluation is equivalent to a compensational policy improvement, which\nalleviates the function approximation error, and is also equivalent to an\nentropy-regularized policy improvement, which prevents the policy from\ncollapsing to a suboptimal solution. Building on this design, we find the\nentropy of the behavior policies' and the target policy's are disentangled.\nBased on this observation, we propose a progressive closed-form entropy control\nmechanism, which explicitly controls the behavior policies' entropy to\narbitrary range. Our experiments show that CASAB is super sample efficient and\nachieves State-Of-The-Art on Arcade Learning Environment. Our mean Human\nNormalized Score is 6456.63% and our median Human Normalized Score is 477.17%,\nunder 200M training scale.",
    "descriptor": "",
    "authors": [
      "Changnan Xiao",
      "Haosen Shi",
      "Jiajun Fan",
      "Shihong Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03923"
  },
  {
    "id": "arXiv:2105.03925",
    "title": "On the Distribution of the Information Density of Gaussian Random  Vectors: Explicit Formulas and Tight Approximations",
    "abstract": "Based on the canonical correlation analysis we derive series representations\nof the probability density function (PDF) and the cumulative distribution\nfunction (CDF) of the information density of arbitrary Gaussian random vectors.\nUsing the series representations we give closed-form expressions of the PDF and\nCDF for important special cases and derive tight approximations for the general\ncase. Furthermore, we discuss the (in)validity of Gaussian approximations of\nthe information density.",
    "descriptor": "",
    "authors": [
      "Jonathan Huffmann",
      "Martin Mittelbach"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.03925"
  },
  {
    "id": "arXiv:2105.03928",
    "title": "Which transformer architecture fits my data? A vocabulary bottleneck in  self-attention",
    "abstract": "After their successful debut in natural language processing, Transformer\narchitectures are now becoming the de-facto standard in many domains. An\nobstacle for their deployment over new modalities is the architectural\nconfiguration: the optimal depth-to-width ratio has been shown to dramatically\nvary across data types (e.g., $10$x larger over images than over language). We\ntheoretically predict the existence of an embedding rank bottleneck that limits\nthe contribution of self-attention width to the Transformer expressivity. We\nthus directly tie the input vocabulary size and rank to the optimal\ndepth-to-width ratio, since a small vocabulary size or rank dictates an added\nadvantage of depth over width. We empirically demonstrate the existence of this\nbottleneck and its implications on the depth-to-width interplay of Transformer\narchitectures, linking the architecture variability across domains to the often\nglossed-over usage of different vocabulary sizes or embedding ranks in\ndifferent domains. As an additional benefit, our rank bottlenecking framework\nallows us to identify size redundancies of $25\\%-50\\%$ in leading NLP models\nsuch as ALBERT and T5.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Noam Wies",
      "Yoav Levine",
      "Daniel Jannai",
      "Amnon Shashua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03928"
  },
  {
    "id": "arXiv:2105.03930",
    "title": "Arbitrary high-order linear structure-preserving schemes for the  regularized long-wave equation",
    "abstract": "In this paper, a class of arbitrarily high-order linear momentum-preserving\nand energy-preserving schemes are proposed, respectively, for solving the\nregularized long-wave equation. For the momentum-preserving scheme, our key\nideas mainly follow the extrapolation/prediction-correction technique and\nsymplectic Runge-Kutta (RK) methods in time combined with the standard Fourier\npseudo-spectral method in space. We show that it is uniquely solvable,\nunconditionally stable and can exactly preserve the momentum of the system.\nSubsequently, based on the energy quadratization approach and the analogous\nlinearized idea used in the construction of the linear momentum-preserving\nscheme, the energy-preserving scheme is presented and it is proven to preserve\nboth the discrete mass and quadratic energy. Numerical results are addressed to\ndemonstrate the accuracy and efficiency of the schemes.",
    "descriptor": "\nComments: 22 pages, 39 figures\n",
    "authors": [
      "Chaolong Jiang",
      "Xu Qian",
      "Songhe Song",
      "Jin Cui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03930"
  },
  {
    "id": "arXiv:2105.03931",
    "title": "Automated Decision-based Adversarial Attacks",
    "abstract": "Deep learning models are vulnerable to adversarial examples, which can fool a\ntarget classifier by imposing imperceptible perturbations onto natural\nexamples. In this work, we consider the practical and challenging\ndecision-based black-box adversarial setting, where the attacker can only\nacquire the final classification labels by querying the target model without\naccess to the model's details. Under this setting, existing works often rely on\nheuristics and exhibit unsatisfactory performance. To better understand the\nrationality of these heuristics and the limitations of existing methods, we\npropose to automatically discover decision-based adversarial attack algorithms.\nIn our approach, we construct a search space using basic mathematical\noperations as building blocks and develop a random search algorithm to\nefficiently explore this space by incorporating several pruning techniques and\nintuitive priors inspired by program synthesis works. Although we use a small\nand fast model to efficiently evaluate attack algorithms during the search,\nextensive experiments demonstrate that the discovered algorithms are simple yet\nquery-efficient when transferred to larger normal and defensive models on the\nCIFAR-10 and ImageNet datasets. They achieve comparable or better performance\nthan the state-of-the-art decision-based attack methods consistently.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Qi-An Fu",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.03931"
  },
  {
    "id": "arXiv:2105.03933",
    "title": "Joint Learning of Deep Retrieval Model and Product Quantization based  Embedding Index",
    "abstract": "Embedding index that enables fast approximate nearest neighbor(ANN) search,\nserves as an indispensable component for state-of-the-art deep retrieval\nsystems. Traditional approaches, often separating the two steps of embedding\nlearning and index building, incur additional indexing time and decayed\nretrieval accuracy. In this paper, we propose a novel method called Poeem,\nwhich stands for product quantization based embedding index jointly trained\nwith deep retrieval model, to unify the two separate steps within an end-to-end\ntraining, by utilizing a few techniques including the gradient straight-through\nestimator, warm start strategy, optimal space decomposition and Givens\nrotation. Extensive experimental results show that the proposed method not only\nimproves retrieval accuracy significantly but also reduces the indexing time to\nalmost none. We have open sourced our approach for the sake of comparison and\nreproducibility.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Han Zhang",
      "Hongwei Shen",
      "Yiming Qiu",
      "Yunjiang Jiang",
      "Songlin Wang",
      "Sulong Xu",
      "Yun Xiao",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03933"
  },
  {
    "id": "arXiv:2105.03934",
    "title": "Fish Disease Detection Using Image Based Machine Learning Technique in  Aquaculture",
    "abstract": "Fish diseases in aquaculture constitute a significant hazard to nutriment\nsecurity. Identification of infected fishes in aquaculture remains challenging\nto find out at the early stage due to the dearth of necessary infrastructure.\nThe identification of infected fish timely is an obligatory step to thwart from\nspreading disease. In this work, we want to find out the salmon fish disease in\naquaculture, as salmon aquaculture is the fastest-growing food production\nsystem globally, accounting for 70 percent (2.5 million tons) of the market. In\nthe alliance of flawless image processing and machine learning mechanism, we\nidentify the infected fishes caused by the various pathogen. This work divides\ninto two portions. In the rudimentary portion, image pre-processing and\nsegmentation have been applied to reduce noise and exaggerate the image,\nrespectively. In the second portion, we extract the involved features to\nclassify the diseases with the help of the Support Vector Machine (SVM)\nalgorithm of machine learning with a kernel function. The processed images of\nthe first portion have passed through this (SVM) model. Then we harmonize a\ncomprehensive experiment with the proposed combination of techniques on the\nsalmon fish image dataset used to examine the fish disease. We have conveyed\nthis work on a novel dataset compromising with and without image augmentation.\nThe results have bought a judgment of our applied SVM performs notably with\n91.42 and 94.12 percent of accuracy, respectively, with and without\naugmentation.",
    "descriptor": "\nComments: 15 pages, 10 figures, 7 tables. Accepted Manuscript. Journal of King Saud University - Computer and Information Sciences\n",
    "authors": [
      "Md Shoaib Ahmed",
      "Tanjim Taharat Aurpa",
      "Md. Abul Kalam Azad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03934"
  },
  {
    "id": "arXiv:2105.03938",
    "title": "Passage Retrieval for Outside-Knowledge Visual Question Answering",
    "abstract": "In this work, we address multi-modal information needs that contain text\nquestions and images by focusing on passage retrieval for outside-knowledge\nvisual question answering. This task requires access to outside knowledge,\nwhich in our case we define to be a large unstructured passage collection. We\nfirst conduct sparse retrieval with BM25 and study expanding the question with\nobject names and image captions. We verify that visual clues play an important\nrole and captions tend to be more informative than object names in sparse\nretrieval. We then construct a dual-encoder dense retriever, with the query\nencoder being LXMERT, a multi-modal pre-trained transformer. We further show\nthat dense retrieval significantly outperforms sparse retrieval that uses\nobject expansion. Moreover, dense retrieval matches the performance of sparse\nretrieval that leverages human-generated captions.",
    "descriptor": "\nComments: Accepted to SIGIR'21 as a short paper\n",
    "authors": [
      "Chen Qu",
      "Hamed Zamani",
      "Liu Yang",
      "W. Bruce Croft",
      "Erik Learned-Miller"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03938"
  },
  {
    "id": "arXiv:2105.03941",
    "title": "Stronger Privacy for Federated Collaborative Filtering with Implicit  Feedback",
    "abstract": "Recommender systems are commonly trained on centrally collected user\ninteraction data like views or clicks. This practice however raises serious\nprivacy concerns regarding the recommender's collection and handling of\npotentially sensitive data. Several privacy-aware recommender systems have been\nproposed in recent literature, but comparatively little attention has been\ngiven to systems at the intersection of implicit feedback and privacy. To\naddress this shortcoming, we propose a practical federated recommender system\nfor implicit data under user-level local differential privacy (LDP). The\nprivacy-utility trade-off is controlled by parameters $\\epsilon$ and $k$,\nregulating the per-update privacy budget and the number of $\\epsilon$-LDP\ngradient updates sent by each user respectively. To further protect the user's\nprivacy, we introduce a proxy network to reduce the fingerprinting surface by\nanonymizing and shuffling the reports before forwarding them to the\nrecommender. We empirically demonstrate the effectiveness of our framework on\nthe MovieLens dataset, achieving up to Hit Ratio with K=10 (HR@10) 0.68 on 50k\nusers with 5k items. Even on the full dataset, we show that it is possible to\nachieve reasonable utility with HR@10>0.5 without compromising user privacy.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Lorenzo Minto",
      "Moritz Haller",
      "Hammed Haddadi",
      "Benjamin Livshits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.03941"
  },
  {
    "id": "arXiv:2105.03943",
    "title": "gComm: An environment for investigating generalization in Grounded  Language Acquisition",
    "abstract": "gComm is a step towards developing a robust platform to foster research in\ngrounded language acquisition in a more challenging and realistic setting. It\ncomprises a 2-d grid environment with a set of agents (a stationary speaker and\na mobile listener connected via a communication channel) exposed to a\ncontinuous array of tasks in a partially observable setting. The key to solving\nthese tasks lies in agents developing linguistic abilities and utilizing them\nfor efficiently exploring the environment. The speaker and listener have access\nto information provided in different modalities, i.e. the speaker's input is a\nnatural language instruction that contains the target and task specifications\nand the listener's input is its grid-view. Each must rely on the other to\ncomplete the assigned task, however, the only way they can achieve the same, is\nto develop and use some form of communication. gComm provides several tools for\nstudying different forms of communication and assessing their generalization.",
    "descriptor": "\nComments: Accepted in NAACL 2021 workshop: Visually Grounded Interaction and Language (ViGIL)\n",
    "authors": [
      "Rishi Hazra",
      "Sonu Dixit"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03943"
  },
  {
    "id": "arXiv:2105.03949",
    "title": "High-performance symbolic-numerics via multiple dispatch",
    "abstract": "As mathematical computing becomes more democratized in high-level languages,\nhigh-performance symbolic-numeric systems are necessary for domain scientists\nand engineers to get the best performance out of their machine without deep\nknowledge of code optimization. Naturally, users need different term types\neither to have different algebraic properties for them, or to use efficient\ndata structures. To this end, we developed Symbolics.jl, an extendable symbolic\nsystem which uses dynamic multiple dispatch to change behavior depending on the\ndomain needs. In this work we detail an underlying abstract term interface\nwhich allows for speed without sacrificing generality. We show that by\nformalizing a generic API on actions independent of implementation, we can\nretroactively add optimized data structures to our system without changing the\npre-existing term rewriters. We showcase how this can be used to optimize term\nconstruction and give a 113x acceleration on general symbolic transformations.\nFurther, we show that such a generic API allows for complementary\nterm-rewriting implementations. We demonstrate the ability to swap between\nclassical term-rewriting simplifiers and e-graph-based term-rewriting\nsimplifiers. We showcase an e-graph ruleset which minimizes the number of CPU\ncycles during expression evaluation, and demonstrate how it simplifies a\nreal-world reaction-network simulation to halve the runtime. Additionally, we\nshow a reaction-diffusion partial differential equation solver which is able to\nbe automatically converted into symbolic expressions via multiple dispatch\ntracing, which is subsequently accelerated and parallelized to give a 157x\nsimulation speedup. Together, this presents Symbolics.jl as a next-generation\nsymbolic-numeric computing environment geared towards modeling and simulation.",
    "descriptor": "",
    "authors": [
      "Shashi Gowda",
      "Yingbo Ma",
      "Alessandro Cheli",
      "Maja Gwozdz",
      "Viral B. Shah",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.03949"
  },
  {
    "id": "arXiv:2105.03953",
    "title": "Continual Mixed-Language Pre-Training for Extremely Low-Resource Neural  Machine Translation",
    "abstract": "The data scarcity in low-resource languages has become a bottleneck to\nbuilding robust neural machine translation systems. Fine-tuning a multilingual\npre-trained model (e.g., mBART (Liu et al., 2020)) on the translation task is a\ngood approach for low-resource languages; however, its performance will be\ngreatly limited when there are unseen languages in the translation pairs. In\nthis paper, we present a continual pre-training (CPT) framework on mBART to\neffectively adapt it to unseen languages. We first construct noisy\nmixed-language text from the monolingual corpus of the target language in the\ntranslation pair to cover both the source and target languages, and then, we\ncontinue pre-training mBART to reconstruct the original monolingual text.\nResults show that our method can consistently improve the fine-tuning\nperformance upon the mBART baseline, as well as other strong baselines, across\nall tested low-resource translation pairs containing unseen languages.\nFurthermore, our approach also boosts the performance on translation pairs\nwhere both languages are seen in the original mBART's pre-training. The code is\navailable at https://github.com/zliucr/cpt-nmt.",
    "descriptor": "\nComments: Accepted in Findings of ACL 2021\n",
    "authors": [
      "Zihan Liu",
      "Genta Indra Winata",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03953"
  },
  {
    "id": "arXiv:2105.03958",
    "title": "Preserving Privacy in Human-Motion Affect Recognition",
    "abstract": "Human motion is a biomarker used extensively in clinical analysis to monitor\nthe progression of neurological diseases and mood disorders. Since perceptions\nof emotions are also interleaved with body posture and movements, emotion\nrecognition from human gait can be used to quantitatively monitor mood changes\nthat are often related to neurological disorders. Many existing solutions often\nuse shallow machine learning models with raw positional data or manually\nextracted features to achieve this. However, gait is composed of many highly\nexpressive characteristics that can be used to identify human subjects, and\nmost solutions fail to address this, disregarding the subject's privacy. This\nwork evaluates the effectiveness of existing methods at recognising emotions\nusing both 3D temporal joint signals and manually extracted features. We also\nshow that this data can easily be exploited to expose a subject's identity.\nTherefore to this end, we propose a cross-subject transfer learning technique\nfor training a multi-encoder autoencoder deep neural network to learn\ndisentangled latent representations of human motion features. By disentangling\nsubject biometrics from the gait data, we show that the subjects privacy is\npreserved while the affect recognition performance outperforms traditional\nmethods.",
    "descriptor": "",
    "authors": [
      "Matthew Malek-Podjaski",
      "Fani Deligianni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03958"
  },
  {
    "id": "arXiv:2105.03962",
    "title": "Stochastic Multi-Armed Bandits with Control Variates",
    "abstract": "This paper studies a new variant of the stochastic multi-armed bandits\nproblem, where the learner has access to auxiliary information about the arms.\nThe auxiliary information is correlated with the arm rewards, which we treat as\ncontrol variates. In many applications, the arm rewards are a function of some\nexogenous values, whose mean value is known a priori from historical data and\nhence can be used as control variates. We use the control variates to obtain\nmean estimates with smaller variance and tighter confidence bounds. We then\ndevelop an algorithm named UCB-CV that uses improved estimates. We characterize\nthe regret bounds in terms of the correlation between the rewards and control\nvariates. The experiments on synthetic data validate the performance guarantees\nof our proposed algorithm.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Arun Verma",
      "Manjesh K. Hanawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03962"
  },
  {
    "id": "arXiv:2105.03966",
    "title": "Unit Ball Model for Hierarchical Embeddings in Complex Hyperbolic Space",
    "abstract": "Learning the representation of data with hierarchical structures in the\nhyperbolic space attracts increasing attention in recent years. Due to the\nconstant negative curvature, the hyperbolic space resembles tree metrics and\ncaptures the tree-like properties of hierarchical graphs naturally, which\nenables the hyperbolic embeddings to improve over traditional Euclidean models.\nHowever, most graph data, even the data with hierarchical structures are not\ntrees and they usually do not ubiquitously match the constant curvature\nproperty of the hyperbolic space. To address this limitation of hyperbolic\nembeddings, we explore the complex hyperbolic space, which has the variable\nnegative curvature, for representation learning. Specifically, we propose to\nlearn the graph embeddings in the unit ball model of the complex hyperbolic\nspace. The unit ball model based embeddings have a more powerful representation\ncapacity to capture a variety of hierarchical graph structures. Through\nexperiments on synthetic and real-world data, we show that our approach\nimproves over the hyperbolic embedding models significantly.",
    "descriptor": "",
    "authors": [
      "Huiru Xiao",
      "Caigao Jiang",
      "Yangqiu Song",
      "James Zhang",
      "Junwu Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03966"
  },
  {
    "id": "arXiv:2105.03968",
    "title": "Fast $n$-fold Boolean Convolution via Additive Combinatorics",
    "abstract": "We consider the problem of computing the Boolean convolution (with\nwraparound) of $n$~vectors of dimension $m$, or, equivalently, the problem of\ncomputing the sumset $A_1+A_2+\\ldots+A_n$ for $A_1,\\ldots,A_n \\subseteq\n\\mathbb{Z}_m$. Boolean convolution formalizes the frequent task of combining\ntwo subproblems, where the whole problem has a solution of size $k$ if for some\n$i$ the first subproblem has a solution of size~$i$ and the second subproblem\nhas a solution of size $k-i$. Our problem formalizes a natural generalization,\nnamely combining solutions of $n$ subproblems subject to a modular constraint.\nThis simultaneously generalises Modular Subset Sum and Boolean Convolution\n(Sumset Computation). Although nearly optimal algorithms are known for special\ncases of this problem, not even tiny improvements are known for the general\ncase.\nWe almost resolve the computational complexity of this problem, shaving\nessentially a factor of $n$ from the running time of previous algorithms.\nSpecifically, we present a \\emph{deterministic} algorithm running in\n\\emph{almost} linear time with respect to the input plus output size $k$. We\nalso present a \\emph{Las Vegas} algorithm running in \\emph{nearly} linear\nexpected time with respect to the input plus output size $k$. Previously, no\ndeterministic or randomized $o(nk)$ algorithm was known.\nAt the heart of our approach lies a careful usage of Kneser's theorem from\nAdditive Combinatorics, and a new deterministic almost linear output-sensitive\nalgorithm for non-negative sparse convolution. In total, our work builds a\nsolid toolbox that could be of independent interest.",
    "descriptor": "\nComments: ICALP 2021, 17 pages\n",
    "authors": [
      "Karl Bringmann",
      "Vasileios Nakos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03968"
  },
  {
    "id": "arXiv:2105.03973",
    "title": "Perturbation-based Frequency Domain Linear and Nonlinear Noise  Estimation",
    "abstract": "In this paper, a new method for the separation of noise categories based on\nFour-Wave Mixing is presented.\nThe theoretical analysis is grounded in the Gaussian Noise model and verified\nby split step simulations. The noise categories react differently to the\nintroduced perturbations, by performing a set of perturbations the behaviour of\nthe different categories can be separated by means of a least-square fitting.\nGiven ASE is independent of the induced perturbations, it is possible to\nseparate noise contributions. The analysis includes constant and variable power\nperturbations.\nThe estimation of the noise categories is discussed from two points of view:\nNSR evolution post-DSP processing, and over the power spectral density in a\nnotched region. The NSR estimation can only be performed at reception, whereas\nthe power spectral density approach can be performed along the optical link if\na high resolution Optical Spectrum Analyzer is available.\nAdditionally, we perform a simple experimental verification considering of\ntwo WaveLogic 3 transceivers for the NSR, successfully estimating the noise\ncontributions.",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "F.J. Vaquero-Caballero",
      "D.J. Ives",
      "S.J. Savory"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03973"
  },
  {
    "id": "arXiv:2105.03979",
    "title": "Improving Patent Mining and Relevance Classification using Transformers",
    "abstract": "Patent analysis and mining are time-consuming and costly processes for\ncompanies, but nevertheless essential if they are willing to remain\ncompetitive. To face the overload induced by numerous patents, the idea is to\nautomatically filter them, bringing only few to read to experts. This paper\nreports a successful application of fine-tuning and retraining on pre-trained\ndeep Natural Language Processing models on patent classification. The solution\nthat we propose combines several state-of-the-art treatments to achieve our\ngoal - decrease the workload while preserving recall and precision metrics.",
    "descriptor": "\nComments: 6th National Conference on Practical Applications of Artificial Intelligence, 2021, Bordeaux, France\n",
    "authors": [
      "Th\u00e9o Ding",
      "Walter Vermeiren",
      "Sylvie Ranwez",
      "Binbin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03979"
  },
  {
    "id": "arXiv:2105.03983",
    "title": "Understanding the Role of Affect Dimensions in Detecting Emotions from  Tweets: A Multi-task Approach",
    "abstract": "We propose VADEC, a multi-task framework that exploits the correlation\nbetween the categorical and dimensional models of emotion representation for\nbetter subjectivity analysis. Focusing primarily on the effective detection of\nemotions from tweets, we jointly train multi-label emotion classification and\nmulti-dimensional emotion regression, thereby utilizing the inter-relatedness\nbetween the tasks. Co-training especially helps in improving the performance of\nthe classification task as we outperform the strongest baselines with 3.4%,\n11%, and 3.9% gains in Jaccard Accuracy, Macro-F1, and Micro-F1 scores\nrespectively on the AIT dataset. We also achieve state-of-the-art results with\n11.3% gains averaged over six different metrics on the SenWave dataset. For the\nregression task, VADEC, when trained with SenWave, achieves 7.6% and 16.5%\ngains in Pearson Correlation scores over the current state-of-the-art on the\nEMOBANK dataset for the Valence (V) and Dominance (D) affect dimensions\nrespectively. We conclude our work with a case study on COVID-19 tweets posted\nby Indians that further helps in establishing the efficacy of our proposed\nsolution.",
    "descriptor": "\nComments: 5 pages, Short Paper accepted at SIGIR 2021\n",
    "authors": [
      "Rajdeep Mukherjee",
      "Atharva Naik",
      "Sriyash Poddar",
      "Soham Dasgupta",
      "Niloy Ganguly"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03983"
  },
  {
    "id": "arXiv:2105.03986",
    "title": "Advising Agent for Service-Providing Live-Chat Operators",
    "abstract": "Call centers, in which human operators attend clients using textual chat, are\nvery common in modern e-commerce. Training enough skilled operators who are\nable to provide good service is a challenge. We suggest an algorithm and a\nmethod to train and implement an assisting agent that provides on-line advice\nto operators while they attend clients. The agent is domain-independent and can\nbe introduced to new domains without major efforts in design, training and\norganizing structured knowledge of the professional discipline. We demonstrate\nthe applicability of the system in an experiment that realizes its full\nlife-cycle on a specific domain and analyze its capabilities.",
    "descriptor": "",
    "authors": [
      "Aviram Aviv",
      "Yaniv Oshrat",
      "Samuel A. Assefa",
      "Tobi Mustapha",
      "Daniel Borrajo",
      "Manuela Veloso",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.03986"
  },
  {
    "id": "arXiv:2105.03994",
    "title": "Dispatcher: A Message-Passing Approach To Language Modelling",
    "abstract": "This paper proposes a message-passing mechanism to address language\nmodelling. A new layer type is introduced that aims to substitute\nself-attention. The system is shown to be competitive with existing methods:\nGiven N tokens, the computational complexity is O(N log N) and the memory\ncomplexity is O(N) under reasonable assumptions. In the end, the Dispatcher\nlayer is seen to achieve comparable perplexity to prior results while being\nmore efficient",
    "descriptor": "",
    "authors": [
      "Alberto Cetoli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03994"
  },
  {
    "id": "arXiv:2105.04003",
    "title": "Efficiency-driven Hardware Optimization for Adversarially Robust Neural  Networks",
    "abstract": "With a growing need to enable intelligence in embedded devices in the\nInternet of Things (IoT) era, secure hardware implementation of Deep Neural\nNetworks (DNNs) has become imperative. We will focus on how to address\nadversarial robustness for DNNs through efficiency-driven hardware\noptimizations. Since memory (specifically, dot-product operations) is a key\nenergy-spending component for DNNs, hardware approaches in the past have\nfocused on optimizing the memory. One such approach is approximate digital CMOS\nmemories with hybrid 6T-8T SRAM cells that enable supply voltage (Vdd) scaling\nyielding low-power operation, without significantly affecting the performance\ndue to read/write failures incurred in the 6T cells. In this paper, we show how\nthe bit-errors in the 6T cells of hybrid 6T-8T memories minimize the\nadversarial perturbations in a DNN. Essentially, we find that for different\nconfigurations of 8T-6T ratios and scaledVdd operation, noise incurred in the\nhybrid memory architectures is bound within specific limits. This hardware\nnoise can potentially interfere in the creation of adversarial attacks in DNNs\nyielding robustness. Another memory optimization approach involves using analog\nmemristive crossbars that perform Matrix-Vector-Multiplications (MVMs)\nefficiently with low energy and area requirements. However, crossbars generally\nsuffer from intrinsic non-idealities that cause errors in performing MVMs,\nleading to degradation in the accuracy of the DNNs. We will show how the\nintrinsic hardware variations manifested through crossbar non-idealities yield\nadversarial robustness to the mapped DNNs without any additional optimization.",
    "descriptor": "\nComments: 6 pages, 8 figures, 3 tables; Accepted in DATE 2021 conference. arXiv admin note: text overlap with arXiv:2008.11298\n",
    "authors": [
      "Abhiroop Bhattacharjee",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.04003"
  },
  {
    "id": "arXiv:2105.04005",
    "title": "Delay-Tolerant Constrained OCO with Application to Network Resource  Allocation",
    "abstract": "We consider online convex optimization (OCO) with multi-slot feedback delay,\nwhere an agent makes a sequence of online decisions to minimize the\naccumulation of time-varying convex loss functions, subject to short-term and\nlong-term constraints that are possibly time-varying. The current convex loss\nfunction and the long-term constraint function are revealed to the agent only\nafter the decision is made, and they may be delayed for multiple time slots.\nExisting work on OCO under this general setting has focused on the static\nregret, which measures the gap of losses between the online decision sequence\nand an offline benchmark that is fixed over time. In this work, we consider\nboth the static regret and the more practically meaningful dynamic regret,\nwhere the benchmark is a time-varying sequence of per-slot optimizers. We\npropose an efficient algorithm, termed Delay-Tolerant Constrained-OCO\n(DTC-OCO), which uses a novel constraint penalty with double regularization to\ntackle the asynchrony between information feedback and decision updates. We\nderive upper bounds on its dynamic regret, static regret, and constraint\nviolation, proving them to be sublinear under mild conditions. We further apply\nDTC-OCO to a general network resource allocation problem, which arises in many\nsystems such as data networks and cloud computing. Simulation results\ndemonstrate substantial performance gain of DTC-OCO over the known best\nalternative.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Juncheng Wang",
      "Ben Liang",
      "Min Dong",
      "Gary Boudreau",
      "Hatem Abou-zeid"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04005"
  },
  {
    "id": "arXiv:2105.04009",
    "title": "RB-CCR: Radial-Based Combined Cleaning and Resampling algorithm for  imbalanced data classification",
    "abstract": "Real-world classification domains, such as medicine, health and safety, and\nfinance, often exhibit imbalanced class priors and have asynchronous\nmisclassification costs. In such cases, the classification model must achieve a\nhigh recall without significantly impacting precision. Resampling the training\ndata is the standard approach to improving classification performance on\nimbalanced binary data. However, the state-of-the-art methods ignore the local\njoint distribution of the data or correct it as a post-processing step. This\ncan causes sub-optimal shifts in the training distribution, particularly when\nthe target data distribution is complex. In this paper, we propose Radial-Based\nCombined Cleaning and Resampling (RB-CCR). RB-CCR utilizes the concept of class\npotential to refine the energy-based resampling approach of CCR. In particular,\nRB-CCR exploits the class potential to accurately locate sub-regions of the\ndata-space for synthetic oversampling. The category sub-region for oversampling\ncan be specified as an input parameter to meet domain-specific needs or be\nautomatically selected via cross-validation. Our $5\\times2$ cross-validated\nresults on 57 benchmark binary datasets with 9 classifiers show that RB-CCR\nachieves a better precision-recall trade-off than CCR and generally\nout-performs the state-of-the-art resampling methods in terms of AUC and\nG-mean.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Koziarski",
      "Colin Bellinger",
      "Micha\u0142 Wo\u017aniak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04009"
  },
  {
    "id": "arXiv:2105.04015",
    "title": "Discomfort: a New Material for Interaction Design",
    "abstract": "This paper proposes discomfort as a new material for HCI researchers and\ndesigners to consider in any application that helps a person develop a new\nskill, practice or state. Discomfort is a fundamental precursor of adaptation\nand adaptation leads to new skill, practice or state. The way in which\ndiscomfort is perceived, and when it is experienced, is also often part of a\nrationale for rejecting or adopting a practice. Engaging effectively with\ndiscomfort may lead to increased personal development. We propose incorporating\ndiscomfort-as-material into our designs explicitly as a mechanism to make\ndesired adaptations available to more of us, more effectively and more of the\ntime. To explore this possibility, we offer an overview of the physiology and\nneurology of discomfort in adaptation and propose 3 issues related to\nincorporating discomfort into design: preparation for discomfort, need for\nrecovery, and value of the practice. We look forward in the Workshop to\nexploring and developing ideas for specific Discomfortable Designs to insource\ndiscomfort as part of positive, resilient adaptation.",
    "descriptor": "\nComments: 8 pages of text + 2 pages refs, 36 references. Accepted paper, 4th Body as Starting Point Workshop, part of ACM CHI2021 conference (this https URL)\n",
    "authors": [
      "m.c. schraefel",
      "Michael Jones"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.04015"
  },
  {
    "id": "arXiv:2105.04017",
    "title": "Concurrent infill topology and shape optimisation of lattice-skin  structures",
    "abstract": "Lattice-skin structures composed of a thin-shell skin and a lattice infill\nare widespread in nature and large-scale engineering due to their efficiency\nand exceptional mechanical properties. Recent advances in additive\nmanufacturing, or 3D printing, make it possible to create lattice-skin\nstructures of almost any size with arbitrary shape and geometric complexity. We\npropose a novel gradient-based approach to optimising both the shape and infill\nof lattice-skin structures to improve their efficiency further. The shell is\nmodelled as a Kirchhoff-Love shell and analysed using isogeometric subdivision\nsurfaces, whereas the lattice is modelled as a pin-jointed truss. The lattice\nconsists of many cells, possibly of different sizes, with each containing a\nsmall number of struts. We propose a penalisation approach akin to the SIMP\n(solid isotropic material with penalisation) method for topology optimisation\nof the lattice. Furthermore, a corresponding sensitivity filter and a lattice\nextraction technique are introduced to ensure the stability of the optimisation\nprocess and to eliminate scattered struts of small cross-sectional areas. The\ndeveloped topology optimisation technique is suitable for non-periodic,\nnon-uniform lattices. For shape optimisation of both the shell and the lattice,\nthe geometry of the lattice-skin structure is parameterised using the free-form\ndeformation technique. The topology and shape optimisation problems are solved\nin an iterative, sequential manner. The effectiveness of the proposed approach\nand the influence of different algorithmic parameters are demonstrated with\nseveral numerical examples.",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Xiao Xiao",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.04017"
  },
  {
    "id": "arXiv:2105.04019",
    "title": "Differentiable Sorting Networks for Scalable Sorting and Ranking  Supervision",
    "abstract": "Sorting and ranking supervision is a method for training neural networks\nend-to-end based on ordering constraints. That is, the ground truth order of\nsets of samples is known, while their absolute values remain unsupervised. For\nthat, we propose differentiable sorting networks by relaxing their pairwise\nconditional swap operations. To address the problems of vanishing gradients and\nextensive blurring that arise with larger numbers of layers, we propose mapping\nactivations to regions with moderate gradients. We consider odd-even as well as\nbitonic sorting networks, which outperform existing relaxations of the sorting\noperation. We show that bitonic sorting networks can achieve stable training on\nlarge input sets of up to 1024 elements.",
    "descriptor": "",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04019"
  },
  {
    "id": "arXiv:2105.04020",
    "title": "End-to-End Optical Character Recognition for Bengali Handwritten Words",
    "abstract": "Optical character recognition (OCR) is a process of converting analogue\ndocuments into digital using document images. Currently, many commercial and\nnon-commercial OCR systems exist for both handwritten and printed copies for\ndifferent languages. Despite this, very few works are available in case of\nrecognising Bengali words. Among them, most of the works focused on OCR of\nprinted Bengali characters. This paper introduces an end-to-end OCR system for\nBengali language. The proposed architecture implements an end to end strategy\nthat recognises handwritten Bengali words from handwritten word images. We\nexperiment with popular convolutional neural network (CNN) architectures,\nincluding DenseNet, Xception, NASNet, and MobileNet to build the OCR\narchitecture. Further, we experiment with two different recurrent neural\nnetworks (RNN) methods, LSTM and GRU. We evaluate the proposed architecture\nusing BanglaWritting dataset, which is a peer-reviewed Bengali handwritten\nimage dataset. The proposed method achieves 0.091 character error rate and\n0.273 word error rate performed using DenseNet121 model with GRU recurrent\nlayer.",
    "descriptor": "\nComments: Accepted in \"The 4th National Computing Colleges Conference\"\n",
    "authors": [
      "Farisa Benta Safir",
      "Abu Quwsar Ohi",
      "M.F. Mridha",
      "Muhammad Mostafa Monowar",
      "Md. Abdul Hamid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04020"
  },
  {
    "id": "arXiv:2105.04021",
    "title": "MS MARCO: Benchmarking Ranking Models in the Large-Data Regime",
    "abstract": "Evaluation efforts such as TREC, CLEF, NTCIR and FIRE, alongside public\nleaderboard such as MS MARCO, are intended to encourage research and track our\nprogress, addressing big questions in our field. However, the goal is not\nsimply to identify which run is \"best\", achieving the top score. The goal is to\nmove the field forward by developing new robust techniques, that work in many\ndifferent settings, and are adopted in research and practice. This paper uses\nthe MS MARCO and TREC Deep Learning Track as our case study, comparing it to\nthe case of TREC ad hoc ranking in the 1990s. We show how the design of the\nevaluation effort can encourage or discourage certain outcomes, and raising\nquestions about internal and external validity of results. We provide some\nanalysis of certain pitfalls, and a statement of best practices for avoiding\nsuch pitfalls. We summarize the progress of the effort so far, and describe our\ndesired end state of \"robust usefulness\", along with steps that might be\nrequired to get us there.",
    "descriptor": "",
    "authors": [
      "Nick Craswell",
      "Bhaskar Mitra",
      "Emine Yilmaz",
      "Daniel Campos",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04021"
  },
  {
    "id": "arXiv:2105.04022",
    "title": "Designing a Web Application for Simple and Collaborative Video  Annotation That Meets Teaching Routines and Educational Requirements",
    "abstract": "Video annotation and analysis is an important activity for teaching with and\nabout audiovisual media artifacts because it helps students to learn how to\nidentify textual and formal connections in media products. But school teachers\nlack adequate tools for video annotation and analysis in media education that\nare easy-to-use, integrate into established teaching organization, and support\nquick collaborative work. To address these challenges, we followed a\ndesign-based research approach and conducted qualitative interviews with\nteachers to develop TRAVIS GO, a web application for simple and collaborative\nvideo annotation. TRAVIS GO allows for quick and easy use within established\nteaching settings. The web application provides basic analytical features in an\nadaptable work space. Key didactic features include tagging and commenting on\nposts, sharing and exporting projects, and working in live collaboration.\nTeachers can create assignments according to grade level, learning subject, and\nclass size. Our work contributes further insights for the CSCW community about\nhow to implement user demands into developing educational tools.",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Daniel Klug",
      "Elke Schlote"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04022"
  },
  {
    "id": "arXiv:2105.04023",
    "title": "Fast and Error-Adaptive Influence Maximization based on Count-Distinct  Sketches",
    "abstract": "Influence maximization (IM) is the problem of finding a seed vertex set that\nmaximizes the expected number of vertices influenced under a given diffusion\nmodel. Due to the NP-Hardness of finding an optimal seed set, approximation\nalgorithms are frequently used for IM. In this work, we describe a fast,\nerror-adaptive approach that leverages Count-Distinct sketches and hash-based\nfused sampling. To estimate the number of influenced vertices throughout a\ndiffusion, we use per-vertex Flajolet-Martin sketches where each sketch\ncorresponds to a sampled subgraph. To efficiently simulate the diffusions, the\nreach-set cardinalities of a single vertex are stored in memory in a\nconsecutive fashion. This allows the proposed algorithm to estimate the number\nof influenced vertices in a single step for simulations at once. For a faster\nIM kernel, we rebuild the sketches in parallel only after observing estimation\nerrors above a given threshold. Our experimental results show that the proposed\nalgorithm yields high-quality seed sets while being up to 119x faster than a\nstate-of-the-art approximation algorithm. In addition, it is up to 62x faster\nthan a sketch-based approach while producing seed sets with 3%-12% better\ninfluence scores",
    "descriptor": "\nComments: 12 pages. Sent to IEEE Transactions on Knowledge and Data Engineering as a regular paper\n",
    "authors": [
      "Gokhan Gokturk",
      "Kamer Kaya"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.04023"
  },
  {
    "id": "arXiv:2105.04024",
    "title": "DocSCAN: Unsupervised Text Classification via Learning from Neighbors",
    "abstract": "We introduce DocSCAN, a completely unsupervised text classification approach\nusing Semantic Clustering by Adopting Nearest-Neighbors (SCAN). For each\ndocument, we obtain semantically informative vectors from a large pre-trained\nlanguage model. Similar documents have proximate vectors, so neighbors in the\nrepresentation space tend to share topic labels. Our learnable clustering\napproach uses pairs of neighboring datapoints as a weak learning signal. The\nproposed approach learns to assign classes to the whole dataset without\nprovided ground-truth labels. On five topic classification benchmarks, we\nimprove on various unsupervised baselines by a large margin. In datasets with\nrelatively few and balanced outcome classes, DocSCAN approaches the performance\nof supervised classification. The method fails for other types of\nclassification, such as sentiment analysis, pointing to important conceptual\nand practical differences between classifying images and texts.",
    "descriptor": "",
    "authors": [
      "Dominik Stammbach",
      "Elliott Ash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04024"
  },
  {
    "id": "arXiv:2105.04026",
    "title": "The Modern Mathematics of Deep Learning",
    "abstract": "We describe the new field of mathematical analysis of deep learning. This\nfield emerged around a list of research questions that were not answered within\nthe classical framework of learning theory. These questions concern: the\noutstanding generalization power of overparametrized neural networks, the role\nof depth in deep architectures, the apparent absence of the curse of\ndimensionality, the surprisingly successful optimization performance despite\nthe non-convexity of the problem, understanding what features are learned, why\ndeep architectures perform exceptionally well in physical problems, and which\nfine aspects of an architecture affect the behavior of a learning task in which\nway. We present an overview of modern approaches that yield partial answers to\nthese questions. For selected approaches, we describe the main ideas in more\ndetail.",
    "descriptor": "\nComments: This review paper will appear as a book chapter in the book \"Theory of Deep Learning\" by Cambridge University Press\n",
    "authors": [
      "Julius Berner",
      "Philipp Grohs",
      "Gitta Kutyniok",
      "Philipp Petersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04026"
  },
  {
    "id": "arXiv:2105.04027",
    "title": "Improving Multi-agent Coordination by Learning to Estimate Contention",
    "abstract": "We present a multi-agent learning algorithm, ALMA-Learning, for efficient and\nfair allocations in large-scale systems. We circumvent the traditional pitfalls\nof multi-agent learning (e.g., the moving target problem, the curse of\ndimensionality, or the need for mutually consistent actions) by relying on the\nALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning\nis decentralized, observes only own action/reward pairs, requires no\ninter-agent communication, and achieves near-optimal (<5% loss) and fair\ncoordination in a variety of synthetic scenarios and a real-world meeting\nscheduling problem. The lightweight nature and fast learning constitute\nALMA-Learning ideal for on-device deployment.",
    "descriptor": "\nComments: Accepted to the 30th International Joint Conference on Artificial Intelligence (IJCAI-21)\n",
    "authors": [
      "Panayiotis Danassis",
      "Florian Wiedemair",
      "Boi Faltings"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04027"
  },
  {
    "id": "arXiv:2105.04030",
    "title": "A Bit More Bayesian: Domain-Invariant Learning with Uncertainty",
    "abstract": "Domain generalization is challenging due to the domain shift and the\nuncertainty caused by the inaccessibility of target domain data. In this paper,\nwe address both challenges with a probabilistic framework based on variational\nBayesian inference, by incorporating uncertainty into neural network weights.\nWe couple domain invariance in a probabilistic formula with the variational\nBayesian inference. This enables us to explore domain-invariant learning in a\nprincipled way. Specifically, we derive domain-invariant representations and\nclassifiers, which are jointly established in a two-layer Bayesian neural\nnetwork. We empirically demonstrate the effectiveness of our proposal on four\nwidely used cross-domain visual recognition benchmarks. Ablation studies\nvalidate the synergistic benefits of our Bayesian treatment when jointly\nlearning domain-invariant representations and classifiers for domain\ngeneralization. Further, our method consistently delivers state-of-the-art mean\naccuracy on all benchmarks.",
    "descriptor": "\nComments: accepted to ICML 2021\n",
    "authors": [
      "Zehao Xiao",
      "Jiayi Shen",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04030"
  },
  {
    "id": "arXiv:2105.04034",
    "title": "NMPC trajectory planner for urban autonomous driving",
    "abstract": "This paper presents a trajectory planner for autonomous driving based on a\nNonlinear Model Predictive Control (NMPC) algorithm that accounts for Pacejka's\nnonlinear lateral tyre dynamics as well as for zero speed conditions through a\nnovel slip angles calculation. In the NMPC framework, road boundaries and\nobstacles (both static and moving) are taken into account thanks to soft and\nhard constraints implementation. The numerical solution of the NMPC problem is\ncarried out using ACADO toolkit coupled with the quadratic programming solver\nqpOASES. The effectiveness of the proposed NMPC trajectory planner has been\ntested using CarMaker multibody models. Time analysis results provided by the\nsimulations shown, state that the proposed algorithm can be implemented on the\nreal-time control framework of an autonomous vehicle under the assumption of\ndata coming from an upstream estimation block.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Francesco Micheli",
      "Mattia Bersani",
      "Stefano Arrigoni",
      "Francesco Braghin",
      "Federico Cheli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04034"
  },
  {
    "id": "arXiv:2105.04035",
    "title": "Knapsack and Subset Sum with Small Items",
    "abstract": "Knapsack and Subset Sum are fundamental NP-hard problems in combinatorial\noptimization. Recently there has been a growing interest in understanding the\nbest possible pseudopolynomial running times for these problems with respect to\nvarious parameters.\nIn this paper we focus on the maximum item size $s$ and the maximum item\nvalue $v$. We give algorithms that run in time $O(n + s^3)$ and $O(n + v^3)$\nfor the Knapsack problem, and in time $\\tilde{O}(n + s^{5/3})$ for the Subset\nSum problem.\nOur algorithms work for the more general problem variants with\nmultiplicities, where each input item comes with a (binary encoded)\nmultiplicity, which succinctly describes how many times the item appears in the\ninstance. In these variants $n$ denotes the (possibly much smaller) number of\ndistinct items.\nOur results follow from combining and optimizing several diverse lines of\nresearch, notably proximity arguments for integer programming due to Eisenbrand\nand Weismantel (TALG 2019), fast structured $(\\min,+)$-convolution by Kellerer\nand Pferschy (J. Comb. Optim. 2004), and additive combinatorics methods\noriginating from Galil and Margalit (SICOMP 1991).",
    "descriptor": "",
    "authors": [
      "Adam Polak",
      "Lars Rohwedder",
      "Karol W\u0119grzycki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.04035"
  },
  {
    "id": "arXiv:2105.04036",
    "title": "A Novel Map of Knowledge for Science",
    "abstract": "With the expansion of scientific research, the number of scientific research\nresults is increasing. How to summarize these data has become an urgent\nproblem. Therefore, knowledge mapping methods come into being, providing a lot\nof management and application functions. However, it is still a problem to\nfully understand the knowledge map, especially in the field of sociology. In\nthis paper, a three-dimensional knowledge map is proposed with time, space and\nnumber based on category and numericity, which concludes all the scientific\nproblems related to numericity interdisciplinary. Compared with the traditional\nway, this map is normative, and puts forward the general production criteria of\nlabeling and digitization. It is also intuitive and readable, on which nature,\nsociety and formal science are expressed in the same picture. Some social\nsubjects are expressed more vividly than traditional text-based expressions,\nand are compatible with the natural science system. Mathematics also show its\nimportance on the map as formal Science, indicating that it is the key to the\ndevelopment of science. This is not only a preliminary model of a comprehensive\nscientific worldview, but also a preliminary framework for the connection and\ncooperation of various disciplines in the future.",
    "descriptor": "",
    "authors": [
      "Fan Shen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "History and Philosophy of Physics (physics.hist-ph)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04036"
  },
  {
    "id": "arXiv:2105.04037",
    "title": "Graph Attention Networks with Positional Embeddings",
    "abstract": "Graph Neural Networks (GNNs) are deep learning methods which provide the\ncurrent state of the art performance in node classification tasks. GNNs often\nassume homophily -- neighboring nodes having similar features and labels--, and\ntherefore may not be at their full potential when dealing with non-homophilic\ngraphs. In this work, we focus on addressing this limitation and enable Graph\nAttention Networks (GAT), a commonly used variant of GNNs, to explore the\nstructural information within each graph locality. Inspired by the positional\nencoding in the Transformers, we propose a framework, termed Graph Attentional\nNetworks with Positional Embeddings (GAT-POS), to enhance GATs with positional\nembeddings which capture structural and positional information of the nodes in\nthe graph. In this framework, the positional embeddings are learned by a model\npredictive of the graph context, plugged into an enhanced GAT architecture,\nwhich is able to leverage both the positional and content information of each\nnode. The model is trained jointly to optimize for the task of node\nclassification as well as the task of predicting graph context. Experimental\nresults show that GAT-POS reaches remarkable improvement compared to strong GNN\nbaselines and recent structural embedding enhanced GNNs on non-homophilic\ngraphs.",
    "descriptor": "",
    "authors": [
      "Liheng Ma",
      "Reihaneh Rabbany",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04037"
  },
  {
    "id": "arXiv:2105.04040",
    "title": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "abstract": "Convolutional neural networks lack shift equivariance due to the presence of\ndownsampling layers. In image classification, adaptive polyphase downsampling\n(APS-D) was recently proposed to make CNNs perfectly shift invariant. However,\nin networks used for image reconstruction tasks, it can not by itself restore\nshift equivariance. We address this problem by proposing adaptive polyphase\nupsampling (APS-U), a non-linear extension of conventional upsampling, which\nallows CNNs to exhibit perfect shift equivariance. With MRI and CT\nreconstruction experiments, we show that networks containing APS-D/U layers\nexhibit state of the art equivariance performance without sacrificing on image\nreconstruction quality. In addition, unlike prior methods like data\naugmentation and anti-aliasing, the gains in equivariance obtained from APS-D/U\nalso extend to images outside the training distribution.",
    "descriptor": "",
    "authors": [
      "Anadi Chaman",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04040"
  },
  {
    "id": "arXiv:2105.04041",
    "title": "Lyapunov-Krasovskii functionals for some classes of nonlinear time delay  systems",
    "abstract": "In this contribution, we study an homogeneous class of nonlinear time delay\nsystems with time-varying perturbations. Using the Lyapunov-Krasovskii\napproach, we introduce a functional that leads to perturbation conditions\nmatching those obtained previously in the Razumikhin framework. The functionals\nare applied to the estimation of the domain of attraction and of the system\nsolutions. An illustrative example is given.",
    "descriptor": "\nComments: Submitted for presentation in 2021 Conference on Decision and Control (CDC)\n",
    "authors": [
      "Gerson Portilla",
      "Irina V. Alexandrova",
      "Sabine Mondi\u00e9"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.04041"
  },
  {
    "id": "arXiv:2105.04043",
    "title": "Fast stable finite difference schemes for nonlinear cross-diffusion",
    "abstract": "The dynamics of cross-diffusion models leads to a high computational\ncomplexity for implicit difference schemes, turning them unsuitable for tasks\nwhen time is of the essence. We propose the use of two operator splitting\nschemes for nonlinear cross-diffusion processes in order to lower the\ncomputational load, and establish their stability properties using discrete\n$L^2$ energy methods. Furthermore, by attaining a stable factorization of the\nsystem matrix as a forward-backward pass, corresponding to the Thomas algorithm\nfor self-diffusion processes, we show that the use of implicit cross-diffusion\ncan be competitive in terms of execution time, widening the range of viable\ncross-diffusion coefficients for on-the-fly applications.",
    "descriptor": "",
    "authors": [
      "Diogo Lobo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04043"
  },
  {
    "id": "arXiv:2105.04045",
    "title": "Swarm Differential Privacy for Purpose Driven  Data-Information-Knowledge-Wisdom Architecture",
    "abstract": "Privacy protection has recently attracted the attention of both academics and\nindustries. Society protects individual data privacy through complex legal\nframeworks. This has become a topic of interest with the increasing\napplications of data science and artificial intelligence that have created a\nhigher demand to the ubiquitous application of the data. The privacy protection\nof the broad Data-InformationKnowledge-Wisdom (DIKW) landscape, the next\ngeneration of information organization, has not been in the limelight. Next, we\nwill explore DIKW architecture through the applications of popular swarm\nintelligence and differential privacy. As differential privacy proved to be an\neffective data privacy approach, we will look at it from a DIKW domain\nperspective. Swarm Intelligence could effectively optimize and reduce the\nnumber of items in DIKW used in differential privacy, this way accelerating\nboth the effectiveness and the efficiency of differential privacy for crossing\nmultiple modals of conceptual DIKW. The proposed approach is proved through the\napplication of personalized data that is based on the open-sourse IRIS dataset.\nThis experiment demonstrates the efficiency of Swarm Intelligence in reducing\ncomputing complexity.",
    "descriptor": "",
    "authors": [
      "Yingbo Li",
      "Yucong Duan",
      "Zakaria Maama",
      "Haoyang Che",
      "Anamaria-Beatrice Spulber",
      "Stelios Fuentes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04045"
  },
  {
    "id": "arXiv:2105.04047",
    "title": "Analyzing Online Political Advertisements",
    "abstract": "Online political advertising is a central aspect of modern election\ncampaigning for influencing public opinion. Computational analysis of political\nads is of utmost importance in political science to understand characteristics\nof digital campaigning. It is also important in computational linguistics to\nstudy features of political discourse and communication on a large scale. In\nthis work, we present the first computational study on online political ads\nwith the aim to (1) infer the political ideology of an ad sponsor; and (2)\nidentify whether the sponsor is an official political party or a third-party\norganization. We develop two new large datasets for the two tasks consisting of\nads from the U.S.. Evaluation results show that our approach that combines\ntextual and visual information from pre-trained neural models outperforms a\nstate-of-the-art method for generic commercial ad classification. Finally, we\nprovide an in-depth analysis of the limitations of our best performing models\nand a linguistic analysis to study the characteristics of political ads\ndiscourse.",
    "descriptor": "\nComments: Accepted at ACL Findings 2021\n",
    "authors": [
      "Danae S\u00e1nchez Villegas",
      "Saeid Mokaram",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04047"
  },
  {
    "id": "arXiv:2105.04048",
    "title": "Complexity-Adaptive Maximum-Likelihood Decoding of Modified  $\\boldsymbol{G}_N$-Coset Codes",
    "abstract": "A complexity-adaptive tree search algorithm is proposed for\n$\\boldsymbol{G}_N$-coset codes that implements maximum-likelihood (ML) decoding\nby using a successive decoding schedule. The average complexity is close to\nthat of the successive cancellation (SC) decoding for practical error rates\nwhen applied to polar codes and short Reed-Muller (RM) codes, e.g., block\nlengths up to $N=128$. By modifying the algorithm to limit the worst-case\ncomplexity, one obtains a near-ML decoder for longer RM codes and their\nsubcodes. Unlike other bit-flip decoders, no outer code is needed to terminate\ndecoding. The algorithm can thus be applied to modified\n$\\boldsymbol{G}_N$-coset code constructions with dynamic frozen bits. One\nadvantage over sequential decoders is that there is no need to optimize a\nseparate parameter.",
    "descriptor": "\nComments: Submitted to an IEEE conference\n",
    "authors": [
      "Peihong Yuan",
      "Mustafa Cemil Co\u015fkun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04048"
  },
  {
    "id": "arXiv:2105.04051",
    "title": "Aggregating From Multiple Target-Shifted Sources",
    "abstract": "Multi-source domain adaptation aims at leveraging the knowledge from multiple\ntasks for predicting a related target domain. Hence, a crucial aspect is to\nproperly combine different sources based on their relations. In this paper, we\nanalyzed the problem for aggregating source domains with different label\ndistributions, where most recent source selection approaches fail. Our proposed\nalgorithm differs from previous approaches in two key ways: the model\naggregates multiple sources mainly through the similarity of semantic\nconditional distribution rather than marginal distribution; the model proposes\na \\emph{unified} framework to select relevant sources for three popular\nscenarios, i.e., domain adaptation with limited label on target domain,\nunsupervised domain adaptation and label partial unsupervised domain adaption.\nWe evaluate the proposed method through extensive experiments. The empirical\nresults significantly outperform the baselines.",
    "descriptor": "",
    "authors": [
      "Changjian Shui",
      "Zijian Li",
      "Jiaqi Li",
      "Christian Gagn\u00e9",
      "Charles Ling",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04051"
  },
  {
    "id": "arXiv:2105.04054",
    "title": "Societal Biases in Language Generation: Progress and Challenges",
    "abstract": "Technology for language generation has advanced rapidly, spurred by\nadvancements in pre-training large models on massive amounts of data and the\nneed for intelligent agents to communicate in a natural manner. While\ntechniques can effectively generate fluent text, they can also produce\nundesirable societal biases that can have a disproportionately negative impact\non marginalized populations. Language generation presents unique challenges in\nterms of direct user interaction and the structure of decoding techniques. To\nbetter understand these challenges, we present a survey on societal biases in\nlanguage generation, focusing on how techniques contribute to biases and on\nprogress towards bias analysis and mitigation. Motivated by a lack of studies\non biases from decoding techniques, we also conduct experiments to quantify the\neffects of these techniques. By further discussing general trends and open\nchallenges, we call to attention promising directions for research and the\nimportance of fairness and inclusivity considerations for language generation\napplications.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Emily Sheng",
      "Kai-Wei Chang",
      "Premkumar Natarajan",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04054"
  },
  {
    "id": "arXiv:2105.04055",
    "title": "Scalar auxiliary variable approach for conservative/dissipative partial  differential equations with unbounded energy",
    "abstract": "In this paper, we present a novel investigation of the so-called SAV\napproach, which is a framework to construct linearly implicit geometric\nnumerical integrators for partial differential equations with variational\nstructure. SAV approach was originally proposed for the gradient flows that\nhave lower-bounded nonlinear potentials such as the Allen-Cahn and\nCahn-Hilliard equations, and this assumption on the energy was essential. In\nthis paper, we propose a novel approach to address gradient flows with\nunbounded energy such as the KdV equation by a decomposition of energy\nfunctionals. Further, we will show that the equation of the SAV approach, which\nis a system of equations with scalar auxiliary variables, is expressed as\nanother gradient system that inherits the variational structure of the original\nsystem. This expression allows us to construct novel higher-order integrators\nby a certain class of Runge-Kutta methods. We will propose second and fourth\norder schemes for conservative systems in our framework and present several\nnumerical examples.",
    "descriptor": "",
    "authors": [
      "Tomoya Kemmochi",
      "Shun Sato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04055"
  },
  {
    "id": "arXiv:2105.04057",
    "title": "Fast Automated Reasoning over String Diagrams using Multiway Causal  Structure",
    "abstract": "We introduce an intuitive algorithmic methodology for enacting automated\nrewriting of string diagrams within a general double-pushout (DPO) framework,\nin which the sequence of rewrites is chosen in accordance with the causal\nstructure of the underlying diagrammatic calculus. The combination of the\nrewriting structure and the causal structure may be elegantly formulated as a\nweak 2-category equipped with both total and partial monoidal bifunctors, thus\nproviding a categorical semantics for the full multiway evolution causal graph\nof a generic Wolfram model hypergraph rewriting system. As an illustrative\nexample, we show how a special case of this algorithm enables highly efficient\nautomated simplification of quantum circuits, as represented in the\nZX-calculus.",
    "descriptor": "\nComments: Submitted to Applied Category Theory 2021. 14 pages, 9 figures\n",
    "authors": [
      "Jonathan Gorard",
      "Manojna Namuduri",
      "Xerxes D. Arsiwalla"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.04057"
  },
  {
    "id": "arXiv:2105.04062",
    "title": "Approximate Fr\u00e9chet Mean for Data Sets of Sparse Graphs",
    "abstract": "To characterize the location (mean, median) of a set of graphs, one needs a\nnotion of centrality that is adapted to metric spaces, since graph sets are not\nEuclidean spaces. A standard approach is to consider the Fr\\'echet mean. In\nthis work, we equip a set of graph with the pseudometric defined by the\n$\\ell_2$ norm between the eigenvalues of their respective adjacency matrix .\nUnlike the edit distance, this pseudometric reveals structural changes at\nmultiple scales, and is well adapted to studying various statistical problems\non sets of graphs. We describe an algorithm to compute an approximation to the\nFr\\'echet mean of a set of undirected unweighted graphs with a fixed size.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Daniel Ferguson",
      "Fran\u00e7ois G. Meyer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04062"
  },
  {
    "id": "arXiv:2105.04064",
    "title": "Leveraging Structural Information to Improve Point Line Visual-Inertial  Odometry",
    "abstract": "Leveraging line features can help to improve the localization accuracy of\npoint-based monocular Visual-Inertial Odometry (VIO) system, as lines provide\nadditional constraints. Moreover, in an artificial environment, some straight\nlines are parallel to each other. In this paper, we designed a VIO system based\non points and straight lines, which divides straight lines into structural\nstraight lines (that is, straight lines parallel to each other) and\nnon-structural straight lines. In addition, unlike the orthogonal\nrepresentation using four parameters to represent the 3D straight line, we only\nused two parameters to minimize the representation of the structural straight\nline and the non-structural straight line. Furthermore, we designed a straight\nline matching strategy based on sampling points to improve the efficiency and\nsuccess rate of straight line matching. The effectiveness of our method is\nverified on both public datasets of EuRoc and TUM VI benchmark and compared\nwith other state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Bo Xu",
      "Peng Wang",
      "Yijia He",
      "Yu Chen",
      "Yongnan Chen",
      "Ming Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04064"
  },
  {
    "id": "arXiv:2105.04065",
    "title": "Voice activity detection in the wild: A data-driven approach using  teacher-student training",
    "abstract": "Voice activity detection is an essential pre-processing component for\nspeech-related tasks such as automatic speech recognition (ASR). Traditional\nsupervised VAD systems obtain frame-level labels from an ASR pipeline by using,\ne.g., a Hidden Markov model. These ASR models are commonly trained on clean and\nfully transcribed data, limiting VAD systems to be trained on clean or\nsynthetically noised datasets. Therefore, a major challenge for supervised VAD\nsystems is their generalization towards noisy, real-world data. This work\nproposes a data-driven teacher-student approach for VAD, which utilizes vast\nand unconstrained audio data for training. Unlike previous approaches, only\nweak labels during teacher training are required, enabling the utilization of\nany real-world, potentially noisy dataset. Our approach firstly trains a\nteacher model on a source dataset (Audioset) using clip-level supervision.\nAfter training, the teacher provides frame-level guidance to a student model on\nan unlabeled, target dataset. A multitude of student models trained on mid- to\nlarge-sized datasets are investigated (Audioset, Voxceleb, NIST SRE). Our\napproach is then respectively evaluated on clean, artificially noised, and\nreal-world data. We observe significant performance gains in artificially\nnoised and real-world scenarios. Lastly, we compare our approach against other\nunsupervised and supervised VAD methods, demonstrating our method's\nsuperiority.",
    "descriptor": "",
    "authors": [
      "Heinrich Dinkel",
      "Shuai Wang",
      "Xuenan Xu",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04065"
  },
  {
    "id": "arXiv:2105.04066",
    "title": "Reconstructive Sequence-Graph Network for Video Summarization",
    "abstract": "Exploiting the inner-shot and inter-shot dependencies is essential for\nkey-shot based video summarization. Current approaches mainly devote to\nmodeling the video as a frame sequence by recurrent neural networks. However,\none potential limitation of the sequence models is that they focus on capturing\nlocal neighborhood dependencies while the high-order dependencies in long\ndistance are not fully exploited. In general, the frames in each shot record a\ncertain activity and vary smoothly over time, but the multi-hop relationships\noccur frequently among shots. In this case, both the local and global\ndependencies are important for understanding the video content. Motivated by\nthis point, we propose a Reconstructive Sequence-Graph Network (RSGN) to encode\nthe frames and shots as sequence and graph hierarchically, where the\nframe-level dependencies are encoded by Long Short-Term Memory (LSTM), and the\nshot-level dependencies are captured by the Graph Convolutional Network (GCN).\nThen, the videos are summarized by exploiting both the local and global\ndependencies among shots. Besides, a reconstructor is developed to reward the\nsummary generator, so that the generator can be optimized in an unsupervised\nmanner, which can avert the lack of annotated data in video summarization.\nFurthermore, under the guidance of reconstruction loss, the predicted summary\ncan better preserve the main video content and shot-level dependencies.\nPractically, the experimental results on three popular datasets i.e., SumMe,\nTVsum and VTW) have demonstrated the superiority of our proposed approach to\nthe summarization task.",
    "descriptor": "\nComments: Accepted by IEEE TPAMI 2021\n",
    "authors": [
      "Bin Zhao",
      "Haopeng Li",
      "Xiaoqiang Lu",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04066"
  },
  {
    "id": "arXiv:2105.04067",
    "title": "Neural Graph Matching based Collaborative Filtering",
    "abstract": "User and item attributes are essential side-information; their interactions\n(i.e., their co-occurrence in the sample data) can significantly enhance\nprediction accuracy in various recommender systems. We identify two different\ntypes of attribute interactions, inner interactions and cross interactions:\ninner interactions are those between only user attributes or those between only\nitem attributes; cross interactions are those between user attributes and item\nattributes. Existing models do not distinguish these two types of attribute\ninteractions, which may not be the most effective way to exploit the\ninformation carried by the interactions. To address this drawback, we propose a\nneural Graph Matching based Collaborative Filtering model (GMCF), which\neffectively captures the two types of attribute interactions through modeling\nand aggregating attribute interactions in a graph matching structure for\nrecommendation. In our model, the two essential recommendation procedures,\ncharacteristic learning and preference matching, are explicitly conducted\nthrough graph learning (based on inner interactions) and node matching (based\non cross interactions), respectively. Experimental results show that our model\noutperforms state-of-the-art models. Further studies verify the effectiveness\nof GMCF in improving the accuracy of recommendation.",
    "descriptor": "\nComments: 10 pages, 6 figures, 4 tables, SIGIR 2021\n",
    "authors": [
      "Yixin Su",
      "Rui Zhang",
      "Sarah Erfani",
      "Junhao Gan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04067"
  },
  {
    "id": "arXiv:2105.04070",
    "title": "Robust Training Using Natural Transformation",
    "abstract": "Previous robustness approaches for deep learning models such as data\naugmentation techniques via data transformation or adversarial training cannot\ncapture real-world variations that preserve the semantics of the input, such as\na change in lighting conditions. To bridge this gap, we present NaTra, an\nadversarial training scheme that is designed to improve the robustness of image\nclassification algorithms. We target attributes of the input images that are\nindependent of the class identification, and manipulate those attributes to\nmimic real-world natural transformations (NaTra) of the inputs, which are then\nused to augment the training dataset of the image classifier. Specifically, we\napply \\textit{Batch Inverse Encoding and Shifting} to map a batch of given\nimages to corresponding disentangled latent codes of well-trained generative\nmodels. \\textit{Latent Codes Expansion} is used to boost image reconstruction\nquality through the incorporation of extended feature maps.\n\\textit{Unsupervised Attribute Directing and Manipulation} enables\nidentification of the latent directions that correspond to specific attribute\nchanges, and then produce interpretable manipulations of those attributes,\nthereby generating natural transformations to the input data. We demonstrate\nthe efficacy of our scheme by utilizing the disentangled latent representations\nderived from well-trained GANs to mimic transformations of an image that are\nsimilar to real-world natural variations (such as lighting conditions or\nhairstyle), and train models to be invariant to these natural transformations.\nExtensive experiments show that our method improves generalization of\nclassification models and increases its robustness to various real-world\ndistortions",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1912.03192, arXiv:2004.02546 by other authors\n",
    "authors": [
      "Shuo Wang",
      "Lingjuan Lyu",
      "Surya Nepal",
      "Carsten Rudolph",
      "Marthie Grobler",
      "Kristen Moore"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04070"
  },
  {
    "id": "arXiv:2105.04072",
    "title": "Meteorological and human mobility data on predicting COVID-19 cases by a  novel hybrid decomposition method with anomaly detection analysis: a case  study in the capitals of Brazil",
    "abstract": "In 2020, Brazil was the leading country in COVID-19 cases in Latin America,\nand capital cities were the most severely affected by the outbreak. Climates\nvary in Brazil due to the territorial extension of the country, its relief,\ngeography, and other factors. Since the most common COVID-19 symptoms are\nrelated to the respiratory system, many researchers have studied the\ncorrelation between the number of COVID-19 cases with meteorological variables\nlike temperature, humidity, rainfall, etc. Also, due to its high transmission\nrate, some researchers have analyzed the impact of human mobility on the\ndynamics of COVID-19 transmission. There is a dearth of literature that\nconsiders these two variables when predicting the spread of COVID-19 cases. In\nthis paper, we analyzed the correlation between the number of COVID-19 cases\nand human mobility, and meteorological data in Brazilian capitals. We found\nthat the correlation between such variables depends on the regions where the\ncities are located. We employed the variables with a significant correlation\nwith COVID-19 cases to predict the number of COVID-19 infections in all\nBrazilian capitals and proposed a prediction method combining the Ensemble\nEmpirical Mode Decomposition (EEMD) method with the Autoregressive Integrated\nMoving Average Exogenous inputs (ARIMAX) method, which we called EEMD-ARIMAX.\nAfter analyzing the results poor predictions were further investigated using a\nsignal processing-based anomaly detection method. Computational tests showed\nthat EEMD-ARIMAX achieved a forecast 26.73% better than ARIMAX. Moreover, an\nimprovement of 30.69% in the average root mean squared error (RMSE) was noticed\nwhen applying the EEMD-ARIMAX method to the data normalized after the anomaly\ndetection.",
    "descriptor": "",
    "authors": [
      "Tiago Tiburcio da Silva",
      "Rodrigo Francisquini",
      "Mari\u00e1 C. V. Nascimento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.04072"
  },
  {
    "id": "arXiv:2105.04075",
    "title": "CFPNet-M: A Light-Weight Encoder-Decoder Based Network for Multimodal  Biomedical Image Real-Time Segmentation",
    "abstract": "Currently, developments of deep learning techniques are providing\ninstrumental to identify, classify, and quantify patterns in medical images.\nSegmentation is one of the important applications in medical image analysis. In\nthis regard, U-Net is the predominant approach to medical image segmentation\ntasks. However, we found that those U-Net based models have limitations in\nseveral aspects, for example, millions of parameters in the U-Net consuming\nconsiderable computation resource and memory, lack of global information, and\nmissing some tough objects. Therefore, we applied two modifications to improve\nthe U-Net model: 1) designed and added the dilated channel-wise CNN module, 2)\nsimplified the U shape network. Based on these two modifications, we proposed a\nnovel light-weight architecture -- Channel-wise Feature Pyramid Network for\nMedicine (CFPNet-M). To evaluate our method, we selected five datasets with\ndifferent modalities: thermography, electron microscopy, endoscopy, dermoscopy,\nand digital retinal images. And we compared its performance with several models\nhaving different parameter scales. This paper also involves our previous\nstudies of DC-UNet and some commonly used light-weight neural networks. We\napplied the Tanimoto similarity instead of the Jaccard index for gray-level\nimage measurements. By comparison, CFPNet-M achieves comparable segmentation\nresults on all five medical datasets with only 0.65 million parameters, which\nis about 2% of U-Net, and 8.8 MB memory. Meanwhile, the inference speed can\nreach 80 FPS on a single RTX 2070Ti GPU with the 256 by 192 pixels input size.",
    "descriptor": "",
    "authors": [
      "Ange Lou",
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.04075"
  },
  {
    "id": "arXiv:2105.04078",
    "title": "Self-supervised spectral matching network for hyperspectral target  detection",
    "abstract": "Hyperspectral target detection is a pixel-level recognition problem. Given a\nfew target samples, it aims to identify the specific target pixels such as\nairplane, vehicle, ship, from the entire hyperspectral image. In general, the\nbackground pixels take the majority of the image and complexly distributed. As\na result, the datasets are weak annotated and extremely imbalanced. To address\nthese problems, a spectral mixing based self-supervised paradigm is designed\nfor hyperspectral data to obtain an effective feature representation. The model\nadopts a spectral similarity based matching network framework. In order to\nlearn more discriminative features, a pair-based loss is adopted to minimize\nthe distance between target pixels while maximizing the distances between\ntarget and background. Furthermore, through a background separated step, the\ncomplex unlabeled spectra are downsampled into different sub-categories. The\nexperimental results on three real hyperspectral datasets demonstrate that the\nproposed framework achieves better results compared with the existing\ndetectors.",
    "descriptor": "\nComments: IGARSS 2021\n",
    "authors": [
      "Can Yao",
      "Yuan Yuan",
      "Zhiyu Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04078"
  },
  {
    "id": "arXiv:2105.04079",
    "title": "Sampling-Frequency-Independent Audio Source Separation Using Convolution  Layer Based on Impulse Invariant Method",
    "abstract": "Audio source separation is often used as preprocessing of various\napplications, and one of its ultimate goals is to construct a single versatile\nmodel capable of dealing with the varieties of audio signals. Since sampling\nfrequency, one of the audio signal varieties, is usually application specific,\nthe preceding audio source separation model should be able to deal with audio\nsignals of all sampling frequencies specified in the target applications.\nHowever, conventional models based on deep neural networks (DNNs) are trained\nonly at the sampling frequency specified by the training data, and there are no\nguarantees that they work with unseen sampling frequencies. In this paper, we\npropose a convolution layer capable of handling arbitrary sampling frequencies\nby a single DNN. Through music source separation experiments, we show that the\nintroduction of the proposed layer enables a conventional audio source\nseparation model to consistently work with even unseen sampling frequencies.",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted for European Signal Processing Conference 2021 (EUSIPCO 2021)\n",
    "authors": [
      "Koichi Saito",
      "Tomohiko Nakamura",
      "Kohei Yatabe",
      "Yuma Koizumi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04079"
  },
  {
    "id": "arXiv:2105.04080",
    "title": "Exponentially convergent multiscale methods for high frequency  heterogeneous Helmholtz equations",
    "abstract": "In this paper, we present a multiscale framework for solving the Helmholtz\nequation in heterogeneous media without scale separation and in the high\nfrequency regime where the wavenumber $k$ can be large. The main innovation is\nthat our methods achieve a nearly exponential rate of convergence with respect\nto the computational degrees of freedom, using a coarse grid of mesh size\n$O(1/k)$ without suffering from the well-known pollution effect. The key idea\nis a coarse-fine scale decomposition of the solution space that adapts to the\nmedia property and wavenumber; this decomposition is inspired by the multiscale\nfinite element method. We show that the coarse part is of low complexity in the\nsense that it can be approximated with a nearly exponential rate of convergence\nvia local basis functions, while the fine part is local such that it can be\ncomputed efficiently using the local information of the right hand side. The\ncombination of the two parts yields the overall nearly exponential rate of\nconvergence. We demonstrate the effectiveness of our methods theoretically and\nnumerically; an exponential rate of convergence is consistently observed and\nconfirmed. In addition, we observe the robustness of our methods regarding the\nhigh contrast in the media numerically.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Y. Chen",
      "T.Y. Hou",
      "Y. Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04080"
  },
  {
    "id": "arXiv:2105.04084",
    "title": "A Coupled Random Projection Approach to Large-Scale Canonical Polyadic  Decomposition",
    "abstract": "We propose a novel algorithm for the computation of canonical polyadic\ndecomposition (CPD) of large-scale tensors. The proposed algorithm generalizes\nthe random projection (RAP) technique, which is often used to compute\nlarge-scale decompositions, from one single projection to multiple but coupled\nrandom projections (CoRAP). The proposed CoRAP technique yields a set of\ntensors that together admits a coupled CPD (C-CPD) and a C-CPD algorithm is\nthen used to jointly decompose these tensors. The results of C-CPD are finally\nfused to obtain factor matrices of the original large-scale data tensor. As\nmore data samples are jointly exploited via C-CPD, the proposed CoRAP based CPD\nis more accurate than RAP based CPD. Experiments are provided to illustrate the\nperformance of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Lu-Ming Wang",
      "Ya-Nan Wang",
      "Xiao-Feng Gong",
      "Qiu-Hua Lin",
      "Fei Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04084"
  },
  {
    "id": "arXiv:2105.04086",
    "title": "Deep Reinforcement Learning-based Methods for Resource Scheduling in  Cloud Computing: A Review and Future Directions",
    "abstract": "As the quantity and complexity of information processed by software systems\nincrease, large-scale software systems have an increasing requirement for\nhigh-performance distributed computing systems. With the acceleration of the\nInternet in Web 2.0, Cloud computing as a paradigm to provide dynamic,\nuncertain and elastic services has shown superiorities to meet the computing\nneeds dynamically. Without an appropriate scheduling approach, extensive Cloud\ncomputing may cause high energy consumptions and high cost, in addition that\nhigh energy consumption will cause massive carbon dioxide emissions. Moreover,\ninappropriate scheduling will reduce the service life of physical devices as\nwell as increase response time to users' request. Hence, efficient scheduling\nof resource or optimal allocation of request, that usually a NP-hard problem,\nis one of the prominent issues in emerging trends of Cloud computing. Focusing\non improving quality of service (QoS), reducing cost and abating contamination,\nresearchers have conducted extensive work on resource scheduling problems of\nCloud computing over years. Nevertheless, growing complexity of Cloud\ncomputing, that the super-massive distributed system, is limiting the\napplication of scheduling approaches. Machine learning, a utility method to\ntackle problems in complex scenes, is used to resolve the resource scheduling\nof Cloud computing as an innovative idea in recent years. Deep reinforcement\nlearning (DRL), a combination of deep learning (DL) and reinforcement learning\n(RL), is one branch of the machine learning and has a considerable prospect in\nresource scheduling of Cloud computing. This paper surveys the methods of\nresource scheduling with focus on DRL-based scheduling approaches in Cloud\ncomputing, also reviews the application of DRL as well as discusses challenges\nand future directions of DRL in scheduling of Cloud computing.",
    "descriptor": "\nComments: 18 pages,9 figures\n",
    "authors": [
      "Guangyao Zhou",
      "Wenhong Tian",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.04086"
  },
  {
    "id": "arXiv:2105.04088",
    "title": "PEARL: Parallelized Expert-Assisted Reinforcement Learning for Scene  Rearrangement Planning",
    "abstract": "Scene Rearrangement Planning (SRP) is an interior task proposed recently. The\nprevious work defines the action space of this task with handcrafted\ncoarse-grained actions that are inflexible to be used for transforming scene\narrangement and intractable to be deployed in practice. Additionally, this new\ntask lacks realistic indoor scene rearrangement data to feed popular\ndata-hungry learning approaches and meet the needs of quantitative evaluation.\nTo address these problems, we propose a fine-grained action definition for SRP\nand introduce a large-scale scene rearrangement dataset. We also propose a\nnovel learning paradigm to efficiently train an agent through self-playing,\nwithout any prior knowledge. The agent trained via our paradigm achieves\nsuperior performance on the introduced dataset compared to the baseline agents.\nWe provide a detailed analysis of the design of our approach in our\nexperiments.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Hanqing Wang",
      "Zan Wang",
      "Wei Liang",
      "Lap-Fai Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04088"
  },
  {
    "id": "arXiv:2105.04089",
    "title": "Effective Methods of QR-Decompositions of Square Complex Matrices by  Fast Discrete Signal-Induced Heap Transforms",
    "abstract": "The purpose of this work is to present an effective tool for computing\ndifferent QR-decompositions of a complex nonsingular square matrix. The concept\nof the discrete signal-induced heap transform (DsiHT, Grigoryan 2006) is used.\nThis transform is fast, has a unique algorithm for any length of the input\nvector/signal and can be used with different complex basic 2x2 transforms. The\nDsiHT zeroes all components of the input signal while moving or heaping the\nenergy of the signal into one component, such as the first. We describe three\ndifferent types of QR-decompositions that use the basic transforms with the T,\nG, and M-type complex matrices we introduce, and also without matrices, but\nusing analytical formulas. We also present the mixed QR-decomposition, when\ndifferent type DsiHTs are used at different stages of the algorithm. The number\nof such decompositions is greater than 3^((N-1)), for an NxN complex matrix.\nExamples of the QR-decomposition are described in detail for the 4x4 and 6x6\ncomplex matrices and compared with the known method of Householder transforms.\nThe precision of the QR-decompositions of NxN matrices, when N are 6, 13, 17,\n19, 21, 40, 64, 100, 128, 201, 256, and 400 is also compared. The MATLAB-based\nscripts of the codes for QR-decompositions by the described DsiHTs are given.",
    "descriptor": "\nComments: 19 pages, 4 figures, 1 table\n",
    "authors": [
      "Artyom M. Grigoryan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04089"
  },
  {
    "id": "arXiv:2105.04090",
    "title": "MuseMorphose: Full-Song and Fine-Grained Music Style Transfer with Just  One Transformer VAE",
    "abstract": "Transformers and variational autoencoders (VAE) have been extensively\nemployed for symbolic (e.g., MIDI) domain music generation. While the former\nboast an impressive capability in modeling long sequences, the latter allow\nusers to willingly exert control over different parts (e.g., bars) of the music\nto be generated. In this paper, we are interested in bringing the two together\nto construct a single model that exhibits both strengths. The task is split\ninto two steps. First, we equip Transformer decoders with the ability to accept\nsegment-level, time-varying conditions during sequence generation.\nSubsequently, we combine the developed and tested in-attention decoder with a\nTransformer encoder, and train the resulting MuseMorphose model with the VAE\nobjective to achieve style transfer of long musical pieces, in which users can\nspecify musical attributes including rhythmic intensity and polyphony (i.e.,\nharmonic fullness) they desire, down to the bar level. Experiments show that\nMuseMorphose outperforms recurrent neural network (RNN) based prior art on\nnumerous widely-used metrics for style transfer tasks.",
    "descriptor": "\nComments: Preprint. 26 pages, 7 figures, and 8 tables\n",
    "authors": [
      "Shih-Lun Wu",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04090"
  },
  {
    "id": "arXiv:2105.04091",
    "title": "Diversity Analysis of Millimeter-Wave OFDM Massive MIMO Systems",
    "abstract": "We analyze the diversity gain for a distributed antenna subarray employing\northogonal frequency-division multiplexing (OFDM) in millimeter-wave (mm-Wave)\nmassive multiple-input multiple-output (MIMO) systems. We show that the\ndiversity gain depends on the number of transmitted data streams, the number of\nremote antenna units, and the number of propagation paths between RAUs.\nFurthermore, we show that by using bit-interleaved coded multiple beamforming\n(BICMB), one can achieve the maximum diversity gain in a distributed antenna\nsubarray system. The assumption in both scenarios is that the number of the\nantennas at the transmitter and the receiver are large enough and channel state\ninformation (CSI) is known at the transmitter and the receiver.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Sadjad Sedighi",
      "Ender Ayanoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04091"
  },
  {
    "id": "arXiv:2105.04093",
    "title": "Elastic Weight Consolidation (EWC): Nuts and Bolts",
    "abstract": "In this report, we present a theoretical support of the continual learning\nmethod \\textbf{Elastic Weight Consolidation}, introduced in paper titled\n`Overcoming catastrophic forgetting in neural networks'. Being one of the most\ncited paper in regularized methods for continual learning, this report\ndisentangles the underlying concept of the proposed objective function. We\nassume that the reader is aware of the basic terminologies of continual\nlearning.",
    "descriptor": "",
    "authors": [
      "Abhishek Aich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04093"
  },
  {
    "id": "arXiv:2105.04097",
    "title": "Examining convolutional feature extraction using Maximum Entropy (ME)  and Signal-to-Noise Ratio (SNR) for image classification",
    "abstract": "Convolutional Neural Networks (CNNs) specialize in feature extraction rather\nthan function mapping. In doing so they form complex internal hierarchical\nfeature representations, the complexity of which gradually increases with a\ncorresponding increment in neural network depth. In this paper, we examine the\nfeature extraction capabilities of CNNs using Maximum Entropy (ME) and\nSignal-to-Noise Ratio (SNR) to validate the idea that, CNN models should be\ntailored for a given task and complexity of the input data. SNR and ME measures\nare used as they can accurately determine in the input dataset, the relative\namount of signal information to the random noise and the maximum amount of\ninformation respectively. We use two well known benchmarking datasets, MNIST\nand CIFAR-10 to examine the information extraction and abstraction capabilities\nof CNNs. Through our experiments, we examine convolutional feature extraction\nand abstraction capabilities in CNNs and show that the classification accuracy\nor performance of CNNs is greatly dependent on the amount, complexity and\nquality of the signal information present in the input data. Furthermore, we\nshow the effect of information overflow and underflow on CNN classification\naccuracies. Our hypothesis is that the feature extraction and abstraction\ncapabilities of convolutional layers are limited and therefore, CNN models\nshould be tailored to the input data by using appropriately sized CNNs based on\nthe SNR and ME measures of the input dataset.",
    "descriptor": "\nComments: Conference paper, 6 pages, 1 table\n",
    "authors": [
      "Nidhi Gowdra",
      "Roopak Sinha",
      "Stephen MacDonell"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04097"
  },
  {
    "id": "arXiv:2105.04098",
    "title": "SRLF: A Stance-aware Reinforcement Learning Framework for Content-based  Rumor Detection on Social Media",
    "abstract": "The rapid development of social media changes the lifestyle of people and\nsimultaneously provides an ideal place for publishing and disseminating rumors,\nwhich severely exacerbates social panic and triggers a crisis of social trust.\nEarly content-based methods focused on finding clues from the text and user\nprofiles for rumor detection. Recent studies combine the stances of users'\ncomments with news content to capture the difference between true and false\nrumors. Although the user's stance is effective for rumor detection, the manual\nlabeling process is time-consuming and labor-intensive, which limits the\napplication of utilizing it to facilitate rumor detection.\nIn this paper, we first finetune a pre-trained BERT model on a small labeled\ndataset and leverage this model to annotate weak stance labels for users'\ncomment data to overcome the problem mentioned above. Then, we propose a novel\nStance-aware Reinforcement Learning Framework (SRLF) to select high-quality\nlabeled stance data for model training and rumor detection. Both the stance\nselection and rumor detection tasks are optimized simultaneously to promote\nboth tasks mutually. We conduct experiments on two commonly used real-world\ndatasets. The experimental results demonstrate that our framework outperforms\nthe state-of-the-art models significantly, which confirms the effectiveness of\nthe proposed framework.",
    "descriptor": "",
    "authors": [
      "Chunyuan Yuan",
      "Wanhui Qian",
      "Qianwen Ma",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04098"
  },
  {
    "id": "arXiv:2105.04100",
    "title": "Z-GCNETs: Time Zigzags at Graph Convolutional Networks for Time Series  Forecasting",
    "abstract": "There recently has been a surge of interest in developing a new class of deep\nlearning (DL) architectures that integrate an explicit time dimension as a\nfundamental building block of learning and representation mechanisms. In turn,\nmany recent results show that topological descriptors of the observed data,\nencoding information on the shape of the dataset in a topological space at\ndifferent scales, that is, persistent homology of the data, may contain\nimportant complementary information, improving both performance and robustness\nof DL. As convergence of these two emerging ideas, we propose to enhance DL\narchitectures with the most salient time-conditioned topological information of\nthe data and introduce the concept of zigzag persistence into time-aware graph\nconvolutional networks (GCNs). Zigzag persistence provides a systematic and\nmathematically rigorous framework to track the most important topological\nfeatures of the observed data that tend to manifest themselves over time. To\nintegrate the extracted time-conditioned topological descriptors into DL, we\ndevelop a new topological summary, zigzag persistence image, and derive its\ntheoretical stability guarantees. We validate the new GCNs with a time-aware\nzigzag topological layer (Z-GCNETs), in application to traffic forecasting and\nEthereum blockchain price prediction. Our results indicate that Z-GCNET\noutperforms 13 state-of-the-art methods on 4 time series datasets.",
    "descriptor": "\nComments: Accepted at the International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Yuzhou Chen",
      "Ignacio Segovia-Dominguez",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04100"
  },
  {
    "id": "arXiv:2105.04102",
    "title": "Deep feature selection-and-fusion for RGB-D semantic segmentation",
    "abstract": "Scene depth information can help visual information for more accurate\nsemantic segmentation. However, how to effectively integrate multi-modality\ninformation into representative features is still an open problem. Most of the\nexisting work uses DCNNs to implicitly fuse multi-modality information. But as\nthe network deepens, some critical distinguishing features may be lost, which\nreduces the segmentation performance. This work proposes a unified and\nefficient feature selectionand-fusion network (FSFNet), which contains a\nsymmetric cross-modality residual fusion module used for explicit fusion of\nmulti-modality information. Besides, the network includes a detailed feature\npropagation module, which is used to maintain low-level detailed information\nduring the forward process of the network. Compared with the state-of-the-art\nmethods, experimental evaluations demonstrate that the proposed model achieves\ncompetitive performance on two public datasets.",
    "descriptor": "\nComments: ICME 2021\n",
    "authors": [
      "Yuejiao Su",
      "Yuan Yuan",
      "Zhiyu Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04102"
  },
  {
    "id": "arXiv:2105.04103",
    "title": "BIM Hyperreality: Data Synthesis Using BIM and Hyperrealistic Rendering  for Deep Learning",
    "abstract": "Deep learning is expected to offer new opportunities and a new paradigm for\nthe field of architecture. One such opportunity is teaching neural networks to\nvisually understand architectural elements from the built environment. However,\nthe availability of large training datasets is one of the biggest limitations\nof neural networks. Also, the vast majority of training data for visual\nrecognition tasks is annotated by humans. In order to resolve this bottleneck,\nwe present a concept of a hybrid system using both building information\nmodeling (BIM) and hyperrealistic (photorealistic) rendering to synthesize\ndatasets for training a neural network for building object recognition in\nphotos. For generating our training dataset BIMrAI, we used an existing BIM\nmodel and a corresponding photo-realistically rendered model of the same\nbuilding. We created methods for using renderings to train a deep learning\nmodel, trained a generative adversarial network (GAN) model using these\nmethods, and tested the output model on real-world photos. For the specific\ncase study presented in this paper, our results show that a neural network\ntrained with synthetic data; i.e., photorealistic renderings and BIM-based\nsemantic labels, can be used to identify building objects from photos without\nusing photos in the training data. Future work can enhance the presented\nmethods using available BIM models and renderings for more generalized mapping\nand description of photographed built environments.",
    "descriptor": "\nComments: Accepted to the 40th Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA 2020)\n",
    "authors": [
      "Mohammad Alawadhi",
      "Wei Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04103"
  },
  {
    "id": "arXiv:2105.04104",
    "title": "AppealNet: An Efficient and Highly-Accurate Edge/Cloud Collaborative  Architecture for DNN Inference",
    "abstract": "This paper presents AppealNet, a novel edge/cloud collaborative architecture\nthat runs deep learning (DL) tasks more efficiently than state-of-the-art\nsolutions. For a given input, AppealNet accurately predicts on-the-fly whether\nit can be successfully processed by the DL model deployed on the\nresource-constrained edge device, and if not, appeals to the more powerful DL\nmodel deployed at the cloud. This is achieved by employing a two-head neural\nnetwork architecture that explicitly takes inference difficulty into\nconsideration and optimizes the tradeoff between accuracy and\ncomputation/communication cost of the edge/cloud collaborative architecture.\nExperimental results on several image classification datasets show up to more\nthan 40% energy savings compared to existing techniques without sacrificing\naccuracy.",
    "descriptor": "\nComments: Accepted by DAC2021\n",
    "authors": [
      "Min Li",
      "Yu Li",
      "Ye Tian",
      "Li Jiang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04104"
  },
  {
    "id": "arXiv:2105.04105",
    "title": "On the Hardness of Opinion Dynamics Optimization with $L_1$-Budget on  Varying Susceptibility to Persuasion",
    "abstract": "Recently, Abebe et al. (KDD 2018) and Chan et al. (WWW 2019) have considered\nan opinion dynamics optimization problem that is based on a popular model for\nsocial opinion dynamics, in which each agent has some fixed innate opinion, and\na resistance that measures the importance it places on its innate opinion;\nmoreover, the agents influence one another's opinions through an iterative\nprocess. Under certain conditions, this iterative process converges to some\nequilibrium opinion vector. Previous works gave an efficient local search\nalgorithm to solve the unbudgeted variant of the problem, for which the goal is\nto modify the resistance of any number of agents (within some given range) such\nthat the sum of the equilibrium opinions is minimized. On the other hand, it\nwas proved that the $L_0$-budgeted variant is NP-hard, where the $L_0$-budget\nis a restriction given upfront on the number of agents whose resistance may be\nmodified.\nInspired by practical situations in which the effort to modify an agent's\nresistance increases with the magnitude of the change, we propose the\n$L_1$-budgeted variant, in which the $L_1$-budget is a restriction on the sum\nof the magnitudes of the changes over all agents' resistance parameters. In\nthis work, we show that the $L_1$-budgeted variant is NP-hard via a reduction\nfrom vertex cover. However, contrary to the $L_0$-budgeted variant, a very\ntechnical argument is needed to show that the optimal solution can be achieved\nby focusing the given $L_1$-budget on as small a number of agents as possible,\nas opposed to spreading the budget over a large number of agents.",
    "descriptor": "",
    "authors": [
      "T-H. Hubert Chan",
      "Chui Shan Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.04105"
  },
  {
    "id": "arXiv:2105.04107",
    "title": "MmWave MIMO Communication with Semi-Passive RIS: A Low-Complexity  Channel Estimation Scheme",
    "abstract": "Reconfigurable intelligent surfaces (RISs) have recently received widespread\nattention in the field of wireless communication. An RIS can be controlled to\nreflect incident waves from the transmitter towards the receiver; a feature\nthat is believed to fundamentally contribute to beyond 5G wireless technology.\nThe typical RIS consists of entirely passive elements, which requires the\nhigh-dimensional channel estimation to be done elsewhere. Therefore, in this\npaper, we present a semi-passive large-scale RIS architecture equipped with\nonly a small fraction of simplified receiver units with only 1-bit\nquantization. Based on this architecture, we first propose an alternating\ndirection method of multipliers (ADMM)-based approach to recover the training\nsignals at the passive RIS elements, We then obtain the global channel by\ncombining a channel sparsification step with the generalized approximate\nmessage passing (GAMP) algorithm. Our proposed scheme exploits both the\nsparsity and low-rankness properties of the channel in the joint\nspatial-frequency domain of a wideband mmWave multiple-input-multiple-output\n(MIMO) communication system. Simulation results show that the proposed\nalgorithm can significantly reduce the pilot signaling needed for accurate\nchannel estimation and outperform previous methods, even with fewer receiver\nunits.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Jiangfeng Hu",
      "Haifan Yin",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04107"
  },
  {
    "id": "arXiv:2105.04110",
    "title": "A Framework for Reasoning About LF Specifications",
    "abstract": "This thesis develops a framework for formalizing reasoning about\nspecifications of systems written in LF. This formalization centers around the\ndevelopment of a reasoning logic that can express the sorts of properties which\narise in reasoning about such specifications. In this logic, type inhabitation\njudgements in LF serve as atomic formulas, and quantification is permitted over\nboth contexts and terms in these judgements. The logic permits arbitrary\nrelations over derivations of LF judgements to be expressed using a collection\nof logical connectives, in contrast to other systems for reasoning about LF\nspecifications. Defining a semantics for these formulas raises issues which we\nmust address, such as how to interpret both term and context quantification as\nwell as the relation between atomic formulas and the LF judgements they are\nmeant to encode.\nThis thesis also develops a proof system which captures informal reasoning\nsteps as sound inference rules for the logic. To achieve this we develop a\ncollection of proof rules including mechanisms for both case analysis and\ninductive reasoning over the derivations of judgements in LF. The proof system\nalso supports applying LF meta-theorems through proof rules that enforce\nrequirements of the LF meta-theorem that cannot be expressed in the logic.\nWe also implement a proof assistant called Adelfa that provides a means for\nmechanizing this approach to reasoning about specifications written in LF. A\ncharacteristic of this proof assistant is that it uses the proof rules that\ncomplement the logic to describe a collection of tactics that are used to\ndevelop proofs in goal-driven fashion. The Adelfa system is used to develop a\ncollection of examples which demonstrate the effectiveness of the framework and\nshowcase how informal reasoning about specifications written in LF can be\nformalized using the logic and associated proof system.",
    "descriptor": "",
    "authors": [
      "Mary Southern"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.04110"
  },
  {
    "id": "arXiv:2105.04112",
    "title": "ROBI: A Multi-View Dataset for Reflective Objects in Robotic Bin-Picking",
    "abstract": "In robotic bin-picking applications, the perception of texture-less, highly\nreflective parts is a valuable but challenging task. The high glossiness can\nintroduce fake edges in RGB images and inaccurate depth measurements especially\nin heavily cluttered bin scenario. In this paper, we present the ROBI\n(Reflective Objects in BIns) dataset, a public dataset for 6D object pose\nestimation and multi-view depth fusion in robotic bin-picking scenarios. The\nROBI dataset includes a total of 63 bin-picking scenes captured with two active\nstereo camera: a high-cost Ensenso sensor and a low-cost RealSense sensor. For\neach scene, the monochrome/RGB images and depth maps are captured from sampled\nview spheres around the scene, and are annotated with accurate 6D poses of\nvisible objects and an associated visibility score. For evaluating the\nperformance of depth fusion, we captured the ground truth depth maps by\nhigh-cost Ensenso camera with objects coated in anti-reflective scanning spray.\nTo show the utility of the dataset, we evaluated the representative algorithms\nof 6D object pose estimation and multi-view depth fusion on the full dataset.\nEvaluation results demonstrate the difficulty of highly reflective objects,\nespecially in difficult cases due to the degradation of depth data quality,\nsevere occlusions and cluttered scene. The ROBI dataset is available online at\nhttps://www.trailab.utias.utoronto.ca/robi.",
    "descriptor": "",
    "authors": [
      "Jun Yang",
      "Yizhou Gao",
      "Dong Li",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04112"
  },
  {
    "id": "arXiv:2105.04113",
    "title": "Multi-Agent Semi-Siamese Training for Long-tail and Shallow Face  Learning",
    "abstract": "With the recent development of deep convolutional neural networks and\nlarge-scale datasets, deep face recognition has made remarkable progress and\nbeen widely used in various applications. However, unlike the existing public\nface datasets, in many real-world scenarios of face recognition, the depth of\ntraining dataset is shallow, which means only two face images are available for\neach ID. With the non-uniform increase of samples, such issue is converted to a\nmore general case, a.k.a long-tail face learning, which suffers from data\nimbalance and intra-class diversity dearth simultaneously. These adverse\nconditions damage the training and result in the decline of model performance.\nBased on the Semi-Siamese Training (SST), we introduce an advanced solution,\nnamed Multi-Agent Semi-Siamese Training (MASST), to address these problems.\nMASST includes a probe network and multiple gallery agents, the former aims to\nencode the probe features, and the latter constitutes a stack of networks that\nencode the prototypes (gallery features). For each training iteration, the\ngallery network, which is sequentially rotated from the stack, and the probe\nnetwork form a pair of semi-siamese networks. We give theoretical and empirical\nanalysis that, given the long-tail (or shallow) data and training loss, MASST\nsmooths the loss landscape and satisfies the Lipschitz continuity with the help\nof multiple agents and the updating gallery queue. The proposed method is out\nof extra-dependency, thus can be easily integrated with the existing loss\nfunctions and network architectures. It is worth noting that, although multiple\ngallery agents are employed for training, only the probe network is needed for\ninference, without increasing the inference cost. Extensive experiments and\ncomparisons demonstrate the advantages of MASST for long-tail and shallow face\nlearning.",
    "descriptor": "\nComments: 12 pages, 8 figures. arXiv admin note: text overlap with arXiv:2007.08398\n",
    "authors": [
      "Hailin Shi",
      "Dan Zeng",
      "Yichun Tai",
      "Hang Du",
      "Yibo Hu",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04113"
  },
  {
    "id": "arXiv:2105.04117",
    "title": "Wiki-Reliability: A Large Scale Dataset for Content Reliability on  Wikipedia",
    "abstract": "Wikipedia is the largest online encyclopedia, used by algorithms and web\nusers as a central hub of reliable information on the web. The quality and\nreliability of Wikipedia content is maintained by a community of volunteer\neditors. Machine learning and information retrieval algorithms could help scale\nup editors' manual efforts around Wikipedia content reliability. However, there\nis a lack of large-scale data to support the development of such research. To\nfill this gap, in this paper, we propose Wiki-Reliability, the first dataset of\nEnglish Wikipedia articles annotated with a wide set of content reliability\nissues. To build this dataset, we rely on Wikipedia \"templates\". Templates are\ntags used by expert Wikipedia editors to indicate content issues, such as the\npresence of \"non-neutral point of view\" or \"contradictory articles\", and serve\nas a strong signal for detecting reliability issues in a revision. We select\nthe 10 most popular reliability-related templates on Wikipedia, and propose an\neffective method to label almost 1M samples of Wikipedia article revisions as\npositive or negative with respect to each template. Each positive/negative\nexample in the dataset comes with the full article text and 20 features from\nthe revision's metadata. We provide an overview of the possible downstream\ntasks enabled by such data, and show that Wiki-Reliability can be used to train\nlarge-scale models for content reliability prediction. We release all data and\ncode for public use.",
    "descriptor": "\nComments: SIGIR'21\n",
    "authors": [
      "KayYen Wong",
      "Miriam Redi",
      "Diego Saez-Trumper"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04117"
  },
  {
    "id": "arXiv:2105.04118",
    "title": "FAID Diversity via Neural Networks",
    "abstract": "Decoder diversity is a powerful error correction framework in which a\ncollection of decoders collaboratively correct a set of error patterns\notherwise uncorrectable by any individual decoder. In this paper, we propose a\nnew approach to design the decoder diversity of finite alphabet iterative\ndecoders (FAIDs) for Low-Density Parity Check (LDPC) codes over the binary\nsymmetric channel (BSC), for the purpose of lowering the error floor while\nguaranteeing the waterfall performance. The proposed decoder diversity is\nachieved by training a recurrent quantized neural network (RQNN) to\nlearn/design FAIDs. We demonstrated for the first time that a machine-learned\ndecoder can surpass in performance a man-made decoder of the same complexity.\nAs RQNNs can model a broad class of FAIDs, they are capable of learning an\narbitrary FAID. To provide sufficient knowledge of the error floor to the RQNN,\nthe training sets are constructed by sampling from the set of most problematic\nerror patterns - trapping sets. In contrast to the existing methods that use\nthe cross-entropy function as the loss function, we introduce a\nframe-error-rate (FER) based loss function to train the RQNN with the objective\nof correcting specific error patterns rather than reducing the bit error rate\n(BER). The examples and simulation results show that the RQNN-aided decoder\ndiversity increases the error correction capability of LDPC codes and lowers\nthe error floor.",
    "descriptor": "\nComments: 7 pages, 3 figures, 3 tables. A shorter version is submitted to the International Symposium on Topics in Coding, 2021\n",
    "authors": [
      "Xin Xiao",
      "Nithin Raveendran",
      "Bane Vasic",
      "Shu Lin",
      "Ravi Tandon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04118"
  },
  {
    "id": "arXiv:2105.04120",
    "title": "Fast constraint satisfaction problem and learning-based algorithm for  solving Minesweeper",
    "abstract": "Minesweeper is a popular spatial-based decision-making game that works with\nincomplete information. As an exemplary NP-complete problem, it is a major area\nof research employing various artificial intelligence paradigms. The present\nwork models this game as Constraint Satisfaction Problem (CSP) and Markov\nDecision Process (MDP). We propose a new method named as dependents from the\nindependent set using deterministic solution search (DSScsp) for the faster\nenumeration of all solutions of a CSP based Minesweeper game and improve the\nresults by introducing heuristics. Using MDP, we implement machine learning\nmethods on these heuristics. We train the classification model on sparse data\nwith results from CSP formulation. We also propose a new rewarding method for\napplying a modified deep Q-learning for better accuracy and versatile learning\nin the Minesweeper game. The overall results have been analyzed for different\nkinds of Minesweeper games and their accuracies have been recorded. Results\nfrom these experiments show that the proposed method of MDP based\nclassification model and deep Q-learning overall is the best methods in terms\nof accuracy for games with given mine densities.",
    "descriptor": "",
    "authors": [
      "Yash Pratyush Sinha",
      "Pranshu Malviya",
      "Rupaj Kumar Nayak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04120"
  },
  {
    "id": "arXiv:2105.04123",
    "title": "Neural Program Repair with Execution-based Backpropagation",
    "abstract": "Neural machine translation (NMT) architectures have achieved promising\nresults for automatic program repair. Yet, they have the limitation of\ngenerating low-quality patches(e.g., not compilable patches). This is because\nthe existing works only optimize a purely syntactic loss function based on\ncharacters and tokens without incorporating program-specific information during\nneural net weight optimization. In this paper, we proposea novel program repair\nmodel called RewardRepair. The core novelty of RewardRepair is to improve\nNMT-based program repair with a loss function based on program compilation and\ntest execution information, rewarding the network to produce patches that\ncompile and that do not overfit. We conduct several experiments to evaluate\nRewardRepair showing that it is feasible and effective to use compilation and\ntest execution results to optimize the underlying neural repair model.",
    "descriptor": "",
    "authors": [
      "He Ye",
      "Matias Martinez",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04123"
  },
  {
    "id": "arXiv:2105.04124",
    "title": "MASS: Multi-task Anthropomorphic Speech Synthesis Framework",
    "abstract": "Text-to-Speech (TTS) synthesis plays an important role in human-computer\ninteraction. Currently, most TTS technologies focus on the naturalness of\nspeech, namely,making the speeches sound like humans. However, the key tasks of\nthe expression of emotion and the speaker identity are ignored, which limits\nthe application scenarios of TTS synthesis technology. To make the synthesized\nspeech more realistic and expand the application scenarios, we propose a\nmulti-task anthropomorphic speech synthesis framework (MASS), which can\nsynthesize speeches from text with specified emotion and speaker identity. The\nMASS framework consists of a base TTS module and two novel voice conversion\nmodules: the emotional voice conversion module and the speaker voice conversion\nmodule. We propose deep emotion voice conversion model (DEVC) and deep speaker\nvoice conversion model (DSVC) based on convolution residual networks. It solves\nthe problem of feature loss during voice conversion. The model trainings are\nindependent of parallel datasets, and are capable of many-to-many voice\nconversion. In the emotional voice conversion, speaker voice conversion\nexperiments, as well as the multi-task speech synthesis experiments,\nexperimental results show DEVC and DSVC convert speech effectively. The\nquantitative and qualitative evaluation results of multi-task speech synthesis\nexperiments show MASS can effectively synthesis speech with specified text,\nemotion and speaker identity.",
    "descriptor": "",
    "authors": [
      "Jinyin Chen",
      "Linhui Ye",
      "Zhaoyan Ming"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04124"
  },
  {
    "id": "arXiv:2105.04126",
    "title": "ExpMRC: Explainability Evaluation for Machine Reading Comprehension",
    "abstract": "Achieving human-level performance on some of Machine Reading Comprehension\n(MRC) datasets is no longer challenging with the help of powerful Pre-trained\nLanguage Models (PLMs). However, it is necessary to provide both answer\nprediction and its explanation to further improve the MRC system's reliability,\nespecially for real-life applications. In this paper, we propose a new\nbenchmark called ExpMRC for evaluating the explainability of the MRC systems.\nExpMRC contains four subsets, including SQuAD, CMRC 2018, RACE$^+$, and C$^3$\nwith additional annotations of the answer's evidence. The MRC systems are\nrequired to give not only the correct answer but also its explanation. We use\nstate-of-the-art pre-trained language models to build baseline systems and\nadopt various unsupervised approaches to extract evidence without a\nhuman-annotated training set. The experimental results show that these models\nare still far from human performance, suggesting that the ExpMRC is\nchallenging. Resources will be available through\nhttps://github.com/ymcui/expmrc",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yiming Cui",
      "Ting Liu",
      "Wanxiang Che",
      "Zhigang Chen",
      "Shijin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04126"
  },
  {
    "id": "arXiv:2105.04128",
    "title": "Examining and Mitigating Kernel Saturation in Convolutional Neural  Networks using Negative Images",
    "abstract": "Neural saturation in Deep Neural Networks (DNNs) has been studied\nextensively, but remains relatively unexplored in Convolutional Neural Networks\n(CNNs). Understanding and alleviating the effects of convolutional kernel\nsaturation is critical for enhancing CNN models classification accuracies. In\nthis paper, we analyze the effect of convolutional kernel saturation in CNNs\nand propose a simple data augmentation technique to mitigate saturation and\nincrease classification accuracy, by supplementing negative images to the\ntraining dataset. We hypothesize that greater semantic feature information can\nbe extracted using negative images since they have the same structural\ninformation as standard images but differ in their data representations. Varied\ndata representations decrease the probability of kernel saturation and thus\nincrease the effectiveness of kernel weight updates. The two datasets selected\nto evaluate our hypothesis were CIFAR- 10 and STL-10 as they have similar image\nclasses but differ in image resolutions thus making for a better understanding\nof the saturation phenomenon. MNIST dataset was used to highlight the\nineffectiveness of the technique for linearly separable data. The ResNet CNN\narchitecture was chosen since the skip connections in the network ensure the\nmost important features contributing the most to classification accuracy are\nretained. Our results show that CNNs are indeed susceptible to convolutional\nkernel saturation and that supplementing negative images to the training\ndataset can offer a statistically significant increase in classification\naccuracies when compared against models trained on the original datasets. Our\nresults present accuracy increases of 6.98% and 3.16% on the STL-10 and\nCIFAR-10 datasets respectively.",
    "descriptor": "\nComments: Conference paper, 6 pages, 3 figures, 1 table\n",
    "authors": [
      "Nidhi Gowdra",
      "Roopak Sinha",
      "Stephen MacDonell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04128"
  },
  {
    "id": "arXiv:2105.04129",
    "title": "Parameter-free Gradient Temporal Difference Learning",
    "abstract": "Reinforcement learning lies at the intersection of several challenges. Many\napplications of interest involve extremely large state spaces, requiring\nfunction approximation to enable tractable computation. In addition, the\nlearner has only a single stream of experience with which to evaluate a large\nnumber of possible courses of action, necessitating algorithms which can learn\noff-policy. However, the combination of off-policy learning with function\napproximation leads to divergence of temporal difference methods. Recent work\ninto gradient-based temporal difference methods has promised a path to\nstability, but at the cost of expensive hyperparameter tuning. In parallel,\nprogress in online learning has provided parameter-free methods that achieve\nminimax optimal guarantees up to logarithmic terms, but their application in\nreinforcement learning has yet to be explored. In this work, we combine these\ntwo lines of attack, deriving parameter-free, gradient-based temporal\ndifference algorithms. Our algorithms run in linear time and achieve\nhigh-probability convergence guarantees matching those of GTD2 up to $\\log$\nfactors. Our experiments demonstrate that our methods maintain high prediction\nperformance relative to fully-tuned baselines, with no tuning whatsoever.",
    "descriptor": "\nComments: 30 pages, 10 figures\n",
    "authors": [
      "Andrew Jacobsen",
      "Alan Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04129"
  },
  {
    "id": "arXiv:2105.04132",
    "title": "An Attention-Fused Network for Semantic Segmentation of  Very-High-Resolution Remote Sensing Imagery",
    "abstract": "Semantic segmentation is an essential part of deep learning. In recent years,\nwith the development of remote sensing big data, semantic segmentation has been\nincreasingly used in remote sensing. Deep convolutional neural networks (DCNNs)\nface the challenge of feature fusion: very-high-resolution remote sensing image\nmultisource data fusion can increase the network's learnable information, which\nis conducive to correctly classifying target objects by DCNNs; simultaneously,\nthe fusion of high-level abstract features and low-level spatial features can\nimprove the classification accuracy at the border between target objects. In\nthis paper, we propose a multipath encoder structure to extract features of\nmultipath inputs, a multipath attention-fused block module to fuse multipath\nfeatures, and a refinement attention-fused block module to fuse high-level\nabstract features and low-level spatial features. Furthermore, we propose a\nnovel convolutional neural network architecture, named attention-fused network\n(AFNet). Based on our AFNet, we achieve state-of-the-art performance with an\noverall accuracy of 91.7% and a mean F1 score of 90.96% on the ISPRS Vaihingen\n2D dataset and an overall accuracy of 92.1% and a mean F1 score of 93.44% on\nthe ISPRS Potsdam 2D dataset.",
    "descriptor": "\nComments: 35 pages. Accepted by ISPRS Journal of Photogrammetry and Remote Sensing\n",
    "authors": [
      "Xuan Yang",
      "Shanshan Li",
      "Zhengchao Chen",
      "Jocelyn Chanussot",
      "Xiuping Jia",
      "Bing Zhang",
      "Baipeng Li",
      "Pan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04132"
  },
  {
    "id": "arXiv:2105.04133",
    "title": "Coupling Intent and Action for Pedestrian Crossing Behavior Prediction",
    "abstract": "Accurate prediction of pedestrian crossing behaviors by autonomous vehicles\ncan significantly improve traffic safety. Existing approaches often model\npedestrian behaviors using trajectories or poses but do not offer a deeper\nsemantic interpretation of a person's actions or how actions influence a\npedestrian's intention to cross in the future. In this work, we follow the\nneuroscience and psychological literature to define pedestrian crossing\nbehavior as a combination of an unobserved inner will (a probabilistic\nrepresentation of binary intent of crossing vs. not crossing) and a set of\nmulti-class actions (e.g., walking, standing, etc.). Intent generates actions,\nand the future actions in turn reflect the intent. We present a novel\nmulti-task network that predicts future pedestrian actions and uses predicted\nfuture action as a prior to detect the present intent and action of the\npedestrian. We also designed an attention relation network to incorporate\nexternal environmental contexts thus further improve intent and action\ndetection performance. We evaluated our approach on two naturalistic driving\ndatasets, PIE and JAAD, and extensive experiments show significantly improved\nand more explainable results for both intent detection and action prediction\nover state-of-the-art approaches. Our code is available at:\nhttps://github.com/umautobots/pedestrian_intent_action_detection.",
    "descriptor": "\nComments: 7pages, 4 figures, 3 tables. Accepted to IJCAI2021\n",
    "authors": [
      "Yu Yao",
      "Ella Atkins",
      "Matthew Johnson Roberson",
      "Ram Vasudevan",
      "Xiaoxiao Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04133"
  },
  {
    "id": "arXiv:2105.04138",
    "title": "Near Interference-Free Space-Time User Scheduling for MmWave Cellular  Network",
    "abstract": "The highly directional beams applied in millimeter wave (mmWave) cellular\nnetworks make it possible to achieve near interference-free (NIF) transmission\nunder judiciously designed space-time user scheduling, where the power of\nintra-/inter-cell interference between any two users is below a predefined\nthreshold. In this paper, we investigate two aspects of the NIF space-time user\nscheduling in a multi-cell mmWave network with multi-RF-chain base stations.\nFirstly, given that each user has a requirement on the number of space-time\nresource elements, we study the NIF user scheduling problem to minimize the\nunfulfilled user requirements, so that the space-time resources can be utilized\nmost efficiently and meanwhile all strong interferences are avoided. A\nnear-optimal scheduling algorithm is proposed with performance close to the\nlower bound of unfulfilled requirements. Furthermore, we study the joint NIF\nuser scheduling and power allocation problem to minimize the power consumption\nunder the constraint of rate requirements. Based on our proposed NIF\nscheduling, an energy-efficient joint scheduling and power allocation scheme is\ndesigned with limited channel state information, which outperforms the existing\nindependent set based schemes, and has near-optimal performance as well.",
    "descriptor": "",
    "authors": [
      "Ziyuan Sha",
      "Siyu Chen",
      "Zhaocheng Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04138"
  },
  {
    "id": "arXiv:2105.04143",
    "title": "Matching Visual Features to Hierarchical Semantic Topics for Image  Paragraph Captioning",
    "abstract": "Observing a set of images and their corresponding paragraph-captions, a\nchallenging task is to learn how to produce a semantically coherent paragraph\nto describe the visual content of an image. Inspired by recent successes in\nintegrating semantic topics into this task, this paper develops a plug-and-play\nhierarchical-topic-guided image paragraph generation framework, which couples a\nvisual extractor with a deep topic model to guide the learning of a language\nmodel. To capture the correlations between the image and text at multiple\nlevels of abstraction and learn the semantic topics from images, we design a\nvariational inference network to build the mapping from image features to\ntextual captions. To guide the paragraph generation, the learned hierarchical\ntopics and visual features are integrated into the language model, including\nLong Short-Term Memory (LSTM) and Transformer, and jointly optimized.\nExperiments on public dataset demonstrate that the proposed models, which are\ncompetitive with many state-of-the-art approaches in terms of standard\nevaluation metrics, can be used to both distill interpretable multi-layer\ntopics and generate diverse and coherent captions.",
    "descriptor": "",
    "authors": [
      "Dandan Guo",
      "Ruiying Lu",
      "Bo Chen",
      "Zequn Zeng",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04143"
  },
  {
    "id": "arXiv:2105.04144",
    "title": "Transitioning from Real to Synthetic data: Quantifying the bias in model",
    "abstract": "With the advent of generative modeling techniques, synthetic data and its use\nhas penetrated across various domains from unstructured data such as image,\ntext to structured dataset modeling healthcare outcome, risk decisioning in\nfinancial domain, and many more. It overcomes various challenges such as\nlimited training data, class imbalance, restricted access to dataset owing to\nprivacy issues. To ensure the trained model used for automated decisioning\npurposes makes a fair decision there exist prior work to quantify and mitigate\nthose issues. This study aims to establish a trade-off between bias and\nfairness in the models trained using synthetic data. Variants of synthetic data\ngeneration techniques were studied to understand bias amplification including\ndifferentially private generation schemes. Through experiments on a tabular\ndataset, we demonstrate there exist a varying levels of bias impact on models\ntrained using synthetic data. Techniques generating less correlated feature\nperforms well as evident through fairness metrics with 94\\%, 82\\%, and 88\\%\nrelative drop in DPD (demographic parity difference), EoD (equality of odds)\nand EoP (equality of opportunity) respectively, and 24\\% relative improvement\nin DRP (demographic parity ratio) with respect to the real dataset. We believe\nthe outcome of our research study will help data science practitioners\nunderstand the bias in the use of synthetic data.",
    "descriptor": "\nComments: Accepted at Synthetic Data Generation Workshop at ICLR 2021 this https URL\n",
    "authors": [
      "Aman Gupta",
      "Deepak Bhatt",
      "Anubha Pandey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04144"
  },
  {
    "id": "arXiv:2105.04146",
    "title": "Polynomial-Delay Enumeration of Large Maximal Matchings",
    "abstract": "Enumerating matchings is a classical problem in the field of enumeration\nalgorithms. There are polynomial-delay enumeration algorithms for several\nsettings, such as enumerating perfect matchings, maximal matchings, and\n(weighted) matchings in specific orders. In this paper, we present\npolynomial-delay enumeration algorithms for maximal matchings with cardinality\nat least given threshold $t$. Our algorithm enumerates all such matchings in\n$O(nm)$ delay with exponential space, where $n$ and $m$ are the number of\nvertices and edges of an input graph, respectively. We also present a\npolynomial-delay and polynomial-space enumeration algorithm for this problem.\nAs a variant of this algorithm, we give an algorithm that enumerates all\nmaximal matchings in non-decreasing order of its cardinality and runs in\n$O(nm)$ delay.",
    "descriptor": "",
    "authors": [
      "Yasuaki Kobayashi",
      "Kazuhiro Kurita",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.04146"
  },
  {
    "id": "arXiv:2105.04150",
    "title": "PeriPy -- A High Performance OpenCL Peridynamics Package",
    "abstract": "This paper presents a lightweight, open-source and high-performance python\npackage for solving peridynamics problems in solid mechanics. The development\nof this solver is motivated by the need for fast analysis tools to achieve the\nlarge number of simulations required for `outer-loop' applications, including\nsensitivity analysis, uncertainty quantification and optimisation. Our python\nsoftware toolbox utilises the heterogeneous nature of OpenCL so that it can be\nexecuted on any platform with CPU or GPU cores. We illustrate the package use\nthrough a range of industrially motivated examples, which should enable other\nresearchers to build on and extend the solver for use in their own\napplications. Step improvements in execution speed and functionality over\nexisting techniques are presented. A comparison between this solver and an\nexisting OpenCL implementation in the literature is presented, tested on\nbenchmarks with hundreds of thousands to tens of millions of nodes. We\ndemonstrate the scalability of the solver on the GeForce RTX 2080 TiGPU from\nNVIDIA, and the memory-bound limitations are analysed. In all test cases, the\nimplementation is between 1.4 and 10.0 times faster than a similar existing GPU\nimplementation in the literature. In particular, this improvement has been\nachieved by utilising local memory on the GPU.",
    "descriptor": "\nComments: peripy.readthedocs.org\n",
    "authors": [
      "B. Boys",
      "T. J. Dodwell",
      "M. Hobbs",
      "M. Girolami"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04150"
  },
  {
    "id": "arXiv:2105.04151",
    "title": "Skew-Oblivious Data Routing for Data-Intensive Applications on FPGAs  with HLS",
    "abstract": "FPGAs have become emerging computing infrastructures for accelerating\napplications in datacenters. Meanwhile, high-level synthesis (HLS) tools have\nbeen proposed to ease the programming of FPGAs. Even with HLS, irregular\ndata-intensive applications require explicit optimizations, among which\nmultiple processing elements (PEs) with each owning a private BRAM-based buffer\nare usually adopted to process multiple data per cycle. Data routing, which\ndynamically dispatches multiple data to designated PEs, avoids data replication\nin buffers compared to statically assigning data to PEs, hence saving BRAM\nusage. However, the workload imbalance among PEs vastly diminishes performance\nwhen processing skew datasets. In this paper, we propose a skew-oblivious data\nrouting architecture that allocates secondary PEs and schedules them to share\nthe workload of the overloaded PEs at run-time. In addition, we integrate the\nproposed architecture into a framework called Ditto to minimize the development\nefforts for applications that require skew handling. We evaluate Ditto on five\ncommonly used applications: histogram building, data partitioning, pagerank,\nheavy hitter detection and hyperloglog. The results demonstrate that the\ngenerated implementations are robust to skew datasets and outperform the\nstateof-the-art designs in both throughput and BRAM usage efficiency.",
    "descriptor": "",
    "authors": [
      "Xinyu Chen",
      "Hongshi Tan",
      "Yao Chen",
      "Bingsheng He",
      "Weng-Fai Wong",
      "Deming Chen"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.04151"
  },
  {
    "id": "arXiv:2105.04153",
    "title": "Slashing Communication Traffic in Federated Learning by Transmitting  Clustered Model Updates",
    "abstract": "Federated Learning (FL) is an emerging decentralized learning framework\nthrough which multiple clients can collaboratively train a learning model.\nHowever, a major obstacle that impedes the wide deployment of FL lies in\nmassive communication traffic. To train high dimensional machine learning\nmodels (such as CNN models), heavy communication traffic can be incurred by\nexchanging model updates via the Internet between clients and the parameter\nserver (PS), implying that the network resource can be easily exhausted.\nCompressing model updates is an effective way to reduce the traffic amount.\nHowever, a flexible unbiased compression algorithm applicable for both uplink\nand downlink compression in FL is still absent from existing works. In this\nwork, we devise the Model Update Compression by Soft Clustering (MUCSC)\nalgorithm to compress model updates transmitted between clients and the PS. In\nMUCSC, it is only necessary to transmit cluster centroids and the cluster ID of\neach model update. Moreover, we prove that: 1) The compressed model updates are\nunbiased estimation of their original values so that the convergence rate by\ntransmitting compressed model updates is unchanged; 2) MUCSC can guarantee that\nthe influence of the compression error on the model accuracy is minimized.\nThen, we further propose the boosted MUCSC (B-MUCSC) algorithm, a biased\ncompression algorithm that can achieve an extremely high compression rate by\ngrouping insignificant model updates into a super cluster. B-MUCSC is suitable\nfor scenarios with very scarce network resource. Ultimately, we conduct\nextensive experiments with the CIFAR-10 and FEMNIST datasets to demonstrate\nthat our algorithms can not only substantially reduce the volume of\ncommunication traffic in FL, but also improve the training efficiency in\npractical networks.",
    "descriptor": "\nComments: To appear in IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Laizhong Cui",
      "Xiaoxin Su",
      "Yipeng Zhou",
      "Yi Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04153"
  },
  {
    "id": "arXiv:2105.04154",
    "title": "Unsupervised Human Pose Estimation through Transforming Shape Templates",
    "abstract": "Human pose estimation is a major computer vision problem with applications\nranging from augmented reality and video capture to surveillance and movement\ntracking. In the medical context, the latter may be an important biomarker for\nneurological impairments in infants. Whilst many methods exist, their\napplication has been limited by the need for well annotated large datasets and\nthe inability to generalize to humans of different shapes and body\ncompositions, e.g. children and infants. In this paper we present a novel\nmethod for learning pose estimators for human adults and infants in an\nunsupervised fashion. We approach this as a learnable template matching problem\nfacilitated by deep feature extractors. Human-interpretable landmarks are\nestimated by transforming a template consisting of predefined body parts that\nare characterized by 2D Gaussian distributions. Enforcing a connectivity prior\nguides our model to meaningful human shape representations. We demonstrate the\neffectiveness of our approach on two different datasets including adults and\ninfants.",
    "descriptor": "\nComments: CVPR 2021 (poster). Project page: this https URL\n",
    "authors": [
      "Luca Schmidtke",
      "Athanasios Vlontzos",
      "Simon Ellershaw",
      "Anna Lukens",
      "Tomoki Arichi",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04154"
  },
  {
    "id": "arXiv:2105.04156",
    "title": "ReLU Deep Neural Networks from the Hierarchical Basis Perspective",
    "abstract": "We study ReLU deep neural networks (DNNs) by investigating their connections\nwith the hierarchical basis method in finite element methods. First, we show\nthat the approximation schemes of ReLU DNNs for $x^2$ and $xy$ are composition\nversions of the hierarchical basis approximation for these two functions. Based\non this fact, we obtain a geometric interpretation and systematic proof for the\napproximation result of ReLU DNNs for polynomials, which plays an important\nrole in a series of recent exponential approximation results of ReLU DNNs.\nThrough our investigation of connections between ReLU DNNs and the hierarchical\nbasis approximation for $x^2$ and $xy$, we show that ReLU DNNs with this\nspecial structure can be applied only to approximate quadratic functions.\nFurthermore, we obtain a concise representation to explicitly reproduce any\nlinear finite element function on a two-dimensional uniform mesh by using ReLU\nDNNs with only two hidden layers.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Juncai He",
      "Lin Li",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04156"
  },
  {
    "id": "arXiv:2105.04157",
    "title": "A Sharp Analysis of Covariate Adjusted Precision Matrix Estimation via  Alternating Gradient Descent with Hard Thresholding",
    "abstract": "In this paper, we present a sharp analysis for an alternating gradient\ndescent algorithm which is used to solve the covariate adjusted precision\nmatrix estimation problem in the high dimensional setting. Without the\nresampling assumption, we demonstrate that this algorithm not only enjoys a\nlinear rate of convergence, but also attains the optimal statistical rate\n(i.e., minimax rate). Moreover, our analysis also characterizes the time-data\ntradeoffs in the covariate adjusted precision matrix estimation problem.\nNumerical experiments are provided to verify our theoretical results.",
    "descriptor": "",
    "authors": [
      "Xiao Lv",
      "Wei Cui",
      "Yulong Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04157"
  },
  {
    "id": "arXiv:2105.04158",
    "title": "CREPO: An Open Repository to Benchmark Credal Network Algorithms",
    "abstract": "Credal networks are a popular class of imprecise probabilistic graphical\nmodels obtained as a Bayesian network generalization based on, so-called\ncredal, sets of probability mass functions. A Java library called CREMA has\nbeen recently released to model, process and query credal networks. Despite the\nNP-hardness of the (exact) task, a number of algorithms is available to\napproximate credal network inferences. In this paper we present CREPO, an open\nrepository of synthetic credal networks, provided together with the exact\nresults of inference tasks on these models. A Python tool is also delivered to\nload these data and interact with CREMA, thus making extremely easy to evaluate\nand compare existing and novel inference algorithms. To demonstrate such\nbenchmarking scheme, we propose an approximate heuristic to be used inside\nvariable elimination schemes to keep a bound on the maximum number of vertices\ngenerated during the combination step. A CREPO-based validation against\napproximate procedures based on linearization and exact techniques performed in\nCREMA is finally discussed.",
    "descriptor": "\nComments: Isipta 2021 (Version with Supplementary Material)\n",
    "authors": [
      "Rafael Caba\u00f1as",
      "Alessandro Antonucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04158"
  },
  {
    "id": "arXiv:2105.04164",
    "title": "Communication coordination in network controllability",
    "abstract": "Better understanding our ability to control an interconnected system of\nentities has been one of the central challenges in network science. The\ntheories of node and edge controllability have been the main methodologies\nsuggested to find the minimal set of nodes enabling control over the whole\nsystem's dynamics. While the focus is traditionally mostly on physical systems,\nthere has been an increasing interest in control questions involving\nsocioeconomic systems. However, surprisingly little attention has been given to\nthe methods' underlying assumptions on control propagation, or communication\nassumptions, a crucial aspect in social contexts. In this paper, we show that\nnode controllability contains a single message assumption, allowing no\nheterogeneity in communication to neighbouring nodes in a network. Edge\ncontrollability is shown to relax this communication assumption but aims to\ncontrol the dynamics of the edge states and not the node states, thus answering\na fundamentally different question. This makes comparisons of the results from\nthe two methods nonsensical. To increase the applicability of controllability\nmethodology to socioeconomic contexts, we provide guiding principles to choose\nthe appropriate methodology and suggest new avenues for future theoretical work\nto encode more realistic communication assumptions.",
    "descriptor": "",
    "authors": [
      "Milan van den Heuvel",
      "Jannes Nys"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04164"
  },
  {
    "id": "arXiv:2105.04165",
    "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language  and Symbolic Reasoning",
    "abstract": "Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. A theorem predictor is also\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate Inter-GPS achieves significant\nimprovements over existing methods.",
    "descriptor": "\nComments: ACL 2021, 13 pages, 5 figures, project page: this https URL\n",
    "authors": [
      "Pan Lu",
      "Ran Gong",
      "Shibiao Jiang",
      "Liang Qiu",
      "Siyuan Huang",
      "Xiaodan Liang",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.04165"
  },
  {
    "id": "arXiv:2105.04166",
    "title": "Few-Shot Conversational Dense Retrieval",
    "abstract": "Dense retrieval (DR) has the potential to resolve the query understanding\nchallenge in conversational search by matching in the learned embedding space.\nHowever, this adaptation is challenging due to DR models' extra needs for\nsupervision signals and the long-tail nature of conversational search. In this\npaper, we present a Conversational Dense Retrieval system, ConvDR, that learns\ncontextualized embeddings for multi-turn conversational queries and retrieves\ndocuments solely using embedding dot products. In addition, we grant ConvDR\nfew-shot ability using a teacher-student framework, where we employ an ad hoc\ndense retriever as the teacher, inherit its document encodings, and learn a\nstudent query encoder to mimic the teacher embeddings on oracle reformulated\nqueries. Our experiments on TREC CAsT and OR-QuAC demonstrate ConvDR's\neffectiveness in both few-shot and fully-supervised settings. It outperforms\nprevious systems that operate in the sparse word space, matches the retrieval\naccuracy of oracle query reformulations, and is also more efficient thanks to\nits simplicity. Our analyses reveal that the advantages of ConvDR come from its\nability to capture informative context while ignoring the unrelated context in\nprevious conversation rounds. This makes ConvDR more effective as conversations\nevolve while previous systems may get confused by the increased noise from\nprevious turns. Our code is publicly available at\nhttps://github.com/thunlp/ConvDR.",
    "descriptor": "\nComments: Accepted by SIGIR 2021\n",
    "authors": [
      "Shi Yu",
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Tao Feng",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04166"
  },
  {
    "id": "arXiv:2105.04169",
    "title": "PillarSegNet: Pillar-based Semantic Grid Map Estimation using Sparse  LiDAR Data",
    "abstract": "Semantic understanding of the surrounding environment is essential for\nautomated vehicles. The recent publication of the SemanticKITTI dataset\nstimulates the research on semantic segmentation of LiDAR point clouds in urban\nscenarios. While most existing approaches predict sparse pointwise semantic\nclasses for the sparse input LiDAR scan, we propose PillarSegNet to be able to\noutput a dense semantic grid map. In contrast to a previously proposed grid map\nmethod, PillarSegNet uses PointNet to learn features directly from the 3D point\ncloud and then conducts 2D semantic segmentation in the top view. To train and\nevaluate our approach, we use both sparse and dense ground truth, where the\ndense ground truth is obtained from multiple superimposed scans. Experimental\nresults on the SemanticKITTI dataset show that PillarSegNet achieves a\nperformance gain of about 10% mIoU over the state-of-the-art grid map method.",
    "descriptor": "\nComments: Accepted to present in the 2021 IEEE Intelligent Vehicles Symposium (IV21)\n",
    "authors": [
      "Juncong Fei",
      "Kunyu Peng",
      "Philipp Heidenreich",
      "Frank Bieder",
      "Christoph Stiller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04169"
  },
  {
    "id": "arXiv:2105.04170",
    "title": "AutoDebias: Learning to Debias for Recommendation",
    "abstract": "Recommender systems rely on user behavior data like ratings and clicks to\nbuild personalization model. However, the collected data is observational\nrather than experimental, causing various biases in the data which\nsignificantly affect the learned model. Most existing work for recommendation\ndebiasing, such as the inverse propensity scoring and imputation approaches,\nfocuses on one or two specific biases, lacking the universal capacity that can\naccount for mixed or even unknown biases in the data.\nTowards this research gap, we first analyze the origin of biases from the\nperspective of \\textit{risk discrepancy} that represents the difference between\nthe expectation empirical risk and the true risk. Remarkably, we derive a\ngeneral learning framework that well summarizes most existing debiasing\nstrategies by specifying some parameters of the general framework. This\nprovides a valuable opportunity to develop a universal solution for debiasing,\ne.g., by learning the debiasing parameters from data. However, the training\ndata lacks important signal of how the data is biased and what the unbiased\ndata looks like. To move this idea forward, we propose \\textit{AotoDebias} that\nleverages another (small) set of uniform data to optimize the debiasing\nparameters by solving the bi-level optimization problem with meta-learning.\nThrough theoretical analyses, we derive the generalization bound for AutoDebias\nand prove its ability to acquire the appropriate debiasing strategy. Extensive\nexperiments on two real datasets and a simulated dataset demonstrated\neffectiveness of AutoDebias. The code is available at\n\\url{https://github.com/DongHande/AutoDebias}.",
    "descriptor": "\nComments: Accepted by SIGIR 2021\n",
    "authors": [
      "Jiawei Chen",
      "Hande Dong",
      "Yang Qiu",
      "Xiangnan He",
      "Xin Xin",
      "Liang Chen",
      "Guli Lin",
      "Keping Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04170"
  },
  {
    "id": "arXiv:2105.04176",
    "title": "HyperLTL Satisfiability is $\u03a3_1^1$-complete, HyperCTL*  Satisfiability is $\u03a3_1^2$-complete",
    "abstract": "Temporal logics for the specification of information-flow properties are able\nto express relations between multiple executions of a system. The two most\nimportant such logics are HyperLTL and HyperCTL*, which generalise LTL and CTL*\nby trace quantification. It is known that this expressiveness comes at a price,\ni.e. satisfiability is undecidable for both logics.\nIn this paper we settle the exact complexity of these problems, showing that\nboth are in fact highly undecidable: we prove that HyperLTL satisfiability is\n$\\Sigma_1^1$-complete and HyperCTL* satisfiability is $\\Sigma_1^2$-complete.\nThese are significant increases over the previously known lower bounds and the\nfirst upper bounds. To prove $\\Sigma_1^2$-membership for HyperCTL*, we prove\nthat every satisfiable HyperCTL* sentence has a model that is equinumerous to\nthe continuum, the first upper bound of this kind. We prove this bound to be\ntight. Finally, we show that the membership problem for every level of the\nHyperLTL quantifier alternation hierarchy is $\\Pi_1^1$-complete.",
    "descriptor": "",
    "authors": [
      "Marie Fortin",
      "Louwe B. Kuijer",
      "Patrick Totzke",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.04176"
  },
  {
    "id": "arXiv:2105.04180",
    "title": "Rate-Distortion Analysis of Minimum Excess Risk in Bayesian Learning",
    "abstract": "Minimum Excess Risk (MER) in Bayesian learning is defined as the difference\nbetween the minimum expected loss achievable when learning from data and the\nminimum expected loss that could be achieved if the underlying parameter $W$\nwas observed. In this paper, we build upon and extend the recent results of (Xu\n& Raginsky, 2020) to analyze the MER in Bayesian learning and derive\ninformation-theoretic bounds on it. We formulate the problem as a (constrained)\nrate-distortion optimization and show how the solution can be bounded above and\nbelow by two other rate-distortion functions that are easier to study. The\nlower bound represents the minimum possible excess risk achievable by\n\\emph{any} process using $R$ bits of information from the parameter $W$. For\nthe upper bound, the optimization is further constrained to use $R$ bits from\nthe training set, a setting which relates MER to information-theoretic bounds\non the generalization gap in frequentist learning. We derive\ninformation-theoretic bounds on the difference between these upper and lower\nbounds and show that they can provide order-wise tight rates for MER. This\nanalysis gives more insight into the information-theoretic nature of Bayesian\nlearning as well as providing novel bounds.",
    "descriptor": "\nComments: Accepted at ICML 2021\n",
    "authors": [
      "Hassan Hafez-Kolahi",
      "Behrad Moniri",
      "Shohreh Kasaei",
      "Mahdieh Soleymani Baghshah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04180"
  },
  {
    "id": "arXiv:2105.04181",
    "title": "KDExplainer: A Task-oriented Attention Model for Explaining Knowledge  Distillation",
    "abstract": "Knowledge distillation (KD) has recently emerged as an efficacious scheme for\nlearning compact deep neural networks (DNNs). Despite the promising results\nachieved, the rationale that interprets the behavior of KD has yet remained\nlargely understudied. In this paper, we introduce a novel task-oriented\nattention model, termed as KDExplainer, to shed light on the working mechanism\nunderlying the vanilla KD. At the heart of KDExplainer is a Hierarchical\nMixture of Experts (HME), in which a multi-class classification is reformulated\nas a multi-task binary one. Through distilling knowledge from a free-form\npre-trained DNN to KDExplainer, we observe that KD implicitly modulates the\nknowledge conflicts between different subtasks, and in reality has much more to\noffer than label smoothing. Based on such findings, we further introduce a\nportable tool, dubbed as virtual attention module (VAM), that can be seamlessly\nintegrated with various DNNs to enhance their performance under KD.\nExperimental results demonstrate that with a negligible additional cost,\nstudent models equipped with VAM consistently outperform their non-VAM\ncounterparts across different benchmarks. Furthermore, when combined with other\nKD methods, VAM remains competent in promoting results, even though it is only\nmotivated by vanilla KD.",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted to IJCAI 2021\n",
    "authors": [
      "Mengqi Xue",
      "Jie Song",
      "Xinchao Wang",
      "Ying Chen",
      "Xingen Wang",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04181"
  },
  {
    "id": "arXiv:2105.04183",
    "title": "UGRec: Modeling Directed and Undirected Relations for Recommendation",
    "abstract": "Recommender systems, which merely leverage user-item interactions for user\npreference prediction (such as the collaborative filtering-based ones), often\nface dramatic performance degradation when the interactions of users or items\nare insufficient. In recent years, various types of side information have been\nexplored to alleviate this problem. Among them, knowledge graph (KG) has\nattracted extensive research interests as it can encode users/items and their\nassociated attributes in the graph structure to preserve the relation\ninformation. In contrast, less attention has been paid to the item-item\nco-occurrence information (i.e., \\textit{co-view}), which contains rich\nitem-item similarity information. It provides information from a perspective\ndifferent from the user/item-attribute graph and is also valuable for the CF\nrecommendation models. In this work, we make an effort to study the potential\nof integrating both types of side information (i.e., KG and item-item\nco-occurrence data) for recommendation. To achieve the goal, we propose a\nunified graph-based recommendation model (UGRec), which integrates the\ntraditional directed relations in KG and the undirected item-item co-occurrence\nrelations simultaneously. In particular, for a directed relation, we transform\nthe head and tail entities into the corresponding relation space to model their\nrelation; and for an undirected co-occurrence relation, we project head and\ntail entities into a unique hyperplane in the entity space to minimize their\ndistance. In addition, a head-tail relation-aware attentive mechanism is\ndesigned for fine-grained relation modeling. Extensive experiments have been\nconducted on several publicly accessible datasets to evaluate the proposed\nmodel. Results show that our model outperforms several previous\nstate-of-the-art methods and demonstrate the effectiveness of our UGRec model.",
    "descriptor": "\nComments: Accepted as a long paper in SIGIR 2021\n",
    "authors": [
      "Xinxiao Zhao",
      "Zhiyong Cheng",
      "Lei Zhu",
      "Jiecai Zheng",
      "Xueqing Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04183"
  },
  {
    "id": "arXiv:2105.04184",
    "title": "Generative Adversarial Networks (GANs) in Networking: A Comprehensive  Survey & Evaluation",
    "abstract": "Despite the recency of their conception, Generative Adversarial Networks\n(GANs) constitute an extensively researched machine learning sub-field for the\ncreation of synthetic data through deep generative modeling. GANs have\nconsequently been applied in a number of domains, most notably computer vision,\nin which they are typically used to generate or transform synthetic images.\nGiven their relative ease of use, it is therefore natural that researchers in\nthe field of networking (which has seen extensive application of deep learning\nmethods) should take an interest in GAN-based approaches. The need for a\ncomprehensive survey of such activity is therefore urgent. In this paper, we\ndemonstrate how this branch of machine learning can benefit multiple aspects of\ncomputer and communication networks, including mobile networks, network\nanalysis, internet of things, physical layer, and cybersecurity. In doing so,\nwe shall provide a novel evaluation framework for comparing the performance of\ndifferent models in non-image applications, applying this to a number of\nreference network datasets.",
    "descriptor": "\nComments: Accepted for publication at Journal of Computer Networks\n",
    "authors": [
      "Hojjat Navidan",
      "Parisa Fard Moshiri",
      "Mohammad Nabati",
      "Reza Shahbazian",
      "Seyed Ali Ghorashi",
      "Vahid Shah-Mansouri",
      "David Windridge"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04184"
  },
  {
    "id": "arXiv:2105.04187",
    "title": "A Rigorous Information-Theoretic Definition of Redundancy and Relevancy  in Feature Selection Based on (Partial) Information Decomposition",
    "abstract": "Selecting a minimal feature set that is maximally informative about a target\nvariable is a central task in machine learning and statistics. Information\ntheory provides a powerful framework for formulating feature selection\nalgorithms -- yet, a rigorous, information-theoretic definition of feature\nrelevancy, which accounts for feature interactions such as redundant and\nsynergistic contributions, is still missing. We argue that this lack is\ninherent to classical information theory which does not provide measures to\ndecompose the information a set of variables provides about a target into\nunique, redundant, and synergistic contributions. Such a decomposition has been\nintroduced only recently by the partial information decomposition (PID)\nframework. Using PID, we clarify why feature selection is a conceptually\ndifficult problem when approached using information theory and provide a novel\ndefinition of feature relevancy and redundancy in PID terms. From this\ndefinition, we show that the conditional mutual information (CMI) maximizes\nrelevancy while minimizing redundancy and propose an iterative, CMI-based\nalgorithm for practical feature selection. We demonstrate the power of our\nCMI-based algorithm in comparison to the unconditional mutual information on\nbenchmark examples and provide corresponding PID estimates to highlight how PID\nallows to quantify information contribution of features and their interactions\nin feature-selection problems.",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Patricia Wollstadt",
      "Sebastian Schmitt",
      "Michael Wibral"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04187"
  },
  {
    "id": "arXiv:2105.04194",
    "title": "The Modulo Radon Transform: Theory, Algorithms and Applications",
    "abstract": "Recently, experiments have been reported where researchers were able to\nperform high dynamic range (HDR) tomography in a heuristic fashion, by fusing\nmultiple tomographic projections. This approach to HDR tomography has been\ninspired by HDR photography and inherits the same disadvantages. Taking a\ncomputational imaging approach to the HDR tomography problem, we here suggest a\nnew model based on the Modulo Radon Transform (MRT), which we rigorously\nintroduce and analyze. By harnessing a joint design between hardware and\nalgorithms, we present a single-shot HDR tomography approach, which to our\nknowledge, is the only approach that is backed by mathematical guarantees.\nOn the hardware front, instead of recording the Radon Transform projections\nthat my potentially saturate, we propose to measure modulo values of the same.\nThis ensures that the HDR measurements are folded into a lower dynamic range.\nOn the algorithmic front, our recovery algorithms reconstruct the HDR images\nfrom folded measurements. Beyond mathematical aspects such as injectivity and\ninversion of the MRT for different scenarios including band-limited and\napproximately compactly supported images, we also provide a first\nproof-of-concept demonstration. To do so, we implement MRT by experimentally\nfolding tomographic measurements available as an open source data set using our\ncustom designed modulo hardware. Our reconstruction clearly shows the\nadvantages of our approach for experimental data. In this way, our MRT based\nsolution paves a path for HDR acquisition in a number of related imaging\nproblems.",
    "descriptor": "\nComments: 32 pages, submitted for possible publication\n",
    "authors": [
      "Matthias Beckmann",
      "Ayush Bhandari",
      "Felix Krahmer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04194"
  },
  {
    "id": "arXiv:2105.04201",
    "title": "REPT: Bridging Language Models and Machine Reading Comprehensionvia  Retrieval-Based Pre-training",
    "abstract": "Pre-trained Language Models (PLMs) have achieved great success on Machine\nReading Comprehension (MRC) over the past few years. Although the general\nlanguage representation learned from large-scale corpora does benefit MRC, the\npoor support in evidence extraction which requires reasoning across multiple\nsentences hinders PLMs from further advancing MRC. To bridge the gap between\ngeneral PLMs and MRC, we present REPT, a REtrieval-based Pre-Training approach.\nIn particular, we introduce two self-supervised tasks to strengthen evidence\nextraction during pre-training, which is further inherited by downstream MRC\ntasks through the consistent retrieval operation and model architecture. To\nevaluate our proposed method, we conduct extensive experiments on five MRC\ndatasets that require collecting evidence from and reasoning across multiple\nsentences. Experimental results demonstrate the effectiveness of our\npre-training approach. Moreover, further analysis shows that our approach is\nable to enhance the capacity of evidence extraction without explicit\nsupervision.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Fangkai Jiao",
      "Yangyang Guo",
      "Yilin Niu",
      "Feng Ji",
      "Feng-Lin Li",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04201"
  },
  {
    "id": "arXiv:2105.04206",
    "title": "You Only Learn One Representation: Unified Network for Multiple Tasks",
    "abstract": "People ``understand'' the world via vision, hearing, tactile, and also the\npast experience. Human experience can be learned through normal learning (we\ncall it explicit knowledge), or subconsciously (we call it implicit knowledge).\nThese experiences learned through normal learning or subconsciously will be\nencoded and stored in the brain. Using these abundant experience as a huge\ndatabase, human beings can effectively process data, even they were unseen\nbeforehand. In this paper, we propose a unified network to encode implicit\nknowledge and explicit knowledge together, just like the human brain can learn\nknowledge from normal learning as well as subconsciousness learning. The\nunified network can generate a unified representation to simultaneously serve\nvarious tasks. We can perform kernel space alignment, prediction refinement,\nand multi-task learning in a convolutional neural network. The results\ndemonstrate that when implicit knowledge is introduced into the neural network,\nit benefits the performance of all tasks. We further analyze the implicit\nrepresentation learnt from the proposed unified network, and it shows great\ncapability on catching the physical meaning of different tasks. The source code\nof this work is at : https://github.com/WongKinYiu/yolor.",
    "descriptor": "",
    "authors": [
      "Chien-Yao Wang",
      "I-Hau Yeh",
      "Hong-Yuan Mark Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04206"
  },
  {
    "id": "arXiv:2105.04208",
    "title": "Action Shuffling for Weakly Supervised Temporal Localization",
    "abstract": "Weakly supervised action localization is a challenging task with extensive\napplications, which aims to identify actions and the corresponding temporal\nintervals with only video-level annotations available. This paper analyzes the\norder-sensitive and location-insensitive properties of actions, and embodies\nthem into a self-augmented learning framework to improve the weakly supervised\naction localization performance. To be specific, we propose a novel two-branch\nnetwork architecture with intra/inter-action shuffling, referred to as\nActShufNet. The intra-action shuffling branch lays out a self-supervised order\nprediction task to augment the video representation with inner-video relevance,\nwhereas the inter-action shuffling branch imposes a reorganizing strategy on\nthe existing action contents to augment the training set without resorting to\nany external resources. Furthermore, the global-local adversarial training is\npresented to enhance the model's robustness to irrelevant noises. Extensive\nexperiments are conducted on three benchmark datasets, and the results clearly\ndemonstrate the efficacy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiao-Yu Zhang",
      "Haichao Shi",
      "Changsheng Li",
      "Xinchu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04208"
  },
  {
    "id": "arXiv:2105.04210",
    "title": "Robust Graph Learning Under Wasserstein Uncertainty",
    "abstract": "Graphs are playing a crucial role in different fields since they are powerful\ntools to unveil intrinsic relationships among signals. In many scenarios, an\naccurate graph structure representing signals is not available at all and that\nmotivates people to learn a reliable graph structure directly from observed\nsignals. However, in real life, it is inevitable that there exists uncertainty\nin the observed signals due to noise measurements or limited observability,\nwhich causes a reduction in reliability of the learned graph. To this end, we\npropose a graph learning framework using Wasserstein distributionally robust\noptimization (WDRO) which handles uncertainty in data by defining an\nuncertainty set on distributions of the observed data. Specifically, two models\nare developed, one of which assumes all distributions in uncertainty set are\nGaussian distributions and the other one has no prior distributional\nassumption. Instead of using interior point method directly, we propose two\nalgorithms to solve the corresponding models and show that our algorithms are\nmore time-saving. In addition, we also reformulate both two models into\nSemi-Definite Programming (SDP), and illustrate that they are intractable in\nthe scenario of large-scale graph. Experiments on both synthetic and real world\ndata are carried out to validate the proposed framework, which show that our\nscheme can learn a reliable graph in the context of uncertainty.",
    "descriptor": "\nComments: 21 pages,9 figures\n",
    "authors": [
      "Xiang Zhang",
      "Yinfei Xu",
      "Qinghe Liu",
      "Zhicheng Liu",
      "Jian Lu",
      "Qiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04210"
  },
  {
    "id": "arXiv:2105.04212",
    "title": "Efficient Error-Correcting-Code Mechanism for High-Throughput Memristive  Processing-in-Memory",
    "abstract": "Inefficient data transfer between computation and memory inspired emerging\nprocessing-in-memory (PIM) technologies. Many PIM solutions enable storage and\nprocessing using memristors in a crossbar-array structure, with techniques such\nas memristor-aided logic (MAGIC) used for computation. This approach provides\nhighly-paralleled logic computation with minimal data movement. However,\nmemristors are vulnerable to soft errors and standard error-correcting-code\n(ECC) techniques are difficult to implement without moving data outside the\nmemory. We propose a novel technique for efficient ECC implementation along\ndiagonals to support reliable computation inside the memory without explicitly\nreading the data. Our evaluation demonstrates an improvement of over eight\norders of magnitude in reliability (mean time to failure) for an increase of\nabout 26% in computation latency.",
    "descriptor": "\nComments: Accepted to 58th Design Automation Conference (DAC) 2021\n",
    "authors": [
      "Orian Leitersdorf",
      "Ben Perach",
      "Ronny Ronen",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.04212"
  },
  {
    "id": "arXiv:2105.04213",
    "title": "Temporal-Spatial Feature Pyramid for Video Saliency Detection",
    "abstract": "In this paper, we propose a 3D fully convolutional encoder-decoder\narchitecture for video saliency detection, which combines scale, space and time\ninformation for video saliency modeling. The encoder extracts multi-scale\ntemporal-spatial features from the input continuous video frames, and then\nconstructs temporal-spatial feature pyramid through temporal-spatial\nconvolution and top-down feature integration. The decoder performs hierarchical\ndecoding of temporal-spatial features from different scales, and finally\nproduces a saliency map from the integration of multiple video frames. Our\nmodel is simple yet effective, and can run in real time. We perform abundant\nexperiments, and the results indicate that the well-designed structure can\nimprove the precision of video saliency detection significantly. Experimental\nresults on three purely visual video saliency benchmarks and six audio-video\nsaliency benchmarks demonstrate that our method achieves state-of-theart\nperformance.",
    "descriptor": "",
    "authors": [
      "Qinyao Chang",
      "Shiping Zhu",
      "Lanyun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04213"
  },
  {
    "id": "arXiv:2105.04216",
    "title": "Event-LSTM: An Unsupervised and Asynchronous Learning-based  Representation for Event-based Data",
    "abstract": "Event cameras are activity-driven bio-inspired vision sensors, thereby\nresulting in advantages such as sparsity,high temporal resolution, low latency,\nand power consumption. Given the different sensing modality of event camera and\nhigh quality of conventional vision paradigm, event processing is predominantly\nsolved by transforming the sparse and asynchronous events into 2D grid and\nsubsequently applying standard vision pipelines. Despite the promising results\ndisplayed by supervised learning approaches in 2D grid generation, these\napproaches treat the task in supervised manner. Labeled task specific ground\ntruth event data is challenging to acquire. To overcome this limitation, we\npropose Event-LSTM, an unsupervised Auto-Encoder architecture made up of LSTM\nlayers as a promising alternative to learn 2D grid representation from event\nsequence. Compared to competing supervised approaches, ours is a task-agnostic\napproach ideally suited for the event domain, where task specific labeled data\nis scarce. We also tailor the proposed solution to exploit asynchronous nature\nof event stream, which gives it desirable charateristics such as speed\ninvariant and energy-efficient 2D grid generation. Besides, we also push\nstate-of-the-art event de-noising forward by introducing memory into the\nde-noising process. Evaluations on activity recognition and gesture recognition\ndemonstrate that our approach yields improvement over state-of-the-art\napproaches, while providing the flexibilty to learn from unlabelled data.",
    "descriptor": "\nComments: 7 pages, 8 figures, 2 tables\n",
    "authors": [
      "Lakshmi Annamalai",
      "Vignesh Ramanathan",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04216"
  },
  {
    "id": "arXiv:2105.04218",
    "title": "Exploiting Elasticity in Tensor Ranks for Compressing Neural Networks",
    "abstract": "Elasticities in depth, width, kernel size and resolution have been explored\nin compressing deep neural networks (DNNs). Recognizing that the kernels in a\nconvolutional neural network (CNN) are 4-way tensors, we further exploit a new\nelasticity dimension along the input-output channels. Specifically, a novel\nnuclear-norm rank minimization factorization (NRMF) approach is proposed to\ndynamically and globally search for the reduced tensor ranks during training.\nCorrelation between tensor ranks across multiple layers is revealed, and a\ngraceful tradeoff between model size and accuracy is obtained. Experiments then\nshow the superiority of NRMF over the previous non-elastic variational Bayesian\nmatrix factorization (VBMF) scheme.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Jie Ran",
      "Rui Lin",
      "Hayden K.H. So",
      "Graziano Chesi",
      "Ngai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04218"
  },
  {
    "id": "arXiv:2105.04221",
    "title": "Similarities between Arabic Dialects: Investigating Geographical  Proximity",
    "abstract": "The automatic classification of Arabic dialects is an ongoing research\nchallenge, which has been explored in recent work that defines dialects based\non increasingly limited geographic areas like cities and provinces. This paper\nfocuses on a related yet relatively unexplored topic: the effects of the\ngeographical proximity of cities located in Arab countries on their dialectical\nsimilarity. Our work is twofold, reliant on: 1) comparing the textual\nsimilarities between dialects using cosine similarity and 2) measuring the\ngeographical distance between locations. We study MADAR and NADI, two\nestablished datasets with Arabic dialects from many cities and provinces. Our\nresults indicate that cities located in different countries may in fact have\nmore dialectical similarity than cities within the same country, depending on\ntheir geographical proximity. The correlation between dialectical similarity\nand city proximity suggests that cities that are closer together are more\nlikely to share dialectical attributes, regardless of country borders. This\nnuance provides the potential for important advancements in Arabic dialect\nresearch because it indicates that a more granular approach to dialect\nclassification is essential to understanding how to frame the problem of Arabic\ndialects identification.",
    "descriptor": "",
    "authors": [
      "Abdulkareem Alsudais",
      "Wafa Alotaibi",
      "Faye Alomary"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04221"
  },
  {
    "id": "arXiv:2105.04222",
    "title": "Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue State  Tracking",
    "abstract": "Zero-shot cross-domain dialogue state tracking (DST) enables us to handle\ntask-oriented dialogue in unseen domains without the expense of collecting\nin-domain data. In this paper, we propose a slot description enhanced\ngenerative approach for zero-shot cross-domain DST. Specifically, our model\nfirst encodes dialogue context and slots with a pre-trained self-attentive\nencoder, and generates slot values in an auto-regressive manner. In addition,\nwe incorporate Slot Type Informed Descriptions that capture the shared\ninformation across slots to facilitate cross-domain knowledge transfer.\nExperimental results on the MultiWOZ dataset show that our proposed method\nsignificantly improves existing state-of-the-art results in the zero-shot\ncross-domain setting.",
    "descriptor": "\nComments: NAACL 2021\n",
    "authors": [
      "Zhaojiang Lin",
      "Bing Liu",
      "Seungwhan Moon",
      "Paul Crook",
      "Zhenpeng Zhou",
      "Zhiguang Wang",
      "Zhou Yu",
      "Andrea Madotto",
      "Eunjoon Cho",
      "Rajen Subba"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04222"
  },
  {
    "id": "arXiv:2105.04228",
    "title": "Exact asymptotic characterisation of running time for approximate  gradient descent on random graphs",
    "abstract": "In this work we study the time complexity for the search of local minima in\nrandom graphs whose vertices have i.i.d. cost values. We show that, for\nErd\\\"os-R\\'enyi graphs with connection probability given by $\\lambda/n^\\alpha$\n(with $\\lambda > 0$ and $0 < \\alpha < 1$), a family of local algorithms that\napproximate a gradient descent find local minima faster than the full gradient\ndescent. Furthermore, we find a probabilistic representation for the running\ntime of these algorithms leading to asymptotic estimates of the mean running\ntimes.",
    "descriptor": "",
    "authors": [
      "Matthieu Jonckheere",
      "Manuel S\u00e1enz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.04228"
  },
  {
    "id": "arXiv:2105.04232",
    "title": "De-homogenization using Convolutional Neural Networks",
    "abstract": "This paper presents a deep learning-based de-homogenization method for\nstructural compliance minimization. By using a convolutional neural network to\nparameterize the mapping from a set of lamination parameters on a coarse mesh\nto a one-scale design on a fine mesh, we avoid solving the least square\nproblems associated with traditional de-homogenization approaches and save time\ncorrespondingly. To train the neural network, a two-step custom loss function\nhas been developed which ensures a periodic output field that follows the local\nlamination orientations. A key feature of the proposed method is that the\ntraining is carried out without any use of or reference to the underlying\nstructural optimization problem, which renders the proposed method robust and\ninsensitive wrt. domain size, boundary conditions, and loading. A\npost-processing procedure utilizing a distance transform on the output field\nskeleton is used to project the desired lamination widths onto the output field\nwhile ensuring a predefined minimum length-scale and volume fraction. To\ndemonstrate that the deep learning approach has excellent generalization\nproperties, numerical examples are shown for several different load and\nboundary conditions. For an appropriate choice of parameters, the\nde-homogenized designs perform within $7-25\\%$ of the homogenization-based\nsolution at a fraction of the computational cost. With several options for\nfurther improvements, the scheme may provide the basis for future interactive\nhigh-resolution topology optimization.",
    "descriptor": "\nComments: 28 pages, 16 figures\n",
    "authors": [
      "Martin O. Elingaard",
      "Niels Aage",
      "J. Andreas B\u00e6rentzen",
      "Ole Sigmund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04232"
  },
  {
    "id": "arXiv:2105.04236",
    "title": "SIRNN: A Math Library for Secure RNN Inference",
    "abstract": "Complex machine learning (ML) inference algorithms like recurrent neural\nnetworks (RNNs) use standard functions from math libraries like exponentiation,\nsigmoid, tanh, and reciprocal of square root. Although prior work on secure\n2-party inference provides specialized protocols for convolutional neural\nnetworks (CNNs), existing secure implementations of these math operators rely\non generic 2-party computation (2PC) protocols that suffer from high\ncommunication. We provide new specialized 2PC protocols for math functions that\ncrucially rely on lookup-tables and mixed-bitwidths to address this performance\noverhead; our protocols for math functions communicate up to 423x less data\nthan prior work. Some of the mixed bitwidth operations used by our math\nimplementations are (zero and signed) extensions, different forms of\ntruncations, multiplication of operands of mixed-bitwidths, and digit\ndecomposition (a generalization of bit decomposition to larger digits). For\neach of these primitive operations, we construct specialized 2PC protocols that\nare more communication efficient than generic 2PC, and can be of independent\ninterest. Furthermore, our math implementations are numerically precise, which\nensures that the secure implementations preserve model accuracy of cleartext.\nWe build on top of our novel protocols to build SIRNN, a library for end-to-end\nsecure 2-party DNN inference, that provides the first secure implementations of\nan RNN operating on time series sensor data, an RNN operating on speech data,\nand a state-of-the-art ML architecture that combines CNNs and RNNs for\nidentifying all heads present in images. Our evaluation shows that SIRNN\nachieves up to three orders of magnitude of performance improvement when\ncompared to inference of these models using an existing state-of-the-art 2PC\nframework.",
    "descriptor": "\nComments: IEEE Security and Privacy 2021\n",
    "authors": [
      "Deevashwer Rathee",
      "Mayank Rathee",
      "Rahul Kranti Kiran Goli",
      "Divya Gupta",
      "Rahul Sharma",
      "Nishanth Chandran",
      "Aseem Rastogi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2105.04236"
  },
  {
    "id": "arXiv:2105.04240",
    "title": "A rigorous introduction for linear models",
    "abstract": "This note is meant to provide an introduction to linear models and the\ntheories behind them. Our goal is to give a rigorous introduction to the\nreaders with prior exposure to ordinary least squares. In machine learning, the\noutput is usually a nonlinear function of the input. Deep learning even aims to\nfind a nonlinear dependence with many layers which require a large amount of\ncomputation. However, most of these algorithms build upon simple linear models.\nWe then describe linear models from different views and find the properties and\ntheories behind the models. The linear model is the main technique in\nregression problems and the primary tool for it is the least squares\napproximation which minimizes a sum of squared errors. This is a natural choice\nwhen we're interested in finding the regression function which minimizes the\ncorresponding expected squared error. We first describe ordinary least squares\nfrom three different points of view upon which we disturb the model with random\nnoise and Gaussian noise. By Gaussian noise, the model gives rise to the\nlikelihood so that we introduce a maximum likelihood estimator. It also\ndevelops some distribution theories for it via this Gaussian disturbance. The\ndistribution theory of least squares will help us answer various questions and\nintroduce related applications. We then prove least squares is the best\nunbiased linear model in the sense of mean squared error and most importantly,\nit actually approaches the theoretical limit. We end up with linear models with\nthe Bayesian approach and beyond.",
    "descriptor": "",
    "authors": [
      "Jun Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04240"
  },
  {
    "id": "arXiv:2105.04241",
    "title": "ReadTwice: Reading Very Large Documents with Memories",
    "abstract": "Knowledge-intensive tasks such as question answering often require\nassimilating information from different sections of large inputs such as books\nor article collections. We propose ReadTwuce, a simple and effective technique\nthat combines several strengths of prior approaches to model long-range\ndependencies with Transformers. The main idea is to read text in small\nsegments, in parallel, summarizing each segment into a memory table to be used\nin a second read of the text. We show that the method outperforms models of\ncomparable size on several question answering (QA) datasets and sets a new\nstate of the art on the challenging NarrativeQA task, with questions about\nentire books. Source code and pre-trained checkpoints for ReadTwice can be\nfound at https://goo.gle/research-readtwice.",
    "descriptor": "\nComments: To appear in the proceedings of NAACL 2021\n",
    "authors": [
      "Yury Zemlyanskiy",
      "Joshua Ainslie",
      "Michiel de Jong",
      "Philip Pham",
      "Ilya Eckstein",
      "Fei Sha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04241"
  },
  {
    "id": "arXiv:2105.04244",
    "title": "Overcoming the Distance Estimation Bottleneck in Camera Trap Distance  Sampling",
    "abstract": "Biodiversity crisis is still accelerating. Estimating animal abundance is of\ncritical importance to assess, for example, the consequences of land-use change\nand invasive species on species composition, or the effectiveness of\nconservation interventions. Camera trap distance sampling (CTDS) is a recently\ndeveloped monitoring method providing reliable estimates of wildlife population\ndensity and abundance. However, in current applications of CTDS, the required\ncamera-to-animal distance measurements are derived by laborious, manual and\nsubjective estimation methods. To overcome this distance estimation bottleneck\nin CTDS, this study proposes a completely automatized workflow utilizing\nstate-of-the-art methods of image processing and pattern recognition.",
    "descriptor": "",
    "authors": [
      "Timm Haucke",
      "Hjalmar S. K\u00fchl",
      "Jacqueline Hoyer",
      "Volker Steinhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04244"
  },
  {
    "id": "arXiv:2105.04246",
    "title": "In-Hindsight Quantization Range Estimation for Quantized Training",
    "abstract": "Quantization techniques applied to the inference of deep neural networks have\nenabled fast and efficient execution on resource-constraint devices. The\nsuccess of quantization during inference has motivated the academic community\nto explore fully quantized training, i.e. quantizing back-propagation as well.\nHowever, effective gradient quantization is still an open problem. Gradients\nare unbounded and their distribution changes significantly during training,\nwhich leads to the need for dynamic quantization. As we show, dynamic\nquantization can lead to significant memory overhead and additional data\ntraffic slowing down training. We propose a simple alternative to dynamic\nquantization, in-hindsight range estimation, that uses the quantization ranges\nestimated on previous iterations to quantize the present. Our approach enables\nfast static quantization of gradients and activations while requiring only\nminimal hardware support from the neural network accelerator to keep track of\noutput statistics in an online fashion. It is intended as a drop-in replacement\nfor estimating quantization ranges and can be used in conjunction with other\nadvances in quantized training. We compare our method to existing methods for\nrange estimation from the quantized training literature and demonstrate its\neffectiveness with a range of architectures, including MobileNetV2, on image\nclassification benchmarks (Tiny ImageNet & ImageNet).",
    "descriptor": "",
    "authors": [
      "Marios Fournarakis",
      "Markus Nagel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04246"
  },
  {
    "id": "arXiv:2105.04247",
    "title": "Expressivity of Parameterized and Data-driven Representations in Quality  Diversity Search",
    "abstract": "We consider multi-solution optimization and generative models for the\ngeneration of diverse artifacts and the discovery of novel solutions. In cases\nwhere the domain's factors of variation are unknown or too complex to encode\nmanually, generative models can provide a learned latent space to approximate\nthese factors. When used as a search space, however, the range and diversity of\npossible outputs are limited to the expressivity and generative capabilities of\nthe learned model. We compare the output diversity of a quality diversity\nevolutionary search performed in two different search spaces: 1) a predefined\nparameterized space and 2) the latent space of a variational autoencoder model.\nWe find that the search on an explicit parametric encoding creates more diverse\nartifact sets than searching the latent space. A learned model is better at\ninterpolating between known data points than at extrapolating or expanding\ntowards unseen examples. We recommend using a generative model's latent space\nprimarily to measure similarity between artifacts rather than for search and\ngeneration. Whenever a parametric encoding is obtainable, it should be\npreferred over a learned representation as it produces a higher diversity of\nsolutions.",
    "descriptor": "\nComments: For code for reproducing experiments, see this https URL\n",
    "authors": [
      "Alexander Hagg",
      "Sebastian Berns",
      "Alexander Asteroth",
      "Simon Colton",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04247"
  },
  {
    "id": "arXiv:2105.04249",
    "title": "Accounting for Model Uncertainty in Algorithmic Discrimination",
    "abstract": "Traditional approaches to ensure group fairness in algorithmic decision\nmaking aim to equalize ``total'' error rates for different subgroups in the\npopulation. In contrast, we argue that the fairness approaches should instead\nfocus only on equalizing errors arising due to model uncertainty (a.k.a\nepistemic uncertainty), caused due to lack of knowledge about the best model or\ndue to lack of data. In other words, our proposal calls for ignoring the errors\nthat occur due to uncertainty inherent in the data, i.e., aleatoric\nuncertainty. We draw a connection between predictive multiplicity and model\nuncertainty and argue that the techniques from predictive multiplicity could be\nused to identify errors made due to model uncertainty. We propose scalable\nconvex proxies to come up with classifiers that exhibit predictive multiplicity\nand empirically show that our methods are comparable in performance and up to\nfour orders of magnitude faster than the current state-of-the-art. We further\npropose methods to achieve our goal of equalizing group error rates arising due\nto model uncertainty in algorithmic decision making and demonstrate the\neffectiveness of these methods using synthetic and real-world datasets.",
    "descriptor": "\nComments: 12 pages, Accepted at AIES 2021\n",
    "authors": [
      "Junaid Ali",
      "Preethi Lahoti",
      "Krishna P. Gummadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04249"
  },
  {
    "id": "arXiv:2105.04250",
    "title": "Expressing and Exploiting the Common Subgoal Structure of Classical  Planning Domains Using Sketches: Extended Version",
    "abstract": "Width-based planning methods exploit the use of conjunctive goals for\ndecomposing problems into subproblems of low width. However, algorithms like\nSIW fail when the goal is not serializable. In this work, we address this\nlimitation of SIW by using a simple but powerful language for expressing\nproblem decompositions introduced recently by Bonet and Geffner, called policy\nsketches. A policy sketch R consists of a set of Boolean and numerical features\nand a set of sketch rules that express how the values of these features are\nsupposed to change. Like general policies, policy sketches are domain general,\nbut unlike policies, the changes captured by sketch rules do not need to be\nachieved in a single step. We show that many planning domains that cannot be\nsolved by SIW are provably solvable in low polynomial time with the SIW_R\nalgorithm, the version of SIW that employs user-provided policy sketches.\nPolicy sketches are thus shown to be a powerful language for expressing\ndomain-specific knowledge in a simple and compact way and a convenient\nalternative to languages such as HTNs or temporal logics. Furthermore, policy\nsketches make it easy to express general problem decompositions and prove key\nproperties like their complexity and width.",
    "descriptor": "",
    "authors": [
      "Dominik Drexler",
      "Jendrik Seipp",
      "Hector Geffner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04250"
  },
  {
    "id": "arXiv:2105.04252",
    "title": "An Analysis of Phenotypic Diversity in Multi-Solution Optimization",
    "abstract": "More and more, optimization methods are used to find diverse solution sets.\nWe compare solution diversity in multi-objective optimization, multimodal\noptimization, and quality diversity in a simple domain. We show that\nmultiobjective optimization does not always produce much diversity, multimodal\noptimization produces higher fitness solutions, and quality diversity is not\nsensitive to genetic neutrality and creates the most diverse set of solutions.\nAn autoencoder is used to discover phenotypic features automatically, producing\nan even more diverse solution set with quality diversity. Finally, we make\nrecommendations about when to use which approach.",
    "descriptor": "",
    "authors": [
      "Alexander Hagg",
      "Mike Preuss",
      "Alexander Asteroth",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04252"
  },
  {
    "id": "arXiv:2105.04253",
    "title": "Tilling of Constellations",
    "abstract": "Motivated by applications in reliable and secure communication, we address\nthe problem of tiling (or partitioning) a finite constellation in\n$\\mathbb{Z}_{2^L}^n$ by subsets, in the case that the constellation does not\npossess an abelian group structure. The property that we do require is that the\nconstellation is generated by a linear code through an injective mapping. The\nintrinsic relation between the code and the constellation provides a sufficient\ncondition for a tiling to exist. We also present a necessary condition.\nInspired by a result in group theory, we discuss results on tiling for the\nparticular case when the finer constellation is an abelian group as well.",
    "descriptor": "",
    "authors": [
      "Maiara F. Bollauf",
      "\u00d8yvind Ytrehus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04253"
  },
  {
    "id": "arXiv:2105.04256",
    "title": "Designing Air Flow with Surrogate-assisted Phenotypic Niching",
    "abstract": "In complex, expensive optimization domains we often narrowly focus on finding\nhigh performing solutions, instead of expanding our understanding of the domain\nitself. But what if we could quickly understand the complex behaviors that can\nemerge in said domains instead? We introduce surrogate-assisted phenotypic\nniching, a quality diversity algorithm which allows to discover a large,\ndiverse set of behaviors by using computationally expensive phenotypic\nfeatures. In this work we discover the types of air flow in a 2D fluid dynamics\noptimization problem. A fast GPU-based fluid dynamics solver is used in\nconjunction with surrogate models to accurately predict fluid characteristics\nfrom the shapes that produce the air flow. We show that these features can be\nmodeled in a data-driven way while sampling to improve performance, rather than\nexplicitly sampling to improve feature models. Our method can reduce the need\nto run an infeasibly large set of simulations while still being able to design\na large diversity of air flows and the shapes that cause them. Discovering\ndiversity of behaviors helps engineers to better understand expensive domains\nand their solutions.",
    "descriptor": "",
    "authors": [
      "Alexander Hagg",
      "Dominik Wilde",
      "Alexander Asteroth",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04256"
  },
  {
    "id": "arXiv:2105.04260",
    "title": "EPICTWIN: An Electric Power Digital Twin for Cyber Security Testing,  Research and Education",
    "abstract": "Cyber-Physical Systems (CPS) rely on advanced communication and control\ntechnologies to efficiently manage devices and the flow of information in the\nsystem. However, a wide variety of potential security challenges has emerged\ndue to the evolution of critical infrastructures (CI) from siloed sub-systems\ninto connected and integrated networks. This is also the case for CI such as a\nsmart grid. Smart grid security studies are carried out on physical test-beds\nto provide its users a platform to train and test cyber attacks, in a safe and\ncontrolled environment. However, it has limitations w.r.t modifying physical\nconfiguration and difficulty to scale.\nTo overcome these shortcomings, we built a digital power twin for a physical\ntest-bed that is used for cyber security studies on smart grids. On the\ndeveloped twin, the users can deploy real world attacks and countermeasures, to\ntest and study its effectiveness. The difference from the physical test-bed is\nthat its users may easily modify their power system components and\nconfigurations. Further, reproducing the twin for using and advancing the\nresearch is significantly cheaper. The developed twin has advanced features\ncompared to any equivalent system in the literature. To illustrate a typical\nuse case, we present a case study where a cyber attack is launched and discuss\nits implications.",
    "descriptor": "",
    "authors": [
      "Nandha Kumar Kandasamy",
      "Sarad Venugopalan",
      "Tin Kit Wong",
      "Leu Junming Nicholas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04260"
  },
  {
    "id": "arXiv:2105.04261",
    "title": "Neuroscience-inspired perception-action in robotics: applying active  inference for state estimation, control and self-perception",
    "abstract": "Unlike robots, humans learn, adapt and perceive their bodies by interacting\nwith the world. Discovering how the brain represents the body and generates\nactions is of major importance for robotics and artificial intelligence. Here\nwe discuss how neuroscience findings open up opportunities to improve current\nestimation and control algorithms in robotics. In particular, how active\ninference, a mathematical formulation of how the brain resists a natural\ntendency to disorder, provides a unified recipe to potentially solve some of\nthe major challenges in robotics, such as adaptation, robustness, flexibility,\ngeneralization and safe interaction. This paper summarizes some experiments and\nlessons learned from developing such a computational model on real embodied\nplatforms, i.e., humanoid and industrial robots. Finally, we showcase the\nlimitations and challenges that we are still facing to give robots human-like\nperception",
    "descriptor": "\nComments: Accepted at ICLR 2021 Brain2AI workshop\n",
    "authors": [
      "Pablo Lanillos",
      "Marcel van Gerven"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2105.04261"
  },
  {
    "id": "arXiv:2105.04264",
    "title": "Threat Landscape for Smart Grid Systems",
    "abstract": "Smart Grids are energy delivery networks, constituting an evolution of power\ngrids, in which a bidirectional flow between power providers and consumers is\nestablished. These flows support the transfer of electricity and information,\nin order to support automation actions in the context of the energy delivery\nnetwork. Insofar, many smart grid implementations and implementation proposals\nhave emerged, with varying degrees of feature delivery and sophistication.\nWhile smart grids offer many advantages, their distributed nature and\ninformation flow streams between energy producers and consumers enable the\nlaunching of a number of attacks against the smart grid infrastructure, where\nthe related consequences may range from economic loss to complete failure of\nthe smart grid. In this paper, we survey the threat landscape of smart grids,\nidentifying threats that are specific to this infrastructure, providing an\nassessment of the severity of the consequences of each attack type, discerning\nfeatures that can be utilized to detect attacks and listing methods that can be\nused to mitigate them.",
    "descriptor": "",
    "authors": [
      "Christos-Minas Mathas",
      "Konstantinos-Panagiotis Grammatikakis",
      "Costas Vassilakis",
      "Nicholas Kolokotronis",
      "Vasiliki-Georgia Bilali",
      "Dimitris Kavallieros"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04264"
  },
  {
    "id": "arXiv:2105.04266",
    "title": "A Probabilistic Approach to Personalize Type-based Facet Ranking for POI  Suggestion",
    "abstract": "Faceted Search Systems (FSS) have become one of the main search interfaces\nused in vertical search systems, offering users meaningful facets to refine\ntheir search query and narrow down the results quickly to find the intended\nsearch target. This work focuses on the problem of ranking type-based facets.\nIn a structured information space, type-based facets (t-facets) indicate the\ncategory to which each object belongs. When they belong to a large multi-level\ntaxonomy, it is desirable to rank them separately before ranking other facet\ngroups. This helps the searcher in filtering the results according to their\ntype first. This also makes it easier to rank the rest of the facets once the\ntype of the intended search target is selected. Existing research employs the\nsame ranking methods for different facet groups. In this research, we propose a\ntwo-step approach to personalize t-facet ranking. The first step assigns a\nrelevance score to each individual leaf-node t-facet. The score is generated\nusing probabilistic models and it reflects t-facet relevance to the query and\nthe user profile. In the second step, this score is used to re-order and select\nthe sub-tree to present to the user. We investigate the usefulness of the\nproposed method to a Point Of Interest (POI) suggestion task. Our evaluation\naims at capturing the user effort required to fulfil her search needs by using\nthe ranked facets. The proposed approach achieved better results than other\nexisting personalized baselines.",
    "descriptor": "\nComments: Accepted at ICWE 2021\n",
    "authors": [
      "Esraa Ali",
      "Annalina Caputo",
      "S\u00e9amus Lawless",
      "Owen Conlan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04266"
  },
  {
    "id": "arXiv:2105.04271",
    "title": "DocOIE: A Document-level Context-Aware Dataset for OpenIE",
    "abstract": "Open Information Extraction (OpenIE) aims to extract structured relational\ntuples (subject, relation, object) from sentences and plays critical roles for\nmany downstream NLP applications. Existing solutions perform extraction at\nsentence level, without referring to any additional contextual information. In\nreality, however, a sentence typically exists as part of a document rather than\nstandalone; we often need to access relevant contextual information around the\nsentence before we can accurately interpret it. As there is no document-level\ncontext-aware OpenIE dataset available, we manually annotate 800 sentences from\n80 documents in two domains (Healthcare and Transportation) to form a DocOIE\ndataset for evaluation. In addition, we propose DocIE, a novel document-level\ncontext-aware OpenIE model. Our experimental results based on DocIE demonstrate\nthat incorporating document-level context is helpful in improving OpenIE\nperformance. Both DocOIE dataset and DocIE model are released for public.",
    "descriptor": "\nComments: Paper to be appearred at Findings of ACL 2021\n",
    "authors": [
      "Kuicai Dong",
      "Yilin Zhao",
      "Aixin Sun",
      "Jung-Jae Kim",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04271"
  },
  {
    "id": "arXiv:2105.04272",
    "title": "Advanced Metering Infrastructures: Security Risks and Mitigation",
    "abstract": "Energy providers are moving to the smart meter era, encouraging consumers to\ninstall, free of charge, these devices in their homes, automating consumption\nreadings submission and making consumers life easier. However, the increased\ndeployment of such smart devices brings a lot of security and privacy risks. In\norder to overcome such risks, Intrusion Detection Systems are presented as\npertinent tools that can provide network-level protection for smart devices\ndeployed in home environments. In this context, this paper is exploring the\nproblems of Advanced Metering Infrastructures (AMI) and proposing a novel\nMachine Learning (ML) Intrusion Prevention System (IPS) to get optimal\ndecisions based on a variety of factors and graphical security models able to\ntackle zero-day attacks.",
    "descriptor": "",
    "authors": [
      "Gueltoum Bendiab",
      "Konstantinos-Panagiotis Grammatikakis",
      "Ioannis Koufos",
      "Nicholas Kolokotronis",
      "Stavros Shiaeles"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04272"
  },
  {
    "id": "arXiv:2105.04273",
    "title": "Loss-Aversively Fair Classification",
    "abstract": "The use of algorithmic (learning-based) decision making in scenarios that\naffect human lives has motivated a number of recent studies to investigate such\ndecision making systems for potential unfairness, such as discrimination\nagainst subjects based on their sensitive features like gender or race.\nHowever, when judging the fairness of a newly designed decision making system,\nthese studies have overlooked an important influence on people's perceptions of\nfairness, which is how the new algorithm changes the status quo, i.e.,\ndecisions of the existing decision making system. Motivated by extensive\nliterature in behavioral economics and behavioral psychology (prospect theory),\nwe propose a notion of fair updates that we refer to as loss-averse updates.\nLoss-averse updates constrain the updates to yield improved (more beneficial)\noutcomes to subjects compared to the status quo. We propose tractable proxy\nmeasures that would allow this notion to be incorporated in the training of a\nvariety of linear and non-linear classifiers. We show how our proxy measures\ncan be combined with existing measures for training nondiscriminatory\nclassifiers. Our evaluation using synthetic and real-world datasets\ndemonstrates that the proposed proxy measures are effective for their desired\ntasks.",
    "descriptor": "\nComments: 8 pages, Accepted at AIES 2019\n",
    "authors": [
      "Junaid Ali",
      "Muhammad Bilal Zafar",
      "Adish Singla",
      "Krishna P. Gummadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04273"
  },
  {
    "id": "arXiv:2105.04274",
    "title": "Compound Channel Capacities under Energy Constraints and Application",
    "abstract": "Compound channel models offer a simple and straightforward way of analyzing\nthe stability of decoder design under model variations. With this work we\nprovide a coding theorem for a large class of practically relevant compound\nchannel models. We give explicit formulas for the cases of the Gaussian\nclassical-quantum compound channels with unknown noise, unknown phase and\nunknown attenuation. We show analytically how the classical compound channel\ncapacity formula motivates nontrivial choices of the displacement parameter of\nthe Kennedy receiver. Our work demonstrates the value of the compound channel\nmodel as a method for the design of receivers in quantum communication.",
    "descriptor": "\nComments: 6 pages, 1 figure, accepted at ISIT - 2021 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Andrea Cacioppo",
      "Janis N\u00f6tzel",
      "Matteo Rosati"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04274"
  },
  {
    "id": "arXiv:2105.04278",
    "title": "A Rate-Distortion Framework for Characterizing Semantic Information",
    "abstract": "A rate-distortion problem motivated by the consideration of semantic\ninformation is formulated and solved. The starting point is to model an\ninformation source as a pair consisting of an intrinsic state which is not\nobservable, corresponding to the semantic aspect of the source, and an\nextrinsic observation which is subject to lossy source coding. The proposed\nrate-distortion problem seeks a description of the information source, via\nencoding the extrinsic observation, under two distortion constraints, one for\nthe intrinsic state and the other for the extrinsic observation. The\ncorresponding state-observation rate-distortion function is obtained, and a few\ncase studies of Gaussian intrinsic state estimation and binary intrinsic state\nclassification are studied.",
    "descriptor": "\nComments: To appear at ISIT 2021, with an appendix added to include general solution for jointly Gaussian models\n",
    "authors": [
      "Jiakun Liu",
      "Wenyi Zhang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.04278"
  },
  {
    "id": "arXiv:2105.04281",
    "title": "Visual Grounding with Transformers",
    "abstract": "In this paper, we propose a transformer based approach for visual grounding.\nUnlike previous proposal-and-rank frameworks that rely heavily on pretrained\nobject detectors or proposal-free frameworks that upgrade an off-the-shelf\none-stage detector by fusing textual embeddings, our approach is built on top\nof a transformer encoder-decoder and is independent of any pretrained detectors\nor word embedding models. Termed VGTR -- Visual Grounding with TRansformers,\nour approach is designed to learn semantic-discriminative visual features under\nthe guidance of the textual description without harming their location ability.\nThis information flow enables our VGTR to have a strong capability in capturing\ncontext-level semantics of both vision and language modalities, rendering us to\naggregate accurate visual clues implied by the description to locate the\ninterested object instance. Experiments show that our method outperforms\nstate-of-the-art proposal-free approaches by a considerable margin on five\nbenchmarks while maintaining fast inference speed.",
    "descriptor": "",
    "authors": [
      "Ye Du",
      "Zehua Fu",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04281"
  },
  {
    "id": "arXiv:2105.04284",
    "title": "A class of power maps with boomerang uniformity four",
    "abstract": "We give a class of power maps with boomerang uniformity four. Moreover, we\ncompute the differential uniformity of this class of power maps and determine\nits complete differential spectrum. As a consequence, we show that for this\nclass of power maps, the differential uniformity is strictly greater than its\nboomerang uniformity, contrary to popular belief.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sartaj Ul Hasan",
      "Mohit Pal",
      "Pantelimon Stanica"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04284"
  },
  {
    "id": "arXiv:2105.04286",
    "title": "Primitive Representation Learning for Scene Text Recognition",
    "abstract": "Scene text recognition is a challenging task due to diverse variations of\ntext instances in natural scene images. Conventional methods based on\nCNN-RNN-CTC or encoder-decoder with attention mechanism may not fully\ninvestigate stable and efficient feature representations for multi-oriented\nscene texts. In this paper, we propose a primitive representation learning\nmethod that aims to exploit intrinsic representations of scene text images. We\nmodel elements in feature maps as the nodes of an undirected graph. A pooling\naggregator and a weighted aggregator are proposed to learn primitive\nrepresentations, which are transformed into high-level visual text\nrepresentations by graph convolutional networks. A Primitive REpresentation\nlearning Network (PREN) is constructed to use the visual text representations\nfor parallel decoding. Furthermore, by integrating visual text representations\ninto an encoder-decoder model with the 2D attention mechanism, we propose a\nframework called PREN2D to alleviate the misalignment problem in\nattention-based methods. Experimental results on both English and Chinese scene\ntext recognition tasks demonstrate that PREN keeps a balance between accuracy\nand efficiency, while PREN2D achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Ruijie Yan",
      "Liangrui Peng",
      "Shanyu Xiao",
      "Gang Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04286"
  },
  {
    "id": "arXiv:2105.04289",
    "title": "Do Concept Bottleneck Models Learn as Intended?",
    "abstract": "Concept bottleneck models map from raw inputs to concepts, and then from\nconcepts to targets. Such models aim to incorporate pre-specified, high-level\nconcepts into the learning procedure, and have been motivated to meet three\ndesiderata: interpretability, predictability, and intervenability. However, we\nfind that concept bottleneck models struggle to meet these goals. Using post\nhoc interpretability methods, we demonstrate that concepts do not correspond to\nanything semantically meaningful in input space, thus calling into question the\nusefulness of concept bottleneck models in their current form.",
    "descriptor": "\nComments: Accepted at ICLR 2021 Workshop on Responsible AI\n",
    "authors": [
      "Andrei Margeloiu",
      "Matthew Ashman",
      "Umang Bhatt",
      "Yanzhi Chen",
      "Mateja Jamnik",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04289"
  },
  {
    "id": "arXiv:2105.04293",
    "title": "An interactive dashboard for searching and comparing soccer performance  scores",
    "abstract": "The performance of soccer players is one of most discussed aspects by many\nactors in the soccer industry: from supporters to journalists, from coaches to\ntalent scouts. Unfortunately, the dashboards available online provide no\neffective way to compare the evolution of the performance of players or to find\nplayers behaving similarly on the field. This paper describes the design of a\nweb dashboard that interacts via APIs with a performance evaluation algorithm\nand provides graphical tools that allow the user to perform many tasks, such as\nto search or compare players by age, role or trend of growth in their\nperformance, find similar players based on their pitching behavior, change the\nalgorithm's parameters to obtain customized performance scores. We also\ndescribe an example of how a talent scout can interact with the dashboard to\nfind young, promising talents.",
    "descriptor": "\nComments: 4 pages, 6 figures\n",
    "authors": [
      "Paulo Cintia",
      "Giovanni Mauro",
      "Luca Pappalardo",
      "Paolo Ferragina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04293"
  },
  {
    "id": "arXiv:2105.04294",
    "title": "Toward asynchronous EEG-based BCI: Detecting imagined words segments in  continuous EEG signals",
    "abstract": "An asynchronous Brain--Computer Interface (BCI) based on imagined speech is a\ntool that allows to control an external device or to emit a message at the\nmoment the user desires to by decoding EEG signals of imagined speech. In order\nto correctly implement these types of BCI, we must be able to detect from a\ncontinuous signal, when the subject starts to imagine words. In this work, five\nmethods of feature extraction based on wavelet decomposition, empirical mode\ndecomposition, frequency energies, fractal dimension and chaos theory features\nare presented to solve the task of detecting imagined words segments from\ncontinuous EEG signals as a preliminary study for a latter implementation of an\nasynchronous BCI based on imagined speech. These methods are tested in three\ndatasets using four different classifiers and the higher F1 scores obtained are\n0.73, 0.79, and 0.68 for each dataset, respectively. This results are promising\nto build a system that automatizes the segmentation of imagined words segments\nfor latter classification.",
    "descriptor": "\nComments: 10 pages, 14 figures\n",
    "authors": [
      "Tonatiuh Hern\u00e1ndez-Del-Toro",
      "Carlos A. Reyes-Garc\u00eda",
      "Luis Villase\u00f1or-Pineda"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04294"
  },
  {
    "id": "arXiv:2105.04295",
    "title": "PyPlutchik: visualising and comparing emotion-annotated corpora",
    "abstract": "The increasing availability of textual corpora and data fetched from social\nnetworks is fuelling a huge production of works based on the model proposed by\npsychologist Robert Plutchik, often referred simply as the ``Plutchik Wheel''.\nRelated researches range from annotation tasks description to emotions\ndetection tools. Visualisation of such emotions is traditionally carried out\nusing the most popular layouts, as bar plots or tables, which are however\nsub-optimal. The classic representation of the Plutchik's wheel follows the\nprinciples of proximity and opposition between pairs of emotions: spatial\nproximity in this model is also a semantic proximity, as adjacent emotions\nelicit a complex emotion (a primary dyad) when triggered together; spatial\nopposition is a semantic opposition as well, as positive emotions are opposite\nto negative emotions. The most common layouts fail to preserve both features,\nnot to mention the need of visually allowing comparisons between different\ncorpora in a blink of an eye, that is hard with basic design solutions. We\nintroduce PyPlutchik, a Python library specifically designed for the\nvisualisation of Plutchik's emotions in texts or in corpora. PyPlutchik draws\nthe Plutchik's flower with each emotion petal sized after how much that emotion\nis detected or annotated in the corpus, also representing three degrees of\nintensity for each of them. Notably, PyPlutchik allows users to display also\nprimary, secondary, tertiary and opposite dyads in a compact, intuitive way. We\nsubstantiate our claim that PyPlutchik outperforms other classic visualisations\nwhen displaying Plutchik emotions and we showcase a few examples that display\nour library's most compelling features.",
    "descriptor": "\nComments: 18 pages, 13 figures. Submitted to IEEE for possible publication; copyright may change\n",
    "authors": [
      "Alfonso Semeraro",
      "Salvatore Vilella",
      "Giancarlo Ruffo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04295"
  },
  {
    "id": "arXiv:2105.04297",
    "title": "How could Neural Networks understand Programs?",
    "abstract": "Semantic understanding of programs is a fundamental problem for programming\nlanguage processing (PLP). Recent works that learn representations of code\nbased on pre-training techniques in NLP have pushed the frontiers in this\ndirection. However, the semantics of PL and NL have essential differences.\nThese being ignored, we believe it is difficult to build a model to better\nunderstand programs, by either directly applying off-the-shelf NLP pre-training\ntechniques to the source code, or adding features to the model by the\nheuristic. In fact, the semantics of a program can be rigorously defined by\nformal semantics in PL theory. For example, the operational semantics,\ndescribes the meaning of a valid program as updating the environment (i.e., the\nmemory address-value function) through fundamental operations, such as memory\nI/O and conditional branching. Inspired by this, we propose a novel program\nsemantics learning paradigm, that the model should learn from information\ncomposed of (1) the representations which align well with the fundamental\noperations in operational semantics, and (2) the information of environment\ntransition, which is indispensable for program understanding. To validate our\nproposal, we present a hierarchical Transformer-based pre-training model called\nOSCAR to better facilitate the understanding of programs. OSCAR learns from\nintermediate representation (IR) and an encoded representation derived from\nstatic analysis, which are used for representing the fundamental operations and\napproximating the environment transitions respectively. OSCAR empirically shows\nthe outstanding capability of program semantics understanding on many practical\nsoftware engineering tasks.",
    "descriptor": "",
    "authors": [
      "Dinglan Peng",
      "Shuxin Zheng",
      "Yatao Li",
      "Guolin Ke",
      "Di He",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04297"
  },
  {
    "id": "arXiv:2105.04301",
    "title": "ADASYN-Random Forest Based Intrusion Detection Model",
    "abstract": "Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using ADASYN oversampling method to balance datasets was proposed\nin this paper. In addition, random forest algorithm was used to train intrusion\ndetection classifiers. Through the comparative experiment of Intrusion\ndetection on CICIDS 2017 dataset, it is found that ADASYN with Random Forest\nperforms better. Based on the experimental results, the improvement of\nprecision, recall and F1 values after ADASYN is then analyzed. Experiments show\nthat the proposed method can be applied to intrusion detection with large data,\nand can effectively improve the classification accuracy of network attack\nbehaviors. Compared with traditional machine learning models, it has better\nperformance, generalization ability and robustness.",
    "descriptor": "",
    "authors": [
      "Zhewei Chen",
      "Linyue Zhou",
      "Wenwen Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04301"
  },
  {
    "id": "arXiv:2105.04302",
    "title": "Video Anomaly Detection By The Duality Of Normality-Granted Optical Flow",
    "abstract": "Video anomaly detection is a challenging task because of diverse abnormal\nevents. To this task, methods based on reconstruction and prediction are wildly\nused in recent works, which are built on the assumption that learning on normal\ndata, anomalies cannot be reconstructed or predicated as good as normal\npatterns, namely the anomaly result with more errors. In this paper, we propose\nto discriminate anomalies from normal ones by the duality of normality-granted\noptical flow, which is conducive to predict normal frames but adverse to\nabnormal frames. The normality-granted optical flow is predicted from a single\nframe, to keep the motion knowledge focused on normal patterns. Meanwhile, We\nextend the appearance-motion correspondence scheme from frame reconstruction to\nprediction, which not only helps to learn the knowledge about object\nappearances and correlated motion, but also meets the fact that motion is the\ntransformation between appearances. We also introduce a margin loss to enhance\nthe learning of frame prediction. Experiments on standard benchmark datasets\ndemonstrate the impressive performance of our approach.",
    "descriptor": "",
    "authors": [
      "Hongyong Wang",
      "Xinjian Zhang",
      "Su Yang",
      "Weishan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04302"
  },
  {
    "id": "arXiv:2105.04308",
    "title": "Parallel Sandpiles or Spurious Bidirectional Icepiles?",
    "abstract": "In a recent paper E. Formenti and K. Perrot (FP) introduce a global rule\nassumed to describe the discrete time dynamics associated with a sandpile model\nunder the parallel application of a suitable local rule acting on d dimensional\nlattices of cells equipped with uniform neighborhood. In this paper we submit\nthis approach to a critical analysis, in the simplest elementary particular\ncase of a one-dimensional lattice, which can be divided in two parts. In the\nfirst part we prove that the FP global rule does not describe the dynamics of\nstandard sandpiles, but rather furnishes a description of the quite different\nsituation of height difference between consecutive piles. This is a semantic\nuncorrect difference of interpretation. In the second part we investigate the\nconsequences of the uncorrect FP assumption proving that their global rule\ndescribes a bidirectional spurious dynamics of icepiles (rather than\nsandpiles), in the sense that this latter is the consequence of application of\nthree local rules: bidirectional vertical rule, bidirectional horizontal rule\n(typical of icepiles), and a granule jump from the bottom to the top (spurious\nrule of the dynamics).",
    "descriptor": "",
    "authors": [
      "Gianpiero Cattaneo",
      "Luca Manzoni"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.04308"
  },
  {
    "id": "arXiv:2105.04309",
    "title": "Multi-modal Conditional Bounding Box Regression for Music Score  Following",
    "abstract": "This paper addresses the problem of sheet-image-based on-line audio-to-score\nalignment also known as score following. Drawing inspiration from object\ndetection, a conditional neural network architecture is proposed that directly\npredicts x,y coordinates of the matching positions in a complete score sheet\nimage at each point in time for a given musical performance. Experiments are\nconducted on a synthetic polyphonic piano benchmark dataset and the new method\nis compared to several existing approaches from the literature for\nsheet-image-based score following as well as an Optical Music Recognition\nbaseline. The proposed approach achieves new state-of-the-art results and\nfurthermore significantly improves the alignment performance on a set of\nreal-world piano recordings by applying Impulse Responses as a data\naugmentation technique.",
    "descriptor": "\nComments: Accepted for publication in the Proceedings of the 29th European Signal Processing Conference (EUSIPCO), Dublin, Ireland, 2021\n",
    "authors": [
      "Florian Henkel",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04309"
  },
  {
    "id": "arXiv:2105.04311",
    "title": "Overcoming Complexity Catastrophe: An Algorithm for Beneficial  Far-Reaching Adaptation under High Complexity",
    "abstract": "In his seminal work with NK algorithms, Kauffman noted that fitness outcomes\nfrom algorithms navigating an NK landscape show a sharp decline at high\ncomplexity arising from pervasive interdependence among problem dimensions.\nThis phenomenon - where complexity effects dominate (Darwinian) adaptation\nefforts - is called complexity catastrophe. We present an algorithm -\nincremental change taking turns (ICTT) - that finds distant configurations\nhaving fitness superior to that reported in extant research, under high\ncomplexity. Thus, complexity catastrophe is not inevitable: a series of\nincremental changes can lead to excellent outcomes.",
    "descriptor": "\nComments: 10 pages, 5 Figures\n",
    "authors": [
      "Sasanka Sekhar Chanda",
      "Sai Yayavaram"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2105.04311"
  },
  {
    "id": "arXiv:2105.04313",
    "title": "DocReader: Bounding-Box Free Training of a Document Information  Extraction Model",
    "abstract": "Information extraction from documents is a ubiquitous first step in many\nbusiness applications. During this step, the entries of various fields must\nfirst be read from the images of scanned documents before being further\nprocessed and inserted into the corresponding databases. While many different\nmethods have been developed over the past years in order to automate the above\nextraction step, they all share the requirement of bounding-box or text segment\nannotations of their training documents. In this work we present DocReader, an\nend-to-end neural-network-based information extraction solution which can be\ntrained using solely the images and the target values that need to be read. The\nDocReader can thus leverage existing historical extraction data, completely\neliminating the need for any additional annotations beyond what is naturally\navailable in existing human-operated service centres. We demonstrate that the\nDocReader can reach and surpass other methods which require bounding-boxes for\ntraining, as well as provide a clear path for continual learning during its\ndeployment in production.",
    "descriptor": "",
    "authors": [
      "Shachar Klaiman",
      "Marius Lehne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04313"
  },
  {
    "id": "arXiv:2105.04319",
    "title": "A Bregman Learning Framework for Sparse Neural Networks",
    "abstract": "We propose a learning framework based on stochastic Bregman iterations to\ntrain sparse neural networks with an inverse scale space approach. We derive a\nbaseline algorithm called LinBreg, an accelerated version using momentum, and\nAdaBreg, which is a Bregmanized generalization of the Adam algorithm. In\ncontrast to established methods for sparse training the proposed family of\nalgorithms constitutes a regrowth strategy for neural networks that is solely\noptimization-based without additional heuristics. Our Bregman learning\nframework starts the training with very few initial parameters, successively\nadding only significant ones to obtain a sparse and expressive network. The\nproposed approach is extremely easy and efficient, yet supported by the rich\nmathematical theory of inverse scale space methods. We derive a statistically\nprofound sparse parameter initialization strategy and provide a rigorous\nstochastic convergence analysis of the loss decay and additional convergence\nproofs in the convex regime. Using only 3.4% of the parameters of ResNet-18 we\nachieve 90.2% test accuracy on CIFAR-10, compared to 93.6% using the dense\nnetwork. Our algorithm also unveils an autoencoder architecture for a denoising\ntask. The proposed framework also has a huge potential for integrating sparse\nbackpropagation and resource-friendly training.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Tim Roith",
      "Daniel Tenbrinck",
      "Martin Burger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.04319"
  },
  {
    "id": "arXiv:2105.04322",
    "title": "RelationTrack: Relation-aware Multiple Object Tracking with Decoupled  Representation",
    "abstract": "Existing online multiple object tracking (MOT) algorithms often consist of\ntwo subtasks, detection and re-identification (ReID). In order to enhance the\ninference speed and reduce the complexity, current methods commonly integrate\nthese double subtasks into a unified framework. Nevertheless, detection and\nReID demand diverse features. This issue would result in an optimization\ncontradiction during the training procedure. With the target of alleviating\nthis contradiction, we devise a module named Global Context Disentangling (GCD)\nthat decouples the learned representation into detection-specific and\nReID-specific embeddings. As such, this module provides an implicit manner to\nbalance the different requirements of these two subtasks. Moreover, we observe\nthat preceding MOT methods typically leverage local information to associate\nthe detected targets and neglect to consider the global semantic relation. To\nresolve this restriction, we develop a module, referred to as Guided\nTransformer Encoder (GTE), by combining the powerful reasoning ability of\nTransformer encoder and deformable attention. Unlike previous works, GTE avoids\nanalyzing all the pixels and only attends to capture the relation between query\nnodes and a few self-adaptively selected key samples. Therefore, it is\ncomputationally efficient. Extensive experiments have been conducted on the\nMOT16, MOT17 and MOT20 benchmarks to demonstrate the superiority of the\nproposed MOT framework, namely RelationTrack. The experimental results indicate\nthat RelationTrack has surpassed preceding methods significantly and\nestablished a new state-of-the-art performance, e.g., IDF1 of 70.5% and MOTA of\n67.2% on MOT20.",
    "descriptor": "\nComments: 11 pages, 5 figures, conference\n",
    "authors": [
      "En Yu",
      "Zhuoling Li",
      "Shoudong Han",
      "Hongwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04322"
  },
  {
    "id": "arXiv:2105.04324",
    "title": "Passivity-based control of mechanical systems with linear damping  identification",
    "abstract": "We propose a control approach for a class of nonlinear mechanical systems to\nstabilize the system under study while ensuring that the oscillations of the\ntransient response are reduced. The approach is twofold: (i) we apply our\ntechnique for linear viscous damping identification of the system to improve\nthe accuracy of the selected control technique, and (ii) we implement a\npassivity-based controller to stabilize and reduce the oscillations by\nselecting the control parameters properly in accordance with the identified\ndamping. Moreover, we provide an analysis for a particular passivity-based\ncontrol approach that has been shown successfully for reducing such\noscillations. Also, we validate the methodology by implementing it\nexperimentally in a planar manipulator.",
    "descriptor": "\nComments: Submission for 7th IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control\n",
    "authors": [
      "Carmen Chan-Zheng",
      "Pablo Borja",
      "Jacquelien Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04324"
  },
  {
    "id": "arXiv:2105.04328",
    "title": "An Autonomous Drone for Search and Rescue in Forests using Airborne  Optical Sectioning",
    "abstract": "Drones will play an essential role in human-machine teaming in future search\nand rescue (SAR) missions. We present a first prototype that finds people fully\nautonomously in densely occluded forests. In the course of 17 field experiments\nconducted over various forest types and under different flying conditions, our\ndrone found 38 out of 42 hidden persons; average precision was 86% for\npredefined flight paths, while adaptive path planning (where potential findings\nare double-checked) increased confidence by 15%. Image processing,\nclassification, and dynamic flight-path adaptation are computed onboard in\nreal-time and while flying. Our finding that deep-learning-based person\nclassification is unaffected by sparse and error-prone sampling within\none-dimensional synthetic apertures allows flights to be shortened and reduces\nrecording requirements to one-tenth of the number of images needed for sampling\nusing two-dimensional synthetic apertures. The goal of our adaptive path\nplanning is to find people as reliably and quickly as possible, which is\nessential in time-critical applications, such as SAR. Our drone enables SAR\noperations in remote areas without stable network coverage, as it transmits to\nthe rescue team only classification results that indicate detections and can\nthus operate with intermittent minimal-bandwidth connections (e.g., by\nsatellite). Once received, these results can be visually enhanced for\ninterpretation on remote mobile devices.",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "D.C. Schedl",
      "I. Kurmi",
      "O. Bimber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04328"
  },
  {
    "id": "arXiv:2105.04332",
    "title": "Bayesian Optimistic Optimisation with Exponentially Decaying Regret",
    "abstract": "Bayesian optimisation (BO) is a well-known efficient algorithm for finding\nthe global optimum of expensive, black-box functions. The current practical BO\nalgorithms have regret bounds ranging from $\\mathcal{O}(\\frac{logN}{\\sqrt{N}})$\nto $\\mathcal O(e^{-\\sqrt{N}})$, where $N$ is the number of evaluations. This\npaper explores the possibility of improving the regret bound in the noiseless\nsetting by intertwining concepts from BO and tree-based optimistic optimisation\nwhich are based on partitioning the search space. We propose the BOO algorithm,\na first practical approach which can achieve an exponential regret bound with\norder $\\mathcal O(N^{-\\sqrt{N}})$ under the assumption that the objective\nfunction is sampled from a Gaussian process with a Mat\\'ern kernel with\nsmoothness parameter $\\nu > 4 +\\frac{D}{2}$, where $D$ is the number of\ndimensions. We perform experiments on optimisation of various synthetic\nfunctions and machine learning hyperparameter tuning tasks and show that our\nalgorithm outperforms baselines.",
    "descriptor": "\nComments: To appear at ICML 2021 (21 pages)\n",
    "authors": [
      "Hung Tran-The",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04332"
  },
  {
    "id": "arXiv:2105.04335",
    "title": "Geometrical Characterization of Sensor Placement for Cone-Invariant and  Multi-Agent Systems against Undetectable Zero-Dynamics Attacks",
    "abstract": "Undetectable attacks are an important class of malicious attacks threatening\nthe security of cyber-physical systems, which can modify a system's state but\nleave the system output measurements unaffected, and hence cannot be detected\nfrom the output. This paper studies undetectable attacks on cone-invariant\nsystems and multi-agent systems. We first provide a general characterization of\nzero-dynamics attacks, which characterizes fully undetectable attacks targeting\nthe non-minimum phase zeros of a system. This geometrical characterization\nmakes it possible to develop a defense strategy seeking to place a minimal\nnumber of sensors to detect and counter the zero-dynamics attacks on the\nsystem's actuators. The detect and defense scheme amounts to computing a set\ncontaining potentially vulnerable actuator locations and nodes, and a defense\nunion for feasible placement of sensors based on the geometrical properties of\nthe cones under consideration.",
    "descriptor": "\nComments: 8 figures\n",
    "authors": [
      "Jianqi Chen",
      "Jieqiang Wei",
      "Wei Chen",
      "Henrik Sandberg",
      "Karl H. Johansson",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04335"
  },
  {
    "id": "arXiv:2105.04339",
    "title": "DefSent: Sentence Embeddings using Definition Sentences",
    "abstract": "Sentence embedding methods using natural language inference (NLI) datasets\nhave been successfully applied to various tasks. However, these methods are\nonly available for limited languages due to relying heavily on the large NLI\ndatasets. In this paper, we propose DefSent, a sentence embedding method that\nuses definition sentences from a word dictionary. Since dictionaries are\navailable for many languages, DefSent is more broadly applicable than methods\nusing NLI datasets without constructing additional datasets. We demonstrate\nthat DefSent performs comparably on unsupervised semantics textual similarity\n(STS) tasks and slightly better on SentEval tasks to the methods using large\nNLI datasets.",
    "descriptor": "",
    "authors": [
      "Hayato Tsukagoshi",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04339"
  },
  {
    "id": "arXiv:2105.04340",
    "title": "Interaction Theory of Hazard-Target System",
    "abstract": "Major accidents (e.g., the Space Shuttle Challenger disaster in the USA, the\nBhopal Disaster in India, Fukushima nuclear accident in Japan, Tianjin Port\nfire and explosion accident in China) have occurred all over the world. Safety\nscientists are always trying to understand why these accidents happened and how\nto prevent these accidents. Accident models and theories form the basis for\nmany safety research fields and practices such as investigation of accidents,\ndesign of a safer system and decision making on safety related field. There is\nno universally accepted model with useful elements relating to understanding\naccident causation, although many accident causation models exist. Based on\nSTAMP and RMF, we proposed a new theory named the Interaction Theory of\nHazard-Target System (ITHTS) that incorporate human, organisational and\ntechnological characteristics in the same framework. Accident analysis methods\nprovide the necessary information to analysis the accident in a specific\nsetting. In order to solve the issues that current accident analysis methods\nstill face, we proposed a new systemic accident analysis method based on ITHTS\nand STPA. We choose Tianjin Port fire and explosion accident in China as a case\nstudy to demonstrate the viability of the Interaction Theory of Hazard-target\nSystem and the applicability of the new accident analysis method. It is\nconcluded that ITHTS can explain the phenomena in safety practice and the new\naccident analysis method can be application in the explanation and analysis of\nmajor accident.",
    "descriptor": "\nComments: 28 pages, 9 figures, 3 tables\n",
    "authors": [
      "Ji Ge",
      "Yu-Yuan Zhang",
      "Kai-Li Xu",
      "Ji-Shuo Li",
      "Xi-Wen Yao",
      "Chun-Ying Wu",
      "Shuang-Yuan Li",
      "Fang Yan",
      "Jin-Jia Zhang",
      "Qing-Wei Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04340"
  },
  {
    "id": "arXiv:2105.04342",
    "title": "Exploring open-ended gameplay features with Micro RollerCoaster Tycoon",
    "abstract": "This paper introduces MicroRCT, a novel open source simulator inspired by the\ntheme park sandbox game RollerCoaster Tycoon. The goal in MicroRCT is to place\nrides and shops in an amusement park to maximize profit earned from park\nguests. Thus, the challenges for game AI include both selecting high-earning\nattractions and placing them in locations that are convenient to guests. In\nthis paper, the MAP-Elites algorithm is used to generate a diversity of park\nlayouts, exploring two theoretical questions about evolutionary algorithms and\ngame design: 1) Is there a benefit to starting from a minimal starting point\nfor evolution and complexifying incrementally? and 2) What are the effects of\nresource limitations on creativity and optimization? Results indicate that\nbuilding from scratch with no costs results in the widest diversity of\nhigh-performing designs.",
    "descriptor": "\nComments: 8 pages, 10 figures, submitted to Foundations of Digital Games Conference 2021\n",
    "authors": [
      "Michael Cerny Green",
      "Victoria Yen",
      "Sam Earle",
      "Dipika Rajesh",
      "Maria Edwards",
      "L. B. Soros"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04342"
  },
  {
    "id": "arXiv:2105.04349",
    "title": "Generative Adversarial Registration for Improved Conditional Deformable  Templates",
    "abstract": "Deformable templates are essential to large-scale medical image registration,\nsegmentation, and population analysis. Current conventional and deep\nnetwork-based methods for template construction use only regularized\nregistration objectives and often yield templates with blurry and/or\nanatomically implausible appearance, confounding downstream biomedical\ninterpretation. We reformulate deformable registration and conditional template\nestimation as an adversarial game wherein we encourage realism in the moved\ntemplates with a generative adversarial registration framework conditioned on\nflexible image covariates. The resulting templates exhibit significant gain in\nspecificity to attributes such as age and disease, better fit underlying\ngroup-wise spatiotemporal trends, and achieve improved sharpness and\ncentrality. These improvements enable more accurate population modeling with\ndiverse covariates for standardized downstream analyses and easier anatomical\ndelineation for structures of interest.",
    "descriptor": "\nComments: 24 pages, 15 figures. Code is available at this https URL\n",
    "authors": [
      "Neel Dey",
      "Mengwei Ren",
      "Adrian V. Dalca",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.04349"
  },
  {
    "id": "arXiv:2105.04351",
    "title": "Attacks on a Privacy-Preserving Publish-Subscribe System and a  Ride-Hailing Service",
    "abstract": "A privacy-preserving Context-Aware Publish-Subscribe System (CA-PSS) enables\nan intermediary (broker) to match the content from a publisher and the\nsubscription by a subscriber based on the current context while preserving\nconfidentiality of the subscriptions and notifications. While a\nprivacy-preserving Ride-Hailing Service (RHS) enables an intermediary (service\nprovider) to match a ride request with a taxi driver in a privacy-friendly\nmanner. In this work, we attack a privacy-preserving CA-PSS proposed by Nabeel\net al. (2013), where we show that any entity in the system including the broker\ncan learn the confidential subscriptions of the subscribers. We also attack a\nprivacy-preserving RHS called lpRide proposed by Yu et al. (2019), where we\nshow that any rider/driver can efficiently recover the secret keys of all other\nriders and drivers. Also, we show that any rider/driver will be able to learn\nthe location of any rider. The attacks are based on our cryptanalysis of the\nmodified Paillier cryptosystem proposed by Nabeel et al. that forms a building\nblock for both the above protocols.",
    "descriptor": "",
    "authors": [
      "Srinivas Vivek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04351"
  },
  {
    "id": "arXiv:2105.04354",
    "title": "AFINet: Attentive Feature Integration Networks for Image Classification",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success in a\nnumber of learning tasks including image classification. Recent advanced models\nin CNNs, such as ResNets, mainly focus on the skip connection to avoid gradient\nvanishing. DenseNet designs suggest creating additional bypasses to transfer\nfeatures as an alternative strategy in network design. In this paper, we design\nAttentive Feature Integration (AFI) modules, which are widely applicable to\nmost recent network architectures, leading to new architectures named AFI-Nets.\nAFI-Nets explicitly model the correlations among different levels of features\nand selectively transfer features with a little overhead.AFI-ResNet-152 obtains\na 1.24% relative improvement on the ImageNet dataset while decreases the FLOPs\nby about 10% and the number of parameters by about 9.2% compared to ResNet-152.",
    "descriptor": "",
    "authors": [
      "Xinglin Pan",
      "Jing Xu",
      "Yu Pan",
      "liangjian Wen",
      "WenXiang Lin",
      "Kun Bai",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04354"
  },
  {
    "id": "arXiv:2105.04357",
    "title": "Agreement in the presence of disagreeing rational players: The Huntsman  Protocol",
    "abstract": "In this paper, a novel Byzantine consensus protocol among $n$ players is\nproposed for the partially synchronous model. In particular, by assuming that\nstandard cryptography is unbreakable, and that\n$n>\\max\\bigl(\\frac{3}{2}k+3t,2(k+t)\\bigr)$, this protocol is an equilibrium\nwhere no coalition of $k$ rational players can coordinate to increase their\nexpected utility regardless of the arbitrary behavior of up to $t$ Byzantine\nplayers. We show that a baiting strategy is necessary and sufficient to solve\nthis, so-called rational agreement problem. First, we show that it is\nimpossible to solve this rational agreement problem without implementing a\nbaiting strategy, a strategy that rewards rational players for betraying its\ncoalition, by exposing undeniable proofs of fraud. Second, we propose the\nHuntsman protocol that solves the rational agreement problem by building recent\nadvances in the context of accountable Byzantine agreement in partial\nsynchrony. This protocol finds applications in distributed ledgers where\nplayers are incentivized to steal assets by leading other players to a\ndisagreement on two distinct decisions where they ``double spend''.",
    "descriptor": "",
    "authors": [
      "Alejandro Ranchal-Pedrosa",
      "Vincent Gramoli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.04357"
  },
  {
    "id": "arXiv:2105.04358",
    "title": "Dynamical low-rank approximation for Burgers' equation with uncertainty",
    "abstract": "Quantifying uncertainties in hyperbolic equations is a source of several\nchallenges. First, the solution forms shocks leading to oscillatory behaviour\nin the numerical approximation of the solution. Second, the number of unknowns\nrequired for an effective discretization of the solution grows exponentially\nwith the dimension of the uncertainties, yielding high computational costs and\nlarge memory requirements. An efficient representation of the solution via\nadequate basis functions permits to tackle these difficulties. The generalized\npolynomial chaos (gPC) polynomials allow such an efficient representation when\nthe distribution of the uncertainties is known. These distributions are usually\nonly available for input uncertainties such as initial conditions, therefore\nthe efficiency of this ansatz can get lost during runtime. In this paper, we\nmake use of the dynamical low-rank approximation (DLRA) to obtain a memory-wise\nefficient solution approximation on a lower dimensional manifold. We\ninvestigate the use of the matrix projector-splitting integrator and the\nunconventional integrator for dynamical low-rank approximation, deriving\nseparate time evolution equations for the spatial and uncertain basis\nfunctions, respectively. This guarantees an efficient approximation of the\nsolution even if the underlying probability distributions change over time.\nFurthermore, filters to mitigate the appearance of spurious oscillations are\nimplemented, and a strategy to enforce boundary conditions is introduced. The\nproposed methodology is analyzed for Burgers' equation equipped with uncertain\ninitial values represented by a two-dimensional random vector. The numerical\nresults show a reduction of the memory requirements, and that the important\ncharacteristics of the original system are well captured.",
    "descriptor": "",
    "authors": [
      "Jonas Kusch",
      "Gianluca Ceruti",
      "Lukas Einkemmer",
      "Martin Frank"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04358"
  },
  {
    "id": "arXiv:2105.04371",
    "title": "Poolingformer: Long Document Modeling with Pooling Attention",
    "abstract": "In this paper, we introduce a two-level attention schema, Poolingformer, for\nlong document modeling. Its first level uses a smaller sliding window pattern\nto aggregate information from neighbors. Its second level employs a larger\nwindow to increase receptive fields with pooling attention to reduce both\ncomputational cost and memory consumption. We first evaluate Poolingformer on\ntwo long sequence QA tasks: the monolingual NQ and the multilingual TyDi QA.\nExperimental results show that Poolingformer sits atop three official\nleaderboards measured by F1, outperforming previous state-of-the-art models by\n1.9 points (79.8 vs. 77.9) on NQ long answer, 1.9 points (79.5 vs. 77.6) on\nTyDi QA passage answer, and 1.6 points (67.6 vs. 66.0) on TyDi QA minimal\nanswer. We further evaluate Poolingformer on a long sequence summarization\ntask. Experimental results on the arXiv benchmark continue to demonstrate its\nsuperior performance.",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Hang Zhang",
      "Yeyun Gong",
      "Yelong Shen",
      "Weisheng Li",
      "Jiancheng Lv",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04371"
  },
  {
    "id": "arXiv:2105.04373",
    "title": "Combinatorial Multi-armed Bandits for Resource Allocation",
    "abstract": "We study the sequential resource allocation problem where a decision maker\nrepeatedly allocates budgets between resources. Motivating examples include\nallocating limited computing time or wireless spectrum bands to multiple users\n(i.e., resources). At each timestep, the decision maker should distribute its\navailable budgets among different resources to maximize the expected reward, or\nequivalently to minimize the cumulative regret. In doing so, the decision maker\nshould learn the value of the resources allocated for each user from feedback\non each user's received reward. For example, users may send messages of\ndifferent urgency over wireless spectrum bands; the reward generated by\nallocating spectrum to a user then depends on the message's urgency. We assume\neach user's reward follows a random process that is initially unknown. We\ndesign combinatorial multi-armed bandit algorithms to solve this problem with\ndiscrete or continuous budgets. We prove the proposed algorithms achieve\nlogarithmic regrets under semi-bandit feedback.",
    "descriptor": "",
    "authors": [
      "Jinhang Zuo",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04373"
  },
  {
    "id": "arXiv:2105.04376",
    "title": "Recommendations for Item Set Completion: On the Semantics of Item  Co-Occurrence With Data Sparsity, Input Size, and Input Modalities",
    "abstract": "We address the problem of recommending relevant items to a user in order to\n\"complete\" a partial set of items already known. We consider the two scenarios\nof citation and subject label recommendation, which resemble different\nsemantics of item co-occurrence: relatedness for co-citations and diversity for\nsubject labels. We assess the influence of the completeness of an already known\npartial item set on the recommender performance. We also investigate data\nsparsity through a pruning parameter and the influence of using additional\nmetadata. As recommender models, we focus on different autoencoders, which are\nparticularly suited for reconstructing missing items in a set. We extend\nautoencoders to exploit a multi-modal input of text and structured data. Our\nexperiments on six real-world datasets show that supplying the partial item set\nas input is helpful when item co-occurrence resembles relatedness, while\nmetadata are effective when co-occurrence implies diversity. This outcome means\nthat the semantics of item co-occurrence is an important factor. The simple\nitem co-occurrence model is a strong baseline for citation recommendation.\nHowever, autoencoders have the advantage to enable exploiting additional\nmetadata besides the partial item set as input and achieve comparable\nperformance. For the subject label recommendation task, the title is the most\nimportant attribute. Adding more input modalities sometimes even harms the\nresult. In conclusion, it is crucial to consider the semantics of the item\nco-occurrence for the choice of an appropriate recommendation model and\ncarefully decide which metadata to exploit.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1907.12366\n",
    "authors": [
      "Iacopo Vagliano",
      "Lukas Galke",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04376"
  },
  {
    "id": "arXiv:2105.04378",
    "title": "The Typical Non-Linear Code over Large Alphabets",
    "abstract": "We consider the problem of describing the typical (possibly) non-linear code\nof minimum distance bounded from below over a large alphabet. We concentrate on\nblock codes with the Hamming metric and on subspace codes with the injection\nmetric. In sharp contrast with the behavior of linear block codes, we show that\nthe typical non-linear code in the Hamming metric of cardinality $q^{n-d+1}$ is\nfar from having minimum distance $d$, i.e., from being MDS. We also give more\nprecise results about the asymptotic proportion of block codes with good\ndistance properties within the set of codes having a certain cardinality. We\nthen establish the analogous results for subspace codes with the injection\nmetric, showing also an application to the theory of partial spreads in finite\ngeometry.",
    "descriptor": "",
    "authors": [
      "Anina Gruica",
      "Alberto Ravagnani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.04378"
  },
  {
    "id": "arXiv:2105.04380",
    "title": "Forsage: Anatomy of a Smart-Contract Pyramid Scheme",
    "abstract": "Pyramid schemes are investment scams in which top-level participants in a\nhierarchical network recruit and profit from an expanding base of defrauded\nnewer participants. Pyramid schemes have existed for over a century, but there\nhave been no in-depth studies of their dynamics and communities because of the\nopacity of participants' transactions.\nIn this paper, we present an empirical study of Forsage, a pyramid scheme\nimplemented as a smart contract and at its peak one of the largest consumers of\nresources in Ethereum. As a smart contract, Forsage makes its (byte)code and\nall of its transactions visible on the blockchain. We take advantage of this\nunprecedented transparency to gain insight into the mechanics, impact on\nparticipants, and evolution of Forsage.\nWe quantify the (multi-million-dollar) gains of top-level participants as\nwell as the losses of the vast majority (around 88%) of users. We analyze\nForsage code both manually and using a purpose-built transaction simulator to\nuncover the complex mechanics of the scheme. Through complementary study of\npromotional videos and social media, we show how Forsage promoters have\nleveraged the unique features of smart contracts to lure users with false\nclaims of trustworthiness and profitability, and how Forsage activity is\nconcentrated within a small number of national communities.",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Tyler Kell",
      "Haaroon Yousaf",
      "Sarah Allen",
      "Sarah Meiklejohn",
      "Ari Juels"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04380"
  },
  {
    "id": "arXiv:2105.04381",
    "title": "Did I delete my cookies? Cookies respawning with browser fingerprinting",
    "abstract": "Stateful and stateless web tracking gathered much attention in the last\ndecade, however they were always measured separately. To the best of our\nknowledge, our study is the first to detect and measure cookie respawning with\nbrowser and machine fingerprinting. We develop a detection methodology that\nallows us to detect cookies dependency on browser and machine features. Our\nresults show that 1,150 out of the top 30, 000 Alexa websites deploy this\ntracking mechanism. We further uncover how domains collaborate to respawn\ncookies through fingerprinting. We find out that this technique can be used to\ntrack users across websites even when third-party cookies are deprecated.\nTogether with a legal scholar, we conclude that cookie respawning with browser\nfingerprinting lacks legal interpretation under the GDPR and the ePrivacy\ndirective, but its use in practice may breach them, thus subjecting it to fines\nup to 20 million euro.",
    "descriptor": "",
    "authors": [
      "Imane Fouad",
      "Cristiana Santos",
      "Arnaud Legout",
      "Nataliia Bielova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04381"
  },
  {
    "id": "arXiv:2105.04382",
    "title": "Numerical studies of CO$_2$ leakage remediation by micp-based plugging  technology",
    "abstract": "Microbially induced calcite precipitation (MICP) is a technology for sealing\nleakage paths to ensure the safe storage of CO$_2$ in geological formations. In\nthis work we introduce a numerical simulator of MICP for field-scale studies.\nThis simulator is implemented in the open porous media (OPM) framework. We\ncompare the numerical results to simulations using an upgraded implementation\nof the mathematical model in the MATLAB reservoir simulation toolbox (MRST).\nFinally, we consider a 3D system consisting of two aquifers separated by\ncaprock with a leakage path across the width of the reservoir. We study a\nstrategy where microbial solution is injected only at the beginning of the\ntreatment and subsequently either growth solution or cementation solution is\ninjected for biofilm development or calcite precipitation. By applying this\nstrategy, the numerical results show that the MICP technology could be used to\nseal these leakage paths.",
    "descriptor": "",
    "authors": [
      "David Landa-Marb\u00e1n",
      "Kundan Kumar",
      "Svenn Tveit",
      "Sarah Eileen Gasda"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.04382"
  },
  {
    "id": "arXiv:2105.04383",
    "title": "A framework for the automation of testing computer vision systems",
    "abstract": "Vision systems, i.e., systems that allow to detect and track objects in\nimages, have gained substantial importance over the past decades. They are used\nin quality assurance applications, e.g., for finding surface defects in\nproducts during manufacturing, surveillance, but also automated driving,\nrequiring reliable behavior. Interestingly, there is only little work on\nquality assurance and especially testing of vision systems in general. In this\npaper, we contribute to the area of testing vision software, and present a\nframework for the automated generation of tests for systems based on vision and\nimage recognition. The framework makes use of existing libraries allowing to\nmodify original images and to obtain similarities between the original and\nmodified images. We show how such a framework can be used for testing a\nparticular industrial application on identifying defects on riblet surfaces and\npresent preliminary results from the image classification domain.",
    "descriptor": "\nComments: 4 pages, Submission version, Accepted at the 2nd ACM/IEEE International Conference on Automation of Software Test AST 2021\n",
    "authors": [
      "Franz Wotawa",
      "Lorenz Klampfl",
      "Ledio Jahaj"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04383"
  },
  {
    "id": "arXiv:2105.04385",
    "title": "Identifying Overly Restrictive Matching Patterns in SMT-based Program  Verifiers",
    "abstract": "Universal quantifiers occur frequently in proof obligations produced by\nprogram verifiers, for instance, to axiomatize uninterpreted functions and to\nexpress properties of arrays. SMT-based verifiers typically reason about them\nvia E-matching, an SMT algorithm that requires syntactic matching patterns to\nguide the quantifier instantiations. Devising good matching patterns is\nchallenging. In particular, overly restrictive patterns may lead to spurious\nverification errors if the quantifiers needed for a proof are not instantiated;\nthey may also conceal unsoundness caused by inconsistent axiomatizations. In\nthis paper, we present the first technique that identifies and helps the users\nremedy the effects of overly restrictive matching patterns. We designed a novel\nalgorithm to synthesize missing triggering terms required to complete a proof.\nTool developers can use this information to refine their matching patterns and\nprevent similar verification errors, or to fix a detected unsoundness.",
    "descriptor": "",
    "authors": [
      "Alexandra Bugariu",
      "Arshavir Ter-Gabrielyan",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.04385"
  },
  {
    "id": "arXiv:2105.04387",
    "title": "Recent Advances in Deep Learning-based Dialogue Systems",
    "abstract": "Dialogue systems are a popular Natural Language Processing (NLP) task as it\nis promising in real-life applications. It is also a complicated task since\nmany NLP tasks deserving study are involved. As a result, a multitude of novel\nworks on this task are carried out, and most of them are deep learning-based\ndue to the outstanding performance. In this survey, we mainly focus on the deep\nlearning-based dialogue systems. We comprehensively review state-of-the-art\nresearch outcomes in dialogue systems and analyze them from two angles: model\ntype and system type. Specifically, from the angle of model type, we discuss\nthe principles, characteristics, and applications of different models that are\nwidely used in dialogue systems. This will help researchers acquaint these\nmodels and see how they are applied in state-of-the-art frameworks, which is\nrather helpful when designing a new dialogue system. From the angle of system\ntype, we discuss task-oriented and open-domain dialogue systems as two streams\nof research, providing insight into the hot topics related. Furthermore, we\ncomprehensively review the evaluation methods and datasets for dialogue systems\nto pave the way for future research. Finally, some possible research trends are\nidentified based on the recent research outcomes. To the best of our knowledge,\nthis survey is the most comprehensive and up-to-date one at present in the area\nof dialogue systems and dialogue-related tasks, extensively covering the\npopular frameworks, topics, and datasets.",
    "descriptor": "\nComments: 75 pages, 19 figures\n",
    "authors": [
      "Jinjie Ni",
      "Tom Young",
      "Vlad Pandelea",
      "Fuzhao Xue",
      "Vinay Adiga",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04387"
  },
  {
    "id": "arXiv:2105.04396",
    "title": "Stability Constrained Mobile Manipulation Planning on Rough Terrain",
    "abstract": "This paper presents a framework that allows online\ndynamic-stability-constrained optimal trajectory planning of a mobile\nmanipulator robot working on rough terrain. First, the kinematics model of a\nmobile manipulator robot, and the Zero Moment Point (ZMP) stability measure are\npresented as theoretical background. Then, a sampling-based quasi-static\nplanning algorithm modified for stability guarantee and traction optimization\nin continuous dynamic motion is presented along with a mathematical proof. The\nrobot's quasi-static path is then used as an initial guess to warm-start a\nnonlinear optimal control solver which may otherwise have difficulties finding\na solution to the stability-constrained formulation efficiently. The\nperformance and computational efficiency of the framework are demonstrated\nthrough an application to a simulated timber harvesting mobile manipulator\nmachine working on varying terrain. The results demonstrate feasibility of\nonline trajectory planning on varying terrain while satisfying the dynamic\nstability constraint.",
    "descriptor": "",
    "authors": [
      "Jiazhi Song",
      "Inna Sharf"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04396"
  },
  {
    "id": "arXiv:2105.04397",
    "title": "Why Aren't Regular Expressions a Lingua Franca? An Empirical Study on  the Re-use and Portability of Regular Expressions",
    "abstract": "This paper explores the extent to which regular expressions (regexes) are\nportable across programming languages. Many languages offer similar regex\nsyntaxes, and it would be natural to assume that regexes can be ported across\nlanguage boundaries. But can regexes be copy/pasted across language boundaries\nwhile retaining their semantic and performance characteristics?\nIn our survey of 158 professional software developers, most indicated that\nthey re-use regexes across language boundaries and about half reported that\nthey believe regexes are a universal language. We experimentally evaluated the\nriskiness of this practice using a novel regex corpus -- 537,806 regexes from\n193,524 projects written in JavaScript, Java, PHP, Python, Ruby, Go, Perl, and\nRust. Using our polyglot regex corpus, we explored the hitherto-unstudied regex\nportability problems: logic errors due to semantic differences, and security\nvulnerabilities due to performance differences.\nWe report that developers' belief in a regex lingua franca is understandable\nbut unfounded. Though most regexes compile across language boundaries, 15%\nexhibit semantic differences across languages and 10% exhibit performance\ndifferences across languages. We explained these differences using regex\ndocumentation, and further illuminate our findings by investigating regex\nengine implementations. Along the way we found bugs in the regex engines of\nJavaScript-V8, Python, Ruby, and Rust, and potential semantic and performance\nregex bugs in thousands of modules.",
    "descriptor": "\nComments: ESEC/FSE 2019\n",
    "authors": [
      "James C. Davis",
      "Louis G. Michael IV",
      "Christy A. Coghlan",
      "Francisco Servant",
      "Dongyoon Lee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.04397"
  },
  {
    "id": "arXiv:2105.04402",
    "title": "AWCD: An Efficient Point Cloud Processing Approach via Wasserstein  Curvature",
    "abstract": "In this paper, we introduce the adaptive Wasserstein curvature denoising\n(AWCD), an original processing approach for point cloud data. By collecting\ncurvatures information from Wasserstein distance, AWCD consider more precise\nstructures of data and preserves stability and effectiveness even for data with\nnoise in high density. This paper contains some theoretical analysis about the\nWasserstein curvature and the complete algorithm of AWCD. In addition, we\ndesign digital experiments to show the denoising effect of AWCD. According to\ncomparison results, we present the advantages of AWCD against traditional\nalgorithms.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Yihao Luo",
      "Ailing Yang",
      "Fupeng Sun",
      "Huafei Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04402"
  },
  {
    "id": "arXiv:2105.04405",
    "title": "A Critical Review of Information Bottleneck Theory and its Applications  to Deep Learning",
    "abstract": "In the past decade, deep neural networks have seen unparalleled improvements\nthat continue to impact every aspect of today's society. With the development\nof high performance GPUs and the availability of vast amounts of data, learning\ncapabilities of ML systems have skyrocketed, going from classifying digits in a\npicture to beating world-champions in games with super-human performance.\nHowever, even as ML models continue to achieve new frontiers, their practical\nsuccess has been hindered by the lack of a deep theoretical understanding of\ntheir inner workings. Fortunately, a known information-theoretic method called\nthe information bottleneck theory has emerged as a promising approach to better\nunderstand the learning dynamics of neural networks. In principle, IB theory\nmodels learning as a trade-off between the compression of the data and the\nretainment of information. The goal of this survey is to provide a\ncomprehensive review of IB theory covering it's information theoretic roots and\nthe recently proposed applications to understand deep learning models.",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Alomrani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04405"
  },
  {
    "id": "arXiv:2105.04408",
    "title": "The Challenges and Opportunities of Human-Centered AI for Trustworthy  Robots and Autonomous Systems",
    "abstract": "The trustworthiness of Robots and Autonomous Systems (RAS) has gained a\nprominent position on many research agendas towards fully autonomous systems.\nThis research systematically explores, for the first time, the key facets of\nhuman-centered AI (HAI) for trustworthy RAS. In this article, five key\nproperties of a trustworthy RAS initially have been identified. RAS must be (i)\nsafe in any uncertain and dynamic surrounding environments; (ii) secure, thus\nprotecting itself from any cyber-threats; (iii) healthy with fault tolerance;\n(iv) trusted and easy to use to allow effective human-machine interaction\n(HMI), and (v) compliant with the law and ethical expectations. Then, the\nchallenges in implementing trustworthy autonomous system are analytically\nreviewed, in respects of the five key properties, and the roles of AI\ntechnologies have been explored to ensure the trustiness of RAS with respects\nto safety, security, health and HMI, while reflecting the requirements of\nethics in the design of RAS. While applications of RAS have mainly focused on\nperformance and productivity, the risks posed by advanced AI in RAS have not\nreceived sufficient scientific attention. Hence, a new acceptance model of RAS\nis provided, as a framework for requirements to human-centered AI and for\nimplementing trustworthy RAS by design. This approach promotes human-level\nintelligence to augment human's capacity. while focusing on contributions to\nhumanity.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Hongmei He",
      "John Gray",
      "Angelo Cangelosi",
      "Qinggang Meng",
      "T.Martin McGinnity",
      "J\u00f6rn Mehnen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04408"
  },
  {
    "id": "arXiv:2105.04414",
    "title": "Predicting Intensive Care Unit Length of Stay and Mortality Using  Patient Vital Signs: Machine Learning Model Development and Validation",
    "abstract": "Patient monitoring is vital in all stages of care. We here report the\ndevelopment and validation of ICU length of stay and mortality prediction\nmodels. The models will be used in an intelligent ICU patient monitoring module\nof an Intelligent Remote Patient Monitoring (IRPM) framework that monitors the\nhealth status of patients, and generates timely alerts, maneuver guidance, or\nreports when adverse medical conditions are predicted. We utilized the publicly\navailable Medical Information Mart for Intensive Care (MIMIC) database to\nextract ICU stay data for adult patients to build two prediction models: one\nfor mortality prediction and another for ICU length of stay. For the mortality\nmodel, we applied six commonly used machine learning (ML) binary classification\nalgorithms for predicting the discharge status (survived or not). For the\nlength of stay model, we applied the same six ML algorithms for binary\nclassification using the median patient population ICU stay of 2.64 days. For\nthe regression-based classification, we used two ML algorithms for predicting\nthe number of days. We built two variations of each prediction model: one using\n12 baseline demographic and vital sign features, and the other based on our\nproposed quantiles approach, in which we use 21 extra features engineered from\nthe baseline vital sign features, including their modified means, standard\ndeviations, and quantile percentages. We could perform predictive modeling with\nminimal features while maintaining reasonable performance using the quantiles\napproach. The best accuracy achieved in the mortality model was approximately\n89% using the random forest algorithm. The highest accuracy achieved in the\nlength of stay model, based on the population median ICU stay (2.64 days), was\napproximately 65% using the random forest algorithm.",
    "descriptor": "\nComments: 23 Pages, 11 Figures, 13 Tables\n",
    "authors": [
      "Khalid Alghatani",
      "Nariman Ammar",
      "Abdelmounaam Rezgui",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04414"
  },
  {
    "id": "arXiv:2105.04419",
    "title": "VDB-EDT: An Efficient Euclidean Distance Transform Algorithm Based on  VDB Data Structure",
    "abstract": "This paper presents a fundamental algorithm, called VDB-EDT, for Euclidean\ndistance transform (EDT) based on the VDB data structure. The algorithm\nexecutes on grid maps and generates the corresponding distance field for\nrecording distance information against obstacles, which forms the basis of\nnumerous motion planning algorithms. The contributions of this work mainly lie\nin three folds. Firstly, we propose a novel algorithm that can facilitate\ndistance transform procedures by optimizing the scheduling priorities of\ntransform functions, which significantly improves the running speed of\nconventional EDT algorithms. Secondly, we for the first time introduce the\nmemory-efficient VDB data structure, a customed B+ tree, to represent the\ndistance field hierarchically. Benefiting from the special index and caching\nmechanism, VDB shows a fast (average \\textit{O}(1)) random access speed, and\nthus is very suitable for the frequent neighbor-searching operations in EDT.\nMoreover, regarding the small scale of existing datasets, we release a\nlarge-scale dataset captured from subterranean environments to benchmark EDT\nalgorithms. Extensive experiments on the released dataset and publicly\navailable datasets show that VDB-EDT can reduce memory consumption by about\n30%-85%, depending on the sparsity of the environment, while maintaining a\ncompetitive running speed with the fastest array-based implementation. The\nexperiments also show that VDB-EDT can significantly outperform the\nstate-of-the-art EDT algorithm in both runtime and memory efficiency, which\nstrongly demonstrates the advantages of our proposed method. The released\ndataset and source code are available on https://github.com/zhudelong/VDB-EDT.",
    "descriptor": "",
    "authors": [
      "Delong Zhu",
      "Chaoqun Wang",
      "Wenshan Wang",
      "Rohit Garg",
      "Sebastian Scherer",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.04419"
  },
  {
    "id": "arXiv:2105.04421",
    "title": "Trials and Tribulations of Developing Hybrid Quantum-Classical  Microservices Systems",
    "abstract": "Quantum computing holds great promise to solve to problems where classical\ncomputers cannot reach. To the point where it already arouses the interest of\nboth scientific and industrial communities. Thus, it is expected that hybrid\nsystems will start to appear where quantum software interacts with classical\nsystems. Such coexistence can be fostered by service computing. Unfortunately,\nthe way in which quantum code can be offered as a service still misses out on\nmany of the potential benefits of service computing. This paper takes the\ntraveling salesman problem, and tackles the challenge of giving it an\nimplementation in the form of a quantum microservice. Then it is used to detect\nwhich of the benefits of service computing are lost in the process. The\nconclusions help to measure the distance between the current state of\ntechnology and the state that would be desirable in order to have a real\nquantum service engineering.",
    "descriptor": "\nComments: 11 pages, 7 figures, 2 tables\n",
    "authors": [
      "Javier Rojo",
      "David Valencia",
      "Javier Berrocal",
      "Enrique Moguel",
      "Jose Garcia-Alonso",
      "Juan Manuel Murillo Rodriguez"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04421"
  },
  {
    "id": "arXiv:2105.04425",
    "title": "MTNet: A Multi-Task Neural Network for On-Field Calibration of Low-Cost  Air Monitoring Sensors",
    "abstract": "The advances of sensor technology enable people to monitor air quality\nthrough widely distributed low-cost sensors. However, measurements from these\nsensors usually encounter high biases and require a calibration step to reach\nan acceptable performance in down-streaming analytical tasks. Most existing\ncalibration methods calibrate one type of sensor at a time, which we call\nsingle-task calibration. Despite the popularity of this single-task schema, it\nmay neglect interactions among calibration tasks of different sensors, which\nencompass underlying information to promote calibration performance. In this\npaper, we propose a multi-task calibration network (MTNet) to calibrate\nmultiple sensors (e.g., carbon monoxide and nitrogen oxide sensors)\nsimultaneously, modeling the interactions among tasks. MTNet consists of a\nsingle shared module, and several task-specific modules. Specifically, in the\nshared module, we extend the multi-gate mixture-of-experts structure to\nharmonize the task conflicts and correlations among different tasks; in each\ntask-specific module, we introduce a feature selection strategy to customize\nthe input for the specific task. These improvements allow MTNet to learn\ninteraction information shared across different tasks, and task-specific\ninformation for each calibration task as well. We evaluate MTNet on three\nreal-world datasets and compare it with several established baselines. The\nexperimental results demonstrate that MTNet achieves the state-of-the-art\nperformance.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Haomin Yu",
      "Yangli-ao Geng",
      "Yingjun Zhang",
      "Qingyong Li",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04425"
  },
  {
    "id": "arXiv:2105.04430",
    "title": "An Enhanced Randomly Initialized Convolutional Neural Network for  Columnar Cactus Recognition in Unmanned Aerial Vehicle Imagery",
    "abstract": "Recently, Convolutional Neural Networks (CNNs) have made a great performance\nfor remote sensing image classification. Plant recognition using CNNs is one of\nthe active deep learning research topics due to its added-value in different\nrelated fields, especially environmental conservation and natural areas\npreservation. Automatic recognition of plants in protected areas helps in the\nsurveillance process of these zones and ensures the sustainability of their\necosystems. In this work, we propose an Enhanced Randomly Initialized\nConvolutional Neural Network (ERI-CNN) for the recognition of columnar cactus,\nwhich is an endemic plant that exists in the Tehuac\\'an-Cuicatl\\'an Valley in\nsoutheastern Mexico. We used a public dataset created by a group of researchers\nthat consists of more than 20000 remote sensing images. The experimental\nresults confirm the effectiveness of the proposed model compared to other\nmodels reported in the literature like InceptionV3 and the modified LeNet-5\nCNN. Our ERI-CNN provides 98% of accuracy, 97% of precision, 97% of recall,\n97.5% as f1-score, and 0.056 loss.",
    "descriptor": "",
    "authors": [
      "Safa Ben Atitallah",
      "Maha Driss",
      "Wadii Boulila",
      "Anis Koubaa",
      "Nesrine Atitallah",
      "Henda Ben Gh\u00e9zala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04430"
  },
  {
    "id": "arXiv:2105.04431",
    "title": "Boosting Semi-Supervised Face Recognition with Noise Robustness",
    "abstract": "Although deep face recognition benefits significantly from large-scale\ntraining data, a current bottleneck is the labelling cost. A feasible solution\nto this problem is semi-supervised learning, exploiting a small portion of\nlabelled data and large amounts of unlabelled data. The major challenge,\nhowever, is the accumulated label errors through auto-labelling, compromising\nthe training. This paper presents an effective solution to semi-supervised face\nrecognition that is robust to the label noise aroused by the auto-labelling.\nSpecifically, we introduce a multi-agent method, named GroupNet (GN), to endow\nour solution with the ability to identify the wrongly labelled samples and\npreserve the clean samples. We show that GN alone achieves the leading accuracy\nin traditional supervised face recognition even when the noisy labels take over\n50\\% of the training data. Further, we develop a semi-supervised face\nrecognition solution, named Noise Robust Learning-Labelling (NRoLL), which is\nbased on the robust training ability empowered by GN. It starts with a small\namount of labelled data and consequently conducts high-confidence labelling on\na large amount of unlabelled data to boost further training. The more data is\nlabelled by NRoLL, the higher confidence is with the label in the dataset. To\nevaluate the competitiveness of our method, we run NRoLL with a rough condition\nthat only one-fifth of the labelled MSCeleb is available and the rest is used\nas unlabelled data. On a wide range of benchmarks, our method compares\nfavorably against the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yuchi Liu",
      "Hailin Shi",
      "Hang Du",
      "Rui Zhu",
      "Jun Wang",
      "Liang Zheng",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04431"
  },
  {
    "id": "arXiv:2105.04432",
    "title": "Explicit Rate-Optimal Streaming Codes with Smaller Field Size",
    "abstract": "Streaming codes are a class of packet-level erasure codes that ensure packet\nrecovery over a sliding window channel which allows either a burst erasure of\nsize $b$ or $a$ random erasures within any window of size $(\\tau+1)$ time\nunits, under a strict decoding-delay constraint $\\tau$. The field size over\nwhich streaming codes are constructed is an important factor determining the\ncomplexity of implementation. The best known explicit rate-optimal streaming\ncode requires a field size of $q^2$ where $q \\ge \\tau+b-a$ is a prime power. In\nthis work, we present an explicit rate-optimal streaming code, for all possible\n$\\{a,b,\\tau\\}$ parameters, over a field of size $q^2$ for prime power $q \\ge\n\\tau$. This is the smallest-known field size of a general explicit rate-optimal\nconstruction that covers all $\\{a,b,\\tau\\}$ parameter sets. We achieve this by\nmodifying the non-explicit code construction due to Krishnan et al. to make it\nexplicit, without change in field size.",
    "descriptor": "",
    "authors": [
      "Myna Vajha",
      "Vinayak Ramkumar",
      "M. Nikhil Krishnan",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04432"
  },
  {
    "id": "arXiv:2105.04443",
    "title": "Neural Quality Estimation with Multiple Hypotheses for Grammatical Error  Correction",
    "abstract": "Grammatical Error Correction (GEC) aims to correct writing errors and help\nlanguage learners improve their writing skills. However, existing GEC models\ntend to produce spurious corrections or fail to detect lots of errors. The\nquality estimation model is necessary to ensure learners get accurate GEC\nresults and avoid misleading from poorly corrected sentences. Well-trained GEC\nmodels can generate several high-quality hypotheses through decoding, such as\nbeam search, which provide valuable GEC evidence and can be used to evaluate\nGEC quality. However, existing models neglect the possible GEC evidence from\ndifferent hypotheses. This paper presents the Neural Verification Network\n(VERNet) for GEC quality estimation with multiple hypotheses. VERNet\nestablishes interactions among hypotheses with a reasoning graph and conducts\ntwo kinds of attention mechanisms to propagate GEC evidence to verify the\nquality of generated hypotheses. Our experiments on four GEC datasets show that\nVERNet achieves state-of-the-art grammatical error detection performance,\nachieves the best quality estimation results, and significantly improves GEC\nperformance by reranking hypotheses. All data and source codes are available at\nhttps://github.com/thunlp/VERNet.",
    "descriptor": "\nComments: Accepted by NAACL2021, 9 pages, 5 figures\n",
    "authors": [
      "Zhenghao Liu",
      "Xiaoyuan Yi",
      "Maosong Sun",
      "Liner Yang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04443"
  },
  {
    "id": "arXiv:2105.04444",
    "title": "Continual Learning via Bit-Level Information Preserving",
    "abstract": "Continual learning tackles the setting of learning different tasks\nsequentially. Despite the lots of previous solutions, most of them still suffer\nsignificant forgetting or expensive memory cost. In this work, targeted at\nthese problems, we first study the continual learning process through the lens\nof information theory and observe that forgetting of a model stems from the\nloss of \\emph{information gain} on its parameters from the previous tasks when\nlearning a new task. From this viewpoint, we then propose a novel continual\nlearning approach called Bit-Level Information Preserving (BLIP) that preserves\nthe information gain on model parameters through updating the parameters at the\nbit level, which can be conveniently implemented with parameter quantization.\nMore specifically, BLIP first trains a neural network with weight quantization\non the new incoming task and then estimates information gain on each parameter\nprovided by the task data to determine the bits to be frozen to prevent\nforgetting. We conduct extensive experiments ranging from classification tasks\nto reinforcement learning tasks, and the results show that our method produces\nbetter or on par results comparing to previous state-of-the-arts. Indeed, BLIP\nachieves close to zero forgetting while only requiring constant memory\noverheads throughout continual learning.",
    "descriptor": "\nComments: CVPR2021\n",
    "authors": [
      "Yujun Shi",
      "Li Yuan",
      "Yunpeng Chen",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04444"
  },
  {
    "id": "arXiv:2105.04447",
    "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation",
    "abstract": "We propose a novel scene flow estimation approach to capture and infer 3D\nmotions from point clouds. Estimating 3D motions for point clouds is\nchallenging, since a point cloud is unordered and its density is significantly\nnon-uniform. Such unstructured data poses difficulties in matching\ncorresponding points between point clouds, leading to inaccurate flow\nestimation. We propose a novel architecture named Sparse\nConvolution-Transformer Network (SCTN) that equips the sparse convolution with\nthe transformer. Specifically, by leveraging the sparse convolution, SCTN\ntransfers irregular point cloud into locally consistent flow features for\nestimating continuous and consistent motions within an object/local object\npart. We further propose to explicitly learn point relations using a point\ntransformer module, different from exiting methods. We show that the learned\nrelation-based contextual information is rich and helpful for matching\ncorresponding points, benefiting scene flow estimation. In addition, a novel\nloss function is proposed to adaptively encourage flow consistency according to\nfeature similarity. Extensive experiments demonstrate that our proposed\napproach achieves a new state of the art in scene flow estimation. Our approach\nachieves an error of 0.038 and 0.037 (EPE3D) on FlyingThings3D and KITTI Scene\nFlow respectively, which significantly outperforms previous methods by large\nmargins.",
    "descriptor": "",
    "authors": [
      "Bing Li",
      "Cheng Zheng",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04447"
  },
  {
    "id": "arXiv:2105.04449",
    "title": "G-Tran: Making Distributed Graph Transactions Fast",
    "abstract": "Graph transaction processing raises many unique challenges such as random\ndata access due to the irregularity of graph structures, low throughput and\nhigh abort rate due to the relatively large read/write sets in graph\ntransactions. To address these challenges, we present G-Tran -- an RDMA-enabled\ndistributed in-memory graph database with serializable and snapshot isolation\nsupport. First, we propose a graph-native data store to achieve good data\nlocality and fast data access for transactional updates and queries. Second,\nG-Tran adopts a fully decentralized architecture that leverages RDMA to process\ndistributed transactions with the MPP model, which can achieve high performance\nby utilizing all computing resources. In addition, we propose a new MV-OCC\nimplementation with two optimizations to address the issue of large read/write\nsets in graph transactions. Extensive experiments show that G-Tran achieves\ncompetitive performance compared with other popular graph databases on\nbenchmark workloads.",
    "descriptor": "",
    "authors": [
      "Hongzhi Chen",
      "Changji Li",
      "Chenguang Zheng",
      "Chenghuan Huang",
      "Juncheng Fang",
      "James Cheng",
      "Jian Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.04449"
  },
  {
    "id": "arXiv:2105.04452",
    "title": "Who Gets What, According to Whom? An Analysis of Fairness Perceptions in  Service Allocation",
    "abstract": "Algorithmic fairness research has traditionally been linked to the\ndisciplines of philosophy, ethics, and economics, where notions of fairness are\nprescriptive and seek objectivity. Increasingly, however, scholars are turning\nto the study of what different people perceive to be fair, and how these\nperceptions can or should help to shape the design of machine learning,\nparticularly in the policy realm. The present work experimentally explores five\nnovel research questions at the intersection of the \"Who,\" \"What,\" and \"How\" of\nfairness perceptions. Specifically, we present the results of a multi-factor\nconjoint analysis study that quantifies the effects of the specific context in\nwhich a question is asked, the framing of the given question, and who is\nanswering it. Our results broadly suggest that the \"Who\" and \"What,\" at least,\nmatter in ways that are 1) not easily explained by any one theoretical\nperspective, 2) have critical implications for how perceptions of fairness\nshould be measured and/or integrated into algorithmic decision-making systems.",
    "descriptor": "\nComments: Accepted at AIES'21\n",
    "authors": [
      "Jacqueline Hannan",
      "Huei-Yen Winnie Chen",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04452"
  },
  {
    "id": "arXiv:2105.04453",
    "title": "Neural Computation of Capacity Region of Memoryless Multiple Access  Channels",
    "abstract": "This paper provides a numerical framework for computing the achievable rate\nregion of memoryless multiple access channel (MAC) with a continuous alphabet\nfrom data. In particular, we use recent results on variational lower bounds on\nmutual information and KL-divergence to compute the boundaries of the rate\nregion of MAC using a set of functions parameterized by neural networks. Our\nmethod relies on a variational lower bound on KL-divergence and an upper bound\non KL-divergence based on the f-divergence inequalities. Unlike previous work,\nwhich computes an estimate on mutual information, which is neither a lower nor\nan upper bound, our method estimates a lower bound on mutual information. Our\nnumerical results show that the proposed method provides tighter estimates\ncompared to the MINE-based estimator at large SNRs while being computationally\nmore efficient. Finally, we apply the proposed method to the optical intensity\nMAC and obtain a new achievable rate boundary tighter than prior works.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted at ISIT2021\n",
    "authors": [
      "Farhad Mirkarimi",
      "Nariman Farsad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04453"
  },
  {
    "id": "arXiv:2105.04454",
    "title": "Physical Fault Injection and Side-Channel Attacks on Mobile Devices: A  Comprehensive Survey",
    "abstract": "The past decade has seen the rapid deployment of mobile devices with densely\npackaged system-on-chips (SoCs) with multi-core, high-frequency CPUs and\ncomplex pipelines. In parallel, sophisticated SoC-assisted security mechanisms,\nsuch as trusted execution environments (TEEs), full-disk and file-based\nencryption, have also been deployed for protecting sensitive data. Both\nadvancements have dramatically complicated the use of physical attacks, which\nhas recently led to the development of specialised attack methods. In this\nsurvey, we consolidate recent developments in physical fault injections (FIAs)\nand side-channel attacks (SCAs) on modern mobile devices. In total, we\ncomprehensively survey over 50 fault injection and side-channel attack papers\npublished between 2009-2021. We evaluate the prevailing attack methods, compare\nexisting attacks using a common framework, identify several challenges and\nshortcomings, and suggest future directions of research.",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Konstantinos Markantonakis",
      "Nico van Heijningen",
      "Driss Aboulkassimi",
      "Cl\u00e9ment Gaine",
      "Thibaut Heckmann",
      "David Naccache"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04454"
  },
  {
    "id": "arXiv:2105.04456",
    "title": "A shape optimisation with the isogeometric boundary element method and  adjoint variable method for the three-dimensional Helmholtz equation",
    "abstract": "This paper presents a shape optimisation system to design the shape of an\nacoustically-hard object in the three-dimensional open space. Boundary element\nmethod (BEM) is suitable to analyse such an exterior field. However, the\nconventional BEM, which is based on piecewise polynomial shape and\ninterpolation functions, can require many design variables because they are\nusually chosen as a part of the nodes of the underlying boundary element mesh.\nIn addition, it is not easy for the conventional method to compute the gradient\nof the sound pressure on the surface, which is necessary to compute the shape\nderivative of our interest, of a given object. To overcome these issues, we\nemploy the isogeometric boundary element method (IGBEM), which was developed in\nour previous work. With using the IGBEM, we can design the shape of surfaces\nthrough control points of the NURBS surfaces of the target object. We integrate\nthe IGBEM with the nonlinear programming software through the adjoint variable\nmethod (AVM), where the resulting adjoint boundary value problem can be also\nsolved by the IGBEM with a slight modification. The numerical verification and\ndemonstration validate our shape optimisation framework.",
    "descriptor": "",
    "authors": [
      "Toru Takahashi",
      "Daisuke Sato",
      "Hiroshi Isakari",
      "Toshiro Matsumoto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.04456"
  },
  {
    "id": "arXiv:2105.04458",
    "title": "Learning Robust Latent Representations for Controllable Speech Synthesis",
    "abstract": "State-of-the-art Variational Auto-Encoders (VAEs) for learning disentangled\nlatent representations give impressive results in discovering features like\npitch, pause duration, and accent in speech data, leading to highly\ncontrollable text-to-speech (TTS) synthesis. However, these LSTM-based VAEs\nfail to learn latent clusters of speaker attributes when trained on either\nlimited or noisy datasets. Further, different latent variables start encoding\nthe same features, limiting the control and expressiveness during speech\nsynthesis. To resolve these issues, we propose RTI-VAE (Reordered Transformer\nwith Information reduction VAE) where we minimize the mutual information\nbetween different latent variables and devise a modified Transformer\narchitecture with layer reordering to learn controllable latent representations\nin speech data. We show that RTI-VAE reduces the cluster overlap of speaker\nattributes by at least 30\\% over LSTM-VAE and by at least 7\\% over vanilla\nTransformer-VAE.",
    "descriptor": "\nComments: Accepted in ACL2021 Findings\n",
    "authors": [
      "Shakti Kumar",
      "Jithin Pradeep",
      "Hussain Zaidi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04458"
  },
  {
    "id": "arXiv:2105.04459",
    "title": "ICON: Learning Regular Maps Through Inverse Consistency",
    "abstract": "Learning maps between data samples is fundamental. Applications range from\nrepresentation learning, image translation and generative modeling, to the\nestimation of spatial deformations. Such maps relate feature vectors, or map\nbetween feature spaces. Well-behaved maps should be regular, which can be\nimposed explicitly or may emanate from the data itself. We explore what induces\nregularity for spatial transformations, e.g., when computing image\nregistrations. Classical optimization-based models compute maps between pairs\nof samples and rely on an appropriate regularizer for well-posedness. Recent\ndeep learning approaches have attempted to avoid using such regularizers\naltogether by relying on the sample population instead. We explore if it is\npossible to obtain spatial regularity using an inverse consistency loss only\nand elucidate what explains map regularity in such a context. We find that deep\nnetworks combined with an inverse consistency loss and randomized off-grid\ninterpolation yield well behaved, approximately diffeomorphic, spatial\ntransformations. Despite the simplicity of this approach, our experiments\npresent compelling evidence, on both synthetic and real data, that regular maps\ncan be obtained without carefully tuned explicit regularizers and competitive\nregistration performance.",
    "descriptor": "",
    "authors": [
      "Hastings Greer",
      "Roland Kwitt",
      "Francois-Xavier Vialard",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04459"
  },
  {
    "id": "arXiv:2105.04462",
    "title": "Friend or Foe: A Review and Synthesis of Computational Models of the  Identity Labeling Problem",
    "abstract": "We introduce the identity labeling problem - given an individual in a social\nsituation, can we predict what identity(ies) they will be labeled with by\nsomeone else? This problem remains a theoretical gap and methodological\nchallenge, evidenced by the fact that models of social-cognition often sidestep\nthe issue by treating identities as already known. We build on insights from\nexisting models to develop a new framework, entitled Latent Cognitive Social\nSpaces, that can incorporate multiple social cues including sentiment\ninformation, socio-demographic characteristics, and institutional associations\nto estimate the most culturally expected identity. We apply our model to data\ncollected in two vignette experiments, finding that it predicts identity\nlabeling choices of participants with a mean absolute error of 10.9%, a 100%\nimprovement over previous models based on parallel constraint satisfaction and\naffect control theory.",
    "descriptor": "\nComments: Accepted at Journal of Mathematical Sociology\n",
    "authors": [
      "Kenneth Joseph",
      "Jonathan Howard Morgan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04462"
  },
  {
    "id": "arXiv:2105.04471",
    "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for  Exponential Family Distributions",
    "abstract": "Uncertainty awareness is crucial to develop reliable machine learning models.\nIn this work, we propose the Natural Posterior Network (NatPN) for fast and\nhigh-quality uncertainty estimation for any task where the target distribution\nbelongs to the exponential family. Thus, NatPN finds application for both\nclassification and general regression settings. Unlike many previous\napproaches, NatPN does not require out-of-distribution (OOD) data at training\ntime. Instead, it leverages Normalizing Flows to fit a single density on a\nlearned low-dimensional and task-dependent latent space. For any input sample,\nNatPN uses the predicted likelihood to perform a Bayesian update over the\ntarget distribution. Theoretically, NatPN assigns high uncertainty far away\nfrom training data. Empirically, our extensive experiments on calibration and\nOOD detection show that NatPN delivers highly competitive performance for\nclassification, regression and count prediction tasks.",
    "descriptor": "",
    "authors": [
      "Bertrand Charpentier",
      "Oliver Borchert",
      "Daniel Z\u00fcgner",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04471"
  },
  {
    "id": "arXiv:2105.04472",
    "title": "Safety of the Intended Driving Behavior Using Rulebooks",
    "abstract": "Autonomous Vehicles (AVs) are complex systems that drive in uncertain\nenvironments and potentially navigate unforeseeable situations. Safety of these\nsystems requires not only an absence of malfunctions but also high performance\nof functions in many different scenarios. The ISO/PAS 21448 [1] guidance\nrecommends a process to ensure the Safety of the Intended Functionality (SOTIF)\nfor road vehicles. This process starts with a functional specification that\nfully describes the intended functionality and further includes the\nverification and validation that the AV meets this specification. For the path\nplanning function, defining the correct sequence of control actions for each\nvehicle in all potential driving situations is intractable. In this paper, the\nauthors provide a link between the Rulebooks framework, presented by [2], and\nthe SOTIF process. We establish that Rulebooks provide a functional description\nof the path planning task in an AV and discuss the potential usage of the\nmethod for verification and validation.",
    "descriptor": "",
    "authors": [
      "Anne Collin",
      "Artur Bilka",
      "Scott Pendleton",
      "Radboud Duintjer Tebbens"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04472"
  },
  {
    "id": "arXiv:2105.04475",
    "title": "Self-Guided Curriculum Learning for Neural Machine Translation",
    "abstract": "In the field of machine learning, the well-trained model is assumed to be\nable to recover the training labels, i.e. the synthetic labels predicted by the\nmodel should be as close to the ground-truth labels as possible. Inspired by\nthis, we propose a self-guided curriculum strategy to encourage the learning of\nneural machine translation (NMT) models to follow the above recovery criterion,\nwhere we cast the recovery degree of each training example as its learning\ndifficulty. Specifically, we adopt the sentence level BLEU score as the proxy\nof recovery degree. Different from existing curricula relying on linguistic\nprior knowledge or third-party language models, our chosen learning difficulty\nis more suitable to measure the degree of knowledge mastery of the NMT models.\nExperiments on translation benchmarks, including WMT14\nEnglish$\\Rightarrow$German and WMT17 Chinese$\\Rightarrow$English, demonstrate\nthat our approach can consistently improve translation performance against\nstrong baseline Transformer.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Lei Zhou",
      "Liang Ding",
      "Kevin Duh",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04475"
  },
  {
    "id": "arXiv:2105.04484",
    "title": "Towards Robust One-shot Task Execution using Knowledge Graph Embeddings",
    "abstract": "Requiring multiple demonstrations of a task plan presents a burden to\nend-users of robots. However, robustly executing tasks plans from a single\nend-user demonstration is an ongoing challenge in robotics. We address the\nproblem of one-shot task execution, in which a robot must generalize a single\ndemonstration or prototypical example of a task plan to a new execution\nenvironment. Our approach integrates task plans with domain knowledge to infer\ntask plan constituents for new execution environments. Our experimental\nevaluations show that our knowledge representation makes more relevant\ngeneralizations that result in significantly higher success rates over tested\nbaselines. We validated the approach on a physical platform, which resulted in\nthe successful generalization of initial task plans to 38 of 50 execution\nenvironments with errors resulting from autonomous robot operation included.",
    "descriptor": "\nComments: 7 pages, 3 figures. Accepted for publication at IEEE ICRA 2021\n",
    "authors": [
      "Angel Daruna",
      "Lakshmi Nair",
      "Weiyu Liu",
      "Sonia Chernova"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04484"
  },
  {
    "id": "arXiv:2105.04485",
    "title": "T-Cash: Transferable Fiat Backed Coins",
    "abstract": "Numerous electronic cash schemes have been proposed over the years - however\nnone have been embraced by financial institutions as an alternative to fiat\ncurrency. David Chaum's ecash scheme was the closest to something that mimicked\na modern day currency system, with the important property that it provided\nanonymity for users when purchasing coins from a bank, and subsequently\nspending them at a merchant premises. However it lacked a crucial element\npresent in current fiat-based systems - the ability to continuously spend or\ntransfer coins. Bitcoin reignited the interest in cryptocurrencies in the last\ndecade but is now seen as more of an asset store as opposed to a financial\ninstrument. One interesting thing that has come out of the Bitcoin system is\nblockchains and the associated distributed consensus protocols. In this paper\nwe propose a transferable electronic cash scheme using blockchain technology\nwhich allows users to continuously reuse coins within the system.",
    "descriptor": "",
    "authors": [
      "Hitesh Tewari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04485"
  },
  {
    "id": "arXiv:2105.04486",
    "title": "Probabilistic Top-k Dominating Queries in Distributed Uncertain  Databases",
    "abstract": "In many real-world applications such as business planning and sensor data\nmonitoring, one important, yet challenging, the task is to rank objects(e.g.,\nproducts, documents, or spatial objects) based on their ranking scores and\nefficiently return those objects with the highest scores. In practice, due to\nthe unreliability of data sources, many real-world objects often contain noises\nand are thus imprecise and uncertain. In this paper, we study the problem of\nprobabilistic top-k dominating(PTD) query on such large-scale uncertain data in\na distributed environment, which retrieves k uncertain objects from distributed\nuncertain databases(on multiple distributed servers), having the largest\nranking scores with high confidences. In order to efficiently tackle the\ndistributed PTD problem, we propose a MapReduce framework for processing\ndistributed PTD queries over distributed uncertain databases. In this MapReduce\nframework, we design effective pruning strategies to filter out false alarms in\nthe distributed setting, propose cost-model-based index distribution mechanisms\nover servers, and develop efficient distributed PTD query processing\nalgorithms. Extensive experiments have demonstrated the efficiency and\neffectiveness of our proposed distributed PTD approach on both real and\nsynthetic data sets through various experimental settings.",
    "descriptor": "",
    "authors": [
      "Niranjan Rai",
      "Xiang Lian"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.04486"
  },
  {
    "id": "arXiv:2105.04487",
    "title": "Tamper Detection against Unitary Operators",
    "abstract": "We consider (Enc, Dec) schemes which are used to encode a classical/quantum\nmessage $m$ and derive an $n$-qubit quantum codeword $\\psi_m$. The quantum\ncodeword $\\psi_m$ can adversarially tamper via a unitary $U \\in \\mathcal{U}$\nfrom some known tampering unitary family $\\mathcal{U}$, resulting in $U \\psi_m\nU^\\dagger$.\nFirstly, we initiate the general study of quantum tamper detection codes,\nwhich must detect that tampering occurred with high probability. In case there\nwas no tampering, we would like to output the message $m$ with a probability of\n$1$. We show that quantum tamper detection codes exist for both classical\nmessages and quantum messages for any family of unitaries $\\mathcal{U}$, such\nthat $|\\mathcal{U}| < 2^{2^{\\alpha n}}$ for some known constant $\\alpha \\in\n(0,1)$ and all the unitaries satisfy one additional condition :\n\\begin{itemize}\n\\item Far from Identity : For each $U \\in \\mathcal{U}$, we require that its\nmodulus of trace value isn't too much i.e. $ |Trace(U)| \\leq \\phi N$, where\n$N=2^n.$\n\\end{itemize}\nQuantum tamper-detection codes are quantum generalizations of classical\ntamper detection codes studied by Jafargholi et al. \\cite{JW15}.\nAdditionally for classical message $m$, if we must either output message $m$\nor detect that tampering occurred and output $\\perp$ with high probability, we\nshow that it is possible without the restriction of Far from Identity condition\nfor any family of unitaries $\\mathcal{U}$, such that $|\\mathcal{U} | <\n2^{2^{\\alpha n}}$. We also provide efficient (Enc, Dec) schemes when the family\nof tampering unitaries are from Pauli group $\\mathcal{P}_n$, which can be\nthought of as a quantum version of the algebraic manipulation detection (AMD)\ncodes of Cramer et al. \\cite{CDFPW08}.",
    "descriptor": "",
    "authors": [
      "Naresh Goud Boddu",
      "Upendra S. Kapshikar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04487"
  },
  {
    "id": "arXiv:2105.04488",
    "title": "A Deep Reinforcement Learning Approach to Audio-Based Navigation in a  Multi-Speaker Environment",
    "abstract": "In this work we use deep reinforcement learning to create an autonomous agent\nthat can navigate in a two-dimensional space using only raw auditory sensory\ninformation from the environment, a problem that has received very little\nattention in the reinforcement learning literature. Our experiments show that\nthe agent can successfully identify a particular target speaker among a set of\n$N$ predefined speakers in a room and move itself towards that speaker, while\navoiding collision with other speakers or going outside the room boundaries.\nThe agent is shown to be robust to speaker pitch shifting and it can learn to\nnavigate the environment, even when a limited number of training utterances are\navailable for each speaker.",
    "descriptor": "\nComments: To be published in ICASSP 2021\n",
    "authors": [
      "Petros Giannakopoulos",
      "Aggelos Pikrakis",
      "Yannis Cotronis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04488"
  },
  {
    "id": "arXiv:2105.04489",
    "title": "Spoken Moments: Learning Joint Audio-Visual Representations from Video  Descriptions",
    "abstract": "When people observe events, they are able to abstract key information and\nbuild concise summaries of what is happening. These summaries include\ncontextual and semantic information describing the important high-level details\n(what, where, who and how) of the observed event and exclude background\ninformation that is deemed unimportant to the observer. With this in mind, the\ndescriptions people generate for videos of different dynamic events can greatly\nimprove our understanding of the key information of interest in each video.\nThese descriptions can be captured in captions that provide expanded attributes\nfor video labeling (e.g. actions/objects/scenes/sentiment/etc.) while allowing\nus to gain new insight into what people find important or necessary to\nsummarize specific events. Existing caption datasets for video understanding\nare either small in scale or restricted to a specific domain. To address this,\nwe present the Spoken Moments (S-MiT) dataset of 500k spoken captions each\nattributed to a unique short video depicting a broad range of different events.\nWe collect our descriptions using audio recordings to ensure that they remain\nas natural and concise as possible while allowing us to scale the size of a\nlarge classification dataset. In order to utilize our proposed dataset, we\npresent a novel Adaptive Mean Margin (AMM) approach to contrastive learning and\nevaluate our models on video/caption retrieval on multiple datasets. We show\nthat our AMM approach consistently improves our results and that models trained\non our Spoken Moments dataset generalize better than those trained on other\nvideo-caption datasets.",
    "descriptor": "\nComments: To appear at CVPR 2021\n",
    "authors": [
      "Mathew Monfort",
      "SouYoung Jin",
      "Alexander Liu",
      "David Harwath",
      "Rogerio Feris",
      "James Glass",
      "Aude Oliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.04489"
  },
  {
    "id": "arXiv:2105.04493",
    "title": "Graph Feature Gating Networks",
    "abstract": "Graph neural networks (GNNs) have received tremendous attention due to their\npower in learning effective representations for graphs. Most GNNs follow a\nmessage-passing scheme where the node representations are updated by\naggregating and transforming the information from the neighborhood. Meanwhile,\nthey adopt the same strategy in aggregating the information from different\nfeature dimensions. However, suggested by social dimension theory and spectral\nembedding, there are potential benefits to treat the dimensions differently\nduring the aggregation process. In this work, we investigate to enable\nheterogeneous contributions of feature dimensions in GNNs. In particular, we\npropose a general graph feature gating network (GFGN) based on the graph signal\ndenoising problem and then correspondingly introduce three graph filters under\nGFGN to allow different levels of contributions from feature dimensions.\nExtensive experiments on various real-world datasets demonstrate the\neffectiveness and robustness of the proposed frameworks.",
    "descriptor": "",
    "authors": [
      "Wei Jin",
      "Xiaorui Liu",
      "Yao Ma",
      "Tyler Derr",
      "Charu Aggarwal",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04493"
  },
  {
    "id": "arXiv:2105.04501",
    "title": "Incorrectness Logic for Graph Programs",
    "abstract": "Program logics typically reason about an over-approximation of program\nbehaviour to prove the absence of bugs. Recently, program logics have been\nproposed that instead prove the presence of bugs by means of under-approximate\nreasoning, which has the promise of better scalability. In this paper, we\npresent an under-approximate program logic for a nondeterministic graph\nprogramming language, and show how it can be used to reason deductively about\nprogram incorrectness, whether defined by the presence of forbidden graph\nstructure or by finitely failing executions. We prove this incorrectness logic\nto be sound and complete, and speculate on some possible future applications of\nit.",
    "descriptor": "\nComments: Accepted by the 14th International Conference on Graph Transformation (ICGT 2021)\n",
    "authors": [
      "Christopher M. Poskitt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.04501"
  },
  {
    "id": "arXiv:2105.04505",
    "title": "Towards Benchmarking the Utility of Explanations for Model Debugging",
    "abstract": "Post-hoc explanation methods are an important class of approaches that help\nunderstand the rationale underlying a trained model's decision. But how useful\nare they for an end-user towards accomplishing a given task? In this vision\npaper, we argue the need for a benchmark to facilitate evaluations of the\nutility of post-hoc explanation methods. As a first step to this end, we\nenumerate desirable properties that such a benchmark should possess for the\ntask of debugging text classifiers. Additionally, we highlight that such a\nbenchmark facilitates not only assessing the effectiveness of explanations but\nalso their efficiency.",
    "descriptor": "\nComments: Short paper, to appear at TrustNLP @ NAACL 2021\n",
    "authors": [
      "Maximilian Idahl",
      "Lijun Lyu",
      "Ujwal Gadiraju",
      "Avishek Anand"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04505"
  },
  {
    "id": "arXiv:2105.04508",
    "title": "MDA-Net: Multi-Dimensional Attention-Based Neural Network for 3D Image  Segmentation",
    "abstract": "Segmenting an entire 3D image often has high computational complexity and\nrequires large memory consumption; by contrast, performing volumetric\nsegmentation in a slice-by-slice manner is efficient but does not fully\nleverage the 3D data. To address this challenge, we propose a multi-dimensional\nattention network (MDA-Net) to efficiently integrate slice-wise, spatial, and\nchannel-wise attention into a U-Net based network, which results in high\nsegmentation accuracy with a low computational cost. We evaluate our model on\nthe MICCAI iSeg and IBSR datasets, and the experimental results demonstrate\nconsistent improvements over existing methods.",
    "descriptor": "",
    "authors": [
      "Rutu Gandhi",
      "Yi Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.04508"
  },
  {
    "id": "arXiv:2105.04512",
    "title": "UPC's Speech Translation System for IWSLT 2021",
    "abstract": "This paper describes the submission to the IWSLT 2021 offline speech\ntranslation task by the UPC Machine Translation group. The task consists of\nbuilding a system capable of translating English audio recordings extracted\nfrom TED talks into German text. Submitted systems can be either cascade or\nend-to-end and use a custom or given segmentation. Our submission is an\nend-to-end speech translation system, which combines pre-trained models\n(Wav2Vec 2.0 and mBART) with coupling modules between the encoder and decoder,\nand uses an efficient fine-tuning technique, which trains only 20% of its total\nparameters. We show that adding an Adapter to the system and pre-training it,\ncan increase the convergence speed and the final result, with which we achieve\na BLEU score of 27.3 on the MuST-C test set. Our final model is an ensemble\nthat obtains 28.22 BLEU score on the same set. Our submission also uses a\ncustom segmentation algorithm that employs pre-trained Wav2Vec 2.0 for\nidentifying periods of untranscribable text and can bring improvements of 2.5\nto 3 BLEU score on the IWSLT 2019 test set, as compared to the result with the\ngiven segmentation.",
    "descriptor": "\nComments: Submitted to IWSLT 2021\n",
    "authors": [
      "Gerard I. G\u00e1llego",
      "Ioannis Tsiamas",
      "Carlos Escolano",
      "Jos\u00e9 A. R. Fonollosa",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04512"
  },
  {
    "id": "arXiv:2105.04515",
    "title": "An end-to-end Optical Character Recognition approach for  ultra-low-resolution printed text images",
    "abstract": "Some historical and more recent printed documents have been scanned or stored\nat very low resolutions, such as 60 dpi. Though such scans are relatively easy\nfor humans to read, they still present significant challenges for optical\ncharacter recognition (OCR) systems. The current state-of-the art is to use\nsuper-resolution to reconstruct an approximation of the original\nhigh-resolution image and to feed this into a standard OCR system. Our novel\nend-to-end method bypasses the super-resolution step and produces better OCR\nresults. This approach is inspired from our understanding of the human visual\nsystem, and builds on established neural networks for performing OCR.\nOur experiments have shown that it is possible to perform OCR on 60 dpi\nscanned images of English text, which is a significantly lower resolution than\nthe state-of-the-art, and we achieved a mean character level accuracy (CLA) of\n99.7% and word level accuracy (WLA) of 98.9% across a set of about 1000 pages\nof 60 dpi text in a wide range of fonts. For 75 dpi images, the mean CLA was\n99.9% and the mean WLA was 99.4% on the same sample of texts. We make our code\nand data (including a set of low-resolution images with their ground truths)\npublicly available as a benchmark for future work in this field.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Julian D. Gilbey",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04515"
  },
  {
    "id": "arXiv:2105.04522",
    "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy  Labels",
    "abstract": "We propose two novel loss functions based on Jensen-Shannon divergence for\nlearning under label noise. Following the work of Ghosh et al. (2017), we argue\nabout their theoretical robustness. Furthermore, we reveal several other\ndesirable properties by drawing informative connections to various loss\nfunctions, e.g., cross entropy, mean absolute error, generalized cross entropy,\nsymmetric cross entropy, label smoothing, and most importantly consistency\nregularization. We conduct extensive and systematic experiments using both\nsynthetic (CIFAR) and real (WebVision) noise and demonstrate significant and\nconsistent improvements over other loss functions. Also, we conduct several\ninformative side experiments that highlight the different theoretical\nproperties.",
    "descriptor": "",
    "authors": [
      "Erik Englesson",
      "Hossein Azizpour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04522"
  },
  {
    "id": "arXiv:2105.04524",
    "title": "AP-side WLAN Analytics",
    "abstract": "Monitoring the network performance experienced by the end-user is crucial for\nmanagers of wireless networks as it can enable them to remotely modify the\nnetwork parameters to improve the end-user experience. Unfortunately, for\nperformance monitoring, managers are typically limited to the logs of the\nAccess Points (APs) that they manage. This information does not directly\ncapture factors that can hinder station (STA) side transmissions. Consequently,\nstate-of-the-art methods to measure such metrics primarily involve active\nmeasurements. Unfortunately, such active measurements increase traffic load and\nif used regularly and for all the STAs can potentially disrupt user traffic,\nthereby worsening performance for other users in the network and draining the\nbattery of mobile devices.\nThis thesis enables passive AP-side network analytics. In the first part of\nthe thesis, I present virtual speed test, a measurement based framework that\nenables an AP to estimate speed test results for any of its associated clients\nsolely based on AP-side observables. Next, I present Uplink Latency Microscope\n(uScope), an AP-side framework for estimation of WLAN uplink latency for any of\nthe associated STAs and decomposition into its constituent components. Similar\nto virtual speed test, uScope makes estimations solely based on passive AP-side\nobservations. We implement both frameworks on a commodity hardware platform and\nconduct extensive field trials on a university campus and in a residential\napartment complex. In over 1 million tests, the two proposed frameworks\ndemonstrate an estimation accuracy with errors under 10%.",
    "descriptor": "",
    "authors": [
      "Peshal Nayak"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.04524"
  },
  {
    "id": "arXiv:2105.04528",
    "title": "Accelerating Large Scale Real-Time GNN Inference using Channel Pruning",
    "abstract": "Graph Neural Networks (GNNs) are proven to be powerful models to generate\nnode embedding for downstream applications. However, due to the high\ncomputation complexity of GNN inference, it is hard to deploy GNNs for\nlarge-scale or real-time applications. In this paper, we propose to accelerate\nGNN inference by pruning the dimensions in each layer with negligible accuracy\nloss. Our pruning framework uses a novel LASSO regression formulation for GNNs\nto identify feature dimensions (channels) that have high influence on the\noutput activation. We identify two inference scenarios and design pruning\nschemes based on their computation and memory usage for each. To further reduce\nthe inference complexity, we effectively store and reuse hidden features of\nvisited nodes, which significantly reduces the number of supporting nodes\nneeded to compute the target embedding. We evaluate the proposed method with\nthe node classification problem on five popular datasets and a real-time spam\ndetection application. We demonstrate that the pruned GNN models greatly reduce\ncomputation and memory usage with little accuracy loss. For full inference, the\nproposed method achieves an average of 3.27x speedup with only 0.002 drop in\nF1-Micro on GPU. For batched inference, the proposed method achieves an average\nof 6.67x speedup with only 0.003 drop in F1-Micro on CPU. To the best of our\nknowledge, we are the first to accelerate large scale real-time GNN inference\nthrough channel pruning.",
    "descriptor": "",
    "authors": [
      "Hongkuan Zhou",
      "Ajitesh Srivastava",
      "Hanqing Zeng",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04528"
  },
  {
    "id": "arXiv:2105.04529",
    "title": "Identification of the nonlinear steering dynamics of an autonomous  vehicle",
    "abstract": "Automated driving applications require accurate vehicle specific models to\nprecisely predict and control the motion dynamics. However, modern vehicles\nhave a wide array of digital and mechatronic components that are difficult to\nmodel, manufactures do not disclose all details required for modelling and even\nexisting models of subcomponents require coefficient estimation to match the\nspecific characteristics of each vehicle and their change over time. Hence, it\nis attractive to use data-driven modelling to capture the relevant vehicle\ndynamics and synthesise model-based control solutions. In this paper, we\naddress identification of the steering system of an autonomous car based on\nmeasured data. We show that the underlying dynamics are highly nonlinear and\nchallenging to be captured, necessitating the use of data-driven methods that\nfuse the approximation capabilities of learning and the efficiency of dynamic\nsystem identification. We demonstrate that such a neural network based\nsubspace-encoder method can successfully capture the underlying dynamics while\nother methods fall short to provide reliable results.",
    "descriptor": "\nComments: Accepted to SYSID 2021 (revised with reviewer feedback)\n",
    "authors": [
      "G. R\u00f6d\u00f6nyi",
      "G. I. Beintema",
      "R. T\u00f3th",
      "M. Schoukens",
      "D. Pup",
      "\u00c1. Kisari",
      "Zs. V\u00edgh",
      "P. K\u0151r\u00f6s",
      "A. Soumelidis",
      "J. Bokor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04529"
  },
  {
    "id": "arXiv:2105.04534",
    "title": "Improving Fairness of AI Systems with Lossless De-biasing",
    "abstract": "In today's society, AI systems are increasingly used to make critical\ndecisions such as credit scoring and patient triage. However, great convenience\nbrought by AI systems comes with troubling prevalence of bias against\nunderrepresented groups. Mitigating bias in AI systems to increase overall\nfairness has emerged as an important challenge. Existing studies on mitigating\nbias in AI systems focus on eliminating sensitive demographic information\nembedded in data. Given the temporal and contextual complexity of\nconceptualizing fairness, lossy treatment of demographic information may\ncontribute to an unnecessary trade-off between accuracy and fairness,\nespecially when demographic attributes and class labels are correlated. In this\npaper, we present an information-lossless de-biasing technique that targets the\nscarcity of data in the disadvantaged group. Unlike the existing work, we\ndemonstrate, both theoretically and empirically, that oversampling\nunderrepresented groups can not only mitigate algorithmic bias in AI systems\nthat consistently predict a favorable outcome for a certain group, but improve\noverall accuracy by mitigating class imbalance within data that leads to a bias\ntowards the majority class. We demonstrate the effectiveness of our technique\non real datasets using a variety of fairness metrics.",
    "descriptor": "\nComments: 8 pages, 19 figures\n",
    "authors": [
      "Yan Zhou",
      "Murat Kantarcioglu",
      "Chris Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04534"
  },
  {
    "id": "arXiv:2105.04538",
    "title": "Learning High-Dimensional Distributions with Latent Neural Fokker-Planck  Kernels",
    "abstract": "Learning high-dimensional distributions is an important yet challenging\nproblem in machine learning with applications in various domains. In this\npaper, we introduce new techniques to formulate the problem as solving\nFokker-Planck equation in a lower-dimensional latent space, aiming to mitigate\nchallenges in high-dimensional data space. Our proposed model consists of\nlatent-distribution morphing, a generator and a parameterized Fokker-Planck\nkernel function. One fascinating property of our model is that it can be\ntrained with arbitrary steps of latent distribution morphing or even without\nmorphing, which makes it flexible and as efficient as Generative Adversarial\nNetworks (GANs). Furthermore, this property also makes our latent-distribution\nmorphing an efficient plug-and-play scheme, thus can be used to improve\narbitrary GANs, and more interestingly, can effectively correct failure cases\nof the GAN models. Extensive experiments illustrate the advantages of our\nproposed method over existing models.",
    "descriptor": "\nComments: code will be updated at this https URL\n",
    "authors": [
      "Yufan Zhou",
      "Changyou Chen",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04538"
  },
  {
    "id": "arXiv:2105.04544",
    "title": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment  Restriction",
    "abstract": "We address the problem of causal effect estimation in the presence of\nunobserved confounding, but where proxies for the latent confounder(s) are\nobserved. We propose two kernel-based methods for nonlinear causal effect\nestimation in this setting: (a) a two-stage regression approach, and (b) a\nmaximum moment restriction approach. We focus on the proximal causal learning\nsetting, but our methods can be used to solve a wider class of inverse problems\ncharacterised by a Fredholm integral equation. In particular, we provide a\nunifying view of two-stage and moment restriction approaches for solving this\nproblem in a nonlinear setting. We provide consistency guarantees for each\nalgorithm, and we demonstrate these approaches achieve competitive results on\nsynthetic data and data simulating a real-world task. In particular, our\napproach outperforms earlier methods that are not suited to leveraging proxy\nvariables.",
    "descriptor": "",
    "authors": [
      "Afsaneh Mastouri",
      "Yuchen Zhu",
      "Limor Gultchin",
      "Anna Korba",
      "Ricardo Silva",
      "Matt J. Kusner",
      "Arthur Gretton",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04544"
  },
  {
    "id": "arXiv:2105.04547",
    "title": "Large-scale memory failure prediction using mcelog-based Data Mining and  Machine Learning",
    "abstract": "In the data center, unexpected downtime caused by memory failures can lead to\na decline in the stability of the server and even the entire information\ntechnology infrastructure, which harms the business. Therefore, whether the\nmemory failure can be accurately predicted in advance has become one of the\nmost important issues to be studied in the data center. However, for the memory\nfailure prediction in the production system, it is necessary to solve technical\nproblems such as huge data noise and extreme imbalance between positive and\nnegative samples, and at the same time ensure the long-term stability of the\nalgorithm. This paper compares and summarizes some commonly used skills and the\nimprovement they can bring. The single model we proposed won the top 15th in\nthe 2nd Alibaba Cloud AIOps Competition belonging to the 25th Pacific-Asia\nConference on Knowledge Discovery and Data Mining.",
    "descriptor": "\nComments: 11 pages, 2 figures, 1 table. Detailed solution will be open source to this https URL after the competition is over\n",
    "authors": [
      "Chengdong Yao"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04547"
  },
  {
    "id": "arXiv:2105.04550",
    "title": "Optimization of Graph Neural Networks: Implicit Acceleration by Skip  Connections and More Depth",
    "abstract": "Graph Neural Networks (GNNs) have been studied from the lens of expressive\npower and generalization. However, their optimization properties are less well\nunderstood. We take the first step towards analyzing GNN training by studying\nthe gradient dynamics of GNNs. First, we analyze linearized GNNs and prove that\ndespite the non-convexity of training, convergence to a global minimum at a\nlinear rate is guaranteed under mild assumptions that we validate on real-world\ngraphs. Second, we study what may affect the GNNs' training speed. Our results\nshow that the training of GNNs is implicitly accelerated by skip connections,\nmore depth, and/or a good label distribution. Empirical results confirm that\nour theoretical results for linearized GNNs align with the training behavior of\nnonlinear GNNs. Our results provide the first theoretical support for the\nsuccess of GNNs with skip connections in terms of optimization, and suggest\nthat deep GNNs with skip connections would be promising in practice.",
    "descriptor": "",
    "authors": [
      "Keyulu Xu",
      "Mozhi Zhang",
      "Stefanie Jegelka",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04550"
  },
  {
    "id": "arXiv:2105.04551",
    "title": "Stochastic Image-to-Video Synthesis using cINNs",
    "abstract": "Video understanding calls for a model to learn the characteristic interplay\nbetween static scene content and its dynamics: Given an image, the model must\nbe able to predict a future progression of the portrayed scene and, conversely,\na video should be explained in terms of its static image content and all the\nremaining characteristics not present in the initial frame. This naturally\nsuggests a bijective mapping between the video domain and the static content as\nwell as residual information. In contrast to common stochastic image-to-video\nsynthesis, such a model does not merely generate arbitrary videos progressing\nthe initial image. Given this image, it rather provides a one-to-one mapping\nbetween the residual vectors and the video with stochastic outcomes when\nsampling. The approach is naturally implemented using a conditional invertible\nneural network (cINN) that can explain videos by independently modelling static\nand other video characteristics, thus laying the basis for controlled video\nsynthesis. Experiments on four diverse video datasets demonstrate the\neffectiveness of our approach in terms of both the quality and diversity of the\nsynthesized results. Our project page is available at https://bit.ly/3t66bnU.",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Michael Dorkenwald",
      "Timo Milbich",
      "Andreas Blattmann",
      "Robin Rombach",
      "Konstantinos G. Derpanis",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04551"
  },
  {
    "id": "arXiv:2105.04553",
    "title": "Self-Supervised Learning with Swin Transformers",
    "abstract": "We are witnessing a modeling shift from CNN to Transformers in computer\nvision. In this paper, we present a self-supervised learning approach called\nMoBY, with Vision Transformers as its backbone architecture. The approach is\nbasically a combination of MoCo v2 and BYOL, tuned to achieve reasonably high\naccuracy on ImageNet-1K linear evaluation: 72.8% and 75.0% top-1 accuracy using\nDeiT-S and Swin-T, respectively, by 300-epoch training. The performance is\nslightly better than recent works of MoCo v3 and DINO which adopt DeiT as the\nbackbone, but with much lighter tricks.\nMore importantly, the general-purpose Swin Transformer backbone enables us to\nalso evaluate the learnt representations on downstream tasks such as object\ndetection and semantic segmentation, in contrast to a few recent approaches\nbuilt on ViT/DeiT which only report linear evaluation results on ImageNet-1K\ndue to ViT/DeiT not tamed for these dense prediction tasks. We hope our results\ncan facilitate more comprehensive evaluation of self-supervised learning\nmethods designed for Transformer architectures. Our code and models are\navailable at https://github.com/SwinTransformer/Transformer-SSL, which will be\ncontinually enriched.",
    "descriptor": "",
    "authors": [
      "Zhenda Xie",
      "Yutong Lin",
      "Zhuliang Yao",
      "Zheng Zhang",
      "Qi Dai",
      "Yue Cao",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04553"
  },
  {
    "id": "arXiv:2105.04554",
    "title": "Local approximate Gaussian process regression for data-driven  constitutive laws: Development and comparison with neural networks",
    "abstract": "Hierarchical computational methods for multiscale mechanics such as the\nFE$^2$ and FE-FFT methods are generally accompanied by high computational\ncosts. Data-driven approaches are able to speed the process up significantly by\nenabling to incorporate the effective micromechanical response in macroscale\nsimulations without the need of performing additional computations at each\nGauss point explicitly. Traditionally artificial neural networks (ANNs) have\nbeen the surrogate modeling technique of choice in the solid mechanics\ncommunity. However they suffer from severe drawbacks due to their parametric\nnature and suboptimal training and inference properties for the investigated\ndatasets in a three dimensional setting. These problems can be avoided using\nlocal approximate Gaussian process regression (laGPR). This method can allow\nthe prediction of stress outputs at particular strain space locations by\ntraining local regression models based on Gaussian processes, using only a\nsubset of the data for each local model, offering better and more reliable\naccuracy than ANNs. A modified Newton-Raphson approach is proposed to\naccommodate for the local nature of the laGPR approximation when solving the\nglobal structural problem in a FE setting. Hence, the presented work offers a\ncomplete and general framework enabling multiscale calculations combining a\ndata-driven constitutive prediction using laGPR, and macroscopic calculations\nusing an FE scheme that we test for finite-strain three-dimensional\nhyperelastic problems.",
    "descriptor": "\nComments: 22 pages, 15 figures\n",
    "authors": [
      "Jan Niklas Fuhg",
      "Michele Marino",
      "Nikolaos Bouklas"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04554"
  },
  {
    "id": "arXiv:1811.12759",
    "title": "A Decentralized Event-Based Approach for Robust Model Predictive Control",
    "abstract": "In this paper, we propose an event-based sampling policy to implement a\nconstraint-tightening, robust MPC method. The proposed policy enjoys a\ncomputationally tractable design and is applicable to perturbed, linear\ntime-invariant systems with polytopic constraints. In particular, the\ntriggering mechanism is suitable for plants with no centralized sensory node as\nthe triggering mechanism can be evaluated locally at each individual sensor.\nFrom a geometrical viewpoint, the mechanism is a sequence of hyper-rectangles\nsurrounding the optimal state trajectory such that robust recursive feasibility\nand robust stability are guaranteed. The design of the triggering mechanism is\ncast as a constrained parametric-in-set optimization problem with the volume of\nthe set as the objective function. Re-parameterized in terms of the set\nvertices, we show that the problem admits a finite tractable convex program\nreformulation and a linear program relaxation. Several numerical examples are\npresented to demonstrate the effectiveness and limitations of the theoretical\nresults.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Arman Sharifi Kolarijani",
      "Sander Bregman",
      "Peyman Mohajerin Esfahani",
      "Tamas Keviczky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1811.12759"
  },
  {
    "id": "arXiv:2008.10362",
    "title": "Fast Approximate Dynamic Programming for Input-Affine Dynamics",
    "abstract": "We propose two novel numerical schemes for approximate implementation of the\nDynamic Programming (DP) operation concerned with finite-horizon optimal\ncontrol of discrete-time, stochastic systems with input-affine dynamics. The\nproposed algorithms involve discretization of the state and input spaces, and\nare based on an alternative path that solves the dual problem corresponding to\nthe DP operation. We provide error bounds for the proposed algorithms, along\nwith a detailed analyses of their computational complexity. In particular, for\na specific class of problems with separable data in the state and input\nvariables, the proposed approach can reduce the typical time complexity of the\nDP operation from O(XU) to O(X+U) where X and U denote the size of the discrete\nstate and input spaces, respectively. In a broader perspective, the key\ncontribution here can be viewed as an algorithmic transformation of the\nminimization in DP operation to addition via discrete conjugation. This bridge\nenables us to utilize any complexity reduction on the discrete conjugation\nfront within the proposed algorithms. In particular, motivated by the recent\ndevelopment of quantum algorithms for computing the discrete conjugate\ntransform, we discuss the possibility of a quantum mechanical implementation of\nthe proposed algorithms.",
    "descriptor": "",
    "authors": [
      "M. A. S. Kolarijani",
      "P. Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.10362"
  },
  {
    "id": "arXiv:2102.08880",
    "title": "Fast Approximate Dynamic Programming for Infinite-Horizon  Continuous-State Markov Decision Processes",
    "abstract": "In this article, we consider the infinite-horizon, discounted cost, optimal\ncontrol of discrete-time systems with separable cost and constraint in the\nstate and input variables. Starting from deterministic linear dynamics, we\nintroduce a novel numerical algorithm for implementation of the value iteration\n(VI) algorithm in the conjugate domain, using the Linear-time Legendre\nTransform algorithm. Detailed analyses of the convergence, complexity, and\nerror of the proposed algorithm are provided. In particular, with a\ndiscretization of size $X$ and $U$ for the state and input spaces,\nrespectively, the proposed approach can reduce the time complexity of each\niteration of the VI algorithm from $O(XU)$ to $O(X)$, by replacing the\nminimization operation in the primal domain with a simple addition in the\nconjugate domain. Also discussed are the direct extensions of the proposed\nalgorithm for nonlinear dynamics and stochastic dynamics with additive noise.",
    "descriptor": "\nComments: 17 pages, 1 figure. arXiv admin note: text overlap with arXiv:2008.10362\n",
    "authors": [
      "M. A. S. Kolarijani",
      "G. F. Max",
      "P. Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.08880"
  },
  {
    "id": "arXiv:2104.14929",
    "title": "On In-network learning. A Comparative Study with Federated and Split  Learning",
    "abstract": "In this paper, we consider a problem in which distributively extracted\nfeatures are used for performing inference in wireless networks. We elaborate\non our proposed architecture, which we herein refer to as \"in-network\nlearning\", provide a suitable loss function and discuss its optimization using\nneural networks. We compare its performance with both Federated- and Split\nlearning; and show that this architecture offers both better accuracy and\nbandwidth savings.",
    "descriptor": "\nComments: Submitted to the 2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), special session on Machine learning at the Edge\n",
    "authors": [
      "Matei Moldoveanu",
      "Abdellatif Zaidi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14929"
  },
  {
    "id": "arXiv:2105.02180",
    "title": "A unifying tutorial on Approximate Message Passing",
    "abstract": "Over the last decade or so, Approximate Message Passing (AMP) algorithms have\nbecome extremely popular in various structured high-dimensional statistical\nproblems. The fact that the origins of these techniques can be traced back to\nnotions of belief propagation in the statistical physics literature lends a\ncertain mystique to the area for many statisticians. Our goal in this work is\nto present the main ideas of AMP from a statistical perspective, to illustrate\nthe power and flexibility of the AMP framework. Along the way, we strengthen\nand unify many of the results in the existing literature.",
    "descriptor": "\nComments: 99 pages, 2 figures\n",
    "authors": [
      "Oliver Y. Feng",
      "Ramji Venkataramanan",
      "Cynthia Rush",
      "Richard J. Samworth"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02180"
  },
  {
    "id": "arXiv:2105.03511",
    "title": "Bounds for the sum of distances of spherical sets of small size",
    "abstract": "We derive upper and lower bounds on the sum of distances of a spherical code\nof size $N$ in $n$ dimensions when $N\\sim n^\\alpha, 0<\\alpha\\le 2.$ The bounds\nare derived by specializing recent general, universal bounds on energy of\nspherical sets. We discuss asymptotic behavior of our bounds along with several\nexamples of codes whose sum of distances closely follows the upper bound.",
    "descriptor": "\nComments: 18 pp\n",
    "authors": [
      "Alexander Barg",
      "Peter Boyvalenkov",
      "Maya Stoyanova"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.03511"
  },
  {
    "id": "arXiv:2105.03538",
    "title": "Equivalent formulations of the oxygen depletion problem, other implicit  free boundary value problems, and implications for numerical approximation",
    "abstract": "The Oxygen Depletion problem is an implicit free boundary value problem. The\ndynamics allow topological changes in the free boundary. We show several\nmathematical formulations of this model from the literature and give a new\nformulation based on a gradient flow with constraint. All formulations are\nshown to be equivalent. We explore the possibilities for the numerical\napproximation of the problem that arise from the different formulations. We\nshow a convergence result for an approximation based on the gradient flow with\nconstraint formulation that applies to the general dynamics including\ntopological changes. More general (vector, higher order) implicit free boundary\nvalue problems are discussed. Several open problems are described.",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Xinyu Cheng",
      "Zhaohui Fu",
      "Brian Wetton"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03538"
  },
  {
    "id": "arXiv:2105.03542",
    "title": "Zero-Shot Personalized Speech Enhancement through Speaker-Informed Model  Selection",
    "abstract": "This paper presents a novel zero-shot learning approach towards personalized\nspeech enhancement through the use of a sparsely active ensemble model.\nOptimizing speech denoising systems towards a particular test-time speaker can\nimprove performance and reduce run-time complexity. However, test-time model\nadaptation may be challenging if collecting data from the test-time speaker is\nnot possible. To this end, we propose using an ensemble model wherein each\nspecialist module denoises noisy utterances from a distinct partition of\ntraining set speakers. The gating module inexpensively estimates test-time\nspeaker characteristics in the form of an embedding vector and selects the most\nappropriate specialist module for denoising the test signal. Grouping the\ntraining set speakers into non-overlapping semantically similar groups is\nnon-trivial and ill-defined. To do this, we first train a Siamese network using\nnoisy speech pairs to maximize or minimize the similarity of its output vectors\ndepending on whether the utterances derive from the same speaker or not. Next,\nwe perform k-means clustering on the latent space formed by the averaged\nembedding vectors per training set speaker. In this way, we designate speaker\ngroups and train specialist modules optimized around partitions of the complete\ntraining set. Our experiments show that ensemble models made up of low-capacity\nspecialists can outperform high-capacity generalist models with greater\nefficiency and improved adaptation towards unseen test-time speakers.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to 2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)\n",
    "authors": [
      "Aswin Sivaraman",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03542"
  },
  {
    "id": "arXiv:2105.03544",
    "title": "Test-Time Adaptation Toward Personalized Speech Enhancement: Zero-Shot  Learning with Knowledge Distillation",
    "abstract": "In realistic speech enhancement settings for end-user devices, we often\nencounter only a few speakers and noise types that tend to reoccur in the\nspecific acoustic environment. We propose a novel personalized speech\nenhancement method to adapt a compact denoising model to the test-time\nspecificity. Our goal in this test-time adaptation is to utilize no clean\nspeech target of the test speaker, thus fulfilling the requirement for\nzero-shot learning. To complement the lack of clean utterance, we employ the\nknowledge distillation framework. Instead of the missing clean utterance\ntarget, we distill the more advanced denoising results from an overly large\nteacher model, and use it as the pseudo target to train the small student\nmodel. This zero-shot learning procedure circumvents the process of collecting\nusers' clean speech, a process that users are reluctant to comply due to\nprivacy concerns and technical difficulty of recording clean voice. Experiments\non various test-time conditions show that the proposed personalization method\nachieves significant performance gains compared to larger baseline networks\ntrained from a large speaker- and noise-agnostic datasets. In addition, since\nthe compact personalized models can outperform larger general-purpose models,\nwe claim that the proposed method performs model compression with no loss of\ndenoising performance.",
    "descriptor": "\nComments: 5 pages, 5 figures, under review\n",
    "authors": [
      "Sunwoo Kim",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03544"
  },
  {
    "id": "arXiv:2105.03556",
    "title": "Inside the Binary Reflected Gray Code: Flip-Swap Languages in 2-Gray  Code Order",
    "abstract": "A flip-swap language is a set S of binary strings of length n such that $S\n\\cup 0^n$ is closed under two operations (when applicable): (1) Flip the\nleftmost 1; and (2) Swap the leftmost 1 with the bit to its right. Flip-swap\nlanguages model many combinatorial objects including necklaces, Lyndon words,\nprefix normal words, left factors of k-ary Dyck words, and feasible solutions\nto 0-1 knapsack problems. We prove that any flip-swap language forms a cyclic\n2-Gray code when listed in binary reflected Gray code (BRGC) order.\nFurthermore, a generic successor rule computes the next string when provided\nwith a membership tester. The rule generates each string in the aforementioned\nflip-swap languages in O(n)-amortized per string, except for prefix normal\nwords of length n which require O($n^{1.864}$)-amortized per string. Our work\ngeneralizes results on necklaces and Lyndon words by Vajnovski [Inf. Process.\nLett. 106(3):96$-$99, 2008].",
    "descriptor": "",
    "authors": [
      "Joe Sawada",
      "Aaron Williams",
      "Dennis Wong"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.03556"
  },
  {
    "id": "arXiv:2105.03568",
    "title": "ChaRRNets: Channel Robust Representation Networks for RF Fingerprinting",
    "abstract": "We present complex-valued Convolutional Neural Networks (CNNs) for RF\nfingerprinting that go beyond translation invariance and appropriately account\nfor the inductive bias with respect to multipath propagation channels, a\nphenomenon that is specific to the fields of wireless signal processing and\ncommunications. We focus on the problem of fingerprinting wireless IoT devices\nin-the-wild using Deep Learning (DL) techniques. Under these real-world\nconditions, the multipath environments represented in the train and test sets\nwill be different. These differences are due to the physics governing the\npropagation of wireless signals, as well as the limitations of practical data\ncollection campaigns. Our approach follows a group-theoretic framework,\nleverages prior work on DL on manifold-valued data, and extends this prior work\nto the wireless signal processing domain. We introduce the Lie group of\ntransformations that a signal experiences under the multipath propagation model\nand define operations that are equivariant and invariant to the frequency\nresponse of a Finite Impulse Response (FIR) filter to build a ChaRRNet. We\npresent results using synthetic and real-world datasets, and we benchmark\nagainst a strong baseline model, that show the efficacy of our approach. Our\nresults provide evidence of the benefits of incorporating appropriate wireless\ndomain biases into DL models. We hope to spur new work in the area of robust RF\nmachine learning, as the 5G revolution increases demand for enhanced security\nmechanisms.",
    "descriptor": "",
    "authors": [
      "Carter N. Brown",
      "Enrico Mattei",
      "Andrew Draganov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03568"
  },
  {
    "id": "arXiv:2105.03583",
    "title": "Domestic activities clustering from audio recordings using convolutional  capsule autoencoder network",
    "abstract": "Recent efforts have been made on domestic activities classification from\naudio recordings, especially the works submitted to the challenge of DCASE\n(Detection and Classification of Acoustic Scenes and Events) since 2018. In\ncontrast, few studies were done on domestic activities clustering, which is a\nnewly emerging problem. Domestic activities clustering from audio recordings\naims at merging audio clips which belong to the same class of domestic activity\ninto a single cluster. Domestic activities clustering is an effective way for\nunsupervised estimation of daily activities performed in home environment. In\nthis study, we propose a method for domestic activities clustering using a\nconvolutional capsule autoencoder network (CCAN). In the method, the deep\nembeddings are learned by the autoencoder in the CCAN, while the deep\nembeddings which belong to the same class of domestic activities are merged\ninto a single cluster by a clustering layer in the CCAN. Evaluated on a public\ndataset adopted in DCASE-2018 Task 5, the results show that the proposed method\noutperforms state-of-the-art methods in terms of the metrics of clustering\naccuracy and normalized mutual information.",
    "descriptor": "\nComments: 5 pages, 2 figures, 5 tables, Accepted by IEEE ICASSP 2021\n",
    "authors": [
      "Ziheng Lin",
      "Yanxiong Li",
      "Zhangjin Huang",
      "Wenhao Zhang",
      "Yufeng Tan",
      "Yichun Chen",
      "Qianhua He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03583"
  },
  {
    "id": "arXiv:2105.03584",
    "title": "Adaptive Latent Space Tuning for Non-Stationary Distributions",
    "abstract": "Powerful deep learning tools, such as convolutional neural networks (CNN),\nare able to learn the input-output relationships of large complicated systems\ndirectly from data. Encoder-decoder deep CNNs are able to extract features\ndirectly from images, mix them with scalar inputs within a general\nlow-dimensional latent space, and then generate new complex 2D outputs which\nrepresent complex physical phenomenon. One important challenge faced by deep\nlearning methods is large non-stationary systems whose characteristics change\nquickly with time for which re-training is not feasible. In this paper we\npresent a method for adaptive tuning of the low-dimensional latent space of\ndeep encoder-decoder style CNNs based on real-time feedback to quickly\ncompensate for unknown and fast distribution shifts. We demonstrate our\napproach for predicting the properties of a time-varying charged particle beam\nin a particle accelerator whose components (accelerating electric fields and\nfocusing magnetic fields) are also quickly changing with time.",
    "descriptor": "",
    "authors": [
      "Alexander Scheinker",
      "Frederick Cropp",
      "Sergio Paiagua",
      "Daniele Filippetto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03584"
  },
  {
    "id": "arXiv:2105.03617",
    "title": "MEGADOCK-GUI: a GUI-based complete cross-docking tool for exploring  protein-protein interactions",
    "abstract": "Information on protein-protein interactions (PPIs) not only advances our\nunderstanding of molecular biology but also provides important clues for target\nselection in drug discovery and the design of PPI inhibitors. One of the\ntechniques used for computational prediction of PPIs is protein-protein docking\ncalculations, and a variety of software has been developed. However, a friendly\ninterface for users who are not sufficiently familiar with the command line\ninterface has not been developed so far. In this study, we have developed a\ngraphical user interface, MEGADOCK-GUI, which enables users to easily predict\nPPIs and protein complex structures. In addition to the original 3-D molecular\nviewer and input file preparation functions, MEGADOCK-GUI is software that can\nautomatically perform complete cross-docking of $M$ vs. $N$ proteins. With\nMEGADOCK-GUI, various applications related to the prediction of PPIs, such as\nensemble docking that handles multiple conformations of proteins and screening\nof binding partner proteins that bind to specific proteins, can now be easily\nperformed.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Masahito Ohue",
      "Yutaka Akiyama"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2105.03617"
  },
  {
    "id": "arXiv:2105.03625",
    "title": "MCTG:Multi-frequency continuous-share trading algorithm with GARCH based  on deep reinforcement learning",
    "abstract": "Making profits in stock market is a challenging task for both professional\ninstitutional investors and individual traders. With the development\ncombination of quantitative trading and reinforcement learning, more trading\nalgorithms have achieved significant gains beyond the benchmark model Buy&Hold\n(B&H). There is a certain gap between these algorithms and the real trading\ndecision making scenarios. On the one hand, they only consider trading signals\nwhile ignoring the number of transactions. On the other hand, the information\nlevel considered by these algorithms is not rich enough, which limits the\nperformance of these algorithms. Thus, we propose an algorithm called the\nMulti-frequency Continuous-share Trading algorithm with GARCH (MCTG) to solve\nthe problems above, which consists of parallel network layers and deep\nreinforcement learning. The former is composed of three parallel network\nlayers, respectively dealing with different frequencies (five minute, one day,\none week) data, and day level considers the volatilities of stocks. The latter\nwith a continuous action space of the reinforcement learning algorithm is used\nto solve the problem of trading stock shares. Experiments in different\nindustries of Chinese stock market show our method achieves more extra profit\ncomparing with basic DRL methods and bench model.",
    "descriptor": "",
    "authors": [
      "Zhishun Wang",
      "Wei Lu",
      "Kaixin Zhang",
      "Tianhao Li",
      "Zixi Zhao"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03625"
  },
  {
    "id": "arXiv:2105.03643",
    "title": "Latency-Controlled Neural Architecture Search for Streaming Speech  Recognition",
    "abstract": "Recently, neural architecture search (NAS) has attracted much attention and\nhas been explored for automatic speech recognition (ASR). Our prior work has\nshown promising results compared with hand-designed neural networks. In this\nwork, we focus on streaming ASR scenarios and propose the latency-controlled\nNAS for acoustic modeling. First, based on the vanilla neural architecture,\nnormal cells are altered to be causal cells, in order to control the total\nlatency of the neural network. Second, a revised operation space with a smaller\nreceptive field is proposed to generate the final architecture with low\nlatency. Extensive experiments show that: 1) Based on the proposed neural\narchitecture, the neural networks with a medium latency of 550ms (millisecond)\nand a low latency of 190ms can be learned in the vanilla and revised operation\nspace respectively. 2) For the low latency setting, the evaluation network can\nachieve more than 19\\% (average on the four test sets) relative improvements\ncompared with the hybrid CLDNN baseline, on a 10k-hour large-scale dataset.\nAdditional 11\\% relative improvements can be achieved if the latency of the\nneural network is relaxed to the medium latency setting.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2021\n",
    "authors": [
      "Liqiang He",
      "Shulin Feng",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03643"
  },
  {
    "id": "arXiv:2105.03660",
    "title": "Deep learning of nanopore sensing signals using a bi-path network",
    "abstract": "Temporary changes in electrical resistance of a nanopore sensor caused by\ntranslocating target analytes are recorded as a sequence of pulses on current\ntraces. Prevalent algorithms for feature extraction in pulse-like signals lack\nobjectivity because empirical amplitude thresholds are user-defined to single\nout the pulses from the noisy background. Here, we use deep learning for\nfeature extraction based on a bi-path network (B-Net). After training, the\nB-Net acquires the prototypical pulses and the ability of both pulse\nrecognition and feature extraction without a priori assigned parameters. The\nB-Net performance is evaluated on generated datasets and further applied to\nexperimental data of DNA and protein translocation. The B-Net results show\nremarkably small relative errors and stable trends. The B-Net is further shown\ncapable of processing data with a signal-to-noise ratio equal to one, an\nimpossibility for threshold-based algorithms. The developed B-Net is generic\nfor pulse-like signals beyond pulsed nanopore currents.",
    "descriptor": "",
    "authors": [
      "Dario Dematties",
      "Chenyu Wen",
      "Mauricio David P\u00e9rez",
      "Dian Zhou",
      "Shi-Li Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03660"
  },
  {
    "id": "arXiv:2105.03678",
    "title": "Nearly Minimax-Optimal Rates for Noisy Sparse Phase Retrieval via  Early-Stopped Mirror Descent",
    "abstract": "This paper studies early-stopped mirror descent applied to noisy sparse phase\nretrieval, which is the problem of recovering a $k$-sparse signal\n$\\mathbf{x}^\\star\\in\\mathbb{R}^n$ from a set of quadratic Gaussian measurements\ncorrupted by sub-exponential noise. We consider the (non-convex) unregularized\nempirical risk minimization problem and show that early-stopped mirror descent,\nwhen equipped with the hyperbolic entropy mirror map and proper initialization,\nachieves a nearly minimax-optimal rate of convergence, provided the sample size\nis at least of order $k^2$ (modulo logarithmic term) and the minimum (in\nmodulus) non-zero entry of the signal is on the order of\n$\\|\\mathbf{x}^\\star\\|_2/\\sqrt{k}$. Our theory leads to a simple algorithm that\ndoes not rely on explicit regularization or thresholding steps to promote\nsparsity. More generally, our results establish a connection between mirror\ndescent and sparsity in the non-convex problem of noisy sparse phase retrieval,\nadding to the literature on early stopping that has mostly focused on\nnon-sparse, Euclidean, and convex settings via gradient descent. Our proof\ncombines a potential-based analysis of mirror descent with a quantitative\ncontrol on a variational coherence property that we establish along the path of\nmirror descent, up to a prescribed stopping time.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.10168\n",
    "authors": [
      "Fan Wu",
      "Patrick Rebeschini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03678"
  },
  {
    "id": "arXiv:2105.03679",
    "title": "EZCrop: Energy-Zoned Channels for Robust Output Pruning",
    "abstract": "Recent results have revealed an interesting observation in a trained\nconvolutional neural network (CNN), namely, the rank of a feature map channel\nmatrix remains surprisingly constant despite the input images. This has led to\nan effective rank-based channel pruning algorithm, yet the constant rank\nphenomenon remains mysterious and unexplained. This work aims at demystifying\nand interpreting such rank behavior from a frequency-domain perspective, which\nas a bonus suggests an extremely efficient Fast Fourier Transform (FFT)-based\nmetric for measuring channel importance without explicitly computing its rank.\nWe achieve remarkable CNN channel pruning based on this analytically sound and\ncomputationally efficient metric and adopt it for repetitive pruning to\ndemonstrate robustness via our scheme named Energy-Zoned Channels for Robust\nOutput Pruning (EZCrop), which shows consistently better results than other\nstate-of-the-art channel pruning methods.",
    "descriptor": "",
    "authors": [
      "Rui Lin",
      "Jie Ran",
      "Ngai Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03679"
  },
  {
    "id": "arXiv:2105.03684",
    "title": "Quantum Machine Learning For Classical Data",
    "abstract": "In this dissertation, we study the intersection of quantum computing and\nsupervised machine learning algorithms, which means that we investigate quantum\nalgorithms for supervised machine learning that operate on classical data. This\narea of research falls under the umbrella of quantum machine learning, a\nresearch area of computer science which has recently received wide attention.\nIn particular, we investigate to what extent quantum computers can be used to\naccelerate supervised machine learning algorithms. The aim of this is to\ndevelop a clear understanding of the promises and limitations of the current\nstate of the art of quantum algorithms for supervised machine learning, but\nalso to define directions for future research in this exciting field. We start\nby looking at supervised quantum machine learning (QML) algorithms through the\nlens of statistical learning theory. In this framework, we derive novel bounds\non the computational complexities of a large set of supervised QML algorithms\nunder the requirement of optimal learning rates. Next, we give a new bound for\nHamiltonian simulation of dense Hamiltonians, a major subroutine of most known\nsupervised QML algorithms, and then derive a classical algorithm with nearly\nthe same complexity. We then draw the parallels to recent \"quantum-inspired\"\nresults, and will explain the implications of these results for quantum machine\nlearning applications. Looking for areas which might bear larger advantages for\nQML algorithms, we finally propose a novel algorithm for Quantum Boltzmann\nmachines, and argue that quantum algorithms for quantum data are one of the\nmost promising applications for QML with potentially exponential advantage over\nclassical approaches.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Leonard Wossnig"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03684"
  },
  {
    "id": "arXiv:2105.03697",
    "title": "Quantum Proofs of Proximity",
    "abstract": "We initiate the systematic study of QMA algorithms in the setting of property\ntesting, to which we refer as QMA proofs of proximity (QMAPs). These are\nquantum query algorithms that receive explicit access to a sublinear-size\nuntrusted proof and are required to accept inputs having a property $\\Pi$ and\nreject inputs that are $\\varepsilon$-far from $\\Pi$, while only probing a\nminuscule portion of their input. Our algorithmic results include a\ngeneral-purpose theorem that enables quantum speedups for testing an expressive\nclass of properties, namely, those that are succinctly decomposable.\nFurthermore, we show quantum speedups for properties that lie outside of this\nfamily, such as graph bipartitneness. We also investigate the complexity\nlandscape of this model, showing that QMAPs can be exponentially stronger than\nboth classical proofs of proximity and quantum testers. To this end, we extend\nthe methodology of Blais, Brody and Matulef (Computational Complexity, 2012) to\nprove quantum property testing lower bounds via reductions from communication\ncomplexity, thereby resolving a problem raised by Montanaro and de Wolf (Theory\nof Computing, 2016).",
    "descriptor": "",
    "authors": [
      "Marcel Dall'Agnol",
      "Tom Gur",
      "Subhayan Roy Moulik",
      "Justin Thaler"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.03697"
  },
  {
    "id": "arXiv:2105.03752",
    "title": "Improving Deep Learning Performance for Predicting Large-Scale  Porous-Media Flow through Feature Coarsening",
    "abstract": "Physics-based simulation for fluid flow in porous media is a computational\ntechnology to predict the temporal-spatial evolution of state variables (e.g.\npressure) in porous media, and usually requires high computational expense due\nto its nonlinearity and the scale of the study domain. This letter describes a\ndeep learning (DL) workflow to predict the pressure evolution as fluid flows in\nlarge-scale 3D heterogeneous porous media. In particular, we apply feature\ncoarsening technique to extract the most representative information and perform\nthe training and prediction of DL at the coarse scale, and further recover the\nresolution at the fine scale by 2D piecewise cubic interpolation. We validate\nthe DL approach that is trained from physics-based simulation data to predict\npressure field in a field-scale 3D geologic CO_2 storage reservoir. We evaluate\nthe impact of feature coarsening on DL performance, and observe that the\nfeature coarsening can not only decrease training time by >74% and reduce\nmemory consumption by >75%, but also maintains temporal error <1.5%. Besides,\nthe DL workflow provides predictive efficiency with ~1400 times speedup\ncompared to physics-based simulation.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Bicheng Yan",
      "Dylan Robert Harp",
      "Bailian Chen",
      "Rajesh J. Pawar"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03752"
  },
  {
    "id": "arXiv:2105.03774",
    "title": "Study of List-Based OMP and an Enhanced Model for Direction Finding with  Non-Uniform Arrays",
    "abstract": "This paper proposes an enhanced coarray transformation model (EDCTM) and a\nmixed greedy maximum likelihood algorithm called List-Based Maximum Likelihood\nOrthogonal Matching Pursuit (LBML-OMP) for direction-of-arrival estimation with\nnon-uniform linear arrays (NLAs). The proposed EDCTM approach obtains improved\nestimates when Khatri-Rao product-based models are used to generate difference\ncoarrays under the assumption of uncorrelated sources. In the proposed LBML-OMP\ntechnique, for each iteration a set of candidates is generated based on the\ncorrelation-maximization between the dictionary and the residue vector.\nLBML-OMP then chooses the best candidate based on a reduced-complexity\nasymptotic maximum likelihood decision rule. Simulations show the improved\nresults of EDCTM over existing approaches and that LBML-OMP outperforms\nexisting sparse recovery algorithms as well as Spatial Smoothing Multiple\nSignal Classification with NLAs.",
    "descriptor": "\nComments: 6 figures, 8 pages\n",
    "authors": [
      "W. S. Leite",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03774"
  },
  {
    "id": "arXiv:2105.03847",
    "title": "Automatic segmentation of vertebral features on ultrasound spine images  using Stacked Hourglass Network",
    "abstract": "Objective: The spinous process angle (SPA) is one of the essential parameters\nto denote three-dimensional (3-D) deformity of spine. We propose an automatic\nsegmentation method based on Stacked Hourglass Network (SHN) to detect the\nspinous processes (SP) on ultrasound (US) spine images and to measure the SPAs\nof clinical scoliotic subjects. Methods: The network was trained to detect\nvertebral SP and laminae as five landmarks on 1200 ultrasound transverse images\nand validated on 100 images. All the processed transverse images with\nhighlighted SP and laminae were reconstructed into a 3D image volume, and the\nSPAs were measured on the projected coronal images. The trained network was\ntested on 400 images by calculating the percentage of correct keypoints (PCK);\nand the SPA measurements were evaluated on 50 scoliotic subjects by comparing\nthe results from US images and radiographs. Results: The trained network\nachieved a high average PCK (86.8%) on the test datasets, particularly the PCK\nof SP detection was 90.3%. The SPAs measured from US and radiographic methods\nshowed good correlation (r>0.85), and the mean absolute differences (MAD)\nbetween two modalities were 3.3{\\deg}, which was less than the clinical\nacceptance error (5{\\deg}). Conclusion: The vertebral features can be\naccurately segmented on US spine images using SHN, and the measurement results\nof SPA from US data was comparable to the gold standard from radiography.",
    "descriptor": "\nComments: 9 pages,5 figures\n",
    "authors": [
      "Hong-Ye Zeng",
      "Song-Han Ge",
      "Yu-Chong Gao",
      "De-Sen Zhou",
      "Kang Zhou",
      "Xu-Ming He",
      "Rui Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03847"
  },
  {
    "id": "arXiv:2105.03854",
    "title": "Surrogate Modeling of Fluid Dynamics with a Multigrid Inspired Neural  Network Architecture",
    "abstract": "Algebraic or geometric multigrid methods are commonly used in numerical\nsolvers as they are a multi-resolution method able to handle problems with\nmultiple scales. In this work, we propose a modification to the commonly-used\nU-Net neural network architecture that is inspired by the principles of\nmultigrid methods, referred to here as U-Net-MG. We then demonstrate that this\nproposed U-Net-MG architecture can successfully reduce the test prediction\nerrors relative to the conventional U-Net architecture when modeling a set of\nfluid dynamic problems. In total, we demonstrate an improvement in the\nprediction of velocity and pressure fields for the canonical fluid dynamics\ncases of flow past a stationary cylinder, flow past 2 cylinders in out-of-phase\nmotion, and flow past an oscillating airfoil in both the propulsion and energy\nharvesting modes. In general, while both the U-Net and U-Net-MG models can\nmodel the systems well with test RMSEs of less than 1%, the use of the U-Net-MG\narchitecture can further reduce RMSEs by between 20% and 70%.",
    "descriptor": "\nComments: 22 pages, 15 figures\n",
    "authors": [
      "Quang Tuyen Le",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03854"
  },
  {
    "id": "arXiv:2105.03863",
    "title": "Non-asymptotic Performances of Robust Markov Decision Processes",
    "abstract": "In this paper, we study the non-asymptotic performance of optimal policy on\nrobust value function with true transition dynamics. The optimal robust policy\nis solved from a generative model or offline dataset without access to true\ntransition dynamics. In particular, we consider three different uncertainty\nsets including the $L_1$, $\\chi^2$ and KL balls in both $(s,a)$-rectangular and\n$s$-rectangular assumptions. Our results show that when we assume\n$(s,a)$-rectangular on uncertainty sets, the sample complexity is about\n$\\widetilde{O}\\left(\\frac{|\\mathcal{S}|^2|\\mathcal{A}|}{\\varepsilon^2\\rho^2(1-\\gamma)^4}\\right)$\nin the generative model setting and\n$\\widetilde{O}\\left(\\frac{|\\mathcal{S}|}{\\nu_{\\min}\\varepsilon^2\\rho^2(1-\\gamma)^4}\\right)$\nin the offline dataset setting. While prior works on non-asymptotic\nperformances are restricted with the KL ball and $(s,a)$-rectangular\nassumption, we also extend our results to a more general $s$-rectangular\nassumption, which leads to a larger sample complexity than the\n$(s,a)$-rectangular assumption.",
    "descriptor": "",
    "authors": [
      "Wenhao Yang",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03863"
  },
  {
    "id": "arXiv:2105.03905",
    "title": "Security Concerns on Machine Learning Solutions for 6G Networks in  mmWave Beam Prediction",
    "abstract": "6G -- sixth generation -- is the latest cellular technology currently under\ndevelopment for wireless communication systems. In recent years, machine\nlearning algorithms have been applied widely in various fields, such as\nhealthcare, transportation, energy, autonomous car, and many more. Those\nalgorithms have been also using in communication technologies to improve the\nsystem performance in terms of frequency spectrum usage, latency, and security.\nWith the rapid developments of machine learning techniques, especially deep\nlearning, it is critical to take the security concern into account when\napplying the algorithms. While machine learning algorithms offer significant\nadvantages for 6G networks, security concerns on Artificial Intelligent (AI)\nmodels is typically ignored by the scientific community so far. However,\nsecurity is also a vital part of the AI algorithms, this is because the AI\nmodel itself can be poisoned by attackers. This paper proposes a mitigation\nmethod for adversarial attacks against proposed 6G machine learning models for\nthe millimeter-wave (mmWave) beam prediction using adversarial learning. The\nmain idea behind adversarial attacks against machine learning models is to\nproduce faulty results by manipulating trained deep learning models for 6G\napplications for mmWave beam prediction. We also present the adversarial\nlearning mitigation method's performance for 6G security in mmWave beam\nprediction application with fast gradient sign method attack. The mean square\nerrors (MSE) of the defended model under attack are very close to the\nundefended model without attack.",
    "descriptor": "\nComments: 13 Pages, under review. arXiv admin note: substantial text overlap with arXiv:2103.07268\n",
    "authors": [
      "Ferhat Ozgur Catak",
      "Evren Catak",
      "Murat Kuzlu",
      "Umit Cali"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03905"
  },
  {
    "id": "arXiv:2105.03924",
    "title": "Computationally Efficient Dynamic Traffic Optimization Of Railway  Systems",
    "abstract": "In this paper we investigate real-time, dynamic traffic optimization in\nrailway systems. In order to enable practical solution times, we operate the\noptimizer in a receding horizon fashion and with optimization horizons that are\nshorter than the full path to destinations, using a model predictive control\n(MPC) approach. We present new procedures to establish safe prediction\nhorizons, providing formal guarantees that the system is operated in a way that\nsatisfies hard safety constraints despite the fact that not all future train\ninteractions are taken into account, by characterizing the minimal required\noptimization horizons. We also show that any feasible solution to our proposed\nmodels is sufficient to maintain a safe, automated operation of the railway\nsystem, providing an upper bound on the computations strictly required.\nAdditionally, we show that these minimal optimization horizons also\ncharacterize an upper bound on computations required to construct a feasible\nsolution for any arbitrary optimization horizon, paving the way for anytime\nalgorithms. Finally, our results enable systematic solution reuse, when\nprevious schedules are available. We test our approach on a detailed simulation\nenvironment of a real-world railway system used for freight transport.",
    "descriptor": "",
    "authors": [
      "Robin Vujanic",
      "Andrew Hill"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03924"
  },
  {
    "id": "arXiv:2105.03939",
    "title": "Lightweight Image Super-Resolution with Hierarchical and Differentiable  Neural Architecture Search",
    "abstract": "Single Image Super-Resolution (SISR) tasks have achieved significant\nperformance with deep neural networks. However, the large number of parameters\nin CNN-based methods for SISR tasks require heavy computations. Although\nseveral efficient SISR models have been recently proposed, most are handcrafted\nand thus lack flexibility. In this work, we propose a novel differentiable\nNeural Architecture Search (NAS) approach on both the cell-level and\nnetwork-level to search for lightweight SISR models. Specifically, the\ncell-level search space is designed based on an information distillation\nmechanism, focusing on the combinations of lightweight operations and aiming to\nbuild a more lightweight and accurate SR structure. The network-level search\nspace is designed to consider the feature connections among the cells and aims\nto find which information flow benefits the cell most to boost the performance.\nUnlike the existing Reinforcement Learning (RL) or Evolutionary Algorithm (EA)\nbased NAS methods for SISR tasks, our search pipeline is fully differentiable,\nand the lightweight SISR models can be efficiently searched on both the\ncell-level and network-level jointly on a single GPU. Experiments show that our\nmethods can achieve state-of-the-art performance on the benchmark datasets in\nterms of PSNR, SSIM, and model complexity with merely 68G Multi-Adds for\n$\\times 2$ and 18G Multi-Adds for $\\times 4$ SR tasks. Code will be available\nat \\url{https://github.com/DawnHH/DLSR-PyTorch}.",
    "descriptor": "",
    "authors": [
      "Han Huang",
      "Li Shen",
      "Chaoyang He",
      "Weisheng Dong",
      "Haozhi Huang",
      "Guangming Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03939"
  },
  {
    "id": "arXiv:2105.03988",
    "title": "Probabilistic forecast of multiphase transport under viscous and  buoyancy forces in heterogeneous porous media",
    "abstract": "In this study, we develop a probabilistic approach to map the parametric\nuncertainty to the output state uncertainty in first-order hyperbolic\nconservation laws. We analyze this problem for nonlinear immiscible two-phase\ntransport in heterogeneous porous media in the presence of a stochastic\nvelocity field. The uncertainty in the velocity field can arise from the\nincomplete description of either porosity field, injection flux, or both. The\nuncertainty in the total-velocity field leads to the spatiotemporal uncertainty\nin the saturation field. Given information about the spatial/temporal\nstatistics of the correlated heterogeneity, we leverage method of distributions\nto derive deterministic equations that govern the evolution of single-point CDF\nof saturation. Unlike Buckley Leverett equation, the equation for the raw CDF\nfunction is linear in space and time. Hereby, we give routes to circumventing\nthe computational cost of Monte Carlo scheme while obtaining the full\nstatistical description of saturation. We conduct a set of numerical\nexperiments and compare statistics of saturation computed with the method of\ndistributions, against those obtained using the statistical moment equations\napproach and kernel density estimation post-processing of high-resolution Monte\nCarlo simulations. This comparison demonstrates that the CDF equations remain\naccurate over a wide range of statistical properties, i.e. standard deviation\nand correlation length of the underlying random fields, while the corresponding\nlow-order statistical moment equations significantly deviate from Monte Carlo\nresults, unless for very small values of standard deviation and correlation\nlength.",
    "descriptor": "",
    "authors": [
      "Farzaneh Rajabi",
      "Hamdi A. Tchelepi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.03988"
  },
  {
    "id": "arXiv:2105.03991",
    "title": "Holomorphic feedforward networks",
    "abstract": "A very popular model in machine learning is the feedforward neural network\n(FFN). The FFN can approximate general functions and mitigate the curse of\ndimensionality. Here we introduce FFNs which represent sections of holomorphic\nline bundles on complex manifolds, and ask some questions about their\napproximating power. We also explain formal similarities between the standard\napproach to supervised learning and the problem of finding numerical Ricci flat\nK\\\"ahler metrics, which allow carrying some ideas between the two problems.",
    "descriptor": "\nComments: 13 pages, version to appear in PAMQ\n",
    "authors": [
      "Michael R. Douglas"
    ],
    "subjectives": [
      "Complex Variables (math.CV)",
      "High Energy Physics - Theory (hep-th)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03991"
  },
  {
    "id": "arXiv:2105.03995",
    "title": "Acute Lymphoblastic Leukemia Detection from Microscopic Images Using  Weighted Ensemble of Convolutional Neural Networks",
    "abstract": "Acute Lymphoblastic Leukemia (ALL) is a blood cell cancer characterized by\nnumerous immature lymphocytes. Even though automation in ALL prognosis is an\nessential aspect of cancer diagnosis, it is challenging due to the\nmorphological correlation between malignant and normal cells. The traditional\nALL classification strategy demands experienced pathologists to carefully read\nthe cell images, which is arduous, time-consuming, and often suffers\ninter-observer variations. This article has automated the ALL detection task\nfrom microscopic cell images, employing deep Convolutional Neural Networks\n(CNNs). We explore the weighted ensemble of different deep CNNs to recommend a\nbetter ALL cell classifier. The weights for the ensemble candidate models are\nestimated from their corresponding metrics, such as accuracy, F1-score, AUC,\nand kappa values. Various data augmentations and pre-processing are\nincorporated for achieving a better generalization of the network. We utilize\nthe publicly available C-NMC-2019 ALL dataset to conduct all the comprehensive\nexperiments. Our proposed weighted ensemble model, using the kappa values of\nthe ensemble candidates as their weights, has outputted a weighted F1-score of\n88.6 %, a balanced accuracy of 86.2 %, and an AUC of 0.941 in the preliminary\ntest set. The qualitative results displaying the gradient class activation maps\nconfirm that the introduced model has a concentrated learned region. In\ncontrast, the ensemble candidate models, such as Xception, VGG-16,\nDenseNet-121, MobileNet, and InceptionResNet-V2, separately produce coarse and\nscatter learned areas for most example cases. Since the proposed kappa\nvalue-based weighted ensemble yields a better result for the aimed task in this\narticle, it can experiment in other domains of medical diagnostic applications.",
    "descriptor": "\nComments: 31 pages, 9 figures\n",
    "authors": [
      "Chayan Mondal",
      "Md. Kamrul Hasan",
      "Md. Tasnim Jawad",
      "Aishwariya Dutta",
      "Md.Rabiul Islam",
      "Md. Abdul Awal",
      "Mohiuddin Ahmad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03995"
  },
  {
    "id": "arXiv:2105.04001",
    "title": "Bayesian Kernelised Test of (In)dependence with Mixed-type Variables",
    "abstract": "A fundamental task in AI is to assess (in)dependence between mixed-type\nvariables (text, image, sound). We propose a Bayesian kernelised correlation\ntest of (in)dependence using a Dirichlet process model. The new measure of\n(in)dependence allows us to answer some fundamental questions: Based on data,\nare (mixed-type) variables independent? How likely is dependence/independence\nto hold? How high is the probability that two mixed-type variables are more\nthan just weakly dependent? We theoretically show the properties of the\napproach, as well as algorithms for fast computation with it. We empirically\ndemonstrate the effectiveness of the proposed method by analysing its\nperformance and by comparing it with other frequentist and Bayesian approaches\non a range of datasets and tasks with mixed-type variables.",
    "descriptor": "",
    "authors": [
      "Alessio Benavoli",
      "Cassio de Campos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04001"
  },
  {
    "id": "arXiv:2105.04014",
    "title": "DiagSet: a dataset for prostate cancer histopathological image  classification",
    "abstract": "Cancer diseases constitute one of the most significant societal challenges.\nIn this paper we introduce a novel histopathological dataset for prostate\ncancer detection. The proposed dataset, consisting of over 2.6 million tissue\npatches extracted from 430 fully annotated scans, 4675 scans with assigned\nbinary diagnosis, and 46 scans with diagnosis given independently by a group of\nhistopathologists, can be found at https://ai-econsilio.diag.pl. Furthermore,\nwe propose a machine learning framework for detection of cancerous tissue\nregions and prediction of scan-level diagnosis, utilizing thresholding and\nstatistical analysis to abstain from the decision in uncertain cases. During\nthe experimental evaluation we identify several factors negatively affecting\nthe performance of considered models, such as presence of label noise, data\nimbalance, and quantity of data, that can serve as a basis for further\nresearch. The proposed approach, composed of ensembles of deep neural networks\noperating on the histopathological scans at different scales, achieves 94.6%\naccuracy in patch-level recognition, and is compared in a scan-level diagnosis\nwith 9 human histopathologists.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Koziarski",
      "Bogus\u0142aw Cyganek",
      "Bogus\u0142aw Olborski",
      "Zbigniew Antosz",
      "Marcin \u017bydak",
      "Bogdan Kwolek",
      "Pawe\u0142 W\u0105sowicz",
      "Andrzej Buka\u0142a",
      "Jakub Swad\u017aba",
      "Piotr Sitkowski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04014"
  },
  {
    "id": "arXiv:2105.04033",
    "title": "Key Assistance, Key Agreement, and Layered Secrecy for Bosonic Broadcast  Channels",
    "abstract": "Secret-sharing building blocks based on quantum broadcast communication are\nstudied. The confidential capacity region of the pure-loss bosonic broadcast\nchannel is determined, both with and without key assistance, and an achievable\nregion is established for the lossy bosonic broadcast channel. If the main\nreceiver has a transmissivity of \\eta<1/2, then confidentiality solely relies\non the key-assisted encryption of the one-time pad. We also address conference\nkey agreement for the distillation of two keys, a public key and a secret key.\nA regularized formula is derived for the key-agreement capacity region in\nfinite dimensions. In the bosonic case, the key-agreement region is included\nwithin the capacity region of the corresponding broadcast channel with\nconfidential messages. We then consider a network with layered secrecy, where\nthree users with different security ranks communicate over the same broadcast\nnetwork. We derive an achievable layered-secrecy region for a pure-loss bosonic\nchannel that is formed by the concatenation of two beam splitters.",
    "descriptor": "",
    "authors": [
      "Uzi Pereg",
      "Roberto Ferrara",
      "Matthieu R. Bloch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04033"
  },
  {
    "id": "arXiv:2105.04044",
    "title": "Practical Parallel Self-testing of Bell States via Magic Rectangles",
    "abstract": "Self-testing is a method to verify that one has a particular quantum state\nfrom purely classical statistics. For practical applications, such as\ndevice-independent delegated verifiable quantum computation, it is crucial that\none self-tests multiple Bell states in parallel while keeping the quantum\ncapabilities required of one side to a minimum. In this work we use the $3\n\\times n$ magic rectangle games (generalisations of the magic square game) to\nobtain a self-test for $n$ Bell states where the one side needs only to measure\nsingle-qubit Pauli observables. The protocol requires small input size\n(constant for Alice and $O(\\log n)$ bits for Bob) and is robust with robustness\n$O(n^{5/2} \\sqrt{\\varepsilon})$, where $\\varepsilon$ is the closeness of the\nobserved correlations to the ideal. To achieve the desired self-test we\nintroduce a one-side-local quantum strategy for the magic square game that wins\nwith certainty, generalise this strategy to the family of $3 \\times n$ magic\nrectangle games, and supplement these nonlocal games with extra check rounds\n(of single and pairs of observables).",
    "descriptor": "\nComments: 26 pages, 4 figures; comments are very welcome!\n",
    "authors": [
      "Sean A. Adamson",
      "Petros Wallden"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04044"
  },
  {
    "id": "arXiv:2105.04046",
    "title": "A likelihood approach to nonparametric estimation of a singular  distribution using deep generative models",
    "abstract": "We investigate statistical properties of a likelihood approach to\nnonparametric estimation of a singular distribution using deep generative\nmodels. More specifically, a deep generative model is used to model\nhigh-dimensional data that are assumed to concentrate around some\nlow-dimensional structure. Estimating the distribution supported on this\nlow-dimensional structure such as a low-dimensional manifold is challenging due\nto its singularity with respect to the Lebesgue measure in the ambient space.\nIn the considered model, a usual likelihood approach can fail to estimate the\ntarget distribution consistently due to the singularity. We prove that a novel\nand effective solution exists by perturbing the data with an instance noise\nwhich leads to consistent estimation of the underlying distribution with\ndesirable convergence rates. We also characterize the class of distributions\nthat can be efficiently estimated via deep generative models. This class is\nsufficiently general to contain various structured distributions such as\nproduct distributions, classically smooth distributions and distributions\nsupported on a low-dimensional manifold. Our analysis provides some insights on\nhow deep generative models can avoid the curse of dimensionality for\nnonparametric distribution estimation. We conduct thorough simulation study and\nreal data analysis to empirically demonstrate that the proposed data\nperturbation technique improves the estimation performance significantly.",
    "descriptor": "\nComments: 33 pages, 12 figures, 1 table\n",
    "authors": [
      "Minwoo Chae",
      "Dongha Kim",
      "Yongdai Kim",
      "Lizhen Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04046"
  },
  {
    "id": "arXiv:2105.04059",
    "title": "Towards a functorial description of quantum relative entropy",
    "abstract": "A Bayesian functorial characterization of the classical relative entropy (KL\ndivergence) of finite probabilities was recently obtained by Baez and Fritz.\nThis was then generalized to standard Borel spaces by Gagn\\'e and Panangaden.\nHere, we provide preliminary calculations suggesting that the\nfinite-dimensional quantum (Umegaki) relative entropy might be characterized in\na similar way. Namely, we explicitly prove that it defines an affine functor in\nthe special case where the relative entropy is finite. A recent non-commutative\ndisintegration theorem provides a key ingredient in this proof.",
    "descriptor": "\nComments: 8 pages, submission to GSI'21 (post-print)\n",
    "authors": [
      "Arthur J. Parzygnat"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.04059"
  },
  {
    "id": "arXiv:2105.04077",
    "title": "Dynamic Multichannel Access via Multi-agent Reinforcement Learning:  Throughput and Fairness Guarantees",
    "abstract": "We consider a multichannel random access system in which each user accesses a\nsingle channel at each time slot to communicate with an access point (AP).\nUsers arrive to the system at random and be activated for a certain period of\ntime slots and then disappear from the system. Under such dynamic network\nenvironment, we propose a distributed multichannel access protocol based on\nmulti-agent reinforcement learning (RL) to improve both throughput and fairness\nbetween active users. Unlike the previous approaches adjusting channel access\nprobabilities at each time slot, the proposed RL algorithm deterministically\nselects a set of channel access policies for several consecutive time slots. To\neffectively reduce the complexity of the proposed RL algorithm, we adopt a\nbranching dueling Q-network architecture and propose an efficient training\nmethodology for producing proper Q-values over time-varying user sets. We\nperform extensive simulations on realistic traffic environments and demonstrate\nthat the proposed online learning improves both throughput and fairness\ncompared to the conventional RL approaches and centralized scheduling policies.",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Muhammad Sohaib",
      "Jongjin Jeong",
      "Sang-Woon Jeon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04077"
  },
  {
    "id": "arXiv:2105.04083",
    "title": "The Behavior of Internet Traffic for Internet Services during COVID-19  Pandemic Scenario",
    "abstract": "Since the end of 2019, the SARS-CoV-2 virus known as COVID-19 has spread\nrapidly around the world, forcing many governments to impose restrictive\nblocking or lockdown to combat the pandemic. With locomotion restriction of\npeople in almost of countries of the world, workers and students needed to keep\ntheir activities at home. As a result, people's behavior, habits, and the way\nthey started using the Internet changed significantly. Like professionals of\noffices, the younger played an important role in this behavior, especially in\nthe type of resources used by them. As result, the characterization and traffic\nof communication networks were affected in some way. In this perspective\narticle, we join from many available studies about the COVID-19 effect at\nnetworks and investigate the effects on the Internet traffic of using services\nsuch as video streaming, video conferencing, and gaming during 2020's months of\nthe pandemic.",
    "descriptor": "\nComments: 4 pages, 2 figures, Submitted to XXXIX Simp\\'osio Brasileiro de Telecomunica\\c{c}\\~oes e Processamento de Sinais, SBrT 2021, Fortaleza, CE, Brasil\n",
    "authors": [
      "Carlos Alexandre Gouvea da Silva",
      "Allan Christian Krainski Ferrari",
      "Cristiano Osinski",
      "Douglas Antonio Firmino Pelacini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.04083"
  },
  {
    "id": "arXiv:2105.04087",
    "title": "Latency Analysis of Consortium Blockchained Federated Learning",
    "abstract": "A decentralized federated learning architecture is proposed to apply to the\nBusinesses-to-Businesses scenarios by introducing the consortium blockchain in\nthis paper. We introduce a model verification mechanism to ensure the quality\nof local models trained by participators. To analyze the latency of the system,\na latency model is constructed by considering the work flow of the\narchitecture. Finally the experiment results show that our latency model does\nwell in quantifying the actual delays.",
    "descriptor": "",
    "authors": [
      "Pengcheng Ren",
      "Tongjiang Yan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04087"
  },
  {
    "id": "arXiv:2105.04106",
    "title": "Validation of image systems simulation technology using a Cornell Box",
    "abstract": "We describe and experimentally validate an end-to-end simulation of a digital\ncamera. The simulation models the spectral radiance of 3D-scenes, formation of\nthe spectral irradiance by multi-element optics, and conversion of the\nirradiance to digital values by the image sensor. We quantify the accuracy of\nthe simulation by comparing real and simulated images of a precisely\nconstructed, three-dimensional high dynamic range test scene. Validated\nend-to-end software simulation of a digital camera can accelerate innovation by\nreducing many of the time-consuming and expensive steps in designing, building\nand evaluating image systems.",
    "descriptor": "",
    "authors": [
      "Zheng Lyu",
      "Krithin Kripakaran",
      "Max Furth",
      "Eric Tang",
      "Brian Wandell",
      "Joyce Farrell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.04106"
  },
  {
    "id": "arXiv:2105.04130",
    "title": "Boltzmann machines as two-dimensional tensor networks",
    "abstract": "Restricted Boltzmann machines (RBM) and deep Boltzmann machines (DBM) are\nimportant models in machine learning, and recently found numerous applications\nin quantum many-body physics. We show that there are fundamental connections\nbetween them and tensor networks. In particular, we demonstrate that any RBM\nand DBM can be exactly represented as a two-dimensional tensor network. This\nrepresentation gives an understanding of the expressive power of RBM and DBM\nusing entanglement structures of the tensor networks, also provides an\nefficient tensor network contraction algorithm for the computing partition\nfunction of RBM and DBM. Using numerical experiments, we demonstrate that the\nproposed algorithm is much more accurate than the state-of-the-art machine\nlearning methods in estimating the partition function of restricted Boltzmann\nmachines and deep Boltzmann machines, and have potential applications in\ntraining deep Boltzmann machines for general machine learning tasks.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Sujie Li",
      "Feng Pan",
      "Pengfei Zhou",
      "Pan Zhang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04130"
  },
  {
    "id": "arXiv:2105.04137",
    "title": "On the inversion number of oriented graphs",
    "abstract": "Let $D$ be an oriented graph. The inversion of a set $X$ of vertices in $D$\nconsists in reversing the direction of all arcs with both ends in $X$. The\ninversion number of $D$, denoted by ${\\rm inv}(D)$, is the minimum number of\ninversions needed to make $D$ acyclic. Denoting by $\\tau(D)$, $\\tau' (D)$, and\n$\\nu(D)$ the cycle transversal number, the cycle arc-transversal number and the\ncycle packing number of $D$ respectively, one shows that ${\\rm inv}(D) \\leq\n\\tau' (D)$, ${\\rm inv}(D) \\leq 2\\tau(D)$ and there exists a function $g$ such\nthat ${\\rm inv}(D)\\leq g(\\nu(D))$. We conjecture that for any two oriented\ngraphs $L$ and $R$, ${\\rm inv}(L\\rightarrow R) ={\\rm inv}(L) +{\\rm inv}(R)$\nwhere $L\\rightarrow R$ is the dijoin of $L$ and $R$. This would imply that the\nfirst two inequalities are tight. We prove this conjecture when ${\\rm\ninv}(L)\\leq 1$ and ${\\rm inv}(R)\\leq 2$ and when ${\\rm inv}(L) ={\\rm inv}(R)=2$\nand $L$ and $R$ are strongly connected. We also show that the function $g$ of\nthe third inequality satisfies $g(1)\\leq 4$.\nWe then consider the complexity of deciding whether ${\\rm inv}(D)\\leq k$ for\na given oriented graph $D$. We show that it is NP-complete for $k=1$, which\ntogether with the above conjecture would imply that it is NP-complete for every\n$k$. This contrasts with a result of Belkhechine et al. which states that\ndeciding whether ${\\rm inv}(T)\\leq k$ for a given tournament $T$ is\npolynomial-time solvable.",
    "descriptor": "",
    "authors": [
      "J\u00f8rgen Bang-Jensen",
      "Jonas Costa Ferreira da Silva",
      "Fr\u00e9d\u00e9ric Havet"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.04137"
  },
  {
    "id": "arXiv:2105.04196",
    "title": "AoI-Aware Resource Allocation for Platoon-Based C-V2X Networks via  Multi-Agent Multi-Task Reinforcement Learning",
    "abstract": "This paper investigates the problem of age of information (AoI) aware radio\nresource management for a platooning system. Multiple autonomous platoons\nexploit the cellular wireless vehicle-to-everything (C-V2X) communication\ntechnology to disseminate the cooperative awareness messages (CAMs) to their\nfollowers while ensuring timely delivery of safety-critical messages to the\nRoad-Side Unit (RSU). Due to the challenges of dynamic channel conditions,\ncentralized resource management schemes that require global information are\ninefficient and lead to large signaling overheads. Hence, we exploit a\ndistributed resource allocation framework based on multi-agent reinforcement\nlearning (MARL), where each platoon leader (PL) acts as an agent and interacts\nwith the environment to learn its optimal policy. Existing MARL algorithms\nconsider a holistic reward function for the group's collective success, which\noften ends up with unsatisfactory results and cannot guarantee an optimal\npolicy for each agent. Consequently, motivated by the existing literature in\nRL, we propose a novel MARL framework that trains two critics with the\nfollowing goals: A global critic which estimates the global expected reward and\nmotivates the agents toward a cooperating behavior and an exclusive local\ncritic for each agent that estimates the local individual reward. Furthermore,\nbased on the tasks each agent has to accomplish, the individual reward of each\nagent is decomposed into multiple sub-reward functions where task-wise value\nfunctions are learned separately. Numerical results indicate our proposed\nalgorithm's effectiveness compared with the conventional RL methods applied in\nthis area.",
    "descriptor": "",
    "authors": [
      "Mohammad Parvini",
      "Mohammad Reza Javan",
      "Nader Mokari",
      "Bijan Abbasi",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.04196"
  },
  {
    "id": "arXiv:2105.04207",
    "title": "Age of Information Aware VNF Scheduling in Industrial IoT Using Deep  Reinforcement Learning",
    "abstract": "In delay-sensitive industrial internet of things (IIoT) applications, the age\nof information (AoI) is employed to characterize the freshness of information.\nMeanwhile, the emerging network function virtualization provides flexibility\nand agility for service providers to deliver a given network service using a\nsequence of virtual network functions (VNFs). However, suitable VNF placement\nand scheduling in these schemes is NP-hard and finding a globally optimal\nsolution by traditional approaches is complex. Recently, deep reinforcement\nlearning (DRL) has appeared as a viable way to solve such problems. In this\npaper, we first utilize single agent low-complex compound action actor-critic\nRL to cover both discrete and continuous actions and jointly minimize VNF cost\nand AoI in terms of network resources under end-to end Quality of Service\nconstraints. To surmount the single-agent capacity limitation for learning, we\nthen extend our solution to a multi-agent DRL scheme in which agents\ncollaborate with each other. Simulation results demonstrate that single-agent\nschemes significantly outperform the greedy algorithm in terms of average\nnetwork cost and AoI. Moreover, multi-agent solution decreases the average cost\nby dividing the tasks between the agents. However, it needs more iterations to\nbe learned due to the requirement on the agents collaboration.",
    "descriptor": "",
    "authors": [
      "Mohammad Akbari",
      "Mohammad Reza Abedi",
      "Roghayeh Joda",
      "Mohsen Pourghasemian",
      "Nader Mokari",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04207"
  },
  {
    "id": "arXiv:2105.04211",
    "title": "SigGPDE: Scaling Sparse Gaussian Processes on Sequential Data",
    "abstract": "Making predictions and quantifying their uncertainty when the input data is\nsequential is a fundamental learning challenge, recently attracting increasing\nattention. We develop SigGPDE, a new scalable sparse variational inference\nframework for Gaussian Processes (GPs) on sequential data. Our contribution is\ntwofold. First, we construct inducing variables underpinning the sparse\napproximation so that the resulting evidence lower bound (ELBO) does not\nrequire any matrix inversion. Second, we show that the gradients of the GP\nsignature kernel are solutions of a hyperbolic partial differential equation\n(PDE). This theoretical insight allows us to build an efficient\nback-propagation algorithm to optimize the ELBO. We showcase the significant\ncomputational gains of SigGPDE compared to existing methods, while achieving\nstate-of-the-art performance for classification tasks on large datasets of up\nto 1 million multivariate time series.",
    "descriptor": "",
    "authors": [
      "Maud Lemercier",
      "Cristopher Salvi",
      "Thomas Cass",
      "Edwin V. Bonilla",
      "Theodoros Damoulas",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04211"
  },
  {
    "id": "arXiv:2105.04230",
    "title": "Practical sufficient conditions for convergence of distributed  optimisation algorithms over communication networks with interference",
    "abstract": "Information exchange over networks can be affected by various forms of delay.\nThis causes challenges for using the network by a multi-agent system to solve a\ndistributed optimisation problem. Distributed optimisation schemes, however,\ntypically do not assume network models that are representative for real-world\ncommunication networks, since communication links are most of the time\nabstracted as lossless. Our objective is therefore to formulate a\nrepresentative network model and provide practically verifiable network\nconditions that ensure convergence of distributed algorithms in the presence of\ninterference and possibly unbounded delay. Our network is modelled by a\nsequence of directed-graphs, where to each network link we associate a process\nfor the instantaneous signal-to-interference-plus-noise ratio. We then\nformulate practical conditions that can be verified locally and show that the\nage of information (AoI) associated with data communicated over the network is\nin $\\mathcal{O}(\\sqrt{n})$. Under these conditions we show that a penalty-based\ngradient descent algorithm can be used to solve a rich class of stochastic,\nconstrained, distributed optimisation problems. The strength of our result lies\nin the bridge between practical verifiable network conditions and an abstract\noptimisation theory. We illustrate numerically that our algorithm converges in\nan extreme scenario where the average AoI diverges.",
    "descriptor": "",
    "authors": [
      "Adrian Redder",
      "Arunselvan Ramaswamy",
      "Holger Karl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.04230"
  },
  {
    "id": "arXiv:2105.04231",
    "title": "Distinct Fringe Subtrees in Random Trees",
    "abstract": "A fringe subtree of a rooted tree is a subtree induced by one of the vertices\nand all its descendants. We consider the problem of estimating the number of\ndistinct fringe subtrees in two types of random trees: simply generated trees\nand families of increasing trees (recursive trees, $d$-ary increasing trees and\ngeneralized plane-oriented recursive trees). We prove that the order of\nmagnitude of the number of distinct fringe subtrees (under rather mild\nassumptions on what `distinct' means) in random trees with $n$ vertices is\n$n/\\sqrt{\\log n}$ for simply generated trees and $n/\\log n$ for increasing\ntrees.",
    "descriptor": "",
    "authors": [
      "Louisa Seelbach Benkner",
      "Stephan Wagner"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.04231"
  },
  {
    "id": "arXiv:2105.04242",
    "title": "T-EMDE: Sketching-based global similarity for cross-modal retrieval",
    "abstract": "The key challenge in cross-modal retrieval is to find similarities between\nobjects represented with different modalities, such as image and text. However,\neach modality embeddings stem from non-related feature spaces, which causes the\nnotorious 'heterogeneity gap'. Currently, many cross-modal systems try to\nbridge the gap with self-attention. However, self-attention has been widely\ncriticized for its quadratic complexity, which prevents many real-life\napplications. In response to this, we propose T-EMDE - a neural density\nestimator inspired by the recently introduced Efficient Manifold Density\nEstimator (EMDE) from the area of recommender systems. EMDE operates on\nsketches - representations especially suitable for multimodal operations.\nHowever, EMDE is non-differentiable and ingests precomputed, static embeddings.\nWith T-EMDE we introduce a trainable version of EMDE which allows full\nend-to-end training. In contrast to self-attention, the complexity of our\nsolution is linear to the number of tokens/segments. As such, T-EMDE is a\ndrop-in replacement for the self-attention module, with beneficial influence on\nboth speed and metric performance in cross-modal settings. It facilitates\ncommunication between modalities, as each global text/image representation is\nexpressed with a standardized sketch histogram which represents the same\nmanifold structures irrespective of the underlying modality. We evaluate T-EMDE\nby introducing it into two recent cross-modal SOTA models and achieving new\nstate-of-the-art results on multiple datasets and decreasing model latency by\nup to 20%.",
    "descriptor": "\nComments: 10 pages,5 figures, 4 tables, 1 code snippet\n",
    "authors": [
      "Barbara Rychalska",
      "Mikolaj Wieczorek",
      "Jacek Dabrowski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04242"
  },
  {
    "id": "arXiv:2105.04257",
    "title": "Rational points of lattice ideals on a toric variety and toric codes",
    "abstract": "We show that the number of rational points of a subgroup inside a toric\nvariety over a finite field defined by a homogeneous lattice ideal can be\ncomputed via Smith normal form of the matrix whose columns constitute a basis\nof the lattice. This generalizes and yields a concise toric geometric proof of\nthe same fact proven purely algebraically by Lopez and Villarreal for the case\nof a projective space and a standard homogeneous lattice ideal of dimension\none. We also prove a Nullstellensatz type theorem over a finite field\nestablishing a one to one correspondence between subgroups of the dense split\ntorus and certain homogeneous lattice ideals. As application, we compute the\nmain parameters of generalized toric codes on subgroups of the torus of\nHirzebruch surfaces, generalizing the existing literature.",
    "descriptor": "\nComments: 21 pages, 1 figure, supported by TUBITAK 119F177\n",
    "authors": [
      "Mesut \u015eahin"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2105.04257"
  },
  {
    "id": "arXiv:2105.04269",
    "title": "Weakly supervised pan-cancer segmentation tool",
    "abstract": "The vast majority of semantic segmentation approaches rely on pixel-level\nannotations that are tedious and time consuming to obtain and suffer from\nsignificant inter and intra-expert variability. To address these issues, recent\napproaches have leveraged categorical annotations at the slide-level, that in\ngeneral suffer from robustness and generalization. In this paper, we propose a\nnovel weakly supervised multi-instance learning approach that deciphers\nquantitative slide-level annotations which are fast to obtain and regularly\npresent in clinical routine. The extreme potentials of the proposed approach\nare demonstrated for tumor segmentation of solid cancer subtypes. The proposed\napproach achieves superior performance in out-of-distribution, out-of-location,\nand out-of-domain testing sets.",
    "descriptor": "",
    "authors": [
      "Marvin Lerousseau",
      "Marion Classe",
      "Enzo Battistella",
      "Th\u00e9o Estienne",
      "Th\u00e9ophraste Henry",
      "Amaury Leroy",
      "Roger Sun",
      "Maria Vakalopoulou",
      "Jean-Yves Scoazec",
      "Eric Deutsch",
      "Nikos Paragios"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04269"
  },
  {
    "id": "arXiv:2105.04290",
    "title": "Meta-Cal: Well-controlled Post-hoc Calibration by Ranking",
    "abstract": "In many applications, it is desirable that a classifier not only makes\naccurate predictions, but also outputs calibrated probabilities. However, many\nexisting classifiers, especially deep neural network classifiers, tend not to\nbe calibrated. Post-hoc calibration is a technique to recalibrate a model, and\nits goal is to learn a calibration map. Existing approaches mostly focus on\nconstructing calibration maps with low calibration errors. Contrary to these\nmethods, we study post-hoc calibration for multi-class classification under\nconstraints, as a calibrator with a low calibration error does not necessarily\nmean it is useful in practice. In this paper, we introduce two practical\nconstraints to be taken into consideration. We then present Meta-Cal, which is\nbuilt from a base calibrator and a ranking model. Under some mild assumptions,\ntwo high-probability bounds are given with respect to these constraints.\nEmpirical results on CIFAR-10, CIFAR-100 and ImageNet and a range of popular\nnetwork architectures show our proposed method significantly outperforms the\ncurrent state of the art for post-hoc multi-class classification calibration.",
    "descriptor": "",
    "authors": [
      "Xingchen Ma",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04290"
  },
  {
    "id": "arXiv:2105.04310",
    "title": "Study on the temporal pooling used in deep neural networks for speaker  verification",
    "abstract": "The x-vector architecture has recently achieved state-of-the-art results on\nthe speaker verification task. This architecture incorporates a central layer,\nreferred to as temporal pooling, which stacks statistical parameters of the\nacoustic frame distribution. This work proposes to highlight the significant\neffect of the temporal pooling content on the training dynamics and task\nperformance. An evaluation with different pooling layers is conducted, that is,\nincluding different statistical measures of central tendency. Notably, 3rd and\n4th moment-based statistics (skewness and kurtosis) are also tested to complete\nthe usual mean and standard-deviation parameters. Our experiments show the\ninfluence of the pooling layer content in terms of speaker verification\nperformance, but also for several classification tasks (speaker, channel or\ntext related), and allow to better reveal the presence of external information\nto the speaker identity depending on the layer content.",
    "descriptor": "",
    "authors": [
      "Mickael Rouvier",
      "Pierre-Michel Bousquet",
      "Jarod Duret"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.04310"
  },
  {
    "id": "arXiv:2105.04321",
    "title": "Reinforcement learning of rare diffusive dynamics",
    "abstract": "We present a method to probe rare molecular dynamics trajectories directly\nusing reinforcement learning. We consider trajectories that are conditioned to\ntransition between regions of configuration space in finite time, like those\nrelevant in the study of reactive events, as well as trajectories exhibiting\nrare fluctuations of time-integrated quantities in the long time limit, like\nthose relevant in the calculation of large deviation functions. In both cases,\nreinforcement learning techniques are used to optimize an added force that\nminimizes the Kullback-Leibler divergence between the conditioned trajectory\nensemble and a driven one. Under the optimized added force, the system evolves\nthe rare fluctuation as a typical one, affording a variational estimate of its\nlikelihood in the original trajectory ensemble. Low variance gradients\nemploying value functions are proposed to increase the convergence of the\noptimal force. The method we develop employing these gradients leads to\nefficient and accurate estimates of both the optimal force and the likelihood\nof the rare event for a variety of model systems.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Avishek Das",
      "Dominic C. Rose",
      "Juan P. Garrahan",
      "David T. Limmer"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04321"
  },
  {
    "id": "arXiv:2105.04350",
    "title": "tFold-TR: Combining Deep Learning Enhanced Hybrid Potential Energy for  Template-Based Modelling Structure Refinement",
    "abstract": "Proteins structure prediction has long been a grand challenge over the past\n50 years, owing to its board scientific and application interests. There are\ntwo major types of modelling algorithm, template-free modelling and\ntemplate-based modelling, which is suitable for easy prediction tasks, and is\nwidely adopted in computer aided drug discoveries for drug design and\nscreening. Although it has been several decades since its first edition, the\ncurrent template-based modeling approach suffers from two important problems:\n1) there are many missing regions in the template-query sequence alignment, and\n2) the accuracy of the distance pairs from different regions of the template\nvaries, and this information is not well introduced into the modeling. To solve\nthe two problems, we propose a structural optimization process based on\ntemplate modelling, introducing two neural network models predict the distance\ninformation of the missing regions and the accuracy of the distance pairs of\ndifferent regions in the template modeling structure. The predicted distances\nand residue pairwise specific accuracy information are incorporated into the\npotential energy function for structural optimization, which significantly\nimproves the qualities of the original template modelling decoys.",
    "descriptor": "\nComments: 27 pages, 9 figures\n",
    "authors": [
      "Liangzhen Zheng",
      "Haidong Lan",
      "Tao Shen",
      "Jiaxiang Wu",
      "Sheng Wang",
      "Wei Liu",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04350"
  },
  {
    "id": "arXiv:2105.04355",
    "title": "Situated Transition Sytems",
    "abstract": "We construct a monoidal category of open transition systems that generate\nmaterial history as transitions unfold, which we call situated transition\nsystems. The material history generated by a composite system is composed of\nthe material history generated by each component. The construction is\nparameterized by a symmetric strict monoidal category, understood as a resource\ntheory, from which material histories are drawn. We pay special attention to\nthe case in which this category is compact closed. In particular, if we begin\nwith a compact closed category of integers then the resulting situated\ntransition systems can be understood as systems of double-entry bookkeeping\naccounts.",
    "descriptor": "\nComments: Preprint. 18 pages including bibliography and appendix. In peer review\n",
    "authors": [
      "Chad Nester"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.04355"
  },
  {
    "id": "arXiv:2105.04356",
    "title": "Coconut trees detection and segmentation in aerial imagery using mask  region-based convolution neural network",
    "abstract": "Food resources face severe damages under extraordinary situations of\ncatastrophes such as earthquakes, cyclones, and tsunamis. Under such scenarios,\nspeedy assessment of food resources from agricultural land is critical as it\nsupports aid activity in the disaster hit areas. In this article, a deep\nlearning approach is presented for the detection and segmentation of coconut\ntress in aerial imagery provided through the AI competition organized by the\nWorld Bank in collaboration with OpenAerialMap and WeRobotics. Maked\nRegion-based Convolutional Neural Network approach was used identification and\nsegmentation of coconut trees. For the segmentation task, Mask R-CNN model with\nResNet50 and ResNet1010 based architectures was used. Several experiments with\ndifferent configuration parameters were performed and the best configuration\nfor the detection of coconut trees with more than 90% confidence factor was\nreported. For the purpose of evaluation, Microsoft COCO dataset evaluation\nmetric namely mean average precision (mAP) was used. An overall 91% mean\naverage precision for coconut trees detection was achieved.",
    "descriptor": "\nComments: Published in IET Computer Vision, 09 April 2021\n",
    "authors": [
      "Muhammad Shakaib Iqbal",
      "Hazrat Ali",
      "Son N. Tran",
      "Talha Iqbal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04356"
  },
  {
    "id": "arXiv:2105.04361",
    "title": "Extension of the single-nonlinear-mode theory by linear attachments and  application to exciter-structure interaction",
    "abstract": "Under certain conditions, the dynamics of a nonlinear mechanical system can\nbe represented by a single nonlinear modal oscillator. The properties of the\nmodal oscillator can be determined by computational or experimental nonlinear\nmodal analysis. The simplification to a single-nonlinear-mode model facilitates\nqualitative and global analysis, and substantially reduces the computational\neffort required for probabilistic methods and design optimization. Important\nlimitations of this theory are that only purely mechanical systems can be\nanalyzed and that the respective nonlinear mode has to be recomputed when the\nsystem's structural properties are varied. With the theoretical extension\nproposed in this work, it becomes feasible to attach linear subsystems to the\nprimary mechanical system, and to approximate the dynamics of this coupled\nsystem using only the nonlinear mode of the primary mechanical system. The\nattachments must be described by linear ordinary or differential-algebraic\nequations with time-invariant coefficient matrices. The attachments do not need\nto be of purely mechanical nature, but may contain, for instance, electric,\nmagnetic, acoustic, thermal or aerodynamic models. This considerably extends\nthe range of utility of nonlinear modes to applications as diverse as model\nupdating or vibration energy harvesting. As long as the attachments do not\nsignificantly deteriorate the host system's modal deflection shape, it is shown\nthat their effect can be reduced to a complex-valued modal impedance and an\nimposed modal forcing term. In the present work, the proposed approach is\ncomputationally assessed for the analysis of exciter-structure interaction.\nMore specifically, the force drop typically encountered in frequency response\ntesting is revisited.",
    "descriptor": "",
    "authors": [
      "Malte Krack"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04361"
  },
  {
    "id": "arXiv:2105.04379",
    "title": "Gradient-based Bayesian Experimental Design for Implicit Models using  Mutual Information Lower Bounds",
    "abstract": "We introduce a framework for Bayesian experimental design (BED) with implicit\nmodels, where the data-generating distribution is intractable but sampling from\nit is still possible. In order to find optimal experimental designs for such\nmodels, our approach maximises mutual information lower bounds that are\nparametrised by neural networks. By training a neural network on sampled data,\nwe simultaneously update network parameters and designs using stochastic\ngradient-ascent. The framework enables experimental design with a variety of\nprominent lower bounds and can be applied to a wide range of scientific tasks,\nsuch as parameter estimation, model discrimination and improving future\npredictions. Using a set of intractable toy models, we provide a comprehensive\nempirical comparison of prominent lower bounds applied to the aforementioned\ntasks. We further validate our framework on a challenging system of stochastic\ndifferential equations from epidemiology.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Steven Kleinegesse",
      "Michael U. Gutmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.04379"
  },
  {
    "id": "arXiv:2105.04404",
    "title": "Topological Uncertainty: Monitoring trained neural networks through  persistence of activation graphs",
    "abstract": "Although neural networks are capable of reaching astonishing performances on\na wide variety of contexts, properly training networks on complicated tasks\nrequires expertise and can be expensive from a computational perspective. In\nindustrial applications, data coming from an open-world setting might widely\ndiffer from the benchmark datasets on which a network was trained. Being able\nto monitor the presence of such variations without retraining the network is of\ncrucial importance. In this article, we develop a method to monitor trained\nneural networks based on the topological properties of their activation graphs.\nTo each new observation, we assign a Topological Uncertainty, a score that aims\nto assess the reliability of the predictions by investigating the whole network\ninstead of its final layer only, as typically done by practitioners. Our\napproach entirely works at a post-training level and does not require any\nassumption on the network architecture, optimization scheme, nor the use of\ndata augmentation or auxiliary datasets; and can be faithfully applied on a\nlarge range of network architectures and data types. We showcase experimentally\nthe potential of Topological Uncertainty in the context of trained network\nselection, Out-Of-Distribution detection, and shift-detection, both on\nsynthetic and real datasets of images and graphs.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Lacombe",
      "Yuichi Ike",
      "Mathieu Carriere",
      "Fr\u00e9d\u00e9ric Chazal",
      "Marc Glisse",
      "Yuhei Umeda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04404"
  },
  {
    "id": "arXiv:2105.04417",
    "title": "A plug-and-play type field-deployable bio-agent free salicylic acid  sensing system",
    "abstract": "Salicylic acid (SA) is a primary phytohormone released in response to stress,\nparticularly biotic infections in plants. Monitoring SA levels may provide a\nway for early disease detection in crops providing a way for applying effective\nmeasures for reducing agricultural losses while increase our agricultural\nefficiency. Additionally, SA is an important chemical used extensively in the\npharmaceutical and healthcare industry due to its analgesic and\nanti-inflammatory properties. Developing a fast and accurate way for monitoring\nSA levels in human serum can have a life-saving impact for patients suffering\nfrom overdosing and/or mis-dosing. In this work, we present a low-cost,\nportable, and field-deployable electrochemical SA sensing system aimed towards\nachieving the above-mentioned goals. The developed sensor consists of a\nplug-and-play type device equipped with specialized designed high accuracy\nsensing electronics and a novel procedure for robust data analysis. The\ndeveloped sensor exhibits excellent linearity and sensitivity and selectivity.\nThe practical applicability of the developed sensor was also demonstrated by\nmeasuring SA levels in real samples with good accuracy.",
    "descriptor": "",
    "authors": [
      "Bhuwan Kashyap",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04417"
  },
  {
    "id": "arXiv:2105.04427",
    "title": "A practical, effective calculation of gamma difference distributions  with open data science tools",
    "abstract": "At present, there is still no officially accepted and extensively verified\nimplementation of computing the gamma difference distribution allowing unequal\nshape parameters. We explore four computational ways of the gamma difference\ndistribution with the different shape parameters resulting from time series\nkriging, a forecasting approach based on the best linear unbiased prediction,\nand linear mixed models. The results of our numerical study, with emphasis on\nusing open data science tools, demonstrate that our open tool implemented in\nhigh-performance Python(with Numba) is exponentially fast, highly accurate, and\nvery reliable. It combines numerical inversion of the characteristic function\nand the trapezoidal rule with the double exponential oscillatory transformation\n(DE quadrature). At the double 53-bit precision, our tool outperformed the\nspeed of the analytical computation based on Tricomi's $U(a, b, z)$ function in\nCAS software (commercial Mathematica, open SageMath) by 1.5-2 orders. At the\nprecision of scientific numerical computational tools, it exceeded open SciPy,\nNumPy, and commercial MATLAB 5-10 times. The potential future application of\nour tool for a mixture of characteristic functions could open new possibilities\nfor fast data analysis based on exact probability distributions in areas like\nmultidimensional statistics, measurement uncertainty analysis in metrology as\nwell as in financial mathematics and risk analysis.",
    "descriptor": "\nComments: 26 pages, 4 figures, 2 tables, 1 box\n",
    "authors": [
      "Martina Han\u010dov\u00e1",
      "Andrej Gajdo\u0161",
      "Jozef Han\u010d"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04427"
  },
  {
    "id": "arXiv:2105.04448",
    "title": "Scaffolding Simulations with Deep Learning for High-dimensional  Deconvolution",
    "abstract": "A common setting for scientific inference is the ability to sample from a\nhigh-fidelity forward model (simulation) without having an explicit probability\ndensity of the data. We propose a simulation-based maximum likelihood\ndeconvolution approach in this setting called OmniFold. Deep learning enables\nthis approach to be naturally unbinned and (variable-, and) high-dimensional.\nIn contrast to model parameter estimation, the goal of deconvolution is to\nremove detector distortions in order to enable a variety of down-stream\ninference tasks. Our approach is the deep learning generalization of the common\nRichardson-Lucy approach that is also called Iterative Bayesian Unfolding in\nparticle physics. We show how OmniFold can not only remove detector\ndistortions, but it can also account for noise processes and acceptance\neffects.",
    "descriptor": "\nComments: 6 pages, 1 figure, 1 table\n",
    "authors": [
      "Anders Andreassen",
      "Patrick T. Komiske",
      "Eric M. Metodiev",
      "Benjamin Nachman",
      "Adi Suresh",
      "Jesse Thaler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.04448"
  },
  {
    "id": "arXiv:2105.04455",
    "title": "Simplicial contagion in temporal higher-order networks",
    "abstract": "Complex networks represent the natural backbone to study epidemic processes\nin populations of interacting individuals. Such a modeling framework, however,\nis naturally limited to pairwise interactions, making it less suitable to\nproperly describe social contagion, where individuals acquire new norms or\nideas after simultaneous exposure to multiple sources of infections. Simplicial\ncontagion has been proposed as an alternative framework where simplices are\nused to encode group interactions of any order. The presence of higher-order\ninteractions leads to explosive epidemic transitions and bistability which\ncannot be obtained when only dyadic ties are considered. In particular,\ncritical mass effects can emerge even for infectivity values below the standard\npairwise epidemic threshold, where the size of the initial seed of infectious\nnodes determines whether the system would eventually fall in the endemic or the\nhealthy state. Here we extend simplicial contagion to time-varying networks,\nwhere pairwise and higher-order simplices can be created or destroyed over\ntime. By following a microscopic Markov chain approach, we find that the same\nseed of infectious nodes might or might not lead to an endemic stationary\nstate, depending on the temporal properties of the underlying network\nstructure, and show that persistent temporal interactions anticipate the onset\nof the endemic state in finite-size systems. We characterize this behavior on\nhigher-order networks with a prescribed temporal correlation between\nconsecutive interactions and on heterogeneous simplicial complexes, showing\nthat temporality again limits the effect of higher-order spreading, but in a\nless pronounced way than for homogeneous structures. Our work suggests the\nimportance of incorporating temporality, a realistic feature of many real-world\nsystems, into the investigation of dynamical processes beyond pairwise\ninteractions.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Sandeep Chowdhary",
      "Aanjaneya Kumar",
      "Giulia Cencetti",
      "Iacopo Iacopini",
      "Federico Battiston"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.04455"
  },
  {
    "id": "arXiv:2105.04460",
    "title": "Galois/monodromy groups for decomposing minimal problems in 3D  reconstruction",
    "abstract": "We consider Galois/monodromy groups arising in computer vision applications,\nwith a view towards building more efficient polynomial solvers. The\nGalois/monodromy group allows us to decide when a given problem decomposes into\nalgebraic subproblems, and whether or not it has any symmetries. Tools from\nnumerical algebraic geometry and computational group theory allow us to apply\nthis framework to classical and novel reconstruction problems. We consider\nthree classical cases--3-point absolute pose, 5-point relative pose, and\n4-point homography estimation for calibrated cameras--where the decomposition\nand symmetries may be naturally understood in terms of the Galois/monodromy\ngroup. We then show how our framework can be applied to novel problems from\nabsolute and relative pose estimation. For instance, we discover new symmetries\nfor absolute pose problems involving mixtures of point and line features. We\nalso describe a problem of estimating a pair of calibrated homographies between\nthree images. For this problem of degree 64, we can reduce the degree to 16;\nthe latter better reflecting the intrinsic difficulty of algebraically solving\nthe problem. As a byproduct, we obtain new constraints on compatible\nhomographies, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Timothy Duff",
      "Viktor Korotynskiy",
      "Tomas Pajdla",
      "Margaret H. Regan"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04460"
  },
  {
    "id": "arXiv:2105.04480",
    "title": "Is there Anisotropy in Structural Bias?",
    "abstract": "Structural Bias (SB) is an important type of algorithmic deficiency within\niterative optimisation heuristics. However, methods for detecting structural\nbias have not yet fully matured, and recent studies have uncovered many\ninteresting questions. One of these is the question of how structural bias can\nbe related to anisotropy. Intuitively, an algorithm that is not isotropic would\nbe considered structurally biased. However, there have been cases where\nalgorithms appear to only show SB in some dimensions. As such, we investigate\nwhether these algorithms actually exhibit anisotropy, and how this impacts the\ndetection of SB. We find that anisotropy is very rare, and even in cases where\nit is present, there are clear tests for SB which do not rely on any\nassumptions of isotropy, so we can safely expand the suite of SB tests to\nencompass these kinds of deficiencies not found by the original tests.\nWe propose several additional testing procedures for SB detection and aim to\nmotivate further research into the creation of a robust portfolio of tests.\nThis is crucial since no single test will be able to work effectively with all\ntypes of SB we identify.",
    "descriptor": "",
    "authors": [
      "Diederick Vermetten",
      "Anna V. Kononova",
      "Fabio Caraffini",
      "Hao Wang",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.04480"
  },
  {
    "id": "arXiv:2105.04504",
    "title": "Deep Neural Networks as Point Estimates for Deep Gaussian Processes",
    "abstract": "Deep Gaussian processes (DGPs) have struggled for relevance in applications\ndue to the challenges and cost associated with Bayesian inference. In this\npaper we propose a sparse variational approximation for DGPs for which the\napproximate posterior mean has the same mathematical structure as a Deep Neural\nNetwork (DNN). We make the forward pass through a DGP equivalent to a ReLU DNN\nby finding an interdomain transformation that represents the GP posterior mean\nas a sum of ReLU basis functions. This unification enables the initialisation\nand training of the DGP as a neural network, leveraging the well established\npractice in the deep learning community, and so greatly aiding the inference\ntask. The experiments demonstrate improved accuracy and faster training\ncompared to current DGP methods, while retaining favourable predictive\nuncertainties.",
    "descriptor": "",
    "authors": [
      "Vincent Dutordoir",
      "James Hensman",
      "Mark van der Wilk",
      "Carl Henrik Ek",
      "Zoubin Ghahramani",
      "Nicolas Durrande"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04504"
  },
  {
    "id": "arXiv:2105.04514",
    "title": "On the Role of Incentives in Evolutionary Approaches to Organizational  Design",
    "abstract": "This paper introduces a model of a stylized organization that is comprised of\nseveral departments that autonomously allocate tasks. To do so, the departments\neither take short-sighted decisions that immediately maximize their utility or\ntake long-sighted decisions that aim at minimizing the interdependencies\nbetween tasks. The organization guides the departments' behavior by either an\nindividualistic, a balanced, or an altruistic linear incentive scheme. Even if\ntasks are perfectly decomposable, altruistic incentive schemes are preferred\nover individualistic incentive schemes since they substantially increase the\norganization's performance. Interestingly, if altruistic incentive schemes are\neffective, short-sighted decisions appear favorable since they do not only\nincrease performance in the short run but also result in significantly higher\nperformances in the long run.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Stephan Leitner"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2105.04514"
  },
  {
    "id": "arXiv:2105.04532",
    "title": "Improved Simultaneous Multi-Slice Functional MRI Using Self-supervised  Deep Learning",
    "abstract": "Functional MRI (fMRI) is commonly used for interpreting neural activities\nacross the brain. Numerous accelerated fMRI techniques aim to provide improved\nspatiotemporal resolutions. Among these, simultaneous multi-slice (SMS) imaging\nhas emerged as a powerful strategy, becoming a part of large-scale studies,\nsuch as the Human Connectome Project. However, when SMS imaging is combined\nwith in-plane acceleration for higher acceleration rates, conventional SMS\nreconstruction methods may suffer from noise amplification and other artifacts.\nRecently, deep learning (DL) techniques have gained interest for improving MRI\nreconstruction. However, these methods are typically trained in a supervised\nmanner that necessitates fully-sampled reference data, which is not feasible in\nhighly-accelerated fMRI acquisitions. Self-supervised learning that does not\nrequire fully-sampled data has recently been proposed and has shown similar\nperformance to supervised learning. However, it has only been applied for\nin-plane acceleration. Furthermore the effect of DL reconstruction on\nsubsequent fMRI analysis remains unclear. In this work, we extend\nself-supervised DL reconstruction to SMS imaging. Our results on prospectively\n10-fold accelerated 7T fMRI data show that self-supervised DL reduces\nreconstruction noise and suppresses residual artifacts. Subsequent fMRI\nanalysis remains unaltered by DL processing, while the improved temporal\nsignal-to-noise ratio produces higher coherence estimates between task runs.",
    "descriptor": "",
    "authors": [
      "Omer Burak Demirel",
      "Burhaneddin Yaman",
      "Logan Dowdle",
      "Steen Moeller",
      "Luca Vizioli",
      "Essa Yacoub",
      "John Strupp",
      "Cheryl A. Olman",
      "K\u00e2mil U\u011furbil",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.04532"
  },
  {
    "id": "arXiv:1312.7832",
    "title": "Defining implication relation for classical logic",
    "abstract": "Comments: 15 pages; 1 table. Major revision: added semantics, rules of inference, and truth values of implication relation; elaborated description of relationship to classical logic; corrected typos",
    "descriptor": "\nComments: 15 pages; 1 table. Major revision: added semantics, rules of inference, and truth values of implication relation; elaborated description of relationship to classical logic; corrected typos\n",
    "authors": [
      "Li Fu"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1312.7832"
  },
  {
    "id": "arXiv:1611.06221",
    "title": "Foundations of Structural Causal Models with Cycles and Latent Variables",
    "abstract": "Comments: 75 pages (including supplementary material)",
    "descriptor": "\nComments: 75 pages (including supplementary material)\n",
    "authors": [
      "Stephan Bongers",
      "Patrick Forr\u00e9",
      "Jonas Peters",
      "Joris M. Mooij"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1611.06221"
  },
  {
    "id": "arXiv:1701.06487",
    "title": "Dirty Pixels: Towards End-to-End Image Processing and Perception",
    "abstract": "Dirty Pixels: Towards End-to-End Image Processing and Perception",
    "descriptor": "",
    "authors": [
      "Steven Diamond",
      "Vincent Sitzmann",
      "Frank Julca-Aguilar",
      "Stephen Boyd",
      "Gordon Wetzstein",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1701.06487"
  },
  {
    "id": "arXiv:1706.07151",
    "title": "Multiplicative Pacing Equilibria in Auction Markets",
    "abstract": "Multiplicative Pacing Equilibria in Auction Markets",
    "descriptor": "",
    "authors": [
      "Vincent Conitzer",
      "Christian Kroer",
      "Eric Sodomka",
      "Nicolas E. Stier-Moses"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1706.07151"
  },
  {
    "id": "arXiv:1709.09452",
    "title": "Rate of Orientation Change as a New Metric for Robot-Assisted and Open  Surgical Skill Evaluation",
    "abstract": "Rate of Orientation Change as a New Metric for Robot-Assisted and Open  Surgical Skill Evaluation",
    "descriptor": "",
    "authors": [
      "Yarden Sharon",
      "Anthony M. Jarc",
      "Thomas S. Lendvay",
      "Ilana Nisky"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1709.09452"
  },
  {
    "id": "arXiv:1802.05935",
    "title": "Decidability for Entailments of Symbolic Heaps with Arrays",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1708.06696",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1708.06696\n",
    "authors": [
      "Daisuke Kimura",
      "Makoto Tatsuta"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1802.05935"
  },
  {
    "id": "arXiv:1809.00082",
    "title": "NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation",
    "abstract": "Comments: 28 pages: main body, 24 pages: appendix, 8 Figures, 11 Tables",
    "descriptor": "\nComments: 28 pages: main body, 24 pages: appendix, 8 Figures, 11 Tables\n",
    "authors": [
      "Anastasis Kratsios",
      "Cody Hyndman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/1809.00082"
  },
  {
    "id": "arXiv:1812.03579",
    "title": "On the Generalized Degrees of Freedom of Noncoherent Interference  Channel",
    "abstract": "Comments: Reorganized the paper and gave more details on gDoF. Clearer channel model. Replaced INR as a function of SNR in the proofs",
    "descriptor": "\nComments: Reorganized the paper and gave more details on gDoF. Clearer channel model. Replaced INR as a function of SNR in the proofs\n",
    "authors": [
      "Joyson Sebastian",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1812.03579"
  },
  {
    "id": "arXiv:1812.09636",
    "title": "GM-PHD Filter for Searching and Tracking an Unknown Number of Targets  with a Mobile Sensor with Limited FOV",
    "abstract": "Comments: 14 pages, 15 figures, Published in IEEE Transactions on Automation Science and Engineering, 2021",
    "descriptor": "\nComments: 14 pages, 15 figures, Published in IEEE Transactions on Automation Science and Engineering, 2021\n",
    "authors": [
      "Yoonchang Sung",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1812.09636"
  },
  {
    "id": "arXiv:1901.07066",
    "title": "On Compression of Unsupervised Neural Nets by Pruning Weak Connections",
    "abstract": "Comments: This paper needs to be further revised",
    "descriptor": "\nComments: This paper needs to be further revised\n",
    "authors": [
      "Zhiwen Zuo",
      "Lei Zhao",
      "Liwen Zuo",
      "Feng Jiang",
      "Wei Xing",
      "Dongming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1901.07066"
  },
  {
    "id": "arXiv:1903.04656",
    "title": "Deep Log-Likelihood Ratio Quantization",
    "abstract": "Comments: Accepted for publication at EUSIPCO 2019. Camera-ready version",
    "descriptor": "\nComments: Accepted for publication at EUSIPCO 2019. Camera-ready version\n",
    "authors": [
      "Marius Arvinte",
      "Ahmed H. Tewfik",
      "Sriram Vishwanath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1903.04656"
  },
  {
    "id": "arXiv:1903.07020",
    "title": "Zeno++: Robust Fully Asynchronous SGD",
    "abstract": "Comments: ICML version with some additional remarks related to the acceptance rate of Byzantine validation, and also with the full version of error bounds in the theorems",
    "descriptor": "\nComments: ICML version with some additional remarks related to the acceptance rate of Byzantine validation, and also with the full version of error bounds in the theorems\n",
    "authors": [
      "Cong Xie",
      "Sanmi Koyejo",
      "Indranil Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1903.07020"
  },
  {
    "id": "arXiv:1904.12175",
    "title": "Unsupervised and Unregistered Hyperspectral Image Super-Resolution with  Mutual Dirichlet-Net",
    "abstract": "Comments: IEEE Transactions on Remote Sensing and Geoscience",
    "descriptor": "\nComments: IEEE Transactions on Remote Sensing and Geoscience\n",
    "authors": [
      "Ying Qu",
      "Hairong Qi",
      "Chiman Kwan",
      "Naoto Yokoya",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1904.12175"
  },
  {
    "id": "arXiv:1906.01715",
    "title": "$hp$-Version discontinuous Galerkin methods on essentially  arbitrarily-shaped elements",
    "abstract": "$hp$-Version discontinuous Galerkin methods on essentially  arbitrarily-shaped elements",
    "descriptor": "",
    "authors": [
      "Andrea Cangiani",
      "Zhaonan Dong",
      "Emmanuil H. Georgoulis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1906.01715"
  },
  {
    "id": "arXiv:1906.07265",
    "title": "Recovering shared structure from multiple networks with unknown edge  distributions",
    "abstract": "Recovering shared structure from multiple networks with unknown edge  distributions",
    "descriptor": "",
    "authors": [
      "Keith Levin",
      "Asad Lodhia",
      "Elizaveta Levina"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.07265"
  },
  {
    "id": "arXiv:1906.07849",
    "title": "Deep Learning-Based Quantization of L-Values for Gray-Coded Modulation",
    "abstract": "Comments: Submitted to IEEE Globecom 2019",
    "descriptor": "\nComments: Submitted to IEEE Globecom 2019\n",
    "authors": [
      "Marius Arvinte",
      "Sriram Vishwanath",
      "Ahmed H. Tewfik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.07849"
  },
  {
    "id": "arXiv:1906.09105",
    "title": "A Topological Application of Labelled Natural Deduction",
    "abstract": "Comments: 42 pages, 5 figures. arXiv admin note: text overlap with arXiv:1804.01413, arXiv:1803.01709, arXiv:1906.09107",
    "descriptor": "\nComments: 42 pages, 5 figures. arXiv admin note: text overlap with arXiv:1804.01413, arXiv:1803.01709, arXiv:1906.09107\n",
    "authors": [
      "Tiago M. L.Veras",
      "Arthur F. Ramos",
      "Ruy J. G. B. de Queiroz",
      "Anjolina G. de Oliveira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/1906.09105"
  },
  {
    "id": "arXiv:1907.07349",
    "title": "Edge computing server placement with capacitated location allocation",
    "abstract": "Edge computing server placement with capacitated location allocation",
    "descriptor": "",
    "authors": [
      "Tero L\u00e4hderanta",
      "Teemu Lepp\u00e4nen",
      "Leena Ruha",
      "Lauri Lov\u00e9n",
      "Erkki Harjula",
      "Mika Ylianttila",
      "Jukka Riekki",
      "Mikko J. Sillanp\u00e4\u00e4"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1907.07349"
  },
  {
    "id": "arXiv:1907.07845",
    "title": "Linear-semiorders and their incomparability graphs",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Asahi Takaoka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1907.07845"
  },
  {
    "id": "arXiv:1907.11210",
    "title": "HUGE2: a Highly Untangled Generative-model Engine for Edge-computing",
    "abstract": "HUGE2: a Highly Untangled Generative-model Engine for Edge-computing",
    "descriptor": "",
    "authors": [
      "Feng Shi",
      "Ziheng Xu",
      "Tao Yuan",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1907.11210"
  },
  {
    "id": "arXiv:1908.00865",
    "title": "Gradient flows and proximal splitting methods: A unified view on  accelerated and stochastic optimization",
    "abstract": "Comments: the paper was reorganized; new additional material; matches published version",
    "descriptor": "\nComments: the paper was reorganized; new additional material; matches published version\n",
    "authors": [
      "Guilherme Fran\u00e7a",
      "Daniel P. Robinson",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.00865"
  },
  {
    "id": "arXiv:1908.02477",
    "title": "Ab Antiquo: Neural Proto-language Reconstruction",
    "abstract": "Comments: Accepted as a long paper in NAACL21",
    "descriptor": "\nComments: Accepted as a long paper in NAACL21\n",
    "authors": [
      "Carlo Meloni",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1908.02477"
  },
  {
    "id": "arXiv:1908.09485",
    "title": "Successive Point-of-Interest Recommendation with Local Differential  Privacy",
    "abstract": "Comments: This paper has been accepted to IEEE Access",
    "descriptor": "\nComments: This paper has been accepted to IEEE Access\n",
    "authors": [
      "Jong Seon Kim",
      "Jong Wook Kim",
      "Yon Dohn Chung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1908.09485"
  },
  {
    "id": "arXiv:1909.02291",
    "title": "Learning Action-Transferable Policy with Action Embedding",
    "abstract": "Learning Action-Transferable Policy with Action Embedding",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Yingfeng Chen",
      "Zhipeng Hu",
      "Tianpei Yang",
      "Changjie Fan",
      "Yang Yu",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1909.02291"
  },
  {
    "id": "arXiv:1909.07558",
    "title": "HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial  Examples",
    "abstract": "Comments: There is some error in our work. For example,\"Notably, we linked a fully connected discriminant network in parallel at the penultimate level of the target classifier.\" (section 3.2) Incorrect description of the network structure can mislead readers. For example, \"associate GAN with human imagination\" is not true.(section 1)",
    "descriptor": "\nComments: There is some error in our work. For example,\"Notably, we linked a fully connected discriminant network in parallel at the penultimate level of the target classifier.\" (section 3.2) Incorrect description of the network structure can mislead readers. For example, \"associate GAN with human imagination\" is not true.(section 1)\n",
    "authors": [
      "Wanting Yu",
      "Hongyi Yu",
      "Lingyun Jiang",
      "Mengli Zhang",
      "Kai Qiao",
      "Linyuan Wang",
      "Bin Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1909.07558"
  },
  {
    "id": "arXiv:1910.12478",
    "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any  Architecture are Gaussian Processes",
    "abstract": "Comments: Appearing in NeurIPS 2019; 10 pages of main text; 12 figures, 11 programs; 73 pages total",
    "descriptor": "\nComments: Appearing in NeurIPS 2019; 10 pages of main text; 12 figures, 11 programs; 73 pages total\n",
    "authors": [
      "Greg Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/1910.12478"
  },
  {
    "id": "arXiv:1911.01503",
    "title": "Metropolized Forest Recombination for Monte Carlo Sampling of Graph  Partitions",
    "abstract": "Comments: 29 pages; 14 figures; 3 page appendix",
    "descriptor": "\nComments: 29 pages; 14 figures; 3 page appendix\n",
    "authors": [
      "Eric Autrey",
      "Daniel Carter",
      "Gregory Herschlag",
      "Zach Hunter",
      "Jonathan C. Mattingly"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1911.01503"
  },
  {
    "id": "arXiv:1911.05844",
    "title": "Naive cubical type theory",
    "abstract": "Naive cubical type theory",
    "descriptor": "",
    "authors": [
      "Bruno Bentzen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1911.05844"
  },
  {
    "id": "arXiv:1911.08054",
    "title": "Policy-Gradient Training of Fair and Unbiased Ranking Functions",
    "abstract": "Policy-Gradient Training of Fair and Unbiased Ranking Functions",
    "descriptor": "",
    "authors": [
      "Himank Yadav",
      "Zhengxiao Du",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.08054"
  },
  {
    "id": "arXiv:1911.12749",
    "title": "A Formal System for the Universal Quantification of Schematic Variables",
    "abstract": "Comments: 37 pages, minor revision",
    "descriptor": "\nComments: 37 pages, minor revision\n",
    "authors": [
      "Ferruccio Guidi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1911.12749"
  },
  {
    "id": "arXiv:1912.13494",
    "title": "A frequency-domain analysis of inexact gradient methods",
    "abstract": "Comments: 42 pages; corrections and additional applications to accelerated methods. To appear in Mathematical Programming",
    "descriptor": "\nComments: 42 pages; corrections and additional applications to accelerated methods. To appear in Mathematical Programming\n",
    "authors": [
      "Oran Gannot"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.13494"
  },
  {
    "id": "arXiv:2001.01283",
    "title": "One-Shot Coordination of First and Last Mode Transportation",
    "abstract": "Comments: Please contact the authors for the supplementary material",
    "descriptor": "\nComments: Please contact the authors for the supplementary material\n",
    "authors": [
      "Subhajit Goswami",
      "Pavankumar Tallapragada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2001.01283"
  },
  {
    "id": "arXiv:2001.01597",
    "title": "RBF-FD analysis of 2D time-domain acoustic wave propagation in  heterogeneous media",
    "abstract": "Comments: To reproduce the numerical tests in this paper, please see the project repository \\url{this https URL}",
    "descriptor": "\nComments: To reproduce the numerical tests in this paper, please see the project repository \\url{this https URL}\n",
    "authors": [
      "Jure Mo\u010dnik - Berljavac",
      "Pankaj K Mishra",
      "Jure Slak",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2001.01597"
  },
  {
    "id": "arXiv:2002.04282",
    "title": "Theories of real addition with and without a predicate for integers",
    "abstract": "Comments: version prepared for publication in LMCS",
    "descriptor": "\nComments: version prepared for publication in LMCS\n",
    "authors": [
      "Alexis B\u00e8s",
      "Christian Choffrut"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2002.04282"
  },
  {
    "id": "arXiv:2002.04491",
    "title": "Signature-based algorithms for Gr{\u00f6}bner bases over Tate algebras",
    "abstract": "Comments: ISSAC 2021 - International Symposium on Symbolic and Algebraic Computation, Jul 2020, Kalamata / Virtual, Greece",
    "descriptor": "\nComments: ISSAC 2021 - International Symposium on Symbolic and Algebraic Computation, Jul 2020, Kalamata / Virtual, Greece\n",
    "authors": [
      "Xavier Caruso",
      "Tristan Vaccon",
      "Thibaut Verron"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2002.04491"
  },
  {
    "id": "arXiv:2002.06887",
    "title": "Approximating Multistage Matching Problems",
    "abstract": "Comments: The definitive version will appear at IWOCA 2021",
    "descriptor": "\nComments: The definitive version will appear at IWOCA 2021\n",
    "authors": [
      "Markus Chimani",
      "Niklas Troost",
      "Tilo Wiedera"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.06887"
  },
  {
    "id": "arXiv:2002.07748",
    "title": "Profile-Guided, Multi-Version Binary Rewriting",
    "abstract": "Profile-Guided, Multi-Version Binary Rewriting",
    "descriptor": "",
    "authors": [
      "Xiaozhu Meng",
      "Buddhika Chamith",
      "Ryan Newton"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.07748"
  },
  {
    "id": "arXiv:2002.07844",
    "title": "Capacity-achieving Spatially Coupled Sparse Superposition Codes with AMP  Decoding",
    "abstract": "Comments: To appear in IEEE Transactions on Information Theory. This version contains proofs of two technical lemmas that were omitted in the journal version",
    "descriptor": "\nComments: To appear in IEEE Transactions on Information Theory. This version contains proofs of two technical lemmas that were omitted in the journal version\n",
    "authors": [
      "Cynthia Rush",
      "Kuan Hsieh",
      "Ramji Venkataramanan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2002.07844"
  },
  {
    "id": "arXiv:2002.08583",
    "title": "Regret Minimization in Stochastic Contextual Dueling Bandits",
    "abstract": "Comments: Wrong result with incremental contribution, major revision required",
    "descriptor": "\nComments: Wrong result with incremental contribution, major revision required\n",
    "authors": [
      "Aadirupa Saha",
      "Aditya Gopalan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.08583"
  },
  {
    "id": "arXiv:2002.08809",
    "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer",
    "abstract": "Comments: Accepted in International Conference on Learning Representations (ICLR) 2021 as Spotlight",
    "descriptor": "\nComments: Accepted in International Conference on Learning Representations (ICLR) 2021 as Spotlight\n",
    "authors": [
      "Guan-Horng Liu",
      "Tianrong Chen",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.08809"
  },
  {
    "id": "arXiv:2002.10710",
    "title": "End-to-end Emotion-Cause Pair Extraction via Learning to Link",
    "abstract": "Comments: 7 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 7 pages, 3 figures, 5 tables\n",
    "authors": [
      "Haolin Song",
      "Chen Zhang",
      "Qiuchi Li",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2002.10710"
  },
  {
    "id": "arXiv:2003.04529",
    "title": "Controllability Issues of Linear Ensemble Systems over Multi-dimensional  Parameterization Spaces",
    "abstract": "Controllability Issues of Linear Ensemble Systems over Multi-dimensional  Parameterization Spaces",
    "descriptor": "",
    "authors": [
      "Xudong Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2003.04529"
  },
  {
    "id": "arXiv:2003.04706",
    "title": "Communication-Efficient Distributed SGD with Error-Feedback, Revisited",
    "abstract": "Communication-Efficient Distributed SGD with Error-Feedback, Revisited",
    "descriptor": "",
    "authors": [
      "Tran Thi Phuong",
      "Le Trieu Phong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.04706"
  },
  {
    "id": "arXiv:2003.08683",
    "title": "Optimal Algorithm Allocation for Single Robot Cloud Systems",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Saeid Alirezazadeh",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.08683"
  },
  {
    "id": "arXiv:2003.09133",
    "title": "Efficient computation of backprojection arrays for 3D light field  deconvolution",
    "abstract": "Comments: 15 pages, 11 figures, 1 table. This is a thoroughly reworked version of the manuscript, with a clearer structure. It avoids any ambigiuties envoked by using the term 'transpose' in the context of multi-dimensional arrays",
    "descriptor": "\nComments: 15 pages, 11 figures, 1 table. This is a thoroughly reworked version of the manuscript, with a clearer structure. It avoids any ambigiuties envoked by using the term 'transpose' in the context of multi-dimensional arrays\n",
    "authors": [
      "Martin Eberhart"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.09133"
  },
  {
    "id": "arXiv:2003.10409",
    "title": "Online stochastic gradient descent on non-convex losses from  high-dimensional inference",
    "abstract": "Comments: final version to appear at Jour. Mach. Learn. Res$.$",
    "descriptor": "\nComments: final version to appear at Jour. Mach. Learn. Res$.$\n",
    "authors": [
      "Gerard Ben Arous",
      "Reza Gheissari",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2003.10409"
  },
  {
    "id": "arXiv:2003.13510",
    "title": "Human Motion Transfer with 3D Constraints and Detail Enhancement",
    "abstract": "Human Motion Transfer with 3D Constraints and Detail Enhancement",
    "descriptor": "",
    "authors": [
      "Yang-Tian Sun",
      "Qian-Cheng Fu",
      "Yue-Ren Jiang",
      "Zitao Liu",
      "Yu-Kun Lai",
      "Hongbo Fu",
      "Lin Gao"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2003.13510"
  },
  {
    "id": "arXiv:2003.14162",
    "title": "Deep State Space Models for Nonlinear System Identification",
    "abstract": "Deep State Space Models for Nonlinear System Identification",
    "descriptor": "",
    "authors": [
      "Daniel Gedon",
      "Niklas Wahlstr\u00f6m",
      "Thomas B. Sch\u00f6n",
      "Lennart Ljung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.14162"
  },
  {
    "id": "arXiv:2004.05566",
    "title": "Hierarchical Interpolative Factorization Preconditioner for Parabolic  Equations",
    "abstract": "Hierarchical Interpolative Factorization Preconditioner for Parabolic  Equations",
    "descriptor": "",
    "authors": [
      "Jordi Feliu-Fab\u00e0",
      "Lexing Ying"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.05566"
  },
  {
    "id": "arXiv:2004.09870",
    "title": "Rice grain disease identification using dual phase convolutional neural  network based system aimed at small dataset",
    "abstract": "Rice grain disease identification using dual phase convolutional neural  network based system aimed at small dataset",
    "descriptor": "",
    "authors": [
      "Tashin Ahmed",
      "Chowdhury Rafeed Rahman",
      "Md. Faysal Mahmud Abid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.09870"
  },
  {
    "id": "arXiv:2004.11262",
    "title": "Supervised Domain Adaptation: A Graph Embedding Perspective and a  Rectified Experimental Protocol",
    "abstract": "Comments: 13 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 13 pages, 7 figures, 5 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Omar Ali Sheikh-Omar",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.11262"
  },
  {
    "id": "arXiv:2004.14539",
    "title": "Physarum Powered Differentiable Linear Programming Layers and  Applications",
    "abstract": "Physarum Powered Differentiable Linear Programming Layers and  Applications",
    "descriptor": "",
    "authors": [
      "Zihang Meng",
      "Sathya N. Ravi",
      "Vikas Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.14539"
  },
  {
    "id": "arXiv:2004.14826",
    "title": "Wide-AdGraph: Detecting Ad Trackers with a Wide Dependency Chain Graph",
    "abstract": "Comments: 9 pages, 7 figures, To appear in the 13th ACM Web Science Conference 2021 (WebSci '21), June 2021",
    "descriptor": "\nComments: 9 pages, 7 figures, To appear in the 13th ACM Web Science Conference 2021 (WebSci '21), June 2021\n",
    "authors": [
      "Amir Hossein Kargaran",
      "Mohammad Sadegh Akhondzadeh",
      "Mohammad Reza Heidarpour",
      "Mohammad Hossein Manshaei",
      "Kave Salamatian",
      "Masoud Nejad Sattary"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.14826"
  },
  {
    "id": "arXiv:2005.00175",
    "title": "Selecting Informative Contexts Improves Language Model Finetuning",
    "abstract": "Comments: Accepted submission at the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
    "descriptor": "\nComments: Accepted submission at the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing\n",
    "authors": [
      "Richard Antonello",
      "Nicole Beckage",
      "Javier Turek",
      "Alexander Huth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2005.00175"
  },
  {
    "id": "arXiv:2005.01986",
    "title": "A Soft Robotic Cover with Dual Thermal Display and Sensing Capabilities",
    "abstract": "A Soft Robotic Cover with Dual Thermal Display and Sensing Capabilities",
    "descriptor": "",
    "authors": [
      "Yukiko Osawa",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2005.01986"
  },
  {
    "id": "arXiv:2005.05684",
    "title": "Flight Time Prediction for Fuel Loading Decisions with a Deep Learning  Approach",
    "abstract": "Flight Time Prediction for Fuel Loading Decisions with a Deep Learning  Approach",
    "descriptor": "",
    "authors": [
      "Xinting Zhu",
      "Lishuai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.05684"
  },
  {
    "id": "arXiv:2005.05744",
    "title": "Deep Learning: Our Miraculous Year 1990-1991",
    "abstract": "Comments: 26 pages, 236 references, based on work of 4 Oct 2019",
    "descriptor": "\nComments: 26 pages, 236 references, based on work of 4 Oct 2019\n",
    "authors": [
      "Juergen Schmidhuber"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2005.05744"
  },
  {
    "id": "arXiv:2005.07257",
    "title": "Optimal Cybersecurity Investments in Large Networks Using SIS Model:  Algorithm Design",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Van Sy Mai",
      "Richard J. La",
      "Abdella Battou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2005.07257"
  },
  {
    "id": "arXiv:2005.09507",
    "title": "Decidability and k-Regular Sequences",
    "abstract": "Decidability and k-Regular Sequences",
    "descriptor": "",
    "authors": [
      "Daniel Krenn",
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2005.09507"
  },
  {
    "id": "arXiv:2005.11232",
    "title": "More on zeros and approximation of the Ising partition function",
    "abstract": "Comments: Several improvements",
    "descriptor": "\nComments: Several improvements\n",
    "authors": [
      "Alexander Barvinok",
      "Nicholas Barvinok"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2005.11232"
  },
  {
    "id": "arXiv:2005.12573",
    "title": "Learning Global and Local Features of Normal Brain Anatomy for  Unsupervised Abnormality Detection",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kazuma Kobayashi",
      "Ryuichiro Hataya",
      "Yusuke Kurose",
      "Amina Bolatkan",
      "Mototaka Miyake",
      "Hirokazu Watanabe",
      "Masamichi Takahashi",
      "Jun Itami",
      "Tatsuya Harada",
      "Ryuji Hamamoto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.12573"
  },
  {
    "id": "arXiv:2005.12647",
    "title": "A Bayesian Approach for Predicting Food and Beverage Sales in Staff  Canteens and Restaurants",
    "abstract": "A Bayesian Approach for Predicting Food and Beverage Sales in Staff  Canteens and Restaurants",
    "descriptor": "",
    "authors": [
      "Konstantin Posch",
      "Christian Truden",
      "Philipp Hungerl\u00e4nder",
      "J\u00fcrgen Pilz"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2005.12647"
  },
  {
    "id": "arXiv:2005.13273",
    "title": "Selective Inference for Latent Block Models",
    "abstract": "Selective Inference for Latent Block Models",
    "descriptor": "",
    "authors": [
      "Chihiro Watanabe",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.13273"
  },
  {
    "id": "arXiv:2005.13407",
    "title": "CausaLM: Causal Model Explanation Through Counterfactual Language Models",
    "abstract": "Comments: Our code and data are available at: this https URL Accepted for publication in Computational Linguistics journal",
    "descriptor": "\nComments: Our code and data are available at: this https URL Accepted for publication in Computational Linguistics journal\n",
    "authors": [
      "Amir Feder",
      "Nadav Oved",
      "Uri Shalit",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.13407"
  },
  {
    "id": "arXiv:2006.00101",
    "title": "A Novel Reliability-based Robust Design Multi-objective Optimization  Formulation Applied in Chemical Engineering",
    "abstract": "A Novel Reliability-based Robust Design Multi-objective Optimization  Formulation Applied in Chemical Engineering",
    "descriptor": "",
    "authors": [
      "Gustavo Barbosa Libotte",
      "Fran S\u00e9rgio Lobato",
      "Francisco Duarte Moura Neto",
      "Gustavo Mendes Platt"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.00101"
  },
  {
    "id": "arXiv:2006.02371",
    "title": "How Gamification Affects Software Developers: Cautionary Evidence from a  Natural Experiment on GitHub",
    "abstract": "Comments: To appear in the proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
    "descriptor": "\nComments: To appear in the proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)\n",
    "authors": [
      "Lukas Moldon",
      "Markus Strohmaier",
      "Johannes Wachs"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.02371"
  },
  {
    "id": "arXiv:2006.03196",
    "title": "Towards Better Driver Safety: Empowering Personal Navigation  Technologies with Road Safety Awareness",
    "abstract": "Comments: Submitted to IEEE Intelligent Transportation System Magazine",
    "descriptor": "\nComments: Submitted to IEEE Intelligent Transportation System Magazine\n",
    "authors": [
      "Runsheng Xu",
      "Shibo Zhang",
      "Yue Zhao",
      "Peixi Xiong",
      "Allen Yilun Lin",
      "Brent Hecht",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2006.03196"
  },
  {
    "id": "arXiv:2006.07584",
    "title": "Mean-Field Approximation to Gaussian-Softmax Integral with Application  to Uncertainty Estimation",
    "abstract": "Mean-Field Approximation to Gaussian-Softmax Integral with Application  to Uncertainty Estimation",
    "descriptor": "",
    "authors": [
      "Zhiyun Lu",
      "Eugene Ie",
      "Fei Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07584"
  },
  {
    "id": "arXiv:2006.09264",
    "title": "Bonsai-Net: One-Shot Neural Architecture Search via Differentiable  Pruners",
    "abstract": "Comments: Accepted to CVPR-NAS 2020. this https URL",
    "descriptor": "\nComments: Accepted to CVPR-NAS 2020. this https URL\n",
    "authors": [
      "Rob Geada",
      "Dennis Prangle",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09264"
  },
  {
    "id": "arXiv:2006.09534",
    "title": "Towards improving discriminative reconstruction via simultaneous dense  and sparse coding",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Abiy Tasissa",
      "Emmanouil Theodosis",
      "Bahareh Tolooshams",
      "Demba Ba"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2006.09534"
  },
  {
    "id": "arXiv:2006.10371",
    "title": "Conformal Moduli of Symmetric Circular Quadrilaterals With Cusps",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Harri Hakula",
      "Semen Nasyrov",
      "Matti Vuorinen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.10371"
  },
  {
    "id": "arXiv:2006.11183",
    "title": "Evaluation Of Hidden Markov Models Using Deep CNN Features In Isolated  Sign Recognition",
    "abstract": "Comments: This paper is the preprint of the accepted manuscript at Multimedia Tools and Applications Journal. It contains 16 pages, 5 figure, 8 tables",
    "descriptor": "\nComments: This paper is the preprint of the accepted manuscript at Multimedia Tools and Applications Journal. It contains 16 pages, 5 figure, 8 tables\n",
    "authors": [
      "Anil Osman Tur",
      "Hacer Yalim Keles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.11183"
  },
  {
    "id": "arXiv:2006.14201",
    "title": "Convex Incremental Dissipativity Analysis of Nonlinear Systems",
    "abstract": "Comments: Extended version; Original version (without Appendix B) submitted to Automatica. Changes: Proof of Theorem 6",
    "descriptor": "\nComments: Extended version; Original version (without Appendix B) submitted to Automatica. Changes: Proof of Theorem 6\n",
    "authors": [
      "Chris Verhoek",
      "Patrick J. W. Koelewijn",
      "Roland T\u00f3th",
      "Sofie Haesaert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.14201"
  },
  {
    "id": "arXiv:2006.14312",
    "title": "New Approximations and Hardness Results for Submodular Partitioning  Problems",
    "abstract": "New Approximations and Hardness Results for Submodular Partitioning  Problems",
    "descriptor": "",
    "authors": [
      "Richard Santiago"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.14312"
  },
  {
    "id": "arXiv:2006.15673",
    "title": "Differential Privacy of Hierarchical Census Data: An Optimization  Approach",
    "abstract": "Comments: Corrected a claim in the Introduction and a typo in Model 1",
    "descriptor": "\nComments: Corrected a claim in the Introduction and a typo in Model 1\n",
    "authors": [
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck",
      "Keyu Zhu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.15673"
  },
  {
    "id": "arXiv:2007.00840",
    "title": "GSoFa: Scalable Sparse Symbolic LU Factorization on GPUs",
    "abstract": "GSoFa: Scalable Sparse Symbolic LU Factorization on GPUs",
    "descriptor": "",
    "authors": [
      "Anil Gaihre",
      "Xiaoye S. Li",
      "Hang Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2007.00840"
  },
  {
    "id": "arXiv:2007.01409",
    "title": "A (Slightly) Improved Approximation Algorithm for Metric TSP",
    "abstract": "A (Slightly) Improved Approximation Algorithm for Metric TSP",
    "descriptor": "",
    "authors": [
      "Anna R. Karlin",
      "Nathan Klein",
      "Shayan Oveis Gharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2007.01409"
  },
  {
    "id": "arXiv:2007.01682",
    "title": "Improving auto-encoder novelty detection using channel attention and  entropy minimization",
    "abstract": "Improving auto-encoder novelty detection using channel attention and  entropy minimization",
    "descriptor": "",
    "authors": [
      "Miao Tian",
      "Dongyan Guo",
      "Ying Cui",
      "Xiang Pan",
      "Shengyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.01682"
  },
  {
    "id": "arXiv:2007.03273",
    "title": "Coded Computing for Federated Learning at the Edge",
    "abstract": "Comments: Work accepted for presentation at the International Workshop on Federated Learning for User Privacy and Data Confidentiality, in Conjunction with ICML 2020 (FL-ICML'20). This work was part of Saurav Prakash's internship projects at Intel. arXiv admin note: text overlap with arXiv:2011.06223",
    "descriptor": "\nComments: Work accepted for presentation at the International Workshop on Federated Learning for User Privacy and Data Confidentiality, in Conjunction with ICML 2020 (FL-ICML'20). This work was part of Saurav Prakash's internship projects at Intel. arXiv admin note: text overlap with arXiv:2011.06223\n",
    "authors": [
      "Saurav Prakash",
      "Sagar Dhakal",
      "Mustafa Akdeniz",
      "A. Salman Avestimehr",
      "Nageen Himayat"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03273"
  },
  {
    "id": "arXiv:2007.04626",
    "title": "DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and  Affective Labels",
    "abstract": "Comments: 24 pages, 3 figures, 17 tables",
    "descriptor": "\nComments: 24 pages, 3 figures, 17 tables\n",
    "authors": [
      "Alberto Barbado",
      "V\u00edctor Fresno",
      "\u00c1ngeles Manjarr\u00e9s Riesco",
      "Salvador Ros"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.04626"
  },
  {
    "id": "arXiv:2007.07356",
    "title": "Efficient Empowerment Estimation for Unsupervised Stabilization",
    "abstract": "Efficient Empowerment Estimation for Unsupervised Stabilization",
    "descriptor": "",
    "authors": [
      "Ruihan Zhao",
      "Kevin Lu",
      "Pieter Abbeel",
      "Stas Tiomkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2007.07356"
  },
  {
    "id": "arXiv:2007.08068",
    "title": "The Swendsen-Wang Dynamics on Trees",
    "abstract": "The Swendsen-Wang Dynamics on Trees",
    "descriptor": "",
    "authors": [
      "Antonio Blanca",
      "Zongchen Chen",
      "Daniel \u0160tefankovi\u010d",
      "Eric Vigoda"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.08068"
  },
  {
    "id": "arXiv:2007.10284",
    "title": "Learning High-Level Policies for Model Predictive Control",
    "abstract": "Comments: Accepted for Publication at the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    "descriptor": "\nComments: Accepted for Publication at the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Yunlong Song",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.10284"
  },
  {
    "id": "arXiv:2007.11193",
    "title": "Numerical solution of a one-dimensional nonlocal Helmholtz equation by  Perfectly Matched Layers",
    "abstract": "Comments: 22 pages, 7 figures",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Yu Du",
      "Jiwei Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.11193"
  },
  {
    "id": "arXiv:2007.12652",
    "title": "MurTree: Optimal Classification Trees via Dynamic Programming and Search",
    "abstract": "MurTree: Optimal Classification Trees via Dynamic Programming and Search",
    "descriptor": "",
    "authors": [
      "Emir Demirovi\u0107",
      "Anna Lukina",
      "Emmanuel Hebrard",
      "Jeffrey Chan",
      "James Bailey",
      "Christopher Leckie",
      "Kotagiri Ramamohanarao",
      "Peter J. Stuckey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.12652"
  },
  {
    "id": "arXiv:2007.15620",
    "title": "Neural Modeling for Named Entities and Morphology (NEMO^2)",
    "abstract": "Comments: Accepted to TACL. This is a pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to TACL. This is a pre-MIT Press publication version\n",
    "authors": [
      "Dan Bareket",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.15620"
  },
  {
    "id": "arXiv:2008.00051",
    "title": "On the Convergence of SGD with Biased Gradients",
    "abstract": "Comments: Accepted to ICML 2020 Workshop \"Beyond First Order Methods in ML Systems\", updated 2021",
    "descriptor": "\nComments: Accepted to ICML 2020 Workshop \"Beyond First Order Methods in ML Systems\", updated 2021\n",
    "authors": [
      "Ahmad Ajalloeian",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.00051"
  },
  {
    "id": "arXiv:2008.04601",
    "title": "Improving Blockchain scalability based on one-time cross-chain contract  and gossip network",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Keyang Liu",
      "Yukio Ohsawa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2008.04601"
  },
  {
    "id": "arXiv:2008.07971",
    "title": "Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement  Learning",
    "abstract": "Comments: Accepted for Publication at the IEEE Robotics and Automation Letters (RA-L) 2021, and International Conference on Robots and Automation (ICRA) 2021",
    "descriptor": "\nComments: Accepted for Publication at the IEEE Robotics and Automation Letters (RA-L) 2021, and International Conference on Robots and Automation (ICRA) 2021\n",
    "authors": [
      "Florian Fuchs",
      "Yunlong Song",
      "Elia Kaufmann",
      "Davide Scaramuzza",
      "Peter Duerr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.07971"
  },
  {
    "id": "arXiv:2008.09682",
    "title": "DwarvesGraph: A High-Performance Graph Mining System with Pattern  Decomposition",
    "abstract": "DwarvesGraph: A High-Performance Graph Mining System with Pattern  Decomposition",
    "descriptor": "",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2008.09682"
  },
  {
    "id": "arXiv:2008.11401",
    "title": "Point Adversarial Self Mining: A Simple Method for Facial Expression  Recognition",
    "abstract": "Point Adversarial Self Mining: A Simple Method for Facial Expression  Recognition",
    "descriptor": "",
    "authors": [
      "Ping Liu",
      "Yuewei Lin",
      "Zibo Meng",
      "Lu Lu",
      "Weihong Deng",
      "Joey Tianyi Zhou",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.11401"
  },
  {
    "id": "arXiv:2008.11589",
    "title": "Learned Transferable Architectures Can Surpass Hand-Designed  Architectures for Large Scale Speech Recognition",
    "abstract": "Comments: Accepted to ICASSP 2021",
    "descriptor": "\nComments: Accepted to ICASSP 2021\n",
    "authors": [
      "Liqiang He",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2008.11589"
  },
  {
    "id": "arXiv:2008.11868",
    "title": "BumbleBee: Application-aware adaptation for container orchestration",
    "abstract": "Comments: This version fixes problems (e.g., with the video-streaming experiments) from the previous versions",
    "descriptor": "\nComments: This version fixes problems (e.g., with the video-streaming experiments) from the previous versions\n",
    "authors": [
      "HyunJong Lee",
      "Shadi Noghabi",
      "Brian Noble",
      "Matthew Furlong",
      "Landon P. Cox"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2008.11868"
  },
  {
    "id": "arXiv:2008.12199",
    "title": "Privacy Intelligence: A Survey on Image Privacy in Online Social  Networks",
    "abstract": "Comments: 32 pages, 9 figures. Under review",
    "descriptor": "\nComments: 32 pages, 9 figures. Under review\n",
    "authors": [
      "Chi Liu",
      "Tianqing Zhu",
      "Jun Zhang",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2008.12199"
  },
  {
    "id": "arXiv:2008.12226",
    "title": "The complexity of L(p,q)-Edge-Labelling",
    "abstract": "The complexity of L(p,q)-Edge-Labelling",
    "descriptor": "",
    "authors": [
      "Gaetan Berthe",
      "Barnaby Martin",
      "Daniel Paulusma",
      "Siani Smith"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.12226"
  },
  {
    "id": "arXiv:2008.12328",
    "title": "A Background-Agnostic Framework with Adversarial Training for Abnormal  Event Detection in Video",
    "abstract": "Comments: Accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Marius Popescu",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.12328"
  },
  {
    "id": "arXiv:2009.00544",
    "title": "High-Resolution Poverty Maps in Sub-Saharan Africa",
    "abstract": "Comments: Changed an author's affiliation, updated the narrowing method for DHS clusters leading to slight changes to all validation results",
    "descriptor": "\nComments: Changed an author's affiliation, updated the narrowing method for DHS clusters leading to slight changes to all validation results\n",
    "authors": [
      "Kamwoo Lee",
      "Jeanine Braithwaite"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2009.00544"
  },
  {
    "id": "arXiv:2009.00563",
    "title": "Flightmare: A Flexible Quadrotor Simulator",
    "abstract": "Comments: Accepted for publication at 4th Conference on Robot Learning (CoRL), Cambridge MA, USA. 2020",
    "descriptor": "\nComments: Accepted for publication at 4th Conference on Robot Learning (CoRL), Cambridge MA, USA. 2020\n",
    "authors": [
      "Yunlong Song",
      "Selim Naji",
      "Elia Kaufmann",
      "Antonio Loquercio",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.00563"
  },
  {
    "id": "arXiv:2009.02276",
    "title": "Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching",
    "abstract": "Comments: First two authors contributed equally. Last two authors contributed equally. 21 pages, 11 figures. Published at ICLR 2021",
    "descriptor": "\nComments: First two authors contributed equally. Last two authors contributed equally. 21 pages, 11 figures. Published at ICLR 2021\n",
    "authors": [
      "Jonas Geiping",
      "Liam Fowl",
      "W. Ronny Huang",
      "Wojciech Czaja",
      "Gavin Taylor",
      "Michael Moeller",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.02276"
  },
  {
    "id": "arXiv:2009.03831",
    "title": "Refined approachability algorithms and application to regret  minimization with global costs",
    "abstract": "Refined approachability algorithms and application to regret  minimization with global costs",
    "descriptor": "",
    "authors": [
      "Joon Kwon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03831"
  },
  {
    "id": "arXiv:2009.04960",
    "title": "Prototype Completion with Primitive Knowledge for Few-Shot Learning",
    "abstract": "Comments: Accepted by CVPR2021",
    "descriptor": "\nComments: Accepted by CVPR2021\n",
    "authors": [
      "Baoquan Zhang",
      "Xutao Li",
      "Yunming Ye",
      "Zhichao Huang",
      "Lisai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.04960"
  },
  {
    "id": "arXiv:2009.05739",
    "title": "Revisiting Factorizing Aggregated Posterior in Learning Disentangled  Representations",
    "abstract": "Revisiting Factorizing Aggregated Posterior in Learning Disentangled  Representations",
    "descriptor": "",
    "authors": [
      "Ze Cheng",
      "Juncheng Li",
      "Chenxu Wang",
      "Jixuan Gu",
      "Hao Xu",
      "Xinjian Li",
      "Florian Metze"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.05739"
  },
  {
    "id": "arXiv:2009.06370",
    "title": "Transparency and granularity in the SP Theory of Intelligence and its  realisation in the SP Computer Model",
    "abstract": "Comments: Published in the book {\\em Interpretable Artificial Intelligence: A Perspective of Granular Computing}, Witold Pedrycz and Shyi-Ming Chen (editors), Springer: Heidelberg, 2021, ISBN 978-3-030-64948-7, DOI: 10.1007/978-3-030-64949-4",
    "descriptor": "\nComments: Published in the book {\\em Interpretable Artificial Intelligence: A Perspective of Granular Computing}, Witold Pedrycz and Shyi-Ming Chen (editors), Springer: Heidelberg, 2021, ISBN 978-3-030-64948-7, DOI: 10.1007/978-3-030-64949-4\n",
    "authors": [
      "J Gerard Wolff"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.06370"
  },
  {
    "id": "arXiv:2009.06693",
    "title": "NextDoor: GPU-Based Graph Sampling for Graph Machine Learning",
    "abstract": "Comments: Published in EuroSys 2021",
    "descriptor": "\nComments: Published in EuroSys 2021\n",
    "authors": [
      "Abhinav Jangda",
      "Sandeep Polisetty",
      "Arjun Guha",
      "Marco Serafini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.06693"
  },
  {
    "id": "arXiv:2009.08295",
    "title": "Neural Rough Differential Equations for Long Time Series",
    "abstract": "Comments: Published at ICML 2021",
    "descriptor": "\nComments: Published at ICML 2021\n",
    "authors": [
      "James Morrill",
      "Cristopher Salvi",
      "Patrick Kidger",
      "James Foster",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08295"
  },
  {
    "id": "arXiv:2009.09215",
    "title": "Faster Smarter Induction in Isabelle/HOL",
    "abstract": "Comments: This is the preprint of our paper of the same title, which is accepted to IJCAI2021. For the formal proceeding, please refer to the IJCAI2021 website",
    "descriptor": "\nComments: This is the preprint of our paper of the same title, which is accepted to IJCAI2021. For the formal proceeding, please refer to the IJCAI2021 website\n",
    "authors": [
      "Yutaka Nagashima"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.09215"
  },
  {
    "id": "arXiv:2009.09457",
    "title": "\"Hey, that's not an ODE\": Faster ODE Adjoints via Seminorms",
    "abstract": "Comments: Published at ICML 2021",
    "descriptor": "\nComments: Published at ICML 2021\n",
    "authors": [
      "Patrick Kidger",
      "Ricky T. Q. Chen",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2009.09457"
  },
  {
    "id": "arXiv:2009.09683",
    "title": "Computing the Rate-Distortion Function of Gray-Wyner System",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Guojun Chen",
      "Yinfei Xu",
      "Tiecheng Song",
      "Xi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.09683"
  },
  {
    "id": "arXiv:2009.10550",
    "title": "URLLC with Massive MIMO: Analysis and Design at Finite Blocklength",
    "abstract": "Comments: 15 pages, 5 figures; to appear in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 15 pages, 5 figures; to appear in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Johan \u00d6stman",
      "Alejandro Lancho",
      "Giuseppe Durisi",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2009.10550"
  },
  {
    "id": "arXiv:2009.10685",
    "title": "Tensor Programs III: Neural Matrix Laws",
    "abstract": "Tensor Programs III: Neural Matrix Laws",
    "descriptor": "",
    "authors": [
      "Greg Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2009.10685"
  },
  {
    "id": "arXiv:2009.13326",
    "title": "Database Assisted Nonlinear Least Squares Algorithm for Visible Light  Positioning in NLOS Environments",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Ahmet Faruk Saz",
      "Sinan Gezici"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.13326"
  },
  {
    "id": "arXiv:2009.13405",
    "title": "Adaptive Sampling for Best Policy Identification in Markov Decision  Processes",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Aymen Al Marjani",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.13405"
  },
  {
    "id": "arXiv:2009.13504",
    "title": "Information Obfuscation of Graph Neural Networks",
    "abstract": "Comments: ICML 2021; Code is available at this https URL",
    "descriptor": "\nComments: ICML 2021; Code is available at this https URL\n",
    "authors": [
      "Peiyuan Liao",
      "Han Zhao",
      "Keyulu Xu",
      "Tommi Jaakkola",
      "Geoffrey Gordon",
      "Stefanie Jegelka",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13504"
  },
  {
    "id": "arXiv:2009.13714",
    "title": "Learned Fine-Tuner for Incongruous Few-Shot Adversarial Learning",
    "abstract": "Learned Fine-Tuner for Incongruous Few-Shot Adversarial Learning",
    "descriptor": "",
    "authors": [
      "Pu Zhao",
      "Sijia Liu",
      "Parikshit Ram",
      "Songtao Lu",
      "Yuguang Yao",
      "Djallel Bouneffouf",
      "Xue Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13714"
  },
  {
    "id": "arXiv:2009.13721",
    "title": "A Comprehensive Review for MRF and CRF Approaches in Pathology Image  Analysis",
    "abstract": "Comments: Arch Computat Methods Eng (2021)",
    "descriptor": "\nComments: Arch Computat Methods Eng (2021)\n",
    "authors": [
      "Yixin Li",
      "Chen Li",
      "Xiaoyan Li",
      "Kai Wang",
      "Md Mamunur Rahaman",
      "Changhao Sun",
      "Hao Chen",
      "Xinran Wu",
      "Hong Zhang",
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.13721"
  },
  {
    "id": "arXiv:2009.13724",
    "title": "One Person, One Model, One World: Learning Continual User Representation  without Forgetting",
    "abstract": "One Person, One Model, One World: Learning Continual User Representation  without Forgetting",
    "descriptor": "",
    "authors": [
      "Fajie Yuan",
      "Guoxiao Zhang",
      "Alexandros Karatzoglou",
      "Joemon Jose",
      "Beibei Kong",
      "Yudong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2009.13724"
  },
  {
    "id": "arXiv:2010.00179",
    "title": "System Design and Analysis for Energy-Efficient Passive UAV Radar  Imaging System using Illuminators of Opportunity",
    "abstract": "System Design and Analysis for Energy-Efficient Passive UAV Radar  Imaging System using Illuminators of Opportunity",
    "descriptor": "",
    "authors": [
      "Zhichao Sun",
      "Junjie Wu",
      "Gary G. Yen",
      "Hang Ren",
      "Hongyang An",
      "Jianyu Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.00179"
  },
  {
    "id": "arXiv:2010.02147",
    "title": "Diversity/Parallelism Trade-off in Distributed Systems with Redundancy",
    "abstract": "Comments: Described several open problems and outlined future directions, added references, corrected typos",
    "descriptor": "\nComments: Described several open problems and outlined future directions, added references, corrected typos\n",
    "authors": [
      "Pei Peng",
      "Emina Soljanin",
      "Philip Whiting"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2010.02147"
  },
  {
    "id": "arXiv:2010.03060",
    "title": "Contrastive Cross-Modal Pre-Training: A General Strategy for Small  Sample Medical Imaging",
    "abstract": "Comments: This work is under review with the IEEE Journal of Biomedical and Health Informatics",
    "descriptor": "\nComments: This work is under review with the IEEE Journal of Biomedical and Health Informatics\n",
    "authors": [
      "Gongbo Liang",
      "Connor Greenwell",
      "Yu Zhang",
      "Xiaoqin Wang",
      "Ramakanth Kavuluru",
      "Nathan Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.03060"
  },
  {
    "id": "arXiv:2010.04953",
    "title": "A Reduced Order Cut Finite Element method for geometrically  parameterized steady and unsteady Navier-Stokes problems",
    "abstract": "A Reduced Order Cut Finite Element method for geometrically  parameterized steady and unsteady Navier-Stokes problems",
    "descriptor": "",
    "authors": [
      "Efthymios N. Karatzas",
      "Monica Nonino",
      "Francesco Ballarin",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.04953"
  },
  {
    "id": "arXiv:2010.05687",
    "title": "Semantic Change Detection with Asymmetric Siamese Networks",
    "abstract": "Semantic Change Detection with Asymmetric Siamese Networks",
    "descriptor": "",
    "authors": [
      "Kunping Yang",
      "Gui-Song Xia",
      "Zicheng Liu",
      "Bo Du",
      "Wen Yang",
      "Marcello Pelillo",
      "Liangpei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.05687"
  },
  {
    "id": "arXiv:2010.06975",
    "title": "Medical Code Assignment with Gated Convolution and Note-Code Interaction",
    "abstract": "Comments: Findings of ACL-IJCNLP 2021",
    "descriptor": "\nComments: Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Shaoxiong Ji",
      "Shirui Pan",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.06975"
  },
  {
    "id": "arXiv:2010.07611",
    "title": "Layer-adaptive sparsity for the Magnitude-based Pruning",
    "abstract": "Comments: ICLR 2021. Changed title (previous ver: A deeper look at the layerwise sparsity of magnitude-based pruning)",
    "descriptor": "\nComments: ICLR 2021. Changed title (previous ver: A deeper look at the layerwise sparsity of magnitude-based pruning)\n",
    "authors": [
      "Jaeho Lee",
      "Sejun Park",
      "Sangwoo Mo",
      "Sungsoo Ahn",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07611"
  },
  {
    "id": "arXiv:2010.09231",
    "title": "CT-CPP: 3D Coverage Path Planning for Unknown Terrain Reconstruction  using Coverage Trees",
    "abstract": "CT-CPP: 3D Coverage Path Planning for Unknown Terrain Reconstruction  using Coverage Trees",
    "descriptor": "",
    "authors": [
      "Zongyuan Shen",
      "Junnan Song",
      "Khushboo Mittal",
      "Shalabh Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.09231"
  },
  {
    "id": "arXiv:2010.09904",
    "title": "Robust & Asymptotically Locally Optimal UAV-Trajectory Generation Based  on Spline Subdivision",
    "abstract": "Robust & Asymptotically Locally Optimal UAV-Trajectory Generation Based  on Spline Subdivision",
    "descriptor": "",
    "authors": [
      "Ruiqi Ni",
      "Teseo Schneider",
      "Daniele Panozzo",
      "Zherong Pan",
      "Xifeng Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.09904"
  },
  {
    "id": "arXiv:2010.10059",
    "title": "Very Fast Streaming Submodular Function Maximization",
    "abstract": "Comments: 9 pages, 14 pages appendix, 5 figures, 2 tables, 10 algorithms",
    "descriptor": "\nComments: 9 pages, 14 pages appendix, 5 figures, 2 tables, 10 algorithms\n",
    "authors": [
      "Sebastian Buschj\u00e4ger",
      "Philipp-Jan Honysz",
      "Lukas Pfahler",
      "Katharina Morik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.10059"
  },
  {
    "id": "arXiv:2010.10507",
    "title": "Superconvergence of Discontinuous Galerkin methods for Elliptic Boundary  Value Problems",
    "abstract": "Superconvergence of Discontinuous Galerkin methods for Elliptic Boundary  Value Problems",
    "descriptor": "",
    "authors": [
      "Limin Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.10507"
  },
  {
    "id": "arXiv:2010.10855",
    "title": "Ultimate Limits of Thermal Pattern Recognition",
    "abstract": "Comments: 15 pages, 7 figures. Close to published version",
    "descriptor": "\nComments: 15 pages, 7 figures. Close to published version\n",
    "authors": [
      "Cillian Harney",
      "Leonardo Banchi",
      "Stefano Pirandola"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2010.10855"
  },
  {
    "id": "arXiv:2010.11483",
    "title": "Multilingual Approach to Joint Speech and Accent Recognition with  DNN-HMM Framework",
    "abstract": "Comments: 5 pages, Conference",
    "descriptor": "\nComments: 5 pages, Conference\n",
    "authors": [
      "Yizhou Peng",
      "Jicheng Zhang",
      "Haobo Zhang",
      "Haihua Xu",
      "Hao Huang",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2010.11483"
  },
  {
    "id": "arXiv:2010.11751",
    "title": "Cross-platform programming model for many-core lattice Boltzmann  simulations",
    "abstract": "Comments: The STLBM library is available at this https URL (see the tag \"benchmarks_plosone\" to reproduce data published in this paper)",
    "descriptor": "\nComments: The STLBM library is available at this https URL (see the tag \"benchmarks_plosone\" to reproduce data published in this paper)\n",
    "authors": [
      "Jonas Latt",
      "Christophe Coreixas",
      "Jo\u00ebl Beny"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.11751"
  },
  {
    "id": "arXiv:2010.12146",
    "title": "Reliable Over-the-Air Computation by Amplify-and-Forward Based Relay",
    "abstract": "Reliable Over-the-Air Computation by Amplify-and-Forward Based Relay",
    "descriptor": "",
    "authors": [
      "Suhua Tang",
      "Huarui Yin",
      "Chao Zhang",
      "Sadao Obana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.12146"
  },
  {
    "id": "arXiv:2010.12167",
    "title": "Approximation Theory Based Methods for RKHS Bandits",
    "abstract": "Approximation Theory Based Methods for RKHS Bandits",
    "descriptor": "",
    "authors": [
      "Sho Takemori",
      "Masahiro Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.12167"
  },
  {
    "id": "arXiv:2010.12605",
    "title": "Using machine learning to correct model error in data assimilation and  forecast applications",
    "abstract": "Using machine learning to correct model error in data assimilation and  forecast applications",
    "descriptor": "",
    "authors": [
      "Alban Farchi",
      "Patrick Laloyaux",
      "Massimo Bonavita",
      "Marc Bocquet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2010.12605"
  },
  {
    "id": "arXiv:2010.12753",
    "title": "Temporal Reasoning on Implicit Events from Distant Supervision",
    "abstract": "Comments: Accepted at NAACL 2021",
    "descriptor": "\nComments: Accepted at NAACL 2021\n",
    "authors": [
      "Ben Zhou",
      "Kyle Richardson",
      "Qiang Ning",
      "Tushar Khot",
      "Ashish Sabharwal",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12753"
  },
  {
    "id": "arXiv:2010.12787",
    "title": "Document-level Event Extraction with Efficient End-to-end Learning of  Cross-event Dependencies",
    "abstract": "Comments: To appear at NAACL 2021 WNU workshop",
    "descriptor": "\nComments: To appear at NAACL 2021 WNU workshop\n",
    "authors": [
      "Kung-Hsiang Huang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12787"
  },
  {
    "id": "arXiv:2010.13559",
    "title": "Multi-Slot Over-The-Air Computation in Fading Channels",
    "abstract": "Multi-Slot Over-The-Air Computation in Fading Channels",
    "descriptor": "",
    "authors": [
      "Suhua Tang",
      "Petar Popovski",
      "Chao Zhang",
      "Sadao Obana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2010.13559"
  },
  {
    "id": "arXiv:2010.14289",
    "title": "Affordance as general value function: A computational model",
    "abstract": "Affordance as general value function: A computational model",
    "descriptor": "",
    "authors": [
      "Daniel Graves",
      "Johannes G\u00fcnther",
      "Jun Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.14289"
  },
  {
    "id": "arXiv:2011.00827",
    "title": "Rounding Error Analysis of Linear Recurrences Using Generating Series",
    "abstract": "Rounding Error Analysis of Linear Recurrences Using Generating Series",
    "descriptor": "",
    "authors": [
      "Marc Mezzarobba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2011.00827"
  },
  {
    "id": "arXiv:2011.05308",
    "title": "EPSR: Edge Profile Super resolution",
    "abstract": "EPSR: Edge Profile Super resolution",
    "descriptor": "",
    "authors": [
      "Jiun Lee",
      "Jaekwang Kim",
      "Inyong Yun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.05308"
  },
  {
    "id": "arXiv:2011.06220",
    "title": "Artificial Neural Variability for Deep Learning: On Overfitting, Noise  Memorization, and Catastrophic Forgetting",
    "abstract": "Comments: Accepted by Neural Computation, MIT Press;20 pages; 13 figures; Key Words: Neural Variability, Neuroscience, Deep Learning, Label Noise, Catastrophic Forgetting",
    "descriptor": "\nComments: Accepted by Neural Computation, MIT Press;20 pages; 13 figures; Key Words: Neural Variability, Neuroscience, Deep Learning, Label Noise, Catastrophic Forgetting\n",
    "authors": [
      "Zeke Xie",
      "Fengxiang He",
      "Shaopeng Fu",
      "Issei Sato",
      "Dacheng Tao",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06220"
  },
  {
    "id": "arXiv:2011.06223",
    "title": "Coded Computing for Low-Latency Federated Learning over Wireless Edge  Networks",
    "abstract": "Comments: Final version to appear in the first issue of the IEEE JSAC Series on Machine Learning for Communications and Networks",
    "descriptor": "\nComments: Final version to appear in the first issue of the IEEE JSAC Series on Machine Learning for Communications and Networks\n",
    "authors": [
      "Saurav Prakash",
      "Sagar Dhakal",
      "Mustafa Akdeniz",
      "Yair Yona",
      "Shilpa Talwar",
      "Salman Avestimehr",
      "Nageen Himayat"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.06223"
  },
  {
    "id": "arXiv:2011.06531",
    "title": "Image analysis for Alzheimer's disease prediction: Embracing  pathological hallmarks for model architecture design",
    "abstract": "Comments: 8 pages, 1 figure, Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract",
    "descriptor": "\nComments: 8 pages, 1 figure, Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract\n",
    "authors": [
      "Sarah C. Br\u00fcningk",
      "Felix Hensel",
      "Catherine R. Jutzeler",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.06531"
  },
  {
    "id": "arXiv:2011.07466",
    "title": "Continuous Conditional Generative Adversarial Networks for Image  Generation: Novel Losses and Label Input Mechanisms",
    "abstract": "Continuous Conditional Generative Adversarial Networks for Image  Generation: Novel Losses and Label Input Mechanisms",
    "descriptor": "",
    "authors": [
      "Xin Ding",
      "Yongwei Wang",
      "Zuheng Xu",
      "William J. Welch",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.07466"
  },
  {
    "id": "arXiv:2011.08067",
    "title": "Hierarchical Transformer for Task Oriented Dialog Systems",
    "abstract": "Comments: v3: Latest camera ready version; 10 pages; Codes: this https URL , this https URL v2: To appear in NAACL 2021 (Long Paper) v1: preprint",
    "descriptor": "\nComments: v3: Latest camera ready version; 10 pages; Codes: this https URL , this https URL v2: To appear in NAACL 2021 (Long Paper) v1: preprint\n",
    "authors": [
      "Bishal Santra",
      "Potnuru Anusha",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.08067"
  },
  {
    "id": "arXiv:2011.08756",
    "title": "Stochastic Client Selection for Federated Learning with Volatile Clients",
    "abstract": "Comments: 20 pages, 7 figures. Under review by IEEE Internet of Things Journal",
    "descriptor": "\nComments: 20 pages, 7 figures. Under review by IEEE Internet of Things Journal\n",
    "authors": [
      "Tiansheng Huang",
      "Weiwei Lin",
      "Li Shen",
      "Keqin Li",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.08756"
  },
  {
    "id": "arXiv:2011.09588",
    "title": "Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty  Quantification",
    "abstract": "Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty  Quantification",
    "descriptor": "",
    "authors": [
      "Youngseog Chung",
      "Willie Neiswanger",
      "Ian Char",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.09588"
  },
  {
    "id": "arXiv:2011.09670",
    "title": "Dense Label Encoding for Boundary Discontinuity Free Rotation Detection",
    "abstract": "Comments: 12 pages, 6 figures, 8 tables, accepted by CVPR21",
    "descriptor": "\nComments: 12 pages, 6 figures, 8 tables, accepted by CVPR21\n",
    "authors": [
      "Xue Yang",
      "Liping Hou",
      "Yue Zhou",
      "Wentao Wang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.09670"
  },
  {
    "id": "arXiv:2011.09810",
    "title": "Continuous calibration of a digital twin: comparison of particle filter  and Bayesian calibration approaches",
    "abstract": "Comments: 23 pages, 19 figures",
    "descriptor": "\nComments: 23 pages, 19 figures\n",
    "authors": [
      "Rebecca Ward",
      "Ruchi Choudhary",
      "Alastair Gregory",
      "Melanie Jans-Singh",
      "Mark Girolami"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2011.09810"
  },
  {
    "id": "arXiv:2011.10704",
    "title": "Neural Group Testing to Accelerate Deep Learning",
    "abstract": "Comments: ISIT 2021. Code & data available at this https URL",
    "descriptor": "\nComments: ISIT 2021. Code & data available at this https URL\n",
    "authors": [
      "Weixin Liang",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.10704"
  },
  {
    "id": "arXiv:2011.11128",
    "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions on Cognitive and Developmental Systems",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Cognitive and Developmental Systems\n",
    "authors": [
      "Shu Gong",
      "Kaibo Xing",
      "Andrzej Cichocki",
      "Junhua Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2011.11128"
  },
  {
    "id": "arXiv:2011.11483",
    "title": "Social Determinants of Recidivism: A Machine Learning Solution",
    "abstract": "Comments: 12 main pages, 5 appendix pages, 12 tables",
    "descriptor": "\nComments: 12 main pages, 5 appendix pages, 12 tables\n",
    "authors": [
      "Vik Shirvaikar",
      "Choudur Lakshminarayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.11483"
  },
  {
    "id": "arXiv:2011.14458",
    "title": "Hybrid Imitation Learning for Real-Time Service Restoration in Resilient  Distribution Systems",
    "abstract": "Hybrid Imitation Learning for Real-Time Service Restoration in Resilient  Distribution Systems",
    "descriptor": "",
    "authors": [
      "Yichen Zhang",
      "Feng Qiu",
      "Tianqi Hong",
      "Zhaoyu Wang",
      "Fangxing Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.14458"
  },
  {
    "id": "arXiv:2012.01764",
    "title": "Optimal labelling schemes for adjacency, comparability, and reachability",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Marthe Bonamy",
      "Louis Esperet",
      "Carla Groenland",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.01764"
  },
  {
    "id": "arXiv:2012.01813",
    "title": "A Multidisciplinary Definition of Privacy Labels: The Story of Princess  Privacy and the Seven Helpers",
    "abstract": "Comments: 29 pages, 6 figures",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Johanna Johansen",
      "Tore Pedersen",
      "Simone Fischer-H\u00fcbner",
      "Christian Johansen",
      "Gerardo Schneider",
      "Arnold Roosendaal",
      "Harald Zwingelberg",
      "Anders Jakob Sivesind",
      "Josef Noll"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2012.01813"
  },
  {
    "id": "arXiv:2012.01870",
    "title": "Model-free Neural Counterfactual Regret Minimization with Bootstrap  Learning",
    "abstract": "Model-free Neural Counterfactual Regret Minimization with Bootstrap  Learning",
    "descriptor": "",
    "authors": [
      "Weiming Liu",
      "Bin Li",
      "Julian Togelius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.01870"
  },
  {
    "id": "arXiv:2012.02030",
    "title": "Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural  Networks",
    "abstract": "Comments: 13 pages, 6 figures, 10 tables",
    "descriptor": "\nComments: 13 pages, 6 figures, 10 tables\n",
    "authors": [
      "Ileana Rugina",
      "Rumen Dangovski",
      "Li Jing",
      "Preslav Nakov",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.02030"
  },
  {
    "id": "arXiv:2012.02130",
    "title": "A similarity-based Bayesian mixture-of-experts model",
    "abstract": "A similarity-based Bayesian mixture-of-experts model",
    "descriptor": "",
    "authors": [
      "Tianfang Zhang",
      "Rasmus Bokrantz",
      "Jimmy Olsson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2012.02130"
  },
  {
    "id": "arXiv:2012.02877",
    "title": "Multi-Source Data Fusion Outage Location in Distribution Systems via  Probabilistic Graph Models",
    "abstract": "Multi-Source Data Fusion Outage Location in Distribution Systems via  Probabilistic Graph Models",
    "descriptor": "",
    "authors": [
      "Yuxuan Yuan",
      "Kaveh Dehghanpour",
      "Zhaoyu Wang",
      "Fankun Bu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02877"
  },
  {
    "id": "arXiv:2012.03062",
    "title": "Learn to Predict Vertical Track Irregularity with Extremely Imbalanced  Data",
    "abstract": "Learn to Predict Vertical Track Irregularity with Extremely Imbalanced  Data",
    "descriptor": "",
    "authors": [
      "Yutao Chen",
      "Yu Zhang",
      "Fei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03062"
  },
  {
    "id": "arXiv:2012.03488",
    "title": "Multi-agent Policy Optimization with Approximatively Synchronous  Advantage Estimation",
    "abstract": "Multi-agent Policy Optimization with Approximatively Synchronous  Advantage Estimation",
    "descriptor": "",
    "authors": [
      "Lipeng Wan",
      "Xuwei Song",
      "Xuguang Lan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.03488"
  },
  {
    "id": "arXiv:2012.03926",
    "title": "Counting ternary square-free words quickly",
    "abstract": "Counting ternary square-free words quickly",
    "descriptor": "",
    "authors": [
      "Vladislav Makarov"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.03926"
  },
  {
    "id": "arXiv:2012.04515",
    "title": "Digital Gimbal: End-to-end Deep Image Stabilization with Learnable  Exposure Times",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Omer Dahary",
      "Matan Jacoby",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.04515"
  },
  {
    "id": "arXiv:2012.05004",
    "title": "Modeling and Identification of Low Rank Vector Processes",
    "abstract": "Comments: A more detailed version of the submission with the same name to IFAC SYSID 2021",
    "descriptor": "\nComments: A more detailed version of the submission with the same name to IFAC SYSID 2021\n",
    "authors": [
      "Giorgio Picci",
      "Wenqi Cao",
      "Anders Lindquist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.05004"
  },
  {
    "id": "arXiv:2012.05131",
    "title": "Optimization of RIS-aided MIMO Systems via the Cutoff Rate",
    "abstract": "Optimization of RIS-aided MIMO Systems via the Cutoff Rate",
    "descriptor": "",
    "authors": [
      "Nemanja Stefan Perovi\u0107",
      "Le-Nam Tran",
      "Marco Di Renzo",
      "Mark F. Flanagan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.05131"
  },
  {
    "id": "arXiv:2012.05414",
    "title": "Rewriter-Evaluator Architecture for Neural Machine Translation",
    "abstract": "Comments: A full paper accepted at ACL-2021",
    "descriptor": "\nComments: A full paper accepted at ACL-2021\n",
    "authors": [
      "Yangming Li",
      "Kaisheng Yao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.05414"
  },
  {
    "id": "arXiv:2012.06628",
    "title": "Sat2Vid: Street-view Panoramic Video Synthesis from a Single Satellite  Image",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Zuoyue Li",
      "Zhenqiang Li",
      "Zhaopeng Cui",
      "Rongjun Qin",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.06628"
  },
  {
    "id": "arXiv:2012.07339",
    "title": "Verifiable Observation of Permissioned Ledgers",
    "abstract": "Comments: Full report of ICBC'21 version",
    "descriptor": "\nComments: Full report of ICBC'21 version\n",
    "authors": [
      "Ermyas Abebe",
      "Yining Hu",
      "Allison Irvin",
      "Dileban Karunamoorthy",
      "Vinayaka Pandit",
      "Venkatraman Ramakrishna",
      "Jiangshan Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.07339"
  },
  {
    "id": "arXiv:2012.07721",
    "title": "Non-linear State-space Model Identification from Video Data using Deep  Encoders",
    "abstract": "Comments: Accepted to SYSID 2021 (revised with reviewer feedback)",
    "descriptor": "\nComments: Accepted to SYSID 2021 (revised with reviewer feedback)\n",
    "authors": [
      "Gerben Izaak Beintema",
      "Roland Toth",
      "Maarten Schoukens"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07721"
  },
  {
    "id": "arXiv:2012.08868",
    "title": "Using Spatio-temporal Deep Learning for Forecasting Demand and  Supply-demand Gap in Ride-hailing System with Anonymized Spatial Adjacency  Information",
    "abstract": "Using Spatio-temporal Deep Learning for Forecasting Demand and  Supply-demand Gap in Ride-hailing System with Anonymized Spatial Adjacency  Information",
    "descriptor": "",
    "authors": [
      "M. H. Rahman",
      "S. M. Rifaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08868"
  },
  {
    "id": "arXiv:2012.09259",
    "title": "ISD: Self-Supervised Learning by Iterative Similarity Distillation",
    "abstract": "ISD: Self-Supervised Learning by Iterative Similarity Distillation",
    "descriptor": "",
    "authors": [
      "Ajinkya Tejankar",
      "Soroush Abbasi Koohpayegani",
      "Vipin Pillai",
      "Paolo Favaro",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09259"
  },
  {
    "id": "arXiv:2012.09913",
    "title": "Quantifying the Unknown: Impact of Segmentation Uncertainty on  Image-Based Simulations",
    "abstract": "Quantifying the Unknown: Impact of Segmentation Uncertainty on  Image-Based Simulations",
    "descriptor": "",
    "authors": [
      "Michael C. Krygier",
      "Tyler LaBonte",
      "Carianne Martinez",
      "Chance Norris",
      "Krish Sharma",
      "Lincoln N. Collins",
      "Partha P. Mukherjee",
      "Scott A. Roberts"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.09913"
  },
  {
    "id": "arXiv:2012.10929",
    "title": "Automated Clustering of High-dimensional Data with a Feature Weighted  Mean Shift Algorithm",
    "abstract": "Comments: To appear at the 35-th AAAI Conference on Artificial Intelligence, February 2-9, 2021",
    "descriptor": "\nComments: To appear at the 35-th AAAI Conference on Artificial Intelligence, February 2-9, 2021\n",
    "authors": [
      "Saptarshi Chakraborty",
      "Debolina Paul",
      "Swagatam Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10929"
  },
  {
    "id": "arXiv:2012.11270",
    "title": "Family Ties: Relating Poncelet 3-Periodics by their Properties",
    "abstract": "Comments: 22 pages, 10 figures, 4 tables, 18 video links",
    "descriptor": "\nComments: 22 pages, 10 figures, 4 tables, 18 video links\n",
    "authors": [
      "Ronaldo Garcia",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.11270"
  },
  {
    "id": "arXiv:2012.13169",
    "title": "SCC: an efficient deep reinforcement learning agent mastering the game  of StarCraft II",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Xiangjun Wang",
      "Junxiao Song",
      "Penghui Qi",
      "Peng Peng",
      "Zhenkun Tang",
      "Wei Zhang",
      "Weimin Li",
      "Xiongjun Pi",
      "Jujie He",
      "Chao Gao",
      "Haitao Long",
      "Quan Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.13169"
  },
  {
    "id": "arXiv:2012.13587",
    "title": "Inception Convolution with Efficient Dilation Search",
    "abstract": "Inception Convolution with Efficient Dilation Search",
    "descriptor": "",
    "authors": [
      "Jie Liu",
      "Chuming Li",
      "Feng Liang",
      "Chen Lin",
      "Ming Sun",
      "Junjie Yan",
      "Wanli Ouyang",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13587"
  },
  {
    "id": "arXiv:2012.14580",
    "title": "Synchronization with prescribed transient behavior: Heterogeneous  multi-agent systems under funnel coupling Extended arXiv version",
    "abstract": "Synchronization with prescribed transient behavior: Heterogeneous  multi-agent systems under funnel coupling Extended arXiv version",
    "descriptor": "",
    "authors": [
      "Jin Gyu Lee",
      "Stephan Trenn",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.14580"
  },
  {
    "id": "arXiv:2101.00595",
    "title": "Bosonic Dirty Paper Coding",
    "abstract": "Bosonic Dirty Paper Coding",
    "descriptor": "",
    "authors": [
      "Uzi Pereg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.00595"
  },
  {
    "id": "arXiv:2101.00774",
    "title": "Retrieving and Reading: A Comprehensive Survey on Open-domain Question  Answering",
    "abstract": "Retrieving and Reading: A Comprehensive Survey on Open-domain Question  Answering",
    "descriptor": "",
    "authors": [
      "Fengbin Zhu",
      "Wenqiang Lei",
      "Chao Wang",
      "Jianming Zheng",
      "Soujanya Poria",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.00774"
  },
  {
    "id": "arXiv:2101.01496",
    "title": "An efficient feature-preserving PDE algorithm for image denoising based  on a spatial-fractional anisotropic diffusion equation",
    "abstract": "Comments: 23 pages, 8 figures",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Maoyuan Xu",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.01496"
  },
  {
    "id": "arXiv:2101.02679",
    "title": "Planning for Multi-stage Forceful Manipulation",
    "abstract": "Comments: Accepted to IEEE ICRA 2021. For videos see: this https URL",
    "descriptor": "\nComments: Accepted to IEEE ICRA 2021. For videos see: this https URL\n",
    "authors": [
      "Rachel Holladay",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Alberto Rodriguez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.02679"
  },
  {
    "id": "arXiv:2101.02683",
    "title": "Does Crowdfunding Really Foster Innovation? Evidence from the Board Game  Industry",
    "abstract": "Does Crowdfunding Really Foster Innovation? Evidence from the Board Game  Industry",
    "descriptor": "",
    "authors": [
      "Johannes Wachs",
      "Balazs Vedres"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2101.02683"
  },
  {
    "id": "arXiv:2101.03805",
    "title": "Multi-objective Conflict-based Search for Multi-agent Path Finding",
    "abstract": "Comments: 7 pages, 5 figures, accepted by ICRA 2021",
    "descriptor": "\nComments: 7 pages, 5 figures, accepted by ICRA 2021\n",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Howie Choset"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.03805"
  },
  {
    "id": "arXiv:2101.04053",
    "title": "Anomaly Detection for Aggregated Data Using Multi-Graph Autoencoder",
    "abstract": "Comments: Title of the thesis has changed. In addition, resubmission of the document was requested in the thesis defense with different structure of the thesis paper, additional background, methods information, and data collection information",
    "descriptor": "\nComments: Title of the thesis has changed. In addition, resubmission of the document was requested in the thesis defense with different structure of the thesis paper, additional background, methods information, and data collection information\n",
    "authors": [
      "Tomer Meirman",
      "Roni Stern",
      "Gilad Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.04053"
  },
  {
    "id": "arXiv:2101.05604",
    "title": "Decoding of Interleaved Linearized Reed-Solomon Codes with Applications  to Network Coding",
    "abstract": "Comments: 6 pages, 2 figures, accepted at ISIT 2021",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted at ISIT 2021\n",
    "authors": [
      "Hannes Bartz",
      "Sven Puchinger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.05604"
  },
  {
    "id": "arXiv:2101.05850",
    "title": "Continual Learning of Knowledge Graph Embeddings",
    "abstract": "Comments: 8 pages, 4 figures. Accepted for publication in IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: 8 pages, 4 figures. Accepted for publication in IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Angel Daruna",
      "Mehul Gupta",
      "Mohan Sridharan",
      "Sonia Chernova"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.05850"
  },
  {
    "id": "arXiv:2101.06547",
    "title": "LookOut: Diverse Multi-Future Prediction and Planning for Self-Driving",
    "abstract": "LookOut: Diverse Multi-Future Prediction and Planning for Self-Driving",
    "descriptor": "",
    "authors": [
      "Alexander Cui",
      "Sergio Casas",
      "Abbas Sadat",
      "Renjie Liao",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06547"
  },
  {
    "id": "arXiv:2101.08390",
    "title": "An Information-Theoretic Analysis of the Impact of Task Similarity on  Meta-Learning",
    "abstract": "Comments: Accepted to ISIT 2021",
    "descriptor": "\nComments: Accepted to ISIT 2021\n",
    "authors": [
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.08390"
  },
  {
    "id": "arXiv:2101.10121",
    "title": "Game-Theoretic and Machine Learning-based Approaches for Defensive  Deception: A Survey",
    "abstract": "Comments: 37 pages, 184 citations",
    "descriptor": "\nComments: 37 pages, 184 citations\n",
    "authors": [
      "Mu Zhu",
      "Ahmed H. Anwar",
      "Zelin Wan",
      "Jin-Hee Cho",
      "Charles Kamhoua",
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10121"
  },
  {
    "id": "arXiv:2101.10139",
    "title": "Estimates for solutions of homogeneous time-delay systems: Comparison of  Lyapunov-Krasovskii and Lyapunov-Razumikhin techniques",
    "abstract": "Comments: This paper has been submitted to International Journal of Control",
    "descriptor": "\nComments: This paper has been submitted to International Journal of Control\n",
    "authors": [
      "Gerson Portilla",
      "Irina Alexandrova",
      "Sabine Mondi\u00e9",
      "Alexey Zhabko"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.10139"
  },
  {
    "id": "arXiv:2101.11091",
    "title": "Nonconvex Regularized Gradient Projection Sparse Reconstruction for  Massive MIMO Channel Estimation",
    "abstract": "Nonconvex Regularized Gradient Projection Sparse Reconstruction for  Massive MIMO Channel Estimation",
    "descriptor": "",
    "authors": [
      "Pengxia Wu",
      "Julian Cheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11091"
  },
  {
    "id": "arXiv:2101.11185",
    "title": "Bayes-Optimal Convolutional AMP",
    "abstract": "Comments: accepted for presentation in ISIT2021",
    "descriptor": "\nComments: accepted for presentation in ISIT2021\n",
    "authors": [
      "Keigo Takeuchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11185"
  },
  {
    "id": "arXiv:2101.11272",
    "title": "VisualMRC: Machine Reading Comprehension on Document Images",
    "abstract": "Comments: Accepted as a full paper at AAAI 2021. The first two authors have equal contribution",
    "descriptor": "\nComments: Accepted as a full paper at AAAI 2021. The first two authors have equal contribution\n",
    "authors": [
      "Ryota Tanaka",
      "Kyosuke Nishida",
      "Sen Yoshida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11272"
  },
  {
    "id": "arXiv:2101.11318",
    "title": "Rate Splitting Multiple Access for Multi-Antenna Multi-Carrier Joint  Communications and Jamming",
    "abstract": "Rate Splitting Multiple Access for Multi-Antenna Multi-Carrier Joint  Communications and Jamming",
    "descriptor": "",
    "authors": [
      "Onur Dizdar",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11318"
  },
  {
    "id": "arXiv:2101.11952",
    "title": "Rethinking Rotated Object Detection with Gaussian Wasserstein Distance  Loss",
    "abstract": "Comments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL",
    "descriptor": "\nComments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL\n",
    "authors": [
      "Xue Yang",
      "Junchi Yan",
      "Qi Ming",
      "Wentao Wang",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.11952"
  },
  {
    "id": "arXiv:2101.12631",
    "title": "A Comprehensive Survey and Experimental Comparison of Graph-Based  Approximate Nearest Neighbor Search",
    "abstract": "Comments: 28 pages, 21 figures, 24 tables, conference",
    "descriptor": "\nComments: 28 pages, 21 figures, 24 tables, conference\n",
    "authors": [
      "Mengzhao Wang",
      "Xiaoliang Xu",
      "Qiang Yue",
      "Yuxiang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2101.12631"
  },
  {
    "id": "arXiv:2102.00324",
    "title": "Video Reenactment as Inductive Bias for Content-Motion Disentanglement",
    "abstract": "Comments: Project page and source code at this https URL",
    "descriptor": "\nComments: Project page and source code at this https URL\n",
    "authors": [
      "Juan F. Hern\u00e1ndez Albarrac\u00edn",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.00324"
  },
  {
    "id": "arXiv:2102.01197",
    "title": "Common Randomness Generation over Slow Fading Channels",
    "abstract": "Common Randomness Generation over Slow Fading Channels",
    "descriptor": "",
    "authors": [
      "Rami Ezzine",
      "Moritz Wiese",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.01197"
  },
  {
    "id": "arXiv:2102.01519",
    "title": "Permute & Add Network Codes via Group Algebras",
    "abstract": "Comments: Accepted for presentation and publication at ISIT 2021. Changes with respect to arXiv:2102.01519v2 - corrected minor errors. Keywords: network coding, circular shifts, group algebra, permutations",
    "descriptor": "\nComments: Accepted for presentation and publication at ISIT 2021. Changes with respect to arXiv:2102.01519v2 - corrected minor errors. Keywords: network coding, circular shifts, group algebra, permutations\n",
    "authors": [
      "Lakshmi Prasad Natarajan",
      "Smiju Kodamthuruthil Joy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.01519"
  },
  {
    "id": "arXiv:2102.02511",
    "title": "High-Rate Quantum Private Information Retrieval with Weakly Self-Dual  Star Product Codes",
    "abstract": "High-Rate Quantum Private Information Retrieval with Weakly Self-Dual  Star Product Codes",
    "descriptor": "",
    "authors": [
      "Matteo Allaix",
      "Lukas Holzbaur",
      "Tefjol Pllaha",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.02511"
  },
  {
    "id": "arXiv:2102.02956",
    "title": "DetectorGuard: Provably Securing Object Detectors against Localized  Patch Hiding Attacks",
    "abstract": "DetectorGuard: Provably Securing Object Detectors against Localized  Patch Hiding Attacks",
    "descriptor": "",
    "authors": [
      "Chong Xiang",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02956"
  },
  {
    "id": "arXiv:2102.03004",
    "title": "The Critical Mean-field Chayes-Machta Dynamics",
    "abstract": "The Critical Mean-field Chayes-Machta Dynamics",
    "descriptor": "",
    "authors": [
      "Antonio Blanca",
      "Alistair Sinclair",
      "Xusheng Zhang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.03004"
  },
  {
    "id": "arXiv:2102.03986",
    "title": "DEFT: Distilling Entangled Factors",
    "abstract": "DEFT: Distilling Entangled Factors",
    "descriptor": "",
    "authors": [
      "Jiantao Wu",
      "Lin Wang",
      "Chunxiuzi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.03986"
  },
  {
    "id": "arXiv:2102.05470",
    "title": "Dark Web Marketplaces and COVID-19: The vaccines",
    "abstract": "Comments: For the \"before the vaccine\" report see this https URL",
    "descriptor": "\nComments: For the \"before the vaccine\" report see this https URL\n",
    "authors": [
      "Alberto Bracci",
      "Matthieu Nadini",
      "Maxwell Aliapoulios",
      "Damon McCoy",
      "Ian Gray",
      "Alexander Teytelboym",
      "Angela Gallo",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.05470"
  },
  {
    "id": "arXiv:2102.06440",
    "title": "Interview Hoarding",
    "abstract": "Interview Hoarding",
    "descriptor": "",
    "authors": [
      "Vikram Manjunath",
      "Thayer Morrill"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2102.06440"
  },
  {
    "id": "arXiv:2102.06912",
    "title": "Universal gauge-invariant cellular automata",
    "abstract": "Universal gauge-invariant cellular automata",
    "descriptor": "",
    "authors": [
      "Pablo Arrighi",
      "Marin Costes",
      "Nathana\u00ebl Eon"
    ],
    "subjectives": [
      "Cellular Automata and Lattice Gases (nlin.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.06912"
  },
  {
    "id": "arXiv:2102.06935",
    "title": "Strong Brascamp-Lieb Inequalities",
    "abstract": "Comments: 39 pages, 4 figures. The single-function version of forward BL inequalities for q&lt;1 and that of reverse BL inequalities for q\\ge 1 have been added, which are asymptotically sharp. Accordingly, Appendices C and D have been added as well, and the strong q-stability theorem has been modified accordingly",
    "descriptor": "\nComments: 39 pages, 4 figures. The single-function version of forward BL inequalities for q&lt;1 and that of reverse BL inequalities for q\\ge 1 have been added, which are asymptotically sharp. Accordingly, Appendices C and D have been added as well, and the strong q-stability theorem has been modified accordingly\n",
    "authors": [
      "Lei Yu"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.06935"
  },
  {
    "id": "arXiv:2102.07061",
    "title": "Query-by-Example Keyword Spotting system using Multi-head Attention and  Softtriple Loss",
    "abstract": "Comments: Accepted by ICASSP 2021",
    "descriptor": "\nComments: Accepted by ICASSP 2021\n",
    "authors": [
      "Jinmiao Huang",
      "Waseem Gharbieh",
      "Han Suk Shim",
      "Eugene Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07061"
  },
  {
    "id": "arXiv:2102.07236",
    "title": "Joint Rate Distortion Function of a Tuple of Correlated Multivariate  Gaussian Sources with Individual Fidelity Criteria",
    "abstract": "Joint Rate Distortion Function of a Tuple of Correlated Multivariate  Gaussian Sources with Individual Fidelity Criteria",
    "descriptor": "",
    "authors": [
      "Evagoras Stylianou",
      "Charalambos D. Charalambous",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.07236"
  },
  {
    "id": "arXiv:2102.07367",
    "title": "A Near-Optimal Algorithm for Stochastic Bilevel Optimization via  Double-Momentum",
    "abstract": "A Near-Optimal Algorithm for Stochastic Bilevel Optimization via  Double-Momentum",
    "descriptor": "",
    "authors": [
      "Prashant Khanduri",
      "Siliang Zeng",
      "Mingyi Hong",
      "Hoi-To Wai",
      "Zhaoran Wang",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07367"
  },
  {
    "id": "arXiv:2102.07373",
    "title": "Generation For Adaption: A GAN-Based Approach for 3D Domain Adaption  with Point Cloud Data",
    "abstract": "Generation For Adaption: A GAN-Based Approach for 3D Domain Adaption  with Point Cloud Data",
    "descriptor": "",
    "authors": [
      "Junxuan Huang",
      "Junsong Yuan",
      "Chunming Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07373"
  },
  {
    "id": "arXiv:2102.07454",
    "title": "Tight Revenue Gaps among Multi-Unit Mechanisms",
    "abstract": "Comments: To appear in EC 2021",
    "descriptor": "\nComments: To appear in EC 2021\n",
    "authors": [
      "Yaonan Jin",
      "Shunhua Jiang",
      "Pinyan Lu",
      "Hengjie Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.07454"
  },
  {
    "id": "arXiv:2102.07753",
    "title": "Learning Intra-Batch Connections for Deep Metric Learning",
    "abstract": "Comments: Accepted to International Conference on Machine Learning (ICML) 2021, includes non-archival supplementary material",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML) 2021, includes non-archival supplementary material\n",
    "authors": [
      "Jenny Seidenschwarz",
      "Ismail Elezi",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07753"
  },
  {
    "id": "arXiv:2102.09251",
    "title": "APIScanner -- Towards Automated Detection of Deprecated APIs in Python  Libraries",
    "abstract": "APIScanner -- Towards Automated Detection of Deprecated APIs in Python  Libraries",
    "descriptor": "",
    "authors": [
      "Aparna Vadlamani",
      "Rishitha Kalicheti",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09251"
  },
  {
    "id": "arXiv:2102.09844",
    "title": "E(n) Equivariant Graph Neural Networks",
    "abstract": "E(n) Equivariant Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Victor Garcia Satorras",
      "Emiel Hoogeboom",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09844"
  },
  {
    "id": "arXiv:2102.09921",
    "title": "Parallel algorithms for power circuits and the word problem of the  Baumslag group",
    "abstract": "Parallel algorithms for power circuits and the word problem of the  Baumslag group",
    "descriptor": "",
    "authors": [
      "Caroline Mattes",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2102.09921"
  },
  {
    "id": "arXiv:2102.10058",
    "title": "Principled Simplicial Neural Networks for Trajectory Prediction",
    "abstract": "Principled Simplicial Neural Networks for Trajectory Prediction",
    "descriptor": "",
    "authors": [
      "Nicholas Glaze",
      "T. Mitchell Roddenberry",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.10058"
  },
  {
    "id": "arXiv:2102.10077",
    "title": "Algorithms for the Minimum Dominating Set Problem in Bounded Arboricity  Graphs: Simpler, Faster, and Combinatorial",
    "abstract": "Comments: abstract shortened to meet arxiv requirement",
    "descriptor": "\nComments: abstract shortened to meet arxiv requirement\n",
    "authors": [
      "Adir Morgan",
      "Shay Solomon",
      "Nicole Wein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.10077"
  },
  {
    "id": "arXiv:2102.10315",
    "title": "EXTRA: Explanation Ranking Datasets for Explainable Recommendation",
    "abstract": "EXTRA: Explanation Ranking Datasets for Explainable Recommendation",
    "descriptor": "",
    "authors": [
      "Lei Li",
      "Yongfeng Zhang",
      "Li Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.10315"
  },
  {
    "id": "arXiv:2102.11600",
    "title": "ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning  of Deep Neural Networks",
    "abstract": "Comments: 25 pages, 4 figures",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Jungmin Kwon",
      "Jeongseop Kim",
      "Hyunseo Park",
      "In Kwon Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11600"
  },
  {
    "id": "arXiv:2103.00070",
    "title": "Knowledge-aware Zero-Shot Learning: Survey and Perspective",
    "abstract": "Comments: Accepted by IJCAI'21 Survey Track",
    "descriptor": "\nComments: Accepted by IJCAI'21 Survey Track\n",
    "authors": [
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Zhuo Chen",
      "Ian Horrocks",
      "Jeff Z. Pan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00070"
  },
  {
    "id": "arXiv:2103.00172",
    "title": "A Survey on Physarum Polycephalum Intelligent Foraging Behaviour and  Bio-Inspired Applications",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1712.02910 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1712.02910 by other authors\n",
    "authors": [
      "Abubakr Awad",
      "Wei Pang",
      "David Lusseau",
      "George M. Coghill"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00172"
  },
  {
    "id": "arXiv:2103.02280",
    "title": "Simplified Data Wrangling with ir_datasets",
    "abstract": "Comments: SIGIR 2021 Resource",
    "descriptor": "\nComments: SIGIR 2021 Resource\n",
    "authors": [
      "Sean MacAvaney",
      "Andrew Yates",
      "Sergey Feldman",
      "Doug Downey",
      "Arman Cohan",
      "Nazli Goharian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.02280"
  },
  {
    "id": "arXiv:2103.02603",
    "title": "Towards Open World Object Detection",
    "abstract": "Comments: To appear in CVPR 2021 as an ORAL paper. Code is available in this https URL",
    "descriptor": "\nComments: To appear in CVPR 2021 as an ORAL paper. Code is available in this https URL\n",
    "authors": [
      "K J Joseph",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02603"
  },
  {
    "id": "arXiv:2103.02646",
    "title": "Critical Slowing Down Near Topological Transitions in Rate-Distortion  Problems",
    "abstract": "Comments: 10 pages, 2 figures, ISIT 2021 submission",
    "descriptor": "\nComments: 10 pages, 2 figures, ISIT 2021 submission\n",
    "authors": [
      "Shlomi Agmon",
      "Etam Benger",
      "Or Ordentlich",
      "Naftali Tishby"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.02646"
  },
  {
    "id": "arXiv:2103.03080",
    "title": "Analyzing the Usefulness of the DARPA OpTC Dataset in Cyber Threat  Detection Research",
    "abstract": "Comments: Accepted in ACM SACMAT 2021",
    "descriptor": "\nComments: Accepted in ACM SACMAT 2021\n",
    "authors": [
      "Md. Monowar Anjum",
      "Shahrear Iqbal",
      "Benoit Hamelin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.03080"
  },
  {
    "id": "arXiv:2103.03095",
    "title": "A Survey on Spoken Language Understanding: Recent Advances and New  Frontiers",
    "abstract": "Comments: Accepted at IJCAI2021. Resources in \\url{this https URL}",
    "descriptor": "\nComments: Accepted at IJCAI2021. Resources in \\url{this https URL}\n",
    "authors": [
      "Libo Qin",
      "Tianbao Xie",
      "Wanxiang Che",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.03095"
  },
  {
    "id": "arXiv:2103.03413",
    "title": "Routing algorithms as tools for integrating social distancing with  emergency evacuation",
    "abstract": "Routing algorithms as tools for integrating social distancing with  emergency evacuation",
    "descriptor": "",
    "authors": [
      "Yi-Lin Tsai",
      "Chetanya Rastogi",
      "Peter K. Kitanidis",
      "Christopher B. Field"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03413"
  },
  {
    "id": "arXiv:2103.03809",
    "title": "PalmTree: Learning an Assembly Language Model for Instruction Embedding",
    "abstract": "PalmTree: Learning an Assembly Language Model for Instruction Embedding",
    "descriptor": "",
    "authors": [
      "Xuezixiang Li",
      "Qu Yu",
      "Heng Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.03809"
  },
  {
    "id": "arXiv:2103.04565",
    "title": "Improving Transformation-based Defenses against Adversarial Examples  with First-order Perturbations",
    "abstract": "Improving Transformation-based Defenses against Adversarial Examples  with First-order Perturbations",
    "descriptor": "",
    "authors": [
      "Haimin Zhang",
      "Min Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04565"
  },
  {
    "id": "arXiv:2103.04850",
    "title": "Quantifying Ignorance in Individual-Level Causal-Effect Estimates under  Hidden Confounding",
    "abstract": "Comments: 19 pages, 5 figures, ICML 2021",
    "descriptor": "\nComments: 19 pages, 5 figures, ICML 2021\n",
    "authors": [
      "Andrew Jesson",
      "S\u00f6ren Mindermann",
      "Yarin Gal",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.04850"
  },
  {
    "id": "arXiv:2103.07087",
    "title": "iToF2dToF: A Robust and Flexible Representation for Data-Driven  Time-of-Flight Imaging",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Felipe Gutierrez-Barragan",
      "Huaijin Chen",
      "Mohit Gupta",
      "Andreas Velten",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.07087"
  },
  {
    "id": "arXiv:2103.07257",
    "title": "An FPTAS for the $\u0394$-modular multidimensional knapsack problem",
    "abstract": "An FPTAS for the $\u0394$-modular multidimensional knapsack problem",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.07257"
  },
  {
    "id": "arXiv:2103.08693",
    "title": "A generalized strong convergence algorithm in the presence of the errors  for the variational inequality problems in Hilbert spaces",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Mostafa Ghadampour",
      "Donal O'Regan",
      "Ebrahim Soori",
      "Ravi. p. Agarwal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2103.08693"
  },
  {
    "id": "arXiv:2103.09452",
    "title": "A New Modified Newton-Type Iteration Method for Solving Generalized  Absolute Value Equations",
    "abstract": "Comments: 20 pages, 6 tables",
    "descriptor": "\nComments: 20 pages, 6 tables\n",
    "authors": [
      "Xu Li",
      "Xiao-Xia Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.09452"
  },
  {
    "id": "arXiv:2103.09731",
    "title": "On additive spanners in weighted graphs with local error",
    "abstract": "On additive spanners in weighted graphs with local error",
    "descriptor": "",
    "authors": [
      "Reyan Ahmed",
      "Greg Bodwin",
      "Keaton Hamm",
      "Stephen Kobourov",
      "Richard Spence"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.09731"
  },
  {
    "id": "arXiv:2103.11016",
    "title": "Multi-Robot Dynamical Source Seeking in Unknown Environments",
    "abstract": "Multi-Robot Dynamical Source Seeking in Unknown Environments",
    "descriptor": "",
    "authors": [
      "Bin Du",
      "Kun Qian",
      "Christian Claudel",
      "Dengfeng Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.11016"
  },
  {
    "id": "arXiv:2103.14282",
    "title": "Rethinking Graph Neural Architecture Search from Message-passing",
    "abstract": "Comments: This paper has been accepted by CVPR2021",
    "descriptor": "\nComments: This paper has been accepted by CVPR2021\n",
    "authors": [
      "Shaofei Cai",
      "Liang Li",
      "Jincan Deng",
      "Beichen Zhang",
      "Zheng-Jun Zha",
      "Li Su",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14282"
  },
  {
    "id": "arXiv:2103.14666",
    "title": "Autonomous Overtaking in Gran Turismo Sport Using Curriculum  Reinforcement Learning",
    "abstract": "Comments: Accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Xi An, 2021",
    "descriptor": "\nComments: Accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Xi An, 2021\n",
    "authors": [
      "Yunlong Song",
      "HaoChih Lin",
      "Elia Kaufmann",
      "Peter Duerr",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14666"
  },
  {
    "id": "arXiv:2103.14972",
    "title": "Building an Expert Annotated Corpus of Brazilian Instagram Comments for  Hate Speech and Offensive Language Detection",
    "abstract": "Building an Expert Annotated Corpus of Brazilian Instagram Comments for  Hate Speech and Offensive Language Detection",
    "descriptor": "",
    "authors": [
      "Francielle Alves Vargas",
      "Isabelle Carvalho",
      "Fabiana Rodrigues de G\u00f3es",
      "Fabr\u00edcio Benevenuto",
      "Thiago Alexandre Salgueiro Pardo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.14972"
  },
  {
    "id": "arXiv:2103.17182",
    "title": "Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to  Improve Generalization",
    "abstract": "Comments: ICML 2021; 19 pages; 12 figures; Key Words: deep learning theory, optimizer, momentum, generalization",
    "descriptor": "\nComments: ICML 2021; 19 pages; 12 figures; Key Words: deep learning theory, optimizer, momentum, generalization\n",
    "authors": [
      "Zeke Xie",
      "Li Yuan",
      "Zhanxing Zhu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.17182"
  },
  {
    "id": "arXiv:2104.00305",
    "title": "Modeling High-order Interactions across Multi-interests for Micro-video  Recommendation",
    "abstract": "Comments: accepted to AAAI 2021",
    "descriptor": "\nComments: accepted to AAAI 2021\n",
    "authors": [
      "Dong Yao",
      "Shengyu Zhang",
      "Zhou Zhao",
      "Wenyan Fan",
      "Jieming Zhu",
      "Xiuqiang He",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.00305"
  },
  {
    "id": "arXiv:2104.01108",
    "title": "Group Collaborative Learning for Co-Salient Object Detection",
    "abstract": "Comments: Accepted to CVPR 2021. Project page: this https URL Note: corrected Fig 9 in this version",
    "descriptor": "\nComments: Accepted to CVPR 2021. Project page: this https URL Note: corrected Fig 9 in this version\n",
    "authors": [
      "Qi Fan",
      "Deng-Ping Fan",
      "Huazhu Fu",
      "Chi Keung Tang",
      "Ling Shao",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01108"
  },
  {
    "id": "arXiv:2104.01309",
    "title": "Tighter bounds on transient moments of stochastic chemical systems",
    "abstract": "Comments: corrected typos and added implementation details",
    "descriptor": "\nComments: corrected typos and added implementation details\n",
    "authors": [
      "Flemming Holtorf",
      "Paul I. Barton"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.01309"
  },
  {
    "id": "arXiv:2104.01508",
    "title": "Learning Neural Representation of Camera Pose with Matrix Representation  of Pose Shift via View Synthesis",
    "abstract": "Learning Neural Representation of Camera Pose with Matrix Representation  of Pose Shift via View Synthesis",
    "descriptor": "",
    "authors": [
      "Yaxuan Zhu",
      "Ruiqi Gao",
      "Siyuan Huang",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01508"
  },
  {
    "id": "arXiv:2104.01835",
    "title": "Advances In Malware Detection- An Overview",
    "abstract": "Advances In Malware Detection- An Overview",
    "descriptor": "",
    "authors": [
      "Heena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.01835"
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Image  Stylization and Domain Mixup",
    "abstract": "Comments: some experimental results are wrong",
    "descriptor": "\nComments: some experimental results are wrong\n",
    "authors": [
      "Pinhao Song",
      "Linhui Dai",
      "Peipei Yuan",
      "Hong Liu",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02230"
  },
  {
    "id": "arXiv:2104.02588",
    "title": "Principal Component Analysis Applied to Gradient Fields in Band Gap  Optimization Problems for Metamaterials",
    "abstract": "Principal Component Analysis Applied to Gradient Fields in Band Gap  Optimization Problems for Metamaterials",
    "descriptor": "",
    "authors": [
      "Giorgio Gnecco",
      "Andrea Bacigalupo",
      "Francesca Fantoni",
      "Daniela Selvi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.02588"
  },
  {
    "id": "arXiv:2104.02903",
    "title": "A Priori Analysis of Stable Neural Network Solutions to Numerical PDEs",
    "abstract": "A Priori Analysis of Stable Neural Network Solutions to Numerical PDEs",
    "descriptor": "",
    "authors": [
      "Qingguo Hong",
      "Jonathan W. Siegel",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.02903"
  },
  {
    "id": "arXiv:2104.02920",
    "title": "Visualization of the Computation Process of a Universal Register Machine",
    "abstract": "Visualization of the Computation Process of a Universal Register Machine",
    "descriptor": "",
    "authors": [
      "Shigeru Ninagawa",
      "Genaro J. Martinez"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.02920"
  },
  {
    "id": "arXiv:2104.03483",
    "title": "Question-Driven Design Process for Explainable AI User Experiences",
    "abstract": "Comments: working paper",
    "descriptor": "\nComments: working paper\n",
    "authors": [
      "Q. Vera Liao",
      "Milena Pribi\u0107",
      "Jaesik Han",
      "Sarah Miller",
      "Daby Sow"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03483"
  },
  {
    "id": "arXiv:2104.03528",
    "title": "Neural Temporal Point Processes: A Review",
    "abstract": "Comments: International Joint Conference on Artificial Intelligence (IJCAI) 2021",
    "descriptor": "\nComments: International Joint Conference on Artificial Intelligence (IJCAI) 2021\n",
    "authors": [
      "Oleksandr Shchur",
      "Ali Caner T\u00fcrkmen",
      "Tim Januschowski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.03528"
  },
  {
    "id": "arXiv:2104.06323",
    "title": "\u03b4-CLUE: Diverse Sets of Explanations for Uncertainty Estimates",
    "abstract": "Comments: Appeared as a workshop paper at ICLR 2021 (Responsible AI | Secure ML | Robust ML)",
    "descriptor": "\nComments: Appeared as a workshop paper at ICLR 2021 (Responsible AI | Secure ML | Robust ML)\n",
    "authors": [
      "Dan Ley",
      "Umang Bhatt",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06323"
  },
  {
    "id": "arXiv:2104.06541",
    "title": "From Solving a Problem Boldly to Cutting the Gordian Knot: Idiomatic  Text Generation",
    "abstract": "From Solving a Problem Boldly to Cutting the Gordian Knot: Idiomatic  Text Generation",
    "descriptor": "",
    "authors": [
      "Jianing Zhou",
      "Hongyu Gong",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.06541"
  },
  {
    "id": "arXiv:2104.06555",
    "title": "Should Semantic Vector Composition be Explicit? Can it be Linear?",
    "abstract": "Should Semantic Vector Composition be Explicit? Can it be Linear?",
    "descriptor": "",
    "authors": [
      "Dominic Widdows",
      "Kristen Howell",
      "Trevor Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06555"
  },
  {
    "id": "arXiv:2104.06655",
    "title": "Decomposed Soft Actor-Critic Method for Cooperative Multi-Agent  Reinforcement Learning",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yuan Pu",
      "Shaochen Wang",
      "Rui Yang",
      "Xin Yao",
      "Bin Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06655"
  },
  {
    "id": "arXiv:2104.06689",
    "title": "Learning Normal Dynamics in Videos with Meta Prototype Network",
    "abstract": "Comments: 9 pages, 4 figures, 6 tables",
    "descriptor": "\nComments: 9 pages, 4 figures, 6 tables\n",
    "authors": [
      "Hui Lv",
      "Chen Chen",
      "Zhen Cui",
      "Chunyan Xu",
      "Yong Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.06689"
  },
  {
    "id": "arXiv:2104.08419",
    "title": "TIE: A Framework for Embedding-based Incremental Temporal Knowledge  Graph Completion",
    "abstract": "Comments: SIGIR 2021 long paper. 13 pages, 4 figures",
    "descriptor": "\nComments: SIGIR 2021 long paper. 13 pages, 4 figures\n",
    "authors": [
      "Jiapeng Wu",
      "Yishi Xu",
      "Yingxue Zhang",
      "Chen Ma",
      "Mark Coates",
      "Jackie Chi Kit Cheung"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08419"
  },
  {
    "id": "arXiv:2104.08427",
    "title": "Models and Predictive Control for Nonplanar Vehicle Navigation",
    "abstract": "Comments: Added appendices, corrected typos",
    "descriptor": "\nComments: Added appendices, corrected typos\n",
    "authors": [
      "Thomas Fork",
      "H. Eric Tseng",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08427"
  },
  {
    "id": "arXiv:2104.08619",
    "title": "Optimal Counterfactual Explanations for Scorecard modelling",
    "abstract": "Optimal Counterfactual Explanations for Scorecard modelling",
    "descriptor": "",
    "authors": [
      "Guillermo Navas-Palencia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.08619"
  },
  {
    "id": "arXiv:2104.08734",
    "title": "Barrier-Free Large-Scale Sparse Tensor Accelerator (BARISTA) For  Convolutional Neural Networks",
    "abstract": "Barrier-Free Large-Scale Sparse Tensor Accelerator (BARISTA) For  Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Ashish Gondimalla",
      "Sree Charan Gundabolu",
      "T.N. Vijaykumar",
      "Mithuna Thottethodi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2104.08734"
  },
  {
    "id": "arXiv:2104.08860",
    "title": "CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip  Retrieval",
    "abstract": "CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip  Retrieval",
    "descriptor": "",
    "authors": [
      "Huaishao Luo",
      "Lei Ji",
      "Ming Zhong",
      "Yang Chen",
      "Wen Lei",
      "Nan Duan",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08860"
  },
  {
    "id": "arXiv:2104.09443",
    "title": "Numerical analysis of a Neumann boundary control problem with a  stochastic parabolic equation",
    "abstract": "Numerical analysis of a Neumann boundary control problem with a  stochastic parabolic equation",
    "descriptor": "",
    "authors": [
      "Qin Zhou",
      "Binjie Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.09443"
  },
  {
    "id": "arXiv:2104.10330",
    "title": "Boundary-Aware 3D Object Detection from Point Clouds",
    "abstract": "Boundary-Aware 3D Object Detection from Point Clouds",
    "descriptor": "",
    "authors": [
      "Rui Qian",
      "Xin Lai",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10330"
  },
  {
    "id": "arXiv:2104.10851",
    "title": "Continuous Learning and Adaptation with Membrane Potential and  Activation Threshold Homeostasis",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Alexander Hadjiivanov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10851"
  },
  {
    "id": "arXiv:2104.11760",
    "title": "DeepCAT: Deep Category Representation for Query Understanding in  E-commerce Search",
    "abstract": "DeepCAT: Deep Category Representation for Query Understanding in  E-commerce Search",
    "descriptor": "",
    "authors": [
      "Ali Ahmadvand",
      "Surya Kallumadi",
      "Faizan Javed",
      "Eugene Agichtein"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11760"
  },
  {
    "id": "arXiv:2104.11969",
    "title": "Vietnamese Open-domain Complaint Detection in E-Commerce Websites",
    "abstract": "Vietnamese Open-domain Complaint Detection in E-Commerce Websites",
    "descriptor": "",
    "authors": [
      "Nhung Thi-Hong Nguyen",
      "Phuong Ha-Dieu Phan",
      "Luan Thanh Nguyen",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.11969"
  },
  {
    "id": "arXiv:2104.12137",
    "title": "Transformer Meets DCFAM: A Novel Semantic Segmentation Scheme for  Fine-Resolution Remote Sensing Images",
    "abstract": "Transformer Meets DCFAM: A Novel Semantic Segmentation Scheme for  Fine-Resolution Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Libo Wang",
      "Rui Li",
      "Chenxi Duan",
      "Xiaoliang Meng",
      "Shenghui Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12137"
  },
  {
    "id": "arXiv:2104.12265",
    "title": "Contextual Lexicon-Based Approach for Hate Speech and Offensive Language  Detection",
    "abstract": "Contextual Lexicon-Based Approach for Hate Speech and Offensive Language  Detection",
    "descriptor": "",
    "authors": [
      "Francielle Alves Vargas",
      "Fabiana Rodrigues de G\u00f3es",
      "Isabelle Carvalho",
      "Fabr\u00edcio Benevenuto",
      "Thiago Alexandre Salgueiro Pardo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12265"
  },
  {
    "id": "arXiv:2104.13018",
    "title": "Attention and Prediction Guided Motion Detection for Low-Contrast Small  Moving Targets",
    "abstract": "Comments: 14 pages, 25 figures",
    "descriptor": "\nComments: 14 pages, 25 figures\n",
    "authors": [
      "Hongxin Wang",
      "Jiannan Zhao",
      "Huatian Wang",
      "Cheng Hu",
      "Jigen Peng",
      "Shigang Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13018"
  },
  {
    "id": "arXiv:2104.13155",
    "title": "Watershed of Artificial Intelligence: Human Intelligence, Machine  Intelligence, and Biological Intelligence",
    "abstract": "Comments: This article reviews the Once Learning mechanism and divides Artificial Intelligence into three categories: Artificial Human Intelligence (AHI), Artificial Machine Intelligence (AMI), and Artificial Biological Intelligence (ABI). The paper is with 16 pages and 3 tables",
    "descriptor": "\nComments: This article reviews the Once Learning mechanism and divides Artificial Intelligence into three categories: Artificial Human Intelligence (AHI), Artificial Machine Intelligence (AMI), and Artificial Biological Intelligence (ABI). The paper is with 16 pages and 3 tables\n",
    "authors": [
      "Li Weigang",
      "Liriam Enamoto",
      "Denise Leyi Li",
      "Geraldo Pereira Rocha Filho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.13155"
  },
  {
    "id": "arXiv:2104.13362",
    "title": "There is no APTAS for 2-dimensional vector bin packing: Revisited",
    "abstract": "Comments: 11 pages, LIPIcs format, changes: fixed typos, added vector bin covering result",
    "descriptor": "\nComments: 11 pages, LIPIcs format, changes: fixed typos, added vector bin covering result\n",
    "authors": [
      "Arka Ray"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.13362"
  },
  {
    "id": "arXiv:2104.14132",
    "title": "Generalization Guarantees for Neural Architecture Search with  Train-Validation Split",
    "abstract": "Comments: to appear in ICML 2021",
    "descriptor": "\nComments: to appear in ICML 2021\n",
    "authors": [
      "Samet Oymak",
      "Mingchen Li",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14132"
  },
  {
    "id": "arXiv:2104.14272",
    "title": "Current Status and Performance Analysis of Table Recognition in Document  Images with Deep Neural Networks",
    "abstract": "Comments: 23 pages, 14 figures",
    "descriptor": "\nComments: 23 pages, 14 figures\n",
    "authors": [
      "Khurram Azeem Hashmi",
      "Marcus Liwicki",
      "Didier Stricker",
      "Muhammad Adnan Afzal",
      "Muhammad Ahtsham Afzal",
      "Muhammad Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14272"
  },
  {
    "id": "arXiv:2104.14362",
    "title": "From Distributed Machine Learning to Federated Learning: A Survey",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Ji Liu",
      "Jizhou Huang",
      "Yang Zhou",
      "Xuhong Li",
      "Shilei Ji",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14362"
  },
  {
    "id": "arXiv:2104.14365",
    "title": "On the Design and Analysis of Multivariable Extremum Seeking Control  using Fast Fourier Transform",
    "abstract": "On the Design and Analysis of Multivariable Extremum Seeking Control  using Fast Fourier Transform",
    "descriptor": "",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.14365"
  },
  {
    "id": "arXiv:2104.14755",
    "title": "Technology Report : Robotic Localization and Navigation System for  Visible Light Positioning and SLAM",
    "abstract": "Comments: This is a technology report from Guan Weipeng's work in HKUST",
    "descriptor": "\nComments: This is a technology report from Guan Weipeng's work in HKUST\n",
    "authors": [
      "Weipeng Guan",
      "Babar Hussain",
      "Patrick Yue"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.14755"
  },
  {
    "id": "arXiv:2104.14763",
    "title": "ICOS: Efficient and Highly Robust Rotation Search and Point Cloud  Registration with Correspondences",
    "abstract": "ICOS: Efficient and Highly Robust Rotation Search and Point Cloud  Registration with Correspondences",
    "descriptor": "",
    "authors": [
      "Lei Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14763"
  },
  {
    "id": "arXiv:2104.14839",
    "title": "The Factual Inconsistency Problem in Abstractive Text Summarization: A  Survey",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Yichong Huang",
      "Xiachong Feng",
      "Xiaocheng Feng",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.14839"
  },
  {
    "id": "arXiv:2104.14852",
    "title": "NTIRE 2021 Challenge on Video Super-Resolution",
    "abstract": "Comments: An official report for NTIRE 2021 Video Super-Resolution Challenge, in conjunction with CVPR 2021",
    "descriptor": "\nComments: An official report for NTIRE 2021 Video Super-Resolution Challenge, in conjunction with CVPR 2021\n",
    "authors": [
      "Sanghyun Son",
      "Suyoung Lee",
      "Seungjun Nah",
      "Radu Timofte",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14852"
  },
  {
    "id": "arXiv:2104.14962",
    "title": "PSEUDo: Interactive Pattern Search in Multivariate Time Series with  Locality-Sensitive Hashing and Relevance Feedback",
    "abstract": "Comments: 11 pages including 2 pages for references, 10 figures including 1 teaser figure, sumbitted to IEEE VIS 2021, gitlab repository this https URL",
    "descriptor": "\nComments: 11 pages including 2 pages for references, 10 figures including 1 teaser figure, sumbitted to IEEE VIS 2021, gitlab repository this https URL\n",
    "authors": [
      "Yuncong Yu",
      "Dylan Kruyff",
      "Tim Becker",
      "Michael Behrisch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.14962"
  },
  {
    "id": "arXiv:2105.00231",
    "title": "Normalization of regressor excitation as a part of dynamic regressor  extension and mixing procedure",
    "abstract": "Comments: 13 pages, 3 figures",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Vladislav Petrov",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.00231"
  },
  {
    "id": "arXiv:2105.00277",
    "title": "Multi-view Clustering via Deep Matrix Factorization and Partition  Alignment",
    "abstract": "Multi-view Clustering via Deep Matrix Factorization and Partition  Alignment",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Siwei Wang",
      "Jiyuan Liu",
      "Sihang Zhou",
      "Pei Zhang",
      "Xinwang Liu",
      "En Zhu",
      "Changwang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.00277"
  },
  {
    "id": "arXiv:2105.00305",
    "title": "Time-periodic steady-state solution of fluid-structure interaction and  cardiac flow problems through multigrid-reduction-in-time",
    "abstract": "Comments: 28 pages; 7 pages Supplementary Materials",
    "descriptor": "\nComments: 28 pages; 7 pages Supplementary Materials\n",
    "authors": [
      "Andreas Hessenthaler",
      "Robert D. Falgout",
      "Jacob B. Schroder",
      "Adelaide de Vecchi",
      "David Nordsletten",
      "Oliver R\u00f6hrle"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.00305"
  },
  {
    "id": "arXiv:2105.00405",
    "title": "PAN++: Towards Efficient and Accurate End-to-End Spotting of  Arbitrarily-Shaped Text",
    "abstract": "Comments: Accepted to TPAMI 2021",
    "descriptor": "\nComments: Accepted to TPAMI 2021\n",
    "authors": [
      "Wenhai Wang",
      "Enze Xie",
      "Xiang Li",
      "Xuebo Liu",
      "Ding Liang",
      "Zhibo Yang",
      "Tong Lu",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00405"
  },
  {
    "id": "arXiv:2105.00542",
    "title": "Kubernetes Autoscaling: YoYo Attack Vulnerability and Mitigation",
    "abstract": "Comments: Paper contains 14 pages, 4 figures. This paper was presented in CLOSER 2021 conference on April 28,2021. CLOSER 2021 is the 11th International Conference on Cloud Computing and Services Science, which was organized by INSTICC. The paper is available soon at SCITEPRESS Digital Library",
    "descriptor": "\nComments: Paper contains 14 pages, 4 figures. This paper was presented in CLOSER 2021 conference on April 28,2021. CLOSER 2021 is the 11th International Conference on Cloud Computing and Services Science, which was organized by INSTICC. The paper is available soon at SCITEPRESS Digital Library\n",
    "authors": [
      "Ronen Ben David",
      "Anat Bremler Barr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.00542"
  },
  {
    "id": "arXiv:2105.00562",
    "title": "Personalized Federated Learning by Structured and Unstructured Pruning  under Data Heterogeneity",
    "abstract": "Personalized Federated Learning by Structured and Unstructured Pruning  under Data Heterogeneity",
    "descriptor": "",
    "authors": [
      "Saeed Vahidian",
      "Mahdi Morafah",
      "Bill Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00562"
  },
  {
    "id": "arXiv:2105.00579",
    "title": "BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning",
    "abstract": "BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Lun Wang",
      "Zaynah Javed",
      "Xian Wu",
      "Wenbo Guo",
      "Xinyu Xing",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00579"
  },
  {
    "id": "arXiv:2105.00613",
    "title": "A C++17 Thread Pool for High-Performance Scientific Computing",
    "abstract": "Comments: 15 pages, source code available at this https URL",
    "descriptor": "\nComments: 15 pages, source code available at this https URL\n",
    "authors": [
      "Barak Shoshany"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00613"
  },
  {
    "id": "arXiv:2105.00761",
    "title": "Lower Bounds on the Time/Memory Tradeoff of Function Inversion",
    "abstract": "Comments: A preliminary version appeared in TCC 2020",
    "descriptor": "\nComments: A preliminary version appeared in TCC 2020\n",
    "authors": [
      "Dror Chawin",
      "Iftach Haitner",
      "Noam Mazor"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00761"
  },
  {
    "id": "arXiv:2105.00767",
    "title": "Mean Field Equilibrium in Multi-Armed Bandit Game with Continuous Reward",
    "abstract": "Comments: IJCAI 2021",
    "descriptor": "\nComments: IJCAI 2021\n",
    "authors": [
      "Xiong Wang",
      "Riheng Jia"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00767"
  },
  {
    "id": "arXiv:2105.00770",
    "title": "Channels of Small Log-Ratio Leakage and Characterization of Two-Party  Differentially Private Computation",
    "abstract": "Comments: A preliminary version appeared in TCC 2019",
    "descriptor": "\nComments: A preliminary version appeared in TCC 2019\n",
    "authors": [
      "Iftach Haitner",
      "Noam Mazor",
      "Ronen Shaltiel",
      "Jad Silbak"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00770"
  },
  {
    "id": "arXiv:2105.00981",
    "title": "Russian News Clustering and Headline Selection Shared Task",
    "abstract": "Comments: Submitted to Dialogue 2021 conference",
    "descriptor": "\nComments: Submitted to Dialogue 2021 conference\n",
    "authors": [
      "Ilya Gusev",
      "Ivan Smurov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.00981"
  },
  {
    "id": "arXiv:2105.01108",
    "title": "Consistent Density Estimation Under Discrete Mixture Models",
    "abstract": "Comments: Reason for withdrawal: There is an issue with the proof of Theorem~1",
    "descriptor": "\nComments: Reason for withdrawal: There is an issue with the proof of Theorem~1\n",
    "authors": [
      "Luc Devroye",
      "Alex Dytso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.01108"
  },
  {
    "id": "arXiv:2105.01740",
    "title": "Reduced order models from computed states of physical systems using  non-local calculus on finite weighted graphs",
    "abstract": "Comments: 72 pages, 19 figures",
    "descriptor": "\nComments: 72 pages, 19 figures\n",
    "authors": [
      "Matthew Duschenes",
      "Krishna Garikipati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.01740"
  },
  {
    "id": "arXiv:2105.01963",
    "title": "One-way communication complexity and non-adaptive decision trees",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Nikhil S. Mande",
      "Swagato Sanyal"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.01963"
  },
  {
    "id": "arXiv:2105.01995",
    "title": "Rare Disease Identification from Clinical Notes with Ontologies and Weak  Supervision",
    "abstract": "Rare Disease Identification from Clinical Notes with Ontologies and Weak  Supervision",
    "descriptor": "",
    "authors": [
      "Hang Dong",
      "V\u00edctor Su\u00e1rez-Paniagua",
      "Huayu Zhang",
      "Minhong Wang",
      "Emma Whitfield",
      "Honghan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.01995"
  },
  {
    "id": "arXiv:2105.02083",
    "title": "AdaBoost and robust one-bit compressed sensing",
    "abstract": "Comments: 26 pages, 4 figures, code available at this https URL",
    "descriptor": "\nComments: 26 pages, 4 figures, code available at this https URL\n",
    "authors": [
      "Geoffrey Chinot",
      "Felix Kuchelmeister",
      "Matthias L\u00f6ffler",
      "Sara van de Geer"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02083"
  },
  {
    "id": "arXiv:2105.02352",
    "title": "Uniqueness typing for intersection types",
    "abstract": "Comments: Superseded by arXiv:1809.08169v2",
    "descriptor": "\nComments: Superseded by arXiv:1809.08169v2\n",
    "authors": [
      "Richard Statman",
      "Andrew Polonsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.02352"
  },
  {
    "id": "arXiv:2105.02395",
    "title": "Weighted Sum-Rate Maximization for Multi-Hop RIS-Aided Multi-User  Communications: A Minorization-Maximization Approach",
    "abstract": "Weighted Sum-Rate Maximization for Multi-Hop RIS-Aided Multi-User  Communications: A Minorization-Maximization Approach",
    "descriptor": "",
    "authors": [
      "Zepeng Zhang",
      "Ziping Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.02395"
  },
  {
    "id": "arXiv:2105.02412",
    "title": "Handwritten Mathematical Expression Recognition with Bidirectionally  Trained Transformer",
    "abstract": "Comments: Accept by ICDAR 2021",
    "descriptor": "\nComments: Accept by ICDAR 2021\n",
    "authors": [
      "Wenqi Zhao",
      "Liangcai Gao",
      "Zuoyu Yan",
      "Shuai Peng",
      "Lin Du",
      "Ziyin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02412"
  },
  {
    "id": "arXiv:2105.02431",
    "title": "Inverting Generative Adversarial Renderer for Face Reconstruction",
    "abstract": "Comments: cvpr2021 oral",
    "descriptor": "\nComments: cvpr2021 oral\n",
    "authors": [
      "Jingtan Piao",
      "Keqiang Sun",
      "KwanYee Lin",
      "Quan Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02431"
  },
  {
    "id": "arXiv:2105.02579",
    "title": "MCMC-driven importance samplers",
    "abstract": "MCMC-driven importance samplers",
    "descriptor": "",
    "authors": [
      "F. Llorente",
      "E. Curbelo",
      "L. Martino",
      "V. Elvira",
      "D. Delgado"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02579"
  },
  {
    "id": "arXiv:2105.02646",
    "title": "Cascade Image Matting with Deformable Graph Refinement",
    "abstract": "Cascade Image Matting with Deformable Graph Refinement",
    "descriptor": "",
    "authors": [
      "Zijian Yu",
      "Xuhui Li",
      "Huijuan Huang",
      "Wen Zheng",
      "Li Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02646"
  },
  {
    "id": "arXiv:2105.02751",
    "title": "On the Ethical Limits of Natural Language Processing on Legal Text",
    "abstract": "Comments: Accepted at ACL Findings 2021",
    "descriptor": "\nComments: Accepted at ACL Findings 2021\n",
    "authors": [
      "Dimitrios Tsarapatsanis",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.02751"
  },
  {
    "id": "arXiv:2105.02927",
    "title": "Securing Parallel-chain Protocols under Variable Mining Power",
    "abstract": "Comments: 26 pages, 18 figures. A shorter version of this paper will appear in the 2021 ACM Conference on Computer and Communications Security (CCS)",
    "descriptor": "\nComments: 26 pages, 18 figures. A shorter version of this paper will appear in the 2021 ACM Conference on Computer and Communications Security (CCS)\n",
    "authors": [
      "Xuechao Wang",
      "Viswa Virinchi Muppirala",
      "Lei Yang",
      "Sreeram Kannan",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.02927"
  },
  {
    "id": "arXiv:2105.02968",
    "title": "This Looks Like That... Does it? Shortcomings of Latent Space Prototype  Interpretability in Deep Networks",
    "abstract": "This Looks Like That... Does it? Shortcomings of Latent Space Prototype  Interpretability in Deep Networks",
    "descriptor": "",
    "authors": [
      "Adrian Hoffmann",
      "Claudio Fanconi",
      "Rahul Rade",
      "Jonas Kohler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02968"
  },
  {
    "id": "arXiv:2105.03310",
    "title": "Context-Based Soft Actor Critic for Environments with Non-stationary  Dynamics",
    "abstract": "Comments: 12 pages, 11 figures",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Yuan Pu",
      "Shaochen Wang",
      "Xin Yao",
      "Bin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03310"
  }
]